<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 20 Dec 2020 08:37:13 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 20 Dec 2020 08:37:13 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to Host a CTF?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25465131">thread link</a>) | @henrikwm
<br/>
December 18, 2020 | https://security.christmas/2020/18 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/18">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><h2>How it all began</h2>
<p>I'm a huge proponent of Capture The Flag competitions, and I've been involved in the CTF scene since my university days. Lucky for me, there was a CTF club at the University of Oslo. I've always been curious about hacking and the club quickly caught my attention. The club formerly known as UiO CTF (now Oslo CTF) organized workshops and competitions. Soon enough I was a dedicated member of the group and was heavily involved in organizing both competitions and workshops. One of my fondest memories is when we hosted an on-campus CTF with over 80 attendees, and we called a large Norwegian pizza restaurant chain requesting pizza for 80 people. The pizza place wasn't too happy, but they delivered while the head of the security department's jaw dropped when figured out that the department had to pay for 80 peoples worth of pizza. We had an absolute blast.</p>
<h2>Challenges</h2>
<p> of the CTF Club
Hosting a CTF is a challenge in itself, infrastructure is hard. Especially while being an inexperienced student. The hosting infrastructure has gone through a few revisions during my time with the club. It started out very manual. Spinning up a virtual machine and deploying every task individually, configuring certificates manually with nginx. Everything hosted using the free credits you get, when signing up for a Google Cloud Platform account. It worked, but it was a pain. The next evolution of the platform was the use of containers. Every task had its own container, and it made starting the challenges easier. My friend ended up writing a bash script for starting everything. We finally had some degree of automation, and we kept working on the platform. More and more scripts were written. We had a script for pulling the challenges from GitHub, one for starting everything, and another for modifying nginx configurations files to set up TLS certificates and subdomains, and another for setting up <a href="https://github.com/CTFd/CTFd">CTFd</a>. In the end, we ended up with a hack job of epic proportions which consisted of several python and bash scripts. It was getting out of hand, and it became excruciatingly unmaintainable, but it did the job.</p>
<h2>Still in the game</h2>
<p>I graduated with a master’s degree in Computer Science with a heavy focus on Information Security and remained involved with the CTF club post-graduation. Real life awaited me and joined Bekk as a consultant in 2019. Soon enough I became involved with the security group at Bekk. The new direction of the security group was to improve security skills and knowledge through the use of CTF-challenges and wargames. The timing could not have been better, and I felt that I could bring something valuable to the group as a whole given my CTF experience. The security group also provides internal and external services. Security consulting, workshops, and so on.</p>
<h2>The Pandemic</h2>
<p>Covid19 hit like a brick, chaos emerged, the S&amp;P 500 tanked, and the Bekk recruitment apparatus had to pivot quickly in order. Company presentations at universities and colleges were no longer possible, thus emerged project Pangea. The goal was an online platform consisting of multiple presentations, articles, activities, and competitions. Every part of Bekk was encouraged to contribute, and I got a request for organizing a CTF. I was excited, and I grossly underestimated the time and effort needed to pull it all together. I could have just reused the stuff we had made during the time at Oslo-CTF, but it didn't feel right, since I didn't technically own it, so I started working on my own infrastructure. Oh boy, how I grossly underestimated the time and effort needed to pull this thing off.</p>
<h2>Chasing clouds</h2>
<p>I dug out a few tasks I had made in the past and started working on quite a few new ones. This was the "easy" part, the challenge was the infrastructure. As I was comfortable with Google Cloud Platform, I picked GCP as my cloud provider. The first thing I looked at was Google Cloud Run, a really neat serverless service. Dockerize the challenge, deploy, and only pay when the container is processing incoming and outgoing traffic. It seemed too good to be true, and unfortunately, it was. I had this odd edge case, where quite a few challenges required interaction over raw TCP. The problem was that Cloud Run requires apps that communicate over HTTP, so back to the drawing board I went. The next obvious choice was Google Compute Engine, a virtual machine.</p>
<h2>Automation Nation</h2>
<p>Since every challenge was a docker container, in addition to there being a docker image for CTFd I ended up putting it all into a docker-compose file. Now I could easily start every challenge rapidly, but I still had the issue of setting up subdomains and TLS certificates. I had used nginx in the past, but as I started configuring, I soon realized that it would be far too tedious to do manually. There had to be a better way, and there was.
After some intense research, I discovered Traefik. Traefik was a total game-changer, if only we had known about this back in my university days. It could do subdomains, service discovery, certificates, and routing. Again, it seemed almost too good to be true, but luckily for me, this time it turned out to be to be the missing piece to the puzzle.</p>
<h2>The Missing Piece</h2>
<p>Traefik was a little finicky to begin with, with their documentation was somewhat lacking in examples. Especially when it came to the business of issuing certificates. I wanted to issue a wild card certificate, but there weren't good any examples in the documentation on how to do this. Secondly, my domain provider didn't even support wild card certs in with their DNS service. Cloudflare came to the rescue. It was free, and very straight forward to set up. Quite a few StackOverflow threads later, I finally figured out how to accomplish what I wanted to achieve. This was the final piece of my infrastructure puzzle. Traefik, CTFd, and the challenges all bundled together in a docker-compose file. One <code>docker-compose up -d</code> later, and I was good to go. All though I did mess things up by repeatedly deleting a folder containing certificates causing my infrastructure to request way too many certs from Let's Encrypt and having to change the subdomains of multiple challenges, it was overall a great success. I managed to pull it all together before the deadline. Hours of hard work and research finally paid off. The CTF was a success and ran without any major hiccups.</p>
<h2>Future Improvements</h2>
<p>My new platform is by no means perfect, and there are some things I wish were different. Like having a proper CI/CD pipeline for deploying the challenges. I don't think my setup will scale very well, and I wish to introduce proper container orchestration with Kubernetes in the future. At least it fits my current needs and is way more modular and reusable than it has ever been. I've put down hours and hours of work, and I have learned so much about so many new things throughout the whole process. It has ultimately been a rewarding experience. This may not be the best way to host a CTF. I don't even know if it a good way to host CTF, but this has been how I host a CTF.</p>
<h2>Onwards and upwards!</h2>
<p>I started out with a total mess and ended up with something I can live with, and it suits my current needs. It's easy to set up, and it does the job. Hopefully, this may be of some use if you ever plan on host a CTF for your friends, colleagues, or CTF club. There are several improvements to be made, and I'll keep hacking at it when I find the time. The dream is to build a platform that can be set up with a click in a matter of seconds at the click of a button, but there's a long way to go, and a bumpy road ahead. The current rig probably won't survive over 9000 hackers, but it has survived 30 hackers with great ease. </p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/18</link>
            <guid isPermaLink="false">hacker-news-small-sites-25465131</guid>
            <pubDate>Fri, 18 Dec 2020 08:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to find contextually relevant link opportunities]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25464356">thread link</a>) | @jbsingh
<br/>
December 17, 2020 | https://tabtimize.com/how-to-find-contextually-relevant-link-opportunities/ | <a href="https://web.archive.org/web/*/https://tabtimize.com/how-to-find-contextually-relevant-link-opportunities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
	
<p>It’s actually quite simple.</p>



<p><strong>Just follow the list below and you’ll be well on your way:</strong></p>



<ol><li>Enter the keyword/topic into Google you want to find link opportunities for.</li><li>Open each result in a new tab.</li><li>Read through all the pages and make an educated guess where on the page it might make sense to get a link from.</li><li>Save each relevant link opportunity in a spreadsheet, with the URL, related keywords/topic, where on the page the link should be linked from, and an anchor text.</li><li>If you want to reach out to these link opportunities, then you must also find one or more relevant email addresses of the people you want to get in touch with.</li><li>To make sure you have the correct contact information, just cross-reference it on any social media platform, preferably LinkedIn, to see if it’s correct.</li></ol>







<p>Repeat steps 1-6 at least hundreds to thousands of times, to make sure that, statistically, you have high enough chances of getting any contextually relevant links.</p>



<p>There must be a better way, right?</p>



<p><strong>Thankfully yes</strong>, and that’s what we’re going to talk about in this post. But before we get into it, let’s look at the numbers behind the “traditional” way of finding RLOs (relevant link opportunities). Prepare to be surprised.</p>







<h2>How long does it take to find contextually relevant link opportunities?</h2>



<p>The “traditional” 6 step approach is an excellent way to get started building contextually relevant backlinks, but it’s definitely a time consuming and mentally draining practice. In fact, this method takes around<strong> 4 minutes on average per link opportunity</strong>, not including the time it takes to do your own keyword/topic analysis and outreach.</p>



<p>Below is a basic example where I try to find relevant link opportunities for a blog on cats. The topic is cat nutrition. Doing steps 1-6 took me <strong>3 minutes and 45 seconds</strong>.</p>







<figure><img loading="lazy" width="600" height="647" src="https://tabtimize.com/wp-content/uploads/2020/11/4-minutes-gif-of-link-opportunity.gif" alt="How long does it take to find contextually link opportunities?"></figure>







<p>With an average hit rate between 3-5% (sources <a rel="noreferrer noopener nofollow" href="https://www.robbierichards.com/seo/13-killer-link-building-strategies/" target="_blank">1</a> &amp; <a rel="noreferrer noopener nofollow" href="https://moz.com/blog/link-building-rules" data-type="URL" data-id="https://moz.com/blog/link-building-rules" target="_blank">2</a>), you will be able to <strong>get a backlink every 1 hour and 20 minutes</strong> at best, and only with the use of automated outreach software. Just think <strong>what it will take to beat the top 5 spots in SERP</strong> for your niche in terms of the number of backlinks… </p>



<p>Now I do not know your specific competitors or niche, but I would assume that it will take you a lot more time than you’d ideally like to spend.</p>



<p>For example, it will take <strong>133.33 hours to build 100 links</strong> on average.</p>



<p>Here is how its calculated:</p>



<p>(100 (number of backlinks) * 80 (the average number of minutes to build 1 backlink)) / 60 (number of minutes per hour) = 133.33 hours.</p>



<p>Want to find out how many hours getting as many backlinks as your competitors will take?</p>



<p>Try it out for yourself in the calculator below:</p>







<div>   
<p>Number of backlinks: </p>
        
<p>The average number of hours it will take to get them: </p>
        <br></div>
        







<h2>The better way to find contextually relevant link opportunities</h2>



<p>We now come to what you have been waiting for, the easiest way to find contextually relevant link opportunities.</p>



<p>Artificial intelligence is becoming a norm in almost everyone’s day to day life. Smart speakers, smart cars, and smart ‘anything’ that make our lives that much easier. So why should it be so ridiculously time-consuming to find contextually relevant link opportunities?</p>



<p>Fortunately for all of us, there is now a much (and I mean <em>much</em>) easier way to find relevant link opportunities.</p>



<p>Luckily, you also do not have to go very far to find the easy way. It’s all inside the <strong>Link Opportunity feature</strong>, which you can find under the ‘Backlink Engine’ menu on Tabtimize.</p>







<figure><img loading="lazy" width="791" height="252" src="https://tabtimize.com/wp-content/uploads/2020/11/Screenshot-of-link-opportunity-feature.png" alt="The Link Opportunity feature" srcset="https://tabtimize.com/wp-content/uploads/2020/11/Screenshot-of-link-opportunity-feature.png 791w, https://tabtimize.com/wp-content/uploads/2020/11/Screenshot-of-link-opportunity-feature-300x96.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/Screenshot-of-link-opportunity-feature-768x245.png 768w" sizes="(max-width: 791px) 100vw, 791px"></figure>







<p>The Link Opportunity feature does all the hard work for you.</p>



<p>It reads the main content of web pages and analyzes the content with many different NLP models. It finds various essential data about the content, such as keywords, topics, contextual understanding, semantic understanding, and more. With all that data, the machine can find a contextual connection between all pages in the database and only match the relevant ones.</p>



<p>Also, it uses a relevance metric (<a rel="noreferrer noopener" href="https://tabtimize.com/link-relevance-score/" data-type="post" data-id="44" target="_blank">Link Relevance Score or LRS</a>) that quantifies the relevance analysis between two pages so that you can understand the degree of relevance between them.</p>







<figure><img loading="lazy" src="https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-1024x421.png" alt="The Link Opportunity feature view of all the relevant link opportunities" width="580" height="238" srcset="https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-1024x421.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-300x123.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-768x316.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-1536x632.png 1536w, https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view.png 1627w" sizes="(max-width: 580px) 100vw, 580px"></figure>







<p>This basically means that the machine will do everything for you in terms of determining if a page is relevant to yours. You can also use the LRS metric to compare and sort link opportunities by the degree of contextual relevance they have to your page.</p>







<h2>But what about the anchor text?</h2>



<p>The anchor text is usually always mentioned as an essential part of understanding what a link refers to. In other words, the anchor text must tell both the users and Google what the content of that link is about. This helps users and Google to determine if the link is relevant to follow.</p>



<p>Therefore, one of the most important tasks in finding relevant link opportunities is also deciding on an anchor text.</p>



<p>Fortunately, this is also something that the Backlink Engine takes into account in its two-page relevance match. In each link opportunity result, you can see a short snippet of a text containing one or more “links” with blue marking. It symbolizes a possible anchor text that can be used If these two pages are to be linked with each other.</p>







<figure><img loading="lazy" width="1024" height="333" src="https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3-1024x333.png" alt="relevant anchor text of a link opportunity " srcset="https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3-1024x333.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3-300x98.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3-768x250.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3.png 1247w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>So not only does it read and link the pages by keyword, topic, and semantic relevance, but the machine also suggests anchor texts for you. Basically, there’s nothing you have to do (manually) to analyze the relevance of the pages.</p>



<p>Okay, a text savvy machine that can link relevant pages to my page, I get that, but what about the whole personalization thing and finding the right contact information?</p>







<h2>Getting the right contact information, the AI way</h2>



<p>When you find the page or pages you want to contact to get a link from in the Link Opportunities feature, you have the possibility to simply click on the green plus icon and select the “request link” button. The machine not only handles the task of finding the right contact information, but it has actually just done the outreach for you too, and eliminating the need for a pitch.</p>







<figure><img loading="lazy" width="1024" height="494" src="https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon-1024x494.png" alt="request a link from a relevant link opportunity" srcset="https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon-1024x494.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon-300x145.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon-768x371.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon.png 1225w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Requesting a link in the Link Opportunities feature</figcaption></figure>



<figure><img loading="lazy" width="1024" height="219" src="https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-1024x219.png" alt="link building management made easy " srcset="https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-1024x219.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-300x64.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-768x164.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-1536x329.png 1536w, https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status.png 1589w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Keep track for your outreach in the Link Community feature</figcaption></figure>







<p>However, if you want to do the outreach yourself, you can always add the opportunities to a list, export them to a CSV file, and do the outreach by yourself.</p>







<figure><img loading="lazy" width="1024" height="153" src="https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-1024x153.png" alt="mass export contextually relevant link opportunities" srcset="https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-1024x153.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-300x45.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-768x114.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-1536x229.png 1536w, https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view.png 1564w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>How does Tabtimize know what the right contact information is? That’s a secret, but one thing is for sure, this method will save you many, <em>many</em> hours of work!</p>



<p>You can actually find out just how many hours it would take to build the same amount of backlinks as your competitors by entering the number of backlinks that you entered in the first calculator in the “number of backlinks” field below.&nbsp;</p>







<div>   
<p>Number of backlinks: </p>
        
<p>The average number of hours it will take with Tabtimize: </p>
        <br></div>
        







<p>How did we calculate it?:</p>



<p>((number of entered backlinks) * 0,5 (the average number of minutes to build 1 backlink with Tabtimize)) / 60 (number of minutes per hour) = XX hours.</p>



<p><strong>An average time-saving percentage of 99.38%</strong> compared to the “traditional” way. Neat right?</p>







<h2>Get your contextual relevant link opportunities without the hassle</h2>



<p>Whether you want to do all the link building yourself, taking on all the hassle that comes with the research, outreach, and link building management, or whether you just want to do one of the ways yourself, link building is still an ultra time-consuming process. Making the process smarter will save you a lot of time and energy, and ensure your efforts aren’t wasted.</p>



<p>For the majority of us, it’s easy to see the benefit of using the Tabtimize method to find contextually relevant link opportunities. Who wouldn’t want to save 99% of their valuable time finding relevant link opportunities, right?&nbsp; It’s all about working smarter, not necessarily harder.&nbsp;</p>



<p>Did you know, it’s completely free to sign up for Tabtimize and start building contextually relevant link opportunities right away?&nbsp;</p>



<p>Click below to check it out:</p>



<p><a href="https://tabtimize.com/link-community-waiting-list/">Get contexutally relevant link opportunities</a></p>



<h2>Final thoughts</h2>



<p>You can save a lot of time if you use the right tools and methods to find and build contextually relevant backlinks. Over 99% (99.38% to be exact) of the time you spend on traditional link building research, can be simplified by using Tabtimize’s Link Opportunities feature. If you also use a smart tool to find content gaps and other content-creating options then you will be able to further optimize your time and efficiency.</p>



<p>I’m curious about other methods to find relevant link opportunities, so if you have a method you think is worth sharing, feel free to include it in the comments below.</p>

</div></div>]]>
            </description>
            <link>https://tabtimize.com/how-to-find-contextually-relevant-link-opportunities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25464356</guid>
            <pubDate>Fri, 18 Dec 2020 06:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Changing one sentence led to 2.5x more reviews]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25464326">thread link</a>) | @dhruvkar
<br/>
December 17, 2020 | https://www.wints.org/blog/2020.12.17/ | <a href="https://web.archive.org/web/*/https://www.wints.org/blog/2020.12.17/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>
    <h3>How Changing One Sentence led to 2.5x more Reviews</h3>
    
        <h6>December 17, 2020</h6>
    
    </p>
  </div><div>
    <div>
		<p><strong><u>June 2019</u></strong><br>
Fifteen years in business and we had a measly three reviews on Google.</p>
<p>Sigh.</p>
<p>I reminded myself that this is <em>exactly</em> why I moved back from the Bay area to work on the family business – to use technology to expand. Let’s fix this!</p>
<figure>
    <img src="https://www.wints.org/img/articles/2020.12.17/2.stoneland-reviews-dec-2019.jpg" alt="Stoneland Reviews December 2020" width="60%"> 
</figure>

<p>I’d read somewhere that people are most willing to review right after their experience – good or bad.
I’d been itching to use Twilio, and this was the perfect use case!
Our inside sales person saves a visitor’s contact information right after a visitor leaves. Their phone number is included in this.</p>
<p>So, June 2019 I wrote a python script that sent an SMS to the visitor an 1 hour after they left. The SMS said:</p>
<div>
	<div>
<blockquote><small><i>If you enjoyed your visit (or didn't), please let us know how we did!<br>http://bit.ly/stoneland-google-stl <br>-Stoneland Team</i></small></blockquote>
</div>
</div>
<p>I thought it was pretty slick, getting the URL, a cohesive message and proper formatting into one SMS.</p>
<p>At the same time, our sales team made a push to get reviews by emailing old customers.</p>
<p><strong><u>December 2019</u></strong><br>
We have 18 reviews now! While a big improvement over the last 15 years, it was still far below our competition.
And most of the reviews were in September when our sales team made the push. Now the trickle had dried up.</p>
<p>I’d been reading and listening to a lot of <a href="https://www.indiehackers.com/">Indiehackers</a>, especially interviews with founders who were marketing specialists. After ingesting Indiehacker nuggets, I settled on changing one factor at a time to understand what drove reviews.</p>
<p>In January 2020, I tweaked the copy of the SMS to read:</p>
<div>
	<div>
<blockquote><small><i>If you enjoyed your visit, leave us a 5 second rating!<br>http://bit.ly/stoneland-google-stl<br>-Stoneland Team</i></small></blockquote></div></div>
<p><strong><u>December 2020</u></strong><br>
That tiny change made all the difference! As of December 15, 2020, we have <strong>93 reviews</strong> with a 4.9 rating!
We’ve outstripped all our competitors in the area, as well as several of our customers.</p>
<p>Bottom line? Copywriting matters.</p>
<figure>
    <img src="https://www.wints.org/img/articles/2020.12.17/1.stoneland-reviews-dec-2020.jpg" alt="Stoneland Reviews December 2020" width="60%"> 
</figure>

<p>P.S. For anyone wondering about the math around ‘2.5x’, here’s the breakdown:</p>
<ul>
<li>June 2019 - December 2020 (~6 months): 15 reviews</li>
<li>Extrapolated over 12 months: 30 reviews</li>
<li>January 2020 - December 2020 (~12 months): 75 reviews</li>
</ul>
<p><span>75/30 = <strong>2.5</strong></span></p>

	</div>
  </div></div>]]>
            </description>
            <link>https://www.wints.org/blog/2020.12.17/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25464326</guid>
            <pubDate>Fri, 18 Dec 2020 06:00:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding Composite Video to a Famicom]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25463627">thread link</a>) | @todsacerdoti
<br/>
December 17, 2020 | https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html | <a href="https://web.archive.org/web/*/https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Since I’ve been reading <a href="https://mitpress.mit.edu/books/i-am-error"><em>I Am Error</em></a>, I’ve been getting more and more interested in the technical aspects of the Famicom. Turns out all you really need to get me interested in your console is prose explanations of how a pattern table works. Also, I get to drip some molten lead into it so I can use a modern TV! Everyone wins.</p>

<p>When I was growing up, a lot of my friends had an NES, but I first had the ColecoVision and then a “Model 2” Sega Genesis when that came out. As a result, I’ve gone the last few decades thinking the NES was full of branded shovelware, because it turns out that’s <a href="https://www.youtube.com/watch?v=MzJ0M-erXAM">the exact kind of game that eight year old boys bought a lot of and then subjected their friends to</a>.</p>

<p>Later, when I was getting interested in collecting old videogames, the NES had already started its stratospheric price rise for many games, and with it the skeeziest members of the game-price-speculator community. None of the cool modern “community” stuff existed then (NESRGB, Everdrives, FDSStick) so I gave the entire system a wide berth and decided to wait until this whole fad was over and prices returned to normal. That hasn’t happened yet… however, in Japan, stuff is still really cheap due to the massive popularity of the Famicom, and the Famicom is different enough from the NES that I’m coming at it without the same preconceptions that I had of those childhood NESes.</p>

<p>Out of the box, the original Famicom only has RF output. If you’re not familiar, <a href="https://www.youtube.com/watch?v=8sQF_K9MqpA">this video by Gravis is the best I’ve seen on how RF output works</a>, and a Nintendo is even used to make it relevant to this post.</p>

<p>Not only does the Famicom only have RF output, the Japanese channel frequencies are such that that RF output only appears on channel 95 and 96 on a Western TV, which a lot of TVs simply can’t reach. On some models, you can <a href="https://www.youtube.com/watch?v=RVyFEMg0Kpg">tweak the pots on the RF can to bring that down to US channel 6</a> to get around this. However, I wanted to play my games on a Commodore 1702 or a PVM, neither of which have an antenna tuner of any kind. Doing a composite mod seemed like the easiest way forward.</p>

<h2 id="giving-it-a-good-squint">Giving It A Good Squint</h2>
<p>The first thing I noticed is that a Famicom is a <em>lot</em> smaller than an NES. They added a bunch of empty space for the American model in order to accommodate the “toaster” mechanism, I guess.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-vs-nes.jpg" alt="A Famicom is sitting on top of an American front-loading NES, which is a spoiled Western brat and doesn't like loading cartridges."></p>

<p>I thought I would hate the hard-wired controllers, but they’re actually really nice. You’re guaranteed to always get first-party controllers when you buy a used system, which is more than I can say for basically any other machine, that NES included. It would be nice if they were in better condition, but if they work I’ll be happy.</p>

<p>There’s a “Famicom Family” logo on the front sticker that I haven’t seen on most other Famicoms; from what I can tell, this is a good way to tell what machines are later models as it ties into <a href="https://maru-chang.com/hard/hvc/english.htm">some kind of later branding</a>.</p>

<h2 id="opening-it-up">Opening It Up</h2>
<p>When mine arrived from Japan, it looked dirty and pretty beaten up, but that’s okay for a test machine. I can always get a nicer one later; another thing to hoard.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-case-damage.jpg" alt="The missing chunk of plastic near the player 1 controller slot."></p>

<p>A corner of the plastic near the player-1 controller mount was missing, and there was grit in the textured plastic. I took a few trips to the sink with the plastic and scrubbed, but the yellowing is obviously not going to come out with soap and water.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-opened.jpg" alt="The Famicom's bottom cover is opened, revealing the underside of the motherboard."></p>

<p>I opened it up - screws were tight, a good sign - and then took a look at the board. It’s a late model, as evidenced by the big power/RF module soldered to the board instead of attached by a ribbon cable.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-gross-pot.jpg" alt="There is a green potentiometer with some gunk and tree debris (seeds?) on it."></p>

<p>This console has spent some time in an old shed or something, based on how much of Mother Nature had crept inside of it, but at least I didn’t find any stray cigarettes inside it unlike the above NES. The motherboard cleaned up quickly with some spray alcohol and cotton swabs.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-1989-copyright.jpg" alt="The copyright reads © 1989 Nintendo"></p>

<p>The board is a 1989, which was a pretty good year for Nintendo. <a href="https://arstechnica.com/gaming/2013/07/time-to-feel-old-inside-the-nes-on-its-30th-birthday/3/">The Famicom apparently kept getting made until <em>2003</em></a>. It would be cool to track one of those down.</p>

<p>I wanted to deep-clean the dirty, scratched-up controllers as well - the controllers still had their protective plastic wrap on them, but they were scratched anyway! - and make sure that the silicone on the D-pads were in good shape, but I stripped one of the screws on controller 1 pretty severely in a moment of clumsiness. I’ll drill that out later and service it, but in the meantime let’s get back to the composite mod.</p>

<h2 id="motherboard-work">Motherboard Work</h2>
<p>I got sort of lucky in having a late-model board. On the later boards there’s a dedicated “video” pin that is broken out near the RF jack that I could just solder to, rather than lifting pin 21 (<a href="http://wiki.nesdev.com/w/index.php/PPU_pin_out_and_signal_description"><code>VOUT</code></a>) of the PPU. This way, you can keep both the RF and composite. Reportedly, this creates a bunch of ‘jailbar’ interference, so I’ve done what others have and lifted pin 21 of the PPU. Sometimes the hard way is the best way.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-pin21-lifted.jpg" alt="Pin 21 lifted out of the PPU. Ignore the Sharpie mark telling me which pin is 21, as if I could have forgotten"></p>

<p>This wasn’t too hard to desolder and lift, but the pin would have looked a lot less mangled if I had also desoldered R6 first to get it out of the way. I had to use a little bit too much force on my “prying tweezers” to lift it out, which could have easily broken the leg on a newer chip where the legs are much more fragile. Thanks, 80s technology!</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-decoupling-caps.jpg" alt="The axial decoupling caps are added."></p>

<p>I also added decoupling caps between 5V and GND on the CPU and PPU chips. It’s just good practice! These 0.1µF axial ceramic cuties were lying in my cap pile ever since I used a handful of them for <a href="https://www.leadedsolder.com/tag/tandy1000sx">the cursed Tandy 1000SX</a>, so I was happy to slam two more of them in. The recipe I was following used <code>/RESET</code> as the 5V source, which feels a little sketchy, but it means you don’t have to run long wires all the way to the other end of the chip. Then again, the copper pour on the back of the board <em>is</em> 5V…</p>

<p>I thought 0.1µF might be a little small, but it’s easy to change these out for a 1µF or larger cap if it doesn’t have much effect. You probably shouldn’t pick decoupling caps based on aesthetics.</p>

<h2 id="video-amplification">Video Amplification</h2>
<p>The whole idea behind the composite mod is that you’re building a simple signal amplifier to replace the one that was originally inside the RF can.</p>

<p>As the baseband video signal comes out of PPU pin 21, you need to step it up to a level that the TV can easily understand. The video chip’s output transistors are simply not designed to directly drive a television, and after the weak signal goes all the way through the AV cable into the back of the TV, there’s probably not much left to pick up anyway.</p>

<p>There are a lot of homebrew mods for this, ranging from cutting out and reusing the stock transistors on the motherboard to building a whole protoboard circuit with some new parts.</p>

<p>After doing some more research, I decided I would try a part that I’ve been meaning to try for a while, <a href="https://www.ti.com/product/THS7314">the TI THS7314 video amplifier IC</a>. It’s used a lot for <a href="https://www.retrorgb.com/thsamps.html">the amplification of analogue RGB signals</a>, and it should work really well for my one-channel signal. The part is designed specifically for this application, and should both install cleanly and produce nice-looking video.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-ths7314-board.png" alt="The prototype board as seen from KiCad. It's very simple, with only a 'video in,' 'audio in,' and 'power in' pinout which then goes to the THS7314 chip."></p>

<p>I made a quick, super-simple little board that basically just broke out the pins of the video amp chip, and sent it to fab at OSH Park. They’ve recently added free (if slow - over a month) shipping to Canada, which makes them a really desirable option for running off onesy-twosie little mod boards like this during the current shipping nightmare we find ourselves in.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-boards-osh.jpg" alt="The two variants of the board - one with the traditional &quot;homebrew amp&quot; design, and the other with the TI THS7314 video amplifier chip."></p>

<p>I made boards to do two variants, one with the original “homebrew” amplifier circuit and one with the THS7314. If the THS7314 doesn’t work out for whatever reason, I can just put in the usual circuit that the community prefers. However - spoilers - the THS7314 worked fine, so I never actually constructed the traditional design.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-v0.2-assembled.jpg" alt="The v0.2 board, assembled. A cap leg comes out of the &quot;R&quot; audio hole, and then directly around in a 180 to the &quot;L&quot; audio hole."></p>

<p>I should have added a jumper to the board to solder left and right audio together (the Famicom is monoaural.) This ugly cap leg trick should be fine for awhile. I decided on a 220µF capacitor for audio, because that’s what was on the top of the cap bin when I opened it.</p>

<h2 id="sound">Sound</h2>
<p>The Famicom supports audio coming from the cartridge, which is why Castlevania III on the Famicom has such better music than that on the NES. I definitely want to be able to hear the cartridge audio, so it’s worth pulling the audio from somewhere other than directly out of the CPU (which also contains the sound hardware – lower chip counts = more profit for Nintendo.) The “<a href="https://wiki.nesdev.com/w/index.php/Cartridge_connector">audio output</a>” pin on the cartridge contains the Famicom’s sound after it has been mixed between the expansion audio and the system audio, where it normally then travels immediately to the RF can for output. Since we’re no longer putting that audio into the RF output stream, it needs to get broken out and fed into the TV using the usual RCA jacks as well.</p>

<p>Reportedly, the GPM-02 motherboard has <a href="https://nerdlypleasures.blogspot.com/2018/01/famicom-nes-simple-tweaks-to-restore.html">a different ‘mix’ between the expansion audio and the system audio compared to the original Famicom motherboard</a>. You can revert back to the original model’s amplifier behaviour by removing the 43kΩ resistor at R7 and replacing it with a 100kΩ part.</p>

<p>I also removed the choke at FC1 on the motherboard, so that the sound didn’t go into the RF can where it might pick up other noise. To source audio, I just went from the “expansion audio” pin (#46) on the cartridge port and added a 220µF capacitor.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-gpm02-audio-mods.jpg" alt="The two audio mods done. R7 is replaced with a 100kΩ resistor that I had on hand (sorry it's so big... and backward) and FC1 is removed entirely."></p>

<p>I only had a giant 100kΩ resistor on hand, so that’s the one that went in. This bugs me more than I thought it would.</p>

<p>These changes <a href="https://www.youtube.com/watch?v=gD22orMjz48">seem to make a pretty significant impact</a>. I generally don’t have an ear for little tweaks, but this is big enough that even I can pick it out. There’s whole instruments that seem to be missing from the unmodified mix.</p>

<h2 id="getting-the-signal-out">Getting The Signal Out</h2>
<p>There’s a lot of different ways I’ve seen of actually getting the composite signal out of the Famicom and into a way that you can plug it into a TV:</p>
<ul>
  <li>Cut out the RF box’s antenna jack, and <a href="http://8bitplus.co.uk/projects/famicom-av-mod-nintendo/">replace it with a TRRS jack</a>, which carries all four signals for RCA on one jack;</li>
  <li><a href="https://www.boards.ie/vbulletin/showthread.php?t=2056561579">Drill holes in the side</a> and put in some panel-mount RCA connectors;</li>
  <li><a href="https://www.youtube.com/watch?v=ky8rFPbzGMU">Run a female or male RCA cable squid out of the case</a> (usually …</li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html">https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html</a></em></p>]]>
            </description>
            <link>https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463627</guid>
            <pubDate>Fri, 18 Dec 2020 03:54:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin: Decentralization Deserves a Chance]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25463561">thread link</a>) | @npguy
<br/>
December 17, 2020 | http://p2p.ai/2020/12/17/decentralization-deserves-a-chance/ | <a href="https://web.archive.org/web/*/http://p2p.ai/2020/12/17/decentralization-deserves-a-chance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-73">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>“In crypto, the price is the news” said a smart person on Twitter.  Today, it most definitely is. With Bitcoin blowing past 20K USD and folks in technology and finance struggling to fit narratives to price changes, it is important that in the midst of all the noise around price we don’t lose sight of a very significant and impactful paradigm shift that Bitcoin is an instance of: Decentralization.</p>



<p>The ‘Digital Gold’ narrative has given a very effective model for most of us to understand Bitcoin. But the simplicity of this model is also its curse – it mostly hides the actual promise that Bitcoin represents – that trust can indeed be decentralized, and a ‘hubless’ world is very much possible. In fact, in a digital world where we all increasingly understand that “we are the product” – a move towards such a hubless economy might be inevitable.</p>



<p>It will help to remember that Decentralization is not a discrete point in the space of how economies work, but a continuous spectrum. The most recent changes in economic models that we have witnessed (Hotel chains to AirBnB, Taxi companies to Uber) tell us that directionally, we are definitely moving towards a peer-to-peer (P2P) model for many economic functions – and while there might be attempts to decentralize most functions (very comparable to the Internet), the ones where a P2P model would be the best fit, the model will stick. Crypto (and the token model representing ownership/utility/governance) just happens to be the current transactional framework that enables such economies to function. There will be more. </p>



<p>Unfortunately, Bitcoin – the first instance of this shift – happens to address a very tricky concept: Money. The fact that many of the early cryptocurrencies that came after Bitcoin chose to just refine the concept – improving what Bitcoin did, on parameters like scalability, privacy and programmability, but still focusing on the concept of Money – brought a lot of skepticism and negative commentary to the space. Obviously, if you put anonymity and Money in the same sentence, the interpretations cannot be very positive. The 2017 ICO boom, where many players chose to ignore the regulations set by governments and organizations that oversee fundraising, added strength to the perception that decentralizing trust is not a good idea – and made many smart people both in technology and finance just stay away from Crypto.</p>



<p>So here is the one good thing that the price of Bitcoin does to the space: it brings the attention back. And while we have the attention, it is important for us to ask: If the Internet – with its promise of disintermediation – deserved a chance, if the sharing economy – with its promise of providing more economic opportunities to individuals – deserved a chance, then, with its promise of a P2P world with no hubs that might misuse our trust for profit – Decentralization Deserves a Chance?   </p>













		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>http://p2p.ai/2020/12/17/decentralization-deserves-a-chance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463561</guid>
            <pubDate>Fri, 18 Dec 2020 03:42:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur bug prevents upgrades to the next version]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25463521">thread link</a>) | @groobongithub
<br/>
December 17, 2020 | https://micromdm.io/blog/big-sur-softwareupdate/ | <a href="https://web.archive.org/web/*/https://micromdm.io/blog/big-sur-softwareupdate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><br><span>Date: Thu, Dec 17, 2020</span><br><span>Reading Time: 7 minutes</span></p><p>If you work with Apple in some capacity, you know that they’re not very likely to admit mistakes. I’m not aware of Apple publishing postmortems after outages or providing details about known issues. So it’s up to the developer and admin communities at large to help each other learn about outages and potential causes. With the release of macOS 11.1 this week I’ve been debugging a new issue with the Mac software update process, one which will affect most enterprise users. I decided I should write about it and let everyone know what the issue is, workarounds, and how to avoid it. I’ve also been paying close attention to some recent changes to the software update mechanism, so I’ll try to mention them below as well.</p><h2 id="a-macos-11-bug-prevents-upgrades-to-the-next-version">A macOS 11 bug prevents upgrades to the next version</h2><p>After macOS 11.1 was released earlier this week, many users <a href="https://twitter.com/Contains_ENG/status/1339399335298166785">started reporting</a> that they were not able to see the software update. Others reported that they saw it, but were not able to download it. I personally experienced this issue when 11.1 was in beta and filed a case with Apple about it, but then moved on to other problems. When the final release came out this week, there were widespread reports of it on the MacAdmins Slack. Reading through system logs, I as well as other admins were able to find what appears to be the root cause. <strong>Under certain conditions, macOS 11.0.1 and macOS 11.1 hosts are requesting the update server send the 11.0.1 update, instead of requesting the next available one. The server rejects this update as it’s already either installed or older.</strong> This somehow corrupts the state of the software update process, and the update is no longer visible as an option in System Preferences.</p><figure><img src="https://micromdm.io/big_sur_softwareupdate/log.jpg"></figure><h3 id="workarounds">Workarounds</h3><ul><li>The update is visible again immediately after the restart. But it’s unclear if the update can always be installed after it’s visible since the condition that made it fail to download the first time can be triggered again.</li><li>Removing the MDM enrollment profile causes the update to be seen again. I and several others tested this extensively, and it’s definitely the enrollment profile, not some other policy managed by MDM. This is obviously a terrible workaround and I’d hesitate to mention it to users as it could cause security agents to stop working, and countless approval dialogs we’re so familiar with. Not to mention some of you have the MDM enrollment profile as non-removable or users who are not administrators, so they don’t have permission to unenroll. Getting them back enrolled in the MDM might prove to be a challenge too.</li><li>Distributing the full 11.1, and eventually the 11.2 installers.</li></ul><h3 id="can-apple-fix-this-bug-without-manual-intervention">Can Apple fix this bug without manual intervention?</h3><p>Apple is well aware this is a problem now, so I am confident the issue will be addressed in 11.2. Unfortunately, it is a client-side issue affecting both 11.0.1 and 11.1 clients. So there’s not much Apple <em>can</em> do to provide a fix. One potential solution I see is for Apple to detect the wrong request and instead of rejecting the download, offer the right file archive instead. But this is a complex system and it’s unclear if the server-side changes alone are enough.</p><p>Something else Apple could try is to side load a patch through another software update. There’s background configuration and malware removal tools that are likely capable of fixing the issue on the system. But it’s an ugly hack and one I’d personally stay clear of even if the option was available.</p><p>In my opinion, the most likely outcome is that the bug will be fixed in 11.2, but clients that have already upgraded to Big Sur (or any M1 macs you might’ve bought) will have to work around the problem themselves. If we’re lucky Apple will publish a support article and that will be that.</p><h2 id="what-else-you-need-to-know">What else you need to know</h2><p>Big Sur has changed the software update mechanism entirely, especially on Apple Silicon macs. It’s a long time coming and Apple spoke about some of this at WWDC in the MDM and IT sessions, so it shouldn’t be entirely surprising. But a lot was left unsaid for us to discover on our own.</p><ul><li>Combo update packages are <a href="https://eclecticlight.co/2020/12/17/apple-has-stopped-providing-standalone-installers-for-macos-updates/">no longer published</a> on the Apple website. This might surprise many of you who rely on distributing them. The main reason is that the entire format of the updates has changed, and it’s also no longer possible to install updates without the Mac having access to the internet. The updates must come from Apple, and they must be managed by <code>softwareupdate</code> and related processes on the system.</li><li>On Apple Silicon, third party processes are no longer able to script the <code>softwareupdate</code> command. Running the software update command as a root process now prompts for the administrator password, who also needs to be a secure token user. There are only two possible options for OS updates to be applied; either the human user of the device itself or the MDM process <a href="https://support.apple.com/guide/deployment-reference-macos/using-secure-and-bootstrap-tokens-apdff2cf769b/1/web/1.0">which has special permission</a>. It might also be possible for the Mac to update itself with the auto-update mechanism, but there are too many bugs right now to observe how well that works. My personal experience is that it doesn’t and I’m greeted with a password prompt to enter the next day…</li><li>Specifying a custom URL for the <code>softwareupdate</code> process to pull updates from is no longer possible. Apple advertised this deprecation for all of last year, so it should surprise no one but it hurts. <a href="https://github.com/wdas/reposado">Reposado</a> was one of several great tools that made it possible to have unstable/beta/stable tracks within an organization.</li><li>—ignore is gone as a flag. It <a href="https://mrmacintosh.com/10-15-5-2020-003-updates-changes-to-softwareupdate-ignore/">was gone</a> in 10.15.5 briefly too, so you likely know about this one. This time it’s gone for good and never coming back. An MDM server can delay the client from seeing OS updates for up to 90 days only, but that is the absolute maximum going forward. Even for a future major release like macOS 12. If this is important to you, file feedback for Apple to provide a second deferral option, specific to major version numbers.</li></ul><p>I work with the MDM protocol a lot day-to-day and have been <a href="https://micromdm.io/blog/os_update/">testing</a> software updates for a while. I was even <a href="https://micromdm.io/blog/wwdc20-what-s-new-in-managing/">optimistic</a> about what it would look like in Big Sur back in June. Apple had promised it’s an entirely new implementation, closer to what is available on iOS and that everything would work better than before. But we’re not off to a good start, and all the concerns I had for several years now are back. The <a href="https://developer.apple.com/documentation/devicemanagement/commands_and_queries">design</a> of OS updates in MDM is brittle, requiring multiple remote procedure calls to accomplish something that was previously done by a few lines of shell scripting. And that would be bad on its own, but the bad design is coupled with a buggy implementation; there are many known issues, besides the one I described above. Unless something drastically changes, we’re likely to see many months, if not years of software update bugs that are entirely out of our control.</p><p>Apple was never particularly great at building systems for the enterprise. But, until recently, the Unix components were available for software developers and system administrators to work with. The end result ended up being that if you made an investment within your organization, macOS was a great experience for end-users. It took a lot of work, but it was all achievable. Today, Apple is no better at developing systems that are required in the enterprise. But the ball is entirely in their court. Apple still makes great tools for consumers, and there will be a demand from employees to provide them with Apple gear. But, if Apple can’t start acting on our collective feedback, the experience of using a Mac in the workplace will quickly become unbearable to most.</p></div></div></div>]]>
            </description>
            <link>https://micromdm.io/blog/big-sur-softwareupdate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463521</guid>
            <pubDate>Fri, 18 Dec 2020 03:35:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Allsorts Font Shaping Engine Year in Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25463410">thread link</a>) | @toothbrush
<br/>
December 17, 2020 | https://yeslogic.com/blog/allsorts-rust-font-shaping-engine-2020-review/ | <a href="https://web.archive.org/web/*/https://yeslogic.com/blog/allsorts-rust-font-shaping-engine-2020-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    

    <div>
      <blockquote>
<p>A year ago YesLogic open-sourced the Allsorts font parser, shaping engine,
and subsetter. In this post we cover how Allsorts has worked out in <a href="https://www.princexml.com/">Prince</a>,
what's improved over the past year, and what we're working on next.</p>
</blockquote>
<p><a href="https://github.com/yeslogic/allsorts">Allsorts</a> is a Rust crate (library) that can parse OpenType, WOFF, and WOFF2
fonts, shape text, and subset fonts<sup><a href="#1">1</a></sup>.</p>
<p>At YesLogic we've been using Allsorts to power all font parsing, shaping of
supported scripts, and subsetting in Prince since version 13 was released in November
2019. Aside from the odd small bug revealed by real-world usage and exposure to
new fonts it has proven to be capable and reliable.</p>
<p>Over the past year we've continued to work on Allsorts, adding support for
additional scripts, bitmap and SVG fonts, and refined the
API to make it easier to use.</p>
<h2 id="new-scripts">New Scripts</h2>
<p>Allsorts can now shape the Arabic and Syriac scripts giving us even more coverage of the
world's scripts.</p>
<figure>
  <img src="https://yeslogic.com/blog/allsorts-rust-font-shaping-engine-2020-review/arabic.png" width="554">
  <figcaption>
    Extract from the
    <a href="https://omniglot.com/babel/arabic.htm">Arabic translation of The Tower of Babel</a>
    shaped in Prince
  </figcaption>
</figure>
<figure>
  <img src="https://yeslogic.com/blog/allsorts-rust-font-shaping-engine-2020-review/syriac.png" width="750">
  <figcaption>
    Extract from the
    <a href="https://omniglot.com/babel/syriac.htm">Syriac translation of The Tower of Babel</a>
    shaped in Prince
  </figcaption>
</figure>
<h2 id="bitmap-and-svg-fonts">Bitmap and SVG Fonts</h2>
<p>We can now parse OpenType font tables containing bitmaps and SVGs:</p>
<ul>
<li><a href="https://docs.microsoft.com/en-us/typography/opentype/spec/cblc"><code>CBDT</code>/<code>CBLC</code></a> and <code>EBDT</code>/<code>EBLC</code>, as used by <a href="https://www.google.com/get/noto/help/emoji/">Noto Color Emoji</a>.</li>
<li><a href="https://docs.microsoft.com/en-us/typography/opentype/spec/sbix"><code>sbix</code></a>, as used by <a href="https://en.wikipedia.org/wiki/Apple_Color_Emoji">Apple Color Emoji</a>.</li>
<li><a href="https://docs.microsoft.com/en-us/typography/opentype/spec/svg"><code>SVG</code></a>, as used by <a href="https://github.com/eosrei/twemoji-color-font">Twitter Color Emoji</a>.</li>
</ul>
<p>We implemented a unified API that supports retrieving the image for a glyph
independent of the tables it originates from.</p>
<p>The bitmap and SVG support has allowed us to bring emoji and colour SVG font
support to Prince 14:</p>
<figure>
  <img src="https://yeslogic.com/blog/allsorts-rust-font-shaping-engine-2020-review/fattern-colour-svg.png" width="355">
  <figcaption>Text set in the <a href="https://www.fontspace.com/fattern-font-f48474">Fattern colour SVG font</a></figcaption>
</figure>
<h2 id="improved-api">Improved API</h2>
<p>Prior to Allsorts 0.5 it was a fairly involved affair to shape some text. You
had to read the font, do glyph mapping, apply glyph substitution (GSUB), and
apply glyph positioning (GPOS) in individual steps which amounted to quite a
bit of code.</p>
<p>Now it's only a few lines. You read the font and construct an instance of the
<code>Font</code> type, turn text into glyphs with a call to <code>map_glyphs</code>, then shape the
text with a call to <code>shape</code>:</p>
<pre><code><span>// Read and parse font
</span><span>let</span><span> buffer = std::fs::read(&amp;opts.font)?;
</span><span>let</span><span> scope = ReadScope::new(&amp;buffer);
</span><span>let</span><span> font_file = scope.read::&lt;FontData&lt;'_&gt;&gt;()?;

</span><span>// Construct Font instance
</span><span>let</span><span> provider = font_file.</span><span>table_provider</span><span>(opts.index)?;
</span><span>let mut</span><span> font = </span><span>match </span><span>Font::new(provider)?
    .</span><span>expect</span><span>("</span><span>unable to find suitable cmap subtable</span><span>");
};

</span><span>// Map glyphs
</span><span>let</span><span> glyphs = font.</span><span>map_glyphs</span><span>("</span><span>some text</span><span>", MatchingPresentation::NotRequired);

</span><span>// Shape glyphs
</span><span>let</span><span> script = tag::</span><span>LATN</span><span>;
</span><span>let</span><span> lang = tag::from_string("</span><span>ENG </span><span>")?;
</span><span>let</span><span> shaped_glyphs = font.</span><span>shape</span><span>(
    glyphs,
    script,
    Some(lang),
    &amp;Features::Mask(GsubFeatureMask::default()),
    </span><span>true</span><span>,
)?;
</span></code></pre>
<p>We also renamed a number of types and methods to make their function more
obvious and accurate.</p>
<h2 id="miscellaneous-improvements-and-fixes">Miscellaneous Improvements and Fixes</h2>
<p>Throughout the year we made several other improvements and fixes, including:</p>
<ul>
<li>
<p>Extended our glyph substitution support, implementing <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/gpos#lookuptype-8-chained-contexts-positioning-subtable">GSUB Lookup Type
8</a> (Reverse Chaining Contextual Single Substitution), which gains us
support for <a href="https://blog.janestreet.com/commas-in-big-numbers-everywhere/">Tristan Hume's Numderline font</a>:</p>
<figure>
  <img src="https://yeslogic.com/blog/allsorts-rust-font-shaping-engine-2020-review/numderline.png" width="586">
  <figcaption>Text set in the <a href="https://thume.ca/numderline/">Numderline font</a></figcaption>
</figure>
</li>
<li>
<p>Fixed a few bugs and handled some quirks revealed by exposing the code to
a variety of real world fonts.</p>
</li>
<li>
<p>Improved performance through:</p>
<ul>
<li>GSUB caching in Arabic, Syriac, and Indic.</li>
<li>Restructuring to avoid unnecessary bounds checks and allocations.</li>
<li>Using <a href="https://lib.rs/crates/tinyvec">tinyvec</a> to store codepoints on glyphs.</li>
</ul>
</li>
<li>
<p>Added support for more OpenType features in GSUB:</p>
<ul>
<li>Standard ligatures (<code>liga</code>).</li>
<li>Discretionary ligatures (<code>dlig</code>).</li>
<li>Historical ligatures (<code>hlig</code>).</li>
<li>Contextual ligatures (<code>clig</code>).</li>
<li>Small caps (<code>smcp</code>).</li>
<li>Small capitals from capitals (<code>c2sc</code>).</li>
<li>Lining figures (<code>lnum</code>).</li>
<li>Oldstyle figures (<code>onum</code>).</li>
<li>Proportional figures (<code>pnum</code>).</li>
<li>Tabular figures (<code>tnum</code>).</li>
<li>Diagonal fractions (<code>frac</code>).</li>
<li>Stacked fractions (<code>afrc</code>).</li>
<li>Ordinals (<code>ordn</code>).</li>
<li>Slashed zero (<code>zero</code>).</li>
<li>Language-specific OpenType shaping (<code>locl</code>).</li>
</ul>
</li>
<li>
<p>Support fonts with Big5 encoded cmap subtables.</p>
</li>
</ul>
<h2 id="future-plans">Future Plans</h2>
<p>We're currently implementing the following features to make Allsorts
better suited for use cases outside our own:</p>
<ul>
<li>Expose glyph positioning information in shaping output so you don't have to
calculate it yourself.</li>
<li>Retrieve glyph contours as a series of basic drawing operations.</li>
</ul>
<p>After those we hope to look into:</p>
<ul>
<li>Text segmentation by script to allow a chunk of text to be supplied to
Allsorts without having to detect and segment it by script first.</li>
<li>Glyph caching.</li>
</ul>
<p>Other items on our radar are:</p>
<ul>
<li>Performance measurement and optimisation to make it competitive with other
shaping libraries.</li>
<li>Support additional scripts such as Sinhala, and <a href="https://github.com/n8willis/opentype-shaping-documents/blob/master/opentype-shaping-use.md">Indic 3/Universal Shaping
Engine</a>.</li>
<li>Unicode normalisation.</li>
<li>Being able to map shaping output back to the source text.</li>
</ul>
<h2 id="links">Links</h2>
<ul>
<li><a href="https://github.com/yeslogic/allsorts">Allsorts on GitHub</a></li>
<li><a href="https://github.com/yeslogic/allsorts-tools">Allsorts Example Tools</a></li>
<li><a href="https://twitter.com/yeslogic">YesLogic on Twitter</a></li>
<li><a href="https://twitter.com/prince_xml">PrinceXML on Twitter</a></li>
</ul>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Thanks to Adrian, Alfie, Michael, Paul, and Peter for helping me write this
post.</p>

<p>Font subsetting refers to decreasing the size of a font by only including the data
for a reduced set of glyphs.</p>

    </div>
    
  </article>

  
</div></div>]]>
            </description>
            <link>https://yeslogic.com/blog/allsorts-rust-font-shaping-engine-2020-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463410</guid>
            <pubDate>Fri, 18 Dec 2020 03:17:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I lost 49.9 lbs (19.5 kg) during Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25463175">thread link</a>) | @Flamingo10
<br/>
December 17, 2020 | https://www.thebeforeafter.com/how-i-lost-49-9-lbs-during-covid-19/ | <a href="https://web.archive.org/web/*/https://www.thebeforeafter.com/how-i-lost-49-9-lbs-during-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.thebeforeafter.com/content/images/size/w300/2020/12/imgonline-com-ua-resize-5Pb49QjX8A.jpg 300w,
                            https://www.thebeforeafter.com/content/images/size/w600/2020/12/imgonline-com-ua-resize-5Pb49QjX8A.jpg 600w,
                            https://www.thebeforeafter.com/content/images/size/w1000/2020/12/imgonline-com-ua-resize-5Pb49QjX8A.jpg 1000w,
                            https://www.thebeforeafter.com/content/images/size/w2000/2020/12/imgonline-com-ua-resize-5Pb49QjX8A.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.thebeforeafter.com/content/images/size/w2000/2020/12/imgonline-com-ua-resize-5Pb49QjX8A.jpg" alt="How I lost 49.9 lbs (19.5 kg) during covid-19">
            </figure>

            <section>
                <div>
                    <blockquote>QUICK STATS<br>NAME: Anja<br>AGE: 27<br>HEIGHT: 162 cm (5'31)<br>BEFORE WEIGHT: 90,5 kg (199.5 lbs)<br>AFTER WEIGHT: 71,0 kg (156.5 lbs)</blockquote><hr><h3 id="hi-who-are-you-and-what-do-you-do-for-a-living">Hi! Who are you and what do you do for a living?</h3><p>Hi my name is Anja I'm 27 years old and I'm a female Dockworker/ longshore women from Denmark 😁 sadly at the moment I'm out of work due to the Covid-19</p><h3 id="what-s-your-backstory-and-why-did-you-start-living-a-healthy-lifestyle">What's your backstory and why did you start living a healthy lifestyle?<br></h3><p>I grew up in a relatively normal family, with a big love/ fondness for food. As a teen, I often ate my feelings away, when I was bored or just generally snacking in front of the TV very late in the evening and ate way too big portions of food.</p><p>The reason why I started my weight loss journey was that I no longer felt happy for the reflection in the mirror and overall the way I looked. My weight started to have a negative effect on my life and my physique, I was tired of hating myself and my body and wanted to be able to love myself. I remembered I got tagged in a video on Instagram and I was surprised to see myself and I thought to myself " is that really how I look, is that the way people see me" and it made me sad.</p><p>Due to covid-19 I got fired from my job and at that time I thought to myself now is my chance to change the way I see myself and the way I look, so I contacted a personal trainer one of my friends had recommended and I started my Weight Loss Journey.<br></p><h3 id="how-was-it-in-the-beginning-and-what-were-the-biggest-obstacles-you-overcame">How was it in the beginning and what were the biggest obstacles you overcame?</h3><p>The first 2 weeks was the hardest, I had to get used to not eating as much as I used to and focusing on getting the right nutritions protein, and veggies, it's hard to break old habits and make new ones but as soon as I got over the two weeks mark, then for me, it started to feel natural and it was easier to incorporate in my daily life/ routine</p><h3 id="what-were-your-worst-mistakes">What were your worst mistakes?</h3><p>My worst mistake was thinking that I didn't do enough, that I didn't eat healthy enough, and that I didn't exercise enough at the beginning of my weight-loss journey. I pushed myself really hard and didn't get fast enough results in my opinion! because of that mentality and because of those thoughts I almost didn't go through with my weight-loss program, I lost my motivation real quick and quickly found out I had to change my mentality to be able to keep moving forward.</p><p>The biggest milestone for me was when my clothing started to feel loose around my body and when I could see the physical change. A good motivation boost was also when I could do more with the weights at my gym and when I could perform more and I didn't get out of breath within 5-minutes. It is often small things that motivate me the most, for example being able to squat a bit more than last time or being able to run a bit longer.</p><h3 id="what-area-of-life-has-changed-after-becoming-more-healthy">What area of life has changed after becoming more healthy?</h3><p>Because I'm being more active and healthy I feel like I have gotten more opportunities in life. I am no longer bound by my physique and I'm happier for my body, I like where I am and it has an effect on the people surrounding me. They can feel that I have gotten a lot more energy and it makes them happy on my behalf.<br></p><h3 id="what-is-your-weekly-training-protocol-how-many-days-per-week-do-you-train-how-are-your-workouts-structured">What is your weekly training protocol? How many days per week do you train, how are your workouts structured?</h3><p>I work with a personal trainer 2 times a week, one day with strength training and one day with cardio training, and an everyday goal of 10.000 steps sometimes I workout more depending on my motivation and the time I have available. (by myself)</p><h3 id="what-is-your-nutrition-and-diet-approach-do-you-follow-a-specific-meal-plan-or-eating-structure">What is your nutrition and diet approach? Do you follow a specific meal plan or eating structure?</h3><p>I do follow a semi-strict meal plan, I eat 1300 calories a day, 6 small meals spread out throughout the day. I drink a lot of water before my meal and in between my meals. I'm focusing mainly on eating proteins and veggies and trying to cut down on carbs, fat, and sugar and I have a strict no food past 21.30 rule.</p><h3 id="do-you-supplement-your-nutrition-with-any-sports-supplements-if-so-can-you-tell-us-which-supplements-you-use">Do you supplement your nutrition with any sports supplements? If so can you tell us which supplements you use?</h3><p>I eat a lot of vitamin supplements, minerals, herbs, and <a href="https://amzn.to/3ahrIEg">fish oil</a> and occasionally I drink protein shakes and eat protein bars. The brands I'm using at the moment are Bodylab, Star nutrition, and <a href="https://amzn.to/2Wn3xw7">Barebells</a>.</p><h3 id="what-are-your-favorite-cheat-meals-and-foods">What are your favorite cheat meals and foods?</h3><p>With the "diet" I have now you don't have a cheat meal or cheat day, it's not a diet but more a lifestyle change, I'm allowed to go out and eat at a restaurant with my friends and family, I can still live life, eat burgers and pizza in moderating portions! everything in moderation.<br>What are your future goals, dreams, and plans?</p><h3 id="what-have-been-the-most-influential-books-podcasts-or-other-resources">What have been the most influential books, podcasts, or other resources?</h3><p>The thing that has had the most influence on me has been having the support of my friends and family but also the network I have gotten to know through my workout/ personal trainer. Having people who have or is in the middle of a weight-loss journey is gold 👌 being able to talk to them and have someone to share your concerns and thought process with has really helped me.<br></p><h3 id="what-advice-do-you-have-for-someone-who-wants-to-start-living-healthy-today">What advice do you have for someone who wants to start living healthy today?</h3><p>The first step is of course to decide for yourself that this is something you're willing to do even if it gets hard, there isn’t a magic pill that makes you lose 10 kilos in 3 weeks, it is only through hard work, dedication, and a healthy meal plan that you can change the body you have spent years on eating to get.</p><p>Seek out help and information on how to get started and how to make a meal plan specifically for your body type. There's a lot of knowledge about the body that you don't learn in school but have to learn from others, whenever it might be through a personal trainer via friends or online</p><p>(do however be critical of the information you get, if it seems to good to be true it probably is)</p><p>Workout at least 2 times a week for one intensive hour. Don't be afraid to ask people at the Gym for help or tips and tricks, it might be scary to ask people, but they are there for a recent and most often they're in the same boat as you or has been there.</p><p>set a goal for 8000-10000 steps a day or more of course depending on your size.</p><p>Don't fixate on the scale and the number that is shown is a bad thing for your mental health and motivation.<br>Don't weigh yourself more than 2 times a week, your weight is going to bounce up and down depending on what you have been eaten the day before, when you stopped eating in the evening if you're bloated from menstruation, the time of the day, etc.</p><p>Find a measuring tape and start measuring your body. Measure the first week and then every 5 weeks so you can see a physical change.</p><p>And last but not least don't compare yourself to others, your body is your body and their body is their body there are not the same. Take your time this is not a quick fix, you have been eating for years to get the body that you have now and it's not going to disappear in 3-weeks.</p><p>Don't be too hard on yourself it is ok too to eat unhealthy from time to time we all have to live life and you do not know if you're going to die tomorrow just remember everything in moderation.</p><p>Find a friend or someone you can work out with or have someone you can talk to about this journey of yours, it's important to be able to talk when you're feeling down or when things are not going the way you want it to, is completely normal and you will get over it.<br></p><h3 id="if-someone-wants-to-connect-with-you-where-can-you-be-found">If someone wants to connect with you, where can you be found?</h3><p>They can find on my <a href="https://www.instagram.com/anjasilja/">Instagram</a> 😊👍<a href="https://www.instagram.com/anjasilja/">@anjasilja</a></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to The Before After</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.thebeforeafter.com/how-i-lost-49-9-lbs-during-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463175</guid>
            <pubDate>Fri, 18 Dec 2020 02:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WeWork: How the $3.5B Flex Space Giant Is Engineering a Comeback]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25462692">thread link</a>) | @gk1
<br/>
December 17, 2020 | https://sacra.com/research/wework-engineering-a-comeback/ | <a href="https://web.archive.org/web/*/https://sacra.com/research/wework-engineering-a-comeback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: “will,” “expect,” “would,” “intend,” “believe,” or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="light-at-the-end-of-the-tunnel">Light at the end of the tunnel</h2><p>WeWork is inarguably one of the most controversial companies in the world. Its unsustainable growth strategy destroyed billions in shareholder value. Has WeWork finally hit rock bottom, or is it a falling knife?&nbsp;</p><p>We don’t have a crystal ball, but based on the work we have done, we believe WeWork has most of the pieces in place for a powerful turnaround.</p><p>In January 2019, WeWork was valued at $47B, making it the second-largest private company at the time, 15x the price of its closest competitor. After its failed IPO at the end of 2019, it nosedived to $7.3B. In March 2020, just as offices around the world were closing amid the coronavirus outbreak, SoftBank refused to participate in a $3B tender offer of early employee shares. The valuation of WeWork fell all the way to $2.9B, down 94% from its peak.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/d878dff8-8141-42de-9292-25cabe8af273_Screen+Shot+2020-12-17+at+14.23.03.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>WeWork’s rise from startup to $47B company took 9 years—its fall back down to $2.9B took just over 1.</em></p><p>The private markets have gone from euphoria to disillusion with WeWork. The company was downgraded again by credit rating agency Fitch in October 2020, and its cash burn through the year so far is estimated to be above $1.6B.</p><p>Our research shows that after all the recent changes, there is a light at the end of the tunnel. We aggregated public data, analyzed financial data, talked to real estate brokers, developers, industry experts and built a model.&nbsp;</p><p>We can scoff at WeWork’s one-page long community adjusted EBITDA, but the company has been undergoing a reorganization towards profitability.&nbsp;</p><p>Key decisions include rightsizing their real estate portfolio, exiting 66 unprofitable leases, effecting a favorable shift in customer mix shift with 60% revenue now coming from enterprises, reducing the size of the workforce from 14,000 to 5,000 and hiring a new management team.&nbsp;</p><p>In addition to WeWork’s internal efforts, the most unexpected tailwind is that the global experiment of remote working that we’ve seen during COVID may give rise to a structurally more flexible and distributed workforce in the near future. Ironically, the economic downturn many thought would sink WeWork may become the very cause of its survival.&nbsp;</p><p>A capital-light strategy is also on the horizon (a genuine one this time). Once the dust settles, WeWork could leverage its existing business and office management services and transform itself into a franchise provider.</p><div>
            <p>Join our list for access to an exclusive 1-hour analyst conference call on the future of WeWork's business.</p>
            
        </div>
    <h2 id="wework-s-road-to-redemption--">WeWork’s road to redemption&nbsp;&nbsp;</h2><ul><li><strong>Our DCF model gives WeWork a valuation of $3.5B.</strong> At this price, WeWork equity resembles a call option, with limited downside but asymmetric upside.</li><li><strong>The site economics behind WeWork's core business are surprisingly positive. </strong>24 months after opening, the average WeWork location can generate a 20% contribution margin, compared with economics from more stable peers. A big reason for WeWork’s cash burn was its lack of mature locations. In 2019, WeWork had the biggest flexible workspace footprint, but the lowest % of mature sites, comparing with its profit-making peers.</li><li><strong>WeWork has become much more prudent in new location openings.</strong> Mature locations are expected to grow to 50% by the end of 2020 and reach 100% in 2022.</li><li><strong>WeWork has spent 2020 stabilizing its core operations</strong> with 4 key measures.</li><li><strong>60% of WeWork's customers are now enterprises.</strong> During the pandemic, WeWork leased 3.5 million square feet to enterprise clients, including TikTok, Mastercard, Microsoft, Citigroup and Deloitte.</li><li><strong>WeWork's new CEO is a real estate veteran.</strong> The current CEO is a disciplined operator with successful turnaround experience.</li><li><strong>WeWork has rightsized its real estate portfolio.</strong> We estimate WeWork has exited 66 locations and amended about 150 leases, driving higher average occupancy and margins across their portfolio.</li><li><strong>WeWork has cut costs.</strong> WeWork has shrunk its workforce by 60% and cut many experimental growth projects, such as WeLive, WeGrow and self-driving chairs. Operating expenses are trending down significantly, from 86% of revenue in 2018 to an estimated 50% in 2019.</li><li><strong>Market dynamics are changing.</strong> Post-COVID, 80% of people want to return to the office a few days a week but keep the benefit of flexibility. Ironically, the downturn many thought would sink WeWork may become the very cause of its survival.</li><li><strong>WeWork is quietly transitioning to an integrated, tech-enabled ecosystem coordinator.</strong> Despite the large cost-cutting, WeWork continues to invest in community services, aka, the "killer app". For example, WeWork Labs is a community digital platform. It provides cross-sector incubator services to support companies to acquire skills, meet peers and experts.</li><li><strong>WeWork could reshape the real estate stack. </strong>It could leverage its physical locations and build a tech-enabled layer on top, thereby, transform into a middleware to connect people and optimize spaces.</li></ul><h2 id="valuation--wework-is-worth--3-5b">Valuation: WeWork is worth $3.5B</h2><p>Our base case discounted cash flow (“DCF”) model implies a 2021 forward equity value of $3.5B for WeWork.&nbsp;</p><p>WeWork still has the shape of a distressed company. The capital structure is heavily indebted and equity is at the bottom of the pecking order. Nevertheless, the equity resembles the asymmetric risk/reward profile of an out of the money call option.&nbsp;</p><p>In other words, given the current financial and operating dynamics of the company, for every one unit of enterprise value increase, the upside is amplified for the equity holders.&nbsp;</p><p>For anyone to stand behind WeWork now, however, they must be comfortable with a lot of macro uncertainties related to GDP, unemployment, speed of returning to the office and the opportunities around what the future of workspace would look like.&nbsp;</p><p>If WeWork can stabilize their operations in the near term through delayed capital spending, improved occupancy and regained focus, there could be a meaningful upside.</p><p>We highlight the structure of our model below.&nbsp;</p><p>Our aim with our model is to capture WeWork’s key growth and cost drivers to have a sense of the company’s profit-making potential. We used company disclosures from 2019 and turnaround guidance to form the base case assumptions. Our model calculates enterprise value by subtracting net debt and capitalized operating leases to derive equity value.&nbsp;</p><p>We can summarize our DCF into three distinct phases:</p><ul><li>Phase 1: 2020 - 2024 turnaround and stabilization.&nbsp;</li><li>Phase 2: 2025 - 2030 disciplined growth in the core business, expansion in franchise model and other business services.&nbsp;</li><li>Phase 3: 2031+ steady-state growth at 2%, with the overall occupancy to remain at 90%.&nbsp;</li></ul><p>We disaggregate revenue into total workstations, total memberships and average revenue per member (“ARPM”) to derive occupancy rates. We also build a CapEx profile based on cost per workstation to calculate location level contribution margin (WeWork defines contribution margin as membership revenue minus location operating expenses before headquarter administrative costs, growth expenses, marketing and stock-based compensation).&nbsp;</p><img src="https://images.prismic.io/sacra/40c25e89-a189-4840-9598-e31e51bb39f4_Screen+Shot+2020-12-17+at+16.39.31.png?auto=compress,format"><p><em>WeWork's revenue drivers. </em></p><p>WeWork doubled its total workstations between 2016 and 2019. As a result, mature locations accounted for only c.30% of the overall portfolio. To preserve cash and streamline operations, the pace of expansion has slowed significantly. The base case assumes total workstations to grow at 5% p.a. to reach 1.2M by 2024.&nbsp;</p><p>We illustrate our key revenue and cost assumptions below.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/651fa87a-afc1-4704-b255-af19682d60fe_Screen+Shot+2020-12-17+at+14.26.02.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Post the initial phase of “growth at all cost” prior to 2019, we model that between 2021 and 2024, WeWork would become more selective in new location openings, as well as, more prudent in the number of new openings.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/ff74c6c7-57a0-4331-973f-cb4f175995e7_Screen+Shot+2020-12-17+at+14.26.18.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Revenue: We model a slower revenue growth rate before WeWork achieves profitability.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/bc338059-f6b2-4418-a579-f4a85000e82a_Screen+Shot+2020-12-17+at+14.26.36.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Mixed shift: Enterprise memberships contribute 60% of the revenue in 2020. It is a positive trend that it almost doubled since 2017.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/bc174c16-e919-48b6-898e-94e5fb1e5aee_Screen+Shot+2020-12-17+at+14.26.48.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>We model that, …</em></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/wework-engineering-a-comeback/">https://sacra.com/research/wework-engineering-a-comeback/</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/wework-engineering-a-comeback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25462692</guid>
            <pubDate>Fri, 18 Dec 2020 01:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Hundred Different Misspellings of Schwarzenegger]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25462660">thread link</a>) | @cowllin
<br/>
December 17, 2020 | https://www.watercoolertrivia.com/blog/schwarzenegger | <a href="https://web.archive.org/web/*/https://www.watercoolertrivia.com/blog/schwarzenegger">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Arnold Alois Schwarzenegger was born in Austria on July 30, 1947. Famously, he reached stratospheric levels of notoriety and success in three wholly distinct professional fields: bodybuilding, acting, and politics, culminating in his eight years as the Governor of California.&nbsp;<br></p><p>For the past 73 years, Schwarzenegger has gone by Arnold, Ahnuld, Governator, <a href="https://en.wikipedia.org/wiki/Arnold_Schwarzenegger">Austrian Oak</a>, Terminator, Running Man, and dozens of other nicknames. In part because he’s charismatic and there’s nicknames aplomb to describe him, sure.&nbsp;<br></p><p><strong>But also because his last name is hard to spell. Like, really hard.</strong> We would know, because Water Cooler Trivia participants have spelled Schwarzenegger 255 different ways. And we’ve dug deep to explore that data.&nbsp;<br></p><p>255 different spellings. <a href="https://www.watercoolertrivia.com/blog/feature-emojis"><strong>We don’t grade responses based on spellings</strong></a>, so these are the spellings we’ve accepted as correct. We’ve got the full list of them at the end of this article, but we wanted to dig deeper into the data<br></p><h2>First things first: here’s the trivia question<br></h2><blockquote><strong>“What is the name of the Austrian bodybuilder who has been Mr. Universe three times and Mr. Olympia seven times?”</strong><br></blockquote><p>The answer, as you’ve surely guessed by now, is Arnold Schwarzenegger. We first wrote this question in April 2019, and since then…</p><ul role="list"><li><strong>3,019 different participants</strong> across 306 different groups have submitted a response</li><li><strong>2,681</strong> (89%) of folks got the question correct</li><li><strong>1,616</strong> (60%) of correct responses were spelled correctly [editor’s note: we suspect phone and browser autocorrect software lent a helping hand here]</li><li><strong>255</strong> different spellings of Schwarzenegger during that time<br></li></ul><p>And now, let’s look at the different ways in which Schwarzenegger has been spelled by Water Cooler Trivia participants.&nbsp;</p><h2>1. What are the most common misspellings?</h2><p>When you remove the correct spelling, you are left with 1,060 participants who spelled Schwarzenegger in 254 different ways.&nbsp;<br></p><p>The most common misspelling is to simply add a <strong>T </strong>after the <strong>R</strong>, a.k.a <strong>Schwartzenegger</strong>. This makes sense, as Schwartz itself is a fairly common German surname. 116 different respondents, 4% of all correct responses, spelled Arnold’s surname with that bonus <strong>T.</strong><br></p><p>Next up was <strong>Schwarzeneger</strong>, which removes a letter rather than adding one, this time removing one of the two <strong>G</strong>s. Again, this matches intuition. Double letters are hard to remember and frequently don’t add anything phonetically to a word. 88 different participants spelled it with this missing <strong>G</strong>, or 3% of all correct responses.<br></p><p>In third place was <strong>Schwarzenager</strong> with 56 people (2% of correct responses) both dropping that same <strong>G </strong>and then also swapping an <strong>E </strong>with a <strong>G. </strong>We get it, spelling is hard.<br></p><p>Below is a chart of the ten most common misspellings, and for the intrepid, here’s the <a href="https://docs.google.com/spreadsheets/d/1QqEL1IZvox3Aypi0YDStZ3QJ2_WuMTPwp7pOJ2batPE/edit#gid=756356712">full list</a> of misspellings.</p><figure id="w-node-73dd971f4f5a-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf08dd766ee0807d28_YMx1QfTHzO6c61u44T5MnhVihFk7AuJUa3aJXoUvDh8sLDYthwp4CYFclY0sUekxH3MYA1U9T9lu0OY0GBnxEtnBW-jUzNYQfk5iRSXSBP2musv3twFKBiNuMHwAPsVhEvrRVvUz.png" alt=""></p></figure><h2>2. Wait, how many letters is it?</h2><p>It’s 14 letters. S-c-h-w-a-r-z-e-n-e-g-g-e-r. But not everyone realized that.&nbsp;<br></p><p>Of the 255 total different spellings,&nbsp;</p><ul role="list"><li><strong>169</strong> (66%) had fewer than 14 letters</li><li><strong>24</strong> (9%) had more than 14 letters</li><li><strong>61</strong> (24%) correctly had 14 letters but were spelled incorrectly</li><li><strong>1</strong> (0.4%) correctly had 14 letters and was spelled correctly<br></li></ul><p>The most popular length was 13 letters with 31% of distinct spellings and 13% of all correct responses.</p><figure id="w-node-b1be6443de1a-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf088a2f4f273d8970_jDn-VaUiTJ_o9aGXBHJpAgFsSNJ4qViTLF0n0X5ZsN1kWQFbC7nS7JO88_K3BwfEaYJEkkT60LeNMN6-x7CwXgXXpJPsO7JLx7fPFXYMxPmM2bmSAaVNS0g1ttJBCkZDVdFqo_jX.png" alt=""></p></figure><h2>3. So it starts with an S... then a C… then...</h2><p>Schwarzenegger starts with the letter S. That’s fairly obvious. In fact, of the 255 distinct spellings that accepted as correct, 100% of them started with the letter <strong>S</strong>. However, once you move on to the second letter, <strong>only 58% of the spellings had C as the second letter.</strong><br></p><p>Unsurprisingly, the share of “correct” letters in terms of positions descends as you get further in the word, with a few noticeable deviations: interestingly, misspellings tend to correctly guess that the 11th letter is a <strong>G</strong> and the 14th letter is an <strong>R</strong>.<strong>&nbsp;</strong></p><figure id="w-node-3153958d4ef7-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf6ef4066cb3b8bc5a_SVo29XaQjA6jKuUkHuTPk1t2s967m2NoVPJrmpRPCGKe3Hrzg40C8kdhQvOqWkjw_BH_8noZ2ds0YGXkppq-B22DsD0PZ6auFQTHvSlEjpjzYw7r1Htdz5sFgWl7oAdN6pVAGp-6.png" alt=""></p></figure><h4>Double Letters</h4><p>On that topic, Schwarzenegger has a double letter in it: two G’s as the 11th and 12th letter. This was a common source of misspellings, as 1<strong>47 of the distinct spellings (58%) guessed that there was only one G</strong> in the politician’s surname.<br></p><h4>Edit Distance</h4><p>Known as edit distance or Levenshtein distance, this is a measure of how many changes you need to make to a word or phrase in order to translate it into another word or phrase. <strong>So “bake” has a distance of one from “cake” or “ake” or “baked”.</strong><br></p><p>When you search the internet for <strong>Girrafe</strong> and the search engine asks <strong><em>“Did you mean Giraffe?”</em></strong><em> </em>they are making that guess because your search query only had an edit distance of two from the more common query term <strong>Giraffe</strong>. One deletion (the first <strong>R</strong>) and one insertion (the second <strong>F</strong>) turns your query into the correct word.&nbsp;<br></p><p>So, basically, this is a way to see <strong><em>how bad </em></strong>certain spellings were. Or, more optimistically, how generous we at Water Cooler Trivia are as graders.&nbsp;<br></p><p>Okay, with all that prologue finished, here’s the edit distance stats for the 255 distinct spellings of Schwarzenegger. Note that we are only surfacing the 1,060 responses that were incorrectly spelled.&nbsp;</p><ul role="list"><li><strong>34% had an edit distance of only one</strong>!</li><li>And another 28% were only off by two characters!</li><li>18% of misspellings had an edit distance of at least four</li></ul><figure id="w-node-00b9f866edfc-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcfee56eb8449ae2563_Qw6LyfdHxuw1-KuhsN3NFHyHzwr-1PnjCWoBqcc6pBTMNmr1DKqO-LmCkjcwMx-wn3K4inzJcTAnSOQCLQokxfe_psFkS6F8YkA4ohbuvw5kcvg7D9ApQtGulyfaG4kXCjRYgV-r.png" alt=""></p></figure><h2>4. What does Schwarzenegger even mean?</h2><p>I was wondering that too. It turns out the name has Germanic roots, divided neatly into two terms.</p><ul role="list"><li>"schwarzen" means "black"</li><li>&nbsp;"egg" refers to a ridge<br></li></ul><p>So the Governator’s surname <strong>translates most literally into English as Black Ridge</strong>, which happens to be the name of a U.S. <a href="https://www.blackridge.us/"><strong>technology services company</strong></a>.</p><h2>Closing thoughts...</h2><p>Looking to learn about more commonly-misspelled names or commonly-mistaken knowledge? Us too! We have a dataset of 2.5 million free text trivia responses. If you want to work with us to mine for fun data-driven stories, email <a href="https://www.watercoolertrivia.com/cdn-cgi/l/email-protection#c5a1a4b1a485b2a4b1a0b7a6aaaaa9a0b7b1b7acb3aca4eba6aaa8"><span data-cfemail="f591948194b58294819087969a9a99908781879c839c94db969a98">[email&nbsp;protected]</span></a> and we can find a way to work together.<br></p><p>Or if you just want to bring a <a href="https://www.watercoolertrivia.com/blog/how-weekly-trivia-impacts-your-mental-well-being"><strong>weekly trivia ritual</strong></a> to your team, that would make our hearts a-flutter. Get started with a four-week free trial at our <a href="http://watercoolertrivia.com/"><strong>homepage</strong></a>.<br></p></div></div>]]>
            </description>
            <link>https://www.watercoolertrivia.com/blog/schwarzenegger</link>
            <guid isPermaLink="false">hacker-news-small-sites-25462660</guid>
            <pubDate>Fri, 18 Dec 2020 01:15:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enhancing My Home Network (Ft. My Raspberry Pi)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25461968">thread link</a>) | @grantjpowell
<br/>
December 17, 2020 | https://hmlhml.com/articles/2020-12-13__enhancing-my-home-network-(ft-my-raspberry-pi).html | <a href="https://web.archive.org/web/*/https://hmlhml.com/articles/2020-12-13__enhancing-my-home-network-(ft-my-raspberry-pi).html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><ul>
 <li><a href="#Intro-to-DNS">Intro to DNS</a>
 <ul>
  <li><a href="#What-27-s-a-DNS-3f-">What's a DNS?</a></li>
  <li><a href="#Why-not-use--3c-code-3e--24-ISP-3c--2f-code-3e--27-s-DNS-3f-">Why not use <code>$ISP</code>'s DNS?</a></li>
 </ul>
 </li>
 <li><a href="#Intro-to-the-Pi-2d-Hole">Intro to the Pi-Hole</a>
 <ul>
  <li><a href="#Ad-Servers-3f--Never-Heard-of--27-em--28--3c-em-3e-wink-3c--2f-em-3e--2c---3c-em-3e-wink-3c--2f-em-3e--29-">Ad Servers? Never Heard of 'em (<em>wink</em>, <em>wink</em>)</a></li>
 </ul>
 </li>
 <li><a href="#DHCP">DHCP</a></li>
 <li><a href="#Accessing-my-Pi-When-I-27-m-on-the-Go">Accessing my Pi When I'm on the Go</a>
 <ul>
  <li><a href="#Cryptography-to-the-Rescue">Cryptography to the Rescue</a></li>
  <li><a href="#Connecting-my-Laptop-to-Tor">Connecting my Laptop to Tor</a></li>
  <li><a href="#Tunneling">Tunneling</a></li>
  <li><a href="#Like-Water-on-a-Rock">Like Water on a Rock</a></li>
 </ul>
 </li>
</ul>
<p>After all the hype about the new <a href="https://www.raspberrypi.org/products/raspberry-pi-400/">Raspberry Pi</a>, I decided to set up my old Pi. I configured my Raspberry Pi to be a “Pi-Hole” (DNS server) for my home network, and I added a publicly routable interface to tunnel traffic back into my home network. Here’s some details about it:</p>

<p><img src="https://hmlhml.com/images/pi-hole-admin-screen.png" alt="Pi Hole Admin Screen"></p>



<h2>What’s a DNS?</h2>

<p>You can’t actually connect to google.com, you can only connect to an IP address. In order to do a google search you need a way to turn a hostname (google.com) into an ip address (<code>64.233.185.101</code>).</p>

<p><img src="https://hmlhml.com/images/isp-dns.png" alt="Basic DNS"></p>

<h2>Why not use <code>$ISP</code>’s DNS?</h2>

<p>My ISP provides DNS services to my network as part of my internet package. ISPs also fought very hard in congress so they could sell your DNS query logs for money. <a href="https://www.eff.org/deeplinks/2019/10/dns-over-https-will-give-you-back-privacy-congress-big-isp-backing-took-away">Relevant EFF</a>.</p>

<p><img src="https://hmlhml.com/images/isp-selling-dns-logs.png" alt="ISP selling DNS records"></p>



<p><a href="https://pi-hole.net/">Pi-Hole</a> is a self hosted DNS server. Pi-Hole lets you have programmable control over how DNS is resolved on your network.</p>

<p><img src="https://hmlhml.com/images/pi-hole-basic-dns.png" alt="Pi Hole Doing DNS"></p>

<h2>Ad Servers? Never Heard of ‘em (<em>wink</em>, <em>wink</em>)</h2>

<p>One of the best features of Pi-Hole is that you can use it to block ad servers from being resolved on your network.</p>

<p><img src="https://hmlhml.com/images/pi-hole-sketchy-ads.png" alt="Pi Hole Blocking Ad Servers"></p>



<p>Some good links</p>

<ul>
<li><a href="https://www.networkworld.com/article/3299438/dhcp-defined-and-how-it-works.html">Network World Article</a></li>
<li><a href="https://www.youtube.com/watch?v=S43CFcpOZSI">CertBros Video</a></li>
</ul>


<p>The (Dynamic Host Configuration Protocol) DHCP protocol is how a device that is joining the network, learns about the network.</p>

<p>While performing the handshake a device learns the following things</p>

<ol>
<li>What IP address it has a “lease” for</li>
<li>Where the gateway is</li>
<li>How to resolve DNS</li>
</ol>


<p>The router we rent from $ISP handles DHCP usually, but won’t let you configure DNS. In order to tell everyone on the network to use the Pi-Hole for DNS with this router, we need to have the Pi-Hole be the DHCP server.</p>

<p><img src="https://hmlhml.com/images/pi-hole-dhcp.png" alt="Pi-Hole DHCP Settings"></p>



<p>Since my Pi-Hole is now the DHCP server for the network, that means that if it’s broken, the network is effectively “down” from the perspective of my roommates. I want to be able to connect to the pi hole/router wherever I am. This is a little tough because I don’t have a static IP address. At any point the external address of my router relative to the internet could change.</p>

<p>One option available to me is to use something like <a href="https://account.dyn.com/">DYN DNS</a>. Dyn DNS allows for your network to dynamically configure it’s external DNS address</p>

<p>But the issue is that Dyn DNS is $55 a year, which is like a ¼ of a <a href="https://wiki.pine64.org/index.php/Pinebook_Pro">Pinebook</a>.</p>

<h2>Cryptography to the Rescue</h2>

<p>One approach to providing a way to route to my server without having an static IP is to use one of the volunteer run cryptographic overlay networks.</p>

<p>Here are two.</p>

<ol>
<li><a href="https://en.wikipedia.org/wiki/Tor_%28anonymity_network%29">Tor</a></li>
<li><a href="https://en.wikipedia.org/wiki/I2P">i2p</a></li>
</ol>


<p>When exposing a server to inbound connections via something like Tor, all connections from your server are outgoing to the Tor network. This means that you can make a server routable on any network that allows outgoing connections on port 443 (pretty much any network).</p>

<p>These cryptographic overlay networks use cryptographic signatures to route within the network. Addresses look like <code>http://bbcnewsv2vjtpsuy.onion</code>.The new Onion addresses are actually the public keys of the servers (the old ones were the beginning of the hash of the key). Since routing is done with cryptographically, you don’t need something like a lease on the limited IPv4 address space.</p>

<p>On the PI (I’ve named it “Io” after Jupiter’s moon) we can expose the SSH server via Tor by using the following configuration. We tell the Tor process to forward connections incoming connections on port 22 to port 22 on the loopback (localhost)</p>

<pre><code>RunAsDaemon 1
DataDirectory /var/lib/tor
HiddenServiceDir /var/lib/tor/ssh_hs/
HiddenServicePort 22 127.0.0.1:22
</code></pre>

<p><img src="https://hmlhml.com/images/io-tor-connection.png" alt="IO Tor Hidden Service"></p>

<h2>Connecting my Laptop to Tor</h2>

<p>There’s a <a href="https://wiki.pine64.org/index.php/Pinebook_Pro">special version of Firefox</a> that ships configured with all the necessary software to connect to the network. When you run the browser, it also runs a SOCKS5 proxy on port <code>9150</code> that any other software can use.</p>

<p>On my laptop I can tell <code>ssh</code> to proxy commands through the Socks5 Proxy by editing my <code>~/.ssh/config</code> like so</p>

<pre><code>Host io
  Hostname &lt;your-onion-address&gt;.onion
  User pi
  IdentityFile ~/.ssh/id_rsa
  ProxyCommand nc -X 5 -x localhost:9150 %h %p
  VerifyHostKeyDNS no
  CheckHostIP no
  IdentitiesOnly yes
</code></pre>

<p><i>Note: I found out the hard way, currently only the BSD edition of <code>netcat</code> supports SOCKS5, and the GNU version does not</i></p>

<p>Most commands that deal with connecting to a server read the <code>~/ssh/config</code> file. So <code>ssh</code> and <code>scp</code> work out of the box with this config</p>

<p><img src="https://hmlhml.com/images/io-tor-ssh.png" alt="IO Tor ssh"></p>

<h2>Tunneling</h2>

<p>Now that we have a way to do ssh connections over the overlay network, we can use ssh to tunnel to other places behind my firewall.</p>

<pre><code>ssh -N -L 127.0.0.1:4000:192.168.1.64:80 io
</code></pre>

<p>This will forward all connections to port <code>4000</code> on your local machines through Io to port 80 on  <code>192.168.1.64</code> (relative to Io). This means I can use chrome to access my router anywhere I go.</p>

<p>You can use this tunneling trick to get to whatever IP address is blocked on whatever network you’re currently on.</p>

<p><img src="https://hmlhml.com/images/io-tor-ssh-tunnel.png" alt="IO Tor ssh tunnel"></p>

<h2>Like Water on a Rock</h2>

<p>Any article about exposing an SSH server should come with the mandatory “Make sure you follow all the SSH hardening guidelines.” If you’re planning on exposing your Pi to <em>ANY</em> network make sure you’ve updated the passwords to something secure. Ideally only allow ssh key login.</p>

<!-- Images used (All Creative Commons)
  - https://commons.wikimedia.org/wiki/File:Raspberry-Pi-2-Bare-BR.jpg
  - https://commons.wikimedia.org/wiki/File:Netgear-Nighthawk-AC1900-WiFi-Router.jpg
--></div></div>]]>
            </description>
            <link>https://hmlhml.com/articles/2020-12-13__enhancing-my-home-network-(ft-my-raspberry-pi).html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25461968</guid>
            <pubDate>Thu, 17 Dec 2020 23:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A free Minecraft server for the Holidays?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25461374">thread link</a>) | @dgiffin
<br/>
December 17, 2020 | https://blog.releaseapp.io/blog/free-minecraft-server-running-on-releaseapp-io | <a href="https://web.archive.org/web/*/https://blog.releaseapp.io/blog/free-minecraft-server-running-on-releaseapp-io">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="setup-your-own-free-minecraft-server-running-on-releaseappio">Setup your own free Minecraft Server running on releaseapp.io</h2><p>One of the coolest things about working at Release has been figuring out all of the fun stuff that we can do with the platform. While our main use case is helping people build environments for their applications, anything that runs in Docker will run easily on Release.</p><p>Early on, I found a handful of repos that helped us build out our platform. One that has been the most fun all along is the <a href="https://github.com/itzg/docker-minecraft-server" target="_blank" rel="noreferrer">docker-minecraft-server from itzg</a>. I used it in the early days because it had a little complexity and a fully working docker-compose ecosystem to play around with. It’s got the great side effect of when it runs, I let my kids test it out!</p><p>So while you’re sipping on egg nog and enjoying a 2020 Holiday season on COVID lock-down, here’s a walkthrough of how to get your very own free Minecraft server up and running on Release.&nbsp;</p><p>I highly recommend following along on the video tutorial. I’ve included step by step instructions for anyone that learns better through reading or if you’re confused about a step.</p><p>If you want to see a live version of this setup, we fired up our own Minecraft server that we built using these steps. So if you’re bored over the Holidays, pop in and say hello! Here’s our Server name if you want to say hi.</p><blockquote><p><strong>Play Minecraft With Us on the Release Team Minecraft Server</strong></p><p><strong>team-release-minecraft.releaseapp.io</strong></p></blockquote><h2 id="full-video-walkthrough-of-this-tutorial">Full video walkthrough of this tutorial</h2><h2 id="detailed-instructions-to-get-your-minecraft-server-up-and-running">Detailed instructions to get your Minecraft Server up and running</h2><h2 id="background">Background</h2><p>At the time of this writing, we have a <a href="https://releaseapp.io/pricing-page" target="_blank" rel="noreferrer">“Starter” plan</a> that’s free so you can give this a shot and have some Holiday fun on Release. Since we’re hosting all of the environments on Release on the starter plan we have a limitation of 2Gb/container. That’s sufficient for a Minecraft server for your kids and their friends.</p><p>To get started, take a look at&nbsp;<a href="https://github.com/awesome-release/docker-minecraft-server" target="_blank" rel="noreferrer">https://github.com/awesome-release/docker-minecraft-server</a>, which we cloned from <a href="https://github.com/itzg/docker-minecraft-server" target="_blank" rel="noreferrer">itzg</a>. Fork or clone this repo into your GitHub account so you’ve got your own version of it to play around with.</p><p>Once you’ve got your own repo to work with, I recommend taking a quick read through the <a href="https://github.com/awesome-release/docker-minecraft-server/blob/master/README.md" target="_blank" rel="noreferrer">README</a>, there are a lot of configuration options and the documentation is extremely well done.&nbsp;</p><p>We’re also going to use the <a href="https://github.com/rcon-web-admin/rcon-web-admin" target="_blank" rel="noreferrer">Rcon Web Administrative portal. Take a look at the documentation</a>, <em>specifically the environment variables that can be configured.</em> itzg made a version of this for Docker called <a href="https://github.com/itzg/docker-rcon-web-admin" target="_blank" rel="noreferrer">docker-rcon-web-admin</a> that we are using when when we load the rcon and rcon-ws services in this tutorial.</p><p>For this walkthrough, we’re going to bring up a vanilla Minecraft server with an Rcon administrative portal running in a standalone container. This will let you and your kids have full control over the Minecraft server and ban friends who can’t fight off Zombie Pig Men.  Here’s an overview of what the system architecture looks like.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2wNwcLD1zGZRa5lebjeTtx/1f910bef3c2f3b07bdb076b6185493f9/Screen_Shot_2020-12-14_at_4.50.14_PM.png" alt="High level overview of Minecraft with Rcon"></p><p>The master branch of this repo is already setup to work with this docker-compose file in Release. Take a look at the .release.yaml file in the root of the repo’s directory. </p><div><pre><p><span>1</span><span>compose: examples/docker-compose-with-rcon.yml</span></p></pre></div><p>This sets the <code>compose</code> directive to `examples/docker-compose-with-rcon.yml’ which tells Release that’s the docker-compose file you want to use. If you want to play around with a Forge server or other examples, just point the .release.yaml file at the corresponding docker-compose.</p><h2 id="1-create-a-new-application-in-release">1. Create a new application in Release</h2><p>Ok, let’s setup the server.</p><ul><li>Fork, clone or copy this repo: <a href="https://github.com/awesome-release/docker-minecraft-server" target="_blank" rel="noreferrer">https://github.com/awesome-release/docker-minecraft-server</a> <a href="https://docs.github.com/en/free-pro-team@latest/github/creating-cloning-and-archiving-repositories/duplicating-a-repository" target="_blank" rel="noreferrer">Here are some simple instructions on how to copy this repo over to your account.</a></li><li>Login or create an account on Release here: <a href="https://releaseapp.io/" target="_blank" rel="noreferrer">https://releaseapp.io</a></li><li>Follow the steps to create your account. Once your account is created, click the “Create an application” button.</li></ul><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/6VWjyyZyzQTIMKKOhMtDJR/968a10010225386a27a2fd8140bdf11c/Screen_Shot_2020-12-17_at_8.34.49_AM.png" alt="Create new app button"></p><ul><li>Select your <code>docker-minecraft-server</code> repo. If you don’t see it in the list, click <code>Configure the Release app on Github</code> link to assign permissions to your repo.</li></ul><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/150rdMfSZdsZNfKjAO2wnp/58321bf2af11408179188ba4af26b477/Screen_Shot_2020-12-17_at_8.37.00_AM.png" alt="Select your repo"></p><ul><li>Add a name for your application. Note this name is used in your server hostname.</li><li>Click Generate App Template.&nbsp;</li></ul><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3AKC0zgywkvWOKaMANDqE2/0f6d197f208a81718c4ef13211ba23d2/Screen_Shot_2020-12-17_at_8.38.03_AM.png" alt="Click Generate App Template"></p><h2 id="2-edit-the-generated-application-template">2. Edit the generated application template</h2><p>Release automatically detects and creates an application template from the docker-compose file but there are a few edits we need to make based on how this repo works and to make sure we can fit the server into the Starter plan. If you want to dive in, <a href="https://docs.releaseapp.io/reference-guide/application-settings/application-template" target="_blank" rel="noreferrer">read the documentation about Release Application Templates.</a></p><p>For a little background, take a look at this diagram.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/31tYP2pKpmfWZcrZ1BGXNP/f93c93fea06f66b3c203a3b792eb7268/Screen_Shot_2020-12-17_at_8.56.30_AM.png" alt="docker-minecraft-server networking architecture"></p><p>We need to make our application reflect this networking setup. </p><p>In Release we have two different kinds of loadbalancers based on Amazon’s <a href="https://aws.amazon.com/elasticloadbalancing/?elb-whats-new.sort-by=item.additionalFields.postDateTime&amp;elb-whats-new.sort-order=desc" target="_blank" rel="noreferrer">ELB’s</a> and <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html" target="_blank" rel="noreferrer">ALB’s</a>. </p><p>We also need to make sure we’re using the correct type of port for the use case. There are two types of ports <code>container_port</code> and <code>node_port</code>. In short, a <code>node_port</code> is exposed to the Internet and a <code>conatiner_port</code> is not. Because the rcon service is only internally facing, we want to set its port to a <code>container_port</code>. For more info on setting the correct type of port, <a href="https://docs.releaseapp.io/reference-guide/application-settings/application-template#ports" target="_blank" rel="noreferrer">read about ports in Release</a>.</p><p>So let’s make the changes necessary to setup the Application Template correctly.</p><h3 id="update-memory-to-2gb">Update memory to 2Gb</h3><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/1qhpslhwNOzPwpGPUjFdpg/eeebe9a0fcb4fb89fb2117492bcd777b/Screen_Shot_2020-12-17_at_8.49.13_AM.png" alt="Increase to 2gi"></p><ul><li>The Minecraft server is setup to use 1Gb of max memory so we need to set the default memory limit in Release to 2Gb to leave enough room with some overhead. Edit the app template to allow the services to use up to 2Gb of memory.</li></ul><h3 id="update-hostnames-and-ports">Update hostnames and ports</h3><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2mbzeFvsEzBbHDcZDQZfNs/7a6d72c07e0a2962d1133c72a2863e32/ports-minecraft.gif" alt="Change ports settings on the minecraft service"></p><ul><li>Change the port <code>type</code> for 25575 to <code>container_port</code> and remove the <code>target_port</code> line.</li><li>Add a <code>loadbalancer: true</code> for port 25565.</li><li>Add a hostname field at the same level as ports in the file and set to <code>hostname: my-server-${env_id}-${domain}</code>. You can set <code>my-server</code> to anything you’d like. ${env_id} and ${domain} are variables that Release will automatically fill in to customize your domain.</li></ul><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/5Hq9WPLrep8YTOStorAv72/308cec8a27f9d421a15f151eb5168139/remove-minecraft-alb.gif" alt="remove minecraft alb"></p><ul><li>Remove the ALB hostname for the <code>minecraft</code> service. (We only need the <code>minecraft</code> service exposed on port 25565 via an ELB not an ALB which is for http/https).</li><li>Click “Save and Continue”.</li></ul><h2 id="3-setup-environment-variables">3. Setup Environment Variables</h2><p>We need to set a few passwords via environment variables and an <a href="https://docs.releaseapp.io/reference-guide/reference-examples/environment-variable-mappings" target="_blank" rel="noreferrer">environment variable mapping</a> for the <code>rcon</code> websocket hostname. For more information about these environment variables, see the documentation/README files here:</p><ul><li><a href="https://github.com/awesome-release/docker-minecraft-server/blob/master/README.md#rcon" target="_blank" rel="noreferrer">Rcon environment variables for the <code>minecraft</code> service.</a></li><li><a href="https://github.com/rcon-web-admin/rcon-web-admin#environment-variables" target="_blank" rel="noreferrer">Environment variables for rcon-web-admin</a></li></ul><p>In this diagram we show the passwords that need to be set via environment variables.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3xnIcjv4BCvfY0Ho2byE2p/8f5951634c0a30eae280e3c832d47867/Screen_Shot_2020-12-17_at_10.37.01_AM.png" alt="Passwords via environment variables"></p><h3 id="setup-passwords-via-environment-variables">Setup passwords via environment variables</h3><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3pzhiCBkhpQ8R4JLKv1YEc/7f53d78a57268a98bdf530e520760407/rcon-password.gif" alt="rcon password envs"></p><p>On the <code>minecraft</code> service we need to set a password for its local <code>rcon</code> service on port 25575 so other containers can connect to it. <code>RCON_PASSWORD</code> is the environment variable that needs to be set for this and on the <code>rcon</code> and <code>rcon-ws</code> service we need to set <code>RWA_RCON_PASSWORD</code> to the same value so those services can control the minecraft server.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3Bqx50fbcFEQo8TeLaWRB1/fb36558ae0cf90fd33ae91a01909438b/rwa-password.gif" alt="rcon web password"></p><ul><li>Click on “Edit” for “Default Environment Variables”.</li><li>Set <code>RCON_PASSWORD</code> in the <code>minecraft</code> service and add <code>secret: true</code>. To encrypt this value in the database.</li><li>Set <code>RWA_RCON_PASSWORD</code> to the same value as you set in step 2 on both the <code>rcon</code> and <code>rcon-ws</code> services.</li><li>Set <code>RWA_PASSWORD</code> which will be the default password used for the RCON Web Administration tool in both the <code>rcon</code> and <code>rcon-ws</code> services. Make sure to add <code>secret: true</code> to encrypt this value.</li></ul><h3 id="setup-mapping-of-environment-variable-rwa_websocket_url_ssl">Setup mapping of environment variable RWA_WEBSOCKET_URL_SSL</h3><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/H7q1NXUl6g0oZ6iYgjnMH/c49e8375ed880c46c302dbb0468f2cd2/Screen_Shot_2020-12-17_at_10.55.38_AM.png" alt="rwa webscoket hostname mapping"></p><p>The last environment variable we need to add is a mapping that tells Release to map <code>RWA_WEBSOCKET_URL_SSL</code> to a dynamically created environment variable for hostnames created in Release <code>RCON_WS_INGRESS_HOST</code>.  <code>RWA_WEBSOCKET_URL_SSL</code> tells the Rcon Web Admin tool which container host url is running the websocket for this service which is on our <code>rcon-ws</code> service on port 4327. </p><p><code>RCON_WS_INGRESS_HOST</code> is automatically created everytime a new environment is created by Release and always conatins the correct hostname for <code>rcon-ws</code>. This value can change when new environments are created, thus we can’t just hard set <code>RWA_WEBSOCKET_URL_SSL</code>.  This is where an environment variable mapping comes into play. The diagram above represents the change we need to add in our Default Environment Variables.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/1W93m0C2YME1uskGVo6fqA/d1c09555747b8d2578f597a44c3fd3d8/env-mappings.gif" alt="set env mapping"></p><ul><li>Add a <code>mapping:</code> directive and map <code>RWA_WEBSOCKET_URL_SSL</code> to the top of the file.</li></ul><div><pre><p><span>1</span><span>mapping:</span></p><p><span>2</span><span>  RWA_WEBSOCKET_URL_SSL: wss://${RCON_WS_INGRESS_HOST}</span></p></pre></div><p>When these chages and your env passwords have been made, your file should look like this:</p><div><pre><p><span>1</span><span>---</span></p><p><span>2</span><span>mapping:</span></p><p><span>3</span><span>  RWA_WEBSOCKET_URL_SSL: wss://${RCON_WS_INGRESS_HOST}</span></p><p><span>4</span><span>defaults:</span></p><p><span>5</span><span>- key: RWA_RCON_HOST</span></p><p><span>6</span><span>  value: minecraft</span></p><p><span>7</span><span>services:</span></p><p><span>8</span><span>  minecraft:</span></p><p><span>9</span><span>  - key: EULA</span></p><p><span>10</span><span>    value: 'TRUE'</span></p><p><span>11</span><span>  - key: MAX_MEMORY</span></p><p><span>12</span><span>    value: 1G</span></p><p><span>13</span><span>  - key: ENABLE_RCON</span></p><p><span>14</span><span>    value: true</span></p><p><span>15</span><span>  - key: RCON_PASSWORD</span></p><p><span>16</span><span>    value: "rcon_password"</span></p><p><span>17</span><span>    secret: true</span></p><p><span>18</span><span>  - key: VIEW_DISTANCE</span></p><p><span>19</span><span>    value: 15</span></p><p><span>20</span><span>  - key: MAX_BUILD_HEIGHT</span></p><p><span>21</span><span>    value: 256</span></p><p><span>22</span><span>  rcon:</span></p><p><span>23</span><span>  - key: RWA_RCON_HOST</span></p><p><span>24</span><span>    value: minecraft</span></p><p><span>25</span><span>  - key: RWA_RCON_PASSWORD</span></p><p><span>26</span><span>    value: "rcon_password"</span></p><p><span>27</span><span>    secret: TRUE</span></p><p><span>28</span><span>  - key: RWA_PASSWORD</span></p><p><span>29</span><span>    value: "rwa_password"</span></p><p><span>30</span><span>    secret: true</span></p><p><span>31</span><span>  rcon-ws:</span></p><p><span>32</span><span>  - key: RWA_RCON_HOST</span></p><p><span>33</span><span>    value: minecraft</span></p><p><span>34</span><span>  - key: RWA_RCON_PASSWORD</span></p><p><span>35</span><span>    value: "rcon_password"</span></p><p><span>36</span><span>    secret: TRUE</span></p><p><span>37</span><span>  - key: RWA_PASSWORD</span></p><p><span>38</span><span>    value: "rwa_password"</span></p><p><span>39</span><span>    secret: true</span></p></pre></div><ul><li>Click ‘Save &amp; Deploy’</li></ul><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/FKamQWEAPHoWSCN6y3rIJ/05f8d3e75578b3042fe253226625dc03/deploy-and-inspect.gif" alt="deploy and view environment"></p><ul><li>Your environment is now deploying, you can click on the deploy and watch its progress. When it’s done, navigate to the environment screen and inspect your created hostnames.</li></ul><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/tsY55jHlEsGV1qQdVtJRl/3590ce1e1adde7289c182ed44d708d17/setup-minecraft-server.gif" alt="Setup minecraft server"></p><ul><li>Using the <code>minecraft</code> hostname that was created by Release, create a new server within the Minecraft Client.</li></ul><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2bqtxnSkRmiTzFGDPe2nJw/13e466cf36005fac0ba61dd1a4501e31/rcon-web-admin.gif" alt="rcon web admin tool"></p><ul><li>Click on the <code>rcon</code> hostname that was created by Release to access the RCON Web Admin user interface.</li><li>Login using the same password you set for the <code>RWA_PASSWORD</code> environment variable.</li><li>Add the <code>minecraft</code> server.</li><li>Add the <code>console</code> widget.</li><li>Run admin commands on your server!</li></ul><h2 id="what-if-it-doesnt-work">What if it doesn’t work???</h2><p>If for any reason you made a mistake and something doesn’t work. You can navigate to your App Settings and edit your Application Template and your Default Environment Variables. Double check you’ve made the proper settings. Once you’ve made these edits, navigate to your environments screen, delete your environment and create a new one. The …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.releaseapp.io/blog/free-minecraft-server-running-on-releaseapp-io">https://blog.releaseapp.io/blog/free-minecraft-server-running-on-releaseapp-io</a></em></p>]]>
            </description>
            <link>https://blog.releaseapp.io/blog/free-minecraft-server-running-on-releaseapp-io</link>
            <guid isPermaLink="false">hacker-news-small-sites-25461374</guid>
            <pubDate>Thu, 17 Dec 2020 22:31:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SuperRT – an expansion chip for realtime raytracing on the SNES]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25460982">thread link</a>) | @app4soft
<br/>
December 17, 2020 | https://shironekolabs.com/posts/superrt/ | <a href="https://web.archive.org/web/*/https://shironekolabs.com/posts/superrt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        
        
        <h2>
        December 13, 2020
        <br>
        
        </h2>
    </header>
    <section id="post-body">
        <p><strong>Video links for this article:</strong></p>

<ul>
<li><a href="https://youtu.be/VeFF344NbZ4">Short trailer</a></li>
<li><a href="https://youtu.be/2jee4tlakqo">Walkthrough and technical details</a></li>
</ul>

<p>I’m pleased to finally have some results to show for a project I’ve been working on in my spare time for the last year or so.</p>

<p>The idea originated when I was trying to think of an interesting idea for a project to help me learn Verilog and FPGA design, and the notion of building a simple raytracer came to mind (partly inspired by a scarily smart friend of mine who is building his own GPU). A bit later - because sometimes my brain hates me and delights in coming up with silly things to do - this turned into “wouldn’t it be interesting to try making a SNES do raytracing?”, and thus the SuperRT chip idea was born.</p>

<p>What I wanted to try and do was something akin to the Super FX chip used in titles such as Star Fox, where the SNES runs the game logic and hands off a scene description to a chip in the cartridge to generate the visuals. To that end I’ve deliberately tried to restrict myself to just using a single custom chip for the design, not making use of the ARM core available on the DE10 board or any other external processing resources.</p>

<p>The end results look something like this:</p>

<p>
 <video width="320" height="240" autoplay="" loop="">
  <source src="https://shironekolabs.com/posts/superrt/Bubbles2.mp4" type="video/mp4">
  SuperRT scene example video
 </video> 
</p>

<blockquote>
<p>Apologies for the poor screenshot quality, incidentally - for some reason my capture card produces terrible results when capturing from my SNES, so I had to resort to the good old “photograph the screen in a darkened room” approach.</p>
</blockquote>

<p><img src="https://shironekolabs.com/posts/superrt/Hardware.jpg" alt="SuperRT development hardware"></p>

<p>The Super Nintendo (technically a Super Famicom) seen here has had the case removed to make room for the cabling, but other than that is totally unmodified. Attached to it is the PCB from a copy of an <em>awful</em> Pachinko game I picked up for 100 yen at a local second-hand store, with the game ROM removed and replaced with a cable breakout. This then passes through a set of level shifters to convert the SNES’s 5v down to 3.3v and then into a DE10-Nano FPGA development board with a Cyclone V FPGA. The level shifter boards are anything but pretty - and assembling them was a nightmare thanks to the necessary ICs only being available in surface-mount packages - but they do the job.</p>

<p><img src="https://shironekolabs.com/posts/superrt/Slide3.jpg" alt="Hardware layout diagram"></p>

<p>The SuperRT chip constructs the scene using a specialised command language which is executed by one of three parallel execution units on the chip - essentially specialised CISC processors - to perform ray intersection tests. The scene description allows objects to be constructed using a subset of CSG operations, using spheres and planes as the basic building blocks and then performing OR, AND and subtraction operations using them to build up the desired geometry. AABBs are also supported, although primarily for use in culling tests (they can be rendered if desired, but they have a lower positional accuracy than other primitives and thus this is not generally very useful except for debugging purposes).</p>

<p>
 <video width="320" height="240" autoplay="" loop="">
  <source src="https://shironekolabs.com/posts/superrt/Artefact.mp4" type="video/mp4">
  SuperRT scene example video
 </video> 
</p>

<p>The renderer casts up to four rays per screen pixel, calculating direct shadows from a directional light source and a single reflection bounce. Surfaces each have a diffuse colour and reflectivity property, and it’s possible to apply modifiers to these based on CSG results or specialised functions - this is used to generate the checkerboard pattern on the floor.</p>

<p><img src="https://shironekolabs.com/posts/superrt/Slide2.jpg" alt="SuperRT screenshot"></p>

<p>The ray colour for each pixel is calculated by a “ray engine”, which handles the overall ray lifecycle and uses an “execution engine” module to run the command program describing the scene as many times as is required to resolve the ray. The command program itself is uploaded from the SNES and stored in a local 4K RAM buffer - animation is performed by writing modified commands into this buffer as required. A disassembled command buffer looks like this:</p>

<pre><code>0000 Start
0001 Plane 0, -1, 0, Dist=-2
0002 SphereSub OH 2, 1, 5, Rad=5
0003 SphereSub OH 4, 1, 4, Rad=4
0004 SphereSub OH 5, 1, 9, Rad=9
0005 SphereSub OH 2, 1, 2, Rad=2
0006 SphereSub OH -0.5, 1, 2, Rad=2
0007 RegisterHitNoReset 0, 248, 0, Reflectiveness=0
0008 Checkerboard ORH 48, 152, 48, Reflectiveness=0
0009 ResetHitState
0010 Plane 0, -1, 0, Dist=-2.150146
0011 RegisterHit 0, 0, 248, Reflectiveness=153
0012 AABB 4, -2.5, 11,    8, 3.5, 13
0013 ResetHitStateAndJump NH 44
0014 Origin 6, 2, 12
0015 Plane -0.2929688, 0, -0.9570313, Dist=0.2497559
0016 PlaneAnd OH 0.2919922, 0, 0.9560547, Dist=0.25
0017 PlaneAnd OH 0, 1, 0, Dist=1
0018 PlaneAnd OH 0, -1, 0, Dist=4
0019 PlaneAnd OH -0.9570313, 0, 0.2919922, Dist=-1
0020 PlaneAnd OH 0.9560547, 0, -0.2929688, Dist=1.499756
0021 RegisterHit 248, 0, 0, Reflectiveness=0
</code></pre>

<p>Each execution engine is a processor module with a 14 cycle pipeline, and in general one instruction is retired per cycle, so each execution unit can calculate about 50 million sphere, plane or AABB intersections per second. The exception to this is that branch operations have to flush the entire pipeline and thus have a  16 cycle overhead (14 cycles to flush the pipeline + 2 cycles instruction fetch delay). To try and avoid this as much as possible a branch prediction system is used - fortunately a lot of the time the spatial coherency of nearby rays means that a high prediction hit rate is achievable.</p>

<p><img src="https://shironekolabs.com/posts/superrt/Slide5.jpg" alt="SuperRT screenshot"></p>

<p>Intersections in the execution engine are carried out by two pipelines, one handling AABBs and the other spheres and planes. The system as a whole works exclusively using 32-bit integer maths in 18.14 fixed point format, with 16-bit (2.14) format used where values are known to be in the +-1 range, and the sphere/plane intersection pipeline has two dedicated additional maths units that calculate reciprocal and square root operations.</p>

<p>
 <video width="320" height="240" autoplay="" loop="">
  <source src="https://shironekolabs.com/posts/superrt/Light.mp4" type="video/mp4">
  SuperRT scene example video
 </video> 
</p>

<p>Once a frame is rendered, the PPU converter module turns the framebuffer into a format that can be DMAed directly to the SNES VRAM for display, reducing it to 256 colours and swizzling it into character tile bitplanes. The screen resolution is 200x160 - this results in exactly 32000 bytes of image data for a full frame, which is transferred to VRAM in two 16000 bytes chunks over successive frames due to bandwidth constraints. Thus the full image can only be refreshed once every two frames, effectively limiting the maximum framerate to 30FPS - although the test scene runs at closer to 20FPS (primarily due to some bottlenecks with the logic on the SNES side at present).</p>

<blockquote>
<p>Many thanks to the participants in <a href="https://forums.nesdev.com/viewtopic.php?f=12&amp;t=20068">this thread</a> over at SNESdev for a lot of useful ideas on fullscreen expansion chip DMA that inspired the solution used here.</p>
</blockquote>

<p><img src="https://shironekolabs.com/posts/superrt/Slide4.jpg" alt="SuperRT screenshot"></p>

<p>The chip also implements a number of other basic functions - there is an interface to the SNES cartridge bus, along with a small program ROM holding 32K of code for the SNES (this is constrained by the fact that the interface board currently only connects up the SNES Address Bus A lines, and thus the effective usable address space is a mere 64K, of which 32K is used for memory-mapped IO registers to communicate with the SuperRT chip). There is also a multiplication accelerator unit that lets the SNES perform 16x16bit multiply operations rapidly.</p>

<p><img src="https://shironekolabs.com/posts/superrt/Shot13.jpg" alt="SuperRT screenshot"></p>

<p>For debugging, I used the HDMI interface on the DE10 board to output data to a second monitor, along with a Megadrive joypad connected to the GPIO pins to manipulate the debug system. Resource constraints mean that this has to be disabled if all three ray engine cores are enabled, however.</p>

<p>So that’s a broad overview of the system - I intend to post some articles giving more details of how individual components work in the near future. In the meantime, though, if you have any questions or thoughts then please get in touch and I’ll do my best to answer!</p>

<p>Many thanks to Matt, Jaymin, Rick and everyone else who has helped with advice, inspiration and support!</p>

<p>
 <video width="320" height="240" autoplay="" loop="">
  <source src="https://shironekolabs.com/posts/superrt/PanDown.mp4" type="video/mp4">
  SuperRT scene example video
 </video> 
</p>

<p><em>“SNES” and “Super Nintendo” are trademarks of Nintendo Co Ltd. This is a hobby project and completely unassociated with Nintendo.</em></p>

    </section>
</article></div>]]>
            </description>
            <link>https://shironekolabs.com/posts/superrt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25460982</guid>
            <pubDate>Thu, 17 Dec 2020 21:51:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop solving problems nobody complained about]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25460113">thread link</a>) | @mcrittenden
<br/>
December 17, 2020 | https://critter.blog/2020/12/17/stop-solving-problems-nobody-complained-about/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/17/stop-solving-problems-nobody-complained-about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1973">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>You don’t know a problem exists if nobody has complained to you about it. </p>



<p>You can’t assume that problem X annoys anyone. You can’t even ask them “are you annoyed by X?” because then they might decide they are even if they’ve never thought about it before. And if they’ve never thought about it before, then it’s not a problem worth solving.</p>



<p>The book <a href="https://www.goodreads.com/book/show/52283963-the-mom-test">The Mom Test</a> is about the art of sneakily uncovering people’s problems without letting them tell you what you want to hear. If you go to your mom with an idea, then she’s going to support it no matter how dumb it is. </p>



<p>Here’s how it goes down:</p>



<blockquote><p><em>You</em>: “Hey Ma, it’s pretty frustrating to kick your dog’s food bowl and spill it everywhere, right?” </p><p><em>Mom</em>: “Yes honey, that is frustrating!”</p><p><em>You</em>: “Well what would you say if I created a food bowl that automatically covered itself when it got kicked?!”</p><p><em>Mom</em>: “That sounds like a great idea! I’d buy that!”</p></blockquote>



<p>And now you have validated an idea for a product nobody would ever buy, because you led her to the answer you wanted. Good job.</p>



<p>How about this?</p>



<blockquote><p><em>You</em>: “Hey Ma, why is there dog food all over the floor?”</p><p><em>Mom</em>: “Oh I just kicked it accidentally.”</p><p><em>You</em>: “Does that happen a lot?”</p><p><em>Mom</em>: “Nope, that’s the first time. Usually I keep the dog bowl in that corner so it’s out of the way, but I was sweeping this morning.”</p></blockquote>



<p>See the difference? When you don’t lead her to the answer you’re looking for, you get a real answer. This problem isn’t a problem.</p>



<p>I see this a lot with <a href="https://critter.blog/2020/09/01/pretend-your-internal-initiative-is-a-startup/">internal initiatives</a>. People <em>assume</em> that a problem frustrates their coworkers, because why wouldn’t it? So they end up with agile transformations that address all the wrong issues or internal technology platform teams that build all the wrong tools. </p>



<p>The book <a href="https://www.goodreads.com/en/book/show/32493686">When Coffee &amp; Kale Compete</a> talks about this in the context of <a href="https://critter.blog/2020/08/24/jobs-to-be-done-is-a-terrible-name/">Jobs To Be Done</a>. It says that you should look for the <em>fire </em>around a problem. If someone gets fired up when they talk about a problem they’re having, that one is worth solving.</p>



<p>Stop solving problems that nobody’s fired up about.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/17/stop-solving-problems-nobody-complained-about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25460113</guid>
            <pubDate>Thu, 17 Dec 2020 20:40:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse engineering the Nest home/away API]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25459560">thread link</a>) | @emilburzo
<br/>
December 17, 2020 | https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/ | <a href="https://web.archive.org/web/*/https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
<p>A while ago I purchased a Nest camera because I liked the idea of only having to provide power and a WiFi connection to get a nice security system.</p>
<p>The fact that you could control it with <a href="https://support.google.com/googlenest/answer/9293712?hl=en">Works with Nest</a> (their open API) was a major factor in that decision.</p>
<p>Then Google bought Nest, and <a href="https://www.consumerreports.org/smart-home/things-to-know-about-works-with-nest-shutdown/">disabled access</a> for users who didn’t sign up in time (including me).</p>
<p>There were some promises that a new open API will be created “soon”.</p>
<p>Eventually, they released the <a href="https://developers.google.com/nest/device-access/api">Smart Device Management API</a>, and although you can do some things (get camera stream), you can’t set the “Home/Away” status.</p>
<p>Bummer.</p>

<p>You can read more about it <a href="https://support.google.com/googlenest/answer/9257400">here</a>, but <strong>TL;DR</strong> the Nest camera movement/sound alarms only trigger if it’s set to “Away”.</p>
<p>For reasons I don’t want to go into, the automatic Home/Away feature doesn’t work for me so I need a way to control it from code so it can be automated, as all good things.</p>

<p>Like all pros, my first try was to just open the Nest webapp with DevTools open, click the Home/Away toggle, copy as curl, run it from the CLI and… nothing.</p>
<p>Didn’t work.</p>
<p>Upon closer inspection I noticed the payload was binary, never a good sign :)</p>
<div><pre><code data-lang="bash">curl --data-binary <span>$'\nB\n\u001aSTRUCTURE_XXXXXXXXXXXXXXXX\u0012$XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\u0012\u0095\u0001\n\u000estructure_mode\u0012u\nTtype.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeRequest\u0012\u001d\u0008\u0002\u0010\u0001\u001a\u0017\n\u0015USER_XXXXXXXXXXXXXXXX\u001a\u000c\u0008ü¸Ìþ\u0005\u0010\u0080É\u0087¸\u0001'</span> <span>'https://grpc-web.production.nest.com/nestlabs.gateway.v1.ResourceApi/SendCommand'</span>  
</code></pre></div><p>(some details redacted)</p>

<p>The host endpoint at the end of the <code>curl</code> command was a very good hint that they are using <a href="https://grpc.io/">gRPC</a>, which I didn’t have any experience with so far.</p>
<p>On the gRPC website was our next clue:</p>
<blockquote>
<p>Define your service using Protocol Buffers, a powerful binary serialization toolset and language</p>
</blockquote>
<p>That matches the binary payload that we previously saw, now it’s getting exciting!</p>

<p>Since the simple payload replay didn’t do anything, I needed to figure out what’s actually in there.</p>
<p>The first (surprising) problem was actually just getting the binary payload into a text file, I guess the binary was getting messed up somewhere between the browser and the file I was pasting to.</p>
<p>The “Save all as HAR with content” feature was very helpful here, especially since there’s a base64 encoded field beneath the binary one.</p>
<p>Extracting that only took a bit of bash magic:</p>
<div><pre><code data-lang="bash">cat set-away-home.nest.com.har                           <span>\
</span><span></span>    | gron                                               <span>\
</span><span></span>    | grep <span>'json.log.entries[1].response.content.text'</span>   <span>\
</span><span></span>    | cut -d <span>'"'</span> -f <span>2</span>                                    <span>\
</span><span></span>    | base64 -d                                          <span>\
</span><span></span>    | base64 -d
</code></pre></div><p>(If you don’t know about <a href="https://github.com/tomnomnom/gron">gron</a>, you should definitely check it out, it makes JSON grep-able)</p>
<p>(No idea why it was base64-encoded twice)</p>

<p>Going through the official protobuf documentation it seemed like I needed the <code>.proto</code> files to do anything useful.</p>
<p>Which I couldn’t figure out how to extract from the Nest website, or if that’s even possible.</p>
<p>Luckily, I stumbled upon <code>protoc --decode_raw</code>, which gave the following output:</p>
<pre><code>1 {
  1 {
    1: "STRUCTURE_XXXXXXXXXXXXXXXX"
    2: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
  }
  2 {
    1 {
      1: "STRUCTURE_XXXXXXXXXXXXXXXX"
      2: "structure_mode"
      3: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
    }
    2: 4
    4 {
      1 {
        1: "type.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeResponse"
        2 {
          1: 1
        }
      }
    }
    6 {
      1 {
        1: "STRUCTURE_XXXXXXXXXXXXXXXX"
        2: "structure_mode"
        3: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
      }
      2 {
        1: "type.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeRequest"
        2 {
          1: 2
          2: 1
          3 {
            1: "USER_XXXXXXXXXXXXXXXX"
          }
        }
      }
      3 {
        1: XXXXXXXXXX
        2: XXXXXXXXX
      }
    }
  }
}
15: ""
2: ""
15: "\000\000"
</code></pre><p>Quite a heavy payload to set a flag.</p>
<p>Then I tried to manually create the <code>.proto</code> files going by the output from above.</p>
<p>Not fun.</p>
<p>By luck (aka searching GitHub for those types) I found out that somebody a lot smarter than me had actually <a href="https://github.com/derek-miller/nest-protobuf">managed to extract the proto files</a> from the Nest website, thank you stranger!</p>

<p>Time to make use of those <code>.proto</code> files.</p>
<p>Start up the IDE and follow the protobuf tutorial on how to build a payload.</p>
<p>It was a lot harder than I expected.</p>
<p>I’m sure most of the hardness came from me never using protobuf before, but it also took me a bit to realize that they serialize the command we care about (<code>StructureModeChangeRequest</code>) into a generic type (<code>ResourceCommandRequest</code>) which is then also serialized.</p>
<p>Eventually I was able to send the protobuf payload to the Nest API and oh boy, seeing that icon switch from “Home” to “Away” was like an early christmas :)</p>
<p><img src="https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/images/nest-home-away.gif" alt="Nest home to away animation"></p>
<p>Hmm, but why isn’t the HTTP connection closing? It just hangs there.</p>
<p>Comparing the headers from the original request I could see that there’s an <code>X-Accept-Response-Streaming: true</code> header, adding it caused the connection to directly close as expected.</p>
<p>Strange, especially since <code>false</code> keeps the connection open. Mystery for another day.</p>
<p>I packaged everything nicely into a <a href="https://github.com/emilburzo/nest-rest">GitHub repo</a> and moved on to the last part.</p>

<p>The standard approach here would be to install some location tracker on all the “home” phones and periodically send it to a server which then decides when to toggle the Nest status.</p>
<p>Although I actually built an <a href="https://graticule.link/">android location sharing app</a>, I didn’t like this approach due to having to make a tradeoff between battery life and responsiveness.</p>
<p>I also looked into Google Location Sharing, but it involved creating another Google Account, permanently sharing my location with it and using that as the source. Too fragile.</p>
<p>The solution I went with in the end was:</p>
<ul>
<li>assign static IPs to all the relevant phones</li>
<li>try to connect to them from the internal network</li>
</ul>
<p>If the response is <code>connection refused</code>, they are on the network/“home”.</p>
<p>Anything else, they aren’t “home”.</p>
<p>Well, maybe also <code>connection accepted</code> if you’re weird and have a server on your phone.</p>
<p>I’m still surprised how well this works, because I read a lot of “don’t do this” online with reasons like:</p>
<ul>
<li>phones will automatically switch off their WiFi overnight</li>
<li>they won’t respond when they are in deep sleep</li>
<li>etc</li>
</ul>
<p>Maybe I got lucky, but it works, and it works very well:</p>
<pre><code>2020-12-17 09:36:07 INFO     found hosts: ['192.168.0.30', '192.168.0.31']
2020-12-17 09:36:07 INFO     192.168.0.30 is home
2020-12-17 09:36:09 INFO     set status to: home (200)
2020-12-17 09:41:09 INFO     192.168.0.30 is home
2020-12-17 09:46:13 INFO     192.168.0.31 is home
2020-12-17 09:51:17 INFO     192.168.0.31 is home
[..]
2020-12-17 11:17:29 INFO     set status to: away (200)
2020-12-17 12:35:11 INFO     192.168.0.31 is home
2020-12-17 12:35:12 INFO     set status to: home (200)
2020-12-17 12:40:16 INFO     192.168.0.31 is home
</code></pre><p>The switch from Away -&gt; Home is quicker than doing it by hand :)</p>
<p>I prepared another <a href="https://github.com/emilburzo/nest-home-away">GitHub repo</a>, fired everything up, and… it works!</p>

<p>It really sucks that I had to spend a day for something that either should just work, or at least I should have access to change on my own.</p>
<p>If the camera quality wasn’t so high I would have just ditched it and gone self-hosted with a DVR/NVR.</p>
<p>It would have taken longer to build all the features, but then I have control over every part.</p>
<p>The Nest app is still annoying me to migrate to a Google account, so let’s see for how long this solution actually works.</p>
    </div></div>]]>
            </description>
            <link>https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25459560</guid>
            <pubDate>Thu, 17 Dec 2020 19:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DRY Is a Trade-Off]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25459506">thread link</a>) | @soopurman
<br/>
December 17, 2020 | https://orbifold.xyz/dry-trade-off.html | <a href="https://web.archive.org/web/*/https://orbifold.xyz/dry-trade-off.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
Fri 11 December 2020

by <a href="https://orbifold.xyz/author/moshe-zadka.html">Moshe Zadka</a>
 


        </p></div><div><p>DRY,
or
<a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">Don't Repeat Yourself</a>
is frequently touted as a principle of software development.
"Copy-pasta"
is the derisive term applied to a violation of it,
tying together the concept of copying code
and
pasta as description of software development bad practices
(see also
<a href="https://en.wikipedia.org/wiki/Spaghetti_code">spaghetti code</a>).</p>
<p>It is so uniformly reviled that some people call DRY a
"principle"
that you should never violate.
Indeed, some linters even detect copy-paste
so that it can never sneak into the code.
But copy-paste is not a comic-book villain,
and DRY does not come bedecked in primary colors to defeat it.</p>
<p>It is worthwhile to know
<em>why</em>
DRY
started out as a principle.
In particular,
some for some modern software development practices,
violating DRY is the right thing to do.</p>
<p>The main problem with <em>repeating</em> a code chunk
is that if a bug is found,
there is more than one place where it needs to be fixed.
On the surface of it,
this seems like a reasonable criticism.
All code has bugs,
those bugs will be fixed,
why not minimize the cost of fixing them?</p>
<p>As with all engineering decisions,
following DRY
is a
<em>trade-off</em>.
DRY leads to the following issues:</p>
<ul>
<li>Loss of locality</li>
<li>Overgeneralized code</li>
<li>Coordination issues</li>
<li>Ownership issues</li>
</ul>
<div id="loss-of-locality">
<h2>Loss of locality</h2>
<p>The alternative to copy-pasting the code is usually to put it in a
function (or procedure, or a subroutine, depending on the language),
and call it.
This means that when reading through the original caller,
it is less clear what the code does.</p>
<p>When you are debugging, this means we need to "Step into" the function.
While stepping into, it is non-trivial to check the original variables.
If you are doing "print debugging",
this means finding the original source for the function and adding
relevant print statements there.</p>
<p>Especially when DRY is pointed out and reactions are instinctive,
the function might have some surprising semantics.
For example, mutating contents of local variables is sensible
in code.
When you move this  code to a function as a part of a straightforward
DRY
refactoring,
this means that now a function is mutating its parameters.</p>
</div>
<div id="overgeneralized-code">
<h2>Overgeneralized code</h2>
<p>Even if the code initially was the same in both places,
there is no a-priori guarantee that it will stay this way.
For example, one of those places might be called frequently,
and so would like to avoid logging too many details.
The other place is called seldom, and those details are
essential to trouble-shooting frequent problems.</p>
<p>The function that was refactored now has to support an extra parameter:
whether to log those details or not.
(This parameter might be a boolean, a logging level, or even a logging
"object" that has correct levels set up.)</p>
<p>Since usually there is no institutional memory to undo
the DRY refactoring,
the function might add more and more cases,
eventually almost being two functions in one.
If the "copy-pasta" was more extensive,
it might lead to extensive over-generalization:
each place needs a slightly different variation of the functionality.</p>
</div>
<div id="coordination-issues">
<h2>Coordination issues</h2>
<p>Each modification of the
"common"
function now requires testing all of its callers.
In some situations,
this can be subtly non-trivial.</p>
<p>For example,
if the repetition was across different repositories,
now updates means updating library versions.
The person making the change might not even be aware of all the callers.
The callers only find out when a new library version is used in their code.</p>
</div>
<div id="ownership-issues">
<h2>Ownership issues</h2>
<p>When each of those code segments were repeated,
ownership and responsibility were trivial.
Whoever owned the surrounding code also owned
the repeated segment.</p>
<p>Now that the code has been moved elsewhere,
to a
"shared"
location,
ownership can often be muddled.
When a bug is found,
who is supposed to fix it?
What happens if that
"bug"
is already relied on by another use?</p>
<p>Especially in case with reactive DRY refactoring,
there is little effort given to specifying the expected
semantics of the common code.
There might be some tests,
but the behavior that is not captured by tests
might still vary.</p>
</div>
<div id="summary">
<h2>Summary</h2>
<p>Having a common library which different code bases can be relied on is good.
However, adding functions to such a library or libraries should be done
mindfully.
A reviewer comment about
"this code duplicates the functionality already implemented <em>here</em>"
or,
even worse,
something like
<cite>pylint</cite>
code duplication detector,
does not have that context or mindfulness.</p>
<p>It is better to acknowledge the duplication,
perhaps track it via a ticket,
and let the actual
"DRY"
application take place later.
This allows gathering more examples,
thinking carefully about API design,
and make sure that ownership and backwards compatibility issues
have been thought of.</p>
<p>Deduplicating code by putting common lines into functions,
without careful thought about abstractions,
is <em>never</em> a good idea.
Understanding how to abstract correctly is essentially
API design.
API design is subtle, and difficult to do well.
There are no easy short-cuts,
and developing expertise in it takes a long time.</p>
<p>Because API design is such a complex skill,
it is not easy to give general guidelines except one:
wait.
Rushing into an API design does not make a good API,
even if the person rushing <em>is</em> an expert.</p>
</div>
</div></div>]]>
            </description>
            <link>https://orbifold.xyz/dry-trade-off.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25459506</guid>
            <pubDate>Thu, 17 Dec 2020 19:44:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon disallows pointing out paid reviews]]>
            </title>
            <description>
<![CDATA[
Score 963 | Comments 422 (<a href="https://news.ycombinator.com/item?id=25459434">thread link</a>) | @kmod
<br/>
December 17, 2020 | http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/ | <a href="https://web.archive.org/web/*/http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-1067">
<p><span><span>17</span>Dec/20</span><span><a href="http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/#comments">11</a></span></p>

<p>I recently bought a webcam from Amazon (late to the party, I know), and when it came it was fine but not amazing.</p>
<p>When I went through the packaging I saw a little card saying "send us a screenshot of your 5-star review and we'll give you a $10 Amazon gift card":</p>
<p><img src="http://blog.kevmod.com/wp-content/uploads/2020/12/IMG_16902.jpg" alt="$10 for 5-star reviews" width="400/"></p>
<p>I thought that other Amazon shoppers would want to know that this was happening and that the reviews were less trustworthy, so I wrote up a review and submitted it to Amazon.</p>
<p>Yesterday I got a notification that my review was rejected.  I heard of Amazon being ham-fisted about this stuff but it was still shocking that it would happen to me:</p>
<p><img src="http://blog.kevmod.com/wp-content/uploads/2020/12/screenshot.png" alt="Amazon review rejection"></p>
<p>I assume they rejected this due to the first rule, "Feedback on the seller ... should be provided [elsewhere]".  I could understand this being a good policy in some cases, but here they're using it to justify silencing talk about reviews.  I suppose we don't know whether they disallow positive comments about other reviews, but I would guess that that never happens.</p>
<p>I remember that I used to use Amazon ratings as the main driver behind my purchases, so it's sad to see the review system become less helpful over time.  It's extra sad that Amazon would rather try to hide the issue and not improve it.</p>
<p>Update:<br>
My premise was that the reviews section should be helpful for making purchasing decisions.  Some people (including Amazon) are saying that the reviews should be about the product, which is coherent but I would argue makes them less useful.  For example I feel quite helped when a review for chocolate mentions that the chocolate arrived melted -- this is not a review about the product intrinsically, but is still very helpful for deciding whether or not to buy the item.  Similarly, as a purchaser I would want to see a warning that there may be paid reviews for the product, and I was very surprised to learn that Amazon disallows such warnings.</p>
<p>Update 2:<br>
I submitted feedback through the link they requested, and here's the result:</p>
<p>https://www.amazon.com/sp?_encoding=UTF8&amp;asin=B087NN41JH&amp;isAmazonFulfilled=1&amp;ref_=olp_merch_name_1&amp;seller=AD5F1I5PAE5XB</p>
<p>I don't think this serves either goal of educating future purchasers or changing the sellers behavior.</p>
<p>Update 3:<br>
I've chatted with an Amazon rep on the issue, and to their credit they seemed to take it seriously and "noted the report violation against the seller".  They said to expect an update in 2-3 business days, though it's not clear what sort of update it will be.</p>







</div></div>]]>
            </description>
            <link>http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25459434</guid>
            <pubDate>Thu, 17 Dec 2020 19:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business Advice I Ever Received]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25459315">thread link</a>) | @nicotesla
<br/>
December 17, 2020 | https://blog.codelitt.com/best-advice-i-ever-received/ | <a href="https://web.archive.org/web/*/https://blog.codelitt.com/best-advice-i-ever-received/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="Post__Main-Content">
        <div>
          <p>The lessons and advice that have stuck with me over the years and proved themselves over and over have not come from the board room or on the internet. </p><p>The best business advice I ever received came from little mountain towns in the Rocky Mountains. I've read a lot of advice over the years in different publications. In the tech world now, it's hard to go one day without a new blog post coming across your screen. However, I've never come across any advice that has been better than what I learned inside my own family circle growing up. My great-grandfather and grandfather were both successful businessmen that I learned a lot from. Both successful in their own rights, they instilled a pursuit of entrepreneurship in me and taught me how to work smarter. My work ethic and leadership advice comes from years of working side-by-side with my father in the rural Rockies. </p><p>Why does that matter? A couple of these have been echoed with similar sentiments online as well, but these are bits of advice that I know are over a century old and have worked for many people across at least 5 different industries*. As I was responding to a request for advice the other day, I compiled this list and decided to share it here for those who are interested:</p><h2 id="1-worrying-is-like-paying-interest-on-a-debt-that-you-don-t-have">1. Worrying is like paying interest on a debt that you don't have</h2><p>This is probably one of my favorites that I try to remember. Worrying fixes, literally, nothing. Nothing. If you're worried about something, get busy. You solve a big problem by breaking it into a bunch of little problems. One foot in front of the other and press on. You can bury yourself with worry and anxiety to the point where you get paralyzed. On top of doing nothing to help your situation, it hurts you and usually is not based in reality but rather a set of hypotheticals that may or may not happen. You're paying interest on a debt you don't have yet.</p><h2 id="2-work-on-the-mine-not-in-the-mine">2. Work on the mine, not in the mine</h2><p>It's easy as entrepreneurs, small businesses, startups, and even in a small corporate team to want to handle the day-to-day operations/services yourself. That's working <em>in</em> the business. It can be easy to do for many reasons: saving money, doing it "right", wanting to work side by side with the team, etc. Your main focus, however, should be working <em>on </em>the business. This would include stuff like building new business relationships, optimizing processes, talking with customers to improve your product, business development etc. Find the right people, trust them, and focus on your responsibilities which are to keep the company moving forward.</p><h2 id="3-lead-from-the-front">3. Lead from the front</h2><p>Now this is going to seem to counterintuitive to the previous advice, but it's not. While you should always try to be working on your business and not in your business, it's also important lead from the front. Another way to put this advice, is never ask your team to do anything that you wouldn't do yourself. If you have a technology team largely involved in programming, learn a bit of code and their processes. If you have a bakery, work a full day with your team baking. If you expect your team to work 14 hour days on a deadline, then you damn well better be doing the same. This bit of advice fosters mutual respect in your team, helps you understand their challenges so you can move obstacles out of their way, and fosters a culture of collaboration.</p><h2 id="4-persistence-and-hard-work-is-90-of-success">4. Persistence and hard work is 90% of success</h2><p>The other 10% is a bit of luck and brains. The '4-hour Workweek' was a book that spawned a bunch of praise and people looking for an easy fix. The book has good processes and solutions for efficiency, but I've yet to meet a real world entrepreneur that doesn't have to work very hard day in and day out for a number of years before realizing a business that can operate with such little input. If success was easy, we would have an entire world filled with millionaires. As well as hard work, persistence is a common denominator of great people doing great things. Something I heard a while back from Jason Roks could be paraphrased by, "A hacker isn't only a genius writing code. A hacker is defined by persistence -- never giving up until you find your way through or around an obstacle."</p><h2 id="5-the-best-investments-free-your-time-up-for-other-investments-projects">5. The best investments free your time up for other investments/projects</h2><p>I am not quite sure how to best summarize this advice, but the basic principles are working smarter and investing in processes and efficiencies. This goes hand and hand with the advice "Work on the mine, not in the mine." Your time is your most valuable asset that you have to invest - even &nbsp;more so than the capital that is being reinvested into the company. There are only so many hours in the day. Nearly every investment that you make with your time should be doing 1 of 2 things. #1, directly impacting revenue or #2, improving a process*. If you're doing #2 then it should be a process that allows more of #1. 20% of your effort gets, 80% of the results. In your own business, find what that 20% is that works and maximize it.</p><hr><ol><li>Probably more. Just 5 that I know of. </li><li>What about stuff like education and employee development? Happy employees impact revenue. You need processes and policies informing employees of their benefits as such. This rule isn't meant to be ruthless. It's meant to drive the question for everything you invest your time in, "How is this impacting revenue and business health?" The truth is many activities, if you asked that question, would not pass the test.</li></ol><hr><h3 id="listen-to-cody-talk-about-the-problems-with-corporate-innovation-on-the-startup-or-start-over-podcast"><a href="https://www.startuporstartover.com/2020/10/corporate-innovation-cody-littlewood/">Listen to Cody talk about the problems with corporate innovation on the Startup or Start Over podcast</a></h3>
        </div>
      </section></div>]]>
            </description>
            <link>https://blog.codelitt.com/best-advice-i-ever-received/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25459315</guid>
            <pubDate>Thu, 17 Dec 2020 19:27:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discord Secures $140M, Doubles Valuation to $7B]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25458833">thread link</a>) | @clashmeifyoucan
<br/>
December 17, 2020 | https://primeunicornindex.com/discord-secures-140m-doubles-valuation-to-7b/ | <a href="https://web.archive.org/web/*/https://primeunicornindex.com/discord-secures-140m-doubles-valuation-to-7b/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-6388">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					<div id="et-boc">
			
		<div>
			<div><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div>
<p>Discord secured $140 million at a valuation of $7 billion if all Series H shares authorized are issued. The communication software company is previously backed by Index Ventures, FirstMark, IVP, and Tencent to name a few. The most recent round, Series H, follows $100 million raised for Series G, valuing the company at $3.55 billion. The terms surrounding the Series H include a pari passu liquidation preference with all other preferred, and conventional convertible meaning they will not participate with common stock if there are remaining proceeds. The most recent price per share is $280.2487, an up round from Series G at $144.1809.</p>
<p>Discord is a Prime Unicorn Index component. Here’s how they are currently tracking against the index:</p>

</div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row --><div>
				<div>
				
				
				<p><a href="https://primeunicornindex.com/q32020reconreport-2/"><span><img loading="lazy" src="https://primeunicornindex.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-17-at-10.06.32-AM.png" alt="" title="Screen Shot 2020-12-17 at 10.06.32 AM" height="auto" width="auto" srcset="https://primeunicornindex.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-17-at-10.06.32-AM.png 650w, https://primeunicornindex.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-17-at-10.06.32-AM-300x228.png 300w, https://primeunicornindex.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-17-at-10.06.32-AM-480x364.png 480w" sizes="(max-width: 650px) 100vw, 650px"></span></a>
			</p>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row --><div>
				<div>
				
				
				<div>
				
				
				<div><p>The Prime Unicorn Index provides a unique opportunity for institutional investors &nbsp;to access a fair representation of the private markets where they can make an investment on the future of their portfolios, whether they want to go long or short.</p>

<p>Additionally, the Index provides up-to-date empirical data used to track today’s private capital markets and offer ways to offset exposure in regard to direct private market investments by taking advantage of the trading opportunities presented by Prime Unicorn Index.</p>

<p>Please&nbsp;<a href="https://primeunicornindex.com/contact/">contact us</a>&nbsp;for information on trading opportunities with the Index.</p>

<p>Follow Prime Unicorn Index on&nbsp;<a href="https://twitter.com/primeunicornidx?lang=en">Twitter</a>&nbsp;and&nbsp;<a href="https://www.linkedin.com/company/prime-unicorn-index/">LinkedIn</a>&nbsp;and be the first to know about early funding rounds and changes in valuations of these fast growing companies listed on the Index.</p>

<p>Bloomberg Ticker:&nbsp;<strong>PUNICORN</strong></p>

<p>Reuters Ticker:&nbsp;<strong>.PUNICORN</strong></p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row --> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->		</div><!-- .et_builder_inner_content -->
	</div><!-- .et-l -->
	
			
		</div><!-- #et-boc -->
							</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

					</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>https://primeunicornindex.com/discord-secures-140m-doubles-valuation-to-7b/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25458833</guid>
            <pubDate>Thu, 17 Dec 2020 18:49:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Cross-Compiling Rust on a Mac for a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25458744">thread link</a>) | @fanf2
<br/>
December 17, 2020 | https://john-millikin.com/notes-on-cross-compiling-rust | <a href="https://web.archive.org/web/*/https://john-millikin.com/notes-on-cross-compiling-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 slot="title">Rustup and Cargo</h2><p><img src="https://john-millikin.com/by-sha256/b049b899f6e55fbbd9a80a31a44c7689068b1ac7050ec5a1a6d425e50cfde69f/Cargo-Logo-Small.png"></p><p>The first build tool I tried is <a href="https://github.com/rust-lang/cargo">Cargo</a>, which I installed with <a href="https://rustup.rs/">rustup</a>. I dislike building with Cargo because it's primitive and inflexible, but since it's the official Rust build tool I hoped it would be the best documented.</p><div><blog-code syntax="toml"><pre># Cargo.toml

[package]
name = "helloworld"
version = "0.0.1"
edition = "2018"

[[bin]]
name = "helloworld"
path = "helloworld.rs"
</pre></blog-code></div><p>Cargo uses the <tt>--target</tt> flag to enable cross-compilation.</p><blog-code syntax="commands"><pre>cargo build --target armv7-unknown-linux-gnueabihf
#    Compiling helloworld v0.0.1 (/Users/john/src/rust-cross-compilation)
# error[E0463]: can't find crate for `std`
#   |
#   = note: the `armv7-unknown-linux-gnueabihf` target may not be installed</pre></blog-code><p>Whereas Go will build its standard library from source when cross-compiling, Rust relies on precompiled libraries<blog-footnote-ref>[<a href="#fn:3">3</a>]</blog-footnote-ref>. We can use <tt>rustup</tt> to fetch a prebuilt <tt>std</tt> for Linux on ARMv7.</p><blog-code syntax="commands"><pre>rustup target add armv7-unknown-linux-gnueabihf
# info: downloading component 'rust-std' for 'armv7-unknown-linux-gnueabihf'
# info: installing component 'rust-std' for 'armv7-unknown-linux-gnueabihf'
# info: using up to 500.0 MiB of RAM to unpack components
#  18.2 MiB /  18.2 MiB (100 %)  11.5 MiB/s in  1s ETA:  0s</pre></blog-code><blog-code syntax="commands"><pre>cargo build --target armv7-unknown-linux-gnueabihf
#    Compiling helloworld v0.0.1 (/Users/john/src/rust-cross-compilation)
# error: linking with `cc` failed: exit code: 1
#   |
#   = note: "cc" "-Wl,--as-needed" "-Wl,-z,noexecstack" "-Wl,--eh-frame-hdr" "-L"
#   [...]
#   "-Wl,-Bdynamic" "-lgcc_s" "-lc" "-lm" "-lrt" "-lpthread" "-lutil" "-ldl" "-lutil"
#   = note: clang: warning: argument unused during compilation: '-pie' [-Wunused-command-line-argument]
#           ld: unknown option: --as-needed
#           clang: error: linker command failed with exit code 1 (use -v to see invocation)</pre></blog-code><p>The source file was successfully compiled, but it couldn't be linked into an executable. It looks like Cargo is trying to use the host system's linker, which will sometimes work, but fails in this particular case because the macOS linker only supports Apple targets.</p><p>Luckily the LLVM project, in addition to the compilation framework, also distributes the cross-platform <a href="https://lld.llvm.org/">LLD</a> linker. While it doesn't cover every platform supported by <tt>rustc</tt>, it does support the common ones. We can configure Cargo to use it for linking our ARMv7 Linux binary.</p><p>I downloaded <a href="https://github.com/llvm/llvm-project/releases/download/llvmorg-11.0.0/clang+llvm-11.0.0-x86_64-apple-darwin.tar.xz"><tt>clang+llvm-11.0.0-x86_64-apple-darwin.tar.xz</tt></a> from <a href="https://releases.llvm.org/download.html">https://releases.llvm.org/download.html</a> and extracted it to <tt>~/.opt/</tt>, then added a <tt>.cargo/config.toml</tt> to my workspace.</p><blog-code syntax="toml"><pre># .cargo/config.toml
[build]

[target.armv7-unknown-linux-gnueabihf]
linker = "/Users/john/.opt/clang+llvm-11.0.0-x86_64-apple-darwin/bin/lld"
</pre></blog-code><blog-code syntax="commands"><pre>cargo build --target armv7-unknown-linux-gnueabihf
#    Compiling helloworld v0.0.1 (/Users/john/src/rust-cross-compilation)
# error: linking with `/Users/john/.opt/clang+llvm-11.0.0-x86_64-apple-darwin/bin/lld` failed: exit code: 1
#   |
#   = note: "/Users/john/.opt/clang+llvm-11.0.0-x86_64-apple-darwin/bin/lld" "-flavor" "gnu" "--eh-frame-hdr" "-L"
#   [...]
#    "-Bdynamic" "-lgcc_s" "-lc" "-lm" "-lrt" "-lpthread" "-lutil" "-ldl" "-lutil"
#   = note: lld: error: unable to find library -lgcc_s
#           lld: error: unable to find library -lc
#           lld: error: unable to find library -lm
#           lld: error: unable to find library -lrt
#           lld: error: unable to find library -lpthread
#           lld: error: unable to find library -lutil
#           lld: error: unable to find library -ldl
#           lld: error: unable to find library -lutil</pre></blog-code><p>Getting closer!</p><p>The linker is being told to build an executable that dynamically links against the GNU libc, which I don't have a copy of. One option here is to download it from (for example) the Ubuntu package hosting, but I don't want to do that because I don't think a Rust binary should be depending on <tt>libc</tt> at all. Rust ought to be considered a replacement for C, rather than a thin layer on top.</p><p>Therefore I'm going to switch the Cargo target to the MUSL variant, which treats <tt>libc</tt> as an implementation detail rather than a core component of the platform.</p><blog-code syntax="commands"><pre>rustup target add armv7-unknown-linux-musleabihf
# info: downloading component 'rust-std' for 'armv7-unknown-linux-musleabihf'
# info: installing component 'rust-std' for 'armv7-unknown-linux-musleabihf'
# info: using up to 500.0 MiB of RAM to unpack components
#  15.8 MiB /  15.8 MiB (100 %)  12.1 MiB/s in  1s ETA:  0s</pre></blog-code><blog-code syntax="toml"><pre># .cargo/config.toml
[build]

[target.armv7-unknown-linux-musleabihf]
linker = "/Users/john/.opt/clang+llvm-11.0.0-x86_64-apple-darwin/bin/lld"
</pre></blog-code><blog-code syntax="commands"><pre>cargo build --target armv7-unknown-linux-musleabihf
#    Compiling helloworld v0.0.1 (/Users/john/src/rust-cross-compilation)
#     Finished dev [unoptimized + debuginfo] target(s) in 1.50s</pre></blog-code><p>Success! The resulting binary is a valid executable for ARMv7 Linux, and can be run as-is on the Raspberry Pi.</p><blog-code syntax="commands"><pre>file target/armv7-unknown-linux-musleabihf/debug/helloworld
# target/armv7-unknown-linux-musleabihf/debug/helloworld: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), statically linked, with debug_info, not stripped</pre></blog-code></div><div><h2 slot="title">Bazel</h2><p><img src="https://john-millikin.com/by-sha256/05daef8103f981c102f1b8486bd7c97f625bdffb14e0ce4875dc4a2ea2b5941e/bazel-icon.svg"></p><p><a href="https://bazel.build/">Bazel</a> is a language-agnostic build system. Its configuration language deals in actions and dependency graphs, rather than executables and libraries, which gives it some interesting scaling properties:</p><ul><li>Building single-language projects with Bazel can be more difficult than using language-specific tools.</li><li>Building multi-language projects is substantially easier in Bazel than in any other build system.</li></ul><p>This makes Bazel a natural choice of build tool for any system that involves (1) FFI, (2) generated code, or (3) well-factored subsystems. It is uniquely capable when compared to Cargo because it can build multiple Rust libraries ("crates") within a single workspace.</p><p>The first step to build Rust with Bazel is to configure the <tt>WORKSPACE</tt> to depend on <a href="https://github.com/bazelbuild/rules_rust">rules_rust</a>. This will also define the default Rust version and edition. There's no need to install toolchains or targets, because Bazel will fetch them on demand.</p><blog-code syntax="python"><pre># WORKSPACE
load("@bazel_tools//tools/build_defs/repo:http.bzl", "http_archive")

http_archive(
    name = "io_bazel_rules_rust",
	# HEAD commit as of 2020-12-05
    urls = ["https://github.com/bazelbuild/rules_rust/archive/67f0c5ec0397d24ccc14264a0eda86915ddf63e8.tar.gz"],
    sha256 = "c587d402e4502100b01e4ba7d9584809cf4f4eb2d2f6634097883637bfb512b1",
	strip_prefix = "rules_rust-67f0c5ec0397d24ccc14264a0eda86915ddf63e8",
)

load("@io_bazel_rules_rust//rust:repositories.bzl", "rust_repositories")

rust_repositories(
    edition = "2018",
    version = "1.48.0",
)
</pre></blog-code><p>Next we need to create a top-level <tt>BUILD</tt> file. This will define a <tt>rust_binary</tt> target for our hello-world executable, and also a <tt>platform</tt> describing what sort of system we want to build for.</p><blog-code syntax="python"><pre># BUILD.bazel
load("@io_bazel_rules_rust//rust:rust.bzl", "rust_binary")

rust_binary(
    name = "helloworld",
    srcs = ["helloworld.rs"],
)

platform(
    name = "linux-armv7",
    constraint_values = [
        "@platforms//os:linux",
        "@platforms//cpu:arm",
    ],
)
</pre></blog-code><p>In the future the Platform would use a more specific <tt>"cpu:armv7"</tt> constraint (<a href="https://github.com/bazelbuild/rules_rust/pull/509">bazelbuild/rules_rust#509</a>) and support constraining on the Rust release channel (<a href="https://github.com/bazelbuild/rules_rust/pull/510">bazelbuild/rules_rust#510</a>).</p><p>Anyway, that should be enough, but if we try running it we'll hit an error about missing toolchains.</p><blog-code syntax="commands"><pre>bazel build //:helloworld --platforms=//:linux-armv7
# [...]
# ERROR: While resolving toolchains for target //:helloworld: no matching toolchains found for types @io_bazel_rules_rust//rust:toolchain</pre></blog-code><p>This is because rules_rust doesn't pre-register toolchains for all supported target platforms – it makes the user register each (host, target) mapping explicitly. We need to tell rules_rust to register a toolchain that can run on macOS (Darwin) and build for ARMv7 Linux.</p><blog-code syntax="python"><pre># WORKSPACE
load("@io_bazel_rules_rust//rust:repositories.bzl", "rust_repository_set")

rust_repository_set(
    name = "rust_linux_armv7",
    edition = "2018",
    exec_triple = "x86_64-apple-darwin",
    extra_target_triples = ["arm-unknown-linux-musleabihf"],
    rustfmt_version = "1.4.20",
    version = "1.48.0",
)
</pre></blog-code><blog-code syntax="commands"><pre>bazel build //:helloworld --platforms=//:linux-armv7
# [...]
# INFO: From Compiling Rust bin helloworld (1 files):
# error: linking with `external/local_config_cc/cc_wrapper.sh` failed: exit code: 1
#   |
#   = note: "external/local_config_cc/cc_wrapper.sh" "-Wl,--as-needed" "-Wl,-z,noexecstack" "-Wl,--eh-frame-hdr" "-nostartfiles"
#   = note: clang: warning: argument unused during compilation: '-no-pie' [-Wunused-command-line-argument]
#           ld: unknown option: --as-needed
#           clang: error: linker command failed with exit code 1 (use -v to see invocation)</pre></blog-code><p>This is the same linker error as we saw with Cargo, and the solution is to tell rules_rust that it should use LLD. However, there's a problem – rules_rust doesn't have its own linker toolchain, it uses the C/C++ toolchain to find a linker.</p><p>We must now contend with the Bazel C/C++ configuration system, which is designed to handle the world's wide range of strange C compilers. I'm not going to give a blow-by-blow here because none of it is relevant to Rust, but a summary is:</p><ul><li>We create a new Bazel package <tt>//cc-toolchain</tt> that will contain the C/C++ configuration. I'm just going to pull in the linker from the filesystem rather than properly <tt>repository_rule</tt> it, so the toolchain file sets will be empty stubs.</li><li>The <tt>CcToolchainConfigInfo</tt> itself requires the path to a bunch of different tools; since the only one needed here is <tt>lld</tt> I'll hardcode the rest to <tt>/bin/false</tt>.</li><li>This project doesn't need to build any C/C++ code for the host (e.g. for codegen), so I'm going to override <tt>--host_crosstool_top</tt> rather than define a true host-compatible toolchain.</li></ul><p>A more complete solution would probably involve the Clang-based toolchains defined in <a href="https://github.com/bazelbuild/bazel-toolchains">https://github.com/bazelbuild/bazel-toolchains</a>.</p><blog-code syntax="python"><pre># cc-toolchain/BUILD

load(":config.bzl", "cc_toolchain_config")

filegroup(name = "empty")

cc_toolchain_suite(
    name = "clang_suite",
    toolchains = {</pre></blog-code></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://john-millikin.com/notes-on-cross-compiling-rust">https://john-millikin.com/notes-on-cross-compiling-rust</a></em></p>]]>
            </description>
            <link>https://john-millikin.com/notes-on-cross-compiling-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-25458744</guid>
            <pubDate>Thu, 17 Dec 2020 18:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralization Deserves a Chance]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25458429">thread link</a>) | @npguy
<br/>
December 17, 2020 | https://p2p.ai/2020/12/17/decentralization-deserves-a-chance/ | <a href="https://web.archive.org/web/*/https://p2p.ai/2020/12/17/decentralization-deserves-a-chance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-73">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>“In crypto, the price is the news” said a smart person on Twitter.  Today, it most definitely is. With Bitcoin blowing past 20K USD and folks in technology and finance struggling to fit narratives to price changes, it is important that in the midst of all the noise around price we don’t lose sight of a very significant and impactful paradigm shift that Bitcoin is an instance of: Decentralization.</p>



<p>The ‘Digital Gold’ narrative has given a very effective model for most of us to understand Bitcoin. But the simplicity of this model is also its curse – it mostly hides the actual promise that Bitcoin represents – that trust can indeed be decentralized, and a ‘hubless’ world is very much possible. In fact, in a digital world where we all increasingly understand that “we are the product” – a move towards such a hubless economy might be inevitable.</p>



<p>It will help to remember that Decentralization is not a discrete point in the space of how economies work, but a continuous spectrum. The most recent changes in economic models that we have witnessed (Hotel chains to AirBnB, Taxi companies to Uber) tell us that directionally, we are definitely moving towards a peer-to-peer (P2P) model for many economic functions – and while there might be attempts to decentralize most functions (very comparable to the Internet), the ones where a P2P model would be the best fit, the model will stick. Crypto (and the token model representing ownership/utility/governance) just happens to be the current transactional framework that enables such economies to function. There will be more. </p>



<p>Unfortunately, Bitcoin – the first instance of this shift – happens to address a very tricky concept: Money. The fact that many of the early cryptocurrencies that came after Bitcoin chose to just refine the concept – improving what Bitcoin did, on parameters like scalability, privacy and programmability, but still focusing on the concept of Money – brought a lot of skepticism and negative commentary to the space. Obviously, if you put anonymity and Money in the same sentence, the interpretations cannot be very positive. The 2017 ICO boom, where many players chose to ignore the regulations set by governments and organizations that oversee fundraising, added strength to the perception that decentralizing trust is not a good idea – and made many smart people both in technology and finance just stay away from Crypto.</p>



<p>So here is the one good thing that the price of Bitcoin does to the space: it brings the attention back. And while we have the attention, it is important for us to ask: If the Internet – with its promise of disintermediation – deserved a chance, if the sharing economy – with its promise of providing more economic opportunities to individuals – deserved a chance, then, with its promise of a P2P world with no hubs that might misuse our trust for profit – Decentralization Deserves a Chance?   </p>













		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://p2p.ai/2020/12/17/decentralization-deserves-a-chance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25458429</guid>
            <pubDate>Thu, 17 Dec 2020 18:17:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Lambda is winning, but first it had to die]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25458325">thread link</a>) | @forrestbrazeal
<br/>
December 17, 2020 | https://acloudguru.com/blog/engineering/aws-lambda-is-winning-but-first-it-had-to-die | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/aws-lambda-is-winning-but-first-it-had-to-die">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p><em>Major feature changes have successfully pushed Lambda workloads into the mainstream, even if FaaS purists feel betrayed</em></p><p>Is serverless winning?</p><p>If you ask AWS, they’ll say <em>definitely</em>. Nearly half of all new applications built inside Amazon this year are <a href="https://siliconangle.com/2020/11/30/exclusive-aws-chief-andy-jassy-wakeup-call-cloud-adoption/">running on Lambda</a>. Andy Jassy took time in his re:Invent keynote to call out the thousands of enterprises who now run Lambda workloads in production, but perhaps most interesting was that this year the new serverless feature announcements graduated to Jassy’s keynote — a spot usually reserved for the flashiest, most strategic reveals of the year. AWS, at least, clearly believes that serverless is now one of the primary selling points for its cloud.</p><p>(On the other hand, there’s <a href="https://thenewstack.io/adoption-of-aws-lambda-serverless-stalls/">this odd article</a>, which spends most of its length demonstrating FaaS growth, but ran under the headline “Serverless Adoption Stalls” because … Kubernetes teams say they aren’t using as much Lambda? In other news, cats report eating fewer vegetables.)</p><p>What’s not in debate is that Lambda, still the 900-pound gorilla of FaaS, looks a lot different today than when it went GA in 2015. The <a href="https://www.linkedin.com/in/forrestbrazeal/">loud, weird niche of engineers</a> who bought into serverless early have always had <a href="https://twitter.com/PaulDJohnston/status/1336765475615879181">very specific ideas</a> about what good serverless systems look like … and lately, Lambda’s been rattling their assumptions.</p><h2 id="h-the-decline-and-fall-of-the-serverless-manifesto">The Decline and Fall of The Serverless Manifesto</h2><p>Those original ideals of FaaS purity didn’t just materialize out of thin air. As recently as 2016, AWS serverless leadership was talking up something they called the Serverless Compute Manifesto. This was a radical vision for how Functions-as-a-Service should, uh, function. The manifesto showed up at <a href="https://www.youtube.com/watch?v=yCOgc3MRUrs">all sorts of talks</a>, including <a href="https://twitter.com/Serverlessconf/status/735839492431548418">at ACG’s ServerlessConf</a>. Here are its key tenets:</p><p><em><strong>The Serverless Compute Manifesto (circa 2016)</strong></em></p><ul><li><em>Functions are the unit of deployment and scaling</em></li><li><em>No machines, VMs, or containers visible in the programming model</em></li><li><em>Permanent storage lives elsewhere</em></li><li><em>Scales per request; Users cannot over- or under-provision capacity</em></li><li><em>Never pay for idle (no cold servers/containers or their costs)</em></li><li><em>Implicitly fault-tolerant because functions can run anywhere</em></li></ul><p>This manifesto formed a shocking and highly countercultural blueprint for how to build and deploy software. It attracted a small but vibrant community of true believers and a somewhat larger and much louder set of skeptics.&nbsp;</p><p>But in retrospect, the serverless compute manifesto had trouble penetrating beyond that small, engaged nucleus. The bold vision just left out too many existing, legacy workloads and teams.</p><p>So, gradually, like the commandments in Orwell’s <em>Animal Farm, </em>AWS’s non-negotiables of serverless compute began to change. Let’s run through each point of the manifesto and see if Lambda still adheres to it.</p><p><strong>Functions are the unit of deployment and scaling?</strong></p><p><em>Sorta, but not strictly. </em>You can deploy multi-function Lambda Layers to manage large binaries, or (now in preview) Lambda Extensions to plug in third-party agents that I’ve been told should definitely not be thought of as “sidecars for Lambda”.</p><p><strong>No machines, VMs, or containers visible in the programming model?</strong></p><p><em>No longer true. </em>As of re:Invent 2020, Lambda <a href="https://acloudguru.com/blog/engineering/packaging-aws-lambda-functions-as-container-images">now allows you to bring your own containers</a> instead of just shipping a ZIP file of code.</p><p><strong>Permanent storage lives elsewhere?</strong></p><p><em>Not necessarily. </em>Lambda now integrates with EFS, which I guess is technically “elsewhere”, but no more so than any other NFS share attached to a server is “elsewhere”. It’s a persistent filesystem mounted to your compute.</p><p><strong>Scales per request?</strong></p><p><em>Yes!</em> Now that Lambda can run containers, I believe the request model is now the biggest remaining conceptual difference between Lambda and a managed container service like AWS Fargate. Lambda gives you a new execution environment per concurrent request, whereas a Fargate-like service will still process multiple concurrent requests on the same (long-lived) container.</p><p><strong>Users cannot over- or under-provision capacity?</strong></p><p><em>No longer true. </em>Meet Provisioned Capacity, which trades your cold start problem for a hot cost problem. (I snark, but Provisioned Capacity is way better than running your own Lambda pre-warming job, which a LOT of people used to do.)</p><p><strong>Never pay for idle (no cold servers/containers or their costs)?</strong></p><p><em>No longer true – </em>not if you use Provisioned Capacity or EFS, anyway.</p><p><strong>Implicitly fault-tolerant because functions can run anywhere?</strong></p><p><em>Ehhhh. </em>This one is about abstracting away availability zones, which a lot of higher-level AWS services besides Lambda (including Fargate!) now do. That said, we’re starting to hear more guidance from AWS that really, the fault domain you need to be thinking about is regions. That’s right: regions are the new availability zones, and savvy Lambda developers are rolling their own (very un-managed) multi-region architectures as we speak.&nbsp;</p><p>To reinforce the trend, let’s check in with two other defining early features of Lambda:</p><p><strong>Intentional time and space constraints?</strong></p><p><em>Less and less true</em>. Function disk sizes, runtime limits, and CPU and memory sizes have steadily increased over the last 5 years. Today you can run a Lambda function for 15 minutes with 10 GB of memory and 6 vCPUs – a hefty enough blob of compute to make you think seriously about multi-threading, multi-purpose functions, and other things that are against the old ideals of FaaS.</p><p><strong>Zero-trust networking?</strong></p><p><em>Only if you want it. </em>In the old days, Lambda architectures biased heavily toward IAM security rather than using VPCs, partly for ideological reasons but also because attaching functions to custom ENIs added tremendous cold start overhead. Today, innovation from AWS has made customer-managed VPCs much more compatible with Lambda.</p><p>So what we have now is an updated manifesto that looks like this:</p><p><em><strong>The Serverless Compute Manifesto (circa 2020)</strong></em></p><ul><li><em><s>Functions are the unit of deployment and scaling</s></em></li><li><em><s>No machines, VMs, or containers visible in the programming model</s></em></li><li><em><s>Permanent storage lives elsewhere</s></em></li><li><em>Scales per request; </em><em><s>Users cannot over- or under-provision capacity</s></em></li><li><em><s>Never pay for idle (no cold servers/containers or their costs)</s></em></li><li><em><s>Implicitly fault-tolerant because functions can run anywhere</s></em></li><li><em><s>Intentional time and space constraints</s></em></li><li><em><s>Zero-trust networking</s></em></li></ul><p>I feel like Willy Wonka at the end of the chocolate factory tour, looking around to see where all the children went. Of all those ideological principles, those lines in the sand, <em>per-request scaling is the only thing left.&nbsp;</em></p><p>You can still build according to the original serverless manifesto, of course. But the service doesn’t <em>require </em>you to.</p><p>If you had to distill the revised value prop of Lambda down into a single maxim, <em>Animal Farm-</em>style, what would you even say at this point? “<em>All workloads are managed, but some are more managed than others?</em>“</p><h2 id="h-the-rise-of-serverless-for-everyone">The rise of serverless for everyone</h2><p>This seems like the right time to clarify that I mostly like the additions to Lambda. I think they are necessary and in many cases, an unmixed good.</p><p>I wouldn’t have said that four years ago. I was much more of a FaaS purist at that time. What changed my mind was years of hearing a very particular type of statement from engineering teams, repeated over and over in different variations:</p><p><strong><em>I would love to use Lambda, if only it …</em></strong><em> </em>[connected back to my on-prem VPC, was big enough to run my workload, let me use the same language or developer tooling as my other systems, was always warm, supported some form of shared storage, etc, etc]</p><p>My first reaction to these statements was: Why would you want to use Lambda if you can’t or won’t embrace stateless, containerless, scale-to-zero functions? That’s the whole <em>point </em>of Lambda. It sounded to me like those Kubernetes cats from the New Stack survey, saying they’d really like to eat vegetables if they only contained more meat.</p><p>But I’ve since come to understand that the really powerful part of that statement is the beginning part. It’s a statement of longing.</p><p><em>I’d love to use Lambda, if only …</em></p><p>What is it about Lambda, and serverless compute in general, that inspires this reaction in so many people? Why does a brand-new baby computing paradigm spark such compulsive interest everywhere from tiny startups to big ol’ legacy enterprises?</p><p>Because more than any specific technical detail, serverless computing is an idea. An idea expressed in a simple phrase: <em>Own less, build more. </em>All the serverless doctrine, all the technical guidance boils down to this goal. Lambda is an aspirational lifestyle.</p><p>Lambda, circa 2016, was massively ahead of its time, and to some extent still is. But because of the new feature additions, up to and including container support, it’s making the <em>own less, build more </em>identity more accessible to more builders than ever before.&nbsp;</p><p>What AWS is doing is, one by one, taking away the <em>if only</em>s<em>. </em>They’re removing reflexive objections to serverless by providing reassuring options — shared storage, provisioned capacity — for teams that need them. <em>I’d love to use Lambda!</em></p><h2 id="h-guiding-the-future">Guiding the future</h2><p>Will some teams use these features out of confusion or inertia, not realizing that they could build something more radical, more manifesto-like? Yes, and I think this is an area where AWS can do a lot more to help.</p><p>Look, the Lambda console is a mess – you know it, I know it, AWS knows it. It’s got more tacked-on feature creep and incoherent UX paths than a 2001 VCR. And say what you will about infrastructure-as-code, the console is still how people explore new services. It’s how they form feelings about what kind of builders they want to be.</p><p>A console redesign is needed for sure, but not just an arbitrary facelift. We need one that foregrounds the Lambda features that support the original manifesto: code-level programming abstractions, function-level deployments. And then a careful reveal of progressive complexity as you push up against the limits of the manifesto or your own organizational constraints. (Is there such a thing as “regressive complexity”? Because that’s the current console.)</p><p>What you want is for builders to be confronted with the simpler, more managed options every time they start a new …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acloudguru.com/blog/engineering/aws-lambda-is-winning-but-first-it-had-to-die">https://acloudguru.com/blog/engineering/aws-lambda-is-winning-but-first-it-had-to-die</a></em></p>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/aws-lambda-is-winning-but-first-it-had-to-die</link>
            <guid isPermaLink="false">hacker-news-small-sites-25458325</guid>
            <pubDate>Thu, 17 Dec 2020 18:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring arrays in Kafka with lateral joins]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25457905">thread link</a>) | @Natasha_Fll
<br/>
December 17, 2020 | https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article we are going to explore <b>lateral joins. </b></p><p><b>"What is a lateral join?"</b> you may ask. It's a new kind of <i>join</i> that allows to extract and work with the single elements found inside an array, as if the array was a normal table.</p><p>Lenses 4.1 comes with a lot of new features that make your life easier when working with arrays: we introduced <a href="https://docs.lenses.io/4.1/sql/functions/#array-functions">6 new functions to work with arrays</a>, better support for array literals, and lateral joins.</p><p>All these features are available both for our Snapshot and Streaming Engine.</p><p>You can read more about <a href="https://docs.lenses.io/4.1/sql/streaming/laterals/">this functionality in our docs</a>, as well as trying it yourself following <a href="https://help.lenses.io/sql/streaming/explode-arrays/">this self-contained tutorial</a>.</p><p>What we would like to focus on in this post, however, is how this feature came to be; designing this functionality has been an exciting journey and we thought it would be useful to share the thought process and iterations behind the implementation.</p><ul><li><p> <!-- -->We will initially explore the high-level requirements that motivated this feature;</p></li><li><p> <!-- -->Then we will explore what a possible solution could look like and the implications of each approach</p></li><li><p> <!-- -->Finally we will go through our design iterations, concluding with the final result and how it delivers all that we set out to achieve.</p></li></ul><p>Let's get cracking.</p><h2>Motivation</h2><p>Assume that you have a topic called <code>batched_readings</code> that collects readings from some kind of sensor meter.</p><p>The upstream system stores "batches" of reading per meter. That means that each single record will contain multiple readings for its meter:</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[81,&nbsp;82,&nbsp;81]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[95,&nbsp;94,&nbsp;93,&nbsp;96]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[80,&nbsp;82]&nbsp;}</pre><pre></pre><pre></pre><p>
Our goal is to extract the single readings for each record, and build a new topic where each record contains only one reading:</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;100&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;101&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;102&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"reading":&nbsp;81&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"reading":&nbsp;82&nbsp;},</pre><pre></pre><pre>...</pre><pre></pre><pre></pre><p>
How can we do that?</p><h2>Exploring the solution space</h2><p>Before starting to work on the feature, we did some research to see if and how this functionality was implemented in other SQL streaming systems or more traditional RDBMS systems.</p><p>We found two main different approaches to the problem:</p><h3>The "Explode" approach</h3><p>
Some systems implement the functionality introducing special functions that can be used as a normal projections, right after the <code>SELECT&nbsp;</code>clause. The idea is that a special function will "explode" the array, making the select emit a record for each item in the array.</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;EXPLODE(readings)&nbsp;AS&nbsp;reading</pre><pre></pre><pre>FROM&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading</pre><p>The syntax is quite straightforward and easy to use in this simple case, but we found it a bit more complex and less predictable in more complicated scenarios, like when multiple <code>EXPLODE</code>s are used or when multi-level arrays need to be worked with.</p><p>Another limitation of this approach is that it is hard to work with the exploded array elements outside the projection. For example, something like this is not possible in KSqlDB:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;EXPLODE(readings)&nbsp;AS&nbsp;reading</pre><pre></pre><pre>FROM&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading</pre><pre></pre><pre>WHERE&nbsp;EXPLODE(readings)&nbsp;&gt;&nbsp;100</pre><p>

In general, we soon realized that treating <code>EXPLODE</code> as a normal function (albeit one that generates more than one output per each input) was not the right choice for us. We could do better.</p><h3>The "Table Function" approach</h3><p>Not satisfied with the solution above, we considered whether moving the <code>EXPLODE</code> to the source would solve the some of the highlighted problems.</p><p>After some research, we realized that this was an approach already embraced by other classical RDBMS systems like PostgreSQL, with its <code>unnest</code> table function.</p><p>This approach is based on two concepts:</p><ol><li><p> <b>Table functions: </b>functions that transforms normal values to tables</p></li><li><p> <b>Lateral joins: </b>with lateral joins it is possible to express a relation between the value of a field on the left-hand side of a join, and its right-hand side. This contrasts with traditional joins, where you can only join tables that are completely independent of one another.</p></li></ol><p>With these concepts to hand, our first design iteration defined a new <code>EXPLODE</code> table function and a new <code>LATERAL</code> keyword, to be able to join a source to the result of a table function:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;EXPLODE(readings&nbsp;as&nbsp;reading)</pre><p>The table function <code>EXPLODE(readings&nbsp;as&nbsp;reading)</code> should be read as follows:</p><blockquote><p><i>Take the current value of the </i><i><code>readings</code></i><i> array and transform it to a table. Such table will have only one column, called </i><i><code>reading</code></i><i>, and each element of the original array will be a row in that table.</i></p></blockquote><p><code>EXPLODE(readings&nbsp;as&nbsp;reading)</code> is a table that depends on the value of the <code>readings</code> field for each single record. Every record will then produce a table.</p><p>Going back to our meter reading example, consider the first record, where <code>readings</code> is <code>[100,&nbsp;101,&nbsp;102]</code>. For that record, the expression <code>EXPLODE(readings&nbsp;as&nbsp;reading)&nbsp;</code>will produce the following table:</p><pre>|&nbsp;reading&nbsp;|</pre><pre></pre><pre>-----------</pre><pre></pre><pre>|&nbsp;100&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre>|&nbsp;101&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre>|&nbsp;102&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre></pre><p>
Since we gave the name <code>reading</code> to the elements inside <code>readings</code>, we can use it in the <code>SELECT</code> as if it were a normal field.</p><p>But not only that, we can use it wherever we want, like in a <code>WHERE</code> or in a <code>GROUP&nbsp;BY</code> !</p><p>The table expression <code>batched_reading&nbsp;LATERAL&nbsp;EXPLODE(readings&nbsp;as&nbsp;reading)</code> can at this point be read as follows:</p><blockquote><p><i>For each record in </i><i><code>batched_reading</code></i><i>, compute the table </i><i><code>EXPLODE(readings&nbsp;as&nbsp;reading)</code></i><i>, and join that table with the original record.</i></p></blockquote><p>That means that if we take again the record <code>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102]&nbsp;}</code> as an example, the above table expression will result in the following table:</p><pre>|&nbsp;meter_id&nbsp;|&nbsp;readings&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;reading&nbsp;|</pre><pre></pre><pre>|----------|----------------|---------|</pre><pre></pre><pre>|1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|[100,&nbsp;101,&nbsp;102]&nbsp;|100&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre>|1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|[100,&nbsp;101,&nbsp;102]&nbsp;|101&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre>|1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|[100,&nbsp;101,&nbsp;102]&nbsp;|102&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre>
<h3>Our final approach</h3><p>After exploring the table function approach, we realized that the only real concrete example of a table function would be <code>EXPLODE</code>; we then understood that we could use directly the array expression as the argument of the <code>LATERAL</code> join, without the <code>EXPLODE</code> function.</p><p>With that simplification the query becomes:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;readings&nbsp;as&nbsp;reading</pre><p>This brings a small but effective improvement to the syntax, as well as making an important aspect of our approach to lateral joins more prominent: we can treat <i>any</i> array as a valid right-hand side of a lateral join, including any expression returning an array.</p><h2>Filtering the results of a lateral join</h2><p>With the approach to lateral joins we just described, we can use the exploded item not only in the projections of a <code>SELECT</code>, but also in all the other places of the query where you can use fields coming from a source. This includes <code>WHERE</code> and <code>GROUP&nbsp;BY</code>.</p><p>Using the same example used above, this query allows you to keep only the readings greater than <code>90</code>:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;readings&nbsp;as&nbsp;reading</pre><pre></pre><pre>WHERE</pre><pre></pre><pre>&nbsp;&nbsp;reading&nbsp;&gt;&nbsp;90</pre><h2>Nested lateral joins</h2><p>The result of a <code>LATERAL</code> is a table expression, so  it can be used inside the left-hand-side of a <code>LATERAL</code>. This can be useful when you want to extract elements inside a nested array.</p><p>Let's take  a slight modification of the <code>batched_readings</code> example:</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"nested_readings":&nbsp;[[100,&nbsp;101],&nbsp;[102]]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"nested_readings":&nbsp;[[81],&nbsp;[82,&nbsp;81]]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"nested_readings":&nbsp;[[95,&nbsp;94],&nbsp;[93,&nbsp;96]]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"nested_readings":&nbsp;[[80,&nbsp;82]]&nbsp;}</pre><pre></pre><pre></pre><p>
Here <code>nested_readings</code> is an array of arrays. We can get the same results as before with the following query:</p><pre>SELECT&nbsp;STREAM</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_readings_nested</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;nested_readings&nbsp;as&nbsp;readings</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;readings&nbsp;as&nbsp;reading</pre><h2>Working with multiple arrays</h2><p>The <code>EXPLODE</code> function approach allowed to specify multiple arrays to be exploded at the same time. When multiple <code>EXPLODE</code>s are used, the arrays are traversed in parallel, and elements with the same index are returned together.</p><p>To achieve similar behavior with <code>LATERAL</code> join it was enough to introduce a new <code>zip</code> array function: <code>zip</code> takes two (or more) arrays, it traverses them in parallel, and it builds a single new array where the elements are objects containing values from the original arrays.</p><p>For example, the following expression:</p><pre>zip([1,&nbsp;2,&nbsp;3],&nbsp;'a',&nbsp;['x',&nbsp;'y',&nbsp;'z'],&nbsp;'b')</pre><pre></pre><pre></pre><p>
will be evaluated to the following array:</p><pre>[{"a":&nbsp;1,&nbsp;"b":&nbsp;"x"},&nbsp;{"a":&nbsp;2,&nbsp;"b":&nbsp;"y"},&nbsp;{"a":&nbsp;3,&nbsp;"b":&nbsp;"z"}]</pre><pre></pre><pre></pre><p>
Let's go back to our original example, and assume now we have a new array where the time of the reading was reported (the time is here a simple integer just to keep the code concise):</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102],&nbsp;"times":&nbsp;[1,&nbsp;2,&nbsp;3]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[81,&nbsp;82,&nbsp;81],&nbsp;"times":&nbsp;[1,&nbsp;2]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[95,&nbsp;94,&nbsp;93,&nbsp;96],&nbsp;"times":&nbsp;[4,&nbsp;5,&nbsp;6,&nbsp;7]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[80,&nbsp;82],&nbsp;"times":&nbsp;[4,&nbsp;5]&nbsp;}</pre><pre></pre><pre></pre><p>
We can use <code>zip</code> to build an intermediate array that will then be passed to the <code>LATERAL</code> join:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading.value,</pre><pre></pre><pre>&nbsp;&nbsp;reading.time</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_readings</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;zip(readings,&nbsp;'value',&nbsp;times,&nbsp;'time')&nbsp;as&nbsp;reading</pre><h2>Lateral joins for streaming data</h2><p>Something that we strive to achieve with Lenses <a href="https://lenses.io/product/sql/">SQL </a>is a consistent and seamless experience over all type of user data, be it static or streaming.</p><p>It will come as little surprise then that lateral joins are fully supported in our Streaming SQL as well as in our Snapshot one.</p><p>The syntax and concepts are the same the we have been explaining throughout this post, but now are used as part of an <a href="https://docs.lenses.io/4.1/sql/streaming/">SQL Processor</a> rather than an <a href="https://docs.lenses.io/4.1/sql/snapshot/">SQL Studio</a> query.</p><p>To illustrate how this would work, let's go back to our sensor meter example, and let's assume that we have the same <code>batched_readings</code> topic as before, which will receive events as below:</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[81,&nbsp;82,&nbsp;81]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[95,&nbsp;94,&nbsp;93,&nbsp;96]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[80,&nbsp;82]&nbsp;},</pre><pre></pre><pre>....</pre><pre></pre><pre>....</pre><pre></pre><pre>....</pre><p>

What if we wanted to <i>split</i> our data to ensure that readings that are inside a <i>normal</i> range are sent downstream to be processed, but readings outside such …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/">https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/</a></em></p>]]>
            </description>
            <link>https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457905</guid>
            <pubDate>Thu, 17 Dec 2020 17:39:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yes, You May Need a Blockchain]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25457865">thread link</a>) | @bobrenjc93
<br/>
December 17, 2020 | https://balajis.com/yes-you-may-need-a-blockchain/ | <a href="https://web.archive.org/web/*/https://balajis.com/yes-you-may-need-a-blockchain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/08/yes-you-may-need-a-blockchain--1-.png 300w,
                                https://balajis.com/content/images/size/w600/2020/08/yes-you-may-need-a-blockchain--1-.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/08/yes-you-may-need-a-blockchain--1-.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/08/yes-you-may-need-a-blockchain--1-.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/08/yes-you-may-need-a-blockchain--1-.png" alt="Yes, You May Need a Blockchain">
                </figure>
                <section>
                    <div>
                        <p><a href="https://www.coindesk.com/yes-you-may-need-a-blockchain"><em>Originally appeared in Coindesk on May 14 2019</em></a></p><p>There’s a certain kind of developer who states that blockchains are just <a href="https://news.ycombinator.com/item?id=13420777">terrible</a> databases. As the narrative goes, why not just use PostgreSQL for your application? It’s mature, robust, and high performance. Compared to relational databases, the skeptic claims that blockchains are just slow, clunky and expensive databases that don’t scale.</p><p>While some critiques of this critique are already out there (<a href="https://medium.com/@mycoralhealth/why-blockchains-dont-suck-and-the-perils-of-distributed-databases-1a522cc7cfe1">1</a>, <a href="https://medium.com/@chainfrog/5-reasons-that-blockchain-is-not-just-a-slow-database-55fe9d913578">2</a>), I’d propose a simple one sentence rebuttal: public blockchains are massively multiclient databases, where every user is a root user. They are useful for storing shared state between users, particularly when that shared state represents valuable data that users want to export without fail — like their money.</p><h2 id="the-data-export-import-problem"><strong>The data export/import problem</strong></h2><figure><img src="https://balajis.com/content/images/2020/08/image-1.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/08/image-1.png 600w, https://balajis.com/content/images/size/w1000/2020/08/image-1.png 1000w, https://balajis.com/content/images/2020/08/image-1.png 1122w" sizes="(min-width: 720px) 720px"><figcaption>AWS has icons for everything, other than shared state between accounts.</figcaption></figure><p>To motivate public blockchains from the standpoint of a non-crypto engineer, take a look at the cloud diagrams for <a href="https://aws.amazon.com/architecture/icons/">Amazon Web Services</a>, <a href="https://online.visual-paradigm.com/features/azure-architecture-diagram-tool/">Microsoft Azure</a>, or <a href="https://cloud.google.com/icons/">Google Cloud</a>. </p><p>There are icons for load balancers, transcoders, queues, and lambda functions. There are icons for VPCs and every type of database under the sun, including the new-ish <a href="https://aws.amazon.com/managed-blockchain/">managed blockchain</a> services (which are distinct from public blockchains, though potentially useful in some circumstances).</p><p>What there isn’t an icon for is <em>shared state between accounts</em>. That is, these cloud diagrams all implicitly assume that a single entity and its employees (namely, the entity with access to the <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html">cloud root account</a>) is the only one laying out the architecture diagram and reading from or writing to the application it underpins. More precisely, these diagrams typically assume the presence of a single economic actor, namely the entity paying the cloud bills.*</p><p>But if we visualize the cloud diagrams for not just one but one hundred corporate economic actors at a time, some immediate questions arise. Can these actors interoperate? Can their users pull their data out and bring it into other applications? And given that the users are themselves economic actors, if this data represents something of monetary value, can the users be confident that their data wasn’t modified during all this exporting and importing?</p><p>These are the types of questions that arise when we think about the data export and import from each entity’s application as a first-class requirement. And (with exceptions that we’ll get into), in general, the answer to these questions today is typically no.</p><p>No — different applications typically don’t have interoperable software, or allow their users to easily export/import their data in a standard form, or give users certainty that their data wasn’t intentionally tampered with or inadvertently corrupted during all the exporting and importing.</p><p>The reason why boils down to incentives. For most major internet services, there is simply <em>no financial incentive to enable users to export their data</em>, let alone to enable competitors to quickly import said data. While some call this the <a href="https://en.wikipedia.org/wiki/Data_portability">data portability</a> problem, let’s call it the data export/import problem to focus attention on the specific mechanisms for export and import.</p><h2 id="how-we-do-data-export-import-today-apis-json-pdf-csv-mbox-and-or-sftp"><strong>How we do data export/import today: APIs, JSON, PDF, CSV, MBOX, and/or SFTP</strong></h2><p>Even though the financial incentives aren’t yet present for a general solution to the data export/import problem, mechanisms have been created for many important special cases. These mechanisms include APIs, JSON/PDF/CSV exports, MBOX files, and (in a banking context) SFTP.</p><p>Let’s go through these in turn to understand the current state of affairs.</p><ul><li><strong>APIs.</strong> One of the most popular ways to export/import data is via Application Programming Interfaces, better known as APIs. Some businesses do let you get some of your data out, or give you the ability to write data to your account. But there’s a cost. First, their internal data format is typically proprietary and not an industry standard. Second, sometimes the APIs are not central to their core business and can be <a href="https://www.siliconrepublic.com/enterprise/twitter-apis-ending">turned off</a>. Third, sometimes the APIs are central to their core business and the price can be <a href="https://geoawesomeness.com/developers-up-in-arms-over-google-maps-api-insane-price-hike/">dramatically raised</a>. In general, if you’re reading or writing to a hosted API, you’re at the mercy of the API provider. We call this platform risk, and being unceremoniously de-platformed has <a href="https://nordicapis.com/twitter-10-year-struggle-with-developer-relations/">harmed</a> <a href="https://techcrunch.com/2015/05/06/meerkat-founder-on-getting-the-kill-call-from-twitter/">many</a> <a href="https://techcrunch.com/2018/04/02/instagram-api-limit/">a</a> <a href="https://mashable.com/article/gmail-ifttt-shutdown-google/">startup</a>.</li><li><strong>JSON.</strong> Another related solution is to allow users or scripts to download JSON files, or read/write them to the aforementioned APIs. This is fine as far as it goes, but JSON is very free form and can describe virtually anything. For example, Facebook’s <a href="https://developers.facebook.com/docs/graph-api/using-graph-api">Graph API</a> and LinkedIn’s <a href="https://docs.microsoft.com/en-us/linkedin/shared/references/v2/profile/profile-picture?context=linkedin/consumer/context">REST API</a> deal with similar things but return very different JSON results.</li><li><strong>PDF.</strong> Another very partial solution is to allow users to export a PDF. This works for documents, as PDF is an <a href="https://blog.marconet.com/blog/bid/326753/8-types-of-pdf-standards-each-serves-a-unique-purpose">open standard</a> that can be read by other applications like Preview, Adobe Acrobat, Google Drive, Dropbox, and so on. But a PDF is meant to be an end product, to be read by a human. It’s not meant to be an input to any application besides a PDF viewer.</li><li><strong><a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a>.</strong> The humble comma separated value file gets closer to what we want for a general solution to the data import/export problem. Unlike the backend of a proprietary API, CSV is a <a href="https://www.loc.gov/preservation/digital/formats/fdd/fdd000323.shtml">standard format</a> described by <a href="https://en.wikipedia.org/wiki/Comma-separated_values">RFC 4180</a>. Unlike JSON, which can represent almost anything, a CSV typically represents just a table. And unlike a PDF, a CSV can typically be edited locally by a user via a spreadsheet or used as machine-readable input to a local or cloud application. Because most kinds of data can be represented in a relational database, and because relational databases can usually be <a href="https://www.postgresql.org/docs/9.4/sql-copy.html">exported</a> as a set of possibly gigantic CSVs, it’s also pretty general. However, CSVs are disadvantaged in a few ways. First, unlike a proprietary API, they aren’t hosted. That is, there’s no single canonical place to read or write a CSV representing (say) a record of transactions or a table of map metadata. Second, CSVs aren’t tamper resistant. If a user exports a record of transactions from service A, modifies it, and re-uploads it to service B, the second service would be none the wiser. Third, CSVs don’t have built-in integrity checks to protect against inadvertent error. For example, the columns of a CSV don’t have explicit type information, which means that a column containing the months of the year from 1-12 could have its type auto-converted upon import into a simple integer, causing <a href="https://superuser.com/questions/318420/formatting-a-comma-delimited-csv-to-force-excel-to-interpret-value-as-a-string">confusion</a>.</li><li><strong><a href="https://en.wikipedia.org/wiki/Mbox">MBOX</a>.</strong> While less well known than CSV, the <a href="https://www.loc.gov/preservation/digital/formats/fdd/fdd000383.shtml">MBOX format</a> for representing collections of email messages is the closest thing out there to a standardized data structure built for import and export between major platforms and independent applications alike. Indeed, there have been <a href="https://mobisocial.stanford.edu/papers/hotpets11.pdf">papers</a> proposing the use of MBOX in contexts outside of email. While CSV represents tabular data, MBOX represents a type of log-structured data. It’s essentially a single huge plain text file of email messages in chronological order, but can also represent <a href="https://www.quora.com/Do-mbox-files-store-images-file-attachments-of-emails">images/file attachments</a> via MIME. Like CSV, MBOX files are an <a href="https://www.loc.gov/preservation/digital/formats/fdd/fdd000383.shtml">open standard</a> and can be exported, edited locally, and reimported. And like CSV, MBOX has the disadvantages of no canonical host or intrinsic data integrity check.</li><li><strong><a href="https://engineering.gusto.com/how-ach-works-a-developer-perspective-part-1/">SFTP</a>.</strong> Before we move on, there’s one more data export/import mechanism that deserves mention: the secure file transfer protocol, or SFTP. While quite old-fashioned, this is actually the way that individuals send ACH payments back and forth to each other. Essentially, financial institutions use SFTP servers to take in electronic transaction data in <a href="https://secureinstantpayments.com/sip/help/interface_specs/external/NACHA_format.pdf">specially formatted files</a> and transmit it to the Federal Reserve each day to sync ACH debits and credits with each other (see <a href="https://engineering.gusto.com/how-ach-works-a-developer-perspective-part-1/">here</a>, <a href="https://engineering.gusto.com/how-ach-works-a-developer-perspective-part-2/">here</a>, <a href="https://engineering.gusto.com/how-ach-works-a-developer-perspective-part-3/">here</a>, and <a href="https://engineering.gusto.com/how-ach-works-a-developer-perspective-part-4/">here</a>).</li></ul><p>Each of these mechanisms is widely used. But they are insufficient for enabling the general case of tamper-resistant import and export of valuable data between arbitrary economic actors — whether they be corporate entities, individual users, or headless scripts. For that, we need public blockchains.</p><h2 id="how-public-blockchains-solve-the-data-import-export-problem"><strong>How public blockchains solve the data import/export problem</strong></h2><p>Public blockchains enable shared state by incentivizing interoperability. They convert many types of data import/export problems into a general class of shared state problems. And they do so in part by incorporating many of the best features of the mechanisms described above.</p><ul><li><strong>A canonical API without centralization.</strong> Public blockchains provide canonical methods for read/write access like a hosted corporate API, but without the same platform risk. No single economic actor can shut down or deny service to clients of a decentralized public blockchain like Bitcoin or Ethereum.</li><li><strong>Lossless import/export.</strong> Public blockchains also enable individual users to export critical data to their local computer or to a new application like JSON/CSV/MBOX (either by sending out funds or exporting private keys) while providing cryptographic guarantees of data integrity.</li><li><strong>Incentivized interoperation.</strong> Public blockchains provide a means for arbitrary economic actors (whether corporations, individual users, or programs) to seamlessly interoperate. Every economic actor who reads from a public blockchain sees the same result, and any economic actor with sufficient funds can write to a public blockchain in the same way. No account setup is necessary and no actor can be blocked from read/write access.</li><li><strong>Cryptographic data integrity.</strong> And perhaps most importantly, public blockchains give financial incentives for interoperability and data integrity.</li></ul><p>This last point deserves elaboration. A public blockchain like Bitcoin or Ethereum typically records the transfer of things of monetary value. This thing could be the intrinsic cryptocurrency of the chain, a token issued on top of the chain, or another kind of digital asset.</p><p>Because the data associated with a public blockchain represents something of monetary value, it finally …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://balajis.com/yes-you-may-need-a-blockchain/">https://balajis.com/yes-you-may-need-a-blockchain/</a></em></p>]]>
            </description>
            <link>https://balajis.com/yes-you-may-need-a-blockchain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457865</guid>
            <pubDate>Thu, 17 Dec 2020 17:36:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tobi Lütke]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25457787">thread link</a>) | @simonebrunozzi
<br/>
December 17, 2020 | https://www.theobservereffect.org/tobi.html | <a href="https://web.archive.org/web/*/https://www.theobservereffect.org/tobi.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>
									Welcome to the third interview on 'The Observer Effect'. We are lucky to have one
									of the most interesting founders in technology and commerce - Tobi Lütke, Founder
									and CEO of Shopify. This interview was published on December 16th, 2020.

							</em></p><p><em>Tobi is one of the most thoughtful and first principles oriented founders I've met and
								this was a fascinating conversation. Enjoy!
								</em>
							</p><p><b><a href="https://sriramk.com/">Sriram Krishnan</a></b><br>
								<em><strong>Let’s start with the basics. Walk me through a typical day in the life of
										Tobi Lütke.</strong></em>
							</p><p>
								Here’s the honest answer: obviously I have a schedule and people helping me manage my
								time, however, I think a lot about where to devote my attention. In this way, there is
								no typical day.

							</p><p>My attention is the most liquid and valuable resource that I have. Even back in the day
								when Shopify went public, I spent a good deal of time pre-selling the various investors.
								During meetings, I would say, “Hey, I'm here, and we've been doing this roadshow, but I
								actually spend a lot of my time on the product.” This was to set expectations because I
								knew I wasn't going to attend very many investor conferences. Fundamentally, my
								attention belonged to the product, not to the sales and marketing of it. </p><p>A day in my life really depends on what's happening. That said, usually I have themes.
								For instance, I have a priority list, and I have decision logs that chronicle all the
								things I am trying to figure out. </p><p>
								These cover different questions. For example, if I had just taken the company over, how
								would I change it? How would I build a company to potentially disrupt Shopify? I try to
								make my calendar match these bigger topics and other urgent priorities. In a way, the
								calendar is nothing more than a strategy. Although it's incredibly easy—and it has
								happened to me quite a lot—to have circumstances dictate the calendar. Because of this,
								there’s this constant tug of war between the actual priorities of the company and the
								kind of things that have to be done.

							</p><p>So, I end up trying to insert themes into my days. Like today, for instance, I have a
								meeting with my small team to begin the week; I reserved my afternoon for product
								reviews—what we call “greenpathing exercises”—where, oddly, I'm trying to discern how
								everyone is thinking about the main things we're working on. I do this because
								oftentimes I feel as though I am the connective tissue combining operations, finance,
								and more formal business functions with the product itself. This connection helps me to
								make good decisions.</p><p>Lastly, on Wednesdays, Shopify doesn't do scheduled meetings. Usually, I have a list of
								memos to read or reactions to record to various mock-ups and so on. This is basically my
								very loosely defined schedule.</p><p>
								<b><i>How do you work with your so-called “expansion pack team” on reallocating your
										portfolio management on time? What does that loop look like?
									</i></b>
							</p><p>
								A lot of this is almost automatic by just having a good color coding system, which is
								really fun.
								<i>[laughs]</i>

							</p><p> At one point, I started complaining about blue weeks where every single time slot was
								taken. And someone said, “Well, if you don't like blue, I can make any color.” And I
								replied, “Well, how about we color based on leverage?” And that’s just what we did. </p><p>
								We ended up labeling my product-related things red, investor/Board of Director-related
								things some kind of teal color, et cetera. And the thing I’m looking for is a balanced
								week; a week where, ideally, I manage to devote about 30% of the time—at least—to the
								product and then as much as possible to things like recruiting, bigger picture projects,
								and one-on-ones.

							</p><p>
								And so, if my calendar becomes too external or too much of anything, it's the first
								thing we see when we sit down for our priorities meeting. This makes scheduling a lot
								easier.

							</p><p>
								<b><i>
										This is a very natural segue to my next question. One of the theories behind
										this whole set of interviews is diving into the atomic bits of how we spend our
										time in meetings. This time compounds over the long term and has a massive
										effect. What does a good meeting with Tobi look like? Alternatively, what does a
										bad meeting with you look like?
									</i>
							</b></p><div>
							<p>So actually, agendas are not terribly successful with me. I admire how other CEOs I’ve
								spoken with always have a strict agenda where everyone has a speaking slot. I find that
								absolutely fascinating. Even if I really set myself to an agenda and say, “Okay, great,
								this is going to happen,” I can't get through half of a meeting like this. Partly
								because a good meeting is, for me personally, when I learn something.</p>
								<blockquote>
									<p>..when I have my own ideas, the first thing I tend to do is
										just try to falsify them, to figure out why what I'm thinking about is probably
										incorrect...<em>
									</em></p>
								</blockquote>
							<p>
								I started a company because I love learning. I went into programming because I found it
								fascinating. During meetings, I just love to hear the things that teams have discovered.
								When you're discussing an idea or a decision, I want to know what has been considered.
								To be honest, I find myself more interested in the inputs of an idea than the actual
								decision. I say this because when I have my own ideas, the first thing I tend to do is
								just try to falsify them, to figure out why what I'm thinking about is probably
								incorrect. This is actually something that I have to explain to people that I work with.
								If I like someone's idea, I tend to do the same thing: I try to poke holes in it.
							</p>

							<p>I usually say, “Well, the implication of this choice means you've made the following
								assumptions. What inputs did you use to make these foundational assumptions?”
								Effectively, I'm trying to figure out if an idea is built on solid fundamentals. I find
								that shaky fundamentals tend to be where things often go wrong. The decision being
								discussed could be the perfect decision according to the various assumptions that
								everyone came into the room with. But if those assumptions are faulty, the seemingly
								perfect decision is faulty too. Interestingly, assumptions are rarely mentioned in the
								briefing docs or in the slide deck. Usually, I'm trying to make sure those are rock
								solid. Through this process, I invariably end up learning something completely new about
								a field. That gives me great confidence and comfort both in the decision and the
								direction.</p>

							
							<h2 id="enneagrams"><b>On Enneagrams and Comprehensivists</b></h2>
							<p>


								<b><i>Two words have come up a lot in preparatory conversations: comprehensivist and
										enneagrams. Could you talk about both?

									</i></b>

							</p>

							<p>Interesting.</p>
							<p>
								<i>[Laughs]</i>
								I feel like I'm becoming known for pointing people towards the enneagram. I actually
								don't think it's that valuable on its own. The valuable thing about any of these
								personality-type constructs is that they do a really good job of teaching people that
								other people are very different. That realization is probably one of the biggest growth
								moments for people in general. It tells you that different people play different roles.
								On that note, I do think that, ideally, people should play their own roles really,
								really well.

							</p>
							<p>
								I play the role of challenger, personally. I find that the enneagram helps me remind
								myself that with different people I have to talk about the same things in different
								ways. I think it allows you to skip some time which would otherwise be touch and go at
								the beginning of a relationship and helps build trust better. In short, it enables us to
								have fruitful and effective conversations.
								And comprehensivist, I mean, that's a fancy word.
							</p>
							<p>

								<i>[Laughs]</i> I don't think I've ever used it outside of putting it into my Twitter
								bio when I was reading Buckminster Fuller. That said, I do like range. I find that the
								first 80% of every field is pretty quick to learn—it’s equivalent to the Pareto
								principle—and I think that creativity generally is people using lessons from one field
								in another field in different ways. Because of this, I find learning fascinating.

								</p><blockquote>
									<p>..creativity generally is people using lessons from one field
										in another field in different ways...<em>
									</em></p>
								</blockquote>
							
						


							<h2 id="decisionmaking"><b>On Time and Attention on Shopify<br></b></h2>
							<p>
								<b><i>
										You try and design how your company spends time and attention. One particular
										incident came up recently which I found really fascinating. You wrote a script
										to delete every recurring meeting at Shopify. Talk about why you did that, and
										what you ended up learning from it.


									</i></b>
							</p>


							<p>
								<i>[Laughs]</i>
								So, going back a little bit further there—you know what, I should talk about books. One
								thing that is interesting is how people have accused Shopify of being a book club thinly
								veiled as a public company.

							</p>
							<p>We tend to read a lot and talk about a lot of books. We read Nassim Taleb’s books and one
								person on my team began talking about Antifragile and gave an outline. He said, “I think
								Nassim is putting a word to the thing that you keep talking about…” </p>

							<p>Now, I come from an engineering perspective. One of my biggest beefs with engineers, in
								general, is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theobservereffect.org/tobi.html">https://www.theobservereffect.org/tobi.html</a></em></p>]]>
            </description>
            <link>https://www.theobservereffect.org/tobi.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457787</guid>
            <pubDate>Thu, 17 Dec 2020 17:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to property-based testing with QuickCheck]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25457744">thread link</a>) | @gbrown_
<br/>
December 17, 2020 | https://jesper.sikanda.be/posts/quickcheck-intro.html | <a href="https://web.archive.org/web/*/https://jesper.sikanda.be/posts/quickcheck-intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>
      Posted
      
            by Jesper
       on December 17, 2020
    </p>
    <p>In February, I will be teaching a new course on Functional Programming at TU Delft. The course will mostly cover Haskell using <a href="https://www.cs.nott.ac.uk/~pszgmh/pih.html">Graham Hutton’s excellent book</a>, though there will be a part on basic usage of dependent types in Agda towards the end as well. For the exercises, we will use the Delft-grown <a href="https://weblab.tudelft.nl/">Weblab platform</a> for letting the students code and run the automated tests using QuickCheck. Unfortunately for me, the book does not talk about QuickCheck at all. Fortunately for you, that means I decided to write a tutorial myself, which you can read here.</p>
<p>Of course there are many excellent QuickCheck tutorials out there already. However I found all of them either assumed too much Haskell knowledge (since I want to introduce QuickCheck as early as possible), skipped out on interesting parts (such as conditional and quantified properties), or were just not up-to-date with the latest version of QuickCheck (such as the new approach for generating random functions using <code>Fun</code>). So I hope this post closes a gap in the current menu of tutorials for at least a few people.</p>
<p>If you spot any errors or opportunities for improvement, please let me know. The students at TU Delft will be grateful!</p>

<p>When you were first learning to program, at some point you were probably told about the importance of writing <em>unit tests</em>: small test cases that each test a small piece of functionality of your code. And while it is true that writing unit tests is important, it is also at the same time <em>boring</em> and <em>difficult</em>. It is boring because you need to write many separate unit tests for each piece of functionality, which all look more or less the same. And it is difficult because it is very easy to miss a certain combination of inputs for which the program crashes. Would it not be nice if we could just write down how the program should behave and have the test cases be generated automatically? That is precisely the approach of <strong>property-based testing</strong>.</p>
<p>In short, property-based testing is an approach to testing where you as the programmer write down properties that you expect to hold of your program. When running the tests, the test runner will generate a lot of different random input values, and then check that the property holds for all these (combinations of) input values. Compared to writing individual unit tests, property-based testing has several advantages:</p>
<ul>
<li>You spend <strong>less time writing test code</strong>: a single property can often replace many hand-written test cases.</li>
<li>You get <strong>better coverage</strong>: by randomly generating inputs, QuickCheck will test lots of combinations you’d never test by hand.</li>
<li>You spend <strong>less time on diagnosis of errors</strong>: if a property fails to hold, QuickCheck will automatically produce a minimized counterexample.</li>
</ul>
<p><strong>QuickCheck</strong> is a tool for property-based testing of Haskell code. Since its introduction for Haskell in 1999, QuickCheck has become very popular as a testing framework and has been ported to many other programming languages such as C, C++, Java, JavaScript, Python, Scala, and many others (see <a href="https://en.wikipedia.org/wiki/QuickCheck">https://en.wikipedia.org/wiki/QuickCheck</a> for a more complete list). However, QuickCheck really benefits from the fact that Haskell is a pure language, so that is where the approach continues to be the most powerful.</p>
<p>This introduction will show you the basic usage of QuickCheck for testing properties of Haskell code, as well as how to use alternative random generators. All the functions that are used come from the module <code>Test.QuickCheck</code> from the QuickCheck package. This package can be installed using the Cabal package manager for Haskell by issuing the following command:</p>
<pre><code>&gt; cabal install QuickCheck</code></pre>

<p>To write a QuickCheck test case, all you have to do is define a Haskell function that defines a <strong>property</strong> of your program that you expect to hold. In the simplest case, a property is just a value of type <code>Bool</code>. For example, suppose we have written a simple Haskell function to calculate the distance between two integers:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>distance ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> <span>Int</span></span>
<span id="cb2-2">distance x y <span>=</span> <span>abs</span> (y<span>-</span>x)</span></code></pre></div>
<p>We can then express the property that the distance between <code>3</code> and <code>5</code> equals <code>2</code>:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>prop_dist35 ::</span> <span>Bool</span></span>
<span id="cb3-2">prop_dist35 <span>=</span> distance <span>3</span> <span>5</span> <span>==</span> <span>2</span></span></code></pre></div>
<p>By convention, names of QuickCheck properties always start with <code>prop_</code>. We can express more general properties by defining a function that returns a <code>Bool</code>:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>-- The distance between any number and itself is always 0</span></span>
<span id="cb4-2"><span>prop_dist_self ::</span> <span>Int</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb4-3">prop_dist_self x <span>=</span> distance x x <span>==</span> <span>0</span></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span>-- The distance between x and y is equal to the distance between y and x</span></span>
<span id="cb4-6"><span>prop_dist_symmetric ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb4-7">prop_dist_symmetric x y <span>=</span> distance x y <span>==</span> distance y x</span></code></pre></div>
<p>When testing a property that takes one or more inputs, QuickCheck will randomly generate several inputs (100 by default) and check that the function returns <code>True</code> for all inputs.</p>
<p>The main function used to call QuickCheck is <code>quickCheck</code>, which is defined in the module <code>Test.QuickCheck</code>. To import it, you can either add <code>import Test.QuickCheck</code> at the top of your file or import it manually if you are working from GHCi. Assuming you have installed the QuickCheck package, you can then load the file and run tests by calling <code>quickCheck</code>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>&gt;</span> ghci</span>
<span id="cb5-2"><span>GHCi</span>, version <span>8.10</span><span>.</span><span>2</span><span>:</span> https<span>://</span>www<span>.</span>haskell<span>.</span>org<span>/</span>ghc<span>/</span>  <span>:?</span> for help</span>
<span id="cb5-3"><span>Loaded</span> package environment from <span>~/.</span>ghc<span>/</span>x86_64<span>-</span>linux<span>-</span><span>8.10</span><span>.</span><span>2</span><span>/</span>environments<span>/</span>default</span>
<span id="cb5-4"><span>&gt;</span> <span>:</span>l QuickCheckExamples.hs</span>
<span id="cb5-5"><span>&gt;</span> quickCheck prop_dist35</span>
<span id="cb5-6"><span>+++</span> <span>OK</span>, passed <span>1</span> test<span>.</span></span></code></pre></div>
<p>QuickCheck tells us that everything is as it should be: it ran the test and got the result <code>True</code>. Since there are no inputs to the test, it is run only once. Let us try out some more properties!</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>&gt;</span> quickCheck prop_dist_self</span>
<span id="cb6-2"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span>
<span id="cb6-3"><span>&gt;</span> quickCheck prop_dist_symmetric</span>
<span id="cb6-4"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span></code></pre></div>
<p>Huge success! For each of the tests, QuickCheck has generated 100 random inputs and verified that for each one the property returns <code>True</code>.</p>
<p>To get more information about the test inputs that are generated by QuickCheck, you can replace the function <code>quickCheck</code> with <code>verboseCheck</code>. This will print out each individual test case as it is generated. Try it out for yourself!</p>
<h2 id="shrinking-counterexamples">Shrinking counterexamples</h2>
<p>What happens if there’s a mistake in our code? Say we forgot to write <code>abs</code> in the definition of <code>distance</code>?</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>&gt;</span> quickCheck prop_dist_symmetric</span>
<span id="cb7-2"><span>***</span> <span>Failed</span><span>!</span> <span>Falsified</span> (after <span>2</span> tests)<span>:</span>                  </span>
<span id="cb7-3"><span>0</span></span>
<span id="cb7-4"><span>1</span></span></code></pre></div>
<p>QuickCheck has found a counterexample: if the first input <code>x</code> is 0 and the second input <code>y</code> is 1, then <code>y-x</code> is not equal to <code>x-y</code>.</p>
<p>When QuickCheck finds a counterexample, it will not always return the first one it encounters. Instead, QuickCheck will look for the smallest counterexample it can find. As an example, let us try to run QuickCheck on the (false) property stating that every list is sorted.</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>sorted ::</span> <span>Ord</span> a <span>=&gt;</span> [a] <span>-&gt;</span> <span>Bool</span> </span>
<span id="cb8-2">sorted (x<span>:</span>y<span>:</span>ys) <span>=</span> x <span>&lt;=</span> y <span>&amp;&amp;</span> sorted (y<span>:</span>ys)</span>
<span id="cb8-3">sorted _        <span>=</span> <span>True</span></span>
<span id="cb8-4"></span>
<span id="cb8-5"><span>-- A (false) property stating that every list is sorted</span></span>
<span id="cb8-6"><span>prop_sorted ::</span> [<span>Int</span>] <span>-&gt;</span> <span>Bool</span></span>
<span id="cb8-7">prop_sorted xs <span>=</span> sorted xs</span></code></pre></div>
<div id="cb9"><pre><code><span id="cb9-1"><span>&gt;</span> verboseCheck prop_sorted</span>
<span id="cb9-2"><span>Passed</span><span>:</span>  </span>
<span id="cb9-3">[]</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span>Passed</span><span>:</span> </span>
<span id="cb9-6">[]</span>
<span id="cb9-7"></span>
<span id="cb9-8"><span>Passed</span><span>:</span>  </span>
<span id="cb9-9">[<span>0</span>]</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span>Failed</span><span>:</span>  </span>
<span id="cb9-12">[<span>2</span>,<span>1</span>,<span>3</span>]</span>
<span id="cb9-13"></span>
<span id="cb9-14"><span>Passed</span><span>:</span>                                 </span>
<span id="cb9-15">[]</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span>Passed</span><span>:</span>                                                 </span>
<span id="cb9-18">[<span>1</span>,<span>3</span>]</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span>Passed</span><span>:</span>                                                 </span>
<span id="cb9-21">[<span>2</span>,<span>3</span>]</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span>Failed</span><span>:</span>                                                 </span>
<span id="cb9-24">[<span>2</span>,<span>1</span>]</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span>...</span></span>
<span id="cb9-27"></span>
<span id="cb9-28"><span>***</span> <span>Failed</span><span>!</span> <span>Falsified</span> (after <span>4</span> tests <span>and</span> <span>3</span> shrinks)<span>:</span>    </span>
<span id="cb9-29">[<span>1</span>,<span>0</span>]</span></code></pre></div>
<p>The first list that is generated that is not sorted is <code>[2,1,3]</code>. Note that this will be a different list every time we run QuickCheck since it is randomly generated. However, QuickCheck does not stop there and instead tries smaller and smaller lists until it converges to a minimal counterexample: <code>[1,0]</code>. This process is called <strong>shrinking</strong>.</p>
<p>It is worth noting that despite the inherent randomness of QuickCheck, shrinking will often converge to one of a small set of minimal counterexamples. For example, if we run <code>quickCheck</code> many times on <code>prop_sorted</code>, we always end up with either <code>[1,0]</code> or <code>[0,-1]</code> as a counterexample.</p>
<p>The precise strategy that QuickCheck uses for shrinking counterexamples depends on the type of the counterexample:</p>
<ul>
<li><p>For numeric types such as <code>Int</code>, QuickCheck will try a random number that is smaller in absolute value (i.e.&nbsp;closer to 0).</p></li>
<li><p>For booleans of type <code>Bool</code>, QuickCheck will try to replace <code>True</code> with <code>False</code>.</p></li>
<li><p>For tuple types <code>(a,b)</code>, QuickCheck will try to shrink one of the components.</p></li>
<li><p>For list types, QuickCheck will try to either delete a random element from the list, or try to shrink one of the values in the list.</p></li>
</ul>
<h2 id="testing-many-properties-at-once">Testing many properties at once</h2>
<p>Instead of running individual tests from GHCi, you can also combine all your tests in a <code>main</code> function:</p>
<div id="cb10"><pre><code><span id="cb10-1">main <span>=</span> <span>do</span></span>
<span id="cb10-2">  quickCheck prop_dist35</span>
<span id="cb10-3">  quickCheck prop_dist_self</span>
<span id="cb10-4">  quickCheck prop_dist_symmetric</span></code></pre></div>
<p>This code makes use of Haskell <code>do</code> keyword that we will study in the chapter on monads. Once you have defined this <code>main</code> function, you can invoke it by calling <code>runghc</code> from the command line:</p>
<div id="cb11"><pre><code><span id="cb11-1"><span>&gt;</span> runghc QuickcheckExamples.hs</span>
<span id="cb11-2"><span>+++</span> <span>OK</span>, passed <span>1</span> test<span>.</span></span>
<span id="cb11-3"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span>
<span id="cb11-4"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span></code></pre></div>
<p>Note that a file may only contain a single <code>main</code> function. In a realistic project, we would instead create a separate file that just defines all QuickCheck properties and puts them together in a <code>main</code> function.</p>
<p><strong>Remark.</strong> When you are writing code in the WebLab instance for this course, you do not need to write a main function for QuickCheck tests: WebLab will automatically collect all functions in the <code>Test</code> tab whose name starts with <code>prop_</code> and run <code>quickCheck</code> on each one.</p>

<p>The biggest challenge in making effective use of QuickCheck lies in coming up with good properties to test. So let us take a look at some examples of good properties to test.</p>
<h2 id="roundtrip-properties">Roundtrip properties</h2>
<p>When one function is an inverse to another function, we can create a property test for that. For example, we can test that reversing a list is its own inverse:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>prop_reverse_reverse ::</span> [<span>Int</span>] <span>-&gt;</span> <span>Bool</span></span>
<span id="cb12-2">prop_reverse_reverse xs <span>=</span> <span>reverse</span> (<span>reverse</span> xs) <span>==</span> xs</span></code></pre></div>
<p>As another example, we can test that inserting an element into a list and then deleting it again …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesper.sikanda.be/posts/quickcheck-intro.html">https://jesper.sikanda.be/posts/quickcheck-intro.html</a></em></p>]]>
            </description>
            <link>https://jesper.sikanda.be/posts/quickcheck-intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457744</guid>
            <pubDate>Thu, 17 Dec 2020 17:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Password Cracking with Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25457715">thread link</a>) | @gsvclass
<br/>
December 17, 2020 | https://42papers.com/p/generative-deep-learning-techniques-for-password-generation | <a href="https://web.archive.org/web/*/https://42papers.com/p/generative-deep-learning-techniques-for-password-generation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://42papers.com/p/generative-deep-learning-techniques-for-password-generation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457715</guid>
            <pubDate>Thu, 17 Dec 2020 17:24:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DLinks – create a decentralized profile without code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25457712">thread link</a>) | @troquerre
<br/>
December 17, 2020 | https://www.namebase.io/dlinks | <a href="https://web.archive.org/web/*/https://www.namebase.io/dlinks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><video controls="" autoplay="" muted="" playsinline="" src="https://videos.ctfassets.net/v3ez3dek3dk6/JygMmZSeUWeCz34eT69tr/e9f61af1db6fdd4749ea29d8637bc1f4/03_-_Feel_It_Out_1.mp4" poster="https://images.ctfassets.net/v3ez3dek3dk6/409bzjS9wHgsz8MyzB1LOZ/ec473cfe56fb5600f2e6d2b448c14d0a/image__1_.png">Looks like your browser doesn't support embedded videos.</video></p><div><div><div><div><div><p>Build on Web 3.0 without code</p><p>Create your dLink in seconds</p><p>Censorship-resistant</p></div></div><div><a target="_blank" rel="noopener noreferrer" href="https://casey.hns.to/"><div><p><img src="https://i.imgur.com/xwCoxsq.png"></p><p>See Casey Caruso's</p></div></a><a target="_blank" rel="noopener noreferrer" href="https://tieshun.hns.to/"><div><p><img src="https://d1fdloi71mui9q.cloudfront.net/7u6x3VMRnSn9UvZfiKb8_NQgVRZM9BV6EO8w1"></p><p>See Tieshun Roquerre's</p></div></a><a target="_blank" rel="noopener noreferrer" href="https://aadil.hns.to/"><div><p><img src="https://pbs.twimg.com/profile_images/1220107241572823040/u91PxG7a_400x400.jpg"></p><p>See Aadil Razvi's</p></div></a></div></div></div></div></div>]]>
            </description>
            <link>https://www.namebase.io/dlinks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457712</guid>
            <pubDate>Thu, 17 Dec 2020 17:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin: Why “Store of Value” Is a Bullshit Argument]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25457698">thread link</a>) | @wiggumspiggums
<br/>
December 17, 2020 | https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/#Is-Preserving-Wealth-What-People-Really-Care-About | <a href="https://web.archive.org/web/*/https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/#Is-Preserving-Wealth-What-People-Really-Care-About">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
												
<p>There’s this narrative in the Bitcoin community that you may have heard: The government doesn’t care about you and is printing money with no conscience. Preserve your wealth with Bitcoin! Money printers go brrrr! </p>



<p>It makes Bitcoin sound virtuous. </p>



<p>But it’s a sales pitch.</p>



<p>In this post, we’ll talk about how Bitcoin stacks up to gold as a hedge against inflation and why we don’t think wealth preservation is what really motivates most Bitcoin investors.</p>



<p>Table of Contents:</p>



<ul><li><a href="#Why-Bitcoin-Is-Compared-to-Gold">Why Bitcoin Is Compared to Gold</a></li><li><a href="#Why-Bitcoin-Is-Better-Than-Gold">Why Bitcoin Is Better Than Gold</a></li><li><a href="#The-Store-of-Value-Argument">The “Store of Value” Argument</a></li><li><a href="#Is-Preserving-Wealth-What-People-Really-Care-About">Is Preserving Wealth What People Really Care About?</a></li></ul>



<h2 id="Why-Bitcoin-Is-Compared-to-Gold">Why Bitcoin Is Compared to Gold</h2>



<p>People call Bitcoin “digital gold” because both Bitcoin and gold have a limited supply. Unlike fiat/paper currency, which can be printed at the discretion of the government, Bitcoin will only ever have 21 millions coins unless +51% of its miners agree to change the protocol (which is highly unlikely). As for gold, there’s only so much that can be mined out of the earth.</p>



<h2 id="Why-Bitcoin-Is-Better-Than-Gold">Why Bitcoin Is Better Than Gold</h2>



<p>Many believe Bitcoin is superior to gold because:</p>



<ol><li>It’s digital so potentially harder to get seized by the government or stolen by a criminal. (Of course, if someone knows you own Bitcoin, they could still threaten you with force or violence to access it). </li><li>It’s easy to send. Anyone with a basic internet connection and some sort of computing device can send/receive Bitcoin. But gold is not because it’s a physical object and a heavy one at that.</li><li>It’s easily verifiable through cryptographic technology.</li><li>It’s infinitely divisible, which of course gold is not. There’s actual a unit of currency called a Satoshi, and 1 Bitcoin equals 100 million Satoshis.</li><li>It is somewhat programmable (though not nearly as advanced as a <a href="https://prudentlycrypto.com/why-invest-in-ethereum/" target="_blank" rel="noreferrer noopener">Ethereum</a>).</li></ol>



<p>But Bitcoin has some important disadvantages:</p>



<ol><li>It’s not fully private. Because the Bitcoin ledger aka blockchain is open to the public, Bitcoin transactions can reveal information about the senders and recipients. Authorities have taken advantage of this lack of complete anonymity to catch criminals.</li><li>It’s not as widely accepted or trusted: by society, financial institutions, governments, etc.</li><li>It’s very speculative &amp; volatile and has a much shorter a track record.</li></ol>



<h2 id="The-Store-of-Value-Argument">The “Store of Value” Argument</h2>



<p>Because both Bitcoin and gold are scarce, people think Bitcoin can serve the same purpose as gold: act as a better store of value over paper money and hedge against inflation.</p>



<p>You may have heard worries over inflation because of governments printing money to provide financial relief due to Covid-19. Some notable investors, like Raoul Pal and Ray Dalio, have said so, too.</p>



<p>So in the eyes of many Bitcoin enthusiasts, one of the most compelling arguments in support of Bitcoin is the fact that it can preserve wealth from being inflated away.</p>



<p>(NOTE: We know <a href="https://www.bloomberg.com/news/articles/2020-05-07/paul-tudor-jones-buys-bitcoin-says-he-s-reminded-of-gold-in-70s" target="_blank" rel="noreferrer noopener">Paul Tudor Jones</a> says that a store of value must have purchasing power, trustworthiness, liquidity and portability. But scarcity is what the majority of folks focus on).</p>



<h2 id="Is-Preserving-Wealth-What-People-Really-Care-About">Is Preserving Wealth What People Really Care About?</h2>



<p>Let’s rephrase this question a bit: Let’s say inflation was high at 10% per year. But a total stock market ETF gave a 15% return on the year. Would anyone give a rat’s ass about Bitcoin, if it kept up with inflation but <em>didn’t</em> beat the market?</p>



<p>We think not. Because, let’s be honest, the excitement around Bitcoin <em>as an “investment</em>” is its outstanding returns.&nbsp;</p>



<p>Many people promote Bitcoin, arguing that it is the best inflation hedge. But protecting against inflation is not as important to them as seeing the price of Bitcoin go up. Because Bitcoin is scarce, getting more people to adopt Bitcoin as an inflation hedge drives up the price. So the justification is your wealth preservation. But the motivation is their wealth accumulation.</p>



<p><em>Now, does this detract from Bitcoin as a financial innovation? </em>No.</p>



<p><em>Does this mean Bitcoin does NOT act as a hedge against inflation? </em>No, it can despite other people’s ulterior motives advocating for it.&nbsp;</p>



<p><em>Does this stop us <a href="https://prudentlycrypto.com/about/" target="_blank" rel="noreferrer noopener">Crypto Prudes</a> from buying and hodling Bitcoin? </em>Not at all.</p>



<p>We just think it’s important to have clear eyes when betting on Bitcoin because Bitcoin as a “store of value” is not what is truly motivating current investors. The truth is they wanna see Bitcoin beat the pants off all other investments. Otherwise, nobody would really give a shit (us included). </p>



<p><em>Disclaimer: this article should be treated as informational only and not as financial, investment or any other advice.&nbsp;</em></p>
											</div></div>]]>
            </description>
            <link>https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/#Is-Preserving-Wealth-What-People-Really-Care-About</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457698</guid>
            <pubDate>Thu, 17 Dec 2020 17:23:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cold War II has started, and China is a bigger challenger than the USSR ever was]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25457476">thread link</a>) | @lawschool333
<br/>
December 17, 2020 | https://www.pairagraph.com/dialogue/cf3c7145934f4cb3949c3e51f4215524?hack | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/cf3c7145934f4cb3949c3e51f4215524?hack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/cf3c7145934f4cb3949c3e51f4215524?hack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457476</guid>
            <pubDate>Thu, 17 Dec 2020 17:04:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The significance of ARM on AWS: cost savings, climate goals and security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25457417">thread link</a>) | @donkersgood
<br/>
December 17, 2020 | https://www.sentiatechblog.com/aws-re-invent-2020-day-10-the-future-of-cloud-runs-on-arm | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/aws-re-invent-2020-day-10-the-future-of-cloud-runs-on-arm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!-- ## AWS re:Invent 2020 Day 10: The Future of Cloud Runs on ARM -->
<p>Graviton2, AWS’ latest generation of ARM-based processors, was announced a year ago at re:Invent 2019. But the amount of times Graviton2 was mentioned in re:Invent 2020 keynotes almost made me believe it was this year’s major announcement. Let’s look at why Amazon seems to be all in on ARM, and what to expect in the coming years.</p>
<h3>The history of ARM and x86</h3>
<p>ARM has been around since the 1980’s. The company Arm Ltd. (also known as Arm Holdings) designs processor architectures and cores based on a reduced instruction set (RISC). The designs for these architectures and cores are licensed to third parties, who use them to design their own microcontrollers (MCUs), Systems-on-Chips (SOCs) and CPUs. Examples are Qualcomm’s Snapdragon, Apple’s mobile CPUs (A4, A5, currently up to A14), Apple’s desktop CPU M1, and Amazon’s Graviton and Graviton2 processors. There are hundreds of other types of processors built on ARM architecture, but these are some of the most famous ones.</p>
<p>ARM processors were originally designed for use in personal computers. However, their efficiency and the fact that third parties could design their own specialized SOCs and CPUs around the ARM core made ARMs especially popular for embedded devices like printers, network appliances and mobile devices. Windows’ rise to dominance on the desktop market, combined with its requirement for the x86 architecture, seemed to seal ARMs faith for use in small, efficient devices only.</p>
<p>Since the start of the century, smartphones have become ubiquitous. These devices need to be small and efficient, which made ARM processors a logical choice. In fact, almost every smartphone runs on ARM. The first iPhone was based on a Samsung 32-bit RISC ARM processor, and the first Android phone - the HTC Dream - was based on a Qualcomm ARM11 processor. There have been a few phones based on the x86 instruction set, but none have been successful.</p>
<p>At the same time, the x86 processors produced by Intel and AMD started to run into their design limits. For decades, these processors became more powerful by increasing their clock speed - they simply were able to run more operations per second. But somewhere between 4GHz and 5GHz, increasing the clock speed became nearly impossible; the increased speed required higher voltages, which led to higher temperatures which had to be channeled away. At some point these CPUs either needed giant cooling systems or they would simply melt. The solution was to introduce multiple cores in a single CPU. Each of these cores was limited at a certain speed, but by executing multiple processes in parallel systems could still become faster. To increase the utilization of these cores, multithreading was invented. With multithreading, a single core could time-share its capacity, allowing two or more threads to run semi-simultaneously on a single core. To make this work, an SMT (simultaneous multithreading) controller had to be added to the CPU. The SMT controller managed and assigned different threads for the CPUs cores. However,  SMT itself uses power, which made multithreading CPUs less efficient. Adding more components also made CPUs more complex and expensive. And as we will see in a later section, SMT controllers introduced new security risks.</p>
<h3>Linux, Raspberry Pi, smartphones and the Apple M1</h3>
<p>Although Windows could not run on ARM, Linux has been supporting desktops on ARM since about the year 2000. Propelled by the introduction of the Raspberry Pi in 2012, many developers and hobbyists have been experimenting with running full-fledged operating systems and desktops on ARM platforms. Additionally, the lucrative smartphone market pushed mobile phone developers to create ever faster and more efficient processors. Apple introduced their A4 SOC in the iPhone 4, and they have been pushing the performance of their ARM processors every year since. In 2018, Anandtech <a rel="noopener noreferrer" href="https://www.anandtech.com/show/13392/the-iphone-xs-xs-max-review-unveiling-the-silicon-secrets/4">wrote</a>:</p>
<blockquote>
<p>What is quite astonishing, is just how close Apple’s A11 and A12 are to current desktop CPUs. I haven’t had the opportunity to run things in a more comparable manner, but taking our server editor, Johan De Gelas’ recent figures from earlier this summer, we see that the A12 outperforms a moderately-clocked Skylake CPU in single-threaded performance.</p>
</blockquote>
<p>This has been a turning point in the history of processors. Since 2018, ARM processors have proven to be more powerful, efficient, secure and cheaper than their x86 siblings. Additionally, the performance growth path for x86 seems to be plateauing, while there is a lot of room for performance improvement in the ARM architecture. With these facts it came as no surprise that Apple started looking into running their personal computer line on ARM years ago. This year they finally released their MacBook Air, MacBook Pro and Mac Mini with the M1 CPU, based on the ARMv8.6-A architecture.</p>
<p>With Apple moving towards ARM, Amazon doing the same, almost all smartphones running ARM now and in the foreseeable future, and the existing market for embedded devices, the future looks bright for ARM. Nvidia definitely seems to agree - they acquired Arm Holdings from Softbank for a cool <a rel="noopener noreferrer" href="https://nvidianews.nvidia.com/news/nvidia-to-acquire-arm-for-40-billion-creating-worlds-premier-computing-company-for-the-age-of-ai">40 billion</a> in September 2020.</p>
<h3>Arguments for ARM-based servers</h3>
<p>Driven by ARM’s increasing popularity, many software platforms, operating systems (including Windows nowadays!), applications and libraries support the AArch64 (ARM 64-bit) architecture. These include popular web server applications like NginX and Apache, databases like MySQL and PostgreSQL, and programming languages like Python and Java.</p>
<p>With this broad support, switching from x86 to AArch64 is not quite as difficult as it used to be. There might be some compatibility issues, but most applications should be able to migrate without too much effort. This means there is a giant market of potential customers of ARM-based servers. But why would customers want to migrate?</p>
<p>The answer is the obvious and only argument for any migration: money. An ARM processor is cheaper than an Intel or AMD processor, while - as discussed above - ARM equals or even tops x86 performance. Depending on your workload, AWS’ Graviton2 processors can offer up to 40% better price/performance than comparable x86 chips. And while 40% is only achievable in ideal situations, even 20% is very significant!</p>
<p>Another driver for ARM based servers is security. As stated earlier the SMT controller adds additional complexity to processors. The controller also needs access to all the cores and threads on the CPU to effectively manage them. Through a <a rel="noopener noreferrer" href="https://www.wired.com/story/researchers-expose-a-new-vulnerability-in-intels-cpus/">recent vulnerability</a> attackers were able to abuse SMT to access sensitive data from other cores. This is especially important in public cloud environments, where customers almost always share physical hardware with other customers. The Graviton2 architecture shares no cache or threads between different cores: every thread runs on a single core with its own L1 and L2 cache.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/6YwGWEdHD71N8jN3710Ud3/4ef35329d5b30550f28d02a3946561b8/separate_cores.jpg?fit=scale&amp;w=920" alt="Separate Cores"></p>
<h3>Driving sustainability with Graviton2</h3>
<p>In the infrastructure keynote it became clear that Graviton2 is an important component in achieving AWS’ sustainability goals. ARM processors require less power to achieve the same performance as x86 processors. This means less power consumption, but it also has indirect benefits. Less power consumption means less excess heat, which means less cooling, which itself means less power consumption as well. Of course, this too is translated into the lower consumer costs for Graviton2.</p>
<h3>Low-friction cost savings with managed services like RDS</h3>
<p>Migrating from x86 to AArch64 is relatively easy. However, ‘relatively easy’ can still be ‘absolutely difficult’ in large and complex environments. If you want to benefit from Graviton’s improved price/performance over x86 as soon as possible, there might be some low hanging fruit. Amazon is supporting Graviton in more and more of their managed services. They started with <a rel="noopener noreferrer" href="https://aws.amazon.com/about-aws/whats-new/2020/07/announcing-preview-for-amazon-rds-m6g-and-r6g-instance-types/">RDS</a>, followed by <a rel="noopener noreferrer" href="https://aws.amazon.com/about-aws/whats-new/2020/10/amazon-elasticache-now-supports-m6g-and-r6g-graviton2-based-instances/">ElastiCache</a> and they just announced support in <a rel="noopener noreferrer" href="https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-amazon-aurora-r6g-instance-types-powered-by-aws-graviton-2-processors-in-preview/">Aurora</a>. These databases are all reachable over a well-established protocol, and the inputs and outputs between one CPU architecture and another should be no different. This allows you to achieve instant cost savings without any architectural change.</p>
<p>Other services currently supporting Graviton2 processors are EMR, EKS, ECS, CodeBuild and Outposts. Switching architectures with these services will require more effort than the databases, but it’s good to be aware of their support.</p>
<h3>Conclusion</h3>
<p>I believe Amazon will bring ARM support to every single one of the services where customers select instance types, including Sagemaker, Neptune, Redshift DocumentDB, DMS, MSK, and so on. Additionally, I think they will internally use Graviton to power many services where the underlying hardware is invisible, such as S3, DynamoDB, Lambda, Cognito, Alexa, Route 53 and many others. It’s simply more cost efficient.</p>
<p>For AWS customers ARM support has unlocked a large number of cost savings opportunities. Frankly I can’t think of any reason not to try RDS, ElastiCache or Aurora on Graviton instances. Likewise, you can’t go wrong exploring the cost savings Graviton2 offers on your compute (EC2, ECS, EKS) workloads. The investment for the migration process might be significant, but I think you’ll be surprised by existing compatibility and the long-term savings you might gain. As they say in Dutch: you’re a thief of your own wallet if you don’t.</p>
<p>This article is part of a series published around re:Invent 2020. If you would like to read more about re:Invent 2020, check out my other posts:</p>
<ul>
<li><a rel="noopener noreferrer" href="https://www.sentiatechblog.com/aws-re-invent-2020-day-1-top-5-announcements">AWS re:Invent 2020 Day 1: Top 5 Announcements</a></li>
<li><a rel="noopener noreferrer" href="https://www.sentiatechblog.com/aws-reinvent-2020-day-1-s3-announcements">AWS re:Invent 2020 Day 1: S3 Announcements</a></li>
<li><a rel="noopener noreferrer" href="https://www.sentiatechblog.com/aws-re-invent-2020-day-2-aws-is-coming-to-a-data-center-or-pizza-parlor-near">AWS re:Invent 2020 Day 2: AWS is coming to a data center (or pizza parlor) near you!</a></li>
<li><a rel="noopener noreferrer" href="https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading">AWS re:Invent 2020 Day 3: Optimizing Lambda Cost with Multi-Threading</a></li>
<li><a rel="noopener noreferrer" href="https://www.sentiatechblog.com/re-invent-2020-day-4-top-5-announcements-for-wednesday-friday">AWS re:Invent 2020 Day 4: Top 5 Announcements for Wednesday - Friday</a></li>
<li><a rel="noopener noreferrer" href="https://www.sentiatechblog.com/aws-re-invent-2020-day-5-aws-is-adding-a-region-near-you">AWS re:Invent 2020 Day 5: AWS is Adding a Region Near You!</a></li>
<li><a rel="noopener noreferrer" href="https://www.sentiatechblog.com/building-a-multiplayer-game-architecture-with-global-accelerator-custom-accelerators">AWS re:Invent 2020 Day 8: Building a Multiplayer Game Architecture with Global Accelerator Custom Routing</a></li>
<li><a rel="noopener noreferrer" href="https://www.sentiatechblog.com/aws-re-invent-2020-day-9-roundup-week-2">AWS re:Invent 2020 Day 9: …</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/aws-re-invent-2020-day-10-the-future-of-cloud-runs-on-arm">https://www.sentiatechblog.com/aws-re-invent-2020-day-10-the-future-of-cloud-runs-on-arm</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/aws-re-invent-2020-day-10-the-future-of-cloud-runs-on-arm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457417</guid>
            <pubDate>Thu, 17 Dec 2020 16:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top SEO myths to kiss goodbye in 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25456877">thread link</a>) | @mogens-kramtoft
<br/>
December 17, 2020 | https://tabtimize.com/top-10-seo-myths-to-kiss-goodbye-in-2020/ | <a href="https://web.archive.org/web/*/https://tabtimize.com/top-10-seo-myths-to-kiss-goodbye-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
	
<p>There are multiple myths and misconceptions surrounding SEO—one of the most critical and important aspects of contemporary online marketing.&nbsp;</p>



<p>Following misleading information can steer even the most well-meaning and hard-working digital marketers and bloggers down the wrong path, blocking their chances of improving site rankings and traffic. Statements such as “<em>SEO results should be instant</em>” or “<em>SEO is a waste of time</em>” are but a few examples of the misinformation that circulates in the digital marketing world. You’ve probably even heard some of these yourself.&nbsp;</p>



<p>So why is there so much deceptive information out there? First off, it’s difficult to pin it to one specific source as it’s because of a combination of factors. However, some causes could be linked to the following:</p>







<h2><strong>It’s profitable for some companies to mislead people online.&nbsp;</strong></h2>



<p>It’s the not-so-nice reality of the competitive SEO game. Most of us are familiar with <a href="https://publicpolicy.googleblog.com/2015/09/protecting-people-from-illegal-robocalls.html" target="_blank" rel="noreferrer noopener">Google having to deal with marketing firms pretending to be them</a> and scamming countless unsuspecting small business owners out of their hard-earned money. Combine the prevalence of online scamming with the fact that most people want their marketing and SEO activities done faster than ever (without having much knowledge on the subject), causes people to fall victim to businesses that advertise “<em>quick results for low monthly cos</em>ts” etc.&nbsp;</p>



<p>The market demand for SEO is high, but confusion surrounding SEO is rampant. This creates an opening for businesses to sell a variety of disadvantageous SEO services to the public—who continue to buy into them. And so the cycle continues.&nbsp;</p>







<h2><strong>SEO is constantly changing—so some advice you see online can be outdated.&nbsp;</strong></h2>



<p>SEO has evolved big time.</p>



<p>What Google looks for, though, has remained the same—the only difference now is that they are more vigilant and much better at managing links. Google’s principal aim is to reward highly relevant sites that can also provide the best solutions to user-specific problems. This requires digital marketers to focus on building relevant links, coding, meta tags—and producing better content. Following outdated SEO advice, might lead to penalties by Google. <a href="https://www.searchenginejournal.com/google-algorithm-history/penguin-update/#close" target="_blank" rel="noreferrer noopener nofollow">You can read about the Google Penguin Algorithm that changed SEO rules in this article.</a>&nbsp;</p>



<p>So what are the most common myths about SEO to avoid in 2020, and have you fallen victim to any of these below? Note that none of these statements are in any particular order, but we believe they represent the most common myths in SEO.&nbsp;</p>







<h2>SEO Myth 1: <strong>“SEO Results should be instant.”&nbsp;</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-1.jpg" alt="SEO myth 1 - SEO Results should be instant" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-1.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-1-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-1-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p><em>“If anyone promises to help your keyword instantly rank #1 on Google, don’t believe them.”&nbsp;</em></p>



<p>This myth is one of the most dangerous and likely originates from people looking for quick wins with the least effort. While you might get lucky and see immediate results with select keywords —it’s an unlikely (and rare) event. Most often, rankings won’t budge until after several months, which is when you’ll see the true benefits of your SEO efforts. As SEO is a long-term strategy, it’s difficult to measure the results in a short time frame. The key is to monitor and experiment with keywords along the way.&nbsp;</p>







<h2>SEO Myth 2: <strong>“SEO is just about buying as many links as possible.”</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-2.jpg" alt="SEO myth 2 - SEO is just about buying as many links as possible" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-2.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-2-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-2-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>As a general rule, if you’re able to buy multiple links at a low price—chances are they’re not relevant and have no domain authority. In short, they’re worthless. Buying links in bulk can be a common (though black hat) activity, and we never recommend you to do so. <a href="https://developers.google.com/search/docs/advanced/guidelines/link-schemes?hl=en&amp;visit_id=637421046067928866-3023184840&amp;rd=1" target="_blank" rel="noreferrer noopener">You’d be committing a big no-no if you buy backlinks specifically to boost your rankings</a>, as it directly goes against Google’s Webmaster Guidelines. Buying large amounts of random backlinks from link farms or FFA sites can land you in hot water and place your brand next to shady websites that could make your brand reputation suffer. Quality of links always wins over quantity.&nbsp;</p>







<h2>SEO Myth 3: <strong>“The type of links don’t matter, and neither does content.”</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-3.jpg" alt="SEO myth 3 - The type of links dont matter, and neither does content" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-3.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-3-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-3-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>As we touched on above, you can be sure that the type of link matters! Random backlinks that don’t have any relevance or authority won’t add any value to your page. The more random links you have on your page, the less they are worth, and might also get you penalized by Google.&nbsp;</p>



<p>Link building is arguably one of the most transformative SEO activities to amplify traffic and a must-have in every strategic marketer’s toolbox. Backlinks and content strategy work synergistically, and without purposeful and engaging content your audience won’t be able to make <strong>purchasing decisions</strong> or <strong>convert into leads</strong>.&nbsp;</p>



<p>Here at Tabtimize, we know that not all links are created equal. You can read more about <a href="https://tabtimize.com/top-3-things-only-tabtimize-can-do-for-you/" target="_blank" rel="noreferrer noopener">why relevant links are so important to your SEO efforts</a>, and <a href="https://tabtimize.com/link-community-waiting-list/">how to build them with the Link Community feature.&nbsp;</a></p>







<h2>SEO Myth 4: <strong>“White hat SEO takes too long.”</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-4.jpg" alt="SEO myth 4 - White hat SEO takes too long" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-4.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-4-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-4-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>While results can take some time to show with White hat SEO, you can guarantee that they will be more sustainable. As we touched on in previous points, the downsides of Black hat SEO could cost you penalties and reputational damage.</p>






<p><img loading="lazy" src="https://lh5.googleusercontent.com/hRNIq2lXlznlD45VNCNxn2ZdWnIPWnhfuC6CUnlAIOiKfgm-fmhe5kclLGu-bM0q08k7I5D_JqkrqolJBlpI4vFaH2gkdA6P6e_8ziXReI2IUl2QgGn2UKnUNBHQnHchtMkinUMY" alt="black hat seo could cause penalties" width="495" height="305"></p>


<p><a href="https://www.seoquake.com/blog/white-hat-seo-vs-black-hat-seo/" target="_blank" rel="noreferrer noopener nofollow">Source</a></p>



<p>It’s important to remember that Google updates and complicates its algorithms and ranking factors frequently, so it’s essential for marketers to stay up to date with the changes and make sure they’re operating under Google’s guidelines. Sites that consistently stick with White hat practices avoid being heavily sanctioned by Google and consistently rank higher in SERP positions, due mostly to their adherence to the rules. It’s a process that takes time but offers stable and sustainable results.&nbsp;</p>







<h2>SEO Myth 5: <strong>“Keyword research doesn’t matter.”</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-5.jpg" alt="SEO Myth 5 - Keyword research doesn't matter " srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-5.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-5-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-5-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>You could irreparably hurt your SEO efforts if you ignore insightful keyword research for your website. Keyword research helps to attract as much organic traffic to your page as possible, a permanent aim of SEO. Performing quality keyword research ensures that you’re optimizing keywords with the user’s intent in mind, and also for the most frequently used way of searching for a topic.&nbsp;</p>







<h2>SEO Myth 6: <strong>“Keyword density is super important.”&nbsp;</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-6.jpg" alt="SEO Myth 6 - Keyword density is super important" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-6.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-6-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-6-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>Is mentioning a keyword you want to rank for within your content, useful? Well, of course, it is. But there isn’t an <em>X</em> number of times you need to mention it for the search engine to pick up on what you’re talking about. The algorithm is smart, and with technology breakthroughs like semantic search—you don’t need to drop keywords every other sentence. <strong>Fun Fact:</strong> <a href="https://tabtimize.com/how-to-find-contextually-relevant-link-opportunities/" target="_blank" rel="noreferrer noopener">Tabtimize also uses the power of semantic understanding to find the contextual correlation between pages</a>. It can break down into percentage points how relevant one piece of content is to the other, making requesting backlinks between sites easy and pitch-free. Neat, right?&nbsp;</p>







<h2>SEO Myth 7: <strong>“SEO is very expensive.”&nbsp;</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-7.jpg" alt="SEO Myth 7 - SEO is very expensive" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-7.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-7-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-7-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>It can be, but it doesn’t always have to be.&nbsp;</p>



<p>How expensive or economical SEO is, entirely depends upon your organizational needs, objectives, and competitive environment. If you’re a large corporation looking to increase your footprint globally, operate in a hyper-competitive environment, and have significant organizational needs—the cost of overhauling such a large SEO effort will be high. Compare that to a small business looking to increase its local visibility. SEO packages and pricing can be customized based on your individual needs and objectives and don’t always need to be ultra-expensive. This is probably also one of the most circulated myths out there, that need to be put to rest.&nbsp;</p>







<h2>SEO Myth 8: <strong>“Long-form content means you will rank higher.”&nbsp;</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-8.jpg" alt="SEO Myth 8 - Long-form content means you will rank higher" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-8.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-8-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-8-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>After Google released the Hummingbird algorithm, the focus is now on user intent, solving user problems, and providing added value. Long-form content is only really useful if it provides this and is closely modeled with user intent in mind. Long-form content can help with rankings if it’s part of a broader content strategy, but shouldn’t be the backbone of it. Not every behemoth blog post or article is going to reach every user, so it’s better to scrap the notion that all your content needs to be lengthy—and instead focus on user problems it can solve or what intent it captures. Still not convinced? <a href="https://tabtimize.com/ideal-word-count-for-seo-2020/" target="_blank" rel="noreferrer noopener">We performed a Content vs. Word count test, that proves that relevant content is more important than word count</a>. Check it out.</p>







<h2>SEO Myth 9: <strong>“Anyone can do SEO in 2020.”</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-9.jpg" alt="SEO Myth 9 - Anyone can do SEO in 2020" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-9.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-9-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-9-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>It’s a dangerous notion to think that you can take on all the responsibility of SEO optimization without having the proper training for it. Though certain things may seem straightforward and logical, you can risk more harm than good if you aren’t 100% aware of how search engines work. By not following Google’s regulations, keeping up to date with the multiple algorithm changes, and working within White Hat guidelines—you could risk causing your rankings to plummet, getting multiple penalties, and possibly getting de-indexed by Google. If you’re unsure about the right way to go about SEO, it’s always a great idea to get some help. In fact, thousands of experienced marketers and agencies rely on the help of outside SEO specialists to ensure they’re getting the best results.&nbsp;</p>







<h2>SEO Myth 10: <strong>“SEO is a waste of time.”&nbsp;</strong></h2>



<figure><img loading="lazy" width="1000" height="639" src="https://tabtimize.com/wp-content/uploads/2020/12/illu-10.jpg" alt="SEO Myth 10 - SEO is a waste of time" srcset="https://tabtimize.com/wp-content/uploads/2020/12/illu-10.jpg 1000w, https://tabtimize.com/wp-content/uploads/2020/12/illu-10-300x192.jpg 300w, https://tabtimize.com/wp-content/uploads/2020/12/illu-10-768x491.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>If it was, no one would bother with it.&nbsp;</p>



<p>Big companies wouldn’t be rushing to bring in large teams of SEO specialists and professionals to help their marketing efforts dominate their respective industries, or startups and small businesses wouldn’t be using it as a scalable high growth channel. SEO is so effective because of the vast number of high-intent searches that are done on it every single day. It’s extremely important to remember that SEO is <em>not</em> a short-term game, you can’t expect to only work on it for a few weeks, a few months, or even a year and then call it quits. For organic results to show, you need to invest both your time and effort to reap valuable rewards.&nbsp;</p>



<p>Your SEO strategy needs to be ongoing and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tabtimize.com/top-10-seo-myths-to-kiss-goodbye-in-2020/">https://tabtimize.com/top-10-seo-myths-to-kiss-goodbye-in-2020/</a></em></p>]]>
            </description>
            <link>https://tabtimize.com/top-10-seo-myths-to-kiss-goodbye-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456877</guid>
            <pubDate>Thu, 17 Dec 2020 16:11:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Investigating performance bottlenecks using our own product and Google Sheets]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25456674">thread link</a>) | @xoelop
<br/>
December 17, 2020 | https://blog.tinybird.co/2020/12/15/eating-our-own-dog-food-how-we-investigate-performance-bottlenecks-using-our-product-and-google-sheets/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2020/12/15/eating-our-own-dog-food-how-we-investigate-performance-bottlenecks-using-our-product-and-google-sheets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>We use ClickHouse under the hood, and it lets some of our customers query hundreds of billions of rows per hour in real time.</p> <blockquote data-lang="en" data-dnt="true" data-theme="light" data-cards="hidden">— Tinybird Co. (@tinybirdco) <a href="https://twitter.com/tinybirdco/status/1336956317735464961?ref_src=twsrc%5Etfw">December 10, 2020</a></blockquote>  <p>But this doesn’t come without challenges. We still have to think very carefully when writing queries and designing how we store and process data. It is an iterative process and when data or concurrency increase, some queries have to be rewritten to maintain performance.</p> <h2 id="monitoring-api-response-times">Monitoring API response times</h2> <p>Our enterprise tier includes performance (QPS and latency) SLAs that our platform needs to satisfy. We provide a platform where our customers can store, process and <a href="https://guides.tinybird.co/guide/using-dynamic-parameters-for-changing-aggregation-types-on-the-fly">define dynamic API endpoints</a> to query their data.</p> <p>As users can define arbitrary endpoints, some of them could end up being too computationally expensive and slow. That would have an impact on performance, so to meet the SLAs we sometimes also help our enterprise customers optimize their data schemas and their queries.</p> <p>Monitoring the requests made to those endpoints and their duration is fundamental to know how well the system is performing and whether more work has to be done to meet performance requirements.</p> <p>This log data is available for all Tinybird accounts via the <a href="https://docs.tinybird.co/api-reference/service-datasources.html#tinybird-pipe-stats-rt">tinybird.pipe_stats_rt</a> service data source, for the past two days.</p> <figure> <img src="https://blog.tinybird.co/images/2020-12-15/pipe_stats_rt.png" alt="The tinybird.pipe_stats_rt Data Source provides request time, endpoints called, full URLs, response durations and error codes, if any"> <figcaption>The tinybird.pipe_stats_rt Data Source provides request time, endpoints called, full URLs, response durations and error codes, if any</figcaption> </figure> <p>But even if you don’t use Tinybird, if you have requests logs for your app’s endpoints, you could do a similar analysis to the one we explain below.</p> <h2 id="correlating-presence-or-absence-of-query-parameters-with-response-times">Correlating presence or absence of query parameters with response times</h2> <p>The goal here is detecting what parameters have a bigger impact on query complexity when they’re present in the request URLs, and then modifying those queries or the underlying schemas to keep response times low.</p> <p>For any given endpoint, if response times are higher when a certain parameter appears in the request URL, and they’re lower when it doesn’t appear, the correlation between response times and whether that parameter was included in the URL will be high.</p> <p>Computing whether and which parameters appear in each request URL can be done with some of the <a href="https://clickhouse.tech/docs/en/sql-reference/functions/string-search-functions/">string search functions</a> that ClickHouse provides us with. To calculate whether the endpoint URL contains the word <code>country</code>, we’d add a column like:</p> <div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>position</span><span>(</span><span>url</span><span>,</span> <span>'country'</span><span>)</span> <span>&gt;</span> <span>0</span> <span>h_country</span><span>,</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>We could also perform the previous step using <a href="https://clickhouse.tech/docs/en/sql-reference/functions/url-functions/#extracturlparameterurl-name">extractURLParameter</a>, another ClickHouse function.</p> <p>To add a column that counts the number of elements of a comma-separated-values parameter, we’d do:</p> <div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>length</span><span>(</span><span>splitByChar</span><span>(</span><span>','</span><span>,</span> <span>coalesce</span><span>(</span><span>extractURLParameter</span><span>(</span><span>url</span><span>,</span> <span>'country'</span><span>),</span> <span>''</span><span>)))</span> <span>n_country</span><span>,</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>And finally, the last step is getting the correlation between whether a query string is present in the endpoint and the duration of the requests made to that endpoint. The higher the correlation, the longer the calls to that endpoint take when that parameter is present, and the more work will likely have to be done to bring request durations down.</p> <p>We can also compute correlation within Tinybird and ClickHouse, with the <a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/reference/corr/">corr</a> function</p> <figure> <img src="https://blog.tinybird.co/images/2020-12-15/corr_node.png" alt="Correlating all the variables we've created with response duration"> <figcaption>Correlating all the variables we've created with response duration</figcaption> </figure> <p>Some elements of the correlation matrix will probably be null (because a parameter was never present in an endpoint), so we’ll replace those null values with 0. ClickHouse lets us do it with the <a href="https://clickhouse.tech/docs/en/sql-reference/functions/conditional-functions/#ternary-operator">ternary operator</a></p> <figure> <img src="https://blog.tinybird.co/images/2020-12-15/fillna_corr.png" alt="Replacing null values with 0"> <figcaption>Replacing null values with 0</figcaption> </figure> <h2 id="visualizing-the-correlation-matrix-in-google-sheets">Visualizing the correlation matrix in Google Sheets</h2> <p>Tinybird allows you to expose the results of a pipe with a JSON or CSV API endpoint. Clicking on the <strong>View API</strong> button in the top right corner you’ll see a self-documenting page for the endpoint exposed:</p> <figure> <img src="https://blog.tinybird.co/images/2020-12-15/api_docs.png" alt="API endpoint documentation page within Tinybird"> <figcaption>API endpoint documentation page within Tinybird</figcaption> </figure> <p>And with the <a href="https://support.google.com/docs/answer/3093335?hl=en">IMPORTDATA</a> function available in Google Sheets, we can import the results into a spreadsheet, where we can visualize them much better:</p> <figure> <img src="https://blog.tinybird.co/images/2020-12-15/corr_matrix.png" alt="Visualizing the correlation matrix in Google Sheets"> <figcaption>Visualizing the correlation matrix in Google Sheets</figcaption> </figure> <h2 id="what-did-we-do-to-fix-it">What did we do to fix it?</h2> <p>For example, in this case we’d see that the endpoints 0, 1 and 14 tend to be slower with non-aggregated data (<code>h_non_aggr</code>). To fix it, we <strong>partitioned the table and set a good sorting key</strong> so that it does not have to do a full scan every time.</p> <p>Also, the bigger the range of dates we’re reading data from (<code>n_day</code>), the slower endpoints 8, 12 and 22 are. To deal with bigger date ranges, the way to go would be <strong>merging data from materialized views with different temporal aggregations</strong>, depending on the date range of the current query.</p> <p>We also noticed that endpoints filtered by country (<code>h_country</code>, <code>h_country2</code>) tend to be faster (except endpoint 2, due to an expensive array filtering). So we <strong>reduced the amount of threads needed for those queries</strong> so that other queries had more threads available.</p> <p>More things: we saw that <code>h_raw_filter</code> impacts performance on most of the endpoints. This is due to an expensive IN filter to a big dimensions Data Source. We did nothing because it would have complicated the logic of other endpoints, but it’s a place where to improve for the future.</p> <p>And finally: the bigger <code>h_page_size</code> is, the slower the queries are. There is nothing to do here. The developers that integrate the endpoints should take it into account, and therefore request <strong>smaller page sizes</strong> and <strong>implement infinite scrolling</strong> or similar.</p> <figure> <img src="https://blog.tinybird.co/images/2020-12-15/old_vs_new_endpoint_times.png" alt="After making these changes, response times went down ~40%"> <figcaption>After making these changes, response times went down ~40%</figcaption> </figure> <p>That’s it! If you’d like to learn more about building real-time analytics systems that perform well over billions of rows, check out our <a href="https://www.tinybird.co/courses/principles-of-real-time-analytics">Principles of Real Time Analytics free course</a></p> <p>Tinybird is the way to build real-time data products. If you too think Data should be analysed as it happens and without worrying about scale, <a href="https://www.tinybird.co/survey">sign-up for an account</a>.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2020/12/15/eating-our-own-dog-food-how-we-investigate-performance-bottlenecks-using-our-product-and-google-sheets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456674</guid>
            <pubDate>Thu, 17 Dec 2020 15:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free 1GB Postgres Database on AWS CloudShell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25456598">thread link</a>) | @ahachete
<br/>
December 17, 2020 | https://www.ongres.com/blog/free-1gb-postgres-database-on-aws-cloudshell/ | <a href="https://web.archive.org/web/*/https://www.ongres.com/blog/free-1gb-postgres-database-on-aws-cloudshell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<main>

        	

	        <section id="post">
	            <p><span>Post</span>
	            </p>

	            <div data-aos="fade-right" data-aos-mirror="false">
	            	
	            	

                    <p> ·
                        <span>Dec 17, 2020</span> ·
                        <span>5 min read</span>
                    </p>

                    

                    

                    <div>
                        
                        <div>
  
  <p><span>Álvaro Hernández</span>
  <span>Founder and CEO</span>
</p></div>
                        
                    </div>
	            </div>

	            <div data-aos="fade-left" data-aos-delay="200" data-aos-mirror="false">
        			
<h3 id="tldr">TL;DR</h3>
<p><a href="https://aws.amazon.com/cloudshell/">AWS CloudShell</a> is a CLI embedded in the AWS Web Console. It is meant to make it
easier to run the AWS CLI, SDK and other scripts from your web browser, without having to install anything locally or
having to deal with local credential and profiles management. <strong>It is a free service</strong>.</p>
<p>It is interesting that you can persist data on your <code>$HOME</code> (up to 1GB!). And this presented an obvious opportunity to
run our favorite database, Postgres, on this environment. Because we all know that
<a href="https://www.lastweekinaws.com/blog/route-53-amazons-premier-database/">everything is a database</a>. AWS CloudShell, too.</p>
<p><strong>If you want to claim your free 1GB Postgres database, per AWS account, per region, you just need to run the following
commands and wait a few seconds/minutes</strong>:</p>
<div><pre><code data-lang="sh">curl -s https://ongres.com/install_postgres_aws_cloudshell.bash | bash
<span>source</span> .bashrc
psql
</code></pre></div><p>(yes, yes, it is a bad practice to run shell scripts from the Internet; please go ahead and
<a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-postgres_on_aws_cloudshell/install_postgres_aws_cloudshell.bash">inspect the short source code</a>
before running it; validate that its <code>sha256sum</code> is <code>102eae7190ba7a4d148d44a62f29c10cfe9d77ffa34eb66438ce5e06941bf6c4</code>;
you get the point)</p>
<p><img src="https://www.ongres.com/img/blog/postgres_on_aws_cloudshell.png" alt="Postgres running on AWS CloudShell"></p>
<h3 id="what">What???</h3>
<p>Yes, you read it well. You can run, for free, a Postgres database on AWS CloudShell, with 1GB (almost) of storage. One
instance per region (where CloudShell is available) per AWS account. There are a few caveats, derived from the
environment, but this is an otherwise unrestricted, non-managed Postgres database:</p>
<ul>
<li>
<p>The instance is not permanently running. Only when you enter the CloudShell from your web browser. Buy hey, <strong>this is
almost like Aurora Serverless</strong>! (well, almost…)</p>
</li>
<li>
<p>You can’t possibly connect to it from the outside. Only locally, and it is configured with this assumption in mind.
But still, you can even use it as your <a href="https://www.terraform.io/docs/backends/types/pg.html">Terraform state storage</a>!</p>
</li>
<li>
<p>There are no replicas (no failover) nor backups. Thought both could be added…</p>
</li>
</ul>
<h3 id="how-it-works">How it works</h3>
<p>The CloudShell environment is a bit restricted, so you cannot just <code>yum install postgresql</code>. In particular, only your
<code>$HOME</code> folder is persistent. This means that no packages can be installed from <code>yum</code> (they may be wiped out).
Postgres will be installed in your home directory: both binaries –in <code>postgres-13</code> folder– and data –in <code>pgdata</code>
folder–. We can neither assume the presence of any external library that Postgres may call/link to, as those would
also not exist if installed via the package manager –we could install them into our <code>$HOME</code> too, but that seemed excessive.</p>
<p>The script needs to be run only once, for the installation. It downloads Postgres source code, configure it with some
appropriate options to keep everything local and not require any additional shared libraries not present in the base
image, compile and installs it locally. Note that some packages are installed via <code>yum</code> (and those will be lost) but are
only needed for compilation, not for running Postgres.</p>
<p>Then the Postgres binaries (including the command line client, <code>psql</code>) and the command to start the database are added
to your <code>.bashrc</code>. So anytime you open CloudShell, your database will be available already for you. Just type <code>psql</code>.</p>
<p>However, what happens when the CloudShell is passivated? Postgres is then abruptly killed. Good news is that Postgres is
a <strong>durable</strong> database, and is designed to survive to these situations. Upon restart, Postgres will find that it wasn’t
shutdown cleanly, and will start recovery. Unless you were doing heavy write load, this recovery process will be quite
fast. If you check the logs, they will be similar to:</p>
<div><pre><code data-lang="sh">2020-12-17 08:45:32.894 GMT <span>[</span>59<span>]</span> LOG:  starting PostgreSQL 13.1 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 7.3.1 <span>20180712</span> <span>(</span>Red Hat 7.3.1-11<span>)</span>, 64-bit
2020-12-17 08:45:32.894 GMT <span>[</span>59<span>]</span> LOG:  listening on IPv4 address <span>"127.0.0.1"</span>, port <span>5432</span>
2020-12-17 08:45:32.905 GMT <span>[</span>59<span>]</span> LOG:  listening on Unix socket <span>"/tmp/.s.PGSQL.5432"</span>
2020-12-17 08:45:32.915 GMT <span>[</span>61<span>]</span> LOG:  database system was interrupted; last known up at 2020-12-17 01:26:37 GMT
2020-12-17 08:45:33.001 GMT <span>[</span>61<span>]</span> LOG:  database system was not properly shut down; automatic recovery in progress
2020-12-17 08:45:33.006 GMT <span>[</span>61<span>]</span> LOG:  invalid record length at 0/17AB4B0: wanted 24, got <span>0</span>
2020-12-17 08:45:33.006 GMT <span>[</span>61<span>]</span> LOG:  redo is not required
2020-12-17 08:45:33.037 GMT <span>[</span>59<span>]</span> LOG:  database system is ready to accept connections
</code></pre></div><p>Also, a slightly optimized configuration for this environment is installed by the script. The most notable tuned parameters are:</p>
<ul>
<li>
<p>max_connections There are two cores on CloudShell, and they appear to be heavily throttled. Plus we’re not serving
really network traffic. Better to keep the value low. Also the configuration includes limiting the processes
parallelism, taking into account the only two cores available.</p>
</li>
<li>
<p>Storage. If you do bulk loadings, you may end up generating a fair amount of WAL, that decreases the effective storage
you may have for your data. So min_wal_size has been set to its minimum possible value in this scenario and
max_wal_size just to 64MB (4 wile segments) to leave some room. If you want to maximize your data storage space you
may have both parameters set to 32MB.</p>
</li>
<li>
<p>Memory parameters. There are 4GB of RAM (nice!), so we can bump up a little bit shared_buffers, work_mem,
maintenance_work_mem and effective_cache_size.</p>
</li>
<li>
<p>Crash recovery. This is very important, since our favorite database will be shutdown abruptly many times. The first
measure is to make frequent checkpoints (by reducing checkpoint_timeout to the minimum value) while increasing the
activity of the background writer, and disabling the “frequent checkpoint warning” –checkpoints they will now be
intentionally frequent.</p>
</li>
<li>
<p>No replicas. Finally we restrict some parameters and minimize wal production knowing that (at least for this post’s
shake) there will be no replicas.</p>
</li>
</ul>
<p>The complete configuration applied to Postgres on CloudShell is the following:</p>

  




<h3 id="next-steps">Next steps</h3>
<p>This could be taken further. It could be possible to add <a href="https://github.com/wal-g/wal-g">WAL-g</a> and make continuous
database backups to S3. Then, by using S3 Cross-Region Replication, that backups and WAL files could be transferred to
another region. And then restore them on another Postgres running on CloudShell and have a read-only replica.</p>
<p>Imagination is the only limit. What’s next, what’s your take?</p>

        		</div>
            </section>

        	

                            
            </main></div></div>]]>
            </description>
            <link>https://www.ongres.com/blog/free-1gb-postgres-database-on-aws-cloudshell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456598</guid>
            <pubDate>Thu, 17 Dec 2020 15:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finnish sauna was chosen to the Unesco Intangible Cultural Heritage list]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25456521">thread link</a>) | @aapokiiso
<br/>
December 17, 2020 | https://www.hs.fi/kulttuuri/art-2000007688939.html | <a href="https://web.archive.org/web/*/https://www.hs.fi/kulttuuri/art-2000007688939.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The decision taken in Paris brings sauna culture to the list, which is a collection of intangible cultural heritage of mankind.</p><p><span>17.12. 15:25</span></p><section><p><span>The waiting</span><span> period has been a long one but now, at last, it happens. The Finnish act of taking a sauna bath is heading to Unescoâ€™s list of intangible human heritage. This elevates the sauna tradition on the global scale to the categories of, say, Indian yoga, Beijing Opera, Argentinian tango, Turkish coffee ceremony ja Iranian rug making.</span></p><p><span>One of the main protagonists of this project, Ms. </span><a href="https://www.hs.fi/haku/?query=Ritva%20Ohmeroluoma">Ritva Ohmeroluoma</a><span> from The Finnish Sauna Society, feels relieved. â€�It took four yearsâ€™ of work to bring the resultâ€�, she says. â€�When we embarked on this a long time ago, we had no idea how long and arduous this process would be.â€�</span></p><p><span>Ms. Ohmeroluoma gives the telephone interview in the middle on something right and proper for the subject. She sits by the sea in Lauttasaari suburb of Helsinki, waiting for the Sauna Societyâ€™s famous saunas to warm up.</span></p><p><span>Finland</span><span> signed Unescoâ€™s Convention for the Safeguarding of the Intangible Cultural Heritage in 2013. The preparations for making it to the list were started a couple of years later.</span></p><p><span>There were, however, many bureaucratic snags on the road. At first The Finnish Heritage Agency had to create a national catalogue of living heritage. Thus far approximately 60 Finnish traditions have been chosen. In addition to sauna bathing the catalogue includes Finnish tango, open-air dance and the knitting of rag rugs.</span></p><p><span>From this catalogue Finland can propose one item each year.</span></p><p><span>Sauna bathing was the first one.</span></p><div><div><p>Ms. Ritva Ohmeroluoma was photographed cooling off on the outdoor terrace of the Finnish Sauna Association in Lauttasaari, Helsinki.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Mika Ranta / HS</span></p></div></div><p><span>It was</span><span> not hard to find arguments to convince the committee of 24 country representatives. The traditions of sauna bathing are repeated over and again in Finnish songs, mythology and storytelling tradition.</span></p><p><span>People were born in sauna, they have thrashed out their lives in sauna and they have washed their dearest for their last rites in sauna.</span></p><p><span>And the tradition lives very strong even nowadays: almost 90 per cent of the Finns go to sauna once a week and there are approximately 3,2 million saunas in the country.</span></p><p><span>No wonder, then, that the prestigious committee of Unesco was impressed.</span></p><p><span>In spite</span><span> of that, it was not easy to formulate the 25-page application. It was decided to give this task to the Finnish Sauna Society.</span></p><p><span>After this decision had been taken, the Ministry of Education and Culture granted financial aid for the Society to be able to recruit one person to complete the application. It became the common cause for sauna associations in various parts of the country. The draft was commented by sauna enthusiasts in Oulu, Tampere and Lappeenranta, among others.</span></p><p><span>One of the tricky questions haunting the writers of the application was how to differentiate the Finnish sauna from the Central European warmth chambers.</span></p><p><span>The solution was the sound of water thrown on the hot stones in any Finnish sauna. This sound was repeated on the video sent to Unesco.</span></p><p><span>Nudity was another challenge. The Finnish Heritage Agency gathered an international test group and read its members the first draft compiled by the Sauna Society. The result was crystal clear: it was not a worthwhile idea to use the word naked at all in the final application text.</span></p><p><span>â€�Nudity in the sauna is, of course, natural for the Finns. Internationally, itâ€™s a different storyâ€�, Ms. Ohmeroluoma says.</span></p><p><span>â€�So we wrote that the Finns go to sauna without clothing.â€�</span></p><p><span>Naked </span><span>skin was censured heavily also from the photos added to the application. One cannot see breasts or buttocks neither in the photos nor in the video, not to mention genitals. Naked children are nowhere to be seen.</span></p><p><span>Ms Ohmeroluoma believes that without assistance the heritage list would have remained a pipe dream.</span></p><p><span>â€�The help was irreplaceable. We were not able to consider all the nuances and without outside help the application would certainly have been turned down.â€�</span></p><p><span>The preparation</span><span> of the application took ten months, and in the last days work lasted late into the night. Still in the final stages one photo deemed too daring was replaced with one Ms. Ohmeroluoma digged from her cellphone.</span></p><p><span>It is a picture of her own favorite sauna: the home beach sauna on the shores of Lake Saimaa.</span></p><p><span>The Finnish sauna is not the first sauna-connected item on the Unesco heritage list. Estonia gained the recognition for the smoke sauna tradition of VÃµrumaa already in 2013. At that time somewhat bitter comments like â€�stealing the saunaâ€� were heard in Finland.</span></p><p><span>Senior Specialist </span><a href="https://www.hs.fi/haku/?query=Leena%20Marsio">Leena Marsio</a><span> from the Finnish Heritage Agency thinks that the success of the neighbor does not hurt Finland. â€�This list is different from Unescoâ€™s World Heritage List. Intangible list makes peopleâ€™s, communitiesâ€™ or groupsâ€™ different cultural heritage visible. The list can include, say, many different puppet theatres. Also these different sauna bathing traditions differ from each other in a fine way. The Estonians have listed the smoke sauna tradition of one region, we have the whole sauna bathing cultureâ€�, she says.</span></p><p><span>â€�People go to saunas elsewhere in the world, as well, but based on numbers, no other nation can rival the Finnish sauna madness. People here eat, sleep and go to saunas.â€�</span></p><p><span>Before the latest decisions Unesco had listed 549 intangible culture heritage items from 127 countries. Now there are about 50 listed items more.</span></p><p><span>Ms. Marsio </span><span>has been involved with the Finnish sauna application from the start. Now sheâ€™s going to put her energy to the next Finnish heritage items to be offered to the list.</span></p><p><span>The first deals with the violin playing tradition from Kaustinen and Finland is also participating in the application concerning the Nordic clinker-built boat. The decisions are expected in one year.</span></p><p><span>Before that itâ€™s time to reap the benefits from the fresh accomplishment. As part of the application the sauna community had defined a whole host of protective measures to support the vitality of sauna traditions.</span></p><p><span>To support these measures, a special organization called Saunarinki was formed. It is an open network for everybody active on this field. The Finnish Heritage Agency has granted the Finnish Sauna Society financial assistance to start the operations.</span></p><p><span>â€�The purpose is to use this network to consider, how the sauna heritage can be promoted. It can mean organizing events and information activitiesâ€�, Ms. Marsio thinks.</span></p><p><span>The Finnish Heritage Agency is also preparing the protection of three public saunas based on special law. These are Kotiharju sauna and Arla sauna in Helsinki and Rajaportti sauna in Tampere.</span></p><p><span>Thought is also given to utilizing the Unesco recognition in marketing. â€�There will undoubtedly be tourism-related benefits. Sauna and lÃ¶yly (throwing water on hot stones) are the only Finnish words known the world over and this strengthens our reputation as the land of saunaâ€�, Ms. Marsio says.</span></p><p><span>Ms. Ohmeroluoma</span><span> from the Sauna Society has plans to celebrate the success of the project in a natural way: by going to sauna. She tells how her own sauna journey got under way in public saunas in the city of Mikkeli in early 1950s.</span></p><p><span>â€�Pretty quickly it became a ritual for me and that ritual has continued for the rest of my lifeâ€�, she says.</span></p><p><span>Memories of childhood sauna visits in the village of Lievestuore have stayed vivid in her mind. Her dad, an inventive person, had installed loudspeakers in the sauna.</span></p><p><span>â€�And there we went, to the sauna, and listened to </span><span>Lauantain toivotut</span><span> (the popular radio show playing the tunes wished by the listeners). And drank juice and ate sausages.â€�</span></p><p><span>The text was translated from Finnish to English by Jyri Raivio. Tuomas Niskakangas also assisted in the process.</span></p><div><div><p>The man was washed in Arla sauna in 1993.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Christian Westerback / HS</span></p></div></div><div><div><p>Mika Leskinen washes the back of his 6-year-old son Viimo. In 2006, the duo said that they visit public saunas 1â€“3 times a week. â€�This is such an oasisâ€�, said Mika Leskinen in Arla sauna.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Petri Krook</span></p></div></div><div><div><p>Rikhard Tupin sold tickets to Rajaportti sauna in Tampere in the summer of 2006.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Reijo Hietanen</span></p></div></div><div><div><p>Rajaportti sauna in Tampere.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Reijo Hietanen</span></p></div></div><div><div><p>Suvi Koskenmaa, Riikka MÃ¤kinen, Sanna Nikula, Mila Nirhamo and Suvi Oja-Heiniemi celebrating bachelorette parties at Kotiharju sauna in summer 2008.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Juhani Niiranen / HS</span></p></div></div><div><div><p>Peter Schild cooled down outside Kotiharju sauna on November 2014.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Markus Jokela / HS</span></p></div></div><div><div><p>Kotiharju sauna on January 2018.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Sami Kero / HS</span></p></div></div><div><div><p>Utopia Chamber Choir tested the acoustics of the Kotiharju sauna in 2010.<span>Â­</span><span>Kuva:Â&nbsp;<!-- -->Petri Krook</span></p></div></div></section></div>]]>
            </description>
            <link>https://www.hs.fi/kulttuuri/art-2000007688939.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456521</guid>
            <pubDate>Thu, 17 Dec 2020 15:40:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sony’s Crunchyroll purchase puts anime at the core of its streaming play]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25456380">thread link</a>) | @donohoe
<br/>
December 17, 2020 | https://restofworld.org/2020/sony-comes-home-to-anime/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/sony-comes-home-to-anime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Three years ago, I asked Kun Gao, a co-founder and former CEO of anime site Crunchyroll, whether he thought the medium on which his company relied would ever go mainstream. We were sitting in what were then Crunchyroll’s headquarters on the seventh floor of the sprawling Westfield Mall building in San Francisco — a space once occupied by Microsoft. He smiled. “It’s still niche,” he said. “But it’s a pretty big niche.”</p>



<p>Last week, Sony took a big bite into that niche by <a href="https://www.ft.com/content/ec7f2580-8098-44cf-aa47-626613ab64de">purchasing Crunchyroll</a> from American telecoms giant AT&amp;T’s WarnerMedia for a cool $1.2 billion. The deal puts the company Gao co-founded 14 years ago with five other computer engineering grads (and self-professed “nerds”) from the University of California, Berkeley, at the very center of Sony’s push to become a direct-to-consumer player, joining the fray with behemoths Netflix, Amazon, and Disney. Entertainment, and anime in particular, will be its cornerstone.</p>



<p>To industry observers, Sony’s purchase, while likely overpriced according to some, is hardly surprising. Over the past five years, the company has been on an international anime buying-spree, acquiring distributor-streamers Wakanim (France), Madman Anime (Australia and New Zealand), Manga Entertainment (U.K.), and Funimation (U.S.), the last of which was Crunchyroll’s only direct competitor in the States (the two forged a 2016 partnership before Sony swallowed both) and a comparative steal at only $150 million.&nbsp;</p>



<p>Still, one of the surprises of the Crunchyroll deal is that it has taken Sony so long to invest heavily in a lucrative entertainment business in its own backyard. Eighty-seven percent of Japan’s anime studios are in Tokyo, most of them a short train ride across town from Sony’s world headquarters. Yet the company’s anime ventures until now have been timid.&nbsp;</p>



<p>Back in 1995, Sony Music Entertainment Japan established its own anime-management subsidiary, Aniplex, which, 10 years later, spawned the anime studio A-1 Pictures. While amply funded, A-1 has so far seen only limited success, primarily with its series “Sword Art Online.”</p>



<p>Japanese companies rarely appreciate the appeal of Japanese culture. Even the mighty Pokémon franchise was sold for a fraction of its eventual worth <a href="https://www.wsj.com/articles/SB934753154504300864">when it was first licensed through a contract that handed all subsidiary rights to its U.S. distributor</a>. A “Galapagos syndrome” mentality, in which Japanese products tend to be developed in isolation, and either fail in international markets, or are never taken overseas, combined with the country’s notoriously risk-averse business culture can make foreign markets seem both alien and daunting.</p>



<p>With Crunchyroll in its grip and a newly branded in-house umbrella company, a joint venture between Funimation and Aniplex called Funimation Group, Sony is taking a bundled approach to anime’s “big niche.” But the sudden billion-dollar buy also looks a little desperate — a proverbial Hail Mary play late in the game with the clock ticking.</p>



<p>Tokyo-based consultant Larry Mahl, a former executive at both Sony Pictures Entertainment and Warner Home Entertainment, points out that as 2020 wound down, Sony was the only major media player without a seat at the streaming table. In a roughly one-year span, Disney had launched Disney Plus (and now owns Hulu), Warner HBO Max, Apple its Apple TV+ product, and NBCUniversal the Peacock platform. ViacomCBS announced in September that it would stream all of its content on Paramount+ in early 2021.</p>



<p>“In the VOD  era, you need a distribution arm,” says Mahl, “or you’re out of the game.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/The-God-of-Highschool_2x3-40x60.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/The-God-of-Highschool_2x3-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/The-God-of-Highschool_2x3-400x600.png 400w, https://restofworld.org/wp-content/uploads/2020/12/The-God-of-Highschool_2x3-600x900.png 600w, https://restofworld.org/wp-content/uploads/2020/12/The-God-of-Highschool_2x3-1000x1500.png 1000w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Crunchyroll</span>
			</figcaption>
		</figure>


<p>The world’s legacy media creators have been falling over themselves in a musical chairs–like scramble to a tune played primarily by Netflix and Amazon Prime — both of which have invested heavily in anime, with Netflix single-handedly transforming the Japanese industry through bidding wars and price bubbles. This October, Netflix entered into four more partnerships with major studios, including veterans Production I.G and Mappa, to raise its <a href="https://www.crunchyroll.com/en-gb/anime-news/2020/10/26-1/netflix-reveals-upcoming-slate-of-anime-titles-for-2021">total to nine</a>, and it has announced a slate of 16 new anime productions for release next year.&nbsp;</p>



<p>Studios that only a few years ago were paid $150,000 to $300,000 to make an episode for an anime series are now routinely commanding $800,000 to $1 million for the same work.</p>



<p>But Covid-19 caused a spike in demand for online anime content that even the rosiest industry forecasts didn’t predict. The shuttering of live-action sets, combined with a stuck-at-home audience desperate for fantasy escapes, has meant that animation, with its low budget, safe-to-make product and unmasked characters, is now the go-to alternative for both producers and viewers.&nbsp;</p>



<p>And not just in Japan. Los Angeles–based animation producer, writer, and consultant Eric Calderon, who oversaw the development of the transcultural joint-venture 2007 anime series “Afro Samurai,” whose main character was voiced by Samuel L. Jackson, says that the number of inquiries he received from U.S. entertainment executives skyrocketed this year.&nbsp;</p>



<p>“People from the live-action world who have never made and know nothing about animation have called me asking about prices,” Calderon says. “The animation medium has been growing in audience acceptance for years, but the pandemic really accelerated interest on the creative side.”</p>



<p>Netflix has reported that the number of households worldwide watching at least one anime title in the year leading up to September 2020 grew by 50% to more than 100 million, and <a href="https://interaksyon.philstar.com/hobbies-interests/2020/10/29/179486/list-of-all-the-anime-series-that-will-drop-on-netflix-soon/">anime products are now among its top 10 titles in almost 100 countries</a>.</p>



<p>For the single-product, anime-dedicated Crunchyroll, it took 10 years to hit the one-million-subscriber mark, in 2016, and two more to hit two million. But in 2020, Crunchyroll surpassed 3.5 million before the year was half over. Today, the company boasts nearly 90 million users and more than 800 employees based in Los Angeles, Tokyo, Paris, Lausanne, Chisinau and Berlin.&nbsp;</p>



<p>“We have experienced a noticeable uptick in users and engagement throughout the pandemic,” says Joellen Ferrer, Crunchyroll’s vice president of communications. “We’re fortunate to be in this business this year.”</p>



<p>Before Covid-19 gave it a boost, anime hadn’t exactly struggled for attention as a global IP. Japanese media titles today account for 11 of the 25 <a href="https://www.titlemax.com/discovery-center/money-finance/the-25-highest-grossing-media-franchises-of-all-time/">highest-grossing media franchises in the world</a>, a list that includes “Star Wars” and “James Bond,” with “Pokémon” and “Hello Kitty” in the top two slots. Those Japanese titles are the only ones from a non-English-speaking country on the list.&nbsp;</p>



<p>It may have been another surprise hit that pushed Sony into buying Crunchyroll and finally embracing its homegrown medium of anime: “Demon Slayer” (<em>Kimetsu no Yaiba</em>). The anime feature film, co-produced by Sony’s Aniplex arm, manga publisher Shueisha, and anime studio Ufotable, opened in October in Japanese cinemas to a record $44 million, making it the biggest theatrical release in the world that weekend.&nbsp;</p>



<p>At the time of writing, “Demon Slayer” had grossed more than $310 million worldwide. It is on its way to becoming the highest-grossing film ever in Japan, surpassing <em>Titanic</em> and the Academy Award–winning Hayao Miyazaki classic <em>Spirited Away</em>. It is also 2020’s highest-grossing film, something Sony can’t ignore.</p>



<p>Netflix’s chief producer of anime, Taiki Sakurai, a former creator of scripts for veteran studio Production I.G, tells me he welcomes the competition from Crunchyroll. No one should dominate the market, he says, and having more players involved, and thus more creative and financial opportunities, will help the industry grow. Covid-19 will continue to drive demand for subscription video on demand shows.</p>



<p>“Anime’s like sushi,” Sakurai said. “When I was a Japanese kid growing up in the U.K. 40 years ago, there were no sushi restaurants, and everyone thought it was gross: <em>raw fish on fermented rice?</em> But now, you can buy sushi everywhere. It may not be authentically Japanese, but who cares? It’s still sushi, and anime will always be anime.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/sony-comes-home-to-anime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456380</guid>
            <pubDate>Thu, 17 Dec 2020 15:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl Supports NASA]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25456369">thread link</a>) | @ddevault
<br/>
December 17, 2020 | https://daniel.haxx.se/blog/2020/12/17/curl-supports-nasa/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/17/curl-supports-nasa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Not everyone understands how open source is made. I received the following email from NASA a while ago.</p>



<h2>Subject: Curl Country of Origin and NDAA Compliance</h2>



<blockquote><p>Hello, my name is [deleted] and I am a Supply Chain Risk Management Analyst at NASA. As such, I ensure that all NASA acquisitions of Covered Articles comply with Section 208 of the Further Consolidated Appropriations Act, 2020, Public Law 116-94, enacted December 20, 2019. To do so, the Country of Origin (CoO) information must be obtained from the company that develops, produces, manufactures, or assembles the product(s). To do so, please provide an email response or a formal document (a PDF on company letterhead is preferred, but a simple statement is sufficient) specifically identifying the country, or countries, in which Curl <strong>is developed and maintained</strong></p></blockquote>



<blockquote><p>If the country of origin is outside the United States, please provide any information you may have stating that testing is performed in the United States prior to supplying products to customers. Additionally, if available, please identify all authorized resellers of the product in question.</p></blockquote>



<blockquote><p>Lastly, please confirm that Curl <strong>is not developed by, contain components developed by</strong>, or receive substantial influence from entities prohibited by Section 889 of the 2019 NDAA. These entities include the following companies and any of their subsidiaries or affiliates:</p></blockquote>



<blockquote><p>Hytera Communications Corporation<br>Huawei Technologies Company<br>ZTE Corporation<br>Dahua Technology Company<br>Hangzhou Hikvision Digital Technology Company</p><p>Finally, we have a time frame of 5 days for a response.<br>Thank you,</p></blockquote>



<h2>My answer</h2>



<p>Okay, I first considered going with strong sarcasm in my reply due to the complete lack of understanding, and the implied threat in that last line. What would happen if I wouldn’t respond in time?</p>



<p>Then it struck me that this could be my chance to once and for all get a confirmation if curl is already actually used in space or not. So I went with informative and a friendly tone.</p>



<blockquote><p>Hi [name],</p><p>I will answer to these questions below to the best of my ability, and maybe you can answer something for me?</p></blockquote>



<blockquote><p>curl (https://curl.se) is an open source project that creates two products, curl the command line tool and libcurl the library. I am the founder, lead developer and core maintainer of the project. To this date, I have done about 57% of the 26,000 changes in the source code repository. The remaining 43% have been done by 841 different volunteers and contributors from all over the world. Their names can be extracted from our git repository: https://github.com/curl/curl</p></blockquote>



<blockquote><p>You can also see that I own most, but not all, copyrights in the project.</p></blockquote>



<blockquote><p>I am a citizen of Sweden and I’ve been a citizen of Sweden during the entire time I’ve done all and any work on curl. The remaining 841 co-authors are from all over the world, but primarily from western European countries and the US. You could probably say that we live primarily “on the Internet” and not in any particular country.</p></blockquote>



<blockquote><p>We don’t have resellers. I work for an American company (wolfSSL) where we do curl support for customers world-wide.</p></blockquote>



<blockquote><p>Our testing is done universally and is not bound to any specific country or region. We test our code substantially before release.</p></blockquote>



<blockquote><p>Me knowingly, we do not have any components or code authored by people at any of the mentioned companies.</p></blockquote>



<blockquote><p>So finally my question: can you tell me anything about where or for what you use curl? Is it used in anything in space?</p></blockquote>



<blockquote><p>Regards,<br>Daniel</p></blockquote>



<h2>Used in space?</h2>



<p>Of course my attempt was completely in vain and the answer back was very brief and it just said…</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/12/NASA_logo.png" alt="" width="399" height="334"></figure></div>



<h5>“We are using curl to support NASA’s mission and vision.”</h5>



<h2>Credits</h2>



<p>Space ship image by <a href="https://pixabay.com/users/eliassch-3372715/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2057420">Elias Sch.</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2057420">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/17/curl-supports-nasa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456369</guid>
            <pubDate>Thu, 17 Dec 2020 15:25:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cats Make Your Life Better, According to Science]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25456357">thread link</a>) | @KaiserSanchez
<br/>
December 17, 2020 | https://www.gethuan.com/how-cats-make-your-life-better/ | <a href="https://web.archive.org/web/*/https://www.gethuan.com/how-cats-make-your-life-better/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="154261b3" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>Cats rule, and dogs drool. And before you come at me, dog owners, I’m sorry — it’s just a fact.</p>



<p>OK, OK. There’s no reason to argue about which pets are the best, because we already know there are <em>so many</em>&nbsp;benefits to having <em>any</em>&nbsp;kind of animal in your life (and we already know that cats win).</p>



<p>The truth is that all pet owners know that their furry (or feathery or scaly or what have you) friends only make their lives better. But cat owners have science on their side.</p>



<p>That’s right —&nbsp;owning a cat is so good for you, there are actual, proven, scientific benefits. Ready to see exactly how your purry, biscuit-making buddy has been improving your life? Here’s what science has to say about the subject.</p>



<h2>The Scientific Benefits of Being a Cat Owner</h2>



<figure><img width="1024" height="548" src="https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science.jpg" alt="The Scientific Benefits of Being a Cat Owner" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-324x173.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-416x223.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-300x161.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-768x411.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-60x32.jpg 60w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20548'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-324x173.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-416x223.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-300x161.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-768x411.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-60x32.jpg 60w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science.jpg"></figure>



<p>Anywhere between 10 and 30 percent of people call themselves “<a href="https://www.gethuan.com/3-surprising-ways-cats-love-their-owners/"><u>cat people</u></a>.” Not dog people. Not equal-opportunity lovers of all animals. Just cat people.</p>



<p>And naturally, some scientists were a little confused by that. After all, cats seem <a href="https://www.gethuan.com/3-reasons-why-cats-run-away-and-what-you-can-do/"><u>generally ungrateful for our love and affection</u></a>. They can go from enjoying a belly rub to digging sharp claws and teeth into your skin without any warning whatsoever. And then there’s all the barfing —&nbsp;seriously, what makes cats throw up so much?</p>



<p>In other words, scientists wondered what makes people love these little animals that can be <a href="https://www.gethuan.com/lost-indoor-cat-behavior/"><u>emotionally volatile</u></a>, messy, and don’t seem to appreciate a single thing their human subjects do for them.</p>



<p>And those scientists actually found out more than they bargained for. It turns out there are <em>a ton</em>&nbsp;of ways cats make our lives better. They make us happier. They make us healthier. And it’s all been proven (or at least supported) by science.</p>



<h3>Cats Can Help You Sleep Better</h3>



<figure><img width="1024" height="680" src="https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep.jpg" alt="Cats Can Help You Sleep Better" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-416x276.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-300x199.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-768x510.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-60x40.jpg 60w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20680'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-416x276.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-300x199.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-768x510.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-60x40.jpg 60w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep.jpg"></figure>



<p>Most people don’t associate cats with good sleep.</p>



<p>They have a bad rap for waking their owners up at the crack of dawn for breakfast, or making noise all night with their nocturnal antics. But science actually shows that sharing your sleeping space with a cat (especially one that cuddles and purrs) can help you get better sleep. <a href="https://www.mayoclinicproceedings.org/article/S0025-6196(15)00674-6/fulltext" target="_blank" rel="noreferrer noopener"><u>In one study</u></a>, 41 percent of people reported sleeping better with their pets by their side.</p>



<h3>Cats Can Calm You Down</h3>



<p>One thing you probably never expected your cat to be is an instant anti-anxiety tool. But that’s exactly what cats can be, according to science.</p>



<p><a href="https://doi.org/10.2752/089279399787000237" target="_blank" rel="noreferrer noopener"><u>Studies have shown</u></a>&nbsp;that because cats appear less dependent on their humans than other types of pets, we tend to see them as a strongly calming presence in our lives. Cat owners <a href="https://static1.squarespace.com/static/5aa6be7de17ba3f559d28f25/t/5aa85bc7e2c4839970ff3190/1520982983501/pet_paper.pdf" target="_blank" rel="noreferrer noopener"><u>have been shown</u></a>&nbsp;to have lower blood pressure and resting heart rates, and in one study, were more likely to be able to respond to challenges without feeling threatened or overwhelmed.</p>



<h3>Cats Can Improve Your Mental Health</h3>



<p>Want to be happier overall? You need a cat, according to science.</p>



<p><a href="https://doi.org/10.2752/089279393787002385" target="_blank" rel="noreferrer noopener"><u>An Australian study</u></a>&nbsp;showed that cat owners largely were more psychologically healthy than people without pets. The people who owned cats reported being more happy, more confident, and less nervous.</p>



<p><a href="https://www.researchgate.net/profile/Gerulf_Rieger/publication/50911102_Spouses_and_cats_and_their_effects_on_human_mood/links/00b7d5326dc2cf12c8000000/Spouses-and-cats-and-their-effects-on-human-mood.pdf" target="_blank" rel="noreferrer noopener"><u>Another study</u></a>&nbsp;showed that people with cats reported fewer negative emotions than people without cats. They reported being in a bad mood less often than even people with other kinds of pets.</p>



<h3>Cats Can Reduce Loneliness</h3>



<figure><img width="1024" height="1002" src="https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science.jpg" alt="Cats Can Reduce Loneliness" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-324x317.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-416x407.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-300x293.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-768x751.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-60x59.jpg 60w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%201002'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-324x317.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-416x407.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-300x293.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-768x751.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-60x59.jpg 60w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science.jpg"></figure>



<p>Who needs humans for company? Pets can make great companions, and science shows they reduce loneliness and feelings of seclusion in their owners.</p>



<p>Besides the obvious benefits —&nbsp;when you’re lonely, you can play with, talk to, or cuddle with your cat —&nbsp;<a href="https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/12764/Marsa_Sambola_2017_Quality_AHD_AAM.pdf?sequence=1" target="_blank" rel="noreferrer noopener"><u>one study</u></a>&nbsp;showed that owning a cat made kids feel less sad and lonely, and made them better enjoy time spent alone, compared to kids who didn’t have cats. We’re sure those benefits extend to grown-ups, too.</p>



<h3>Cats Can Help You Make Friends</h3>



<p>There’s a stereotype that “crazy cat ladies” are socially awkward, but according to science, that’s very far from the truth.</p>



<p>Multiple studies have shown that cat owners are <a href="http://psycnet.apa.org/record/1983-32714-001" target="_blank" rel="noreferrer noopener"><u>more socially sensitive</u></a>, <a href="http://psycnet.apa.org/record/1983-32714-001"><u>trust people more</u></a>, and <a href="https://www.tandfonline.com/doi/abs/10.1080/08927936.1998.11425085" target="_blank" rel="noreferrer noopener"><u>like people more</u></a>&nbsp;than non-pet owners. <a href="https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/12764/Marsa_Sambola_2017_Quality_AHD_AAM.pdf?sequence=1" target="_blank" rel="noreferrer noopener"><u>Yet another study</u></a>&nbsp;showed that kids who had cats as pets were better at communicating with their human friends.</p>



<p>“Pets appear to act as ‘social catalysts,’ inducing social contact between people,” that study’s author wrote. “A pet can be accepting, openly affectionate, consistent, loyal, and honest, characteristics that can fulfill a person’s basic need to feel a sense of self-worth and loved.”</p>



<h3>Cats Can Entertain You For Hours</h3>



<figure><img width="1024" height="680" src="https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science.jpg" alt="Cats Can Entertain You For Hours" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-416x276.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-300x199.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-768x510.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-60x40.jpg 60w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20680'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-416x276.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-300x199.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-768x510.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-60x40.jpg 60w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science.jpg"></figure>



<p>Anyone who’s ever played with an energetic cat knows just how entertaining they can be.</p>



<p>Cats are natural-born hunters with fierce prey drives, and that means that a ball, a feather, or a piece of string can have them jumping, pouncing, and chasing for hours. Most cats are perfectly content to play by themselves with any object that can be batted across the floor, giving their humans plenty to watch and laugh at.</p>



<h3>Cats Can Encourage You to Get Up and Play</h3>



<p>What’s even better about how playful our feline friends can be is that they encourage their owners to get up and play, too. Sure, you’re probably not going to get as much aerobic exercise with a cat as you would with a dog. But running around the house with a toy on a string, even for just 10 or 15 minutes a day, can provide more exercise benefits than you might think.</p>



<h3>Cats Can Encourage You to Rest and Take Naps</h3>



<p>On the other hand, sometimes the best way to practice some good, old-fashioned self care is to take a nap. Studies have shown that most house cats sleep around 16 hours a day, so if you need some encouragement to slow down and get some shuteye, just look to your cat, an expert at cat naps who would love to take a snooze with you at any time of the day.</p>



<h3>Cats Have Lower Carbon Footprints Than Dogs</h3>



<p>Just another benefit to choosing a cat over a dog: It’s better for the earth. A <a href="https://www.seattletimes.com/seattle-news/dogs-eco-footprint-a-hummer-study-says/" target="_blank" rel="noreferrer noopener"><u>2009 study</u></a>&nbsp;found that the carbon footprint of owning a dog was about the equivalent of driving a Hummer. On the other hand, owning a cat was like owning a Volkswagen with reduced carbon emissions. Neither pet is perfect, but cats are contributing less to climate change than dogs.</p>



<h3>Cats Can Fight Depression</h3>



<figure><img width="1024" height="630" src="https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science.jpg" alt="Cats Can Fight Depression" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science-324x199.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science-416x256.jpg 416w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20630'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science-324x199.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science-416x256.jpg 416w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science.jpg"></figure>



<p>Now for the actual medical benefits of cat ownership — and there are a lot of them. It turns out that owning a cat is exceptionally good for your overall health, both mental and physical.</p>



<p>First up: Mental health. Because they tend to increase happiness and decrease feelings of loneliness and isolation, studies have shown that cats can help alleviate some of the symptoms of clinical depression, since they’re exacerbated by those things.</p>



<h3>Cats Can Lower Your Blood Pressure</h3>



<p>Aside from their mental health benefits, cats can have a positive effect on our physical health, too.</p>



<p>Studies have shown that cat owners have lower blood pressure on average, and that stroking a cat can release hormones that tell our bodies to calm down, lower their heart rates, and lower blood pressure even more. As an added bonus, most cats find stroking to be calming and enjoyable, too.</p>



<h3>Cats Can Reduce Your Risk of a Stroke</h3>



<p>Studies have shown that people who own cats have greatly reduced risk of cardiovascular diseases, including heart attacks and strokes.</p>



<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3317329/" target="_blank" rel="noreferrer noopener"><u>A 2009 study</u></a>&nbsp;showed that people who currently own cats are at far less risk of cardiovascular problems, and that even people who owned cats in the past but don’t any longer have less risk of these kinds of diseases. The scientists who worked on that study attributed their subjects’ better health to the fact that cats reduce stress and blood pressure, putting less strain on the cardiovascular system over a lifetime and allowing it to stay healthy long term.</p>



<h3>Cats Can Lower Your Cholesterol and Triglycerides</h3>



<p>That same 2009 study showed yet another surprising cardiovascular benefit to having a cat as a pet: They lower your cholesterol and triglycerides. In fact, researchers found that in some cases, getting a cat was more effective at bringing patients’ high cholesterol into a normal range than using medication meant to lower cholesterol.</p>



<p>Scientists aren’t exactly sure why cats have this particular benefit for their owners, but there’s no question that owning a cat has positive effects on your overall health.</p>



<h3>Cats Can Help Heal Bone and Muscle Injuries</h3>



<p>If you ever injure a bone or muscle or suffer from a minor wound, add this surprising step to your treatment plan: Cuddling with a cat.</p>



<p>Cats purr at a frequency between 20 and 140 Hz, which <a href="https://www.scientificamerican.com/article/why-do-cats-purr/" target="_blank" rel="noreferrer noopener"><u>studies have shown</u></a>&nbsp;can help promote better bone density and help minor injuries heal faster. In other words, your cat’s purr has literal healing powers.</p>



<h3>Cats Can Help You Fight Off Allergies and Asthma</h3>



<p>Well, cats unfortunately can’t do much for your existing allergies. But if you want your children to avoid them, get a cat.</p>



<p>In 2002, the National Institutes of Health released a study that showed that kids who were exposed to cats regularly when they were under a year old were less likely to suffer from all kinds of allergies —&nbsp;in addition to pet dander, those kids were less likely to have dust mite, ragweed, grass, and other allergies.</p>



<h3>Cats Can Help You Live Longer</h3>



<figure><img width="1024" height="680" src="https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science.jpg" alt="Cats Can Help You Live Longer" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science-416x276.jpg 416w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20680'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science-416x276.jpg 416w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science.jpg"></figure>



<p>With all those health benefits, it’s no wonder that cat owners live longer than those who don’t have feline friends in their lives. That just means you have plenty of time to continue to enjoy all the benefits of being a cat lover.</p>



<h3>Can’t Have a Cat? Even Just Watching Cat Videos Can Be Good for You</h3>



<p>Not everyone can have a cat —&nbsp;we understand what a serious commitment any pet is, and why it’s not for everyone.</p>



<p>But if you’d like to reap some of the benefits of having a cat in your life, even if you’re not up for the task of caring for one, just queue up some cat videos online. A <a href="https://www.goodnet.org/articles/7-scientifically-proven-health-benefits-being-cat-owner" target="_blank" rel="noreferrer noopener"><u>2015 study</u></a>&nbsp;from the University of Indiana showed that watching cat videos gave people an instant mood and energy boost, and decreased their negative feelings throughout the day.</p>



<p>Now that you know all the scientific …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gethuan.com/how-cats-make-your-life-better/">https://www.gethuan.com/how-cats-make-your-life-better/</a></em></p>]]>
            </description>
            <link>https://www.gethuan.com/how-cats-make-your-life-better/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456357</guid>
            <pubDate>Thu, 17 Dec 2020 15:24:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Take on the Fortune 500 – Ranking Companies by Page Speed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25456248">thread link</a>) | @tomhanlon
<br/>
December 17, 2020 | https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/ | <a href="https://web.archive.org/web/*/https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2>The Performance 500</h2><p>Google <a href="https://developers.google.com/search/blog/2020/11/timing-for-page-experience">recently announced</a> that Page Rank changes are coming: performance metrics (Core Web Vitals like Largest Contentful Paint, Cumulative Layout Shift and First Input Delay) will soon be taken into account for prioritizing search listings.</p><p>We wanted to see how some of America's top companies —The Fortune 500— would stack up against each other when viewed in a different light: website performance. Is there a correlation between business performance and Page Speed performance? What else might we find?</p><p>Using Google’s <a href="https://developers.google.com/speed/pagespeed/insights/">PageSpeed Insights API</a> and 2020 Fortune 500 data, we compiled what we’re calling “The Performance 500”.</p><p><a href="https://docs.google.com/spreadsheets/d/17qQh1zKpa5qwNBzXcCgkVbsy-YMHV0DB_doNgktcp8M/edit?usp=sharing"><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-chart.avif" type="image/avif"><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-chart.webp" type="image/webp"><img src="https://reachlightspeed.com/img/blog/post-performance-500-chart.jpg" width="768" loading="lazy" alt="The Performance 500 (Google Sheets)"></picture></a></p><p><a href="https://docs.google.com/spreadsheets/d/17qQh1zKpa5qwNBzXcCgkVbsy-YMHV0DB_doNgktcp8M/edit?usp=sharing">The Performance 500</a></p><h3>And the Winner Is</h3><p>You’ll notice a recognizable name in first place for the Performance 500: <a href="https://www.berkshirehathaway.com/">Berkshire Hathaway</a>. Its Chairman and CEO, Warren Buffet, famous for continuing to live in the same house he purchased in 1958, bested even Google’s parent company in page speed performance using a simple HTML site with minimal resources to deliver content. Hats off to you, Warren and team.</p><h3>Other Interesting Findings</h3><ul><li>Only 4 sites out of the 500 (.8%) scored above a 90% or above on their PageSpeed Insights Performance Score</li><li>~85% (424/500) of sites have a Performance Score of less than 50</li><li>The average Performance Score is ~29</li><li>The average Largest Contentful Paint (LCP) metric is 13.5 seconds(!)</li><li>Less than half of the Fortune 500 had a Cumulative Layout Shift (CLS) Score of better than .1</li><li>Only 11 of the 500 have "Good" First Input Delay (FID) scores</li></ul><h3>Understanding Core Web Vitals (LCP, CLS &amp; FID)</h3><p>A quick reference:</p><ul><li>LCP: Largest Contentful Paint - How long does it take to render the largest element within the viewport (measured in seconds)</li><li>CLS: Cumulative Layout Shift - How often things move around as the page loads (presented as a score value)</li><li>FID: First Input Delay - How soon after a user input does the browser process the event (measured in milliseconds)</li></ul><p>We’ve included <a href="#understanding-core-web-vitals">a section below</a> that explains these in further detail in the language used on <a href="https://web.dev/">web.dev</a>.</p><h3>How We Tested</h3><p>We ran 5 tests at different times of day over a period of two weeks. Those results have been averaged into the scores presented in the table above. PageSpeed Insights never returned a Performance Score for ViacomCBS so we ranked it last.</p><h3>Ranking Methodology</h3><p>We chose to rank these companies “Performance 500” rank first by Google’s PageSpeed Insights Performance Score, then by Largest Contentful Paint (LCP), then by Cumulative Layout Shift (CLS), then First Input Delay (FID). We preferred this ranking order as FID is not assigned a weight in <a href="https://web.dev/performance-scoring/#lighthouse-6">Google’s weighting of the performance score</a>.</p><h3>Color Coding</h3><p>We chose to use the green, yellow and red labels using the same color coding scheme used by Page Speed Insights. These vary by metric and can be found in the <a href="https://developers.google.com/speed/docs/insights/v5/about#categories">PageSpeed Insights documentation</a>.</p><h3>Device Type</h3><p>We also chose to only show the mobile rankings of these sites. A prior version of this table existed with desktop scores as well but we felt it was too cluttered to meaningfully show desktop and mobile metrics in the same table.</p><h2 id="understanding-core-web-vitals">Understanding Core Web Vitals (Loading, Visual Stability, and Interactivity Metrics)</h2><p>Starting next May, as Google Search Results start to take into account Loading (Largest Contentful Paint), Interactivity (First Input Delay) and Visual Stability (Cumulative Layout Shift) metrics, sites that have not focused on improving these metrics will be penalized against sites that are faster to load. Let’s take a look at each of these categories.</p><h3>Loading: Largest Contentful Paint (LCP)</h3><p>Google's Definition: The Largest Contentful Paint (LCP) metric reports the render time of the largest image or text block visible within the viewport. <a href="https://web.dev/lcp/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-lcp-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-lcp-lg.svg" width="768" loading="lazy" alt="Largest Contentful Paint (LCP)"></picture><h3>Visual Stability: Cumulative Layout Shift (CLS)</h3><p>Google's Definition: CLS measures the sum total of all individual layout shift scores for every unexpected layout shift that occurs during the entire lifespan of the page.</p><p>A layout shift occurs any time a visible element changes its position from one rendered frame to the next. <a href="https://web.dev/cls/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-cls-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-cls-lg.svg" width="768" loading="lazy" alt="Cumulative Layout Shift (CLS)"></picture><h3>Interactivity: First Input Delay (FID)</h3><p>Google's Definition: FID measures the time from when a user first interacts with a page (i.e. when they click a link, tap on a button, or use a custom, JavaScript-powered control) to the time when the browser is actually able to begin processing event handlers in response to that interaction. <a href="https://web.dev/fid/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-fid-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-fid-lg.svg" width="768" loading="lazy" alt="First Input Delay (FID)"></picture><h2>Incentivizing A Faster Web</h2><p>We think these Page Rank changes from Google will have a positive impact, incentivizing companies to focus on improving page speed performance and ultimately the user experience.</p><p>Special thanks to Lekshmi Nair’s <a href="https://github.com/lekshmicnair/Fortune500_Financial_Analysis">repo</a> as a starter for most of the 2020 Fortune 500 company data in this table.</p></section></div>]]>
            </description>
            <link>https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456248</guid>
            <pubDate>Thu, 17 Dec 2020 15:13:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make comic book layouts in the browser]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455659">thread link</a>) | @TiredGuy
<br/>
December 17, 2020 | https://andrewfulrich.gitlab.io/panelle/ | <a href="https://web.archive.org/web/*/https://andrewfulrich.gitlab.io/panelle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://andrewfulrich.gitlab.io/panelle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455659</guid>
            <pubDate>Thu, 17 Dec 2020 14:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expert Survey on Formal Methods [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25455636">thread link</a>) | @todsacerdoti
<br/>
December 17, 2020 | http://www.fmeurope.org/documents/Garavel-terBeek-vandePol-20.pdf | <a href="https://web.archive.org/web/*/http://www.fmeurope.org/documents/Garavel-terBeek-vandePol-20.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>×Òu{	ð}�x‰MÌî»
s{·¹ýÏ¼ÐŸŸ¯0Ð/©ú\ã}‹N�@^_–ÞCOd³çÅ=ÿœÚZ:‡sÏïXýwê«áâ¦‘áÝ/À"…,hàRâÜ/â!½4fˆDÿŸáØ‡éÍnÇß
ðßwÑë!“‹aR¬£	&gt;“ËGNÔ©F8ÚóG	¼›I¦`]„BkÇu@·?xûü”?¨úuÕž*Œ&amp;Þî´d&gt;ŽÃQÁž?zîChÀ·ƒ_÷uÚ‚ë~]õCå¡Bµ'¯–Ï—é÷°ó¸Ø×Eïåg¯¼×î‘]Åãð:±'“‹™–ÓŒ?ÛYwÊd0p:/viŠ"zÿÑdÿq
Ù£’¢|*T¯ D°‡Ò)L,«Õ–í
DÉ‡¼…§Âf´JÐ¬j&nbsp;Â)&amp;x
õãúæ‡O·0ywÇ³Šu…l{�´ÕŒõLôx*ª®Í!wQè]»C˜Ú)°åÃðo›E$œ#e,x¬WíÀûàÜ�³Ø°ƒA�h¾ðT«²Ô—zÃ�žï
Ÿý‰kgÕ#Z®Þ”ó¤ã&lt;&gt;æ$7R�ÆŒ²ã	í„Qúø&gt;†gÎÎ&nbsp;:Œ8ã
Þípa‡cßÙaŠ•€&amp;×¼×(b)
†Zò-_1|É	fqQ Á”ô+1
Nl‘¤S•ç"ŒZ?¼%jÉþ;LÛ¢È©5W	³0b-<pòŒ py�;‡j�¸­�¨ÃÝ7ß)¢‚ñ{g“zpuËgv†="" #{p»a?„©'ûæÇ~Þî{^yÄkÄÂf‚="" ³_-‘·qÓÐêub8mð‚,é1'†—<}´û-xŽ="">ÒêMJ”ÛNŒÄ‹êX±šô¼Œæ…g;íPyõh2ôê¿¨Ö×€Ëª·‚"»™‹­61(Ö3:S¦³PG2[Ì ef¼�¹­*À—ÌVñ‰’RÊªçÅþl,ÜÇÅÍ"ÊË`ã_®Œ}“4
C+¹¬	~ušœê‘æS?YÒH$ÇÆ0�’»Ú+"AÛÔnƒý-®åü)ººÆÇ¹âŠ*X¦€_RÞ ÀIJéúÊØpÕi!ïî2eñ2,´•¢°T£­AôÂ`YèÄØQOd‰3ô¨,‹Ö·Ñ&lt;Ãâ«·î/5Ì‡u-ØßvèàqDŠÈCõÄ·°ÄX¼p†ø\su‹žà„wÕÞWÆÒLîVš÷è³Ës¹Ö¸Í1ýÌÒÑ¥æŽ¿÷ê²(UºÑ�tE¸ÂwÉ3„±uœààO1­LÃÔ‘„`å{2ÓVñ7Æ¢È£›\vÊþç¥B3õ¤´Ywq�Ô¦W…®/)¿‚ôú[(‘ƒ5„çZÝ`uÜßéòš…/[ÿv}¶éJÅªÚýõfŸS\}ŽAßíùÄÜ†TÙš˜uËuÊ¨ZÌ5ªV±_æ§@35Ä� ¢T´ST¼H¾¤«y29{÷‡~Ê�9´%…žÁ¸¶«»½ÞÆÊ¡ß©Ó5LNj}z{âŒV&nbsp;žeP@�P}RˆLÚTª ¯5æOÂåsPSõð©hÈ2
	’&amp;,Aîð&lt;æÔ2¶	F(£Ñ™ìÚ«XL*w
š!¡œAè&nbsp;¡X¿ãYËFßþäŠÀ™M©-èÄc¦³&lt;÷ÃýL»¶ßQ
g6ÁÂ€¾Ó~�=Ês&amp;úd{,Íè¿1Uf�%" ƒ2ÖŒÞXß„_ÓÇBœÇD/,$°˜èèP¬ÛW¨Ÿ`~‹,=AåÜ²ÉÂ”u¹èö´gÇÙp5y˜S)™Ê®¶¹ÞD|§u˜ÄÎ‘Â=Ç‹�]�%Ñ_+.� Öpg¯w†SÛŠ"w¢s,Øµ7Æ·Z�·¹úíyÒ¨fËñ7Á"Òa¢ð‚D
Ã·H� …Q-§:§&nbsp;Rëb6(w‘øWfÍ1®Ûüt
é8kýL5h �þšÂ!­_k,2­eÎK¼„\ÇoaÂIó’kõ„­Òl4Ym/ )ÊÛ1ºê æÁ’`­ý¥T£c;­llüÇK¬Ö¼sÁ(G!àÎ¡æÁî–’R3Jª&gt;Öšò¢Qœ}&nbsp;
œ~SÐàáp•AMh¬‰´{ê8Ig«†�5˜&amp;àÇIï¦ZÉÁL2tÚþœï'ý7	Ë†€¡vF”ÃZ<uø—e… rcÇ~û­—8°{ÉÌÓµÑý¶lØ%÷v–´™àuõè�&)¨`Çtä¥jª‚s8í,Ìmös”eÊÙŠh'>$³~C&gt;-pæ™Ò£ÉÉ—FcðÌ[ì!œ}°6î¶ãÝ†P½ð¤·éF°­AkÞ¥ÔmÑ]yT^ðÁùñhÕÇHÝè¿a–ÑX4“—4PHÅ
™|¿…¡@ª´NO%ø‚�Â%Êá÷œŽÓF¤qëõ—?­zä÷ÿ&nbsp;Û[^H*œñë¾–0¡£œá¾&nbsp;yI˜š"ÂöÍ¢gN`Â6<vçÛn·`xÖ•êÇ¹þùc×¦aØmÛiôãç!a,\Ì Å¡µÉ{Çá€¢="" ÒdÔlŸöfgrŽ="" …<w�noz%¸ÆjêìëÎ6ÈaãæuÎdþ¬&Ç#½r="" ��x„”ótàl¹­ly="" µgwqpôx="" éhjiwš}§›a="" ëz›òÙ%b'ù,2ÛoØÌ*“iøtƒm~‚r¬¢ê="" vÈ„á{-xš4Ïmrf“¾¯öˆ;å°@ê‰ƒ#‹²3±bô—ˆ¥Ë9—¨‹Â’nÚ¦="" k¡0›¥”µöû†6�3j¿’ÅØ›¤ÚÙ$Ñ�qŸ7z4t�iÏÑÔä®ydµÀd1Ùsu�¤üpÁ´�‹ühžÒlroa�½�bŸu©ÈÃsþˆ¡‰mbò[Ê¡ôx—ú¯ƒgÖsÆ©sž´Å'r€+Ïj²d©%‡Ëew†êooÆržêºz‚Ã÷c?éÕ’ï5�—´b="" Ùt~&%lãiËäÂãk0±¦«r¶tw…;½]íŒ,8="" oØì="" lÊ©¦Ýµ%x="9=8Ô¡é&quot;~÷äm°ËñÈžµÜO@u/§Œì²Zõ¤àž|«¢ÜL)B]àÑÎœ<ç¦B" w¡”‘„Ç?êÜ¡˜õo¡�ÜÆaÁe‚ÃèšŸi·Ô]¸ÿ?i!f:gcm4ãp&Ç”Ûj\˜«-ù(kŽ‘û+="">5†ö,øí8Ü£Ùà”òY<z–cû»×{6{Ö“±cÙrÙd¸jgªŸÔ¼Àá$Ÿ|Ñyr¡9ö,¨u(dÀqv¹x"tÆþ«=:ýø‹d1k  l&›8Œçepª5xv="" s="" ƒ�ÙÄ[ÖÁÖàØÛöÇln˜ö|åñ°¨˜(ÃÜ4¹Ð="›t!'O¡^" '.©ÃŸmµç�Í·©©="" ¦e�ãg!cÎús£Ï¯x‘n:8�m¥!yãñåu+‹¿¨Ðn¯}±i×¿�÷s�Ê¦î<ôýë@2Š‡À#�Úob~ˆ8vöß:d6égd×í^,¶æmfÃ{¬ÛlkrrñúökÙ�cûË="" ]¼ú¥È®›ŸcðÆîl�Ó_ÞÌ÷ýææz›¯Ø="" endstream="" endobj="" 12="" 0="" obj="" <<="" type="" xobject="" subtype="" form="" formtype="" 1="" ptex.filename="" (.="" orcid_color-eps-converted-to.pdf)="" ptex.pagenumber="" ptex.infodict="" 26="" r="" bbox="" [0="" 9="" 9]="" resources="" procset="" [="" pdf="" ]="" extgstate="" r8="" 27="">&gt;/Properties &lt;&lt;
/R5 28 0 R
&gt;&gt;&gt;&gt;
/Length 436
/Filter /FlateDecode
&gt;&gt;
stream
xœe“Mn1…÷:….š¤DQÚ&amp;é²‹dÓIdœ i{ÿRcQc¸À#~#==þø3"PÄñÌw?‡ÓãGÿ{~yÿsz–xÿøNÏ5þü&gt;Æš!k)ñÆªÔºÈ¶ÚçïñõWøß‚Ø»Q+ñXµLË@DJ¦ðª&amp;á˜	šè¸nªÁ"Ðs¼[Š™A¨Éé� kºb¸ÐÅ»ù4¹œR‰~À}»¨Ç=øÅNÜ˜+Ü8ïá5&lt;í¥»ãºd_/q¯É¥–5T%ŠÌPPÄÒæ­Ö´È¶ˆT&nbsp;Fy�yêrœz
©�TŽ¬À¼70+(a[dÒ �Ž8)–BnS™)Î8#dBÅp¢ ¥ä(j_j”…tÇ¹ä#îîÂÁvkkÌI²òQË‡qô&gt;Û¢ÊÛ¸6ÛÌ8(v8[Kl_åJG|øœ$‘)5Ûa³ÖRÝd	ÛÁ”Ú
û²0ÁvëiÔ,«Ú¨Xã½YNh‘­UfÇb–d•6nºâL_¯vŒÅ¡àñ¼£‡E¬´6^K&nbsp;Ú´%:®˜qË„ïp“Sà&amp;‹1¯ß¾?ØÌ&gt;…vjÎì
endstream
endobj
29 0 obj
&lt;&lt;
/Filter /FlateDecode
/Subtype /XML
/Type /Metadata
/Length 9079
&gt;&gt;
stream
xœí|Ùò£H³ßýáwèè/Âaþ¦XÄÖžéHH,‹HÀ«Øw$àÕ|áGò+¸$uOï=3&gt;çDøbè!AVVåR¿Ì,¨ÿ¯ÿ65^�GÃ?º¦ÕooÿÏÿúßoß¤áoo/¤‚*Í&amp;JRqé¢Ó¢šÁ’løößÞÿã×éÝT6e4xo¦²¨úwÓoo½°ö£wðûã2xûæI2ä¿½å7ÞØŠþfSwÑòâ_Šao(êlERö?Þà(†þ§þ…­Þ‘Ô;œ~óáxûþðükÆï~÷¡;øë··É04ï¸ßï¿Ü‰_êî
0–elpü_�â_ý\
Þô¯ªÿç‹ÉG&gt;|Ô]Úi]½yüöüz~{ûöo&gt;;&gt;ÈU6¿wTõ¿<eü%¨k0y À~aÁ="" ryýyÃ+hË+ø}`�±Ávï6]ä="" ugÖuñþ¥8©(Æ~èwßlnÔ›ÿvi«°¾÷ÿýwðuƒïñŠxøylýeþ…±&Ž¾Ãˆw+aÉwú“åw<Ìd,ýÊk‹þý’="">ÉÃ—W?Þ(Ò§b¯ë#sn¢ßÞQ_�]½ý¦Á‡ž{wOÃ!y�“ÔsXŸ]úY£$J¯Éðe«×~Ö,®»ÒÞËúVøÔîÃÅŸµKKï½lVw&lt;å®l\¹5wÝr'n-qè#×[Brvñö.ñÊ¨pÜê˜*‡&nbsp;ÜóXs�þql¹ÿúÏ‰ûŸÜñÑGn
�Çç»ÜÇå‚ÌWƒøœo^�Û5gm×Wk·¾æÂúèÈ›ûUX_¯ž«÷›{½2ä×œÂs÷ÇçÈs+}Ë1¿VÌÝúhn§»/L} NLüûç¾×÷@å9Ô�=8Bb;£~Þ{2ü‚ø/~=^×q¹ûÖx‰ÌIwT(Ú–óžÒ‹ÜCºã–ûtwÜ]&nbsp;ZÄ
—Cñà½«ÄM÷A‡ÜJõH›c}€·7°ž»7ðÔdT)ÐXŠ‡²“i:ž·Âß¦�³µ”FHÖÓe:¦úúÉÐÄD™Ü”Ùóõ¶-Ž‹aæí~v}£ZÇ*§´EMBËM%I®y“\ÝD†ªkOèyPÏûu7¯€¾}2Ä4uíË®ð.ØÚ{qñ¤ñÊ¡÷/äÍ!,¬ÂUd7t,bHLhÛÄñÄT*÷éjV³Ùääé\4‘SºO†­_ÉxT‘û¬Ù_Ê†J›¶ûÎ£nµõÅ—øõºËÑÙn&nbsp;Cø�%[~½Ùžk»³5‘®îtu·ó“aí‹÷�"«“ºÙ�å4¸m™7økâ�¬ù’:ôa³&amp;ô“ÉÛëZùýúYÎÜ��†y¸³¦Õ–û|mžQD_ù”Ši‘ºQ„ÎåÜøö‹lÌ(Ü2¬½KÓù6úø‰ÿdˆð…|¹dê–ÍT.ç­–7žWµû²m©yèZä&lt;èhüÃ#¶ãŽµV-½³�ÏOO†¯Ÿç=9Ò,c/dy”x8);qEÚÅrœR27Äòš¯³zrÉ×áxêÅÖöÓá«Õ™¦�¯
:¾f
ž&nbsp;ŒZ
�b.W	ÄÕÚ“Ptþt&lt;¬†‹q»!Û8)ë%BGÏF�L¤ã‰){r.vyc8%XIŸc–M0÷†›C|6ÉE¿ãÙi'ƒª7¦Åž
p;Œ.Ý%@§9Á`ÅRH`ÛGRäðÀdBÖ¬'Ã¼ö¦³�Þhj_5ö¶÷\`»QeÖÁ�U•XHÙªékœ`ÐÈñc„¾‘­mÌ˜¤[8¦š|¡Ù�°ù“¡’'˜yA�bÛÒ(U§ýÊŠ=Ùª'¤8­Áçw´A¥:(·¡YSqapÎW(fôÂ\ó¡Ô¡[KW„Ê^:d%v�Ðroc4†H�Þ_Wâ9³/	Šé42+ñöl�­^6ˆŸ"âÏ«þÎn“.žÌ1¹]žæðÉ0íúsøgN-‡Ù¶
�©W‘¹¤6wˆð–×ÄÂcÑmrÖÁòdh˜3—ëÅ1[‚L	†uX-Ûu"¸a”.Å52ßVäŒwlÍäl\­	fAjM?hæìt.á©¼�EäÙÃ0�€¨Å³ëšê,Ëž—ØA’~0LRŒÔ;ãïD;ê†§·Ž3KjVv+¿tˆx‹»³FaGsê¨”Ë5Z²˜áVûÑïNáÍe.èÍèl8ôÁÄ«ÃŽÁ=£¶iÎ
¤Îp=£ç´O†UM&nbsp;.vIéË�Ê1)‘#r\÷Ùã¾§óON�ÜÔŽTeè¬^~¸ƒBsœT’Y	àëNn®ø
”ÛépAr&gt;½	?•V¬‹ÐšEÙú›	@	êºB"¸·žçEç'ÃÆ­¼Óy9WAQÊì�Q°H„„ŸVä~‘¾™ÿß9ÍÕ1ÖàÎ“¡O
„Çj†Nc½b @µFôå%u›§
ä¶PeUj× ÍåR_VãA³NSÕØšDKÔfi¦'C²f,Þ	Zå�ä™=üÐ
×X|ñÅSg;œÕYvÊBB¿ÖË+‡‰ŠÄ�‚&lt;®ÂÓTH†@/¼
”t
æšTØ7ÝÎoãDc8wÉ{ì‰^dZ3�g(ÄµQÔ%˜º”££}f£'ÃŸYžv”ÛlSÌ‡tÉ?£OìÙ‰x~TfUmûrcï84ž×È�WL‰ªÈÖUµè›‹GZ_N\Õêd®q»ŒÈaŽ—Ÿç
©ê�äÛœ^¼!ûžR.O† ¯=+ú¥D´3•n8qUIÀZš#B9·ªº!ýœIˆ^^¶G¦ÅÌ³OXôÐ•tœÓ±k³…ö5Íëú“ápn’,ƒ"oHW|!åt­+aú'æóÓù´‰^#$Ê“·^Äƒ�´¦&gt;ym›c±E�¹P5·B‡3³E�C—'êñègµÌéxÁ‚­KÄ®îÝ1n%ÓîšíŠ×La
µ‘?_éä¨õÔÍ£ÎÎ-$Ö”oL,°;Á),WõL!c.$�9—R"[ª	©ê5BH*ŸÞ³…Ý·È}Yº³×F‘[)4Im·7äaMfýK0FÙ¢Ì5K2ïrd·Ç]©£¼|LöF+õ/pàR™•±‘)9[é¼&nbsp;u³¡µuRÆÙ3UÎÞo¯º²Ë�&lt;ÜÊ¥6ý‡Ÿ?¿fß—Ó}n[˜þlS7m5[r)¯×ur´Û¸0u×íº{^ìF'P'ùf±q&amp;æ5ðdHË´)4‰nîk¿\1ÕVWõ§�OVìË‘w¾æ–WTËqûœÜÓF.$”kT]Ž•ñ¥ÃÅ[âÒÂ.xÖ·m4#2‹Ó$Iàž,òQŠ³[ Êzº·Ü®äŸò\7æÑÏÙuÚa`¦kuhv×z’ÞZ&gt;XBÜ÷`Î†ª]üš4ŒÃ‰�®€¬&amp;Q)�LëºÝnÏk\Ò|.Åýå°`µzkVÔ½î&gt;Ðý+.Ç¦hØ—j_]y»©6áHm4^’�x¦Ó›UéíD7&lt;¹ù¡ñÉðùÍÐ*/	¨82ì°'„‹„‰WƒX³©2¢H]$¥&lt;‘‰bÅÖH‹ãíe’\Xîä-]¯´YÐÌð^:Ôê)
bš'´P8§¨_ZóÇ.9pçîC,;žáÌ�h‰®Ú6žtÔ�õ�Ç—t$D®šZV¨óšËÕ~Ô&gt;NGÔJ²üdDíVÙ³û+vŸ
c°‡¢ïDÑìÂ£:§%Ìû‘Ø§ötwkÒÙ‘Á÷œ¿kñÚ4ÎqÏ`Ã`�S]éŠæ5£�¹pä,j•ºÆ”•Ñå©')EZŠJü¾Ÿ¿«_I—o%G�[)+½¢òƒj×
pcJCIÐ}Ò+ØíS8±ÓRÖZÐÝ“á"&gt;¤µÖ]ÙN”ÝäØŠÝÌ›ÜÙfék(ºMõŽb”Qu zw®/LX–EUB/O™&gt;Û{Z„F‹¼WnSÂr@#×m§|Ž¾&gt;%“5fŸö�ßË’&nbsp;škÙêìi·Ùðå„ê^é›¾¡Nt6»÷YØûDLæÞK‡òúd´_Ï{áˆÁ©k–
pÍÆóå´32A¯Ÿ¯;—$»Ô%›JÉû¤¥{/¯´¸Ò¬Ù=©ù «í¾Œã_‚fÖ`2
�h‡Ê—.ÀC	—©¾¢ù81©×L¡—fj²2YK½%(°ÈRºÓt—Ž™Â�¥0ÒV@BÿŸè£›Å¬:&lt;Ãb1¤&nbsp;žAcë)`:U9.•�|F[æœÄ¦$K]t1x4ÜºÉ@_]WäµcoÈâh6¨o¸óEVòU§Àà„Î6é€Z0émsÞ\öy÷™10ãz4ì¸Úb;©[Ë:(›G´Ž!›e&lt;œ|ÀÉ»0·7_™ƒ wúÆ~Pä¢Å ¿V‰gÜF·¢íŒ¨LÀm1RêŸ:ÿ¬ÙƒñKdSd†”3bØÉá†BX†
§Š!
€r@ÑßÜž÷Œ„LÙ4ƒ|]czó�lW'û[~^�âµD€ú)U\aÇÃ8/È¢º!¸&nbsp;“Ï];¡ËÅqK/ß&amp;ì&gt;¾¯TBGZOT3üü
R€[R›‘q}îâ®HËîÆ(ƒÆÑÃ{l9â&amp;;©L±:˜ÃdW·*¶—kyeÎ#]^¨Ñ……åeX=-Œ‘íI%ÍºRœ&lt;œæ�ø…ó�™ª`¯\nKHM­jÑ�¹uÚÇKÇJŽöÊ
rî«¾ÅHd¹P–À4Æw@HÁáÀ§ƒzÂ&nbsp;mébÂ†I�N?×Á•Þúü3�˜¯z9K³V€øl9²±&amp;«»éû[�Ðkö2gçì¶¤b3Ø²)b.ÉqÕœ¼s,N
Ÿ¥Q&amp;¨gp1kö^kúÒÜ¨-ÆA_³D"£ôÒ±å¬2VÇdÈÐWºí"q‹¼Žu™âÙÞé�˜êE¥ºý–�%‰Sëµ¨&gt;ç†ÿÆžÑY¡©ÕÞÎŸ{ožxÔ…¹¬ˆLºðDÝˆ&amp;Ö\áUj.Â„ˆ´¨N§qÏ½½"õVÇõÞÓÃy­fGf‡È7ŒsÓÕâ+
6Z°°WÂ!³cäº÷.Õ¾LsoçX‚&gt;9Ãzî•}‘:bf.µÆyÀI�¸‘­ÜÁ©Büdˆ¬(‚Ö,öT˜]S×#BgüŠÑÙYÜÌÀ²ÒÅ|(i¼Ê[Â‹%˜ûbž(iÓ†–÷¹ˆh·ƒVŒATÍ‹{8
¹ƒÖ»	)
JE«i4AY‰î?B"{ªG0a¤ÝçR†{�qr3�‚&gt;A˜¢iib!ÅuÝ.®Œ¦ì²;€u Ñ!Z1og¯UÛvc¹¹ÛýaŒÒà.@{óH«U“r'ÄWÌ5UeÊað‘Û(Ç…Ÿ®7é
«õuÍUáÞ¢¯˜¢ëbR&amp;"³½¤«dBæLoG™‰©®¯Ñ¤‚³óï:„S}8ôcTÄ]—@œ"e:Ùªƒ½lôdø»µz.`O¨˜£ÄIn™F6œÍÉ§ï‹‡:­Pi3Ãjì€Ø+dš•5Ñ@)i¥l/l«÷wã…ØèN"¬�×F‡rÕ£N¼8 F¸LqÉ]²¯ƒÎsf3õäÍù
�®á¬þñ*|¾räëY}ç~à$ßøódxXæ[&gt;d—²É«Ì“Þbw¢áAxÜzBM¦b£›
ž’ý�P”Õ"‘
ÂŒHxÏÂ+·!*óXÝØÄW8šÍ‘Èh‘	&nbsp;ùèá&amp;V¬r3uš§o˜fòûÍ¬«0—Si÷‚ÑÞ|ækž;Ñ�8jø+?t™mÐóg”�†Ó�b‡¤e´¼/.™&gt;O`©£q(Q×Â¸n¼xïˆªGâ¦UöËíý›*&nbsp;õ£óáFudÒ7û|�V�Ê4ë;G¼Yœ°po&lt;¦ð$Æ°e¤`Òá¦²w(!³R�]ª?T»ÕW/†ùˆ1•Ø6ÕÒÁh–«óÞ$»Ë×„Ùó&lt;æ?óXùÂ´ŸYõeåßMËpbþkÚÏ¬úyáã¯%IR7êÝH7ZÍ&amp;YÇ–“9Dv¾9ç6«:éÊÄL2tÜ›Ã‘LVÁBMl
.dt�£É=W¯õÃa&gt;F¡ºïHOÝ… žŠãQ:V¢ªãD}îyFÕ~ÆJ^ßø¹Óu‚ÿ¢ö¦4cE¾Îüˆ†ÁBÖëVQÜ­0¡gúžFR'ÉF@Ø90e&lt;$–ÉXÊ
PµØ‹_åeí-·_3…“�C îÁšåè5œçŒ‰o‡Ò‰¨wü¶‡ø³‰bGƒe†–7÷.Iã$È�€ñ¸ºØTš_¼¢ûX§ûB›$Ï^¢îHÂJÉve;‰"s¿Š5gzÃV}7ôU•�&nbsp;QêŠLÂ4ë²x%í�šfÚ=õæNd:v�LU‡Ì/†žß»ªAÄ½’¯•&nbsp;Ùúºß�9Ò"gÐ…ŠÂB¼MsO‡þ´ç$ðZfÙëõº©ÊØÓ*FÔ÷âQô	1ÐÖš*äãÂ;_,ºL²Ü†sÔ|gIæ«^Õ(ø�a@Ý|ˆU_gÏä‚&lt;¥,¤ùirñ`¿›aÜoºLØÚ7C¡’�ŒNJžãh6ùˆ°d 
aj�¿Ö±g&amp;*9Pæ«SpAˆÍ—Hí–Š™}?i±›¦å¨¾*Œ6‚˜ôiE-FAL9+ÂÉ*mø0S_KU?,V£1bÄr†¸’ÁøúQ»ÇÌç&gt;Åñ�ÚÍÙ2�ùéSO†3 •¦ªn~…¨""$Ÿ¸q»7Üö2@Uõ�ô\Ç\jàsÑIÂ¼ˆv$©Qä·vyÕ)úŒÊÀq�è`(\—¸BUàŽä…Ï^+||—ÁzAWÑ¨�’b]ÉÆ 	J0Ñ¸âÁ+�[Ñ_z.r@;j•6&amp;JÚ—ëNï{�	j+)œöæb)í£Ö+%ÖYÂ‡¤ÙOˆN‹¢£
(W¾]ˆÌ9©
'“1SZËBHÀƒ ¹÷7l'õØá�–ýdÈâÕ,R={If¾?Žóé¶a˜*¾­Ëš˜/´Am™.¦o¥[ìÌÙ¬£…­9ˆh–¯T„¡ÌbµîçJ»úU8ÍÍç’é�Ï³pÖ]œÁVYÑxU!L"Žk}}àkáý~Óœ üÌ,¯©×4d=€”È· rëæ
 j¿ ˜¯[7CŠx!\rm¥Eäðë¯}½#w€|`Ö«
ø\ÓEŸ`�u¤Ð‚÷˜š� Ý´¾~pàQÄŽñŠÐW1�k»©›]Ùx´Ëœ‚ñ•,!Gp®ZT;†é?�Wv•Ó]õÕb#ø³Ö{ûK8ïÎ&amp;kwî&gt;¥'XïØ=’á*nŠÁ}ÁWá8÷nësæ€Ó$/(T{|,'¼#DÇv¬âŸOK`4}Ø_)¬öe{´®&nbsp;*ü†ò²,C§¯Ê×s½ÂÞkÄà´uÍ O—³êrLg-s\köœrÜ¹â
uemWÓ¶9DéÔÀù§BB£Cò*|ÄÐ2XuP%­©øÁ­…â‡Jÿ#}¿’ö¿&nbsp;ô?Ò÷“áãÛÅAŽúa1		»¬lvâN‡`{9ÜòŠê-À%+}jbS,ÈŠ­ˆv%QGaMž8Œ8oÑÛéUëÑSªÁp"›&amp;ásF3w6n“ë}®0*õTíþ“ÝR&gt;(Q#S•®nN¦¬»ÏjáWyë ¶o—ñ¢ˆ–à^œ˜Ü‹9±:”.§Œ©o`.sq¿¯7³à�Òp�®	v«ºÅyr�ÍiS�íu
ú5BG;ì8;`Ž ²ƒfTÄè`5L_Oåg(/„ƒMÎ1S	Ê÷"Ø9@¤g²),¯ûsÈåæ†ü0Œÿqÿ2ìãƒ�—Ô�8‘7Ìƒò­Ž´.Ó\x¶	„ž–8,CX-n¡‹W"Û@#yœViË”Áó;~ûáQæ)‘êûÎØá‡sB8m¸dk¤{.è×Ñ‰ÛW
Ä|	cåˆ��ÝÍ.ó�3¾¦Ù
˜aEhkÚ£a‰ñª—5AG
}ÄÜæÎôôA`ÐÎú\{;.&nbsp;ö»¶Çpãì{ZZÝ£#*‚MÒSÜ¿g�\¿Ð…ÕÕíÎGxH
NS~€ûˆ�â,Ó*f�#ÆWêÆ)øÞÒÉ;„ÂôØ[ŒŠYXë3*ŸÝÚú[—Ì^x(¯k†à.«Ý·90§|UÞÜ7ß�œüH+È×RÕŠoc„#ç€bÁm&amp;ÀJ}<fÏ4Ü×ü+ûªép@˜wyäyébxŒ«�ñ”˜å?rØ_\aàÒ¾$xÕË²&’�Ç˜ Âïìlc p‰-yƒ¸#.°n×“ÁvÈÅÇÖ#½ââaÞñèf€wn;z�Õz<‹+„Ìñµ="" y1¨3ybmó$¦wöf9jlƒnÈ¬×‚;±¹óã:ô¾³ºow‹;dé‘;™g="">ÈW9Úqº&amp;Vªÿd˜ˆ(mÚÝ&amp;NÆCãØ'"­§Ò¸~EÙP›ëÉÉ¨¨�3i#,ÿPÜe¿”â—ëÏÊŠ¨AŒðé• Ûän*Ò†9XYg¤Òz�	l’†š^x¡î“%„3,dcCÛe�4H4ª_…�š,0Á£YÐ,×‘äÕ%NEt!Ýfã)ÐU!�nª„iÄ_+KŸ�œû=åß[ö
üu2&lt;}�£îÃƒzjsuÌ%!!à¤‡Ñ­„rf9b±7òkÖífËª—]Nà"G×´šúPI%60:ÎÊÒhü3ÂOð©ÀÄFl"î‚KdÍ'^=b_%…5m„jl
Ö@¿Ö¾&lt;4÷ÙÕ�–T\'ÜÂ;˜¢^d\h²Õ¹Ô²ê[)•ZIÛï¹¶Õ®’WŽkˆ‡Îì•ìQŸÝS†üzÅèÚwpócp�˜ŒÌîÝ†ØˆKEæ�V[±ÄH	ó2
Çí dR2¹ªÐÎtº�o¸çìðd¸ÕlI&amp;•eéYÉ&nbsp;¶Ÿz*(Æº“¢¶²Çµg:§ô›˜Éx`*7`è:âèåÌì²<l,ló^ðå)†ªníu=jûutc¦Åðˆ3[;¦]g·ž{êñk?]ýÙ­odiïÛ´u¿�‰4•Éãe¹¶9½$Å×ºm5Ú1Ó©# tÅõ‘Í="" "rÂbqk. äÉneÒ¼·_ü="" <r'¦�ÅËšÁc¼!ç’ÐÁáõ"y¤;„ˆ[z="" rƒ}„`îa ºo.ëÇ’À7<l8="" ¤³äc:ƒË+¹Çj,êaâ‚eÄ*Ý)Òw¥¾lf©+úä.óÖ`�Ö›ÕÃãkßîÐ�kÏÇ:j%cøu¢©q³¼f="" ã‰q="" ­Û‘qp¼ÔØåæþÝj(q7×avÍò’³Ýeu¶&tˆl="" g¯w–bÔæ9Ò="" hŸ'â!èÖ¢‡;$ºdo÷`pñxÖ¸�Ý£ƒ?¤—…öps�!@ÛÑ*&®¾ÍØ—‚^§#?ukËw†2ñþÒsô¯n¯*ÀiË¸="" 7´1mÃ="" u*nŸ±¥"Æ”‰="" 0iÂs­žsŽ="" ã`iÄô€!û½¶—¥Ûl5×îáôÙq="" +%¯5ƒãà$º="">¾çôä½¢aoí®8¸×‰ûý™¾²¥8ò…Ð&nbsp;L€+÷bÞË¥1f›‡Ê<p§e\«åÃê\xz¬ öƒc—²¸ÎÂvtÀnä÷°¤ÿ£gÞôü±�³ßŸ.†sc‡y;¶{u="">…×u’mg‰#ä3µ�t£¬¾Q8ô2[¹2Ñœá¶nhó«¢_¦¦EjYÀ™Õé¾:Vš¯öŸz9™‹IVÎu±½9GÓŸÅ:Þ	l†^7Ø=êUâÀ:düJ8=&amp;×$}ß¬äZ®’ò8ÍSÞRb»Q¤âî¹3ï¶š`œªÜúvÁà«ÓË¿{÷fÄ²XXxzhÏTqh&amp;P3&gt;©'}ØÆ‹È¬+—MØ"ôÝÌcb®Ñl÷áž&gt;ô‹	÷ÄW,VŠ¬ÕpIÕÅçävÃ;ìZZ#3q[‰ªŒø	”&amp;àÇØÃ\%DØÉ’Êø=cµ;Ù’Ï¨cI-jÛŠ›äõCÖc?ÿÁ[PŸ�¾ZÇ¦™1O�i
§S¶É.X§"~Ô1^ëi�àô¬Ù;8Ù0Ww©.ÚWµý“áëg®—þÜxÔ´£R+¹å;‰¸Qå´Ûj(2;^~ÑÍœØ™‚±dÑ
•]VÄá‚[§9¿žˆµ±º²eeZ^	6¯XðsÒ<a.¾}róÃ“m§wy1Äm‹aygæè< È¹Çõ…]Ç…="a\¹…'K7™�#ÓEaS&quot;%V¼6Ó{š´¾´#û´½-¦­Zâp`¨óí‡�/�§;^ç:ƒ%Ezôµ„9ûŠ}¦b+1Ê„ôŠk¬_ì" ‚-sreãze="" ûd”sqÚëÌånº':¸mÒv¤ï’¤Ë´uâÅÌo»2üÞ#kÝˆccÝ'<k6¼a'lnsÉ&ex�k?Ö0u$bôñ~®~="" 9¦£Âšú°4qjÀ&cÏvÜgaëô~òœ‹j²€É¹v¦�¦à¾ógøúŠ)š‡‘¬l6h="" "="" !ã:b•ÄÊz="" Šè|id”Ùrµé°†Ùtk-mâ6µ)s7†›#ÞÞvf1$wç²£÷Ëj%7+ve<2ØÚ»›o="" Ã|ÿdà%%·e£o="6kâµìLIz9ÕÊ<¨u?ØFÖ‰X-„µ.—c" Ò;îÜÁŒ©–Ç="" rì‚ùŒbuf´ôÒí#‰½“0¼¥Ú+„{2ŒÉèÄíõ¤®¡?rs¬¦çÆq·¾q�’óo…©×+f;«Âô¹¨="" upÃ´ÛcÞrfªžèh¦ºm4«zi(ž©7\="" úà4="Ïèx–½ûˆåö" *›æ•Š@ßr££nðê®bk7cèœ§Ù²^ñèic3mäø—&ïÁªý="">¿"ñ=èQÄï;k…&lt;£	²\KÏóë‘úÉÐ¬ÜÈƒðìlE:+×{9õ$˜Ü÷½á¾9qk«r8çº/w`8¥ÓåTH&nbsp;t£
`¶`ë–ÎøZ2Œ)··asiËnÙ&gt;ž	ìtIFrE»ñÚ›Uö¾êÍ÷×´J6ñÅiÑS&lt;ã¢NU&amp;¥x7WeÁ?¼í&lt;˜BûØ1°IAlÃ&amp;ã=Ô3BZ-$haáä$ùæÄÐ&gt;í¡oÛýÓ`Á”r{áî_˜/@öµDð1Šà~ÚëñÚÈñÍþðÚÀòÕvðí~—×Ö™ïn�yn�Q¢Á½Áû3p¾&nbsp;ýšO¦ñü§¸|¢üÇçãþlÃÓ¿c#”©ÿÁ–¦4×ïnˆê&gt;-Þ¶l�,ªz8œþŸ?ÚXõG»ª¾ÞQGýNñ \_£SºDr_Ò¯Ï!¿»¿Ç1ôj�Ä¯}�2y�³4¤D1âwÊä»”c•ï•´(&nbsp;¬CÔõ©Ÿ×¿ò®¯ÿÑÔÇ½þ=ö;ù‡ßRŠ^NûÔ/"³óªê ª‚ùýÎ+úè÷Ö? ú7íuM—VÃY}¢ø–�^@oU½2úÞþ²SÔþhÙûÍìUßŸ«Ÿ)PÕàý!�E}ÿC²uáùÏâËÿ®Šï
ùQ§»7‰ÐÕcóuð×÷Ø½»&gt;ºyŒä=ÅÞXo^Ý¿yöÿÂÆÏˆ~ÎçÑë{ôóFÏ+Q&nbsp;°ïéä?ÊÂàwiÆ®xî
Ÿ¡‡8‚}‰"aðq_&nbsp;×4Ex�^@S÷Ã«Ï_Á'ŠÿÜU”Ÿc^Yþt··áÏ€îG·ÙÞ&nbsp;øÿü?å�˜öCÝÍÿ™Îùì;/xª*¨+ˆC&gt;&nbsp;ñ³ë?nûñ^hú&gt;îêòÍ÷íôf¨¿¸s«ÂJI?í±ýØçg,ÿœCÿ-ú¿OôÞ»ý±Óª¼*ˆ$þ=tÒ_Ò4|G“$Ë®øÊRÔ–Â0nEñ;†Ül7«ƒïˆ�¼?kúcþ÷$ª~–n}Fõc&amp;}wB¹GúãíÜßkôcæAâU×(|&gt;6üxáß‰¿ß�ð�€�ºZi÷p´Y|§YŒlý`…</a.¾}róã“m§wy1äm‹aygæè<></p§e\«åãê\xz¬></l,ló^ðå)†ªníu=jûutc¦åðˆ3[;¦]g·ž{êñk?]ýù­odiïû´u¿�‰4•éãe¹¶9½$å×ºm5ú1ó©#></fï4ü×ü+ûªép@˜wyäyébxœ«�ñ”˜å?rø_\aàò¾$xõë²&’�ç˜></eü%¨k0y></z–cû»×{6{ö“±cùrùd¸jgªÿô¼àá$ÿ|ñyr¡9ö,¨u(dàqv¹x"tæþ«=:ýø‹d1k ></vçûn·`xö•êç¹þùc×¦aømûiôãç!a,\ì></uø—e… rcç~û­—8°{éìóµñý¶lø%÷v–´™àuõè�&)¨`çtä¥jª‚s8í,ìmös”eêùšh'></pòœ></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.fmeurope.org/documents/Garavel-terBeek-vandePol-20.pdf">http://www.fmeurope.org/documents/Garavel-terBeek-vandePol-20.pdf</a></em></p>]]>
            </description>
            <link>http://www.fmeurope.org/documents/Garavel-terBeek-vandePol-20.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455636</guid>
            <pubDate>Thu, 17 Dec 2020 14:04:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make a Language in Rust: Refactoring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25455607">thread link</a>) | @azhenley
<br/>
December 17, 2020 | https://arzg.github.io/lang/16/ | <a href="https://web.archive.org/web/*/https://arzg.github.io/lang/16/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The right-hand side of the <code>let lhs = ...</code> in <code>expr_binding_power</code> is getting quite long, so let’s extract it to its own function:</p><div><pre><code data-lang="rust"><span>// expr.rs
</span><span></span><span>
</span><span></span><span>use</span><span> </span><span>super</span>::<span>marker</span>::<span>CompletedMarker</span><span>;</span><span>
</span><span></span><span>use</span><span> </span><span>super</span>::<span>Parser</span><span>;</span><span>
</span><span></span><span>use</span><span> </span><span>crate</span>::<span>lexer</span>::<span>SyntaxKind</span><span>;</span><span>
</span><span>
</span><span></span><span>// snip
</span><span></span><span>
</span><span></span><span>fn</span> <span>expr_binding_power</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>,</span><span> </span><span>minimum_binding_power</span>: <span>u8</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>lhs</span><span> </span><span>=</span><span> </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>lhs</span><span>)</span><span> </span><span>=</span><span> </span><span>lhs</span><span>(</span><span>p</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>lhs</span><span>
</span><span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span> </span><span>// we’ll handle errors later.
</span><span></span><span>    </span><span>};</span><span>
</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>fn</span> <span>lhs</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>Option</span><span>&lt;</span><span>CompletedMarker</span><span>&gt;</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>cm</span><span> </span><span>=</span><span> </span><span>match</span><span> </span><span>p</span><span>.</span><span>peek</span><span>()</span><span> </span><span>{</span><span>
</span><span>        </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>Number</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            </span><span>// snip
</span><span></span><span>        </span><span>}</span><span>
</span><span>        </span><span>// all the other arms are also here, unchanged
</span><span></span><span>        </span><span>_</span><span> </span><span>=&gt;</span><span> </span><span>return</span><span> </span><span>None</span><span>,</span><span>
</span><span>    </span><span>};</span><span>
</span><span>
</span><span>    </span><span>Some</span><span>(</span><span>cm</span><span>)</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><pre><code data-lang="-">$ cargo t -q
running 35 tests
...................................
test result: ok. 35 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>Let’s also extract the parsers for each of the <code>match</code> arms in <code>lhs</code>:</p><div><pre><code data-lang="rust"><span>fn</span> <span>lhs</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>Option</span><span>&lt;</span><span>CompletedMarker</span><span>&gt;</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>cm</span><span> </span><span>=</span><span> </span><span>match</span><span> </span><span>p</span><span>.</span><span>peek</span><span>()</span><span> </span><span>{</span><span>
</span><span>        </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>Number</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>literal</span><span>(</span><span>p</span><span>),</span><span>
</span><span>        </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>Ident</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>variable_ref</span><span>(</span><span>p</span><span>),</span><span>
</span><span>        </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>Minus</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>prefix_expr</span><span>(</span><span>p</span><span>),</span><span>
</span><span>        </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>LParen</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>paren_expr</span><span>(</span><span>p</span><span>),</span><span>
</span><span>        </span><span>_</span><span> </span><span>=&gt;</span><span> </span><span>return</span><span> </span><span>None</span><span>,</span><span>
</span><span>    </span><span>};</span><span>
</span><span>
</span><span>    </span><span>Some</span><span>(</span><span>cm</span><span>)</span><span>
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>// snip
</span><span></span><span>
</span><span></span><span>fn</span> <span>literal</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>CompletedMarker</span><span> </span><span>{</span><span>
</span><span>    </span><span>assert_eq</span><span>!</span><span>(</span><span>p</span><span>.</span><span>peek</span><span>(),</span><span> </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>Number</span><span>));</span><span>
</span><span>
</span><span>    </span><span>let</span><span> </span><span>m</span><span> </span><span>=</span><span> </span><span>p</span><span>.</span><span>start</span><span>();</span><span>
</span><span>    </span><span>p</span><span>.</span><span>bump</span><span>();</span><span>
</span><span>    </span><span>m</span><span>.</span><span>complete</span><span>(</span><span>p</span><span>,</span><span> </span><span>SyntaxKind</span>::<span>Literal</span><span>)</span><span>
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>fn</span> <span>variable_ref</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>CompletedMarker</span><span> </span><span>{</span><span>
</span><span>    </span><span>assert_eq</span><span>!</span><span>(</span><span>p</span><span>.</span><span>peek</span><span>(),</span><span> </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>Ident</span><span>));</span><span>
</span><span>
</span><span>    </span><span>let</span><span> </span><span>m</span><span> </span><span>=</span><span> </span><span>p</span><span>.</span><span>start</span><span>();</span><span>
</span><span>    </span><span>p</span><span>.</span><span>bump</span><span>();</span><span>
</span><span>    </span><span>m</span><span>.</span><span>complete</span><span>(</span><span>p</span><span>,</span><span> </span><span>SyntaxKind</span>::<span>VariableRef</span><span>)</span><span>
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>fn</span> <span>prefix_expr</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>CompletedMarker</span><span> </span><span>{</span><span>
</span><span>    </span><span>assert_eq</span><span>!</span><span>(</span><span>p</span><span>.</span><span>peek</span><span>(),</span><span> </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>Minus</span><span>));</span><span>
</span><span>
</span><span>    </span><span>let</span><span> </span><span>m</span><span> </span><span>=</span><span> </span><span>p</span><span>.</span><span>start</span><span>();</span><span>
</span><span>
</span><span>    </span><span>let</span><span> </span><span>op</span><span> </span><span>=</span><span> </span><span>PrefixOp</span>::<span>Neg</span><span>;</span><span>
</span><span>    </span><span>let</span><span> </span><span>((),</span><span> </span><span>right_binding_power</span><span>)</span><span> </span><span>=</span><span> </span><span>op</span><span>.</span><span>binding_power</span><span>();</span><span>
</span><span>
</span><span>    </span><span>// Eat the operator’s token.
</span><span></span><span>    </span><span>p</span><span>.</span><span>bump</span><span>();</span><span>
</span><span>
</span><span>    </span><span>expr_binding_power</span><span>(</span><span>p</span><span>,</span><span> </span><span>right_binding_power</span><span>);</span><span>
</span><span>
</span><span>    </span><span>m</span><span>.</span><span>complete</span><span>(</span><span>p</span><span>,</span><span> </span><span>SyntaxKind</span>::<span>PrefixExpr</span><span>)</span><span>
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>fn</span> <span>paren_expr</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>CompletedMarker</span><span> </span><span>{</span><span>
</span><span>    </span><span>assert_eq</span><span>!</span><span>(</span><span>p</span><span>.</span><span>peek</span><span>(),</span><span> </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>LParen</span><span>));</span><span>
</span><span>
</span><span>    </span><span>let</span><span> </span><span>m</span><span> </span><span>=</span><span> </span><span>p</span><span>.</span><span>start</span><span>();</span><span>
</span><span>
</span><span>    </span><span>p</span><span>.</span><span>bump</span><span>();</span><span>
</span><span>    </span><span>expr_binding_power</span><span>(</span><span>p</span><span>,</span><span> </span><span>0</span><span>);</span><span>
</span><span>
</span><span>    </span><span>assert_eq</span><span>!</span><span>(</span><span>p</span><span>.</span><span>peek</span><span>(),</span><span> </span><span>Some</span><span>(</span><span>SyntaxKind</span>::<span>RParen</span><span>));</span><span>
</span><span>    </span><span>p</span><span>.</span><span>bump</span><span>();</span><span>
</span><span>
</span><span>    </span><span>m</span><span>.</span><span>complete</span><span>(</span><span>p</span><span>,</span><span> </span><span>SyntaxKind</span>::<span>ParenExpr</span><span>)</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>Writing out that <code>assert_eq!</code> at the start of each subparser is getting annoying. Let’s write a helper method on <code>Parser</code> to make this easier:</p><div><pre><code data-lang="rust"><span>// parser.rs
</span><span></span><span>
</span><span></span><span>impl</span><span>&lt;</span><span>'l</span><span>,</span><span> </span><span>'input</span><span>&gt;</span><span> </span><span>Parser</span><span>&lt;</span><span>'l</span><span>,</span><span> </span><span>'input</span><span>&gt;</span><span> </span><span>{</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>
</span><span>    </span><span>fn</span> <span>at</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>kind</span>: <span>SyntaxKind</span><span>)</span><span> </span>-&gt; <span>bool</span> <span>{</span><span>
</span><span>        </span><span>self</span><span>.</span><span>peek</span><span>()</span><span> </span><span>==</span><span> </span><span>Some</span><span>(</span><span>kind</span><span>)</span><span>
</span><span>    </span><span>}</span><span>
</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>}</span><span>
</span></code></pre></div><p>We can now update all those <code>assert_eq!</code>s:</p><div><pre><code data-lang="rust"><span>// expr.rs
</span><span></span><span>
</span><span></span><span>fn</span> <span>literal</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>CompletedMarker</span><span> </span><span>{</span><span>
</span><span>    </span><span>assert</span><span>!</span><span>(</span><span>p</span><span>.</span><span>at</span><span>(</span><span>SyntaxKind</span>::<span>Number</span><span>));</span><span>
</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>fn</span> <span>variable_ref</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>CompletedMarker</span><span> </span><span>{</span><span>
</span><span>    </span><span>assert</span><span>!</span><span>(</span><span>p</span><span>.</span><span>at</span><span>(</span><span>SyntaxKind</span>::<span>Ident</span><span>));</span><span>
</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>fn</span> <span>prefix_expr</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>CompletedMarker</span><span> </span><span>{</span><span>
</span><span>    </span><span>assert</span><span>!</span><span>(</span><span>p</span><span>.</span><span>at</span><span>(</span><span>SyntaxKind</span>::<span>Minus</span><span>));</span><span>
</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>fn</span> <span>paren_expr</span><span>(</span><span>p</span>: <span>&amp;</span><span>mut</span><span> </span><span>Parser</span><span>)</span><span> </span>-&gt; <span>CompletedMarker</span><span> </span><span>{</span><span>
</span><span>    </span><span>assert</span><span>!</span><span>(</span><span>p</span><span>.</span><span>at</span><span>(</span><span>SyntaxKind</span>::<span>LParen</span><span>));</span><span>
</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>
</span><span>    </span><span>assert</span><span>!</span><span>(</span><span>p</span><span>.</span><span>at</span><span>(</span><span>SyntaxKind</span>::<span>RParen</span><span>));</span><span>
</span><span>    </span><span>p</span><span>.</span><span>bump</span><span>();</span><span>
</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>}</span><span>
</span></code></pre></div><pre><code data-lang="-">$ cargo t -q
running 35 tests
...................................
test result: ok. 35 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>I was under the impression that a ‘token’ is an identifier of a given chunk of the input (in our case a <code>SyntaxKind</code>), and that a ‘lexeme’ is a token plus the text that token applies to. Once again it seems that my assumptions about terminology are incorrect: although <a href="https://stackoverflow.com/a/14958865">this StackOverflow answer</a> agrees with my definition of ‘token’, it explains that the word ‘token’ can also be used to describe what I’ve been calling a ‘lexeme’. My definition of ‘lexeme’ is incorrect; the answer says that ‘lexeme’ refers to the text a token applies to, <em>and that only.</em></p><p>Use your editor’s project-wide search and replace to rename <code>Lexeme</code> to <code>Token</code>, <code>lexeme</code> to <code>token</code> and <code>'l</code> to <code>'t</code>. Make sure to run <code>cargo fmt</code> afterwards to maintain formatting.</p><p>See <a href="https://github.com/arzg/eldiro/commit/0d5ba1682698654c27c20139fc7f1ba139d70ad1">the commit</a> where this change is made if you have any trouble.</p><p>When we want to add a token to the current branch, we use this event:</p><div><pre><code data-lang="rust"><span>Event</span>::<span>AddToken</span><span> </span><span>{</span><span>
</span><span>    </span><span>kind</span>: <span>SyntaxKind</span>::<span>Foo</span><span>,</span><span>
</span><span>    </span><span>text</span>: <span>"bar"</span><span>.</span><span>into</span><span>(),</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>We get the <code>SyntaxKind</code> and text of this token from the source, which stores an array of tokens internally. Once parsing is complete, the sink goes through each event and processes it. The sink also stores the same array of tokens.</p><p>This means that the the parser doesn’t need to tell the sink the <code>SyntaxKind</code> and text of each token it’s adding, since the sink already has the data to work this out. Let’s remove the unnecessary fields from <code>Event::AddToken</code>:</p><div><pre><code data-lang="rust"><span>// event.rs
</span><span></span><span>
</span><span></span><span>use</span><span> </span><span>crate</span>::<span>lexer</span>::<span>SyntaxKind</span><span>;</span><span>
</span><span>
</span><span></span><span>#[derive(Debug, Clone, PartialEq)]</span><span>
</span><span></span><span>pub</span><span>(</span><span>super</span><span>)</span><span> </span><span>enum</span> <span>Event</span><span> </span><span>{</span><span>
</span><span>    </span><span>StartNode</span><span> </span><span>{</span><span>
</span><span>        </span><span>kind</span>: <span>SyntaxKind</span><span>,</span><span>
</span><span>        </span><span>forward_parent</span>: <span>Option</span><span>&lt;</span><span>usize</span><span>&gt;</span><span>,</span><span>
</span><span>    </span><span>},</span><span>
</span><span>    </span><span>AddToken</span><span>,</span><span>
</span><span>    </span><span>FinishNode</span><span>,</span><span>
</span><span>    </span><span>Placeholder</span><span>,</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>This has reduced the size of <code>Event</code> from 32 bytes to 24 bytes. Let’s update <code>Parser::bump</code> to match:</p><div><pre><code data-lang="rust"><span>// parser.rs
</span><span></span><span>
</span><span></span><span>impl</span><span>&lt;</span><span>'t</span><span>,</span><span> </span><span>'input</span><span>&gt;</span><span> </span><span>Parser</span><span>&lt;</span><span>'t</span><span>,</span><span> </span><span>'input</span><span>&gt;</span><span> </span><span>{</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>
</span><span>    </span><span>fn</span> <span>bump</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>self</span><span>.</span><span>source</span><span>.</span><span>next_token</span><span>().</span><span>unwrap</span><span>();</span><span>
</span><span>        </span><span>self</span><span>.</span><span>events</span><span>.</span><span>push</span><span>(</span><span>Event</span>::<span>AddToken</span><span>);</span><span>
</span><span>    </span><span>}</span><span>
</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>}</span><span>
</span></code></pre></div><p>We also need to change <code>Sink</code>:</p><div><pre><code data-lang="rust"><span>// sink.rs
</span><span></span><span>
</span><span></span><span>use</span><span> </span><span>super</span>::<span>event</span>::<span>Event</span><span>;</span><span>
</span><span></span><span>use</span><span> </span><span>crate</span>::<span>lexer</span>::<span>Token</span><span>;</span><span>
</span><span></span><span>use</span><span> </span><span>crate</span>::<span>syntax</span>::<span>EldiroLanguage</span><span>;</span><span>
</span><span></span><span>use</span><span> </span><span>rowan</span>::<span>{</span><span>GreenNode</span><span>,</span><span> </span><span>GreenNodeBuilder</span><span>,</span><span> </span><span>Language</span><span>};</span><span>
</span><span></span><span>use</span><span> </span><span>std</span>::<span>mem</span><span>;</span><span>
</span><span>
</span><span></span><span>// snip
</span><span></span><span>
</span><span></span><span>impl</span><span>&lt;</span><span>'t</span><span>,</span><span> </span><span>'input</span><span>&gt;</span><span> </span><span>Sink</span><span>&lt;</span><span>'t</span><span>,</span><span> </span><span>'input</span><span>&gt;</span><span> </span><span>{</span><span>
</span><span>    </span><span>// snip
</span><span></span><span>
</span><span>    </span><span>pub</span><span>(</span><span>super</span><span>)</span><span> </span><span>fn</span> <span>finish</span><span>(</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span>-&gt; <span>GreenNode</span><span> </span><span>{</span><span>
</span><span>        </span><span>for</span><span> </span><span>idx</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>self</span><span>.</span><span>events</span><span>.</span><span>len</span><span>()</span><span> </span><span>{</span><span>
</span><span>            </span><span>match</span><span> </span><span>mem</span>::<span>replace</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>.</span><span>events</span><span>[</span><span>idx</span><span>],</span><span> </span><span>Event</span>::<span>Placeholder</span><span>)</span><span> </span><span>{</span><span>
</span><span>                </span><span>// snip
</span><span></span><span>                </span><span>Event</span>::<span>AddToken</span><span> </span><span>=&gt;</span><span> </span><span>self</span><span>.</span><span>token</span><span>(),</span><span>
</span><span>                </span><span>// snip
</span><span></span><span>            </span><span>}</span><span>
</span><span>
</span><span>            </span><span>self</span><span>.</span><span>eat_trivia</span><span>();</span><span>
</span><span>        </span><span>}</span><span>
</span><span>
</span><span>        </span><span>self</span><span>.</span><span>builder</span><span>.</span><span>finish</span><span>()</span><span>
</span><span>    </span><span>}</span><span>
</span><span>
</span><span>    </span><span>fn</span> <span>eat_trivia</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>while</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>token</span><span>)</span><span> </span><span>=</span><span> </span><span>self</span><span>.</span><span>tokens</span><span>.</span><span>get</span><span>(</span><span>self</span><span>.</span><span>cursor</span><span>)</span><span> </span><span>{</span><span>
</span><span>            </span><span>if</span><span> </span><span>!</span><span>token</span><span>.</span><span>kind</span><span>.</span><span>is_trivia</span><span>()</span><span> </span><span>{</span><span>
</span><span>                </span><span>break</span><span>;</span><span>
</span><span>            </span><span>}</span><span>
</span><span>
</span><span>            </span><span>self</span><span>.</span><span>token</span><span>();</span><span>
</span><span>        </span><span>}</span><span>
</span><span>    </span><span>}</span><span>
</span><span>
</span><span>    </span><span>fn</span> <span>token</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>let</span><span> </span><span>Token</span><span> </span><span>{</span><span> </span><span>kind</span><span>,</span><span> </span><span>text</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>self</span><span>.</span><span>tokens</span><span>[</span><span>self</span><span>.</span><span>cursor</span><span>];</span><span>
</span><span>
</span><span>        </span><span>self</span><span>.</span><span>builder</span><span>
</span><span>            </span><span>.</span><span>token</span><span>(</span><span>EldiroLanguage</span>::<span>kind_to_raw</span><span>(</span><span>kind</span><span>),</span><span> </span><span>text</span><span>.</span><span>into</span><span>());</span><span>
</span><span>
</span><span>        </span><span>self</span><span>.</span><span>cursor</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><pre><code data-lang="-">$ cargo t -q
running 35 tests
...................................
test result: ok. 35 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>I’ve used these terms inconsistently throughout the series, and thought it might be a good time to clean this up.</p><ul><li><em>Binary operator</em> means ‘an operator with two operands’</li><li><em>Infix operator</em> means ‘an operator placed between its operands’</li><li><em>Unary operator</em> means ‘an operator with one operand’</li><li><em>Prefix operator</em> means ‘an operator placed before its operands’</li></ul><p>I’ve used the ‘binary’ terminology in <code>SyntaxKind</code>, but used ‘infix’ for the type representing these binary operators in <code>expr.rs</code>. I’ve used the ‘prefix’ terminology in both <code>SyntaxKind</code> and <code>expr.rs</code>.</p><p>To stay consistent we should name things after the position of the operator, or the number of operands. The parser has to worry about the position, but future parts of Eldiro (such as an interpreter) have to worry about the number of operands. To convey this we’ll rename <code>SyntaxKind::BinaryExpr</code> to <code>SyntaxKind::InfixExpr</code>, <code>InfixOp</code> to <code>BinaryOp</code> and <code>PrefixOp</code> to <code>UnaryOp</code>. Make sure you change the tests too! If you get stuck feel free to look at <a href="https://github.com/arzg/eldiro/commit/1d494614433548cf045dcb5abbf91a8b937c6832">the relevant commit</a>.</p></div></div>]]>
            </description>
            <link>https://arzg.github.io/lang/16/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455607</guid>
            <pubDate>Thu, 17 Dec 2020 14:00:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[More information on the plant disturbance at Olkiluoto 2]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455279">thread link</a>) | @ericdanielski
<br/>
December 17, 2020 | https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html | <a href="https://web.archive.org/web/*/https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455279</guid>
            <pubDate>Thu, 17 Dec 2020 13:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next level of coding courses]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25455153">thread link</a>) | @skyfantom
<br/>
December 17, 2020 | https://blog.rukomoynikov.ru/next-level-of-coding-courses/ | <a href="https://web.archive.org/web/*/https://blog.rukomoynikov.ru/next-level-of-coding-courses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-429">

<div>
<p>Recently I’ve got a message from a coding school. They offer two options to go through their courses. One is cheaper, but without review. You are simply watching prerecorded videos. Other one includes exercises and code reviews. </p>
<p>So, I come up with idea of coding courses where content like video and exercises are open and free for everyone. But, coding review is a paid function. And you can choose a person who will review your code. And price of review will be different. Like you want to hire someone who is more detailed in review or who has some very rare knowledge. You decide. </p>
<p>You choose a reviewer for particular exercises. Exercise may have different levels, like to reverse a string or create a web server. Also reviews can be plain text or recorded video with explanations.</p>
<p>Sure, reviewers have rating and reviews 😉 What do you think about the idea?</p>
</div>

</article></div>]]>
            </description>
            <link>https://blog.rukomoynikov.ru/next-level-of-coding-courses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455153</guid>
            <pubDate>Thu, 17 Dec 2020 12:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Guide to ENS Domains and IPFS (Ethereum Name Service)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25455073">thread link</a>) | @itsnicoggi
<br/>
December 17, 2020 | https://blog.fleek.co/posts/guide-ens-domains-ipfs-ethereum-name-service | <a href="https://web.archive.org/web/*/https://blog.fleek.co/posts/guide-ens-domains-ipfs-ethereum-name-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://fleek-team-bucket.storage.fleek.co/thumbnails-blog/ENS%20-%20Introduction%20Guide.jpg"></p>
<p>ENS (<a href="https://ens.domains/" target="_blank" rel="nofollow noopener noreferrer">Ethereum Name Service</a>) domains, much like the name entails, are the decentralized Ethereum-based naming system alternative to DNS (Domain Name System).</p>
<p>Both carry out the same basic task. <strong>They are lookup systems</strong> which use domain names to map and reference complex addresses. The difference is that, while DNS uses domain names to translate a website’s underlying IP address, ENS uses .eth suffix domain names to reference <a href="https://ethereum.org/" target="_blank" rel="nofollow noopener noreferrer">Ethereum</a> addresses, or any other hard to remember resources, like IPFS file hashes or Tor .onion addresses!</p>
<p>Instead of recalling, for example, a 42 character hexadecimal ETH wallet address that looks something like “oxe989eb1ddd3442a24…”, you can replace it with a more familiar ENS domain name that’s easier to remember, like <strong>mywallet.eth</strong>, and make it easier for anyone to make a transfer via an ENS-compatible wallet without typing down the full hexadecimal address.</p>
<p>But, there’s more to ENS domain names than just making memorable wallet addresses, or accessing your favorite IPFS-hosted picture on the go.</p>
<p>ENS opens up the door for websites, Dapps, and more Dweb resources/services to make themselves accessible via a <strong>decentralized, censorship-resistant, and user-controlled</strong> domain naming system.</p>
<p>Unlike DNS, which is handled by centralized authorities, ENS lives on smart contracts on the Ethereum blockchain and is censorship-resistant.</p>
<p>Let’s do an overview of what ENS domains are, why they are important, and how to buy and use them for your IPFS site.</p>
<p><strong>What you will learn on this article:</strong></p>
<ul>
<li><a href="#what-is-the-ethereum-name-service-ens">What is the Ethereum Name Service (ENS)?</a></li>
<li><a href="#how-to-buy-ens-domains-and-register-them">How to buy ENS domains and register them?</a></li>
<li><a href="#how-to-link-ens-domains-to-ipfs-sites">How to link your ENS domain to an IPFS site with Fleek.</a></li>
</ul>
<h2 id="what-is-the-ethereum-name-service-ens"><a href="#what-is-the-ethereum-name-service-ens" aria-label="what is the ethereum name service ens permalink"></a>What is the Ethereum Name Service (ENS)?</h2>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/ENS%20Domains.png"></p>
<p>ENS is an open source, distributed, and community-owned naming system that resides in the Ethereum blockchain. It was developed at the Ethereum Foundation in early 2017, proposed and created originally by the developer Nick Johnson and Alex Van de Sande.</p>
<p>At its core, ENS is composed of two main pieces. <strong>Firstly, the ENS registry,</strong> which lives in a smart contract running on the Ethereum blockchain and has a record of all domains and subdomains, detailing the owner, resolver, and caching TTL (time-to-live) for all records under that domain.</p>
<p><strong>The second key piece are resolvers</strong>, which are the actors responsible for translating the ENS domain names into the underlying referenced address or hash. These are also smart contracts on the blockchain, which carry the task of being asked what the “mywallet.eth” domain references, and responding with the resource’s address: ““oxe989eb1ddd3442a24…”.</p>
<p>With those two components we can map the basic ENS architecture and flow. When resolving an ENS address, one first queries the ENS registry for an ENS address → the registry then answers what resolver should be queried for the mapped content → and that resolver in return points the user to the final address or content the domain references.</p>
<p>Right now ENS is growing in popularity and browsers like Opera mobile, MetaMask mobile, or any popular browser using the MetaMask extension supports .eth domains. <a href="http://fleek.co/" target="_blank" rel="nofollow noopener noreferrer">Even in Fleek</a>, ENS domains are gaining a lot of traction! Over 10% of deployments in Fleek are associated with an ENS domain, and over 4000 sites have added an ENS name already.</p>
<p>What’s more, “.eth” is not the only suffix! As of today, some TLDs like .xyz <a href="https://docs.ens.domains/dns-registrar-guide" target="_blank" rel="nofollow noopener noreferrer">can be registered</a> and claimed on ENS, however “.eth” does still benefit from being exclusively blockchain-native.</p>
<h3 id="why-are-ens-domains-important"><a href="#why-are-ens-domains-important" aria-label="why are ens domains important permalink"></a>Why are ENS domains important?</h3>
<p>Not only ENS offers a decentralized alternative to address complex resources on or off the blockchain with easy-to-read names, but it also is a complementary piece on the <strong>road to decentralizing web/app hosting entirely</strong>.</p>
<p>Instead of having Domain Name Registrars like GoDaddy, and DNS Servers, ENS has two decentralized components that cut these middlemen and let the community handle both domain purchases/ownership and resolving.</p>
<p>After all, today in the Web 2.0, <strong>most hosting components are centralized</strong>: Domains, dedicated hosting servers, and CDNs. ENS is the starting point for changing that, by making internet naming decentralized.</p>
<p>And, when combined with <a href="https://ipfs.io/" target="_blank" rel="nofollow noopener noreferrer">IPFS</a> (InterPlanetary File System), a distributed, P2P file system, ENS begins to open up the door for getting rid of the centralized, censorship-prone DNS components of Web 2.0, and making <strong>decentralized, P2P and censorship-resistant websites &amp; apps possible</strong>.</p>
<p>Especially because of the fact ENS allows us to access content on decentralized storage like IPFS via decentralized <a href="https://blog.fleek.co/posts/immutable-ipfs" target="_blank" rel="nofollow noopener noreferrer">constant links</a>. Remember that, on IPFS, files are identified by their content not by a storage URL. Meaning their addresses/hashes (CID) change every time the content does. Imagine having to change your website’s url every time you made an update!</p>
<p>ENS adoption still needs to grow, and P2P content storage/delivery networks are evolving as well to better achieve this (<a href="https://blog.space.storage/posts/how-is-space-different-from-cloud-storage" target="_blank" rel="nofollow noopener noreferrer">we’re working on that with Space</a>!). But, ENS domains -and the idea behind them- definitely represent the base structure of what hosting and content serving should look like in Web 3.0, because unlike DNS they are:</p>
<ul>
<li>Decentralized</li>
<li>Immutable</li>
<li>Censorship-resistant</li>
<li>User-owned/controlled</li>
</ul>
<p>And, above all, ENS resides in the Ethereum ecosystem, which is not a minor perk! Rather than being an alternate blockchain/network, it exists in an ecosystem in which it can easily interact with most of the decentralized use cases it pairs up well with: Dapps, Defi, NFTs, DAOs, wallets, etc.</p>
<p>Not only that, but it can integrate all of those use cases under a single address! With DNS,  your domain, identity, payments, and bank are all separate things. ENS can unite it all in a single address that becomes not only your site, but identity, and bank. After all, not only it can carry an IPFS hash, but ETH, or BTC addresses and more things at once. </p>
<h2 id="how-to-buy-ens-domains-and-register-them"><a href="#how-to-buy-ens-domains-and-register-them" aria-label="how to buy ens domains and register them permalink"></a>How to Buy ENS Domains and Register Them</h2>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/I%20want%20one%20ENS.jpg"></p>
<p>Let’s get started on your road to decentralizing your website using ENS and IPFS. The first step you need to take is <strong>registering an ENS domain.</strong> We’ll use ENS’s dashboard as an example, and then follow Fleek’s flow for integrating it with your IPFS-hosted site.</p>
<p>The acquisition, ownership, and registration aspect of ENS is decentralized as well.</p>
<p>Initially, domain name auctions lasted three days, in which a Vickrey Auction process was executed. Someone opened an auction for a name they wanted to buy, people bid for three days, and the winner owned the domain until they released it and recovered their funds. This, however, promoted domain squatting/hoarding, and a new model was introduced.</p>
<p>As of last year, <strong>you can buy and register ENS domains instantly</strong>, with a slight one minute delay. Instead of paying an undefined fee, there is a <strong>yearly rent</strong> model which costs approximately USD$5 payable in ETH (some domains are slightly more expensive due to popularity). These funds now go to <a href="https://medium.com/the-ethereum-name-service/what-will-ens-do-with-all-that-rent-money-heres-what-you-need-to-know-c7fe26a7e0e9" target="_blank" rel="nofollow noopener noreferrer">initiatives and grants</a> to help maintain/develop ENS and the Ethereum ecosystem overall.</p>
<p>Let’s go over the registration process.</p>
<h3 id="1-go-to-the-ens-domain-application"><a href="#1-go-to-the-ens-domain-application" aria-label="1 go to the ens domain application permalink"></a>1. Go to the <a href="https://app.ens.domains/" target="_blank" rel="nofollow noopener noreferrer">ENS domain application</a>.</h3>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/ENS%20Application.jpg"></p>
<p>To register your first ENS domain, visit the <a href="https://app.ens.domains/" target="_blank" rel="nofollow noopener noreferrer">Ethereum Name Service app </a>and search for an address/name you want to register and is available. At the moment, you can register domains that are a minimum of 3 characters long (no maximum limit), and you can include emojis.</p>
<h3 id="2-connect-to-the-main-network"><a href="#2-connect-to-the-main-network" aria-label="2 connect to the main network permalink"></a>2. Connect to the Main Network.</h3>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/ENS%20Connect.gif"></p>
<p>To pay for the registration fee of your ENS domain, and declare your ownership for it, you will have to connect to the Mainnet using one of the offered integrations (MetaMask, WalletConnect, Portis, Torus, Authereum, MEW wallet). We’ll use <a href="https://metamask.io/" target="_blank" rel="nofollow noopener noreferrer">MetaMask</a> for this example.</p>
<h3 id="3-define-registration-period-and-confirm"><a href="#3-define-registration-period-and-confirm" aria-label="3 define registration period and confirm permalink"></a>3. Define Registration Period and Confirm</h3>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/ENS%20Registration%20Period.png"></p>
<p>Choose for how long you will want to rent that domain, and verify the final ETH fee to pay. Once you’re good to go, hit “Request to Register” and a transaction will begin. It takes about one minute to verify because during that period the platform is verifying no one else already tried or is trying to acquire the same domain.</p>
<p>If everything is good, your wallet will pop up to execute the final transaction, and confirm your ownership and purchase.</p>
<h3 id="4-review-details-and-setup-renewal-reminder"><a href="#4-review-details-and-setup-renewal-reminder" aria-label="4 review details and setup renewal reminder permalink"></a>4. Review Details and Setup Renewal Reminder</h3>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/ENS%20Domain%20Details.jpg"></p>
<p>Once your transaction is successful, you will see a page similar to the one above (using the ens.eth domain as an example). Let’s go over the details on this page.</p>
<p><strong>The registrant</strong> is the owner of the ENS domain, in this case, it will be you! The registrant can set the controller address, change the resolver, or transfer the registration to a new owner.</p>
<p><strong>The controller</strong> can be seen as the account or user who is in charge of changing the content/addresses/records on this domain, and create or manage subdomains. By default, the registrant will be the controller, but it can be modified.</p>
<p><strong>The resolver</strong> is a smart contract that handles the translation from your ENS domain name to the content you actually link it to. By default, it is set to the Public Resolver managed by the ENS team but it can be modified for custom resolver contracts.</p>
<p><strong>The expiration date</strong> is your renewal date for this domain, when you will have to pay again to maintain the domain’s ownership for a new period. Anyone can choose to pay to renew your domain’s ownership, without them gaining any control over it. <strong>Set up a reminder</strong> for your renewal date using the “Remind Me” button, which allows you to schedule an event in your calendar, or specify an email address where a notification will be sent.</p>
<p><strong>The records</strong> in your domain are where the magic happens! Here you can specify all the resources/addresses that your ENS domain name references. For example, an ETH, BTC, LTC, or DOGE address, content such as the IPFS hash to your website, or text records for things like email or Twitter handles.</p>
<p>Each time you modify a record, there is a ETH gas transaction to be paid. Usually, this is a manual process that you have to do each time you make a new deployment for your website, but we’ll show you later how to automate it using Fleek! A quick spoiler: Fleek covers the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.fleek.co/posts/guide-ens-domains-ipfs-ethereum-name-service">https://blog.fleek.co/posts/guide-ens-domains-ipfs-ethereum-name-service</a></em></p>]]>
            </description>
            <link>https://blog.fleek.co/posts/guide-ens-domains-ipfs-ethereum-name-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455073</guid>
            <pubDate>Thu, 17 Dec 2020 12:48:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyberpunk 2077 Din Schachtdeckel]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25455049">thread link</a>) | @Fake4d
<br/>
December 17, 2020 | https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel | <a href="https://web.archive.org/web/*/https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Gamer diskutieren derzeit über deutsche DIN-Schachtdeckel in einem weltbekannten Computerspiel. Den RSV freut's.</strong></p>
<p>Im amerikanischen Schauplatz des Spiels "Cyberpunk 2077" kommen Schachtabdeckungen nach deutscher Bauart zum Einsatz – allerdings dort, wo es eigentlich nicht DIN-konform wäre. Nach ersten Diskussionen in sozialen Netzwerken gibt es nun sogar schon eine - nicht ganz ernst gemeinte - <a href="https://www.change.org/p/the-cyberpunk-developers-fix-the-manhole-covers-in-cyberpunk-2077" target="_blank" rel="noopener">Petition</a>, die die Entwickler zu mehr Sorgfalt auffordert.</p>
<p><strong>RSV: Endlich mehr Aufmerksamkeit für unsere Branche</strong></p>
<p>Volle Unterstützung gibt es auch vom RSV: "Wir freuen uns über die wachsende Anerkennung für diesen bisher unterbelichteten Bereich in der Öffentlichkeit und hoffen, dass die Entwickler dieses Detail der DIN-Norm zuliebe ausbessern", sagt RSV-Geschäftsführerin Reinhild Haacker dazu, nicht ohne Augenzwinkern. "Deutsche Qualität und Normen liegen uns beim RSV am Herzen. Es ist beruhigend zu wissen, dass deutsche Schachtdeckel – zumindest nach Einschätzung der Gaming-Entwickler – in 57 Jahren zum Einsatz kommen werden, und das sogar in den USA. Dennoch sehen wir uns verpflichtet, im Sinne der Qualitätssicherung darauf hinzuweisen, dass eine DIN 4271 Schachtabdeckung nicht, wie im Spiel gezeigt, auf einer Fahrbahn verbaut werden darf."</p>
<p><strong>Gamer stoßen Petition an</strong></p>
<p>In dem Computerspiel, das derzeit millionenfach gespielt wird, schlüpfen Gamer in die Rolle eines Hackers in einer fiktiven US-Metropole im Jahr 2077. Deutsche Fans des Spiels teilten auf Twitter und in Gaming-Foren Bilder des falsch verbauten DIN-Schachtdeckels, bevor sie scherzhaft eine <a href="https://www.change.org/p/the-cyberpunk-developers-fix-the-manhole-covers-in-cyberpunk-2077">Petition</a> zum Thema einleiteten.</p>
<p>Für das Spiel hatten die polnischen Entwickler übrigens sogar Stadtplaner engagiert, um möglichst realitätsnah rüberzukommen. Möglicherweise haben die vollmundigen Ankündigungen auch dazu geführt, dass Gamer - mit der gewohnten deutschen Gründlichkeit - besonders genau hinschauen.</p>
</div></div>]]>
            </description>
            <link>https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455049</guid>
            <pubDate>Thu, 17 Dec 2020 12:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to let go of a lifelong dream]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455014">thread link</a>) | @known
<br/>
December 17, 2020 | https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Emma Garber began dancing aged three. By the time she was a teenager â€“ following years of dedicated, exhausting, sometimes painful training â€“ it was her burning ambition to become a professional ballet dancer. â€˜I think around age 14, I sat my parents down and I said: <em>This is what I want to do with my life. This is what makes me happy</em>,â€™ she says.</p>
<p>All of us have dreams and hopes for our future. They are often career-focused, but not always. Some people dream of starting a family or living in another country, for instance. Our dreams form part of our identity, giving us purpose and direction. That is, until reality gets in the way, as so often happens: the change might come from within us, as our passion wanes, or the obstacles to realising the dream might become insurmountable (or a mixture of the two).</p>
<p>Garberâ€™s dream began to fade amid burnout and doubt during her freshman year at the University of Massachusetts. After a particularly terrible dance class, she recalls: â€˜I was like, <em>I donâ€™t think I want to do this for the rest of my life</em>. I stood up, I walked out, I called my mom and I was like, <em>I donâ€™t even know what I want to do with my life anymore</em>.â€™</p>
<p>You might be experiencing one of these unsettling fork-in-the-road moments yourself. Perhaps the dying breath of a fading dream is leaving you with intense feelings of regret and failure. You might fear how others will judge you. After all, in todayâ€™s culture, in many parts of the world, weâ€™re taught from a young age that success is born from stubborn perseverance.</p>
<p>â€˜To be gritty,â€™ writes the psychologist Angela Duckworth in her bestselling <a href="https://www.penguin.co.uk/books/110/1109188/grit/9781785042669.html" rel="nofollow noreferrer noopener">book</a> <em>Grit</em> (2016), â€˜is to fall down seven times, and rise eight.â€™ The gist of her advice has echoed through different eras. â€˜Many of lifeâ€™s failures are people who did not realise how close they were to success when they gave up,â€™ wrote the inventor Thomas Edison.</p>
<p>Given this dominant narrative of the virtues of perseverance, and considering how our ambitions can become a core part of our sense of self, itâ€™s understandable that you might be finding it difficult and unsettling to face the prospect of losing your dream. You can take comfort, though, in knowing that being adaptable and flexible in oneâ€™s ambitions is just as important as being gritty or determined. â€˜By definition, if you cannot achieve what you want to achieve, you will fail repeatedly if you donâ€™t stop,â€™ says Carsten Wrosch, a psychology professor at Concordia University in Montreal, who has been studying the construct of â€˜goal adjustment capacityâ€™ for more than 20 years.</p>
<p>Goal adjustment capacity â€“ which psychologists <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/jopy.12492" rel="nofollow noreferrer noopener">see</a> as a beneficial form of â€˜self-regulationâ€™ or â€˜self-managementâ€™ â€“ encapsulates two key components: the ability to disengage from fruitless goals and the ability to reengage in new, more productive goals. You could see it as knowing when and how to switch from one dream to another. Itâ€™s measured by agreement with questionnaire items such as â€˜Itâ€™s easy for me to stop thinking about the goal and let it goâ€™ and â€˜I tell myself that I have a number of other new goals to draw upon.â€™</p>
<p>Wrosch says that people who lack this capacity are inclined to â€˜bang their head against the wallâ€™ when theyâ€™re confronted by an unobtainable goal, and, long-term, theyâ€™re more prone to stress and chronic illness. In contrast, those with greater adjustment capacity â€˜have a much easier timeâ€™ â€“ they decommit to the fruitless goal and find a different ambition to pursue. The virtues of being flexible and adaptable are also recognised by careers researchers, who <a href="https://www.sciencedirect.com/science/article/abs/pii/S0001879116300604" rel="nofollow noreferrer noopener">refer</a> to â€˜career adaptabilityâ€™, aspects of which involve being curious about new opportunities and being confident in oneâ€™s ability to learn new skills. People who score highly in this trait are generally â€˜happier. They perform better. They get promoted â€¦ Just a whole range of good things,â€™ says Rajiv Amarnani, a lecturer in the University of Western Australia Business School. That youâ€™re contemplating giving up your dream suggests that you have a healthy willingness to adjust and adapt, which is to your advantage.</p>
<p>If youâ€™re nonetheless finding it difficult to look beyond the immediate sense of loss or failure, know that there are routes ahead and that other opportunities will emerge. By having the wisdom and flexibility to know when to let go, or when to redirect your passion, youâ€™ll be following in the footsteps of many who have achieved greatness. David Foster Wallace let go of his tennis-greatness dreams and became an acclaimed novelist and writer instead. Meanwhile, Roger Federerâ€™s dreams of tennis greatness came true, but only at the expense of his dream of becoming a professional footballer. And Maryam Mirzakhani let go her childhood dream of becoming a novelist but went on to be awarded the Fields Medal for mathematics in 2014 â€“ the first and only woman ever to receive the honour.</p>
<p>These are dramatic examples, but they show that the path to fulfilment isnâ€™t always smooth or direct. Once youâ€™ve come to terms with your loss, youâ€™ll find other passions. New dreams await.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>Come to terms with your decision</strong></p>
<p>As you let your dream go, you might be agonising over whether youâ€™re making a mistake. â€˜Thereâ€™s no good answer, thereâ€™s no formulaâ€™ for deciding whether to plough on or give up, says Wrosch. However, he recommends bearing in mind a phenomenon known as â€˜goal shieldingâ€™ â€“ when weâ€™re highly focused on a particular dream or ambition, we tend to filter out inconvenient information that might imperil the project. â€˜Motivational psychologists call it an â€œimplemental mindsetâ€�,â€™ says Wrosch. â€˜If you cross the Rubicon, you focus on what you want to achieve, and you donâ€™t have that balance [in how you process the situation] any more.â€™ For that reason, he says most us are, if anything, probably more at risk of stubbornly pursuing a dream for too long than giving up too early.</p>
<p>The author and entrepreneur Seth Godin agrees with Wrosch â€“ â€˜thereâ€™s no calculusâ€™ for deciding when to give up, he says. He too warns that most of us â€˜lie to ourselves all the time about whether we have the resources to get through the dipâ€™. â€˜The dipâ€™ is Godinâ€™s term â€“ taken from his 2007 <a href="https://www.penguinrandomhouse.com/books/300938/the-dip-by-seth-godin/" rel="nofollow noreferrer noopener">book</a> of the same name, and subtitled <em>A Little Book That Teaches You When to Quit (and When to Stick)</em> â€“ that he says refers to the â€˜difficult space in between the joy of starting and the benefit of getting to the other sideâ€™.</p>
<p>One way to think about this emotionally difficult moment is as a chance to be objective about your dream. Was pursuing it coming at great personal cost, in terms of your relationships and other goals in life? If so, that would suggest it was what psychologists call an â€˜obsessive passionâ€™ and youâ€™re wise to give it up (as distinct from a â€˜harmonious passionâ€™ that fits well into the rest of your life).</p>
<p>Also, try to think, if you can, more like a â€˜healthy perfectionistâ€™: recognise that letting go of your goals doesnâ€™t cast some final verdict on you as a person, and acknowledge the influence of circumstances beyond your control. Remember too that success isnâ€™t all or nothing â€“ although you might not have fulfilled your dream in its entirety, you will likely have learned much along the way, and you now have the chance to redirect your energy and passion in new ways. This is also a good time to seek the counsel of close family and friends. Theyâ€™ll be able to help you view your situation objectively and come to terms with your decision.</p>
<p><strong>Be realistic about what you just gave up</strong></p>
<p>When you decide to let go of a dream, itâ€™s almost inevitable that itâ€™s going to hurt, at least for a time, but there are ways to ease the discomfort and move on. â€˜My approach to this is starting with the tragic realism of it, that itâ€™s going to be hard, itâ€™s going to hurt,â€™ says Amarnani, who likens the experience of giving up a dream to a romantic breakup. â€˜To have an ambition is to have this vision of your future self, and to drop that is to drop a piece of you,â€™ he says.</p>
<p>That parallel with relationships offers an effective clue for how to cope. In the context of romantic relationships, Amarnani says that it can be therapeutic to be realistic, rather than idealistic, about the person youâ€™re breaking from, even to focus deliberately on their flaws. If weâ€™re honest, many of our dreams are romanticised, and itâ€™s worth remembering that what youâ€™re giving up is not that fantasy version of the future. We think of doctors as healing people, says Amarnani, or that staff at the United Nations are building peace, but then their daily reality is often far more mundane â€“ doctors are navigating the bureaucracy of their healthcare system; workers at the UN are pushing paperwork around.</p>
<p>Amarnani speaks partly from personal experience. He once harboured a dream to become a computational cognitive neuroscientist, but he suffered repeated rejections and then the financial crisis hit. He changed gears to become a management scholar â€“ â€˜I thought I was selling my soul,â€™ he says, â€˜but really what I was doing was just adjusting to the situation, being adaptable and trusting that, when you try something new, the passion will come.â€™ To help make peace with his decision, Amarnani focused on the negatives of the field he gave up â€“â€˜Decades of research on the brain has taught us next to nothing about the mindâ€™ â€“ and today he couldnâ€™t be happier that he gave up his dream. â€˜I grieved, genuinely,â€™ he says, â€˜but life does go on.â€™</p>
<p><strong>Find a new passion</strong></p>
<p>Itâ€™s a clichÃ© to say that one door closing means another opening, but itâ€™s true. By letting go of an impossible dream, youâ€™re freeing yourself to put time and effort into a potentially more rewarding project. Itâ€™s tempting to look at a high achiever such as Godin and assume that he arrived at his …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion">https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455014</guid>
            <pubDate>Thu, 17 Dec 2020 12:37:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Julia after 2 weeks]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454943">thread link</a>) | @the_origami_fox
<br/>
December 17, 2020 | https://liorsinai.github.io/coding/2020/12/15/julia-review.html | <a href="https://web.archive.org/web/*/https://liorsinai.github.io/coding/2020/12/15/julia-review.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>

        <p><em>Julia is a fast, flexible and robust language. Having used Julia for 2 weeks, and Python for 7 years, I can already say I prefer Julia. It is not as mature as Python, but I believe it has the potential to far exceed it.</em></p>



<p>It was Ars Technica’s “<a href="https://arstechnica.com/science/2020/10/the-unreasonable-effectiveness-of-the-julia-programming-language/">The unreasonable effectiveness of the Julia programming language</a>” that finally convinced me to learn the Julia programming language.
For years, I’ve heard whispers and glowing praises about Julia. 
It’s a dynamic programming language, but is said to be much faster than Python, and even as fast as C.
The terse, clean syntax is supposed to allow very generic but also robust code creation, reducing friction to collaboration. 
On top of that, it has math friendly syntax like in Matlab or R but also with real maths symbols. 
All of this has been driving adoption of Julia in academia, a highly scientific, collaborative environment with very high computational needs.
The adoption in industry has been predictably slower.</p>

<figure id="SIR model">
<img src="https://liorsinai.github.io/assets/posts/julia-review/SIR%20epidemic%20model.png" alt="SIR model">
	<figcaption>A snapshot of agents moving around a grid with an infection spreading when they touch, and the resulting infection outbreak graphs. Generated by the author using Julia.</figcaption>
</figure>

<p>So does Julia live up to the hype? I decided to find out.
To this end, I completed the recently released Julia Academy course “<a href="https://juliaacademy.com/p/computational-modeling-in-julia-with-applications-to-the-covid-19-pandemic">Computational Modeling in Julia with Applications to the COVID-19 Pandemic</a>”.
This is a 16 hour course which works with real Covid-19 pandemic data, and teaches you how to implement SIR epidemiology models as well.<sup id="fnref:SIR" role="doc-noteref"><a href="#fn:SIR">1</a></sup>
See the above picture.
After completing this course I challenged myself to rewrite my Random Forest Python <a href="https://github.com/LiorSinai/randomForests">code</a> in Julia and also my corresponding blog <a href="https://liorsinai.github.io/coding/2020/09/29/random-forests.html">post</a>.
You can see the Julia code <a href="https://github.com/LiorSinai/RandomForest-jl">here</a> and the twin blog post <a href="https://liorsinai.github.io/coding/2020/12/14/random-forests-jl.html">here</a>. 
This resulted in code of similar length, but that was 9 times faster and that felt much more robust.</p>

<p>The table below has a quick comparison of the Python and Julia Random Forests fitting times.
This was on the <a href="https://www.kaggle.com/sriharipramod/bank-loan-classification/">Universal Bank Loan</a> data, with 4000 training samples and 1000 test samples.
The random forest had 20 trees, with each tree having 40 to 120 leaves. 
Tests were run from the Anaconda CMD and Julia REPL.</p>
<table>
<caption>*after first compile run for Julia. Time to first compile was 4.6s</caption>
<thead>
  <tr>
    <th> </th>
    <th>Number of runs</th>
    <th>Scikit-learn</th>
    <th>Python</th>
    <th>Julia</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Fitting time (s)*</td>
    <td>10</td>
    <td>0.04810 ± 0.00951</td>
    <td>6.87132 ± 0.31106</td>
    <td>0.73991 ± 0.04208</td>
  </tr>
  <tr>
    <td>ratio mean times</td>
    <td>10</td>
    <td>1.00</td>
    <td>142.85</td>
    <td>15.38</td>
  </tr>
  <tr>
    <td>test accuracy (%)</td>
    <td>10</td>
    <td>98.43 ± 0.58</td>
    <td>98.56 ±  0.46</td>
    <td>98.66 ± 0.37</td>
  </tr>
</tbody>
</table>
<p>Scikit-learn (written in Cython) is still the fastest, but that code is more heavily optimised than mine, and also it use parallel processing.</p>

<p>In general, my experience with Julia was very positive. 
It is indeed fast and powerful, and the syntax is very nice.
It is not an upgrade to Python, but I am going to frame much of this article as such.
It operates under some very different paradigms - for example, Julia is very much a functional programming language, whereas Python is object-orientated.
The creators themselves tried to integrate the best of several different languages into Julia including Python, R, Matlab, Ruby, C and Lisp
(see their 2012 <a href="https://julialang.org/blog/2012/02/why-we-created-julia/">release statement</a>). But my experience is mostly with Matlab, C++ and Python. 
Of these, Julia is most likely to replace the code I write with Python.</p>

<p>C++ is a complex and powerful static typed language with memory management capabilities, and I don’t see Julia replacing mission critical software written with it.
Matlab is proprietary software which has great support for specialised scientific computing.
Its Simulink control software and image processing toolbox are the nicest of their kind that I’ve used.
Python, however, is a different story.</p>

<p>Python is easy to learn and lovely to tinker with, but as soon as your project expands that joy dissipates.
It’s noticeably slower than other languages. It has no type checking and very generous scoping rules.
This makes you think less when writing your own code, which is great, but it makes you think <em>more</em> when reviewing someone else’s.
Did they intend this variable to be an array? A string? A custom type? Have I accidently reused an identifier?
Popular packages go out of their way to <em>not</em> use Python for core processing, including Numpy, Scikit-learn and TensorFlow (they use, C, C++ and Cython).
Julia promises to fix these many issues, and it’s a relief.</p>

<p>I want to state upfront that my main frustration with Julia is that it is not as mature as Python.
The release of Julia 1.0 was just over two years ago; Python 1.0 was released 25 years ago.
The Julia community is playing catch-up with Python and has the second-mover advantage of knowing what works and what doesn’t.
But there simply are not as many packages, features, tutorials or videos as Python has. 
Fewer people ask questions on StackOverflow or Discourse.
Like many open-source projects, the documentation is often lacking.<sup id="fnref:pie" role="doc-noteref"><a href="#fn:pie">2</a></sup>
The language itself is changing fast, and some code on Julia Academy’s own online tutorials is already out of date.<sup id="fnref:out_of_date" role="doc-noteref"><a href="#fn:out_of_date">3</a></sup>
Then there is all the massive amounts of legacy code in companies and institutions.
So if you’re a beginner programmer, you can stop reading now. My advice is focus on Python. It has more resources and will get you further.
But if you can relate to my frustrations with Python or have more of your own, read on.</p>



<p>So what makes Julia special? A good summary is given by Serdar Yegulalp at <a href="https://www.infoworld.com/article/3241107/julia-vs-python-which-is-best-for-data-science.html">www.infoworld.com</a>, which I’ll briefly repeat here:</p>

<ul>
  <li>Julia is just-in-time (JIT) compiled, not interpreted. Furthermore, it is type-specific compiled for each datatype. 
For example, the same function will be compiled differently if integers are passed to it instead of floats. 
This means compiled Julia code can be heavily optimised and therefore is fast.
A downside is that the first call where JIT compiling takes place is slow.
A more detailed explanation can be found at <a href="http://www.stochasticlifestyle.com/7-julia-gotchas-handle/">ww.stochasticlifestyle.com/7-julia-gotchas-handle/</a>.</li>
  <li>Julia uses multiple dispatch to combine the benefits of dynamic typing and static typing. 
In short, multiple methods with different argument types can exist for a single function and Julia will choose the best one to use at compile time.
To facilitate  this, Julia has a comprehensive type system which can easily be extended.
This <a href="https://www.youtube.com/watch?v=kc9HwsxE1OY">video</a> by one of the founders explains this concept the best.</li>
  <li>Julia has a terse and straightforward syntax. It has 32 keywords (compared to Python’s 35 and C++’s original 63, now 97). 
Of these, 16 have a direct parallel with a Python keyword.</li>
  <li>Julia comes with expansive Base and Core modules. A further 12 of the Python keywords are provided by functions and operators in these modules.
These modules are mostly written in Julia which makes them easily accessible and extendable.</li>
  <li>Julia has full Unicode support and mathematical-like notation. The following is a fully working piece of code which can be copied directly into the Julia REPL: 
<span><code>gaussian(x, μ, σ) = 1/(σ*√(2π))*exp(-(x-μ)^2/(2σ^2))</code></span>. A disadvantage is that string indexing sometimes breaks because Unicode characters can take two or more bytes. 
So Base functions like <code>isascii()</code>, <code>nextind()</code> and <code>eachind()</code> should be used to handle strings properly.</li>
  <li>Julia supports metaprogramming, such as macros (like in C++) and creating expression objects with the keyword <code>quote</code>. So Julia programs can generate other Julia programs.</li>
  <li>Julia can call Python, C, and Fortran libraries. This is presumably to facilitate  crossover to Julia.</li>
</ul>

<p>The next three sections are <a href="#Things I like about Julia">Things I like about Julia</a>, <a href="#Neutral issues about Julia">Neutral issues about Julia</a>, 
and <a href="#Things I dislike about Julia">Things I dislike about Julia</a>.
Lastly there are small <a href="#Annoyances">Annoyances</a> I would like to vent after using it for 2 weeks.
I guess no programming language is perfect.</p>

<h2 id="things-i-like-about-julia">Things I like about Julia<a id="Things I like about Julia"></a></h2>

<p>Like all programming languages, there was a learning curve to Julia. This was made more difficult by the lack of resources. 
However generally it was easy to learn coming from a Python background and there are many things I definitely  prefer about Julia.</p>

<h4 id="the-type-system-and-multiple-dispatch">The type system and multiple dispatch</h4>
<p>This really does balance controlling types with giving the user flexibility.
For my random forest <a href="https://github.com/LiorSinai/RandomForest-jl">code</a>, it essentially provided a way to make object specific functions, even though Julia is a functional language.
For example, the <a href="https://github.com/LiorSinai/RandomForest-jl/blob/89a948fe30c22bb92947f7016f7ca25135e1720b/DecisionTree.jl#L203"><code>DecisionTreeClassifier</code></a> and <a href="https://github.com/LiorSinai/RandomForest-jl/blob/89a948fe30c22bb92947f7016f7ca25135e1720b/RandomForest.jl#L104"><code>RandomForestClassifier</code></a> have different <code>fit!()</code> methods associated with each of them.
I had no problem calling the <code>DecisionTreeClassifier</code> <code>fit!()</code> method from within the  <code>RandomForestClassifier</code> <code>fit!()</code> method.</p>

<p>A mistake I made at first is to use <code>AbstractFloat</code> inside the struct, whereas the recommendation is to always have concrete types in definitions.
This definitely slowed down my code, which is why I added the type to the struct definition: <code>DecisionTreeClassifier{T}</code>.
I also added an outer constructor to set this to <code>Float64</code> as a default.</p>

<p>Multiple dispatch can easily be abused because finding the best fit is a problem that grows exponentially with the number of different arguments.
However most functions have a very low number of methods associated with them.<sup id="fnref:exceptions" role="doc-noteref"><a href="#fn:exceptions">4</a></sup>
Another fault is that sometimes it is not fully unambiguous which method should be called, especially with <code>Union</code> data types. 
But this is being worked on and clearer rules should be published in the future.</p>

<p>A prime advantage of the type system is on display with my <a href="https://github.com/LiorSinai/RandomForest-jl/blob/89a948fe30c22bb92947f7016f7ca25135e1720b/Classifier.jl#L35"><code>score()</code></a> function. 
For my Python code, I wrote a separate score function inside the <code>DecisionTreeClassifier</code> and <a href="https://github.com/LiorSinai/randomForests/blob/1b3737097e8d80a947aa880ce20038db09016383/TreeEnsemble.py#L98"><code>RandomForestClassifier</code></a> classes.
They are however essentially identical functions.
For my Julia code, I wrote a single function which takes in a type of <code>AbstractClassifier</code>. 
Since I defined both my classifiers to be subtypes of <code>AbstractClassifier</code>, calling score on those objects dispatches to this <code>score</code> function.</p>

<p>Of course you can argue I could have made a super class in Python which implements <code>score</code>, and then have both <code>DecisionTreeClassifier</code> and <code>RandomForestClassifier</code> inherit from it.
However this adds complexity without much benefit.
In Julia, there is a robust type system and it makes sense to follow those design patterns.</p>

<p>Another use case is with my <a href="https://github.com/LiorSinai/RandomForest-jl/blob/89a948fe30c22bb92947f7016f7ca25135e1720b/Utilities.jl#L65"><code>calc_f1_s…</code></a></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://liorsinai.github.io/coding/2020/12/15/julia-review.html">https://liorsinai.github.io/coding/2020/12/15/julia-review.html</a></em></p>]]>
            </description>
            <link>https://liorsinai.github.io/coding/2020/12/15/julia-review.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454943</guid>
            <pubDate>Thu, 17 Dec 2020 12:25:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Great Covid Class War]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454874">thread link</a>) | @DeusExMachina
<br/>
December 17, 2020 | https://www.thebellows.org/the-great-covid-class-war | <a href="https://web.archive.org/web/*/https://www.thebellows.org/the-great-covid-class-war">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.thebellows.org/the-great-covid-class-war</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454874</guid>
            <pubDate>Thu, 17 Dec 2020 12:13:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome Extensions Every Web Developer Needs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454736">thread link</a>) | @shahednasser
<br/>
December 17, 2020 | https://shahednasserblog.tk/chrome-extensions-every-programmer-needs/ | <a href="https://web.archive.org/web/*/https://shahednasserblog.tk/chrome-extensions-every-programmer-needs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><section><p>As a web developer, you might face a lot of tedious and repetitive tasks, or tasks that can be a hassle to manually do.</p><p>I have curated for you a list of Chrome extensions that will make your everyday work easier!</p><hr><h2 id="colorzilla"><a href="https://chrome.google.com/webstore/detail/colorzilla/bhlhnicpbhignbdhedgjhgdocnmhomnp?hl=en">ColorZilla</a></h2><figure><img src="https://res-4.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/colorzilla.jpg.jpg"></figure><p>I use ColorZilla almost every day. It's a great help to get a color from any website or image, and as a web developer you'll need that a lot. </p><hr><h2 id="pushbullet"><a href="https://chrome.google.com/webstore/detail/pushbullet/chlffgpmiacpedhhbkiomidkjlcfhogd?hl=en">Pushbullet</a></h2><figure><img src="https://res-5.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/pushbullet.jpg"></figure><p>Pushbullet is great for all people in general, especially for work. It makes communication between your devices or team easier. You can send to your devices or team links, images, or any kind of messages. You can also check your devices' notifications and SMS.</p><hr><h2 id="gitpod"><a href="https://chrome.google.com/webstore/detail/gitpod-dev-environments-i/dodmmooeoklaejobgleioelladacbeki?hl=en">Gitpod</a></h2><figure><img src="https://res-5.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/gitpod.jpg"></figure><p>If you don't know what <a href="https://gitpod.io/">Gitpod</a> is, it basically lets you create a remote environment for your repositories. Integrated with GitHub, you can open any repository in Gitpod and create a workspace that you can access from anywhere.</p><p>This extension helps make it easier to open any repository in Gitpod right away just by clicking on the extension icon when you are in the repository's page.</p><hr><h2 id="fake-data-a-form-filler-you-won-t-hate"><a href="https://chrome.google.com/webstore/detail/fake-data-a-form-filler-y/gchcfdihakkhjgfmokemfeembfokkajj?hl=en">Fake Data - A form filler you won't hate</a></h2><figure><img src="https://res-1.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/fake-data.jpg"></figure><p>When you are testing your websites, testing forms repeatedly and with real looking data (i.e. not "abcd") can be time consuming. With Fake Data, you can right click on any input and choose a fake value for the input. It includes values for first names, email, city, country, password, and more. You can also add custom types and values to it from the extension's settings.</p><hr><figure><img src="https://res-2.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/social-share-preview.jpg"></figure><p>SEO is very important for any website, and one of the most important parts about it is how your website or webpage will look like when it is shared on social media like Facebook, Twitter, and other platforms. Social Share Preview makes it easy to check by just clicking the extension's icon on the page you want to check. It will show you a preview of how your website will look like when it is shared, and will give you some tips on how to fix problems if there are any.</p><hr><h2 id="awesome-screenshot-screen-recorder"><a href="https://chrome.google.com/webstore/detail/awesome-screenshot-screen/nlipoenfbbikpbjkfpfillcgkoblgpmj?hl=en">Awesome Screenshot &amp; Screen Recorder</a></h2><figure><img src="https://res-1.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/awesome-screenshot.jpg"></figure><p>This one is also not specific for programmers, however it can be helpful. This extension helps you record or screenshot the screen in your browser easily and with additional options like choosing just the visible part of the page or entire page, as well as other options.</p><hr><h2 id="html-error-checker"><a href="https://chrome.google.com/webstore/detail/html%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%81%E3%82%A7%E3%83%83%E3%82%AB%E3%83%BC/ohdllebchmmponnofchalfkegpjojcaf?hl=en">HTML Error Checker</a></h2><figure><img src="https://res-5.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/html-error-checker.jpg"></figure><p>You can't always spot HTML errors like forgetting to close a tag or closing one too early. This can affect your website and sometimes you won't even notice it until later on. This extension helps you find any errors on the website you're on.</p><p><strong>NOTE: </strong>For some reason, this extension caused some problems when trying to log in to phpmyadmin when it is pinned.</p><hr><h2 id="web-developer-checklist"><a href="https://chrome.google.com/webstore/detail/web-developer-checklist/iahamcpedabephpcgkeikbclmaljebjp?hl=en-US">Web Developer Checklist</a></h2><figure><img src="https://res-4.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/web-developer-checklist.jpg"></figure><p>Web Developer Checklist helps you remember all the details necessary for your website. A lot of tasks when making websites can be forgotten, especially when focusing on the bigger parts. By clicking the icon of the extension on the webpage, you can see any violations to best practices.</p><hr><h2 id="webpage-spell-check"><a href="https://chrome.google.com/webstore/detail/webpage-spell-check/mgdhaoimpabdhmacaclbbjddhngchjik">Webpage Spell-Check</a></h2><figure><img src="https://res-3.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/webpage-spell-checker.jpg"></figure><p>Typos can be hard to spot on the website. This extension enables you to check typos by making all the text on your website editable, and thus using the browser's out-of-the-box spell-checker to find the typos.</p><hr><h2 id="web-developer"><a href="https://chrome.google.com/webstore/detail/web-developer/bfbameneiokkgbdmiekhjnmfkcnldhhm">Web Developer</a></h2><figure><img src="https://res-3.cloudinary.com/hbqmf3mbz/image/upload/q_auto/v1/ghost-blog-images/web-developer.jpg"></figure><p>Web Developers extension basically gives super powers in an extension. It gives you so many functionalities that can be helpful while you develop websites and remove a lot of hassles that you can run into.</p><hr><h2 id="conclusion">Conclusion</h2><p>These are just some of the extensions that can make your life as a developer a little easier, but there are many others out there. Please add any extensions you think are also helpful below in the comments!</p></section></section></div>]]>
            </description>
            <link>https://shahednasserblog.tk/chrome-extensions-every-programmer-needs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454736</guid>
            <pubDate>Thu, 17 Dec 2020 11:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deprecating Excalidraw Electron in favor of the Web version]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454687">thread link</a>) | @markdog12
<br/>
December 17, 2020 | https://blog.excalidraw.com/deprecating-excalidraw-electron/ | <a href="https://web.archive.org/web/*/https://blog.excalidraw.com/deprecating-excalidraw-electron/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.excalidraw.com/deprecating-excalidraw-electron/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454687</guid>
            <pubDate>Thu, 17 Dec 2020 11:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Suspend COVID19 patents the time of the pandemic, says Curevac]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454609">thread link</a>) | @zoobab
<br/>
December 17, 2020 | https://www.stuttgarter-zeitung.de/inhalt.kampf-gegen-corona-curevac-patente-fuer-impfstoffe-aussetzen.568f0c24-6dd1-4724-a46f-8683d53c8444.html | <a href="https://web.archive.org/web/*/https://www.stuttgarter-zeitung.de/inhalt.kampf-gegen-corona-curevac-patente-fuer-impfstoffe-aussetzen.568f0c24-6dd1-4724-a46f-8683d53c8444.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.stuttgarter-zeitung.de/inhalt.kampf-gegen-corona-curevac-patente-fuer-impfstoffe-aussetzen.568f0c24-6dd1-4724-a46f-8683d53c8444.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454609</guid>
            <pubDate>Thu, 17 Dec 2020 11:29:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React vs. Angular vs. Vue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454595">thread link</a>) | @oczek
<br/>
December 17, 2020 | https://blog.graphqleditor.com/react-angular-vue/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/react-angular-vue/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.graphqleditor.com/react-angular-vue/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454595</guid>
            <pubDate>Thu, 17 Dec 2020 11:27:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Covid-19 Pandemic and the Art of Geo Time Series]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25454448">thread link</a>) | @MorganeR
<br/>
December 17, 2020 | https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
<p>As <a rel="noreferrer noopener" href="https://senx.io/" target="_blank">SenX</a> enters its second week of remote work, I thought it would be a good time to write about the importance of time and <a href="https://blog.senx.io/working-with-geo-data-in-warp-10/" target="_blank" rel="noreferrer noopener">geo time series</a> during a pandemic like the one we are experiencing with the coronavirus and the associated COVID-19.</p>



<p>For millions if not billions of people on Earth, <strong>some time series has become the most important thing to look at.</strong> Whether it is the #FlattenTheCurve graph or the Hammer and the dance illustration, or the various graphs showing the evolution of the number of cases, recovering patients, and unfortunately deaths, those are all-time series, i.e. graphs whose x-axis represents the time and the y-axis the evolution of tracked quantities.</p>



<figure><img src="https://media.wired.com/photos/5e6aac7295ff060008467cf9/master/w_1600%2Cc_limit/Science_Covid19-Infographic.jpg" alt="Coronavirus COVID-19 #FlattenTheCurve strategy"><figcaption>#FlattenTheCurve</figcaption></figure>



<h2>Contact Tracing</h2>



<p>But another trend about to begin will bring people exposed even more to time series. As the world learns how countries such as Singapore, South Korea, or Taiwan have dealt with the COVID-19 outbreak, the notion of <a href="https://en.wikipedia.org/wiki/Contact_tracing" target="_blank" rel="noreferrer noopener">Contact Tracing</a> has appeared in the media and will soon be in everybody's mouth.</p>



<p>The reaction to that notion, which is widely used in public health but may appear new to many, varies from country to country, and among countries varies with culture, political background, or religious belief. Some are considering it as the end of privacy and liberty. The others as a salvation technique or more moderate ones as a good temporary tactic for fighting the outbreak.</p>



<h3>But what exactly is contact tracing? </h3>



<p>The idea is very simple. It keeps a log of who you came close to so when someone gets tested positive with COVID-19 his or her log can be accessed. The people appearing in the log can be contacted to test them too. Logs used to be your memory, now with the advent of technology they can be tracked automatically.</p>



<p>By relying on those automated logs, the sphere of contagion of the newly discovered patient can easily be determined from the patient's own log and from those of the people that were in contact with that patient with the same process being extended as individuals are tested positive.</p>



<h3>How are the people you came in contact with identified? </h3>



<p>Well, that is rather simple, with the help of technology. Contact tracing relies on a mobile app which exploits the <strong>Bluetooth signal of the phone</strong> it is installed on. Bluetooth is a short-range radio system. It means that it cannot be transmitted more than a few meters. So technically if you can receive the Bluetooth signal from another phone, then this phone is in the vicinity of yours. </p>


<span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D9855&amp;text=Due%20to%20COVID-19%2C%20for%20millions%20of%20people%2C%20some%20time%20series%20has%20become%20the%20most%20important%20thing%20to%20look%20at.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Due to COVID-19, for millions of people, some time series has become the most important thing to look at. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D9855&amp;text=Due%20to%20COVID-19%2C%20for%20millions%20of%20people%2C%20some%20time%20series%20has%20become%20the%20most%20important%20thing%20to%20look%20at.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span>


<p>When that happens, the mobile application adds an entry to its log, saying it saw a signal from another application. The id logged is a random id that is assigned to your phone at the time you installed the app. <strong>Only the organization responsible for the application can associate this random id with your phone number</strong>. So yes, you should trust this organization for willing to not do evil.</p>



<p>That is all there is to it, contact tracing in a few paragraphs. </p>



<h3>Back to our own topic now </h3>



<p>The log kept by the contact tracing application has one important component, <strong>the timestamping</strong> of the entries. Because if you came in contact with someone more than 21 days ago (roughly the longest incubation period for COVID-19), then there is no need to contact that person as you were probably not contagious when you two came close. So yes, the base of contact tracing is recording time series and later analyzing them to reconstruct a timed graph of interactions.</p>



<figure></figure>



<h2>What about Warp 10?</h2>



<p><a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10</a> is our advanced time series platform. It can be used to analyze those time series, even at a large scale, at the scale of a whole population if need be. So any agency willing to put contact tracing in place should contact us, we can help.</p>



<p>Note that beyond the contact tracing some countries have used in the case of the COVID-19 pandemic, there might be some other situations where more information may need to be collected, most notably actual location data when a pathogen agent is really contagious and can stay in the environment and spread without human to human contact. In that case, besides obvious debates about privacy or lack thereof that would be legitimate to have, the data collected are no longer simply time series but geo time series. And there again Warp 10 can help to analyze them.</p>



<p>The weeks to come will undoubtedly bring on the table the question of contact tracing. I hope this article helped you understand better how it works. The social implication of contact tracing will need to be balanced with the benefit that it can bring to fighting the ongoing pandemic. When those debates will have settled, remember that technology such as Warp 10 can help analyze those data fast.</p>



<p><strong>Keep safe, stay at home!</strong></p>



<p>The Ministry of Health of Singapore just announced it would be open-sourcing its own contact tracing application is used for fighting the COVID-19 outbreak.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454448</guid>
            <pubDate>Thu, 17 Dec 2020 10:59:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[51% of 4M Docker images have critical vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 323 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25454207">thread link</a>) | @AnnieNma
<br/>
December 17, 2020 | https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454207</guid>
            <pubDate>Thu, 17 Dec 2020 10:09:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to debug Elixir/Erlang compiler performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454147">thread link</a>) | @wojtekmach
<br/>
December 17, 2020 | https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> December 15th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/compiler">compiler</a>, <a href="https://dashbit.co/blog/tags/performance">performance</a>
  </li>
</ul>
<p>
Recently someone opened up an <a href="https://github.com/elixir-gettext">issue on Gettext</a> saying compilation of Gettext modules got slower in Erlang/OTP 23. In this article, we are going to explore how I have debugged this problem and the three separate pull requests sent to the Erlang/OTP repository to improve compiler performance.</p>
<p>
For those not familar, the Gettext project converts <code>.po</code> files like this:</p>
<pre><code># pt
msgid "Hello world"
msgstr "Olá mundo"

# pl
msgid "Hello world"
msgstr "Witaj świecie"</code></pre>
<p>
Into a module with functions:</p>
<pre><code><span>def</span><span> </span><span>translate</span><span data-group-id="9576884584-1">(</span><span>"pt"</span><span>,</span><span> </span><span>"Hello world"</span><span data-group-id="9576884584-1">)</span><span>,</span><span> </span><span>do</span><span>:</span><span> </span><span>"Olá mundo"</span><span>
</span><span>def</span><span> </span><span>translate</span><span data-group-id="9576884584-2">(</span><span>"pl"</span><span>,</span><span> </span><span>"Hello world"</span><span data-group-id="9576884584-2">)</span><span>,</span><span> </span><span>do</span><span>:</span><span> </span><span>"Witaj świecie"</span></code></pre>
<p>
While we start with an Elixir application, we end-up doing most of the work with the Erlang compiler and tools, so most of the lessons here are applicable to the wider ecosystem. Be sure to read until the end for a welcome surprise.</p>
<h2>
Isolating the slow file</h2>
<p>
When project compilation is slow, the first step is to identify which files are slow. In Elixir v1.11, this can be done like this:</p>
<pre><code>$ mix compile --force --profile time</code></pre>
<p>
The command above will print:</p>
<pre><code>...
[profile] lib/ecto/query/planner.ex compiled in 1376ms (plus 596ms waiting)
[profile] lib/ecto/association.ex compiled in 904ms (plus 1168ms waiting)
[profile] lib/ecto/changeset.ex compiled in 869ms (plus 1301ms waiting)
[profile] Finished compilation cycle of 95 modules in 2579ms
[profile] Finished group pass check of 95 modules in 104ms</code></pre>
<p>
Compilation of each file in your project is done in parallel. The overall message is:</p>
<pre><code>[profile] FILE compiled in COMPILE_TIME (plus WAITING_TIME waiting)</code></pre>
<p>
<code>COMPILE_TIME</code> is the time we were effectively compiling code. However, since a file may depend on a module defined in another file, <code>WAITING_TIME</code> is the time we wait until the file we depend on becomes available. High waiting times are not usually a concern, so we focus on the files with high compilation times.</p>
<p>
At the end, we print two summaries:</p>
<pre><code>[profile] Finished compilation cycle of 95 modules in 2579ms
[profile] Finished group pass check of 95 modules in 104ms</code></pre>
<p>
The first includes the time to compile all files in parallel and includes how many modules have been defined. The second is the time to execute a group pass which looks at all modules at once, in order to find undefined functions, emit deprecations, etc.</p>
<p>
Unless the “group pass check” is the slow one - which would be a bug in the Elixir compiler - we are often looking at a single file being the root cause of slow compilation. With this file in hand, it is time to dig deeper.</p>
<h2>
Timing the slow file</h2>
<p>
Once we have identified the slow file, we need to understand why it is slow. When Elixir compiles a file, it executes code at three distinct stages. For example, let’s assume the slow down was in <code>lib/problematic_file.ex</code> that looks like this:</p>
<pre><code><span># FILE LEVEL</span><span>
</span><span>defmodule</span><span> </span><span>ProblematicModule</span><span> </span><span data-group-id="0623758596-1">do</span><span>
  </span><span># MODULE LEVEL</span><span>
  </span><span>def</span><span> </span><span>function</span><span> </span><span data-group-id="0623758596-2">do</span><span>
    </span><span># FUNCTION LEVEL</span><span>
  </span><span data-group-id="0623758596-2">end</span><span>
</span><span data-group-id="0623758596-1">end</span></code></pre>
<p>
When compiling the file above, Elixir will execute each level in order. If that file has multiple modules, then compilation will happen for each module in the file, first at MODULE LEVEL and then FUNCTION LEVEL.</p>
<blockquote>
  <p>
TIP: If a file with multiple modules is slow, I suggest breaking those modules into separate files and repeating the steps in the previous section.  </p>
</blockquote>
<p>
With this knowledge in hand, we want to compile the file once again, but now passing the <code>ERL_COMPILER_OPTIONS=time</code> flag to the underlying Erlang compiler, which will print time reports. One option is to do this:</p>
<pre><code>$ mix compile
$ touch lib/problematic_file.ex
$ ERL_COMPILER_OPTIONS=time mix compile</code></pre>
<p>
Then, for each module being compiled (which includes the one in your <code>mix.exs</code>), you will see a report like this:</p>
<pre><code>core             :  0.653 s   72136.4 kB
sys_core_fold    :  0.482 s   69055.3 kB
sys_core_alias   :  0.146 s   69055.3 kB
core_transforms  :  0.000 s   69055.3 kB
sys_core_bsm     :  0.098 s   69055.3 kB
v3_kernel        :  2.250 s  169439.0 kB</code></pre>
<p>
Most compilers work by doing multiple passes on your code. Above we can see how much time was spent on each pass and how much memory the code representation, also known as Abstract Syntax Tree (AST), takes after each pass.</p>
<p>
The <code>ERL_COMPILER_OPTIONS=time mix compile</code> command above has one issue though. If other files depend on the problematic file, they may be recompiled too, and that will add noise to your output. If that’s the case, you can also do this:</p>
<pre><code>$ ERL_COMPILER_OPTIONS=time mix run lib/problematic_file.ex</code></pre>
<p>
This is a rather neat trick: we are re-running a file that we have just compiled. You will get warnings about modules being redefined but they are safe to ignore.</p>
<p>
With the time reports in hand, there are two possible scenarios here:</p>
<ol>
  <li>
    <p>
One (or several) of the passes in the report are slow. This means the slow down happens when compiling at the FUNCTION LEVEL and it will be associated with the generation of the <code>.beam</code> file for <code>ProblematicModule</code>    </p>
  </li>
  <li>
    <p>
All passes are fast and the slow down happens before the reports emitted by <code>ERL_COMPILER_OPTIONS=time</code> are printed. If this is the case, the slowdown is actually happening at the MODULE LEVEL, before the generation of the <code>.beam</code> file    </p>
  </li>
</ol>
<p>
Most times, the slowdown is actually at the FUNCTION LEVEL, including the one reported as a Gettext issue, so that’s the one we will explore. Performance issues at the MODULE LEVEL may still happen though, especially in large module bodies as seen in Phoenix’s Router - but don’t worry, those have often already been optimized throughout the years!</p>
<h2>
Moving to Erlang</h2>
<p>
At this point, we have found a module that is slow to compile. Given the original Gettext issue pointed to a difference of performance between Erlang versions, my next step is to remove Elixir from the equation.</p>
<p>
Luckily, this is very easy to do with the <a href="https://github.com/michalmuskala/decompile">decompile</a> project:</p>
<pre><code>$ mix archive.install github michalmuskala/decompile
$ mix decompile ProblematicModule --to erl</code></pre>
<p>
This command will emit a <code>Elixir.ProblematicModule.erl</code> file, which is literally the compiled Elixir code, represented in Erlang. Now, let’s compile it again, but without involving Elixir at all:</p>
<pre><code>$ erlc +time Elixir.ProblematicModule.erl</code></pre>
<blockquote>
  <p>
TIP: the command above may not work out of the box. That’s because the <code>.erl</code> file generated by <code>decompile</code> may have invalid syntax. In those cases, you can manually fix those errors. They are often small nits.  </p>
</blockquote>
<p>
If you want to try it yourself, you can <a href="https://gist.github.com/josevalim/694c1799143fcf25e43aa27e3e11e4c1">find the <code>.erl</code> file for the Gettext report here</a>:</p>
<pre><code>$ erlc +time Elixir.GettextCompile.Gettext.erl</code></pre>
<p>
Here are the relevant snippets of the report I got on my machine:</p>
<pre><code>...
expand_records         :      0.065 s   19988.0 kB
core                   :      3.295 s  373293.3 kB
...
beam_ssa_bool          :      1.125 s   39252.7 kB
...
beam_ssa_bsm           :      2.432 s   39263.1 kB
   ...
beam_ssa_funs          :      0.119 s   39263.1 kB
beam_ssa_opt           :      6.242 s   39298.0 kB
   ...
...
beam_ssa_pre_codegen   :      3.426 s   48897.5 kB
   ...
...</code></pre>
<p>
Looking at the report you can start building an intuition about which passes are slow. Given we were also told the code compiled fast on Erlang/OTP 22.3, I compiled the same file with that Erlang version and compared the reports side by side. Here are my notes:</p>
<ol>
  <li>
    <p>
The <code>core</code> pass got considerably slower between Erlang/OTP versions (from 1.8s to 3.2s)    </p>
  </li>
  <li>
    <p>
Going from the <code>expand_records</code> pass to <code>core</code> increases the memory usage by almost 20 times (although this behaviour was also there on Erlang/OTP 22)    </p>
  </li>
  <li>
    <p>
The <code>beam_ssa_bool</code> did not exist on Erlang/OTP 22    </p>
  </li>
</ol>
<p>
In Erlang/OTP 22.3, the module takes 22 seconds to compile. On version 23.1, it takes 32 seconds. We have some notes and a reasonable target of 22 seconds to optimize towards. Let’s get to work.</p>
<blockquote>
  <p>
Note: it is worth saying that it is very natural for new passes to be added and others to be removed between Erlang/OTP versions, precisely because the compiler is getting smarter all the time! As part of this process, some passes get faster and others get slower. Such is life. :)  </p>
</blockquote>
<h2>
Pull request #1: the profiler option</h2>
<p>
The Erlang compiler also has a neat feature that alows us to profile any compiler pass. Since we have detected the slow down in the <code>core</code> file, let’s profile it:</p>
<pre><code>$ erlc +'{eprof, core}' Elixir.ProblematicModule.erl</code></pre>
<p>
It will print a report like this:</p>
<pre><code>core: Running eprof

****** Process &lt;0.111.0&gt;    -- 100.00 % of profiled time ***
FUNCTION                   CALLS        %      TIME  [uS / CALLS]
--------                   -----  -------      ----  [----------]
gen:do_for_proc/2              1     0.00         0  [      0.00]
gen:'-call/4-fun-0-'/4         1     0.00         0  [      0.00]
v3_core:unforce/2              2     0.00         0  [      0.00]
v3_core:make_bool_switch/5     2     0.00         0  [      0.00]
v3_core:expr_map/4             1     0.00         0  [      0.00]
v3_core:safe_map/2             1     0.00         0  [      0.00]</code></pre>
<p>
With the slowest entries coming at the bottom. In this Gettext module, the slowest entry was:</p>
<pre><code>cerl_trees:mapfold/4     3220377    19.14   2447684  [      0.76]</code></pre>
<p>
Jackpot! 20% of the compilation time was spent on a single function. This is a great opportunity for optimization.</p>
<p>
I usually like to say there are two types of performance improvements. You have semantic improvements, which you can only pull off by having a grasp of the domain. The more you understand, the more likely you are to be able to come up with an improved algorithm (or the more you will be certain you are already implementing the state of the art). There are also mechanical improvements, which are more about how the runtime and the data structures in the language work. Often you work with a mixture of both.</p>
<p>
In this case, the function <code>cerl_trees:mapfold/4</code> is a function that traverses all AST nodes recursively. You can also see it was called more than 3 million times. The <a href="https://github.com/erlang/otp/blob/db13f8883721c7a217a80cb2c73a1e419f462d83/lib/compiler/src/v3_core.erl#L3040">caller of this function in the <code>core</code> pass has the following goal</a>:</p>
<blockquote>
  <p></p></blockquote></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance">https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454147</guid>
            <pubDate>Thu, 17 Dec 2020 09:57:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto in Layman's Terms]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453703">thread link</a>) | @alex_portabella
<br/>
December 17, 2020 | https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/ | <a href="https://web.archive.org/web/*/https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This is a post I've been wanting to write for a while now. I want to put down in layman's terms what various cryptographic operations represent, and common use cases for them. When designing large systems we don't need to get bogged down in details of how a Diffie-Hellman handshake works, what we need are abstractions, patterns and black boxes we can effectively use together and reason about.</p><p>With this post I hope to present terms you may or may not have heard before, hopefully with a few examples, one for anyone to understand and at least one for developers to understand.</p><p>Before we go any further it's worth mentioning the old adage - never roll your own crypto. Always build on proven, audited libraries and preferably get the implementation looked at by someone who knows what they're doing. Cryptographic operations can fail (often silently) in unpredictable ways, leaving you stuck with the assumption that what you've built is secure, when it's really not.</p><div><h2 id="hashing">Hashing</h2><p>Hashing has many, many use cases in the digital world. For our purposes it can be easiest to explain hashing as a deep check for equality. Given two things (files, sentences, words, images) how do we ascertain that they are identical? This can be hard to reason about outside of computing because almost never are two items perfectly equal.</p><h5 id="in-a-system">In a system</h5><p>The most common use case almost all of us will be familiar with is password hashing. When users enter their password we don’t want to store that in plaintext, if a database of raw user passwords was leaked it’d be catastrophic. What we do instead is hash the password and store that. If the database is ever leaked the user passwords can’t be reversed from the hash.</p><p>I don’t need to provide another example for hashing because it’s so common, however let’s briefly look at how we might leverage hashing to build a custom image caching system. When we browse user profiles on a mobile application, the mobile application (hopefully) doesn’t fetch the images every time you see the image. What it <em>could</em> do, to save bandwidth, is just send the hash of the current image to the server. The server checks if this hash matches the hash of the latest upload, and only sends the new image if it doesn’t match, meaning the clients version is outdated.</p><h2 id="symmetric-encryption">Symmetric encryption</h2><p>Symmetric encryption is something most of us are probably familiar with, however if not, it’s simply the act of encrypting something with a key. If you don’t have the key, you can’t decrypt the data.</p><p>A good analogy can be to liken symmetric encryption with a safe. It’s big, heavy and you know whatever’s in there is going to be private. If you’ve got the combination - awesome - you’ve got full access to it. If not, you’re out of luck and you’re gonna have to try break it open.</p><h5 id="in-a-system-1">In a system</h5><p>As a practical example of symmetric encryption in a wider digital system, imagine you want to save data in the cloud. You’ve run out of space on your laptop and want to use Dropbox to store your data. Just sending your data to Dropbox is a recipe for disaster, anyone at Dropbox would be able to view your private information. However if you generate a symmetric key and encrypt your data with it before sending it to Dropbox, you know no one else is going to be able to see it.</p><h2 id="asymmetric-encryption">Asymmetric encryption</h2><p>Asymmetric encryption is a really powerful concept we can model entire systems around. It all boils down to there being a different key for encryption and decryption.</p><p>As a simple example, let’s liken asymmetric encryption to a letterbox. With a letterbox anyone can put mail in it, however only people with the key can read said mail. This is at odds with symmetric encryption from our previous example, where you need the key to put anything into the box.</p><h5 id="in-a-system-2">In a system</h5><p>I’ve struggled here to just pick one example to explore, but perhaps the most relevant is encrypted communication. With asymmetric encryption you have a public key (this is what others see, like the name on your letterbox) and you have a private key (like the name suggests, this one should be kept secret - otherwise anyone could open your letterbox). When two users want to communicate securely they simply encrypt their messages to the recipients public key. Now no one else other than those two can read their messages. To spell this out:</p><ul><li>User B (recipient) publishes their public key</li><li>User A (sender) encrypts a message to B’s public key</li><li>User A sends the encrypted message to B</li><li>User B receives the message and decrypts it with their private key.</li></ul><h2 id="signatures">Signatures</h2><p>Another great aspect of asymmetric cryptography is the ability to provide proof that a message came from someone in particular. To use the mail analogy again, this can be thought of as a stamp on the letter. You know that only Steve has the stamp “Steve’s stamp”, so you can trust any letter with this to be from him.</p><h5 id="in-a-system-3">In a system</h5><p>Digital signatures are used almost everywhere in the internet today. In the context of cryptocurrency and blockchains, every transaction you send it accompanied by a signature over the payload you’re sending - asserting that it came from you.</p><p>Let’s also take a moment to think about internal or external communication between various services you’ve written. How do you know when a request comes from your payments service that it’s really your payments service sending this message? When a user of your website does an action (buying an item, for example), how do you tie that action to the right user?</p><p>A common solution is signed payloads, <a href="https://jwt.io/">JSON Web Tokens</a> being a popular specification to follow. A session token is any many aspects just a signature over some payload you’ve provided, an assertion that at some point this user authenticated with you. A basic user authentication flow might go:</p><ul><li>User sends you their username and password</li><li>You verify that the password hash matches the saved hash for this username</li><li>You generate a signed payload that includes their unique ID and potentially anything else you don’t want to have to read from the database for every request.</li></ul><p>Now every request that comes to your server can just verify the signature provided, and you allow them access to the system based on that.</p><h2 id="blind-signatures">Blind Signatures</h2><p>A blind signature is one where the signer doesn’t need to about the contents of the message. This can be hard to reason about but one simple example is in an election voting situation. Alice comes in to vote and proves her identity to the officials at the location. After voting (her choice remains a secret) she hands the sealed envelope to the official, who signs and submits it. In this case the signer has no idea what choice Alice has made, however later at the vote counting station we can verify that this envelope is valid because it was signed by an official.</p><h5 id="in-a-system-4">In a system</h5><p>We could improve upon the above voting example and think about payments. Imagine we’re wanting to make a payment somewhere and not have the merchant know our identity, this is where we could leverage blind signatures to make transactions privately.</p><ol><li>We go to the bank and ask for a cheque for $100</li><li>We take this cheque and send our order to a shop (anonymously), asking for $100 worth of goods</li><li>The shop can verify this blind signature with the bank and send our goods to our specified address</li><li>We’ve successfully completed a purchase without either the bank knowing what we’re buying, or the merchant knowing who we are.</li></ol><h2 id="secret-sharing">Secret sharing</h2><p>I’ve wracked my brain for hours trying to think of a good analogy for secret sharing, but I wasn’t able to come up with one. Essentially it comes down to (what seems like) magic, you and another party are able to agree on something without ever communicating, it’s pretty cool.</p><p>What we’re talking about here are Diffie-Hellman key exchanges. They underpin almost all modern communication. Most of your browser traffic these days is secured via TLS (which implies some kind of key exchange between your browser and the server) however I’d like to explore another cool use case in the context of privacy preserving applications.</p><p>Before we dive into the example, at the highest level a Diffie-Hellman key exchange works as follows:</p><ul><li><code>DH(Alice's public key, Bob's private key) = shared_secret</code></li><li><code>DH(Bob's public key, Alice's private key) = shared_secret</code></li></ul><p>This <code>shared_secret</code> is only computable by Alice and Bob, no one else would be able to figure it out.</p><h5 id="a-use-case">A use case</h5><p>Let’s explore how we could build a privacy preserving messaging platform using a centralised database. At its most basic (and totally open) a message between two parties would look like this:</p><table><thead><tr><th>from</th><th>to</th><th>payload</th></tr></thead><tbody><tr><td>Alice</td><td>Bob</td><td>Hi!</td></tr><tr><td>Bob</td><td>Alice</td><td>Hey! What’s up?</td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr></tbody></table><p>This is how most applications have been built for the last twenty years. Maybe data is encrypted at rest, but in my experience working at software companies encryption at rest means nothing, every employee still has access to this data on demand, in the worst case it’s a Jira ticket away.</p><p>Step one in our privacy preserving journey is to encrypt the data swapped between parties, Alice encrypts messages to Bob’s public key and vice-versa. Now we as the providers of this service can’t see the data being swapped:</p><table><thead><tr><th>from</th><th>to</th><th>payload</th></tr></thead><tbody><tr><td>Alice</td><td>Bob</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>Bob</td><td>Alice</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr></tbody></table><p>However here we can unfortunately still tell that Alice and Bob are communicating. What could we do to hide the communication between these two?</p><p>One solution I’ll propose - which also has the benefit of sender privacy, so we’re killing two birds with one stone here - would be to generate a shared secret and hash it with the recipients identifier. Now messages just have a <code>payload</code> and a <code>to</code> property. The <code>to</code></p><table><thead><tr><th>to</th><th>payload</th></tr></thead><tbody><tr><td>HASH(alice_bob_shared_secret, Bob)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>HASH(alice_bob_shared_secret, Alice)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>HASH(alice_bob_shared_secret, Bob)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>…</td><td>…</td></tr><tr><td>…</td><td>…</td></tr><tr><td>…</td><td>…</td></tr></tbody></table><p>Remember only Alice and Bob can generate this shared secret, and the HASH function is some irreversible function that hides its content. Now whenever Bob wants to find messages from Alice he computes <code>HASH(alice_bob_shared_secret, Bob)</code> and queries all messages that match that <code>to</code> field.</p><p>As you can see now we only …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/">https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/</a></em></p>]]>
            </description>
            <link>https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453703</guid>
            <pubDate>Thu, 17 Dec 2020 08:23:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling (organization) by bubbling the problems out]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453685">thread link</a>) | @liveweird
<br/>
December 17, 2020 | https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5fda593d1605500039b287da">
	

	<section>
		<p>Working in many different environments provided me a good perspective on what scaling models are applied by different companies. Today I'd like to spend a bunch of keystrokes on one of the worst scaling models I've ever encountered.</p><p>I call it:</p><blockquote>Scaling by bubbling the problems out</blockquote><p>A <em>'busy person'</em>, usually a leader or manager, identifies a persistent problem within the organization: something that consumes focus and time, impacts the quality, slows down the value delivery, etc. This problem is either completely new (caused by the growth) or has evolved over time, but now its severity is more apparent.</p><p>Here are a few examples (of such problems) to make sure we're on the same page:</p><ul><li><strong>the number of quality defects</strong> (for the whole product) is increasing; until now, each team had been able to deal with their deliverables' quality</li><li><strong>the quality of internal communication</strong> deteriorates - people start complaining they don't know what's happening in the org, there are more and more misunderstandings and misalignments</li><li>the engineering unit needs to grow, and the <strong>recruitment takes more time increasingly</strong> - hereby hemorrhaging the last reserves of time of the unit's manager</li></ul><p>Initially, such a problem is dealt with in an ad-hoc way (through a one-off, point-directed action). But it keeps popping up back (as due to its nature, it can't be eliminated permanently). Apparently, that kind of a problem requires continuous effort and ownership (to make sure it doesn't get out of control).</p><p>Finally, the <em>'busy person'</em> (mentioned above) decides that burying her/his head in the sand won't work anymore, so why not do what all the handbooks advise?</p><p>That sounds like a tremendous idea, but the devil is in details. The <em>'busy person'</em> doesn't delegate responsibility, function, or role. (S)he <strong>outsources</strong> the problem by creating a new (formal or no) position (or even a sub-unit) to deal with that problem, so all the annoyances are out of the <em>'busy person's'</em> back.</p><p>This way the problem is contained within some sort of a <strong>bubble</strong>, but it's someone else's bubble! Problem-related black box our <em>'busy person'</em> doesn't have to worry about.</p><p>Got it?</p><ul><li>Problem <strong>X</strong> -&gt; <strong>X</strong> Manager / <strong>X</strong> Team</li><li><strong>Quality </strong>problem -&gt; <strong>Quality </strong>Manager / <strong>Quality </strong>(Assurance) Team</li><li><strong>Communication </strong>problem -&gt; <strong>Communication </strong>Manager / <strong>Communication</strong> Team</li><li><strong>Recruitment </strong>problem -&gt; <strong>Recruitment </strong>Manager / <strong>Recruitment </strong>Team</li></ul><p>Oh, how convenient is that! If the problem re-appears, it's clear who's guilt...^M^M^M to be asked to fix the situation.</p><p>As the crisis is prevented now, the <em>'busy person'</em> continues with her/his quest, smug and oblivious to the consequences of the change just made ...</p><p>Yes, it seems that short-term, we're all good here. Putting someone in charge of the crisis sounds like a decent plan. But it's not really what happened here. A new position has been spawned <strong>not to solve</strong> the actual problem (which may be hidden and unobvious) <strong>but to patch</strong> its visible symptoms, potentially making the organization more complex, inter-dependent, and bureaucratic.</p><p>Instead of well-thought-through systemic change, we're adding a sub-unit (usually with the manager in charge) with the responsibility of dealing with problem X. If you had any hopes for getting rid of problem X permanently - abandon any faith in that. If problem X is the sole reason for the sub-unit's existence, it will subliminally act <strong>to preserve and solidify</strong> that problem (under control, but still).</p><p>In more simple words:</p><ol><li>no wider context</li><li>no holistic view (to understand the flow of work and value, or the nature of the problem)</li><li>no systemic approach (System's Theory)</li></ol><p>While in fact the solutions to before-mentioned problems may be much more simple and straightforward:</p><ul><li><strong>the quality issues</strong> may be a result of reaching the critical capacity of manual regression testing (with test automation as a likely answer) or pushing quality checks towards the end of process (e.g. by not doing proper reviews)</li><li><strong>internal communication</strong> could deteriorate because of the increasing number of actors - a good idea is to check the component/area boundaries to verify the number &amp; validity of dependencies; other potential root cause may be an underlying conflict or misaligned priorities of two (or more) parties</li><li><strong>extensive recruitment</strong> will be a problem if you centralize the 'gating' too much - although acquiring talent is manager's/leader's duty, (s)he should get a lot of control over it directly to the teams (who are looking for more members) - it's their skin in the game of getting the most proper people on board</li></ul><hr><p>Just to make sure I'm clear - what I'm saying here is not against the popular principle of <em>'single-threaded teams'</em> (ones dedicated end-to-end, exclusively to well-defined narrow topic). I'm all for crystal-clear focus and unequivocal responsibility range, but the area covered by such a team should be <strong>defined by product/service vision</strong>, instead of what kind of piece of garbage has been thrown over the fence to save you some time ...</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453685</guid>
            <pubDate>Thu, 17 Dec 2020 08:19:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25453663">thread link</a>) | @ingve
<br/>
December 17, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453663</guid>
            <pubDate>Thu, 17 Dec 2020 08:13:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin price will hit $1M by the end of the decade: My prediction]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25453620">thread link</a>) | @kprimice
<br/>
December 17, 2020 | https://thenextwave.blog/bitcoin-future-price-prediction/ | <a href="https://web.archive.org/web/*/https://thenextwave.blog/bitcoin-future-price-prediction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Asset valuation and, in particular, Bitcoin valuation is hard. Although Bitcoin is empirically one of the best investments of the past decade, it remains controversial. It has simultaneously been compared to the internet revolution and to the Tulip bubble. Bitcoin is an experiment; failure is still possible.</p><p><strong>What if Bitcoin succeeds? How much will it be worth 10 years from now?</strong></p><p>Investors have well-established frameworks for evaluating assets like equities, credit, and real estate. Yet there is no clear framework for Bitcoin. My opinion is Bitcoin could have an enormous upside if it catches on. In this article, you will learn why Bitcoin could hit a $1M valuation by 2030 if the adoption continues to grow.</p><h3 id="key-takeaways-">Key takeaways:</h3><ul><li>Supply/demand balance of commodities such as oil and gold</li><li>Supply/demand balance of Bitcoin</li><li>Price prediction of Bitcoin: 3 scenarios</li></ul><p><em>First time here? Subscribe and receive The Next Wave directly in your inbox:</em></p><section>
<form data-members-form="subscribe">

<p>
Great! Check your inbox and click the link to confirm your subscription.
</p>
<p>
Please enter a valid email address!
</p>
</form>
</section><h2 id="the-supply-demand-balance-of-commodities">The supply/demand balance of commodities</h2><p>The first step of asset valuation is to understand fundamental economics. Equities, bonds, and real estate derive their value from cash flows (and future cash flows). Whereas commodities (such as oil, gold, or bitcoin) are utility-based, and their price depends more on supply and demand. No clear framework exists for them.</p><h3 id="oil-supply-demand-balance">Oil supply/demand balance</h3><p>Oil price is the balance between supply and demand. If the demand increases, you can expect the price to increase as well. If demand drops, price drops. The same goes with supply (in the opposite direction).</p><p>Human civilization requires a certain number of barrels of oil per day to function. That number can be estimated. On the supply side, it costs a certain amount of money to get the oil out of the ground (depending on the technology used, localization, and taxes). If it costs $50 to get a barrel worth of oil out of the ground, then the long-term oil price can't really go below that level for too long. If it does go below that floor price, oil companies will go bankrupt. Supply will decrease, and the price will correct back toward a new equilibrium level.</p><p>In the past months, because of Covid-19, the oil demand dropped (no planes, cars, less energy consumption in general) while the supply stayed the same. Oil price dropped.</p><p>The price stayed so low for so long that some oil producers could not cope with it and went out of business. The oil supply decreased, oil prices corrected and started to increase again.</p><p>The demand is still low; however, it is increasing. As more and more countries go out of lock-down. And with the vaccines coming, we see the end of the tunnel. Ultimately, my bet is the oil will not only get back to the previous level but also surpass them. Remember: Some oil companies went out of business, so the supply is lower than before the crisis. The demand is getting back to normal.</p><p>What applies to oil also applies to silver, gold, and bitcoin.</p><h3 id="gold-supply-demand-balance">Gold supply/demand balance</h3><p>Gold, unlike oil, is not consumed nor destroyed. Gold that existed thousands of years ago still is in circulation today. The global reserve of gold is, therefore, constantly increasing. For the price of gold to stay constant, you need a demand that matches the supply. There are two sources of gold supply:</p><ul><li>75% come from gold mining. Approximately 2,500-3,000 tonnes per year.</li><li>25% come from recycling, most of it comes from jewelry.</li></ul><p>According to the World Gold Council, about 175,000 tonnes have been mined since the beginning of existence. The new mining represents an inflation rate of the gold supply of about 1.7% per year.</p><p>The average inflation of the U.S. dollar is about 2-3% per year.</p><h3 id="bitcoin-supply-demand-balance">Bitcoin supply/demand balance</h3><p>Bitcoin supply is different: it is predictable. It is set in stone and won't change even if most <em>miners</em> go out of business.</p><p>Bitcoin supply is halved every 4 years. No matter what. We can compute Bitcoin current and future average inflation rate and plot it against gold:</p><figure><img src="https://thenextwave.blog/content/images/2020/12/bitcoin_inflation_rate_vs_gold-1.png" alt="Bitcoin inflation rate as a function of time (orange line) and gold average inflation rate (yellow line)" srcset="https://thenextwave.blog/content/images/size/w600/2020/12/bitcoin_inflation_rate_vs_gold-1.png 600w, https://thenextwave.blog/content/images/size/w1000/2020/12/bitcoin_inflation_rate_vs_gold-1.png 1000w, https://thenextwave.blog/content/images/size/w1600/2020/12/bitcoin_inflation_rate_vs_gold-1.png 1600w, https://thenextwave.blog/content/images/2020/12/bitcoin_inflation_rate_vs_gold-1.png 2362w" sizes="(min-width: 720px) 720px"><figcaption>Bitcoin inflation rate as a function of time (orange line) and gold average inflation rate (yellow line).</figcaption></figure><p>On May 11, 2020, the last Bitcoin Halving dropped Bitcoin's inflation rate from 3.6% to 1.8% and will soon cross gold's inflation rate. What does it mean? Bitcoin supply will grow slower than the gold supply.</p><p><a href="https://thenextwave.blog/what-is-bitcoin-explained/">As we've seen</a>, scarcity is one of Bitcoin's (main) feature. There is a fixed supply of bitcoins that can ever be <em>mined</em>. Currently, there are over 18.5 million bitcoins in existence, and the theoretical limit is 21 million. <strong>There will never be more than 21 million bitcoins.</strong> Think about it: this is, at most, 0.003 bitcoins per human being.</p><p>This is key. Even gold does not share the same property: every year, tons of gold is mined. Yes, there is a limited supply underground, but there is also an <strong>unlimited</strong> supply in space. You think I'm joking? <a href="https://eu.usatoday.com/story/news/nation/2020/10/29/metal-asteroid-psyche-nasa-hubble-images/6069223002/">Look what NASA found</a>.</p><h2 id="price-prediction-of-bitcoin-3-scenarios">Price prediction of Bitcoin: 3 scenarios</h2><p>Bitcoin has significant headroom if it continues to gain broader acceptance. How big can it grow? I based my estimates on the current worldwide value of all mediums of exchanges and stores of value comparable to Bitcoin.</p><p>Let's dive into 3 different scenarios (by increasing order of optimism).</p><h3 id="future-bitcoin-price-if-considered-a-store-of-value">Future Bitcoin price if considered a store of value</h3><p>The first milestone Bitcoin will reach the store of value status. Bitcoin does not have the history of gold as a store of value. However, do you imagine millennials buying and storing gold as some older generations did? Would they rather own Bitcoin instead? It certainly is easier to store, transport, buy, and sell. Gold does not have more reason to be considered a store of value as <a href="https://thenextwave.blog/what-is-bitcoin-explained/">Bitcoin has</a>.</p><p>For this first scenario, we compare Bitcoin's market size to gold's. Gold aggregate value is estimated to be nine trillion dollars (December 2020). <strong>If Bitcoin achieved that capitalization on a base of 21M coins, each coin would be worth ~$420,000.</strong></p><p>Beyond complementing gold's investment demand, Bitcoin may also address broader store of value markets indirectly. Consider various collectibles like art or gemstones, some of which are owned primarily as stores of value. Or consider the empty NYC apartment owned by a foreigner interested in storing value outside his or her native country. Bitcoin could plausibly address subsets of these behaviors more effectively. As it is difficult to estimate, we don't include it in our scenario.</p><p>Bitcoin offers many more possibilities compared to gold. So, what are the next steps?</p><p>As you know, it is difficult to use gold as a medium of exchange. Transporting gold on the street to buy goods is impractical. However, using Bitcoin is entirely feasible. Therefore the market demand for an asset such as Bitcoin could vastly exceed gold. Especially given the prevailing direction of global monetary policy.</p><h3 id="future-bitcoin-price-if-considered-as-money-medium-of-exchange-m1-money">Future Bitcoin price if considered as money/medium of exchange: M1 money</h3><p>The money supply is broken into different buckets: M0, <a href="https://www.investopedia.com/terms/m/m1.asp">M1</a>, <a href="https://www.investopedia.com/terms/m/m2.asp">M2</a>, and MZM. M0 refers to currency in circulation. M1 is M0 plus demand deposits like checking accounts. Since M1 is readily accessible for use in commerce, we consider this bucket as a medium of exchange. It includes:</p><ul><li>Physical currency (coins and banknotes)</li><li>Demand deposits, travelers' checks, and other checkable deposits,</li><li>Negotiable order of withdrawal (NOW) accounts</li></ul><p>The global M1 Money stock by region is about:</p><ul><li><a href="https://fred.stlouisfed.org/series/M1">$6.5 trillion</a> in the U.S.</li><li><a href="https://tradingeconomics.com/euro-area/money-supply-m1">$12 trillion</a> in Europe.</li><li><a href="https://tradingeconomics.com/china/money-supply-m1">$9 trillion</a> in China</li><li><a href="https://fred.stlouisfed.org/series/MYAGM1JPM189N">$7 trillion</a> in Japan</li></ul><p>40 trillion dollars is a conservative lower-bound for global M1 Money stock (which includes M0). If Bitcoin were to achieve a 10% market penetration as a medium of exchange, its market capitalization in today's money would be 4 trillion U.S. dollars.<strong> It would lead to a $190,000 price increase per bitcoin. So about $610,000 per bitcoin.</strong></p><h3 id="future-bitcoin-price-if-considered-as-money-of-zero-maturity">Future Bitcoin price if considered as Money of Zero Maturity</h3><p>The money of zero maturity (MZM) is an even broader bucket. MZM has become one of the preferred measures of the money supply. It represents money readily available for spending and consumption. It includes:</p><ul><li>Our previously defined M1 money</li><li>Savings accounts</li><li>Money market funds</li></ul><p>The global MZM Money stock by region is about:</p><ul><li><a href="https://fred.stlouisfed.org/series/MZM">$22 trillion</a> in the U.S.</li><li><a href="https://tradingeconomics.com/euro-area/money-supply-m3">$18 trillion</a> in Europe.</li><li><a href="https://take-profit.org/en/statistics/money-supply-m1/china/">$34 trillion</a> in China</li><li><a href="https://fred.stlouisfed.org/series/MYAGM3JPM189N">$14 trillion</a> in Japan.</li></ul><p>100 trillion dollars is a conservative lower-bound for global MZM Money stock. If Bitcoin were to achieve 10% of this total estimate for <a href="https://www.investopedia.com/terms/g/gdax.asp">the global value of mediums of exchange</a> and store of value, its market capitalization would reach 10 trillion U.S. dollars. <strong>If Bitcoin achieved that capitalization on a base of 21M coins, each coin would be worth ~$920,000.</strong></p><p>None of the above account for the dollar's inflation rate, which is about 2%-3% per year. It will easily bring the valuation to more than one million dollars per bitcoin.</p><h2 id="conclusion">Conclusion</h2><blockquote> "All models are wrong, some are useful." – George Box (Mathematician)</blockquote><p>It is important to understand our framework's variables. From our model it is possible that Bitcoin's price will increase by orders of magnitude. But it all depends on Bitcoin's level of adoption: <strong>The most important question is: "Will people use Bitcoin?"</strong></p><p><strong>Further readings:</strong></p><ul><li><a href="https://coinmarketcap.com/alexandria/article/what-price-will-bitcoin-reach-this-time?utm_source=coinmarketcap&amp;utm_medium=alert&amp;utm_content=&amp;utm_campaign=btcpricepredictions&amp;utm_term=">What price will Bitcoin reach?</a></li><li><a href="https://thenextwave.blog/what-is-bitcoin-explained/">Is Bitcoin the new Gold? Understanding Bitcoin and the history of money</a></li><li><a href="https://www.investopedia.com/terms/m/moneyzeromaturity.asp">Money Zero Maturity (MZM)</a></li></ul>
</div>
</section>
<h2><span id="cove-count"></span> Comments</h2>
<p>Sign in or become a The Next Wave member to join the conversation.<br>
Just enter your email below to get a log in link.</p>



<section>
<h3>Subscribe to The Next Wave</h3>
<p>Paper airplanes delivered right to your inbox containing actionable secrets to improve your personal finance</p>
<form data-members-form="subscribe">

<p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
</p>
<p>
Please enter a valid email address!
</p>
</form>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://thenextwave.blog/bitcoin-future-price-prediction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453620</guid>
            <pubDate>Thu, 17 Dec 2020 08:03:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deep learning tool that repairs damaged/faded photos]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25453481">thread link</a>) | @panabee
<br/>
December 16, 2020 | https://hotpot.ai/restore-picture?s=hn | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBox">

			<div>
				<p><img src="https://hotpot.ai/images/site/transparent.gif">
				</p>
			</div>

			

			<p><span>Restore</span>
			</p>

		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			Enable "Has Scratches" to explicitly remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453481</guid>
            <pubDate>Thu, 17 Dec 2020 07:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creative Code-Generated Art]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25453252">thread link</a>) | @dzink
<br/>
December 16, 2020 | https://www.editorx.com/shaping-design/article/creative-coding | <a href="https://web.archive.org/web/*/https://www.editorx.com/shaping-design/article/creative-coding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><p id="viewer-foo"><span><span>Have you ever experienced true novelty? Something so mind-altering that it questions your definition of what you’ve known to be true for so long. I imagine the first people to watch a film or see an airplane felt this. It’s an inexplicable energy that has the power to redefine. In many ways, artists have been at the center of challenging commonly held beliefs, and using entirely new mediums to express speculative ideas. </span></span></p><p id="viewer-fa7pc"><span><span>While never the first thing to come to mind when discussing art, creative coding is revolutionizing what art is and can be. As we enter a more digital world, creative coding may be the contemporary art movement we need in order to articulate major societal challenges we are facing as technology advances. </span></span></p><p id="viewer-gar4"><span><span>Put simply, creative coding is an emerging specialty that utilizes code and programming as a medium to create art. Programming’s versatility and ubiquitous nature makes it especially expressive, allowing it to manifest itself as digital paintings, data visualization, or even robotics. </span></span></p><p id="viewer-aesrq"><span><span>Unlike the functional focus of most uses of code - like the code lines of a navigation app - creative coding uses programming languages for a solely artistic purpose.</span></span></p><p id="viewer-bg2ev"><span><span>As artists, we generally hold a stigma regarding coding having high barriers to entry, and as engineers, we also hold a stigma surrounding the difficulties of creative expression. However, these fields no longer need to be separate entities, as they are more closely tied than people expect. </span></span></p><p id="viewer-80qt3"><span>With programming resources being incredibly open-source and <a href="https://www.editorx.com/shaping-design/article/drawing-inspiration-for-designers" target="_blank" rel="noopener"><u>creative inspiration</u></a> democratized across the internet, getting into this field is as easy as watching some coding tutorials on Youtube and making a Pinterest board. </span></p><p id="viewer-2vgh3"><span>If you haven’t already, you can <a href="https://www.editorx.com/shaping-design/article/should-designers-code" target="_blank" rel="noopener"><u>learn to code</u></a> by picking up a coding language such as HTML, CSS, and JavaScript. There are many online resources available, such as:</span></p><ul><li id="viewer-27t6d"><p><a href="https://www.w3schools.com/" target="_blank" rel="noopener"><u>W3Schools</u></a></p></li><li id="viewer-5oukm"><p><a href="https://www.youtube.com/watch?v=2qDywOS7VAc" target="_blank" rel="noopener"><u>Youtube Tutorials</u></a></p></li><li id="viewer-4rsku"><p><a href="https://www.linkedin.com/learning/" target="_blank" rel="noopener"><u>LinkedIn Learning</u></a></p></li><li id="viewer-a6fsj"><p><a href="https://www.learnpython.org/" target="_blank" rel="noopener"><u>Learnpython.org</u></a></p></li><li id="viewer-8el3i"><p><a href="https://www.codecademy.com/?g_network=g&amp;g_device=c&amp;g_adid=459321005730&amp;g_keyword=codecademy&amp;g_acctid=243-039-7011&amp;g_adtype=search&amp;g_adgroupid=70946090375&amp;g_keywordid=kwd-41065460761&amp;g_campaign=US_Brand_Core_Exact_Net+New+%28Auto+Tagging%29&amp;g_campaignid=1955172604&amp;utm_id=t_kwd-41065460761:ag_70946090375:cp_1955172604:n_g:d_c&amp;utm_term=codecademy&amp;utm_campaign=US_Brand_Core_Exact_Net%20New%20(Auto%20Tagging)&amp;utm_source=google&amp;utm_medium=paid-search&amp;utm_content=459321005730&amp;hsa_acc=2430397011&amp;hsa_cam=1955172604&amp;hsa_grp=70946090375&amp;hsa_ad=459321005730&amp;hsa_src=g&amp;hsa_tgt=kwd-41065460761&amp;hsa_kw=codecademy&amp;hsa_mt=e&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gclid=CjwKCAiAzNj9BRBDEiwAPsL0d6bnyHp-tuJuJPB6ESAc8vQsGp2os6n9SvJ_fN73bAazebYH-FcctRoCuOMQAvD_BwE" target="_blank" rel="noopener"><u>The Code Academy</u></a> </p></li><li id="viewer-6638e"><p><a href="https://processing.org/" target="_blank" rel="noopener"><u>Processing</u></a></p></li></ul><p id="viewer-cbn64"><span>From there, finding inspiration can be as simple as reading the rest of this article or exploring dedicated art-technology spaces such as <a href="https://www.artechouse.com/" target="_blank" rel="noopener"><u>Artechouse</u></a>.</span></p><p id="viewer-erafq"><span>Here are some interesting fields within creative coding that you can experiment with once you get started:</span></p><ul><li id="viewer-ehb6t"><p><span><strong>Machine learning:</strong> The development of computer algorithms that automatically learn and improve their performance through experience and data.</span>


</p></li><li id="viewer-32vc4"><p><span><strong>Projection mapping:</strong> A technique to project video on irregularly shaped surfaces, such as sculptures or buildings. </span>


</p></li><li id="viewer-f009e"><p><span><strong>Generative design:</strong> An iterative design process in which a program, usually using algorithms, generates a certain number of outputs based on a set of constraints.</span>


</p></li><li id="viewer-5n77p"><p><span><strong>Live coding:</strong> A form of performance art in which coders program in real-time. It usually involves sound, image and light design.</span></p></li></ul><p id="viewer-ep6sm"><span><span>To get some ideas flowing and inspire your own creative coding pieces, here are some examples of how expansive, stunning, and novel creative coding can be.</span></span></p><ol><li id="viewer-eeo5c"><p><span>Audience by Random International</span></p></li><li id="viewer-fha9v"><p><span>New Nature Digital Petting Zoo by Marpi Studio</span></p></li><li id="viewer-a5o8e"><p><span>Everything in Existence by fuse*</span></p></li><li id="viewer-8gq1n"><p><span>Infinite Command Team by Casey Reas </span></p></li><li id="viewer-4eu7u"><p><span>Land Lines by Zach Lieberman </span></p></li><li id="viewer-3unh"><p><span>ALGOBABEZ by Shelly Knotts</span></p></li><li id="viewer-538vu"><p><span>XYZT: Abstract Landscapes by Adrien M &amp; Claire B</span></p></li><li id="viewer-b7vhn"><p><span>Tecnicontrol by Bradley G Munkowitz (GMUNK)</span></p></li><li id="viewer-bprm6"><p><span>PEmbroider created at Frank-Ratchye STUDIO for Creative Inquiry</span></p></li><li id="viewer-akhtn"><p><span>Learning to See by Memo Akten</span></p></li></ol><p id="viewer-bahbh"><span><span>Random International is a London-based experimental art studio that has been pioneering the creative coding space for well over a decade now. Their work touches on deep social themes and has been exhibited internationally in spaces like the MoMa. </span></span></p><p id="viewer-fduu8"><span><span><em>Audience</em>, one of their earlier pieces of work from 2008, uses motion tracking software and creative coding to create an almost uncomfortable, anthropomorphic experience. As a gallery visitor steps in front of rows of individually dancing mirrors, they instantly synchronize and lock onto the viewer. With 100 mirrors now looking right back at you, you then become the focal point of your own onlooking. </span></span></p><p id="viewer-8dmeo"><span><span>Created by Marpi Studio, New Nature is a digitally interactive petting zoo that relies on gesture-based technology and programming to create virtual organisms. </span></span></p><p id="viewer-65ego"><span><span>Through machine learning, Marpi has forged a virtual terrarium of creatures and plants that rely on the physical interactions of the viewers to come alive. As viewers engage with the digital creatures, the artwork responds with real-time computer-generated motions, simulating the movement of an organic creature being pet. </span></span></p><p id="viewer-60ee9"><span><span><em>Everything in Existence</em> questions our perceptions of reality. Using real-time data processing tools and algorithmic software, fuse* creates a living piece of art that constantly evolves and adapts depending on its interactions with onlookers. </span></span></p><p id="viewer-bna5m"><span><span>The artworks are constantly generating new visuals in response to the viewers, their social networks, sound and more. This solo exhibition by fuse*, which premiered in Washington DC in 2019, creates digitally interactive experiences independently of an artist. Its self-sufficient and generative nature suggests an entirely new form of artistic expression.</span></span></p><p id="viewer-274p6"><span><span>Casey Reas’ <em>Infinite Command Team</em> investigates the relationship between particles that are encoded to construct images, and the code that forges those particles. </span></span></p><p id="viewer-c3cum"><span><span>Using pixelation of different weights and sizes, the piece creates a digital mosaic of television signals that become abstract and collage-like, reminiscent of TV channel-surfing. The piece is a celebration of art and technology that showcases the potential of combining digital fragments into a holistic piece of work. </span></span></p><p id="viewer-fhi88"><span><span>One of the most exciting aspects of creative coding is that it’s so readily available. Regardless of where you go in the world, there will always be code present guiding new innovations or digital platforms. </span></span></p><p id="viewer-8344v"><span><span>Creative coder Zach Lieberman takes advantage of how constantly present code is in our lives by using Google Maps to create art. In his proj</span>ect <a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><em><u>Land Lines</u></em></a>, Lieberm<span>an uses machine learning, optimized algorithms, and card power to harness images from Google Maps and match them with viewers’ drawings. </span></span></p><p id="viewer-ab3mh"><span><span>Lieberman asks his viewers to draw shapes and lines on the screen, which in turn are converted into real spaces on earth that resemble the line they drew. </span></span></p><div id="viewer-6292q"><a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="Land Lines by Zach Lieberman website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_1000%2Ch_715%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Land Lines by Zach Lieberman website screenshot"></p></div></div></a></div><p id="viewer-8vtqk"><span><span>Shelly Knotts takes creative coding to an entirely new plane in her live-coding pop band, ALGOBABEZ. Based in the UK, Shelly collaborates with other musicians and programmers in her pseudo-improvised live-coded music performances. Her coded music has been played to international audiences and explores themes of data, music, networks, and code.</span></span></p><p id="viewer-5b9e7"><span><span>Created by the company Adrien M &amp; Claire B, <em>XYZT</em> explores the intersection of mathematics and imaginary landscapes. </span></span></p><p id="viewer-bstnp"><span><span>Leveraging technology, programming, and lighting design, <em>XYZT</em> allows visitors to explore the four primary planes of existence: horizontal (the X axis), vertical (Y), depth (Z), and time (T). The exhibit allows for unparalleled interactivity across each of the planes, responding to visitors’ motion and creating new visuals in real time. </span></span></p><p id="viewer-3jqso"><span><span>In his creative coding work <em>Technicontrol</em>, Bradley Munkowitz, also known as GMUNK in the art community, investigates the ways in which robotics, code and screen content can result in a choreographed piece of work. </span></span></p><p id="viewer-b6arv"><span><span>Rather than using typical projection-mapped canvases, he pushed for LED-screen-wielding robots and a motion-controlled camera. The end result is a whimsical, technology-driven video piece with a truly marvelous storyline tracing the steps of a television abduction.</span></span></p><p id="viewer-178s8"><span><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><em><u>PEmbroider</u></em></a> is a<span>n open-source computational embroidery library. The goal of the creative coding library is to empower artists and craftspeople to make generative embroidery work for free. </span></span></p><p id="viewer-2ua6k"><span><span>Usually, tools such as this would be costly, and oftentimes are inaccessible to most artists or hobbyists. By creating an open-source repository, PEmbroider allows anyone to forge new, generative embroidery work through code. </span></span></p><div id="viewer-ecl5u"><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="PEmbroider creative coding website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_1000%2Ch_661%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="PEmbroider creative coding website screenshot"></p></div></div></a></div><p id="viewer-18rug"><span><span>Memo Akten is an artist and researcher who examines the nature of vision and perception through computational creativity and artificial intelligence. In his series of works, <em>Learning To See</em>, Akten has developed an artificial neural network to view and make sense of the world around us. </span></span></p><p id="viewer-bnqsf"><span><span>By comparing everyday objects with their interpretations through the eyes of neural networks, Memo Akten is able to digitally emulate the way we humans observe the world and make sense of objects.</span></span></p><p id="viewer-1q52f"><span><span>As he states, “it can only see through the filter of what it already knows. Just like us. Because we too, see things not as they are, but as we are.”</span></span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.editorx.com/shaping-design/article/creative-coding</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453252</guid>
            <pubDate>Thu, 17 Dec 2020 06:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell with Elm: How to Setup IHP with Elm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453058">thread link</a>) | @_query
<br/>
December 16, 2020 | https://driftercode.com/blog/ihp-with-elm/ | <a href="https://web.archive.org/web/*/https://driftercode.com/blog/ihp-with-elm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Get Elm with hot reloading on top of IHP, the new framework that makes Haskell a cool kid in web dev.</p><article><p><em>This is <strong>part 1</strong> of the series <a target="_blank" rel="noreferrer noopener" href="https://driftercode.com/blog/ihp-with-elm-series">IHP with Elm</a></em></p><p><a target="_blank" rel="noreferrer noopener" href="https://elm-lang.org/">Elm</a> was my gateway drug into type-safe functional programming. It's such a good tool for making robust frontends. Writing big projects in React and TypeScript honestly bums me out because of it.</p><p>I have always wanted have to have the equivalent type-safe joy on the backend like I have with Elm.</p><p>Now I have it all, with SSR included and an amazing developer experience 😍</p><p><strong><a target="_blank" rel="noreferrer noopener" href="https://ihp.digitallyinduced.com/">IHP</a> is a new web framework that has opened a wide door for the web development community to get into Haskell.</strong> Like Rails and Laravel, it's great for quick prototyping, well documented and easy to use.</p><p>It even has the pipe operator (<code>|&gt;</code>) included making it even more similar to the Elm syntax.</p><p><strong>Disclaimer: This tutorial should work for Mac and Linux. If you develop on Windows, it might not work without some tweaks on your own</strong></p><h2>Create a new IHP Project</h2><p>If you haven't installed IHP already, make sure you do. <a target="_blank" rel="noreferrer noopener" href="https://ihp.digitallyinduced.com/Guide/installation.html">It's surprisingly easy to get going</a>.</p><p>Start a fresh IHP project for this tutorial. Luckily, it couldn't be easier as soon as IHP is properly installed.</p><code-editor language="bash"></code-editor><p>To verify the app is working, cd into the <code>ihp-with-elm</code> folder and run <code>./start</code>.</p><h2>Update .gitignore</h2><p>Let's update <code>.gitignore</code> as soon as possible to avoid pushing unwanted stuff into git.</p><code-editor language="bash"></code-editor><h2>Initialize node and elm</h2><p>In your <code>default.nix</code> file in the root folder, add <code>Node.js</code> and <code>elm</code> to <code>otherDeps</code>:</p><code-editor language="nix"></code-editor><p>To update your local environment, close the server <strong>(ctrl+c)</strong> and run</p><code-editor language="bash"></code-editor><p>Then initialize Node.js and elm at the project root.</p><code-editor language="bash"></code-editor><p>For this tutorial, we will rename the <code>src</code> folder that elm generated into <code>elm</code>.</p><code-editor language="bash"></code-editor><p>Set the source directories folder to <strong>"elm"</strong> in <code>elm.json</code>.</p><code-editor language="json"></code-editor><h2>Getting the Haskell template ready</h2><p>Let's start writing the Elm entrypoint into the Haskel template.</p><p>Go to <code>Web/View/Static/Welcome.hs</code> and replace all the html inside the HSX in <code>VelcomeView</code>:</p><code-editor language="hs"></code-editor><p>If your IHP app is not already running, run it with <code>./start</code> and see the output on <code>localhost:8000</code>.</p><p><img src="https://driftercode.com/images/archive/ihp-with-elm/elm-not-loaded.jpg" alt="Elm not running" loading="lazy"></p><p>As you see, Elm has not been loaded, because we naturally haven't written any Elm code yet. Let's close the server <strong>(ctrl+c)</strong> and do that now.</p><h2>Setting up Elm</h2><p>Install <code>node-elm-compiler</code> for compiling and <code>elm-hot</code> for hot reloading in development. <code>parcel-bundler</code> is a "zero config" JavaScript bundler.</p><code-editor language="bash"></code-editor><p>You could do it all without a bundler like Parcel. IHP discourages bundlers, and I agree that it's not always necessary.</p><p>Still, Parcel provides valuable niceties like tight production minification and good hot reloading in development, so I prefer to use Parcel when things get a bit more advanced.</p><p>Create <code>index.js</code> and <code>Main.elm</code> in the elm folder:</p><code-editor language="bash"></code-editor><p>The <code>elm/index.js</code> should look like this to initialize the Elm file.</p><code-editor language="javascript"></code-editor><p>Finally, lets' insert the code for <code>elm/Main.elm</code>!</p><code-editor language="elm"></code-editor><p>Add the scripts for building the app both in production and development into <code>package.json</code>:</p><p>Then replace the <code>start</code> script in <code>package.json</code> and add accordingly:</p><code-editor language="json"></code-editor><p>With that you can now run both the IHP app and the JavaScript simultaneously with this single command in development.</p><code-editor language="bash"></code-editor><p>And quit with <strong>(ctrl+c)</strong> as always.</p><p>There you should have it! Elm in Haskell with hot reloading and the Elm debugger is ready for you in the bottom right corner. Beautiful!</p><p><img src="https://driftercode.com/images/archive/ihp-with-elm/elm-loaded.jpg" alt="Elm running" loading="lazy"></p><h2>Build for production</h2><p>When pushing your IHP app to production, you need to make sure that it builds the Elm applications.</p><p>Go to the <code>Makefile</code> in the project root and remove all unused JavaScript files until these are your only <code>JS_FILES</code>:</p><code-editor language="makefile"></code-editor><p>We're keeping <code>flatpickr</code> because we are using the datepicker, but other than that, Turbolinks seems to complicate the Elm loading and jQuery gives us nothing Elm can't give us.</p><p>We're keeping bootstrap css just so we don't need to do any styling for this tutorial.</p><p>Put this code at the bottom of the <code>Makefile</code> to build Elm in production.</p><code-editor language="makefile"></code-editor><p>It should now be ready to ship to production for example to IHP Cloud.</p><p>For a complete overview of what has been done, see the <a target="_blank" rel="noreferrer noopener" href="https://github.com/kodeFant/ihp-with-elm/compare/1-initial...2-ihp-with-elm">diff from a fresh IHP install</a>.</p><h2>Things I don't use Elm for in IHP</h2><p>IHP gives you HTML templating (HSX) with pure functions, very similar to Elm. In that regard it's partially overlapping with Elm.</p><p>It can be a blurry line for beginners, so here are my recommendations for how to set those lines.</p><ul><li>Use HSX for <strong>basic HTML</strong>, even if it requires a couple of lines of JavaScript. I would for example write a basic hamburger menu in HSX/HTML.</li><li>Use HSX for <strong>forms</strong>. Forms are pretty much always a bigger pain written in app code. If you have been living in the Single Page App world for a while, you will realize forms written in normal HTML is not that bad. IHP gives you a convenient way of writing forms with server-side validation.</li><li>Use Elm for the <strong>advanced UI stuff</strong> requiring heavy use of DOM manipulation. Elm shines in writing user interfaces with high complexity. If the lines of JavaScript are getting too many, turn to Elm!</li><li>Do you want the content to have <strong>SSR</strong> for search engine optimization? Use HSX.</li></ul><p>So unless you really want to write a full Single Page App, Elm should be used with restraint in IHP, for only specific supercharged parts of the site.</p><p><strong>Most sites are actually better off outputting just HTML and CSS.</strong></p><h2>Next up</h2><p>I want to take this application further in future posts showing you how to interact between IHP and Elm, and how use Elm within protected boundaries (requiring authentication). <a href="https://driftercode.com/blog/passing-flags-from-ihp-to-elm">Read on to part 2 if these are topics that intrigue you 😊</a></p></article></div>]]>
            </description>
            <link>https://driftercode.com/blog/ihp-with-elm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453058</guid>
            <pubDate>Thu, 17 Dec 2020 06:05:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React's UseRef Deep Dive]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25452146">thread link</a>) | @giovannibenussi
<br/>
December 16, 2020 | https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1 | <a href="https://web.archive.org/web/*/https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/Article"><header></header><p><code>useRef</code> allows you to keep a mutable value within a component, similar to <code>useState</code> or instance variables on a class, without triggering re-renders.</p><p>For example, this component stores the number of clicks for a button:</p><div data-language="jsx"><pre><code><span>function</span> <span>RefButton</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> clicks <span>=</span> <span>useRef</span><span>(</span><span>0</span><span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks<span>.</span>current <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>.</span>current<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>This is how this component looks like (I added a re-render button so you can
actually test it out 😄):</p><div><h2>Interactive Example</h2><p>The example below is completely interactive, try clicking the "Clicks" button and then click on "Re-render".</p></div><p>As you can see, if you click the "Clicks" button it doesn't do anything. However, after click on "Re-render", it gets updated with the number of clicks we did previously.</p><h2>Difference with a variable</h2><p>You might wonder why not just use a simple variable as the example below:</p><div data-language="jsx"><pre><code><span>let</span> clicks <span>=</span> <span>0</span><span>;</span>

<span>function</span> <span>OutsideVariableButton</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>And here's an interactive example for it:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span></p></div><p>The button works the same way that our previous example. However, the problem arises when you have multiple instances of the same component like the example below. Try clicking just one of the buttons and then click on re-render to see the result.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span><span>outside variable</span><span>outside variable</span></p></div><p>As you were able to see, the clicks are not isolated. In fact, all the examples
from this article uses the same button component, so if you click the button
from the first example and then click on "re-render" on the second example, the count it is gonna be
incremented! What a bug 🐛.</p><p>On the other hand, <code>useRef</code> values are completely isolated between components:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>ref</span><span>ref</span><span>ref</span></p></div><h2>Difference with&nbsp;useState</h2><blockquote><p>The main difference between useState and useRef, is that useState triggers a
re-render and useRef doesn't.</p></blockquote><p>In the following example I added two buttons: one that updates its count with <code>useRef</code> and the other one with <code>useState</code>. I added some labels so you can identify them easily.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>state</span><span>ref</span></p></div><p>You'll notice that clicking on the button with <code>useRef</code> doesn't trigger a re-render and thus, the view isn't updated. On the other side, when you click on the button that uses <code>useState</code>, it will update its clicks count immediately.</p><p>To perform imperative actions on DOM nodes, React provides a way to get a
reference to them via refs. All you have to do is to assign a <code>ref</code> property to
a node with a ref object like this:</p><div data-language="jsx"><pre><code><span>function</span> <span>CustomInput</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>The way to get a DOM reference using refs works (informally 😅) as follows:</p><div><p><span>Today</span></p><div><p>React</p><p>Hey, what's up?<span>12:00</span></p></div><div><p>Could you give me a reference to this dom node?<span>12:00<svg style="color:#34B7F1" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><svg style="color:#34B7F1;margin-left:-12px" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg></span></p></div><div><p>React</p><p>Sure, I assigned it to the 'current' property of your ref.<span>12:00</span></p></div></div><p>On the first render, <code>inputRef</code>'s value will be <code>{ current: null }</code> and in the
following renders it will have its <code>current</code> property assigned to the specified DOM
node:</p><p>However, if you only reference <code>inputRef</code> inside <code>useEffect</code> then it'll always
reference the DOM node so you don't need to worry about it being undefined.</p><p>Let's update our example to get an idea of how this works:</p><div data-language="jsx"><pre><code><span>function</span> <span>AttachingToDomExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  console<span>.</span><span>log</span><span>(</span><span>"Render inputRef value:"</span><span>,</span> inputRef<span>)</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"useEffect inputRef value:"</span><span>,</span> inputRef<span>)</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>Here's the console output when rendering this component:</p><table><thead><tr><th>Render</th><th>Location</th><th>Value</th></tr></thead><tbody><tr><td>1</td><td>Render</td><td>{ current: undefined }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>2</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>3</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr></tbody></table><p>As you can see, if you access the <code>inputRef</code> inside <code>useEffect</code> then you don't
need to worry about it being <code>undefined</code> because React will assign it
automatically for you.</p><p>Let's start with a simple real-world application for refs: <code>usePrevious</code>. This
hook stores the previous value for a given state variable.
<a href="https://reactjs.org/docs/hooks-faq.html#how-to-get-the-previous-props-or-state" target="_blank" rel="nofollow">It is even referenced on React's docs</a> as a way to "get the previous props or state". Let's see it in
action first:</p><div data-language="jsx"><pre><code><span>function</span> <span>UsePreviousExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>clicks<span>,</span> setClicks<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span>
  
  <span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span>clicks<span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setClicks</span><span>(</span>clicks <span>+</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
        Clicks: </span><span>{</span>clicks<span>}</span><span> - Before: </span><span>{</span>previousClicks<span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>Here's the output so you can play with it:</p><p>You can notice that the <code>previousClicks</code> variable stores the value for the previous render
for a given variable. Here's its implementation:</p><div data-language="jsx"><pre><code><span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    ref<span>.</span>current <span>=</span> value
  <span>}</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>Let's analyze how it works.</p><p>Let's simulate what happens on the first render. We can remove the call to
<code>useEffect</code> since it doesn't affect the return value on the first render:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>On the first render it is called with a value of <code>0</code>:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>0</span><span>)</span></code></pre></div><p>In this case, <code>usePrevious</code> will return <code>undefined</code>:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>After increase the value for count, here's how the <code>usePrevious</code> call will look:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>1</span><span>)</span></code></pre></div><p>Since <code>usePrevious</code> is called again, its effect needs to run:</p><div data-language="jsx"><pre><code><span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  ref<span>.</span>current <span>=</span> <span>0</span>
<span>}</span><span>)</span></code></pre></div><p>After this, the <code>usePrevious</code> function is called again:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>And so on. Here's the value for each render for both variables:</p><table><thead><tr><th>Render</th><th>clicks</th><th>previousClicks</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>undefined</td></tr><tr><td>2</td><td>1</td><td>0</td></tr><tr><td>3</td><td>2</td><td>1</td></tr><tr><td>4</td><td>3</td><td>2</td></tr></tbody></table><p>Callback Refs are a different way to set refs. It gives you a fine-grain control
over when refs are attached and detached because you provide a function instead
of a ref variable. This function gets called every time the component mounts and
unmounts.</p><p><a href="https://codesandbox.io/s/callback-ref-example-lqe8w?file=/src/App.js" target="_blank" rel="nofollow">Here's an example</a> that shows/hides an emoji every time you click its button.
The important thing here is the <code>ref</code> prop that we added. We use a function to log
the provided ref:</p><div data-language="jsx"><pre><code><span>const</span> <span>callback</span> <span>=</span> <span>(</span><span>ref</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"callback:"</span><span>,</span> ref<span>)</span>

<span>function</span> <span>App</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>show<span>,</span> setShow<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setShow</span><span>(</span><span>!</span>show<span>)</span><span>}</span></span><span>&gt;</span></span><span>
        </span><span>{</span>show <span>?</span> <span>"Hide"</span> <span>:</span> <span>"Show"</span><span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span>{</span>show <span>&amp;&amp;</span> <span><span><span>&lt;</span>span</span> <span>ref</span><span><span>=</span><span>{</span>callback<span>}</span></span><span>&gt;</span></span><span>👋</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div><p>Here's an interactive version of the previous code (you can check the output in
the console to see that I'm not lying 🙃):</p><p><em>Note: If you use callback refs as inline functions, it will be called
twice: one with <code>null</code> and another one with the DOM element.
This is because React needs to clear the previous ref every time the function is
created. A workaround for this is to use a class method.</em></p><div><h2>Warning</h2><p><a href="https://reactjs.org/docs/refs-and-the-dom.html#legacy-api-string-refs" target="_blank" rel="nofollow">String refs</a> are a legacy feature and they are likely to be removed in future React versions.</p></div><p>The way it works is that you provide a string as a ref value like <code>ref="exampleRef"</code> and it automatically gets assigned to <code>this.refs</code>.</p><p><em>Note: String refs can only be used with class components.</em></p><p>Here's an usage example:</p><div data-language="jsx"><pre><code><span>export</span> <span>default</span> <span>class</span> <span>App</span> <span>extends</span> <span>React<span>.</span>Component</span> <span>{</span>
  <span>render</span><span>(</span><span>)</span> <span>{</span>
    console<span>.</span><span>log</span><span>(</span><span>this</span><span>.</span>refs<span>)</span><span>;</span>

    <span>return</span> <span>(</span>
      <span><span><span>&lt;</span>div</span> <span>ref</span><span><span>=</span><span>"</span>exampleRef<span>"</span></span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span> dummy<span>:</span> <span>0</span> <span>}</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>Re-render</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Here's the value for <code>this.refs</code> across renders:</p><table><thead><tr><th>Render</th><th>this.refs</th></tr></thead><tbody><tr><td>1</td><td><code>{}</code></td></tr><tr><td>2</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>3</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>4</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr></tbody></table><p>As you can see, on the first render <code>this.refs.exampleRef</code> will be undefined and
on the following renders it will point out to the specified DOM node.</p><p>We saw what <code>useRef</code> is, how it differentiates with a plain old variable and
state variables, and we saw real world examples that uses it. I hope that most
of the content makes sense to you!</p><p>I'd love to hear your feedback. You can <a href="https://twitter.com/giovannibenussi" target="_blank" rel="nofollow">reach out to me on
Twitter</a> at any time :-)</p><hr></article></div></div>]]>
            </description>
            <link>https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25452146</guid>
            <pubDate>Thu, 17 Dec 2020 03:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Probabilistic Data Labels to Train a Classifier]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25451910">thread link</a>) | @gk1
<br/>
December 16, 2020 | https://www.watchful.io/tutorials/working-with-probabilistic-data-labels-to-train-a-classifier | <a href="https://web.archive.org/web/*/https://www.watchful.io/tutorials/working-with-probabilistic-data-labels-to-train-a-classifier">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>The Labeling Problem</h2><p>The efficacy of a machine learning model is limited to the quality and quantity of data being used to train the model. The most powerful models typically require massive amounts of data to train. If the target variables in the model are categorical, there is an equally massive amount of labels in the dataset. Unfortunately, most of these labels are done by hand-- a painstakingly slow and resource intensive process. The time and resources that come with labeling datasets by hand creates inefficiencies in many machine learning pipelines. The categorical datasets that data scientists and programmers often learn from – such as those hosted on the <a href="https://archive.ics.uci.edu/ml/datasets.php">UCI Machine Learning Repository </a>or those preprocessed and uploaded to <a href="https://www.kaggle.com/datasets">Kaggle</a> – are idealized cases that do not reflect the typical reality of handling categorical data. In these datasets, someone has already taken the time to clean and process the data, providing the labels needed to train machine models. In real-life cases, this is usually not the case.</p><p>The origin of the categorical data labels often varies with the type of data in question. For example, pattern-recognition algorithms are often trained on labels provided through crowdsourcing. An algorithm trying to distinguish dogs from cats in images relies on humans to label each image beforehand. In ambiguous images, multiple people can assign different labels, resulting in a lower confidence for each category. On the other hand, medical diagnoses are often given in degrees of confidence either by some predefined test or by the doctor themselves. Similarly, natural language processing algorithms use confidence metrics to evaluate which definition of a word to employ (and, therefore, which meaning is intended) based on the context in which it is used. Despite the apparent categorical nature to these use cases, the reality can be quite the opposite.</p><p>Common in all of these cases is the association of a <em>probability </em>with the label. Whether the probability is simply an ensemble of multiple labels or intrinsic to the labeling methodology, the machine learning algorithms that train on these datasets must be able to handle probabilistic data labels. In some sense, the probability of a label is more informative than the label itself, as it also conveys the degree of confidence for a given observation. Understanding how to take advantage of this, and which approaches to handling these probabilistic data labels produce better models is a practical skill for data scientists and programmers encountering real-world categorical datasets. Additionally, tools that speed up or automate the labeling process in the machine learning pipeline resolve the inefficiencies that come with human labeling. Programmatically labeling is one such approach to do so.</p><p>In this tutorial, I use Python to walk through several different approaches to using probabilistic data labels to train machine learning models. I use a dataset that has both probabilistic labels and true labels to show that, if the probabilistic labels are of high quality, they are more than sufficient in constructing high performance machine learning models.</p><h2>Getting Started</h2><p>To follow along with the code in this tutorial, you’ll need to have a recent version of Python installed. I use the <a href="https://anaconda.org/">Anaconda Navigator</a> for all my programming needs, but the code used in this tutorial is generalized to work with any Python 3.7 distribution. To install Anaconda, go <a href="https://docs.anaconda.com/anaconda/install/">here</a>. &nbsp;You can find all of the code and data used on my <a href="https://gitlab.com/dsblendo/prob_data_labels">GitLab repository</a>.</p><p>All of the packages I will be using are prebuilt into the Anaconda distribution, except for the <a href="https://keras.io/">Keras package</a>. Keras provides us with the building blocks to construct our neural nets. To install for use in Anaconda, we can use <a href="https://conda-forge.org/">conda-forge</a> (you may also have to <a href="https://conda-forge.org/docs/user/introduction.html">install conda-forge</a>):</p><p>&lt;pre&gt;&lt;code class="python"&gt;conda install -c conda-forge keras&lt;/code&gt;&lt;/pre&gt;</p><p>Alternatively, if you are using another Python distribution, you can install Keras with pip:</p><p>&lt;pre&gt;&lt;code class="python"&gt;pip install keras&lt;/code&gt;&lt;/pre&gt;</p><p>To import the necessary packages and functions that we will use, in Python run:</p><p>&lt;pre&gt;&lt;code class="python"&gt;<strong>import</strong> numpy <strong>as</strong> np<br><strong>import</strong> pandas <strong>as</strong> pd<br><strong>import</strong> matplotlib.pyplot <strong>as</strong> plt<br><strong>from</strong> sklearn.metrics <strong>import</strong> accuracy_score<br><strong>from</strong> sklearn.metrics <strong>import</strong> precision_recall_fscore_support <br><strong>from</strong> sklearn.model_selection <strong>import</strong> train_test_split<br><strong>from</strong> sklearn.feature_extraction.text <strong>import</strong> TfidfVectorizer<br><strong>from</strong> keras.models <strong>import</strong> Model<br><strong>from</strong> keras <strong>import</strong> optimizers<br><strong>from</strong> keras.layers <strong>import</strong> Input, Dense, Dropout&lt;/code&gt;&lt;/pre&gt;</p><p>If any error indicates that a package cannot be found, simply install it using the same syntax as above, switching out the package name as needed. <br>‍</p><p>The data I will be working with is the <a href="https://www.kaggle.com/wanderfj/enron-spam">Enron Spam classification dataset</a> from Kaggle. The dataset contains the text from 33,715 emails that are classified as either wanted (ham) or unwanted (spam). &nbsp;As can be seen below, the &lt;pre class="inline"&gt;&lt;code class="python"&gt;Text&lt;/code&gt;&lt;/pre&gt; column contains the text of each email. We will use this text to train our model to classify the email as either ham or spam. </p><p>The &lt;pre class="inline"&gt;&lt;code class="python"&gt;Spam_Gold&lt;/pre&gt;&lt;/code&gt; column contains the ‘gold’ labels included in the original <em>.csv</em> file from Kaggle: 0 for ham and 1 for spam. There is an additional column that is not in the original Kaggle dataset: the &lt;pre class="inline"&gt;&lt;code class="python"&gt;Spam_Pred&lt;/pre&gt;&lt;/code&gt;<em> </em>column<em>.</em> This column contains probabilistic labels from 0 to 100 (rather than the binary labels in the &lt;pre class="inline"&gt;&lt;code class="python"&gt;Spam_Gold&lt;/pre&gt;&lt;/code&gt; column) that indicate the probability of each email belonging to the spam class. </p><p>These probabilities were programmatically labeled using <a href="https://www.watchful.io/">Watchful</a>, without looking at the original gold labels. It would take days for a human to label each email to by hand, while Watchful accomplished this in around 3 hours. &nbsp; </p><p>To import the dataset, we can use the<em> </em>&lt;pre class="inline"&gt;&lt;code class="python"&gt;pandas&lt;/code&gt;&lt;/pre&gt; package:</p><p>&lt;pre&gt;&lt;code class="python"&gt;file_path = 'watchful_export.csv'<br>email_df = pd.read_csv(file_path)<br>email_df.head()&lt;/code&gt;&lt;/pre&gt;</p><p>The output should look something like this:</p><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551c4e081336a4_lMVu2dmf4RMJnd1IEucaulz17cuRIdK4qweUknWLuduEplP55gg4a9TYNu-OtnZW5uvadw8pTtl3fFnq3gPXhlkg4zbzD2azXTUmdcV5YOBF1R5BYANjItlhYmXjNmjbbkUR0zJD.png" alt=""></p></figure><p>All set? Let’s go.</p><h2>Exploring the Data</h2><p>Before we get to the model implementation, it is always a good idea to explore the data we are working with. We can also compare the probabilistic data labels provided by Watchful with the original gold labels and evaluate how well the algorithm did. In most real-life cases, this is not possible, as the true labels are either limited to a few observations, not known at all, or have poor quality. </p><p>First, it is worth looking at the distribution of spam and ham emails in the gold labels and the probabilistic labels. This gives us an idea of the balance of the dataset, as well as how well the probabilistic labels match up to the gold labels. &nbsp;</p><p>&lt;pre&gt;&lt;code class="python"&gt;gold_col_name = 'Spam_Gold'<br>pred_col_name = 'Spam_Pred'<br>text_col_name = 'Text'<br>pct_spam = email_df[gold_col_name].sum() / email_df.shape[0]<br>pct_ham = 1 - pct_spam<br>pct_spam, pct_ham&lt;/code&gt;&lt;/pre&gt;</p><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551c78a41336c8_VtYibTj6IYwpv8vQnofsEzLXZknIAdMi-NyTfM8ep6hDCBAIm1-nF7ZJGwK2hGhgq-Kv2n4XKObnIri8Nd9vTg8g8Jocgok0BPzgRvey6eUbl1xuCBdEanlQdeESi2KdGvf7yHlK.png" alt=""></p></figure><p>So, the dataset has nearly an equal distribution of spam and ham emails. Dealing with sparse data is not trivial for most machine learning algorithms. Fortunately, we don’t have to worry about it. As, expected, the histogram of gold labels is nearly equal in height:</p><p>&lt;pre&gt;&lt;code class="python"&gt;plt.hist(email_df[gold_col_name])<br>plt.show()&lt;/code&gt;&lt;/pre&gt;</p><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551c35f4133692__jnMfpcDBpKOL_PUwnyz0kWOWBaZaRA2v8hf5CsFdfQBMSTqqmR7qFd2chzDdjsKYgwmaUqsF_EZ_wPPfgxwp-Ylb0Y6IW8y8XqSSVaEPKIk63E6mKwMKt2rC4cdQXP9nrCRJ-Fp.png" alt=""></p></figure><p>And for the probabilistic labels:</p><p>&lt;pre&gt;&lt;code class="python"&gt;plt.hist(email_df[pred_col_name])<br>plt.show()&lt;/code&gt;&lt;/pre&gt;<br></p><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551ccb721336ec_fcbwX4G08cR9jGH2dHljz611Pmh4PXe1xLE_1hRmApL3Bx-qTG5nMZwTQS9g141qSpW2Bk6JktXXrvBjayV8Hw41vqpGso3MBR8Hi8Lni2nwtlaObjuu2IbQKwr_Y6NCP_Hs-dGc.png" alt=""></p></figure><p>The distributions are pretty similar. This is an indication that the probabilistic labels assigned by Watchful are well aligned with the gold labels – a promising sign for being solely generated by the email text. </p><p>‍</p><p>From a qualitative perspective, certain characteristics of the emails are bound to correlate with either being spam or ham. For example, one could imagine that curt, plain text is probably not an advertisement for some product and is therefore an indicator of a ham email. On the other hand, text that is long and superfluous is generally more common in advertisements, and may indicate a spam email. </p><p>To get an idea of the distribution of the number of words used in the emails, we can take advantage of Python’s list comprehension syntax:</p><p>&lt;pre&gt;&lt;code class="python"&gt;lengths = np.array([len(doc.split()) <strong>for</strong> doc <strong>in</strong> email_df[text_col_name]])<br>pd.DataFrame(lengths).describe()&lt;/code&gt;&lt;/pre&gt;<br></p><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551c243c1336b6_EYN_5xU56hJ15QgNOLP3EmEqd6gF-mP-PgWbdv-JyDiBLvPYUFapSe0m5yP1tZ_gS-OeoWU-JQrhyjCf04-MSbqO0DO30rd-X22ToTLL8M9bcYFkRTxlua8mGFmeB31oa226knO9.png" alt=""></p></figure><p>And to visualize the email length distribution:</p><p>&lt;pre class="inline"&gt;&lt;code class="python"&gt;plt.hist(lengths[lengths &lt; 1000])&lt;/code&gt;&lt;/pre&gt;</p><p>&lt;pre class="inline"&gt;&lt;code class="python"&gt;plt.show()&lt;/code&gt;&lt;/pre&gt;<br></p><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551c99b21336da_yrc6gT2jZBziyvh20WyReaApqY-f8qhxSmFPhCQCQI6wuX7bouHAKja3bGZlMy8knBZcVrh-9Qtlgnmc6GWxyv61Fz5YEGbK5DniKzEJmf7_wLRdUg3eSbGHnqk8JbGX-od97H__.png" alt=""></p></figure><p>The distribution is heavily skewed, as expected for a text-based communication medium – most emails are relatively short, and the probability of a longer email scales inversely with the length. It is also worth looking at the number of unique words used in each email. This distribution should mimic the right-skewed distribution of the email word length. </p><div><p>&lt;pre&gt;&lt;code class="python"&gt;vocabs = np.array([len(set(doc.split())) <strong>for</strong> doc <strong>in</strong> email_df[text_col_name]])</p><p>pd.DataFrame(vocabs).describe()&lt;/code&gt;&lt;/pre&gt;</p></div><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551c88f91336fd_X4k57jF3VKR00pfNdxr0-ORZUR-251vs9tYtt_a1eS0qHzaZzbYzd70XF8woxKHUTIK8WWiXVT8fKhkhz2zU-DU0a6zWgIjreGsU3UJU1Y_HIekb1m_LuiOrrrVKstQwOdaxXXs5.png" alt=""></p></figure><p>‍</p><p>&lt;pre&gt;&lt;code class="python"&gt;plt.hist(vocabs[vocabs &lt; 500])<br>plt.show()&lt;/code&gt;&lt;/pre&gt;<br></p><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551c5422133707_or_uT0Z79lUjkht-xysIgvUqg6HoUvC-9EeyNSthoNmR_MvnxdxNlfhNDsi8d3ZyLcOYOglhndXgBIA9Zi3bmADhcXj4qcPMP1rOot2lrsndJ4u7THPsbl58L1RnIpAKUUrMVCNc.png" alt=""></p></figure><p>The distribution is reasonable relative to the email length distribution. One would expect that common articles (‘a’, ‘the’, ‘and’, etc.) &nbsp;are repeated several times in a given email, and the true number of unique words is 2-4x lower than the total number of words. We can also check how well the probabilistic labels align with the gold labels, assuming a probability higher than 50% indicates a spam. &nbsp;</p><p>&lt;pre&gt;&lt;code class="python"&gt;email_df[pred_col_name] = email_df[pred_col_name].apply(<strong>lambda</strong> r: 0 <strong>if</strong> r &lt; 50 <strong>else</strong> 1)<br>accuracy_score(email_df[gold_col_name], email_df[pred_col_name], <strong>True</strong>)&lt;/code&gt;&lt;/pre&gt;</p><figure><p><img src="https://assets.website-files.com/5f93514c79551c30eb133543/5f93514c79551c6a16133706_Q83d1T3H5OHW4HC4iQ84zH8JVqFP9q83zDKUmhtQL21ZHkoJSBBmY5dXGJKjksN-Lt1Uvue8HguhFTD327Aziu14VYr25kjDwhiyvxUZzUDuqRoxqw3GGRW_I6RIyWhcCNm2Adts.png" alt=""></p></figure><p>The agreement is pretty good assuming a simple 50% threshold. When handling classification data, accuracy is not the only important metric in evaluating how well a given model performs (in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.watchful.io/tutorials/working-with-probabilistic-data-labels-to-train-a-classifier">https://www.watchful.io/tutorials/working-with-probabilistic-data-labels-to-train-a-classifier</a></em></p>]]>
            </description>
            <link>https://www.watchful.io/tutorials/working-with-probabilistic-data-labels-to-train-a-classifier</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451910</guid>
            <pubDate>Thu, 17 Dec 2020 03:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passing of a Great Mind (1957)]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25451727">thread link</a>) | @unclefuzzy
<br/>
December 16, 2020 | https://qualiacomputing.com/2018/06/21/john-von-neumann/ | <a href="https://web.archive.org/web/*/https://qualiacomputing.com/2018/06/21/john-von-neumann/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2>Passing of a Great Mind</h2>
<h3>John von Neumann, a Brilliant, Jovial Mathematician, was a Prodigious Servant of Science and his Country</h3>
<p><em>by Clary Blair Jr</em>. –&nbsp;<em>Life Magazine</em>&nbsp;(February 25th, 1957)</p>
<p>The world lost one of its greatest scientists when Professor John von Neumann, 54, died this month of cancer in Washington, D.C. His death, like his life’s work, passed almost unnoticed by the public. But scientists throughout the free world regarded it as a tragic loss. They knew that Von Neumann’s brilliant mind had not only advanced his own special field, pure mathematics, but had also helped put the West in an immeasurably stronger position in the nuclear arms race. Before he was 30 he had established himself as one of the world’s foremost mathematicians. In World War II he was the principal discoverer of the implosion method, the secret of the atomic bomb.</p>
<p>The government officials and scientists who attended the requiem mass at the Walter Reed Hospital chapel last week were there not merely in recognition of his vast contributions to science, but also to pay personal tribute to a warm and delightful personality and a selfless servant of his country.</p>
<p>For more than a year Von Neumann had known he was going to die. But until the illness was far advanced he continued to devote himself to serving the government as a member of the Atomic Energy Commission, to which he was appointed in 1954. A telephone by his bed connected directly with his EAC office. On several occasions he was taken downtown in a limousine to attend commission meetings in a wheelchair. At Walter Reed, where he was moved early last spring, an Air Force officer, Lieut. Colonel Vincent Ford, worked full time assisting him. Eight airmen, all cleared for top secret material, were assigned to help on a 24-hour basis. His work for the Air Force and other government departments continued. Cabinet members and military officials continually came for his advice, and on one occasion Secretary of Defence Charles Wilson, Air Force Secretary Donald Quarles and most of the top Air Force brass gathered in Von Neumann’s suite to consult his judgement while there was still time. So relentlessly did Von Neumann pursue his official duties that he risked neglecting the treatise which was to form the capstone of his work on the scientific specialty, computing machines, to which he had devoted many recent years.</p>
<p><img data-attachment-id="26616" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_1_1/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1316%2C920&amp;ssl=1" data-orig-size="1316,920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_1_1" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=300%2C210&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1000%2C699&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;ssl=1" alt="von_neumann_1_1" width="1000" height="699" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>His fellow scientists, however, did not need any further evidence of Von Neumann’s rank as a scientist – or his assured place in history. They knew that during World War II at Los Alamos Von Neumann’s development of the idea of implosion speeded up the making of the atomic bomb by at least a full year. His later work with electronic computers quickened U.S. development of the H-bomb by months. The chief designer of the H-bomb, Edward Teller, once said with wry humor that Von Neumann was “one of those rare mathematicians who could descend to the level of the physicist.” Many theoretical physicists admit that they learned more from Von Neumann in methods of scientific thinking than from any of their colleagues. Hans Bethe, who was director of the theoretical physics division at Los Alamos, says, “I have sometimes wondered whether a brain like Von Neumann’s does not indicate a species superior to that of man.”</p>
<p><img data-attachment-id="26617" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_2/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" data-orig-size="226,304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_2" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=223%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;ssl=1" alt="von_neumann_2" width="226" height="304" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The foremost authority on computing machines in the U.S., Von Neumann was more than anyone else responsible for the increased use of the electronic “brains” in government and industry. The machine he called MANIAC (mathematical analyzer, numerical integrator and computer), which he built at the Institute for Advanced Study in Princeton, N.J., was the prototype for most of the advanced calculating machines now in use. Another machine, NORC, which he built for the Navy, can deliver a full day’s weather prediction in a few minutes. The principal adviser to the U.S. Air Force on nuclear weapons, Von Neumann was the most influential scientific force behind the U.S. decision to embark on accelerated production of intercontinental ballistic missiles. His “theory of games,” outlined in a book which he published in 1944 in collaboration with Economist Oskar Morgenstern, opened up an entirely new branch of mathematics. Analyzing the mathematical probabilities behind games of chance, Von Neumann went on to formulate a mathematical approach to such widespread fields as economics, sociology and even military strategy. His contributions to the quantum theory, the theory which explains the emission and absorption of energy in atoms and the one on which all atomic and nuclear physics are based, were set forth in a work entitled <em>Mathematical Foundations of Quantum Mechanics</em>&nbsp;which he wrote at the age of 23. It is today one of the cornerstones of this highly specialized branch of mathematical thought.</p>
<p>For Von Neumann the road to success was a many-laned highway with little traffic and no speed limit. He was born in 1903 in Budapest and was of the same generation of <a href="http://slatestarcodex.com/2017/05/26/the-atomic-bomb-considered-as-hungarian-high-school-science-fair-project/">Hungarian physicists</a> as Edward Teller, Leo Szilard and Eugene Wigner, all of whom later worked on atomic energy development for the U.S.</p>
<p>The eldest of three sons of a well-to-do Jewish financier who had been decorated by the Emperor Franz Josef, John von Neumann grew up in a society which placed a premium on intellectual achievement. At the age of 6 he was able to divide two eight-digit numbers in his head. By the age of 8 he had mastered college calculus and as a trick could memorize on sight a column in a telephone book and repeat back the names, addresses and numbers. History was only a “hobby,” but by the outbreak of World War I, when he was 10, his photographic mind had absorbed most of the contents of the 46-volume works edited by the German historian Oncken with a sophistication that startled his elders.</p>
<p>Despite his obvious technical ability, as a young man Von Neumann wanted to follow his father’s financial career, but he was soon dissuaded. Under a kind of supertutor, a first-rank mathematician at the University of Budapest named Leopold Fejer, Von Neumann was steered into the academic world. At 21 he received two degrees – one in chemical engineering at Zurich and a PhD in mathematics from the University of Budapest. The following year, 1926, as Admiral Horthy’s rightist regime had been repressing Hungarian Jews, he moved to Göttingen, Germany, then the mathematical center of the world. It was there that he published his major work on quantum mechanics.</p>
<h4>The young professor</h4>
<p>His fame now spreading, Von Neumann at 23 qualified as a <em>Privatdozent</em>&nbsp;(lecturer) at the University of Berlin, one of the youngest in the school’s history. But the Nazis had already begun their march to power. In 1929 Von Neumann accepted a visiting lectureship at Princeton University and in 1930, at the age of 26, he took a job there as professor of mathematical physics – after a quick trip to Budapest to marry a vivacious 18-year-old named Mariette Kovesi. Three years later, when the Institute for Advanced Study was founded at Princeton, Von Neumann was appointed – as was Albert Einstein – to be one of its first full professors. “He was so young,” a member of the institute recalls, “that most people who saw him in the halls mistook him for a graduate student.”</p>
<p><img data-attachment-id="26618" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_3/" data-orig-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1210%2C1028&amp;ssl=1" data-orig-size="1210,1028" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_3" data-image-description="" data-medium-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=300%2C255&amp;ssl=1" data-large-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1000%2C850&amp;ssl=1" loading="lazy" src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;ssl=1" alt="von_neumann_3" width="1000" height="850" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Although they worked near each other in the same building, Einstein and Von Neumann were not intimate, and because their approach to scientific matters was different they never formally collaborated. A member of the institute who worked side by side with both men in the early days recalls, “Einstein’s mind was slow and contemplative. He would think about something for years. Johnny’s mind was just the opposite. It was lightning quick – stunningly fast. If you gave him a problem he either solved it right away or not at all. If he had to think about it a long time and it bored him, hist interest would begin to wander. And Johnny’s mind would not shine unless whatever he was working on had his undivided attention.” But the problems he did care about, such as his “theory of games,” absorbed him for much longer periods.</p>
<h4>‘Proof by erasure’</h4>
<p>Partly because of this quicksilver quality Von Neumann was not an outstanding teacher to many of his students. But for the advanced students who could ascend to his level he was inspirational. His lectures were brilliant, although at times difficult to follow because of his way of erasing and rewriting dozens of formulae on the blackboard. In explaining mathematical problems Von Neumann would write his equations hurriedly, starting at the top of the blackboard and working down. When he reached the bottom, if the problem was unfinished, he would erase the top equations and start down again. By the time he had done this two or three times most other mathematicians would find themselves unable to keep track. On one such occasion a colleague at Princeton waited until Von Neumann had finished and said, “I see. Proof by erasure.”</p>
<p>Von Neumann himself was perpetually interested in many fields unrelated to science. Several years ago his wife gave him a 21-volume Cambridge History set, and she is sure he memorized every name and fact in the books. “He is a major expert on all the royal family trees in Europe,” a friend said once. “He can tell you who fell in love with whom, and why, what obscure cousin this or that czar married, how many illegitimate children he had and so on.” One night during the Princeton days a world-famous expert on Byzantine history came to the Von Neumann house for a party. “Johnny and the professor got into a corner and began discussing some obscure facet,” recalls a friend who was there. “Then an argument arose over a date. Johnny insisted it was this, the professor that. So Johnny said, ‘Let’s get the book.’ They looked it up and Johnny was right. A few weeks later the professor was invited to the Von Neumann house again. He called Mrs. von Neumann and said jokingly, ‘I’ll come if Johnny promises not to discuss Byzantine history. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qualiacomputing.com/2018/06/21/john-von-neumann/">https://qualiacomputing.com/2018/06/21/john-von-neumann/</a></em></p>]]>
            </description>
            <link>https://qualiacomputing.com/2018/06/21/john-von-neumann/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451727</guid>
            <pubDate>Thu, 17 Dec 2020 02:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Graying of Gnome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25451433">thread link</a>) | @pabs3
<br/>
December 16, 2020 | https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/ | <a href="https://web.archive.org/web/*/https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div id="content"><section id="primary"><main id="main" role="main"><article id="post-622"><div><p><a href="https://gnome.org/">The GNOME project</a> turned 23 this year, and despite equally persistent rumors to the contrary, it’s still alive and kicking.</p><p>Just how alive, though? All I know is this: Where the topic of GNOME’s health goes, accurate data rarely follows. Of course, there <em>is</em> data — lots of it in fact, in public source code repositories. Though flawed in many ways, it allows us to make comparisons to the past — and maybe predictions for the future: Are a few organizations carrying most of the workload, making them critical points of failure? Are new contributors able to pick up the slack from those who leave? Is the project graying (i.e. increasingly dominated by veterans)?</p><p>In one of my occasional fits of hubris, I set out to process this data to see if I could shake out anything meaningful. I’m usually fine with just satisfying my own curiosity and leaving it at that, but it’s one of those times where the results seem interesting enough for a blog post. So here we are.</p><p>I’m going to lead with the nice graphs and follow on with a <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#methodology">section on methodology</a>. The latter is long, boring, and mandatory reading.</p><h2 id="contributors">Active contributors</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png" alt="Active GNOME authors per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>The stacked histogram above shows the number of contributors who touched the project on a yearly basis. Each contributor is assigned to a generational cohort based on the year of their first contribution. The cohorts tend to shrink over time as people leave.</p><p>There’s a special “drive-by” cohort (in a fetching shade of off-white) for contributors who were only briefly involved, meaning all their activity fits in a three-month window. It’s a big group. In a typical year, it numbers 200-400 persons who were not seen before or since. Most of them contribute a single commit.</p><p>According to this, GNOME peaked at slightly above 1,400 contributors in 2010 and went into decline with the GNOME 3.0 release the following year. However, 2020 saw the most contributors in a long time, even with preliminary data — there’s still two weeks to go. Who knows if it’s an anomaly or not. It’s been an atypical year across the board.</p><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png" alt="Active GNOME authors per month, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>This is the same histogram, but with per-month bins. There’s a clear periodicity caused by the semiannual release cycle. The peak month was March 2011, right before the <a href="https://www.gnome.org/press/2011/04/gnome-3-0-released-better-for-users-developers-3/">GNOME 3.0 release</a>. About 450 contributors got involved that month.</p><p>The drive-by cohort is relatively smaller on a monthly basis. This makes sense, as it has little overlap from month to month, and the per-year bins tend to add them all up.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png" alt="Active GNOME authors per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Above, the top 15 affiliations of active contributors. I’ve excluded personal accounts. This is pretty flawed (details below), but interesting nonetheless. For what it’s worth, it mostly lines up with my memory of things.</p><p>The pattern tracks well with the total despite only capturing a minority portion of it. I think this means that paid and unpaid contributions are driven by the same underlying trends, or that there’s a lot of the former hiding in the latter.</p><h2 id="commitcount">Commit count</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png" alt="Number of GNOME commits per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Here I’m counting the number of commits per year in the various cohorts.</p><p>At first glance, this looks much less dire. However, note how newcomers are having a smaller impact, especially from 2014 on. And the 2018-2020 bounce is entirely due to a handful of veterans making a comeback.</p><p>Half the commits in 2020 were made by contributors who’ve been with the project for ten years or more. Also noteworthy, drive-by commits are a vanishingly small portion of the total.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png" alt="Number of GNOME commits per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Top 15 affiliations again, but now ordered by commit counts. It’s safe to say that GNOME is dependent on paid developers in a big way. Specifically, and to no one’s surprise, it leans heavily on Red Hat.</p><h2 id="observations">General observations</h2><p>A few observations can be made with confidence:</p><ul><li>By F/OSS standards, the project is not <em>un</em>healthy. It has hundreds of experienced and first-time contributors every year. It is well-organized and arguably well-funded compared to its peers. But:</li><li>Every metric has the project peaking around 2010.</li><li>A diminishing number of veterans is doing an increasing share of the work.</li><li>Although recruitment is stable, newcomers don’t seem to be hitting their stride in terms of commits.</li><li>Corporate sponsorship is probably necessary to keep the project going, but the field of sponsors has kept thinning.</li></ul><p>I think GNOME is addressing the risk factors competently by modernizing infrastructure (<a href="https://gitlab.gnome.org/">GitLab</a>, <a href="https://discourse.gnome.org/">Discourse</a>). This has obvious value even in the absence of quantifiable results, but it’ll be interesting to see if the effect can be measured over the next couple of years.</p><p>Diminished enthusiasm may also be due to there being fewer ways for a new contributor to make their mark or assume a role of responsibility. GNOME has become more conservative, certainly much more so than it was a decade ago in the run-up to GNOME 3. The rationale and phrasing in <a href="https://discourse.gnome.org/t/new-gnome-versioning-scheme/4235">the announcement of the new versioning scheme</a> (e.g. <em>“Radical technological and design changes are too disruptive for maintainers, users, and developers”</em>) seems indicative of this trend<sup>1</sup>.</p><h2 id="methodology">Notes on methodology</h2><p>So what’s wrong with this analysis? If you’re so inclined, you can find the details under the next couple of subheadings and pass harsh, harsh judgement.</p><p>I’ve set the unscientific rigor bar high enough to hopefully yield something useful, but low enough that I could do it in my spare time and not get stuck in the dreaded state commonly known as “90% done”.</p><h3>Module selection</h3><p>I aggregated data from <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-repos">189 Git repositories</a>. The vast majority of these are hosted on <code>gnome.org</code>, with a handful from <code>freedesktop.org</code> and <code>github.com</code>. Commits are uniquely identified by their commit hash, meaning trivial duplicates are counted only once.</p><p>GNOME has always been a decentralized, big-tent project, so it’s not obvious how to delineate it. I’ve tried to be fair by including most of the repositories from a full meta-gnome-desktop jhbuild, including fairly low-level dependencies like Cairo, Pango, and Pipewire, as well as past, present and would-be flagship applications under the GNOME umbrella. Documentation and infrastructure is represented, as are many archived projects (e.g. ORBit2, Bonobo, Sabayon, GAL).</p><p>I was a little uncertain about what to do with X.Org and Wayland. In the end I decided to include the latter, but not the former, since Wayland has close ties to GNOME (it even references GTK+ in its TODO file), while X.Org has its roots in the much older XFree86.</p><p>Mono is another project I resisted including; its development was tangential to GNOME proper, diverging completely in the most recent decade. However, I did include GtkSharp and several GNOME-hosted C# applications common on desktops in the 2005-2010 time frame.</p><p>Since I haven’t established hard criteria for module selection, it’s subject to various biases. Older code is probably underrepresented, since providers of important functionality were more loosely attached to the project early on (e.g. GNOME Online Accounts and Telepathy got pulled in, should I have included Gaim or Pidgin too? How about XChat?).</p><p>Anyway, the list isn’t terrible, but there’s room for improvement.</p><h3>Contributor identities</h3><p>Similar studies often identify contributors by their e-mail addresses. I used full author names instead, since there’s good reason to think they’re more stable over a 20-year time span. We’re fairly consistent in spelling our own names, and we change them rarely (often never). On the other hand, e-mail addresses come and go with different hosting arrangements, employers, etc.</p><p>An added challenge with this approach is that sometimes different people have the exact same name. In practice, I’m not aware of any instances of this happening in GNOME. It seems to be rare enough that I doubt it’d introduce significant error in most projects.</p><p>I should add here that the drive-by cohort depends on a fair amount of hindsight (you never know when someone might come back with more contributions, but the likelihood drops off quickly as time passes). This means the cohorts for 2020 are preliminary. They’ll be a lot more accurate with another run late next year.</p><h3>Domain names</h3><p>I’m using e-mail domain names as a proxy for organizations in some of the graphs. This is a notoriously unreliable approach for at least three reasons:</p><ol><li>Contributors often use personal e-mail addresses for paid work, leading to significant undercounting in general.</li><li>Specific companies may require their employees (or ask them nicely) to use company e-mail for collaboration. Out of the listed companies, I know of at least one that definitely did this. However, there are many that don’t, and these will be comparatively less well represented.</li><li>The mapping between DNS and organizations isn’t one-to-one. A company may operate under multiple names or TLDs (e.g. <code>.co.uk</code> and <code>.com</code>).</li></ol><p>Despite these weaknesses, it’s common to slice the data this way. It’s difficult to do better without access to semi-closed data troves, and depending on your views on privacy and ability to handle <a href="https://en.wikipedia.org/wiki/Personal_data">PII</a> safely, it might not be something you’d want to get into anyway. But I bet you’d be well-positioned for it if you were, say, the corporate owner of both LinkedIn and GitHub.</p><p>When grouping by organization, the goal is to get an idea of which outside entities are sponsoring contributions. Therefore, I’ve filtered out addresses from the biggest mass e-mail providers like <code>@gmail.com</code> and project-centric providers of personal accounts (e.g. <code>@gnome.org</code>, <code>@gtk.org</code>).</p><p>I took the liberty of reassigning the personal domains of a few extra prolific authors who would’ve otherwise showed up as individual organizations. Since there’s no way I’m doing it for everyone, this introduces some bias. The full details are in <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-meta.json">the project’s metadata file</a> (see: <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#code">code</a>).</p><h3>Version control systems</h3><p>Changeovers in version control systems divide GNOME’s VCS history into three eras with noticeable discontinuities between them.</p><h4>Before 1998: Dark ages</h4><p>In the Bad Old Days, Free Software would often use plain <a href="https://en.wikipedia.org/wiki/Revision_Control_System">RCS</a> or no version control at all. I have basically no data for this era: The GIMP, being the ur-project from which …</p></div></article></main></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</a></em></p>]]>
            </description>
            <link>https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451433</guid>
            <pubDate>Thu, 17 Dec 2020 01:57:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learning could be fundamentally unexplainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25451334">thread link</a>) | @eindiran
<br/>
December 16, 2020 | https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable | <a href="https://web.archive.org/web/*/https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-12-16</p>
        
<p>I'm going to consider a fairly unpopular idea: most efforts towards "explainable AI" are essentially pointless. Useful as an academic pursuit and topic for philosophical debate, but not much else.</p>
<p>Consider this article a generator of interesting intuitions and viewpoints, rather than an authoritative take-down of explainability techniques.</p>
<p>That disclaimer aside:</p>
<hr>
<p>What if almost every problem for which it is desirable to use machine learning is unexplainable?</p>
<p>At least unexplainable in an efficient-enough way to be worth explaining. Whether it is an algorithm or a human that is doing the explanation.</p>
<p>Let's define "<a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">explainable AI</a>" in a semi-narrow sense, inspired by the DARPA definition, as an inference system that can answer the questions:</p>
<blockquote>
<p>Why was that prediction made as a function of our inputs and their interactions?</p>
</blockquote>
<blockquote>
<p>Under what conditions would the outcome differ?</p>
</blockquote>
<blockquote>
<p>How confident can we be in this prediction and why is the confidence such?</p>
</blockquote>
<p>Why might we be unable to answer the above questions in a satisfactory manner for most machine learning algorithms? I think I can name four chief reasons:</p>
<ol>
<li>Some problems are just too complex to explain. Often enough, these are perfect problems for machine learning, it's exactly their intractability to our brains that makes them ideal for equation-generating algorithms to solve.</li>
<li>Some problems, while not that complex, are really boring and no human wants or should be forced to understand them.</li>
<li>Some problems can be understood, but understanding in itself is different for every single one of us, and people's culture and background often influence what "understanding" means. So explainable for one person is not explainable for another.</li>
<li>Even given an explanation that everyone agrees on, this usually puts us no closer to most of what we want to achieve with said explanation, things like gathering better data or removing "biases" from our models.</li>
</ol>
<h2>I - Unexplainable due to complexity</h2>
<p>Let's say, physicists, take in 100 PetaBytes of experimental data, reduce them using equations, and claim with a high probability that there exists this thing called a "Higgs Boson" with implications for how gravity works, among other things.</p>
<p>The resulting Boson can probably be defined within a few pages of text via things such as mass, the things it decays into, its charge, its spin, the various interactions it can have with other particles, and so on.</p>
<p>But if a luddite like myself asks the physicists:</p>
<blockquote>
<p>Why did you predict this fundamental particle exists?</p>
</blockquote>
<p>I will either get a "press conference answer" which carries no meaning other than providing a "satisfying" feeling, but it doesn't answer any of the above questions.</p>
<p>It doesn't tell me why the data shows the existence of the Higgs Boson, it doesn't tell me how the data could have been different in order for this not to be the case, and it doesn't tell me how confident they are in this inference and why.</p>
<p>If I press for an answer that roughly satisfies the explainability criteria I mentioned above, I will at best get them to say:</p>
<blockquote>
<p>Look, the standard model is a fairly advanced concept in physics, so you first have to understand that and why it came to be. Then you have to understand the experimental statistics needed to interpret the kind of data we work with here. In the process, you'll obviously learn quantum mechanics, but to understands the significance of the Higgs boson specifically it's very important that you have an amazing grasp of general relativity, since part of the reason we defined it as is and why it's so relevant is because it might be a unifying link between the two theories. Depending on how smart you are this might take 6 to 20 years to wrap your head around, really you won't even be the same person by the time you're done with this. And oh, once you get your Ph.D. and work with us for half a decade there's a chance you'll disagree with your statistics and our model and might think that we are wrong, which is fine, but in that case, you will find the explanation unsatisfactory.</p>
</blockquote>
<p>We are fine with this, since physics is bound to be complex, it earns its keep by being useful and making predictions about very specific things with very tight error margins, its fundamental to all other areas of scientific inquiry.</p>
<p>When we say that we "understand" physics what we really mean is that there are a few dozen of thousands of blokes that spent half their lives turning their brains into hyper-optimized physics-thinking machines and they assure us that they "understand" it.</p>
<p>For the rest of us, the edges of physics are a black box, I know physics works because Nvidia sells me GPUs with more VRAM each year and I'm able to watch videos of nuclear reactors glowing on youtube while patients in the nearby oncology ward are getting treated with radiation therapy.</p>
<p>This is true for many complex areas, we "understand" them because a few specialists say they do, and the knowledge that trickles down from those specialists has results that are obvious to all. Or, more realistically, because a dozen-domain long chain of specialists combined, each relying on the other, is able to produce results that are obvious to all.</p>
<p>As long as there is a group of specialist that understands the field, as long as those specialists can prove to us that their discoveries can affect the real world (thus excluding groups of well-synchronized insane people) and as long as they can teach other people to understand the field... we claim that it's "understood".</p>
<hr>
<p>But what about a credit risk analysis "AI" making a prediction that we should loan Steve at most 14,200$?</p>
<p>The model making this prediction might be operating with TBs worth of data about Steve, his browsing history, his transaction history, his music preferences, a video of him walking into the bank... each time he walked into the bank for the last 20 years, various things data aggregators tell us about him, from his preference about clothing to the likelihood he wants to buy an SUV, and of course, the actual stated purpose Steve gave us for the credit, both in text and as a video recording.</p>
<p>Not only that, but the "AI" has been trained on previous data from millions of people similar to Steve and the outcomes of the loans handed to then, thus working with petabytes of data in order to draw the 1-line conclusion of "You should loan steve, at most, 14,200$, if you want to probabilistically make a profit".</p>
<p>If we ask the AI:</p>
<blockquote>
<p>Why is the maximum loan 14,200$? How did the various inputs and their interactions contribute to coming up with this number?</p>
</blockquote>
<p>Well, the real answer is probably something like:</p>
<blockquote>
<p>Look, I can explain this to you, but 314,667,344,401 parameters had a significant role in coming up with this number, and if you want to "truly" understand that then you'd have to understand my other 696,333,744,001 parameters and the ways they related to each other in the equation. In order to do this, you have to gain an understanding of human-gate analysis as well as how its progress over time relates to life-satisfaction, credit history analysis, shopping preference analysis, error theory behind the certainty of said shopping preferences, and about 100 other mini-models that end up coalescing into the broader model that gave this prediction. And the way they "coalesce" is even more complex than any of the individual models. You can probably do this given 10 or 20 years, but basically, you'd have to re-train your brain from scratch to be like an automated risk analyst, you'd only be able to explain this to another automated risk analysts, and the "you" "understanding" my decision will be quite different from the "you" that is currently asking.</p>
</blockquote>
<p>And even the above is an optimist take assuming the "AI" is made of multiple modules that are somewhat explainable.</p>
<p>So, is the "AI" unexplainable here?</p>
<p>Well, not more so than the physicists are. Both of them can, in theory, explain the reasoning behind their choice. But in both cases, the reasoning is not simple, there's no single data point that is crucial, if even a few inputs were to change slightly the outcome might be completely different, but the input space is so fast it's impossible to reason about all significant changes to it.</p>
<p>This is just the way things are in physics and it might be just the way things are in credit risk analysis. After all, there's no fundamental rule of the universe saying it should be easy to comprehend by the human mind. The reason this is more obvious in physics is simply because physicists have been gathering loads of data for a long time. But it might be equally true in all other fields of inquiry, based on current models, it probably is. It's just that those other fields didn't have enough data nor the intelligence required to grok through it until recently.</p>
<h2>II - Some problems are boring</h2>
<p>There is a class of problems that is complex, but not as complex as to be impenetrable to the vast majority of human minds.</p>
<p>To harken back to the physics example, think classical mechanics. Given the observations made by Galileo and some training in analysis, most of us could, in principle, understand classical mechanics.</p>
<p>But this is still difficult, it requires a lot of background knowledge, although fairly common and useful background knowledge and a significant amount of times. Ranging from, say, a day to several months depending on the person.</p>
<p>This is time well spent learning classical mechanics, but what if the problem domain was something else, say:</p>
<ul>
<li>Figuring out if a blotch on a dental CT scan is more likely to indicate a streptococcus or a lactobacillus infection.</li>
<li>Understanding what makes an image used to advertise a hiking pole attractive to middle-class Slovenians over the age of 54.</li>
<li>Figuring out, using l2 data, if the spread for the price of soybean oil is too wide, and whether the bias is towards the sell or buy.</li>
<li>Finding the optimal price at which to pre-sell a new brand of luxury sparkling water based on yet uncertain …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable">https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451334</guid>
            <pubDate>Thu, 17 Dec 2020 01:47:01 GMT</pubDate>
        </item>
    </channel>
</rss>
