<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 15 Dec 2020 01:12:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 15 Dec 2020 01:12:45 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Goodreads plans to retire API access, disables existing API keys]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25405737">thread link</a>) | @buttscicles
<br/>
December 13, 2020 | https://joealcorn.co.uk/blog/2020/goodreads-retiring-API | <a href="https://web.archive.org/web/*/https://joealcorn.co.uk/blog/2020/goodreads-retiring-API">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      
<!-- site-header -->


      <div>
        <article>

  

  <div>
    <p>In news that surprises nobody, Goodreads last week quietly announced the deprecation of their public APIs. And I mean really quietly – the only people who were told about this were those unfortunate enough to have their existing <a href="https://blog.stephanieawilkinson.com/posts/2020-12-10-yonderbook-and-goodreads/" target="_blank" rel="noopener noreferrer">API keys disabled</a> without warning. Other than a small banner at the top of the API docs which mentions vague “plans to retire these tools”, nobody else appears to have heard anything from Goodreads, including those whose API keys remain active. So far it seems any key unused for 30 days has been disabled.</p>

<p><img src="https://joealcorn.co.uk/assets/img/posts/2020/12/deprecated.png" alt="Deprecation notice on Goodreads API documentation"></p>

<p>So this is an “announcement” much in the way a windshield announces its presence to bugs on a highway, and with the same consequences: dead bugs. Some developers have taken to the <a href="https://www.goodreads.com/topic/show/21788520-api-deprecation" target="_blank" rel="noopener noreferrer">API discussion boards</a> and blogs, but the overall impression I’m getting is grim acceptance. Really the surprising thing is how long it took them: Amazon has been in charge at Goodreads for almost 8 years now, and I think we’ve all been expecting this to come at some point.</p>

<p>So why now? What’s changed? Well, the fact is the market’s changing – and Goodreads isn’t. Alternative options are starting to emerge, and since Goodreads has forgotten how to innovate, it wants to use its market position to stifle innovation instead.</p>

<p>The sad thing is it really only hurts the hobbyist projects and Goodreads users themselves. Anybody seriously attempting to compete with Goodreads is well aware of the Amazon-shaped elephant in the room and is likely prepared. It’s the users and the hackers that this move will harm, and if anything it further reinforces the need for viable alternatives.</p>

<p>Personally I’m going to continue pouring my efforts into building <a href="https://beta.readng.co/?utm_source=joealcorn.co.uk" target="_blank" rel="noopener noreferrer">readng</a>. I’m already using it to keep track of my reads &amp; collections, along with a few thousand beta testers. I’m really excited by our plans and think we have the right team to execute, but we also need a shift in consumer behaviour.</p>

<p>The web has to mature beyond advertising as a business model. For this to happen people are going to have to open their wallets, pay for the services they use, and support independent businesses. That’s how we build a web where indies can thrive - one that’s more village centre than financial centre. I think the shift is underway.</p>


<hr>

<p>PS: <a href="https://beta.readng.co/user/joe?utm_source=joealcorn.co.uk" target="_blank" rel="noopener noreferrer">here’s my own readng profile</a>. You should probably use our Goodreads importer while our API key works, huh?</p>

  </div>

</article>













      </div>
      <!-- site-content -->

      
<!-- site-footer -->



<!-- <script src="/assets/js/main.js"></script> -->



<!-- Fathom - simple website analytics - https://github.com/usefathom/fathom -->

<!-- / Fathom -->
  <!-- / Fathom -->


    </div></div>]]>
            </description>
            <link>https://joealcorn.co.uk/blog/2020/goodreads-retiring-API</link>
            <guid isPermaLink="false">hacker-news-small-sites-25405737</guid>
            <pubDate>Sun, 13 Dec 2020 11:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Object Observation Debugger]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25405447">thread link</a>) | @jpcooper
<br/>
December 13, 2020 | https://ku-fpg.github.io/software/hood/ | <a href="https://web.archive.org/web/*/https://ku-fpg.github.io/software/hood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                    <div>
                        <div>
    <!--
                          This use of replace: does not feel right. See if you can use css for it
    -->
                        <div>

  

  <article>
  <p>Haskell Object Observation Debugger (HOOD) is a small post-mortem
debugger for the lazy functional language
<a href="http://www.haskell.org/">Haskell</a>. It is based on the concept of
observation of intermediate data structures, rather than the more
traditional stepping and variable examination paradigm used by
imperative language debuggers.</p>

<h2 id="features">Features</h2>

<ul>
  <li>Observation of base types (Int, Bool, Float, etc)</li>
  <li>Observation of both finite and infinite structures (Lists, trees,
arrays, etc).</li>
  <li>Observation of usage patterns for functions.</li>
  <li>Observation of monadic actions, including IO actions.</li>
  <li>Hooks to add observational capabilities for new base type and used
defined types.</li>
  <li>Programmable browsing capabilities - structure browsers can be coded
and plugged in.</li>
  <li>Includes a basic structure rendering package that uses a
Haskell-like syntax.</li>
  <li>Thread-safe observations are are supported.</li>
  <li>Supports observations on exceptions (on certain compilers).</li>
</ul>

<h2 id="examples">Examples</h2>

<p>Hood can observe data structures:</p>

<div><div><pre><code>main = runO ex2

ex2 = print
      . reverse
      . (observe "intermediate")
      . reverse
      $ [0..9]
</code></pre></div></div>

<p>Running this program gives this output:</p>

<div><div><pre><code>[0,1,2,3,4,5,6,7,8,9]

-- intermediate
  9 : 8 : 7 : 6 : 5 : 4 : 3 : 2 : 1 : 0 : []
</code></pre></div></div>

<p>Hood can also observe functions, showing both the arguments and result
of each call:</p>

<div><div><pre><code>main = runO ex9

ex9 = print $ observe "foldl (+) 0 [1..4]" foldl (+) 0 [1..4]
</code></pre></div></div>

<p>Running this program gives this output:</p>

<div><div><pre><code>10

-- foldl (+) 0 [1..4]
  { \ { \ 0 1  -&gt; 1
      , \ 1 2  -&gt; 3
      , \ 3 3  -&gt; 6
      , \ 6 4  -&gt; 10
      } 0 (1 : 2 : 3 : 4 : []) 
       -&gt; 10
  }
</code></pre></div></div>

<p>Note that Hood preserves the type and strictness properties of the
function under observation. If an argument is not examined in the
function, it remains unevaluated. As an example:</p>

<div><div><pre><code>ghci&gt; runO $ print $ observe "sum xs" (\ xs ys -&gt; sum xs) [0..2] [0..]
</code></pre></div></div>

<p>Notice that ys is left unevaluated (denoted by the underscore):</p>

<div><div><pre><code>3

-- sum xs
  { \ (0 : 1 : 2 : []) _  -&gt; 3
  }
</code></pre></div></div>

<h2 id="history">History</h2>

<p>Hood was developed at OGI, in 1999, for GHC 4.X. We are looking into a
debugging toolkit for Haskell and Lava, so we ported Hood to GHC 6.X,
and re-released it on hackage. We hope you find it useful.</p>

<h3 id="key-links">Key Links</h3>

<ul>
  <li><a href="http://hackage.haskell.org/package/hood">http://hackage.haskell.org/package/hood</a></li>
</ul>

<h3 id="hood-papers">HOOD Papers</h3>

<ul>
      
      
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
		<li><p>A. Gill, “<a href="https://ku-fpg.github.io/papers/Gill-00-HOOD">Debugging <span>H</span>askell by observing intermediate data
structures</a>,” in <span><em>Proceedings of the 2000 ACM SIGPLAN
<span>W</span>orkshop on Haskell, Technical report of the University of
Nottingham</em></span>, 2000.</p>
</li>
		
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
</ul>


  </article>

</div>

                        </div>
                    </div>
                </div>
            </div></div>]]>
            </description>
            <link>https://ku-fpg.github.io/software/hood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25405447</guid>
            <pubDate>Sun, 13 Dec 2020 09:55:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An anti-book recommendation tool (to help you escape your echo chamber)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25405259">thread link</a>) | @padolsey
<br/>
December 13, 2020 | https://abooklikefoo.com/escape/ | <a href="https://web.archive.org/web/*/https://abooklikefoo.com/escape/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app"><div><div><div><h3>Escape your literary echo chamber! ðŸ“š</h3><p><em>Break the Bubble</em> allows you to find out which books you are statistically <strong>unlikely</strong> to read. The more narrow your reading tastes are, the more you will be challenged by the results.</p><p>Start your search by entering a book you <strong><u>do</u></strong> like. You'll then be asked to enter a second book. Etc. The more books you add, the more accurate we can be in discovering these anti-correlations and odd new reading possibilities!</p><p>Try out these examples:</p><ul><li><a href="https://abooklikefoo.com/escape/?q=Ez4,L9pX,KJJ&amp;pop=p&amp;fnf=n&amp;period=a">Bubble-breakers for readers of Ayn Rand</a>.</li><li><a href="https://abooklikefoo.com/escape/?q=lNr,jNl,49O0&amp;pop=c&amp;fnf=a&amp;period=a">Bubble-breakers that are well-acclaimed for readers of Harry Potter</a>.</li><li><a href="https://abooklikefoo.com/escape/?q=VQV9,yyo6,7lQ,gxoY&amp;pop=b&amp;fnf=a">Bubble-breakers for readers of software engineering topics</a>.</li></ul><p><strong>How does it work?</strong>: Briefly, for each book entered we find the rarest but highest rated intersections and provide those to you. The query can be summarised as: which highly rated books are least read (and enjoyed) by people who've also read the books I have? To find out more about the recommendation engine generally, visit <a href="https://abooklikefoo.com/">the homepage</a>.</p><p><small>Note: this is an experimental feature of <a href="https://abooklikefoo.com/">A Book Like Foo</a> and was created by <a href="https://twitter.com/padolsey">James Padolsey</a>.</small></p></div><p>Your query is taking a while. ðŸ˜± Sorry about that, but it's not long now! We're leaving no book unturned in order to find you your perfect matches. ðŸ¤“</p></div></div></div></div>]]>
            </description>
            <link>https://abooklikefoo.com/escape/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25405259</guid>
            <pubDate>Sun, 13 Dec 2020 09:05:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Nano Editor – Prototype, build, and publish simple web apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25404696">thread link</a>) | @ent101
<br/>
December 12, 2020 | https://www.outpan.com/app/543e836b6a/nano-editor | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/543e836b6a/nano-editor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/543e836b6a-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>6</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/543e836b6a/nano-editor">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/543e836b6a/nano-editor</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404696</guid>
            <pubDate>Sun, 13 Dec 2020 06:16:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Who Owns the Stars: The Trouble with Urbit]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25404575">thread link</a>) | @deegles
<br/>
December 12, 2020 | http://distributedweb.care/posts/who-owns-the-stars/ | <a href="https://web.archive.org/web/*/http://distributedweb.care/posts/who-owns-the-stars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2>
  <a href="http://distributedweb.care/">
    Distributed Web of Care
  </a>
  </h2>
  <section>
    
    

    <p>by Francis Tseng</p>

<p>The application that introduced peer-to-peer (P2P) computing to the mainstream was file sharing, services like Napster, Kazaa, Gnutella, and BitTorrent. For me, these programs were the first time the contradiction of artificial scarcity—the imposed scarcity of infinitely replicable digital information—and the excessive measures that were used to enforce it became startlingly clear. Over time, I encountered the term P2P in other settings and alongside other ideas—democratic governance, communalism, autonomy, cooperatives—and I started to see the purchase this idea had beyond file sharing and networking protocols.</p>

<p><a href="https://p2pfoundation.net/the-p2p-foundation/about-the-p2p-foundation">The P2P Foundation’s mission and strategic priorities</a>, for example, extend the early P2P ideas of open culture and exchange into values of cooperative living and regenerative production. <a href="https://www.scuttlebutt.nz/principles/">Scuttlebutt, a more recent P2P social networking protocol, has its own “principles stack”</a> that similarly advocates pluralistic exchange and mutual interdependence. It’s beautiful how, at least in the ideal scenario, by using a P2P service we are helping others access it as well. P2P is both an acknowledgment of our shared needs and an example of how cooperation helps us fulfill those needs.</p>

<p>Over the years, I’ve followed along with P2P projects because of these shared values, and I always find it exciting when new projects emerge. It seems that P2P is experiencing something of a renaissance, likely due to the frenzy around blockchain (which purports to offer something similar to P2P) and the increasing popular anxiety around centralized internet services like Facebook.</p>

<p>Urbit, “<a href="https://urbit.org/">a personal server built from scratch</a>,” first came across my radar a couple of years ago. Urbit positions itself as a P2P project, but it stands out in contrast to other P2P projects, mainly because the person behind it, Curtis Yarvin, seems antithetical to what I understand P2P to represent.</p>

<p>My central question is this: <em>Is Urbit a project that should be supported?</em></p>

<p>We can further break this down into two parts. First, Urbit’s marketing materials correctly identify that concentrated data aggregation and decision-making power are fundamental issues of the internet-as-we-know-it. Twitter’s persistent neglect of harassment on its platform is one everyday example. It is clear that new protocols and platforms that reduce our dependency on distant power are needed to challenge these issues. What’s less clear, though, is whether or not Urbit actually offers a meaningful alternative. Does Urbit genuinely enable new kinds of relations? Or, does it merely replace the old aristocracy with a new one?</p>

<p>The second, and more urgent, question is: who and what are we supporting by supporting Urbit? Many people in tech still believe that technology can be divorced from its creators; however, those of us in tech need to recognize that we have a considerable amount of influence over which products enter the mainstream consciousness, which products get created at all, and who receives both financial and social capital (shout out to <a href="https://techworkerscoalition.org/">Tech Workers Coalition</a> et al.). For example, consider Peter Thiel , who co-founded PayPal and was an early investor in Facebook. Early support of PayPal and Facebook contributed to their financial success, which developed Thiel’s influence and made him quite rich. Thiel then turned that money and influence into Palantir Technologies, a software company that <a href="https://theintercept.com/2017/03/02/palantir-provides-the-engine-for-donald-trumps-deportation-machine/">develops technologies to help expand surveillance and deportation for the government</a>. We have to consider what similar groundwork we help to lay by supporting Urbit.</p>

<h2 id="context">Context</h2>

<p>In order to discuss Urbit’s design, we need to have an understanding of the politics of its creator, Curtis Yarvin. <a href="https://en.wikipedia.org/wiki/Curtis_Yarvin">Curtis Yarvin</a> is innocuously described on Wikipedia as an “American political theorist and computer scientist,” but to many, he is better known as <a href="https://www.theatlantic.com/politics/archive/2017/02/behind-the-internets-dark-anti-democracy-movement/516243/">one of the intellectual forebears of the alt-right</a>. From 2007 to 2014<sup id="fnref:1"><a href="#fn:1">1</a></sup>, working under the pen name Mencius Moldbug, Yarvin writings, which among other things espoused anti-democratic ideas and scientific racism and helped introduce many of what are now understood as the alt-right’s foundational ideologies to a wider public. The term “red pill,” which describes the process of reactionary radicalization and the community around it, was first used in this way by Yarvin.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Defenders of Urbit are quick to dismiss any inclusion of Yarvin’s politics in discussions about Urbit as unfair or irrelevant, and might point out that Yarvin left the project in January of this year.<sup id="fnref:3"><a href="#fn:3">3</a></sup> However, given that Yarvin basically laid out the general design for Urbit independently, as he worked on it alone for 11 years<sup id="fnref:3:1"><a href="#fn:3">3</a></sup> and in parallel with his political writings<sup id="fnref:4"><a href="#fn:4">4</a></sup>, and that Urbit, as a P2P project, is a fundamentally social and thus incorporates ideas about how people should be organized, Yarvin’s politics should be considered as something that influences his design decisions and his long-term vision for the project. <a href="https://lobste.rs/s/z5j1hq/urbit_2017#c_4z4gik">Dog-whistles</a> have been identified in some of his writing about Urbit and its design, including his <a href="https://urbit.org/posts/essays/the-dao-as-a-lesson-in-decentralized-governance/">leaning on Nazi philosopher Carl Schmitt</a> for questions around Urbit’s governance.</p>

<p>To save space I’ll provide only a very brief overview of Yarvin’s political philosophy—if you like, you can read more about it <a href="https://thebaffler.com/latest/mouthbreathing-machiavellis">here</a>, <a href="https://www.viewpointmag.com/2017/03/28/the-darkness-at-the-end-of-the-tunnel-artificial-intelligence-and-neoreaction/">here</a>, <a href="https://thebaffler.com/latest/the-moldbug-variations-pein">here</a>, and <a href="https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/">here</a>.</p>

<p>Yavin refers to his brand of political philosophy as “neocameralism.” Neocameralism, as described in his essay “<a href="https://www.unqualified-reservations.org/2007/08/against-political-freedom/">Against Political Freedom</a>,” is a political philosophy arguing that state should be run like a business, (i.e., with a CEO at its head and no democratic mechanisms). His ideas are credited as being foundational to the “<a href="https://techcrunch.com/2013/11/22/geeks-for-monarchy/">neoreactionary” movement</a>, which could be described as a neo-monarchist movement (though Yarvin himself doesn’t identify as a “monarchist” because of its association with a constitutional monarchy and not absolute monarchy). In the neoreactionary movement, “divine right” is supplanted with “genetic right” based on scientific racism reframed as “human biodiversity.” Yarvin’s writings are also popular within the right-libertarian sects of Silicon Valley, such as <a href="https://thebaffler.com/latest/the-moldbug-variations-pein">with Peter Thiel</a> (<a href="https://www.theverge.com/2017/2/21/14671978/alt-right-mencius-moldbug-urbit-curtis-yarvin-tlon">Peter Thiel also has a stake in Tlön</a>, Yarvin’s company which develops Urbit, via Thiel’s VC firm, Founders Fund). The point here is that Yarvin is not a fringe philosopher. His writings have influence over people with considerable power and contributes to the intellectual miasma that emboldens and normalizes anti-democratic, anti-immigrant, misogynistic, and racist policies and attacks.</p>

<h2 id="urbit">Urbit</h2>
<h4 id="a-self-sovereign-internet">A self-sovereign internet</h4>

<p>Urbit positions itself as infrastructure for self-sovereignty in the digital age, liberating people from ceding control of their data to corporations.<sup id="fnref:5"><a href="#fn:5">5</a></sup> The core idea is that Urbit helps you run a personal server that acts as an intermediary between you and other services, including existing services like Facebook (yes, there is a lot more to Urbit—such as its reinvention of parts of the lower-level computational stack—but its P2P layer is what’s of interest here).</p>

<p>Self-sovereignty is an important principle, and I wager that many who regularly use the internet would agree that more of it is valuable for a healthy internet: for being able to control who can access your data, who can and cannot contact you, and so on. <em>But</em>, self-sovereignty is far too vague of a concept on its own. Left- and right-libertarianism both start with self-sovereignty as a core value, but they end up with vastly different conceptions of what meaningful self-sovereignty looks like and how it can be achieved. Left-libertarianism finds that self-sovereignty arises from social organizing, care, and democratic governance, which build towards positive freedoms (freedom to learn, to flourish, and so on); whereas, right-libertarianism believes it comes from the market and that negative freedoms (freedom from restrictions and regulation) are the goal. Though Yarvin does not identify as a libertarian (he is, in his own words, sympathetic to it), his neocameralism is right-libertarianism taken to its logical conclusion<sup id="fnref:6"><a href="#fn:6">6</a></sup> of corporate tyranny and serfdom.</p>

<p>To draw an example that you might be familiar with, consider the Twitter-alternative, Gab, which markets itself as a bastion for free speech. Gab, in practice, operates as a niche platform for members of the far-right who have been banned from Twitter: “<a href="https://www.nytimes.com/2018/10/28/us/gab-robert-bowers-pittsburgh-synagogue-shootings.html">a haven for white nationalists, neo-Nazis and other extremists</a>”. We might ask then, is Gab a platform for free speech, or is it a platform for hate speech? Who’s speech does Gab prioritize? It quickly becomes clear that the concept of “free speech” that Gab deploys is not quite the same as what others see it to mean.</p>

<p>In a similar way, this slipperiness of self-sovereignty as a concept, especially in light of Yarvin’s political writings, makes me suspicious of what it really means in the context of Urbit. Is Urbit actually designed to give users more autonomy and control? Does it restore any power to internet users?</p>

<p>One central design feature of Urbit is its network hierarchy. As a participant in Urbit, you may be a galaxy (the top of the hierarchy), a star (which fall under galaxies), or a planet (which fall under stars). The description of this hierarchy <a href="https://github.com/cgyarvin/urbit/blob/6ac688960687aa9c89d4da6fff49a3125c10aca1/Spec/urbit/3-intro.txt">used to use explicitly feudal metaphors</a> as part of what Yarvin called “digital feudalism,” with himself as the “prince,” and further contributes to my suspicion of Yarvin’s conception of self-sovereignty actually entails.</p>

<p>In trying to backpedal on these naming conventions, Yarvin claims that his ideas about governance are flipped for the internet:</p>

<blockquote>
  <p>If the real world today is governed as an insanely dysfunctional republic, and the Internet today is governed as a cluster of insanely despotic corporate monarchies, it doesn’t strike me as at all inconsistent with historical thought to treat the former case of misgovernment with efficient monarchism, and the latter case with liberating republicanism.<sup id="fnref:7"><a href="#fn:7">7</a></sup></p>
</blockquote>

<p>The rationale for why the …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://distributedweb.care/posts/who-owns-the-stars/">http://distributedweb.care/posts/who-owns-the-stars/</a></em></p>]]>
            </description>
            <link>http://distributedweb.care/posts/who-owns-the-stars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404575</guid>
            <pubDate>Sun, 13 Dec 2020 05:41:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China’s Radical New Vision of Globalization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25404210">thread link</a>) | @s3v
<br/>
December 12, 2020 | https://www.noemamag.com/chinas-radical-new-vision-of-globalization/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				<div>
  <p>Credits</p>
  <p>James Crabtree is an associate professor in practice at the Lee Kuan Yew School of Public Policy at the National University of Singapore. He is the author of “The Billionaire Raj.”</p>
</div>


<p>SINGAPORE —&nbsp;Back in August, Chinese President Xi Jinping met with a group of economists in Beijing. “In the coming period, we will face more and more headwinds,” he <a href="http://www.xinhuanet.com/english/2020-08/25/c_139314902.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">explained</a>, using unusually blunt language. Without naming names, Xi talked about China’s worsening trade and technology war with the United States under President Donald Trump, set against a backdrop of growing certainty in Beijing that America is bent on containing his nation’s geopolitical rise.</p>



<p>But then came the interesting part. “Since the beginning of this year, I have said on many occasions that we must promote the formation of a new development pattern, in which domestic and international cycles are the mainstay, and the domestic and international dual cycles promote each other,” Xi said. To an outsider, this might seem unremarkable, cloaked as it is in the elliptical phraseology that often marks Chinese economic ideas. But the “dual circulation” strategy Xi outlined actually represents a radical new understanding of globalization and of China’s place within it.</p>



<p>More than just a buzzword, dual circulation describes the deeply pessimistic worldview that has settled over Beijing. Once China’s leaders saw opportunity in globalization. Now, they expect the U.S. and its allies to deny China the technology it needs to build “a modern socialist country” by mid-century, meaning a wealthy superpower fit to rival the U.S. Although likely to be less pugilistic, Beijing rightly believes an incoming Biden administration will also press forward with policies designed to stop advanced technologies finding their way into Beijing’s hands. Chinese thinking has long valorized self-reliance, dating back to ideas developed by former Chinese leader Mao Zedong during the country’s civil war, which ended with the foundation of the People’s Republic of China in 1949. Now, Trump’s tariffs, as well as his campaigns against companies like Huawei and TikTok, have given new impetus to the modern form of self-reliance Xi dubs “internal” development.</p>



<p>Many experts have noted a changing Western consensus on China, as leaders in Washington abandoned the idea that economic modernization would inevitably lead to political liberalization in Beijing. But there has been a comparable shift in China’s internal conversation on the West too. Beginning with semiconductors but potentially expanding to all manner of other areas, China now expects it will have to develop technologically on its own. Xi’s new theory now sits at the heart of the country’s <a href="http://www.xinhuanet.com/english/2020-10/29/c_139476451.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">14th five-year plan</a>, which covers development from 2021 to 2025, and was unveiled in draft form in October. The result will accelerate China’s decoupling from the West, while also increasing the importance of trading links forged with other parts of the world — for instance, via Xi’s signature Belt and Road Initiative. Put more bluntly, while the world was distracted by the drama of the U.S. presidential election, Xi quietly unveiled an economic strategy fit for a new Cold War. Both for China and for globalization itself, the results are likely to be profound.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “China expects the U.S. and its allies to act ever more aggressively to deny China the technology it needs.”    </p>

    
    
  </div>
</div>




<hr>



<p>To see how much China’s consensus has changed, recall Xi’s <a href="https://america.cgtn.com/2017/01/17/full-text-of-xi-jinping-keynote-at-the-world-economic-forum" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">remarks</a> at Davos in 2017. There, he portrayed globalization not as a threat, but as an inevitability. “The global economy is the big ocean that you cannot escape from,” he suggested. “China will vigorously foster an external environment of opening-up for common development.” Just as Trump was turning against the idea, China would act as steward of the existing global order. It would even help to remedy many of the problems that rapid integration had caused, Xi argued, from economic inequality to climate change.</p>



<p>Three years later and, under <a href="https://research.nus.edu.sg/eai/wp-content/uploads/sites/2/2020/10/EAIC-20-20201020.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">dual circulation</a>, things look much different. The idea splits the world into two systems. First comes external circulation, meaning China’s global trade, but also the way it invites foreigners into its domestic economy. This was the focus of Xi’s Davos remarks and the approach that powered his country’s decades of rapid growth, transforming China into an exporting powerhouse. The second component is then internal circulation, meaning domestic demand from Chinese consumers, but also domestic supply chains and “made in China” technologies.&nbsp;</p>



<p>This division shares something in common with “<a href="https://www.straitstimes.com/40-years-of-china-opening-up" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">reform and opening up</a>,” a phrase that has dominated China’s economic thinking for decades. That idea suggested Beijing should reform its domestic (or internal) economy to make it more market-led, while also opening up to the (external) world via globalization, gaining new ideas, production techniques and technologies along the way. Dual circulation also echoes longstanding attempts to wean China off a growth model dominated by exports and infrastructure investment and build instead the kind of consumption-led economy common in rich countries.</p>



<p>Such attempts have been only partially successful. A decade ago, about <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China's%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">34%</a> of China’s economy came via domestic consumption, less than <a href="https://tradingeconomics.com/united-states/final-consumption-expenditure-etc-percent-of-gdp-wb-data.html#:~:text=(%25%20of%20GDP)%20in%20United,compiled%20from%20officially%20recognized%20sources." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">half the level</a> in the U.S. at the time. By 2019, this has reached just <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China%20Private%20Consumption%3A%20%25%20of%20GDP,-1952%20%2D%202019%20%7C%20Yearly&amp;text=China%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">39%</a> — progress, of a sort, but hardly dramatic. When the phrase dual circulation first emerged earlier this year, many saw it as merely yet one more push toward this long-term objective of Chinese internal economic rebalancing.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Beginning with semiconductors but potentially expanding to all manner of other technologies, China now expects it will have to develop economically on its own.”    </p>

    
    
  </div>
</div>




<p>It is China’s deteriorating geopolitical environment that marks dual circulation as a decisive break from the past, however. “China thinks there is a good prospect of even worse relations with the U.S. and its friends in the coming years,” I was told recently by Li Mingjiang, a Chinese political scientist based in Singapore and long-time observer of Beijing’s intricate political economy. “So, it needs to do something about it.”</p>



<p>It is not hard to see why. Trump’s tariffs and battles over soybeans generated more headlines, but it is advanced technology that really matters in Beijing. China is a global tech leader in some sectors, from online payments to artificial intelligence. But it lags in others. Despite its geopolitical heft, it still remains a firmly middle-income economy, with a gross domestic product per capita of roughly <a href="https://www.google.com/search?q=china+gdp+per+capita&amp;rlz=1C5CHFA_enSG865SG865&amp;oq=china+gdp&amp;aqs=chrome.0.69i59j69i57j0i67l3j0j69i60j69i61.4682j0j7&amp;sourceid=chrome&amp;ie=UTF-8" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">$9,700</a> — about on par with <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Kazakhstan</a> and roughly half that of <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Greece</a>. Access to cutting-edge technology is critical in changing this, especially as its economy moves away from the kind of basic exported manufactured goods that have long dominated its growth model.</p>



<p>Over recent decades, China has had many routes to acquiring such technology. Often, it simply bought it, as when Chinese companies snapped up everything from Rolls Royce jet engines to Qualcomm semiconductors. Foreign businesses rushed to set up Chinese operations, often as part of local joint ventures, eager to tap into a vast consumer market. Chinese businesses bought foreign technology groups, while Chinese academics and scientists built partnerships at the world’s best universities. Beijing <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">employed</a> darker methods too, from forced technology transfer to outright intellectual property theft. But there were always plenty of legitimate avenues to go with them.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi has quietly unveiled an economic strategy fit for a new Cold War.”    </p>

    
    
  </div>
</div>




<p>Now, many of these routes are closing fast. Rather than tariffs, America’s “entity list” has proved its most potent weapon. Back in 2016, President Barack Obama first used this process in <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">accusing</a> ZTE, China’s second-largest telecoms supplier, of selling U.S. technologies to Iran, crippling the Chinese company in the process. Trump then escalated this approach, banning U.S. businesses from trading with dozens of Chinese enterprises, from state-owned giants to niche artificial intelligence providers with links to Xinjiang and its embattled Muslim Uighur minority. More recent <a href="https://www.commerce.gov/news/press-releases/2020/08/commerce-department-further-restricts-huawei-access-us-technology-and" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">measures</a> unveiled this August hit foreign suppliers too, for instance stopping semiconductor operators in Taiwan from selling to Chinese entities. Huawei has been one high-profile victim, leading experts to <a href="https://www.ft.com/content/bdd2a70f-ecd2-4aff-b6c7-c0624bfdeebb" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">question</a> whether China’s state-linked tech champion can survive.</p>



<p>What started with semiconductors is unlikely to end there, however, hence dual circulation’s underlying pessimism. Under Trump, the U.S. has unveiled a range of further measures limiting China’s technology access, from its 2018 <a href="https://www.cliffordchance.com/briefings/2018/02/the_export_controlreformactof2018risksan.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Export Control Reform Act</a> to more targeted measures in areas like geospatial imagery software. Allies in Europe are being cajoled to follow suit. Many Western governments have also acted to stop China from buying up advanced tech companies entirely, while also <a href="https://www.chinacenter.net/2020/china_currents/19-3/scholars-or-spies-u-s-china-tension-in-academic-collaboration/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">limiting</a> academic collaborations with Chinese partners. The recent battle over TikTok was illustrative too, showing how rapidly the U.S. has lowered the bar on what counts as a national security threat, a category that now includes not just critical 5G telecoms architecture of the sort provided by Huawei, but also jocular teenage social media platforms.</p>



<p>Elsewhere, U.S. strategists are particularly vexed by China’s doctrine of “<a href="https://www.floridadaily.com/marco-rubio-introduces-bill-to-keep-chinese-military-companies-from-accessing-american-capital-markets/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">military-civil fusion</a>,” which mandates that technologies acquired by China’s private sector must be shared with its armed forces. The problem is that, when you look hard enough, almost anything can potentially be seen as a dual-use technology, from nuclear equipment and renewable energy batteries to civilian aircraft, drones and autonomous vehicles.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi’s plans clearly place more emphasis on domestic production and state control.”    </p>

    
    </div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404210</guid>
            <pubDate>Sun, 13 Dec 2020 04:04:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bypassing traditonal Linux bottlenecks: Seastar in 2020]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25403351">thread link</a>) | @ta988
<br/>
December 12, 2020 | https://www.mikelangelo-project.eu/technology/seastar-library/ | <a href="https://web.archive.org/web/*/https://www.mikelangelo-project.eu/technology/seastar-library/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><!-- class="sidebar-none", class="sidebar-left", class="sidebar-right" -->

		
		
		<div>
			<div>

				
	
		
			<div id="content" role="main">

			
					
					<h2>Introduction</h2>
<p>As we noted above, the primary goal of OSv is to run existing Linux software, because most MIKELANGELO use cases required running existing code. Today’s Linux APIs – POSIX system calls, socket API, etc. – were formed by decades of Unix and Linux legacy, and some aspects of them are inherently inefficient. OSv can improve the performance of applications which use these APIs, but not dramatically. So our second goal in the development of the guest operating system was to propose new APIs which will offer new applications dramatically better performance than unmodified Linux applications – provided that the application is rewritten to use these new APIs,</p>
<p>In the research paper “OSv — Optimizing the Operating System for Virtual Machines”[<a href="#_edn1" name="_ednref1">[i]</a>], one of the benchmarks used was Memcached, a popular cloud application used for caching of frequently requested objects to lower the load on slower database servers. Memcached demonstrated how an unmodified network application can run faster on OSv than it does on Linux – a 22% speedup was reported in the paper.</p>
<p>22% is a nice speedup that we get just by replacing Linux in the guest by OSv, without modifying the application at all. But we wanted to understand if there is something we could do to get significantly higher performance. When we profiled memcached on OSv, we quickly discovered two performance bottlenecks:</p>
<ol>
<li><strong>Inefficiencies inherent in the Posix API</strong>, so OSv cannot avoid them and still remain POSIX compatible: For example, in one benchmark we noticed that 20% of the memcached runtime was locking and unlocking mutexes – almost always uncontended. For every packet we send or receive, we lock and unlock more than a dozen mutexes. Part of OSv’s performance advantage over Linux is that OSv uses a “netchannel” design for the network stack reducing locks (see the previous section), but we still have too many of them, and the Posix API forces us to leave many of them: For example, the Posix API allows many threads to use the same socket, allows many threads to modify the list of file descriptors, to poll the same file descriptors – so all these critical operations involve locks, that we cannot avoid. The socket API is also synchronous, meaning that when a send() returns the caller is allowed to modify the buffer, which forces the network code in OSv to not be zero-copy.</li>
<li><strong>Unscalable application design: </strong>It is not easy to write an application to scale linearly in the number of cores in a multi-core machine, and many applications that work well on one or two cores, scale very badly to many cores. For example memcached keeps some global statistics (e.g., the number of requests served) and updates it under a lock – which becomes a major bottleneck when the number of cores grow. What might seem like an acceptable solution – lock-free atomic variables – is also not scalable, because while no mutex is involved, atomic operations, and the <em>cache line bounces </em>(as different CPUs read and write the same variable), both become slower as the number of cores increase. So writing a really scalable application – one which can run on (for example) 64 cores and run close to 64 times faster than it does on a single core – is a big challenge and most applications are not as scalable as they should be – which will become more and more noticeable as the number of cores per machine continues to increase.</li>
</ol>
<p>In the aforementioned OSv paper, we tried an experiment to quantify the first effect – the inefficiency of the Posix API. The subset of memcached needed for the benchmark was very simple: a request is a single packet (UDP), containing a “GET” or “PUT” command, and the result is a single UDP packet as well. So we implemented in OSv a simple “packet filter” API: every incoming ethernet packet gets processed by a function (memcached’s hash-table lookup) which immediately creates the response packet. There is no additional network stack, no locks or atomic operations (we ran this on a single CPU), no file descriptors, etc. The performance of this implementation was an impressive 4 times better than the original memcached server.</p>
<p>But while the simple “packet filter” API was useful for the trivial UDP memcached, it was not useful for implementing more complex applications, for example applications which are asynchronous (cannot generate a response immediately from one request packet), use TCP or need to use multiple cores. Fast “packet filter”-like APIs are already quite commonly used (DPDK is a popular example) and are excellent to implement routers and similar packet-processing software; But they are not really helpful if you try to write a complex, highly-asynchronous network applications of the kind that is often used on the cloud – such as a NoSQL database, HTTP server, search engine, and so on.</p>
<p>For the MIKELANGELO project, we set out to design a new API which could answer both above requirements: An API which new applications can use to achieve optimal performance (i.e., the same level of performance achieved by the “packet filtering API” implementation), while at the same time allows the creation of complex real-life applications: The result of this design is <em>Seastar</em>:</p>
<ul>
<li>Seastar is a C++14 library, which can be used on both OSv and Linux. Because Seastar bypasses the kernel for most things, we do not expect additional speed improvements by running it on OSv – though some of OSv’s other advantages (such as image size and boot time) may still be relevant.</li>
<li>Seastar is designed for the needs of complex asynchronous server applications of the type common on the cloud – e.g., NoSQL databases, HTTP servers, etc. Here “asynchronous” means that a request usually triggers a cascade of events (disk reads, communication with other nodes, etc.) and only at a later time can the reply be composed.</li>
<li>Seastar provides the application the mechanisms it needs to solve both performance bottlenecks mentioned at the top of this section: Achieve optimal efficiency on one core, as well as scalability in the number of cores. We’ll explain how Seastar does this below.</li>
<li>Seastar can bypass the legacy kernel APIs, e.g., it can directly access the network card directly using DPDK. Seastar provides a full TCP/IP stack (which DPDK does not).</li>
</ul>
<p>We’ve reimplemented memcached using Seastar, and measured 2 to 4-fold performance improvement over the original memcached as well as near-perfect scalability to 32 cores (something which the “packet filter” implementation couldn’t do). Figure below for more details.</p>
<p><a href="https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached.png" data-dt-img-description=""><img src="https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached.png" alt="" width="938" height="580" srcset="https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached.png 938w, https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached-300x186.png 300w, https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached-768x475.png 768w" sizes="(max-width: 938px) 100vw, 938px"></a>Figure: Performance of stock memcached (orange) vs Seastar reimplementation of memcached (blue), using TCP and the memaslap[<a href="#_edn2" name="_ednref2">[ii]</a>] workload generator – for varying number of cores The red bars show a non-standard memcached deployment using multiple separate memcached processes (instead of one memcached with multiple threads); Such a run is partially share-nothing (the separate processes do not share memory or locks) so performance is better than the threaded server, but still the kernel and network stack is shared so performance is not as good as with Seastar.</p>
<p>Applications that want to use Seastar will need to be rewritten to use its new (and very different) APIs. This requires significant investment, but also comes with significant rewards: The creator of the Seastar library, ScyllaDB, spent the last two years reimplementing the popular Cassandra distributed database in C++ and Seastar, and the result, “Scylla” (which, like Seastar and OSv, is released as open source[<a href="#_edn3" name="_ednref3">[iii]</a>]), has much higher throughput than Cassandra: Independent benchmarks[<a href="#_edn4" name="_ednref4">[iv]</a>] by Samsung showed Scylla to have between 10 to 37 times higher throughput than Cassandra on a cluster of 24-core machines in different workloads,&nbsp; In fact, the Scylla distributed database performs so well that it has become ScyllaDB’s main product, making the company highly dependent on Seastar’s exploitation. For this reason, ScylllaDB has been investing into Seastar additional efforts beyond what is being funded by the MIKELANGELO project, and plans to continue developing Seastar even after the project ends.</p>
<p>We use Scylla, the Seastar-based reimplementation of Cassandra, in the “Cloud Bursting” use case. But our goal is for Seastar to be a general-purpose APIs which will be useful to many kinds of asynchronous server applications, which are often run on the cloud. As such, we are making an effort of providing a rich, well-balanced, and well documented API, and also writing a tutorial on writing Seastar applications (a draft of which was already included in D4.4 and D4.5). At the time of this writing, we know of at least two other companies besides ScyllaDB which based their product on Seastar, and more are considering doing this.</p>
<h2>Seastar architecture</h2>
<p>How can an application designed to use Seastar be so much faster than one using more traditional APIs such as threads, shared memory and sockets? The short answer is that modern computer architecture has several performance traps that are easy to fall into, and Seastar ensures that you don’t by using the following architecture:</p>
<ol>
<li><strong>Sharded (“share nothing”) design:</strong></li>
</ol>
<p>Modern multi-core machines have shared memory, but using it incorrectly can drastically reduce an application’s performance: Locks are very slow, and so are processor-provided “lock-free” atomic operations and memory fences. Reading and writing the same memory object from different cores significantly slows down processing compared to one core finding the object in its cache (this phenomenon is known as “cache line bouncing”). All of these slow operations already hurt one-core performance, but get progressively slower as the number of cores increases, so it also hurts the scaling of the application to many cores.</p>
<p>Moreover, as the number of cores increases, multi-core machines inevitably become multi-socket, and we start seeing NUMA (non-uniform memory access) issues. I.e., some cores are closer to some parts of memory – and accessing the …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mikelangelo-project.eu/technology/seastar-library/">https://www.mikelangelo-project.eu/technology/seastar-library/</a></em></p>]]>
            </description>
            <link>https://www.mikelangelo-project.eu/technology/seastar-library/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403351</guid>
            <pubDate>Sun, 13 Dec 2020 01:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bay Area to Austin: A Breakdown of the Financial Savings]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25403248">thread link</a>) | @musks_musk
<br/>
December 12, 2020 | https://www.thriftythoughts.io/silicon-hills/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/silicon-hills/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.thriftythoughts.io/silicon-hills/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403248</guid>
            <pubDate>Sun, 13 Dec 2020 00:46:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To listen well, get curious]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25403240">thread link</a>) | @axiomdata316
<br/>
December 12, 2020 | https://www.benkuhn.net/listen/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/listen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><a href="https://www.benkuhn.net/listen/shawarma.jpg" title="fullsize"><img width="414" height="139" src="https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_828x278_resize_q75_box.jpg" srcset="https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_828x278_resize_q75_box.jpg 2x, https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_414x139_resize_q75_box.jpg"></a><figcaption><a href="https://twitter.com/thecassiecao/status/1276506378388017155/photo/1">source</a></figcaption></figure><p>A common piece of interacting-with-people advice goes: “often when people complain, they don’t want help, they just want you to listen!”</p><p>For instance, <em>Nonviolent Communication</em>:<sup><label for="sn0">✻</label><span><span><sup>✻</sup>
<em>Nonviolent Communication</em>, ch. 7.</span></span></sup></p><blockquote><p>It is often frustrating for someone needing empathy to have us assume that they want reassurance or “fix-it” advice.</p></blockquote><p><em>Active Listening</em>:<sup><label for="sn1">†</label><span><span><sup>†</sup>
<a href="https://www.benkuhn.net/listen/active-listening.pdf">Active Listening</a>, p. 2</span></span></sup></p><blockquote><p>Similarly, advice and information are almost always seen as efforts to change a person and thus serve as barriers to his self-expression and the development of a creative relationship.</p></blockquote><p>You can find similar advice in most books on relationships, people management, etc.</p><p>This always used to seem silly to me. If I complain at my partner and she “just listens,” I’ve accomplished nothing except maybe made her empathetically sad. When I complain at people, I want <em>results</em>, not to grouse into the void!<sup><label for="sn2">‡</label><span><span><sup>‡</sup>
Empirically, I did notice that I usually got better results from listening than from giving advice. So I inferred that this advice was true for other people, but not me, because other people didn’t actually want to fix their problems.</span></span></sup></p><p>Frequently the “just listen” advice comes with tactical tips, like “reflect what people said back to you to prove that you’re listening.” For instance, consider these example dialogues from <em>Nonviolent Communication</em>:<sup><label for="sn3">§</label><span><span><sup>§</sup>
<em>Nonviolent Communication</em>, Chapter 7, Exercise 5.5, 5.6 and solutions.</span></span></sup></p><blockquote><p>Person A: How could you say a thing like that to me?</p><p>Person B: Are you feeling hurt because you would have liked me to agree to do what you requested?</p></blockquote><p>Or:</p><blockquote><p>Person A: I’m furious with my husband. He’s never around when I need him.</p><p>Person B: So you’re feeling furious because you would like him to be around more than he is?</p></blockquote><p>I say this with great respect for <em>Nonviolent Communication</em>, but these sound like a <a href="https://en.wikipedia.org/wiki/ELIZA" target="_blank">1970s-era chatbot</a>. If I were Person A in either of these dialogues my next line would be “yes, you dingbat—can you turn the nonviolence down a couple notches?” I’d feel alienated knowing that someone is going through their NVC checklist on me.</p><hr><p>Recently, I realized why people keep giving this weird-seeming advice. Good listeners <em>do</em> often reflect words back—but not because they read it in a book somewhere. Rather, it’s <a href="https://en.wikipedia.org/wiki/Cargo_cult_science" target="_blank">cargo cult advice</a>: it teaches you to imitate the surface appearance of good listening, but misses what’s actually important, the thing that’s <em>generating</em> that surface appearance.</p><p>The generator is curiosity.</p><p>When I’ve listened the most effectively to people, it’s because I was intensely curious—I was trying to build a <em>detailed, precise</em> understanding of what was going on in their head. When a friend says, “I’m furious with my husband. He’s never around when I need him,” that one sentence has a huge amount underneath. How often does she need him? What does she need him for? Why isn’t he around? Have they talked about it? If so, what did he say? If not, why not?</p><p>It turns out that <a href="http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail" target="_blank">reality has a surprising amount of detail</a>, and those details can matter a lot to figuring out what the root problem or best solution is. So if I want to help, I can’t treat those details as a black box: I need to <a href="https://www.lesswrong.com/posts/B7P97C27rvHPz3s9B/gears-in-understanding" target="_blank">open it up and see the gears inside</a>. Otherwise, anything I suggest will be wrong—or even if it’s right, I won’t have enough “shared language” with my friend for it to land correctly.</p><p>Some stories from recent memory:</p><ul><li><p>When we started doing a pair programming rotation at Wave, I suggested that, to make scheduling easier, we designate a default time when pairing sessions would happen. A coworker objected that this seemed authoritarian. I was extremely puzzled, but they’d previously mentioned being an anarchist, so I was tempted to just chalk it up to a political disagreement and move on. But instead I tried to get curious and explore more deeply whatever “political” models were generating that disagreement. After a lot of digging into what was or wasn’t authoritarian for them and why, it turned out the disagreement was because they’d missed the word “default” and thought I was suggesting a single <em>mandatory</em> time for pair programming.</p></li><li><p>My partner, Eve, wrote a post about Polish attitudes about sex, with some details that upset her (Polish) parents. When her parents told her that, she initially got very stressed about having to have a conversation to calm them down. I thought she shouldn’t be worried and the conversation would be fine, but of course just telling her that wasn’t very helpful. Instead, I summoned up my curiosity and asked lots of questions about her relationship with her parents, her parents’ relationship with each other, each of their relationships with Catholicism, etc. By the end of the conversation, after thinking through all the baggage involved, Eve agreed with me, and her attitude about the upcoming conversation shifted from impending doom to compassionate curiosity about where her parents were coming from.</p></li><li><p>I was stressed by work and complained to Eve about some things that I felt frustrated and stuck about. Instead of suggesting solutions, she kept asking for more details until she had more or less a complete snapshot of my mental state. At that point, she observed that every time I mentioned feeling sad, I sounded contemptuous and exasperated with myself. She hypothesized that I wasn’t giving myself permission to be sad. The “solution” to my problem ended up being to give me a big hug and let me cry on her shoulder for a bit, after which I immediately felt much less stressed.</p></li></ul><p>In each case, the “helper” tried to learn about the “complainer’s” reality in as much detail as possible—not just the problem, but the whole person and whatever else was behind the immediate issue. And that’s what made it possible for them to actually help.</p><p>It often feels like I understand enough to be helpful without knowing all those details. But when I think that, I’m usually wrong: I end up giving bad advice, based on bad assumptions, and the person I’m talking to ends up having to do a bunch of work to argue with me and correct my bad assumptions. That makes the conversation feel disfluent and adversarial instead of collaborative.</p><p>It turns out this is a really common failure mode of helping-conversations, which is what I think generates the old saw at the beginning of this post, that “sometimes people don’t want help, just to be listened to.”</p><p>But I think that’s actually too nice to the helper, and uncharitable to the complainer (in that it assumes they weirdly don’t care about solving their problem). What’s really going on is probably that your advice is bad, because you didn’t really listen, because you weren’t curious enough.</p><hr><p>When I’m curious about what someone’s saying, I often do repeat things back to them in my own words. But it’s because I’m genuinely curious, not because I’m checking off the “reflect words” box in my “be a good listener” checklist. That means I do it in a way that sounds like my natural speech, instead of mimicking them like a chatbot.</p><p>When done this way, reflective listening feels validating rather than alienating. It’s a way of demonstrating that I care a lot about what someone has to say. Putting their idea into my own words shows them that I’ve fully digested it, and helps us establish a shared language in which to talk about it. That, in turn, makes the conversation fluent and collaborative, rather than a zigzag of bad assumptions and corrections.</p><p>So the right advice isn’t “listen harder and repeat everything back”—you won’t be genuine if you’re just imitating the surface appearance of a good listener. Instead, be humble and get curious! Remind yourself that there’s a ton of detail behind whatever you’re hearing, and try to internalize all of it that you can. Once you’ve done that, your advice will be more likely hit the mark, and you’ll be able to communicate it clearly.</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/listen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403240</guid>
            <pubDate>Sun, 13 Dec 2020 00:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why radio receivers won’t tune 800-900 MHz]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 120 (<a href="https://news.ycombinator.com/item?id=25403163">thread link</a>) | @jtakkala
<br/>
December 12, 2020 | https://computer.rip/2020-11-28%20the%20verboten%20band.html | <a href="https://web.archive.org/web/*/https://computer.rip/2020-11-28%20the%20verboten%20band.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://computer.rip/2020-11-28%20the%20verboten%20band.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403163</guid>
            <pubDate>Sun, 13 Dec 2020 00:32:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rizin – a free and open-source Reverse Engineering framework]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25402690">thread link</a>) | @homarp
<br/>
December 12, 2020 | https://rizin.re/posts/announcing-rizin/ | <a href="https://web.archive.org/web/*/https://rizin.re/posts/announcing-rizin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We are excited to announce Rizin — a <strong>free</strong> and <strong>open-source</strong> Reverse Engineering framework, providing a complete binary analysis experience with features like Disassembler, Hexadecimal editor, Emulation, Binary inspection, Debugger, and more.</p><p>Rizin is a fork of radare2 with a focus on usability, stability, and working features, which strives to provide a welcoming environment for developers and users alike. Rizin was founded by a group of the core developers of radare2 and Cutter who contributed to the project in one way or the other in the past years and together constructed the Core group of radare2. With the establishment of Rizin, we are committed to creating an environment and a project which will be aligned with our values and vision.</p><p>During recent years, the environment that was created in radare2 was one where many of us felt stressed, disrespected, and unwelcome. Moreover, the number of users of radare2 grew every year, and we held the ultimate responsibility to provide them a stable, usable framework. As the core developer team, we have come to the conclusion that it is impossible for us to continue to pursue the goal of making radare2 better under the current circumstances and environment, and we decided to move forward on our own and fork the project. Cutter, the Graphical User Interface for radare2, and its entire team will also join Rizin and will use it as its backend.</p><p>Rizin is a newborn project that was created from radare2, hence more and more changes and differences will appear over time. A lot of efforts were put into improving our workflows, putting more tests in place, improving the API, removing redundant features, and more. We hope to provide better consistency between releases, making the framework more trustworthy to users.</p><p>We are also working to create a more inclusive and diverse community that will be inviting for new contributors and users. As an initial step, we adopted a <a href="https://rizin.re/code-of-conduct">Code of Conduct</a> that we believe is aligned with our values and with the community we want to create around Rizin.</p><p>Finally, we know and understand that now it is our turn to prove that Rizin can become a tool you can trust and enjoy using, and a community in which you feel welcome. We invite you to read our answers to your <a href="https://rizin.re/posts/faq/">Frequently Asked Questions</a> and join our communities on <a href="https://im.rizin.re/">Mattermost</a> and other chat platforms.</p></div></article></div></div>]]>
            </description>
            <link>https://rizin.re/posts/announcing-rizin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402690</guid>
            <pubDate>Sat, 12 Dec 2020 23:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bulk loading into PostgreSQL: Options and comparison]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25402430">thread link</a>) | @eatonphil
<br/>
December 12, 2020 | https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/ | <a href="https://web.archive.org/web/*/https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
<p>You have a file, possibly a huge CSV, and you want to import its content into your database. There are lots of options to do this but how would you decide which one to use. More often than not the&nbsp;question is how much time would the&nbsp;bulk load would take. I found my self&nbsp;doing the same few days back when I wanted to design a data ingestion process for PostgreSQL where we needed to bulk load around 250GB of data from CSV files every 24 hours.</p>



<p>Goto solution for bulk loading into PostgreSQL is the native copy command. But one limitation with the copy command is that it requires the CSV file to be placed on the server. So I decided to do a simple comparison of bulk loading options and techniques.</p>



<p>In short I wanted to see the performance difference of loading the data into standard vs unlogged tables and want to compare the loading time difference between loading into table that has an index vs drop-index-&gt;load-&gt;recreate-index option.</p>



<p>Moreover, I wanted to see the performance difference of COPY command, client-side copy command, loading through file_fdw, and pg_bulkload for each of the above options.</p>



<h2>Database and system settings</h2>



<p>Since the intention was to do a relative performance comparison among different data loading techniques and options, so using the personal MacBook Pro running macOS Catalena with 16GB of RAM, 2.7 GHz Quad-Core Intel Core i7 processor, and 500 GB SSD disk was good enough to serve the purpose. </p>



<p>For database I compiled PostgreSQL v12 from source code with default configure options. I left most of the configuration parameter to their default values and only changed the below mentioned settings.</p>



<pre><code>shared_buffers = 2GB
work_mem = 400MB
maintenance_work_mem = 640MB
</code></pre>



<h2>Sample data and schema</h2>



<p>For the purpose of this exercise, I downloaded a sample CSV file from <a href="http://eforexcel.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/">http://eforexcel.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/</a> with 5million rows.</p>



<p>The sample CSV file contains 5 million rows, 14 columns and 624MB in size.</p>



<p><img loading="lazy" width="986" height="71" src="https://www.highgo.ca/wp-content/uploads/2020/12/1-3.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/1-3.png 986w, https://www.highgo.ca/wp-content/uploads/2020/12/1-3-300x22.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/1-3-768x55.png 768w" sizes="(max-width: 986px) 100vw, 986px"></p>



<p><img loading="lazy" width="2618" height="390" src="https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv.png 2618w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-300x45.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1024x153.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-768x114.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1536x229.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-2048x305.png 2048w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1920x286.png 1920w" sizes="(max-width: 2618px) 100vw, 2618px"></p>



<p>To keep things simple I created a sales_record table in PostgreSQL with one to one mapping with the CSV file</p>



<pre>CREATE TABLE sales_record 
(
	region VARCHAR,
	country VARCHAR,
	item_type VARCHAR,
	sales_channel VARCHAR,
	order_priority CHAR,
	order_date DATE,
	order_id INT,
	ship_date DATE,
	unit_sold INT,
	unit_price FLOAT,
	unit_cost FLOAT,
	total_revenue FLOAT,
	total_cost FLOAT,
	total_profit FLOAT
);</pre>



<p>Along with that I also wanted to see the impact of having an index on the bulk load performance, So for tests that&nbsp;require&nbsp;an INDEX, I created a <code>btree</code> index on the <code>country</code> column.</p>



<pre><code>CREATE INDEX country_idx ON sales_record USING btree (country);</code></pre>



<h2>Load using the <a href="https://www.postgresql.org/docs/current/sql-copy.html">COPY</a> command</h2>



<p><code>COPY</code>&nbsp;moves data between&nbsp;PostgreSQL&nbsp;tables and standard file-system files. The copy command comes in two variants, COPY TO and COPY FROM. The former copies the table content to the file, while we will use the latter to load data into the table from the file.</p>



<pre><code>COPY sales_record FROM '/Users/muhammadusama/work/data/5m_Sales_Records.csv' CSV HEADER;</code></pre>



<h2>Load using <a href="https://www.postgresql.org/docs/current/app-psql.html">psql</a> ‘\copy’</h2>



<p>‘<code>\copy</code>‘ is a <code>psql</code> operation that runs an&nbsp;SQL&nbsp;<a href="https://www.postgresql.org/docs/current/sql-copy.html">COPY</a>&nbsp;command, but instead of the server reading or writing the specified file,&nbsp;<code>psql</code>&nbsp;(client) reads or writes the file and routes the data between the server and the local file system. This means that file accessibility and privileges are those of the local user, not the server, and no SQL superuser privileges are required.</p>



<pre>\copy sales_record FROM '/Users/muhammadusama/work/data/5m_Sales_Records.csv' csv header;</pre>



<h2>Through <a href="https://www.postgresql.org/docs/current/file-fdw.html">file_fdw</a></h2>



<p>The foreign-data wrapper&nbsp;<code>file_fdw</code>, can be used to access data files in the server’s file system, or to execute programs on the server and read their output.&nbsp;We can also use the file_fdw to load data from CSV to PostgreSQL tables.</p>



<pre><code>-- Create file_fdw extension and foreign server
CREATE  EXTENSION file_fdw ;
CREATE SERVER file_fdw_server FOREIGN DATA WRAPPER file_fdw; 

-- Define the foreign table that points to our CSV file
CREATE FOREIGN TABLE foreign_sales_record (
	region VARCHAR,
	country VARCHAR,
	item_type VARCHAR,
	sales_channel VARCHAR,
	order_priority CHAR,
	order_date DATE,
	order_id INT,
	ship_date DATE,
	unit_sold INT,
	unit_price FLOAT,
	unit_cost FLOAT,
	total_revenue FLOAT,
	total_cost FLOAT,
	total_profit FLOAT) SERVER file_fdw_server
		OPTIONS (
			format 'csv',
			header 'false' ,
			filename '/Users/muhammadusama/work/data/5m_Sales_Records.csv',
			delimiter ',',
			null '');

-- Copy the data from foreign table to local table
INSERT INTO sales_record SELECT * from foreign_sales_record;
</code></pre>



<p>Although <code>file_fdw</code> is not expected to be as fast as COPY command when it comes to loading the data but it provides a lot of flexibility and options when it comes to pre-processing the data before loading.</p>



<h2><a href="https://github.com/ossc-db/pg_bulkload">pg_bulkload</a> tool</h2>



<p>pg_bulkload is also a very interesting option when it comes to high speed data loading. Its an open-source tool that achieves its performance by skipping the shared buffers and WAL logging.</p>



<pre><code>-- CREATE pg_bulkload extension
$ bin/psql -c "CREATE EXTENSION pg_bulkload" postgres

-- Create control file with appropriate contents
$ more sample_csv.ctl 
WRITER = PARALLEL
OUTPUT = public.sales_record  # [&lt;schema_name&gt;.]table_name
INPUT = /Users/muhammadusama/work/data/5m_Sales_Records.csv  # Input data location (absolute path)

TYPE = CSV           # Input file type
QUOTE = "\""         # Quoting character
ESCAPE = \           # Escape character for Quoting
DELIMITER = ","      # Delimiter

-- Execute pg_bulkload utility
$ bin/pg_bulkload -d postgres -h localhost sample_csv.ctl
</code></pre>



<h2>Results</h2>



<p>Below chart shows the time taken by each tool/command to load 5 million rows from CSV file </p>



<p><img loading="lazy" width="2162" height="756" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM.png 2162w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-300x105.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1024x358.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-768x269.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1536x537.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-2048x716.png 2048w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1920x671.png 1920w" sizes="(max-width: 2162px) 100vw, 2162px"></p>



<p><img loading="lazy" width="1784" height="1092" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM.png 1784w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-300x184.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1024x627.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-768x470.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1536x940.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1764x1080.png 1764w" sizes="(max-width: 1784px) 100vw, 1784px"></p>



<p><img loading="lazy" width="1904" height="1204" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM.png 1904w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-300x190.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1024x648.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-768x486.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1536x971.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1708x1080.png 1708w" sizes="(max-width: 1904px) 100vw, 1904px"></p>



<p><img loading="lazy" width="1794" height="928" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM.png 1794w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-300x155.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-1024x530.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-768x397.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-1536x795.png 1536w" sizes="(max-width: 1794px) 100vw, 1794px"></p>



<h2>Conclusion</h2>



<p>Each method for data loading has its own pros and cons which may make one preferred choice over others for a particular use case. But when it comes to raw performance pg_bulkload is a clear winner with COPY and /copy line up behind while file_fdw stands at the last place.</p>



<p>While no matter which data loading method we use, loading into an indexed table is always slow, So do consider <code>drop-index-&gt;load-&gt;create-index </code>when you have a huge data to be loaded.</p>



<blockquote><p>Comparison of all the tools was an apple to apple comparison with both client and server were running on the same machine. So, /copy had no network overhead. In the case of PostgreSQL server and client are on different<em> machines the /copy command may not perform as well as these above results.</em></p></blockquote>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><a href="https://www.highgo.ca/author/muhammad-u/"><img src="https://www.highgo.ca/wp-content/uploads/2019/08/usama.jpg" alt="" itemprop="image"></a></p><div><p>Muhammad Usama is a database architect / PostgreSQL consultant at HighGo Software and also Pgpool-II core committer. Usama has been involved with database development (PostgreSQL) since 2006, he is the core committer for open source middleware project Pgpool-II and has played a pivotal role in driving and enhancing the product. Prior to coming to open source development, Usama was doing software design and development with the main focus on system-level embedded development. After joining the EnterpriseDB, an Enterprise PostgreSQL’s company in 2006 he started his career in open source development specifically in PostgreSQL and Pgpool-II. He is a major contributor to the Pgpool-II project and has contributed to many performance and high availability related features.</p></div></div>                                                                    </div></div>]]>
            </description>
            <link>https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402430</guid>
            <pubDate>Sat, 12 Dec 2020 22:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declouding Chinese WiFi Plugs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25402218">thread link</a>) | @kn100
<br/>
December 12, 2020 | https://kn100.me/declouding-chinese-wifi-plugs/ | <a href="https://web.archive.org/web/*/https://kn100.me/declouding-chinese-wifi-plugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>So, it turns out that a lot of smart gear from many manufacturers, including ones
you’ve almost certainly heard of, comes from a company called Tuya. They
seem to make all sorts of fun IOT gear, which all connects to the Tuya cloud.
What Tuya seem to do is sell whitelabeled ‘versions’ of their products to various
brands who then sell them as if they’d manufactured them themselves. Very
interesting right?</p>
<p>There exist many projects to de-cloud these products.
One such project is called Tuya-convert. Tuya convert is a tool which emulates
the update server these plugs connect to in order to deliver custom firmware to
the plug that it can run. This project is amazing, since it gives you the option
of declouding IOT gear without having to do any hardware modification at all.
Unfortunately, it seems this project is dead in the water right now since Tuya
is playing the typical cat and mouse game with the developers, and currently
Tuya is winning.</p>
<p>I wanted to open my plug up next, in order to figure out what made it tick.
Opening it was fairly difficult, given that it is held together with nothing but
clips. After running a guitar pick around the seam a few times, I finally
managed to pop the cover. What I found really surprised me. There was a board in
there that looked suspiciously like an ESP based platform. Further searching led
me to realise that the board in there that handles all the ‘smart’ of the plug
is actually an implementation of the ESP8285 - which is a cheaper (but just as
hackable) variant of the ESP8286, which is related to the ESP32.</p>
<p>Consulting the easily accessible datasheet for the TYWE-2s - we can quickly
identify the serial pins, and solder wires to them. Then, we can connect it up
to some Serial to USB adaptor and could flash whatever code we wanted to the ESP.
I however wanted a nicer solution. I found Tasmota. Tasmota is another open source
project that runs on these plugs that allows you to connect them up to HomeAssistant
or similar. It works really well. Read on for the process:</p>
<ol>
<li>Buy a WiFi plug.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-package.jpg"> <figcaption>
<h4>My plug, the Ultrabrite Smart Power.</h4>
</figcaption>
</figure>
<ol start="2">
<li>Open it up, in order to figure out where the serial pins are. We can see on mine,
there is a nice TYWE-2S module which unfortunately due the construction of this plug
has awkward to access serial pins.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-board-1.jpeg"> <figcaption>
<h4>Front view of the board.</h4>
</figcaption>
</figure>
<figure>
<img src="https://kn100.me/images/plug-board-2.jpeg"> <figcaption>
<h4>View of the pins we need access to. Unfortunately, the two options you have for getting access to them are to desolder the enormous blobs of solder holding the mains plug pins on, or to cut into the case. I went with cutting into the case. Ugly, but works.</h4>
</figcaption>
</figure>
<ol start="3">
<li>Put it back together, and cut a hole where the pins you need are.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-hole.jpg"> <figcaption>
<h4>View of the hole I cut. I cut it using a hacksaw and a hot knife.</h4>
</figcaption>
</figure>
<figure>
<img src="https://kn100.me/images/plug-pins.jpg"> <figcaption>
<h4>The hole on a different plug didn't go as cleanly. This photo shows the relevant pins though.</h4>
</figcaption>
</figure><p>
See <a href="https://developer.tuya.com/en/docs/iot/device-development/module/wifi-module/we-series-module/wifie2smodule?id=K9605u79tgxug">here</a> for a data sheet to help identify which pins are which.</p>
<ol start="4">
<li>Solder some female jumper wires to the pins we need access to, and connect them to
the serial interface. You’ll want to make especially super sure that your interface
is clever enough to support 3.3v logic level input. Otherwise you risk frying the
board or just failing to flash the board repeately. Ask me how I know.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-serial.jpg"> <figcaption>
<h4>Soldered wires, and a serial adaptor. I specifically used one of the cheap CH340G adaptors from eBay</h4>
</figcaption>
</figure>
<ol start="5">
<li>Grab <a href="https://github.com/tasmota/tasmotizer">Tasmotiser</a> and follow the instructions. Make very sure your wifi details are correct, otherwise you’ll end up having to flash the plug a second time.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-tasmotizer.png"> <figcaption>
<h4>Soldered wires, and a serial adaptor. I specifically used one of the cheap CH340G adaptors from eBay</h4>
</figcaption>
</figure>
<ol start="6">
<li>Once your Tasmotised plug is up, and you can control it from a web interface, it’s time
to interface it with your HomeAssistant install. Your Home Assistant install must already
have the MQTT integration. Ensure you enable <em>discovery</em> in your Home Assistant MQTT config.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-mqtt-discovery.png"> <figcaption>
<h4>Enabling MQTT discovery in Home Assistant.</h4>
</figcaption>
</figure>
<ol start="7">
<li>Go back to the web server for your WiFi Plug. Configure the MQTT server to connect to
the MQTT server your Home Assistant is connected to.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-mqtt.png"> <figcaption>
<h4>The web interface for configuring mqtt. See the Tasmota docs for more info.</h4>
</figcaption>
</figure>
<ol start="8">
<li>In this same interface, head to console, and type <code>SetOption19 1</code>. This causes the plug
to emit an autodiscovery message which should mean Home Assistant picks up on your plug and
you should now be able to control it in Home Assistant, sans cloud!</li>
</ol>
</div></div>]]>
            </description>
            <link>https://kn100.me/declouding-chinese-wifi-plugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402218</guid>
            <pubDate>Sat, 12 Dec 2020 22:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Hacked into Facebook's Legal Department Admin Panel]]>
            </title>
            <description>
<![CDATA[
Score 560 | Comments 236 (<a href="https://news.ycombinator.com/item?id=25401294">thread link</a>) | @hackerpain
<br/>
December 12, 2020 | https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/ | <a href="https://web.archive.org/web/*/https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>We’ve been in this pandemic since&nbsp; March and once the pandemic started I was having plenty of free time, And I need to use that time wisely, So I’ve decided to take the OSWE certification and I finished the exam on 8 of August, after that, I took a couple of weeks to recover from the OSWE exam, then in the med of September, I said you know what? I did not register my name in the Facebook hall of fame for 2020 as I do every year. okay, let’s do it.</p>

<p>I never found a vulnerability on one of Facebook subdomains, and I took a look at some writeups and I saw one writeup in one of Facebook subdomains which It got all my attention It was a great write up you can check it out <a href="https://ysamm.com/?p=280">[HTML to PDF converter bug leads to RCE in Facebook server.]</a></p>
<p>So after reading this writeup now I took a good idea about how many vulnerabilities I could find in such a huge web app.</p>

<p>So my main target was https://legal.tapprd.thefacebook.com and my goal was RCE or something similar.</p>

<p>I ran some fuzzing tools just to get the full endpoints of this web app and I took a 2 hours nap and watched a movie, Then I got back to see the results okay I got some good results.</p>

<p>Dirs found with a 403 response:</p>
<pre><code>
Dirs found with a 403 response:

/tapprd/
/tapprd/content/
/tapprd/services/
/tapprd/Content/
/tapprd/api/
/tapprd/Services/
/tapprd/temp/
/tapprd/logs/
/tapprd/logs/portal/
/tapprd/logs/api/
/tapprd/certificates/
/tapprd/logs/auth/
/tapprd/logs/Portal/
/tapprd/API/
/tapprd/webroot/
/tapprd/logs/API/
/tapprd/certificates/sso/
/tapprd/callback/
/tapprd/logs/callback/
/tapprd/Webroot/
/tapprd/certificates/dkim/
/tapprd/SERVICES/
</code></pre>
<p>Okay, I think this result is very enough to support my previous theory about how huge this application, Then I started to read the javascript files to see how the website works and what methods it uses ..etc</p>

<p>I noticed a way to bypass the redirection into the Login SSO, https://legal.tapprd.thefacebook.com/tapprd/portal/authentication/login and after analyzing the login page, I noticed this endpoint</p>
<p><strong> /tapprd/auth/identity/user/forgotpassword</strong></p>
<p>and after doing some fuzzing on the user endpoint I’ve noticed another endpoint which its <strong>/savepassword&nbsp;&nbsp;</strong>and it was expecting a POST request, Then after reading the javascript files I knew how the page work, there should be a generated token and xsrf token.. etc The idea that first came to me okay, Lets test it and see if it will work I tried to change manually using burp suite but I got an error, the error <em>was execution this operation failed</em>.</p>

<p>I said okay, this might be because the email is wrong or something? let’s get an admin email, Then I started to put random emails in a list to make a wordlist and after that, I used the intruder and I said let’s see what will happen.</p>
<p>I got back after a couple of hours I found the same error results plus one other result, This one was 302 redirect to the login page, I said wow, I’ll be damned if this worked Haha.</p>

<p>So let’s get back to see what I’ve done here, I sent random requests using intruder with a CSRF token and random emails with a new password to this endpoint <em><strong>/savepassword</strong></em></p>
<p>and one of the results was 302 redirect.</p>
<div id="attachment_128"><p><img aria-describedby="caption-attachment-128" loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/redirect-login.png" alt="fbredtrect" width="989" height="446" srcset="https://alaa.blog/wp-content/uploads/2020/11/redirect-login.png 1671w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-300x135.png 300w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-1024x461.png 1024w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-768x346.png 768w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-1536x692.png 1536w" sizes="(max-width: 989px) 100vw, 989px"></p><p id="caption-attachment-128">Redirect</p></div>
<p><strong>Now I went to the login page and I put the login email and the new password and BOOM I logged in Successfully into the application and I can enter the admin panel 🙂</strong></p>

<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin.png" alt="" width="882" height="468" srcset="https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin.png 1785w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-300x159.png 300w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-1024x543.png 1024w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-768x407.png 768w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-1536x815.png 1536w" sizes="(max-width: 882px) 100vw, 882px"></p>

<p>I read the hacker report who found RCE before using the PDF and they gave him a reward of 1000$ only so I said okay, let’s make a good Impact here and a perfect exploit.</p>
<p>I wrote a quick and simple script to exploit this vulnerability with python you put the email and the new password and the script will change the password.</p>
<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/Exploit1.png" alt="" width="983" height="123" srcset="https://alaa.blog/wp-content/uploads/2020/11/Exploit1.png 983w, https://alaa.blog/wp-content/uploads/2020/11/Exploit1-300x38.png 300w, https://alaa.blog/wp-content/uploads/2020/11/Exploit1-768x96.png 768w" sizes="(max-width: 983px) 100vw, 983px"></p>
<p><strong>The Impact here was so high because the Facebook workers used to login with their workplace accounts, Which mean they’re using their Facebook accounts access token, and maybe if another attacker wanted to exploit this it might give him the ability to gain access to some Facebook workers accounts .. etc&nbsp;</strong></p>
<p>Then I reported the vulnerability and the report triaged.</p>

<p><strong>And on 2 of October, I received a bounty of 7500$&nbsp;</strong></p>
<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/reward.png" alt="" width="654" height="171" srcset="https://alaa.blog/wp-content/uploads/2020/11/reward.png 696w, https://alaa.blog/wp-content/uploads/2020/11/reward-300x78.png 300w" sizes="(max-width: 654px) 100vw, 654px"></p>
<p>I enjoyed exploiting this vulnerability so much, so I said that’s not enough, this is a weak script! let’s dig more and more.</p>
<p>And I found two more vulnerabilities on the same application, But we will talk about the other vulnerabilities in the Part two writeup 🙂</p>

<p>Cheers.</p>
<div id="sexy-author-bio"><p><a id="sab-Email" href="https://alaa.blog/cdn-cgi/l/email-protection#08696469697b696a7a617b60486f65696164266b6765" target="_top"><img id="sig-Email" alt="Alaa Abdulridha on Email" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabemail.png"></a><a id="sab-Facebook" href="https://www.facebook.com/alaa.abdulridha.716" target="_top"><img id="sig-Facebook" alt="Alaa Abdulridha on Facebook" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabfacebook.png"></a><a id="sab-Github" href="https://github.com/Alaa-abdulridha" target="_top"><img id="sig-Github" alt="Alaa Abdulridha on Github" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabgithub.png"></a><a id="sab-Instagram" href="https://www.instagram.com/al_shwele" target="_top"><img id="sig-Instagram" alt="Alaa Abdulridha on Instagram" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabinstagram.png"></a><a id="sab-Twitter" href="https://twitter.com/alaa0x2" target="_top"><img id="sig-Twitter" alt="Alaa Abdulridha on Twitter" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabtwitter.png"></a></p><p><a href="https://alaa.blog/author/alaaabdulridha/" target="_top"><img src="https://alaa.blog/wp-content/uploads/2019/08/aaaaaaaaaa-150x150.jpg" width="100" height="100" alt="Alaa Abdulridha"></a></p><p>My name is Alaa Abdulridha I'm a computer engineering student and cybersecurity researcher I'm interested in web application pen-testing and game development, also I'm interested in some bug bounty programs, I like a lot of things such as reverse engineering, reading the others code to learn and then to find my own exploits and teaching it to you, Do you want to know more about me? <a href="https://alaa.blog/whoami/">Click Here</a>.</p></div>						
											</div></div>]]>
            </description>
            <link>https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25401294</guid>
            <pubDate>Sat, 12 Dec 2020 20:17:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meetings and Team Efficiency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25400985">thread link</a>) | @patapizza
<br/>
December 12, 2020 | https://jodent.io/posts/meetings-and-team-efficiency | <a href="https://web.archive.org/web/*/https://jodent.io/posts/meetings-and-team-efficiency">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jodent.io/posts/meetings-and-team-efficiency</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400985</guid>
            <pubDate>Sat, 12 Dec 2020 19:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Agent vs. System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400872">thread link</a>) | @stopachka
<br/>
December 12, 2020 | https://stopa.io/post/273 | <a href="https://web.archive.org/web/*/https://stopa.io/post/273">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span><p>Does it feel like society is heading off a cliff?</p><p>Social media companies create platforms so addicting that children can’t help but stick to their phones. Politicians make increasingly vicious personal attacks, to the point where elections look like dog-fights. Newspapers pump out so much biased click-bait that people have vilified opposing views. Companies produce such horrible food that obesity is now one of the most deadly threats. Universities teach so poorly that all the youth end up with are vague ideas and a mountain of debt.</p><p>This makes the future bleak, but it gets worse when you try to find a cause.</p><p>It feels like there are simple solutions right in front of us: Facebook could just change their algorithm to be less addicting. Politicians could just uphold a modicum of respect. Newspapers could just increase their journalistic standard. Food companies could just sell healthier food.</p><p>And when we consider those solutions, we can’t help but feel indignation: It’s like our leaders have forsaken us. They can just make those choices, but they don’t. They imperil our society, even the livelihood of their own grandchildren, for what seems like avarice and short-sightedness. </p><p>With that view, one solution sprouts up: <strong>what if we</strong> <strong><em>forced</em></strong> <strong>our leaders to do the right thing?</strong> </p><p>We could replace Mark Zuckerberg with someone who would make sure the algorithms were less addicting. We could make the New York Times and Fox News report a balanced viewpoint. We could tell food companies to remove sugar from their food. We could ask Literature professors to teach something more useful — perhaps prose.</p><p>Simple right?</p><p>Well, it turns out we’ve tried this before. Many, many times, actually. At innumerable points in our history, we’ve tried to solve moneylending, conspicuous consumption, alcohol, prostitution, various child-rearing practices, emigration, immigration, the list goes on. Most of the time, we employed the same methods and reached the same result: utter failure.</p><p>Why? </p><p>Let’s look at Facebook for clues. What would happen if Mark Zuckerberg made Facebook’s algorithm less addictive? If our conviction is that Facebook is the reason people cling to their phones, we would expect a sustained decrease in social media usage. But would that really happen? </p><p>If Facebook’s algorithm became less addictive, the only change we’d notice is a decrease in <em>Facebook’s</em> market share, not social media usage. Twitter, Tik Tok, Snapchat, and many a startup would gladly eat Facebook’s lunch.</p><p>Here we enter our first logical fallacy. We’ve ascribed too much power to Facebook. People don’t exist, so Facebook can show them ads. Facebook exists <em>because</em> people want to see what their friends are up too, and are okay with seeing ads. The underlying force that decides the demand for Facebook is people and their wants. Facebook doesn’t dictate what people <em>should</em> want.</p><p>Abstract “Facebook” and “Social Media” away, and you get to a general principle. The “system” (in this case, “Social Media”) is what drives behavior, not the “agent” (in this case, “Facebook”). The agent is merely a player, powerful to the extent that they can satisfy the system. </p><p>You can see this by looking at Facebook’s history: had Facebook failed to transition to mobile or to purchase Instagram, it would be a lot less relevant today. Social media, however, would very much remain relevant. </p><p>The other ills of society fit this abstraction. Presidential Candidates lower their standards because the people who select them respond positively to dog fights. The New York Times writes biased articles because people prefer to read them. Harvard teaches English Literature, because people still study it.</p><p>So we come to an uncomfortable truth: what you see on your feed isn’t quite as up to Mark Zuckerberg as we think. </p><p>If we really want to solve society’s ills, we need to think one level higher. How does the <em>system</em> work? Why is the current incentives in social media gluing us to phones? Why is it most profitable to share divisive news? Why do dog-fights win elections?</p><p>The answers to these questions are the clues we need to change how the system works. But, finding the answers is so hard that we’ve stopped trying. Instead, we look for solutions that come to mind immediately. </p><p>What solution comes to mind immediately? Regulation.</p><p>Instead of replacing Mark Zuckerberg, what if we regulated the algorithms that social media companies could use? Similarly, what if we made rules about what is “balanced” news? What if we specified what politicians were allowed to say? What if we made laws about college curriculums?</p><p>These ideas flower up over and over again across our civilizations.</p><p>In the middle ages for example, we tried to solve consumption with sumptuary laws: regulations on the amount of money classes could spend on clothes. If you’re a knight, your wife can spend at most this much for a coat, if you’re a doctor, this much, and so on.</p><p>More closer to home, there was prohibition. The majority agreed that alcohol was bad for society. The moral choice seemed simple: let’s just ban it. If alcohol sellers aren’t allowed to sell alcohol, then people would stop drinking, and society would be better off.</p><p>Of course, both of these ideas failed, and they look ridiculous to us now. </p><p>Why did they fail?</p><p>The consumption that sumptuary laws were trying to curb was driven by an underlying human need: the need to distinguish oneself. This is so core to our collective existence that no amount of regulation could curb it. As Montaigne astutely pointed out, the laws even made consumption <em>more attractive:</em> why not get the goods that “only princes” could wear?</p><p>The same was true for prohibition. Make alcohol illegal, and watch the bootleggers flourish. The way a river finds the shortest path down a mountain, a seller finds the shortest path to a customer. The need was too strong.</p><p>Worse still, these laws share a common blindness: they don’t consider to second order effects. Sumptuary laws failed to react to changes in fashions, and didn’t consider the counterintuitive increase in desire for distinguishing goods. Prohibition didn’t consider the bootleggers.  </p><p>This is because regulation works in large sweeps and requires concerted effort, while systems are versatile, decentralized, and can change faster than the time it takes you to finish this sentence. We used a slow, one dimension process to change a fast, multi-dimensional system. The flaw is inherent in our method.</p><p>So, our simple solutions are no longer so simple. The picture may seem bleaker, but at least we’ve now pruned some incorrect methods. So what paths are promising? </p><p>As far as I know, two methods have worked.</p><p>The first, is Natural Selection. In the same way that the environment forces a gazelle to be fast, reality forces our society to be effective. Imagine if the United States, for example, descended into socialism. This wouldn’t mean that the whole world would be doomed to it. If the consequences of socialism bear fruit, our society would lose productivity. As long as <em>some</em> society was able to maintain freedom from this kind of coercion, given enough time that society would become the world power. What we did to the Soviet Union, this more productive society would do to us.</p><p>Natural Selection works, but it is a bleak option to rely on: it takes a while and has no mercy. We’d sacrifice lives, increase suffering, and may have to wait through a new dark age. And the world isn’t so theoretical: while we wait, there are existential threats that could end society completely.</p><p>Thankfully, this is not the only option. Humanity has one trump card up its sleeve, and it’s saved us over and over again: Innovation.</p><p>Consider electric cars. If we tried to force people to buy electric cars, we’d end up with the same problems as prohibition. As long as electric cars suck compared to gas-guzzlers, people will want gas-guzzlers. Tesla solved that problem. How? they out-innovated gas-guzzlers, and better served the human want for transportation.</p><p>For news, we don’t need to force the New York Times to report fairly. Substack may do more to fix reporting quality than any regulation could have. Now, journalists can build an audience and support content that isn’t dependent on clicks. To the joy of reporters and readers alike, they changed the incentives that governed journalism.</p><p>What’s the analog of this for Facebook? Could we build a social network that made offline interactions as fun and intuitive as online ones? Could we build platforms that made constructive debate more engaging than Twitter? Could we integrate political transparency in our government, so that presidential candidates would filter to high-integrity? Could we make a University that encouraged free thinking and creation, at a hundredth the cost?</p><p>It’s hard, but once we choose to search along viable paths, the outlook is optimistic. </p><p>There have been many points in our past that imperiled our society, and innovation was up to the task. It is just as powerful, decentralized, and versatile as the most pernicious of society’s ills. </p><p>It’s a wonder that so many people today can live a life that lords could only have dreamed of a few hundred years ago. Slavery is eradicated in most of the world, and feudal societies are the rarest. Our production supports billions of people — an idea that would have seemed ridiculous to Malthus. </p><p>It has been done before, and we know this path has viable solutions, while our simple solution is known to fail. If you’re a person who wants to make a dent in the world, now you know two things: what <em>not</em> to do, and a potential path to success. Regulation or moralizing won’t help. Innovation will.</p><p>You may balk at the task ahead of you: climate change is a problem so daunting that it’s hard to think about. Luckily, innovation is opaque. You don’t need to attack problems directly. </p><p>Penicillin just showed up on Fleming’s desk. Rocket engines evolved from car engines. Ideas tend to compound together, forming ever-more complex ideas. This means you don’t have …</p></span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/273">https://stopa.io/post/273</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/273</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400872</guid>
            <pubDate>Sat, 12 Dec 2020 19:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yo WASM – The Easy Way to WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25400837">thread link</a>) | @praveenperera
<br/>
December 12, 2020 | https://deislabs.io/posts/introducing-yo-wasm/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/introducing-yo-wasm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>WebAssembly (Wasm) is a portable standard for bytecode, allowing code to be compiled to an efficient representation that’s amenable to just-in-time optimisation, and to be run on the operating system and runtime environment of your choice.  An ever-increasing number of languages offer compilation to Wasm, and Wasm runtimes are available in major browsers and as separate programs.  The existence of runtimes outside the browser, such as <a href="https://wasmtime.dev/"><code>wasmtime</code></a> and <a href="https://wascc.dev/"><code>waSCC</code></a>, opens up the possibility of using WASM as a general-purpose bytecode format, similar to <a href="https://en.wikipedia.org/wiki/Java_bytecode">Java bytecode</a> or <a href="https://en.wikipedia.org/wiki/Common_Intermediate_Language">.NET CIL</a>.  For example, the <a href="https://deislabs.io/posts/introducing-krustlet/">Krustlet</a> project provides a way to run WebAssembly modules as Kubernetes pods, performing compute work or serving HTTP requests.</p>

<p>Although languages such as <a href="https://rustwasm.github.io/docs/book/">Rust</a> and <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/C_to_wasm">C/C++</a> can compile to WASM, it’s not always obvious how to set up projects in this way - there is extra ceremony compared to most languages’ “native” target.  Setting up debugging and deployment also involves extra steps too, and those aren’t always obvious.  So there’s a barrier to entry in the first place, and unwelcome configuration every time you create a new project.</p>

<p>To make this a bit easier, we’re building a Wasm project generator, using the popular <a href="https://yeoman.io/">Yeoman</a> code generator, to take care of this setup for you.  We’ve just released the first preview and we’d love folks to try it out and let us know how it goes.</p>

<p>To install Yeoman and the Wasm generator, you’ll need to have Node.js and NPM already installed; then run:</p>

<pre><code>npm install -g yo
npm install -g generator-wasm
</code></pre>

<p>Then generate your new project:</p>

<pre><code>mkdir myproject
cd myproject
yo wasm
</code></pre>

<p>The generator will ask you a few questions, of which two are interesting:</p>

<ol>
<li><p>Which language do you want the project generated in?  At the moment, we can do Rust, C and AssemblyScript.  We’d be delighted to have more.</p></li>

<li><p>Do you want to publish the compiled Wasm module to an OCI registry, and if so which one?  This is relevant for workloads that you envisage running in a cloud environment such as Kubernetes with Krustlet.  You don’t have to publish to an OCI registry; if you do, we currently only offer Azure Container Registry, but again would love to extend that to other OCI registries.</p></li>
</ol>

<p><img src="https://i.imgur.com/QYAQcHH.png" alt="Project setup in yo wasm"></p>

<p>The result of all this is a “hello, world” application.  The code itself is uninteresting, being just a minimal Rust, C or AssemblyScript program, but the generator also provides a bunch of things to make the development experience easier:</p>

<ol>
<li><p>Visual Studio Code tasks to build and debug the Wasm build.  This means that - if you’re a VS Code user - you can get up and running editing and debugging the project very quickly.  The Debug Wasm debug configuration uses <code>wasmtime</code> to run the program, and the LLDB debugger to support breakpoints, etc. in the running Wasm.</p>

<p><img src="https://i.imgur.com/ypz6o0P.png" alt="The Debug WASM configuration in VS Code"></p></li>

<li><p>GitHub actions to build pull requests, and to publish the compiled Wasm module to your chosen OCI registry when you merge to <code>main</code> or tag a release with a string of the form <code>v*</code> (e.g. <code>v1.0.0</code>).  (If you chose not to publish to an OCI registry, this action just creates a build artifact.)</p>

<p><img src="https://i.imgur.com/ARpY3jl.png" alt="Build and publish workflows running out of the box"></p></li>
</ol>

<p>The preview release has some limitations.  We’ve mentioned the limited language and registry options.  One important restriction is that all our current templates target WASI (WebAssembly System Interface) and the <code>wasmtime</code> runtime.  We’d love to have templates for other environments and runtimes, but we could really do with feedback on that before we invest in it.</p>

<p>We hope you’ll give <code>yo wasm</code> a try.  Please let us know if you run into any problems by raising an issue at <a href="https://github.com/deislabs/generator-wasm/issues">https://github.com/deislabs/generator-wasm/issues</a>, or feel free to send a pull request if there’s something you’d like to add or improve.  Thanks!</p>

      
      
    </div></div>]]>
            </description>
            <link>https://deislabs.io/posts/introducing-yo-wasm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400837</guid>
            <pubDate>Sat, 12 Dec 2020 19:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Still Rusting – One Year Later]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400826">thread link</a>) | @praveenperera
<br/>
December 12, 2020 | https://deislabs.io/posts/still-rusting-one-year-later/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/still-rusting-one-year-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>It has been about a year since the DeisLabs team starting using Rust in a “serious” project. About this time last year, we started work on what became the <a href="https://github.com/deislabs/krustlet">Krustlet</a> project. Since then, we have been using Rust extensively across our projects and have learned a ton more about the language’s strengths and weaknesses. As “Rust After the Honeymoon” posts currently seem to be all the rage, we thought we could contribute a little to the discussion with our experiences writing applications for the cloud world.</p>

<p>This post is organized using the classic (if not tired) good, bad, and ugly structure. In the bad and ugly sections, everything is stated as points of feedback and is not meant as a complaint. The whole point of this post is to go beyond the more superficial parts of the language and into things that really make a difference in our day-to-day programming work. Spoiler alert: We still <em>really</em> like Rust, so all of this is intended as helpful data for those working on the language, to give people new to the language a good idea of some of the things they might run into, and to help others evaluate Rust for their own use. We have tried to incorporate ideas of possible solutions, no matter how vague, to the problems we bring up.</p>

<p>At the very end, we also have a bonus feature about Go and Rust. Given the team’s background in many Go projects, we often hear something like this: “Well, what about Go? Do you regret moving to Rust? What do you miss from Go?” Addressing this in the context of our discussion of Rust felt like a smart decision. If you don’t care about that topic or it doesn’t interest you, feel free to skip it.</p>

<p>Now with that out of the way, let’s get going!</p>

<h2 id="the-good">The Good</h2>

<h3 id="traits">Traits</h3>

<p>First up, let’s talk about traits. We have absolutely loved the trait system in Rust. In particular, we really enjoy the conversion and reference traits (e.g. <code>TryFrom</code>/<code>From</code>, <code>AsRef</code>, <code>FromStr</code>, <code>Deref</code>, etc.). These are great examples of why traits are better than most other interface-style types – because the type itself doesn’t have to implement an interface to be used as another type. <code>FromStr</code> allows any type to implement a way to parse a bare string into a type (really useful for APIs). Another simple example can be found in the many types that implement <code>AsRef&lt;[u8]&gt;</code> or <code>Deref&lt;Type = [u8]&gt;</code>. Instead of having some sort of <code>Bytes</code> interface that all the types have to implement to be able to do operations as if it was a slice of bytes, you can just automatically pick up the methods from the underlying type. Yes, I know you could embed types or use inheritance, but the elegance of this is quite nice. This also allows me to write custom types and have easy/cheap conversions or references to them from other external types. It leads to generic parameters that look like this:</p>

<pre><code>// A function that can write anything that can be accessed as bytes:
// write_all("hello!")
// write_all(String::from("hello!"))
// write_all(b"hello!")
fn write_all&lt;T: AsRef&lt;[u8]&gt;&gt;(data: T)

// Or, I can take anything that can be converted to my custom type
fn do_something&lt;T: Into&lt;MyType&gt;&gt;(thing: T)
</code></pre>

<p>Basically, traits allow you to design flexible APIs for users that allow them to latch on to and/or extend the functionality of your code. This leads to my next point – <a href="https://serde.rs/">Serde</a>.</p>

<h3 id="a-love-letter-to-serde">A Love Letter to Serde</h3>

<p>Allow us to indulge in a brief love letter to Serde, the much-used serialization/deserialization library leveraged across the Rust ecosystem. To us, it is a first-rate product of Rust’s unique combination of features. It leverages macros, traits, and Rust’s emphasis on zero-cost abstractions to create a library that is powerful, easy to use, and performant. Developers can easily add serialization or deserialization with a simple <code>#[derive(Serialize, Deserialize)]</code> and then customize deserialization behaviors with attributes. Even if you have to implement it manually, there are plenty of docs to read. Once those traits are implemented, any serialization format that has a Serde implementation (like JSON, YAML, etc.) can then serialize or deserialize that data.</p>

<h3 id="error-handling-option-and-iter">Error handling, <code>Option</code>, and <code>Iter</code></h3>

<p>Another thing high on our “impressive Rust features” list is an amazing set of mapping, unwrapping, and iteration tools. The built in <code>Result</code> and <code>Option</code> types combined with their various mapping methods (and <code>if let</code> or <code>let thing = match {...}</code>) makes it easy to handle errors/missing data in an easy to read way. It also nudges you towards clean and readable error handling patterns (like the try <code>?</code> operator), which is helpful for people new to the language. On top of the error handling, we have the <code>Iterator</code> trait and its associated methods. There are a whole suite of chainable filters, maps, splitting, and zipping methods (similar to how LINQ and functional programming languages handle collections) along with the all-powerful <code>collect</code> method. Below is an example from Krustlet that shows unwrapping an optional value and then mapping and filtering from a collection of data:</p>

<pre><code>fn mount_setting_for(key: &amp;str, items_to_mount: &amp;Option&lt;Vec&lt;KeyToPath&gt;&gt;) -&gt; ItemMount {
    match items_to_mount {
        None =&gt; ItemMount::MountAt(key.to_string()),
        Some(items) =&gt; ItemMount::from(
            items
                .iter()
                .find(|kp| kp.key == key)
                .map(|kp| kp.path.to_string()),
        ),
    }
}
</code></pre>

<h3 id="enums">Enums</h3>

<p>We’ve found Rust enums really expressive and convenient. Rust enums aren’t just single values: they can carry associated data. What’s more, each variant can have a different data structure (like discriminated unions from other languages), and you can work with these different cases using pattern matching. They’re also full-blown types, so you can implement functions and traits on them.</p>

<p>The value of this is that you can bundle a bunch of possible cases into a single type to pass into (or return from) and function. Working with the cases is safe because you don’t need to have optional fields that only may apply to certain cases, and you can only access a case’s data when the enum matches that case. The case structure also encourages code that processes enums to adopt a clear, regular layout, making for some quite beautiful code:</p>

<pre><code>pub enum ClientError {
    /// The item already exists
    AlreadyExists,
    /// The error returned when the request is invalid. Contains the underlying HTTP status code and
    /// any message returned from the API
    InvalidRequest {
        status_code: reqwest::StatusCode,
        message: Option&lt;String&gt;,
    },
    /// A server error was encountered. Contains an optional message from the server
    ServerError(Option&lt;String&gt;),
}

pub fn handle_error(e: ClientError) {
    match e {
        ClientError::AlreadyExists =&gt; {
            println!("Item already exists")
        }
        ClientError::InvalidRequest { status_code, message } =&gt; {
            println!("Invalid request. HTTP code: {}, message: {}", status_code, message.unwrap_or_default())
        }
        ClientError::ServerError(Some(message)) =&gt; {
            println!("Server error: {}", message)
        },
        ClientError::ServerError(None) =&gt; {
            println!("Server error")
        },
        
    }
}
</code></pre>

<p>In this example, we created a simple error type and then unwrapped it according to the data contained inside of each variant. The Rust compiler makes sure we handle all variants of the enum, preventing programmer error (likely from getting distracted by a meme someone posted in chat).</p>

<h3 id="grab-bag">Grab Bag</h3>

<ul>
<li>Macros are awesome and allow you to do some powerful things (and clean up code)</li>
<li>Cargo still has our hearts. It is hands down one of the top dependency manager and build tools we’ve used</li>
<li>To quote a coworker: “NO DAMN NULL POINTERS” (emphasis theirs). You explicitly have to label code as <code>unsafe</code> to even get them</li>
</ul>

<h2 id="the-bad">The Bad</h2>

<h3 id="docs-and-clarity">Docs and Clarity</h3>

<p>As we have been using various crates across the ecosystem, we’ve found some interesting patterns in the documentation. Docs are sometimes unclear on what is happening in the actual code. They describe the functionality well, but we generally have to go digging through the code to find out whether it is truly a zero cost abstraction or if there are possible side effects to what we are doing. When you first start on projects, generally these kinds of details don’t matter. But as you start doing things that require more advanced usage, you end up digging under the hood to see what exactly is going on. For example, if we are using a library that writes data to disk, make sure to clarify which methods flush data or close things down.</p>

<p>Related to this, but slightly different, is trait documentation. As users, if we are trying to find out how we can customize behavior, we always end up jumping through a million functions, looking at all the trait bounds, before we can figure out what we need to implement (It also seems to always be a trait imported from <em>another</em> crate). An example of this from some recent work on Krustlet. We were using the <a href="https://docs.rs/tonic/0.3.1/tonic/"><code>tonic</code></a> crate and implementing a socket listener for the server. We ended up at one of the functions that allows for a custom handler, but that had 3-4 distinct bounds, 2 of which were traits from external crates. We eventually found an example in the crate repo and it wasn’t too difficult, but there was no clear documentation what needed to be implemented without digging more. This experience is <em>really really frustrating</em> for new Rust developers and we’ve seen this in multiple crates. The suggestion here would be to put a little more polish into describing what precisely needs to be implemented (even if just linking to an example) on functions with multiple trait bounds.</p>

<h3 id="missing-pieces">Missing Pieces</h3>

<p>Something to be aware of coming into the Rust ecosystem is that a lot of crates are still missing features. A recent example of this was finding out that there isn’t much support for <code>multipart</code> content types in HTTP requests except for <code>multipart/form-data</code>. This is not meant to be a complaint against any developer of any crate. We …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/still-rusting-one-year-later/">https://deislabs.io/posts/still-rusting-one-year-later/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/still-rusting-one-year-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400826</guid>
            <pubDate>Sat, 12 Dec 2020 19:31:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Adam Test: A Few More Steps to Better Code]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400806">thread link</a>) | @aard
<br/>
December 12, 2020 | http://adamard.com/adam_test.html | <a href="https://web.archive.org/web/*/http://adamard.com/adam_test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>{<br>&nbsp;&nbsp;&nbsp;&nbsp;Adam Ard<br>}</h2><br>
  <h2>The Adam Test: A Few More Steps to Better Code</h2>
  <p>In the year 2000, Joel Spolsky published <a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/" target="_blank" rel="noopener">12 questions</a> for assessing the quality of any engineering team. These questions were immensely useful and are still relevant today. Over time, I have accumulated a few extra questions of my own. I hope you find them equally helpful:</p>
<h3><strong>1. Do programmers <em>REALLY</em> have quiet working conditions?</strong></h3>
<p>Even though Joel already put this one on his list, I wanted to repeat it (I added the <em>REALLY</em> for emphasis) because the industry has totally disregarded it. The norm now is to use flashy but useless open office plans that are full of noise and interruptions. Because the software engineering world is turned so backwards on this issue, I added a few follow-up questions to make it crystal clear what “quiet working conditions” <em>REALLY</em> are:</p>
<ul>
<li>Do you have individual private work spaces with doors, or at least cubicles with six foot high walls?</li>
<li>Do you have at least 100 total square feet per developer with 30 square feet of table space?¹</li>
<li>If developers do not have private offices, are they at least limited to sharing private offices with only one other person?</li>
<li>Can developers position themselves with their backs to the wall?</li>
<li>If you must have an open office do you at least implement <a href="https://m.signalvnoise.com/library-rules-how-to-make-an-open-office-plan-work-f9f6d69a2d4c" target="_blank" rel="noopener">Library Rules</a>?</li>
<li>Do you have a good work-from-home policy so developers can escape to places of solitude to concentrate?</li>
</ul>
<h3>2. Do you divide, organize and assign roles instead of&nbsp;tasks?</h3>
<p>This question may seem like a triviality, but it is hugely important. To put it simply, if you assign tasks to developers you are likely a micro-manager. But, if you assign roles (areas of major responsibility), you are utilizing the <a href="http://adamard.com/green_and_clean.html">Covey principle of stewardship delegation</a>. For motivation, and employee engagement, this distinction will make all the difference in the world.</p>
<p>For more on this read:</p>
<ul>
<li><a href="http://adamard.com/little_tasks.html">Little Tasks, Little Trust</a></li>
</ul>
<h3><strong>3. Are you careful to never fix the scope and release date for your deliverables?</strong></h3>
<p>Don’t let people fool you by trying to alter this equation. Many will comment that if you add people or resources, you can get around it. They haven’t read <a href="https://en.wikipedia.org/wiki/Brooks%27s_law" target="_blank" rel="noopener">Brook’s Law</a>. Others will say that you can cheat on the quality to push things through. But, in the end, if you aren’t aiming for high quality your team’s morale will suffer and you will lose more productivity from disengagement than you’ll gain by cutting corners. As a result, it is just better to concentrate on scope and date. Here are some good examples in the industry:</p>
<ul>
<li><a href="https://m.signalvnoise.com/how-we-set-up-our-work-cbce3d3d9cae" target="_blank" rel="noopener">Basecamp</a> has fixed release periods, with the conviction that there is a very good 6 week version of pretty much any feature. So, essentially they pick a release date and let the scope change.</li>
<li>Others (game companies are famous for this) will simply say that their next release will be ready when it is ready. Most will complain that they don’t have this luxury in their industry (they might be surprised at how long customers will wait/pay for a superior product), but it is a nice option if you can pull it off. This is how you fix your scope, but let the date change.</li>
</ul>
<p>An interesting corollary to this is that you really shouldn’t waste your time in estimation exercises either — estimation by definition is picking a date and a scope.</p>
<h3>4. Do you utilize strong code ownership?</h3>
<p><a href="https://docs.microsoft.com/en-us/azure/devops/learn/devops-at-microsoft/code-ownership-software-quality" target="_blank" rel="noopener">Microsoft ran a study</a> of their own extensive code base (if anyone has a bunch of code to run studies on, it’s Microsoft), and found that when only one person makes the majority of the commits to a file, executable or directory, those code units have a lower incidence of bugs.</p>
<p>You can whoop and holler all you want about how <em>the magic </em>happens when everyone holds hands and codes in perfect harmony, but the truth is, people need to own what they work on. They need to have separate responsibilities. They need to be able to think deeply about what they are doing, be a custodian of the conceptual integrity of their design, and they need to be left alone to work on it.</p>
<p>This doesn’t mean that people shouldn’t bounce ideas off each other, seek advice of experts and peers, and be humble enough to except constructive criticism. It also doesn’t mean that they shouldn’t be transparent about what they are planning and producing. It just means that after all the advice comes in, and the ideas have been bounced around, one person needs executive authority over the decisions in a given domain.</p>
<p>For more on this read:</p>
<ul>
<li><a href="http://adamard.com/code_ownership.html">Strong Code Ownership</a></li>
<li><a href="http://adamard.com/fountainhead.html">The Fountainhead and Software Engineering</a></li>
<li><a href="http://adamard.com/code_reviews_broke.html">Code Reviews are Broken — Here is How to Fix Them</a></li>
<li><a href="http://adamard.com/three_agile.html">Three Ways Agile has Gone Astray</a></li>
</ul>
<h3>5. Are worker metrics kept private to individuals and never revealed to management?</h3>
<p>It is best to avoid companies that rely too heavily on scientific management practices, also known as <a href="https://en.wikipedia.org/wiki/Scientific_management" target="_blank" rel="noopener">Taylorism</a>. Programming in particular is not a profession that will benefit from being managed by trying to optimize a group of performance indicators. Anyone who has been managed in this way can attest to the dysfunction that it creates. Sadly, as soon as a worker metric is used to motivate programmer output, it loses its ability to be useful. Some people call this <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law" target="_blank" rel="noopener">Goodhart’s Law</a>.</p>
<blockquote>
<p>When a measure becomes a target, it ceases to be a good measure</p>
</blockquote>
<p>Tom DeMarco and Timothy Lister, the authors of Peopleware, recommend a novel way to maintain the usefulness of metrics--don’t let management see them:</p>
<blockquote>
<p>Work measurement can be a useful tool for method improvement, motivation, and enhanced job satisfaction, but it is almost never used for these purposes. Measurement schemes tend to become threatening and burdensome.</p>
<p>In order to make the concept deliver on its potential , management has to be perceptive and secure enough to cut itself out of the loop. That means the data on individuals is not passed up to management, and everybody in the organization knows it. Data collected on the individual’s performance has to be used only to benefit that individual. The measurement scheme is an exercise in self-assessment, and only the sanitized averages are made available to the boss.²</p>
</blockquote>
<h3>6. Are you careful that managers have enough direct&nbsp;reports?</h3>
<p>I don’t know what the ideal number of direct reports actually is, but I know it isn’t 2 or 3 or even 10. It is much bigger. “It is not uncommon for google managers to have 30 direct reports”³. Why does this matter? Because good managers don’t micromanage and they can’t if they have enough people to take care of. In a way, the number of direct reports assigned to a manager is an indicator of how an organization thinks about management in general.</p>
<h3>7. Do engineers choose what they work&nbsp;on?</h3>
<p>This one is rare but wonderful if you can find it. <a href="https://steamcdn-a.akamaihd.net/apps/valve/Valve_NewEmployeeHandbook.pdf" target="_blank" rel="noopener">Valve’s employee manual</a> famously tells new employees to go find a project they like because no one is going to pick it for them. Oh what a glorious world that would be. Hat tip to the enlightened companies that do this already — you are the future of management! If you find yourself at a place like this, hold it tight, and never let go.</p>
<h3>8. Do engineers own and manage their own deployments and infrastructure?</h3>
<p>This keeps your organization lean and scalable. Setting up a centralized infrastructure team is rarely a good idea because teams have such varied needs. The burden of keeping a shared infrastructure up all the time is not trivial. Additionally, dedicated devops teams tend to want to wrap essential deployment APIs in homemade access management tools, creating bottlenecks for engineers that are clamoring to use new aws services or kubernetes resources that haven’t been exposed yet. Trust your engineers to pick and learn the best tools for what they are trying to accomplish, and to safely and effectively utilize them. If you have up-time or security concerns, focus on training (books, conferences, courses) or consider an organizational model where you have a devops expert on each team that can teach and train the other developers. But don’t create a separate devops team.</p>
<h3>9. Can engineers choose their own tools for task management and coordination?</h3>
<p>Does your organization use something awful like Team Foundation Server or Jira (or any of a million other painful task trackers) to track and manage engineers? You are not alone. Man <em>YEARS</em> are wasted keeping these red tape generators running and up to date. It is simply not healthy to make engineers track and coordinate their work with a tool that they haven’t chosen themselves. If they want to use post-it notes or emacs org-mode, then let them. Questionably valuable reports that you get from big enterprise tools are not worth the loss in productivity and morale.</p>
<h3>10. Do engineers have full administrative control of their machines? Can they choose their computer model and operating system?</h3>
<p>This one is a no-brainer. Would you hire a mechanic but tell them they can’t use their own tool box? If you hire a Linux nerd that has spent a decade or more tuning their development configuration, it makes no sense to force them to use Windows or MacOS. It is equally counterproductive to make a Windows guru suffer through setting up a Unix based environment. Virtualization is almost always sufficient for providing ways to test and develop on alternative target environments. But peoples' host machines, their home base, should be what they are most comfortable with.</p>
<p>And when they get their machine, don’t lock it down so they can’t install what they need. If people are responsible enough to load software on their home computers, they are most certainly capable of managing the software on their work machine.</p>
<h3>Summary</h3>
<p>If you want a highly satisfying and productive culture, give these suggestions a try. And if you are interviewing, make sure that you know how your potential employers score on the Adam Test — let that help you make a decision of who to work for. You won’t regret it!</p>
<h3><strong>Sources</strong></h3>
<p>1,2. <em>Peopleware</em> by Tom DeMarco and Timothy Lister</p>
<p>3. <a href="https://hbr.org/2013/12/how-google-sold-its-engineers-on-management" target="_blank" rel="noopener">https://hbr.org/2013/12/how-google-sold-its-engineers-on-management</a></p>
    </div></div>]]>
            </description>
            <link>http://adamard.com/adam_test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400806</guid>
            <pubDate>Sat, 12 Dec 2020 19:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Source and Business: needs strict rules – here is my manifesto]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400716">thread link</a>) | @metaralf
<br/>
December 12, 2020 | https://www.deskfiler.org/oss-business.php | <a href="https://web.archive.org/web/*/https://www.deskfiler.org/oss-business.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<nav>
<p><span data-responsive-toggle="topbar-responsive" data-hide-for="medium">

</span>
<a href="https://www.deskfiler.org/" title="Cross Platform Applications" rel="home">
<img src="https://www.deskfiler.org/img/main/deskfilerlogowhite.png" alt="Cross Platform Applications">
</a>
</p>

</nav>

<section>
<div>
<h2>Open Source and Business - Our Manifesto</h2><p>
Feel free to copy this and modify as you see fit. It is totally a &nbsp;
<a href="https://en.wikipedia.org/wiki/Permissive_software_license" target="_blank">BSD-like</a>
statement for you to adapt for your own company, if you work with Open Source methods! This page has explicitly no copyright! Take it, copy it, improve it!
</p></div>
</section>

<section>
<div>
<div>
<p>
This declaration of values and viewpoints on Open Source Software
development and business requirements shall reflect our common
understanding as a team in a complex world of personal preferences
and common requirements to function increasingly healthy, happily and
pleasantly together.
</p>
<div><p>
Past separations of "Open Source" AGAINST "Business" or the split
of topics and cultures have caused turmoil between colleagues and
misunderstandings to a level, that we feel it is time to address.
</p><p>

Since the concepts of Open Source and Free Software were formalized in the
80s and 90s of the last century, they have been constantly confusing people
from other industries and from outside the software business.
</p><p>

Either the fear of "Why should someone pay for freely available software?"
or the expectation that someone will copy and steal the openly accessible
product have triggered misperception of the Open Source method and by that
caused ultimateley a basic "marketing problem" for many Open Source businesses.
</p></div>
<ol>
<li>
<b>What is Open Source to us?</b>
<div><p>
We think that Open Source can be a very attractive method to develop
excellent software products. We also think, that choosing this method
does not automatically make our (or any) product better.
</p><p>

Open Source for product development has to be carefully planned out,
sensitively managed by all developers and team members and finally be
constantly adjusted to the fast paced evolvement of development best
practices and technologies.
</p><p>

It also involves a <a href="https://en.wikipedia.org/wiki/Open-source_license" target="_blank">fundamental understanding of software licensing</a>
and avoiding the pitfalls of miscommunication in a very complex group of
people with very different backgrounds and interests.
</p><p>

Some developers just want to improve the world or are drawn into solving
complex problems for the fun of it. Some want fame. Some want to use
their code as "self marketing" to make more money.
</p><p>

We are OK with this. We will try to understand and help each other with
these goals and if we do not like them, we will try to find a compromise.
Actively.
</p></div>
</li>
<li>
<b>What does Open Source development mean for us?</b>
<div><p>
a) Our code and ideas are visible to the world. It has an exemplatory
and educational meaning as well as a "marketing meaning" for us as a group.
</p><p>

We have to be more meticulous and strict in our way of development than
in closed code environments, because others might copy us and bad code
or bad coding style might be copied by others and worsen certain technologies,
that should improve the daily life of thousands.
</p><p>

In those aspects: We are taking the hard way to develop a product by choice
and we are aware of it. We value the fact, that our product shall improve
the life of users - however small the improvement is on the scale of things.
</p></div>
<div><p>
b) As a development method above the daily processes (Agile, SCRUM, XP, etc.) it
is selected by us to support the users of the product. It inherently and
actively asks the users out there to give feedback and critize our product.
</p><p>

This has to be understood, valued and accepted by the whole company or
the concept of Open Source does not work in business.
</p><p>

Feedback and ideas of users also have to be managed and evaluated in a
structured process.
</p></div>
</li>
<li>
<b>What does <a href="https://en.wikipedia.org/wiki/Business_models_for_open-source_software" target="_blank">Open Source Business</a> mean to us?</b>
<div><p>
Simply put: "Business" means to make more money that we spend in an entity
we are calling "our company". In the modern software world, solid business growth
is achieved by selling licenses and services around the software product to
users, who need the software for specific problems and therefor are willing
to pay for it.
</p><p>

Accepting and dealing with this monetary aspect for a company and as a group
of people with very different goals, values and opinions is our core challenge.
</p><p>

By upholding and expanding the Open Source method in our product development
we have to carefully decide on each module, each hour of service and each
request from the outside of our company:
</p><p>

Is this part strengthening our core product and helping us to thrive as
a company or is it following the natural desire of other business entities
to earn more than they spend (on us)?
</p></div>
</li>
<li>
<b>Establishing momentum and growth</b>
<div><p>
Growth for us means primarily to reach more users with our work and to sustain
this growth with solid internal structures and methods. Financing this growth
with money is only (however important) means for this purpose.
</p><p>

We believe our products are and continously will be useful and crucial to many
users, companies and institutions. So, whenever users want or need our software
for business purposes, we believe, we can and should be rewarded for the
product and services around it. These rewards do not necessarily need to be money,
but in order to continue to produce better software, we will continue to put prices on
certain parts of our doing and production and come up with new commercial
aspects of our work under Open Source rules.
</p></div>
</li>
</ol>
</div>

</div>
</section>












</div>]]>
            </description>
            <link>https://www.deskfiler.org/oss-business.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400716</guid>
            <pubDate>Sat, 12 Dec 2020 19:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a picture frame with a greyscale e-paper that runs on battery for years]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25400702">thread link</a>) | @clash
<br/>
December 12, 2020 | https://framelabs.eu/en/ | <a href="https://web.archive.org/web/*/https://framelabs.eu/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="moove_gdpr_cookie_modal" role="complementary" aria-label="GDPR Settings Screen" data-no-translation-aria-label="">
  <div>
    <div>
      
<p><img src="https://framelabs.eu/wp-content/plugins/gdpr-cookie-compliance/dist/images/gdpr-logo.png" alt="Frame Labs">
</p>
<!--  .moove-gdpr-company-logo-holder -->      <ul id="moove-gdpr-menu">
        
<li>
  
</li>

  <li>
    
  </li>




      </ul>
      
<div>
  
		<p><a href="https://wordpress.org/plugins/gdpr-cookie-compliance" target="_blank" rel="noopener">Powered by&nbsp; <span data-no-translation="" data-trp-gettext="">GDPR Cookie Compliance</span></a>
		</p></div>
<!--  .moove-gdpr-branding -->    </div>
    <!--  .moove-gdpr-modal-left-content -->
    <div>
      
      <!-- .moove-gdpr-modal-ritle -->
      <div>

        <div>
          
<div id="privacy_overview">
      <p><span data-no-translation="" data-trp-gettext="">Privacy Overview</span></p><p data-no-translation="" data-trp-gettext="">This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful.</p>
  <!--  .moove-gdpr-tab-main-content -->

</div>
<!-- #privacy_overview -->          
  
  <!-- #strict-necesarry-cookies -->
          
          
          
        </div>
        <!--  .moove-gdpr-tab-content -->
      </div>
      <!--  .main-modal-content -->
      <div>
        
<!--  .moove-gdpr-button-holder -->      </div>
      <!--  .moove-gdpr-modal-footer-content -->
    </div>
    <!--  .moove-gdpr-modal-right-content -->

    

  </div>
  <!--  .moove-gdpr-modal-content -->
</div></div>]]>
            </description>
            <link>https://framelabs.eu/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400702</guid>
            <pubDate>Sat, 12 Dec 2020 19:19:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thread-Per-Core Buffer Management for a modern storage system]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25400350">thread link</a>) | @arjunnarayan
<br/>
December 12, 2020 | https://vectorized.io/blog/tpc-buffers/ | <a href="https://web.archive.org/web/*/https://vectorized.io/blog/tpc-buffers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p><a href="https://vectorized.io/blog/redpanda-raison-detre">As I have previously observed</a>, software does not run on category theory, it runs on superscalar CPUs with wide, multi-channel GB/s memory units and NVMe SSD access times in the order of 10-100’s of microseconds. The reason some software written a decade ago - on a different hardware platform - feels slow is because it fails to exploit the advances in modern hardware.</p>
<p>The new bottleneck in storage systems is the CPU. SSD devices are 100-1000x faster than spinning disks and are 10x cheaper today[1] than they were a decade ago, from $2,500 down to $200 per Terabyte. Networks have 100x higher throughput in public clouds from 1Gbps to 100Gbps.</p>
<p>Although computers did, in fact, get faster, single-core speeds remain roughly the same. The reason being that CPU frequency has a cubic dependency on power consumption, and we’ve hit a wall. Instruction level parallelism, prefetching, speculative execution, branch prediction, deep hierarchy of data caches and instruction caches, etc, have contributed to programs <em>feeling</em> faster when you interact with them, but in the datacenter, the material improvements have come from the rise in core count. While the instructions per clock are 3x higher than a decade ago, core count is up 20x.</p>
<p>This is all to say that the rise of readily available, many-core systems necessitates a different approach for building infrastructure. Case in point[9]: in order to take full advantage of 96 vCPUs on a i3en.metal on AWS, you’ll need to find a way to exploit sustained CPU clock speed of 3.1 GHz, 60 TB of total NVMe instance storage, 768 GiB of memory and NVMe devices capable of delivering up to 2 million random IOPS at 4 KB block sizes. This kind of beast necessitates a new kind of storage engine and threading model that leverages these hardware advances.</p>
<p><a href="https://vectorized.io/redpanda" target="_self" rel="nofollow">Redpanda</a> - a Kafka-API compatible system for mission critical workloads[3] - addresses all of these issues. It uses a thread-per-core architecture with Structured Message Passing (SMP) to communicate between these pinned threads. Threading is a foundational decision for any application, whether you are using a thread-pool, pinned threads with a network of Single Producer Single Consumer SPSC[7] queues, or any other of the advanced Safe Memory Reclamation (SMR) techniques, threading is your ring-0, the true kernel of your application. It tells you what your sensitivity is for blocking - which for Redpanda is less than 500 microseconds - otherwise, Seastar’s[4] reactor will print a stack trace warning you of the blocking since it effectively injects latency on the network poller.</p>
<p>Once you have decided on your threading model, the next step is your memory model and ultimately, for storage engines, your buffer management. In this post, we’ll cover the perils of buffer management in a thread-per-core environment and describe <code>iobuf</code>, our solution for a 0-copy memory management in the world of Seastar.</p>
<h2 id="Request-Flow-Architecture">Request Flow Architecture<a href="#Request-Flow-Architecture" aria-label="Request Flow Architecture permalink"></a></h2>
<p>As mentioned earlier, Redpanda uses a <em>single</em> pinned thread per core architecture to do everything. Network polling, submitting async IO to the kernel, reaping events, triggering timers, scheduling compute tasks, etc. Structurally, it means nothing can block for longer than 500 microseconds, or you’ll be introducing latency in other parts of your stack. This is an incredibly strict programming paradigm, but this opinionated idea forces a truly asynchronous system, whether you like it or not as the programmer.</p>
<p><img src="https://vectorized.io/31d1a730c507b605e6c1ebea60eb1e56/flow.svg" alt="Kafka request flow">
<small>
Figure 1: request flow architecture. Core-0 accepts the connection from the Kafka Java client and becomes the source core. After the request goes through the metadata cache(valid request) it filters through the partition router which decides to send the request to core-1, the destination core. Core-1 then accepts the write through the Raft-log interface and saves it to disk.
</small></p>
<p>The challenge in a TpC (thread-per-core) architecture[8] is that all communication between cores is explicit. This muscles the programmer into implementing algorithms that favor core-locality (d-cache, i-cache) over the straightforward multi-threaded implementations via mutexes. This imperative has to be co-designed with the asynchronicity of a <strong>future&lt;&gt;</strong>-based implementation.</p>
<p>For our Kafka-API implementation as shown in Figure 1, we explicitly trade memory usage to reduce latency and increase throughput by materializing key components. The metadata Cache is materialized on every core since every request has to know if the partition exists, and that that particular machine is, in fact, the leader of the partition. The Partition Router maintains a map of which logical core actually owns the underlying Kafka partition on the machine. Other things like Access Control Lists (ACLs) are deferred until the request reaches the destination core since they can get unwieldy in memory footprint.  We have no hard and fast rule of what we materialize on every core vs. what is deferred for the destination core, and it’s often a function of memory (smaller data structures are good candidates for broadcast), computation (how much time is spent deciding) and frequency of access (very likely operations tend to get materialized on every core).</p>
<p>One question remaining is how, exactly, does memory management work in a TpC architecture? How does data actually travel from L-core-0 to L-core-66 safely using a network of SPSC queues within a fully asynchronous execution model where things can suspend at any point in time?</p>
<h2 id="struct-iobuf--">struct iobuf { };<a href="#struct-iobuf--" aria-label="struct iobuf   permalink"></a></h2>
<h3 id="Redpandas-0-copy-buffer-management-for-TpC">Redpanda’s 0-copy buffer management for TpC<a href="#Redpandas-0-copy-buffer-management-for-TpC" aria-label="Redpandas 0 copy buffer management for TpC permalink"></a></h3>
<p>To understand <strong>iobuf</strong>, we need to understand the actual memory constraints of Seastar, our TpC framework. During program bootstrap, Seastar allocates the full memory of the computer and splits it evenly across all the cores. It consults the hardware to understand what memory belongs to each particular core, reducing inter-core traffic to main memory.</p>
<p><img src="https://vectorized.io/efa273909c5b695bf7f978f77b32c12b/seastar_model.svg" alt="Seastar mental model">
<small>
Figure 2: Copy from alexgallego.org (<a href="https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html" target="_self" rel="nofollow">https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html</a>) Seastar threading model. Seastar uses a network of SPS queues to send messages to neighboring cores. Similar to other message passing or actor models like Erlang, Orleans and Pony, once a function is futurized, transitive functions too will become futurized. Both approaches, however, are intrinsically safe. The programmer worries about correctness and construction while the frameworks worry about efficient execution. Counter to general wisdom, it is actually faster and more scalable than the synchronous approach. While the machine does more work, it is executing your code simultaneously. This simultaneity is the key to finishing work sooner.
</small></p>
<p>As Figure 2 suggests, memory allocated on core-0, <em>must</em> be deallocated on core-0. However, there is no way to guarantee that a Java or Go client connecting to Redpanda will actually communicate with the exact core that owns the data.</p>
<p>At its core, an iobuf is a ref-counted, fragmented-buffer-chain with deferred deletes that allows Redpanda to simply share a view of a remote core’s parsed messages as the fragments come in, without incurring a copy overhead.</p>
<p><img src="https://vectorized.io/6df6fc00e05201d068dc5d03e080606a/iobuf.svg" alt="iobuf architecture"></p>
<p>The fragmented buffers abstraction is not new. The linux kernel has <strong>sk_buff</strong>[5] and the freebsd kernel has an <strong>mbuf</strong>[6] which are roughly similar. The additional extension of an iobuf is that it works in the TCP model leveraging Seastar’s network of SPSC queues to have proper deletes in addition to being able to share sub-views arbitrarily, tailored for a storage-like workload.</p>
<p>Removing the C++ templates, allocators, pooling, pointer caching, etc, one could think of an iobuf as being equivalent to:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>fragment</span> <span>{</span>
    <span>void</span> <span>*</span> data<span>;</span>
    size_t ref_count<span>;</span>
    size_t capacity<span>;</span>
    size_t size<span>;</span>

    fragment<span>*</span> next<span>;</span>  
    fragment<span>*</span> prev<span>;</span>
<span>}</span>
<span>struct</span> <span>iobuf</span> <span>{</span>
    fragment<span>*</span> head<span>;</span>
<span>}</span><span>;</span></code></pre></div>
<p>The origins of iobuf are rooted in one of our central product tenets for building a Kafka® replacement for mission critical systems - giving users 10x lower tail latencies for most workloads. Aside from a thread-per-core architecture, the memory management would have been our second bottleneck if not designed from the ground up for latency. On long running storage systems, memory fragmentation is a real problem, and one that is eventually either met with a proper solution (iobuf), stalls or an OOM.</p>
<p>Like its predecessors skbuff and mbuff, iobuf allows us to optimize and train our memory allocator with predictable memory sizes. Here is our iobuf allocation table logic:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>io_allocation_size</span> <span>{</span>
   <span>static</span> <span>constexpr</span> size_t max_chunk_size <span>=</span> <span>128</span> <span>*</span> <span>1024</span><span>;</span>
   <span>static</span> <span>constexpr</span> size_t default_chunk_size <span>=</span> <span>512</span><span>;</span>

   
   
   
   
   
   
   <span>static</span> <span>constexpr</span> std<span>::</span>array<span>&lt;</span><span>uint32_t</span><span>,</span> <span>15</span><span>&gt;</span> alloc_table <span>=</span>
     
     <span>{</span><span>{</span><span>512</span><span>,</span>
       <span>768</span><span>,</span>
       <span>1152</span><span>,</span>
       <span>1728</span><span>,</span>
       <span>2592</span><span>,</span>
       <span>3888</span><span>,</span>
       <span>5832</span><span>,</span>
       <span>8748</span><span>,</span>
       <span>13122</span><span>,</span>
       <span>19683</span><span>,</span>
       <span>29525</span><span>,</span>
       <span>44288</span><span>,</span>
       <span>66432</span><span>,</span>
       <span>99648</span><span>,</span>
       <span>131072</span><span>}</span><span>}</span><span>;</span>

   <span>static</span> size_t <span>next_allocation_size</span><span>(</span>size_t data_size<span>)</span><span>;</span>
<span>}</span><span>;</span>   </code></pre></div>
<p>Predictability, memory pooling, fixed sizes, size capping, fragmented traversal, etc, are all known techniques to reduce latency. Asking for contiguous and variably sized memory could cause the allocator to compact all of the arenas and reshuffle a lot of bytes for what could be a short-lived request, not only injecting latency on the request path, but for the entire system since we have exactly one thread performing all operations.</p>
<p>Hardware is the platform. When we ask the network layer to give us exactly 11225 bytes in contiguous memory, we are simply asking the allocator to linearize an empty buffer of that exact size and for the network layer to copy bytes as the fragments come from the hardware into the destination buffer. There is ultimately no free lunch when it comes to trying to squeeze every single ounce of performance of your hardware and often it requires re-architecting from zero.</p>
<p>If you made it this far, I encourage you to sign up for our <a href="https://vectorized.io/slack" target="_self" rel="nofollow">Community Slack (here!)</a> and ask us questions directly or engage with us on twitter via <a href="https://twitter.com/vectorizedio" target="_self" rel="nofollow">@vectorize…</a></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/blog/tpc-buffers/">https://vectorized.io/blog/tpc-buffers/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/blog/tpc-buffers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400350</guid>
            <pubDate>Sat, 12 Dec 2020 18:34:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero to Production in Rust, Part Six: Using Types to Guarantee Domain Invariants]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400332">thread link</a>) | @praveenperera
<br/>
December 12, 2020 | https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <article>
    
      
      
<ul id="frontmatter">
    <li>
        <time datetime="2020-12-11T15:00:10.47Z">December 11, 2020</time>
    </li>
    <span></span>
    <li> 6507 words </li>
    <span></span>
    <li> 33 min </li>
</ul>

      <p><em><a href="https://zero2prod.com/"><strong>Zero To Production In Rust</strong></a> is an opinionated introduction to backend development in Rust.<br>
You can pre-order the book on <a href="https://zero2prod.com/">zero2prod.com</a>.<br>
<a href="https://www.lpalmieri.com/subscribe">Subscribe to the newsletter</a> to be notified when a new episode is published.</em></p>

<ol>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#1-requirements">Requirements</a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#11-domain-constraints">1.1. Domain Constraints</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#12-security-constraints">1.2. Security Constraints</a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#2-first-implementation">First Implementation</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#3-validation-is-a-leaky-cauldron">Validation Is A Leaky Cauldron</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#4-type-driven-development">Type-Driven Development</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#5-ownership-meets-invariants">Ownership Meets Invariants</a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#51-asref">5.1. <code>AsRef</code></a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#6-panics">Panics</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#7-error-as-values---result">Error As Values - <code>Result</code></a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#71-converting-parse-to-return-result">7.1. Converting <code>parse</code> To Return <code>Result</code></a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#8-insightful-assertion-errors-claim">Insightful Assertion Errors: <code>claim</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#9-unit-tests">Unit Tests</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#10-handling-a-result">Handling A <code>Result</code></a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#101-map_err">10.1. <code>map_err</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#102-the--operator">10.2. The <code>?</code> Operator</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#103-400-bad-request">10.3. 400 Bad Request</a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#11-summary">Summary</a></li>
</ol>
<p>Our newsletter API is live, hosted on a Cloud provider.<br>
We have a basic set of instrumentation to troubleshoot issues that might arise.<br>
There is an exposed endpoint (<code>POST /subscriptions</code>) to subscribe to our content.</p>
<p>We have come a long way!</p>
<p>But we have cut a few corners along the way: <code>POST /subscriptions</code> is fairly... permissive.<br>
Our input validation is extremely limited: we just ensure that both the name and the email fields are provided, nothing else.</p>
<p>We can add a new integration test to probe our API with some "troublesome" inputs:</p>
<pre><code><span>//! tests/health_check.rs
// [...]

</span><span>#[</span><span>actix_rt</span><span>::</span><span>test</span><span>]
async </span><span>fn </span><span>subscribe_returns_a_200_when_fields_are_present_but_empty</span><span>() {
    </span><span>// Arrange
    </span><span>let</span><span> app = </span><span>spawn_app</span><span>().await;
    </span><span>let</span><span> client = reqwest::Client::new();
    </span><span>let</span><span> test_cases = vec![
        ("</span><span>name=&amp;email=ursula_le_guin%40gmail.com</span><span>", "</span><span>empty name</span><span>"),
        ("</span><span>name=Ursula&amp;email=</span><span>", "</span><span>empty email</span><span>"),
        ("</span><span>name=Ursula&amp;email=definitely-not-an-email</span><span>", "</span><span>invalid email</span><span>"),
    ];

    </span><span>for </span><span>(body, description) in test_cases {
        </span><span>// Act
        </span><span>let</span><span> response = client
            .</span><span>post</span><span>(&amp;format!("</span><span>{}</span><span>/subscriptions</span><span>", &amp;app.address))
            .</span><span>header</span><span>("</span><span>Content-Type</span><span>", "</span><span>application/x-www-form-urlencoded</span><span>")
            .</span><span>body</span><span>(body)
            .</span><span>send</span><span>()
            .await
            .</span><span>expect</span><span>("</span><span>Failed to execute request.</span><span>");

        </span><span>// Assert
        </span><span>assert_eq!(
            </span><span>200</span><span>,
            response.</span><span>status</span><span>().</span><span>as_u16</span><span>(),
            "</span><span>The API did not return a 200 OK when the payload was {}.</span><span>",
            description 
        );
    }
}
</span></code></pre>
<p>The new test, unfortunately, passes.<br>
Although all those payloads are clearly invalid, our API is gladly accepting them, returning a <code>200 OK</code>.<br>
Those troublesome subscriber details end up straight in our database, ready to give us problems down the line when it is time to deliver a newsletter issue.</p>
<p>We are asking for two pieces of information when subscribing to our newsletter: a name and an email.<br>
This chapter will focus on name validation: what should we look out for?</p>
<blockquote>
<p><em>Discuss the article on HackerNews or <a href="https://www.reddit.com/r/rust/comments/kbddrq/zero_to_production_in_rust_part_six_using_types/">r/rust</a></em>.</p>
</blockquote>

<h2 id="1-1-domain-constraints">1.1. Domain Constraints</h2>
<p>It turns out that names are complicated<sup><a href="#patio-names">1</a></sup>.<br>
Trying to nail down what makes a name <em>valid</em> is a fool's errand. Remember that we chose to collect a name to use it in the opening line of our emails - we do not need it to match the real identity of a person, whatever that means in their geography. It would be totally unnecessary to inflict the pain of incorrect or overly prescriptive validation on our users.</p>
<p>We could thus settle on simply requiring the name field to be non-empty (as in, it must contain at least a non-whitespace character).</p>
<h2 id="1-2-security-constraints">1.2. Security Constraints</h2>
<p>Unfortunately, not all people on the Internet are good people.<br>
Given enough time, especially if our newsletter picks up traction and becomes successful, we are bound to capture the attention of malicious visitors.<br>
Forms and user inputs are a primary attack target - if they are not properly sanitised, they might allow an attacker to mess with our database (<a href="https://en.wikipedia.org/wiki/SQL_injection">SQL injection</a>), execute code on our servers, crash our service and other nasty stuff.<br>
Thanks, but no thanks.</p>
<p>What is likely to happen in our case? What should we brace for in the wild range of possible attacks?<sup><a href="#threat-modelling">2</a></sup><br>
We are building an email newsletter, which leads us to focus on:</p>
<ul>
<li>denial of service - e.g. trying to take our service down to prevent other people from signing up. A common threat for basically any online service;</li>
<li>data theft - e.g. steal a huge list of email addresses;</li>
<li>phishing - e.g. use our service to send what looks like a legitimate email to a victim to trick them into clicking on some links or perform other actions.</li>
</ul>
<p>Should we try to tackle all these threats in our validation logic?<br>
Absolutely not!<br>
But it is good practice to have a layered security approach<sup><a href="#defense-in-depth">3</a></sup>: by having mitigations to reduce the risk for those threats at multiple levels in our stack (e.g. input validation, parametrised queries to avoid SQL injection, escaping parametrised input in emails, etc.) we are less likely to be vulnerable should any of those checks fail us or be removed later down the line.</p>
<p>We should always keep in mind that software is a living artifact: holistic understanding of a system is the first victim of the passage of time.<br>
You have the whole system in your head when writing it down for the first time, but the next developer touching it will not - at least not from the get-go. It is therefore possible for a load-bearing check in an obscure corner of the application to disappear (e.g. HTML escaping) leaving you exposed to a class of attacks (e.g. phishing).<br>
Redundancy reduces risk.</p>
<p>Let's get to the point - what validation should we perform on names to improve our security posture given the class of threats we identified?<br>
I suggest:</p>
<ul>
<li>Enforcing a maximum length. We are using <code>TEXT</code> as type for our email in Postgres, which is virtually unbounded - well, until disk storage starts to run out. Names come in all shapes and forms, but 256 characters should be enough for the greatest majority of our users<sup><a href="#longest-name">4</a></sup> - if not, we will politely ask them to enter a nickname.</li>
<li>Reject names containing troublesome characters. <code>/()"&lt;&gt;\{}</code> are fairly common in URLs, SQL queries and HTML fragments - not as much in names<sup><a href="#xkcd">5</a></sup>. Forbidding them raises the complexity bar for SQL injection and phishing attempts.</li>
</ul>

<p>Let's have a look at our request handler, as it stands right now:</p>
<pre><code><span>//! src/routes/subscriptions.rs
</span><span>use </span><span>actix_web::{web, HttpResponse};
</span><span>use </span><span>chrono::Utc;
</span><span>use </span><span>sqlx::PgPool;
</span><span>use </span><span>uuid::Uuid;

#[</span><span>derive</span><span>(serde::Deserialize)]
</span><span>pub struct </span><span>FormData {
    </span><span>email</span><span>: String,
    </span><span>name</span><span>: String,
}

#[</span><span>tracing</span><span>::</span><span>instrument</span><span>(
    name = "</span><span>Adding a new subscriber</span><span>",
    </span><span>skip</span><span>(form, pool),
    </span><span>fields</span><span>(
        email = %form.email,
        name = %form.name
    )
)]
</span><span>pub</span><span> async </span><span>fn </span><span>subscribe</span><span>(
    </span><span>form</span><span>: web::Form&lt;FormData&gt;,
    </span><span>pool</span><span>: web::Data&lt;PgPool&gt;,
) -&gt; Result&lt;HttpResponse, HttpResponse&gt; {
    </span><span>insert_subscriber</span><span>(&amp;pool, &amp;form)
        .await
        .</span><span>map_err</span><span>(|_| HttpResponse::InternalServerError().</span><span>finish</span><span>())?;
    Ok(HttpResponse::Ok().</span><span>finish</span><span>())
}

</span><span>// [...]
</span></code></pre>
<p>Where should our new validation live?</p>
<p>A first sketch could look somewhat like this:</p>
<pre><code><span>//! src/routes/subscriptions.rs
 
// An extension trait to provide the `graphemes` method 
// on`String` and `&amp;str`
</span><span>use </span><span>unicode_segmentation::UnicodeSegmentation;
</span><span>// [...]

</span><span>pub</span><span> async </span><span>fn </span><span>subscribe</span><span>(
    </span><span>form</span><span>: web::Form&lt;FormData&gt;,
    </span><span>pool</span><span>: web::Data&lt;PgPool&gt;,
) -&gt; Result&lt;HttpResponse, HttpResponse&gt; {
    </span><span>if </span><span>!</span><span>is_valid_name</span><span>(&amp;form.name) {
        </span><span>return </span><span>Err(HttpResponse::BadRequestError().</span><span>finish</span><span>());
    }
    </span><span>insert_subscriber</span><span>(&amp;pool, &amp;form)
        .await
        .</span><span>map_err</span><span>(|_| HttpResponse::InternalServerError().</span><span>finish</span><span>())?;
    Ok(HttpResponse::Ok().</span><span>finish</span><span>())
}

</span><span>/// Returns `true` if the input satisfies all our validation constraints 
/// on subscriber names, `false` otherwise.
</span><span>pub fn </span><span>is_valid_name</span><span>(</span><span>s</span><span>: &amp;</span><span>str</span><span>) -&gt; </span><span>bool </span><span>{
    </span><span>// `.trim()` returns a view over the input `s` without trailing 
    // whitespace-like characters.
    // `.is_empty` checks if the view contains any character.
    </span><span>let</span><span> is_empty_or_whitespace = s.</span><span>trim</span><span>().</span><span>is_empty</span><span>();

    </span><span>// A grapheme is defined by the Unicode standard as a "user-perceived" 
    // character: `å` is a single grapheme, but it is composed of two characters 
    // (`a` and `̊`).
    //
    // `graphemes` returns an iterator over the graphemes in the input `s`.
    // `true` specifies that we want to use the extended grapheme definition set,
    // the recommended one.
    </span><span>let</span><span> is_too_long = s.</span><span>graphemes</span><span>(</span><span>true</span><span>).</span><span>count</span><span>() &gt; </span><span>256</span><span>;

    </span><span>// Iterate over all characters in the input `s` to check if any of them matches 
    // one of the characters in the forbidden array.
    </span><span>let</span><span> forbidden_characters = ['</span><span>/</span><span>', '</span><span>(</span><span>', '</span><span>)</span><span>', '</span><span>"</span><span>', '</span><span>&lt;</span><span>', '</span><span>&gt;</span><span>', '</span><span>\\</span><span>', '</span><span>{</span><span>', '</span><span>}</span><span>'];
    </span><span>let</span><span> contains_forbidden_characters = s
        .</span><span>chars</span><span>()
        .</span><span>filter</span><span>(|</span><span>g</span><span>| forbidden_characters.</span><span>contains</span><span>(g))
        .</span><span>count</span><span>()
        &gt; </span><span>0</span><span>;

    </span><span>// Return `false` if any of our conditions has been violated 
    </span><span>!(is_empty_or_whitespace || is_too_long || contains_forbidden_characters)
}
</span></code></pre>
<p>To compile the new function successfully we will have to add the <code>unicode-segmentation</code> crate to our dependencies:</p>
<pre><code><span>cargo</span><span> add unicode-segmentation
</span></code></pre>
<p>While it <em>looks like</em> a perfectly fine solution (assuming we add a bunch of tests), functions like <code>is_valid_name</code> give us a false sense of safety.</p>

<p>Let's shift our attention to <code>insert_subscriber</code>.<br>
Let's imagine, for a second, that it requires <code>form.name</code> to be non-empty otherwise something horrible is going to happen (e.g. a panic!).</p>
<p>Can <code>insert_subscriber</code> safely assume that <code>form.name</code> will be non-empty?<br>
Just by looking at its <em>type</em>, it cannot: <code>form.name</code> is a <code>String</code>. There is no guarantee about its content.<br>
If you were to look at our program in its entirety you might say: we are checking that it is non-empty at the edge, in the request handler, therefore we can safely assume that <code>form.name</code> will be non-empty every time <code>insert_subscriber</code> is invoked.</p>
<p>But we had to shift from a <em>local</em> approach (let's look at this function's parameters) to a <em>global</em> approach (let's scan the whole codebase) to make such a claim.<br>
And while it might be feasible for a small project such as ours, examining all the calling sites of a function (<code>insert_subscriber</code>) to ensure that a certain validation step has been performed beforehand quickly becomes unfeasible on larger projects.</p>
<p>If we are to stick with <code>is_valid_name</code>, the only …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/">https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400332</guid>
            <pubDate>Sat, 12 Dec 2020 18:30:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Hat Goes Full IBM and Says Farewell to CentOS]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 292 (<a href="https://news.ycombinator.com/item?id=25400249">thread link</a>) | @vanburen
<br/>
December 12, 2020 | https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg" data-caption="Red Hat Distro Family Progression 2020-2025"><img width="696" height="391" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-400x224.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-800x449.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1536x862.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-2048x1149.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1068x599.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-749x420.jpg 749w" sizes="(max-width: 696px) 100vw, 696px" alt="Red Hat Distro Family Progression 2020-2025" title="Red Hat Distro Family Progression 2020-2025"></a><figcaption>Red Hat Distro Family Progression 2020-2025</figcaption></figure></div>
            <!-- content --><p>This week, Red Hat caught a lot of the Linux community off-guard by what was a shocking announcement for many: CentOS 8 as we know it, will see a reduced lifecycle, ending in December 2021. Further, while the project will still support CentOS 7, CentOS, as the community has known it, is effectively a dead project at this point. This is fairly consistent with how <a href="https://www.servethehome.com/ibm-gobbles-up-red-hat/">IBM</a> is known to do some acquisitions, but it is still shocking.<span id="more-49249"></span></p>
<h2>The Video Version</h2>
<p>Since we have been doing more content with video lately, we are also including a version of this as a video for you to listen to.</p>
<p><iframe title="Red Hat Says Sayonara to CentOS" width="696" height="392" src="https://www.youtube.com/embed/qqc3k5Ym1tA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Of course, we know most of the folks on here prefer to read, but this video is a fairly close representation of what is in the article. Feel free to open it on YouTube and check it out there.</p>
<h2>CentOS Project Key History</h2>
<p>While some will like to go back to the founding of CentOS, we instead wanted to focus on what CentOS had effectively become over the last 5-10 years: a Red Hat Enterprise Linux (RHEL) alternative without the support contract.</p>
<figure id="attachment_49262" aria-describedby="caption-attachment-49262"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2020/" rel="attachment wp-att-49262"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-scaled.jpg" alt="Red Hat 2020" width="2560" height="1439" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-2048x1151.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-1068x600.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-747x420.jpg 747w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49262">Red Hat Distro Family Progression 2020</figcaption></figure>
<p>Even if you run on Debian derivatives, you are aware of how mature the RHEL ecosystem is. It is a testament to Red Hat being the top open-source company in the world. CentOS releases generally lagged the RHEL releases by a few months, but effectively were clones of RHEL for those that did not have the budget for RHEL. Some can say CentOS was something different, but if we are being fair, a huge portion of the usage was effectively to access key parts of the RHEL ecosystem while not paying a subscription fee.</p>
<p>In 2014, Red Hat saw the potential and the benefits to its ecosystem and brought the CentOS team in-house. There is a team inside Red Hat developing CentOS with salaries and badges. The rationale from what I have been told is that it was better to have applications built on CentOS then brought up to RHEL as they matured rather than putting more development effort into the Ubuntu/ Debian ecosystem. That is both simplistic, but also makes a lot of sense. As part of this arrangement, Red Hat effectively got control of the CentOS governing body. That makes a lot of sense since Red Hat would be paying for developers, but it also made a few folks think about what could happen with CentOS not being independent.</p>
<figure id="attachment_49263" aria-describedby="caption-attachment-49263"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-acquisition-passage/" rel="attachment wp-att-49263"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage.jpg" alt="Red Hat Acquisition Passage" width="1714" height="1602" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage.jpg 1714w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-321x300.jpg 321w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-800x748.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-1536x1436.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-696x651.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-1068x998.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-449x420.jpg 449w" sizes="(max-width: 1714px) 100vw, 1714px"></a><figcaption id="caption-attachment-49263">Red Hat Absorbs CentOS Press Release</figcaption></figure>
<p>Taking a step back to 2014, anyone building applications saw Red Hat’s signal that it was committing resources to CentOS and frankly felt fairly good about platforming on CentOS. We almost switched back our hosting infrastructure to CentOS because of that, but there was a not-insignificant risk that we would get forced into a subscription at some point.</p>
<p>Between that acquisition, and 2020, we had a period where loosely CentOS would follow RHEL releases, supported by official Red Hat resources, by a few months. It took some time to extract bits of IP in RHEL and other changes, but for years, this was the operating model.</p>
<figure id="attachment_49269" aria-describedby="caption-attachment-49269"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-centos-eol-summary/" rel="attachment wp-att-49269"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary.jpg" alt="Red Hat CentOS EOL Summary" width="1118" height="188" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary.jpg 1118w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-400x67.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-800x135.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-696x117.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-1068x180.jpg 1068w" sizes="(max-width: 1118px) 100vw, 1118px"></a><figcaption id="caption-attachment-49269">Red Hat CentOS EOL Summary</figcaption></figure>
<p>Another key factoid is that the end of support for CentOS 6 was in November 2020. Since RHEL and CentOS are known for long support cycles, a lot of organizations decided to jump from CentOS 6 to 8 instead of re-platforming on 7 since that maximizes the time until another re-platforming effort would need to be scheduled. Or that is what many in the industry thought.</p>
<figure id="attachment_49267" aria-describedby="caption-attachment-49267"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2022/" rel="attachment wp-att-49267"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-scaled.jpg" alt="Red Hat 2022" width="2560" height="1444" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-400x226.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-800x451.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-1536x866.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-2048x1155.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-1068x602.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-745x420.jpg 745w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49267">Red Hat Distro Family Progression 2022</figcaption></figure>
<p>Then, on December 8, 2020, Red Hat announced that it was going to cut the current CentOS 8 support timeframe down considerably in the process of effectively killing the project. While 2021 may not be impacted, with CentOS 6 EOL on November 30, 2020, and CentOS 8 EOL on December 31, 2021, by January 1, 2022 CentOS 7 will be the only one receiving Maintenance Updates. The CentOS name will live on but in a different part of the ecosystem than it has to date.</p>
<h2>CentOS Stream and the New Red Hat Operating Model</h2>
<p>CentOS Stream is a project that sits between the upstream Fedora Linux and RHEL. While CentOS 8 is being shut down, and we do not expect a CentOS 9 unless there is a major change in direction at Red Hat, the CentOS name will live on for now in the CentOS Stream after CentOS 7 eventually goes EOL on June 30, 2024. By the second half of 2024, and by 2025 we expect this is what the diagram will look like.</p>
<figure id="attachment_49268" aria-describedby="caption-attachment-49268"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2025/" rel="attachment wp-att-49268"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-scaled.jpg" alt="Red Hat 2025" width="2560" height="1449" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-400x226.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-800x453.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-1536x870.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-2048x1159.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-696x394.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-1068x605.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-742x420.jpg 742w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49268">Red Hat Distro Family Progression 2025</figcaption></figure>
<p>For those who are current CentOS users, this means that what will be known as CentOS is being moved upstream of RHEL instead of downstream. Many of the current CentOS users like the fact that it is broadly tied to the RHEL ecosystem, and by moving it upstream it becomes a different value proposition.</p>
<figure id="attachment_49272" aria-describedby="caption-attachment-49272"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-summary/" rel="attachment wp-att-49272"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg" alt="Red Hat Summary" width="2560" height="1436" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-400x224.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-800x449.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1536x862.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-2048x1149.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1068x599.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-749x420.jpg 749w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49272">Red Hat Distro Family Progression 2020-2025</figcaption></figure>
<p>As much as I have an affinity for the CentOS brand, I do not like “CentOS Stream” being used, especially without CentOS being discontinued as a downstream distribution from RHEL. It made some sense for both to be active, but CentOS Stream may as well be called “BigBlue Hat Enterprise Linux Stream” or something like that. Fedora is not RHEL Stream for a reason. In the future Fedora, CentOS Stream, then RHEL will make sense from a branding perspective, except that CentOS is so widely used that it has a history, a history that will be chronicled for decades in Q&amp;A sites, how-tos, and other user support artifacts from the CentOS (non-stream) era.</p>
<h2>What Red Hat Needs to Do, ASAP</h2>
<p>As part of the announcement, RHEL has hinted that it would be doing something with its RHEL licensing to help the CentOS community, and there is a step it could take to turn this into an amazing gambit for Red Hat: opening a non-subscription level to RHEL beyond the current developer license.</p>
<p>“There are different kinds of CentOS users, and we are working with the CentOS Project Governing Board to tailor programs that meet the needs of these different user groups. In the first half of 2021, we plan to introduce low- or no-cost programs for a variety of use cases, including options for open source projects and communities and expansion of the Red Hat Enterprise Linux Developer subscription use cases to better serve the needs of systems administrators. We’ll share more details as these initiatives coalesce.“ (<strong>Source</strong>: <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux">Red Hat</a>)</p>
<p>This is the sort of move that could yield huge dividends for Red Hat. If the migration path was from CentOS 8 to a carefully crafted “RHEL-freemium” distribution, which is how many viewed CentOS at a high-level anyway, then it has the ability to greatly increase Red Hat’s installed base in its main RHEL distribution. There are huge ramifications for this from an IP, licensing, and even just a business perspective, but it would be an amazing move. At the same time, it is a move that if Red Hat wanted to do, it should have been announced along with the CentOS retirement to quell the confusion. Effectively, Red Hat would be doing what iXsystems did to migrate FreeNAS to TrueNAS Core just on a much grander scale.</p>
<p>Red Hat desperately needs to have a good path forward. Perhaps none are perfect, but asking CentOS users to upgrade to CentOS Stream, pay for a RHEL license, or leave the ecosystem seems like a highly imperfect set of options.</p>
<h2>Final Words</h2>
<p>The intellectually easy answer to what is happening is that IBM is putting pressure on Red Hat to hit bigger numbers in the future. Red Hat sees a captive audience in its CentOS userbase and is looking to covert a percentage to paying customers. Everyone else can go to Ubuntu or elsewhere if they do not want to pay. That seems a bit shortsighted of an explanation we have heard offered.</p>
<figure id="attachment_30704" aria-describedby="caption-attachment-30704"><a href="https://www.servethehome.com/ibm-gobbles-up-red-hat/ibm-and-red-hat-merger/" rel="attachment wp-att-30704"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger.jpg" alt="IBM And Red Hat Merger" width="1039" height="572" srcset="https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger.jpg 1039w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-400x220.jpg 400w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-800x440.jpg 800w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-696x383.jpg 696w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-763x420.jpg 763w" sizes="(max-width: 1039px) 100vw, 1039px"></a><figcaption id="caption-attachment-30704">IBM And Red Hat Merger</figcaption></figure>
<p>The strange part of the Red Hat announcement was that it sets a precedent that is not great. Both Red Hat, and IBM its parent, are very large, sophisticated companies. There is little chance they did not foresee community outcry over an abrupt change of direction like this. Sometimes, those changes have to be made, and in the technology industry change should be the status quo. At the same time, seeing a large, established company making this kind of abrupt change, that has a major operating impact on a large user base, without a clear path forward, is a scary precedent. RHEL customers are taking notice asking if this is what they can expect from the company moving forward.</p>
<p>There are basically two paths forward here. One is that Red Hat becomes the Apple (or IBM?) of the Linux ecosystem, becoming a high-priced exclusive vendor with great technology. The second is that Red Hat unveils a roadmap that does not leave the CentOS community peering over the edge of an end-of-support cliff.</p>
<p>As always, we would love to hear STH community’s thoughts on the announcement. There is a thread in our <a href="https://forums.servethehome.com/index.php?threads/centos-8-to-be-discontinued-at-end-of-2021.31052/">forums here</a>.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400249</guid>
            <pubDate>Sat, 12 Dec 2020 18:19:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Dark Mode is too Dark]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 184 (<a href="https://news.ycombinator.com/item?id=25400139">thread link</a>) | @karenying7
<br/>
December 12, 2020 | https://blog.karenying.com/posts/github-darkmode-sucks | <a href="https://web.archive.org/web/*/https://blog.karenying.com/posts/github-darkmode-sucks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>If you hate it too this is why. Using color theory to show why GitHub dark mode is disappointing</p><div><p><span>
      <a href="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6389a/github-darkmode-sucks.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/8ac56/github-darkmode-sucks.webp 240w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/d3be9/github-darkmode-sucks.webp 480w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/e46b2/github-darkmode-sucks.webp 960w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/30504/github-darkmode-sucks.webp 1325w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/09b79/github-darkmode-sucks.jpg 240w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/7cc5e/github-darkmode-sucks.jpg 480w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6a068/github-darkmode-sucks.jpg 960w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6389a/github-darkmode-sucks.jpg 1325w" sizes="(max-width: 960px) 100vw, 960px" type="image/jpeg">
        <img src="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6a068/github-darkmode-sucks.jpg" alt="toggle" title="toggle" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>This past week, GitHub <a href="https://twitter.com/github/status/1336362679506784256" target="_blank">released</a> a long-awaited feature — dark mode. Like many devs around the world, I was hype. In 2020, a dark mode toggle for anything remotely related to tech seems like a requirement.</p>
<p>So I flipped the switch. My immediate reaction was that it seemed a bit off. But I wanted to give it a chance and credited that feeling towards just not being used to the theme yet.</p>
<p>Flash forward a couple of days, I found myself switching to light mode for code review specifically. I didn’t feel confident code reviewing in dark mode. I was scared I would miss something. It was after a couple of instances of this did I realize, GitHub dark mode is <em>too</em> dark. And here’s why.</p>
<h2 id="the-proof-is-in-the-palette-pudding"><a href="#the-proof-is-in-the-palette-pudding" aria-label="the proof is in the palette pudding permalink"></a>The Proof is in the Palette (Pudding)</h2>
<h3 id="accessibility-and-contrast-ratio"><a href="#accessibility-and-contrast-ratio" aria-label="accessibility and contrast ratio permalink"></a>Accessibility and Contrast Ratio</h3>
<p>I explain contrast ratio in depth <a href="https://blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color#wcag-and-contrast-ratio" target="_blank">here</a> but this is what you need to know:</p>
<ul>
<li>The contrast ratio between two colors mathematically calculates how different our eyes perceive them to be</li>
<li>It ranges between <strong>1</strong> (two of the same colors) to <strong>21</strong> (black and white)</li>
<li>The smaller the text is, the larger the contrast ratio between the text color and the background color needs to be</li>
<li>The <a href="https://www.w3.org/WAI/standards-guidelines/wcag/" target="_blank">Web Content Accessibility Guidelines</a> (WCAG) defines a level <strong>AA</strong> contrast ratio as above <strong>4.5</strong> and level <strong>AAA</strong> as above <strong>7</strong> for small text</li>
<li><strong>AAA</strong> is considered the gold standard level for web accessibility</li>
</ul>
<h3 id="other-dark-mode-site-palettes"><a href="#other-dark-mode-site-palettes" aria-label="other dark mode site palettes permalink"></a>Other Dark Mode Site Palettes</h3>
<p><em>I did a deep dive into the dark mode palettes of Spotify, Twitter, Facebook and more in this <a href="https://blog.karenying.com/posts/50-shades-of-dark-mode-gray" target="_blank">post</a>.</em></p>
<p>I grabbed the dark mode colors of a couple of popular sites/apps. Every palette image shows the background color, primary text color, and secondary text color from left to right. <strong>I put the contrast ratios of the primary and secondary colors with the background color on top of the respective color.</strong></p>
<p><strong>Spotify</strong>:
<span>
      <a href="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/cd7c1/spotify.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/8ac56/spotify.webp 240w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d3be9/spotify.webp 480w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/e46b2/spotify.webp 960w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/f992d/spotify.webp 1440w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/0dd1a/spotify.webp 1547w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/8ff5a/spotify.png 240w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/e85cb/spotify.png 480w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d9199/spotify.png 960w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/07a9c/spotify.png 1440w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/cd7c1/spotify.png 1547w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d9199/spotify.png" alt="spotify" title="spotify" loading="lazy">
      </picture>
  </a>
    </span></p>
<p><strong>Facebook</strong>:
<span>
      <a href="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/dca52/facebook.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/8ac56/facebook.webp 240w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d3be9/facebook.webp 480w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/e46b2/facebook.webp 960w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/f992d/facebook.webp 1440w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/eb054/facebook.webp 1550w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/8ff5a/facebook.png 240w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/e85cb/facebook.png 480w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d9199/facebook.png 960w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/07a9c/facebook.png 1440w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/dca52/facebook.png 1550w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d9199/facebook.png" alt="facebook" title="facebook" loading="lazy">
      </picture>
  </a>
    </span></p>
<p><strong>YouTube</strong>:
<span>
      <a href="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/acd79/youtube.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/8ac56/youtube.webp 240w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d3be9/youtube.webp 480w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/e46b2/youtube.webp 960w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/f992d/youtube.webp 1440w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/bb338/youtube.webp 1543w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/8ff5a/youtube.png 240w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/e85cb/youtube.png 480w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d9199/youtube.png 960w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/07a9c/youtube.png 1440w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/acd79/youtube.png 1543w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d9199/youtube.png" alt="youtube" title="youtube" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>All of these satisfy the AAA standard of a contrast ratio of at least 7 👍🏼</p>
<p>And then we have GitHub’s new look…</p>
<p><strong>GitHub</strong>:
<span>
      <a href="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3deb/github.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/8ac56/github.webp 240w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3be9/github.webp 480w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/e46b2/github.webp 960w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/f992d/github.webp 1440w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/383eb/github.webp 1758w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/8ff5a/github.png 240w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/e85cb/github.png 480w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d9199/github.png 960w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/07a9c/github.png 1440w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3deb/github.png 1758w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d9199/github.png" alt="github" title="github" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>Not only do the colors look noticeably darker than their counterparts in other apps, <strong>the secondary text color fails AAA standards</strong>! It’s important for the secondary text color to have high contrast because of how small the font is. I knew my eyes didn’t deceive me.</p>
<p><strong>While contrast ratios aren’t <a href="https://www.bounteous.com/insights/2019/03/22/orange-you-accessible-mini-case-study-color-ratio/" target="_blank">everything</a>, they are a simple way to quantify the difference between two colors.</strong> In this case, it’s clear that GitHub’s dark mode colors <em>are</em> darker. This can make it harder to read text.</p>
<h3 id="code-review-palette"><a href="#code-review-palette" aria-label="code review palette permalink"></a>Code Review Palette</h3>
<p>Finally, my main gripe with GitHub dark mode is that the red / green for code diffs looks super off to me.</p>
<p>On the right is the light mode colors and left is the new shades. I overlaid the respective background colors on top:</p>
<p><span>
      <a href="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/c95f0/diff.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/8ac56/diff.webp 240w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d3be9/diff.webp 480w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/e46b2/diff.webp 960w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/f992d/diff.webp 1440w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/2ac07/diff.webp 1842w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/8ff5a/diff.png 240w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/e85cb/diff.png 480w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d9199/diff.png 960w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/07a9c/diff.png 1440w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/c95f0/diff.png 1842w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d9199/diff.png" alt="diff colors" title="diff colors" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>I did calculate the contrast ratios of both palettes and they were pretty similar (close to 1 lol). However, for some reason the lighter one is easier for me to parse at a cursory glance. Maybe I’m not used to it yet, but I really dislike how dark the new diff colors are. For something as important as code review, I’m using GitHub light mode.</p>
<p>I also investigated <strong>VSCode’s Git integration</strong> diff colors (which I enjoy!):</p>
<p><span><span>
      <a href="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/dc61a/vscode-diff.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/8ac56/vscode-diff.webp 240w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d3be9/vscode-diff.webp 480w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/e46b2/vscode-diff.webp 960w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/f8f9f/vscode-diff.webp 1147w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/8ff5a/vscode-diff.png 240w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/e85cb/vscode-diff.png 480w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d9199/vscode-diff.png 960w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/dc61a/vscode-diff.png 1147w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d9199/vscode-diff.png" alt="vscode diff colors" title="vscode diff colors" loading="lazy">
      </picture>
  </a>
    </span></span></p>
<p>IMO these shades work well even on a darker background and don’t hinder code review.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>While there is no color theory justification that GitHub’s new code diff palette is worse, its text colors are not as WCAG accessible as other dark mode apps we use daily.</p>
<p>Maybe if GitHub put as much effort into researching their dark mode palette as they did into the <a href="https://twitter.com/github/status/1336362679506784256" target="_blank">promo video</a> they released, we wouldn’t be here. This is still a beta feature so I have hope. <strong>GitHub, please give us the dark mode experience we deserve 🥺</strong></p>
<p><em>Thanks for reading. Happy hacking!</em></p></div></div>]]>
            </description>
            <link>https://blog.karenying.com/posts/github-darkmode-sucks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400139</guid>
            <pubDate>Sat, 12 Dec 2020 18:03:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I've designed Python fantasy cards to learn it easier]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25400117">thread link</a>) | @tomaszs
<br/>
December 12, 2020 | https://summonthejson.com/products/summon-the-json-python-deck | <a href="https://web.archive.org/web/*/https://summonthejson.com/products/summon-the-json-python-deck">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p data-mce-style="text-align: left;">If you are learning to code, it is often hard to discover and memorize all programming functions. STJ&nbsp;Python flashcards make it super easy. It combines state of art memory techniques to help you remember functions fast.</p>
<p data-mce-style="text-align: left;"><strong>The science behind STJ:&nbsp;Python</strong></p>
<div data-mce-style="text-align: left;"><p>According to research, images help stick the information in the long term memory, transmit messages faster, improve comprehension, trigger emotions, motivate learners. In fact, 90% of information transmitted to the brain is visual (<a href="https://www.shiftelearning.com/blog/bid/350326/studies-confirm-the-power-of-visuals-in-elearning">source</a>). That is why STJ: Python intriguing and beautiful illustrations can help you memorize faster. Side-by-side with the fantasy setting and funny descriptions STJ:&nbsp;Python cards are a great combo to help boost your memory! They are eye-catching but also cause emotions - the cornerstone of fast memorization (<a href="https://www.memory-key.com/memory/emotion">source</a>).</p><p>Dive into a fantasy world of Summon The JSON, where excellent visual design, creatures, and fun descriptions will help you remember&nbsp;Python function automagically.</p></div>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117083121_1024x1024.jpg?v=1606044111"></p>
<p data-mce-style="text-align: left;">STJ:&nbsp;Python is an excellent choice if you:</p>
<p data-mce-style="text-align: left;"><strong>Want to become a programmer</strong></p>
<div data-mce-style="text-align: left;"><p>Flashcards contain the most useful set of&nbsp;Python functions programmers use most of the time. STJ:&nbsp;Python will give you a great overview of what tools every programmer has at hand. With that knowledge, it will be easier for you to start thinking about how to create your application from these building blocks.</p><p><strong>Go to a coding job interview</strong></p></div>
<p data-mce-style="text-align: left;">A lot of companies use knowledge tests and whiteboard tasks to assess coding job candidate knowledge. STJ:&nbsp;Python helps you remember functions easier. Regular flashcards are boring and make it hard to stick programming functions to anything meaningful.&nbsp; Contrary STJ:&nbsp;Python helps your brain store information about&nbsp;Python functions in an efficient way.&nbsp; It increases the chance, that during a job interview your brain will be able to give you all information you need.<br></p>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117083241_8b6c81c4-e7f9-4e0a-b7aa-b22ca2d539a8_1024x1024.jpg?v=1606044472"></p>
<p data-mce-style="text-align: left;"><strong>Switch from another language to&nbsp;Python</strong></p>
<p data-mce-style="text-align: left;">If you are already a software developer, you know how confusing it is to switch to learn another language. Some functions are similar. Some are not. It gets even worse when you code in 2 or 3 languages at the same time. There is a lot of things to remember in every language. You need to find equivalents. STJ:&nbsp;Python will help you progress faster in learning Python. It shows you the toolset of the language and helps you remember it faster. Also, if you come back to Python, you can also take a look at cards, to recalibrate your brain easier.</p>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082424_1024x1024.jpg?v=1606044528"></p>
<p data-mce-style="text-align: left;"><strong>Write faster without searching online</strong><br></p>
<p data-mce-style="text-align: left;">It is great, we have a lot of easily accessible sources on the Internet, we can find all information within seconds or minutes. But the Internet will never beat the human brain speed. If you remember function names, you will code faster. Moreover, your coding experience will become more fulfilling. You won't worry about connection lags, that the search engine does not give the answer you are looking for. You won't be distracted by websites and online ads. Focus is one of the most important assets of a programmer. STJ:&nbsp;Python will help you be more focused in the zone!</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082538_1024x1024.jpg?v=1606044208" alt=""></p>

<div data-mce-style="text-align: left;"><p>Summon The JSON:&nbsp;Python is not only a flashcard deck. It is also a game for everyone. Up to four people can play a game with STJ: Python. The deck is divided into heroes, animals, and food.&nbsp; Some cards have points, some have super-powers. You can combine them to win battles against other players.</p><p>STJ:&nbsp;Python game can be played by everyone. You don't need to have any prior programming knowledge to do so. In fact, it is a great way to spend time in a mixed group of geeks and non-geeks. You can play it with your family, friends, colleagues, or even meet new people</p></div>
<p data-mce-style="text-align: left;">STJ:&nbsp;Python game is a great ice-breaker, conversation starter, and a way to spend time with other people, chat, and bond. Have a great time together.</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082016_1024x1024.jpg?v=1606044238" alt=""></p>
<h2 data-mce-style="text-align: left;">What is inside?</h2>
<p data-mce-style="text-align: left;">One deck contains:</p>
<ul>
<li data-mce-style="text-align: left;">A complete deck of 65-cards with several custom cards (make your own cards)</li>
<li data-mce-style="text-align: left;">8-page long booklet instruction with 2 memorization modes and game instruction</li>
</ul>
<p data-mce-style="text-align: left;">Cards are premium quality with linen texture and durable UV coating. The learning game takes approx 3 minutes. Each game takes about 15 minutes and can be repeated indefinitely.&nbsp;</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082811_1024x1024.jpg?v=1606044272" alt=""></p>
</div></div>]]>
            </description>
            <link>https://summonthejson.com/products/summon-the-json-python-deck</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400117</guid>
            <pubDate>Sat, 12 Dec 2020 18:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[More Batteries Included with Emacs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399994">thread link</a>) | @fanf2
<br/>
December 12, 2020 | https://karthinks.com/software/more-batteries-included-with-emacs/ | <a href="https://web.archive.org/web/*/https://karthinks.com/software/more-batteries-included-with-emacs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Continuing from <a href="https://karthinks.com/software/batteries-included-with-emacs/">last time</a>, here are a dozen more tricks Emacs has up its
sleeve that it’s shy about telling you. We continue to chip away at Emacs’
discoverability problem, one demo at a time.</p>
<p>Same rules as before:</p>
<ul>
<li>
<p>No packages, <strong>stock Emacs only</strong></p>
</li>
<li>
<p>No steep learning curves. <strong>Learn each feature in under five minutes or bust</strong>. (Up from two minutes last time.)</p>
</li>
<li>
<p><strong>No gimmicks</strong>. No doctor, tetris, snake, dunnet…</p>
</li>
<li>
<p><strong>Just the deltas</strong>. No commonly mentioned packages like flymake, doc-view,
outline-minor-mode, gnus or eww. Nothing that Emacs brings up automatically or
a nonspecific Google search gets you.</p>
</li>
<li>
<p>Assume a modern Emacs, 26.3+.</p>
<p>Also, if you’re new to Emacs:</p>
<table>
<thead>
<tr>
<th>Emacs jargon</th>
<th>Modern parlance</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>M-x</code></td>
<td>Alt + x</td>
</tr>
<tr>
<td><code>C-x</code></td>
<td>Ctrl + x</td>
</tr>
<tr>
<td>Frame</td>
<td>Emacs window</td>
</tr>
<tr>
<td>Window</td>
<td>split/pane</td>
</tr>
<tr>
<td>Buffer</td>
<td>Contiguous chunk of text/data</td>
</tr>
<tr>
<td>Point</td>
<td>Cursor position in buffer</td>
</tr>
<tr>
<td>Active Region</td>
<td>Text selection</td>
</tr>
<tr>
<td>Region</td>
<td>Text selection (not highlighted)</td>
</tr>
<tr>
<td>Face</td>
<td>Font, color and display properties</td>
</tr>
</tbody>
</table>
</li>
</ul>
<p>(Sorry.)</p>
<p>Okay? Let’s go:</p>
<h2 id="strokes--m-x-strokes-help">Strokes (<code>M-x strokes-help</code>)</h2>
<p>Control Emacs with mouse gestures:</p>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/strokes-mode-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Why are you using Emacs with a mouse, you ask.</p>
<p>In this demo I used gestures to handle window management:
<img src="https://karthinks.com/img/strokes-list.png" alt=""></p>
<p>This is because I lack imagination. Consider: You can bind <em>any</em> gesture to <em>any</em> Emacs command.</p>
<p>The real utility of this feature is when you find yourself going back and forth between different interaction paradigms, like a web browser and Emacs, requiring frequent context switching between full keyboard and keyboard/mouse based interaction.</p>
<p>Want to <code>org-capture</code> or <code>org-roam-insert</code> something from your browser? Want to quickly recompile a TeX document while you’re busy mousing through the corresponding PDF? Need to tweak some markup in your document while you work on graphics in Inkscape? <a href="http://xenodium.com/emacs-clone-git-repo-from-clipboard/">Clone a repository you found online</a>?  <code>strokes-mode</code>.</p>
<p>The second use case for Strokes is to control Emacs during reading-centric activities, like email or RSS. Star or delete messages, pause or skip music tracks (with some elisp around <code>playerctl</code>), navigate info nodes, or cycle through Elfeed searches.</p>
<p><code>M-x strokes-help</code> will get you started. As with most things Emacs, there’s more to the library than meets the eye, like support for multi-part strokes you can use to edit documents in Chinese. The buffer showing the gesture being traced is for demo purposes only, you can customize <code>strokes-use-strokes-buffer</code>:</p>
<div><pre><code data-lang="emacs-lisp">(<span>global-set-key</span> (<span>kbd</span> <span>"&lt;down-mouse-3&gt;"</span>) <span>'strokes-do-stroke</span>) <span>; Draw strokes with RMB</span>
(<span>setq</span> <span>strokes-use-strokes-buffer</span> <span>nil</span>) <span>; Don't draw strokes to the screen</span>
</code></pre></div><hr>
<h2 id="minibuffer-completion-styles--c-h-v-completion-styles">Minibuffer completion styles (<code>C-h v completion-styles</code>)</h2>
<p>The default minibuffer experience is annoying enough to send anyone into the
arms of <code>ido</code>, <code>ivy</code> or <code>helm</code>. But Emacs does a lot better in the
tab-completions department than it lets on. The minibuffer can match by
substrings, regexps, initials and even (as of Emacs 27+) fuzzily, and it can do
all of them at once if you don’t mind a giant pile of matches.</p>
<p>You can do worse than</p>
<div><pre><code data-lang="emacs-lisp">(<span>setq</span> <span>completion-styles</span> <span>'</span>(<span>initials</span> <span>partial-completion</span> <span>flex</span>)) <span>; &gt; Emacs 27.1</span>
(<span>setq</span> <span>completion-cycle-threshold</span> <span>10</span>)
</code></pre></div><p>Now <code>M-x ohba</code> tab-expands to <code>org-hide-block-all</code>, <code>M-x qrr</code> to
<code>query-replace-regexp</code> and so on, allowing you to tab-cycle between up to ten
completions. Use tab to match file names fuzzily and expand short paths
(<code>~/.l/sh/g</code>) to long ones (<code>~/.local/share/git</code>).</p>
<p>Stretching the five minute rule a bit: You probably want different matching
rules for different categories, though. Flex matching on extended commands
(<code>M-x</code>) can dump hundreds of irrelevant matches on short input, for instance.
You can customize <code>completion-category-overrides</code> to set the matching style by
the category being completed.</p>
<p>Finally, note that completion styles dictate how a candidate pool is found.
Incremental completion systems like <code>ido</code> specify how found candidates are
displayed and chosen. These are orthogonal functions, so any set of completion
styles should work with any completion system. Unfortunately this isn’t the
case, because <code>ivy</code> and <code>helm</code> are off doing their own thing. Emacs’ built in
completion styles do work with <code>icomplete</code>, <code>ido</code> and possibly <code>selectrum</code>
though.</p>
<hr>
<h2 id="fake-ido--m-x-fido-mode">Fake Ido ( <code>M-x fido-mode</code>)</h2>
<p>Improves the other half of the default minibuffer experience: interacting with
selection candidates. Navigating to, from and inside the default completions
buffer takes too many key presses. <code>fido-mode</code> brings <code>ido</code> like selection to
every command in Emacs that uses <code>completing-read</code>, which is most of them.</p>
<p>Of course, <code>ido</code> is also built in, but you know all about it. It also takes some
effort to get ido to work with every command. <code>fido-mode</code> is set-and-forget, but
it’s Emacs 27+ only.</p>
<hr>
<h2 id="easier-rectangle-editing--m-x-cua-selection-mode">Easier rectangle editing (<code>M-x cua-selection-mode</code>)</h2>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/cua-selection-mode-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>The default rectangle commands in Emacs (<code>C-x r</code> map) leave a little to be
desired in terms of interactivity. Emacs has fully featured rectangle editing,
but it’s presented in an odd sort of way, as a subfeature of Common User Access.
It’s pretty nifty:</p>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/cua-selection-mode-demo-2.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Start or clear a rectangle selection with <code>C-&lt;return&gt;</code>. Cycle through rectangle
corners with <code>&lt;return&gt;</code>. Yes, you’ll need to rebind it if you use Org or ESS.</p>
<p>It’s a very handy feature, but note that <code>cua-selection-mode</code> does <em>not</em> mesh
well with undo. If you use <code>undo-tree</code>, it can lock up trying to undo a
<code>cua-selection</code> edit.</p>
<hr>
<h2 id="speedbar--m-x-speedbar">speedbar (<code>M-x speedbar</code>)</h2>
<p>A file explorer and much, much more in Emacs. If you need the Neotree or
dired-sidebar package to do anything in Emacs, check out speedbar.</p>
<p>Speedbar pops up a side frame that looks like a file browser, which it is. But
it also integrates with <code>imenu</code> to show you headings/tags inside files, and with
<code>vc</code> to show you the status of your files:</p>
<figure>
    <img src="https://karthinks.com/img/speedbar-tags-demo.png" alt="Figure 1: Speedbar showing tags and VC status"> <figcaption>
            <p>Figure 1: Speedbar showing tags and VC status</p>
        </figcaption>
</figure>

<figure>
    <img src="https://karthinks.com/img/speedbar-org-demo.png" alt="Figure 2: Speedbar showing headings in an org file"> <figcaption>
            <p>Figure 2: Speedbar showing headings in an org file</p>
        </figcaption>
</figure>

<p>From inside speedbar you can act on files with (frustratingly, <em>almost</em>
dired-like) keybindings. Most regular commands run from speedbar will be run in
the associated buffer.</p>
<p>It tracks the active buffer to show you appropriate hierarchical information.
Here I moved point into <code>info</code> and <code>latex-mode</code> buffers:</p>
<p><img src="https://karthinks.com/img/speedbar-info-demo.png" alt="">
<img src="https://karthinks.com/img/speedbar-latex-demo.png" alt=""></p>
<p>Perhaps you’d like a list of your buffers instead. Switch between buffer and
file view with <code>b</code> / <code>f</code>. (You can expand a buffer entry for tag/headings.)</p>
<figure>
    <img src="https://karthinks.com/img/speedbar-buffers-demo.png"> 
</figure>

<hr>
<h2 id="orgtbl-minor-mode--m-x-orgtbl-mode">Orgtbl minor mode (<code>M-x orgtbl-mode</code>)</h2>
<p>Org-mode is its own thing, a full fledged notetaking, publishing,
literate-programming, task tracking application with a growing ecosystem that’s
parallel to Emacs’.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>But it does provide a handy tool that’s useful in any mode: Making tables. If
you’re one of the dozen Emacs users who haven’t hopped on the Org train, this
one’s for you.</p>
<p>With <code>orgtbl-mode</code>, you can make tables by starting a line with the pipe
character and hitting tab to make a field–like you would in <code>org-mode</code>–but
<strong>without getting in the way of your major mode</strong>. You can just leave it on and
get on with your work.</p>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/orgtbl-mode-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Here I table some parameters in matlab-mode as a comment, but even more lazily
than prescribed above by calling <code>orgtbl-create-or-convert-from-region</code>
(<code>C-c |</code>) on some data.</p>
<p>With some work, you can export the table in place to html or LaTeX, but setting
this up would break the five minute rule. You can also use the table as a
spreadsheet, which is beyond me.</p>
<hr>
<h2 id="regexp-builder--m-x-re-builder">Regexp builder (<code>M-x re-builder</code>)</h2>
<p><img src="https://karthinks.com/img/re-builder-demo.png" alt="">
Emacs’ regular expressions syntax can be idiosyncratic if you’re used to <a href="https://www.pcre.org/">PCRE</a>. Are unescaped parens matched literally or do they act as capture groups? Does + need to be escaped to match multiple occurrences of a character? How do I match whitespace again?<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>I can never remember. For regularly confused users like me there is <code>re-builder</code>. Build your regular expressions interactively, one character at a time. Save it to the kill ring for later use. This is a godsend when testing regexes for non-interactive use, like when writing elisp helpers.</p>
<p>A cleaner approach to regular expressions in Emacs, as most package maintainers will tell you, is to use the <code>rx</code> library instead. <code>rx</code> translates regular expressions in sexp form to a regexp string:</p>
<div><pre><code data-lang="emacs-lisp">(<span>rx</span> (<span>and</span> <span>"("</span>
         (<span>or</span> <span>"use-package"</span> <span>"require"</span>)
         (<span>+</span> <span>space</span>)
         (<span>group</span> (<span>syntax</span> <span>symbol</span>))))
</code></pre></div><div><pre><code data-lang="text">(\(?:\(?:requir\|use-packag\)e\)[[:space:]]+\(\s_\)
</code></pre></div><hr>
<h2 id="future-history--m-n-in-prompts">Future history (<code>M-n</code> in prompts)</h2>
<p><code>M-p</code> and <code>M-n</code> cycle through history items in minibuffer prompts. So what happens when you press <code>M-n</code> when you’re at a blank prompt?</p>
<p>Emacs tries to Do What You Mean. If the cursor is over a file name, for instance, <code>M-n</code> at the find-file prompt inserts the file path at point into the minibuffer. From the manual:</p>
<blockquote>
<p>The “future history” for file names includes several possible alternatives you may find useful, such as the file name or the URL at point in the current buffer. The defaults put into the “future history” in this case are controlled by the functions mentioned in the value of the option file-name-at-point-functions.</p>
</blockquote>
<p>Like the DWIM behavior of Emacs commands on regions, many utilities account for <code>future-history</code>. You can usually drag whatever relevant object point is at into the minibuffer prompt with <code>M-n</code>.</p>
<hr>
<h2 id="transpose-regions--m-x-transpose-region">Transpose regions (<code>M-x transpose-region</code>)</h2>
<p>Lurking in the bevy of transposition commands in Emacs is <code>transpose-region</code>,
which does what it says on the tin<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>:</p>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/transpose-regions-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Exchange any two non-overlapping regions in a buffer. You’ll need to assign a
keybinding though.</p>
<div><pre><code data-lang="emacs-lisp">(<span>global-set-key</span> (<span>kbd</span> <span>"C-x C-M-t"</span>) <span>'transpose-regions</span>)
</code></pre></div><p>Also of note: <code>transpose-paragraphs</code>, which sounds like a text-mode utility but
works pretty well on adjacent blocks of code.</p>
<hr>
<h2 id="view-mode-again--m-x-view-mode">View mode, again (<code>M-x view-mode</code>)</h2>
<p>View-mode got an airing <a href="https://karthinks.com/software/batteries-included-with-emacs/#view-mode--m-x-view-mode">the last time around</a> but I like it so much I will repeat
myself. <strong>Turn Emacs into a pager.</strong></p>
<p>By default, pressing <code>v</code> in dired will open a file in view-mode. You can dismiss
the window and buffer with <code>q</code>, so regular buffers can essentially function as
info or help buffers do with <code>View</code>. You can scroll or isearch without pressing
any …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karthinks.com/software/more-batteries-included-with-emacs/">https://karthinks.com/software/more-batteries-included-with-emacs/</a></em></p>]]>
            </description>
            <link>https://karthinks.com/software/more-batteries-included-with-emacs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399994</guid>
            <pubDate>Sat, 12 Dec 2020 17:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Accordions with Native HTML]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399984">thread link</a>) | @championshuttle
<br/>
December 12, 2020 | https://itsopensource.com/creating-accordions-with-native-html/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/creating-accordions-with-native-html/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Accordions are one of the most commonly used UI components for any website. For example FAQs section of the website, where only the question is shown, and when clicked the answer just opens up.
Generally, we handle this by creating 2 <code>divs</code> and adding some javascript to handle the open and close of the accordion. But recently I stumbled upon this hidden gem in HTML that eliminates the need of all this - <a href="https://developer.mozilla.org/docs/Web/HTML/Element/details"><code>&lt;details&gt;</code></a></p>
<p>We can simply design a simple FAQ or summary section with <code>&lt;details&gt;</code> HTML tag without using Javascript!!! 🤯🤯🤯.
And the best part… it is supported by all the modern browsers (obviously except IE :( ) - <a href="https://caniuse.com/?search=details">browser compatibility</a>.  </p>
<h3>Using <code>&lt;details&gt;</code> tag</h3>
<p>There are two elements here: <code>&lt;details&gt;</code> and <code>&lt;summary&gt;</code>. <code>&lt;details&gt;</code> is the wrapper for all the content you want to show and hide, and <code>&lt;summary&gt;</code> contains the — well, the summary and title of the section. <code>&lt;summary&gt;</code> is optional, if you do not add it, the browser will use some default text. For example, in Firefox and Chrome, it is <code>Details</code>. Below is a sample HTML markup:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>details</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>summary</span><span>&gt;</span></span>Details<span><span><span>&lt;/</span>summary</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>p</span><span>&gt;</span></span>Something small enough to escape casual notice.<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>details</span><span>&gt;</span></span></code></pre></div>
<p>And it will render like:</p>
<p><img src="https://itsopensource.com/24758e046144be6cff4069952a25332c/1.gif" alt="part1"></p>
<p>This markup can be designed with CSS as any other HTML element. Now for creating beautiful accordions all you need is just HTML and CSS (and a will to let go of IE).</p>
<p>Demo: <a href="https://bit.ly/htmldetails">https://itsopensource.com/demos/details/</a></p>
<h3>References</h3>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/details">MDN: details</a></li>
</ul>
<p>Cheers.</p></section></div>]]>
            </description>
            <link>https://itsopensource.com/creating-accordions-with-native-html/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399984</guid>
            <pubDate>Sat, 12 Dec 2020 17:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[eInk Monitor Setup for Coding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399908">thread link</a>) | @tyler109
<br/>
December 12, 2020 | https://forum.ei2030.org/t/best-dasung-eink-monitor-setup/42 | <a href="https://web.archive.org/web/*/https://forum.ei2030.org/t/best-dasung-eink-monitor-setup/42">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p><span>#4</span></p>
<ul>
<li>Minimize scrolling by using page up/down keyboard shortcuts</li>
<li>Have a plain white desktop</li>
<li>Switch off animations in accessibility</li>
<li>Reduce the animation effects in the dock settings</li>
<li>I prefer mine at 1600x1200</li>
<li>Make the mouse pointer larger</li>
<li>Use large text</li>
<li>Use a font designed for e-ink: Literata is my favourite</li>
<li>Zoom in on websites</li>
<li>I mirror my MacBook screen, but only have its brightness up to watch videos or check colours</li>
<li>Don’t use dark modes, and make customisable apps very white</li>
<li>Have warm light directional lamps pointing at the screen instead of using the built in lights</li>
<li>Have the top of the screen at eye level</li>
</ul>
<p><span>#5</span></p>
<p>So, my tips:</p>
<ul>
<li>
<p>Learn all possible shortcuts (switch tabs in browser, switch apps, validate dialog, space bar to page down, zoom size text, …)</p>
</li>
<li>
<p>You have a checkbox in “system pref / accessibility / display” to increase contrast : it add an extra border on some macos ui element (I find the slider below not useful)</p>
</li>
<li>
<p>There is an extension for firefox to improve contrast (“font contrast”). FF also have a high contrast mode that I find not practical</p>
</li>
<li>
<p>Try to understand M1/M2/M3 Vs contrast +/-. My understanding is: contrast +/- “moves the range” from light/medium to medium/dark, and M1/M2/M3 makes this range wider, at the price of less level of gray. But I may be wrong</p>
</li>
<li>
<p>There are 9 level of contrasts</p>
</li>
<li>
<p>Usually for videos you want to use lowest contrast level</p>
</li>
<li>
<p>Don’t use the software, it’s too buggy, just use the button on the screen</p>
</li>
<li>
<p>Take really care that you don’t use a software like flux or night shift. And even when quitting flux, you may still have the profile activated (Displays / colour / display profile)</p>
</li>
<li>
<p>For anything which is white with black background (video tutorial, site …), you can set an os shortcut to inverse all color of the screen: sys preference / keyboard / shortcut / accessibility / invert colors (I use ctrl+alt+cmd 8)</p>
</li>
<li>
<p>It’s nice to have a white desktop background, but you may have difficulty to read the name of the icons on the desktop. so : right click on desktop / show view options, and then increase the size of the font. Alternatively hit cmd+A to have everything selected and then readable</p>
</li>
<li>
<p>I use 1100x824</p>
</li>
</ul>
<p><span>#6</span></p>
<p>hi for code editor I have to say that i abandoned (i am using visual studio code) - syntax highlighting is so useful and not usable in B&amp;W. I am interested if you have any good configuration for it.</p>
<p>the only additional tips i could give you according to previous posts is that I put my dasung on an articulated arm of photo camera. It allows me to use it without backlight and to avoid annoying light reflection by moving it easily. I also tried a classics monitor arm but the dasung was to light for it.</p>
<p>The drivers are buggy and each time I connect my dasung on my mac I have to adjust the settings again. (i use M2 with black+)</p>
<p>Anyone knows if the config can be saved on the dasung ?</p>
<p><span>#7</span><br>
On my side I’m happy with coding on dasung, as long as I use a light theme. I use mostly phpstorm, and the difference of level of grey / background color / italic / underline makes syntax highlighting somehow noticeable enough. Definitely not perfect though</p>
<p>I think that without or with the driver installed, the settings are resetted every time you reconnect the screen. (Just that, with the driver, you have extra bugs)</p>
<p>Another tip or solution about light reflection : putting yourself (and the screen) perpendicular to a window : you’ll still have some outside lights, but no reflection</p>
<p><span>#8</span></p>
<p>I finally succeeded in activating high dpi on mac</p>
<p>I use SwitchResX and I had to add a new scaled resolution for the dasung : 2201x1650 (the real resolution does not allow hidpi (it is a mac os bug)</p>
<p>then I choose the 1101x825 and it works like a charm</p>
        </div></div>]]>
            </description>
            <link>https://forum.ei2030.org/t/best-dasung-eink-monitor-setup/42</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399908</guid>
            <pubDate>Sat, 12 Dec 2020 17:31:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyTorch Dynamic Quantization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399867">thread link</a>) | @keyboardman
<br/>
December 12, 2020 | https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Dynamic quantization quantize the weights of neural networks to integers, but the activations are dynamically quantized during inference. Comparing to floating point neural networks, the size of dynamic quantized model is much smaller since the weights are stored as low-bitwidth integers. Comparing to other quantization techniques, dynamic quantization does not require any data for calibration or fine-tuning. More details about the mathematical foundations of quantization for neural networks could be found in my article <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">â€œQuantization for Neural Networksâ€�</a>.</p>



<p>Given a pre-trained floating point model, we could easily create an dynamically quantized model, run inference, and potentially achieve better latency without too much additional effort. In this blog post, I would like to show how to use PyTorch to do dynamic quantizations.</p>

<h3 id="pytorch-dynamic-quantization">PyTorch Dynamic Quantization</h3>

<p>Unlike TensorFlow 2.3.0 which supports integer quantization using arbitrary bitwidth from 2 to 16, PyTorch 1.7.0 only supports 8-bit integer quantization. The workflow is as easy as loading a pre-trained floating point model and apply a dynamic quantization wrapper.</p>



<p>In this case, I would like to use the BERT-QA model from HuggingFace Transformers as an example. I was dynamically quantizing the <code>torch.nn.Linear</code> layer for the BERT-QA model since the majority of the computation for Transformer based models are matrix multiplications. The source code could also be downloaded from <a href="https://github.com/leimao/PyTorch-Dynamic-Quantization">GitHub</a>.</p>

<div><div><pre><code><span># qa.py
</span>
<span>import</span> <span>os</span>
<span>import</span> <span>time</span>
<span>import</span> <span>torch</span>
<span>from</span> <span>transformers</span> <span>import</span> <span>BertTokenizer</span><span>,</span> <span>BertForQuestionAnswering</span>

<span>def</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>,</span> <span>inputs</span><span>,</span> <span>num_samples</span><span>=</span><span>100</span><span>):</span>

    <span>start_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>num_samples</span><span>):</span>
        <span>_</span> <span>=</span> <span>model</span><span>(</span><span>**</span><span>inputs</span><span>)</span>
    <span>end_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>elapsed_time</span> <span>=</span> <span>end_time</span> <span>-</span> <span>start_time</span>
    <span>elapsed_time_ave</span> <span>=</span> <span>elapsed_time</span> <span>/</span> <span>num_samples</span>

    <span>return</span> <span>elapsed_time_ave</span>

<span>def</span> <span>get_bert_qa_model</span><span>(</span><span>model_name</span><span>=</span><span>"deepset/bert-base-cased-squad2"</span><span>,</span> <span>cache_dir</span><span>=</span><span>"./saved_models"</span><span>):</span>

    <span># https://huggingface.co/transformers/model_doc/bert.html#transformers.BertForQuestionAnswering
</span>    <span>tokenizer</span> <span>=</span> <span>BertTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>,</span> <span>cache_dir</span><span>=</span><span>cache_dir</span><span>)</span>
    <span>model</span> <span>=</span> <span>BertForQuestionAnswering</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>,</span> <span>cache_dir</span><span>=</span><span>cache_dir</span><span>,</span> <span>return_dict</span><span>=</span><span>True</span><span>)</span>

    <span>return</span> <span>model</span><span>,</span> <span>tokenizer</span>

<span>def</span> <span>prepare_qa_inputs</span><span>(</span><span>question</span><span>,</span> <span>text</span><span>,</span> <span>tokenizer</span><span>,</span> <span>device</span><span>=</span><span>None</span><span>):</span>

    <span>inputs</span> <span>=</span> <span>tokenizer</span><span>(</span><span>question</span><span>,</span> <span>text</span><span>,</span> <span>return_tensors</span><span>=</span><span>"pt"</span><span>)</span>
    <span>if</span> <span>device</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>inputs_cuda</span> <span>=</span> <span>dict</span><span>()</span>
        <span>for</span> <span>input_name</span> <span>in</span> <span>inputs</span><span>.</span><span>keys</span><span>():</span>
            <span>inputs_cuda</span><span>[</span><span>input_name</span><span>]</span> <span>=</span> <span>inputs</span><span>[</span><span>input_name</span><span>].</span><span>to</span><span>(</span><span>device</span><span>)</span>
        <span>inputs</span> <span>=</span> <span>inputs_cuda</span>
    
    <span>return</span> <span>inputs</span>

<span>def</span> <span>move_inputs_to_device</span><span>(</span><span>inputs</span><span>,</span> <span>device</span><span>=</span><span>None</span><span>):</span>

    <span>inputs_cuda</span> <span>=</span> <span>dict</span><span>()</span>
    <span>for</span> <span>input_name</span> <span>in</span> <span>inputs</span><span>.</span><span>keys</span><span>():</span>
        <span>inputs_cuda</span><span>[</span><span>input_name</span><span>]</span> <span>=</span> <span>inputs</span><span>[</span><span>input_name</span><span>].</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span>return</span> <span>inputs_cuda</span>

<span>def</span> <span>run_qa</span><span>(</span><span>model</span><span>,</span> <span>tokenizer</span><span>,</span> <span>question</span><span>,</span> <span>text</span><span>,</span> <span>device</span><span>=</span><span>None</span><span>):</span>

    <span>inputs</span> <span>=</span> <span>prepare_qa_inputs</span><span>(</span><span>question</span><span>=</span><span>question</span><span>,</span> <span>text</span><span>=</span><span>text</span><span>,</span> <span>tokenizer</span><span>=</span><span>tokenizer</span><span>)</span>

    <span>all_tokens</span> <span>=</span> <span>tokenizer</span><span>.</span><span>convert_ids_to_tokens</span><span>(</span><span>inputs</span><span>[</span><span>"input_ids"</span><span>].</span><span>numpy</span><span>()[</span><span>0</span><span>])</span>

    <span>if</span> <span>device</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>inputs</span> <span>=</span> <span>move_inputs_to_device</span><span>(</span><span>inputs</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
        <span>model</span> <span>=</span> <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span>outputs</span> <span>=</span> <span>model</span><span>(</span><span>**</span><span>inputs</span><span>)</span>

    <span>start_scores</span> <span>=</span> <span>outputs</span><span>.</span><span>start_logits</span>
    <span>end_scores</span> <span>=</span> <span>outputs</span><span>.</span><span>end_logits</span>

    <span>answer_start_idx</span> <span>=</span> <span>torch</span><span>.</span><span>argmax</span><span>(</span><span>start_scores</span><span>,</span> <span>1</span><span>)[</span><span>0</span><span>]</span>
    <span>answer_end_idx</span> <span>=</span> <span>torch</span><span>.</span><span>argmax</span><span>(</span><span>end_scores</span><span>,</span> <span>1</span><span>)[</span><span>0</span><span>]</span> <span>+</span> <span>1</span>

    <span>answer</span> <span>=</span> <span>" "</span><span>.</span><span>join</span><span>(</span><span>all_tokens</span><span>[</span><span>answer_start_idx</span> <span>:</span> <span>answer_end_idx</span><span>])</span>

    <span>return</span> <span>answer</span>

<span>def</span> <span>get_model_size</span><span>(</span><span>model</span><span>,</span> <span>temp_dir</span><span>=</span><span>"/tmp"</span><span>):</span>

    <span>model_dir</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>temp_dir</span><span>,</span> <span>"temp"</span><span>)</span>
    <span>torch</span><span>.</span><span>save</span><span>(</span><span>model</span><span>.</span><span>state_dict</span><span>(),</span> <span>model_dir</span><span>)</span>
    <span># model.save_pretrained(model_dir)
</span>    <span>size</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>getsize</span><span>(</span><span>model_dir</span><span>)</span>
    <span>os</span><span>.</span><span>remove</span><span>(</span><span>model_dir</span><span>)</span>
    
    <span>return</span> <span>size</span>

<span>def</span> <span>main</span><span>():</span>

    <span>cuda_device</span> <span>=</span> <span>torch</span><span>.</span><span>device</span><span>(</span><span>"cuda:0"</span><span>)</span>
    <span>num_samples</span> <span>=</span> <span>100</span>

    <span>model</span><span>,</span> <span>tokenizer</span> <span>=</span> <span>get_bert_qa_model</span><span>(</span><span>model_name</span><span>=</span><span>"deepset/bert-base-cased-squad2"</span><span>)</span>
    <span>model</span><span>.</span><span>eval</span><span>()</span>
    <span># https://pytorch.org/docs/stable/torch.quantization.html?highlight=torch%20quantization%20quantize_dynamic#torch.quantization.quantize_dynamic
</span>    <span>quantized_model</span> <span>=</span> <span>torch</span><span>.</span><span>quantization</span><span>.</span><span>quantize_dynamic</span><span>(</span><span>model</span><span>,</span> <span>{</span><span>torch</span><span>.</span><span>nn</span><span>.</span><span>Linear</span><span>},</span> <span>dtype</span><span>=</span><span>torch</span><span>.</span><span>qint8</span><span>)</span>

    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>
    <span>print</span><span>(</span><span>"Model Sizes"</span><span>)</span>
    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>

    <span>model_size</span> <span>=</span> <span>get_model_size</span><span>(</span><span>model</span><span>=</span><span>model</span><span>)</span>
    <span>quantized_model_size</span> <span>=</span> <span>get_model_size</span><span>(</span><span>model</span><span>=</span><span>quantized_model</span><span>)</span>

    <span>print</span><span>(</span><span>"FP32 Model Size: {:.2f} MB"</span><span>.</span><span>format</span><span>(</span><span>model_size</span> <span>/</span> <span>(</span><span>2</span> <span>**</span> <span>20</span><span>)))</span>
    <span>print</span><span>(</span><span>"INT8 Model Size: {:.2f} MB"</span><span>.</span><span>format</span><span>(</span><span>quantized_model_size</span> <span>/</span> <span>(</span><span>2</span> <span>**</span> <span>20</span><span>)))</span>

    <span>question</span> <span>=</span> <span>"What publication printed that the wealthiest 1% have more money than those in the bottom 90%?"</span>

    <span>text</span> <span>=</span> <span>"According to PolitiFact the top 400 richest Americans </span><span>\"</span><span>have more wealth than half of all Americans combined.</span><span>\"</span><span> According to the New York Times on July 22, 2014, the </span><span>\"</span><span>richest 1 percent in the United States now own more wealth than the bottom 90 percent</span><span>\"</span><span>. Inherited wealth may help explain why many Americans who have become rich may have had a </span><span>\"</span><span>substantial head start</span><span>\"</span><span>. In September 2012, according to the Institute for Policy Studies, </span><span>\"</span><span>over 60 percent</span><span>\"</span><span> of the Forbes richest 400 Americans </span><span>\"</span><span>grew up in substantial privilege</span><span>\"</span><span>."</span>

    <span>inputs</span> <span>=</span> <span>prepare_qa_inputs</span><span>(</span><span>question</span><span>=</span><span>question</span><span>,</span> <span>text</span><span>=</span><span>text</span><span>,</span> <span>tokenizer</span><span>=</span><span>tokenizer</span><span>)</span>
    <span>answer</span> <span>=</span> <span>run_qa</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>tokenizer</span><span>=</span><span>tokenizer</span><span>,</span> <span>question</span><span>=</span><span>question</span><span>,</span> <span>text</span><span>=</span><span>text</span><span>)</span>
    <span>answer_quantized</span> <span>=</span> <span>run_qa</span><span>(</span><span>model</span><span>=</span><span>quantized_model</span><span>,</span> <span>tokenizer</span><span>=</span><span>tokenizer</span><span>,</span> <span>question</span><span>=</span><span>question</span><span>,</span> <span>text</span><span>=</span><span>text</span><span>)</span>

    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>
    <span>print</span><span>(</span><span>"BERT QA Example"</span><span>)</span>
    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>

    <span>print</span><span>(</span><span>"Text: "</span><span>)</span>
    <span>print</span><span>(</span><span>text</span><span>)</span>
    <span>print</span><span>(</span><span>"Question: "</span><span>)</span>
    <span>print</span><span>(</span><span>question</span><span>)</span>
    <span>print</span><span>(</span><span>"Model Answer: "</span><span>)</span>
    <span>print</span><span>(</span><span>answer</span><span>)</span>
    <span>print</span><span>(</span><span>"Dynamic Quantized Model Answer: "</span><span>)</span>
    <span>print</span><span>(</span><span>answer_quantized</span><span>)</span>

    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>
    <span>print</span><span>(</span><span>"BERT QA Inference Latencies"</span><span>)</span>
    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>

    <span>model_latency</span> <span>=</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>inputs</span><span>=</span><span>inputs</span><span>,</span> <span>num_samples</span><span>=</span><span>num_samples</span><span>)</span>
    <span>print</span><span>(</span><span>"CPU Inference Latency: {:.2f} ms / sample"</span><span>.</span><span>format</span><span>(</span><span>model_latency</span> <span>*</span> <span>1000</span><span>))</span>

    <span>quantized_model_latency</span> <span>=</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>=</span><span>quantized_model</span><span>,</span> <span>inputs</span><span>=</span><span>inputs</span><span>,</span> <span>num_samples</span><span>=</span><span>num_samples</span><span>)</span>
    <span>print</span><span>(</span><span>"Dynamic Quantized CPU Inference Latency: {:.2f} ms / sample"</span><span>.</span><span>format</span><span>(</span><span>quantized_model_latency</span> <span>*</span> <span>1000</span><span>))</span>

    <span>inputs_cuda</span> <span>=</span> <span>move_inputs_to_device</span><span>(</span><span>inputs</span><span>,</span> <span>device</span><span>=</span><span>cuda_device</span><span>)</span>
    <span>model</span><span>.</span><span>to</span><span>(</span><span>cuda_device</span><span>)</span>
    <span>model_cuda_latency</span> <span>=</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>inputs</span><span>=</span><span>inputs_cuda</span><span>,</span> <span>num_samples</span><span>=</span><span>num_samples</span><span>)</span>
    <span>print</span><span>(</span><span>"CUDA Inference Latency: {:.2f} ms / sample"</span><span>.</span><span>format</span><span>(</span><span>model_cuda_latency</span> <span>*</span> <span>1000</span><span>))</span>

    <span># No CUDA backend for dynamic quantization in PyTorch 1.7.0
</span>    <span># quantized_model_cuda = quantized_model.to(cuda_device)
</span>    <span># quantized_model_cuda_latency = measure_inference_latency(model=quantized_model_cuda, inputs=inputs_cuda, num_samples=num_samples)
</span>    <span># print("Dynamic Quantized GPU Inference Latency: {:.2f} ms / sample".format(quantized_model_cuda_latency * 1000))
</span>
<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>

    <span>main</span><span>()</span>
</code></pre></div></div>

<p>With PyTorch 1.7.0, we could do dynamic quantization using x86-64 and aarch64 CPUs. However, NVIDIA GPUs have not been supported for PyTorch dynamic quantization yet.</p>

<div><div><pre><code>$ python qa.py 
===========================================================================
Model Sizes
===========================================================================
FP32 Model Size: 411.00 MB
INT8 Model Size: 168.05 MB
===========================================================================
BERT QA Example
===========================================================================
Text: 
According to PolitiFact the top 400 richest Americans "have more wealth than half of all Americans combined." According to the New York Times on July 22, 2014, the "richest 1 percent in the United States now own more wealth than the bottom 90 percent". Inherited wealth may help explain why many Americans who have become rich may have had a "substantial head start". In September 2012, according to the Institute for Policy Studies, "over 60 percent" of the Forbes richest 400 Americans "grew up in substantial privilege".
Question: 
What publication printed that the wealthiest 1% have more money than those in the bottom 90%?
Model Answer: 
New York Times
Dynamic Quantized Model Answer: 
New York Times
===========================================================================
BERT QA Inference Latencies
===========================================================================
CPU Inference Latency: 78.91 ms / sample
Dynamic Quantized CPU Inference Latency: 47.83 ms / sample
CUDA Inference Latency: 10.40 ms / sample
</code></pre></div></div>

<p>We could see that the model size of the INT8 quantized model is much smaller than the FP32 model. The inference latency of INT8 dynamic quantization on CPU is much faster than the FP32 ordinary inference on CPU. However, FP32 inference using NVIDIA GPU is still the fastest.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://github.com/leimao/PyTorch-Dynamic-Quantization">PyTorch Dynamic Quantization</a></li>
  <li><a href="https://leimao.github.io/article/Neural-Networks-Quantization/">Quantization for Neural Networks</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399867</guid>
            <pubDate>Sat, 12 Dec 2020 17:27:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Compile-Time Function Evaluation and Type Systems]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399809">thread link</a>) | @pcr910303
<br/>
December 12, 2020 | https://www.ralfj.de/blog/2018/07/19/const.html | <a href="https://web.archive.org/web/*/https://www.ralfj.de/blog/2018/07/19/const.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="-content">
      <header>
    
    
</header>

<p>For some time now (since the 1.26 release, to be precise), Rust has a <a href="https://github.com/rust-lang/rust/pull/46882">very powerful machinery for CTFE</a>, or compile-time function evaluation.
Since then, there have been various discussions about which operations should be allowed during CTFE, which checks the compiler should do, how this all relates to promotion and which kinds of guarantees we should be able to expect around CTFE.
This post is my take on those topics, and it should not be surprising that I am going to take a very type-system centric view.
Expect something like a structured brain dump, so there are some unanswered questions towards the end as well.</p>

<!-- MORE -->

<h2 id="some-background">Some Background</h2>

<p>CTFE is the mechanism used by the compiler, primarily, to evaluate items like <code>const x: T = ...;</code>.
The <code>...</code> here is going to be Rust code that must be “run” at compile-time, because it can be used as a constant in the code – for example, it can be used for array lengths.</p>

<p>Notice that CTFE is <em>not</em> the same as constant propagation: Constant propagation is an optimization pass done by compilers like LLVM that will opportunistically change code like <code>3 + 4</code> into <code>7</code> to avoid run-time work.
Being an optimization, constant propagation must, by definition, not change program behavior and will not be observable at all (other than performance).
CTFE, on the other hand, is about code that <em>must</em> be executed at compile-time because the compiler needs to know its result to proceed – for example, it needs to know the size of an array to compute how to lay out data in memory.
You can statically see, just from the syntax of the code, whether CTFE applies to some piece of code or not:
CTFE is only used in places like the value of a <code>const</code> or the length of an array.</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>demo</span><span>()</span> <span>{</span>
  <span>const</span> <span>X</span><span>:</span> <span>u32</span> <span>=</span> <span>3</span> <span>+</span> <span>4</span><span>;</span> <span>// CTFE</span>
  <span>let</span> <span>x</span><span>:</span> <span>u32</span> <span>=</span> <span>4</span> <span>+</span> <span>3</span><span>;</span> <span>// no CTFE (but maybe constant propagation)</span>
<span>}</span></code></pre></figure>

<p>We say that the <code>3 + 4</code> above is in <em>const context</em> and hence subject to CTFE, but the <code>4 + 3</code> is not.</p>

<h2 id="const-safety">Const Safety</h2>

<p>Not all operations can be used in const context.
For example, it makes no sense to compute your array length as “please go read that file from disk and compute something” – we can’t know what will be on the disk when the program actually runs.
We could use the disk of the machine compiling the program, but that does not sound very appealing either.
Things get even worse when you consider letting the program send information to the network.
Clearly, we don’t want CTFE to have actually observable side-effects outside of compilation.</p>

<p>In fact, just naively letting programs read files would also be grossly unsafe:
When computing the length of an array twice, it is important that we obtain the same result.
<strong>Update:</strong> As @eddyb points out, things get even worse once you consider const generics, traits, and coherence: At that point, you have to <a href="https://internals.rust-lang.org/t/mir-constant-evaluation/3143/47">rely on evaluating the same expression in different crates to produce the same result</a>. <strong>/Update</strong></p>

<blockquote>
  <p><em>CTFE must be deterministic.</em></p>
</blockquote>

<p>If not, the compiler could end up thinking that two arrays have the same length, but then later compute different layouts.
That would be a disaster.
So, any kind of external input and any kind of non-determinism is a complete no-go for CTFE.
This does not just concern I/O, even converting a reference to a <code>usize</code> is not deterministic.</p>

<p>The compiler will throw a CTFE error if such an operation is ever attempted to be executed.
Those programs that <em>are</em> executable in const context are called <em>const safe</em>:</p>

<blockquote>
  <p><em>A program is const safe if it can be executed by CTFE without hitting an error (panics are allowed).</em></p>
</blockquote>

<p>This is very much in analogy with the idea that a <em>safe</em> (or <em>run-time safe</em>, to distinguish it from const safe) program is a program that does not cause any memory errors or data races.
In fact, we will see that this analogy between “programs that are well-behaved under CTFE” (const safety) and “programs that do not cause UB” (run-time safety) can carry us very far.</p>

<p>One very interesting question now is whether some given function <code>foo</code> should be allowed to be called in const context.
We could just always say “yes”, and rely on the fact that CTFE will throw an error when <code>foo</code> does anything fishy.
The problem with this approach is that, if <code>foo</code> is in a library, updating the library might change <code>foo</code> in a way that makes it no longer const-safe.
In other words, making <em>any</em> function not const-safe any more would be a semver violation because it could break downstream crates.</p>

<p>The typical mechanism to solve that problem is to have an annotation that explicitly marks a function as “usable in const context”.
In Rust, the proposed mechanism for this purpose is <a href="https://github.com/rust-lang/rust/issues/24111"><code>const fn</code></a>; in C++ it is called <code>constexpr</code>.
The compiler can now reject calling non-<code>const</code> functions in const context, so library authors can add non-const-safe operations without breaking semver.</p>

<h2 id="const-type-system-and-const-soundness">Const Type System and Const Soundness</h2>

<p>This leads us to the interesting situation that the compiler will reject code in const context that it would accept just fine outside of const context.
In particular, the body of a <code>const fn</code> is <em>also</em> considered to be in const context – otherwise, if we allowed calling arbitrary functions, we would have the same problem again.
One useful way to think about this is that we have a second type system, a “const type system”, that is used to type-check code in const context.
This type system does not allow calls to non-<code>const</code> functions.</p>

<p>It should probably also not allow casting a reference to an integer, because (as discussed above) that is a non-deterministic operation which cannot be performed during CTFE.
What else?</p>

<p>Before we go on and add random additional checks, let us step back and think about what our goals are here.
Typically, the purpose of a type system is to establish some sort of guarantee for a well-typed program.
For Rust’s “main” (“run-time”) type system, that guarantee is “no undefined behavior”, which means no memory errors and no data races.
What is the guarantee for our new const type system?
We have already talked about it above: It’s const safety!
This leads us to the definition of const soundness:</p>

<blockquote>
  <p><em>Our const type system is sound if well-typed programs are const-safe.</em></p>
</blockquote>

<p>Again, notice how this is very similar to the correctness statement for the run-time type system, which guarantees run-time safety.</p>

<p>However, we have to be a bit careful here.
Consider the following piece of code:</p>

<figure><pre><code data-lang="rust"><span>const</span> <span>fn</span> <span>is_eight_mod_256</span><span>(</span><span>x</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span> <span>x</span> <span>%</span> <span>256</span> <span>==</span> <span>8</span> <span>}</span></code></pre></figure>

<p>We will definitely want to allow this code.
Why should <code>==</code> or <code>%</code> not be const-safe?
Well, we could call our function as follows:</p>

<figure><pre><code data-lang="rust"><span>is_eight_mod_256</span><span>(</span><span>Box</span><span>::</span><span>into_raw</span><span>(</span><span>Box</span><span>::</span><span>new</span><span>(</span><span>0</span><span>))</span> <span>as</span> <span>usize</span><span>);</span></code></pre></figure>

<p>That statement is certainly <em>not</em> const-safe as the result depends on where exactly the allocator puts our <a href="https://doc.rust-lang.org/stable/std/boxed/struct.Box.html"><code>Box</code></a>.
However, we want to blame the <code>as usize</code> for this issue, not the <code>is_eight_mod_256</code>.</p>

<p>The solution is for the const type system to not just have separate rules about which operations are allowed, we also must change our notion of which values are “valid” for a given type.
An integer obtained from a pointer is valid for <code>usize</code> at run-time, but it is <em>not</em> valid for <code>usize</code> in const mode!
After all, there are basic arithmetic operations that we expect all <code>usize</code> to support, that CTFE cannot support for pointers.</p>

<blockquote>
  <p><em>A function is const-safe if, when executed with const-valid arguments, it does not trigger a CTFE error and returns a const-valid result (if it returns at all).</em></p>
</blockquote>

<p>Under this definition, <code>is_eight_mod_256</code> is const-safe because whenever <code>x</code> is an actual integer, it will evaluate without any error.
At the same time, this shows that converting a reference into <code>usize</code> is <em>not</em> const-safe, because the input of this operation is const-valid, but the output is not!
This provides a solid justification for rejecting such casts in const context.</p>

<h2 id="ctfe-correctness">CTFE correctness</h2>

<p>In Rust, CTFE is performed by miri, a MIR interpreter that used to be a <a href="https://github.com/solson/miri/">separate project</a> but whose core engine has been integrated into rustc.
miri will execute the code in const context step-by-step and just complain and fail with an error when an operation cannot be performed.
This does not just concern non-determinism; miri does not support everything it could support because @oli-obk is <a href="https://github.com/rust-lang/rust/blob/5ba21844f6c85a0cd55c8ea0250d5cd758134f84/src/librustc_mir/interpret/const_eval.rs#L199">super careful</a> about not accidentally stabilizing behavior that should undergo an RFC.</p>

<p>In fact, right now miri will reject all operations on raw pointers.
They all raise a CTFE error and hence must all be rejected by the const type system.
The plan is to change miri so that it can support more operations, but we have to be careful in doing so.
I have already mentioned that miri must be deterministic, but there is another point to consider that you might have expected to play a much more prominent role:
CTFE, at least if it succeeds, should match run-time behavior!</p>

<blockquote>
  <p><em>CTFE is correct if, when it loops forever, completes with a result, or panics, that behavior matches the run-time behavior of the same code.</em></p>
</blockquote>

<p>We clearly do not want code to behave differently when it lives in const context and is run by CTFE, and when it is compiled to machine-code and executed “for real”.</p>

<p>Or, do we?
Don’t get me wrong, I am not advocating for deliberately breaking that property, but it sure is worth considering what would go wrong if miri was <em>not</em> CTFE-correct.
Maybe surprisingly, it turns out that this would not be a soundness issue!
All we care about for the purpose of soundness is for CTFE to be deterministic, as already discussed.
We don’t re-run the same code at run-time and rely on it still doing the same, so nothing actually breaks if CTFE behavior diverges from run-time behavior.</p>

<p>That said, not being CTFE correct is surely very surprising and we should avoid it best we can.
However, I am told that actually predicting the result of floating-point operations deterministically <a href="https://gafferongames.com/post/floating_point_determinism/">is extremely hard</a> and <a href="https://github.com/rust-lang/rust/issues/24111#issuecomment-386765720">LLVM isn’t exactly helping</a>.
So, we will likely have to live with either considering floating point operations to be const-unsafe (raising a CTFE error), or not having CTFE correctness when floating point operations are …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ralfj.de/blog/2018/07/19/const.html">https://www.ralfj.de/blog/2018/07/19/const.html</a></em></p>]]>
            </description>
            <link>https://www.ralfj.de/blog/2018/07/19/const.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399809</guid>
            <pubDate>Sat, 12 Dec 2020 17:21:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Certificate Pinning with OkHttp]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399728">thread link</a>) | @palebt
<br/>
December 12, 2020 | https://www.rockandnull.com/certificate-pinning-android/ | <a href="https://web.archive.org/web/*/https://www.rockandnull.com/certificate-pinning-android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>If your app is doing something relatively complicated, it will likely need a server to communicate with.</p><p>The basic step for ensuring secure communication with the server is well known: use HTTPS. What's lesser-known in secure app-server communication, is the certificate pinning. Not all apps will need this, but apps that transfer sensitive data from the app to the server might benefit from one additional security clause.</p><p>In short, certificate pinning ensures that your app will only connect to a server that has a specific certificate, not just a valid certificate. By default, when you connect to your server with HTTPS you require the server to have a valid certificate for the connected domain. This opens the window of man-in-the-middle attacks that some bad actor might pose to be your server to see the data you are sending. This is not the simplest thing to do (since the attacker will require to have a valid certificate as well) but is doable.</p><h2 id="do-you-need-certificate-pinning">Do you need certificate pinning?</h2><p>I don't think all apps need to implement certificate pinning. Only if your app is sending sensitive data to your server (e.g. credit card numbers) you should consider this. Why not everyone? Because it's adding some maintenance cost. Certificates expire and you will need to update the app with the new certificate that should be trusted when this happens. If you are fine with this maintenance cost, sure go ahead and implement it even if you are not the most "sensitive" app out there.</p><h2 id="ok-i-am-using-okhttp-how-do-i-do-it">Ok, I am using OkHttp. How do I do it?</h2><p>It's quite simple actually. Modify the <a href="https://square.github.io/okhttp/">OkHttp</a> client builder as follow.</p><pre><code>val client = OkHttpClient()
    .newBuilder().certificatePinner(
        certificatePinner = CertificatePinner.Builder()
            .add("example.com",
            "sha256/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=")
            .build()
        ).build()</code></pre><p>Run your app and make a network call with this client. Search your logs for something similar to this.</p><pre><code>javax.net.ssl.SSLPeerUnverifiedException: Certificate pinning failure!
    Peer certificate chain: 
        sha256/BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
        sha256/CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
        sha256/DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD</code></pre><p>Replace the client code above to include the actual signatures of your certificate. You are done! Your app will only connect using HTTPS to your server and refuse to connect if it fails to detect your own certificate.</p><pre><code>val client = OkHttpClient()
    .newBuilder().certificatePinner(
        certificatePinner = CertificatePinner.Builder()
            .add("example.com", "sha256/BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB")
            .add("example.com", "sha256/CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC")
            .add("example.com", "sha256/DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD")
            .build()
        ).build()</code></pre><p>Might be a good idea to repeat this process for a backup domain. This way, if one of your domain certificates expires, you app can use the other one until you update the app.</p><p>If you want to pin all the subdomains of your domain, check the <a href="https://square.github.io/okhttp/4.x/okhttp/okhttp3/-certificate-pinner/#domain-patterns">official doc</a>.</p><p>Don't forget that this is not "unhackable". A bad actor might modify your app and change these hashes. But still, it requires significantly more effort to do this. There's nothing "unhackable" anyway, we just add as many protective measures as possible to keep bad actors away.</p><h2 id="what-if-i-don-t-use-okhttp">What if I don't use OkHttp?</h2><p>It's slightly more complicated but here's the official doc (<a href="https://developer.android.com/training/articles/security-ssl#Pinning">1</a>, <a href="https://developer.android.com/training/articles/security-ssl">2</a>) on how to do this. There are also countless blog posts one search away.</p><p>Happy coding!</p>
			</section></div>]]>
            </description>
            <link>https://www.rockandnull.com/certificate-pinning-android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399728</guid>
            <pubDate>Sat, 12 Dec 2020 17:12:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust, Python and Fish]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399709">thread link</a>) | @onidaito
<br/>
December 12, 2020 | https://benjamin.computer/posts/2020-12-12-rust-python.html | <a href="https://web.archive.org/web/*/https://benjamin.computer/posts/2020-12-12-rust-python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

	<a href="https://benjamin.computer/"><img src="https://benjamin.computer/images/bcpu_04_flat.png" alt="benjamin.computer"></a>
  
	<ul>
	<li><a href="https://benjamin.computer/about.html">ABOUT</a></li>
  	<li><a href="http://eepurl.com/haZQoT">MAILING LIST</a></li>
	<li><a href="https://benjamin.computer/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide Atom feed">RSS</a></li>
	<li><a href="https://mastodon.social/web/accounts/220949">MASTODON</a></li>
	<li><a href="https://www.github.com/onidaito">GITHUB</a></li>
	<li><a href="mailto:me@benjamin.computer">EMAIL</a></li>
	</ul>
 

<hr>

<p><h2>Rust, Python and Fish</h2></p> 
<em>12-12-2020</em> 
<p><em>Quick reminder! You can get my posts fresh in your inbox if you join the mailing list</em> <a href="http://eepurl.com/haZQoT">here</a></p>
<p>I'm telling a little bit of a lie here really. When I say fish, I really mean <a href="https://en.wikipedia.org/wiki/Poisson_distribution">poisson</a> and when I say poisson I really mean <a href="https://www.jasondavies.com/poisson-disc/">Poisson Disc Sampling</a>. Turns out, Poisson disc sampling is really useful in my A.I research. Problem is, it's not the fastest process in the world, particularly when python is involved. So what can we do? Turns out there are lots of options - investigating them has been fun and might be useful for other folks working in this area.</p>
<h3>Fish Discs</h3>
<p>Poisson Disc sampling is a method for creating <em>pleasing</em> random patterns, or rather, random distributions with a somewhat regular spacing. Take a look at the image below and you'll see what I mean.</p>
<figure><img src="https://shutr.benjamin.computer/inpost/poisson.png" alt="Poisson Sample"><figcaption>Random sampling vs. Poisson Sampling <a href="https://medium.com/@hemalatha.psna/implementation-of-poisson-disc-sampling-in-javascript-17665e406ce1">(image courtesy of this lovely writeup)</a></figcaption></figure>

<p>I believe the name comes from the <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson Distribution</a> - I'm not really sure to be honest. How I understand the algorithm is you start with one point and then add another within a circle or sphere of a set distance away with an increasing probability towards the boundary. The idea is to maintain a minimum distance from one point to any other point. This leads to a bit of a problem though as it's quite computationally expensive to check each additional point against all other points. There have been a few attempts to speed things up. I settled on <a href="http://www.cemyuksel.com/research/sampleelimination/">Sample Elimination for Generating Poisson Disk Sample Sets algorithm by Cem Yuksel</a>. This algorithm works by creating a large random set first, then removing points from the set until the Poisson property is - more or less - obtained. It relies on two data-structures - the <a href="https://en.wikipedia.org/wiki/K-d_tree">kdtree</a> and the <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a>. </p>
<p>Sample elimination assigns weights to each point, adding them to the heap as we go. We then take a point off the heap, finding all these points nearest to this point using the tree. With this point removed, we rebuild the heap using the weight formula, and go again, until we arrive at the number of point we want. In my tests, one needs roughly 8 time the number of points you want in order to get a good final result.</p>
<h3>Python</h3>
<p>I'm a tad bored of Python; it tends to dominate the AI world at the moment. I believe there are a few other languages people can use but the vast majority of code seems to be in Python. It has some advantages - it's fairly easy to get into and works on most platforms, but like all interpreted languages, there is a bit of an overhead. <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/performance/nbody.html">Python performance has improved over the years</a> but it still isn't top. However, the first place to start in speeding up your code is to take a look at how you've built the algorithm. </p>
<p>Firstly, I removed many of the <em>sqrt()</em> calls, as we merely want to order the points in the sample rather than record the actual distances. This seemed to have some effect on performance though not as much as I'd thought. </p>
<p>One thing we can do is measure where our code is taking the most time. Python has a number of profilers such as <a href="https://docs.python.org/3/library/profile.html">cprofile</a> and <a href="https://github.com/nvdv/vprof">vprof</a> to name a couple. They are quite easy to use too. Once I measured where my program was spending it's time, I decided I needed to remove numpy from the equation and work with some simpler datatypes, reducing any unnecessary conversions. Around this time, I was made aware of a package called <a href="https://numba.pydata.org/">numba</a>. </p>
<h3>numba</h3>
<p>I thought I'd ask around to see what other people were doing to speed up their scientific code. What better place to start than the <a href="https://society-rse.org/">UK Research Software Engineering group</a>. I quickly received the answer I was looking for - some software called <a href="https://numba.pydata.org/">numba</a>.</p>
<p>Numba is a <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JIT  -Just in Time Compiler</a> that aims to speedup certain python functions. Certain parts of python and numpy can be compiled down into a faster code blob. One need only decorate the function in question and replace a few types and <em>Boom!</em> - faster code.</p>
<p>In practice, it's a little more tricky than that. One needs to do a little conversion from complicated to more simple types that numba can handle, but this isn't too onerous. </p>
<h3>Rust</h3>
<p>I've <a href="https://benjamin.computer/posts/2019-07-31-rust-research.html">spoken before about Rust</a> and how I enjoy writing code with it. I spotted <a href="https://www.nature.com/articles/d41586-020-03382-2">an article recently about how scientists are moving to rust</a>. Rust's popularity among programmers is quite well known. I think this is partially because it's a hard language to learn initially and requires some knowledge of the machine, data-types, borrowing and the like. It certainly strokes your programmer ego, which isn't such a bad thing if kept in check. I certainly feel a sense of accomplishment when I write working code in Rust - something I never really get in Python. It definitely takes longer to write Rust code than Python, but it <em>feels</em> better and runs faster. The code seems tighter, leaner with fewer bugs and more tests (I think tests are easier to write in Rust than in any other language). It's become my goto for writing any performant code.</p>
<p>I rewrote the algorithm for Poisson Disc Sampling in Rust and received a reasonable amount of speedup over numba. Not a lot mind you, which was a surprise, but enough to keep going and see how far I could push it. </p>
<h3>Going parallel</h3>
<p>One of the easy wins for speed is to parallelise your code. In Python, I've always found this to be more difficult than it should be. I also think Rust could do better in this regard. In the past, Rust used to have the <em>scoped</em> keyword that helped in determining how long variables would live for in each individual thread. This was removed some time ago however, which was a bit of a pain. Now, if we want to do work with threads, it's somewhat tricky - even the simple pattern of <a href="https://en.wikipedia.org/wiki/Fork%E2%80%93join_model">fork-join</a>. Not exactly living up to Rust's touted 'fearless concurrency' I think.</p>
<p>Fork-Join, or divide and conquer is a really simple approach to parallelising your code. Divide up the dataset, work on each bit individually and once all the threads are done, combine the results together. Simple right? Well, perhaps not as simple as you might think.</p>
<p>Rust's main strength and it's main barrier to understanding is the borrowing mechanism it works on. Variables have lifetimes and are owned by parts of the program. Threads and concurrency mess with this sort of thing a lot. I mean, can you guarantee that a thread will stop before the code that called it ends? What happens to a shared variable, particularly something like a vector that can be modified at any time by multiple processes? It is a tricky thing to have to write yourself, made more difficult as there are a lot of options in Rust, many of which are not built in as standard. </p>
<p>Having written the fork-join algorithm a couple of times, I've found a way that I think works quite well. I used the <a href="http://kimundi.github.io/scoped-threadpool-rs/scoped_threadpool/index.html">scoped-threadpool</a> crate and some <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html">mutexes</a>. I've tried things like <a href="https://doc.rust-lang.org/std/cell/">Cells</a>, <a href="https://doc.rust-lang.org/std/sync/struct.Arc.html">Arcs</a> and a whole manner of oddly named libraries but this method seems to be the simplest:</p>
 <pre><code>let rsamples :Mutex&lt;Vec&lt;Quat&gt;&gt; = Mutex::new(vec!());
let rpoints : Mutex&lt;Vec&lt;Quat&gt;&gt; = Mutex::new(vec!());

let mut pool = Pool::new(partitions as u32);
pool.scoped(|scoped| {

    for i in 0..partitions {
        let bsamples = &amp;rsamples;
        let bpoints = &amp;rpoints;

        scoped.execute( move || {
            let ns : usize = sample_size / partitions;
            let mut tpoints : Vec&lt;Quat&gt; = vec!();
            for p in points.iter() {
                let aa = p.axis_angle();
                // DO ALL THE WORK HERE
            }
            //println!("{}, {}", i, tpoints.len() );
            let trval = sample(&amp;tpoints, ns);
            for q in trval.0.iter() {
                let mut t = bsamples.lock().unwrap();
                t.push(*q);
            }
            for q in trval.1.iter() {
                let mut t = bpoints.lock().unwrap();
                t.push(*q);
            }
        });
    }
    scoped.join_all();
});

(rsamples.into_inner().unwrap(), rpoints.into_inner().unwrap())
</code></pre> 
<p>Like so many things in life, when you figure it out, it becomes quite simple. There are many crates out there that provide fancy options for Rust concurrency but scoped-threadpool is simple enough. We create a pool first, then call <em>scoped.execute</em> as many times for as many threads as we want, using the <em>move</em> keyword to move our variables into the scope of each thread. The key here is we are moving in a reference to our shared vectors at the top of the code, so each thread can access the vectors. By wrapping the vector in a mutex we guarantee it can only be accessed by one thread at a time. This is quite similar to how we tend to write this sort of algorithm in languages like C++. Sometimes, it can be easy to be distracted by the fancy crates and syntax rust offers, but the basics are still there doing a good job.  </p>
<p>Parallelising the Poisson Disc algorithm is not without it's problems. Dividing up the space into equal chunks and performing the sampling on each chunk works <em>a bit</em>, but it one isn't careful, you can get some bad artefacts. Consider a chunk where there are a large number of samples - say 1000 - and you only want 2 points. Typically, these points will be close to the border of the space in question, which makes sense if you want to maximise the distance between all the points in your sample. However, when you combine these chunks, you get a pattern where the points all lie along the <em>joins</em> of the areas. Not ideal. </p>
<p>This basically means we can only go so far with parallelising the algorithm to get some speed up. Still, it's better than nothing. </p>
<h3>Talking to Python</h3>
<p>So Rust and threading gets us to <em>good-enough</em> performance. Now how do we get rust to talk to Python? There are a few ways, including writing results to a file and having python read it, but perhaps there's a better way? Asking around on the UKRSE group again, a few folks suggested <a href="https://docs.python.org/3/library/ctypes.html">ctypes</a>, but I decided to go with <a href="https://github.com/PyO3/PyO3">PyO3</a>. PyO3 works in both directions - either calling Rust from Python or vice-versa. In my case I want to call Rust from Python, sending some simple data in, and getting a load of points back. </p>
<p>In order to do this, we …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamin.computer/posts/2020-12-12-rust-python.html">https://benjamin.computer/posts/2020-12-12-rust-python.html</a></em></p>]]>
            </description>
            <link>https://benjamin.computer/posts/2020-12-12-rust-python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399709</guid>
            <pubDate>Sat, 12 Dec 2020 17:09:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The better the chess player is the fewer captures per move they make]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25399690">thread link</a>) | @pkacprzak
<br/>
December 12, 2020 | https://blog.chessvision.ai/average-captures-per-move-by-elo/ | <a href="https://web.archive.org/web/*/https://blog.chessvision.ai/average-captures-per-move-by-elo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    

    

    
      
      

      <span>
        
        
          2 minute read
        
      </span>
    
  </p>


        </header>
      

      <section itemprop="text">
        
        <p>Often when watching chess video lectures, I hear the advice of not capturing the opponent’s piece in favor of putting more pressure, for example, to get a more decisive attack. Also, often we hear the phrase:</p>

<blockquote>
  <p><strong>When you see a good move, look for a better one</strong></p>
</blockquote>

<p>and sometimes this good move can be a capture, but the better move is not a capture. The simplest example is probably going for a checkmate attack and ignore the opponent’s hanging Queen.</p>

<p>Having these ideas, I thought that we can try to form a <strong>hypothesis</strong>:</p>

<blockquote>
  <p><strong>The better the player is the fewer captures per move on average they make</strong></p>
</blockquote>

<p>Let’s see if we can prove it using real data.</p>

<h2 id="data-source">Data source</h2>

<p>Our data source is <a href="https://database.lichess.org/">Lichess game database</a>, specifically games played in October 2020 on Lichess. In order to have a more representative sample, we discard bullet games, and we take a sample of 2M remaining games. Next, we remove Elo outliers - in this case, the remaining players have Elo ranging from 1000 up to 2650.</p>

<h2 id="source-code">Source code</h2>
<p>The complete source code for this experiment in the notebook form is available here: <a href="https://github.com/chessvision-ai/average-number-of-captures-by-elo">https://github.com/chessvision-ai/average-number-of-captures-by-elo</a></p>

<h2 id="results">Results</h2>

<p>The plot  generated by the provided source code:</p>

<p><a href="https://blog.chessvision.ai/assets/images/average_captures_by_elo/plot.png"><img src="https://blog.chessvision.ai/assets/images/average_captures_by_elo/plot.png" alt="Average number of captures per move by Elo rating"></a></p>

<h2 id="observations">Observations</h2>

<ul>
  <li>
    <p>We can observe that the average number of captures per move is negatively correlated with Elo of the players. This is a great result as the common wisdom is now backed up by real data</p>
  </li>
  <li>
    <p>Also, what is probably even more important, is the fact that the average number of captures per move in a game, when averaged over many games, can be potentially used as an accurate and very simplistic estimator of a player’s Elo. There are researches about estimating players’ Elo from games they play and most methods use significantly more computationally intensive methods, e.g. <strong>average centipawn loss</strong>, which is Average is the difference of player’s move to the best computer move averaged over all moves. In the case of this new <strong>average-captures-per-move</strong> metric, computing it is as simple as going through all the moves made in a game and counting how many were captures, so it’s as optimal it could be.</p>
  </li>
</ul>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://blog.chessvision.ai/average-captures-per-move-by-elo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399690</guid>
            <pubDate>Sat, 12 Dec 2020 17:07:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Rubys Superiority over Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25399625">thread link</a>) | @connerj
<br/>
December 12, 2020 | https://www.connerjensen.com/blog/ruby-code-examples | <a href="https://web.archive.org/web/*/https://www.connerjensen.com/blog/ruby-code-examples">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>In this post I will prove that Ruby is better than Python.</h3>
<p>.
<br>
.
<br>
.
<br>
.</p>
<p>Just kidding. <strong>I'm going to show off some cool Ruby code examples</strong>, then compare and contrast them with the same examples done in Python.</p>
<p>The reason behind this post is to have some fun comparing the two languages and to show off some of my favorite examples of Ruby's expressivness and power.</p>
<p>You may not agree with some of the examples, and might think they are difficult to understand, sub optimal, or just plain ugly.</p>
<p>That is completely understandable.</p>
<p>Let's get started with a little example of opening a file and reading it line by line.</p>
<h4>Opening and reading files by line</h4>

<p><strong>Ruby Code Example</strong></p>
<pre><code>file = File.open('example.txt').read

file.each_line do |line|
    puts line
end
</code></pre>
<p>I enjoy how simple it is to open and read text files in Ruby. The fact that Ruby has a built in <code>each_line</code> method on the <code>String</code> object speaks to how the Ruby language wants to make developers <a href="https://www.artima.com/intv/ruby.html">happy</a> by taking care of the little things for them.</p>
<blockquote>Programmers often feel joy when they can concentrate on the creative side of programming, So Ruby is designed to make programmers happy. -<b>Yukihiro Matsumoto</b> (Creator of Ruby)
</blockquote>
<p><strong>Python Code Example</strong></p>
<pre><code>file = open('example.txt', 'r') 
lines = file.readlines() 

for line in lines: 
    print(line.strip())
</code></pre>
<p>This example seems fine too. However, I don't like how one has to specify 'r' as the second parameter to <code>open</code> and how one needs to call <code>strip()</code> on each line.</p>
<p>These examples are both four lines long and they are simple enough, but I prefer the Ruby example. The way it reads is not only clearer, but there are less details for the programmer to remember.</p>
<p>Looking at the ruby example it feels very much like english. There is no remembering to specify an 'r' as the second parameter to <code>open</code>, and no need to call <code>strip()</code> on each line.</p>
<p><strong>I'd imagine that someone who knew neither Ruby or Python would have an easier time understanding the Ruby code example.</strong></p>
<p>The differences between these examples may seem small, but the way a language handles the small stuff can often times shed light on how things are handled in the language as a whole.</p>
<p>Ok, on to the next example.</p>
<h4>Returning early from a function/method</h4>
<p><strong>Ruby Code Example</strong></p>
<pre><code>def example_method(x, y)
    return if x == 7
    return unless y == 10

    x + y
end
</code></pre>
<p>One of my favorite features of Ruby is the unless keyword. It's the same as a <code>!=</code> but I think it makes the code not only look nicer, but also easier to read.</p>
<p><strong>Python Code Example</strong></p>
<pre><code>def example_method(x, y):
    if x == 7:
        return
    if y != 10:
        return

    return x + y
</code></pre>
<p>This Python example is completely fine, but I don't think it has the succinctness and character that the Ruby example has.</p>
<p>My eye much prefers the Ruby examples. It seems so clean and neat, with the return on the same line as the conditional check. The assumed return at the end of the Ruby example is also very pleasing and puts all the focus on the actual "logic" that's being preformed.</p>
<p>However, I do like how Python methods do not need an <code>end</code>, this not only makes them shorter but cleans up nested methods, functions, and classes.</p>
<h4>Defining a class with a constructor method</h4>

<p><strong>Ruby Code Example</strong></p>
<pre><code>class ExampleClass
    def initialize(a, b)
        @a, @b = a, b
    end
end

ec = ExampleClass.new(1,2)
</code></pre>
<p>In this example, I like how there is no need to pass in a reference to the object being constructed. I also think the ruby syntax of using an @ sign to denote an instance variable looks clean and reads well.</p>
<p>One thing I don't like about Ruby is how you must use the <strong>new</strong> method on the class to instantiate an object. I much prefer using just the class name, like Python does (ExampleClass()).</p>
<p><strong>Python Code Example</strong></p>
<pre><code>class ExampleClass: 
    def __init__(self, a, b): 
        self.a, self.b = a, b

ec = ExampleClass(1,2)
</code></pre>
<p>As I said above I prefer how you instantiate an object with Python, because there is no need for the <strong>new</strong> keyword.</p>
<p>I don't enjoy the name of either Ruby's or Python's constructor. In Ruby, the word initialize is difficult to type and I don't like how it is not abbreviated in any way. In Python the "dunders" (__) are unsightly, however they do make it easy to see the constructor while scanning lines of code.</p>
<p><strong>Overall, I like Ruby's constructor better, mainly because of the lack of selfs scattered all over the place.</strong></p>
<h4>Error Handling</h4>

<p><strong>Ruby Code Example</strong> </p>
<pre><code>begin
    1 + 2
    raise 'EXCEPTION'
rescue StandardError =&gt; e
    puts "An exception #{e} was raised"
end
</code></pre>
<p>This is pretty a pretty standard try catch block, but there are some cool things you can do with Ruby error handling, such as omitting the begin block in a method.</p>
<pre><code>def method_that_raises_exception
    raise 'EXCEPTION'
rescue StandardError =&gt; e
    puts "An exception #{e} was raised"
end
</code></pre>
<p>I quite like this syntax as I think it cleans up the method body and makes it clear where exception handling code begins and the "real" body of the function ends.</p>
<p><strong>Python Code Example</strong></p>
<pre><code>try:
    1 + 1
    raise Exception("EXCEPION")
except Exception as e:
    print(e)
</code></pre>
<p>I prefer the arrow syntax (=&gt;) Ruby uses to give the exception a name over Python's use of as. I also like how in Ruby you can raise a StandardError by just saying <code>raise 'What you want your exception to say'</code> without having to specify the error class. </p>
<p>The keywords of begin/rescue also flow better than try/except and the intent would be clearer to the naive reader.</p>
<h4>Conclusion</h4>
<p>Hopefully you found these Ruby code example and Pyton code example comparisons useful. </p>
<p>I did not intend to offend anyone who prefers Python, I mearly wanted to demonstrate the expressiveness and power of the Ruby programming language. </p>
<p>I think Ruby does the small things well, and gives programmers the tools to write code that makes the most sense for their specific situations.</p>
<p>If you are interested in learning more about Ruby I highly recommend checking out this <a href="https://www.connerjensen.com/blog/the_ruby_programming_language_review">book</a>.</p>
<p>Thank you very much for reading, feel free to leave a comment or reach out to me via email or twitter.</p></div></div>]]>
            </description>
            <link>https://www.connerjensen.com/blog/ruby-code-examples</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399625</guid>
            <pubDate>Sat, 12 Dec 2020 17:00:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minecraft speedrunning team catch top runner as cheater via statistical analysis [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25399567">thread link</a>) | @torranceyang
<br/>
December 12, 2020 | https://mcspeedrun.com/dream.pdf | <a href="https://web.archive.org/web/*/https://mcspeedrun.com/dream.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mcspeedrun.com/dream.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399567</guid>
            <pubDate>Sat, 12 Dec 2020 16:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unlimited Is a Ponzi Scheme]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399344">thread link</a>) | @svmanager
<br/>
December 12, 2020 | https://staysaasy.com/product/2020/12/12/unlimitted.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2020/12/12/unlimitted.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recently Google Photos ended their unlimited storage. You shouldn’t have been shocked, because unlimited is more often than not an unsustainable Ponzi Scheme.</p>

<h2 id="good-at-business">Good at Business</h2>

<p>When a software company gives you unlimited storage for anything, the only way for them to maintain that business in the long run is for them to make (amortized or not) incremental and recurring money from each thing they store. This is true, because storage is a recurring and forever cost.</p>

<p>Most B2C companies don’t make recurring money off of the data they store for you. They make money inversely proportional to how recent you stored the thing. Sometimes they don’t make any money at all. So it’s no surprise that unlimited is a Ponzi scheme, because that’s the only way to make the ledger look right.</p>

<h2 id="the-unlimited-ponzi-scheme">The Unlimited Ponzi Scheme</h2>

<p>Businesses will often follow a Ponzi Scheme-esque model with storage for their product. As they go through growth, newer customers are instantly delivering new revenue while their cost is very little - they haven’t started accruing much data. These customers offset older customers, who are getting more expensive as data retention continues forever.</p>

<p>Then, one day, the growth stops. You’ve gained most of the market you’re going to gain.  All of the sudden margin starts to slip. Fewer new users exist to offset the old users People look into and realize the unlimited scheme is up. Then they implement a retention policy and customers freak out.</p>

<h2 id="handling-unlimited-as-a-business">Handling Unlimited as a Business</h2>

<p>Businesses often fail at unlimited in a few ways.</p>

<p>First, companies should offer a way to pay more to get more storage. I can’t be mad that you won’t run a ridiculous business for me. I will get mad if you sink me into your product and don’t give me the option to pay a fair value to continue service.</p>

<p>Second, companies should be mindful of data retention policies from day 1.  The unlimited Ponzhi scheme is in many products not something that companies even know is happening. Things look good  until they don’t.</p>

<p>If you keep data around without retention policies, you will face a long road of performance, stability, and customer issues as you scale. Especially as your growth numbers slow, you should be mindful of the upcoming business realities sooner rather than later if you have anything that is unlimited in your product.</p>

<h2 id="summary">Summary</h2>

<p>There’s no free lunch in this world unless you’re willing to run around to different dumpsters to get it.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2020/12/12/unlimitted.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399344</guid>
            <pubDate>Sat, 12 Dec 2020 16:32:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tiered Subnet Calculator in Terraform]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399302">thread link</a>) | @JayQ_One
<br/>
December 12, 2020 | https://jq1.io/posts/tiered_subnet_calculator/ | <a href="https://web.archive.org/web/*/https://jq1.io/posts/tiered_subnet_calculator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I’ve been thinking about adding support for building tiered subnets of any size
for the next iteration of the <a href="https://jq1.io/posts/dynamic_vpc/">Dynamic VPC Module</a>.
It occurred to me that auto subnet generation inside the module actually
makes the subnetting less dynamic.</p>
<p>Furthermore, auto subnet calculation should be in assistance to
the process of allocating subnets and should not be fed directly as input
to the VPC module. This is due to the fact that order matters only for the
subnetting. So when tiers or AZs are changed, added or removed,
the calculation will shift for none, some or all tiers.</p>
<p>Removing the subnet generation will simplify the module itself and it will reinforce
the notion that engineers should know their subnetting when architecting networks.
With all that in mind, I created a <a href="https://github.com/JudeQuintana/terraform-modules/tree/master/utils/tiered_subnet_calculator">Tiered Subnet Calculator</a> module to assist with allocating subnets per AZ per network tier.</p>
<p><code>tiers.auto.tfvars</code></p>
<pre><code>base_cidr_block = "10.0.0.0/16"

tiers = [
  {
    name   = "app"
    acl    = "public"
    newbit = 4
  },
  {
    name   = "db"
    acl    = "private"
    newbit = 4
  },
  {
    name   = "worker"
    acl    = "private"
    newbit = 4
  },
  {
    name   = "lbs"
    acl    = "public"
    newbit = 4
  }
]

az_newbits = {
  a = 4
  b = 4
  c = 4
  d = 4
}

</code></pre><p><code>variables.tf</code></p>
<pre><code>variable "base_cidr_block" {
  type = string
}

variable "tiers" {
  type = set(object({
    name   = string
    acl    = string
    newbit = number
  }))
}

variable "az_newbits" {
  type = map(number)
}

</code></pre><p><code>main.tf</code></p>
<pre><code>locals {
  # generate top level networks for each tier based on tier newbit + base_cidr_block mask ie /4 + /16 = /20
  tier_networks = zipmap(var.tiers[*].name, cidrsubnets(var.base_cidr_block, var.tiers[*].newbit...))

  # generate a subnet based on each az newbit (in azs_new_bits map) per tier network ie /4 + /20 = /24
  tier_subnets = { for t, n in local.tier_networks : t =&gt; cidrsubnets(n, values(var.az_newbits)...) }

  # generate azs to subnet map per tier
  tier_az_subnets = { for t, s in local.tier_subnets : t =&gt; zipmap(keys(var.az_newbits), s) }

  # build new tiers list with their associated network and az to subnets map
  tiers_with_subnets_per_az = [
    for t in var.tiers : {
      name    = t.name,
      acl     = t.acl,
      network = lookup(local.tier_networks, t.name)
      azs     = lookup(local.tier_az_subnets, t.name),
  }]

}

output "calculated_tiers" {
  value = local.tiers_with_subnets_per_az
}

</code></pre><p><code>terraform refresh</code></p>
<pre><code>$ terraform refresh

Empty or non-existent state file.

Refresh will do nothing. Refresh does not error or return an erroneous
exit status because many automation scripts use refresh, plan, then apply
and may not have a state file yet for the first run.


Outputs:

calculated_tiers = [
  {
    "acl" = "public"
    "azs" = {
      "a" = "10.0.0.0/24"
      "b" = "10.0.1.0/24"
      "c" = "10.0.2.0/24"
      "d" = "10.0.3.0/24"
    }
    "name" = "app"
    "network" = "10.0.0.0/20"
  },
  {
    "acl" = "private"
    "azs" = {
      "a" = "10.0.16.0/24"
      "b" = "10.0.17.0/24"
      "c" = "10.0.18.0/24"
      "d" = "10.0.19.0/24"
    }
    "name" = "db"
    "network" = "10.0.16.0/20"
  },
  {
    "acl" = "private"
    "azs" = {
      "a" = "10.0.32.0/24"
      "b" = "10.0.33.0/24"
      "c" = "10.0.34.0/24"
      "d" = "10.0.35.0/24"
    }
    "name" = "worker"
    "network" = "10.0.32.0/20"
  },
  {
    "acl" = "public"
    "azs" = {
      "a" = "10.0.48.0/24"
      "b" = "10.0.49.0/24"
      "c" = "10.0.50.0/24"
      "d" = "10.0.51.0/24"
    }
    "name" = "lbs"
    "network" = "10.0.48.0/20"
  },
]
</code></pre><p>If you want to see each tier transform you can open the
<code>terraform console</code> and call them to see their output.</p>
<pre><code>$ terraform console
&gt; local.tier_networks
{
  "app" = "10.0.0.0/20"
  "db" = "10.0.16.0/20"
  "lbs" = "10.0.48.0/20"
  "worker" = "10.0.32.0/20"
}
&gt; local.tier_subnets
{
  "app" = [
    "10.0.0.0/24",
    "10.0.1.0/24",
    "10.0.2.0/24",
    "10.0.3.0/24",
  ]
  "db" = [
    "10.0.16.0/24",
    "10.0.17.0/24",
    "10.0.18.0/24",
    "10.0.19.0/24",
  ]
  "lbs" = [
    "10.0.48.0/24",
    "10.0.49.0/24",
    "10.0.50.0/24",
    "10.0.51.0/24",
  ]
  "worker" = [
    "10.0.32.0/24",
    "10.0.33.0/24",
    "10.0.34.0/24",
    "10.0.35.0/24",
  ]
}
&gt; local.tier_az_subnets
{
  "app" = {
    "a" = "10.0.0.0/24"
    "b" = "10.0.1.0/24"
    "c" = "10.0.2.0/24"
    "d" = "10.0.3.0/24"
  }
  "db" = {
    "a" = "10.0.16.0/24"
    "b" = "10.0.17.0/24"
    "c" = "10.0.18.0/24"
    "d" = "10.0.19.0/24"
  }
  "lbs" = {
    "a" = "10.0.48.0/24"
    "b" = "10.0.49.0/24"
    "c" = "10.0.50.0/24"
    "d" = "10.0.51.0/24"
  }
  "worker" = {
    "a" = "10.0.32.0/24"
    "b" = "10.0.33.0/24"
    "c" = "10.0.34.0/24"
    "d" = "10.0.35.0/24"
  }
}
</code></pre><p>Filtering tiers easy too.</p>
<pre><code>locals {
  private_tiers = [for t in local.tier_subnets_per_az : t if t.acl == "private"]
}
</code></pre><p>Now I can start tweaking the <code>tiers</code> object set and <code>az_newbits</code> map
to generate different tiered network configurations.</p>
<p><code>tiers.auto.tfvars</code></p>
<pre><code>base_cidr_block = "10.0.0.0/16"

tiers = [
  {
    name   = "app"
    acl    = "public"
    newbit = 6
  },
  {
    name   = "db"
    acl    = "private"
    newbit = 6
  },
  {
    name   = "worker"
    acl    = "private"
    newbit = 4
  },
]

az_newbits = {
  b = 2
  c = 4
  d = 4
}
</code></pre><pre><code>$ terraform refresh
Empty or non-existent state file.

Refresh will do nothing. Refresh does not error or return an erroneous
exit status because many automation scripts use refresh, plan, then apply
and may not have a state file yet for the first run.


Outputs:

calculated_tiers = [
  {
    "acl" = "public"
    "azs" = {
      "b" = "10.0.0.0/24"
      "c" = "10.0.1.0/26"
      "d" = "10.0.1.64/26"
    }
    "name" = "app"
    "network" = "10.0.0.0/22"
  },
  {
    "acl" = "private"
    "azs" = {
      "b" = "10.0.4.0/24"
      "c" = "10.0.5.0/26"
      "d" = "10.0.5.64/26"
    }
    "name" = "db"
    "network" = "10.0.4.0/22"
  },
  {
    "acl" = "private"
    "azs" = {
      "b" = "10.0.16.0/22"
      "c" = "10.0.20.0/24"
      "d" = "10.0.21.0/24"
    }
    "name" = "worker"
    "network" = "10.0.16.0/20"
  },
]
</code></pre><p>I’m able to take this output, add or remove AZs and subnets
that may have not been in the original calculation. I can chop up
networks as I see fit.</p>
<pre><code>tiers = [
  {
    "acl" = "public"
    "azs" = {
      "b" = "10.0.0.0/24"
      "c" = "10.0.1.0/26"
    }
    "name" = "app"
    "network" = "10.0.0.0/22"
  },
  {
    "acl" = "private"
    "azs" = {
      "c" = "10.0.5.0/26"
      "d" = "10.0.5.64/26"
    }
    "name" = "db"
    "network" = "10.0.4.0/22"
  },
  {
    "acl" = "private"
    "azs" = {
      "b" = "10.0.16.0/22"
      "d" = "10.0.21.0/24"
      "c" = "10.0.22.0/24"
    }
    "name" = "worker"
    "network" = "10.0.16.0/20"
  },
]
</code></pre><p>Also, I can further validate tiered network ranges with <code>ipcalc</code>.</p>
<pre><code>$ ipcalc 10.0.16.0/20

Address:   10.0.16.0            00001010.00000000.0001 0000.00000000
Netmask:   255.255.240.0 = 20   11111111.11111111.1111 0000.00000000
Wildcard:  0.0.15.255           00000000.00000000.0000 1111.11111111
=&gt;
Network:   10.0.16.0/20         00001010.00000000.0001 0000.00000000
HostMin:   10.0.16.1            00001010.00000000.0001 0000.00000001
HostMax:   10.0.31.254          00001010.00000000.0001 1111.11111110
Broadcast: 10.0.31.255          00001010.00000000.0001 1111.11111111
Hosts/Net: 4094                  Class A, Private Internet
</code></pre><p>A more detailed break down of subnets within a tiered network.</p>
<pre><code>$ ipcalc 10.0.16.0/20 /24

Address:   10.0.16.0            00001010.00000000.0001 0000.00000000
Netmask:   255.255.240.0 = 20   11111111.11111111.1111 0000.00000000
Wildcard:  0.0.15.255           00000000.00000000.0000 1111.11111111
=&gt;
Network:   10.0.16.0/20         00001010.00000000.0001 0000.00000000
HostMin:   10.0.16.1            00001010.00000000.0001 0000.00000001
HostMax:   10.0.31.254          00001010.00000000.0001 1111.11111110
Broadcast: 10.0.31.255          00001010.00000000.0001 1111.11111111
Hosts/Net: 4094                  Class A, Private Internet

Subnets after transition from /20 to /24

Netmask:   255.255.255.0 = 24   11111111.11111111.11111111. 00000000
Wildcard:  0.0.0.255            00000000.00000000.00000000. 11111111

 1.
Network:   10.0.16.0/24         00001010.00000000.00010000. 00000000
HostMin:   10.0.16.1            00001010.00000000.00010000. 00000001
HostMax:   10.0.16.254          00001010.00000000.00010000. 11111110
Broadcast: 10.0.16.255          00001010.00000000.00010000. 11111111
Hosts/Net: 254                   Class A, Private Internet

 2.
Network:   10.0.17.0/24         00001010.00000000.00010001. 00000000
HostMin:   10.0.17.1            00001010.00000000.00010001. 00000001
HostMax:   10.0.17.254          00001010.00000000.00010001. 11111110
Broadcast: 10.0.17.255          00001010.00000000.00010001. 11111111
Hosts/Net: 254                   Class A, Private Internet

...

 15.
Network:   10.0.30.0/24         00001010.00000000.00011110. 00000000
HostMin:   10.0.30.1            00001010.00000000.00011110. 00000001
HostMax:   10.0.30.254          00001010.00000000.00011110. 11111110
Broadcast: 10.0.30.255          00001010.00000000.00011110. 11111111
Hosts/Net: 254                   Class A, Private Internet

 16.
Network:   10.0.31.0/24         00001010.00000000.00011111. 00000000
HostMin:   10.0.31.1            00001010.00000000.00011111. 00000001
HostMax:   10.0.31.254          00001010.00000000.00011111. 11111110
Broadcast: 10.0.31.255          00001010.00000000.00011111. 11111111
Hosts/Net: 254                   Class A, Private Internet


Subnets:   16
Hosts:     4064
</code></pre><p>The moral of the story is <code>Know Thy Subnetting</code>.</p>
<p>~jq1</p>

  </div></div>]]>
            </description>
            <link>https://jq1.io/posts/tiered_subnet_calculator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399302</guid>
            <pubDate>Sat, 12 Dec 2020 16:28:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buy Don't Build]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 185 (<a href="https://news.ycombinator.com/item?id=25399250">thread link</a>) | @jrott
<br/>
December 12, 2020 | https://jrott.com/posts/why-buy/ | <a href="https://web.archive.org/web/*/https://jrott.com/posts/why-buy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p>Standing up and managing a service or building a custom service is a common desire for engineers. It’s usually a major mistake, that ends up costing a ton of time and money.
The desire to build custom versions of everything seems to come from a few places:</p>

<ol>
<li>The hope that it will be cheaper to build than buy.</li>
<li>The idea that their companies process is special so industry-standard stuff will not work.</li>
<li>That they need to have total control over what the service does.</li>
<li>To avoid vendor lock-in</li>
</ol>

<p>All four of those things are less true and less important than you would think. It’s worth building when something is core to your business or provides a significant competitive advantage. Otherwise, it’s probably worth using the services that your cloud provider has or another saas. Running your own stuff has a significant operational burden and a large opportunity cost.
If you only get one thing out of this let it be: Building stuff is fun, but being paged at two in the morning about a Rube Goldberg contraption of a system to handle customer analytics isn’t.</p>

<h2 id="p-align-center-running-services-isn-t-easy-p"><p> Running services isn’t easy </p></h2>

<p>Keeping systems up in production takes time and energy. Building them isn’t where most of the expense lies. Instead, that comes with running and maintaining complicated systems.
Most enterprise systems require an engineering team to keep them running. Engineers aren’t cheap to hire and there is also additional complexity that gets introduced to keep a large number of teams coordinated. This all results in slower decision making.</p>

<p>Slower decisions happen because more teams are needed to maintain more services. These teams then need to work together and coordinate. All of a sudden, to make a change there are a million teams that need to be informed and handoffs that have to be managed. That can lead to fiefdoms for managers and way more politics, since there are now more teams and a more complicated organizational structure.</p>

<p>If you are following a DevOps model, the team that builds the service will also end up maintaining it. The more moving pieces that there are for the team to maintain, the less time that they will have for new feature development. This is painful, especially in young companies with a rapidly evolving product. Slowing down the time it takes to find product-market fit in exchange for getting to run your own stuff is a bad trade.</p>

<p>You also have to consider the level of operational excellence that exists in your organization. To put it bluntly, who do you trust more for uptime - Amazon or you? The answer, for services which you absolutely depend on for survival, might be you. Other systems though may suffer from getting less time and attention, because it becomes harder to justify the expense of keeping them up and running.</p>

<h2 id="p-align-center-vendor-lock-in-p"><p> Vendor lock-in </p></h2>

<p>At this point, you might be thinking “But I don’t want to be stuck on a vendor’s special snowflake of a system”. My counter-argument to that is there is also lock-in with internal systems. The most common version of this is The Keeper of The Spreadsheet. Now, if you’re going “what spreadsheet?”, well that’s a fair question. But it’s the one that for some important internal process that has turned into The Keeper of The Spreadsheet’s job. Most large companies have at least one spreadsheet like this. If you work at a large company, you probably realize that is a gross understatement - there can be many.</p>

<p>The Keeper(s) of The Spreadsheet will defend their process, and not want to change it at all costs, because they are worried that they’ll get fired if that process gets automated or is no longer necessary. You also see this with engineering teams, where they become the Keepers of A Database or ticketing system. All of a sudden you’ve got a system that sucks, and nobody wants to advocate for getting rid of it because their co-worker is convinced that they’ll lose their job if it happens. This also creates a political trap for the unwary when they try and fix that process.</p>

<p>Being The Keeper of The Ticketing System isn’t all that fun usually either. It’s a good way to get pigeonholed into boring work. It also means that you end up with a system that isn’t the most important thing to the business, instead of allowing an outside company to take it. That outside company is likely to specialize in solving that problem, and has built deeper expertise because of that. Unless of course you’re slightly evil and looking for awful projects to exile people to.</p>

<p>All of this makes being locked into a vendor less of a concern than most people think. There is lock-in no matter what you do. The thing that you want to avoid is giving wholesale pricing power to any vendor. This can be avoided by making sure that the key differentiators for your business are in-house.</p>

<h2 id="p-align-center-engineering-time-is-expensive-p"><p> Engineering time is expensive </p></h2>

<p>Software and systems engineers aren’t cheap to hire. As a group, we also tend to undervalue our time. Think about how often you hear “Oh I could build that in a week”, or “That’ll be easy”. With luck that’s just a comment on Reddit or hacker news, but if it’s at work then it usually turns into a total slog.</p>

<p>It’s common to express the cost of owning or maintaining a service in terms of the total cost of ownership (TCO). This is often really hard to calculate since many of the things that go into TCO aren’t tracked. The major issue that you’ll run into is that it’s not just the cost of the engineer. The metric we care about is the opportunity cost of the other things that engineers could be producing.</p>

<p>Another reason that will come up for building something custom is for unique company processes. Usually with the idea that you couldn’t customize the software to make it work, or that it’d cost more than just building it. While these can be  valid reasons to build, it’s true less often than you would think. Many processes are shared across a large number of businesses. Also, processes tend to get bloated over time. Large amounts of the custom work that is needed to match up with a business’s processes are stuff that could just not be done. For an absurd example, that happened at a company I worked with:
1. Our process for recommending articles is complicated and requires tons of joins on fuzzy data
2. We can build our own database system that is designed specially to handle this.
3. A few months of intense development go by.
4. It turns out operating this thing is hard, we don’t know why some queries take the system down, and why our customers complaining about the recommendations.</p>

<p>You really don’t want that to be you. It’s demoralizing to have built and maintained a product for something that doesn’t even work correctly. When things are getting so complicated that no existing tooling will work for it, you should be asking if all of the complexity is fundamental to the domain or if the model you are using is flawed.</p>

<h2 id="p-align-center-loss-of-focus-p"><p> Loss of focus </p></h2>

<p>A significant problem that comes from running your own version of a service is that it’s another thing that engineers have to pay attention to. There is a limit on how many things can be important. What then happens to all of the non-core services that you are running is usually some form of neglect, where they are kept in a barely good enough state.</p>

<p>The problem then with that is everyone who is working on those services is usually trying to get off of them. After all, no one wants to work on something that their boss doesn’t care about. So you end up with a ton of maneuvering since people are trying to change teams, and that increases drag.</p>

<p>Compounding this problem even further is that not revenue-generating things are frequently ignored. Yes, your CI/CD system is absolutely critical, but it’s easy for executives to not think about. This leads to a failure mode where you have a lost garden of internal tools. Whereas if you are paying someone money to do the same thing, it is their business so they keep working on it.</p>

<h2 id="p-align-center-opportunity-cost-p"><p> Opportunity cost </p></h2>

<p>In many ways, the biggest problem with building a service is opportunity cost. The reason isn’t salary but instead what else could be done. It’s basically the same problem that you see when a company is building a one-off feature to close a sale. The big difference is that engineering is doing it to themselves so there may be willful blindness to the damage being done.</p>

<p>Engineers like building things, and many like to be in control of all the buttons and knobs. Many times this is a good thing. After all, it’s how anything super cool actually gets built. The problem with it arises when that impulse exists, without a keen sense of the business effects of decisions that are made.</p>

<p>The question you should be asking is what else could be done instead of tuning your own stuff or building a new internal system. The answer is usually spending more time coming up with the correct architecture,or developing actual customer-facing features, instead of fighting fires .</p>

<p>Having large operational footprints usually results in reduced velocity and fewer changes happening per engineer. Think about the difference in speed between big companies and startups. This isn’t because startups hire smarter people, instead it’s the amount of stuff that is tied up with any change at a big company.</p>

<p>This is an area where engineering can’t just think about the software that is being built. Instead, you have to think of the health of the entire product. It’s about building stuff that is useful for the customer and letting go of things that aren’t critical. By keeping a tight focus on core projects things are built faster. There is also less craft and maintenance work that goes along with the product.</p>

<h2 id="p-align-center-summing-up-p"><p> Summing up </p></h2>

<p>None of these reasons might apply in your case. There are many good reasons to build. However, if you haven’t considered whether you can just buy something to solve a problem instead of building it yourself, you should.</p>

<p>Think about if it’s worth as being paged at 2 in the morning over. If you are willing to be paged over it, also consider if someone else can …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jrott.com/posts/why-buy/">https://jrott.com/posts/why-buy/</a></em></p>]]>
            </description>
            <link>https://jrott.com/posts/why-buy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399250</guid>
            <pubDate>Sat, 12 Dec 2020 16:22:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semgrep for Cloud Security]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25398963">thread link</a>) | @okram87
<br/>
December 12, 2020 | https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/ | <a href="https://web.archive.org/web/*/https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<ul id="markdown-toc">
<li><a href="#what-is-semgrep" id="markdown-toc-what-is-semgrep">What is Semgrep?</a></li>
<li><a href="#semgrep-for-infrastructure-as-code" id="markdown-toc-semgrep-for-infrastructure-as-code">Semgrep for Infrastructure as Code</a> <ul>
<li><a href="#terraform" id="markdown-toc-terraform">Terraform</a> <ul>
<li><a href="#unencrypted-ebs-volumes" id="markdown-toc-unencrypted-ebs-volumes">Unencrypted EBS Volumes</a></li>
<li><a href="#open-security-groups" id="markdown-toc-open-security-groups">Open Security Groups</a></li>
</ul>
</li>
<li><a href="#kubernetes" id="markdown-toc-kubernetes">Kubernetes</a></li>
</ul>
</li>
<li><a href="#conclusions" id="markdown-toc-conclusions">Conclusions</a></li>
</ul>
<p><a href="https://semgrep.dev/" target="_blank">Semgrep</a> is an emerging
static analysis tool which is getting traction within the AppSec
community. Its broad support to multiple programming languages, together with
the easiness with which is possible to create rules, makes it a
powerful tool that can help AppSec teams scaling their efforts into preventing
complete classes of vulnerabilities from their codebases.</p>
<p>But what about cloud security? In the era of Infrastructure as Code,
where tools like Terraform, CloudFormation, Pulumi (and many others) are used
to provision infrastructure from (de-facto) source code, can we apply the
same approach to eradicate classes of cloud-related vulnerabilities from a
codebase?</p>

<p>I decided to spend part of my weekend experimenting with this,
and to get an idea of what Semgrep can provide to cloud/platform security teams.</p>

<p>Before jumping into the details, it is worth explaining what Semgrep
actually is.
As per their <a href="https://github.com/returntocorp/semgrep" target="_blank">website</a>, Semgrep is:</p>
<blockquote>
<p>A fast, open-source, static analysis tool that excels at expressing code standards — without complicated queries — and surfacing bugs early at editor, commit, and CI time.</p>
<p>Precise rules look like the code you’re searching; no more traversing abstract syntax trees or wrestling with regexes.</p>
<p>The Semgrep Registry has 1,000+ rules written by the Semgrep community covering security, correctness, and performance bugs. No need to DIY unless you want to.</p>
</blockquote>
<p>At a high level, Semgrep leverages Abstract Syntax Trees (ASTs)
to build a model of the code you are analyzing. Unlike other tools based on ASTs,
though, Semgrep lowers the entry bar by abstracting away the AST syntax itself.</p>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_ast.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_ast.jpg" alt="Code as ASTs">
</a>
<figcaption>Code as ASTs. Image courtesy of <a href="https://docs.google.com/presentation/d/1j9uqQsMlePEuSzOD6E4Th2IYY4Hi7dl5XYbHdSDMkrc/edit#slide=id.g787344da8e_0_1645" target="_blank">Clint Gibler</a>.</figcaption>
</figure>
<p>Out of the box, Semgrep supports mainstream programming languages
(e.g., Go, Java, Python, Ruby, Javascript, etc.) and has a library of
<a href="https://github.com/returntocorp/semgrep-rules" target="_blank">open source rules</a>
ready to be re-used.</p>
<p>Explaining how to use Semgrep is out of scope for this blog post,
but the <a href="https://semgrep.dev/docs/" target="_blank">official documentation</a>
is really well made, and the
<a href="https://semgrep.dev/editor" target="_blank">online playground</a>
is an excellent space where to start playing with it
(without having to spend time installing anything).</p>
<hr>

<p>As briefly mentioned earlier, the benefit that Semgrep can bring to AppSec teams
is obvious (and if you are still not convinced, I recommend you to watch this
<a href="https://docs.google.com/presentation/d/1j9uqQsMlePEuSzOD6E4Th2IYY4Hi7dl5XYbHdSDMkrc/" target="_blank">this presentation</a> from <a href="https://twitter.com/clintgibler/" target="_blank">Clint Gibler</a>).</p>
<p>What I was curious to try was how well the same approach could fit a codebase
made of Terraform (HCL) and YAML files, as those languages are not currently
supported by Semgrep. Hence, I relied on its <code>Generic Pattern Matching</code> engine.</p>
<h2 id="terraform">Terraform</h2>
<p>The official <a href="https://github.com/returntocorp/semgrep-rules/tree/develop/terraform/lang/security" target="_blank">semgrep-rules</a> repository already contains a folder dedicated to Terraform.</p>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_terraform_rules.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_terraform_rules.jpg" alt="Open source Terraform rules">
</a>
<figcaption>Open source Terraform rules.</figcaption>
</figure>
<p>Within this folder, we can see 7 rules already made open source, mainly focusing
on <a href="https://github.com/bridgecrewio/terragoat" target="_blank">Terragoat</a>
scenarios and S3 buckets.</p>
<h3 id="unencrypted-ebs-volumes">Unencrypted EBS Volumes</h3>
<p>Let’s start wrapping our head around it by picking the <code>unencrypted-ebs-volume</code> rule.
In the repo we can see a sample <a href="https://github.com/returntocorp/semgrep-rules/blob/develop/terraform/lang/security/ebs-unencrypted-volume.tf" target="_blank">Terraform file</a> (shown here below):</p>
<figure><pre><code data-lang="terraform"><span>resource</span> <span>"aws_ebs_volume"</span> <span>"web_host_storage"</span> <span>{</span>
  <span>availability_zone</span> <span>=</span> <span>"ap-southeast-2"</span>
  <span>encrypted</span>         <span>=</span> <span>false</span>
  <span>size</span> <span>=</span> <span>1</span>
  <span># ruleid: unencrypted-ebs-volume</span>
  <span>tags</span> <span>=</span> <span>{</span>
    <span>Name</span> <span>=</span> <span>"abcd-ebs"</span>
  <span>}</span>
<span>}</span></code></pre></figure>
<p>Quite straightforward, with an <code>aws_ebs_volume</code> resource declaring an EBS volume
with encryption disabled (as it can bee seen from <code>encrypted = false</code>).</p>
<p>So what we want to <code>grep</code> here is for an occurrence of <code>encrypted = false</code>
(or the lack of <code>encrypted = true</code>), as shown in the
<a href="https://github.com/returntocorp/semgrep-rules/blob/develop/terraform/lang/security/ebs-unencrypted-volume.yaml" target="_blank">corresponding rule</a>:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>unencrypted-ebs-volume</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern-either</span><span>:</span>
      <span>-</span> <span>pattern</span><span>:</span> <span>|</span>
          <span>{...}</span>
    <span>-</span> <span>pattern-not-inside</span><span>:</span> <span>|</span>
        <span>resource "aws_ebs_volume" "..." {... encrypted=true ...}</span>
    <span>-</span> <span>pattern-inside</span><span>:</span> <span>|</span>
        <span>resource "aws_ebs_volume" "..." {...}</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.tf'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>An EBS volume is configured without encryption enabled.</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ZWrA/" target="_blank">https://semgrep.dev/s/ZWrA/</a>.</p>
<h3 id="open-security-groups">Open Security Groups</h3>
<p>As a second test, I wanted to create my first Semgrep rule to detect
a Security Group open to the world (<code>0.0.0.0/0</code>), like the one below:</p>
<figure><pre><code data-lang="terraform"><span>resource</span> <span>"aws_security_group"</span> <span>"allow_tls"</span> <span>{</span>
  <span>name</span>        <span>=</span> <span>"allow_tls"</span>
  <span>description</span> <span>=</span> <span>"Allow TLS inbound traffic"</span>
  <span>vpc_id</span>      <span>=</span> <span>aws_vpc</span><span>.</span><span>main</span><span>.</span><span>id</span>

  <span>ingress</span> <span>{</span>
    <span>description</span> <span>=</span> <span>"TLS from VPC"</span>
    <span>from_port</span>   <span>=</span> <span>443</span>
    <span>to_port</span>     <span>=</span> <span>443</span>
    <span>protocol</span>    <span>=</span> <span>"tcp"</span>
    <span>cidr_blocks</span> <span>=</span> <span>[</span><span>"10.0.1.0/24"</span><span>,</span> <span>"0.0.0.0/0"</span><span>]</span>
  <span>}</span>

  <span>tags</span> <span>=</span> <span>{</span>
    <span>Name</span> <span>=</span> <span>"allow_tls"</span>
  <span>}</span>
<span>}</span></code></pre></figure>
<p>What we want to <code>grep</code> here is any occurrence of <code>0.0.0.0/0</code> within an <code>ingress</code> block:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>open-security-group</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern-inside</span><span>:</span> <span>ingress { ... }</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>"</span><span>0.0.0.0/0"</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.tf'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>A security group is allowing inbound traffic from the public internet (0.0.0.0/0).</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_rule_sg.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_rule_sg.jpg" alt="open-security-group rule">
</a>
<figcaption>open-security-group rule.</figcaption>
</figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ne51/" target="_blank">https://semgrep.dev/s/ne51/</a>.</p>
<p>Of course this is a vary basic case, where the offending string (<code>0.0.0.0/0</code>)
is directly hardcoded within the security group definition. The rule
will have to be extended if we want to take into account cases where
the CIDR can be specified, for example, via variables.</p>
<h2 id="kubernetes">Kubernetes</h2>
<p>Next, I wanted to create a rule more focused on Kubernetes (or, more precisely, YAML files).</p>
<p>Let’s take as a sample the case where you might want to enforce all your
Kubernetes Ingresses to be private, removing all the <code>public</code> ones:</p>
<figure><pre><code data-lang="yaml"><span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>test-ingress</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.class</span><span>:</span> <span>public</span>
<span>spec</span><span>:</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>/testpath</span>
        <span>pathType</span><span>:</span> <span>Prefix</span>
        <span>backend</span><span>:</span>
          <span>service</span><span>:</span>
            <span>name</span><span>:</span> <span>test</span>
            <span>port</span><span>:</span>
              <span>number</span><span>:</span> <span>80</span></code></pre></figure>
<p>In this example, we want to <code>grep</code> for the <code>kubernetes.io/ingress.class</code>
annotation, and ensure it has the approved value of <code>nginx-internal</code>:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>public-ingress</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>kubernetes.io/ingress.class</span>
    <span>-</span> <span>pattern-not-inside</span><span>:</span> <span>|</span>
        <span>kubernetes.io/ingress.class: nginx-internal</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.yaml'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>An Ingress has been made public.</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ErGE/" target="_blank">https://semgrep.dev/s/ErGE/</a>.</p>
<hr>

<p>I have to say the extensibility, and simple syntax, of Semgrep are making it
very promising for cloud security teams as well.
In a few hours, thanks to the official documentation and Playground, I was able
to go from absolute 0 to writing my first rules.</p>
<p>The main challenge I can think of at the moment is: how much does Semgrep
overlap with <a href="https://github.com/open-policy-agent/conftest" target="_blank">OPA Conftest</a>?
Although Conftest has been created with cloud resources in mind,
and benefits from the sinergies
with the rest of the OPA offering (like <a href="https://github.com/open-policy-agent/gatekeeper" target="_blank">Gatekeeper</a>), basically everyone in the
industry at some point complained about how cumbersome the <a href="https://www.openpolicyagent.org/docs/latest/policy-language/" target="_blank">Rego</a> language is.
In my opinion, this could be a defining factor that might help expand the adotpion
of Semgrep from platform teams.</p>
<p>I’m quite curious to hear other people’s opinions on this, so please
feel free to reach out to me on <a href="https://twitter.com/lancinimarco" target="_blank">Twitter</a>.</p>
</div></div>]]>
            </description>
            <link>https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398963</guid>
            <pubDate>Sat, 12 Dec 2020 15:51:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paying the Privacy Tax]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398501">thread link</a>) | @reimbar
<br/>
December 12, 2020 | https://www.getrevue.co/profile/themarkup/issues/paying-the-privacy-tax-298830 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/themarkup/issues/paying-the-privacy-tax-298830">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/themarkup/issues/paying-the-privacy-tax-298830</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398501</guid>
            <pubDate>Sat, 12 Dec 2020 14:45:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, engineers don't suck at time estimates]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398344">thread link</a>) | @kiyanwang
<br/>
December 12, 2020 | https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/ | <a href="https://web.archive.org/web/*/https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><p>No, engineers don’t suck at time estimates - and generally speaking humans are better estimators than what most people believe. This seems rather surprising given all we’ve heard about the problems of bad time estimations, projects going overboard, etc and of course, your personal experience with software time estimates. But if people are really bad at estimation, how does that fit with our obvious evolutionary need to make quick decisions based on partial data? if we can’t estimate well how did we decide if a gap is wide enough to jump over, if an animal is worth the hunt, if a certain area is more likely to have water and shade? Without estimation skills we wouldn’t survive. So what’s going on?</p><p>One obvious explanation is that we are only good at estimating physical things such as sizes and distances. However, this does not seem likely given the large number of non-physical decisions we needed to make, like selecting a mate.
Another, more likely explanation is that the estimates are good, but the interpretation and usage of the estimates is flawed. In other (slightly cynical) words: the engineers are good at estimating, it’s the project managers who suck at using the estimates.</p><p>Let me explain.</p><p>“your estimate was wrong” - is something i’ve heard many times. But this sentence doesn’t make any sense… after all, an estimate is by definition not exact; in fact, if the results would always agree with estimates foul play would be immedialy suspected. If I estimated one day and the actual time was 1.5 days, was I “wrong”? most people would say I wasn’t. But if if the actual time was 20 days most people would argue I was wrong. Somewhere between one and 20 days there is an implicit “reasonable error” threshold we never discussed! I never gave an error margin for my estimate, did I?</p><p>Since we don’t expect an estimate to be an exact guess of the actual value, what do we expect from an estimate? When we make decisions based on estimates, we can only be right or wrong in our decision, you can’t be “a lot more right”. We need to guess a value beyond a certain threshold and within a certain tolerance, with high probability of being right because that our lives depend on that gap being just short enough for us to jump over. Decisions are almost always non-linear like that and it should not be surprising given the nature of knowledge and learning. We take in examples and extrapolate patterns and behaviours. Which means we are dealing with groups, and probability distributions. This may be surprising at first, because when you are estimating this one <em>particular</em> job, you don’t think of a distribution of a million other <em>different</em> jobs. An estimate is predicting the future in which we see the actual value.
</p><div><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><p><img itemprop="thumbnail" src="https://blog.nukemberg.com/img/time-estimate.jpg" alt="/img/time-estimate.jpg"></p><a href="https://blog.nukemberg.com/img/time-estimate.jpg" itemprop="contentUrl"></a></figure></div><p>What we need to know, is that in a certain number of futures, say 90% of them, a value won’t be over or under a certain threshold. Or phrased mathematically, that the 90th percentile of the distribution of futures will be over (or under) a certain number. An estimate is a percentile! but which percentile? is it the median? the 99th?
For software time estimates it has been <a href="https://erikbern.com/2019/04/15/why-software-projects-take-longer-than-you-think-a-statistical-model.html">observed to be the median</a> (50th percentile), meaning to be right about half the times. Is this inherent? Estimates can desmonstrably be calibrated to higher percentiles by as little as <a href="https://www.tonym-v.com/blog/2019/10/2/improve-your-estimations-with-the-equivalent-bet-test">brief emotional self manipulation</a>; You could easily estimate the 90th percentile of many things - just read <a href="https://www.amazon.com/How-Measure-Anything-Intangibles-Business-ebook/dp/B00INUYS2U">How to measure anything</a>.</p><p>Usally when I tell this to people, they often respond with “we’ll train to estimate the average”. Sadly, this is not possible. The mean is a statistically “unstable” or “unrobust” aggregate, where as percentiles are “stable” or “robust”. Consider a group of task completion times [73, 67, 12, 38, 18, 11, 42]. The mean is ~37.29 and the median is pretty close, 38. But as soon as we get another measurement, say 293, the mean changes significantly to 69.25 while the median changes only slightly to 42. The mean is sensitive to outliers, and the more skewed and high variance the distribution the less robust and stable it will be.</p><p>Having estimated tasks, what do we do with them? We sum them up.</p><p>Either for project budget or for by enqueuing with the next tasks, we sum them. But wait, we know that percentiles are not additive! how can this ever work? it never does. Summing up percentiles compounds errors and with skewed distributions, and in particular heavy tailed distributions, the errors are very large. Let’s have a look at what a task completion time distribution would look like:</p><div><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><p><img itemprop="thumbnail" src="https://blog.nukemberg.com/img/task-time-distribution.png" alt="/img/task-time-distribution.png"></p><a href="https://blog.nukemberg.com/img/task-time-distribution.png" itemprop="contentUrl"></a></figure></div><p>A task has some minimum time it has to take, but beyond that it can pretty much take as long as inifinity. We all know from experience, that when things get out of control they go wayyyy out of control. Once you hit a rare bug, you might be chasing a wild goose for two months. That 10% over the estimate might be a day late or a year, the higher percentile you pick the more extreme the errors relatively.</p><p>To be honest, it’s old news; This has been known for a long time. Percentile based project predictions have been done as early as World War II, perhaps even before that - yet they remain fairly unknown in the industry. Not only are we ignorant of proven methods, we invent new ones which are outright harmful. Remember that burn down chart? the <em>backlog</em> is nothing more than a sum of time estimates! And every two weeks, sitting in the famous sprint retrospective people work to calibrate their estimates to the random walk sum of task completion times on the burndown chart. How do you calibrate a percentile to a sum? If the distribution is something like a log-normal distribution, the random walk sum will converge to the mean, and the median is relatively close to the mean - which is summable, and both are pretty stable. So by repeatedly calibrating estimates to the running-sum of task completion times (the backlog) you will converge close to the median. Now go tell your project manager there is a 50% chance of their project running late, anywhere between a day and eternity, and see how they respond. A 50% chance of uncapped delay is a useless estimate.</p><p><strong>Scrum is a training method for useless time estimates</strong>. It actively destroys your ability to manage your project.</p><p>Don’t get me wrong, I’m not against Agile; The spirit of Agile, some of the methods and ceremonies of Scrum have value. But Scrum <em>as a system</em> is actively harmful, especially in high variance situations where the work is far from the nice log-normal distribution. If you <a href="https://blog.nukemberg.com/post/the-burndown-chart-fallacy/">optimize for an arbitrary metric</a>, you will get arbitrary results. In ops/SRE and pure research many people have intuitive sense that Scrum and traditional project management are wrong, although they can’t quite articulate why. The reasons become very clear when we consider what happens to sum based project management methods if the task distribution becomes heavy tailed. A task that is one week late is likely to take <em>at least</em> one more week - is a common thumb rule in such domains; This is called a “Power law” and can be modeled by the famous Pareto distribution. The thing about the Pareto distribution is that its mean does not converge! In other words, using sum based planning methods with such distributions is equivalent to managing by rolling dice. A little worse actually, as dice are a cheap method of generating random numbers where as time estimates are intrusive and sometimes expensive. This isn’t a problem unique to Scrum, nor does it originate from it. The problem is the assumption of determinism and accuracy which is the prevaling “machine age” mindset. Pretty much all of the common project management tools have the same issue - have a look at a Gantt chart, it has no probability intervals or error ranges. They are all worse than useless. It shouldn’t be a surprise that despite people being bad at estimating large tasks naive estimates are reliably more accurate than project management tools.</p><p>Recognizing the probabilistic nature of the world is key. Probability isn’t a tool for making predictions, it is a tool for quantifiying uncertainty. Instead of managing resources (which are usually highly certain) we should be managing uncertainty, with probabilistic methods appropriate for the task. With this mindset, the first thing to do is understand the business context and the distributions involed: are you in a low or high variation domain? Industrial methods which aim to improve throughput and efficiency all assume low variance, sometimes actively force low variance by getting rid of outliers; this isn’t necessarily possible in your business context. Industrial methods are good when used in context, but horrible when used in high variability and unpredictable domains. For those we have other methods, which emphasize low latency and rapid adaptation. Instead of Scrum, you could try:</p><ul><li><a href="https://www.joelonsoftware.com/2007/10/26/evidence-based-scheduling/">Monte-Carlo simulations based on time estimates</a></li><li><a href="https://basecamp.com/shapeup/2.1-chapter-07">Time boxing and bets</a></li><li>Latency optimizing methods which dispense with time estimates, like Kanban</li></ul><p>I’ve listed the methods above in order of rising uncertainty, Monte-Carlo simulations or time boxing would probably be easiest to start with. The biggest obstacle in implementing these is convincing managers that “predictability” isn’t so important as they imagine. For high variation domains it’s nothing more than a fantasy anyway.</p><p>So there you have it: people don’t suck at estimation. They suck at management 🤷</p><hr></article></div></div></div></div>]]>
            </description>
            <link>https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398344</guid>
            <pubDate>Sat, 12 Dec 2020 14:18:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem Today Is Not Tribalism but Its Absence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25398325">thread link</a>) | @blindm
<br/>
December 12, 2020 | https://www.discoursemagazine.com/culture-and-society/2020/05/20/the-problem-today-is-not-tribalism-but-its-absence/ | <a href="https://web.archive.org/web/*/https://www.discoursemagazine.com/culture-and-society/2020/05/20/the-problem-today-is-not-tribalism-but-its-absence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                <p>The dirtiest word in US politics these days is tribalism. For pundits and policymakers, tribalism is blind group loyalty that is tearing our country apart. Mindless tribal affiliations, they say, drive our polarizations and prevent us from finding common ground. The greatest danger of tribalism, we are told, is that it morphs political leanings into social identities, creating political morass, gridlock, and decay.</p>
<p>But these pundits and policymakers have the story backwards. Indeed, we have enormous political challenges because we no longer value or know how to live like tribes: to make rules together, to develop consensus, to work out difficult problems without calling for outside help. In fact, tribes—real tribes—provide a great deal of meaning, community, and connection. Let me take this a step further: if American society were to adopt some “tribal” characteristics, we would all be a lot better off.</p>
<p>During the medieval period, Arab historian Ibn Khaldun (b. 1332) developed a sophisticated theory of tribal politics that has enormous resonance today. In his treatise&nbsp;<em>Muqaddimah</em>&nbsp;he wrote that tribal societies are defined by their social cohesion and a sense of group interconnectedness. This solidarity brings groups together in ways that are crucial for the creation of public goods. The secret to success was what he termed&nbsp;<em>asabiyya</em>—or group feeling. Tribes that had strong&nbsp;<em>asabiyya&nbsp;</em>could build strong empires, forge strong armies, and develop effective governance structures. Leaders who could not cultivate this group feeling among members struggled to find legitimacy, and ultimately collapsed.</p>
<p><em>Asabiyya</em>&nbsp;is a kind of social capital. It is the glue that holds a society together. It is central to the success and failure of tribal governance structures. Yet, we would never know that if we looked at how tribes are described in modern parlance. Contemporary political “tribalism” is just the opposite of all of this. It is an ephemeral factionalism manifested in 280-character tweets or by an endless cycle of cable news pundits.</p>
<p>The problem is compounded by the abuse of the term “tribes.” Today, “tribalism” has become a basket category for our nasty state of affairs; that is, the things we believe cause our increased polarization. In her popular recent book&nbsp;<a href="https://www.penguinrandomhouse.com/books/535371/political-tribes-by-amy-chua/"><em>Political Tribes</em></a>, Amy Chua decries political tribalism as a source of political decay but never defines what tribes are. Similarly,&nbsp;<a href="https://journals.sagepub.com/doi/10.1177/0963721419862289">psychologists</a>&nbsp;argue that so-called tribalism is “a natural and nearly ineradicable form of human cognition and that no group—not even one’s own—is immune.” For writers like George Packer, tribes are&nbsp;<a href="https://www.newyorker.com/news/daily-comment/a-new-report-offers-insights-into-tribalism-in-the-age-of-trump">badges of identity</a>, not of ideology or thought.</p>
<h3>Tribes Protect and Provide</h3>
<p>Anthropologists view tribes differently, seeing them as foundational social units that do a wide range of things. At minimum they are an identity marker. At maximum they provide public goods, such as dispute resolution, self-defense, and even small-scale infrastructure. Anthropologist&nbsp;<a href="https://anthrosource.onlinelibrary.wiley.com/doi/abs/10.1525/aa.1977.79.2.02a00090">Emanuel Marx</a>&nbsp;described tribes as “units of subsistence.” There is huge variation in the way tribes work all over the world, and it is dangerous to generalize, but it in broad strokes tribes are lineage structures that can protect and provide. They even nurture.</p>
<p>No doubt, there are ugly sides to tribes in blood feuds and seemingly internecine conflicts. Yet, as political scientists&nbsp;<a href="https://doi.org/10.1017/S0003055403000534">James Fearon and David Laitin</a>&nbsp;pointed out almost two decades ago, groups with differences exist side by side all around the world but very few of them engage in violent conflict. In other words, conflict among groups with strong affinities is an aberration rather than the norm.</p>
<p>By contrast, for pundits and policymakers the idea of tribe has provided a conceptual hook that helps them explain the loss of community we see around the world. This idea has become an empty vessel for something larger. Indeed, I would argue that what they describe as tribalism is actually its absence. They describe a derisive politics that is a yearning for group feeling. It is a yearning for&nbsp;<em>asabiyya</em>.</p>
<p>In my wanderings around dozens of Afghan villages, I found something unexpected: the death of tribal and other forms of customary authority was greatly exaggerated. Instead, communities worked quickly to resurrect customary structures out of the ashes of conflict. Why? Because they provided the kinds of public goods and services that were of value to people when they could not rely on a state that was unwilling or unable to help.</p>
<p>Not only did communities resurrect tribal and other forms of customary governance structures, they created new institutions that would encompass diversity. This means they updated technologies of custom to help them solve the most challenging of modern conflicts.</p>
<p>For years, American strategists in Afghanistan ignored the positive role tribes and customary authorities could play in politics as they fixated on strengthening top-down government institutions. Several years into the war, young soldiers posted to remote locations started demanding change. Unlike the designers of the intervention who sat in Washington, Brussels, or Kabul, these boots on the ground faced life or death every day. What many of them found was that maintaining good relations with community leaders was key to their survival. On message boards and blogs, they argued the United States was losing in Afghanistan because it was not working with customary structures.</p>
<p>One of these voices, Maj. James Gant wrote a famous white paper, “<a href="https://smallwarsjournal.com/blog/one-tribe-at-a-time">One Tribe at a Time</a>,” where he argued that tribal systems in Afghanistan were the key to victory because they protected residents from abuses by the Taliban and the state. Gant was no anthropologist and there is much he got wrong about the social order he thought he was describing, but he was onto something: the power of community and local self-governance in rural Afghanistan.</p>
<p>Gant’s perspective was important because it contrasted with the standard script, which stated that Afghanistan required a strong state because the tribes had withered away due to decades of conflict. According to conventional wisdom, the collapse of the tribal system led directly to the&nbsp;<a href="https://yalebooks.yale.edu/book/9780300095197/fragmentation-afghanistan">fragmentation of the state</a>; it also&nbsp;<a href="https://yalebooks.yale.edu/book/9780300163681/taliban">created a vacuum</a>&nbsp;that religious extremists, like the Taliban, could fill.</p>
<h3>A Sense of Community and Belonging</h3>
<p>In my book&nbsp;<a href="https://www.cambridge.org/core/books/informal-order-and-the-state-in-afghanistan/5B0FB8D4B407988910AE737DB46C0E66"><em>Informal Order and the State in Afghanistan</em></a><em>,&nbsp;</em>I found that customary leaders were able to build legitimacy because they cultivated a sense of group belonging. They did this by treating most people with dignity, fairness, and respect—even those with whom they disagreed. A far cry from the tribalism frequently weaponized in the US.</p>
<p>The real danger facing the United States now is not tribalism but factionalism. America’s Founders warned us against this even before the Constitution was signed. In&nbsp;<a href="https://avalon.law.yale.edu/18th_century/fed10.asp">Federalist 10</a>, James Madison famously wrote of these dangers. They have always been here; they are not new. The key is to have leaders who can help us overcome divisiveness and rely on one another, just as leaders within tribes must build consensus.</p>
<p>In Afghanistan and beyond, tribal structures are not the primary driver of division. It is the politicians, warlords, and insurgents feeding off donor largesse whose thirst for state power have undermined a sense of common meaning—<em>asabiyya</em>.</p>
<p>In the US, it is not tribalism driving our profane politics, but its absence. Without a strong sense of&nbsp;<em>asabiyya</em>—of group feeling that we are all in this together—we are going nowhere fast. Khaldun’s theory of tribal politics, while written centuries ago, is a powerful parable. It shows how the breakdown of meaningful social relationships leads to political decay.</p>
<p>What society has lost is<em>&nbsp;asabiyya</em>—the glue that holds us together. Tribes can provide us this glue, a sense of community and belonging. Certainly, tribes can exclude, but this is not their&nbsp;<em>raison d’être</em>, which is to provide, to give meaning, and to protect.</p>
					</div></div>]]>
            </description>
            <link>https://www.discoursemagazine.com/culture-and-society/2020/05/20/the-problem-today-is-not-tribalism-but-its-absence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398325</guid>
            <pubDate>Sat, 12 Dec 2020 14:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Badges of kindness for your website footers, repos, and more]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25398272">thread link</a>) | @Nathanael
<br/>
December 12, 2020 | https://kindspeech.org/badges/ | <a href="https://web.archive.org/web/*/https://kindspeech.org/badges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article class="page" id="post-190">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Badges are a discrete and simple way to offer kindness:</p>



<figure><img src="https://api.kindspeech.org/v1/badge" alt=""></figure>



<p>They display a changing, short, kind message, which aspires to make the recipient feel good about who they are and what they already have.</p>



<h2>How to Use Them</h2>



<p>They can easily be embedded online, any place where an image can be displayed from a URL:</p>



<pre><code>https://api.kindspeech.org/v1/badge</code></pre>



<p>The background color can also be customized:</p>



<figure><img src="https://api.kindspeech.org/v1/badge?color=plum" alt=""></figure>



<pre><code>https://api.kindspeech.org/v1/badge?color=plum</code></pre>



<p>For detailed technical information see <a href="https://api.kindspeech.org/">the API documentation.</a></p>



<h4>Markdown</h4>



<pre><code>![](https://api.kindspeech.org/v1/badge)</code></pre>



<h4>HTML</h4>



<pre><code>&lt;img src="https://api.kindspeech.org/v1/badge" /&gt;</code></pre>



<h2>Where to Use Them</h2>



<p>Just a few suggestions! The rest is entirely up to you. 😄</p>



<h4>Website Footers</h4>



<p>A little surprise for those who reach the bottom of your pages.</p>



<figure><img src="https://api.kindspeech.org/v1/badge?color=1e8296" alt=""></figure>



<h4>GitHub Repository Documentation</h4>



<p>Many GitHub repositories use badges to display dynamic information about the state of their project. The Kind Speech badges were designed to have a consistent look and feel so that you can share some love along with the state of your build:</p>



<p>
<img src="https://img.shields.io/badge/contributors-9000-green">
<img src="https://img.shields.io/badge/build-passing-green">
<img src="https://api.kindspeech.org/v1/badge">
</p>



<h4>Email Signatures</h4>



<p>Share some love with every email you send out! Note that some email providers block outside images by default, so recipients may need to explicitly allow the image to load before they can see it. 🤷</p>



<blockquote><p>Dear Doug,</p><p>I was so glad to meet you from your wonderful email. It was interesting to know about your fish and how you take care of them.</p><p>You’re special — just because you’re you.</p><p>Your television friend,</p><cite>—<br>Mister Rogers<p><img src="https://api.kindspeech.org/v1/badge?color=dc5830"></p></cite></blockquote>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://kindspeech.org/badges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398272</guid>
            <pubDate>Sat, 12 Dec 2020 14:04:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Show the current application's shortcuts on Windows, Linux and macOS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25398232">thread link</a>) | @tkainrad
<br/>
December 12, 2020 | https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>Looking up keyboard shortcuts on the web takes you out of the current context and breaks your workflow. That’s why, <a href="https://tkainrad.dev/posts/setting-up-linux-workstation/">as a Linux user</a>, I have always been a bit envious of macOS users, who had access to tools that could instantly show the current application’s shortcuts, such as <a href="https://www.mediaatelier.com/CheatSheet/">CheatSheet</a>, and <a href="https://github.com/amiechen/pretzel">Pretzel</a>.</p>
<p>On Windows and Linux, there was no such thing. You had to find shortcut information in the software’s documentation and hope that it was searchable. Or even worse, suffer a massive context switch and google for the shortcuts, until now. KeyCombiner Desktop is free to use and can show the active application’s shortcuts on Windows, Linux, and macOS.</p>
<p>Suppose you are on macOS and already use one of the existing solutions. In that case, you might still want to read further because KeyCombiner goes far beyond looking up the active application’s shortcuts.</p>

<p>If a picture says more than 1000 words, an animation will speak for itself:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/lookup-three-apps2.gif" alt="Instant shortcut lookup for three example applications."> <figcaption>
<p>Instant shortcut lookup for three example applications.</p>
</figcaption>
</figure>
<p>Upon pressing the global trigger, the lookup will appear with a search field in focus, where you can start to type right away. The default trigger is <kbd>super</kbd>+<kbd>shift</kbd>+<kbd>c</kbd> on Windows and Linux, and <kbd>cmd</kbd>+<kbd>shift</kbd>+<kbd>k</kbd> on macOS. This can be configured, I use <kbd>super</kbd>+<kbd>c</kbd> on Linux.</p>
<p>The search terms will be applied to the shortcut description, the key binding, and some hidden fields like the shortcut category. Do you want to search for all file-related bindings that use <kbd>Ctrl</kbd>? Type something like <code>file ctrl</code> and you have your answer.</p>
<p>The lookup window disappears whenever you click outside of it, when you press <kbd>esc</kbd>, or when you switch to another application via <kbd>cmd</kbd>/<kbd>ctrl</kbd>+<kbd>tab</kbd>. If you close via <kbd>esc</kbd>, the search term will be cleared. If you use <kbd>cmd</kbd>/<kbd>ctrl</kbd>+<kbd>tab</kbd>, you can switch back to the active application without losing the cursor position.</p>

<p>If you carefully watched the animation above, you might have noticed that the rows are grouped. The first group has the prefix <code>Active:</code> and is highlighted with a blue background. This group shows the shortcuts for the active application. Everything that is shown below this group is from the user’s personal shortcut and command collections.</p>
<p>To explain what these are, I have to provide some background. KeyCombiner is an application to organize, learn, and practice keyboard shortcuts. A core idea is to learn precisely the shortcuts you need. The only way to achieve this is to choose them yourself, which is done by creating personal collections of shortcuts and text snippets. I like to compare this concept to how you build playlists in music software. Instead of browsing your favorite artists’ albums, KeyCombiner allows you to browse shortcut collections of your favorite applications. Instead of adding songs to your playlists, you can add keyboard shortcuts and text snippets to your personal collections.</p>
<p>The instant lookup of KeyCombiner Desktop profits immensely from these collection building features, and vice-versa. Having instant access to your collections makes them a lot more valuable. In short, these two features complete each other.</p>
<p>The instant lookup works offline. Your personal collections are downloaded only on application startup. If you modified your collections while KeyCombiner Desktop was running, you may reload the lookup via (<kbd>Ctrl</kbd>/<kbd>Cmd</kbd>+<kbd>R</kbd>).</p>
<p>I will try to illustrate this with my personal experience. Currently, I have 10 personal KeyCombiner collections. My largest one contains more or less all shortcuts that I already knew when I started to use KeyCombiner. This collection is publicly accessible via this <a href="https://keycombiner.com/collecting/collections/shared/89e47af4-0f2e-4d5d-98fa-6966bc7453cc/">shareable link</a>. Then, I did a <a href="https://tkainrad.dev/posts/how-i-learned-50-new-keyboard-shortcuts-in-42-minutes/">blog post challenge to learn 50 new keyboard shortcuts as fast as possible</a>. More recently, I <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">learned <em>all</em> VSCode keyboard shortcuts</a>, which evolved my developing habits and added another collection with 151 shortcuts to my repertoire.
Add to that a few smaller collections I used for learning the shortcuts of Chrome DevTools, Nautilus, Spotify, and Vimium. Having instant access to all of these shortcuts without leaving my current context feels like a superpower, even though I admit that some of those superpowers you see in movies look even more powerful.</p>
<p>My most recent new use case is to look up regular expressions. There is an <a href="https://tkainrad.dev/posts/automatically-add-kbd-tags-with-a-single-regex/">article</a> on how to automatically add HTML &lt;kbd&gt;-tags to any text via a single regex replace operation. I use this for all of my blog posts, all &lt;kbd&gt; tags you see in this post are added this way. However, it wouldn’t be so convenient if I couldn’t instantly look up and copy-paste the required regular expression:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/lookup-regex.gif" alt="The lookup also shows shortcuts and text snippets from your personal collections."> <figcaption>
<p>The lookup also shows shortcuts and text snippets from your personal collections.</p>
</figcaption>
</figure>
<p>KeyCombiner’s instant lookup is a cheatsheet of sorts. But it is context-aware, searchable, and you can expand it quickly by importing from public or shared collections. It is also friendlier to the environment than printing out PDFs and hanging them next to your desk.</p>

<p>There is a very boring answer to this question: By maintaining an extensive public database of keyboard shortcuts. You might have noticed from reading this post that I am quite excited about Keycombiner. That’s why I spend considerable time to parse the documentation pages of software tools for their keyboard shortcuts. It’s not as dull as it sounds like; creative use of regular expressions makes it quite fun. Don’t judge me; everyone has a weird hobby.</p>
<p>You can browse the database at <a href="https://keycombiner.com/collections/">https://keycombiner.com/collections/</a>.<br>
The instant lookup works for all desktop-based applications that are listed there. In particular, it should work for all apps that an average software developer uses (VSCode, JetBrains IDEs, Vim, Eclipse, Chrome, Firefox, Safari, Nautilus, Finder, Notion, Slack, Explorer, Terminal, iTerm2, Obsidian,…). This list is growing fast, and I am happy to take suggestions.</p>
<p>One downside of this approach is that KeyCombiner can only show the default bindings for the active application. If you have changed these bindings, that’s not ideal. Fortunately, If you went through the trouble of changing a binding, you usually won’t need to look it up. In any case, you can add the customized binding to a personal collection, and the lookup will show it as explained above.</p>
<p>Existing tools for macOS use a different approach. They rely on a macOS API to retrieve menu keyboard shortcuts for the current application. This has its advantages and disadvantages. The great thing about it is that it works automatically for all applications that have a menu. On the other hand, applications
don’t necessarily register all of their shortcuts as menu shortcuts.</p>



<p>Simply go to <a href="https://keycombiner.com/desktop/">https://keycombiner.com/desktop/</a> and grab the installer for your system. On macOS, you need to grant some permissions for the instant lookup to work. Please refer to the bottom of the linked page for instructions on how to do that.</p>
<p>KeyCombiner is a SaaS with a generous free tier. <strong>All features described in this article are entirely free to use.</strong> If you use KeyCombiner a lot, please consider upgrading to a Pro subscription to get access to additional features and to support hosting and development efforts.</p>


<p>KeyCombiner can do a lot more things than what’s described in this post. However, the instant lookup has quickly become one of my favorite features. Admittedly, I don’t use KeyCombiner every day for learning shortcuts. Usually, after I have <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">mastered all shortcuts</a> of a new collection, it takes a couple of days or even weeks until I get back to frequent practice.</p>
<p>In contrast, I use the instant lookup <em>all the time</em>. If I am on a different computer without KeyCombiner installed, I notice that something is missing after a couple of minutes.</p>
<p><strong>Enough about me, though. I’d be thrilled to hear about your experience with the software.</strong></p>
<br>
</div></div>]]>
            </description>
            <link>https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398232</guid>
            <pubDate>Sat, 12 Dec 2020 13:56:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image codec comparison: AVIF (aom, rav1e, svt), JPEG XL, WebP 2]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398218">thread link</a>) | @jonsneyers
<br/>
December 12, 2020 | https://eclipseo.github.io/image-comparison-web | <a href="https://web.archive.org/web/*/https://eclipseo.github.io/image-comparison-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h2>Statistics</h2>
        <p><a href="https://eclipseo.github.io/speed_results.html" target="_blank">Lossless compression ratio and encoding speed</a>.
        </p><p><a href="https://eclipseo.github.io/lossy_results.html" target="_blank">Lossy compression metrics</a>.
        </p><p><a href="https://eclipseo.github.io/avif_results.html" target="_blank">Comparison between AVIF encoders</a>.
        </p><p><a href="https://eclipseo.github.io/webp_results.html" target="_blank">Comparison between WebP and WebP2</a>.
        </p><p><a href="https://eclipseo.github.io/report.html" target="_blank">Full methodology</a>.
        </p><h2>Notes</h2>
        <p>Large images were first encoded with BPG at q24 filesizes. Big images are 180% of Large. Medium is 60% of Large. Small is 60% of Medium. Tiny is
            60% of Small. Everything else was matched to +/- 5% filesize.</p>
        <p>All the pictures have been compressed from RGB PNGs except SVT-AV1. SVT-AV1 only supports YUV420 input so the filesizes reported are not comparable with other encoders supporting RGB input.</p>
        <p>Both rav1e ard svt-av1 do not support lossless compression, the pictures presented here are only near lossless, so their filesizes is not representative of actual lossless.</p>
        <p>Use Shift to swap images.</p>
        <p>This page is based on <a href="http://people.xiph.org/~xiphmont/demo/daala/update1-tool2b.shtml" target="_blank">Xiph.org's</a>            Daala comparison page. <a href="https://github.com/xooyoozoo/yolo-octo-bugfixes" target="_blank">Originally developed by xooyoozoo</a>.
            A list of sources for the images can be found in <a href="http://eclipseo.github.io/image-comparison-web/cite_images.txt" target="_blank">this text file</a>.</p>
        <p>Last updated: December 2020.</p>
    </div></div>]]>
            </description>
            <link>https://eclipseo.github.io/image-comparison-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398218</guid>
            <pubDate>Sat, 12 Dec 2020 13:53:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple's M1 Chip Benchmarks focused on the real-world programming]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398201">thread link</a>) | @ssut
<br/>
December 12, 2020 | https://tech.ssut.me/apple-m1-chip-benchmarks-focused-on-the-real-world-programming/ | <a href="https://web.archive.org/web/*/https://tech.ssut.me/apple-m1-chip-benchmarks-focused-on-the-real-world-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://tech.ssut.me/content/images/size/w300/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg 300w,
                            https://tech.ssut.me/content/images/size/w600/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg 600w,
                            https://tech.ssut.me/content/images/size/w1000/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg 1000w,
                            https://tech.ssut.me/content/images/size/w2000/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://tech.ssut.me/content/images/size/w2000/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg" alt="Apple's M1 Chip Benchmarks focused on the real-world programming">
            </figure>

            <section>
                <div>
                    <p>I'm pretty impressed by what I've seen with Apple's M1 Chip. It's really fast and powerful for essential everyday tasks, which include browsing the web, working with Intel-based apps, and using programming apps. Yes – the ecosystem is moving, and that may take time, but I think M1 is worth paying for it because of its phenomenal performance.</p><p>M1 is fast, and many benchmarks have proved its performance. However, I was curious about the performance of the programming languages using M1. So I decided to test it for the most popular workloads here.</p><p>Before you see the results, you should know that some benchmark suites are memory-intensive, some are CPU-intensive, and some have no benefits with multi-core processing because of its overhead or its difficulty for utilizing. It means that M1 can have an advantage over the desktop-class multi-core Ryzen processor even though the core count is lesser. <strong>Most importantly, I've focused more on real-world development performance testing rather than synthetic, production tests.</strong></p><p>You can check the raw benchmark data <a href="https://docs.google.com/spreadsheets/d/1g4U7LAImfEcXRihJbySZcRr32tn6WSWAtslfXltds58/edit?usp=sharing">here</a>.</p><p>I add the following comment as of Dec 14: we care how fast our dev computer runs. the multi-core advantage of 3900X is useless for most of the benchmarks here that don't represent the real-world production performance at all but devs usually work on their laptops, desktops, etc most of the time so I think such real-world development performance benchmarks make it worthwhile though. of course, Ryzen 3900X will perform way better than M1 and Intel when it comes to production, mostly achieved by parallelizing.</p><h2 id="test-environment">Test Environment</h2><ul><li>Apple M1: Mac Mini (16GB RAM), MacBook Air (8GB RAM) / macOS Big Sur 11.0.1 (All executables used for benchmarks are natively compiled for Apple Silicon.)</li><li>Ryzen 3900X: ASRock Rack X570D4I-2T / 16GB DDR4-3200 x 2 / Ubuntu 20.04.1 LTS (tested after shutting down background tasks.) – You may wonder why I used 3900X instead of Ryzen 5000-series CPUs: Because I don't have it.</li><li>Intel i7-9750H: MacBook Pro 16" / 16GB / macOS Big Sur &nbsp;11.0.1</li><li>Intel i9-9880H: MacBook Pro 16" / 32GB / macOS Big Sur 11.0.1</li></ul><h2 id="java-renaissance">Java Renaissance</h2><p><strong>Less is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/Java-Renaissance-Benchmarks--3-.svg" alt=""></figure><p>Renaissance is a modern, open, and diversified benchmark suite for the JVM, aimed at testing JIT compilers, garbage collectors, profilers, analyzers and other tools.</p><p>Since JVM is memory intensive, and memory is one of the largest bottlenecks for any Java applications, Apple M1 performance is stunning compared to Ryzen 3900X.</p><h2 id="java-scimark-2-0-nist-">Java SciMark 2.0 (NIST)</h2><p><strong>Higher is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/Java-SciMark-2.0-Benchmarks--NIST---1-.svg" alt=""></figure><p>SciMark 2.0 is a Java benchmark for scientific and numerical computing. It measures several computational <a href="https://math.nist.gov/scimark2/about.html">kernels</a> and reports a composite score in approximate Mflops (Millions of floating point operations per second).</p><h2 id="java-dacapo">Java DaCapo</h2><p><strong>Less is better</strong> </p><figure><img src="https://tech.ssut.me/content/images/2020/12/Java-DaCapo-Benchmarks--309e1fa---1-.svg" alt=""></figure><p>DaCapo benchmark suite is intended as a tool for Java benchmarking by the programming language, memory management and computer architecture communities. It consists of a set of open source, real world applications with non-trivial memory loads.</p><h2 id="python-pyperformance">Python PyPerformance</h2><p><strong>Less is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/PyPerformance-Benchmarks.svg" alt=""></figure><figure><img src="https://tech.ssut.me/content/images/2020/12/PyPerformance-Benchmarks--Total-Seconds-Elapsed---2-.svg" alt=""></figure><p>The pyperformance project is intended to be an authoritative source of benchmarks for all Python implementations. The focus is on real-world benchmarks, rather than synthetic benchmarks, using whole applications when possible.</p><p>Edit (Dec 15, at 01:55 KST): Fixed an issue I made a mistake that the actual unit is Seconds instead of Milliseconds in the last 'Total Seconds Elapsed' chart while I reuse the subtitles for the benchmark charts.</p><h2 id="go-golang-org-x-benchmarks-">Go (golang.org/x/benchmarks)</h2><p><strong>Less is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/golang.org_x_benchmarks--3-.svg" alt=""></figure><p>Note here that Go utilized all cores during this benchmark.</p><h2 id="go-golang-benchmarks-">Go (<a href="https://github.com/SimonWaldherr/golang-benchmarks">golang-benchmarks</a>)</h2><p><strong>(Unit: ns/op, Less is better)</strong></p><!--kg-card-begin: html--><table xmlns="http://www.w3.org/1999/xhtml" dir="ltr"><colgroup><col width="221"><col width="129"><col width="151"><col width="100"><col width="100"></colgroup><tbody><tr><td></td><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Apple M1 (Mac Mini)&quot;}">Apple M1 (Mac Mini)</td><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Apple M1 (MacBook Air)&quot;}">Apple M1 (MacBook Air)</td><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Ryzen 3900X&quot;}">Ryzen 3900X</td><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Intel i7-9750H&quot;}">Intel i7-9750H</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBase64decode-24&quot;}">BenchmarkBase64decode-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:68.65}">68.65</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:69.77}">69.77</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:137.1}">137.1</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:103}">103</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBase64regex-24&quot;}">BenchmarkBase64regex-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12001}">12001</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12250}">12250</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32803}">32803</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18255}">18255</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkNumberRegEx-24&quot;}">BenchmarkNumberRegEx-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7759}">7759</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7931}">7931</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:23379}">23379</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12206}">12206</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkFulltextRegEx-24&quot;}">BenchmarkFulltextRegEx-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6388}">6388</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6957}">6957</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18627}">18627</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10014}">10014</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkNumberParse-24&quot;}">BenchmarkNumberParse-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:48.69}">48.69</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:50.19}">50.19</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:66.83}">66.83</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:58}">58</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkFulltextParse-24&quot;}">BenchmarkFulltextParse-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:726.3}">726.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:729.7}">729.7</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:933.2}">933.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:839}">839</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkConcatString-24&quot;}">BenchmarkConcatString-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:21949}">21949</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:22810}">22810</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:65498}">65498</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:43343}">43343</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkConcatBuffer-24&quot;}">BenchmarkConcatBuffer-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.338}">4.338</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.648}">4.648</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.258}">6.258</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.24}">6.24</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkConcatBuilder-24&quot;}">BenchmarkConcatBuilder-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2.37}">2.37</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.1}">3.1</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2.934}">2.934</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.02}">3.02</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkContains-24&quot;}">BenchmarkContains-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5.007}">5.007</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5.204}">5.204</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.467}">7.467</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.94}">7.94</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkContainsNot-24&quot;}">BenchmarkContainsNot-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.322}">6.322</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.406}">6.406</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.693}">7.693</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8.9}">8.9</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkContainsBytes-24&quot;}">BenchmarkContainsBytes-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5.33}">5.33</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5.511}">5.511</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.5}">7.5</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8.49}">8.49</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkContainsBytesNot-24&quot;}">BenchmarkContainsBytesNot-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.57}">6.57</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.773}">6.773</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:9.188}">9.188</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10.3}">10.3</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCompileMatch-24&quot;}">BenchmarkCompileMatch-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:70.66}">70.66</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:75.09}">75.09</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:110.1}">110.1</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:83}">83</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCompileMatchNot-24&quot;}">BenchmarkCompileMatchNot-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:31.65}">31.65</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32.08}">32.08</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:62.42}">62.42</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:42.1}">42.1</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatch-24&quot;}">BenchmarkMatch-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:800.2}">800.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:804.6}">804.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2376}">2376</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1313}">1313</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatchNot-24&quot;}">BenchmarkMatchNot-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:758.1}">758.1</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:779.3}">779.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2311}">2311</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1262}">1262</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkForMap-24&quot;}">BenchmarkForMap-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18.89}">18.89</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18.92}">18.92</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:20.37}">20.37</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:20.6}">20.6</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkRangeMap-24&quot;}">BenchmarkRangeMap-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:47.66}">47.66</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:48.59}">48.59</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:53.25}">53.25</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:56.7}">56.7</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkRangeSlice-24&quot;}">BenchmarkRangeSlice-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.446}">3.446</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.47}">3.47</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2.022}">2.022</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.4}">3.4</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkRangeSliceKey-24&quot;}">BenchmarkRangeSliceKey-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.072}">4.072</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.121}">4.121</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2.906}">2.906</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.15}">3.15</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkAdler32-24&quot;}">BenchmarkAdler32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:699}">699</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:719.4}">719.4</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:644.4}">644.4</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:700}">700</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBlake2b256-24&quot;}">BenchmarkBlake2b256-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2340}">2340</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2415}">2415</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2026}">2026</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1932}">1932</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBlake2b512-24&quot;}">BenchmarkBlake2b512-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2343}">2343</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2400}">2400</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1985}">1985</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1945}">1945</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBlake3256-24&quot;}">BenchmarkBlake3256-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5753}">5753</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5854}">5854</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2489}">2489</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2634}">2634</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMMH3-24&quot;}">BenchmarkMMH3-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:374.3}">374.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:383.2}">383.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:294}">294</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:377}">377</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCRC32-24&quot;}">BenchmarkCRC32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:255.5}">255.5</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:260.4}">260.4</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:152.9}">152.9</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:122}">122</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkFnv128-24&quot;}">BenchmarkFnv128-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4468}">4468</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4502}">4502</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5540}">5540</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4210}">4210</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMD5-24&quot;}">BenchmarkMD5-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3193}">3193</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3211}">3211</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2464}">2464</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2534}">2534</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA1-24&quot;}">BenchmarkSHA1-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:900.4}">900.4</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:910.9}">910.9</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1898}">1898</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1961}">1961</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA256-24&quot;}">BenchmarkSHA256-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:913.5}">913.5</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:927.6}">927.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4016}">4016</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4525}">4525</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA512-24&quot;}">BenchmarkSHA512-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6999}">6999</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7033}">7033</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2883}">2883</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3249}">3249</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA3256-24&quot;}">BenchmarkSHA3256-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4213}">4213</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4231}">4231</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5957}">5957</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5878}">5878</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA3512-24&quot;}">BenchmarkSHA3512-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7329}">7329</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7429}">7429</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10233}">10233</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10394}">10394</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkWhirlpool-24&quot;}">BenchmarkWhirlpool-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32042}">32042</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32624}">32624</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:35714}">35714</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:39205}">39205</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMapStringKeys-24&quot;}">BenchmarkMapStringKeys-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:68.14}">68.14</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:70.66}">70.66</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:87.62}">87.62</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:100}">100</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMapIntKeys-24&quot;}">BenchmarkMapIntKeys-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:43.6}">43.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:48.49}">48.49</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:42.51}">42.51</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:60}">60</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkJsonMarshal-24&quot;}">BenchmarkJsonMarshal-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1240}">1240</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1261}">1261</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2258}">2258</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1720}">1720</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkJsonUnmarshal-24&quot;}">BenchmarkJsonUnmarshal-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4969}">4969</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5102}">5102</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:9597}">9597</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6484}">6484</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathInt8-24&quot;}">BenchmarkMathInt8-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3128}">0.3128</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3235}">0.3235</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2298}">0.2298</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.24}">0.24</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathInt32-24&quot;}">BenchmarkMathInt32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3145}">0.3145</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3166}">0.3166</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2324}">0.2324</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.239}">0.239</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathInt64-24&quot;}">BenchmarkMathInt64-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3131}">0.3131</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3158}">0.3158</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2367}">0.2367</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.237}">0.237</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathAtomicInt32-24&quot;}">BenchmarkMathAtomicInt32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.9}">6.9</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.965}">6.965</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.02}">4.02</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.33}">4.33</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathAtomicInt64-24&quot;}">BenchmarkMathAtomicInt64-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.898}">6.898</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.051}">7.051</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.044}">4.044</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.27}">4.27</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathMutexInt-24&quot;}">BenchmarkMathMutexInt-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.51}">13.51</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.63}">13.63</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8.118}">8.118</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12.1}">12.1</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathFloat32-24&quot;}">BenchmarkMathFloat32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3142}">0.3142</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3142}">0.3142</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2356}">0.2356</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.241}">0.241</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathFloat64-24&quot;}">BenchmarkMathFloat64-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.313}">0.313</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3167}">0.3167</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.239}">0.239</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.239}">0.239</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkParseBool-24&quot;}">BenchmarkParseBool-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1.427}">1.427</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1.43}">1.43</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2252}">0.2252</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.308}">0.308</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkParseInt-24&quot;}">BenchmarkParseInt-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10.97}">10.97</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:11.15}">11.15</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:11.84}">11.84</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.5}">13.5</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkParseFloat-24&quot;}">BenchmarkParseFloat-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:64.52}">64.52</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:65.74}">65.74</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:90.89}">90.89</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:87}">87</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathRand-24&quot;}">BenchmarkMathRand-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.55}">13.55</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.71}">13.71</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:17.27}">17.27</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:21.5}">21.5</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCryptoRand-24&quot;}">BenchmarkCryptoRand-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:106.6}">106.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:112}">112</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1311}">1311</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:145}">145</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCryptoRandString-24&quot;}">BenchmarkCryptoRandString-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:107.6}">107.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:110.7}">110.7</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:222}">222</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:138}">138</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatchString-24&quot;}">BenchmarkMatchString-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4957}">4957</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5148}">5148</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13869}">13869</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7616}">7616</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatchStringCompiled-24&quot;}">BenchmarkMatchStringCompiled-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:475.5}">475.5</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:496.2}">496.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:499.2}">499.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:464}">464</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatchStringGolibs-24&quot;}">BenchmarkMatchStringGolibs-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:479.3}">479.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:496.3}">496.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:491.3}">491.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:480}">480</td></tr></tbody></table><!--kg-card-end: html--><h2 id="sqlite-bench">SQLite Bench</h2><p><strong>Less is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/SQLite-Bench--1--1.svg" alt=""></figure><figure><img src="https://tech.ssut.me/content/images/2020/12/SQLite-Bench.svg" alt=""></figure><h2 id="redis">Redis</h2><p><strong>Higher is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/Redis-v6.0.9-Benchmark--1-000-000-Requests-.svg" alt=""></figure><p><strong>Higher is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/JavaScript-Web-Tooling-Benchmark--v8---1-.svg" alt=""></figure><p>V8 Web Tooling Benchmark is a benchmark suite designed to measure the JavaScript-related workloads commonly used by web developers, such as the core workloads in popular tools like <a href="https://github.com/babel/babel">Babel</a> or <a href="https://github.com/Microsoft/TypeScript">TypeScript</a>. The goal is to measure <strong>only</strong> the JavaScript performance aspect (which is affected by the JavaScript engine) and not measure I/O or other unrelated aspects.</p><p>See the <a href="https://github.com/v8/web-tooling-benchmark/blob/master/docs/in-depth.md">in-depth analysis</a> for a detailed description of the tests included in this benchmark suite.</p><h2 id="javascript-octane-2-0">JavaScript <a href="https://developers.google.com/octane/">Octane 2.0</a></h2><p><strong>Higher is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/JavaScript-Octane-2.0.svg" alt=""></figure><figure><img src="https://tech.ssut.me/content/images/2020/12/JavaScript-Octane-2.0-Overall.svg" alt=""></figure><h2 id="webpack-build">Webpack Build</h2><p><strong>Less is better</strong></p><p>Target build project: <a href="https://github.com/zuiidea/antd-admin">antd-admin</a></p><figure><img src="https://tech.ssut.me/content/images/2020/12/Antd-admin-webpack-build-time--2-.svg" alt=""></figure><h2 id="conclusion">Conclusion</h2><p>It is very impressive to see the performance of Apple's M1 Chip. It performs better than the existing x86 does in such real-world benchmarks.</p><p>I don't feel like I need to say much: <strong>Just Buy M1 if you'd like to have a low-power, long-lasting, quiet, and performant dev machine.</strong><br><em>M1은 사드세요 제발.</em></p><p><em>The results of MacBook Air (M1) and MacBook Pro 16" (i9-9880H) were provided by courtesy of <a href="https://github.com/zinozzino">Jinho Jeong (@zinozzino)</a>.</em></p>
                </div>
            </section>



            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://tech.ssut.me/apple-m1-chip-benchmarks-focused-on-the-real-world-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398201</guid>
            <pubDate>Sat, 12 Dec 2020 13:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing Lambda Cost with Multi-Threading]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398091">thread link</a>) | @kiyanwang
<br/>
December 12, 2020 | https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!--## AWS re:Invent 2020 Day 3: Optimizing Lambda Cost with Multi-Threading-->
<p>Amazon has released support for up to 10 GB memory and 6 vCPUs for your Lambda functions. In this article we will explore how these new memory configuration options can drive down costs and execution times for compatible workloads.</p>
<p>Let’s quickly review the Lambda pricing scheme. We’ll ignore the free tier. Lambda is billed at $0.0000166667 for every GB-second. A GB-second is the unit of measurement for 1 GB of memory running for 1 second. Lambdas are often very short lived, so let’s say a particular function has an average execution time of 100ms, and is executed 100 times every minute. That’s 10 seconds of execution time per minute, 14.400 seconds per day, and 432.000 seconds per 30 days. This function is configured to use 128 MB or RAM (1/8th of a GB), so you’re billed for 432.000 / 8 = 54.000 GB-seconds per month. At $0.0000166667 per GB-second, this function will cost a whopping $0.90 per month.</p>
<p>The only tunable performance configuration for Lambda is the amount of memory available to the function. The CPU performance scales with the memory configuration. Lambda functions used to always have 2 vCPU cores, regardless of memory. These cores would be throttled at certain memory configurations. The <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-memory.html">documentation</a> states that at 1,769 MB, a function has the equivalent of one vCPU.</p>
<p>With the increased maximum memory of 10GB, up from 3008 MB (<a rel="noopener noreferrer" href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/">AWS News</a> - <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/new-for-aws-lambda-functions-with-up-to-10-gb-of-memory-and-6-vcpus/">AWS Blog</a>), the number of CPUs has become more flexible. We ran some tests and found out that Lambda now has the following CPU tiers:</p>
<table>
<thead>
<tr>
<th>Memory</th>
<th>vCPUs</th>
</tr>
</thead>
<tbody>
<tr>
<td>128 - 3008 MB</td>
<td>2</td>
</tr>
<tr>
<td>3009 - 5307 MB</td>
<td>3</td>
</tr>
<tr>
<td>5308 - 7076 MB</td>
<td>4</td>
</tr>
<tr>
<td>7077 - 8845 MB</td>
<td>5</td>
</tr>
<tr>
<td>8846+ MB</td>
<td>6</td>
</tr>
</tbody>
</table>
<p>This opens up a number of new price tuning options. If a workload supports multi-threading, for example, we can try to optimize the number of vCPUs to reduce execution time. A multi-threading function configured at 3009 MB might execute 1.5x as fast as a 3008 MB function, a 33.3% cost reduction! Let’s see if we can produce these results in real life benchmarks.</p>
<h3>Running tests with ffmpeg</h3>
<p>To test Lambda’s performance we compiled <code>ffmpeg</code> from source and packaged it together with a 100 MB sample video and a simple Python app. Because this package exceeds the maximum size for Lambda deployment packages, we used the new Lambda  Container Image Support (<a rel="noopener noreferrer" href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-now-supports-container-images-as-a-packaging-format/">AWS News</a> - <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support">AWS Blog</a>) to put <code>ffmpeg</code> and the video together in a container and create a Lambda function from that container. Our performance benchmark will consist of 100 iterations of a video format conversion. The exact command for our initial run of benchmarks is <code>ffmpeg -i source.mkv -c:v libx264 -b:a 128k -threads 1 -y /tmp/target.mp4</code></p>
<p>As you can see, this command is hardcoded to use only one thread. This allows us to set a single-threaded baseline on various memory configurations. We ran 100 iterations on the key memory sizes in the table below. The values chosen are the top and bottom values for every CPU tier. 832 MB was the minimum required to successfully convert the video within 15 minutes.</p>
<h3>Single thread results</h3>
<table>
<thead>
<tr>
<th>Memory</th>
<th>vCPUs</th>
<th>Threads</th>
<th>Average Execution Time</th>
<th>Cost for 100 Executions</th>
</tr>
</thead>
<tbody>
<tr>
<td>832 MB</td>
<td>2</td>
<td>1</td>
<td>832308 ms (832.31 s)</td>
<td>$1.1271</td>
</tr>
<tr>
<td>1769 MB</td>
<td>2</td>
<td>1</td>
<td>396342 ms (396.34 s)</td>
<td>$1.1412</td>
</tr>
<tr>
<td>3008 MB</td>
<td>2</td>
<td>1</td>
<td>361768 ms (361.77 s)</td>
<td>$1.7712</td>
</tr>
<tr>
<td>3009 MB</td>
<td>3</td>
<td>1</td>
<td>361907 ms (361.91 s)</td>
<td>$1.7724</td>
</tr>
<tr>
<td>5307 MB</td>
<td>3</td>
<td>1</td>
<td>362551 ms (362.55 s)</td>
<td>$3.1316</td>
</tr>
<tr>
<td>5308 MB</td>
<td>4</td>
<td>1</td>
<td>359439 ms (359.44 s)</td>
<td>$3.1053</td>
</tr>
<tr>
<td>7076 MB</td>
<td>4</td>
<td>1</td>
<td>360534 ms (360.53 s)</td>
<td>$4.1523</td>
</tr>
<tr>
<td>7077 MB</td>
<td>5</td>
<td>1</td>
<td>359426 ms (359.43 s)</td>
<td>$4.1401</td>
</tr>
<tr>
<td>8845 MB</td>
<td>5</td>
<td>1</td>
<td>359287 ms (359.29 s)</td>
<td>$5.1724</td>
</tr>
<tr>
<td>8846 MB</td>
<td>6</td>
<td>1</td>
<td>360957 ms (360.96 s)</td>
<td>$5.1970</td>
</tr>
<tr>
<td>10240 MB</td>
<td>6</td>
<td>1</td>
<td>361495 ms (361.49 s)</td>
<td>$6.0249</td>
</tr>
</tbody>
</table>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/2usIrwWt5S0vVYYUpe5lKY/cc8d1b2aa761055af87c205a5b96d245/single_threaded.png" alt="Single-threaded Results"></p>
<p>This data clearly shows that any memory configuration above 3008 MB does not improve single thread performance. Memory configurations up to 1769 MB are throttled, from 1769 MB to 3008 MB there are some minor performance increases, and from 3008 MB and up you’re using the full capacity of a single core, which means the average execution time plateaus. At the same time the costs for higher memory configurations are skyrocketing. Clearly, if you’re running single-threaded processes in Lambda you would do well to fit your Lambda’s memory closely to your function’s actual requirements.</p>
<h3>Multi-threaded results</h3>
<p>For our multi-threaded tests, we obtain the number of CPUs from <code>/proc/cpuinfo</code> and configure <code>ffmpeg</code> to use as many threads as there are cores. Let’s take a look at the results.</p>
<table>
<thead>
<tr>
<th>Memory</th>
<th>vCPUs</th>
<th>Threads</th>
<th>Average Execution Time</th>
<th>Diff vs. Single-threaded</th>
<th>Cost for 100 Executions</th>
</tr>
</thead>
<tbody>
<tr>
<td>832 MB</td>
<td>2</td>
<td>2</td>
<td>880404 ms (880.40 s)</td>
<td>+5.78%</td>
<td>$1.1922</td>
</tr>
<tr>
<td>1769 MB</td>
<td>2</td>
<td>2</td>
<td>402968 ms (402.97 s)</td>
<td>+1.67%</td>
<td>$1.1602</td>
</tr>
<tr>
<td>3008 MB</td>
<td>2</td>
<td>2</td>
<td>241733 ms (241.73 s)</td>
<td>-33.18%</td>
<td>$1.1835</td>
</tr>
<tr>
<td>3009 MB</td>
<td>3</td>
<td>3</td>
<td>237562 ms (237.56 s)</td>
<td>-34.36%</td>
<td>$1.1635</td>
</tr>
<tr>
<td>5307 MB</td>
<td>3</td>
<td>3</td>
<td>168755 ms (168.76 s)</td>
<td>-53.45%</td>
<td>$1.4577</td>
</tr>
<tr>
<td>5308 MB</td>
<td>4</td>
<td>4</td>
<td>150779 ms (150.78 s)</td>
<td>-58.05%</td>
<td>$1.3026</td>
</tr>
<tr>
<td>7076 MB</td>
<td>4</td>
<td>4</td>
<td>142042 ms (142.04 s)</td>
<td>-60.60%</td>
<td>$1.6359</td>
</tr>
<tr>
<td>7077 MB</td>
<td>5</td>
<td>5</td>
<td>104318 ms (104.32 s)</td>
<td>-70.98%</td>
<td>$1.2016</td>
</tr>
<tr>
<td>8845 MB</td>
<td>5</td>
<td>5</td>
<td>95304 ms (95.30 s)</td>
<td>-73.47%</td>
<td>$1.3720</td>
</tr>
<tr>
<td>8846 MB</td>
<td>6</td>
<td>6</td>
<td>90039 ms (90.04 s)</td>
<td>-75.06%</td>
<td>$1.2964</td>
</tr>
<tr>
<td>10240 MB</td>
<td>6</td>
<td>6</td>
<td>87455 ms (87.46 s)</td>
<td>-75.81%</td>
<td>$1.4576</td>
</tr>
</tbody>
</table>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/3U0RNbpfoWamiGYTzgQvxK/4437e7a6b9f8baa6ae6f5fd841ef2a44/multi_threaded.png" alt="Multi-threaded Results"></p>
<p>What jumps out immediately is that at 832 MB using two threads is actually slower than the single-threaded benchmark. This likely relates to the CPU throttling applied to Lambda functions below 1769 MB: two threads competing for the same limited resources are slower than a single thread having those resources to itself.</p>
<p>At 1769 MB the multi-threaded measurement is almost exactly equal to the single-threaded result. This makes sense, since the documentation states that at 1769 MB, a function has the equivalent of one vCPU. At this level contestation is apparently no longer an issue.</p>
<p>At 3008 MB, the old maximum memory configuration, we start to benefit from using multiple cores. But it starts to get interesting at exactly 1 MB higher, at 3009 MB. This is the first time we get to use more than two cores, and we would expect an immediate performance bump. However, the results at three cores and 3009 MB are only 1.73% better than at two cores and 3008 MB. Apparently, the three cores at 3009 MB do not offer 1.5x the performance of the two cores at 3008 MB, and some throttling is taking place. This is corroborated by the benchmark at 5307 MB: even though this configuration has the same amount of cores, its performance is 28.96% higher than at 3009 MB. This means that AWS is dynamically limiting the amount of processing power available to the function, based on its memory configuration.</p>
<p>Next, at 5308 MB, we have our first four-core benchmark. Here we see that the fourth core adds a significant improvement. Although we added only 0.0188% of memory, performance jumped by 10.65%. The other four-core measurement at 7076 MB yields further improvements, but not enough to offset the additional cost.</p>
<p>Then at 7077 MB, the first five-core benchmark, we see another BIG jump. Again, we only added a single MB of memory, but the fifth core increased performance by an incredible 26.56%. Increasing memory to 8845 MB adds another improvement of 8.64%, but like in the four-core block, this doesn’t offset the additional cost.</p>
<p>At 8846 MB the additional MB and 6th core yields a 5.52% performance boost, and the maximum configuration of 10240 MB is 2.87% faster than the 8846 MB setting.</p>
<h3>Understanding these results</h3>
<p>The single-threaded benchmarks showed that a single core maxes out at relatively low memory configurations. The same logic doesn’t apply to multi-threaded solutions: every tier increased multi-threaded performance. Adding an additional core sometimes adds a big performance gain, and sometimes it hardly adds value.</p>
<p>This leads me to conclude that AWS applies a sort of dynamic capacity ceiling to Lambda functions. For example, this ceiling might be set at 0.5 at 832 MB, which means you can at max use half a core. It’s set to 1.0 at 1769 MB, which means we can use one full core. At 3008 it seems to be set to 1.6667. A full list of ceiling values can be found in the table below:</p>
<table>
<thead>
<tr>
<th>Memory</th>
<th>vCPUs</th>
<th>CPU Ceiling</th>
</tr>
</thead>
<tbody>
<tr>
<td>832 MB</td>
<td>2</td>
<td>0.50</td>
</tr>
<tr>
<td>1769 MB</td>
<td>2</td>
<td>1.00</td>
</tr>
<tr>
<td>3008 MB</td>
<td>2</td>
<td>1.67</td>
</tr>
<tr>
<td>3009 MB</td>
<td>3</td>
<td>1.70</td>
</tr>
<tr>
<td>5307 MB</td>
<td>3</td>
<td>2.39</td>
</tr>
<tr>
<td>5308 MB</td>
<td>4</td>
<td>2.67</td>
</tr>
<tr>
<td>7076 MB</td>
<td>4</td>
<td>2.84</td>
</tr>
<tr>
<td>7077 MB</td>
<td>5</td>
<td>3.86</td>
</tr>
<tr>
<td>8845 MB</td>
<td>5</td>
<td>4.23</td>
</tr>
<tr>
<td>8846 MB</td>
<td>6</td>
<td>4.48</td>
</tr>
<tr>
<td>10240 MB</td>
<td>6</td>
<td>4.72</td>
</tr>
</tbody>
</table>
<p>This explains how single-threaded functions can completely utilize a single core, but multi-threaded applications can’t do the same on multiple cores.</p>
<p>Please note that these values are for my specific video conversion benchmark. This benchmark might not be able to max out all the cores available to it. Other benchmarks might be able to use multiple cores more efficiently and produce different results.</p>
<p>The core take-away is that this benchmark has run exactly the same process under different memory configurations, and consistently produces better results for higher memory configurations in the same CPU tier.</p>
<p>The second finding is that adding an additional core always yields a performance benefit for multi-threaded processes. Some cores (the third and sixth) provide smaller benefits than others (the fourth and fifth). If your function is configured just below one of these thresholds, slightly increasing the value might result in big gains.</p>
<h3>Determining the ideal price point</h3>
<p>Multi-threaded Lambda functions complete faster at higher memory settings, leading to lower costs. In general, the lower execution time offsets a big chunk of the higher memory costs. This is especially visible at 1769, 3009 and 7077 MB: the first configuration costs $1.1602 for 100 executions. The second configuration completes its operation 41.05% faster, at a 0.28% price increase ($1.1635). The 7077 MB setting completes 74.11% faster than the 1769 MB variant, at a 3.57% price increase ($1.2016).</p>
<p>Deciding which price point is best for your workload depends on your requirements: if it’s purely cost-driven, 1769 MB or 3009 MB might be a good starting point. If it’s performance driven, do run some tests at 5308, 7077 and 8846 MB. These memory configurations might perform significantly better at a marginally higher cost.</p>
<h3>Conclusion</h3>
<p>You might have hoped that the new high-memory Lambda functions would also improve single-threaded performance, but alas - the functions seem to run on exactly the same hardware as their lowly 3008 MB siblings. However, the higher Lambda tiers do include three, four, five and six CPU cores. In multi-threaded processes, a single MB …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading">https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398091</guid>
            <pubDate>Sat, 12 Dec 2020 13:23:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accidental Observations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398025">thread link</a>) | @bondarchuk
<br/>
December 12, 2020 | https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html | <a href="https://web.archive.org/web/*/https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<br>


<h2><a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange2.html">Continued here …</a></h2>
<a name="qringe"></a>
<h2>Quetelet rings</h2>

<p>Quetelet rings may be not very rare, but until now I have only seen artificially produced ones. Impressive examples due to dust particles or algae on the surface of a pond or puddle may be found in the web <a href="http://www.uni-muenster.de/imperia/md/content/fachbereich_physik/didaktik_physik/publikationen/433_colored_rings_on_dusty_surfaces.pdf">[1]</a>, <a href="http://www.atoptics.co.uk/fz96.htm">[2]</a>,<a href="http://www.atoptics.co.uk/fza151.htm">[3]</a>, <a href="https://atoptics.wordpress.com/tag/quetelet-rings/">[4]</a>.
</p><p>
Recently Aleksandr Berdnikov uploaded three photographs of a dusty mirror which show this phenomenon very clearly:</p>
<p>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/Qu-close.jpg" alt="" width="36%"></span>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/Qu-far.jpg" alt="" width="25%"></span>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/Qu-par.jpg" alt="" width="34%"></span>
</p>
<p>The images (source: Wikimedia Commons <a href="https://commons.wikimedia.org/wiki/File:Quetelet_close.jpg">[A]</a>, <a href="https://commons.wikimedia.org/wiki/File:Quetelet_far.jpg">[B]</a>, <a href="https://commons.wikimedia.org/wiki/File:Quetelet_par.jpg">[C]</a>) have been taken with lhe light source closer to the mirror than the camera (about half as far, left image), with the flashlight twice as far as the camera (middle), and with camera and light approximately at the same distance (right).</p>
<p>Aleksandr in his comments to the images describes the relative positions of the flashlight to the camera; but this can be deduced from the images, if only the relative distances are known. In the right picture, the mirror images of the light source and the camera are visible, therefore the arrangement is clear. The other two photos show only the flashlight mirrored. But the dark area in the lower right corner of the first picture must be the back of the light, thus it is to the right and lower than the camera, while in the second picture there  certainly it is the shadow of the camera which obscures part of the lower right, which means that the light is to the left and higher up. There are some reflections of the surroundings in this shadow and below. (Click on the pictures to enlarge!)
</p><p>
As seen on the photographs, the rings are circular, but unlike coronas or aureoles they are not centred around the light source. 
</p>
<p><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/figuren/QuSkizze1.png" alt="" width="256"></span><br>
&nbsp;&nbsp;<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/figuren/QuSkizze4.png" alt="" width="128"></span><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/figuren/QuSkizze3.png" alt="" width="128"></span>
</p>
<p>I first deal with the case (which I haven't yet seen) of algae like Chromulina rosanoffii <!--or other dust particles--> over a calm water surface. As shown by Marko Riikonen <a href="https://atoptics.wordpress.com/tag/quetelet-rings/">[4]</a> “this unique sort of alga separates itself from the water surface by forming a stalk on top of which it rests”. 
</p><p>
The colours are due to the <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/twobeams.html">interference</a> of light rays coming from the same point of the source and arriving at the same point of the retina (or the camera's sensor), but having travelled different paths. The two interfering beams are: light, which is reflected at the water surface and is afterwards scattered to the observer by the particle (an alga), the black line in the neighbouting sketch, and light which first is scattered by a particle, then is reflected by the water surface and finally reaches the observer (white line). 
</p><p>
The sketch to the right is not to scale, actually the particle (white circle) and its mirror image (light grey circle) are so close together that they cannot be resolved by the eye (or camera). 
</p><p>
Knowing that the rings are concentric circles (I shall show this later), it is not difficult to find the position of the centre. Consider the brightest circle which goes through the mirror image of the sun, which is the locus of all points where the two paths have the same length. Another easily to locate point on this circle is the antisolar point in the shadow of one's head. The centre of the rings is just halfway between the antisolar point and the image of the sun, and this is just under the feet of the observer, the nadir.
</p><p>
This is not the case if the light source is close, comparable with the distance of the observer from the mirror. Instead of the antisolar point now the point has to be considered which is just hidden by the lamp (B in the adjacent sketch) or where the shadow of the observer's eye would be (B in the rightmost sketch). If produced by dust on a mirror, the rings are only seen if the illumination angle and viewing angle (as measured from the normal) are small. The pair of sketches to the right illustrates how to find the centre of the rings in this case, and they also illustrate that the rings on the mirror are not changed when the positions of observer and lamp are exchanged.</p>
<a name="mehr"></a>
<p>
The three photos below have been taken with a small circular mirror with 11&nbsp;cm diameter. For the left and middle one, a small incandescent lamp was positioned approximately 5&nbsp;m far from it, and the camera at about half that distance. These two images differ only in focusing: the rings get more pronounced if the light source is in focus, not the grains on the glass. 
</p><p>The third photograph below has been taken with the camera at 2.5&nbsp;m and the lamp at 80&nbsp;cm effective distance. A glass plate has been used to reflect its light to the mirror, therefore “point B” is not obscured by the lamp's case.
</p>  
<center>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1060005-33.jpg" alt="Quetelet rings" width="25%"></span>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1060021-33.jpg" alt="Quetelet rings" width="25%"></span>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1060238-33.jpg" alt="Quetelet rings" width="25%"></span><br>
</center>
<h4>Circles on water</h4>
<p>
To show that the coloured rings are circular, I first treat the simpler case … <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/qrings.html#mehr">READ MORE</a></p><br>


<a name="Pholcus"></a>
<h2>Glistening spider silk</h2>
<p>Optical effects on spider webs have already been treated here <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/spiderweb.html">[1],</a> <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html#spiderweb">[2].</a> There, the main focus was on the colours seen on the sticky threads of orb webs lit from behind. The non-sticky strands show less conspicuous colours to the eye, but recently I saw a series of surprisingly candy-striped out-of-focus highlights in the blog “The Natural History of Bodega Head” by Jackie Sones <a href="http://bodegahead.blogspot.com/2017/06/silk-road-to-enlightenment.html">[3a,</a>
<a href="http://bodegahead.blogspot.com/2017/07/questions-about-colors.html">b,</a> 
<a href="http://bodegahead.blogspot.com/2017/07/color-combinations.html">c,</a> 
<a href="http://bodegahead.blogspot.com/2017/07/game-of-threads.html">d,</a> 
<a href="http://bodegahead.blogspot.com/2017/07/shifting-sun.html">e,</a> 
<a href="http://bodegahead.blogspot.com/2017/08/the-thread-continues.html">f]</a> 
, which puzzled me. Here are two examples (shown with permission):
</p><p>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/strand3_sones_jun2017.jpg" alt="" width="49%"></span>&nbsp;&nbsp;
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/strand5_sones_jun2017.jpg" alt="" width="49%"></span>&nbsp;&nbsp;
</p><p> Why are many of the glints cigar-shaped? Shouldn't one expect that the blurred image of the gloss is everywhere as wide as that of the strand so that the shape would be more or less rectangular?</p><p>
Fortunately a cellar spider provided the possibility to investigate this. Cigar shaped striped highlights could be obtained, but the results seemingly depend on the camera. The above pictures have been taken with a SLR camera with a 22.5&nbsp;×&nbsp;15&nbsp;mm sensor; my camera's sensor measures 6&nbsp;×&nbsp;4.5&nbsp;mm.
</p>
<p><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1040880p10.jpg" alt="spider web colours" width="49%"></span>&nbsp;&nbsp;
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1040710m10r.jpg" alt="spider web colours" width="49%"></span></p>
<p>Glossy strands of the web of Pholcus phalangioides (longbodied cellar spider). Left side: strands slightly out of focus, right side: focused to infinity.
</p>
<a name="MORE"></a>
<p>
With bare eyes this could not be seen because one involuntarily focuses on the spot where one looks, and then most of the colours vanish. But even if one succeeds to focus on the far background with a glistening silk strand nearby, the colours will not be as beautiful as in a photograph. With the camera arbitrary defocussing is easy, and moreover, details of a high resolution image can be enlarged. The larger the sensor of a digital camera, and the larger the aperture, the more impressive are the results.
</p>
<p>
When focused to infinity, so to say to the sun's one-dimensional mirror image, the highlights are only thin stripes orthogonal to the threads. The width of the coloured stripes is the apparent diameter of the sun, their length is the apparent breadth of the out-of-focus strands (which are not seen in the right picture except for their glints). The closer the strands, the longer the stripes. If, however, the strand is focussed at, the (one-dimensional) image of the sun gets blurred  and the gloss is seen on a longer stretch which is given by the apparent diameter of the blurred sun.
</p>
<p>The colours are due to the fact that the surfaces of the silk strands are not smooth, but slightly wrinkled. If out of focus, light arriving at one point of the sensor comes from nearby points of the strand and has travelled different path lengths because of the wrinkles. Interference can result in extinction of parts of the spectrum and enhancement of  other parts. This is perceived as colour. </p>
<p>But what is the reason for the peculiar shapeof the highlights?
<a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/Pholcus.html#MORE">Read more …</a></p>
<br>

<a name="behaucht"></a>
<h2>Dewed windowpane aureole II</h2>
<p>After having written about the <a href="#dewcorona">dewed windowpane,</a> I did not see again such a colourful aureole. But it is possible to see a quite similar one when breathing on the window glass while looking at a distant street lamp. In this case, one can to some extent vary the sizes of the droplets and their distances. The following images have been obtained in that way. </p>

<p><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/qDSC08622.jpg" alt="window dew aureole" width="500"></span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</p><p><br>
As only a small part of a window can be breathed at, the produced mist is not uniform. Therefore, the diffraction image is not easily interpreted. Towards the rim of the misted area, the droplets get smaller and their distances increase. In the adjacent image the outermost region is grey, which means that the scattered light is white, though dim. The droplets are so small that the product of scattering angle times droplet radius corresponds to the central region of the diffraction image of a small disc.  The small picture below shows the computed colours for diffraction by a circular black disc; the scale gives the product of deflection angle (in degrees) and radius (in micrometers). (The similarity of the diffraction patterns of small drops and black discs has been demonstrated <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/miecolor.html#aureole">elsewhere.</a> More on that can be found in the section on <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/diffraction.html">diffraction.</a>)



</p><p>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bildchen/irisiwo4.png" alt="">
</p>
<p> 
Towards the centre of the misted area, the sizes of the droplets increase, and though the scattering angle gets smaller, the product of angle times radius at first increases and the colour becomes straw yellow, brownish, then dark purple and dark green. Still closer to the centre, one might expect the colour sequence to be reversed, as the product mentioned decreases again, but now the density of the droplets is so high that the interference effects due to short-range correlations take over, and the <a href="#dewcorona">previous description</a> is valid. For the smallest scattering angles, there is almost complete destructive interference, the immediate surrounding of the lamp, i.e. the centre of the aureole is dark, and then follows a ringed “spectrum”, blue, then white, then red. In the following, only this central region is dealt with.
</p>
<p><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/qDSC08879.jpg" alt="window dew aureole" width="300"></span>
</p>

<p>
It is remarkable how the diffraction image changes when the breathing on the glass is continued so that the density of the mist is slowly increased, or when one first looks throught the outer region of the mist and then moves towards the centre. At first, there is a large dark central region surrounded by greenish grey, then yellow and red. Then, almost suddenly, the radii of the rings decrease and also their colours change. 
</p>
<p>
This can be seen in the image to the right. The photograph has been taken looking not through the centre of the misted region, but to the left of it, so …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html">https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html</a></em></p>]]>
            </description>
            <link>https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398025</guid>
            <pubDate>Sat, 12 Dec 2020 13:09:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Reliably Scale Your Data Platform for High Volumes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398009">thread link</a>) | @oedmarap
<br/>
December 12, 2020 | https://shopify.engineering/reliably-scale-data-platform | <a href="https://web.archive.org/web/*/https://shopify.engineering/reliably-scale-data-platform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><strong>By&nbsp;Arbab Ahmed and Bruno Deszczynski</strong></p>
<p><strong></strong>Black Friday and Cyber Monday—or as we like to call it, BFCM—is one of the largest sales events of the year. It’s also one of the most important moments for Shopify and our merchants. To put it into perspective, this year our merchants across more than 175 countries sold a record breaking $5.1+ billion over the sales weekend.&nbsp;</p>
<p>That’s a lot of sales. That’s a lot of data, too.</p>
<p>This BFCM, the Shopify data platform saw an average throughput increase of 150 percent. Our mission as the Shopify Data Platform Engineering (DPE) team is to ensure that our merchants, partners, and internal teams have access to data quickly and reliably. It shouldn’t matter if a merchant made one sale per hour or a million; they need access to the most relevant and important information about their business, without interruption. While this is a must all year round, the stakes are raised during BFCM.</p>
<p>Creating a data platform that withstands the largest sales event of the year means our platform services need to be ready to handle the increase in load. In this post, we’ll outline the approach we took to reliably scale our data platform in preparation for this high-volume event.&nbsp;</p>

<p>Shopify’s data platform is an interdisciplinary mix of processes and systems that collect and transform data for use by our internal teams and merchants. It enables access to data through a familiar pipeline:</p>
<ul>
<li>
<strong>Ingesting data</strong> in any format, from any part of Shopify. “Raw” data (for example, pageviews, checkouts, and orders) is extracted from Shopify’s operational tables without any manipulation. Data is then conformed to an Apache Parquet format on disk.</li>
</ul>
<ul>
<li>
<strong>Processing data,</strong> in either <em>batches</em> or <em>streams,</em> to form the foundations of business insights. Batches of data are “enriched” with models developed by data scientists, and processed within Apache Spark or <a href="https://shopify.engineering/build-production-grade-workflow-sql-modelling" target="_blank" title="How to Build a Production Grade Workflow with SQL Modelling" rel="nofollow noopener noreferrer">dbt</a>.&nbsp;</li>
</ul>
<ul>
<li>
<strong>Delivering</strong> <strong>data</strong> to our merchants, partners, and internal teams so they can use it to make great decisions quickly. We rely on an internal collection of streaming and serving applications, and libraries that power the merchant-facing analytics in Shopify. They’re backed by BigTable, GCS, and CloudSQL.</li>
</ul>
<p>In an average month, the Shopify data platform processes about 880 billion MySQL records and 1.75 trillion Kafka messages.</p>
<h2>Tiered Services</h2>
<p>As engineers, we want to conquer every challenge <em>right now.</em> But that’s not always realistic or strategic, especially when not all data services require the same level of investment. At Shopify, a <strong>tiered services</strong> taxonomy helps us prioritize our reliability and infrastructure budgets in a broadly declarative way. It’s based on the potential impact to our merchants and looks like this:</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Tier 1</strong></p>
</td>
<td>
<p>This service is <em>critical</em> <em>externally</em>, for example. to a merchant’s ability to run their business</p>
</td>
</tr>
<tr>
<td>
<p><strong>Tier 2</strong></p>
</td>
<td>
<p>This service is <em>critical</em> <em>internally</em> to business functions, e.g. a operational monitoring/alerting service</p>
</td>
</tr>
<tr>
<td>
<p><strong>Tier 3</strong></p>
</td>
<td>
<p>This service is <em>valuable internally</em>, for example, internal documentation services</p>
</td>
</tr>
<tr>
<td>
<p><strong>Tier 4</strong></p>
</td>
<td>
<p>This service is an <em>experiment</em>, in very early development, or is otherwise disposable. For example, an emoji generator</p>
</td>
</tr>
</tbody>
</table>

<p>The highest tiers are top priority. Our ingestion services, called <em>Longboat</em> and <em>Speedboat</em>, and our merchant-facing query service <em>Reportify</em> are examples of services in Tier 1.</p>

<p>As we’ve mentioned, each BFCM the Shopify data platform receives an unprecedented volume of data and queries. Our data platform engineers did some forecasting work this year and predicted nearly two times the traffic of 2019. The challenge for DPE is ensuring our data platform is prepared to handle that volume.&nbsp;</p>
<p>When it comes to BFCM, the primary risk to a system’s reliability is directly proportional to its throughput requirements. We call it <em>throughput risk.</em> It increases the closer you get to the front of the data pipeline, so the systems most impacted are our <strong><em>ingestion</em></strong> and <strong><em>processing systems</em></strong>.</p>
<p>With such a titillating forecast, the risk we faced was unprecedented throughput pressure on data services. In order to be BFCM ready, we had to prepare our platform for the tsunami of data coming our way.</p>

<p>We tasked our Reliability Engineering team with Tier 1 and Tier 2 service preparations for our ingestion and processing systems. Here’s the steps we took to prepare our systems most impacted by BFCM volume:</p>
<h2>1. Identify Primary Objectives of Services</h2>
<p>A data ingestion service's main operational priority can be different from that of a batch processing or streaming service. We determine upfront what the service is optimizing for. For example, if we’re extracting messages from a limited-retention Kafka topic, we know that the ingestion system needs to ensure, above all else, that no messages are lost in the ether because they weren’t consumed fast enough. A batch processing service doesn’t have to worry about that, but it may need to prioritize the delivery of one dataset versus another.</p>
<p>In Longboat’s case, as a batch data ingestion service, its primary objective is to ensure that a raw dataset is available within the interval defined by its data freshness service level objective (SLO). That means Longboat is operating reliably so long as every dataset being extracted is no older than eight hours— the default <em>freshness</em> SLO. For Reportify<strong>, </strong>our main query serving service, its primary objective is to get query results out as fast as possible; its reliability is measured against a <em>latency </em>SLO.</p>
<h2>2. Pinpoint Service Knobs and Levers</h2>
<p>With primary objectives confirmed, you need to identify what you can “turn up or down” to sustain those objectives.</p>
<p>In Longboat’s case, extraction jobs are orchestrated with a batch scheduler, and so the first obvious lever is <em>job frequency</em>. If you discover a raw production dataset is stale, it could mean that the extraction job simply needs to run more often. This is a service-specific lever.</p>
<p>Another service-specific lever is Longboat’s “overlap interval” configuration, which configures an extraction job to redundantly ingest some overlapping span of records in an effort to catch late-arriving data. It’s specified in a number of hours.</p>
<p>Memory and CPU are universal compute levers that we ensure we have control of. Longboat and Reportify run on Google Kubernetes Engine, so it’s possible to demand that jobs request more raw compute to get their expected amount of work done within their scheduled interval (ignoring total compute constraints for the sake of this discussion).</p>
<p>So, in pursuit of data freshness in Longboat, we can manipulate:</p>
<ol>
<li>Job frequency</li>
<li>Longboat overlap interval</li>
<li>Kubernetes Engine Memory/CPU requests</li>
</ol>
<p>In pursuit of <em>latency</em> in Reportify, we can turn knobs like its:</p>
<ol>
<li>BigTable node pool size&nbsp;</li>
<li>ProxySQL connection pool/queue size</li>
</ol>
<h2>3. Run Load Tests!</h2>
<p>Now that we have some known controls, we can use them to deliberately constrain the service’s resources. As an example, to simulate an unrelenting N-times throughput increase, we can turn the infrastructure knobs so that we have 1/N the amount of compute headroom, so we’re at N-times nominal load.</p>
<p>For Longboat’s simulation, we manipulated its “overlap interval” configuration and tripled it. Every table suddenly looked like it had roughly three times more data to ingest within an unchanged job frequency; throughput was tripled.</p>
<p>For Reportify, we leveraged our <a href="https://shopify.engineering/performance-testing-shopify" target="_blank" title="Pummelling the Platform–Performance Testing Shopify - Shopify Engineering" rel="nofollow noopener noreferrer">load testing tools</a> to simulate some truly haunting throughput scenarios, issuing an increasingly extreme volume of queries, as seen here:</p>
<figure><img alt="A line graph showing streaming service queries per second by source. The graph shows increase in the volume of queries over time during a load test." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/streaming-queries-per-second-graph.jpg?v=1607444696" src="https://cdn.shopify.com/s/files/1/0779/4361/files/streaming-queries-per-second-graph.jpg?v=1607444696">
<figcaption>Streaming service queries per second metric after the load test</figcaption>
</figure>
<p>In this graph, the doom is shaded purple.&nbsp;</p>
<p>Load testing answers a few questions immediately, among others:</p>
<ul>
<li>Do infrastructure constraints affect service uptime?&nbsp;</li>
<li>Does the service’s underlying code gracefully handle memory/CPU constraints?</li>
<li>Are the raised service alarms expected?</li>
<li>Do you know what to do in the event of every fired alarm?</li>
</ul>
<p>If any of the answers to these questions leave us unsatisfied, the reliability roadmap writes itself: we need to engineer our way into satisfactory answers to those questions. That leads us to the next step.&nbsp;</p>
<h2>4. Confirm Mitigation Strategies Are Up-to-Date</h2>
<p>A service’s reliability depends on the speed at which it can recover from interruption. Whether that recovery is performed by a machine or human doesn’t matter when your CTO is staring at a service’s reliability metrics! After deliberately constraining resources, the operations channel turns into a (controlled) hellscape and it's time to act as if it were a real production incident.</p>
<p>Talking about mitigation strategy could be a blog post on its own, but here are the tenets we found most important:</p>
<ol>
<li>
<strong>Every alert must be directly actionable</strong>. Just saying “the curtains are on fire!” without mentioning “put it out with the extinguisher!” amounts to noise.</li>
<li>
<strong>Assume that mitigation instructions will be read by someone broken out of a deep sleep</strong>. Simple instructions are carried out the fastest.</li>
<li>
<strong>If there is </strong><strong><em>any </em></strong><strong>ambiguity or unexpected behavior during controlled load tests, you’ve identified new reliability risks.</strong> Your service is less reliable than you expected. For Tier 1 services, that means everything else drops and those risks should be addressed immediately.</li>
<li>
<strong>Plan another controlled load test</strong> and ensure you’re confident in your recovery.</li>
<li>
<strong>Always over-communicate, even if acting alone</strong>. Other engineers will devote their brain power to your struggle.</li>
</ol>
<h2>5. Turn the Knobs Back</h2>
<p>Now that we know what can happen with an overburdened infrastructure, we can make an informed decision whether the service carries real throughput risk. If we absolutely hammered the service and it skipped along smiling without risking its primary objective, we can leave it alone (or even scale <em>down</em>, which will have the CFO smiling too).</p>
<p>If we don’t feel confident in our ability to recover, we’ve unearthed new risks. The service’s development team can use this information to plan resiliency projects, and we can collectively scale our infrastructure to minimize throughput risk in the interim.</p>
<p>In general, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/reliably-scale-data-platform">https://shopify.engineering/reliably-scale-data-platform</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/reliably-scale-data-platform</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398009</guid>
            <pubDate>Sat, 12 Dec 2020 13:05:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resiliency Planning for High-Traffic Events]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398002">thread link</a>) | @oedmarap
<br/>
December 12, 2020 | https://shopify.engineering/resiliency-planning-for-high-traffic-events | <a href="https://web.archive.org/web/*/https://shopify.engineering/resiliency-planning-for-high-traffic-events">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Each year, Black Friday Cyber Monday weekend represents the peak of activity for Shopify. Not only is this the most traffic we see all year, but it’s also the time our merchants put the most trust in our team. Winning this weekend each year requires preparation, and it starts as soon as the weekend ends.</p>
<h2>Load Testing &amp; Stress Testing:&nbsp;How Does the System React?</h2>
<p>When preparing for a high traffic event, load testing regularly is key. We have discussed some of the tools we use <a href="https://shopify.engineering/performance-testing-shopify" target="_blank" rel="nofollow noopener noreferrer">already</a>, but I want to explain how we use these exercises to build towards a more resilient system.</p>
<p>While we use these tests to confirm that we can sustain required loads or probe for new system limits, we can also use regular testing to find potential regressions. By executing the same experiments on a regular basis, we can spot any trends at easily handled traffic levels that might spiral into an outage at higher peaks.</p>
<p>This same tool allows us to run similar loads against differently configured shops and look for differences caused by the theme, configuration, and any other dimensions we might want to use for comparison.</p>
<h2>Resiliency Matrix:&nbsp;What are Our Failure Modes?</h2>

<figure>
<p><img alt="This user-centric resiliency matrix shows the potential failures and their impact on user experience. For example, can a user browse (yes) or check out (no) if MySQL is down. " data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/resiliency_matrix.png?format=jpg&amp;quality=90&amp;v=1607622786" src="https://cdn.shopify.com/s/files/1/0779/4361/files/resiliency_matrix.png?format=jpg&amp;quality=90&amp;v=1607622786"></p>
<figcaption>User-centric resiliency matrix documenting expected user experience and possible failures</figcaption>
</figure>
<div><p>The act of writing this matrix serves as a very basic tabletop chaos exercise. It forces teams to consider how well they understand their dependencies and what the expected behaviors are.</p><p>This exercise also provides a visual representation of the interactions between dependencies and their failure modes. Looking across rows and columns reveals areas where the system is most fragile. This provides the starting point for planning work to be done. In the above example, this matrix should start to trigger discussion around the ‘User can check out’ experience and what can be done to make this more resilient to a single dependency going ‘down’.</p></div>
<h2>Game Days:&nbsp;Do Our Models Match?</h2>
<div><p>So, we’ve written our resilience matrix. This is a representation of our mental model of the system, and when written, it's probably a pretty accurate representation. However, systems change and adapt over time, and this model can begin to diverge from reality. </p><p>This divergence is often unnoticed until something goes wrong, and you’re stuck in the middle of a production incident asking “Why?”. Running a <a href="https://shopify.engineering/four-steps-creating-effective-game-day-tests" target="_blank" rel="nofollow noopener noreferrer">game day</a> exercise allows us to test the documented model against reality and adjust in a controlled setting.</p><p>The plan for the game day will derive from the resilience matrix. For the matrix above, we might formulate a plan like:</p></div>
<figure><img alt="This game day exercise allows us to test the model against reality and adjust in a controlled setting. This plan lays out scenarios to be tested and how they will be accomplished." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Game_day_exercise_480x480.png?format=jpg&amp;quality=90&amp;v=1607622968" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Game_day_exercise_480x480.png?format=jpg&amp;quality=90&amp;v=1607622968">
<figcaption>Game day planning scenarios&nbsp;</figcaption>
</figure>
<p>Here, we are laying out what scenarios are to be tested, how those will be accomplished, and what we expect to happen.&nbsp;</p>
<p>We’re not only concerned with external effects (what works, what doesn’t), but internally do any expected alerts fire, are the appropriate on-call teams paged, and do those folks have the information available to understand what is happening?</p>
<p>If we refer back to How Complex Systems Fail, the defences against failure are technical, human, and organizational. On a good game day, we’re attempting to exercise all of these.</p>
<ul>
<li>Do any automated systems engage?</li>
<li>Do the human operators have the knowledge, information and tools necessary to intervene?</li>
<li>Do the processes and procedures developed help or hinder responding to the outage scenario?</li>
</ul>
<p>By tracking the actual observed behavior, we can then update the matrix as needed or make changes to the system in order to bring our mental model and reality back into alignment.</p>
<h2>Incident Analysis:&nbsp;How Do We Get Better?</h2>
<div><p>During the course of the year, incidents happen which disrupt service in some capacity. While the primary focus is always in restoring service as fast as possible, each incident also serves as a learning opportunity.</p><p>This article is not about why or how to run a post-incident review; there are more than enough well-written pieces by folks who are experts on the subject. But to refer back to How Complex Systems Fail, one of the core tenets in how we learn from incidents is “<a href="https://how.complexsystems.fail/#7" title="Post-accident attribution to a ‘root cause’ is fundamentally wrong" target="_blank" rel="nofollow noopener noreferrer">Post-accident attribution to a ‘root cause’ is fundamentally wrong</a>.” </p><p>When focusing on a single root cause, we stop at easy, shallow actions to resolve the ‘obvious’ problem. However, this ignores deeper technical, organizational, and cultural issues that contributed to the issue and will again if uncorrected.</p></div>
<h2>What’s Special About BFCM?</h2>
<div><p>We’ve talked about the things we’re constantly doing, year-round to ensure we’re building for reliability and resiliency and creating an anti-fragile system that gets better after every disruption. So what do we do that’s special for the big weekend?</p><p>We’ve already mentioned How Complex Systems Fail several times, but to go back to that well once more, “<a href="https://how.complexsystems.fail/#14" target="_blank" title="Change introduces new forms of failure" rel="nofollow noopener noreferrer">Change introduces new forms of failure</a>.” As we get closer to Black Friday, we slow down the rate of change.</p><p>This doesn’t mean we’re sitting on our hands and hoping for the best, but rather we start to <a href="https://shopify.engineering/organizing-2000-developers-bfcm-remotely" target="_blank" rel="nofollow noopener noreferrer">shift where we’re investing our time</a>. Fewer new services and features as we get closer, and more time spent dealing with issues of performance, reliability, and <a href="https://shopify.engineering/capacity-planning-shopify" target="_blank" rel="nofollow noopener noreferrer">scale</a>. </p><p>We review defined resilience matrices carefully, start running more frequent game days and <a href="https://shopify.engineering/performance-testing-shopify" target="_blank" rel="nofollow noopener noreferrer">load tests</a> and working on any issues or bottlenecks those reveal. This means updating runbooks, refining internal tools, and shipping fixes for issues that this activity brings to light.</p><p>All of this comes together to provide a robust, reliable platform to power over $5.1 billion in sales.</p></div>
<p><strong>Ryan</strong> is a Senior Development Manager at Shopify. He currently leads the Resiliency team, a centralized globally distributed SRE team responsible for keeping commerce better for everyone.</p>
<hr>
<p>We're planning to DOUBLE our engineering team in 2021 by hiring 2,021 new technical roles (see what we did there?). Our platform handled record-breaking sales over BFCM and commerce isn't slowing down.&nbsp;<a href="https://www.shopify.com/careers/2021" target="_blank" title="We’re planning to double our engineering team in 2021 by hiring 2,021 new technical roles" rel="noopener noreferrer">Help us scale &amp; make commerce better for everyone</a>.</p>
</div><div><div><div><h3>Get stories like this in your inbox!</h3><p>Stories from the teams who build and scale Shopify, the leading cloud-based, multi-channel commerce platform powering over 1,000,000 businesses around the world.</p><p>Share your email with us and receive monthly updates.</p></div></div></div></div>]]>
            </description>
            <link>https://shopify.engineering/resiliency-planning-for-high-traffic-events</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398002</guid>
            <pubDate>Sat, 12 Dec 2020 13:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware – how to stay one step ahead of the cybercriminals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397639">thread link</a>) | @henrikwm
<br/>
December 12, 2020 | https://security.christmas/2020/12 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://www.stockvault.net/data/2016/07/04/203783/preview16.jpg" alt=""><div><section><p>Ransomware is extremely costly and difficult to get rid of, and once your files are encrypted you may have lost that data permanently. Giving in to the ransom demand is expensive, gives no guarantee that your data will be restored, and only encourages cybercriminals to keep attacking and extorting money from individuals and companies alike. Clearly, the best way to deal with the increased rise in ransomware attacks is to implement solid preventative measures to avoid getting infected in the first place. And, if the worst should happen and all your files do get encrypted, to have alternative ways of restoring your data. </p>
</section><article><section><p>This article will go over some good measures to reduce the risk of getting ransomware on your computer, as well as some advice what to do if you do get infected. Ransomware was covered in our <a href="https://security.christmas/2020/11">previous post</a>, so check it out for more details about what ransomware is, how it works, and the most common ways your computer gets infected. </p>
<p>The main way ransomware gets installed on your computer is through <a href="https://www.csoonline.com/article/2117843/what-is-phishing-how-this-cyber-attack-works-and-how-to-prevent-it.html">phishing</a>, a form of social engineering where an individual is tricked into installing the malware. There are several things to look out for:</p>
<h2>Social engineering – reduce the people factor</h2>
<ol>
<li>Do not click on any links that are not verified. These can come through a seemingly legit email or website. Downloads will usually start as soon as you click on a link, so use extra caution, and if in doubt do not click on it. </li>
<li>Do not open email attachments from untrusted sources. Also, be aware that some phishing attacks are highly specialized and could be adapted for you specifically or the company you work in (so-called spear phishing). One tip is to use the show file extensions feature to see if any attachments are executable, e.g. ending in .bat, .sh, .dmg, or .exe. If so, do not open it. </li>
<li>If an colleague sends a genuine email that looks like phishing, let them know so that the culture for writing good a proper emails will improve in your company. </li>
<li>Use caution when downloading from websites. Browsers will give an indication if the site is verified, usually in the form of a lock symbol or a shield. However, even verified websites may have security vulnerabilities or may even be phishing sites, so it is still necessary to exercise caution. Also, make sure the site uses HTTPS instead of HTTP to ensure secure encryption of requests and responses. </li>
<li>Be careful not to share personal information. Criminals may use this information to send personalized emails specifically to you, increasing the likelihood of doing what they ask of you. </li>
<li>For companies, provide training for employees so that they can recognize malicious emails and phishing attempts more easily. </li>
</ol>
<p>Ransomware can also exploit technological vulnerabilities. There are a few dos and don’ts to make sure your technological routines are up to scratch. </p>
<h2>Limit technological vulnerabilities</h2>
<ol>
<li>Make sure you scan all your emails and attachments using content scanning and filtering on your mail servers. This will reduce the chance of a malicious email ending up in your inbox. </li>
<li>Outdated versions on browsers, software, and operating systems may have vulnerabilities that can be exploited, so make sure to always update to the latest versions when possible. </li>
<li>Use good antivirus software that also include ransomware, and a firewall. There are several good ones that will block infected files and prevent your computer from being encrypted, but only use from reputable sources as there are also a lot of fake antivirus software out there. </li>
<li>When connecting to the Internet from a public WIFI, make sure you use a VPN. </li>
<li>Only give admin privileges when necessary. Restricted access for normal users may reduce the spread of the malware if one employee’s computer is attacked by ransomware.</li>
</ol>
<h2>Backup your data!</h2>
<p>This cannot be stressed enough and may be the most important measure you do. Having a good backup system is key to protect yourself from losing your data. Instead of paying the ransom, it is better to reinstall everything from good and recent backups, so make sure you have a backup on an external hard drive or in the cloud so that the backup data doesn’t get infected along with your computer. </p>
<h2>Worst case scenario – all my files are encrypted</h2>
<p>First off, make sure it is actual ransomware and not just an imitation (such as screen-locking ransomware). The latter may be more easily removed, and is often characterized by trying to shame the victim (eg having been caught looking at adult websites) and pretending to from a source such as the FBI or the police. If you can read most of your files and navigate through your computers system, it is most likely a fake. </p>
<p>However, if the ransomware is authentic there are three main paths you could chose:</p>
<h3>Paying the ransom</h3>
<p>First off, it is not recommended to pay the ransom. This will only encourage this type of attack, and there is no guarantee that you will receive the decryption key. Some may even ask for the ransom one more time before they give what you payed for. </p>
<p>That being said, some have chosen to recover the data by paying the fee, especially in the case of medical records or where there is no good backup to reinstall your files from. This is not an easy issue, and the pros and cons can be discussed at length. Again, take good backups of your data, and you will not have to be faced with this dilemma should you be so unfortunate to have all your files encrypted. </p>
<h3>Restoring your system from backups</h3>
<p>Disconnect your infected computer or system from the Internet and other devices, and use an antivirus to remove the ransomware. Note, this will not recover your files, but should remove the virus from your system. Check if there are any deleted files you might recover. Also, finding the exact type of ransomware strain might help you decrypt the files (though not in most cases). There are some online tools like <a href="https://id-ransomware.malwarehunterteam.com/">ID Ransomware</a> and <a href="https://www.nomoreransom.org/crypto-sheriff.php">Crypto Sheriff</a> that will help you with this. There are also some decryption tools available for some strains, so checkout <a href="https://www.nomoreransom.org/en/index.html">No More Ransom</a> if a decryption key exist for a specific strain. </p>
<p>If decryption is not possible, then restore the files from your backups. The best is to wipe your computer or system completely, reinstall the operating system, and then restore the files to make sure all traces of the virus is removed. Make sure your backup is not infected before you start. This is the fastest and cheapest way of getting your systems up and running again.</p>
<h3>Restore your system and lose you data</h3>
<p>This may not be optimal, but if your data is not very important or something you can’t replace, then simply choosing to reinstall you affected system may be a good solution. </p></section></article></div></article></main></div></div>]]>
            </description>
            <link>https://security.christmas/2020/12</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397639</guid>
            <pubDate>Sat, 12 Dec 2020 11:37:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A one-click WordPress-to-static tool]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397515">thread link</a>) | @m1guelpf
<br/>
December 12, 2020 | https://sitesauce.app/for/wordpress | <a href="https://web.archive.org/web/*/https://sitesauce.app/for/wordpress">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>If you have an existing website, migrating your theme, plugins and content can be a hard task. You'd also lose the simplicity of having an admin panel and allowing multiple users to work on your content together.</p><p>Part of this problem could be solved by having your static site pull data from WordPress on build, but this brings up other problems, like having to manage two different codebases for a single website, migrating your themes over or needing to deploy to preview your content.</p><p>Sitesauce takes care of all this for you. After signing up and entering a URL, we'll generate a production-ready static version of your website and deploy it. You keep your dashboard and remove unnecessary complexity.</p></div></div></div></div>]]>
            </description>
            <link>https://sitesauce.app/for/wordpress</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397515</guid>
            <pubDate>Sat, 12 Dec 2020 11:10:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handling hyperlinks in the Google Sheets C# SDK – tietokone.io]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397405">thread link</a>) | @lukedawilson
<br/>
December 12, 2020 | https://blog.tietokone.io/handling-hyperlinks-in-google-sheets-c-sdk/ | <a href="https://web.archive.org/web/*/https://blog.tietokone.io/handling-hyperlinks-in-google-sheets-c-sdk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recently, when writing a script to import data from Google Sheets into a database using the <a href="https://developers.google.com/sheets/api/quickstart/dotnet">C# SDK</a>, I came across a problem handling pasted hyperlinks in the source spreadsheet. The solution in the end was, thankfully, fairly straightforward, but Google’s documentation was quite poor, and I found little useful information on the web. Hopefully this post will save a few developers some time (and prevent a few grey hairs in the process).</p>

<p>As Martin Hawksey explains in his <a href="https://mashe.hawksey.info/2020/04/everything-a-google-apps-script-developer-wanted-to-know-about-reading-hyperlinks-in-google-sheets-but-was-afraid-to-ask/">blog</a>, Google Sheets (and indeed Excel) handles hyperlinks in three different ways:</p>

<ul>
  <li>Plain text that Google sheets detects as links</li>
  <li>The <code>HYPERLINK</code> <a href="https://support.google.com/docs/answer/3093313?hl=en-GB">formula</a></li>
  <li>Hidden links – scenarios such as copy/pasting links from a website to Google Sheets</li>
</ul>

<p>The SDK handles the first two types of link without problems, but when it comes to the third kind, it simply returns the link title, losing the link address! This seems a particularly poor design, but there we are.</p>

<p><img src="https://mcdn.hawksey.info/wp-content/uploads/2020/04/hyperlink.gif" alt="Example from Martin Hawksey's blog">
<em>In Martin’s example, the C# SDK would process the first two links correctly, but would only return <code>HOME</code> for the third link, losing the address entirely.</em></p>

<p>Fortunately, the <a href="https://developers.google.com/sheets/api/reference/rest/v4/spreadsheets/get?apix_params=%7B%22spreadsheetId%22%3A%221UAAnqHrIL9fvVSq626NcoBcPwJ5U-jrnmoqeV6pFBD0%22%2C%22ranges%22%3A%5B%22B1%3AB3%22%5D%2C%22fields%22%3A%22sheets%2Fdata%2FrowData%2Fvalues%2FuserEnteredValue%2Csheets%2Fdata%2FrowData%2Fvalues%2Fhyperlink%22%7D">REST API</a> can be made to return both the title and the address, by specifying the <code>sheets/data/rowData/values/userEnteredValue</code> and <code>sheets/data/rowData/values/hyperlink</code> fields:</p>

<div><div><pre><code><span>$ </span>curl <span>\</span>
  <span>'https://sheets.googleapis.com/v4/spreadsheets/1UAAnqHrIL9fvVSq626NcoBcPwJ5U-jrnmoqeV6pFBD0?ranges=B1%3AB3&amp;fields=sheets%2Fdata%2FrowData%2Fvalues%2FuserEnteredValue%2Csheets%2Fdata%2FrowData%2Fvalues%2Fhyperlink&amp;key=[YOUR_API_KEY]'</span> <span>\</span>
  <span>--header</span> <span>'Authorization: Bearer [YOUR_ACCESS_TOKEN]'</span> <span>\</span>
  <span>--header</span> <span>'Accept: application/json'</span> <span>\</span>
  <span>--compressed</span>
</code></pre></div></div>

<p>The response will look something like this:</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"sheets"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>{</span><span>
      </span><span>"data"</span><span>:</span><span> </span><span>[</span><span>
        </span><span>{</span><span>
          </span><span>"rowData"</span><span>:</span><span> </span><span>[</span><span>
            </span><span>{</span><span>
              </span><span>"values"</span><span>:</span><span> </span><span>[</span><span>
                </span><span>{</span><span>
                  </span><span>"userEnteredValue"</span><span>:</span><span> </span><span>{</span><span>
                    </span><span>"stringValue"</span><span>:</span><span> </span><span>"https://developers.google.com/apps-script/"</span><span>
                  </span><span>},</span><span>
                  </span><span>"hyperlink"</span><span>:</span><span> </span><span>"https://developers.google.com/apps-script/"</span><span>
                </span><span>}</span><span>
              </span><span>]</span><span>
            </span><span>},</span><span>
            </span><span>{</span><span>
              </span><span>"values"</span><span>:</span><span> </span><span>[</span><span>
                </span><span>{</span><span>
                  </span><span>"userEnteredValue"</span><span>:</span><span> </span><span>{</span><span>
                    </span><span>"formulaValue"</span><span>:</span><span> </span><span>"=HYPERLINK(</span><span>\"</span><span>https://developers.google.com/apps-script/</span><span>\"</span><span>, </span><span>\"</span><span>This is a HYPERLINK</span><span>\"</span><span>)"</span><span>
                  </span><span>},</span><span>
                  </span><span>"hyperlink"</span><span>:</span><span> </span><span>"https://developers.google.com/apps-script/"</span><span>
                </span><span>}</span><span>
              </span><span>]</span><span>
            </span><span>},</span><span>
            </span><span>{</span><span>
              </span><span>"values"</span><span>:</span><span> </span><span>[</span><span>
                </span><span>{</span><span>
                  </span><span>"userEnteredValue"</span><span>:</span><span> </span><span>{</span><span>
                    </span><span>"stringValue"</span><span>:</span><span> </span><span>"HOME"</span><span>
                  </span><span>},</span><span>
                  </span><span>"hyperlink"</span><span>:</span><span> </span><span>"https://developers.google.com/apps-script/"</span><span>
                </span><span>}</span><span>
              </span><span>]</span><span>
            </span><span>}</span><span>
          </span><span>]</span><span>
        </span><span>}</span><span>
      </span><span>]</span><span>
    </span><span>}</span><span>
  </span><span>]</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>By reverse-engineering the SDK, I was able to determine how it builds up the request, and found that it exposes the authenticated HTTP client that it uses to send requests. From there, it was a simple matter to construct the appropriate request, grab the client, and parse the response JSON:</p>

<div><div><pre><code><span>// Configure and authorise service</span>
<span>using</span> <span>var</span> <span>stream</span> <span>=</span> <span>new</span> <span>FileStream</span><span>(</span><span>"path/to/credentials"</span><span>,</span> <span>FileMode</span><span>.</span><span>Open</span><span>,</span> <span>FileAccess</span><span>.</span><span>Read</span><span>,</span> <span>FileShare</span><span>.</span><span>Read</span><span>);</span>

<span>var</span> <span>credential</span> <span>=</span> <span>(</span><span>ServiceAccountCredential</span><span>)</span><span>GoogleCredential</span><span>.</span><span>FromStream</span><span>(</span><span>stream</span><span>).</span><span>UnderlyingCredential</span><span>;</span> <span>// this example is for a service account, but you could also use web authorisation</span>
<span>credential</span> <span>=</span> <span>new</span> <span>ServiceAccountCredential</span><span>(</span><span>new</span> <span>ServiceAccountCredential</span><span>.</span><span>Initializer</span><span>(</span><span>credential</span><span>.</span><span>Id</span><span>)</span>
<span>{</span>
    <span>User</span> <span>=</span> <span>"MyUsername"</span><span>,</span>
    <span>Key</span> <span>=</span> <span>credential</span><span>.</span><span>Key</span><span>,</span>
    <span>Scopes</span> <span>=</span> <span>new</span><span>[]</span> <span>{</span> <span>SheetsService</span><span>.</span><span>Scope</span><span>.</span><span>Spreadsheets</span> <span>}</span>
<span>});</span>

<span>var</span> <span>options</span> <span>=</span> <span>new</span> <span>BaseClientService</span><span>.</span><span>Initializer</span>
<span>{</span>
    <span>HttpClientInitializer</span> <span>=</span> <span>credential</span><span>,</span>
    <span>ApplicationName</span> <span>=</span> <span>"MyApplication"</span><span>,</span>
<span>};</span>

<span>var</span> <span>sheetsService</span> <span>=</span> <span>new</span> <span>SheetsService</span><span>(</span><span>options</span><span>);</span>

<span>// Define the request, specifying the 'hyperlink' field</span>
<span>var</span> <span>request</span> <span>=</span> <span>sheetsService</span><span>.</span><span>Spreadsheets</span><span>.</span><span>Get</span><span>(</span><span>mySpreadsheetId</span><span>);</span>
<span>request</span><span>.</span><span>Ranges</span> <span>=</span> <span>new</span> <span>Repeatable</span><span>&lt;</span><span>string</span><span>&gt;(</span><span>new</span><span>[]</span> <span>{</span> <span>myRange</span> <span>});</span>
<span>request</span><span>.</span><span>Fields</span> <span>=</span> <span>"sheets/data/rowData/values/userEnteredValue,sheets/data/rowData/values/hyperlink"</span><span>;</span>

<span>// Make the http request, and parse the response</span>
<span>using</span> <span>var</span> <span>httpRequest</span> <span>=</span> <span>request</span><span>.</span><span>CreateRequest</span><span>();</span>
<span>var</span> <span>response</span> <span>=</span> <span>await</span> <span>sheetsService</span><span>.</span><span>HttpClient</span><span>.</span><span>SendAsync</span><span>(</span><span>httpRequest</span><span>);</span>
<span>var</span> <span>content</span> <span>=</span> <span>await</span> <span>response</span><span>.</span><span>Content</span><span>.</span><span>ReadAsStringAsync</span><span>();</span>
<span>var</span> <span>rows</span> <span>=</span> <span>JsonConvert</span><span>.</span><span>DeserializeObject</span><span>&lt;</span><span>GoogleSheetsResponse</span><span>&gt;(</span><span>content</span><span>);</span> <span>// Newtonsoft.Json</span>
</code></pre></div></div>

<p>The response structure has a bit of nesting, so I defined the following classes to deserialise it into:</p>

<div><div><pre><code><span>public</span> <span>class</span> <span>GoogleSheetsResponse</span>
<span>{</span>
    <span>public</span> <span>Sheet</span><span>[]</span> <span>Sheets</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>

<span>public</span> <span>class</span> <span>Sheet</span>
<span>{</span>
    <span>public</span> <span>Data</span><span>[]</span> <span>Data</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>

<span>public</span> <span>class</span> <span>Data</span>
<span>{</span>
    <span>public</span> <span>RowData</span><span>[]</span> <span>RowData</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>

<span>public</span> <span>class</span> <span>RowData</span>
<span>{</span>
    <span>public</span> <span>Value</span><span>[]</span> <span>Values</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>

<span>public</span> <span>class</span> <span>Value</span>
<span>{</span>
    <span>public</span> <span>UserEnteredValue</span> <span>UserEnteredValue</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
    <span>public</span> <span>string</span> <span>Hyperlink</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>

    <span>public</span> <span>string</span> <span>GetString</span><span>()</span> <span>=&gt;</span> <span>UserEnteredValue</span><span>?.</span><span>StringValue</span> <span>??</span> <span>UserEnteredValue</span><span>?.</span><span>NumberValue</span><span>?.</span><span>ToString</span><span>();</span>

    <span>public</span> <span>long</span> <span>GetNumber</span><span>()</span> <span>=&gt;</span>
        <span>UserEnteredValue</span><span>?.</span><span>NumberValue</span> <span>??</span>
            <span>(</span><span>long</span><span>.</span><span>TryParse</span><span>(</span><span>UserEnteredValue</span><span>?.</span><span>StringValue</span><span>,</span> <span>out</span> <span>var</span> <span>parsed</span><span>)</span> <span>?</span> <span>parsed</span> <span>:</span> <span>(</span><span>long</span><span>?)</span><span>null</span><span>)</span> <span>??</span>
                <span>throw</span> <span>new</span> <span>InvalidOperationException</span><span>();</span>
<span>}</span>

<span>public</span> <span>class</span> <span>UserEnteredValue</span>
<span>{</span>
    <span>public</span> <span>string</span> <span>StringValue</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
    <span>public</span> <span>long</span><span>?</span> <span>NumberValue</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>So there we have it. I do hope Google update their SDK to handle this, or at least improve the documentation, but for now, we have a viable workaround.</p>

<p>In my next post, I’ll be continuing the Google Sheets theme, looking at how to convert Excel workbooks into Google spreadsheets.</p>

  </div></div>]]>
            </description>
            <link>https://blog.tietokone.io/handling-hyperlinks-in-google-sheets-c-sdk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397405</guid>
            <pubDate>Sat, 12 Dec 2020 10:50:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional TypeScript with FP-Ts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397089">thread link</a>) | @bendiksolheim
<br/>
December 12, 2020 | https://functional.christmas/2020/12 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>I know, I know, I’m not really supposed to feel this way. It’s supposed to be this weird language full of flaws that never follows established rules and conventions, and we’re all supposed to not like it. But that’s just not the case for me – despite all the quirks and unusual behavior I still enjoy it.</p>
<p>There are, of course, sides of it I enjoy less. The two things I dislike the most are lack of strong, static typing, and a well-built standard library. The standard library is still growing, and the newer parts of it are not too bad – the older parts, though, are all over the place: they mutate, and lack consistency.</p>
<p>Not too long ago I came across this library named <code>fp-ts</code>, that together with <code>TypeScript</code> made my whole JavaScript experience <em>a lot</em> better. This blog post aims to give you a short introduction to this library, and show you some of its strenghts. To keep this blog post short, I will assume you know both JavaScript and TypeScript. You will probably still understand most of it even if you are not fluid in any of them, but consider yourself warned.</p>
<h2>fp-ts</h2>
<p><a href="https://github.com/gcanti/fp-ts">fp-ts</a> introduces <em>many</em> functional concepts. If you come from Java or Kotlin, you can compare it to <a href="https://www.vavr.io/">Vavr</a> or <a href="https://arrow-kt.io/">Arrow</a>, respectively. It provides several well known data types, type classes, a consistent library of functions, and several other functional abstractions.</p>
<p>Wading through every feature of fp-ts would be an enourmous task, and one way too overkill for this blog. Instead, I will take you through some of the simpler concepts that anyone can benefit from. My goal is to show you exactly how to make use of some of these concepts, so you can take use of them right after.</p>
<p>Let’s get started!</p>
<h3>The Data Types</h3>
<p>Let’s start with two data types I use more or less daily: <code>Option</code> and <code>Either</code>. If you are completely new to functional programming, I suggest starting with these as they encourage a coding style that is safe, and can help you understand other aspects of functional programming later on.</p>
<p>An <code>Option</code> type represents an optional value. Something you either have, or don’t have. This is useful when lacking a value is valid in your domain, or when a function may or may not return a value. Let’s see some code.</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> Option<span>,</span> some<span>,</span> none<span>,</span> map <span>}</span> <span>from</span> <span>"fp-ts/Option"</span>

<span>type</span> <span>User</span> <span>=</span> <span>{</span>
  id<span>:</span> <span>number</span><span>,</span>
  username<span>:</span> <span>string</span><span>,</span>
  expiration<span>:</span> Date
<span>}</span>

<span>function</span> <span>getUserById</span><span>(</span>id<span>:</span> <span>number</span><span>)</span><span>:</span> Option<span>&lt;</span>User<span>&gt;</span> <span>{</span> <span>.</span><span>.</span> <span>}</span>

<span>const</span> userOne <span>=</span> <span>getUserById</span><span>(</span><span>1</span><span>)</span> 
<span>const</span> userTwo <span>=</span> <span>getUserById</span><span>(</span><span>2</span><span>)</span> 

<span>const</span> getUserName <span>=</span> <span>(</span>u<span>:</span> User<span>)</span><span>:</span> <span>string</span> <span>=&gt;</span> u<span>.</span>username

<span>const</span> usernameOne <span>=</span> <span>map</span><span>(</span>getUserName<span>)</span><span>(</span>userOne<span>)</span> 
<span>const</span> usernameTwo <span>=</span> <span>map</span><span>(</span>getUserName<span>)</span><span>(</span>userTwo<span>)</span> </code></pre></div>
<p>Before we go through the code, I’d just like to point out the use of <a href="https://en.wikipedia.org/wiki/Partial_application">partial application</a> in the two last lines. Lots of functions in <code>fp-ts</code> are <a href="https://en.wikipedia.org/wiki/Currying">curried</a> by default, as is often common in functional languages. This pattern is really convenient when you want to bind some, but not all, parameters of a function.</p>
<p>So, an <code>Option</code>&nbsp;wraps a value, and allows operations to be performed through functions such as <code>map</code>, <code>filter</code>, <code>fold</code> and others. This example demonstrates a really nice property of the <code>Optional</code>: your business code can describe the "happy path" – error handling is abstracted into the <code>Option</code> itself. We never have to check for <code>null</code>&nbsp;values before getting the username from the user, because the function <code>getUserName</code> is run in a safe context. <code>map</code> runs the provided function on an <code>Option</code> only if it is a <code>some</code>, and not a <code>none</code>. The same is true for other functions on the <code>Option</code>.</p>
<p>But what if you wanted to display, or use, the username? You can’t just extract the value from inside an <code>Option</code>, as you don’t know whether it is a <code>some</code> or a <code>none</code>. To get the actual value from the <code>Option</code>, you need to specify what to do both when it is a <code>none</code>, and a <code>some</code>. Let’s take a look at two safe ways of extracting your value from the <code>Option</code>.</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> fold<span>,</span> getOrElse <span>}</span> <span>from</span> <span>"fp-ts/Option"</span><span>;</span>


<span>const</span> usernameLength <span>=</span> <span>fold</span><span>(</span>
  <span>(</span><span>)</span> <span>=&gt;</span> <span>0</span><span>,</span>
  <span>(</span>username<span>:</span> <span>string</span><span>)</span> <span>=&gt;</span> username<span>.</span>length
<span>)</span><span>;</span>

<span>const</span> usernameOneLength<span>:</span> <span>number</span> <span>=</span> <span>usernameLength</span><span>(</span>usernameOne<span>)</span><span>;</span> 
<span>const</span> usernameTwoLength<span>:</span> <span>number</span> <span>=</span> <span>usernameLength</span><span>(</span>usernameTwo<span>)</span><span>;</span> 

<span>const</span> getOrEmpty <span>=</span> <span>getOrElse</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>""</span><span>)</span><span>;</span>

<span>const</span> usernameOneValue<span>:</span> <span>string</span> <span>=</span> <span>getOrEmpty</span><span>(</span>usernameOne<span>)</span><span>;</span> 
<span>const</span> usernameTwoValue<span>:</span> <span>string</span> <span>=</span> <span>getOrEmpty</span><span>(</span>usernameTwo<span>)</span><span>;</span> </code></pre></div>
<p>With both <code>fold</code> and <code>getOrElse</code>, the type system forces us to handle both the missing and the non-missing state. You now have a safe way of handling missing values, and even a safe way of getting them out as well – no more checking for <code>null</code> all over the place!</p>
<p>Let’s modify the function <code>getUserById</code> from the first example a bit. Instead of just returning a <code>none</code>, we would like to know <em>why</em> it was not returned. An <code>Option</code> can’t help you with this. Instead, you need something like the <code>Either</code>. Where an <code>Option</code> is either a <code>none</code> or a <code>some</code>, the <code>Either</code> is either a <code>left</code> or a <code>right</code>. It holds a value in both cases. The <code>Either</code> is often used to model situations where an operation can either fail or succeed. By convention, the <code>left</code> case represents the failure, and the <code>right</code> case represents success.</p>
<p>Aaaaaanyway. As stated, let’s change our <code>getUserById</code> function to also tell us <em>why</em> it was unsuccessful.</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> Either<span>,</span> right<span>,</span> left<span>,</span> map <span>}</span> <span>from</span> <span>"fp-ts/Either"</span>

<span>type</span> <span>UserError</span> <span>=</span> <span>"UserNotFound"</span> <span>|</span> <span>"UserExpired"</span>

<span>function</span> <span>getUserById</span><span>(</span>id<span>:</span> <span>number</span><span>)</span><span>:</span> Either<span>&lt;</span>UserError<span>,</span> User<span>&gt;</span> <span>{</span> <span>.</span><span>.</span> <span>}</span>


<span>const</span> userOne <span>=</span> <span>getUserById</span><span>(</span><span>1</span><span>)</span> 
<span>const</span> userTwo <span>=</span> <span>getUserById</span><span>(</span><span>2</span><span>)</span> 

<span>const</span> usernameOne <span>=</span> <span>map</span><span>(</span>getUserName<span>)</span><span>(</span>userOne<span>)</span> 
<span>const</span> usernameTwo <span>=</span> <span>map</span><span>(</span>getUserName<span>)</span><span>(</span>userTwo<span>)</span> </code></pre></div>
<p>This is not too far from the first example with the <code>Option</code>, with the added value that we now also know why it failed. It was either not found, or it was expired. Just as with the <code>Option</code>, <code>Either</code> is also a wrapper around your value(s), abstracting away the error case until you need the actual value. <code>Either</code> has its own version of <code>fold</code>, among others, which can be used to extract the value. I’ll leave you with the task of implementing this – if you need a hint, I can tell you it’s more or less the same as with <code>Option</code>!</p>
<p>So, which type should you use? It’s the usual, booring answer: it all the depends. It all depends on how the operation might fail, and what it would result in. It also boils down to semantics – is the lack of a value valid in your domain, or is it an error? In the former case, and <code>Option</code> is more suitable. In the latter, an <code>Either</code> might be better. As always: if you are unsure, just try one of them – you will soon find out if it was right or wrong.</p>
<h3>Pipes and flows</h3>
<p>Function composition is a central concept in functional programming. It is the act of combining simple functions to build more complicated ones. Smaller and simpler functions are easier to reason about and test, but can’t perform complex operations by themselves.</p>
<p>You could of course just call your simple functions in succession in a larger function. Either by saving the result of each step, or wrapping your functions inside each other. Both of these gets more and more tedious the more functions you need to call, and hides the important details: the actual logic and transformation. Let’s take a look at two functions called&nbsp;<code>pipe</code> and <code>flow</code>, which both make composition easier. They are quite alike, but have different use cases.</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> pipe<span>,</span> flow <span>}</span> <span>from</span> <span>"fp-ts/function"</span><span>;</span>

<span>const</span> <span>square</span> <span>=</span> <span>(</span>x<span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> x <span>*</span> x<span>;</span>
<span>const</span> <span>timesTen</span> <span>=</span> <span>(</span>x<span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> x <span>*</span> <span>10</span><span>;</span>

<span>const</span> result <span>=</span> <span>pipe</span><span>(</span><span>3</span><span>,</span> square<span>,</span> timesTen<span>)</span><span>;</span> 

<span>const</span> squareAndMultiply <span>=</span> <span>flow</span><span>(</span>square<span>,</span> timesTen<span>)</span><span>;</span>

<span>const</span> result2 <span>=</span> <span>squareAndMultiply</span><span>(</span><span>3</span><span>)</span><span>;</span> </code></pre></div>
<p><code>result</code> and <code>result2</code> have the same value, but are computed differently. <code>pipe</code> gives us the ability to pipe a value through a list of functions, and produce an output. This is nice for those one-off situations where you need to combine a few functions to produce a result. <code>flow</code> is more suited for those situations where you want to compose functions and create a new function permanently. In both cases, everything needs to typecheck – the input to one function needs to be of the same type as the output from the previous, all the way through.</p>
<h3>Extended built-ins</h3>
<p>As I said in the beginning of this post, JavaScripts standard library is in a bit of a weird position. If we take <code>Array</code> as an example, there is a distinction between functions that mutates in place, and functions that instead returns a new value. Things are moving to a better place, but we still have these old, mutating, functions that we have to live with. <code>fp-ts</code>&nbsp;fixes this by providing a consistent library even for JavaScript built-ins such as <code>Array</code> and <code>Map</code>. It’s not only consistent on the different types themselves, but also across the types thanks to extensive use of type classes <sup id="fnref-1"><a href="#fn-1">1</a></sup>. Every class that adheres to the <code>Functor</code> type class supports the <code>map</code> function, and every class that adheres to the <code>Filterable</code> type class can be filtered and partitioned. If this is greek to you, just ignore the lingo and appreciate the fact that most types has <code>map</code>, <code>filter</code>, <code>reduce</code> and loads of other functions implemented on them. You can even implement them on types you create yourself as well!</p>
<h3>... and so much more</h3>
<p>We have only really scratched the surface here. These concepts should give you enough to get you started, and hopefully see the value in this library. When you’re ready, there are tons of other concepts to dive into, which can make your code even more readable and safe. I haven’t had the time to wade through it all myself, so I still keep finding small gems which makes my day just a bit easier.</p>
<p>If you want to know more, the <a href="https://gcanti.github.io/fp-ts/learning-resources/">learning resources section</a> of the <a href="https://gcanti.github.io/fp-ts/">documentation</a> is actually quite good. As the author states, fp-ts does not really aim to teach functional programming from the ground up, but the resources are still good and manages to convince at least me quite well.</p>
<p>I also recommend reading the source code. It is surprisingly readable, even to me – a person who is neither fluent in advanced typescript or an FP zealot.</p>
<p><sup id="fnref-1"><a href="#fn-1">1</a></sup> – These are not «real» type classes, they are type classes implementet with interfaces. You can’t use the same <code>map</code> function on all <code>Functor</code>s, but all <code>Functor</code>s has …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://functional.christmas/2020/12">https://functional.christmas/2020/12</a></em></p>]]>
            </description>
            <link>https://functional.christmas/2020/12</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397089</guid>
            <pubDate>Sat, 12 Dec 2020 09:47:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oracle Migration to Austin to Take Place over Next 100 Years]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25396874">thread link</a>) | @markthethomas
<br/>
December 12, 2020 | https://unicorn.computer/oracle-migration-to-austin-taking-place-over-next-100-years | <a href="https://web.archive.org/web/*/https://unicorn.computer/oracle-migration-to-austin-taking-place-over-next-100-years">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(San Francisco, CA) - Another longtime corporate resident of the San Francisco Bay Area is leaving town. Oracle, maker of acronym-based software (CRM, ERP, HCM, SCM, and more) as well as database technology is pulling up roots and moving to Austin, Texas. The move comes as a number of other companies have announced similar plans to migrate their corporate headquarters out of California, including Tesla, Palantir, and Hewlett Packard Enterprise.</p>
<p>A difference for Oracle, however, is that the migration process will take much, much longer than other companies. We were able to reach an Oracle spokesperson to help us understand why the migration will take so long:</p>
<blockquote>
<p>"Well, our legal units will move first. They're the heart of our company and comprise about 125,000 of our 135,000 employees. That should be fast. 3-5 years, tops. The real challenge comes for migrating our database teams and technologies. That will be a herculean effort. Our team's earliest estimates show it taking anywhere between 75 and 100 years to complete the migration"</p>
</blockquote></div></div>]]>
            </description>
            <link>https://unicorn.computer/oracle-migration-to-austin-taking-place-over-next-100-years</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396874</guid>
            <pubDate>Sat, 12 Dec 2020 08:59:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Positive habits are underestimated [All the time]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396845">thread link</a>) | @KlimYadrintsev
<br/>
December 12, 2020 | https://klimy.co/blog/positive-habits-12-12-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/positive-habits-12-12-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <p>We, humans, tend to have a very tough time taking breaks and regenerating. We tend to set for ourself goals that are either too hard to achieve or straight up take too much of our time.</p>
<p>We have all been there. We decide to learn an additional skill, or we decided to lose that last weight that has been bringing us down.</p>
<p>The problem starts when we have outlined the goal, and we decide on the path of reaching it. We get motivated to start by motion which as a result, at the beginning we fill that we are superhumans. That can cause you to overestimate your free time and capabilities.</p>
<p>How many of us quit the gym completely, just because going there every day was not sustainable? How many of us stopped learning a new language because cramming study sessions on the weekends is not healthy and neither fun? Raise your hands. I know that I did both of those.</p>
<p>I have been a victim for underestimating how much time could the task take and the effort that will be required to finish it. I am <a href="https://klimy.co/blog/why-small-habits-11-12-2020">raising a hand for that.</a></p>
<h2>How human usually deal with no energy</h2>
<p>So if you constantly do something too challenging, you are draining your energy instead of getting the boost of cognitive resources. That, of course, can not go forever and at one point you will realise that you are not able to do the task and even the idea of starting makes you want to do anything, but that.</p>
<p>That is the point at which people can either:</p>
<ol>
<li>Quit</li>
<li>Preserver and quit in a week</li>
<li>Take a break and quit in a month</li>
<li>Change the task completely so that it is sustainable</li>
</ol>
<p>As you could imagine, the 4th option is the optimal one. But it is also the one that is chosen the least. </p>
<p>If you have driven yourself to the point of hate, it will be tough to make you like the habit ever again.</p>
<p>The worst part of our lives is that this is an essential step in understanding how to become more efficient. I don’t know a single person that has become productive and coincidentally achieved greatness in life but hasn’t burned out at least once.</p>
<p>Why is that? It seems to start small and improve everything with little steps(which is <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-58565-5_6">proven to be the best way to achieve great goals</a>), you have to fail in achieving something couple of times.</p>
<p>This knowledge is not programmed into our brain or genes. That is why we need to learn on our own mistakes to understand the right course of actions.</p>
<h2>Why does this matter?</h2>
<p>I understand that some people don’t want to do anything that is not immediately satisfactory. I understand that good habits are boring and not fun at all. </p>
<p>The main reason they are not fun is that the effect and the result are postponed so much into the future that our brain, due to smartphones and social media, has been reprogrammed to expect low-cost dopamine hits in everything that we do. </p>
<p>Why do people still perform good, boring habits, then?</p>
<p>Because in the long run, the total amount of dopamine that you get will increase with every time you do the task, and eventually it will snowball into the most amazing feeling you will ever experience.</p>
<p>Writing a chapter of a book is boring and most likely is <a href="https://klimy.co/blog/when-productivity-increases">extremely unrewarding</a>. You spent your time researching, writing and editing. It was super boring and maybe even painful. There is literally no dopamine there.</p>
<p>But, once you write your book, the combined effect of all the sessions will hit your right in the face with the most amazing and happy feeling ever. Maybe even that book will let you retire and become the happiest human on earth, who knows?</p>
<p><img alt="progress vs happiness" src="https://i.gyazo.com/ee36f0c65178aca1860c7e924f182fc2.png"></p>
<p>The thing is that every good habit is like this. Don’t underestimate what you can achieve by just doing <a href="https://klimy.co/blog/impact-through-motion">the right thing, consistently.</a></p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/positive-habits-12-12-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396845</guid>
            <pubDate>Sat, 12 Dec 2020 08:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tacit Programming (APL)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396753">thread link</a>) | @jpcooper
<br/>
December 12, 2020 | https://aplwiki.com/wiki/Tacit_programming | <a href="https://web.archive.org/web/*/https://aplwiki.com/wiki/Tacit_programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en-GB" dir="ltr"><div><p>Tacit functions apply to implicit arguments. This is in contrast to the explicit use of arguments in <a href="https://aplwiki.com/wiki/Dfns" title="Dfns">dfns</a> (<code dir="ltr"><span>⍺</span> <span>⍵</span></code>) and <a href="https://aplwiki.com/wiki/Tradfns" title="Tradfns">tradfns</a> (which have named arguments). Some APL dialects allow to combine functions into <b>trains</b> following a small set of rules. This allows creating complex derived functions without specifying any arguments explicitly.
</p><p>Known dialects which implement trains are <a href="https://aplwiki.com/wiki/Dyalog_APL" title="Dyalog APL">Dyalog APL</a>, <a href="https://aplwiki.com/wiki/Dzaima/APL" title="Dzaima/APL">dzaima/APL</a>, <a href="https://aplwiki.com/wiki/Ngn/apl" title="Ngn/apl">ngn/apl</a> and <a href="https://aplwiki.com/wiki/NARS2000" title="NARS2000">NARS2000</a>.
</p>


<h2><span id="Primitives">Primitives</span></h2>
<p>All <a href="https://aplwiki.com/wiki/Primitive_functions" title="Primitive functions">primitive functions</a> are tacit. Some APLs allow primitive functions to be named.
</p>
<div dir="ltr"><pre><span></span>      <span>plus</span> <span>←</span> <span>+</span>
      <span>times</span> <span>←</span> <span>×</span>
      <span>6</span> <span>times</span> <span>3</span> <span>plus</span> <span>5</span>
<span>48</span>
</pre></div>
<h2><span id="Derived_functions">Derived functions</span></h2>
<p>Functions derived from a monadic operator and an operand, or from a dyadic operator and two operands are tacit functions:
</p>
<div dir="ltr"><pre><span></span>      <span>Sum</span> <span>←</span> <span>+</span><span>/</span>
      <span>Sum</span> <span>⍳</span><span>10</span>
<span>55</span>

      <span>Dot</span> <span>←</span> <span>+</span><span>.</span><span>×</span>
      <span>3</span> <span>1</span> <span>4</span> <span>dot</span> <span>2</span> <span>7</span> <span>1</span>
<span>17</span>
</pre></div>
<h2><span id="Derived_operators">Derived operators</span></h2>
<p>A dyadic operator with its right operand forms a tacit monadic operator:
</p>
<div dir="ltr"><pre><span></span>      <span>1</span><span>(</span><span>+</span><span>⍣</span><span>2</span><span>)</span><span>10</span>
<span>12</span>
      <span>Twice</span> <span>←</span> <span>⍣</span><span>2</span>
      <span>1</span> <span>+</span><span>Twice</span> <span>10</span>
<span>12</span>
</pre></div>
<h2><span id="Trains">Trains</span></h2>
<p>A train is a series of functions in isolation. An isolated function is either surrounded by parentheses or named. Below, <code dir="ltr"><span>⍺</span></code> and <code dir="ltr"><span>⍵</span></code> refer to the arguments of the train. <code dir="ltr"><span>f</span></code>, <code dir="ltr"><span>g</span></code>, and <code dir="ltr"><span>h</span></code> are functions (which themselves can be tacit or not), and <code dir="ltr"><span>A</span></code> is an array. The arguments are processed by the following rules:
</p>
<h3><span id="Forks">Forks</span></h3>
<p>A 3-train is a <i>fork</i>:
</p>

<p>The <i>left tine</i> of a fork can be an array:
</p>

<h3><span id="Atops">Atops</span></h3>
<p>A 2-train is an <i>atop</i>:
</p>

<p>Only <a href="https://aplwiki.com/wiki/Dzaima/APL" title="Dzaima/APL">dzaima/APL</a> allows <code dir="ltr"><span>(</span><span>A</span> <span>h</span><span>)</span></code>, which it treats as <code dir="ltr"><span>A</span><span>∘</span><span>h</span></code>.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> See <a href="https://aplwiki.com/wiki/Bind" title="Bind">Bind</a>.
</p>
<h2><span id="Debugging">Debugging</span></h2>
<p>In <a href="https://aplwiki.com/wiki/Dyalog_APL" title="Dyalog APL">Dyalog APL</a>, analysis of trains is assisted by a <a href="https://aplwiki.com/wiki/User_command" title="User command">user command</a> <code dir="ltr"><span>]</span><span>Boxing</span> <span>on</span></code>. This is achieved by executing the command <code dir="ltr"><span>]</span><span>Boxing</span> <span>on</span></code> and then entering a train without any parameters. A structure of the train will be displayed.
</p><p>For example, the "accursed train" from the section below can be analysed like this:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span>
<span>Was</span> <span>OFF</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
<span>┌───────────────────────────────┬───────┐</span>
<span>│┌───────────┬─────────────────┐│┌─┬─┬─┐│</span>
<span>││┌───────┬─┐│┌─┬─┬───────────┐│││</span><span>1</span><span>│</span><span>↓</span><span>│</span><span>⍳</span><span>││</span>
<span>│││┌─┬─┬─┐│</span><span>⍨</span><span>│││</span><span>⊢</span><span>│</span><span>~</span><span>│┌───────┬─┐│││└─┴─┴─┘│</span>
<span>││││</span><span>+</span><span>│</span><span>.</span><span>│</span><span>×</span><span>││</span> <span>│││</span> <span>│</span> <span>││┌─┬─┬─┐│</span><span>⍨</span><span>││││</span>       <span>│</span>
<span>│││└─┴─┴─┘│</span> <span>│││</span> <span>│</span> <span>│││</span><span>∘</span><span>│</span><span>.</span><span>│</span><span>×</span><span>││</span> <span>││││</span>       <span>│</span>
<span>││└───────┴─┘││</span> <span>│</span> <span>││└─┴─┴─┘│</span> <span>││││</span>       <span>│</span>
<span>││</span>           <span>││</span> <span>│</span> <span>│└───────┴─┘│││</span>       <span>│</span>
<span>││</span>           <span>│└─┴─┴───────────┘││</span>       <span>│</span>
<span>│└───────────┴─────────────────┘│</span>       <span>│</span>
<span>└───────────────────────────────┴───────┘</span>
</pre></div>
<p>Alternatively, a train can be represented in form of a tree:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span> <span>-</span><span>trains</span><span>=</span><span>tree</span>
<span>Was</span> <span>ON</span> <span>-</span><span>trains</span><span>=</span><span>box</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
     <span>┌───┴───┐</span>  
   <span>┌─┴─┐</span>   <span>┌─┼─┐</span>
   <span>⍨</span> <span>┌─┼─┐</span> <span>1</span> <span>↓</span> <span>⍳</span>
 <span>┌─┘</span> <span>⊢</span> <span>~</span> <span>⍨</span>      
 <span>.</span>     <span>┌─┘</span>      
<span>┌┴┐</span>    <span>.</span>        
<span>+</span> <span>×</span>   <span>┌┴┐</span>       
      <span>∘</span> <span>×</span>
</pre></div>
<p>Or fully parenthesised:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span> <span>-</span><span>trains</span><span>=</span><span>parens</span>
<span>Was</span> <span>OFF</span> <span>-</span><span>trains</span><span>=</span><span>box</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
<span>(((</span><span>+</span><span>.</span><span>×</span><span>)</span><span>⍨</span><span>)(</span><span>⊢~</span><span>((</span><span>∘.</span><span>×</span><span>)</span><span>⍨</span><span>)))(</span><span>1</span><span>↓⍳</span><span>)</span>
</pre></div>
<h2><span id="Examples">Examples</span></h2>
<p>One of the major benefits of tacit programming is the ability to convey a short, well-defined idea as an isolated expression. This aids both human readability (<a href="https://aplwiki.com/wiki/Semantic_density" title="Semantic density">semantic density</a>) and the computer's ability to interpret code, potentially executing special code for particular <a href="https://aplwiki.com/index.php?title=Idiom&amp;action=edit&amp;redlink=1" title="Idiom (page does not exist)">idioms</a>.
</p>
<h3><span id="Plus_and_minus">Plus and minus</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>+,-</span><span>)</span> <span>2</span>     <span>⍝ ±2</span>
<span>2</span> <span>¯2</span>
      <span>5</span> <span>(</span><span>+,-</span><span>)</span> <span>2</span>   <span>⍝ 5±2</span>
<span>7</span> <span>3</span>
</pre></div>
<h3><span id="Arithmetic_mean">Arithmetic mean</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>+</span><span>⌿</span><span>÷≢</span><span>)</span> <span>⍳</span><span>10</span>       <span>⍝ Mean of the first ten integers</span>
<span>5.5</span>
      <span>(</span><span>+</span><span>⌿</span><span>÷≢</span><span>)</span> <span>5</span> <span>4</span><span>⍴⍳</span><span>4</span>    <span>⍝ Mean of columns in a matrix</span>
<span>1</span> <span>2</span> <span>3</span> <span>4</span>
</pre></div>
<h3><span id="Fractions">Fractions</span></h3>
<p>We can convert decimal numbers to fractions. For example, we can convert <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ace31f232e5ba24a1a418586f322f06724e5e12d" aria-hidden="true" alt="{\displaystyle 2.625}"></span> to the improper fraction <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1c58d4e0e0fdb69d9aa1ea7296259ddb24d56e39" aria-hidden="true" alt="{\displaystyle {\tfrac {21}{8}}}"></span> with
</p>

<p>Alternatively, we can convert it to the mixed fraction <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3a15740caaa334e457b2766a3bcfc22366196cec" aria-hidden="true" alt="{\displaystyle 2{\tfrac {5}{8}}}"></span> with a mixed fraction:
</p>

<h3><span id="Is_it_a_palindrome?"></span><span id="Is_it_a_palindrome.3F">Is it a palindrome?</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>⌽≡⊢</span><span>)</span><span>'racecar'</span>
<span>1</span>
      <span>(</span><span>⌽≡⊢</span><span>)</span><span>'racecat'</span>
<span>0</span>
</pre></div>
<h3><span id="Split_delimited_text">Split delimited text</span></h3>
<div dir="ltr"><pre><span></span>      <span>','</span><span>(</span><span>≠</span><span>⊆</span><span>⊢</span><span>)</span><span>'comma,delimited,text'</span>
<span>┌─────┬─────────┬────┐</span>
<span>│</span><span>comma</span><span>│</span><span>delimited</span><span>│</span><span>text</span><span>│</span>
<span>└─────┴─────────┴────┘</span>
      <span>' '</span><span>(</span><span>≠</span><span>⊆</span><span>⊢</span><span>)</span><span>'space delimited text'</span>
<span>┌─────┬─────────┬────┐</span>
<span>│</span><span>space</span><span>│</span><span>delimited</span><span>│</span><span>text</span><span>│</span>
<span>└─────┴─────────┴────┘</span>
</pre></div>
<h3><span id="Component_of_a_vector_in_the_direction_of_another_vector">Component of a vector in the direction of another vector</span></h3>
<p>Sometimes a train can make an expression nicely resemble its equivalent definition in traditional mathematical notation. As an example, here is a program to compute the component of a vector <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/af9f1604cec45bc8d60e31610f9ec1b7c6599b68" aria-hidden="true" alt="{\displaystyle {\textbf {a}}}"></span> in the direction of another vector <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/29890eb931b98e8816c928582f07d7eaa86cc348" aria-hidden="true" alt="{\displaystyle {\textbf {b}}}"></span>:
</p>
<dl><dd><dl><dd><dl><dd><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8bd13a4409c254c27e5740a13f040bac84cb6a93" aria-hidden="true" alt="{\displaystyle {\textbf {a}}_{\textbf {b}}=({\textbf {a}}\cdot {\hat {\textbf {b}}}){\hat {\textbf {b}}}}"></span></dd></dl></dd></dl></dd></dl>
<div dir="ltr"><pre><span></span>      <span>Root</span> <span>←</span> <span>*</span><span>∘</span><span>÷</span><span>⍨</span>              <span>⍝ Nth root</span>
      <span>Norm</span> <span>←</span> <span>2</span> <span>Root</span> <span>+</span><span>.</span><span>×</span><span>⍨</span>       <span>⍝ Magnitude (norm) of numeric vector in Euclidean space</span>
      <span>Unit</span> <span>←</span> <span>⊢÷</span><span>Norm</span>            <span>⍝ Unit vector in direction of vector ⍵</span>
      <span>InDirOf</span> <span>←</span> <span>(</span><span>⊢×+</span><span>.</span><span>×</span><span>)</span><span>∘</span><span>Unit</span>   <span>⍝ Component of vector ⍺ in direction of vector ⍵</span>
      <span>3</span> <span>5</span> <span>2</span> <span>InDirOf</span> <span>0</span> <span>0</span> <span>1</span>      <span>⍝ Trivial example</span>
<span>0</span> <span>0</span> <span>2</span>
</pre></div>
<p>For a more parallel comparison of the notations, see the <a href="https://aplwiki.com/wiki/Comparison_with_traditional_mathematics#Practical_example" title="Comparison with traditional mathematics">comparison with traditional mathematics</a>.
</p>
<h3><span id="The_Number_of_the_Beast">The Number of the Beast</span></h3>
<p>The following expression for computing the <a href="https://en.wikipedia.org/wiki/666_(number)" title="wikipedia:666 (number)">number of the Beast</a> (and of <a href="https://aplwiki.com/wiki/I.P._Sharp" title="I.P. Sharp">I.P. Sharp</a>'s APL-based email system, <a href="https://aplwiki.com/index.php?title=666_BOX&amp;action=edit&amp;redlink=1" title="666 BOX (page does not exist)">666 BOX</a>) nicely illustrates how to read a train.
</p>
<div dir="ltr"><pre><span></span>      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span><span>17</span> <span>⍝ Accursed train</span>
<span>666</span>
</pre></div>
<p>First, <code dir="ltr"><span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span></code> is supplied with only one argument <code dir="ltr"><span>17</span></code> and is thus interpreted monadically.
</p><p>Second, <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span></code> is a 4-train: reading right-to-left, the last 3 components are interpreted as the fork <code dir="ltr"><span>1</span><span>↓⍳</span></code> and the 4-train is interpreted as the atop <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)(</span><span>1</span><span>↓⍳</span><span>)</span></code>.
Similarly, <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span></code> is also a 4-train and interpreted as the atop <code dir="ltr"><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span></code>. 
</p><p>Thus the accursed train is interpreted as <code dir="ltr"><span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>))(</span><span>1</span><span>↓⍳</span><span>))</span><span>17</span></code>. Having read the train, we now evaluate it monadically.
</p>
<div dir="ltr"><pre><span></span>      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>))(</span><span>1</span><span>↓⍳</span><span>))</span><span>17</span> <span>⍝ Accursed train as an atop over a fork atop a fork</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>17</span>       <span>⍝ Atop evalution</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢</span><span>1</span><span>↓⍳</span><span>17</span><span>)</span><span>~</span><span>∘.</span><span>×</span><span>⍨</span><span>1</span><span>↓⍳</span><span>17</span>  <span>⍝ Fork evalution</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>1</span><span>↓⍳</span><span>17</span><span>)</span><span>~</span><span>∘.</span><span>×</span><span>⍨</span><span>1</span><span>↓⍳</span><span>17</span>   <span>⍝ ⊢ evaluation</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>2</span> <span>3</span> <span>5</span> <span>7</span> <span>11</span> <span>13</span> <span>15</span> <span>17</span> <span>⍝ numbers 2 through 17 without those appearing in their multiplication table are primes</span>
<span>666</span>                           <span>⍝ the sum of the squares of the primes up to 17</span>
</pre></div>
<p>Note that <code dir="ltr"><span>((</span><span>⊢</span><span>⍨∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span></code> is a train computing primes up to the given input.
</p><p>A more satisfying variation of the accursed train is the following.
</p>
<div dir="ltr"><pre><span></span>      <span>(</span><span>⍎⊢,⍕</span><span>∘</span><span>≢</span><span>)</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span>                    <span>⍝ Accursed train 2.0</span>
      <span>⍎</span><span>(</span><span>⊢,⍕</span><span>∘</span><span>≢</span><span>)</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span>                    <span>⍝ 4-train intepreted as an atop</span>
      <span>⍎</span><span>(</span><span>⊢</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span><span>)</span><span>,⍕</span><span>∘</span><span>≢</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span> <span>⍝ fork evaluation</span>
      <span>⍎</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span><span>,</span><span>'17'</span>                      <span>⍝ ⊢ evaluation and ⍕∘≢ evaluation</span>
      <span>⍎</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)17'</span>                         <span>⍝ , evaluation</span>
<span>666</span>                                                  <span>⍝ ⍎ executes original Accursed train</span>
</pre></div>
<h2><span id="External_links">External links</span></h2>
<h3><span id="Tutorials">Tutorials</span></h3>
<ul><li>Dyalog: <a rel="nofollow" href="https://help.dyalog.com/16.0/Content/RelNotes14.0/Function%20Trains.htm">version 14.0 release notes</a></li>
<li><a href="https://aplwiki.com/wiki/APL_Cultivation" title="APL Cultivation">APL Cultivation</a>: <a rel="nofollow" href="https://chat.stackexchange.com/rooms/52405/conversation/lesson-23-transcribing-to-and-reading-trains">Transcribing to and reading trains</a></li>
<li><a href="https://aplwiki.com/wiki/APLtrainer" title="APLtrainer">APLtrainer</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=kt4lMZbn-so">How to read trains in Dyalog APL code</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/APLtrainer" title="APLtrainer">APLtrainer</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=A2LqqBosvY0">Function trains in APL</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/Dyalog_webinar" title="Dyalog webinar">Dyalog webinar</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=Enlh5qwwDuY?t=440">Train Spotting in Dyalog APL</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/Dyalog_%2713" title="Dyalog '13">Dyalog '13</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=7-93GzDqC08">Train Spotting in Version 14.0</a> (video)</li></ul>
<h3><span id="Documentation">Documentation</span></h3>
<ul><li><a rel="nofollow" href="https://help.dyalog.com/16.0/Content/RelNotes14.0/Function%20Trains.htm">Announcement</a></li>
<li><a rel="nofollow" href="https://help.dyalog.com/latest/Content/Language/Introduction/Trains.htm">Dyalog</a></li></ul>
<h2><span id="References">References</span></h2>


<table>
<tbody><tr>
<th colspan="2"><b><big>APL syntax</big></b> [<a rel="nofollow" href="https://aplwiki.com/index.php?title=Template:APL_syntax&amp;action=edit">edit</a>]
</th></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/APL_syntax" title="APL syntax">General</a>
</th>
<td><a href="https://aplwiki.com/wiki/Comparison_with_traditional_mathematics" title="Comparison with traditional mathematics">Comparison with traditional mathematics</a> ∙ <a href="https://aplwiki.com/index.php?title=Precedence&amp;action=edit&amp;redlink=1" title="Precedence (page does not exist)">Precedence</a> ∙ <a>Tacit programming</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Array" title="Array">Array</a>
</th>
<td><a href="https://aplwiki.com/index.php?title=Numeric_literal&amp;action=edit&amp;redlink=1" title="Numeric literal (page does not exist)">Numeric literal</a> ∙ <a href="https://aplwiki.com/wiki/String" title="String">String</a> ∙ <a href="https://aplwiki.com/wiki/Strand_notation" title="Strand notation">Strand notation</a> ∙ <a href="https://aplwiki.com/index.php?title=Object_literal&amp;action=edit&amp;redlink=1" title="Object literal (page does not exist)">Object literal</a> ∙ <a href="https://aplwiki.com/wiki/Array_notation" title="Array notation">Array notation</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Function" title="Function">Function</a>
</th>
<td><a href="https://aplwiki.com/wiki/Argument" title="Argument">Argument</a> ∙ <a href="https://aplwiki.com/wiki/Function_valence" title="Function valence">Function valence</a> ∙ <a href="https://aplwiki.com/wiki/Derived_function" title="Derived function">Derived function</a> ∙ <a href="https://aplwiki.com/wiki/Derived_operator" title="Derived operator">Derived operator</a> ∙ <a href="https://aplwiki.com/wiki/Niladic_function" title="Niladic function">Niladic function</a> ∙ <a href="https://aplwiki.com/wiki/Monadic_function" title="Monadic function">Monadic function</a> ∙ <a href="https://aplwiki.com/wiki/Dyadic_function" title="Dyadic function">Dyadic function</a> ∙ <a href="https://aplwiki.com/wiki/Ambivalent_function" title="Ambivalent function">Ambivalent function</a> ∙ <a href="https://aplwiki.com/wiki/Tradfn" title="Tradfn">Tradfn</a> ∙ <a href="https://aplwiki.com/wiki/Dfn" title="Dfn">Dfn</a> ∙ <a href="https://aplwiki.com/wiki/Function_train" title="Function train">Function train</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Operator" title="Operator">Operator</a>
</th>
<td><a href="https://aplwiki.com/wiki/Operand" title="Operand">Operand</a> ∙ <a href="https://aplwiki.com/wiki/Operator_valence" title="Operator valence">Operator valence</a> ∙ <a href="https://aplwiki.com/wiki/Tradop" title="Tradop">Tradop</a> ∙ <a href="https://aplwiki.com/wiki/Dop" title="Dop">Dop</a> ∙ <a href="https://aplwiki.com/wiki/Derived_operator" title="Derived operator">Derived operator</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/index.php?title=Assignment&amp;action=edit&amp;redlink=1" title="Assignment (page does not exist)">Assignment</a>
</th>
<td><a href="https://aplwiki.com/index.php?title=Multiple_assignment&amp;action=edit&amp;redlink=1" title="Multiple assignment (page does not exist)">Multiple</a> ∙ <a href="https://aplwiki.com/index.php?title=Indexed_assignment&amp;action=edit&amp;redlink=1" title="Indexed assignment (page does not exist)">Indexed</a> ∙ <a href="https://aplwiki.com/index.php?title=Selective_assignment&amp;action=edit&amp;redlink=1" title="Selective assignment (page does not exist)">Selective</a> ∙ <a href="https://aplwiki.com/index.php?title=Modified_assignment&amp;action=edit&amp;redlink=1" title="Modified assignment (page does not exist)">Modified</a>
</td></tr>
<tr>
<th>Other
</th>
<td><a href="https://aplwiki.com/wiki/Function_axis" title="Function axis">Function axis</a> ∙ <a href="https://aplwiki.com/wiki/Branch" title="Branch">Branch</a> ∙ <a href="https://aplwiki.com/wiki/Quad_name" title="Quad name">Quad name</a> ∙ <a href="https://aplwiki.com/wiki/System_command" title="System command">System command</a> ∙ <a href="https://aplwiki.com/wiki/User_command" title="User command">User command</a> ∙ <a href="https://aplwiki.com/index.php?title=Keyword&amp;action=edit&amp;redlink=1" title="Keyword (page does not exist)">Keyword</a> ∙ <a href="https://aplwiki.com/index.php?title=Dot_notation&amp;action=edit&amp;redlink=1" title="Dot notation (page does not exist)">Dot notation</a> ∙ <a href="https://aplwiki.com/wiki/Function-operator_overloading" title="Function-operator overloading">Function-operator overloading</a>
</td></tr></tbody></table>
<!-- 
NewPP limit report
Cached time: 20201113092414
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.439 seconds
Real time usage: 14.465 seconds
Preprocessor visited node count: 606/1000000
Preprocessor generated node count: 1305/1000000
Post‐expand include size: 1601/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 26166/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 10147.365      1 -total
  0.06%    5.898      6 Template:←→
  0.05%    5.146      1 Template:APL_syntax
-->

<!-- Saved in parser cache with key aplwiki:pcache:idhash:487-0!canonical!math=5 and timestamp 20201113092359 and revision id 5726
 -->
</div></div></div>]]>
            </description>
            <link>https://aplwiki.com/wiki/Tacit_programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396753</guid>
            <pubDate>Sat, 12 Dec 2020 08:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a beautiful purple theme for Jupyter Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396553">thread link</a>) | @DataCrayon
<br/>
December 11, 2020 | https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
    <div>
        <!--Body content-->
        
        
<article itemscope="itemscope" itemtype="http://schema.org/Article"><div>
    
        <div>
            <div>
            <div>
                <div>
                <div>
                    <h2>Get the Books</h2>
                    <p>
                    Enjoying these notebooks and want to support the work? Check out the practical books on Data Science, Visualisation, and Evolutionary Algorithms.
                    </p>
                    <p><a href="https://datacrayon.com/shop/product/data-is-beautiful/">Get the books</a>
                </p></div>
                <p><img src="https://datacrayon.com/images/datacrayon/shop/covertops.jpg">
</p>
                </div>
            </div>
            </div>
        </div>
    
    
    <header>

        
        

    </header><div itemprop="articleBody text">
    <!--% if post.meta('has_toc'):-->
    

        

        
            

            
<div>

<div>

<div>
<div>
<h2 id="Installation-through-Jupyter-Lab">Installation through Jupyter Lab<a href="#Installation-through-Jupyter-Lab">¶</a>
</h2>
<p>You can install it through the Jupyter Lab Extension Manager UI, or with the following command:</p>
<p><code>jupyter labextension install @shahinrostami/theme-purple-please</code></p>
<h2 id="GitHub-Repository">GitHub Repository<a href="#GitHub-Repository">¶</a>
</h2>
<p>You can navigate and download the source code at <a href="https://github.com/shahinrostami/theme-purple-please">https://github.com/shahinrostami/theme-purple-please</a>.</p>

</div>
</div>
</div>

</div>




                    <div id="support-this-work-bottom">
                                    <p>Support this work</p>
                                    <p>
        You can support this work by <a href="https://datacrayon.com/shop/">getting the e-books</a>. This notebook will always be available for free in its online format.
        </p>
                                </div>
                            </div>
                            <!-- Modal -->

                            <!-- Modal -->
</div>
                    </article><!--End of body content-->
</div>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396553</guid>
            <pubDate>Sat, 12 Dec 2020 07:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bit Manipulation with C++20]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25396151">thread link</a>) | @todsacerdoti
<br/>
December 11, 2020 | http://www.modernescpp.com/index.php/bit-manipulation-with-c-20 | <a href="https://web.archive.org/web/*/http://www.modernescpp.com/index.php/bit-manipulation-with-c-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent">
				<p>This post concludes my presentation of library features in C++20. Today I write about the class<code> std::source_location</code> and a few functions for bit manipulation.</p>

<h2 id="h1-std-source-location"><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/TimelineCpp20CoreLanguage2.png" alt="TimelineCpp20CoreLanguage2" width="650" height="265"><code>std::source_location</code></h2>
<p><code>std::source_location</code> represents information about the source code. This information includes file names, line numbers, and function names. The information is precious when you need information about the call site, such as for debugging, logging, or testing purposes. The class <code>std::source_location</code> is the better alternative for the predefined C++11 macros <code>__FILE__</code> and<code> __LINE__</code> and should, therefore, be used.</p>
<p>The following table shows the interface of <code>std::source_location</code>.</p>
<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/sourceLocation.png" alt="sourceLocation" width="500" height="161"></p>
<p>The call <code>std::source_location::current()</code> creates a new source location object<code> src. sr</code>c represents the information of the call site. Now, no C++ compiler supports <code>std::source_location</code>. Consequently, the following program <code>sourceLocation.cpp</code> is from <a href="https://en.cppreference.com/w/cpp/utility/source_location">cppreference.com/source_location</a>.</p>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// sourceLocation.cpp</span>
<span>// from cppreference.com</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;string_view&gt;</span>
<span>#include &lt;source_location&gt;</span>
 
<span>void</span> <span>log</span>(std<span>::</span>string_view message,
         <span>const</span> std<span>::</span>source_location<span>&amp;</span> location <span>=</span> std<span>::</span>source_location<span>::</span>current())
{
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"info:"</span>
              <span>&lt;&lt;</span> location.file_name() <span>&lt;&lt;</span> <span>':'</span>
              <span>&lt;&lt;</span> location.line() <span>&lt;&lt;</span> <span>' '</span>
              <span>&lt;&lt;</span> message <span>&lt;&lt;</span> <span>'\n'</span>;
}
 
<span>int</span> <span>main</span>()
{
    log(<span>"Hello world!"</span>);  <span>// info:main.cpp:19 Hello world!</span>
}
</pre>
</div>

<p>The output of the program is part of its source code.</p>
<p>C++20 makes it quite comfortable to access or manipulate bits or bit sequences.</p>
<h2 id="h2-bit-manipulation">Bit Manipulation</h2>
<p>Thanks to the new type std::endian, you get the endianness of a scalar type.</p>
<h3 id="h2-1-endianness">Endianness</h3>
<ul>
<li>Endianness can be big-endian or little-endian. Big-endian means that the most significant byte comes first; little-endian means that the least significant byte comes first.</li>
<li>A scalar type is either an arithmetic type, an <code>enum</code>, a pointer, a member pointer, or a <code>std::nullptr_t</code>.</li>
</ul>
<p>The class <code>endian</code> provides the endianness of all scalar types:</p>
<div>
<pre><span>enum</span> <span>class</span> <span>endian</span>
{
    little <span>=</span> <span>/*implementation-defined*/</span>,
    big    <span>=</span> <span>/*implementation-defined*/</span>,
    native <span>=</span> <span>/*implementation-defined*/</span>
};
</pre>
</div>

<ul>
<li>If all scalar types are little-endian, <code>std::endian::native</code> is equal to <code>std::endian::little</code>.</li>
<li>If all scalar types are big-endian,<code> std::endian::native</code> is equal <code>to std::endian::big</code>.</li>
</ul>
<p>Even corner cases are supported:</p>
<ul>
<li>If all scalar types have <code>sizeof</code> 1 and therefore endianness does not matter; the values of the enumerators <code>std::endian::little</code>, <code>std::endian::big</code>, and <code>std::endian::native</code> are identical.</li>
<li>If the platform uses mixed endianness, <code>std::endian::native</code> is neither equal to <code>std::endian::big</code> nor <code>std::endian::little</code>.</li>
</ul>
<p>When I perform the following program <code>getEndianness.cpp</code> on an x86 architecture, I get the answer little-endian.</p>

<div>
<div>
<div>
<pre><span>// getEndianness.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;iostream&gt;</span>

<span>int</span> <span>main</span>() {

    <span>if</span> constexpr (std<span>::</span>endian<span>::</span>native <span>==</span> std<span>::</span>endian<span>::</span>big) {
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"big-endian"</span> <span>&lt;&lt;</span> <span>'\n'</span>;
    }
    <span>else</span> <span>if</span> constexpr (std<span>::</span>endian<span>::</span>native <span>==</span> std<span>::</span>endian<span>::</span>little) {
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"little-endian"</span>  <span>&lt;&lt;</span> <span>'\n'</span>;      <span>// little-endian</span>
    }

}
</pre>
</div>

<p><a href="https://en.cppreference.com/w/cpp/language/if"><code>constexpr if</code></a> enables it to compile source code conditionally. This means that the compilation depends on the endianness of your architecture. If you want to know more about endianness, read the same-named <a href="https://en.wikipedia.org/wiki/Endianness">Wikipedia page</a>.</p>
</div>
</div>
<h3 id="h2-2-accessing-or-manipulating-bits-or-bit-sequences">Accessing or Manipulating Bits or Bit Sequences</h3>
<p>The following table gives you the first overview of all functions.</p>

<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bitInterface5.png" alt="bitInterface5" width="600" height="222"></p>

<p>The functions except of <code>std::bit_cast</code> require an unsigned integer type (<code>unsigned char, unsigned short, unsigned int, unsigned long,</code> or<code> unsigned long long</code>).</p>
<p>The program<code> bit.cpp</code> shows the usage of the functions.</p>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// bit.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;bitset&gt;</span>
<span>#include &lt;iostream&gt;</span>
 
<span>int</span> <span>main</span>() {
    
    std<span>::</span><span>uint8_t</span> num<span>=</span> <span>0</span>b00110010;
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::has_single_bit(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>has_single_bit(num) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_ceil(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>bit_ceil(num)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_floor(0b00110010): "</span> 
              <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>bit_floor(num)) <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_width(5u): "</span> <span>&lt;&lt;</span> std<span>::</span>bit_width(<span>5u</span>) <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::rotl(0b00110010, 2): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>rotl(num, <span>2</span>)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::rotr(0b00110010, 2): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>rotr(num, <span>2</span>)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countl_zero(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countl_zero(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countl_one(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countl_one(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countr_zero(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countr_zero(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countr_one(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countr_one(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::popcount(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>popcount(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    
}
</pre>
</div>

<p>Here is the output of the program:</p>
<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bit2.png" alt="bit2" width="411" height="286"></p>
<p>The next program shows the application and the output of the functions&nbsp;<code>std::bit_floor</code>,<code> std::bit_ceil</code>, <code>std::bit_width</code>, and <code>std::bit_popcount</code> for the numbers 2 to 7.&nbsp;</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// bitFloorCeil.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;bitset&gt;</span>
<span>#include &lt;iostream&gt;</span>
 
<span>int</span> <span>main</span>() {

    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha;
    
    <span>for</span> (<span>auto</span> i <span>=</span> <span>2u</span>; i <span>&lt;</span> <span>8u</span>; <span>++</span>i) {
         std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_floor("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                   <span>&lt;&lt;</span> std<span>::</span>bit_floor(i) <span>&lt;&lt;</span> <span>'\n'</span>;

        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_ceil("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>bit_ceil(i) <span>&lt;&lt;</span> <span>'\n'</span>;

        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_width("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>bit_width(i) <span>&lt;&lt;</span> <span>'\n'</span>;
                  
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_popcount("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>popcount(i) <span>&lt;&lt;</span> <span>'\n'</span>;   
        
        std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    }
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    
}
</pre>
</div>

<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bitFloorCeil.PNG" alt="bitFloorCeil" width="250" height="644"></p>
<h2 id="h3-what-s-next">What's next?</h2>
<p>Additionally to coroutines, C++20 has much to offer for concurrency First, C++20 has new atomics. The new atomics exists for floating-point values and smart pointers. C++20 also enables waiting on atomics. To coordinate threads, semaphore, latches, and barriers come into play. Also, the <code>std::thread</code> was improved with <code>std::jthread</code>. The execution of a&nbsp;<code>std::jthread </code>can be interrupted and joins automatically in its destructor.<code><br></code></p>

<div>
	<p><strong>Thanks a lot to my <a href="https://www.patreon.com/rainer_grimm">Patreon Supporters</a></strong><strong>: Matt Braun, Roman Postanciuc, Tobias Zindl, Marko, </strong><span title="Emyr Williams"><strong>G Prvulovic, Reinhold Dröge, Abernitzke,</strong> </span><strong><span title="Emyr Williams">Frank Grimm</span></strong><span title="Emyr Williams"><strong>, Sakib, Broeserl, </strong></span><strong><span title="Emyr Williams">António Pina, Darshan Mody, Sergey Agafyin, <span data-tag="user-details-full-name">Андрей Бурмистров, Jake, GS, Lawton Shoemake, Animus24, Jozo Leko, John Breland, espkk, Wolfgang Gärtner</span></span><span title="Emyr Williams"><span><span></span></span></span>,&nbsp; Louis St-Amour, Stephan Roslen, Venkat Nandam, Jose Francisco, Douglas Tinkham, Kuchlong Kuchlong, Avi Kohn, Robert Blanch, Truels Wissneth, Kris Kafka, Mario Luoni, Neil Wang, Friedrich Huber, Sudhakar Balagurusamy, lennonli, and Pramod Tikare Muralidhara.</strong></p>

<p><strong>Thanks in particular to Jon Hess, Lakshman,</strong> <strong>Christian Wittenhorst, Sherhy Pyton, and Dendi Suhubdy<br></strong></p>

<h2>Seminars</h2>
<p>I'm happy to give online-seminars or face-to-face seminars world-wide. Please call me if you have any questions.</p>
<h3>Bookable (Online)</h3>
<h4>Deutsch</h4>
<ul>
<li><a href="https://www.modernescpp.de/index.php/c/2-c/29-embedded-programmierung-mit-modernem-c20201029102414">Embedded Programmierung mit modernem C++:&nbsp; </a>26.01.2021 - 28.01.2021</li>
</ul>
<h4>English</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/2-c/31-c-20">C++20 - A Deep Insight: </a>Feb. 1. 2021 - Feb. 3. 2021 (16:00 - 20:00 UTC)</li>
</ul>
<h3>Standard Seminars&nbsp;</h3>
<p>Here is a compilation of my standard seminars. These seminars are only meant to give you a first orientation.</p>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/22">C++ - The Core Language</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - The Standard Library</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - Compact</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/18">C++11 and C++14</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/19">Concurrency with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/21">Design Patterns and Architecture Patterns with C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Embedded Programming with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Generic Programming (Templates) with C++</a></li>
</ul>
<h4>New</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/16">Clean Code with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/25">C++20</a></li>
</ul>
<h3>Contact Me</h3>
<ul>
<li>Tel.: +49 7472 917441</li>
<li>Mobil: +49 152 31965939</li>
<li>Mail: <a href="http://www.modernescpp.com/%3Ca%20href="><span id="cloak75c8564583529a4b4a9106b0e799e4c4">This email address is being protected from spambots. You need JavaScript enabled to view it.</span></a></li>
<li>German Seminar Page: <a href="https://www.modernescpp.de/">www.ModernesCpp.de</a></li>
<li>English Seminar Page: <a href="http://www.modernescpp.net/">www.ModernesCpp.net</a></li>
</ul>
<h3>Modernes C++,</h3>
<p><img src="http://www.modernescpp.com/images/signatur/RainerGrimmSmall.png" alt="RainerGrimmSmall"></p></div>

			</div></div>]]>
            </description>
            <link>http://www.modernescpp.com/index.php/bit-manipulation-with-c-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396151</guid>
            <pubDate>Sat, 12 Dec 2020 06:34:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Colab Python Notebooks Useful Tips]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395858">thread link</a>) | @sean_pedersen
<br/>
December 11, 2020 | https://amitness.com/2020/06/google-colaboratory-tips/ | <a href="https://web.archive.org/web/*/https://amitness.com/2020/06/google-colaboratory-tips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>Colab is one of the best products to come from Google. It has made GPUs freely accessible to learners and practitioners like me who otherwise wouldn’t be able to afford a high-end GPU.</p>
<p>While the interface is very easy to use, there are many lesser-known and undocumented features in colab. In this post, I will share those features that I’ve discovered from basic usage and their official talks.</p>
<h2 id="1-scratchpad-notebook">1. Scratchpad Notebook</h2>
<p>It’s a pretty common scenario that we have a bunch of cluttered untitled notebooks created when we try out temporary stuff on colab.</p>
<p><img src="https://amitness.com/images/colab-clutter.png" alt="Clutter of Untitled Notebooks in Colab"><br>
To solve this, you can bookmark the link given below. It will open a special <strong>scratch notebook</strong> and any changes you make to that notebook are not saved to your main account.</p>
<blockquote>
<p><a href="https://colab.research.google.com/notebooks/empty.ipynb">https://colab.research.google.com/notebooks/empty.ipynb</a></p>
</blockquote>
<h2 id="2-timing-execution-of-cell">2. Timing Execution of Cell</h2>
<p>It’s pretty common that we manually calculate the difference between start and end times of a piece of code to gauge the time taken.</p>
<p>Colab provides an inbuilt feature to do this. After a cell is executed, just hover over the cell run icon and you will get an estimate of the execution time taken.</p>
<p><img src="https://amitness.com/images/colab-cell-hover.png" alt="Execution Time by hovering on run cell"></p>
<h2 id="3-run-part-of-a-cell">3. Run part of a cell</h2>
<p>You can also run only a part of the cell by selecting it and pressing the <code>Runtime &gt; Run Selection</code> button or using the keyboard shortcut <code>Ctrl + Shift + Enter</code>.</p>
<p><img src="https://amitness.com/images/colab-run-few-lines.gif" alt="Running specific line in colab"></p>
<h2 id="4-jupyter-notebook-keyboard-shortcuts">4. Jupyter Notebook Keyboard Shortcuts</h2>
<p>If you are familiar with keyboard shortcuts from Jupyter Notebook, they don’t work directly in Colab. But I found a mental model to map between them.</p>
<p>Just add <code>Ctrl + M</code> before whatever keyboard shortcut you were using in Jupyter. This rule of thumb works for the majority of common use-cases.</p>
<table>
<thead>
<tr>
<th>Action</th>
<th>Jupyter Notebook</th>
<th>Google Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td>Add a cell above</td>
<td>A</td>
<td>Ctrl + <strong>M</strong> + A</td>
</tr>
<tr>
<td>Add a cell below</td>
<td>B</td>
<td>Ctrl + <strong>M</strong> + B</td>
</tr>
<tr>
<td>See all keyboard shorcuts</td>
<td>H</td>
<td>Ctrl + <strong>M</strong> + H</td>
</tr>
<tr>
<td>Change cell to code</td>
<td>Y</td>
<td>Ctrl + <strong>M</strong> + Y</td>
</tr>
<tr>
<td>Change cell to markdown</td>
<td>M</td>
<td>Ctrl + <strong>M</strong> + M</td>
</tr>
<tr>
<td>Interrupt the kernel</td>
<td>II</td>
<td>Ctrl + <strong>M</strong> + I</td>
</tr>
<tr>
<td>Delete a cell</td>
<td>DD</td>
<td>Ctrl + <strong>M</strong> + D</td>
</tr>
<tr>
<td>Checkpoint notebook</td>
<td>Ctrl + S</td>
<td>Ctrl + <strong>M</strong> + S</td>
</tr>
</tbody>
</table>
<p>Below are some notable exceptions to this rule for which either the shortcut is changed completely or kept the same.</p>
<table>
<thead>
<tr>
<th>Action</th>
<th>Jupyter Notebook</th>
<th>Google Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td>Restart runtime</td>
<td>00</td>
<td>Ctrl + <strong>M</strong> + <strong>.</strong></td>
</tr>
<tr>
<td>Run cell</td>
<td>Ctrl + Enter</td>
<td>Ctrl + Enter</td>
</tr>
<tr>
<td>Run cell and add new cell below</td>
<td>Alt + Enter</td>
<td>Alt + Enter</td>
</tr>
<tr>
<td>Run cell and goto the next cell below</td>
<td>Shift + Enter</td>
<td>Shift + Enter</td>
</tr>
<tr>
<td>Comment current line</td>
<td>Ctrl + /</td>
<td>Ctrl + /</td>
</tr>
</tbody>
</table>
<h2 id="5-jump-to-class-definition">5. Jump to Class Definition</h2>
<p>Similar to an IDE, you can go to a class definition by pressing <code>Ctrl</code> and then clicking a class name. For example, here we view the class definition of the Dense layer in Keras by pressing Ctrl and then clicking the <code>Dense</code> class name.</p>
<p><img src="https://amitness.com/images/colab-goto-class.gif" alt="Demo of jumping to class definition"></p>
<h2 id="6-open-notebooks-from-github">6. Open Notebooks from GitHub</h2>
<p>The Google Colab team provides an official chrome extension to open notebooks on GitHub directly on colab. You can install it from <a href="https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo">here</a>.</p>
<p>After installation, click the colab icon on any GitHub notebook to open it directly.</p>
<p><img src="https://amitness.com/images/colab-from-github.png" alt="Extension for opening github notebook in colab"></p>
<p>Alternatively, you can also manually open any GitHub notebook by replacing <code>github.com</code> with <code>colab.research.google.com/github</code>.</p>
<blockquote>
<p>https://<strong>github.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>to</p>
<blockquote>
<p>https://<strong>colab.research.google.com/github</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>An even easier way is to replace <code>github.com</code> with <code>githubtocolab.com</code>. It will redirect you to a colab notebook.</p>
<blockquote>
<p>https://<strong>github.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>to</p>
<blockquote>
<p>https://<strong>githubtocolab.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<h2 id="7-run-flask-apps-from-colab">7. Run Flask apps from Colab</h2>
<p>With a library called <a href="https://github.com/gstaff/flask-ngrok">flask-ngrok</a>, you can easily expose a Flask web app running on colab to demo prototypes. First, you need to install <code>flask</code> and <code>flask-ngrok</code>.</p>
<div><div><pre><code><span>!</span><span>pip</span> <span>install</span> <span>flask</span><span>-</span><span>ngrok</span> <span>flask</span><span>==</span><span>0.12</span><span>.</span><span>2</span>
</code></pre></div></div>
<p>Then, you just need to pass your flask app object to <code>run_with_ngrok</code> function and it will expose a ngrok endpoint when the server is started.</p>
<div><div><pre><code><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>
<span>from</span> <span>flask_ngrok</span> <span>import</span> <span>run_with_ngrok</span>

<span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>
<span>run_with_ngrok</span><span>(</span><span>app</span><span>)</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>hello</span><span>():</span>
    <span>return</span> <span>'Hello World!'</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>app</span><span>.</span><span>run</span><span>()</span>
</code></pre></div></div>
<p><img src="https://amitness.com/images/colab-flask.png" alt="Example of running flask-ngrok"></p>
<p>You can try this out from the package author’s <a href="https://colab.research.google.com/github/gstaff/flask-ngrok/blob/master/examples/flask_ngrok_example.ipynb">official example</a> on Colab.</p>
<h2 id="8-switch-between-tensorflow-versions">8. Switch between Tensorflow versions</h2>
<p>You can easily switch between Tensorflow 1 and Tensorflow 2 using this magic flag. <br>
To switch to Tensorflow 1.15.2, use this command:</p>

<p>To switch to Tensorflow 2.2, run this command:</p>

<p>You will need to restart the runtime for the effect to take place. Colab recommends using the pre-installed Tensorflow version instead of installing it from <code>pip</code> for performance reasons.</p>
<h2 id="9-tensorboard-integration">9. Tensorboard Integration</h2>
<p>Colab also provides a magic command to use Tensorboard directly from the notebook. You just need to set the logs directory location using the <code>--logdir</code> flag. You can learn to use it from the <a href="https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb">official notebook</a>.</p>
<div><div><pre><code><span>%</span><span>load_ext</span> <span>tensorboard</span>
<span>%</span><span>tensorboard</span> <span>--</span><span>logdir</span> <span>logs</span>
</code></pre></div></div>
<p><img src="https://amitness.com/images/colab-tensorboard.png" alt="Embedded Tensorboard in Colab"></p>
<h2 id="10-gauge-resource-limits">10. Gauge resource limits</h2>
<p>Colab provides the following specs for their free and pro versions. Based on your use case, you can switch to the pro version at $10/month if you need a better runtime, GPU, and memory.</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>GPU</th>
<th>GPU Ram</th>
<th>RAM</th>
<th>Storage</th>
<th>CPU Cores</th>
<th>Idle Timeout</th>
<th>Maximum Runtime</th>
</tr>
</thead>
<tbody>
<tr>
<td>Free</td>
<td>Tesla K80</td>
<td>11.44GB</td>
<td>13.7GB</td>
<td>37GB</td>
<td>2</td>
<td>90 min</td>
<td>12 hrs</td>
</tr>
<tr>
<td>Pro</td>
<td>Tesla P100</td>
<td>16GB</td>
<td>27.4GB</td>
<td>37GB</td>
<td>4</td>
<td>90 min</td>
<td>24 hrs</td>
</tr>
</tbody>
</table>
<p>You can view the GPU you have been assigned by running the following command</p>

<p>For information on the CPU, you can run this command</p>

<p>Similarly, you can view the RAM capacity by running</p>
<div><div><pre><code><span>import</span> <span>psutil</span>
<span>ram_gb</span> <span>=</span> <span>psutil</span><span>.</span><span>virtual_memory</span><span>().</span><span>total</span> <span>/</span> <span>1e9</span>
<span>print</span><span>(</span><span>ram_gb</span><span>)</span>
</code></pre></div></div>
<h2 id="11-use-interactive-shell">11. Use interactive shell</h2>
<p>There is no built-in interactive terminal in Colab. But you can use the <code>bash</code> command to try out shell commands interactively. Just run this command and you will get an interactive input.</p>

<p>Now, you can run any shell command in the given input box.</p>
<p><img src="https://amitness.com/images/colab-bash.png" alt="Using interactive shell in colab"></p>
<p>To quit from the shell, just type <code>exit</code> in the input box.</p>
<p><img src="https://amitness.com/images/colab-bash-exit.png" alt="Exiting interactive shell in colab"></p>
<h2 id="12-current-memory-and-storage-usage">12. Current memory and storage usage</h2>
<p>Colab provides an indicator of RAM and disk usage. If you hover over the indicator, you will get a popup with the current usage and the total capacity.</p>
<p><img src="https://amitness.com/images/colab-ram-usage.png" alt="Showing current memory and ram usage in colab"></p>
<h2 id="13-open-in-colab-badge">13. “Open in Colab” Badge</h2>
<p>You can add a ‘Open in Colab’ badge to your <code>README.md</code> or jupyter notebooks using the following markdown code.<br>
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></p>
<p>In the markdown code, we’re loading an SVG image and then linking it to a colab notebook.</p>
<div><div><pre><code><span>[</span><span>![Open In Colab</span><span>](</span><span>https://colab.research.google.com/assets/colab-badge.svg</span><span>)</span>](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)
</code></pre></div></div>
<h2 id="14-interactive-tables-for-pandas">14. Interactive Tables for Pandas</h2>
<p>Colab provides a notebook extension to add interactive sorting and filtering capabilities to pandas dataframes. To use it, run the following code.</p>
<div><div><pre><code><span>%</span><span>load_ext</span> <span>google</span><span>.</span><span>colab</span><span>.</span><span>data_table</span>
</code></pre></div></div>
<p>You can see the regular pandas dataframe and the interactive dataframe after loading the extension below.<br>
<img src="https://amitness.com/images/pandas-table-before.png" alt="Regular pandas dataframe output"><br>
<img src="https://amitness.com/images/colab-pandas-after.png" alt="Interactive pandas dataframe output"></p>
<h2 id="15-setup-conda-environment">15. Setup Conda environment</h2>
<p>If you use miniconda as your python environment manager, you can setup it on colab by running these commands at the top of your notebook.</p>
<div><div><pre><code><span># Download Miniconda installation script</span>
<span>!</span>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

<span># Make it executable</span>
<span>!</span><span>chmod</span> +x Miniconda3-latest-Linux-x86_64.sh

<span># Start installation in silent mode</span>
<span>!</span>bash ./Miniconda3-latest-Linux-x86_64.sh <span>-b</span> <span>-f</span> <span>-p</span> /usr/local

<span># Make conda packages available in current environment</span>
import sys
sys.path.append<span>(</span><span>'/usr/local/lib/python3.7/site-packages/'</span><span>)</span>
</code></pre></div></div>
<p>After the cell is executed, you can use conda to install packages as usual.</p>

<h2 id="16-manage-colab-notebooks-from-command-line">16. Manage Colab Notebooks from Command Line</h2>
<p>You can use a library called <a href="https://github.com/Akshay090/colab-cli">colab-cli</a> to easily create and sync colab notebooks with your local notebooks.</p>
<p><a href="https://asciinema.org/a/314749"><img src="https://asciinema.org/a/314749.svg" alt="colab-cli-demo"></a></p>
<h2 id="17-run-background-tasks">17. Run background tasks</h2>
<p>There are use-cases when we need to start some web server or background tasks before we can execute our regular program.</p>
<p>To run background tasks, use the <code>nohup</code> command followed by your regular shell command and add <code>&amp;</code> to the end to run it in the background. This makes sure that you can run cells afterward in the notebook without your background task blocking it.</p>

<h2 id="18-notify-on-training-completion">18. Notify on Training Completion</h2>
<p>If you’re running a long task such as training a model, you can setup Colab to send a desktop notification once it’s completed.</p>
<p>To enable that, goto Tools ⮕ Settings ⮕ Site and enable <code>Show desktop notifications</code> checkbox.</p>
<p><img src="https://amitness.com/images/colab-notification.png" alt=""></p>
<p>You will get a popup to enable browser notification. Just accept it and colab will notify you on task completion even if you are on another tab, window or application.</p>
<h2 id="19-run-javascript-code">19. Run javascript code</h2>
<p>You can run javascript code by using the <code>%%javascript</code> magic command.</p>
<p><img src="https://amitness.com/images/colab-javascript.png" alt=""></p>
<h2 id="20-run-vscode-on-colab">20. Run VSCode on Colab</h2>
<p>You can run a full-fledged VSCode editor on Colab by following the method I have explained in another <a href="https://amitness.com/vscode-on-colab/">article</a>.</p>
<p><img src="https://amitness.com/images/colab-code-step-3.png" alt=""></p>
<h2 id="21-custom-snippets">21. Custom snippets</h2>
<p>You can save your own collections of useful snippets and access them easily in any colab notebook.</p>
<ul>
<li>
<p>Create a colab notebook called <code>snippets.ipynb</code>. To add each of your snippets, create a markdown cell and add name of the snippet as header. Below, the markdown cell, add a code cell with the snippet code.</p>
<p><img src="https://amitness.com/images/custom-snippets-step-1.png" alt=""></p>
</li>
<li>
<p>Copy the link of this notebook from the browser tab.</p>
<p><img src="https://amitness.com/images/custom-snippets-step-2.png" alt=""></p>
</li>
<li>
<p>Click <code>Tools &gt; Settings</code> in your menu bar to open preference of colab.<br>
<img src="https://amitness.com/images/custom-snippets-step-3.png" alt=""></p>
</li>
<li>
<p>Paste the link into the <code>Custom snippet notebook URL</code> textbox and click save.</p>
</li>
</ul>
<p><img src="https://amitness.com/images/custom-snippets-step-4.png" alt=""></p>
<ul>
<li>Now, the snippets are available in any colab notebook you use. Just click the <strong>&lt;&gt;</strong> icon on sidebar, search for your snippet name and click <strong>Insert</strong>. The code will be inserted into a new cell.</li>
</ul>
<p><img src="https://amitness.com/images/custom-snippets-usage.gif" alt=""></p>
<h2 id="22-run-jupyterlab-on-google-colab">22. Run JupyterLab on Google Colab</h2>
<p>You can start a JupyterLab instance on colab by running the following commands in a cell.</p>
<div><div><pre><code><span>!</span><span>pip</span> <span>install</span> <span>jupyterlab</span> <span>pyngrok</span> <span>-</span><span>q</span>

<span># Run jupyterlab in the background
</span><span>!</span><span>nohup</span> <span>jupyter</span> <span>lab</span> <span>--</span><span>ip</span><span>=</span><span>0.0</span><span>.</span><span>0.0</span> <span>&amp;</span>

<span># Get ngrok URL mapped to port 8888
</span><span>from</span> <span>pyngrok</span> <span>import</span> <span>ngrok</span>
<span>print</span><span>(</span><span>ngrok</span><span>.</span><span>connect</span><span>(</span><span>8888</span><span>))</span>
</code></pre></div></div>
<p>Once executed, click the printed ngrok URL to access the JupyterLab interface.</p>
<p><img src="https://amitness.com/images/colab-jupyterlab.png" alt=""></p>
<h2 id="references">References</h2>
<ul>
<li>Timothy Novikoff, <a href="https://www.youtube.com/watch?v=pnClcwTCyc0">“Making the most of Colab (TF Dev Summit ‘20)”</a></li>
<li>Gal Oshri, <a href="https://www.youtube.com/watch?v=xM8sO33x_OU">“What’s new in TensorBoard (TF Dev Summit ‘19)”</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/2020/06/google-colaboratory-tips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395858</guid>
            <pubDate>Sat, 12 Dec 2020 05:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Flows Toward Order]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395794">thread link</a>) | @akeck
<br/>
December 11, 2020 | http://m.nautil.us/issue/93/forerunners/time-flows-toward-order | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/93/forerunners/time-flows-toward-order">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>T</span>he one law of physics that virtually all scientists believe will never be found to be wrong is the second law of thermodynamics. Despite this exalted status, it has long been associated with a great mystery and a bleak implication. The mystery is that all the known laws of nature except one do not distinguish a temporal direction. The second law, however, asserts the existence of an all-powerful unidirectionality in the way all events throughout the universe unfold. According to standard accounts, the second law says that entropy, described as a measure of disorder, will always (with at most small fluctuations) increase. That’s the rub: Time has an arrow that points to heat death.</p><p>Surprisingly, evidence that a more nuanced account is needed is hiding in plain sight: the universe itself. Very soon after the Big Bang, the universe was in an extremely uniform state, which since then has become ever more varied and structured. Even if uniformity equates to order, that initial state was surely bland and dull. And who can see disorder in the fabulously structured galaxies or the colors and shapes of the trees in the fall? In fact, the sequence in which two of the greatest discoveries in science were made resolves the paradox: The second law was discovered eight decades before the expansion of the universe.</p><figure data-alt="Barbour_BREAKER"><img src="http://static.nautil.us/17977_f1b4a1e8b4c12f7c7f2e390c76b4cc12.png" width="733" alt=""><figcaption><span><strong>BOTH SIDES NOW:</strong> Two people walking down opposite sides of Mount Fuji would see the terrain change in much the same way. To author Julian Barbour, the hikers’ perceptions offers an apt analogy for how beings on either side of what he calls a “Janus Point” in the universe would experience moving orderly in time.</span><span>Martina Badini / Shutterstock</span></figcaption></figure><p>The time lag is critical for one simple reason. The laws of thermodynamics, discovered in 1850 by William Thomson (later ennobled to Lord Kelvin) and Rudolf Clausius, emerged from a brilliant study that Sadi Carnot (son of Napoleon’s greatest general) published in 1824. In a slim booklet that laid out all but one of the foundational principles of thermodynamics, he sought to establish the maximum efficiency steam engines could achieve. Steam engines can only function if their working medium is confined in a cylinder. This led all early work on thermodynamics to be based on systems in a conceptual box. Clausius’s discovery and definition of entropy—one of the wonders of science—relied totally on infinitesimal changes from one equilibrium state of a confined system to another. The pioneers of statistical mechanics, the theoretical framework created above all by Clausius, James Clerk Maxwell, and Ludwig Boltzmann to provide a microscopic atomistic explanation of phenomenological thermodynamics, invariably considered models of gas molecules trapped in a box and forced to bounce off its walls and each other.<br></p><p>A rich conceptual framework, completely valid and immensely fruitful for confined systems, developed out of this simple model, and reached its definitive form in the work of J. Willard Gibbs. The model proved the existence of atoms and molecules, established their sizes, determined the incredible number of them in a grain of sand, and struck the death knell of Newtonian classical physics. That was when Planck discovered the first quantum effect in 1900. What’s more, both the first and second law appeared to be founded on a rock-solid principle: the impossibility of creating perpetual motion machines.</p><blockquote><p>I don’t deny the arrow of time. But the “box mentality” has led us to misunderstand what is happening in the universe.</p> </blockquote><p>It’s therefore not surprising that few, if any, scientists have disagreed with the great astrophysicist Arthur Eddington’s warning, “If your theory is found to be against the second law of thermodynamics I can give you no hope; there is nothing for it but to collapse in deepest humiliation.” Einstein, surely a greater scientist than Eddington, was more cautious. A few years before his death, Einstein said of thermodynamics, “It is the only physical theory of universal content which I am convinced that, within the framework of applicability of its basic concepts, will never be overthrown.” The caveat is all important: Do conditions in an expanding universe remain within the framework of applicability?<br></p><p>That is what I question. I don’t suggest we can ever alter the facts that Thomson and Clausius first brought to light. Neither you nor I are going to get younger or see a shattered cup miraculously reassemble itself and jump back onto the table. There is a pervasive unidirectionality, an arrow of time, about the way things happen in the universe. Kelvin, the first to recognize its significance, called it “a universal tendency in nature to the dissipation of mechanical energy.” I don’t deny the existence of the arrow, but I do suggest that the “box mentality” has led us to misunderstand what is happening in the universe and even blinded us to the beauty that it is creating. A one-way street need not lead to a scrap yard; it might bring us to a finely landscaped park.</p><p>Compare two situations. First, the molecules in their box. If, every now and then, you open it to look at them, you can be sure to find them filling the box uniformly and going through their habitual routine—bumping into each other with random outcomes. Nothing of interest develops. This, nevertheless, was the model used to interpret mundane measurements of pressure and temperature. It led to all those marvelous discoveries and much of the technology on which today we so depend. No wonder it inspired confidence.</p><p>But now picture the box in space with its walls suddenly removed. What will the molecules do? The answer’s in Siegfried Sassoon’s poem “Everyone Sang”:</p><p>As prisoned birds must find in freedom, Winging wildly across the white<br>Orchards and dark-green fields; on – on – and out of sight.</p><p>In mathematical rather than poetic terms, the molecules soon cease to interact and fly apart, maintaining forever their release velocities and getting ever further from each other. In fact, a simple calculation may surprise you: The speed with which the molecules move apart approximates ever better the law of galactic recession that Hubble announced in 1929. This simple Big Bang model does not look like disorder on the increase.</p><p><span>T</span>here is a greater mismatch between entropic disorder and reality in the very heart of Newton’s theory of universal gravitation. He achieved fame by explaining not only Kepler’s laws of planetary motion but also the fall of an apple. However, the problem of three bodies—he had in mind the earth, sun, and moon moving in their mutual gravitational fields—gave him headaches. Although a famously difficult problem, in 1772 the great mathematician Joseph-Louis Lagrange made some progress, including a significant discovery about the behavior of a “three-body universe” that was later shown to be true for any number of bodies. It concerns what is now called the center-of-mass moment of inertia, <i>I</i>. This measures the extent of the system—for bees it would be about the diameter of a swarm—and behaves in a characteristic universal way if a single condition is satisfied: The total energy of the system is not negative.</p><blockquote><p>The beauty is in the ratios, and they persist forever even in the expanding universe.</p> </blockquote><p>To understand what the behavior is, assume with Newton that time flows forever forward from past to future. Then what Lagrange found is that <i>I</i> decreases from infinity in the distant past, passes through a unique minimum, and grows to infinity in the distant future. I call this unique minimum a Janus Point. The Roman divinity can be invoked because he looks simultaneously in two opposite directions of time at once. What he sees is striking. In the region around the threshold on which he traditionally stands, the distribution of the particles (especially when there are many) is more uniform than anywhere else on the timeline of the universe. Then, in both directions, the particles cluster, taking on a shape that is more ordered and forming “galaxies.” From his vantage point, Janus can see this, but if you, being a mere mortal, were in such a universe you would necessarily be on one or the other side of the Janus point and could not “see through it” to the other side. You would find that the laws of nature around you do not distinguish a direction of time but that your universe gets ever more clumpy in one direction.</p><p>There is a precise, mathematically significant quantity that may be called complexity and increases (with small fluctuations) in both directions from Janus. The big difference from what entropy does is that growth of complexity reflects an increase of order, not disorder. The effects in confined and unconfined systems are the exact opposites of each other. Moreover, the increase of complexity in unconfined systems follows directly from the governing dynamical law whereas entropy increases in confined systems for statistical reasons.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/36/Aging/to-understand-your-past-look-to-your-future" data-trval="to-understand-your-past-look-to-your-future" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/9275_1d936dadf30010a96155a780553d5513.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Physics">Also in Physics</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/36/Aging/to-understand-your-past-look-to-your-future" data-trval="to-understand-your-past-look-to-your-future" data-trlbl="foc_rec" data-tract="internal_art">To Understand Your Past, Look to Your Future</a></h4>
<p>By Ken Wharton &amp; Huw Price</p>
<p>
You’re thinking about time all wrong, according to our best physical theories. In Einstein’s general theory of relativity, there’s no conceptual distinction between the past and the future, let alone an objective line of “now.” There’s also no sense in...<strong><a href="http://m.nautil.us/issue/36/Aging/to-understand-your-past-look-to-your-future" data-trval="to-understand-your-past-look-to-your-future" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div><p>Traditional arguments assume that somehow, for an as yet unfathomable reason, the universe gets in a special state of low entropy and correspondingly high order that is then remorselessly destroyed. A model often given is molecules confined to a little box in the corner of a big box. That’s the special initial condition. Now lift the lid of the little box; the laws of dynamics allow two quite different outcomes. It’s conceivable, but barely so, that the molecules will collect in the corner of the little box and then be in an even more special state. But it is statistically more likely that the molecules will spread out into the large box and eventually fill it uniformly. This is a statistical explanation of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/93/forerunners/time-flows-toward-order">http://m.nautil.us/issue/93/forerunners/time-flows-toward-order</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/93/forerunners/time-flows-toward-order</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395794</guid>
            <pubDate>Sat, 12 Dec 2020 05:15:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regex literals optimization (or how to cheat on benchmarks)]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25395709">thread link</a>) | @nitely
<br/>
December 11, 2020 | https://nitely.github.io/2020/11/30/regex-literals-optimization.html | <a href="https://web.archive.org/web/*/https://nitely.github.io/2020/11/30/regex-literals-optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The regex literals optimization avoids running the regex engine on parts of the input text that cannot possibly ever match the regex.</p>

<p>An example of a regex this can be applied to is <code>\w+@\w+\.\w+</code>, where the algorithm <em>quickly</em> finds the first <code>@</code>, then matches <code>\w+</code> backwards to find the start of the match, and then matches <code>\w+\.\w+</code> forward to find the end of the match. It then finds the second <code>@</code>, starting from the end of the previous match, and so on. This is a fairly naive (and incorrect) implementation, but it gives the idea of how it works.</p>

<p>I’ve recently implemented it in my pet project <a href="https://github.com/nitely/nim-regex/pull/68">nim-regex</a>, an NFA based regex engine that runs in (super)linear time. The results show it’s around ~100x faster than before in some benchmarks. It’s up to ~60x faster than PCRE when the optimization kicks in. The tests are based on <a href="https://github.com/mariomka/regex-benchmark">mariomka/regex-benchmark</a>.</p>

<p>This is not to be confused with <em>Chivers’ String Prefix Optimization</em>.</p>

<h2 id="literals-optimization">Literals Optimization</h2>

<p>Since nim-regex has to guarantee linear time, I’ll describe optimizations that are guaranteed to take linear time. We must also ensure the matches are not overlapped.</p>

<p>Here’s a high-level description of the algorithm:</p>

<ul>
  <li>We pick a literal that is <code>memchr</code>‘ed to skip parts of the text.</li>
  <li>The prefix is the regex part before the literal; none of the
characters or symbols within the prefix must match the literal.</li>
  <li>The prefix is ran backwards to find the start of the match.</li>
  <li>A full scan is ran from the start of the match
until a character that cannot be matched is found (safe break point)
or the end is reached. The scan tries to start the match at every character (NFAs can do this in linear time).</li>
  <li>Go to step one and repeat from the last scanned char. Make the prefix
match until the previous last scanned char.</li>
</ul>

<p>There are two important constraints to picking a literal:</p>

<ul>
  <li><em>“none of the characters or symbols within the prefix must match the literal”</em>, why? consider the regex: <code>\d\w+x</code>, and the input text: <code>xxxxxxxxxxx</code>; this would take quadratic time, as the prefix will match until the start of the string every time. What about the limit? while the limit does avoid the excessive matching, sometimes we’d need to match past the limit, ex: regex: <code>\d\w+x</code>, and text: <code>1xxx</code>. If we add this constraint, the literal becomes a delimeter, and these cases are solved.</li>
  <li>The literal cannot be part of a repetition, nor it can be part of an alternation. For example: <code>(abc)*def</code> the first literal candidate is <code>d</code>, since <code>(abc)*</code> may or may not be part of the match. Same thing for alternations.</li>
</ul>

<p>Here’s the main algorithm in <a href="https://nim-lang.org/">Nim</a>:</p>

<figure><pre><code data-lang="nim"><span>func</span> <span>findAll</span><span>(</span>
  <span>matches</span><span>:</span> <span>var</span> <span>Matches</span><span>,</span>
  <span>text</span><span>:</span> <span>string</span><span>,</span>
  <span>regex</span><span>:</span> <span>Regex</span><span>,</span>
  <span>start</span><span>:</span> <span>int</span>
<span>):</span> <span>int</span> <span>=</span>
  <span>var</span> <span>i</span> <span>=</span> <span>start</span>
  <span>var</span> <span>limit</span> <span>=</span> <span>start</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>text</span><span>.</span><span>len</span><span>:</span>
    <span>limit</span> <span>=</span> <span>i</span>  <span># rather pointless since the literal is a delimiter</span>
    <span>i</span> <span>=</span> <span>memchr</span><span>(</span><span>text</span><span>,</span> <span>regex</span><span>.</span><span>lit</span><span>,</span> <span>i</span><span>)</span>
    <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
      <span>return</span> <span>-</span><span>1</span>
    <span>var</span> <span>litIdx</span> <span>=</span> <span>i</span>
    <span>i</span> <span>=</span> <span>matchPrefix</span><span>(</span><span>text</span><span>,</span> <span>regex</span><span>,</span> <span>i</span><span>,</span> <span>limit</span><span>)</span>
    <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
      <span>i</span> <span>=</span> <span>litIdx</span><span>+</span><span>1</span>
    <span>else</span><span>:</span>
      <span>i</span> <span>=</span> <span>findSome</span><span>(</span><span>matches</span><span>,</span> <span>text</span><span>,</span> <span>regex</span><span>,</span> <span>i</span><span>)</span>
      <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
        <span>return</span> <span>-</span><span>1</span>
      <span>if</span> <span>matches</span><span>.</span><span>len</span> <span>&gt;</span> <span>0</span><span>:</span>
        <span>return</span> <span>i</span>  <span># this is used as "start" to resume the matching</span>
  <span>return</span> <span>-</span><span>1</span></code></pre></figure>

<p>A given character may be consumed only twice, once by the backward prefix match, and a second time by the forward scan. Hence the algorithm runs in linear time.</p>

<p>I may describe how <code>matchPrefix</code> and <code>findSome</code> work, how to construct the reversed NFA in the right order, and how to pick the literal in a future article. The nim-regex code contains descriptions of the algorithms, though.</p>

<h2 id="benchmarks">Benchmarks</h2>

<p>The <a href="https://github.com/nitely/nim-regex/tree/master/bench">benchmarks</a> regexes are based on <a href="https://github.com/mariomka/regex-benchmark">mariomka/regex-benchmark</a>. The only difference is the regexes are pre-compiled, so just the matching is tested. The results show nim-regex is ~63x faster than PCRE in the email test, and ~2x faster in the URI and IP tests.</p>

<p>Why is nim-regex so fast in the email case? The regex engine doesn’t run as often. There are orders of magnitud more IP/URI candidates than email candidates (<code>@</code> chars within the text) to match. In the former case the time is dominated by the regex engine, while in the latter case it’s dominated by searching the char literal.</p>

<div><div><pre><code>==================================================
GlobalBenchmark       relative  time/iter  iters/s
==================================================
GlobalBenchmark                  294.86ps    3.39G
==================================================
bench.nim             relative  time/iter  iters/s
==================================================
pcre_email                        21.76ms    45.96
nim_regex_email       3247.14%   670.02us    1.49K
nim_regex_email_macro 6335.93%   343.38us    2.91K
pcre_uri                          22.15ms    45.14
nim_regex_uri           92.82%    23.87ms    41.90
nim_regex_uri_macro    256.29%     8.64ms   115.68
pcre_ip                            5.73ms   174.58
nim_regex_ip            88.70%     6.46ms   154.84
nim_regex_ip_macro     214.75%     2.67ms   374.91
</code></pre></div></div>

<blockquote>
  <p>Note Nim’s PCRE is at the top of the mariomka/regex-benchmark. I ran those benchmarks, and IIRC nim-regex was just a bit faster, mainly because the non-macro regex engine is slower (see the above results), and the regex compilation is also tested.</p>
</blockquote>

<h2 id="other-optimizations">Other optimizations</h2>

<p>Here are other possible optimizations:</p>

<ul>
  <li>Picking a literal —even if the prefix matches it— should take linear time as long as the prefix is bounded (i.e: does not contain repetitions), ex: <code>\d\wx</code>.</li>
  <li>Picking a literal within a “one or more” repetition/repetition group should be possible, since <code>(abc)+</code> matches the same as <code>abc(abc)*</code>.</li>
  <li>It’s better to pick the last literal within the first literal sequence, since that way we always try to match as many literals as possible early on, and potentially fail early. We want to keep the prefix regex as short as possible, so the picking a literal in the first sequence is best.</li>
  <li>Alternations can be optimized this very same way in some cases, ex: <code>bar|baz</code>, since both alternations have <code>ba</code> in common, <code>a</code> can be picked as the literal.</li>
  <li>Alternations can be optimized in other cases. PCRE seems to use <code>memchr</code> or similar for up to two alternation terms. A DFA could be used to quickly match candidates instead of <code>memchr</code>, as that’s a more general solution.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Literals optimization is not a general optimization as it does not work on every regex, but when it does, it can greatly improve the matching speed.</p>

<p>Can a backtracker like PCRE implement this? PCRE in particular already has some sort of similar optimization, but it’s not as good/fast as this one. Backtrackers cannot implement this as described here exactly, but they can do something similar that requires backtracking. If they provide a resumable <code>find</code> function, then probably yes.</p>

<p>Hopefully, more regex engines will implement these sort of optimizations, so they are more compelling alternatives to backtrackers such as PCRE.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nitely.github.io/2020/11/30/regex-literals-optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395709</guid>
            <pubDate>Sat, 12 Dec 2020 04:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon owns more than $2B worth of IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 338 | Comments 338 (<a href="https://news.ycombinator.com/item?id=25395432">thread link</a>) | @dangoldin
<br/>
December 11, 2020 | https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/ | <a href="https://web.archive.org/web/*/https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
    

    <section>
      
<p>While listening to a <a href="https://softwareengineeringdaily.com/2020/12/02/bgp-with-andree-toonk/">podcast discussing BGP</a> I heard the fact that AWS owns more than $2B worth of IP addresses. I knew AWS was massive but this came as a big shock so I decided to do some digging around. I came across a <a href="https://ipv4marketgroup.com/ipv4-pricing/">site</a> that listed the market prices of IP addresses and the range looks to be anywhere from $20 to $30 per IP depending on the block size. Now it was time to figure out the IP addresses owned by Amazon. I figured this would be difficult but lucky for us AWS actually <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">publishes</a> their entire set of IP addresses as JSON.</p>

<p>The work is simply to download the JSON and then convert the CIDR blocks to the number of IPs and add them all up. As of today, December 11, 2020 AWS self reports owning 109,847,486 IPV4 addresses - at a price of $20 this is almost $2.2B and at $30 it’s almost $3.3B. That’s wild.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>urllib.request</span>
<span>import</span> <span>json</span>

<span>with</span> <span>urllib</span><span>.</span><span>request</span><span>.</span><span>urlopen</span><span>(</span><span>' https://ip-ranges.amazonaws.com/ip-ranges.json'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>j</span> <span>=</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>f</span><span>.</span><span>read</span><span>().</span><span>decode</span><span>(</span><span>'utf-8'</span><span>))</span>

<span>print</span><span>(</span><span>'All keys'</span><span>,</span> <span>j</span><span>.</span><span>keys</span><span>())</span>

<span>print</span><span>(</span><span>'IPV4 prefixes'</span><span>,</span> <span>len</span><span>(</span><span>j</span><span>[</span><span>'prefixes'</span><span>]))</span>

<span>ips</span> <span>=</span> <span>0</span>
<span>for</span> <span>prefix</span> <span>in</span> <span>j</span><span>[</span><span>'prefixes'</span><span>]:</span>
    <span>cidr</span> <span>=</span> <span>int</span><span>(</span><span>prefix</span><span>[</span><span>'ip_prefix'</span><span>].</span><span>split</span><span>(</span><span>'/'</span><span>)[</span><span>1</span><span>])</span>
    <span>ips</span> <span>+=</span> <span>2</span><span>**</span><span>(</span><span>32</span><span>-</span><span>cidr</span><span>)</span>

<span>print</span><span>(</span><span>'# IPS'</span><span>,</span> <span>ips</span><span>)</span></code></pre></figure>

    </section>

    
    <br>
    

    

    

    

  </article>
</div></div>]]>
            </description>
            <link>https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395432</guid>
            <pubDate>Sat, 12 Dec 2020 04:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full Text Search in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395237">thread link</a>) | @imshashank
<br/>
December 11, 2020 | https://system.camp/databases/full-text-search-in-postgresql/ | <a href="https://web.archive.org/web/*/https://system.camp/databases/full-text-search-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary">
		
	<article id="post-2458">
		<div>
			


			
<div>
	

<h3>What is wrong with the good old SQL searches?</h3>



<ul><li>There is no support for common languages. Regular expressions do not suffice because they cannot easily handle words that essentially mean the same, i.e., blocked and blocking is one such example. You might miss documents that contain blocked, although you probably would like to find them when searching for blocking. Now don’t tell me you are going to use OR through all the derived words – that’s not what a good developer would do 😉</li><li>There is no support for indexes and thus, you have to process the whole document every time you need to search something which is rather tedious and slow.</li></ul>



<h3>What is full text search?</h3>



<p>As the <a href="https://www.postgresql.org/docs/9.5/textsearch-intro.html" target="_blank" rel="noopener">official documentation</a> defines it – Full Text Searching (or just text search) provides the capability to identify natural-language documents that satisfy a query, and optionally to sort them by relevance to the query. The most common type of search is to find all documents containing given query terms and return them in order of their similarity to the query. Notions of query and similarity are very flexible and depend on the specific application. The simplest search considers query as a set of words and similarity as the frequency of query words in the document.</p>



<p>This essentially means that you can now just search for block and you’re going get all it’s derivatives in the document that you want! Isn’t that cool?</p>



<h3>How does it work though?</h3>



<p>PostgreSQL has two utility functions that will help us through this quest – <code>to_tsvector()</code> and <code>to_tsquery()</code></p>



<ul><li>The <code>to_tsvector()</code> command will create a set of lexemes using the document provided to it. It’ll conveniently omit any words that have little meaning – words like ‘the’, ‘an’, etc. When you run this,<br><code>SELECT to_tsvector('english', 'Full text search is an awesome feature');</code></li></ul>



<p>The result is a ‘map’ of words or a dictionary which represents the location of each word.<br><code>’awesom’:6’featur’:7’full’:1’search’:3’text’:2</code></p>



<ul><li>The <code>to_tsquery()</code> takes in a list of words that will be searched against the result of our <code>to_tsvector()</code> function.</li></ul>



<p><code>SELECT to_tsvector(‘Full text search is an awesome feature’) @@ to_tsquery(‘full’);</code></p>



<p>The query above will give us a result <code>true</code>.</p>



<p>Now how to use it? The most apt use would be to create a <code>tsvector</code> of the columns of your database you want to search on and run a <code>tsquery</code> command against that to select the rows you need. What’s more interesting is that you can use operators like <code>&amp;</code>, <code>|</code>, <code>!</code>, etc in your queries!</p>



<p>The official documentation does an awesome job of explaining things! This is just an overview – for more details please go through <a href="https://www.postgresql.org/docs/9.6/functions-textsearch.html" target="_blank" rel="noopener">this</a> link.</p>






<div>
    <div>
        <div>
            <p><a href="https://system.camp/profile/pratyush/" rel="author">
					<img alt="" src="https://secure.gravatar.com/avatar/d80daceadb74f29f9ebe0abf4519d748?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/d80daceadb74f29f9ebe0abf4519d748?s=160&amp;d=mm&amp;r=g 2x" height="80" width="80" loading="lazy">                </a>
            </p>
            <div>
                <p><span>
                    
                </span>
                <span>
                    <span>Member since</span>
                     <time datetime="2020-12-06 05:37">
                        October 6, 2020                     </time>
                </span>
            </p></div>

			
	    

			
        </div>
		    </div>

	
	</div>
</div>
		</div>

		
<!-- .entry-footer -->
	</article><!-- #post-2458 -->

	

	</div></div>]]>
            </description>
            <link>https://system.camp/databases/full-text-search-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395237</guid>
            <pubDate>Sat, 12 Dec 2020 03:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Reviews Not Code Approvals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394597">thread link</a>) | @aard
<br/>
December 11, 2020 | http://adamard.com/code_reviews.html | <a href="https://web.archive.org/web/*/http://adamard.com/code_reviews.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>{<br>&nbsp;&nbsp;&nbsp;&nbsp;Adam Ard<br>}</h2><br>
  <h2>Code Reviews Not Code Approvals</h2>
  <p>In our brave new world of remote work, asynchronous methods of
 collaboration are especially important. When you are working in
 different locations, perhaps on different schedules, you need
 communication mediums that allow you to send a message and go on to
 something else. When someone on the other end of that message finds
 time, they will respond and quickly go on with <em>their</em> own
 work. No one is blocked. The alternative would be
 intolerable. Waiting for responses that may not come for hours, or
 even days, before continuing your work would be a colossal waste of
 time. And being forced to stop whatever activity you are engaged in
 to immediately respond to incoming requests, all to avoid making
 someone wait, is equally problematic.</p><p>While there are times
 when you need information quickly and are truly blocked, if this is
 common, there are likely issues with how your project is being
 managed. Is your manager feeding you tasks, one after another,
 without giving necessary high-level direction? Is your engineering
 organization failing to collect on-boarding information into
 documentation that is available for reference when you get stuck?
 Whatever the reason, it is clear that people need the ability to work
 independently without having to continuously ask for
 guidance.</p><p>But assuming you are able to code independently most
 of the time and have good asynchronous ways to communicate with
 coworkers, there is still the issue of code reviews. If you really
 want to stick with an asynchronous working paradigm, then code
 reviews are totally backwards. When a piece of code is ready to
 deploy, it always gets stuck waiting for a code review. Progress
 comes to a screeching halt. Isn’t this a synchronous wait? Blocking
 the pipeline with a manual approval step? You may wait for days
 before someone can look it over. Sure you can work on some other
 project, but context switching is expensive. And when you are pushing
 forward with momentum on your highest priority item being stopped for
 a code review is about as wasteful as it gets. Efficiency experts
 shed tears over this kind of stuff. Even assuming that you could move
 forward on a secondary project, what happens when you finish another
 task and the first project’s task still hasn’t been approved? Do you
 work on a third project? At some point the madness must
 stop.</p><p>The real problem here is that code reviews are really
 not <em>reviews</em> at all. The word r<em>eview</em> implies that
 something has been completed, and you are just looking it
 over — after the fact. What we do now should be called a code
 approval. Something is almost done (your scrum master will be quick
 to point out that nothing is ‘done’ until it is in production), and
 someone needs to check a box so it can move to completion. It is held
 up because it is hitting against a gatekeeper. If it were truly
 a <em>review</em>, you could have pushed it up and been on your
 way. But instead, you are waiting for permission. You’re stopped,
 sitting on the side of the road, watching while your competitors run
 by.</p><p>In an ideal world, you could deploy and then someone would
 immediately get a notification that there was new stuff to look
 at. Then, when they had a chance, when their brain wasn’t deep in
 another problem, they could look over it. In the meantime you can
 make progress on your next item.</p><p>I am aware that this would
 give some managers heartburn, but it needn’t. If something is broken
 in code that goes live, it can be fixed in a future commit (that will
 go up nice and quick since it doesn’t have to sit waiting for a
 review). If it is a serious issue, hopefully a basic smoke test would
 catch it and automatically roll it back. Truthfully, I would trust a
 test suite to catch a problem more than a human reviewer
 anyway. Wouldn’t time spent on reviews be better spent building more
 comprehensive tests anyway?</p><p>Have I convinced you? Are you
 ready to start doing actual code reviews and leave code approvals to
 the birds?</p></div></div>]]>
            </description>
            <link>http://adamard.com/code_reviews.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394597</guid>
            <pubDate>Sat, 12 Dec 2020 02:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching an open start up Interviewing SaaS Business Owners]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394221">thread link</a>) | @hustld
<br/>
December 11, 2020 | https://hustld.com/blog/launching-an-open-start-up-journey | <a href="https://web.archive.org/web/*/https://hustld.com/blog/launching-an-open-start-up-journey">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          
<p>This is the date that I, <a href="https://twitter.com/itsdevdaniel" target="_blank" rel="noopener">Daniel Lasek</a>, have launched Hustld. It's meant to be a community of business owners (specifically SaaS owners) who tell their story on how they got started. My goal was to target individuals who want to create their own companies and who might require guidence or inspiration from other entrepreneurs.&nbsp; I only got 5 interviews and soon after I decided I wanted to work on other projects. I closed down the server and stopped the site.</p>

<p>Here we are today. I remembered that I had purchased a server for a year on AWS and enjoyed when users visited Hustld to read business interviews. In addition I want to log my journey of Hustld and how I plan to grow it. I am turning Hustld into an "<a href="https://hackernoon.com/what-does-it-mean-to-be-an-open-startup-f4446984189" target="_blank" rel="noopener">open start up</a>". I will share all my progress on my twitter (<a href="https://twitter.com/itsdevdaniel">@itsdevdaniel</a>) and write blogs on here. As of right now the site is not monetized in anyway but I do plan do add some sponsored posts, subscription and cool features in the future! My primary goal as of now isn't MRR (Monthly Reccuring Revenue) it is the # of interviews I can get per month. I am hoping to get at least 5 interviews before 2021 and 10 interviews in January 2021.</p>
<div><p>If you are a business owner (Saas preferred) and would like me to interview you <a href="https://hustld.com/contact">send me a message</a>.</p></div>

<p>5 New Interviews</p>
          
        </div></div>]]>
            </description>
            <link>https://hustld.com/blog/launching-an-open-start-up-journey</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394221</guid>
            <pubDate>Sat, 12 Dec 2020 01:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principle of Maximum Entropy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394064">thread link</a>) | @keyboardman
<br/>
December 11, 2020 | https://leimao.github.io/blog/Maximum-Entropy/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Maximum-Entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>The principle of maximum entropy states that the probability distribution which best represents the current state of knowledge is the one with largest entropy, in the context of precisely stated prior data (such as a proposition that expresses testable information). These prior data serves as the constrains to the probability distribution.</p>



<p>Given the second law of thermodynamics (principle of increase of entropy), isolated systems spontaneously evolve towards thermodynamic equilibrium, the state with maximum entropy, maximum entropy distributions become the most natural distributions under certain constrains. In this blog post, I would like to discuss entropy maximization and a couple of maximum entropy distributions.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="gaussian-integral">Gaussian Integral</h4><p>

\[\begin{align}
\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi} \\
\end{align}\]

</p><p>I will skip the proof here, since the proof from <a href="https://en.wikipedia.org/wiki/Gaussian_integral">Wikipedia</a> is not that difficult to understand.</p>

<h4 id="useful-integrals">Useful Integrals</h4><p>

\[\begin{align}
\int_{-\infty}^{\infty} x e^{-x^2} dx &amp;= -\frac{1}{2} \int_{-\infty}^{\infty} e^{-x^2} d(-x^2) \\
&amp;= -\frac{1}{2} e^{-x^2} \big\rvert_{-\infty}^{\infty}\\
&amp;= 0 \\
\end{align}\]

\[\begin{align}
\int_{-\infty}^{\infty} x^2 e^{-x^2} dx &amp;= -\frac{1}{2} \int_{-\infty}^{\infty} x d (e^{-x^2}) \\
&amp;= -\frac{1}{2} \Big( x e^{-x^2} \big\rvert_{-\infty}^{\infty} - \int_{-\infty}^{\infty} e^{-x^2} dx \Big) \\
&amp;= -\frac{1}{2} \Big( 0 - \sqrt{\pi} \Big) \\
&amp;= \frac{\sqrt{\pi}}{2} \\
\end{align}\]

</p><p>Notice that here we used integral by parts.</p>

<h3 id="entropy-maximization">Entropy Maximization</h3>

<h4 id="discrete-probability-distribution">Discrete Probability Distribution</h4>

<p>Suppose $P$ is a discrete probability distribution. The entropy is defined as</p><p>

\[\begin{align}
H(P) &amp;= - \sum_{x \in X}^{} P(x) \log P(x) \\
\end{align}\]

</p><p>We further have some constrains on $P$:</p>

<ul>
  <li>$P(x) \geq 0$</li>
  <li>$\sum_{x \in X}^{} P(x) = 1$</li>
  <li>$\sum_{x \in X}^{} P(x) r_i(x) = \alpha_i$ for $1 \leq i \leq m$</li>
</ul>

<p>The first two constrains are trivial given $P$ is a probability distribution. The third constrain is optional and it indicates a constrain on the entire system. Notice that there could be more than one constrain if $m &gt; 1$.</p>



<p>We would like to maximize the entropy.</p><p>

\[\max_{P} H(P) = \max_{P} \Big( - \sum_{x \in X}^{} P(x) \log P(x) \Big)\]

</p><p>Letâ€™s try to solve this optimization problem. We would use Lagrange multiplier for the constrains.</p><p>

\[\begin{align}
L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \sum_{x \in X}^{} P(x) \log P(x) + \lambda_0 \Big(\sum_{x \in X}^{} P(x) - 1 \Big) + \sum_{i=1}^{m} \lambda_i \sum_{x \in X}^{} \Big(P(x) r_i(x) - \alpha_i \Big) \\
\end{align}\]

</p><p>We take the derivative of $L(P, \lambda_0, \lambda_1, \cdots, \lambda_m)$ with respect to $P(x)$ and the derivative should be $0$.</p><p>

\[\begin{align}
\frac{\partial}{\partial P(x)} L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \log P(x) - 1 + \lambda_0 + \sum_{i=1}^{m} \lambda_i r_i(x) \\
&amp;= 0 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[\begin{align}
P(x) &amp;= e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{e^{1 - \lambda_0}} \\
\end{align}\]

</p><p>Because $\sum_{x \in X}^{} P(x) = 1$,</p><p>

\[\begin{align}
\sum_{x \in X}^{} P(x) &amp;= \sum_{x \in X}^{} e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= e^{\lambda_0 - 1} \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[e^{1 - \lambda_0} = \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)}\]

</p><p>With this, we could rewrite $P(x)$ as</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} } \\
\end{align}\]

</p><h4 id="continuous-probability-distribution">Continuous Probability Distribution</h4>

<p>Similarly, suppose $P$ is a continuous probability distribution. The entropy is defined as</p><p>

\[\begin{align}
H(P) &amp;= - \int_{X}^{} P(x) \log P(x) dx \\
\end{align}\]

</p><p>With the following constrains</p>

<ul>
  <li>$P(x) \geq 0$</li>
  <li>$\int_{X}^{} P(x) dx = 1$</li>
  <li>$\int_{X}^{} P(x) r_i(x) dx = \alpha_i$ for $1 \leq i \leq m$</li>
</ul>

<p>Similarly, to maximize the entropy, we maximize the Lagrangian for the continuous case.</p><p>

\[\begin{align}
L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \int_{X}^{} P(x) \log P(x) dx + \lambda_0 \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
\end{align}\]

</p><p>We take the derivative of $L(P, \lambda_0, \lambda_1, \cdots, \lambda_m)$ with respect to $P(x)$ and the derivative should be $0$. We will also use the <a href="https://en.wikipedia.org/wiki/Calculus_of_variations">calculus of variations</a> to compute the derivative, which is slightly more complicated. Without going into all the details, we have the following derivatives.</p><p>

\[\begin{align}
\frac{\partial}{\partial P(x)} L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \frac{\partial}{\partial P(x)} \int_{X}^{} P(x) \log P(x)  dx + \lambda_0 \frac{\partial}{\partial P(x)} \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \frac{\partial}{\partial P(x)} \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
&amp;= - \int_{X}^{} \frac{\partial}{\partial P(x)} \big( P(x) \log P(x) \big)  dx + \lambda_0 \frac{\partial}{\partial P(x)} \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \frac{\partial}{\partial P(x)} \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
&amp;= - \log P(x) - 1 + \lambda_0 + \sum_{i=1}^{m} \lambda_i r_i(x) \\
&amp;= 0 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[\begin{align}
P(x) &amp;= e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{e^{1 - \lambda_0}} \\
\end{align}\]

</p><p>Because $\int_{X}^{} P(x) dx = 1$,</p><p>

\[\begin{align}
\int_{X}^{} P(x) dx &amp;= \int_{X}^{} e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } dx \\
&amp;= e^{\lambda_0 - 1} \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[e^{1 - \lambda_0} = \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx\]

</p><p>With this, we could rewrite $P(x)$ as</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx } \\
\end{align}\]

</p><h3 id="maximum-entropy-distribution-examples">Maximum Entropy Distribution Examples</h3>

<h4 id="roll-dice">Roll Dice</h4>

<p>A conventional dice has 6 faces. $X = \{ 1, 2, 3, 4, 5, 6 \}$. Because we donâ€™t have additional constrains, therefore</p><p>

\[\lambda_1 = \lambda_2 = \cdots = \lambda_m = 0\]

</p><p>So, the maximum entropy probability distribution of getting each face of the dice is</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} } \\
&amp;= \frac{ e^{0} }{ \sum_{x \in X}^{} e^{0} } \\
&amp;= \frac{ 1 }{ 6 } \\
\end{align}\]

</p><h4 id="uniform-distribution">Uniform Distribution</h4>

<p>The only constrain we put on a distribution is $X = [a, b]$. Because we donâ€™t have additional constrains, therefore</p><p>

\[\lambda_1 = \lambda_2 = \cdots = \lambda_m = 0\]

</p><p>So the maximum entropy probability distribution is actually uniform distribution.</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx } \\
&amp;= \frac{ e^{0} }{ \int_{a}^{b} e^{0} dx } \\
&amp;= \frac{ 1 }{ b - a } \\
\end{align}\]

</p><h4 id="gaussian-distribution">Gaussian Distribution</h4>

<p>We could also derive Gaussian Distribution using entropy maximization. The constrains for the maximum entropy distribution are</p>

<ul>
  <li>$X = (-\infty, \infty)$</li>
  <li>$\mathbb{E}[X] = \int_{-\infty}^{\infty} x P(x) dx = \mu$</li>
  <li>$\mathbb{V}[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \mathbb{E}[X^2] - \mu^2 = \int_{-\infty}^{\infty} x^2 P(x) dx - \mu^2 = \sigma^2$</li>
</ul>

<p>which translates to</p>

<ul>
  <li>$m = 2$</li>
  <li>$r_1(x) = x$, $\alpha_1 = \mu$</li>
  <li>$r_2(x) = x^2$, $\alpha_2 = \sigma^2$</li>
</ul><p>

\[\begin{align}
P(x) &amp;= e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} \\
\end{align}\]

</p><p>Because</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= 1 \\
\end{align}\]

</p><p>We have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \int_{-\infty}^{\infty} e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} dx  \\
&amp;= \int_{-\infty}^{\infty} e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \big( \lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2 \big) dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \Big[ \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2^2} \Big] \bigg) dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2} \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( -(-\lambda_2) \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
\end{align}\]

</p><p>Here we assume $\lambda_2 &lt; 0$, we further have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( -(-\lambda_2) \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)^2 \bigg) dx  \\
&amp;= \frac{1}{\sqrt{ -\lambda_2 }} \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)^2 \bigg) d \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)  \\
\end{align}\]

</p><p>To make it more clear, we set</p><p>

\[y = \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big)\]

</p><p>So using Gaussian integral, we further have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \frac{1}{\sqrt{ -\lambda_2 }} \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Maximum-Entropy/">https://leimao.github.io/blog/Maximum-Entropy/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Maximum-Entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394064</guid>
            <pubDate>Sat, 12 Dec 2020 01:05:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China’s Radical New Vision of Globalization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25393779">thread link</a>) | @DimiD
<br/>
December 11, 2020 | https://www.noemamag.com/chinas-radical-new-vision-of-globalization/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				<div>
  <p>Credits</p>
  <p>James Crabtree is an associate professor in practice at the Lee Kuan Yew School of Public Policy at the National University of Singapore. He is the author of “The Billionaire Raj.”</p>
</div>


<p>SINGAPORE —&nbsp;Back in August, Chinese President Xi Jinping met with a group of economists in Beijing. “In the coming period, we will face more and more headwinds,” he <a href="http://www.xinhuanet.com/english/2020-08/25/c_139314902.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">explained</a>, using unusually blunt language. Without naming names, Xi talked about China’s worsening trade and technology war with the United States under President Donald Trump, set against a backdrop of growing certainty in Beijing that America is bent on containing his nation’s geopolitical rise.</p>



<p>But then came the interesting part. “Since the beginning of this year, I have said on many occasions that we must promote the formation of a new development pattern, in which domestic and international cycles are the mainstay, and the domestic and international dual cycles promote each other,” Xi said. To an outsider, this might seem unremarkable, cloaked as it is in the elliptical phraseology that often marks Chinese economic ideas. But the “dual circulation” strategy Xi outlined actually represents a radical new understanding of globalization and of China’s place within it.</p>



<p>More than just a buzzword, dual circulation describes the deeply pessimistic worldview that has settled over Beijing. Once China’s leaders saw opportunity in globalization. Now, they expect the U.S. and its allies to deny China the technology it needs to build “a modern socialist country” by mid-century, meaning a wealthy superpower fit to rival the U.S. Although likely to be less pugilistic, Beijing rightly believes an incoming Biden administration will also press forward with policies designed to stop advanced technologies finding their way into Beijing’s hands. Chinese thinking has long valorized self-reliance, dating back to ideas developed by former Chinese leader Mao Zedong during the country’s civil war, which ended with the foundation of the People’s Republic of China in 1949. Now, Trump’s tariffs, as well as his campaigns against companies like Huawei and TikTok, have given new impetus to the modern form of self-reliance Xi dubs “internal” development.</p>



<p>Many experts have noted a changing Western consensus on China, as leaders in Washington abandoned the idea that economic modernization would inevitably lead to political liberalization in Beijing. But there has been a comparable shift in China’s internal conversation on the West too. Beginning with semiconductors but potentially expanding to all manner of other areas, China now expects it will have to develop technologically on its own. Xi’s new theory now sits at the heart of the country’s <a href="http://www.xinhuanet.com/english/2020-10/29/c_139476451.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">14th five-year plan</a>, which covers development from 2021 to 2025, and was unveiled in draft form in October. The result will accelerate China’s decoupling from the West, while also increasing the importance of trading links forged with other parts of the world — for instance, via Xi’s signature Belt and Road Initiative. Put more bluntly, while the world was distracted by the drama of the U.S. presidential election, Xi quietly unveiled an economic strategy fit for a new Cold War. Both for China and for globalization itself, the results are likely to be profound.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “China expects the U.S. and its allies to act ever more aggressively to deny China the technology it needs.”    </p>

    
    
  </div>
</div>




<hr>



<p>To see how much China’s consensus has changed, recall Xi’s <a href="https://america.cgtn.com/2017/01/17/full-text-of-xi-jinping-keynote-at-the-world-economic-forum" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">remarks</a> at Davos in 2017. There, he portrayed globalization not as a threat, but as an inevitability. “The global economy is the big ocean that you cannot escape from,” he suggested. “China will vigorously foster an external environment of opening-up for common development.” Just as Trump was turning against the idea, China would act as steward of the existing global order. It would even help to remedy many of the problems that rapid integration had caused, Xi argued, from economic inequality to climate change.</p>



<p>Three years later and, under <a href="https://research.nus.edu.sg/eai/wp-content/uploads/sites/2/2020/10/EAIC-20-20201020.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">dual circulation</a>, things look much different. The idea splits the world into two systems. First comes external circulation, meaning China’s global trade, but also the way it invites foreigners into its domestic economy. This was the focus of Xi’s Davos remarks and the approach that powered his country’s decades of rapid growth, transforming China into an exporting powerhouse. The second component is then internal circulation, meaning domestic demand from Chinese consumers, but also domestic supply chains and “made in China” technologies.&nbsp;</p>



<p>This division shares something in common with “<a href="https://www.straitstimes.com/40-years-of-china-opening-up" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">reform and opening up</a>,” a phrase that has dominated China’s economic thinking for decades. That idea suggested Beijing should reform its domestic (or internal) economy to make it more market-led, while also opening up to the (external) world via globalization, gaining new ideas, production techniques and technologies along the way. Dual circulation also echoes longstanding attempts to wean China off a growth model dominated by exports and infrastructure investment and build instead the kind of consumption-led economy common in rich countries.</p>



<p>Such attempts have been only partially successful. A decade ago, about <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China's%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">34%</a> of China’s economy came via domestic consumption, less than <a href="https://tradingeconomics.com/united-states/final-consumption-expenditure-etc-percent-of-gdp-wb-data.html#:~:text=(%25%20of%20GDP)%20in%20United,compiled%20from%20officially%20recognized%20sources." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">half the level</a> in the U.S. at the time. By 2019, this has reached just <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China%20Private%20Consumption%3A%20%25%20of%20GDP,-1952%20%2D%202019%20%7C%20Yearly&amp;text=China%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">39%</a> — progress, of a sort, but hardly dramatic. When the phrase dual circulation first emerged earlier this year, many saw it as merely yet one more push toward this long-term objective of Chinese internal economic rebalancing.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Beginning with semiconductors but potentially expanding to all manner of other technologies, China now expects it will have to develop economically on its own.”    </p>

    
    
  </div>
</div>




<p>It is China’s deteriorating geopolitical environment that marks dual circulation as a decisive break from the past, however. “China thinks there is a good prospect of even worse relations with the U.S. and its friends in the coming years,” I was told recently by Li Mingjiang, a Chinese political scientist based in Singapore and long-time observer of Beijing’s intricate political economy. “So, it needs to do something about it.”</p>



<p>It is not hard to see why. Trump’s tariffs and battles over soybeans generated more headlines, but it is advanced technology that really matters in Beijing. China is a global tech leader in some sectors, from online payments to artificial intelligence. But it lags in others. Despite its geopolitical heft, it still remains a firmly middle-income economy, with a gross domestic product per capita of roughly <a href="https://www.google.com/search?q=china+gdp+per+capita&amp;rlz=1C5CHFA_enSG865SG865&amp;oq=china+gdp&amp;aqs=chrome.0.69i59j69i57j0i67l3j0j69i60j69i61.4682j0j7&amp;sourceid=chrome&amp;ie=UTF-8" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">$9,700</a> — about on par with <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Kazakhstan</a> and roughly half that of <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Greece</a>. Access to cutting-edge technology is critical in changing this, especially as its economy moves away from the kind of basic exported manufactured goods that have long dominated its growth model.</p>



<p>Over recent decades, China has had many routes to acquiring such technology. Often, it simply bought it, as when Chinese companies snapped up everything from Rolls Royce jet engines to Qualcomm semiconductors. Foreign businesses rushed to set up Chinese operations, often as part of local joint ventures, eager to tap into a vast consumer market. Chinese businesses bought foreign technology groups, while Chinese academics and scientists built partnerships at the world’s best universities. Beijing <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">employed</a> darker methods too, from forced technology transfer to outright intellectual property theft. But there were always plenty of legitimate avenues to go with them.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi has quietly unveiled an economic strategy fit for a new Cold War.”    </p>

    
    
  </div>
</div>




<p>Now, many of these routes are closing fast. Rather than tariffs, America’s “entity list” has proved its most potent weapon. Back in 2016, President Barack Obama first used this process in <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">accusing</a> ZTE, China’s second-largest telecoms supplier, of selling U.S. technologies to Iran, crippling the Chinese company in the process. Trump then escalated this approach, banning U.S. businesses from trading with dozens of Chinese enterprises, from state-owned giants to niche artificial intelligence providers with links to Xinjiang and its embattled Muslim Uighur minority. More recent <a href="https://www.commerce.gov/news/press-releases/2020/08/commerce-department-further-restricts-huawei-access-us-technology-and" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">measures</a> unveiled this August hit foreign suppliers too, for instance stopping semiconductor operators in Taiwan from selling to Chinese entities. Huawei has been one high-profile victim, leading experts to <a href="https://www.ft.com/content/bdd2a70f-ecd2-4aff-b6c7-c0624bfdeebb" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">question</a> whether China’s state-linked tech champion can survive.</p>



<p>What started with semiconductors is unlikely to end there, however, hence dual circulation’s underlying pessimism. Under Trump, the U.S. has unveiled a range of further measures limiting China’s technology access, from its 2018 <a href="https://www.cliffordchance.com/briefings/2018/02/the_export_controlreformactof2018risksan.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Export Control Reform Act</a> to more targeted measures in areas like geospatial imagery software. Allies in Europe are being cajoled to follow suit. Many Western governments have also acted to stop China from buying up advanced tech companies entirely, while also <a href="https://www.chinacenter.net/2020/china_currents/19-3/scholars-or-spies-u-s-china-tension-in-academic-collaboration/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">limiting</a> academic collaborations with Chinese partners. The recent battle over TikTok was illustrative too, showing how rapidly the U.S. has lowered the bar on what counts as a national security threat, a category that now includes not just critical 5G telecoms architecture of the sort provided by Huawei, but also jocular teenage social media platforms.</p>



<p>Elsewhere, U.S. strategists are particularly vexed by China’s doctrine of “<a href="https://www.floridadaily.com/marco-rubio-introduces-bill-to-keep-chinese-military-companies-from-accessing-american-capital-markets/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">military-civil fusion</a>,” which mandates that technologies acquired by China’s private sector must be shared with its armed forces. The problem is that, when you look hard enough, almost anything can potentially be seen as a dual-use technology, from nuclear equipment and renewable energy batteries to civilian aircraft, drones and autonomous vehicles.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi’s plans clearly place more emphasis on domestic production and state control.”    </p>

    
    </div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25393779</guid>
            <pubDate>Sat, 12 Dec 2020 00:34:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering the TP-Link HS110]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25393505">thread link</a>) | @zdw
<br/>
December 11, 2020 | https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/ | <a href="https://web.archive.org/web/*/https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<div>
			
<article id="post-3286">

<div>
<div>
	<!-- .entry-header -->

		<div>
      
		<p><em>by Lubomir Stroetmann, Consultant and Tobias Esser, Consultant</em></p>
<p><teaser><br>The <strong>TP-Link HS110 Wi-Fi</strong> is a cloud-enabled power plug that can be turned on and off remotely via app and offers energy monitoring and scheduling capabilities. As part of ongoing research into Internet of Things security, we performed a security analysis by reverse engineering the device firmware and Android app, sniffing app-to-device and device-to-app communications and <a href="https://www.softscheck.com/de/fuzzing-de/" target="_blank" rel="noopener noreferrer">fuzzing</a> the proprietary protocols being used.</teaser></p>
<p>While cloud communication was found to be reasonably secure for an IoT device, we discovered two insecure proprietary local configuration protocols: A human-readable JSON protocol “encrypted” with an easily reversible autokey XOR cipher and a binary DES-encrypted configuration and debugging protocol (<strong>TDDP – TP-Link Device Debug Protocol</strong>). TDDP is in use across most of the TP-Link product line including routers and access points and thus merits further research. We also release a <a href="https://github.com/softScheck/tplink-smartplug" target="_blank" rel="noopener noreferrer">Wireshark dissector and two python clients</a> for the proprietary protocols on GitHub.</p>

<p><strong id="nav">Contents</strong> </p>
<ol>
<li><a href="#Security Analysis Summary">Security Analysis Summary</a></li>
<li><a href="#Device Setup">Device Setup</a></li>
<li><a href="#Reverse Engineering the firmware">Reverse Engineering the firmware</a></li>
<li><a href="#Busybox">Busybox</a></li>
<li><a href="#Portscan">Portscan</a></li>
<li><a href="#TP-Link Smart Home Protocol">TP-Link Smart Home Protocol</a></li>
<li><a href="#Test Mode">Test Mode</a></li>
<li><a href="#TP-Link Device Debug Protocol">TP-Link Device Debug Protocol</a></li>
</ol>
<p><strong id="Security Analysis Summary">1. Security Analysis Summary</strong> <a href="#nav"></a></p>
<p><strong>The Good:</strong></p>
<ul>
<li>Cloud functionality can be turned off</li>
<li>Cloud communication uses HTTPS and CA pinning</li>
<li>Stores energy monitoring data locally</li>
<li>Firmware update checks signature against RSA keys</li>
</ul>
<p><strong>The Bad:</strong></p>
<ul>
<li>Useless encryption for local communication</li>
<li>No authentication: Anybody on the local network can turn the Smart Plug on and off, reset it or render it inoperable</li>
<li>TLS cloud connection could be intercepted with any valid Symantec EV certificate (only Root CA is checked)</li>
<li>Phones home even if set up as local-only</li>
<li>Undocumented configuration and debug service (TDDP)</li>
</ul>
<p><strong id="Device Setup">2. Device Setup</strong> <a href="#nav"></a></p>
<p>The Smart Plug has two physical buttons: An on/off relay switch and a device reset button that resets the device if pushed for five seconds or longer. When plugged in, an unconfigured or freshly reset Smart Plug will start an unsecured open Access Point with the SSID “<code>TP-LINK_Smart Plug_XXXX</code>” where XXXX are four hexadecimal numbers. A quick search on <a href="https://www.wigle.net/" target="_blank" rel="noopener noreferrer">WiGLE</a> reveals several unconfigured TP-Link Smart Plugs in the wild:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/wigle-suche-1.png" alt="wigle-suche"></p>
<p>&nbsp;<br>
TP-Link’s Smart Home app “<a href="https://play.google.com/store/apps/details?id=com.tplink.kasa_android" target="_blank" rel="noopener noreferrer">Kasa</a>” makes the smartphone connect to this access point, sends UDP broadcast packets to <code>255.255.255.255</code> to find the Smart Plug IP and proceeds to configure it with the SSID and password that the user entered into the app. The Smart Plug then turns off the Access Point and connects to the configured WiFi as a client.</p>
<p>We perform a KARMA attack using the Sensepost <a href="https://github.com/sensepost/mana" target="_blank" rel="noopener noreferrer">MANA Toolkit</a>, forcibly deauthenticating the Smart Plug and trying to get it to connect to a rogue Access Point with the same SSID and no security. The attack is not successful; however repeated deauthentication can be used to perform a temporary Denial of Service attack against the device.</p>
<p><strong id="Reverse Engineering the firmware">3. Reverse Engineering the TP-Link HS110 firmware</strong> <a href="#nav"></a></p>
<p>We download the current official firmware for the device (<code>HS110(US)_V1_151016.zip</code>) and use binwalk to extract the contents of the .bin file:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/binwalk-1.png" alt="binwalk"></p>
<p>&nbsp;<br>
As we can see, the firmware is a typical embedded Linux system and contains three parts:</p>
<ul>
<li>U-Boot Bootloader 1.1.4 (Oct 16 2015 – 11:22:22)</li>
<li>Linux Kernel 2.6.31—LSDK-9.2.0_U11.14 (yt@yangtao.localdomain)</li>
<li>Squashfs filesystem</li>
</ul>
<p>Examining the contents of the filesystem, we find the following interesting files:</p>
<ul>
<li>/bin/busybox v1.01 (2015.10.16-03:17+0000)</li>
<li>/etc/newroot2048.crt</li>
</ul>
<p>This is the certificate used to verify the identity of the cloud server. The file contains the “<a href="https://www.symantec.com/theme/roots">VeriSign Class 3 Public Primary Certification Authority – G5</a>” root certificate. This means the only check performed when establishing a TLS connection to the cloud is if the provided server certificate has been signed by the Symantec/VeriSign CA for Extended Validation (EV) certificates (<a href="https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning" target="_blank" rel="noopener noreferrer">CA pinning</a>). A determined attacker could buy his own EV certificate and use it to impersonate a cloud server.</p>
<ul>
<li>/etc/shadow</li>
</ul>
<pre>root:7KBNXuMnKTx6g:15502:0:99999:7:::</pre>
<p>The oldschool descrypt password is trivially broken, the password is “media”.</p>
<ul>
<li>/usr/bin/shd – the main server application</li>
<li>/usr/bin/shdTester – client for energy monitor calibration</li>
<li>/usr/bin/calDump – dumps wifi calibration data from /dev/caldata</li>
</ul>
<p>All proprietary server logic is contained in the shd (“Smart Home Daemon”) binary, which is <code>MIPS32 R2 Big Endian</code>:</p>
<pre>shd: ELF 32-bit MSB executable, MIPS, MIPS32 rel2 version 1 (SYSV), 
dynamically linked, interpreter /lib/ld-uClibc.so.0, corrupted section header size
</pre>
<p>The shd binary also contains a copy of <code>OpenSSL 1.0.1j 15 Oct 2014</code> for establishing TLS connections to the cloud server.<br>
We load the shd binary into IDA and start analyzing!</p>
<p><strong id="Busybox">4. Busybox</strong> <a href="#nav"></a></p>
<p>The Busybox version provided in the firmware is vulnerable to <a href="https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2011-2716" target="_blank" rel="noopener noreferrer">CVE-2011-2716</a>, a command injection vulnerability in the udhcpc DHCP client component of Busybox, which allows to inject shell commands into one of the following DHCP options: (12) Hostname, (15) Domainname, (40) NIS Domain or (66) TFTP Server Name. For this to work, those values have to be actually used by the shell script invoking udhcpc. Analyzing the firmware we find that the shd binary creates a shell script <code>/tmp/udhcpc.script</code> containing:</p>
<pre>#!/bin/sh
if[ $1 = renew –o $1 = bound]
then
    ifconfig $interface $ip netmask $subnet
    route del default
    route add default gw $router
   echo "nameserver $dns" &gt; /tmp/resolv.conf
fi
</pre>
<p>It then executes udhcpc:</p>
<pre>/sbin/udhcpc –b –H "HS100(US)" –i br0 –s /tmp/udhcpc.script
</pre>
<p>As we can see, the hostname is hardcoded and none of the other options are used. Unfortunately, the udhcpc vulnerability is not exploitable in this case.</p>
<p><strong id="Portscan">5. Portscan</strong> <a href="#nav"></a></p>
<p>An nmap port scan on all TCP and UDP ports reveals the following:</p>
<table>
<thead>
<tr>
<th><strong>Port</strong></th>
<th><strong>Protocol</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>80/tcp</td>
<td>HTTP</td>
</tr>
<tr>
<td>9999/tcp</td>
<td>TP-Link Smart Home Protocol</td>
</tr>
<tr>
<td>1040/udp</td>
<td>TP-Link Device Debug Protocol (TDDP)</td>
</tr>
</tbody>
</table>
<p>The Webserver on Port <code>80</code> replies with a meaningless ellipsis, no matter what the request is:</p>
<pre>HTTP/1.1 200 OK
Server: TP-LINK Smart Plug
Connection: close
Content-Length: 5
Content-Type: text/html

…
</pre>
<p>Looking through the shd binary we see that the HTTP Server routine is called “<code>fake_httpd</code>” and will always return this hardcoded reply.</p>
<p>Port <code>9999 TCP</code> is used for controlling the Smart Plug on the local network via the Kasa app and is described in the <a href="#TP-Link Smart Home Protocol">TP-Link Smart Home Protocol section</a>. Port <code>1040 UDP</code> is described in the <a href="#TP-Link Device Debug Protocol">TP-Link Device Debug Protocol section</a>.</p>
<p><strong id="TP-Link Smart Home Protocol">6. TP-Link Smart Home Protocol</strong> <a href="#nav"></a></p>
<p>Sniffing the local wireless network traffic reveals that the TP-Link Kasa SmartHome app talks to the HS110 Smart Plug on TCP port 9999 using what looks like encrypted data.</p>
<p>After decompiling the Kasa app for Android, we find the encryption function:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/tphome-encryption-1.png" alt="hs110 tphome-encryption"></p>
<p>We see the initial key (initialization vector) i has a hardcoded value of <code>-85 (= 171)</code>. The first byte of the plaintext is <code>XORed</code> with the key. The key is then set to the plaintext byte. During the next iteration, the next plaintext byte is <code>XORed</code> with the previous plaintext byte. Decryption works the same, with the keystream made out of cyphertext bytes. This is known as an <a href="https://en.wikipedia.org/wiki/Autokey_cipher" target="_blank" rel="noopener noreferrer">autokey cipher</a> and while it has better statistical properties than simple XOR encryption with a repeating key, it can be easily broken by known plaintext attacks.</p>
<p>Now that we know the algorithm and the key, we implement a Wireshark dissector in LUA which automatically decrypts TP-Link Smart Home packets on port <code>9999</code>. It turns out that the protocol uses JSON, so we also pass the decrypted contents to the JSON dissector. We can now monitor communications between the Kasa app and the Smart Plug on the local WiFi:</p>
<p><a href="https://www.softscheck.com/assets/img/blog/wireshark-dissector-1.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/wireshark-dissector-1.png" alt="wireshark-dissector"></a></p>
<p>&nbsp;<br>
The Smart Plug commands are grouped into the following categories:</p>
<ul>
<li>system</li>
<li>netif (WLAN interface commands)</li>
<li>cnCloud (cloud connection)</li>
<li>time</li>
<li>emeter (energy meter)</li>
<li>schedule (scheduled on/off)</li>
<li>count_down (countdown on/off)</li>
<li>anti_theft (random scheduled on/off)</li>
</ul>
<p>We provide a comprehensive list of JSON commands (<a href="https://github.com/softScheck/tplink-smartplug/blob/master/tplink-smarthome-commands.txt" target="_blank" rel="noopener noreferrer">tplink-smarthome-commands.txt</a>) and a python client to send them with (<a href="https://github.com/softScheck/tplink-smartplug/blob/master/tplink_smartplug.py" target="_blank" rel="noopener noreferrer">tplink_smartplug.py</a>).</p>
<p><strong>System Commands</strong></p>
<p>We can read out information about the system using the <code>get_sysinfo</code> command:</p>
<pre>{"system":{"get_sysinfo":{}}}</pre>
<p>To send the command using our python client, invoke it with the <code>–c</code> info option:</p>
<pre>./tplink_smartplug.py –t 192.168.0.1 –c info</pre>
<p>We provide several predefined commands to read out information from the HS110 Smart Plug using <code>–c</code> options.<br>
Alternatively, you can use the <code>–j</code> option and provide the full JSON string:</p>
<pre>./tplink_smartplug.py –t 192.168.0.1 –j '{"system":{"get_sysinfo":{}}}'</pre>
<p>This allows to send any of the commands listed in <code>tplink-smarthome-commands.txt</code>.<br>
The <code>get_sysinfo</code> reply will contain the following information:</p>
<p><a href="https://www.softscheck.com/assets/img/blog/sysinfo.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/sysinfo.png" alt="hs110 sysinfo"></a></p>
<p>&nbsp;<br>
We can turn the HS110 Smart Plug on and off using the <code>set_relay_state</code> command, using <code>1</code> for on and <code>0</code> for off:</p>
<pre>{“system":{"set_relay_state":{"state":1}}}</pre>
<p>We can reboot the HS110 Smart Plug using the <code>reboot</code> command which requires a <code>delay</code> parameter in seconds:</p>
<pre>{"system":{"reboot":{"delay":1}}}</pre>
<p>The HS110 Smart Plug can be reset to factory settings, making it act as an open Access Point again:</p>
<pre>{"system":{"reset":{"delay":1}}}</pre>
<p>Note that since the protocol does not provide authentication, anybody on your network can send this command and force a reset. Here, a prankster would set a high delay value, giving them time to leave the premises.</p>
<p>There are further commands to change the MAC address, change the Device and Hardware IDs, turn off the device LED (night mode) etc.</p>
<p>Of special interest are the firmware flashing commands. You can download a&nbsp; firmware file from an arbitrary URL using:</p>
<pre>{"system":{"download_firmware":{"url":"http://..."}}}</pre>
<p>While downloading, you can get the download state using:</p>
<pre>{"system":{"get_download_state":{}}}</pre>
<p>Once the download is finished, you can flash the firmware using:</p>
<pre>{"system":{"flash_firmware":{}}}</pre>
<p>Flashing a modified image will not work since the image’s signature has to match one of four hardcoded RSA keys (we won’t go into wild speculations why there are four keys here):</p>
<p><a href="https://www.softscheck.com/assets/img/blog/checkfirmware2-1.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/checkfirmware2-1.png" alt="hs110 checkfirmware2"></a></p>
<p>&nbsp;<br>
<strong>WiFi Commands</strong></p>
<p>You can instruct the …</p></div></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/">https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/</a></em></p>]]>
            </description>
            <link>https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25393505</guid>
            <pubDate>Sat, 12 Dec 2020 00:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The era of the JVM is coming to an end]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25392805">thread link</a>) | @pdeva1
<br/>
December 11, 2020 | https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/ | <a href="https://web.archive.org/web/*/https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
    
    


    <div id="ajax-container">
        
<div>
<article>
    

    <div>

        <p>For over two decades, the JVM (and thus Java) has ruled supreme while other runtimes have come and gone. Ruby, Python, .Net, NodeJS, have all tried to take the throne. But the JVM offered something none could: a multi-threaded, JIT-compiled, high-performance, fully backward compatible runtime.</p><p>That the JVM hasn't kept up with the times, can be demonstrated with a simple example. Say you write a small command-line utility function in Java that has dependencies on a few jars. How does one package and distribute this utility? One could look at StackOverflow to see which plugin of your favorite build system is currently popular to create a Fat Jar. However, the official 'Java way' to package your code and its dependencies is still the good old .war file. A faster moving organization would have acknowledged how users like to ship their code. They would have extended the .jar file format (or introduced a new file format) to be able to package dependencies in a standardized manner. But no such thing on the horizon with Java.</p><p>Java is moving faster than ever now, one might say. It does get 2 minor releases a year now. (Though, does anyone really use the features of non-LTS Java versions?). Sure the module system in Java 9 allowed the JVM to shed some of its weight, but major additions to the JVM which would put it on par with competition still seem to be a long way away. Project Valhalla, which was supposed to introduce 'Value Types' to Java, was announced back in 2014 and still has no release date. Project Loom, which brings green threads, was announced in 2018 and is in a similar state. Want to interop with native code, one still has to deal with the insanity of 20-year-old JNI interfaces.</p><p>One also wonders, even after these features are introduced, how compelling would they be to use compared to their implementations in other languages/runtimes. Java's Achilles heel after all is the need to maintain backward compatibility. Its that backward compatibility requirement that got us the Java Streams API, where instead of <code>myList.map(...)</code> one has to write the monstrosity that is <code>myList.stream().map(...).collect(Collectors.toList()</code>.</p><p>There was a time where Java was the best choice for almost everything. GWT on the frontend, Spring on the backend. Databases like Hadoop, ElasticSearch, Kafka, Spark, all written on top of the JVM. Java also had the absolute best IDE in Eclipse and Intellij, making it a reason to choose Java over other languages in a professional environment.</p><p>What's different in the 2020s is that over the last decade, languages/runtimes have evolved to become best in class for specific domains. They took their learnings from the JVM, finally realizing that type safety is needed and performance is important. They ackonowledged that one language/runtime doesnt fit all needs.</p><ul><li>Want to write a large, complicated UI? ReactJS and Typescript allow you to do that while providing a type system even more expressive than the JVM.</li><li>Want to write a web server? Golang allows you to handle thousands of requests at a time without the need for a thread per request. It makes concurrency so easy, the equivalent in Java would be an order of magnitude more complex.</li><li>Want to write a big data database? Rust has you covered. Deal with huge amounts of data without needing to battle the GC and interact with low-level system calls without battling with JNI or <code>sun.misc.Unsafe</code>.</li></ul><p>With all these languages being fully typed, Jetbrains now has been able to make equally good IDE for those languages too.</p><p>From 2020 onwards, the JVM doesn't seem to be the best choice for anything. It will continue its legacy as a big, heavyweight, one size fits all VM. Good at everything, but never the best. The future is polyglot and it's free of the JVM.</p>
    </div>

    
</article></div>
    </div>
</div></div>]]>
            </description>
            <link>https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25392805</guid>
            <pubDate>Fri, 11 Dec 2020 23:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Measuring Memory Usage in Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25392791">thread link</a>) | @lukastyrychtr
<br/>
December 11, 2020 | https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="preamble">
<div>

<p>This post documents a couple of fun tricks we use in rust-analyzer for measuring memory consumption.</p>
<p>In general, there are two broad approaches to profiling the memory usage of a program.</p>
<p><em>The first approach</em> is based on “heap parsing”.
At a particular point in time, the profiler looks at all the memory currently occupied by the program (the heap).
In its raw form, the memory is just a bag of bytes, <code>Vec&lt;u8&gt;</code>.
However the profiler, using some help from the language’s runtime, is able to re-interpret these bytes as collections of object (“parse the heap”).
It then traverses the graph of objects and computes how many instances of each object are there and how much memory they occupy.
The profiler also tracks the ownership relations, to ferret out facts like “90% of strings in this program are owned by the <code>Config</code> struct”.
This is the approach I am familiar with from the JVM ecosystem.
Java’s garbage collector needs to understand the heap to search for unreachable objects, and the same information is used to analyze heap snapshots.</p>
<p><em>The second approach</em> is based on instrumenting the calls to allocation and deallocation routines.
The profiler captures backtraces when the program calls <code>malloc</code> and <code>free</code> and constructs a flamegraph displaying “hot” functions which allocate a lot.
This is how, for example, <a href="https://github.com/KDE/heaptrack">heaptrack</a> works (see also <a href="https://github.com/cuviper/alloc_geiger">alloc geiger</a>).</p>
<p>The two approaches are complementary.
If the problem is that the application does too many short-lived allocations (instead of re-using the buffers), it would be invisible for the first approach, but very clear in the second one.
If the problem is that, in a steady state, the application uses too much memory, the first approach would work better for pointing out which data structures need most attention.</p>
<p>In rust-analyzer, we are generally interested in keeping the overall memory usage small, and can make better use of heap parsing approach.
Specifically, most of the rust-analyzer’s data is stored in the incremental computation tables, and we want to know which table is the heaviest.</p>
<p>Unfortunately, Rust does not use garbage collection, so just parsing the heap bytes at runtime is impossible.
The best available alternative is instrumenting data structures for the purposes of measuring memory size.
That is, writing a proc-macro which adds <code>fn total_size(&amp;self) → usize</code> method to annotated types, and calling that manually from the root of the data.
There is Servo’s <a href="https://github.com/servo/servo/tree/2d3811c21bf1c02911d5002f9670349c5cf4f500/components/malloc_size_of"><code>malloc_size_of</code></a> crate for doing that, but it is not published to crates.io.</p>
<p>Another alternative is running the program under valgrind to gain runtime introspectability.
<a href="https://www.valgrind.org/docs/manual/ms-manual.html">Massif</a> and and <a href="https://www.valgrind.org/docs/manual/dh-manual.html">DHAT</a> work that way.
Running with valgrind is pretty slow, and still doesn’t give Java-level fidelity.</p>
<p>Instead, rust-analyzer mainly relies on a much simpler approach for figuring out which things are heavy.
This is the first trick of this article:</p>
</div>
</div><div>
<h2 id="archimedes-method"><a href="#archimedes-method"></a>Archimedes' Method</h2>
<div>
<p>It’s relatively easy to find out the total memory allocated at any given point in time.
For glibc, there’s <a href="https://man7.org/linux/man-pages/man3/mallinfo.3.html">mallinfo</a> function, a <a href="https://docs.rs/jemalloc-ctl/0.3.3/jemalloc_ctl/stats/struct.allocated.html">similar API</a> exists for jemalloc.
It’s even possible to implement a <a href="https://doc.rust-lang.org/stable/std/alloc/trait.GlobalAlloc.html"><code>GlobalAlloc</code></a> which tracks this number.</p>
<p>And, if you can measure total memory usage, you can measure memory usage of any specific data structure by:</p>
<div>
<ol>
<li>
<p>measuring the current memory usage</p>
</li>
<li>
<p>dropping the data structure</p>
</li>
<li>
<p>measuring the current memory usage again</p>
</li>
</ol>
</div>
<p>The difference between the two values is the size of the data structure.
And this is exactly what rust-analyzer does to find the largest caches: <a href="https://github.com/rust-analyzer/rust-analyzer/blob/b988c6f84e06bdc5562c70f28586b9eeaae3a39c/crates/ide_db/src/apply_change.rs#L104-L238">source</a>.</p>
<p>Two small notes about this method:</p>
<div>
<ul>
<li>
<p>It’s important to ask the allocator about the available memory, and not the operating system.
OS can only tell how many pages the program consumes.
Only the allocator knows which of those pages are free and which hold allocated objects.</p>
</li>
<li>
<p>When measuring relative sizes, it’s important to note the unaccounted-for amount in the end, such that the total adds up to 100%.
It might be the case that the bottleneck lies in the dark matter outside of explicit measurements!</p>
</li>
</ul>
</div>
</div>
</div><div>
<h2 id="amdahls-estimator"><a href="#amdahls-estimator"></a>Amdahl’s Estimator</h2>
<div>
<p>The second trick is related to the <a href="https://en.wikipedia.org/wiki/Amdahl%E2%80%99s_law">Amdahl’s law</a>.
When optimizing a specific component, it’s important to note not only how much more efficient it becomes, but also overall contribution of the component to the system.
Making an algorithm twice as fast can improve the overall performance only by 5%, if the algorithm is only 10% of the whole task.</p>
<p>In rust-analyzer’s case, the optimization we are considering is adding interning to <code>Name</code>.
At the moment, a <code>Name</code> is represented with a small sized optimized string (24 bytes inline + maybe some heap storage):</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>struct</span> <span>Name</span> <span>{</span>
    <span>text</span><span>:</span> <span>SmolStr</span><span>,</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Instead, we can use an interned index (4 bytes):</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>struct</span> <span>Name</span> <span>{</span>
    <span>idx</span><span>:</span> <span>u32</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>However, just trying out this optimization is not easy, as an interner is a thorny piece of global state.
Is it worth it?</p>
<p>If we look at the <code>Name</code> itself, it’s pretty clear that the optimization is valuable: it reduces memory usage by 6x!
But how important is it in the grand scheme of things?
How to measure the impact of <code>Name</code>s on overall memory usage?</p>
<p>One approach is to just apply the optimization and measure the improvement after the fact.
But there’s a lazier way: instead of making the <code>Name</code> smaller and measuring the improvement, we make it <strong>bigger</strong> and measure the worsening.
Specifically, its easy to change the <code>Name</code> to this:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>struct</span> <span>Name</span> <span>{</span>
    <span>text</span><span>:</span> <span>SmolStr</span><span>,</span>
    <span>// Copy of `text`</span>
    <span>_</span><span>ballast</span><span>:</span> <span>SmolStr</span><span>,</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Now, if the new <code>Name</code> increases the overall memory consumption by <code>N</code>, we can estimate the total size of old <code>Name</code>s as <code>N</code> as well, as they are twice as small.</p>
<p>Sometimes, quick and simple hacks works better than the finest instruments :).</p>
</div>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25392791</guid>
            <pubDate>Fri, 11 Dec 2020 23:02:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do People Write for Wikipedia? (2005) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25392096">thread link</a>) | @MrXOR
<br/>
December 11, 2020 | http://andreaforte.net/ForteBruckmanWhyPeopleWrite.pdf | <a href="https://web.archive.org/web/*/http://andreaforte.net/ForteBruckmanWhyPeopleWrite.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://andreaforte.net/ForteBruckmanWhyPeopleWrite.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25392096</guid>
            <pubDate>Fri, 11 Dec 2020 22:16:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the second wave overloading Sweden's intensive care units?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25391787">thread link</a>) | @juusto
<br/>
December 11, 2020 | https://www.thelocal.se/20201211/is-the-second-wave-overloading-swedens-intensive-care-units | <a href="https://web.archive.org/web/*/https://www.thelocal.se/20201211/is-the-second-wave-overloading-swedens-intensive-care-units">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.thelocal.se/20201211/is-the-second-wave-overloading-swedens-intensive-care-units</link>
            <guid isPermaLink="false">hacker-news-small-sites-25391787</guid>
            <pubDate>Fri, 11 Dec 2020 21:59:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Annual Cost of Sales Tax]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25391483">thread link</a>) | @calicruisin
<br/>
December 11, 2020 | https://www.thriftythoughts.io/sales-tax/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/sales-tax/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h2 id="how-much-do-we-actually-pay-in-sales-tax-every-year">How much do we actually pay in sales tax every year?</h2><p><br>Sales tax tends to fly under the radar. It can vary depending on what items you purchase, what state you're in, and what city you're in. Whenever you see it show up on a bill or receipt it can appear to be a relatively small, innocuous number. So how much are we actually spending per year on sales tax?</p><p>According to research commissioned by Ladder and conducted by OnePoll Americans spend <strong>$18,000</strong> per year on non-essential items. Given that sales tax generally applies to non-essential items, how much does this sales tax amount to in a given year in different locales across the U.S.?</p><figure><img src="https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--13-.png" alt="" srcset="https://www.thriftythoughts.io/content/images/size/w600/2020/12/UNCLAIMED-PROPERTY--13-.png 600w, https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--13-.png 800w" sizes="(min-width: 720px) 720px"></figure>
                            <section>
                                <h2>Enjoying these posts? Subscribe for more</h2>
                                
                                <br>
                                
                            </section>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.thriftythoughts.io/sales-tax/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25391483</guid>
            <pubDate>Fri, 11 Dec 2020 21:43:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NLP and Named Entity Recognition]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25391245">thread link</a>) | @yuchi
<br/>
December 11, 2020 | https://techblog.smc.it/en/2020-12-11/nlp-ner | <a href="https://web.archive.org/web/*/https://techblog.smc.it/en/2020-12-11/nlp-ner">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><em>This is the first in a series of articles covering that part of machine learning known as Natural Language Processing (NLP).</em></p><p><em>This article refers to several key concepts in Machine Learning.<br>
Read the article <a href="https://techblog.smc.it/en/2020-05-25/machine-learning-industry"><strong>Machine learning and applications for industry</strong></a>
for the main definitions.</em></p><p>With <a href="https://it.wikipedia.org/wiki/Elaborazione_del_linguaggio_naturale"><strong>Natural Language Processing</strong></a>
we refer to that interdisciplinary research field that embraces computer science, artificial intelligence and linguistics,
whose purpose is to develop algorithms capable of analyzing, representing and therefore "understanding"
natural language, written or spoken, in a similar or even more efficient way than human beings.</p><p>Huge amounts of text and speech content are generated and stored nowadays. Very often
no use is made of this data, unaware of the fact that instead they represent an invaluable source of value, thanks to which
it is possible to create tools and applications which can bring a considerable added value.</p><p>By exploiting the textual and vocal content available, it is possible, for example, to create tools for::</p><ul><li><strong>Named Entity Recognition</strong>: recognize and extract entities and semantic information from the text.</li><li><strong>Text Classification</strong>: classify textual content, for example the sentiment analysis of a text (positive or negative).</li><li><strong>Entity linking</strong>: disambiguate the entities identified in the text (link the textual entities to identifying concepts).</li><li><strong>Topic Modeling</strong>: automatically extract the main topics present in a textual corpus.</li><li><strong>Autocompletion</strong>: autocompletion of a query for example.</li><li><strong>Machine translation</strong>: translation of textual content from one language to another.</li><li><strong>Speech Recognition</strong>: transformation of voice content into textual content (technology behind chatbots).</li></ul><p>In this first article we will cover the task known as <a href="https://en.wikipedia.org/wiki/Named-entity_recognition"><strong>Named Entity Recognition (NER)</strong></a>.
We will see how it is possible to create a tool capable of recognizing entities in the text and what are some of its possible applications.</p><p>The Named Entity Recognition is placed within that subclass of task which in NLP is defined as <a href="https://en.wikipedia.org/wiki/Information_extraction"><strong>Information Extraction</strong></a>.
Through NER it is possible to identify entities in the text and associate them with the corresponding semantic categories such as persons, organizations, entities of
geopolitical type, geographic, numbers, temporal expressions and so on.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/8de58/entities.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/c85cb/entities.webp 300w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/e88ff/entities.webp 600w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/92f8c/entities.webp 1200w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/4fba2/entities.webp 1219w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/5a46d/entities.png 300w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/0a47e/entities.png 600w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/c1b63/entities.png 1200w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/8de58/entities.png 1219w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/png">
        <img alt="Figure 1 - Named Entity Recognition" src="https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/c1b63/entities.png" title="Figure 1 - Named Entity Recognition" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 1 - Named Entity Recognition</figcaption>
  </figure>   <p>We are talking about a task that has had a strong development in recent times, especially thanks to the advent of <a href="https://en.wikipedia.org/wiki/Deep_learning"><strong>Deep Learning</strong></a>.
The use of very deep neural networks has greatly increased and improved the effectiveness of entity recognition tools. <br>
Before the advent of Deep Learning, the most used tool was the so-called <a href="https://en.wikipedia.org/wiki/Hidden_Markov_model">Hidden Markov Model</a>,
a statistical model based on <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov chain</a>, but that did not guarantee
the same performance as today's Deep Learning-based models. <br>
Two examples of training models for entity recognition will be shown later in the article, both based on the use of algorithms
made with neural networks.</p><p>The task of the Named Entity Recognition is addressed through approaches of <a href="https://en.wikipedia.org/wiki/Supervised_learning"><strong>supervised type</strong></a>,
and for this reason it is necessary to have a set of labeled data available in order to train a model to recognize entities.
Each textual content must be labeled with the list of tokens and related tags for each entity that is to be recognized in the text.</p><p>There are several formats to represent a training dataset for Named Entity Recognition. Let's see the two most used.</p><p>A first format is the one called <strong> BILUO </strong> scheme, where the different parts of the entities are mapped according to the scheme in Figure 2.
Entities are tagged with the semantic category preceded by one of the defined prefixes.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/biluooo.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/c85cb/biluooo.webp 300w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/e88ff/biluooo.webp 600w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/bf818/biluooo.webp 870w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/5a46d/biluooo.png 300w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/0a47e/biluooo.png 600w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/biluooo.png 870w" sizes="(max-width: 870px) 100vw, 870px" type="image/png">
        <img alt="Figure 2 - BILUO scheme" src="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/biluooo.png" title="Figure 2 - BILUO scheme" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 2 - BILUO scheme</figcaption>
  </figure><p>The mapping between tokens and entities is then saved in a <strong> csv </strong> file, using a separate label for all tokens
that do not fall within the semantic categories of reference.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/d7542/biluo-map.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/c85cb/biluo-map.webp 300w,https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/e88ff/biluo-map.webp 600w,https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/385bc/biluo-map.webp 810w" sizes="(max-width: 810px) 100vw, 810px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/5a46d/biluo-map.png 300w,https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/0a47e/biluo-map.png 600w,https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/d7542/biluo-map.png 810w" sizes="(max-width: 810px) 100vw, 810px" type="image/png">
        <img alt="Figure 3 - Mapping with BILUO scheme" src="https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/d7542/biluo-map.png" title="Figure 3 - Mapping with BILUO scheme" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 3 - Mapping with BILUO scheme</figcaption>
  </figure><p>The BILUO scheme is perhaps the most popular format.</p><p>A second format is a simplified version of the BILUO scheme. It is called the <strong>IOB</strong> schema. This is a less fine-grained scheme, where
the prefix associated with the entity indicates only whether it is a token at the beginning or within the entity consisting of several words. <br>
The scheme follows the specifications defined in the figure below.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/fe76acc16315189d87de5de47a2234ba/11b93/iob.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/fe76acc16315189d87de5de47a2234ba/c85cb/iob.webp 300w,https://techblog.smc.it/static/fe76acc16315189d87de5de47a2234ba/e88ff/iob.webp 600w,https://techblog.smc.it/static/fe76acc16315189d87de5de47a2234ba/e9b15/iob.webp 1124w" sizes="(max-width: 1124px) 100vw, 1124px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/fe76acc16315189d87de5de47a2234ba/5a46d/iob.png 300w,https://techblog.smc.it/static/fe76acc16315189d87de5de47a2234ba/0a47e/iob.png 600w,https://techblog.smc.it/static/fe76acc16315189d87de5de47a2234ba/11b93/iob.png 1124w" sizes="(max-width: 1124px) 100vw, 1124px" type="image/png">
        <img alt="Figure 4 - IOB Scheme" src="https://techblog.smc.it/static/fe76acc16315189d87de5de47a2234ba/11b93/iob.png" title="Figure 4 - IOB Scheme" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 4 - IOB Scheme</figcaption>
  </figure><p>A third representation is in <strong> jsonl </strong> format.
In this format, each textual content is associated with a list that indicates, for each entity, the position in the text and the associated semantic category.</p><figure><div><div><pre data-language="json" data-index="0"><code><span><span>{   </span></span>
<span><span>  </span><span>"text"</span><span>: </span><span>""</span><span>Sharon</span><span> </span><span>flew</span><span> </span><span>to</span><span> </span><span>Miami</span><span> </span><span>last</span><span> </span><span>friday</span><span>""</span><span>, </span></span>
<span><span>  </span><span>"entities"</span><span>: [</span><span>(</span><span>0</span><span>, </span><span>5</span><span>, </span><span>"PERSON"</span><span>)</span><span>, </span><span>(</span><span>15</span><span>, </span><span>20</span><span>, </span><span>"LOC"</span><span>)</span><span>, </span><span>(</span><span>26</span><span>, </span><span>32</span><span>, </span><span>"DATE"</span><span>)</span><span>]</span></span>
<span><span>}</span></span></code></pre><figcaption>Source Code 1 - Example in jsonl format</figcaption></div></div></figure><p>Experts identify the BILUO scheme as the best to make models for Named Entity Recognition as accurate as possible.
This is because, through the multi-prefix scheme, they specify more detailed information in the text, which improves the capabilities of
learning of the Machine Learning algorithm used. <br>
But even using the IOB and jsonl format, very often it is possible to achieve noteworthy performance. <br>
Switching between formats is relatively simple and can be accomplished by defining rules-based procedures
easy intuition.
In addition, many NLP libraries already define predefined functions to transform your dataset into the desired format.</p><p>To label and transform data into one of these formats, there are ad hoc tools called <strong> annotators </strong>.
An annotator allows you to upload your data as plain text and then label it in a graphical environment which makes the annotation process more agile.
Annotators allow you to label data for NER, but also for textual classification tasks rather than sequence-to-sequence tasks.</p><p>In the case of NER, an annotator presents a graphic like the one below in the figure, with functionalities that allow
to carry out the annotation activity simply by highlighting the text and specifying the label to assign.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/10b63/doccano.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/c85cb/doccano.webp 300w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/e88ff/doccano.webp 600w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/92f8c/doccano.webp 1200w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/62ed8/doccano.webp 1800w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/eccbe/doccano.webp 1897w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/5a46d/doccano.png 300w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/0a47e/doccano.png 600w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/c1b63/doccano.png 1200w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/d61c2/doccano.png 1800w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/10b63/doccano.png 1897w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/png">
        <img alt="Figure 5 - Docccano screenshot" src="https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/c1b63/doccano.png" title="Figure 5 - Docccano screenshot" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 5 - Docccano screenshot</figcaption>
  </figure><p>The example screen is from <a href="https://github.com/doccano/doccano"><strong>doccano</strong></a>, a well structured and open source annotator. Doccano, once
labeled the data, allows you to export the dataset in <strong>jsonl</strong> format.
To be mentioned, on the other hand, among the paid ones <!-- -->[<strong> Prodigy </strong>]<!-- --> (<a href="https://prodi.gy/">https://prodi.gy/</a>), an advanced annotator, enhanced  through the concept
of active learning; this is developed by <!-- -->[Explosion.ai]<!-- --> (<a href="https://explosion.ai/">https://explosion.ai/</a>), creators of the opensource library of NLP <!-- -->[<strong> Spacy </strong>]<!-- --> (<a href="https://spacy.io/">https://spacy.io/</a>).</p><h2 id="dataset">Dataset</h2><p>If you want to train models for the recognition of entities, one option is to first analyze some labeled datasets present at
state of the art.
These tend to be generic datasets, with entities labeled with semantic categories relating to personal names, organizations, locations, dates,
temporal entities; however, it is also possible to find datasets labeled, concerning to more specific domains.
These datasets are almost always in English, but very often this problem can be overcome by using machine translation tools before carrying out
the activity of Named Entity Recognition, translating the content from the Italian language to the English language, and vice versa.</p><p>Here is a list of some of the tagged datasets on the net:</p><ul><li><a href="https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus?select=ner_dataset.csv"><strong>Annotated Corpus for Named Entity Recognition</strong></a>: dataset
in BILUO Schema containing textual content labeled with geographical, geopolitical, temporal entities, etc ...</li><li><a href="https://www.clips.uantwerpen.be/conll2003/ner/"><strong>CoNLL 2003</strong></a>: dataset in BILUO Scheme containing news articles annotated with (LOC) locality,
ORG (organizations), PER (people) and MISC (miscellaneous).</li><li><a href="http://www.cs.cmu.edu/~enron/"><strong>Enron Email Dataset</strong></a>: more than 500,000 emails tagged with names, dates and time entities.</li><li><a href="https://catalog.ldc.upenn.edu/LDC2013T19"><strong>OntoNotes 5</strong></a>: it is a dataset of news, telephone conversations, blog content tagged with
entities of different kinds.</li></ul><p>At the state of the art there are many tools and libraries that deal with the creation and implementation of tools in the field of
Natural Language Processing. These tools provide both pre-trained templates that are easy to use and quickly integrate into your code, and the
possibility to train new ones with your own data, using predefined modules that simplify the training of new Machine Learning tools. <br>
In the next section we will see how to train custom models on your own data.
Now let's see some easy-to-use tools that provide pre-trained models for recognizing entities in the text.</p><h3 id="spacy">Spacy</h3><figure>
    <span>
      <a href="https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/f7616/spacy-rasa.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/c85cb/spacy-rasa.webp 300w,https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/e88ff/spacy-rasa.webp 600w,https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/3fcdd/spacy-rasa.webp 766w" sizes="(max-width: 766px) 100vw, 766px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/5a46d/spacy-rasa.png 300w,https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/0a47e/spacy-rasa.png 600w,https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/f7616/spacy-rasa.png 766w" sizes="(max-width: 766px) 100vw, 766px" type="image/png">
        <img alt="Figure 6 - Spacy" src="https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/f7616/spacy-rasa.png" title="Figure 6 - Spacy" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 6 - Spacy</figcaption>
  </figure><p>[<strong> Spacy </strong>]<!-- --> (<a href="https://spacy.io/">https://spacy.io/</a>) is a Natural Language Processing framework, which deals with the development and implementation of
Machine Learning techniques for many of the most popular nlp tasks.
Spacy, a completely open source tool, also provides a list of pre-trained models, with support for different languages, through
which can be performed on textual content some natural language processing tasks, such as entity recognition.</p><figure><div><div><pre data-language="bash" data-index="1"><code><span><span># installazione di spacy</span></span>
<span><span>pip install -U spacy</span></span>
<span></span>
<span><span>#download del modello</span></span>
<span><span>python -m spacy download it_core_news_sm</span></span></code></pre><pre data-language="python" data-index="2"><code><span><span># import</span></span>
<span><span>import</span><span> spacy</span></span>
<span><span>​</span></span>
<span><span># loading of choosen model</span></span>
<span><span>nlp = spacy.load(</span><span>"en_core_web_sm"</span><span>)</span></span>
<span></span>
<span><span># running model on text and printing recognized entities</span></span>
<span><span>doc = nlp(</span><span>"Apple is looking at buying U.K. startup for $1 billion"</span><span>)</span></span>
<span><span>​</span><span>for</span><span> ent </span><span>in</span><span> doc.ents:</span></span>
<span><span>    </span><span>print</span><span>(ent.text, ent.start_char, ent.end_char, ent.label_)</span></span></code></pre><figcaption>Source Code 2 - Spacy Named Entity Recognition</figcaption></div></div></figure><p>In these two code snippets we see how to install through <a href="https://pypi.org/project/pip/"><strong>pip</strong></a> in the
your <strong>Python</strong> environment the library and download the chosen model.
Subsequently, with two simple lines of code, you can load the model and run it on textual content.</p><h3 id="stanford-nlp">Stanford NLP</h3><figure>
    <span>
      <a href="https://techblog.smc.it/static/1c1141ed75dbdf0ab8861712a460625a/863e1/stanford-ner.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/1c1141ed75dbdf0ab8861712a460625a/d7e55/stanford-ner.webp 225w" sizes="(max-width: 225px) 100vw, 225px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/1c1141ed75dbdf0ab8861712a460625a/863e1/stanford-ner.jpg 225w" sizes="(max-width: 225px) 100vw, 225px" type="image/jpeg">
        <img alt="Figure 7 - Stanford NLP" src="https://techblog.smc.it/static/1c1141ed75dbdf0ab8861712a460625a/863e1/stanford-ner.jpg" title="Figure 7 - Stanford NLP" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 7 - Stanford NLP</figcaption>
  </figure><p><a href="https://nlp.stanford.edu/"><strong>Stanford NLP</strong></a> is a research group at Stanford University dedicated to NLP and which
has created a <a href="https://nlp.stanford.edu/software/">suite</a> of tools …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techblog.smc.it/en/2020-12-11/nlp-ner">https://techblog.smc.it/en/2020-12-11/nlp-ner</a></em></p>]]>
            </description>
            <link>https://techblog.smc.it/en/2020-12-11/nlp-ner</link>
            <guid isPermaLink="false">hacker-news-small-sites-25391245</guid>
            <pubDate>Fri, 11 Dec 2020 21:27:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Stopped Hating TDD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25391169">thread link</a>) | @thip
<br/>
December 11, 2020 | https://davidcapper.dev/posts/how-i-stopped-hating-tdd | <a href="https://web.archive.org/web/*/https://davidcapper.dev/posts/how-i-stopped-hating-tdd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://davidcapper.dev/assets/gabriel-garcia-marengo-2_F8_vP-_Sg-unsplash.jpg" alt="hourglass">
<em>Photo by <a href="https://unsplash.com/@gabrielgm">Gabriel Garcia Marengo</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>

<p>I didn’t used to enjoy TDD.  I thought I understood it - I’d tell people it was a useful practice and I’d go through all the motions when demonstrating it to them; but when push came to shove I’d quietly drop it as soon as I needed to do anything taxing.</p>

<p>I’ve always felt some embarrassment about this, possibly even guilt. The people I admired and looked up to as developers seemed so adamant that it is the right way to write software. They commanded such respect within the organisations and communities that they worked, and I wanted to be like them; calm, confident and measured , no project too daunting.</p>

<p>Yet, try as I might, I just couldn’t work out what their secret was. Why did they find TDD so enjoyable? Why did I get lost every time I tried to make an honest go of it? Why did I feel like such an imposter?</p>

<p>I think part of the problem was the apparent simplicity of the process. You write test code before you write production code. How hard can it be? It doesn’t help that people who have mastered the practice make it look effortless. The thing is… it’s not effortless. Not to start with anyway. I think the biggest pothole on the road to TDD enlightenment is the idea that you are suddenly going to feel enlightened. Like anything TDD takes practice and experience.</p>

<p>We get better at things little by little, step by step. The premise behind TDD is simple, but its application is nuanced. It’s okay (and normal) for things not to be perfect when you’re just starting out. If you find yourself stuck, don’t get hung up on it. Take a break from TDD and do what you need to do to move on. Writing code that is missing a few tricky tests is much more valuable than having something unfinished that no one gets to use.</p>

<p>It wasn’t until I started to forgive myself for not doing perfect TDD all the time that I started to get better at it. You need to give yourself room to make mistakes and learn what’s easy, and what’s difficult. If you don’t allow yourself to do things sub-optimally and move on, it’s impossible to look back and reflect upon how you might do it differently next time.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://davidcapper.dev/posts/how-i-stopped-hating-tdd</link>
            <guid isPermaLink="false">hacker-news-small-sites-25391169</guid>
            <pubDate>Fri, 11 Dec 2020 21:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Code Resource List]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25390486">thread link</a>) | @richardawoyemi
<br/>
December 11, 2020 | https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef | <a href="https://web.archive.org/web/*/https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef</link>
            <guid isPermaLink="false">hacker-news-small-sites-25390486</guid>
            <pubDate>Fri, 11 Dec 2020 20:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Technical Interviewer's Checklist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25390177">thread link</a>) | @jchen42
<br/>
December 11, 2020 | https://jeffchen.dev/posts/Technical-Interview-Checklist/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Technical-Interview-Checklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><main><article><div><p>I've interviewed hundreds of engineering candidates across multiple companies. With that experience, I've created a checklist to help ensure my technical interviews are effective and empathetic. Read on for the list!</p>
<!-- excerpt -->
<h2 id="before-the-interview">Before the interview</h2>
<ul>
<li>Read their resume and any prep materials you have (cover letter, notes from previous interviews, etc).</li>
<li>If it's a videocall, make sure your mic and webcam work - and turn your camera on!</li>
<li>Respect the candidate by showing up on time.</li>
</ul>
<h2 id="intros">Intros</h2>
<ul>
<li>Introduce yourself and smile when you do!</li>
<li>Ease the candidate in by having them talk about an interesting project they've worked on.
<ul>
<li>It'll help candidates calm their nerves by thinking about something they're already comfortable with.</li>
<li>Always respond positively to what they say!</li>
</ul>
</li>
<li>Set ground rules before diving into the question: Do you need working code? Can they Google things? What languages can they use? What are you looking to get out of the question?</li>
<li>Your interview question should have a clear CTA. After posing your question, candidates should know exactly what their next steps are.</li>
</ul>
<h2 id="the-technical-question">The technical question</h2>
<ul>
<li>Remember what it's like to be on the other side. Interviews are always stressful and scary: be empathetic and do whatever you can to reduce that stress!</li>
<li>Guide candidates through the question. If they're stuck, help them out. You'll get better signal by seeing them approach the whole problem.
<ul>
<li>In particular - help candidates with standard library calls. Having the standard library memorized or not isn't good signal.</li>
</ul>
</li>
<li>Take notes: it's hard to remember what happened in an interview after the fact.</li>
<li>Try to end on a positive note: if we end in the middle of a section, I like to connect where they are with where I wanted them to go.</li>
<li>As you close the question, tie it back back to a real-world problem.</li>
</ul>
<h2 id="closing-out">Closing out</h2>
<ul>
<li>Leave 5-10 minutes for them to ask you questions - and make sure to end on time.</li>
<li>Have answers to common questions prepared. Some common questions:
<ul>
<li>Why did you join Company X?</li>
<li>What's an interesting problem you've worked on at Company X?</li>
<li>What's something you don't like about Company X?</li>
</ul>
</li>
<li>Thank them for their time.</li>
<li>Submit your interview feedback ASAP.</li>
</ul>
</div><strong>Enjoyed this post? <a href="https://www.twitter.com/iambald" target="_blank">Follow me on Twitter</a> for more content like this!</strong><a href="">Scroll to top</a></article></main></div></div></div></div>]]>
            </description>
            <link>https://jeffchen.dev/posts/Technical-Interview-Checklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25390177</guid>
            <pubDate>Fri, 11 Dec 2020 19:59:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IP Monopolies, Not Pirates, Are the Real Threat to Artists]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25389787">thread link</a>) | @panic
<br/>
December 11, 2020 | https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/ | <a href="https://web.archive.org/web/*/https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-postid="3718">
  <div>

    <div>
      <div>

        <div>
          
<p>We’ve all been lied to about piracy. Many of us have been made to believe that online “pirates” rob artists of their livelihood, while Intellectual Property (IP) law exists as a means of protecting the rights of individual creators to make a profit and protect their integrity.&nbsp;</p>



<p>What the rise of tech monopolies in the last decade has shown us is the opposite: IP law mostly serves corporate interests, while anyone who participates in digital public preservation, archiving and sharing is increasingly criminalized as a “pirate.”&nbsp;</p>



<p>The IP legal regime wasn’t created as an idealistic attempt to protect the rights of creators, but rather to grease the wheels for the further expansion of capital. Here’s how IP law has been used to create monopolies, crush the public domain and hurt the artists its proponents say it serves.&nbsp;</p>



<h3><strong>IP Laws And Monopolies</strong></h3>



<p>IP — that is, copyright, trademark, patents and to a lesser extent, trade secrets — didn’t really come into vogue until the latter half of the 19th century, notably in England.&nbsp;</p>



<p>At first, when competition was high, industrialists largely opposed expanded trademark and patent protections. Yet as monopolies and cartels grew, they began to support extra protections on trademarks. This is because, <a href="https://monthlyreview.org/2003/01/01/the-political-economy-of-intellectual-property/">according</a> to Marxist economist Michael Perelman, these companies needed more robust legal frameworks for protecting intangible assets such as brand exclusivity, and patents were also incredibly useful for companies in the United States looking to circumvent the Sherman Antitrust Act.&nbsp;</p>



<p>The term “intellectual property” wasn’t <a href="https://cyber.harvard.edu/people/tfisher/iphistory.pdf">used regularly</a> until the post-Second World War economic decline, when companies that had been opposed to state overreach in the past came to view property rights as a means to increase profits.</p>



<p>In the late 1980s, IP began to be even further expanded, at a dizzyingly rapid pace. Since then, scholars and activists have been warning that this expansion is serving monopoly capital in the growing tech sector.</p>



<p>Central European University sociological researcher Jakob Rigi has <a href="https://www.triple-c.at/index.php/tripleC/article/view/487/667">written</a> about how information itself, especially in the digital age, has nearly zero value because it requires little to no labour cost to reproduce (unlike, say, an iPhone). As a result, it’s nearly impossible to extract profit from information.&nbsp;</p>



<p>So, these tech multinationals are now wielding IP law to extract rents by selling access to, and exclusivity of, information — not by selling the information itself. Trademarks, patents and copyrights are instrumental for monopoly capital because they allow these large companies to extract rents in the form of subscriptions, franchises and licensing fees.&nbsp;</p>



<p>For example, the TRIPS agreement, which brought IP law into multilateral trading, was <a href="https://www.eff.org/issues/trips">ratified</a> in 1994. In 1998, United States President Bill Clinton signed the DMCA into law, which is still being <a href="https://www.highlandernews.org/34672/disney-lobbies-congress-change-copyright-laws/">tweaked</a> to privilege rights holders.</p>



<p>This dynamic has only been heightened in the past decade, with the Stop Online Piracy Act and Protect IP Act being brought to the U.S. House floor in 2011 with the <a href="https://en.wikipedia.org/wiki/List_of_organizations_with_official_stances_on_the_SOPA_and_PIPA#:~:text=The%20Stop%20Online%20Piracy%20Act,unions%20in%20the%20cable%2C%20movie%2C">backing</a> of ISPs and established entertainment industry cartels.</p>



<p>These acts were shelved a year later due to <a href="https://www.theverge.com/2012/1/18/2715300/sopa-blackout-wikipedia-reddit-mozilla-google-protest">vociferous resistance</a> from a huge array of tech companies (including Amazon and Google), which were, at that point, still in a period of high competition. However, now that some of these companies have succeeded in conquering the “Wild West” of the Internet and establishing monopolies, they’ve totally inverted their position.</p>



<h3><strong>IP Laws To Crush The Public Domain</strong></h3>



<p>As time wears on, and IP law is used to criminalize all forms of file-sharing and sampling, it becomes increasingly clear that the focus on “piracy” and illegal file-sharing is only a pretext at wearing down what still exists of the public domain to squeeze it for profit. This is because the companies using IP law in this way need to enclose and privatize what remains of the cultural commons to keep up their rate of profit.&nbsp;</p>



<p>In 2002, University of Gothenburg associate professor Johan Söderberg <a href="https://firstmonday.org/article/view/938/860">pointed out</a> that digital activists were fighting a major corporate tide against what remained of fair use and the Creative Commons. This has continued, and there are numerous examples of companies cracking down in the past decade alone.&nbsp;</p>



<p>In 2013, Reddit co-creator Aaron Swartz took his own life after prosecutors pursued charges against him carrying sentences of up to 35 years in federal prison for illicitly downloading nearly five million academic documents off of JSTOR. This happened even though JSTOR <a href="https://www.rollingstone.com/culture/culture-news/the-brilliant-life-and-tragic-death-of-aaron-swartz-177191/">refused</a> to press charges after Swartz returned the documents he’d downloaded (for reasons unknown, it was actually MIT that let the case go forward).</p>



<p>Then, there’s the ongoing lawsuit to destroy the Internet Archive, brought forward by major publishers such as HarperCollins and Hachette. The suit was in response to the Internet Archive launching the National Emergency Library at the outset of the pandemic, which is a temporary lending program to assist students.&nbsp;</p>



<p>The plaintiffs claim that the Internet Archive “illegally” scans the books it lends, which is not only a deliberate misrepresentation of special exceptions for libraries in the Copyright Act, but, according to The Nation writer Maria Bustillos <a href="https://www.thenation.com/article/society/publishers-are-taking-the-internet-to-court/">betrays</a> a “rentier mentality” that could unravel these protections.</p>



<p>Moreover, in late October, Amazon <a href="https://www.hollywoodreporter.com/thr-esq/amazon-argues-users-dont-actually-own-purchased-prime-video-content">filed</a> to dismiss a complaint from an Prime Video user who claimed the tech giant had engaged in “unfair competition and false advertising” for reserving the right to lock or remove on-demand content after it had been purchased.&nbsp;</p>



<p>Amazon’s motion argues that Prime customers don’t purchase the content they view. Rather, they purchase a “limited license” to consume the content. Already-existing IP law enables Amazon, which in its younger days had opposed SOPA and PIPA, to extend its domain into content streaming via a subscription model.&nbsp;</p>



<p>Shortly after, Twitch — an Amazon subsidiary, <a href="https://www.theinformation.com/articles/amazon-nears-deal-to-acquire-twitch">purchased in 2014</a>— found itself on the receiving end of ire for its handling of a sudden influx of DMCA notices (in all likelihood prompted by a pandemic-related <a href="https://www.weforum.org/agenda/2020/05/this-is-how-covid-19-is-affecting-the-music-industry/">drop</a> in recording industry profits this year.) In an official <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">blog post</a> published on November 11, the live-streaming service magnanimously describes new rules imposed on streamers to comply with copyright claims on background music, including muting in-game music.&nbsp;</p>



<p>These rules and tools were criticized for being haphazard, draconian and confusing, which led Twitch to issue a slight mea culpa before explaining that users can avail themselves of rights-cleared music libraries including Soundtrack, which they just so happen to own.&nbsp;</p>



<p>The consequences of these digital turf battles over licensing between corporate giants inevitably falls on users, while the spoils of profit and ownership go to the monopolies.&nbsp;</p>



<p>The use of IP to enclose information and sell access in exchange for a rent obviously has wide-ranging effects. When all human knowledge is eventually privatized, public archiving, preservation, curation and skill-sharing will be outlawed, and there will be <a href="https://www.i24news.tv/en/news/international/1600882251-zoom-cancels-scheduled-videoconference-with-palestinian-hijacker-leila-khaled">total</a> corporate control of speech rights.&nbsp;</p>



<h3><strong>IP Law Hurting Artists</strong></h3>



<p>Even the recent history of IP law shows that many of us, including artists, have been led astray chasing the windmills of “piracy” while monopolies expand into new frontiers. High profile cases like <a href="https://www.kerrang.com/features/metallica-vs-napster-the-lawsuit-that-redefined-how-we-listen-to-music/">Metallica vs. Napster</a><em> </em>or <a href="https://www.theverge.com/2015/2/14/8039413/megaupload-conviction-felony-nomm-kim-dotcom">Megaupload</a> are instructive, both in terms of the precedents they’ve set and how they’ve helped tech and entertainment companies control the narrative about what’s keeping artists poor.&nbsp;</p>



<p>While it’s reasonable to claim that such third party companies do profit from infringement (unlike the Internet Archive, digital libraries or public domain sites, which rely on work that’s either licensed, out of copyright and otherwise legally obtained), it’s as legitimate to claim that the corporations suing them are just as guilty of theft<strong> </strong>through IP farming, onerous contracts with obscenely low rates and sometimes outright plagiarism.&nbsp;</p>



<p>These monopolies succeeded in part by destroying file-sharing sites and refining and monetizing the streaming model once they were mostly out of the way. Intellectual property rights are as robust as ever, and the rise of music streaming has actually led to a music industry recovery that <a href="https://www.visualcapitalist.com/music-industry-sales/">began</a> in 2017, after about 15 years of decline following the death of the CD thanks to new, untamed digital technology. Yet somehow artists continue to lose both money and control over the work they make.&nbsp;</p>



<p>The recent Union of Musicians and Allied Workers (UMAW) “Justice at Spotify” <a href="https://www.complex.com/music/2020/10/union-of-musicians-and-allied-workers-demands-equity-justice-at-spotify-initiative">campaign</a> demonstrates that the rise of rentier platforms has: lowered the value of creative material to a greater extent than online piracy could ever achieve; made it more difficult for original creators to retain ownership of their work; concentrated the value of this work into fewer hands.&nbsp;</p>



<p>The UMAW <a href="https://www.unionofmusicians.org/justice-at-spotify-demands">list of demands</a> states, “Music workers create all of the enormous wealth Spotify accumulates for its CEO, its investors, and the major labels. But we artists continue to be underpaid, misled, and otherwise exploited by the company.” </p>



<p>UMAW calls for a restructuring of Spotify’s payment model, a 1-cent minimum payout per stream and for Spotify to <a href="https://variety.com/2020/music/news/spotify-amazon-songwriter-royalties-court-appeals-1203528044/">stop fighting artists</a> in court over rate hikes.&nbsp;</p>



<hr>



<p>The obvious answer to the question of monopoly capital and the legal regimes it uses to keep itself in power is usually some form of antitrust policy to break them up and increase competition. But we know from history that the nature of capitalism makes these boon periods temporary, volatile and prone to monopolism regardless of the law.&nbsp;</p>



<p>As writer Gavin Mueller has <a href="https://www.boundary2.org/2018/07/mueller/">noted</a>, the “cyberlibertarian” bent of preserving market competition and even enabling piracy to favour small business is largely “petty producer fantasies” that ignore the capitalist cycles that lead to monopolies in the first …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/">https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/</a></em></p>]]>
            </description>
            <link>https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25389787</guid>
            <pubDate>Fri, 11 Dec 2020 19:34:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$100 robot kit running ROS2 and Navigation2]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25389266">thread link</a>) | @jackp510
<br/>
December 11, 2020 | https://blog.hadabot.com/ros2-nav2-go-to-goal-low-cost-robot-kit.html | <a href="https://web.archive.org/web/*/https://blog.hadabot.com/ros2-nav2-go-to-goal-low-cost-robot-kit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	  <p><a href="https://www.hadabot.com/">Hadabot</a> is a low-cost robot kit for students, software engineers, makers to learn <a href="https://index.ros.org/doc/ros2/">ROS2</a> and robotics in a hands-on manner. Our robot kits are easy to build, extensible, and customizable. The Hadabot software stack consists of an open source web browser-based coding environment to make the hacking experience frustration-free.</p>
<p><a href="https://www.hadabot.com/">Hadabot ROS2 "Turtle" robot kits are available for purchase</a>!</p>
<hr>
<p>In a previous post, we showcased the <a href="https://index.ros.org/doc/ros2/Tutorials/Turtlesim/Introducing-Turtlesim/">ROS 2 turtlesim</a> running with the <a href="https://navigation.ros.org/">Navigation2 (aka Nav2)</a> package. That exercise required the use of the <a href="https://wiki.ros.org/tf2">tf2</a> which manages all <a href="https://blog.hadabot.com/ros2-navigation-tf2-tutorial-using-turtlesim.html#what-is-tf2">the various coordinate frames of a robotics application</a>.</p>
<p>In this post, instead of turtlesim, we'll have Nav2 direct a physical Hadabot Turtle differential drive robot to a goal pose - position and orientation. This exercise will bring together rviz, tf2, Nav2 with our past writeups about the <a href="https://blog.hadabot.com/implement-ros2-odometry-using-vscode-in-web-browser.html">Turtle robot's odometry and kinematics</a>. We'll touch upon:</p>
<ol>
<li>
<p>How we compute odometry for Nav2</p>
</li>
<li>
<p>The Nav2 parameters we tweaked</p>
</li>
</ol>
<div>
  <p><img src="https://blog.hadabot.com/images/hadabot_ros2_nav2_logos.jpg">
  </p>
</div>

<hr>
<h3>1. ROS 2 Nav2 with a Hadabot Turtle robot</h3>
<p>As with all Hadabot examples, you can use the Hadabot stacks browser-based VSCode to compile and run the code.</p>
<p>Follow these steps:</p>
<ol>
<li>
<p>Set up / update your turn-key Hadabot software stack (which leverages Docker containers to ensure your code runs securely and efficiently on your local machine):</p>
<ul>
<li>
<p>If <strong>you are new to Hadabot</strong>, follow these <a href="https://www.hadabot.com/new-user-software-stack-setup.html" target="_blank">steps to set up Docker and get the Hadabot software stack up and running</a> (5 to 15 minutes).</p>
</li>
<li>
<p>Else if you are a <strong>returning Hadabot hacker</strong>, follow these <a href="https://www.hadabot.com/software-stack-update.html" target="_blank">steps to update your Hadabot software stack</a> (1-3 minutes).</p>
</li>
</ul>
</li>
<li>
<p><a href="http://localhost:9123/?folder=/home/hadabot/hadabot_main/content/p9" target="_blank">Launch the browser-based VSCode workspace specific to this post</a> (this link points to your localhost so everything is running securely on your local system).</p>
</li>
<li>
<p>In the left VSCode Explorer panel, right-click the <strong>README.md</strong> file -&gt; Open Preview.</p>
</li>
<li>
<p>Follow the instructions in the README to:</p>
<ul>
<li>
<p>Update your ROS 2 packages</p>
</li>
<li>
<p>Flash the example's ESP32 firmware</p>
</li>
<li>
<p>Compile the Navigation2 Hadabot Turtle robot controller and coordinate frame code.</p>
</li>
<li>
<p>Launch a browser-based VNC client to run the example.</p>
</li>
<li>
<p>Run a go-to-goal Navigation2 Hadabot Turtle example.</p>
</li>
</ul>
</li>
</ol>
<div>
    <div>
        <p>
            <iframe src="https://www.youtube-nocookie.com/embed/goSqLnv6jhE?start=0&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        </p>
    </div>
</div>

<h5>Rviz to visualize the Nav2 go-to-goal Hadabot Turtle example</h5>
<p>If you successfully ran the example, you'll notice that the Turtle starts in the middle of the "arena" (ie map). Each grid-box represents 1 meter in physical distance. The red-axis presents the Turtle pointed forward. Since ROS uses a right-handed coordinate system, positive <span>\(\omega\)</span> rotation results in the Turtle turning counter-clockwise. </p>
<p>For the video example, the goal pose was 1 meter to the Turtle's left, with a 90 degree orientation from its initial orientation. </p>
<p>Notice the Turtle didn't end up exactly 1 meter to its left, nor was it oriented exactly 90 degrees from its initial pose. This is due to 2 reasons due to nothing happening exactly in the real world (this is not a simulation anymore Dorothy) - (1) the Hadabot Turtle's speed sensors have errors which accumulates over time resulting in odometry drift, and (2) Nav2 goal checker allows for a tolerance in both distance and orientation from the specificed end-goal.</p>
<hr>
<h3>2. How we construct TF2 messages from odometry</h3>
<p>The Hadabot Turtle publishes each wheel's rotational velocity in radians per second. With the measured wheelbase and wheel radius of the Turtle, we apply <a href="https://en.wikipedia.org/wiki/Dead_reckoning">dead-reckoning</a> to determine how far each wheel has traveled in meters.</p>
<p>Once we know how far each wheel has traveled for our differential drive model, we can compute the linear distance and angular rotation <span>\((v, \omega)\)</span> for a unicycle model, which allows us to update the current pose and velocities of our Hadabot Turtle as an <a href="http://docs.ros.org/en/melodic/api/nav_msgs/html/msg/Odometry.html">Odometry ROS message</a>. All this is done in the <em>hadabot_controller.cpp</em> file.</p>
<p>Then we use effectively the same code as the turtlesim example to extract the pose information from the Odometry message and publish that out as tf2 messages which is used by Nav2 and rviz.</p>
<hr>
<h3>3. Setting up Nav2 for the Hadabot Turtle</h3>
<p>Nav2 is a complex ROS 2 package with a number of sub-packages / components around 3 main capabilities - localization, planning/controller, and mapping. For our go-to-goal example, we mainly use the planning/controller component.</p>
<p>There are conceptually 2 types of planners in Nav2 - a global planner, and a local planner. The global planner computes a global trajectoy to get to our goal pose. The local planner references the global plan to determine the best linear and angular velocity for the robot to undertake to safely move along the global trajectory. </p>
<p>The global planner (as of 2020-12) defaults to a variation of a <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">A* search</a> based planner. The local planner is called the <a href="https://vimeo.com/236487972">DWB planner, initially created by David Lu back in the ROS 1 days</a>, which implements the <a href="https://en.wikipedia.org/wiki/Dynamic_window_approach">Dynamic Window Approach (DWA) algorithm</a> created by Dieter Fox, Wolfram Burgard, and Sebastian Thrun. The DWB planner is driven by "critics" which vote on various local trajectories to undertake. Each critic "cares" about a certain behavior (ie avoiding abstacles, avoiding oscillation, going fast, etc). The local trajectory with the highest vote wins and that results as the Twist message command to direct the robot's current velocities.</p>
<p>Configuring Nav2 for our go-to-goal example involved tuning the parameters for the planning/controller. The ones we tweaked for the Hadabot Turtle are the max velocities of our robot, and controller update frequency (to update frequently enough but not so much that it floods our "hobbyist" network capabilities). There are many other <a href="https://navigation.ros.org/configuration/index.html">Nav2 parameters we can consider and tune</a>, which can be a series of posts and exercises on its own. </p>
<hr>
<h3>4. Conclusion</h3>
<p>In this post, we did the following:</p>
<ol>
<li>
<p>Showed a example of running a physical real-life Hadabot Turtle robot using ROS 2 Nav2.</p>
</li>
<li>
<p>We described how we use dead-reckoning to compute the Turtle's pose and velocities.</p>
</li>
<li>
<p>We talked a bit about Nav2 and what we tweaked to get our goal-to-goal example to work.</p>
</li>
</ol>
<p>In future posts, we can take this exercise down 2 separate threads - (1) to walk through some of the Nav2 parameters in more detail, start looking closer at Nav2, or (2) to showcase a Hadabot Turtle with a skirt of range-sensors (add-on for the base Turtle kit) to further explore localization and then SLAM with Nav2.</p>
<p>Additionally, we are working with various professors to create a more structured ROS 2 robotics syllabus and curriculum.</p>
<p>Please sign up to stay in touch for more info (as well as any promo offers we will run in the near future)!</p>
<hr>
<p>Thanks again for following along. If you enjoyed the post, there are 2 ways to continue to learn with Hadabot:</p>
<ol>
<li>
<p>Sign up to stay in touch (via the <strong>Stay in Touch</strong> buttons above and below) with future post updates, as well as promos and giveaway opps.</p>
</li>
<li>
<p><a href="https://www.hadabot.com/purchase.html">Purchase a Hadabot Turtle kit</a> to start your robotics adventures!</p>
</li>
</ol>
<p>Thanks and happy building!<br>
Jack "the Hadabot Maker"</p>

	</div>
      </div></div>]]>
            </description>
            <link>https://blog.hadabot.com/ros2-nav2-go-to-goal-low-cost-robot-kit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25389266</guid>
            <pubDate>Fri, 11 Dec 2020 18:56:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales tax creates more unnecessary pain than value added tax]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 150 (<a href="https://news.ycombinator.com/item?id=25389123">thread link</a>) | @dyno-might
<br/>
December 11, 2020 | https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 9, 2020</strong></p>
            
            <p>It turns out that sales tax has a huge, gigantic, terrible flaw: It punishes specialized businesses. A value added tax (VAT) has no such problems.</p>

<p>The US has sales tax. Most of the planet has VAT.</p>

<p><img src="https://dyno-might.github.io/img/vat/VAT_map_updated.png" alt="VAT map"></p>

<p>Maybe it’s not the most important issue in the world, but it’s just so <em>clear</em>. Sales tax is dumb and VAT is better.</p>



<p>Many people apparently believe that in the US today, sales tax is only paid by final consumers. <strong><a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">THIS IS FALSE</a></strong>. It varies hugely by state, but the current situation is a hybrid between a “pure final retail consumer only” sales tax and what the toy model below describes. You can debate if it’s “sales tax” or “gross receipts tax” or whatever, but it’s a fact that <em>businesses pay tax on business inputs</em> all the time. You can find proof of this <a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">here</a> or <a href="https://www.ncsl.org/documents/standcomm/sccomfc/Business-Inputs-Study.pdf">here</a> or <a href="https://www.jstor.org/stable/41788786">here</a> or <a href="https://en.wikipedia.org/wiki/Gross_receipts_tax#United_States">here</a>.</p>

<p>I emphasize that the explanation below is a toy, intended to illustrate in the simplest possible way how specialization gets punished when transfers are taxed in proportion to their values. The current reality not <em>nearly</em> this bad due to many complex exemptions, as I discuss at the end. But the flaw described <em>does</em> exist and <em>does</em> punish specialization. I beg you: <strong><a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">IF YOU THINK THE US DOESN’T HAVE TAXES WHERE THE SAME UNIT OF VALUE IS TAXED MULTIPLE TIMES PLEASE READ THIS LINK.</a></strong></p>

<p>OK, let’s continue.</p>



<p>Say you decide to get into the decorative <a href="https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/(https://dyno-might.github.io/2020/09/11/comparative-advantage-and-when-to-blow-up-your-island/)">coconut</a> manufacturing business.</p>

<p>You’re good at painting coconuts. You find a friend who is good at picking them, and another who’s good at making coconut paint. You find a third friend who’s a genius with applying finishing lacquer and a fourth who runs a store.</p>

<p>You buy coconuts and paint, apply the paint, then sell to the finisher. He applies lacquer and sells to a retailer.</p>

<p><img src="https://dyno-might.github.io/img/vat/supply_chain.jpg" alt="supply chain"></p>

<p>After negotiating prices, you settle on $1 for a raw coconut, $1 for a coconut’s worth of paint, $3 for a painted coconut, $4 for a finished coconut, and $5 retail. This works out to everyone making $1 of profit.</p>

<p><img src="https://dyno-might.github.io/img/vat/market.jpg" alt="market"></p>

<p>Here’s a table showing the accounts:</p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconuts</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2 (raw coconut+paint)</td>
      <td>$1</td>
      <td>$3</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$3 (painted coconut)</td>
      <td>$1</td>
      <td>$4</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$4 (finished coconut)</td>
      <td>$1</td>
      <td>$5</td>
    </tr>
  </tbody>
</table>



<p>For a while, everything runs beautifully. Every day you wake eager to help capture more beauty in coconut form — and then the government announces a 20% sales tax. Whenever you sell something, you need to pay 20% of the sale price to the government.</p>

<p>You talk it over. Everyone feels they still deserve to make the same $1 profit as before. Since you now pay $1.20 for a raw coconut and $1.20 for paint, you need to mark up to $3.40 before tax, and $4.08 after.</p>

<p>After everyone marks up their prices in this way, here are the results:</p>

<p><img src="https://dyno-might.github.io/img/vat/sales_tax.jpg" alt="sales tax"></p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
      <th>Price after tax</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconut</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2.4</td>
      <td>$1</td>
      <td>$3.40</td>
      <td>$4.08</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$4.08</td>
      <td>$1</td>
      <td>$5.08</td>
      <td>$6.10</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$6.10</td>
      <td>$1</td>
      <td>$7.10</td>
      <td>$8.52</td>
    </tr>
  </tbody>
</table>

<p>Your customers aren’t thrilled about the increase in price, but what are they going to do — live <em>without</em> painted coconuts? So they pay the higher price, the government gets its tax, and life continues.</p>



<p>A few months later, your unscrupulous  cousin hears about your business. He’s the jealous type and decides to try stealing your customers. He opens a store and finds four friends to help make coconuts. Unlike you, however, he hires everyone as <em>employees</em>. He sells the coconuts for $6 ($5 plus tax) and gives everyone $1 per coconut in wages.</p>

<p><img src="https://dyno-might.github.io/img/vat/integrated.jpg" alt="integrated"></p>

<p>Your cousin and friends don’t appreciate the subtle art of coconut decoration. Everyone agrees yours are better but they start to complain: Why are you charging $8.52 when a slightly worse product is available for only $6? Slowly, your loyal customers drift away and you go out of business.</p>

<p>How could this happen? Your team was asking for the same profit while doing a better job! Yet everyone is left with your cousin’s knock-off coconuts.</p>



<p>Suppose the government had instead announced a 20% VAT. With a VAT, whenever you sell something, you only pay tax on the sale price <em>minus the price of the stuff you bought to make it</em>.</p>

<p>As before, you’ll need to pay $1.20 for raw coconuts and $1.20 paint. You charge $3.40 for painted coconuts, now you’re only taxed on the profit of $3.40-$2.40=$1.00. The price with tax is now $3.60.</p>

<p>Here are the final prices as they go through through the system. Everyone is making a profit of $1, so everyone pays a tax of $0.20.</p>

<p><img src="https://dyno-might.github.io/img/vat/vat.jpg" alt="vat"></p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
      <th>Price after tax</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconut</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2.4</td>
      <td>$1</td>
      <td>$3.40</td>
      <td>$3.60</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$3.60</td>
      <td>$1</td>
      <td>$4.60</td>
      <td>$4.80</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$4.80</td>
      <td>$1</td>
      <td>$5.80</td>
      <td>$6.00</td>
    </tr>
  </tbody>
</table>

<p>The final price is $6.00. Since your coconuts are better, your cousin won’t be able to drive you out of business with his low-grade stuff.</p>



<p>What happened? Your cousin created a <em>vertically integrated</em> business. A sales tax is collected every time someone buys something. If you just do it yourself, no tax is collected.</p>

<p>Are vertically integrated businesses bad? Not necessarily.</p>

<p>However, take your chain of independent independent artisans making and selling coconut products. Imagine someone invents a paint that customers prefer. You almost <em>have</em> to switch, or some other painter will drive you out of business. Contrast this with cousin’s integrated business making all coconuts. In theory, the inventor could convince your cousin to hire him or license the paint process. If he won’t be convinced, the only way for that paint to get to customers is if the inventor develops an entire independent coconut manufacturing chain. Vertical integration means there are price signals at fewer points during production, which tends to make it harder for innovations to thrive.</p>

<p>There are times where vertical integration is better. (If everyone is independent, a lot of time is spent on negotiations!) That’s perfectly fine. What we <em>don’t</em> want is to artificially encourage vertical integration even when it’s less efficient, which sales tax does.</p>



<p>Another advantage of the VAT is it tends to be easier to enforce. When I sell something, I need to provide certificates proving I paid VAT on my inputs. This gives everyone an incentive to ensure compliance in the previous layer of the chain. With a sales tax, the government needs to watch every single transaction.</p>

<p>Of course, people know sales tax is distortionary. Many exceptions exist to minimize the worst distortions. For example, a retailer usually won’t pay sales tax on a manufactured good they intend to a consumer in the same form. Without this exception, we’d probably have a crazy economy where manufacterers sell directly to consumers. The messy patchwork of exceptions reduces the problems with sales tax but doesn’t eliminate them.</p>

<p>I think there are two major reasons to oppose replacing sales tax with VAT. The first is a Leninist “worse is better” attitude. If you think <em>all taxes are bad</em> then you’d want to keep them painful and visible so people will be maximally annoyed by them. The second is that VAT is complicated to administer, particularly when sales tax can be different in each local area. This might be true, but I find it a bit hard to believe. VAT is more self-enforcing and sales taxes are <em>already</em> a nightmare, particularly for anyone selling to different cities/states. If we’re keeping the sales tax to keep things simple, where’s the payoff?</p>

<p><img src="https://dyno-might.github.io/img/vat/lenin_text_small.png" alt="lenin"></p>

<h3 id="notes">Notes</h3>

<ul>
  <li>The initial map is based on Wikipedia, but found that many places (<a href="https://taxsummaries.pwc.com/thailand/corporate/other-taxes">Thailand</a>, <a href="https://home.kpmg/us/en/home/insights/2020/05/tnf-saudi-arabia-vat-rate-to-increase-to-15-percent-covid-19.html">Saudi Arabia</a>, <a href="https://en.wikipedia.org/wiki/Taxation_in_Iran#Value_added_tax_(VAT)">Iran</a>, <a href="https://www2.deloitte.com/om/en/pages/tax/articles/oman-to-implement-vat-from-2021.html">Oman</a>, <a href="https://u.ae/en/information-and-services/finance-and-investment/taxation/valueaddedtaxvat">UAE</a>, <a href="https://www.reuters.com/article/us-kuwait-economy-tax-idUSKCN1IG0OW">Kuwait</a>, <a href="https://news.bloombergtax.com/daily-tax-report-international/insight-early-days-for-angola-value-added-tax">Angola</a>, <a href="https://www.avalara.com/vatlive/en/vat-news/liberia-to-introduce-vat-2019.html">Liberia</a>) have recently implemented VAT. I checked that most of the others (<a href="https://taxsummaries.pwc.com/jordan/corporate/other-taxes">Jordan</a>, <a href="https://en.wikipedia.org/wiki/Taxation_in_Greenland">Greenland</a>, <a href="https://www.tradecommissioner.gc.ca/france/market-facts-faits-sur-le-marche/7685.aspx?lang=eng#valuetax">French Guinana</a>, <a href="https://www.nordeatrade.com/en/explore-new-market/cuba/taxes">Cuba</a>, <a href="https://taxsummaries.pwc.com/libya/individual/other-taxes">Libya</a>, Hong Hong) still do not have a VAT.</li>
  <li>To be sure, if you could implement a sales tax that only applied to final consumers, that would be economically equivalent to VAT. Is that how state taxes work in the US? It’s hard to make simple generalizations because (1) it’s sometimes hard to say what a “final consumer” is (2) there are different laws in each state and (3) the relevant tax is sometimes called a “gross receipts” tax. The important question is: <strong>Does the US have taxes on intermediate products</strong> that “cascade” like described in the above model? The answer to that question is <a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">YES</a>.</li>
</ul>

        </div>

        

        
        
    </div>
</div></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25389123</guid>
            <pubDate>Fri, 11 Dec 2020 18:45:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No VPN? No problem! Using SSH tunnels for remote access to closed networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25388960">thread link</a>) | @admsg
<br/>
December 11, 2020 | https://adamsgaard.dk/ssh-tunnels.html | <a href="https://web.archive.org/web/*/https://adamsgaard.dk/ssh-tunnels.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>
	
	<p><strong>Last modification on </strong> <time datetime="2020-12-11">2020-12-11</time></p>
</header>

<h2>Rationale</h2>

<p>Corporate and academic networks are closed by design, with routers
and firewalls forwarding and filtering content going to and from
the wider internet.  For security reasons this is an absolute
necessity, as the guardkeeping prevents unwanted incoming connections
to the networked devices.</p>

<p>However, it is often necessary to connect to internal devices or
services from the outside.  This could be the case if an employee
needs to access a shared database on the company network, or a
subscription website only allows full access from a certain range
of IP addresses.  Network administrators usually offer virtual
private network (VPN) access to achieve such goals.  Unfortunately,
VPN access occasionally requires particular software that may not
work on all operating systems.  In other cases, the network
administrators may enforce strict requirements to the remote systems
before allowing VPN access.</p>

<pre><code> ###### Closed Network ######
 #                          #
 #  +----------+      +----------+             +----------+
 #  |  Office  |      | Router/  |      ?      | Outside  |
 #  | Computer |&lt;~~~~&gt;| Firewall |    ?   ?    | Computer |
 #  +----------+      +----------+             +----------+
 #                          #
 ############################
</code></pre>

<p>So what do you do if you need outside access to a network, have no
administrative rights over the router and firewall, and cannot (or
don't want to) access via VPN?  Fortunately, OpenSSH, the widely
used secure shell (SSH) implementation, offers simple and secure
solutions to this problem.  Almost all Linux/BSD/UNIX/MacOS systems
come with OpenSSH preinstalled, so you might already have it on
your system.</p>

<p>If you can access the closed network from the outside via SSH, this
makes things straightforward as described in Scenario 1 below.  If
not, see Scenario 2.</p>


<h2>Scenario 1: SSH access available from the outside</h2>

<p>Some networks are configured to allow outsiders to connect to an
internal SSH server through port forwarding on the network router:</p>

<pre><code> ###### Closed Network ######
 #                          #
 #  +----------+      +----------+      +----------+
 #  |  Office  |  SSH | Router/  |  SSH | Outside  |
 #  | Computer |&lt;~~~~~| Firewall |&lt;~~~~~| Computer |
 #  +----------+      +----------+      +----------+
 #                          #
 ############################
</code></pre>

<p>For the purposes described here, this is an ideal situation since
it is easy to create a tunnel that connects the outside computer
with the internal network via SSH.  The following command creates
the tunnel when executed on the outside computer:</p>

<pre><code>ssh -D 1337 -C -N company-domain.com
</code></pre>

<p>Note that the port number specified with the -D option should be
greater than 1000 when running as an unpriviledged (non-root) user.
The -C option turns on compression, which is useful for slow network
connections at the cost of little CPU overhead.</p>

<p>With the SSH tunnel in place, you can make most webbrowsers and
other network programs on the outside computer use the tunnel for
all their network traffic by pointing them to the SOCKSv5 proxy
"socks://localhost:1337".  This allows access from programs on the
outside computer to any device within the closed network.  Connections
to the wider internet utilizing the tunnel will originate from an
IP address associated with the closed network, achieving the
objectives stated above.</p>


<h2>Scenario 2: SSH access unavailable from the outside</h2>

<p>Unfortunately, outside SSH access to corporate networks is becoming
increasingly rare.  However, the OpenSSH toolset again offers a
solution if you have a persistent SSH server outside of the network
at your disposal:</p>

<pre><code> ###### Closed Network ######
 #                          #
 #  +----------+      +----------+      +---------+      +---------+
 #  |  Office  |  SSH | Router/  |  SSH | Outside |  SSH | Outside |
 #  | Computer |&lt;~~~~&gt;| Firewall |&lt;~~~~&gt;| Server  |&lt;~~~~~| Laptop  |
 #  +----------+      +----------+      +---------+      +---------+
 #                          #
 ############################
</code></pre>

<p>As long as you can initiate *outgoing* SSH connections from inside
the closed network to your outside SSH server, you can create a
reverse ssh tunnel and utilize it in a similar manner as in the
previous scenario.  On the office computer, create a reverse tunnel
to the outside server:</p>

<pre><code>ssh -f -N -R 10022:localhost:22 outside-server.com
</code></pre>

<p>As long as the above command runs, you can initiate new SSH connections
from the outside server to the office computer with the command
`ssh -p 10022 localhost`.  If you're working from an outside laptop,
you can utilize this reverse tunnel to connect to the office computer
and network.  Add the following configuration to `~/.ssh/config`
on the outside laptop:</p>

<pre><code>Host office_computer
    ProxyCommand ssh -q outside-server.com nc localhost 10022
</code></pre>

<p>With the above configuration, it is very easy to establish a SSH
connection from the outside laptop to the office computer:</p>

<pre><code>ssh office_computer
</code></pre>

<p>As in the previous example, you can use this setup to create a SSH
tunnel all the way from the outside laptop to the office computer:</p>

<pre><code>ssh -D 1337 -C -N office_computer
</code></pre>

<p>Again, this creates a SOCKSv5 proxy that you can use for tunneling
network traffic from the outside laptop to the closed network.  It
is useful to automatically monitor the tunnel status using pgrep(1),
and reinitialize it if the ssh command unexpectedly quits.</p>


<h2>References</h2>

<ul>
<li>OpenSSH: <a href="https://www.openssh.com/">https://www.openssh.com/</a></li>
<li>ssh(1) manual page: <a href="https://man.openbsd.org/ssh">https://man.openbsd.org/ssh</a></li>
<li>gramscii(1), used for drawings in this post: git://bitreich.org/gramscii</li>
</ul>

<p>Thanks to KatolaZ for feedback on this post.</p>

			</article></div>]]>
            </description>
            <link>https://adamsgaard.dk/ssh-tunnels.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388960</guid>
            <pubDate>Fri, 11 Dec 2020 18:31:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Obscure Government Agency Changing VC Investing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25388867">thread link</a>) | @donnyNz
<br/>
December 11, 2020 | https://contrarycap.com/content/cfius | <a href="https://web.archive.org/web/*/https://contrarycap.com/content/cfius">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><hr>
<p>When Chinese tech giant ByteDance acquired LA-based <a href="http://musical.ly/">Musical.ly</a> in 2019 to create TikTok, they didn't think the U.S. federal government would even note the transaction.</p>
<p>Then, an obscure group of Treasury Department regulators wrote a report.</p>
<p>Fast-forward to today: <a href="https://www.cnn.com/2020/11/11/tech/tiktok-deadline-trump-november/index.html">TikTok is sitting in legal purgatory</a>, under pressure from the White House, as companies like Oracle and Microsoft attempt to carve off pieces of it from ByteDance. Should the sale fall apart, there's a real possibility the Department of Justice will sue ByteDance to force a divestment.</p>
<p>The TikTok saga is the tip of the iceberg. As recently as 2017, Chinese venture investors were breaking records, putting in billions of dollars across hundreds of deals in U.S. based startups. By 2019, those numbers had fallen by about half, as this graph from Preqin shows.</p>
<p><img src="https://contrarycap.com/images/content/cfius-graph.png" alt="/images/content/cfius-graph.png"></p>
<p>Simultaneously, regulators <a href="https://www.reuters.com/article/us-grindr-m-a-beijingkunlun/chinas-kunlun-tech-agrees-to-u-s-demand-to-sell-grindr-gay-dating-app-idUSKCN1SJ28N">forced the divestment of Grindr</a> and <a href="https://www.stayntouch.com/news/stayntouch-remains-committed-to-customers-and-growth-after-trump-administrations-order">StayNTouch</a>, and blocked a $1.2B deal between Moneygram and Ant Financial.</p>
<p>What happened? <a href="https://www.lawfareblog.com/foreign-investment-risk-review-modernization-act-2018">FIRRMA happened</a>.</p>
<p>This law, passed in August 2018, gave significant new powers to a traditionally toothless Treasury agency, and turned it into one of the most important players in the tech world. We're talking about <strong>the Committee on Foreign Investment in the U.S., or CFIUS.</strong></p>
<p>Almost immediately after Congress beefed up CFIUS, there were reports of previously solid deals that began falling apart as VCs and entrepreneurs became cold on working with foreign sources of capital.</p>
<p>Their new reluctance was well-founded. CFIUS 2.0 has created a lot of risk for entrepreneurs and investors that work with foreign-based capital. This post is a guide on when CFIUS comes into play, and a breakdown of how this Treasury agency has changed venture investing in the last two years.</p>
<h2><a name="its-the-critical-technology"></a>It's the Critical Technology</h2>
<p>The Foreign Investment Risk Review Modernization Act (FIRRMA) didn't get a lot of press coverage when President Trump signed it into law in August 2018, but it made CFIUS powerful.</p>
<p>It expanded their jurisdiction to cover a much larger spread of investments made by foreigners — defined as people who aren't citizens or legal residents of the U.S. — compared to before. Previously, CFIUS review was almost always voluntary, and the agency only reviewed deals where a foreign investor would take a majority stake in a company. FIRRMA gave CFIUS the ability to evaluate any investment in a private company, <em>even a minority stake</em>, so long as all one or more of these triggers apply:</p>
<ul>
<li>The business receiving investment "owns, operates, manufactures, fabricates, or services critical infrastructure"</li>
<li>If the company works with a "critical technology" (this includes 27 broad categories, like artificial intelligence, autonomous mobility, battery technology, Fintech, VR, and cybersecurity)</li>
<li>If the company maintains or collects exploitable, sensitive personal data of U.S. citizens.
<ul>
<li>Grindr's sale to a Chinese company in 2016 prompted this, and in March 2019, CFIUS ordered Kunlun Tech to divest Grindr over expected concerns about access to personal data. That's right - CFIUS can launch an investigation and force divestment any time.</li>
</ul></li>
</ul>
<p>If CFIUS identifies a security risk, the White House can block a deal or force a divestment. <a href="https://www.hklaw.com/en/insights/publications/2020/02/new-cfius-regulations-finally-take-effect">This article</a> from the law firm Holland and Knight gives a deeper dive on the regulations and covers some of the nuances, like the <a href="https://www.lexology.com/library/detail.aspx?g=bc12e415-9a3f-4f66-a14a-5006c91a8005">exempted countries</a>.</p>
<p>CFIUS has had a significant impact in early-stage investing, because lot of VC deals fall the agency's broad definition of critical technology.</p>
<p>If you're an entrepreneur working in their critical technology space, and you try to take on foreign funding, what happens?</p>
<p>Before 2018, nothing. Now, both parties (the company and the investors) are legally obligated to apply for review by CFIUS. They give out big fines for failing to apply, and they work with the FBI to monitor for deals that tried to sneak through without review. They reject any applications where the investment would pose a "national security risk" - which puts Chinese-based investments under high scrutiny given geopolitical tensions.</p>
<p>This might not sound too onerous, and CFIUS reportedly approves a fair percentage of applicants. The issue is time - CFIUS reviews can take up to 90 days. Entrepreneurs that are raising need a fast yes/no from investors, and many haven't been willing to submit to the delays and scrutiny that come with taking foreign capital. Investors are also advising their companies to hunt for capital elsewhere, instead of from a foreign source that might lead to a CFIUS review or a block.</p>
<p>Now, there is a caveat here. CFIUS only comes into play in a non-controlling investment if the foreign investor gains access to "material nonpublic technical information", or "has substantive involvement in the U.S. business's decision-making with respect to the technology, infrastructure, or data."</p>
<p>This leaves room for a lot of exemptions. For example, a VC firm with American general partners could have all foreign-based LPs, and as long as those LPs were kept in the dark on their portfolio companies (and you can bet the FBI will monitor that) the firm would be in the clear. A "silent money" investor, who gives capital but has no real involvement in the business, would also be safe. But, most founders want more from their investors than capital, and most investors aren't going to make a deal where a single update email could lead to regulatory scrutiny.</p>
<p>So while there are potential workarounds, the broad definition of "critical technology" and the long review process is chilling certain foreign investment in U.S. startups.</p>
<h2><a name="cfius-makes-their-mark"></a>CFIUS Makes Their Mark</h2>
<p>Let's not overstate it. Despite CFIUS, billions in foreign capital is still flowing through the U.S. startup ecosystem. They try to approve most applications within a month, and the committee has reviewed then approved hundreds, if not thousands, of deals.</p>
<p>At the same time, a lot less deals are being made by Chinese-based investors compared to before. U.S. investors and entrepreneurs aren't accepting their money with such ease, and prospective Chinese investors are deciding the headache just isn't worth it. Given how broad the "critical technology" category is, too many of their deals are required to file the application. For example, Alibaba, which has invested billions in U.S. based startups since 2013, <a href="https://www.ft.com/content/9f2aaea0-4ae2-11ea-95a0-43d18ec715f5">made no publicly disclosed investments in the U.S.</a> in 2019. In fact, publicly disclosed investments in US start-ups by Baidu, Alibaba and Tencent fell 84 per cent from 2018, according to an analysis by PitchBook. A number of Chinese VC firms, like <a href="https://www.cnbc.com/2019/05/14/kai-fu-lee-sinovation-ventures-retreats-from-us-amid-trade-dispute.html">Sinovation Ventures</a>, have completely stopped making U.S. investments.</p>
<p>Why have Chinese investors been especially hard hit? It's because CFIUS makes a final decision on whether or not to approve a deal based on national security risk. Current political tensions, the Chinese Communist Party's deep involvement in "private" Chinese companies/investors, and the Communist Party's publicly-admitted habit of IP theft, puts investments stemming from China in a high risk category, according to the federal government.</p>
<p>Post-FIRRMA, the environment has changed so much that Chinese investors are willingly opting out of the U.S. market. Their logic is that successful entrepreneurs running hot startups have plenty of options for financing that won't trigger a review by the U.S. government, so a China-based VC firm is unlikely to get in to the best deals, anyway.</p>
<p>Theodore Schleifer has a <a href="https://www.vox.com/recode/2019/5/1/18511540/silicon-valley-foreign-money-china-saudi-arabia-cfius-firrma-geopolitics-venture-capital">solid piece in Recode on foreign cash in Silicon Valley</a>, and collected some interesting words from VCs on how they are cautioning their portfolio companies:</p>
<p>One venture capitalist active in financing companies in frontier technologies said he now assumed that his portfolio companies could never raise money from foreign investors from now on. A second said his firm recommended to a CEO that going through CFIUS review in order to take Chinese capital was not worth the headache. Schleifer writes that "Some in Silicon Valley have even undertaken projects to identify all venture firms primarily backed by the Chinese government — crafting their own private investor blacklists."</p>
<p>These investors are playing it safe for good reason. Ultimately, the new CFIUS, combined with <a href="https://www.washingtonpost.com/opinions/2020/07/14/tensions-with-china-are-rising-whats-next-step/">rising U.S.-China</a> tension, has made it riskier and much more burdensome for entrepreneurs to work with foreign investors. It's also made it riskier for VCs to take on foreign LPs, unless said LPs are truly passive and kept almost completely in the dark on how their portfolio companies are performing. The years of CFIUS flying under the radar have come to an end, and they're going to be a big player in the tech world for decades to come.</p>
</div></div></div>]]>
            </description>
            <link>https://contrarycap.com/content/cfius</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388867</guid>
            <pubDate>Fri, 11 Dec 2020 18:22:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Complexity Zoo” has moved]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25388790">thread link</a>) | @furcyd
<br/>
December 11, 2020 | https://complexityzoo.net/Complexity_Zoo | <a href="https://web.archive.org/web/*/https://complexityzoo.net/Complexity_Zoo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><div>
<h2><span id="Introduction">Introduction</span></h2>
<p>Welcome to the <b>Complexity Zoo</b>... There are now 545 classes and counting!
</p>
<div><div><p><a href="https://complexityzoo.net/File:Zoo.gif"><img alt="" src="https://complexityzoo.net/images/f/f6/Zoo.gif" decoding="async" width="200" height="100"></a></p></div></div>
<p><i>Complexity classes by letter:</i>
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols" title="Complexity Zoo:Symbols">Symbols</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A" title="Complexity Zoo:A">A</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B" title="Complexity Zoo:B">B</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C" title="Complexity Zoo:C">C</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D" title="Complexity Zoo:D">D</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E" title="Complexity Zoo:E">E</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F" title="Complexity Zoo:F">F</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G" title="Complexity Zoo:G">G</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H" title="Complexity Zoo:H">H</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I" title="Complexity Zoo:I">I</a> -
<a href="https://complexityzoo.net/index.php?title=Complexity_Zoo:J&amp;action=edit&amp;redlink=1" title="Complexity Zoo:J (page does not exist)">J</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:K" title="Complexity Zoo:K">K</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L" title="Complexity Zoo:L">L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M" title="Complexity Zoo:M">M</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N" title="Complexity Zoo:N">N</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:O" title="Complexity Zoo:O">O</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P" title="Complexity Zoo:P">P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q" title="Complexity Zoo:Q">Q</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R" title="Complexity Zoo:R">R</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S" title="Complexity Zoo:S">S</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T" title="Complexity Zoo:T">T</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U" title="Complexity Zoo:U">U</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V" title="Complexity Zoo:V">V</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W" title="Complexity Zoo:W">W</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X" title="Complexity Zoo:X">X</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y" title="Complexity Zoo:Y">Y</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z" title="Complexity Zoo:Z">Z</a>
</p><p><i>Lists of related classes:</i>
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Communication_Complexity_Classes" title="Complexity Zoo:List of Communication Complexity Classes">Communication Complexity</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Hierarchies" title="Complexity Zoo:List of Hierarchies">Hierarchies</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Nonuniform_Classes" title="Complexity Zoo:List of Nonuniform Classes">Nonuniform</a>
</p>
<dl><dt>Zookeeper</dt>
<dd><a rel="nofollow" href="http://www.scottaaronson.com/">Scott Aaronson</a></dd>
<dt>Veterinarian</dt>
<dd><a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/">Greg Kuperberg</a></dd>
<dt>Zoo Conservationist</dt>
<dd><a rel="nofollow" href="https://www.linkedin.com/in/oliver-habryka-8a585297">Oliver Habryka</a> on behalf of the <a rel="nofollow" href="https://www.lesswrong.com/">LessWrong</a> community</dd></dl>
<p>The Zoo first opened in 2002.  It was made into a wiki in 2005, and hosted at the University of Waterloo from 2012 to 2020.
</p><p>Errors?  Omissions?  Misattributions?  Your favorite class not here?  Then please contribute to the zoo as you see fit by <a href="https://complexityzoo.net/Special:UserLogin" title="Special:UserLogin"> signing up</a> and clicking on the edit links.  Please include references, or better yet links to papers if available.
</p><p>To create a new class, click on the edit link of the class before or after the one that you want to add and copy the format of that class.  (The classes are alphabetized by their tag names.)  Then add the class to the table of contents and increment the total number of classes.  After this, you can use the side edit links to edit the individual sections. For more on using the wiki language, see our <a href="https://complexityzoo.net/index.php?title=Help:Contents&amp;action=edit&amp;redlink=1" title="Help:Contents (page does not exist)"> simple wiki help page</a>.
</p><p>If you would like to contribute but feel unable to make the updates yourself, email the zookeeper at scott at scottaaronson.com.
</p>
<h2><span id="See_Also">See Also</span></h2>
<p><i>Introductory Resources</i>
</p>
<ul><li><a href="https://complexityzoo.net/Zoo_Intro" title="Zoo Intro">Introductory Essay</a>: New visitors may want to stop here and see what the Zoo is all about.</li>
<li><a href="https://complexityzoo.net/Petting_Zoo" title="Petting Zoo">Petting Zoo</a>: A more gentle version of the Zoo with fewer classes, meant for new initiates in complexity. (If you're looking for where the Most Important Classes went, look in the Petting Zoo.)</li></ul>
<p><i>Other Collections and Resources</i>
</p>
<ul><li><a href="https://complexityzoo.net/Complexity_Garden" title="Complexity Garden">Complexity Garden</a>: Problems of interest in complexity theory and some notes about important inclusions.</li>
<li><a href="https://complexityzoo.net/Complexity_Dojo" title="Complexity Dojo">Complexity Dojo</a>: A collection of major theorems in complexity theory.</li>
<li><a href="https://complexityzoo.net/Zoo_Exhibit" title="Zoo Exhibit">Special Exhibit</a>: A collection of classes of quantum states and probability distributions.</li>
<li><a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/zoology/intro.html">Complexity Zoology</a>: A computer-assisted survey maintained by the <a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/">Greg Kuperberg</a>, including <a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/zoology/diagram.xml">active</a> and <a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/zoology/diagram.pdf">static</a> inclusion diagrams.</li>
<li><a rel="nofollow" href="http://satoshihada.wordpress.com/complexity-zoo-for-ipad/">Complexity Zoo for iPad (and iPhone)</a>: An iOS viewer for Complexity Zoo.</li></ul>
<p><i>Appendices</i>
</p>
<ul><li><a href="https://complexityzoo.net/Zoo_Glossary" title="Zoo Glossary">Glossary</a>: Definitions of some complexity theoretic terms.</li>
<li><a href="https://complexityzoo.net/Zoo_References" title="Zoo References">References</a>: Bibliography for the Zoo.</li>
<li><a href="https://complexityzoo.net/Zoo_Pronunciation" title="Zoo Pronunciation">Pronunciation Guide</a>: A resource for those who insist on communicating verbally about complexity.</li>
<li><a href="https://complexityzoo.net/index.php?title=Zoo_Conventions&amp;action=edit&amp;redlink=1" title="Zoo Conventions (page does not exist)">Conventions and Notation</a>: Common notational conventions used here at the Zoo.</li>
<li><a href="https://complexityzoo.net/index.php?title=Zoo_Operators&amp;action=edit&amp;redlink=1" title="Zoo Operators (page does not exist)">Operators</a>: A (very short) list of operators which act upon classes.</li>
<li><a href="https://complexityzoo.net/Zoo_Acknowledgments" title="Zoo Acknowledgments">Acknowledgments</a>: Where the Zookeeper and friends acknowledge those who have helped out with the Zoo.</li>
<li><a href="https://complexityzoo.net/index.php?title=Meta:Complexity_Zoo_Contributor%27s_Guide&amp;action=edit&amp;redlink=1" title="Meta:Complexity Zoo Contributor's Guide (page does not exist)">Complexity Zoo Contributor's Guide</a>: A guide on how to get started helping out with the Zoo.</li></ul>
<p><i>NB:</i> Longtime Zoo watchers may recall Chris Bourke's LaTeX version of the Zoo and Chad Brewbaker's graphical inclusion diagram.  These references are obsolete until further notice.
</p>
<h2><span id="All_Classes">All Classes</span></h2>
<p><i>Complexity classes by letter:</i>
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols" title="Complexity Zoo:Symbols">Symbols</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A" title="Complexity Zoo:A">A</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B" title="Complexity Zoo:B">B</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C" title="Complexity Zoo:C">C</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D" title="Complexity Zoo:D">D</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E" title="Complexity Zoo:E">E</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F" title="Complexity Zoo:F">F</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G" title="Complexity Zoo:G">G</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H" title="Complexity Zoo:H">H</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I" title="Complexity Zoo:I">I</a> -
<a href="https://complexityzoo.net/index.php?title=Complexity_Zoo:J&amp;action=edit&amp;redlink=1" title="Complexity Zoo:J (page does not exist)">J</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:K" title="Complexity Zoo:K">K</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L" title="Complexity Zoo:L">L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M" title="Complexity Zoo:M">M</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N" title="Complexity Zoo:N">N</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:O" title="Complexity Zoo:O">O</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P" title="Complexity Zoo:P">P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q" title="Complexity Zoo:Q">Q</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R" title="Complexity Zoo:R">R</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S" title="Complexity Zoo:S">S</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T" title="Complexity Zoo:T">T</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U" title="Complexity Zoo:U">U</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V" title="Complexity Zoo:V">V</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W" title="Complexity Zoo:W">W</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X" title="Complexity Zoo:X">X</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y" title="Complexity Zoo:Y">Y</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z" title="Complexity Zoo:Z">Z</a>
</p><p><i>Lists of related classes:</i>
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Communication_Complexity_Classes" title="Complexity Zoo:List of Communication Complexity Classes">Communication Complexity</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Hierarchies" title="Complexity Zoo:List of Hierarchies">Hierarchies</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Nonuniform_Classes" title="Complexity Zoo:List of Nonuniform Classes">Nonuniform</a>
</p>
<h3><span id="Symbols">Symbols</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:Symbols#01npc" title="Complexity Zoo:Symbols">0-1-NP<sub>C</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#1nauxpdap" title="Complexity Zoo:Symbols">1NAuxPDA<sup>p</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#2exp" title="Complexity Zoo:Symbols">2-EXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#3sumhard" title="Complexity Zoo:Symbols">3SUM-hard</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpac0" title="Complexity Zoo:Symbols">#AC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpl" title="Complexity Zoo:Symbols">#L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharplpoly" title="Complexity Zoo:Symbols">#L/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpga" title="Complexity Zoo:Symbols">#GA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpp" title="Complexity Zoo:Symbols">#P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpwt" title="Complexity Zoo:Symbols">#W[t]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#parityexp" title="Complexity Zoo:Symbols">⊕EXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#parityl" title="Complexity Zoo:Symbols">⊕L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#paritylpoly" title="Complexity Zoo:Symbols">⊕L/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#parityp" title="Complexity Zoo:Symbols">⊕P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#paritypcc" title="Complexity Zoo:Symbols">⊕P<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#paritysac0" title="Complexity Zoo:Symbols">⊕SAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#paritysac1" title="Complexity Zoo:Symbols">⊕SAC<sup>1</sup></a>
</p>
<h3><span id="A">A</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:A#a0pp" title="Complexity Zoo:A">A<sub>0</sub>PP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ac" title="Complexity Zoo:A">AC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ac0" title="Complexity Zoo:A">AC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ac0m" title="Complexity Zoo:A">AC<sup>0</sup>[m]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ac1" title="Complexity Zoo:A">AC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#acc0" title="Complexity Zoo:A">ACC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ah" title="Complexity Zoo:A">AH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#al" title="Complexity Zoo:A">AL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#all" title="Complexity Zoo:A">ALL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#alogtime" title="Complexity Zoo:A">ALOGTIME</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#algppoly" title="Complexity Zoo:A">AlgP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#almostnp" title="Complexity Zoo:A">Almost-NP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#almostp" title="Complexity Zoo:A">Almost-P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#almostpspace" title="Complexity Zoo:A">Almost-PSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#am" title="Complexity Zoo:A">AM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#amcc" title="Complexity Zoo:A">AM<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#amexp" title="Complexity Zoo:A">AM<sub>EXP</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#amicoam" title="Complexity Zoo:A">AM ∩ coAM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ampolylog" title="Complexity Zoo:A">AM[polylog]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ampmp" title="Complexity Zoo:A">AmpMP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#amppbqp" title="Complexity Zoo:A">AmpP-BQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ap" title="Complexity Zoo:A">AP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#app" title="Complexity Zoo:A">APP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#apspace" title="Complexity Zoo:A">APSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#apx" title="Complexity Zoo:A">APX</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#aspace" title="Complexity Zoo:A">ASPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#atime" title="Complexity Zoo:A">ATIME</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#aucspace" title="Complexity Zoo:A">AUC-SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#auxpda" title="Complexity Zoo:A">AuxPDA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#avbpp" title="Complexity Zoo:A">AVBPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#avge" title="Complexity Zoo:A">AvgE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#avgp" title="Complexity Zoo:A">AvgP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awp" title="Complexity Zoo:A">AW[P]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awpp" title="Complexity Zoo:A">AWPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awsat" title="Complexity Zoo:A">AW[SAT]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awstar" title="Complexity Zoo:A">AW[*]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awt" title="Complexity Zoo:A">AW[t]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#axp" title="Complexity Zoo:A">AxP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#axpp" title="Complexity Zoo:A">AxPP</a>
</p>
<h3><span id="B">B</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:B#betap" title="Complexity Zoo:B">βP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bcequalsp" title="Complexity Zoo:B">BC<sub>=</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bh" title="Complexity Zoo:B">BH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpdp" title="Complexity Zoo:B">BP<sub>d</sub>(P)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpe" title="Complexity Zoo:B">BPE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpee" title="Complexity Zoo:B">BPEE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bphspace" title="Complexity Zoo:B">BP<sub>H</sub>SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpl" title="Complexity Zoo:B">BPL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpnp" title="Complexity Zoo:B">BP&amp;#149;NP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpp" title="Complexity Zoo:B">BPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppcc" title="Complexity Zoo:B">BPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppkcc" title="Complexity Zoo:B">BPP<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" aria-hidden="true" alt="{\displaystyle k}"></span></sub><sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppkt" title="Complexity Zoo:B">BPP<sup>KT</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpplog" title="Complexity Zoo:B">BPP/log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppmlog" title="Complexity Zoo:B">BPP/mlog</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppsslog" title="Complexity Zoo:B">BPP//log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpprlog" title="Complexity Zoo:B">BPP/rlog</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppobdd" title="Complexity Zoo:B">BPP-OBDD</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpppath" title="Complexity Zoo:B">BPP<sub>path</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpqp" title="Complexity Zoo:B">BPQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpspace" title="Complexity Zoo:B">BPSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bptime" title="Complexity Zoo:B">BPTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqnc" title="Complexity Zoo:B">BQNC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqnp" title="Complexity Zoo:B">BQNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqp" title="Complexity Zoo:B">BQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqplog" title="Complexity Zoo:B">BQP/log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqppoly" title="Complexity Zoo:B">BQP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpmlog" title="Complexity Zoo:B">BQP/mlog</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpmpoly" title="Complexity Zoo:B">BQP/mpoly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpqlog" title="Complexity Zoo:B">BQP/qlog</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpqpoly" title="Complexity Zoo:B">BQP/qpoly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpobdd" title="Complexity Zoo:B">BQP-OBDD</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpspace" title="Complexity Zoo:B">BQPSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpctc" title="Complexity Zoo:B">BQP<sub>CTC</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpttpoly" title="Complexity Zoo:B">BQP<sub>tt</sub>/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqtime" title="Complexity Zoo:B">BQTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bwbp" title="Complexity Zoo:B">k-BWBP</a>
</p>
<h3><span id="C">C</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:C#cequalsac0" title="Complexity Zoo:C">C<sub>=</sub>AC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cequalsl" title="Complexity Zoo:C">C<sub>=</sub>L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cequalsp" title="Complexity Zoo:C">C<sub>=</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cc" title="Complexity Zoo:C">CC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cc0" title="Complexity Zoo:C">CC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cfl" title="Complexity Zoo:C">CFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#clog" title="Complexity Zoo:C">CLOG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#ch" title="Complexity Zoo:C">CH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#check" title="Complexity Zoo:C">Check</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#clsharpp" title="Complexity Zoo:C">CL#P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#ckp" title="Complexity Zoo:C">C<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cnp" title="Complexity Zoo:C">CNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coam" title="Complexity Zoo:C">coAM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cocequalsp" title="Complexity Zoo:C">coC<sub>=</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cofrip" title="Complexity Zoo:C">cofrIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coh" title="Complexity Zoo:C">Coh</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coma" title="Complexity Zoo:C">coMA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#comodkp" title="Complexity Zoo:C">coMod<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#compip" title="Complexity Zoo:C">compIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#compnp" title="Complexity Zoo:C">compNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cone" title="Complexity Zoo:C">coNE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conexp" title="Complexity Zoo:C">coNEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conl" title="Complexity Zoo:C">coNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conp" title="Complexity Zoo:C">coNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conpcc" title="Complexity Zoo:C">coNP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conppoly" title="Complexity Zoo:C">coNP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conqp" title="Complexity Zoo:C">coNQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#core" title="Complexity Zoo:C">coRE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cornc" title="Complexity Zoo:C">coRNC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#corp" title="Complexity Zoo:C">coRP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cosl" title="Complexity Zoo:C">coSL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cosparse" title="Complexity Zoo:C">coSPARSE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coucc" title="Complexity Zoo:C">coUCC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coup" title="Complexity Zoo:C">coUP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cp" title="Complexity Zoo:C">CP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cqsigma2" title="Complexity Zoo:C">cq-Σ<sub>2</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#csize" title="Complexity Zoo:C">CSIZE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#csl" title="Complexity Zoo:C">CSL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#csp" title="Complexity Zoo:C">CSP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#czk" title="Complexity Zoo:C">CZK</a>
</p>
<h3><span id="D">D</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:D#dsharpp" title="Complexity Zoo:D">D#P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dcfl" title="Complexity Zoo:D">DCFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#delta2p" title="Complexity Zoo:D">Δ<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#deltabpp" title="Complexity Zoo:D">δ-BPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#deltarp" title="Complexity Zoo:D">δ-RP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#det" title="Complexity Zoo:D">DET</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#diffac0" title="Complexity Zoo:D">DiffAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#disnp" title="Complexity Zoo:D">DisNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#distnp" title="Complexity Zoo:D">DistNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dp" title="Complexity Zoo:D">DP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dqc1" title="Complexity Zoo:D">DQC1</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dqp" title="Complexity Zoo:D">DQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dspace" title="Complexity Zoo:D">DSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dtime" title="Complexity Zoo:D">DTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dtisp" title="Complexity Zoo:D">DTISP(t(n),s(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dynfo" title="Complexity Zoo:D">Dyn-FO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dynthc0" title="Complexity Zoo:D">Dyn-ThC<sup>0</sup></a>
</p>
<h3><span id="E">E</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:E#e" title="Complexity Zoo:E">E</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#ee" title="Complexity Zoo:E">EE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eee" title="Complexity Zoo:E">EEE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eespace" title="Complexity Zoo:E">EESPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eexp" title="Complexity Zoo:E">EEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eh" title="Complexity Zoo:E">EH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#elementary" title="Complexity Zoo:E">ELEMENTARY</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#elkp" title="Complexity Zoo:E">EL<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#ep" title="Complexity Zoo:E">EP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eptas" title="Complexity Zoo:E">EPTAS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eqbp" title="Complexity Zoo:E">k-EQBP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eqp" title="Complexity Zoo:E">EQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eqpk" title="Complexity Zoo:E">EQP<sub>K</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eqtime" title="Complexity Zoo:E">EQTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#espace" title="Complexity Zoo:E">ESPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#existsbpp" title="Complexity Zoo:E">∃BPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#existsniszk" title="Complexity Zoo:E">∃NISZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#exp" title="Complexity Zoo:E">EXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#exppoly" title="Complexity Zoo:E">EXP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#expspace" title="Complexity Zoo:E">EXPSPACE</a>
</p>
<h3><span id="F">F</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:F#fbqp" title="Complexity Zoo:F">FBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fert" title="Complexity Zoo:F">FERT</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpert" title="Complexity Zoo:F">FPERT</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#few" title="Complexity Zoo:F">Few</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fewexp" title="Complexity Zoo:F">FewEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fewp" title="Complexity Zoo:F">FewP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fh" title="Complexity Zoo:F">FH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fixp" title="Complexity Zoo:F">FIXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fnl" title="Complexity Zoo:F">FNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fnlpoly" title="Complexity Zoo:F">FNL/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fnp" title="Complexity Zoo:F">FNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fo" title="Complexity Zoo:F">FO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fodtc" title="Complexity Zoo:F">FO(DTC)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#folfp" title="Complexity Zoo:F">FO(LFP)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fopfp" title="Complexity Zoo:F">FO(PFP)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fotc" title="Complexity Zoo:F">FO(TC)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fot" title="Complexity Zoo:F">FO(<span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/70b64a27c4f55221162f329285382cc470e3827e" aria-hidden="true" alt="{\displaystyle t(n)}"></span>)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#foll" title="Complexity Zoo:F">FOLL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fp" title="Complexity Zoo:F">FP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpnplog" title="Complexity Zoo:F">FP<sup>NP[log]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpl" title="Complexity Zoo:F">FPL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpr" title="Complexity Zoo:F">FPR</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpras" title="Complexity Zoo:F">FPRAS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpt" title="Complexity Zoo:F">FPT</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fptnu" title="Complexity Zoo:F">FPT<sub>nu</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fptsu" title="Complexity Zoo:F">FPT<sub>su</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fptas" title="Complexity Zoo:F">FPTAS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fqma" title="Complexity Zoo:F">FQMA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#frip" title="Complexity Zoo:F">frIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#ftape" title="Complexity Zoo:F">F-TAPE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#ftime" title="Complexity Zoo:F">F-TIME(f(n))</a>
</p>
<h3><span id="G">G</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:G#ga" title="Complexity Zoo:G">GA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#ganspace" title="Complexity Zoo:G">GAN-SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gapac0" title="Complexity Zoo:G">GapAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gapl" title="Complexity Zoo:G">GapL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gapp" title="Complexity Zoo:G">GapP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gc" title="Complexity Zoo:G">GC(s(n),C)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gcsl" title="Complexity Zoo:G">GCSL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gi" title="Complexity Zoo:G">GI</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#glo" title="Complexity Zoo:G">GLO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gpcd" title="Complexity Zoo:G">GPCD(r(n),q(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gt" title="Complexity Zoo:G">G[t]</a>
</p>
<h3><span id="H">H</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:H#halfp" title="Complexity Zoo:H">HalfP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurbpp" title="Complexity Zoo:H">HeurBPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurbptime" title="Complexity Zoo:H">HeurBPTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurdtime" title="Complexity Zoo:H">HeurDTIME<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c5321cfa797202b3e1f8620663ff43c4660ea03a" aria-hidden="true" alt="{\displaystyle \delta }"></span></sub>(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurp" title="Complexity Zoo:H">HeurP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurpp" title="Complexity Zoo:H">HeurPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurntime" title="Complexity Zoo:H">HeurNTIME<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c5321cfa797202b3e1f8620663ff43c4660ea03a" aria-hidden="true" alt="{\displaystyle \delta }"></span></sub>(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#hkp" title="Complexity Zoo:H">H<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#hvszk" title="Complexity Zoo:H">HVSZK</a>
</p>
<h3><span id="I">I</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:I#iclogpoly" title="Complexity Zoo:I">IC[log,poly]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I#ip" title="Complexity Zoo:I">IP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I#ipp" title="Complexity Zoo:I">IPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I#ippolylog" title="Complexity Zoo:I">IP[polylog]</a>
</p>
<h3><span id="L">L</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:L#l" title="Complexity Zoo:L">L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lc0" title="Complexity Zoo:L">LC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lh" title="Complexity Zoo:L">LH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lin" title="Complexity Zoo:L">LIN</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lkp" title="Complexity Zoo:L">L<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#logcfl" title="Complexity Zoo:L">LOGCFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#logfew" title="Complexity Zoo:L">LogFew</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#logfewnl" title="Complexity Zoo:L">LogFewNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#loglog" title="Complexity Zoo:L">LOGLOG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lognp" title="Complexity Zoo:L">LOGNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#logsnp" title="Complexity Zoo:L">LOGSNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#l.2Fpoly" title="Complexity Zoo:L">L/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lwpp" title="Complexity Zoo:L">LWPP</a>
</p>
<h3><span id="M">M</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:M#ma" title="Complexity Zoo:M">MA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#macc" title="Complexity Zoo:M">MA<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maprime" title="Complexity Zoo:M">MA'</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mac0" title="Complexity Zoo:M">MAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mae" title="Complexity Zoo:M">MA<sub>E</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maexp" title="Complexity Zoo:M">MA<sub>EXP</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mal" title="Complexity Zoo:M">mAL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mapolylog" title="Complexity Zoo:M">MA<sub>POLYLOG</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maxnp" title="Complexity Zoo:M">MaxNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maxpb" title="Complexity Zoo:M">MaxPB</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maxsnp" title="Complexity Zoo:M">MaxSNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maxsnp0" title="Complexity Zoo:M">MaxSNP<sub>0</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mconl" title="Complexity Zoo:M">mcoNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#minpb" title="Complexity Zoo:M">MinPB</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mip" title="Complexity Zoo:M">MIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mipstar" title="Complexity Zoo:M">MIP*</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mipns" title="Complexity Zoo:M">MIP<sup>ns</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mipexp" title="Complexity Zoo:M">MIP<sub>EXP</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mkp" title="Complexity Zoo:M">(M<sub>k</sub>)P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#ml" title="Complexity Zoo:M">mL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mm" title="Complexity Zoo:M">MM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mmsnp" title="Complexity Zoo:M">MMSNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mnc1" title="Complexity Zoo:M">mNC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mnl" title="Complexity Zoo:M">mNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mnp" title="Complexity Zoo:M">mNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modkl" title="Complexity Zoo:M">Mod<sub>k</sub>L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modl" title="Complexity Zoo:M">ModL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modkp" title="Complexity Zoo:M">Mod<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modp" title="Complexity Zoo:M">ModP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modzkl" title="Complexity Zoo:M">ModZ<sub>k</sub>L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mp" title="Complexity Zoo:M">mP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mp2" title="Complexity Zoo:M">MP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mpc" title="Complexity Zoo:M">MPC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mppoly" title="Complexity Zoo:M">mP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mtc0" title="Complexity Zoo:M">mTC<sup>0</sup></a>
</p>
<h3><span id="N">N</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:N#nauxpdap" title="Complexity Zoo:N">NAuxPDA<sup>p</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nc" title="Complexity Zoo:N">NC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nc0" title="Complexity Zoo:N">NC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nc1" title="Complexity Zoo:N">NC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nc2" title="Complexity Zoo:N">NC<sup>2</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#ne" title="Complexity Zoo:N">NE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nepoly" title="Complexity Zoo:N">NE/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nearlyp" title="Complexity Zoo:N">Nearly-P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nee" title="Complexity Zoo:N">NEE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#neee" title="Complexity Zoo:N">NEEE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#neexp" title="Complexity Zoo:N">NEEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nexp" title="Complexity Zoo:N">NEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nexppoly" title="Complexity Zoo:N">NEXP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nipzk" title="Complexity Zoo:N">NIPZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#niqszk" title="Complexity Zoo:N">NIQSZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#niszk" title="Complexity Zoo:N">NISZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#niszkh" title="Complexity Zoo:N">NISZK<sub>h</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nl" title="Complexity Zoo:N">NL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nlpoly" title="Complexity Zoo:N">NL/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nlin" title="Complexity Zoo:N">NLIN</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nlo" title="Complexity Zoo:N">NLO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nlog" title="Complexity Zoo:N">NLOG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#none" title="Complexity Zoo:N">NONE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nnc" title="Complexity Zoo:N">NNC(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#np" title="Complexity Zoo:N">NP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npc" title="Complexity Zoo:N">NPC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npc2" title="Complexity Zoo:N">NP<sub>C</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npcc" title="Complexity Zoo:N">NP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npkcc" title="Complexity Zoo:N">NP<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" aria-hidden="true" alt="{\displaystyle k}"></span></sub><sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npi" title="Complexity Zoo:N">NPI</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npiconp" title="Complexity Zoo:N">NP ∩ coNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npiconppoly" title="Complexity Zoo:N">(NP ∩ coNP)/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nplog" title="Complexity Zoo:N">NP/log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npmv" title="Complexity Zoo:N">NPMV</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npmvsel" title="Complexity Zoo:N">NPMV-sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npmvt" title="Complexity Zoo:N">NPMV<sub>t</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npmvtsel" title="Complexity Zoo:N">NPMV<sub>t</sub>-sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npo" title="Complexity Zoo:N">NPO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npopb" title="Complexity Zoo:N">NPOPB</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nppoly" title="Complexity Zoo:N">NP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nppsamp" title="Complexity Zoo:N">(NP,P-samplable)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npr" title="Complexity Zoo:N">NP<sub>R</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npspace" title="Complexity Zoo:N">NPSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npsv" title="Complexity Zoo:N">NPSV</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npsvsel" title="Complexity Zoo:N">NPSV-sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npsvt" title="Complexity Zoo:N">NPSV<sub>t</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npsvtsel" title="Complexity Zoo:N">NPSV<sub>t</sub>-sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nqp" title="Complexity Zoo:N">NQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nspace" title="Complexity Zoo:N">NSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nt" title="Complexity Zoo:N">NT</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#ntstar" title="Complexity Zoo:N">NT*</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#ntime" title="Complexity Zoo:N">NTIME(f(n))</a>
</p>
<h3><span id="O">O</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:O#optp" title="Complexity Zoo:O">OptP</a>
</p>
<h3><span id="P">P</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:P#p" title="Complexity Zoo:P">P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#plog" title="Complexity Zoo:P">P/log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppoly" title="Complexity Zoo:P">P/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#psharpp" title="Complexity Zoo:P">P<sup>#P</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#psharpp1" title="Complexity Zoo:P">P<sup>#P[1]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pctc" title="Complexity Zoo:P">P<sub>CTC</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pac0" title="Complexity Zoo:P">PAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pbp" title="Complexity Zoo:P">PBP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#kpbp" title="Complexity Zoo:P">k-PBP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pc" title="Complexity Zoo:P">P<sub>C</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pcc" title="Complexity Zoo:P">P<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pkcc" title="Complexity Zoo:P">P<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" aria-hidden="true" alt="{\displaystyle k}"></span></sub><sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pcd" title="Complexity Zoo:P">PCD(r(n),q(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pclose" title="Complexity Zoo:P">P-Close</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pcp" title="Complexity Zoo:P">PCP(r(n),q(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pdqp" title="Complexity Zoo:P">PDQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#permup" title="Complexity Zoo:P">PermUP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pexp" title="Complexity Zoo:P">PEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pf" title="Complexity Zoo:P">PF</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pfchk" title="Complexity Zoo:P">PFCHK(t(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ph" title="Complexity Zoo:P">PH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#phcc" title="Complexity Zoo:P">PH<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#phi2p" title="Complexity Zoo:P">Φ<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#php" title="Complexity Zoo:P">PhP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pi2p" title="Complexity Zoo:P">Π<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pinc" title="Complexity Zoo:P">PINC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pio" title="Complexity Zoo:P">PIO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pk" title="Complexity Zoo:P">P<sup>K</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pkc" title="Complexity Zoo:P">PKC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pl" title="Complexity Zoo:P">PL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pl1" title="Complexity Zoo:P">PL<sub>1</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#plinfinity" title="Complexity Zoo:P">PL<sub>∞</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#plf" title="Complexity Zoo:P">PLF</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pll" title="Complexity Zoo:P">PLL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pls" title="Complexity Zoo:P">PLS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnp" title="Complexity Zoo:P">P<sup>NP</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnpcc" title="Complexity Zoo:P">P<sup>NPcc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pparnp" title="Complexity Zoo:P">P<sup>||NP</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnpk" title="Complexity Zoo:P">P<sup>NP[k]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnplog" title="Complexity Zoo:P">P<sup>NP[log]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnplog2" title="Complexity Zoo:P">P<sup>NP[log^2]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pobdd" title="Complexity Zoo:P">P-OBDD</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#podn" title="Complexity Zoo:P">PODN</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#polyl" title="Complexity Zoo:P">polyL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#postbpp" title="Complexity Zoo:P">PostBPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#postbppcc" title="Complexity Zoo:P">PostBPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#postbqp" title="Complexity Zoo:P">PostBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pp" title="Complexity Zoo:P">PP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppcc" title="Complexity Zoo:P">PP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pppoly" title="Complexity Zoo:P">PP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppa" title="Complexity Zoo:P">PPA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppad" title="Complexity Zoo:P">PPAD</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppads" title="Complexity Zoo:P">PPADS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppp2" title="Complexity Zoo:P">P<sup>PP</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppp" title="Complexity Zoo:P">PPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppspace" title="Complexity Zoo:P">PPSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pqmalog" title="Complexity Zoo:P">P<sup>QMA[log]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pquery" title="Complexity Zoo:P">PQUERY</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pr" title="Complexity Zoo:P">PR</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pr2" title="Complexity Zoo:P">P<sub>R</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#prhspace" title="Complexity Zoo:P">Pr<sub>H</sub>SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promisebpp" title="Complexity Zoo:P">PromiseBPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promisebqp" title="Complexity Zoo:P">PromiseBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promisep" title="Complexity Zoo:P">PromiseP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promiserp" title="Complexity Zoo:P">PromiseRP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promiseup" title="Complexity Zoo:P">PromiseUP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#prspace" title="Complexity Zoo:P">PrSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#psel" title="Complexity Zoo:P">P-Sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#psk" title="Complexity Zoo:P">PSK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pspace" title="Complexity Zoo:P">PSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pspacecc" title="Complexity Zoo:P">PSPACE<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pspacepoly" title="Complexity Zoo:P">PSPACE/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pt1" title="Complexity Zoo:P">PT<sub>1</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ptape" title="Complexity Zoo:P">PTAPE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ptas" title="Complexity Zoo:P">PTAS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ptwk" title="Complexity Zoo:P">PT/WK(f(n),g(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pzk" title="Complexity Zoo:P">PZK</a>
</p>
<h3><span id="Q">Q</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:Q#q" title="Complexity Zoo:Q">Q</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qac0" title="Complexity Zoo:Q">QAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qac0m" title="Complexity Zoo:Q">QAC<sup>0</sup>[m]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qacc0" title="Complexity Zoo:Q">QACC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qacwf0" title="Complexity Zoo:Q">QAC<sub>f</sub><sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qam" title="Complexity Zoo:Q">QAM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qcfl" title="Complexity Zoo:Q">QCFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qcma" title="Complexity Zoo:Q">QCMA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qcph" title="Complexity Zoo:Q">QCPH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qh" title="Complexity Zoo:Q">QH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qip" title="Complexity Zoo:Q">QIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qip2" title="Complexity Zoo:Q">QIP[2]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#ql" title="Complexity Zoo:Q">QL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qma" title="Complexity Zoo:Q">QMA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qma-plus" title="Complexity Zoo:Q">QMA-plus</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qma2" title="Complexity Zoo:Q">QMA(2)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qma1" title="Complexity Zoo:Q">QMA<sub>1</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmalog" title="Complexity Zoo:Q">QMA<sub>log</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmam" title="Complexity Zoo:Q">QMAM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmaqpoly" title="Complexity Zoo:Q">QMA/qpoly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmip" title="Complexity Zoo:Q">QMIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmiple" title="Complexity Zoo:Q">QMIP<sub>le</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmipne" title="Complexity Zoo:Q">QMIP<sub>ne</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qnc" title="Complexity Zoo:Q">QNC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qnc0" title="Complexity Zoo:Q">QNC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qncf0" title="Complexity Zoo:Q">QNC<sub>f</sub><sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qnc1" title="Complexity Zoo:Q">QNC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qp" title="Complexity Zoo:Q">QP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qph" title="Complexity Zoo:Q">QPH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qplin" title="Complexity Zoo:Q">QPLIN</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qpspace" title="Complexity Zoo:Q">QPSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qrg" title="Complexity Zoo:Q">QRG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qrgk" title="Complexity Zoo:Q">QRG(k)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qrg2" title="Complexity Zoo:Q">QRG(2)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qrg1" title="Complexity Zoo:Q">QRG(1)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qszk" title="Complexity Zoo:Q">QSZK</a>
</p>
<h3><span id="R">R</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:R#r" title="Complexity Zoo:R">R</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rbqp" title="Complexity Zoo:R">RBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#re" title="Complexity Zoo:R">RE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#reg" title="Complexity Zoo:R">REG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#revspace" title="Complexity Zoo:R">RevSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rg" title="Complexity Zoo:R">RG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rg1" title="Complexity Zoo:R">RG[1]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rhl" title="Complexity Zoo:R">R<sub>H</sub>L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rhspace" title="Complexity Zoo:R">R<sub>H</sub>SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rl" title="Complexity Zoo:R">RL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rnc" title="Complexity Zoo:R">RNC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rp" title="Complexity Zoo:R">RP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rpcc" title="Complexity Zoo:R">RP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rpkcc" title="Complexity Zoo:R">RP<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" aria-hidden="true" alt="{\displaystyle k}"></span></sub><sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rpp" title="Complexity Zoo:R">RPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rqp" title="Complexity Zoo:R">RQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rspace" title="Complexity Zoo:R">RSPACE(f(n))</a>
</p>
<h3><span id="S">S</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:S#s2p" title="Complexity Zoo:S">S<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#s2exppnp" title="Complexity Zoo:S">S<sub>2</sub>-EXP&amp;#149;P<sup>NP</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sac" title="Complexity Zoo:S">SAC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sac0" title="Complexity Zoo:S">SAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sac1" title="Complexity Zoo:S">SAC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#saptime" title="Complexity Zoo:S">SAPTIME</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sbp" title="Complexity Zoo:S">SBP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sbpcc" title="Complexity Zoo:S">SBP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sbqp" title="Complexity Zoo:S">SBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sc" title="Complexity Zoo:S">SC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#se" title="Complexity Zoo:S">SE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#seh" title="Complexity Zoo:S">SEH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#selfnp" title="Complexity Zoo:S">SelfNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sfk" title="Complexity Zoo:S">SF<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sigma2p" title="Complexity Zoo:S">Σ<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#skc" title="Complexity Zoo:S">SKC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sl" title="Complexity Zoo:S">SL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#slicewisepspace" title="Complexity Zoo:S">SLICEWISE PSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#snp" title="Complexity Zoo:S">SNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#so" title="Complexity Zoo:S">SO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sohorn" title="Complexity Zoo:S">SO(Horn)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sokrom" title="Complexity Zoo:S">SO(Krom)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#solfp" title="Complexity Zoo:S">SO(LFP)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sotc" title="Complexity Zoo:S">SO(TC)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sot" title="Complexity Zoo:S">SO[<span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/70b64a27c4f55221162f329285382cc470e3827e" aria-hidden="true" alt="{\displaystyle t(n)}"></span>]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sp" title="Complexity Zoo:S">SP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#spanl" title="Complexity Zoo:S">span-L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#spanp" title="Complexity Zoo:S">span-P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sparse" title="Complexity Zoo:S">SPARSE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#spl" title="Complexity Zoo:S">SPL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#spp" title="Complexity Zoo:S">SPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sqg" title="Complexity Zoo:S">SQG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#subexp" title="Complexity Zoo:S">SUBEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#symp" title="Complexity Zoo:S">symP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#szk" title="Complexity Zoo:S">SZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#szkh" title="Complexity Zoo:S">SZK<sub>h</sub></a>
</p>
<h3><span id="T">T</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:T#tally" title="Complexity Zoo:T">TALLY</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#tc0" title="Complexity Zoo:T">TC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#tfnp" title="Complexity Zoo:T">TFNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#theta2p" title="Complexity Zoo:T">Θ<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#ti" title="Complexity Zoo:T">TI</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#tower" title="Complexity Zoo:T">Tower</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#treebqp" title="Complexity Zoo:T">TreeBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#treeregular" title="Complexity Zoo:T">TREE-REGULAR</a>
</p>
<h3><span id="U">U</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:U#uamcc" title="Complexity Zoo:U">UAM<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#uap" title="Complexity Zoo:U">UAP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ucc" title="Complexity Zoo:U">UCC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ucc" title="Complexity Zoo:U">UCFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ue" title="Complexity Zoo:U">UE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ul" title="Complexity Zoo:U">UL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ulpoly" title="Complexity Zoo:U">UL/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#up" title="Complexity Zoo:U">UP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#upcc" title="Complexity Zoo:U">UP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#upostbppcc" title="Complexity Zoo:U">UPostBPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#uppcc" title="Complexity Zoo:U">UPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#us" title="Complexity Zoo:U">US</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#usbpcc" title="Complexity Zoo:U">USBP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#uwappcc" title="Complexity Zoo:U">UWAPP<sup>cc</sup></a>
</p>
<h3><span id="V">V</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:V#vck" title="Complexity Zoo:V">VC<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vcor" title="Complexity Zoo:V">VC<sub>OR</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vnc" title="Complexity Zoo:V">VNC<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vnp" title="Complexity Zoo:V">VNP<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vp" title="Complexity Zoo:V">VP<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vpl" title="Complexity Zoo:V">VPL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vqp" title="Complexity Zoo:V">VQP<sub>k</sub></a>
</p>
<h3><span id="W">W</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:W#w1" title="Complexity Zoo:W">W[1]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wapp" title="Complexity Zoo:W">WAPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wappcc" title="Complexity Zoo:W">WAPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#while" title="Complexity Zoo:W">WHILE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wp" title="Complexity Zoo:W">W[P]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wpp" title="Complexity Zoo:W">WPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wsat" title="Complexity Zoo:W">W[SAT]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wstar" title="Complexity Zoo:W">W[*]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wt" title="Complexity Zoo:W">W[t]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wstart" title="Complexity Zoo:W">W<sup>*</sup>[t]</a>
</p>
<h3><span id="X">X</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:X#xormipstar21" title="Complexity Zoo:X">XOR-MIP*[2,1]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X#xl" title="Complexity Zoo:X">XL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X#xnl" title="Complexity Zoo:X">XNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X#xp" title="Complexity Zoo:X">XP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X#xpuniform" title="Complexity Zoo:X">XP<sub>uniform</sub></a>
</p>
<h3><span id="Y">Y</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:Y#yacc" title="Complexity Zoo:Y">YACC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y#yp" title="Complexity Zoo:Y">YP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y#ypp" title="Complexity Zoo:Y">YPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y#yqp" title="Complexity Zoo:Y">YQP</a>
</p>
<h3><span id="Z">Z</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:Z#zamcc" title="Complexity Zoo:Z">ZAM<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zbqp" title="Complexity Zoo:Z">ZBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zk" title="Complexity Zoo:Z">ZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zpe" title="Complexity Zoo:Z">ZPE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zpp" title="Complexity Zoo:Z">ZPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zppcc" title="Complexity Zoo:Z">ZPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zptime" title="Complexity Zoo:Z">ZPTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zqp" title="Complexity Zoo:Z">ZQP</a>
</p>
<!-- 
NewPP limit report
Cached time: 20201215005357
Cache expiry: 86400
Dynamic content: false
Complications: []
CPU time usage: 0.167 seconds
Real time usage: 0.399 seconds
Preprocessor visited node count: 855/1000000
Post‐expand include size: 45273/2097152 bytes
Template argument size: 8963/2097152 bytes
Highest expansion depth: 5/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 288/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%   85.158      1 -total
 91.77%   78.149     25 Template:CZ-Letter-Section
  5.01%    4.269      1 Template:CZ-P
  4.47%    3.803      1 Template:CZ-N
  3.87%    3.298      1 Template:CZ-B
  3.86%    3.291      1 Template:CZ-M
  3.85%    3.279      1 Template:CZ-S
  3.84%    3.269      1 Template:CZ-Q
  3.79%    3.224      1 Template:CZ-C
  3.75%    3.196      1 Template:CZ-A
-->

<!-- Saved in parser cache with key zoo:pcache:idhash:8-0!canonical!math=5 and timestamp 20201215005356 and revision id 6693
 -->
</div></div></div>]]>
            </description>
            <link>https://complexityzoo.net/Complexity_Zoo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388790</guid>
            <pubDate>Fri, 11 Dec 2020 18:16:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canada to implement its first national vaccine injury compensation program]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25388410">thread link</a>) | @finphil
<br/>
December 11, 2020 | https://www.ctvnews.ca/health/coronavirus/canada-to-implement-its-first-national-vaccine-injury-compensation-program-1.5226609 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/health/coronavirus/canada-to-implement-its-first-national-vaccine-injury-compensation-program-1.5226609">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>TORONTO -- 
	As part of Canadaâ€™s vaccine rollout, the federal government has announced that anyone who experiences a severe adverse reaction to a COVID-19 vaccine will be eligible for compensation â€” a first in Canadaâ€™s history.</p>
<p>
	The no-fault program was announced Thursday, as Canada gets ready to roll out the first of seven new vaccines.</p>
<p>
	â€œSerious side-effects are incredibly rare,â€� Prime Minister Justin Trudeau said in a press conference Thursday. â€œIn the very unlikely event of an adverse reaction though, we want to make sure Canadians have fair access to support. So today, I can announce that weâ€™re creating a federal support program around vaccine safety for all Canadians and for all vaccines. This includes COVID-19 vaccines that will be rolled out soon.â€�</p>
<ul>
	<li>
		<em><strong><a href="https://www.ctvnews.ca/newsletters/the-covid19-brief-newsletter-signup" target="_blank">Newsletter sign-up: Get The COVID-19 Brief sent to your inbox</a></strong></em></li>
</ul>
<p>
	Before a vaccine reaches the public, it will have gone through clinical trials involving thousands of people. The Pfizer-BioNTech vaccine, which Health Canada approved Wednesday, used more than 40,000 people in its final phases of testing. Although side-effects did occur for some participants, almost all were temporary, and the vaccine has been deemed safe for the general public.</p>
<p>
	Serious reactions are not impossible, however. In the U.K., two people with a history of severe allergic reactions to things such as vaccines, medicine or food <a href="https://www.ctvnews.ca/world/u-k-to-refine-allergy-warning-on-pfizer-vaccine-sparked-by-two-adverse-reactions-1.5223107" target="_blank">suffered serious reactions to the Pfizer vaccine this week.</a> The situation is still being investigated to figure out what triggered the reactions.</p>
<p>
	<a href="https://www.canada.ca/en/public-health/news/2020/12/government-of-canada-announces-pan-canadian-vaccine-injury-support-program.html" target="_blank">In a news release on todayâ€™s compensation program</a>, the federal government pointed out that the chances of someone experiencing a truly serious adverse reaction are â€œextremely rare -- less than one in a million.â€�</p>
<p>
	Trudeau added in the press conference that the program was â€œbased on the model that Quebec has had for the last 30 years and follows the lead of all other G7 countries.â€�</p>
<p>
	More than 20 countries already have vaccine injury support programs, according to the press release, with Canada being the last G7 country to follow suit.</p>
<p>
	â€œCanadians can have confidence in the rigour of the vaccine approvals system, however, in the rare event that a person experiences an adverse reaction, this program will help ensure they get the support they need,â€� Health Minister Patty Hajdu said in the release. â€œI will work with my provincial and territorial counterparts to set this program in place quickly.â€�</p>
<p>
	So far, no details have been released on how one would qualify for the program, or how much they could be eligible for in response to a permanent injury as a result of taking a vaccine.</p>
<p>
	<em>With files from Avis Favaro&nbsp;</em></p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/health/coronavirus/canada-to-implement-its-first-national-vaccine-injury-compensation-program-1.5226609</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388410</guid>
            <pubDate>Fri, 11 Dec 2020 17:43:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Survey 2020 Results]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25388353">thread link</a>) | @todd8
<br/>
December 11, 2020 | https://emacssurvey.org/2020/ | <a href="https://web.archive.org/web/*/https://emacssurvey.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2>Questions</h2>
      <p>For reference, this was <a href="https://emacssurvey.org/2020/emacs-user-survey-2020.org">the survey questions</a> in org-mode format.</p>
      <h2>Data</h2>
      <ul>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-raw.csv">Raw data</a>
          <ul>
            <li>the reconciled data from both webform and email submissions</li>
            <li>absolutely no change made aside from a few instances where PII and email addresses were redacted</li>
          </ul>
        </li>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-clean.csv">Cleaned up data</a><br>
          It might get updated in the future, but right now it was derived from the raw data in a best-effort attempt:
          <ul>
            <li>removed negative years in "For how many years have you been using Emacs?"</li>
            <li>unified responses for "How did you hear about this survey?" as Hacker News, Emacs China and Emacs News weren't part of the options</li>
            <li>unified responses for "Which theme do you use?", especially around spelling</li>
            <li>general cleanup and unified of responses which only differed by punctuation and casing</li>
          </ul>
        </li>
      </ul>
      <h2>Statistics about the survey</h2>
      
      <h2>Analysis</h2>
      <p>There is a lot of data to look at in many different ways. For now, I performed a simple question-by-question analysis using a <a href="https://github.com/abrochard/emacs-survey/blob/main/2020/Emacs%20User%20Survey%202020.ipynb">Jupyter Notebook</a>.</p>
      <p>Also, since free text was available for most questions, it can be hard to categorize some of the results. For multiple choice questions, I did a best effort attempt to bundle responses with low cardinality into an "other" section, which can get quite big in some cases! I also did not attempt to graph anything for pure free text questions. I encourage anyone who is curious to inspect the full responses, either in the notebook or looking at the data directly. The omitted free text questions are:
        </p><ul>
          <li>If you use org-mode, for what purpose?</li>
          <li>Do you use a language server with lsp-mode or eglot? With what languages?</li>
          <li>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</li>
          <li>What are some of the Emacs improvements you are the most interested in?</li>
          <li>What do you think are Emacs' greatest strengths?</li>
          <li>Can you recall any difficulties you faced initially learning Emacs?</li>
          <li>What is the one thing you would like Emacs to do differently?</li>
          <li>If there is another survey in 2021, would you be opposed to it containing optional &amp; general demographics questions?</li>
          <li>Do you have a preferred platform for filling out the survey in the future?</li>
          <li>Do you have general feedback about the survey process?</li>
        </ul>
      

      <p>Also if you have some cool analysis and want to share it, please <a href="mailto:contact@emacssurvey.org">let us know</a> and we can link to you.</p>
      <p><img src="https://emacssurvey.org/2020/how-would-you-characterize-your-use-of-emacs.png">
      <img src="https://emacssurvey.org/2020/what-do-you-use-emacs-for.png">
      <img src="https://emacssurvey.org/2020/for-how-many-years-have-you-been-using-emacs.png">
      <img src="https://emacssurvey.org/2020/which-version-of-emacs-do-you-primarily-use.png">
      <img src="https://emacssurvey.org/2020/which-os-do-you-primarily-use-emacs-on.png">
      <img src="https://emacssurvey.org/2020/how-do-you-run-emacs.png">
      <img src="https://emacssurvey.org/2020/how-do-you-use-emacs.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-gui-do-you-disable-any-of-the-graphical-elements.png">
      <img src="https://emacssurvey.org/2020/is-your-configuration-based-on-any-starter-kit.png">
      <img src="https://emacssurvey.org/2020/what-keybindings-do-you-use-now.png">
      <img src="https://emacssurvey.org/2020/when-you-started-using-emacs-what-keybindings-did-you-use-then.png">
      <img src="https://emacssurvey.org/2020/prior-to-using-emacs-what-was-your-primary-editor.png">
      <img src="https://emacssurvey.org/2020/describe-your-org-mode-usage.png"></p><!-- <p>If you use org-mode, for what purpose?</p> -->
      <p><img src="https://emacssurvey.org/2020/which-completionselection-framework-do-you-use.png">
      <img src="https://emacssurvey.org/2020/how-do-you-manage-third-party-elisp.png">
      <img src="https://emacssurvey.org/2020/how-do-you-get-emacs-packagesif-applicable.png">
      <img src="https://emacssurvey.org/2020/can-you-list-some-of-your-favorite-packages.png">
      <img src="https://emacssurvey.org/2020/which-theme-do-you-use.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-error-checking.png">
      <img src="https://emacssurvey.org/2020/do-you-use-tramp.png">
      <img src="https://emacssurvey.org/2020/do-you-use-magit.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-project-management.png">
      <img src="https://emacssurvey.org/2020/do-you-use-a-shellterminal-emulator-in-emacs.png">
      <img src="https://emacssurvey.org/2020/do-you-use-an-email-client-in-emacs.png">
      <img src="https://emacssurvey.org/2020/what-is-your-elisp-proficiency.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-for-programming-which-languages-do-you-program-in.png"></p><!-- <p>Do you use a language server with lsp-mode or eglot? With what languages?</p>
           <p>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</p> -->
      <p><img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-gnu-emacs-coreelpa.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-melpa-package.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-financially-to-emacs-development-either-via-fsf-or-directly.png">
      <img src="https://emacssurvey.org/2020/what-emacs-community-forums-have-you-visited-in-the-past-year.png"></p><!-- <p>What are some of the Emacs improvements you are the most interested in?</p>
           <p>What do you think are Emacs' greatest strengths?</p>
           <p>Can you recall any difficulties you faced initially learning Emacs?</p>
           <p>What is the one thing you would like Emacs to do differently?</p> -->
      <p><img src="https://emacssurvey.org/2020/how-did-you-hear-about-this-survey.png"></p><!-- <p>If there is another survey in 2021, would you be opposed to it containing optional & general demographics questions?</p>
           <p>Do you have a preferred platform for filling out the survey in the future?</p>
           <p>Do you have general feedback about the survey process?</p> -->
    </div></div>]]>
            </description>
            <link>https://emacssurvey.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388353</guid>
            <pubDate>Fri, 11 Dec 2020 17:38:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a garbage-free network stack for Kafka streams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25388119">thread link</a>) | @prtkgpt
<br/>
December 11, 2020 | https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams | <a href="https://web.archive.org/web/*/https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><figure><img alt="Steam network of a Pennsylvania coal power plant" height="433" src="https://questdb.io/img/blog/2020-12-10/banner.jpg" width="650"><figcaption>Photo by <a href="https://unsplash.com/photos/a_PDPUPuNZ8" target="_blank" rel="noopener noreferrer">Martin Adams</a> on <a href="https://unsplash.com/" target="_blank" rel="noopener noreferrer">Unsplash</a></figcaption></figure><p>At QuestDB, we're building an open source high-performance time series database
used in IoT applications, financial trading, industrial monitoring, machine
learning, and anywhere time series data lives. Our community showed a lot of
interest in integrations with third-party tools, and after adding Grafana
support earlier this year, ingesting data from Kafka topics was our next goal.</p><p>To build reliable support for Kafka, we improved our PostgreSQL wire protocol
implementation and introduced functionality that we thought readers might like
to hear about. As we fully avoid garbage collection, we bypassed Java's native
non-blocking IO and built our own notification system. To do this, we built a
configurable dispatcher that can delegate tasks to worker threads and uses
queues for events and socket connections. The result is a new generic network
stack used to handle all incoming network connections to QuestDB.</p><p>Kafka Connect support is now available since version 5.0.5, and the QuestDB
source is available to <a href="https://github.com/questdb/questdb" target="_blank" rel="noopener noreferrer">browse on GitHub</a>. If you like the
content and the new functionality or if you know of a better way to approach what
we built, we'd love to know your thoughts! Feel free to share your feedback
<a href="https://slack.questdb.io/" target="_blank" rel="noopener noreferrer">in our Slack Community</a>.</p><h2>Flow control<a href="#flow-control" title="Direct link to heading">#</a></h2><p>When we have multiple nodes on a network, there are usually disparities in their
performance in computing power and network bandwidth. Some nodes can read
incoming packets at different rates than others, or conversely, some nodes may
be able to send data at a different rate.</p><p>Let's say we have a network with two nodes; a sender and a receiver. If the
sender can produce a lot more data than the receiver can read, the receiver is
likely to be overwhelmed. We're in luck, though, as TCP uses a built-in flow
control protocol that acts as a pressure valve to ensure the receiver is not
affected by such cases.</p><p>Control flow manifests itself in different ways, depending on whether the
network socket is blocking or non-blocking. If the receiver can process data
faster than a sender, a non-blocking socket is identical to a blocking one, and
the receiver thread would be parked while no data is read. There's not much
concern about this situation if it happens infrequently, but the park and unpark
is a waste of resources and CPU cycles if the receiver is under heavy load.</p><p>Let's assume the receiver gets 0-length data on a non-blocking socket,
indicating no data has arrived from the sender; there are two options:</p><ol><li>Loop over reads continuously, waiting for data to arrive on a socket.</li><li>Stop looping and consult our parser on two possible actions to take: park for
more reads or switch to write.</li></ol><p>The first option is quite wasteful, so we went with the second approach. To park
socket read operations without blocking the thread, we need a dedicated system
to enqueue the socket and notify us when the socket has more data to read. On
the OS kernel level, IO notification utilities exist as <code>epoll</code> on Linux,
<code>kqueue</code> on FreeBSD and OSX, and <code>select</code> on Windows. In QuestDB, we've
implemented a dispatcher that operates exactly as these IO notification systems
for enqueuing sockets, and we named it IODispatcher.</p><h2>Java NIO and garbage collection<a href="#java-nio-and-garbage-collection" title="Direct link to heading">#</a></h2><p>As you would expect from cross-platform languages, the IO Notification system
must be abstracted away to make application code portable. In Java, this
abstraction is called <code>Selector</code>. If we were to oversimplify a typical
interaction with the IO Notification system, it would essentially be a loop.
More often than not, this is an infinite loop, or rather, it executes
continuously during the server's uptime.</p><p>Since we are on a quest to have everything garbage-free, Selector presents a
problem right away - the output of the selector is a set of keys, coming from a
concurrent hash map via an iterator. All of this allocates objects on every
iteration of the loop. If you are not careful, this allocation continues even
when the server is idling. The behavior is intrinsic to the Java Non-blocking
I/O (NIO) implementation and cannot be changed.</p><p>To send or receive data from the network, Java mandates ByteBuffer instances.
When looked at in a vacuum, ByteBuffer may seem like a reasonable abstraction.
But if we look closer, it's easy to see it's a bit confused. It is a concrete
class instead of an interface, meaning that the whole NIO is stuck with the
provided implementation. The API is inconsistent as the OS requires memory
pointers for send and receive methods, but ByteBuffer does not provide an
explicit semantic for each case. So how does ByteBuffer translate to a memory
pointer?</p><p>When your data is on the heap, there is a memory copy for each socket IO. When
ByteBuffer is direct, there is no copy, but there is an issue releasing memory
and general Java paranoia about language safety.</p><div><p>Native Java socket write implementation</p></div><p>Considering the allocating nature of the Selector, that Java NIO libraries are a
layer above the OS, and how computationally expensive the overhead is with
ByteBuffer, we decided to go out on a limb and interact directly with the OS via
the Java Native Interface (JNI). This worked for QuestDB insofar as the API is
non-allocating outside of the normal bootstrap phase and lets us work with the
memory pointers directly.</p><div><p>QuestDB's JNI call for sending data to a socket</p></div><h2>QuestDB's thread model<a href="#questdbs-thread-model" title="Direct link to heading">#</a></h2><p>Starting threads is expensive, and they're more often than not just wrappers for
the connection state. QuestDB operates a fixed number of threads to isolate the
database instance to specific cores and reduce the overhead of starting and
stopping threads at runtime. The actual threads are encapsulated by a WorkerPool
class.</p><p>The worker pool's idea is to have a simple list of "jobs" that all workers will
run all the time. Jobs themselves encapsulate "piece of work" and do not have
tight loops in them. Hence a job can simply return if IO is not available or the
queue is full or empty.</p><p>We have a notion of a "synchronized job." It is different from the definition of
"synchronized" in Java in that the QuestDB's thread never blocks. However,
synchronized jobs guarantee that only one thread can execute a job instance at
any moment in time.</p><h2>Introducing QuestDB's IODispatcher<a href="#introducing-questdbs-iodispatcher" title="Direct link to heading">#</a></h2><p>IODispatcher is QuestDB's implementation of the IO Notification loop. We have
implemented <code>epoll</code>, <code>kqueue</code>, and <code>select</code>, so this works cross-platform. The
appropriate implementation is automatically chosen at runtime based on the OS.
The IODispatched API is message-driven via QuestDB's implementation of
non-blocking and non-allocating queues. These queues are outside of the scope of
this article, but you can read about them in our community
<a href="https://questdb.io/blog/2020/11/26/http-server-contribution">contribution from Alex Pelagenko</a>.</p><figure><img alt="A diagram of QuestDB's IODispatcher" height="284" src="https://questdb.io/img/blog/2020-12-10/iodispatcher-diagram.png" width="650"><figcaption>IODispatcher and queues for events, interest, and disconnections</figcaption></figure><p>IODispatcher is a synchronized job in context of QuestDB's thread model. It consumes
queues on the left and publishes to the queue on the right. IODispatcher's main
responsibility is to deliver socket handles (individual connection identifiers), that are ready for the IO to the worker
threads. Considering that socket handles are read or written to by one thread at a time the
underlying IO notification system works in ONESHOT mode. This means socket handle is
removed from the IO notification system while there is socket activity and re-introduced
back when activity tapers off. Interacting with the IO notification system
is expensive. Worker thread will only recurse back to the IODispatcher for enqueueing
if there has been zero data from the socket for the set period of time, which we call hysteresis.</p><p>You can find source code of the implementations of the IODispatcher for <a href="https://github.com/questdb/questdb/blob/master/core/src/main/java/io/questdb/network/IODispatcherLinux.java" target="_blank" rel="noopener noreferrer">epoll</a>
, <a href="https://github.com/questdb/questdb/blob/master/core/src/main/java/io/questdb/network/IODispatcherOsx.java" target="_blank" rel="noopener noreferrer">kqueue</a> and
<a href="https://github.com/questdb/questdb/blob/master/core/src/main/java/io/questdb/network/IODispatcherWindows.java" target="_blank" rel="noopener noreferrer">select</a> on GitHub. Let's take a look at the components in the diagram above with an outline of their purpose:</p><p><strong>IO Event Queue:</strong> Single publisher, multiple consumer queue. It is the
recipient of the IO events from as in epoll, kqueue, select. The events are
socket handles and the type of operation the OS has associated them with, e.g.,
read or write. The IODispatcher plays the publisher role, and any number of
worker threads are the consumers.</p><p><strong>Interest Queue:</strong> Multiple publisher, single consumer queue. Worker threads
publish socket handles and operations to this queue when IO is unavailable,
e.g., socket read or write returns zero. The IODispatcher will enqueue the
socket handle for more reads or writes as defined by the operation.</p><p><strong>Disconnect Queue:</strong> Multiple publisher, single consumer queue. Worker threads
publish socket handles to this queue destined to be disconnected from the server
and have their resources reused by other connections. The worker thread does not
disconnect the socket by itself because multiple threads may attempt to access a
data structure that is not thread-safe.</p><h3>Configuration<a href="#configuration" title="Direct link to heading">#</a></h3><p>We disregarded ByteBuffer for not being an interface, so it would only be fair
for us to have interfaces in key places. One of these places is configuration,
which provides IODispatcher with basics such as:</p><ul><li>The IP address of the network interface</li><li>Port to bind to</li><li>Bias</li><li>Buffer sizes</li><li>Network facade</li><li>Clock facade</li><li>Connection context factory</li></ul><p>It's necessary to explain bias here, which might not be so obvious. When the TCP
connection is first accepted, it is enqueued for IO right away. The bias
provides an expectation of the initial operation of a connection, such as read
or write. For example, most TCP protocols would have 'read bias', which means
that connecting clients will have to send data before the server replies
anything. You can probably think of a protocol that requires the server to
respond first before the client sends anything - in this case, the bias will be
'write'.</p><p>Network &amp; clock facades have static implementations for production runtime, but
for tests, they can be both spot-implemented to simulate OS failures and produce
stable timestamps.</p><h3>Connection Context<a href="#connection-context" title="Direct link to heading">#</a></h3><p>Connection context is a Java object that encapsulates the connection state,
which is protocol-specific. It is stored together with the socket handle and
managed by …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams">https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams</a></em></p>]]>
            </description>
            <link>https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388119</guid>
            <pubDate>Fri, 11 Dec 2020 17:18:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Federated Learning in less than 20 lines of code]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25387700">thread link</a>) | @tanto
<br/>
December 11, 2020 | https://flower.dev/blog/2020-12-11-federated-learning-in-less-than-20-lines-of-code | <a href="https://web.archive.org/web/*/https://flower.dev/blog/2020-12-11-federated-learning-in-less-than-20-lines-of-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Can we build a fully-fledged Federated Learning system in less than 20 lines of code? Spoiler alert: yes, we can.</p><p><a href="https://flower.dev/">Flower</a> was built with a strong focus on usability. This blog post shows how we can use Flower and <a href="https://tensorflow.org/">TensorFlow</a> to train <a href="https://arxiv.org/abs/1801.04381">MobilNetV2</a> on <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> - in just 19 lines of code.
The system will start one server and two clients, each holding their own local dataset.</p><h2>Flower client</h2><p>Let's first build the client in <code>client.py</code>.
The client starts by importing Flower (<code>flwr</code>) and TensorFlow, compiling the model (MobileNetV2), and loading the data (CIFAR-10):</p><div><article><p>Copy</p><pre><code><span>import</span><span> flwr </span><span>as</span><span> fl
</span><span></span><span>import</span><span> tensorflow </span><span>as</span><span> tf
</span>
<span></span><span># Load and compile Keras model</span><span>
</span><span>model = tf.keras.applications.MobileNetV2((</span><span>32</span><span>, </span><span>32</span><span>, </span><span>3</span><span>), classes=</span><span>10</span><span>, weights=</span><span>None</span><span>)
</span><span>model.</span><span>compile</span><span>(</span><span>"adam"</span><span>, </span><span>"sparse_categorical_crossentropy"</span><span>, metrics=[</span><span>"accuracy"</span><span>])
</span>
<span></span><span># Load CIFAR-10 dataset</span><span>
</span>(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
</code></pre></article></div><p>This should look familiar to anyone who has prior experience with TensorFlow or Keras.
Next, we build a Flower client called <code>CifarClient</code> which is derived from Flower's convenience class <code>KerasClient</code>.
The abstract base class <code>KerasClient</code> defines three methods that clients need to override.
These methods allow Flower to trigger training and evaluation of the previously defined Keras model:</p><div><article><p>Copy</p><pre><code><span># Define Flower client</span><span>
</span><span></span><span>class</span><span> </span><span>CifarClient</span><span>(</span><span>fl.client.keras_client.KerasClient</span><span>):</span><span>
</span><span>    </span><span>def</span><span> </span><span>get_weights</span><span>(</span><span>self</span><span>):</span><span>
</span><span>        </span><span>return</span><span> model.get_weights()
</span>
<span>    </span><span>def</span><span> </span><span>fit</span><span>(</span><span>self, weights, config</span><span>):</span><span>
</span>        model.set_weights(weights)
<span>        model.fit(x_train, y_train, epochs=</span><span>1</span><span>, batch_size=</span><span>32</span><span>, steps_per_epoch=</span><span>3</span><span>)  </span><span># Remove `steps_per_epoch=3` to train on the full dataset</span><span>
</span><span>        </span><span>return</span><span> model.get_weights(), </span><span>len</span><span>(x_train), </span><span>len</span><span>(x_train)
</span>
<span>    </span><span>def</span><span> </span><span>evaluate</span><span>(</span><span>self, weights, config</span><span>):</span><span>
</span>        model.set_weights(weights)
<!-- -->        loss, accuracy = model.evaluate(x_test, y_test)
<span>        </span><span>return</span><span> </span><span>len</span><span>(x_test), loss, accuracy</span></code></pre></article></div><p>Flower's <code>KerasClient.fit</code> method receives weights from the server, updates the model with those weights, trains the model on the locally held dataset (<code>x_train</code>/<code>y_train</code>), and then returns the updated weights (via <code>model.get_weights</code>).
Note that you can do a quick "dry run" by passing <code>steps_per_epoch=3</code> to <code>model.fit</code> - this will only process three batches per epoch instead of the entire dataset.
Remove <code>steps_per_epoch=3</code> to train on the full dataset (this will take longer).</p><p>The <code>evaluate</code> method works similarly, but it uses the provided weights to evaluate the model on the locally held dataset (<code>x_test</code>/<code>y_test</code>).
The last step is to create an instance of <code>CifarClient</code> and run it:</p><div><article><p>Copy</p><pre><code><span># Start Flower client</span><span>
</span><span>fl.client.start_keras_client(server_address=</span><span>"[::]:8080"</span><span>, client=CifarClient())</span></code></pre></article></div><p>That's it for the client. We create the model, load the data, implement a subclass <code>KerasClient</code>, and start the client. Let's build the server script next.</p><h2>Flower server</h2><p>In a new script called <code>server.py</code>, we add the following two lines to start a Flower server that performs three rounds of <a href="https://arxiv.org/pdf/1602.05629.pdf">Federated Averaging</a>:</p><div><article><p>Copy</p><pre><code><span>import</span><span> flwr </span><span>as</span><span> fl
</span><span>fl.server.start_server(config={</span><span>"num_rounds"</span><span>: </span><span>3</span><span>})</span></code></pre></article></div><p>That's it! We can now run our system. Are we still within our lines of code limit? Lines of code (excluding blank lines or comments): 19 <!-- -->🎉</p><h2>Running the system</h2><p>First, we start the server:</p><p>Next, we open a new terminal and start the first client:</p><p>Finally, we open another new terminal and start the second client:</p><p>This should result in the following output in terminal 2 or 3 (one of those running <code>client.py</code>).
We can see that three rounds of federated learning improve the accuracy to about 46% on the training set and 28% on the test set (if we train on the full dataset, so no <code>steps_per_epoch=3</code>).
There's obviously lots of room for improvement, for example, by doing more rounds of federated learning and by tuning hyperparameters. </p><div><article><p>Copy</p><pre><code><span>DEBUG flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>18</span><span>:</span><span>57</span><span>:</span><span>18</span><span>,</span><span>259</span><span> | connection.py:</span><span>36</span><span> | ChannelConnectivity.IDLE
</span><span>DEBUG flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>18</span><span>:</span><span>57</span><span>:</span><span>18</span><span>,</span><span>260</span><span> | connection.py:</span><span>36</span><span> | ChannelConnectivity.CONNECTING
</span><span>DEBUG flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>18</span><span>:</span><span>57</span><span>:</span><span>18</span><span>,</span><span>261</span><span> | connection.py:</span><span>36</span><span> | ChannelConnectivity.READY
</span><span>INFO flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>18</span><span>:</span><span>57</span><span>:</span><span>18</span><span>,</span><span>261</span><span> | app.py:</span><span>61</span><span> | Opened (insecure) gRPC connection
</span><span></span><span>1563</span><span>/</span><span>1563</span><span> [==============================] - </span><span>123</span><span>s </span><span>79</span><span>ms/step - loss: </span><span>1.8809</span><span> - accuracy: </span><span>0.3158</span><span>
</span><span></span><span>313</span><span>/</span><span>313</span><span> [==============================] - </span><span>6</span><span>s </span><span>21</span><span>ms/step - loss: </span><span>2.3204</span><span> - accuracy: </span><span>0.1000</span><span>
</span><span></span><span>1563</span><span>/</span><span>1563</span><span> [==============================] - </span><span>141</span><span>s </span><span>90</span><span>ms/step - loss: </span><span>1.7094</span><span> - accuracy: </span><span>0.3861</span><span>
</span><span></span><span>313</span><span>/</span><span>313</span><span> [==============================] - </span><span>4</span><span>s </span><span>13</span><span>ms/step - loss: </span><span>2.3337</span><span> - accuracy: </span><span>0.1000</span><span>
</span><span></span><span>1563</span><span>/</span><span>1563</span><span> [==============================] - </span><span>140</span><span>s </span><span>90</span><span>ms/step - loss: </span><span>1.5050</span><span> - accuracy: </span><span>0.4645</span><span>
</span><span></span><span>313</span><span>/</span><span>313</span><span> [==============================] - </span><span>5</span><span>s </span><span>14</span><span>ms/step - loss: </span><span>2.0941</span><span> - accuracy: </span><span>0.2799</span><span>
</span><span>DEBUG flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>19</span><span>:</span><span>04</span><span>:</span><span>30</span><span>,</span><span>284</span><span> | connection.py:</span><span>68</span><span> | Insecure gRPC channel closed
</span><span>INFO flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>19</span><span>:</span><span>04</span><span>:</span><span>30</span><span>,</span><span>284</span><span> | app.py:</span><span>72</span><span> | Disconnect </span><span>and</span><span> shut down</span></code></pre></article></div><p>Congratulations, you have built a running Federated Learning system in less than 20 lines of code!</p><p>The full source code can be found <a href="https://github.com/adap/flower/tree/main/src/py/flwr_example/tensorflow_minimal">here</a>.</p><h2>Next steps</h2><p>Our system is of course simplified in some ways, for example, both clients load the same dataset.
Real-world FL systems would use a different data partition on each client and a lot more clients overall.
Here are a few ideas on what to try next:</p><ul><li>Split CIFAR-10 into two partitions and load one partition on each client</li><li>Start additional clients and see how the server behaves (no coding required, just open more terminals or use a script which starts client processes in the background)</li><li>Try to find better hyperparameters</li><li>Use your own model and/or dataset</li><li><a href="https://flower.dev/docs/strategies.html">Customize the federated learning strategy</a></li></ul><p>We'd be delighed to hear from you!</p><ul><li>Join the Flower community on Slack! -&gt; Button in the top right corner</li><li><a href="https://github.com/adap/flower">Star Flower on GitHub</a></li></ul></div></div></div>]]>
            </description>
            <link>https://flower.dev/blog/2020-12-11-federated-learning-in-less-than-20-lines-of-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387700</guid>
            <pubDate>Fri, 11 Dec 2020 16:44:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paper, Pen and Tools for Thinking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25387504">thread link</a>) | @kawera
<br/>
December 11, 2020 | https://situated.blog/2020/11/tools-for-thinking | <a href="https://web.archive.org/web/*/https://situated.blog/2020/11/tools-for-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><time datetime="2020-11-19T00:00:00+00:00">November 19, 2020</time><blockquote><p>“The art of thinking is grounded in the mind’s astonishing capacity to create beyond what it intends, beyond what it can foresee.” — Theodore Roszak, <a href="https://www.ucpress.edu/book/9780520085848/the-cult-of-information">The Cult of Information</a></p></blockquote><p>Perhaps one of the best habits that I’ve picked up and sustained in 2020 is the art of <a href="https://bulletjournal.com/pages/learn">bullet journaling</a>. Now that I’m a few months in, my journal has since become a trusty sidekick, the daily ritual of its care and feeding now an essential, calming practice. Journaling is how I both start and end my day. It is how I reflect on the activities of the previous week, the highs and lows of the previous month, how I track all of my tasks and todos and remember important events. Writing things down on paper in a structured way has genuinely helped me focus, remember things, think more clearly, maintain other habits, and even pare down my commitments in ways I was never able to achieve with more sophisticated digital tools. And over the years I have tried <em>a lot</em> of digital tools—<a href="https://todoist.com/">todo lists</a>, <a href="https://dayoneapp.com/">journaling apps</a>, <a href="https://www.onenote.com/">notetaking apps</a> and <a href="https://www.notion.so/">apps that transcend these boundaries</a>. I still use these tools, but they have become secondary, playing a supporting role to a <a href="https://www.leuchtturm1917.us/notebook-medium-a5-hardcover-251-numbered-pages-5-3-4-x-8-1-4-in.html">simple, black dotted notebook</a> that has since become the star of my daily routine.</p><p>The allure and promise of so many digital productivity tools is that they purport to be better than the analog tools from which they derive inspiration. In some ways this is true; they offer near-ubiquitous ease of access, better searchability, collaboration support with distant colleagues, protection against data loss, etc. But computational devices—be they laptops, desktops, phones, tablets—remain fairly poor instruments for the act of <em>thinking</em>. In this, nothing seems to top the simplicity of paper and pen.</p><p>There are several reasons for this:</p><ul><li><p>First, paper is <em>approachable</em> in a way that a blank screen is not. It is disposable. It invites mark-making, doodling, folding, crumpling and tossing. Something about the tangiblity of paper feels less intimidating during those tenuous first moments when you’re trying to coax your mind to focus and action. But beyond that it encourages fiddling, which in turn stimulates the mind in a way I haven’t found replicable with digital devices. Without a better way of describing it, paper is simply more human.</p></li><li><p>Second, paper is <em>immediate</em>. There is no machine to power on, no app to find and open. It’s just right there, available and ready to absorb a thought. Assuming you have a pen handy, the number of obstacles you have to overcome from moment you have a thought to recording that thought is essentially zero.</p></li><li><p>Finally, paper encourages <em>focus</em>. It is a single-purpose object without unnecessary distractions. Whether you’re taking notes in a notebook or papering your wall with post-it notes, analog tools create an environment that won’t distract you from the task of thinking. There are no notifications, no icons tempting you to browse the web or check Twitter.</p></li></ul><p>A few days ago I <a href="https://www.youtube.com/watch?v=vrhBaR2fNjQ&amp;feature=youtu.be&amp;ab_channel=TheGeneralist">watched a panel conversation</a> put together by Mario Gabriele of <a href="https://thegeneralist.substack.com/">The Generalist</a> on independent research, tools for thought and internet academia. The conversation opens with the question: “What is your favorite tool for thought?” Several of the panelists respond by sharing favorite analog tools—reams of dot-matrix printer paper, four-color pens, books, post-it notes. When any panelist did share a digital tool—<a href="https://www.are.na/">Are.na</a> or <a href="">Google Scholar</a>, for instance—it was a tool used for purposes of information gathering and organization rather than creating, assembling, drawing, searching for patterns, the hard work of thought.</p><p>Computing just isn’t there yet.</p><p>The devices <a href="https://web.archive.org/web/20141022035044/http://www.ubiq.com/hypertext/weiser/SciAmDraft3.html">Mark Weiser once dreamed about</a> have become reality, with input modalities on par with the expressive fidelity of paper and pen. And perhaps one day we will invent better tools for augmenting thought beyond digital facsimiles of analog solutions. But not without much more investment in this space. Over two decades ago, during the heyday of labs like <a href="https://en.wikipedia.org/wiki/PARC_%28company%29">Xerox PARC</a>, computing tools for thinking, productivity and creativity felt richly explored and researched. Today, the bulk of the tech world has focused on, as <a href="https://twitter.com/_adamwiggins_">Adam Wiggins</a> asserts in the conversation mentioned above, social media, video, search, and other consumer-focused endeavors. The promise of computing to serve human creativity, thought, and productivity feels, these days, somewhat quaint—a whisper of some bygone era lost in a cacophony of services competing for ever-smaller slices of attention.</p><p>There’s a lot of room to innovate, but lately the industry feels like it’s lost all ambition here.</p></article></div></div>]]>
            </description>
            <link>https://situated.blog/2020/11/tools-for-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387504</guid>
            <pubDate>Fri, 11 Dec 2020 16:28:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smash Training Retrospective]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25387356">thread link</a>) | @arxanas
<br/>
December 11, 2020 | https://waleedkhan.name/blog/smash-training-retrospective/ | <a href="https://web.archive.org/web/*/https://waleedkhan.name/blog/smash-training-retrospective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
    <p><a href="https://ssb.fit/"><em>Smash Training</em></a> is a spaced-repetition training web-app I created to help my progression with <em>Super Smash Bros. Ultimate</em>. I released it on May 16, 2020 <a href="https://www.reddit.com/r/CrazyHand/comments/gkybpe/trying_to_get_into_elite_smash_this_quarantine/?utm_source=share&amp;utm_medium=web2x&amp;context=3">on Reddit</a> to warm reception. As of December 2020, it receives 150-200 monthly users. I’d rank it as my most successful project!</p>

<p>In this article, I discuss the choices I made for this project. The source code is available at <a href="https://github.com/arxanas/smashtraining">https://github.com/arxanas/smashtraining</a>.</p>

<ul id="markdown-toc">
  <li><a href="#project-requirements" id="markdown-toc-project-requirements">Project requirements</a></li>
  <li><a href="#domain-name" id="markdown-toc-domain-name">Domain name</a></li>
  <li><a href="#user-studies-and-ui" id="markdown-toc-user-studies-and-ui">User studies and UI</a>    <ul>
      <li><a href="#ui" id="markdown-toc-ui">UI</a></li>
      <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a></li>
    </ul>
  </li>
  <li><a href="#tech-stack" id="markdown-toc-tech-stack">Tech stack</a>    <ul>
      <li><a href="#build-system" id="markdown-toc-build-system">Build system</a></li>
      <li><a href="#typescript" id="markdown-toc-typescript">TypeScript</a></li>
      <li><a href="#vue" id="markdown-toc-vue">Vue</a></li>
      <li><a href="#vuetify" id="markdown-toc-vuetify">Vuetify</a></li>
      <li><a href="#netlify-for-hosting" id="markdown-toc-netlify-for-hosting">Netlify for hosting</a></li>
      <li><a href="#custom-database" id="markdown-toc-custom-database">Custom database</a></li>
      <li><a href="#github-as-a-static-data-store" id="markdown-toc-github-as-a-static-data-store">Github as a static data-store</a></li>
    </ul>
  </li>
  <li><a href="#conclusions" id="markdown-toc-conclusions">Conclusions</a></li>
</ul>

<h2 id="project-requirements">Project requirements</h2>

<p>I decided that I wanted to build a spaced-repetition training app, rather than reuse a general-purpose spaced-repetition flash-card system such as Anki, because the project would benefit from domain-specific knowledge. For example:</p>

<ul>
  <li>Exercises have large numbers of variants, such as “short-hop” vs “full-hop”, or “facing left” vs “facing right”, which should be tracked separately.</li>
  <li>Many of the exercises have natural dependencies on others: they shouldn’t be attempted unless a certain underlying fundamental skill has been mastered.</li>
  <li>Exercises to train one character don’t necessarily confer the same skill for other characters. Some exercises may only be applicable to some characters.</li>
</ul>

<p>I decided to make an app to automate the spaced repetition regimen I was attempting to follow by hand, which I could then share with others.</p>

<p>Here were my engineering requirements:</p>

<ul>
  <li>Should be mobile-first, but preferably also available on desktop.</li>
  <li>Should be local-first, or at least not require creating an account to use.</li>
  <li>Should be architected to support sync between devices, although the sync itself was not a requirement for the first iteration.</li>
  <li>Should have approximately zero hosting costs.</li>
  <li>Should be hosted on of a stable platform which doesn’t require monitoring (e.g. not my home computer).</li>
</ul>

<h2 id="domain-name">Domain name</h2>

<p>I wanted to choose between a permutation like the following for the domain name:</p>

<ul>
  <li>smashtraining.com</li>
  <li>ssbtraining.com</li>
  <li>smash.training</li>
  <li>ssb.training</li>
  <li>smash.fit</li>
  <li>ssb.fit</li>
</ul>

<p>In the end, I used <code>ssb.fit</code> because 1) <code>smash.training</code> got taken (!) and 2) I wanted to optimize for typing it in on a mobile device, even though the name is less memorable. This lack of memorability unfortunately manifested in <a href="https://www.reddit.com/r/CrazyHand/comments/gp9sem/wtf_was_that_smash_training_website_called/frkscwe/?context=3">this Reddit thread titled “WTF was that smash training website called?”</a>. However, another commenter writes “ssb.fit is better, short for mobile”, perhaps vindicating the original choice.</p>

<p>It’s unfortunate that the domain name and the website title don’t exactly match up. Many people seemed to address it as “ssb.fit” hence, so maybe that’s what the project should have been called too (rather than “Smash Training”).</p>

<h2 id="user-studies-and-ui">User studies and UI</h2>

<p>I conducted several user studies with friends and family, including some people who had played Smash before and some who hadn’t.</p>

<h3 id="ui">UI</h3>

<p>The first main thing I iterated on was the design of the exercise tracker widget. I originally based it off of the <em>Stronglifts</em> app:</p>

<figure>
        <a href="https://waleedkhan.name/blog/assets/posts/smash-training-retrospective/stronglifts.png"><img src="https://waleedkhan.name/blog/assets/posts/smash-training-retrospective/stronglifts.png" alt="Advertisement screenshot of the Stronglifts workout app." title="Advertisement screenshot of the Stronglifts workout app."></a>
        <figcaption><p>Advertisement screenshot of the Stronglifts workout app.</p>
</figcaption>
      </figure>

<p><em>Stronglifts</em> has you note down how many repetitions of the exercise you succeeded at (out of five). However, the <em>Smash Training</em> paradigm is different, and has you repeat the exercise for a length of time and rate your accuracy.</p>

<p>I experimented with a “smiley-face” UI rather than a rep-count UI, as in Stronglifts, along with a few other options. After a lot of feedback from friends, I arrived at a slider-based widget like this:</p>

<figure>
        <a href="https://waleedkhan.name/blog/assets/posts/smash-training-retrospective/smash-training-exercise-widget.png"><img src="https://waleedkhan.name/blog/assets/posts/smash-training-retrospective/smash-training-exercise-widget.png" alt="Screenshot of the Smash Training exercise widget." title="Screenshot of the Smash Training exercise widget."></a>
        <figcaption><p>Screenshot of the Smash Training exercise widget.</p>
</figcaption>
      </figure>

<p>This uses a slider approach (with five possible notches), and renders a description of what each notch corresponds to, i.e. “all or nearly all reps correct”.</p>

<h3 id="documentation">Documentation</h3>

<p>The second main thing was the ordering of the elements in the “Learn exercise” page. Each exercise has a step-by-step description of how to do the exercise, what controller inputs must be performed, background on the technique and its importance, a video tutorial, etc.</p>

<p>My assumption was that most people would read very little of it, so I should put the most important items first. However, various users disagreed on which item was the most important. There was no strong consensus, but the end result was this ordering:</p>

<ul>
  <li>Step-by-step exercise description.</li>
  <li>Controller inputs.</li>
  <li>Technique overview.</li>
  <li>The rest of the documentation elements (not as important).</li>
</ul>

<p>There were also hints on these steps such as how to enter the Training Stage to perform the exercises. Some users missed these steps altogether, and were left confused on how to perform the exercise. Unfortunately, I was unable to design a UI that mitigated this problem.</p>

<h2 id="tech-stack">Tech stack</h2>

<p>I chose to write a web-app, since they are cross-platform and I already had some familiarity with the area. In particular, I didn’t want to spend money on an iOS developer license, but I also didn’t want to exclude iOS users. (Post-hoc analytics indicate that the ratio of Android-to-iOS users is about 2:1, which consitutes a significant cohort for iOS.)</p>

<h3 id="build-system">Build system</h3>

<p>All Javascript web-app bundling solutions are fundamentally terrible, and Webpack is no exception. But it works.</p>

<p><a href="https://github.com/arxanas/smashtraining/commit/f621f02af95da697435cb720563b590d57f38b87">I encountered one mysterious bug in Babel during development</a>, which I was unable to isolate. I worked around it by targeting only newer browsers, after which the problem disappeared.</p>

<p>I used <code>vue-cli-service</code> as a wrapper around the build, test, and lint actions, as recommended by Vue. But I found it hard to configure and debug. When I had an issue with tests not properly compiling an imported module, <a href="https://github.com/arxanas/smashtraining/blame/d0c31a33ab880e8c58824c0f58247c8bd8f38485/src/utils.ts#L38-L44">I gave up and reimplemented the function I needed myself</a>.</p>

<h3 id="typescript">TypeScript</h3>

<p>I also used <a href="https://www.typescriptlang.org/">TypeScript</a>, since I find its static typing system useful for maintenance purposes.</p>

<p>TypeScript support for Vue was not ideal. Many Vue patterns are not easy to express in TypeScript. Libraries like <a href="https://github.com/istrib/vuex-typescript"><code>vuex-typescript</code></a> exist, but require a lot of boilerplate in order to get static typing support. The <a href="https://github.com/paroi-tech/direct-vuex"><code>direct-vuex</code></a> library had less boilerplate, but <a href="https://github.com/arxanas/smashtraining/commit/9a8c0c0baf05d048a564b11f62afdfafc9f66a62">I couldn’t figure out how to test it</a>.</p>

<p>TypeScript was generally pleasant to work with, although in the project, I pushed it to its extremes and it was unable to keep pace. In my case, it was unable to track associated/mapped types adequately. It’s perhaps exemplified by this <code>@ts-ignore</code> comment:</p>

<div><div><pre><code><span>export</span> <span>type</span> <span>TechVariantOf</span><span>&lt;</span><span>T</span> <span>extends</span> <span>TechId</span><span>&gt;</span> <span>=</span> <span>{</span>
  <span>// @ts-ignore "Type 'x' cannot be used to index type 'AllTechVariants'."</span>
  <span>// Strangely, the correct type is calculated here anyways, and can be used for</span>
  <span>// exhaustiveness-checking later.</span>
  <span>[</span><span>x</span> <span>in</span> <span>keyof</span> <span>AllTechMetadata</span><span>[</span><span>T</span><span>][</span><span>"</span><span>variants</span><span>"</span><span>]]:</span> <span>AllTechVariants</span><span>[</span><span>x</span><span>];</span>
<span>};</span>
</code></pre></div></div>

<p>I also ran into <a href="https://github.com/microsoft/TypeScript/issues/13215#issuecomment-531632919">this issue</a> when working on the same thing.</p>

<p>Given that this is reasonably advanced type-level hackery, I was generally happy with TypeScript’s ability to describe the data domain.</p>

<h3 id="vue">Vue</h3>

<p>I chose to use <a href="https://vuejs.org/">Vue</a> as the front-end web framework, since I had heard good things about it from <a href="https://news.ycombinator.com/">Hacker News</a>. In particular, I wanted an opinionated framework, so as to spend less time configuring things myself.</p>

<p>When I used it, Vue promoted the <a href="https://vuejs.org/v2/guide/single-file-components.html">“single-file component”</a> system, in which HTML, CSS, and Javascript are mixed into the same file. It was not a great experience:</p>

<ul>
  <li>This complicates the build process, as something has to convert these single-file components into assets consumable by the browser.</li>
  <li>The mental model is an extra layer of indirection, as these single-file components are themselves compiled into Javascript classes, but also contain Javascript classes in the script portion of the file.</li>
  <li>The tooling support was poor. For example, go-to-definition doesn’t work on the HTML components, despite the fact that they’re ultimately backed by Javascript classes.</li>
  <li>TypeScript does not check the HTML components.</li>
</ul>

<p>I would have preferred to use a <a href="https://www.typescriptlang.org/docs/handbook/jsx.html">JSX</a> solution, as it removes some of the indirection and has better tooling support.</p>

<p>I wish Vue had fewer ways to do things. For example, attributes on HTML elements can be set with the normal <code>=</code> syntax, but also with a leading <code>:</code> (expression evaluation) or a leading <code>@</code> (callback) for brevity. In comparison, React with JSX only has <code>=</code> for all of these situations.</p>

<h3 id="vuetify">Vuetify</h3>

<p><a href="https://vuetifyjs.com/">Vuetify</a> is a library to provide Material Design UI for Vue. The presence of a solid, all-in-one Material Design library was one other reason why I chose to use Vue. The library and documentation are both very good, and I was able to prototype my app (from a UI perspective) effectively. I would strongly recommend it if you’re using Vue.</p>

<p><a href="https://github.com/vuetifyjs/vuetify/pull/8877">I opened one pull request</a> for the documentation, which was merged promptly, <a href="https://github.com/vuetifyjs/vuetify/issues/10140">and +1’d one documentation issue</a>, which has a workaround but unfortunately remains unresolved.</p>

<h3 id="netlify-for-hosting">Netlify for hosting</h3>

<p>I used <a href="https://www.netlify.com/">Netlify</a> to host the front-end of the website using its free tier, and stored data locally for the user. This worked well, as Netlify knew how to build and deploy my Vue project, and had good Github integrations.</p>

<p>Another option would have been Github Pages, which would have made the project dependent on fewer underlying services, but also would have required me to write a build step of my own.</p>

<h3 id="custom-database">Custom database</h3>

<p>I stored data locally on the client using the <a href="https://developer.mozilla.org/docs/Web/API/Window/localStorage"><code>localStorage</code> APIs</a>. I was careful to design the data schema such that it was append-only and such that each record had a unique ID, the idea being to make it easy to merge changes from multiple clients. However, this alone makes it difficult to delete records without some more thought.</p>

<p>I later discovered <a href="https://couchdb.apache.org/">CouchDB</a> as a distributed document-store in exactly the manner I had already architected my application, but including sync and delete capabilities. I also discovered the <a href="https://pouchdb.com/">PouchDB</a> library, which exposes a CouchDB interface and allows you to store your data locally or sync it remotely. It also supports more backends than just <code>localStorage</code>.</p>

<p>I wish I had used PouchDB from the beginning! Now I’m stuck with an inefficient, feature-lacking implementation of it, which would …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://waleedkhan.name/blog/smash-training-retrospective/">https://waleedkhan.name/blog/smash-training-retrospective/</a></em></p>]]>
            </description>
            <link>https://waleedkhan.name/blog/smash-training-retrospective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387356</guid>
            <pubDate>Fri, 11 Dec 2020 16:14:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Delight, a free hosted cross-platform Spark UI and Spark History Server]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25387036">thread link</a>) | @jstephan
<br/>
December 11, 2020 | https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server | <a href="https://web.archive.org/web/*/https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>Data Mechanics is a cloud-based Spark platform - an alternative to Databricks, EMR, Dataproc, Azure HDInsight, and so forth - with a focus on making Spark easy-to-use and cost-effective for data engineers. It is deployed on a Kubernetes cluster inside our customers’ cloud account, and adds a lot of <a href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source" target="_blank">features on top of Spark on Kubernetes open source</a>.&nbsp;<br></p><p>But today, we’re not talking about a new feature of our platform.&nbsp;<br></p><p>Today we’re releasing a web-based Spark UI which works on top of any Spark platform, whether it’s on-premise or in the cloud, over Kubernetes or over YARN, with a commercial service or running on open-source Apache Spark.</p><figure id="w-node-88b9c15563c8-19fe54b3"><p><img src="https://uploads-ssl.webflow.com/5e72486289a61e0d8c9dbb56/5fb28b0e04eb4b7fc26fca43_Free%20Hosted%20Spark%20History%20Server.png" loading="lazy" alt=""></p></figure><p>It consists of a dashboard listing your Spark applications after they have finished running, and a hosted Spark History Server that will back the Spark UI for this application at the click of a button. This project is partially open-sourced, and it is entirely free of charge.</p><h2>How Can I Use it?<br></h2><h3>Create an account on <a href="https://delight.datamechanics.co/login" target="_blank">https://delight.datamechanics.co/login</a>.</h3><p>You should use your company’s Google account if you want to share a single dashboard with your colleagues, or your personal Google account if you want the dashboard to be private to you. As of today, you need a Google account to access our dashboard, but additional sign-in methods will be added in the future. Once your account is created, go under Settings and create a personal access token. This will be needed in the next step.<br></p><h3>Attach our open-source agent to your Spark applications.</h3><p>Follow the instructions on our <a href="https://github.com/datamechanics/delight" target="_blank">Github page.</a> We have instructions available for the most common setups of Spark, with instructions for generic spark-submit, and instructions specific to Databricks, EMR, Dataproc, and <a href="https://www.datamechanics.co/apache-spark-on-kubernetes">Spark on Kubernetes</a> using the Spark operator. If you run into an issue, <a href="https://www.datamechanics.co/contact" target="_blank">ask us a question</a>, we’ll be happy to help.</p><figure id="w-node-371025b2e346-19fe54b3"><p><img src="https://uploads-ssl.webflow.com/5e72486289a61e0d8c9dbb56/5fb28c47df3884aa76c86847_Spark%20History%20Server%20%26%20Spark%20UI%20-%20Delight%20Dashboard.png" loading="lazy" alt=""></p></figure><p>Your applications will automatically appear on our dashboard once they complete (successfully or with a failure). Clicking on an application opens up the corresponding Spark UI. That’s it!</p><h2>How Does It Work? Is It Secure?</h2><p>This project consists of two parts:</p><ul role="list"><li>An <a href="https://github.com/datamechanics/delight" target="_blank">open-source</a> Spark agent which runs inside your Spark applications. This agent will stream non-sensitive Spark event logs from your Spark application to our backend.</li><li>A closed-source backend consisting of a real-time logs ingestion pipeline, storage services, a web application, and an authentication layer to make this secure.<br></li></ul><figure id="w-node-6a6ad7bcf1a5-19fe54b3"><p><img src="https://uploads-ssl.webflow.com/5e72486289a61e0d8c9dbb56/5fb2b739e125da142c5bbf46_ezgif.com-gif-maker.png" loading="lazy" alt=""></p></figure><p>The agent collects your Spark applications event logs. This is non-sensitive information about the metadata of your Spark application. For example, for each Spark task there is metadata on memory usage, CPU usage, network traffic (<a href="https://uploads-ssl.webflow.com/5e724862760345325327026c/5fc104251c29738912ed5a94_Sample%20Event%20Log%20Delight.png" target="_blank">view a sample event log</a>). The agent does not record sensitive information such as the data that your Spark applications actually work on. The agent does not collect your application logs either -- as typically they may contain sensitive information.<br></p><p>This data is encrypted using your personal access token and sent over the internet using the HTTPS protocol. This information is then stored securely inside the Data Mechanics control plane behind an authentication layer. Only you and your colleagues from your Google/GSuite organization will be able to see your application in our dashboard. The collected data will automatically be deleted 30 days after your Spark application completion.&nbsp;</p><h2>What’s Next?</h2><p>The release of this free and cross-platform hosted Spark History Server is our first step towards building a Spark UI replacement tool called <a href="https://www.datamechanics.co/delight" target="_blank">Data Mechanics Delight</a>. This will be a free and cross-platform Spark UI replacement with new metrics and visualizations that will "delight" you! Our announcement in June 2020 to build a Spark UI replacement had indeed generated a <a href="https://www.datamechanics.co/blog-post/building-a-better-spark-ui-data-mechanics-delight" target="_blank">lot of interest</a> from the Spark community. We’re targeting the next release for January 2021.</p><figure><p><img src="https://uploads-ssl.webflow.com/5e72486289a61e0d8c9dbb56/5ef23be7c40e3df997a03146_gif4.gif" loading="lazy" alt=""></p></figure><p>We know the current release is far from what Delight fans expect, but we hope it will still be valuable to the Spark community, as the Spark History Server is not always easy to set up. More importantly, the current release means we have built most of the base infrastructure of the project -- the Spark agent, a real-time logs collection pipeline, a storage system, an authentication layer and a webapp. We will now gradually add the new screens and visualizations that the community awaits.<br></p><p>The next release of Delight, scheduled in January 2021, will consist of an overview screen giving a bird’s-eye view of your applications’ performance. Links to specific jobs, stages or executor pages will still take you to the corresponding Spark UI pages until we gradually replace these pages too. If you’d like to be notified when the next release is out, <a href="https://www.datamechanics.co/delight#form" target="_blank">fill out this form</a>.&nbsp;<br></p><p>Our mission at Data Mechanics is to make Spark easier-to-use and more cost-effective for data engineering workloads. We hope this tool will contribute to this goal and prove useful to the Spark community. We’d love your feedback about it!<br></p></div></div></div></div></div><div><div data-w-id="5a5714fb-90d7-002f-5fdc-7fabecb251ba"><h4>Read more</h4><h4>Our Latest Blog Posts<br></h4><p>Learn about company news, product updates, and technology best practices straight from the Data Mechanics engineering team.</p></div><div><div><div role="list"><div role="listitem"><div><a href="https://www.datamechanics.co/blog-post/data-ai-summit-europe-2020-highlights"></a><a href="https://www.datamechanics.co/blog-post/data-ai-summit-europe-2020-highlights"></a><p>Data + AI Summit 2020 Highlights: What’s new for the Apache Spark community? In this article we’ll go over the highlights of the conference, focusing on the new developments which were recently added to Apache Spark or are coming up in the coming months: Spark on Kubernetes, Koalas, Project Zen.</p><p>Tuesday, November 24, 2020</p></div></div><div role="listitem"><div><a href="https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server" aria-current="page"></a><a href="https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server" aria-current="page"></a><p>Today we’re releasing a web-based Spark UI and Spark History Server which work on top of any Spark platform, whether it’s on-premise or in the cloud, over Kubernetes or YARN, with a commercial service or using open-source Apache Spark. This is our first step towards building Data Mechanics Delight - the new and improved Spark UI.</p><p>Monday, November 16, 2020</p></div></div><div role="listitem"><div><a href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source"></a><a href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source"></a><p>How Is Data Mechanics different than running Spark on Kubernetes open-source? In this article, we explain how our platform extends and improves on Spark on Kubernetes to make it easy-to-use, flexible, and cost-effective. We'll go over our intuitive user interfaces, dynamic optimizations, and custom integrations</p><p>Tuesday, November 10, 2020</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387036</guid>
            <pubDate>Fri, 11 Dec 2020 15:50:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubectl Create Pizza]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25387011">thread link</a>) | @cirowrc
<br/>
December 11, 2020 | https://ops.tips/notes/kubernetes-pizza/ | <a href="https://web.archive.org/web/*/https://ops.tips/notes/kubernetes-pizza/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <section itemprop="articleBody">
    <p>Hey,</p>
<p>I recently created a series of articles and videos that goes through the
development of Kubernetes custom resources and controllers (see
<a href="https://gum.co/kubernetes-crds">gum.co/kubernetes-crds</a>), but I missed that
nice catchy example that would showcase what custom resources are all about.</p>
<p>So, why not implement the ultimate missing feature that Kubernetes should have?</p>
<p><img width="300px" src="https://user-images.githubusercontent.com/3574444/101922101-b81fe600-3b9b-11eb-95a3-9a5f2a067997.JPG"></p>
<p><em>tl;dr: see <a href="https://github.com/cirocosta/pizza-controller">https://github.com/cirocosta/pizza-controller</a></em></p>
<h2 id="usage">usage</h2>
<p>First, create a secret with the credit card information (<em>yeah, this is fine,
trust me</em>) to be used during payment:</p>
<div><pre><code data-lang="yaml"><span>kind</span><span>:</span><span> </span><span>Secret</span><span>
</span><span></span><span>apiVersion</span><span>:</span><span> </span><span>v1</span><span>
</span><span></span><span>metadata</span><span>:</span><span>
</span><span>  </span><span>name</span><span>:</span><span> </span><span>credit-card</span><span>
</span><span></span><span>stringData</span><span>:</span><span>
</span><span>  </span><span>number</span><span>:</span><span> </span><span>123343132314232</span><span>
</span><span>  </span><span>expiration</span><span>:</span><span> </span><span>12</span><span>/02</span><span>
</span><span>  </span><span>securityCode</span><span>:</span><span> </span><span>123</span><span>
</span><span>  </span><span>zip</span><span>:</span><span> </span><span>m5d0l2</span><span>
</span></code></pre></div><p>then, create a <code>PizzaCustomer</code>, the representation of <em>you</em>, the customer:</p>
<div><pre><code data-lang="yaml"><span>kind</span><span>:</span><span> </span><span>PizzaCustomer</span><span>
</span><span></span><span>apiVersion</span><span>:</span><span> </span><span>ops.tips/v1alpha1</span><span>
</span><span></span><span>metadata</span><span>:</span><span>
</span><span>  </span><span>name</span><span>:</span><span> </span><span>you</span><span>
</span><span></span><span>spec</span><span>:</span><span>
</span><span>  </span><span>firstName</span><span>:</span><span> </span><span>barack</span><span>
</span><span>  </span><span>lastName</span><span>:</span><span> </span><span>obama</span><span>
</span><span>  </span><span>email</span><span>:</span><span> </span><span>obama@gov.gov</span><span>
</span><span>  </span><span>phone</span><span>:</span><span> </span><span>"31241323"</span><span>
</span><span>  </span><span>streetNumber</span><span>:</span><span> </span><span>"20"</span><span>
</span><span>  </span><span>streetName</span><span>:</span><span> </span><span>King St</span><span>
</span><span>  </span><span>city</span><span>:</span><span> </span><span>Toronto</span><span>
</span><span>  </span><span>state</span><span>:</span><span> </span><span>"ON"</span><span>
</span><span>  </span><span>zip</span><span>:</span><span> </span><span>m5lz8j</span><span>
</span></code></pre></div><p>With the <code>PizzaCustomer</code> object created, we can see what’s the closest store available
for it:</p>
<pre><code data-lang="console">$ kubectl get pizzacustomer

NAME              CLOSEST
you               store-123
</code></pre><p>Looking at the PizzaStore object, we can check out its menu:</p>
<pre><code data-lang="console">$ kubectl get pizzastore store-123 -o yaml

kind: PizzaStore
metadata:
  name: store-123
spec:
  address: |
    51 Niagara St
    Toronto, ON M5V1C3
  id: "10391"
  phone: 416-364-3939
  products:
    - description: Unique Lymon (lemon-lime) flavor, clear, clean and crisp with no caffeine.
      id: 2LSPRITE
      name: Sprite
      size: 2 Litre
</code></pre><p>Knowing what’s available to us, we can place the order:</p>
<div><pre><code data-lang="yaml"><span>kind</span><span>:</span><span> </span><span>PizzaOrder</span><span>
</span><span></span><span>apiVersion</span><span>:</span><span> </span><span>ops.tips/v1</span><span>
</span><span></span><span>metadata</span><span>:</span><span>
</span><span>  </span><span>name</span><span>:</span><span> </span><span>ma-pizza</span><span>
</span><span></span><span>spec</span><span>:</span><span>
</span><span>  </span><span>yeahSurePlaceThisOrder</span><span>:</span><span> </span><span>true</span><span>  </span><span># otherwise, it'll just calculate the price</span><span>
</span><span>  </span><span>storeRef</span><span>:</span><span> </span>{<span>name</span><span>:</span><span> </span><span>store-123}</span><span>
</span><span>  </span><span>customerRef</span><span>:</span><span> </span>{<span>name</span><span>:</span><span> </span><span>you}</span><span>
</span><span>  </span><span>payment</span><span>:</span><span>
</span><span>    </span><span>creditCardSecretRef</span><span>:</span><span> </span>{<span>name</span><span>:</span><span> </span><span>cc}</span><span>
</span><span>  </span><span>items</span><span>:</span><span>
</span><span>    </span>- <span>ticker</span><span>:</span><span> </span><span>10SCREEN</span><span>
</span><span>      </span><span>quantity</span><span>:</span><span> </span><span>1</span><span>
</span></code></pre></div><p>To keep track of what’s going on with your pizza, check out the order’s status:</p>
<pre><code data-lang="console">$ kubectl get pizzaorder ma-pizza

NAME    PRICE      ID                     CONDITION     AGE
order   9.030000   Wlz6HcE6BPlfQNlxDAXa   OrderPlaced   68m
</code></pre><p>and, there we go!</p>
<p><img width="300px" src="https://user-images.githubusercontent.com/3574444/101922114-bb1ad680-3b9b-11eb-8850-5fca08598d2d.JPG"></p>
<h2 id="wait-but-why">wait, but why?</h2>
<p>no no, wait, <strong>why not</strong>?</p>
<p>see, with CI/CD being part of Kubernetes through projects like Argo and Tekton,
where you declare what your pipeline/workflow will be in terms of Kubernetes
resources, we’re now able to get that nice pizza for the team after a
successfull release.</p>
<pre><code>apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: release-
spec:
  entrypoint: pi-tmpl
  templates:
  - name: main
    steps:
      - - name: unit-tests
          template: test
        - name: integration-tests
          template: test
          arguments:
            parameters:
              - name: type
                value: integration
      - - name: release
          template: release
      - - name: get-that-pizza
          template: order-pizza

  - name: order-pizza
    resource:
      action: create      
      manifest: |
        kind: PizzaOrder
        apiVersion: ops.tips/v1
        metadata:
          name: ma-pizza
        spec:
          yeahSurePlaceThisOrder: true
          storeRef: {name: store-123}
          customerRef: {name: you}
          payment:
            creditCardSecretRef: {name: cc}
          items:
            - ticker: 10SCREEN
              quantity: 2
</code></pre><p>i don’t know about you, but that sounds quite right to me <code>¯\_(ツ)_/¯</code></p>
<h2 id="installation">installation</h2>
<p>being a legit Kubernetes custom resource, you install it just like you would
install Tekton, kpack, or anything like that: you submit a manifest that
contains the <code>CustomResourceDefinition</code> objects to Kubernetes, a <code>Deployment</code>
that materializes the controller as a container in a pod, and then … that’s
it!</p>
<pre><code>git clone https://github.com/cirocosta/pizza-controller
cd pizza-controller

kapp deploy -a pizza-controller -f ./config/release.yaml


# OR .. plain old kubectl
#
kubectl apply -f ./config/release.yaml
</code></pre><h2 id="but-thats-dumb">but, that’s dumb</h2>
<p>i disagree</p>
<p>I think it’s a pretty cool example of the concepts behind extending
kubernetes via custom resources, and something that might bring you some
thoughts of ways in which you could bring the
declarative nature of Kubernetes objects plus the level-triggered approach to
controllers to bring to Kubernetes the ability to request external resources.</p>
<p>for instance, projects like <a href="https://crossplane.io/">crossplane</a> give you pretty
much that, except that instead of ordering a pizza, you’re ordering … a
database (or things like that).</p>
<h2 id="whats-next">what’s next?</h2>
<p>are you <em>really</em> into ordering pizza using <code>kubectl</code>?</p>
<p>like, really? are you sure?</p>
<p>here’s what’s missing:</p>
<ul>
<li>well, any .. tests :horse:</li>
<li>order tracking (it’s <code>xml</code>-based - SOAP stuff)</li>
<li>being more flexible with non-canadian folks (it’s currently hardcoded for
Canada, but could easily be changed)</li>
</ul>
<p>at the moment I got my pizza .. development finished :sweat_smile: maybe you’ll
carry it forward? head to <a href="https://github.com/cirocosta/pizza-controller">https://github.com/cirocosta/pizza-controller</a></p>
<h2 id="want-to-know-more">want to know more?</h2>
<p>check out <a href="https://gum.co/kubernetes-crds">https://gum.co/kubernetes-crds</a></p>

  </section>
</article></div>]]>
            </description>
            <link>https://ops.tips/notes/kubernetes-pizza/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387011</guid>
            <pubDate>Fri, 11 Dec 2020 15:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I got to $9.99 MRR after 7 years]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25386872">thread link</a>) | @louisbarclay
<br/>
December 11, 2020 | https://cloak.ist/blog/how-i-got-to-9-99-mrr-after-7-years/ | <a href="https://web.archive.org/web/*/https://cloak.ist/blog/how-i-got-to-9-99-mrr-after-7-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>It's been a really long ride at <a href="http://cloak.ist/">Cloakist</a>.</p><p>I've been through the highest highs, and the lowest lows.</p><p>But now, looking back on it all, with $9.99 coming into my bank account every month <em>just like clockwork</em>, I can definitively say:</p><p>It's all been worth it.</p><p>Here is the story of how I managed to turn 7 years of my life into cold, hard cash.</p><p>And not just any amount of cash.</p><p>$9.99 so far.</p><h2 id="you-can-t-succeed-without-starting">You can't succeed without starting</h2><p>7 years ago, I was just another incredibly privileged highly-skilled software developer whose parents can support him indefinitely meaning he doesn't have to get a proper job and can risk it all on starting a business, even though his Uncle Les offered him a good, stable living as a junior accountant at his firm, as his mum never goddamn stops reminding him.</p><p>Today, I am the CEO of a successful startup.</p><p>How did I get there?</p><p>It's simple.</p><p>I started.</p><p>One day, I woke up and navigated to <a href="https://godaddy.com/">GoDaddy.com</a>.</p><p>You might not have heard of it if you aren't a software developer.</p><p>It's a place you go to buy startup websites.</p><p>It's really that simple. You think of a name, and then you go there and type it in.</p><p>In <em>seconds, </em>you'll have results showing you whether your name is available.</p><p>For me, it took a few tries to get it right. I started off trying <code>business.com</code> Â&nbsp;because I wanted my business to have a name that made it clear that it was a business.</p><p>But it was already taken.</p><p>So I moved onto <code>company.com</code>. That was taken too.</p><p>Eventually I landed on https://cloak.ist.</p><p>The journey had started.</p><h2 id="the-long-hard-slog">The long hard slog</h2><p>But boy, it was one hell of a journey.</p><p>This is where another key startup concept comes in:</p><p><em>The pivot.</em></p><p>I wasn't always banking hot, fresh Benjamins from selling custom domains as a service, like I do now.</p><p>I went through 365 different products <em>a year</em> before I settled on custom domains.</p><p>You might be thinking 'Huh, strange â€“ that's the exact number of days in a year'.</p><p>You've hit the nail on the head. Cloakist started off by offering NCaaS.</p><p>Neighborhood-Chores-as-a-service.</p><p>They say you should start with a problem that you see in real life.</p><p>Well, in my mum's neighborhood, I saw hundreds of problems.</p><p>And there were people willing to pay for <em>all of them!</em></p><p>There was Mr Baxter, whose toilet got blocked by his cat. That was a particularly hard pivot to make.</p><p>There were many, many clients in the plus-age category who needed ambulatory assistance with regards to pedestrian activity.</p><p>In other words, they needed help crossing the road.</p><p>And there was teaching coding to the kids at the local primary school, until the bullying became too much for me to handle.</p><p>But here's why none of those NCaaS offerings could ever have worked:</p><p><em>I wasn't getting recurring revenue.</em></p><p>None of my customers came back for a second time.</p><p>It wasn't anything to do with me. I know this because my mum told me so. It was that the products I was offering weren't sticky enough.</p><p>I wanted â€“ I <em>craved â€“ </em>my Stripe account filling up with money every month <em>without me even having to do anything!</em></p><h2 id="sometimes-your-customer-is-right-under-your-nose">Sometimes your customer is right under your nose</h2><p>I still remember how it happened.</p><p>I had spent another night cranking on code in my mum's basement.</p><p>I came up to get some orange juice from the fridge.</p><p>A shoe came hurtling through the air at my computer, which fell and smashed on the ground. I lost all my code, because for 7 whole years I'd never figured out a way to back it up.</p><p>"You lazy, no-good piece of crap!"</p><p>My mum was angry.</p><p>I'd never <em>seen </em>her this angry.</p><p>I knew something had to change. And I got this twinkle in my eye.</p><p>"Mum, do you need a custom domain for one of your public sites like Notion, Trello, Airtable, or anything else?"</p><p>I'd found my first customer.</p><h2 id="the-negotiation">The negotiation</h2><p>But boy, did she fight me on it.</p><p>I started off asking for $100 a month, to try and recoup some of the costs of working for nothing for 7 years.</p><p>My mum wasn't having it. She didn't understand what a custom domain was, and she didn't understand what a public site was.</p><p>That severely limited the amount she was willing to pay for my solution.</p><p>I offered $50/m. She said no.</p><p>I offered $20/m. She went to take out the trash. And when she came back, she still said no.</p><p>Finally, I offered $10/m. And...</p><p>She said $9.99.</p><p>And I said...</p><p>"HELL YES!"</p><p>We both started crying.</p><p>Me, out of joy.</p><p>Her, I think out of sadness for what I am and what I've become.</p><p>But still â€“ it was raw, unfettered emotion.</p><p>The MRR had started to pour in.</p><p>And who cares if it's tied to other conditions, like me moving out and promising to think again about Uncle Les's accounting firm.</p><p>MRR is MRR. It's as simple as that.</p><h2 id="it-doesn-t-stop-there">It doesn't stop there</h2><p>The crazy thing about where I've got to now is how much momentum I'm feeling.</p><p>Next month, if all goes well, it's looking like I'll have $19.98 in my bank account.</p><p>The month after that, $29.97.</p><p>Because that's how momentum works.</p><p>Once you get it started, it just keeps going on its own.</p><p>Here's to the next 7 years!</p><hr><p>Thank you so much for reading.</p><p>Give yourself a congratulations: you've just completed Startup Lesson 101: How To Succeed.</p><p>If you'd like to enrol in further classes, feel free to <a href="https://twitter.com/louisbarclay">follow me on Twitter</a>.</p><p>And if you'd like to read a true, but much more boring story about getting MRR, go <a href="https://cloak.ist/blog/how-we-got-to-400-mrr-in-5-months/">here</a>.</p>
</div></div>]]>
            </description>
            <link>https://cloak.ist/blog/how-i-got-to-9-99-mrr-after-7-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25386872</guid>
            <pubDate>Fri, 11 Dec 2020 15:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Rust's dbg! in Python]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25386358">thread link</a>) | @soopurman
<br/>
December 11, 2020 | https://rtpg.co/2020/12/11/dbg-in-python.html | <a href="https://web.archive.org/web/*/https://rtpg.co/2020/12/11/dbg-in-python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Rust has an <a href="https://doc.rust-lang.org/edition-guide/rust-next/dbg-macro.html">amazing dbg macro</a> that lets you quickly set up an expression printer that will also put in the source line. It also returns the value of the expression so you can even easily inline the printing when you want to! </p>
<div><pre><span></span><code><span>let</span><span> </span><span>a</span><span> </span><span>=</span><span> </span><span>2</span><span>;</span><span></span>
<span>let</span><span> </span><span>b</span><span> </span><span>=</span><span> </span><span>dbg!</span><span>(</span><span>a</span><span> </span><span>*</span><span> </span><span>2</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>;</span><span></span>
<span>//      ^-- prints: [src/main.rs:2] a * 2 = 4</span>
<span>assert_eq!</span><span>(</span><span>b</span><span>,</span><span> </span><span>5</span><span>);</span><span></span>
</code></pre></div>

<p>Doing a bunch of Python, I <em>want this</em> in Python as well. I want a debug macro, one that gives me the file location + the expression used to calculate the value.</p>
<p>My <em>ideal</em> would be to have a function where <code>dbg(foo.bar[1])</code> that would:</p>
<ul>
<li>print <code>[source line] foo.bar[1] = &lt;the value&gt;</code></li>
<li>return the value so we can use it within expressions easily</li>
</ul>
<p>When doing this by hand I always reach for <code>f</code>-strings, to do something like:</p>
<div><pre><span></span><code><span>print</span><span>(</span><span>f</span><span>"foo.bar[1]=</span><span>{</span><span>foo</span><span>.</span><span>bar</span><span>[</span><span>1</span><span>]</span><span>}</span><span>"</span><span>)</span>
</code></pre></div>

<p>This is annoying because you end up typing the same expression twice, you can't inline it, and it just doesn't look very cool.</p>
<p>The first thing when trying to implement this is to come to terms with Python's lack of macros. You can't really mess with the syntax tree, so you're really only operating on calculated values. So it's really hard to capture an expression <em>and its result</em> in a single operation because, well, your expressions get evaluated.</p>
<p>So it'll be hard, to print <code>some_expr = &lt;result of some_expr&gt;</code> without providing the string of <code>some_expr</code> at one point.</p>
<p><em>However</em>, thanks to <code>eval</code>, you can flip this idea on its head. You <em>need</em> the string for the expression, but you don't need the expression itself!</p>
<div><pre><span></span><code><span>foo</span> <span>=</span> <span>{</span>
    <span>'bar'</span><span>:</span> <span>3</span>
<span>}</span>
<span>print</span><span>(</span><span>eval</span><span>(</span><span>"foo['bar'[]"</span><span>))</span> <span># prints 3</span>
</code></pre></div>

<p>One step backwards, let's now go two steps forward. We can start writing our <code>dbg</code> helper function</p>
<div><pre><span></span><code><span>foo</span> <span>=</span> <span>{</span>
    <span>"bar"</span><span>:</span> <span>3</span>
<span>}</span>

<span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span>result</span> <span>=</span> <span>eval</span><span>(</span><span>expr</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>

<span>dbg</span><span>(</span><span>"foo['bar']"</span><span>)</span>  <span># foo['bar'] = 3</span>
</code></pre></div>

<p>So far so good, we have a nice pretty printer here at the cost of two quotation marks.</p>
<p>Of course this doesn't work perfectly:</p>
<div><pre><span></span><code><span>expr</span> <span>=</span> <span>5</span>
<span>dbg</span><span>(</span><span>"expr"</span><span>)</span> <span># expr = expr</span>
</code></pre></div>

<p>Turns out that when calling <code>eval</code> without arguments we are evaluating <em>within the scope of <code>dbg</code></em>. Our examples work because <code>dbg</code> is defined alongside our expressions (so <code>foo</code> is accessible within <code>dbg</code>) but it's susceptible to name shadowing or outright not being able to calculate the expression because it could be defined in a different scope</p>
<div><pre><span></span><code><span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span># we're calculating the result here....</span>
    <span>result</span> <span>=</span> <span>eval</span><span>(</span><span>expr</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>

<span># but actually want to calculate</span>
<span># the result within this scope</span>
<span>dbg</span><span>(</span><span>"expr"</span><span>)</span>
</code></pre></div>

<p><code>eval</code> by default will evaluate the expression within the current frame. But we can pass in our own globals and locals to instead evaluate the expression within an arbitrary environment</p>
<div><pre><span></span><code><span>x</span> <span>=</span> <span>3</span>
<span>print</span><span>(</span><span>eval</span><span>(</span><span>"x"</span><span>,</span> <span>{</span><span>"x"</span><span>:</span> <span>4</span><span>}))</span> <span># gives 4</span>
</code></pre></div>

<p>So let's reproduce the caller's environment to get us the right results. Enter <a href="https://docs.python.org/3/library/inspect.html"><code>inspect</code></a>:</p>
<blockquote>
<p>There are four main kinds of services provided by this module: type checking, <em>getting source code</em>, inspecting classes and functions, and <em>examining the interpreter stack</em>.</p>
</blockquote>
<p>Let's try out <code>inspect.stack()</code></p>
<div><pre><span></span><code><span>import</span> <span>inspect</span>

<span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span>print</span><span>(</span><span>inspect</span><span>.</span><span>stack</span><span>()[</span><span>0</span><span>]</span><span>.</span><span>code_context</span><span>)</span>
    <span>result</span> <span>=</span> <span>eval</span><span>(</span><span>expr</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>result</span>

<span>dbg</span><span>(</span><span>"foo['bar']"</span><span>)</span>

<span>expr</span> <span>=</span> <span>5</span>

<span>dbg</span><span>(</span><span>"expr"</span><span>)</span>

<span>if</span> <span>dbg</span><span>(</span><span>"True"</span><span>):</span>
    <span>print</span><span>(</span><span>"Passed"</span><span>)</span>
</code></pre></div>

<p>trying this out, we get the following:</p>
<div><pre><span></span><code><span>[</span><span>'    print(inspect.stack()[0].code_context)</span><span>\n</span><span>'</span><span>]</span>
<span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>'    print(inspect.stack()[0].code_context)</span><span>\n</span><span>'</span><span>]</span>
<span>expr</span> <span>=</span> <span>expr</span>
<span>[</span><span>'    print(inspect.stack()[0].code_context)</span><span>\n</span><span>'</span><span>]</span>
<span>True</span> <span>=</span> <span>True</span>
<span>Passed</span>
</code></pre></div>

<p>Since this is in a function call we'll actually need to go up the stack one frame (<code>inspect.stack()[1]</code>) to get the proper line:</p>
<div><pre><span></span><code><span>[</span><span>'dbg("foo[</span><span>\'</span><span>bar</span><span>\'</span><span>]")</span><span>\n</span><span>'</span><span>]</span>
<span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>'dbg("expr")</span><span>\n</span><span>'</span><span>]</span>
<span>expr</span> <span>=</span> <span>expr</span>
<span>[</span><span>'if dbg("True"):</span><span>\n</span><span>'</span><span>]</span>
<span>True</span> <span>=</span> <span>True</span>
<span>Passed</span>
</code></pre></div>

<p>OK, now we are getting closer to where we need. the second element in our stack is where we'll also get the file path and the line number. Let's clean this up a bit and now we get:</p>
<div><pre><span></span><code><span>[</span><span>/</span><span>home</span><span>/</span><span>rtpg</span><span>/</span><span>proj</span><span>/</span><span>configfiles</span><span>/</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>21</span><span>]</span> <span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>/</span><span>home</span><span>/</span><span>rtpg</span><span>/</span><span>proj</span><span>/</span><span>configfiles</span><span>/</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>25</span><span>]</span> <span>expr</span> <span>=</span> <span>expr</span>
<span>[</span><span>/</span><span>home</span><span>/</span><span>rtpg</span><span>/</span><span>proj</span><span>/</span><span>configfiles</span><span>/</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>27</span><span>]</span> <span>True</span> <span>=</span> <span>True</span>
</code></pre></div>

<p>Here we have the full file path... one might do a trick here to stick with the file name:</p>
<div><pre><span></span><code><span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span>frame</span> <span>=</span> <span>inspect</span><span>.</span><span>stack</span><span>()[</span><span>1</span><span>]</span><span>.</span><span>frame</span>
    <span>filename</span> <span>=</span> <span>frame</span><span>.</span><span>filename</span><span>.</span><span>split</span><span>(</span><span>"/"</span><span>)[</span><span>-</span><span>1</span><span>]</span>
    <span>print</span><span>(</span><span>f</span><span>"[</span><span>{</span><span>filename</span><span>}</span><span>: </span><span>{</span><span>frame</span><span>.</span><span>lineno</span><span>}</span><span>] </span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>result</span>
</code></pre></div>

<p>OK so with this we end up with the following nice printed output</p>
<div><pre><span></span><code><span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>21</span><span>]</span> <span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>25</span><span>]</span> <span>expr</span> <span>=</span> <span>expr</span>
<span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>27</span><span>]</span> <span>True</span> <span>=</span> <span>True</span>
</code></pre></div>

<p>OK so this is good on the formatting. But we still haven't fixed <code>eval</code>! That's a tiny fix this:</p>
<div><pre><span></span><code><span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span>frame</span> <span>=</span> <span>inspect</span><span>.</span><span>stack</span><span>()[</span><span>1</span><span>]</span><span>.</span><span>frame</span>
    <span>result</span> <span>=</span> <span>eval</span><span>(</span><span>expr</span><span>,</span> <span>frame</span><span>.</span><span>f_globals</span><span>,</span> <span>frame</span><span>.</span><span>f_locals</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>result</span>
</code></pre></div>

<p>This gets us the right values, properly evaluating <code>expr</code> from the calling scope instead of <code>dbg</code>:</p>
<div><pre><span></span><code><span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>21</span><span>]</span> <span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>25</span><span>]</span> <span>expr</span> <span>=</span> <span>5</span> 
<span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>27</span><span>]</span> <span>True</span> <span>=</span> <span>True</span>
</code></pre></div>

<p>The <code>f_globals</code> and <code>f_locals</code> on the frames is still one of my favorite Python features. It lets basically anyone write very good debugging tools without having to do a bunch of magic.</p>
<p>As an added bonus, if you're an IPython user you can add this to <a href="https://switowski.com/blog/ipython-startup-files">a startup script</a>  over in <code>~/.ipython/profile_default/</code> and make this available in any interactive shell.</p>
<p>For those who value silly things like correctness, performance, and intellectual integrity your journey ends here. This is a nice little helper that you can use in your projects, and there's nothing else for you to see here.</p>
<p>For those who like to live dangerously, I have something to show you.....</p>
<p>



So.</p>
<p>Inside the frame, we have a bunch of information, but one thing that's pretty nice for explorative debugging is the <code>code_context</code></p>
<div><pre><span></span><code><span>print</span><span>(</span><span>frame</span><span>.</span><span>code_context</span><span>[</span><span>0</span><span>])</span>
<span># prints dbg('foo["bar"]')</span>
</code></pre></div>

<p>So we actually have the source line from the <code>dbg</code> call built in!</p>
<p>Let's imagine going back a bit to our "idealized" debug function:</p>


<p>Now, if we ran such a function, the body would receive the <em>value</em> of <code>foo['bar']</code> and not the expression. <em>But</em> thanks to the stack we could theoretically recover the original expression! </p>
<p>This gets a bit tricker if you want to do more clever stuff like:</p>
<div><pre><span></span><code><span>if</span> <span>dbg</span><span>(</span><span>my_func</span><span>(</span><span>3</span><span>,</span> <span>foo</span><span>[</span><span>"bar"</span><span>]</span> <span>+</span> <span>"()"</span><span>)))</span> <span>==</span> <span>5</span><span>:</span>
   <span>do_stuff</span><span>()</span>
</code></pre></div>

<p>But let's try to work this out from first principles a bit.</p>
<p>If you have the source code line with the <code>dbg</code> call, how can you recover the expression being debugged?</p>
<p>The first thing is just to find the beginning of the expression. That's pretty easy, just look for <code>dbg(</code></p>
<div><pre><span></span><code>if dbg(my_func(3, foo["bar"] + "()")) == 5:
   ^^^^
</code></pre></div>

<p>So we find the beginning of the expression, right? And since a function call in Python is an open parentheses, some expressions, then a close parentheses, we just have to find the close parentheses and we have the string fragment representing our expression. Let's apply the logic here:</p>
<div><pre><span></span><code>if dbg(my_func(3, foo["bar"] + "()")) == 5:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
</code></pre></div>

<p>Great! Our expression is <code>my_func(3, foo["bar"] + "(</code>. Definitely what we wanted. Yep.</p>
<p>This is one of those things where the only way to parse out an expression is to actually parse it out. Simple string matching won't cut it, especially when you start getting inner function calls in the mix.</p>
<p>You could write a simple parser, try and count parens, open quotes, escaping in quotes, all the fun little games. But honestly I want a thing that works, and I don't want to think about it too hard.</p>
<p>I just want to find out where the expression is in this string.</p>
<p>So here's my amazing plan to deal with this:</p>
<div><pre><span></span><code><span>ast</span><span>.</span><span>parse</span><span>(</span><span>'my_func(3, foo["bar"] + "()")) == 5:'</span><span>)</span>
<span># fails</span>
<span>ast</span><span>.</span><span>parse</span><span>(</span><span>'my_func(3, foo["bar"] + "()")) == 5'</span><span>)</span>
<span># fails</span>
<span>ast</span><span>.</span><span>parse</span><span>(</span><span>'my_func(3, foo["bar"] + "()")) == '</span><span>)</span>
<span># fails</span>
<span>...</span>
<span>ast</span><span>.</span><span>parse</span><span>(</span><span>'my_func(3, foo["bar"] + "()")'</span><span>)</span>
<span># doesn't fail =&gt; I have my expression!</span>
</code></pre></div>

<p>I just start with the longest possible string, and slowly shrink it until I find something that looks like an expression. Because the <code>)</code> from the debug call imbalances everything I'm like... 80% sure that this way of finding the expression is correct.</p>
<p>There are some edge cases that make this strategy not work. For example if you do something like:</p>


<p>You have two <code>dbg</code>s on the same line, so it's hard to know <em>which</em> call you're in, because you're only provided the line number. (On some other project I spent a lot of time hand-wringing on this exact problem and could not find a solution, even with tricks like counting executions. I'm fairly convinced this is equivalent to the halting problem somehow)</p>
<p>And to be honest my solution here isn't battle-tested, it just feels right and works with the complicated expressions I've thrown at it. But it was a fun thing to write and now the following works:</p>
<div><pre><span></span><code><span>dbg</span><span>(</span><span>foo</span><span>[</span><span>"bar"</span><span>])</span>
<span># [pyhelpers.py: 49] foo["bar"] = 3</span>

<span>if</span> <span>dbg</span><span>(</span><span>my_func</span><span>(</span><span>3</span><span>,</span> <span>foo</span><span>[</span><span>"bar"</span><span>]</span> <span>+</span> <span>"()"</span><span>))</span> <span>==</span> <span>5</span><span>:</span>
<span># [pyhelpers.py: 52] my_func(3, foo["bar"] + "()") = 5</span>
    <span>print</span><span>(</span><span>"Success"</span><span>)</span>
</code></pre></div>

<p>No more stringifying silliness, no more calls to <code>eval</code>, just a really silly parsing hack that has no real foundation except my gut feeling. </p>
<p>Good enough for me!</p>
<p>the final implemetaion is below:</p>
<div><pre><span></span><code><span>def</span> <span>dbg</span><span>(</span><span>result</span><span>):</span>
    <span>"""</span>
<span>    Recover the expression giving the result, and then</span>
<span>    print a helpful debug statement showing this</span>
<span>    """</span>
    <span>frame</span> <span>=</span> <span>inspect</span><span>.</span><span>stack</span><span>()[</span><span>1</span><span>]</span>
    <span>expr</span> <span>=</span> <span>extract_dbg</span><span>(</span><span>frame</span><span>.</span><span>code_context</span><span>[</span><span>0</span><span>])</span>
    <span>filename</span> <span>=</span> <span>frame</span><span>.</span><span>filename</span><span>.</span><span>split</span><span>(</span><span>"/"</span><span>)[</span><span>-</span><span>1</span><span>]</span>
    <span>print</span><span>(</span><span>f</span><span>"[</span><span>{</span><span>filename</span><span>}</span><span>: </span><span>{</span><span>frame</span><span>.</span><span>lineno</span><span>}</span><span>] </span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>result</span>

<span>def</span> <span>extract_dbg</span><span>(</span><span>code_fragment</span><span>):</span>
    <span># from a line of source text, try and find the expression </span>
    <span># given to a call to dbg</span>
    <span>expression_options</span> <span>=</span> <span>code_fragment</span><span>.</span><span>split</span><span>(</span><span>"dbg("</span><span>)</span>
    <span>if</span> <span>len</span><span>(</span><span>expression_options</span><span>)</span> <span>!=</span> <span>2</span><span>:</span>
        <span># if there are either multiple dbg statements</span>
        <span># or I can't find the dbg line, bail</span>
        <span>return</span> <span>"???"</span>
    <span># get the part to the right of dbg(</span>
    <span>expr_candidate</span> <span>=</span> <span>expression_options</span><span>[</span><span>1</span><span>]</span>
    <span>while</span> <span>expr_candidate</span><span>:</span>
        <span>try</span><span>:</span>
            <span>ast</span><span>.</span><span>parse</span><span>(</span><span>expr_candidate</span><span>)</span>
            <span>return</span> <span>expr_candidate</span>
        <span>except</span> <span>SyntaxError</span><span>:</span>
            <span>expr_candidate</span> <span>=</span> <span>expr_candidate</span><span>[:</span><span>-</span><span>1</span><span>]</span>
    <span># …</span></code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rtpg.co/2020/12/11/dbg-in-python.html">https://rtpg.co/2020/12/11/dbg-in-python.html</a></em></p>]]>
            </description>
            <link>https://rtpg.co/2020/12/11/dbg-in-python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25386358</guid>
            <pubDate>Fri, 11 Dec 2020 14:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rugpullindex.com, the first decentralized dataset index in the world]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25385834">thread link</a>) | @timdaub
<br/>
December 11, 2020 | https://timdaub.github.io/2020/12/11/rugpullindex/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/12/11/rugpullindex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <h2 id="tldr">TL;DR</h2>
<p><strong>TL;DR:</strong> I built a financial index that <strong>rates data sets</strong> by their markets' performance (<strong>liquidity</strong> and <strong>equality of liquidity shares</strong>). <strong>Check out the <a target="_blank" rel="noopener" href="https://rugpullindex.com/">website</a></strong> and the minimalistic <a target="_blank" rel="noopener" href="https://rugpullindex.com/changelog.txt">blog</a>, or keep on reading the article.</p>
<p><img src="https://timdaub.github.io/assets/images/rugpullindex.png" alt="A screenshot of the
rugpullindex.com website"></p>
<h2 id="why-building-a-data-set-index">Why Building a Data Set Index?</h2>
<p><strong>Would you pay a stranger on the internet</strong> to buy a data set they're offering without knowing them or ever having seen the data? Tough decision! But that's precisely the type of situation <a target="_blank" rel="noopener" href="https://oceanprotocol.com/">Ocean Protocol</a> users face in its newly-launched decentralized <a target="_blank" rel="noopener" href="https://market.oceanprotocol.com/">data set market</a> [3].</p>
<p>I'll spare you most of the details of how it all works and say this: 2020's most transforming technology has been <strong>on-chain markets</strong>. In particular, the implementation that <a target="_blank" rel="noopener" href="https://uniswap.org/">uniswap.org</a> is using called <strong>automated market makers</strong>.</p>
<p>Simply put, they work by incentivizing users to <em>pool</em> a pair of assets at a ratio they deem as the assets' current prices. These users, I herein call them <strong>liquidity providers</strong>, e.g., pool 1 ETH and 540 USDC, so that when a buyer of either asset comes along, they can immediately trade 1 ETH for 540 USDC or 540 USDC for 1 ETH. This principle works fantastically at scale, as the pool incentivizes liquidity-providing by charging buyers and sellers a small fee, which is distributed by the pool to each liquidity provider, respectively [1].</p>
<p><img src="https://timdaub.github.io/assets/images/marketmakers.png"></p>
<p>This model has been so successful that there've been days where decentralized trading on Uniswap outperformed volumes on Coinbase! Which, of course, has lots of implications on the cryptocurrency space. I think it's no overstatement to say that automated market makers may be <strong>the killer app for crypto</strong>.</p>

<p>But there's one implication I've been particularly keen on exploring: all <strong>the openly-accessible data produced by on-chain markets</strong>. See, if you ever tried building a trading bot, you'll have noticed the terrible resolution publicly-available market data has. You might have also noticed that it's quite difficult even to find data at all. It's not by accident. <strong>Trading data is valuable</strong>.</p>
<h2 id="rating-a-data-set-by-its-markets-performance">Rating a Data Set by its Market's Performance</h2>
<p>Remember when I asked you at the beginning of this article about <strong>buying a data set from a random stranger on the internet?</strong> Well, it turns out that Ocean Protocol is now betting on the same technology that made Uniswap successful. They allow users to publish a data set, along with a fungible <strong>data token</strong> and an integrated <strong>automated market maker</strong>. Meaning, you can now buy access to a data set by purchasing tokens. These tokens get priced by liquidity providers providing a ratio of OCEAN Tokens to <em>data tokens</em>.</p>
<p>However, just because data sets are now available for sale on the market, doesn't mean you know they're valuable! After all, if ebay.com didn't have a rating system for sellers, how would you know which seller to trust?</p>
<p>On ebay.com, you know which seller to trust because you can see how many articles they've sold and what each buyer's experience was. It's a simple identity-based rating system.</p>
<p>But within the anarchistic world of cryptocurrencies, there are no working identity-based rating systems! Instead, the space is filled with <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Sock_puppet_account">sock puppets</a> and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Sybil_attack">sybils</a>. <strong>Then, without buying a data set first, how are we supposed to know if a data set is valuable or an outright scam?</strong></p>
<h2 id="introducing-rugpullindex.com">Introducing rugpullindex.com</h2>
<p>That's where <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a> comes into play. <strong>We crawl all of Ocean Protocol's data token pools daily</strong> and rate each market's liquidity provider distribution by its equality using the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gini_coefficient">Gini coefficient</a>. While ranking markets based on their liquidity is common industry-practice, calculating a Gini score for each market's liquidity provider shares isn't. The idea behind this is that the more liquidity providers with an equal share back an asset in the market, the less likely it is for a "rug pull" attack to happen (details <a target="_blank" rel="noopener" href="https://github.com/oceanprotocol/multi-repo-issue/issues/30#issuecomment-726132174">here</a>). By factoring in a pool's relative liquidity, it allows us to derive a score <span><span><math><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span></span> that is <span><span><math><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>s</mi><mo>&lt;</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">0 &lt; s &lt; 100</annotation></semantics></math></span></span>.</p>
<p>For users of <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a>, this <strong>yields a few attractive benefits</strong>:</p>
<ol type="1">
<li>They can now choose to adjust their data set investments based on market data.</li>
<li>They can decide to invest in data sets relative to their performance on to <em>increase their diversivication and hence lower their exposure risk</em>. And finally;</li>
<li>If they're unsure about <strong>sending a random stranger on the internet money for a data set</strong>, they can check out the data set's market performance to make an informed decision.</li>
</ol>
<p>It's a widely-known fact that index-based investment yields superior results compared to stock picking [2]. The same is true when <em>investing</em> in data, which makes me excited about working on this project.</p>
<h2 id="what-does-the-future-hold">What Does The Future Hold?</h2>
<p>I have many ideas for <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a> and not as much time as I'd like to have. However, my overarching goal is to make the ranking so reliable that I can build a smart contract-based index fund on top of it.</p>
<p>I think that rating assets based on their markets' performance is valuable occupation in itself. Not only within the data set market but beyond. I'm particularly interested in rating a wide range of on-chain asset markets, but I'm also thinking about rating more on-chain intellectual property markets. I'm eager to crawl more data and explore. Until then, I hope you're having fun using <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a>.</p>
<p><em><strong>If you have questions, feedback, or business inquiries, please contact me: tim@daubenschuetz.de</strong>. If you want to follow along by building journey, <strong>please subscribe to my newsletter at the end of the page!</strong></em></p>
<h2 id="references">References</h2>
<ul>
<li>1: <a target="_blank" rel="noopener" href="https://ethresear.ch/t/improving-front-running-resistance-of-x-y-k-market-makers/1281">Ethresearch: Improving front running resistance of x*y=k market makers</a></li>
<li>2: KAHNEMAN, Daniel. Thinking, fast and slow. Macmillan, 2011.</li>
<li>3: <a target="_blank" rel="noopener" href="https://blog.oceanprotocol.com/oceans-on-ethereum-mainnet-ba9be1aee0ce">Ocean’s on Ethereum Mainnet</a></li>
</ul>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/12/11/rugpullindex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25385834</guid>
            <pubDate>Fri, 11 Dec 2020 14:03:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nietzsche on Truth and Lie (1991)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25385213">thread link</a>) | @chordalkeyboard
<br/>
December 11, 2020 | http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/ | <a href="https://web.archive.org/web/*/http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Last updated: 04 November 2020</p>
<p><strong>Download: </strong><a href="http://rickroderick.org/download/1991%20Nietzsche%20and%20the%20Post-Modern%20Condition/2%20-%20Nietzsche%20on%20Truth%20and%20Lie.mov">Nietzsche and the Post-Modern Condition (1991) Lecture 2: Nietzsche on Truth and Lie.mov</a></p>

<p><strong>Transcript: </strong>Lecture two will attempt to answer one of the paradoxes I raised in the first lecture – and this will be a specific form of it – and that’s a rather famous charge in philosophy. In fact this is the charge of relativism and one of the things that professional philosophers do in order to display their professional credentials is to respond to the relativist and to the sceptic. Nietzsche has been accused of being a relativist. One form of this accusation is a kind of mislabelling – in my opinion it’s a mislabelling – of Nietzsche’s view about the function of truth and lie. He opposes that to true and false. Truth and lie. The function of that within philosophical discourse. He has an account of that we are going to discuss. <span id="more-53"></span></p>
<p>One of the ways that philosophers have mislabelled this position is “perspectivism”, and the reason I hate that label is like “relativism”, it makes someone think that someone – in this case Nietzsche, or someone else – might hold the absolutely ridiculous view that every view was as good as every other view. That is a complete straw person argument. No-one has ever – or does now – hold the view that every view is as good as every other view.</p>
<p>So whenever the spectre of relativism is raised, you know, by someone for you, either in the popular press or in a university setting, the first small thing that should come to your mind is there aren’t any. So the refutation in a certain sense is bound to miss at least one point, namely that you are not arguing against anyone. Now it could be the case that my audience today, or the audience that will watch the tapes, I will find someone in the United States, or across the world that will hold the view that every other view is as good as every other view. But if I do, it will be very idiosyncratic, and in my experience so far, no.</p>
<p>Nietzsche is not a relativist, and I think perspectivism is also an unfortunate term to describe Nietzsche’s style of thinking. Because perspectivism calls up the idea that, “Well, I am right from my perspective, and you are right from your perspective, and everybody is right from their perspectives”, and I also don’t believe that that’s a view that anyone can hold or has ever held. I think, and this is the the way I will try to discuss Nietzsche’s paradox in terms of relativism, is that…</p>
<p>Nietzsche was opposed to what might be called the dogmatism of not only the Western Philosophical tradition, but the Western Theoretical tradition in general. Its dogmatism in this regard. Believing… about its beliefs that they were good not only for them and their tribe… because after all Western Civilisation is a big word… it’s a strange word… you know, big words and strange words, but, after all it is just a very large tribe with very large armies and lots of televisions… and a large historical project, but still its a tribe. Big, big tribe.</p>
<p>I think Nietzsche considered it dogmatic to hold that your beliefs – or the beliefs of your tribe – were binding on all. That is the way I want to present Nietzsche’s perspectivism. In other words, he didn’t believe that all beliefs were equally good, interesting, or whatever. In fact, I am sure he considered some of his own beliefs to be far more interesting than for example, the beliefs of John Stuart Mill, who he referred to as “That blockhead”. Or I think that he found his views more interesting than the views of the English Utilitarians in general, about whom he said “No human beings want to be happy. Only the British want that”. [crowd laughter]. So I think he thinks his views were more interesting than those.</p>
<p>And I think where the dogmatism for Nietzsche came in was when you search for views… and then develop your beliefs, and then think that they should be binding on all. This is not a criticism that you shouldn’t have beliefs, or that all your beliefs are no better than anyone else’s. It’s just the further belief about your beliefs that everyone else should believe the same damn way. So it’s a meta-belief, if you will. A belief about your beliefs.</p>
<p>In fact I think that it’s perfectly consistent to believe a wide number of things with a great deal of passion, and then believe about those beliefs that you could be wrong. I hope that’s not a further paradox, I do not think that it is. It seems to me to be perfectly consistent to believe something passionately, to believe it in a very deep way and have a belief about that belief that “Well, you know. I could be wrong.”</p>
<p>So the dogmatism that Nietzsche is after runs very deep in our theoretical traditions. I can’t overestimate this. It’s a dogmatism that has continued throughout what might be called the project of the West, and it’s even built into the Socratic pursuit. When Socrates asks the question “What is X?”, and what fills in the “X” are those famous Greek ideals; virtue, excellence, beauty, goodness, and so on. Now Nietzsche had the highest respect for Socrates, and as I just said, as I said before, Nietzsche considered him to be an <a href="http://dictionary.reference.com/browse/exemplary" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://dictionary.reference.com/browse/exemplary', 'exemplary']);">exemplary</a> person, coupled with Plato’s construction of him, they in a way were ideal for Nietzsche.</p>
<p>But the dogmatic part of Socrates was that Socrates wanted – for Nietzsche – Socrates wanted an answer to the question “What is X”, like what is beauty, goodness, truth, excellence. It wouldn’t be good for just Socrates, or good for the Greeks, but once discovered had to bind everyone. In other words, it wouldn’t be enough just to believe it, which seems… what Nietzsche calls the gay, happy theorist to be enough, to just find a belief that you can live with and believe. No, the theoretical enterprise of the West is imperialistic in a way. It’s got to find a belief that others then have to believe, and that he considered dogmatic.</p>
<p>This by the way you may notice is not – in my view – a relativist position at all. Because it’s not inconsistent with the view that you think your beliefs – precisely because they are your beliefs – are superior to some other beliefs. In fact I take it to be banally the case that if you didn’t think that, they wouldn’t be your beliefs. In other words, somebody comes up to you and gives you some other ones and you go “Oh hell, those are better than mine”. Then they will be yours after you have heard them out, right? So it seems fairly natural that you believe your beliefs. The dogmatic assumption is that everyone else should believe your beliefs. And this is not relativism. There have been some modern philosophical names attached to this position called <a href="https://en.wikipedia.org/wiki/Fallibilism" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'https://en.wikipedia.org/wiki/Fallibilism', 'fallibilism']);">fallibilism</a>, and yet Nietzsche is too interesting in a certain way to be called that either.</p>
<p>In other words, I want to present Nietzsche not specifically within that philosophical context, but I do want to present him as addressing it, which he does. And anyone who has ever addressed any issue in philosophy knows that the irritating thing is how the simplest questions can turn into philosophical ones. Sometimes philosophers realise that what we do is ask a series of rhetorical questions that come up whenever people are very frustrated. In other words, we ask questions like “What the hell does that mean?”. You know, generally in a fight – a domestic fight – a rhetorical question. “I can’t do the dishes now” – “Well what the hell does that mean?”. Well, the philosopher takes that rhetorical question and just places it in a foreign context. Someone goes “There’s an object” and you go “Object… what the hell does that mean?” [crowd laughter]. In the other context, the remark had a home and a meaning, and so it means that the person’s <em>pissed</em>, I guess. Or <em>upset</em>, okay. In this other context though, “What does it – you know – does it mean?” doesn’t seem to have any purchase.</p>
<p>About those, sort of, metaphysical beliefs, Nietzsche was no metaphysician. In fact, he thought that was, in a way, a very pompous thing to be. To try to answer those kinds of questions in a way binding for all. Now I call that a kind of <em>imperialism</em>, and I didn’t use that political term without thinking about it for a while. It’s the kind of imperialism – this dogmatic tradition against which Socrates saw himself fighting – is the kind of imperialist tradition we might have in some of our educational institutions when we have an African-American student who speaks eloquent rap street language talk. And I am not trying to say that’s all that African-Americans speak. Some of them are Neo-Conservatives that garble around as bad as others. Paleo-Conservatives. You know, some are just as unfortunately stupid as their Anglo-American, or Anglo-Saxon counterparts.</p>
<p>No, but I mean I am talking now about, you know, someone who does… says “ain’t” and repeats themselves, rhymes and things. Well, in a way it’s just imperialistic to think that that is somehow less profound than the Cambridge accent that discusses in detail the problem of relativism. It is not only a class and a racial bias, it’s just stupid. Because, as <a href="http://en.wikipedia.org/wiki/William_James" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://en.wikipedia.org/wiki/William_James', 'William James']);">William James</a> once said “The trail of the human serpent is over all”. There are many forms of life, many cultures, many ways to look at things. And Nietzsche at his best expresses in his work that diversity and that complexity of the many ways to interpret, to speak.</p>
<p>Now, “imperialistic” in this educational sense means that we want you to leave our institutions of higher learning talking like we talk and writing like we write. And we divide through by the issue of whether you think at all, because all the evidence we have for that is what you have said and what you have written. You may be not thinking at all, or thinking very bizarre thoughts, or you may be on some hallucinogenic drug, who knows what’s inside. But if you leave there writing like we write, talking like we talk – in short obeying relations of power – then you are educated. You certainly… and certainly Nietzsche saw this as conformity, and not connected with truth.</p>
<p>So …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/">http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/</a></em></p>]]>
            </description>
            <link>http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25385213</guid>
            <pubDate>Fri, 11 Dec 2020 12:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Dynamic DNS with Netlify API and Bash]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25384968">thread link</a>) | @krustymeathead
<br/>
December 11, 2020 | https://blog.skylerlewis.io/2020/12/diy-dynamic-dns-using-netlify-api.html | <a href="https://web.archive.org/web/*/https://blog.skylerlewis.io/2020/12/diy-dynamic-dns-using-netlify-api.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-606233900384767253">
<p>I don't really need to send many calls back to my network at my house when I am away, but when I want to show someone the progress we are making on the family Minecraft Christmas village, it is nice to be able to call to a <a href="https://github.com/miclav/mapcrafter/tree/world116">Mapcrafter</a> server at my house.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-X1eJAH2v7Wg/X9AD2Ct3cjI/AAAAAAAARVQ/o29jbVBMlLAWv1UAhF_DMsEsYiyKj052wCLcBGAsYHQ/s2048/christmas_village.png"><img data-original-height="1200" data-original-width="2048" height="376" src="https://1.bp.blogspot.com/-X1eJAH2v7Wg/X9AD2Ct3cjI/AAAAAAAARVQ/o29jbVBMlLAWv1UAhF_DMsEsYiyKj052wCLcBGAsYHQ/w640-h376/christmas_village.png" title="The Family Minecraft Christmas Village" width="640"></a></td></tr><tr><td>This is the current family Minecraft Christmas Village. The image is generated by Mapcrafter&nbsp;using <a href="https://github.com/skylerwlewis/realms-mapcrafter-renderer">this group</a> of Bash scripts.</td></tr></tbody></table><p>Now I don't have a business internet line at my house, so my IP can change theoretically at any time. I have looked at a&nbsp;<a href="https://www.noip.com/">few</a> <a href="https://dyndnss.net/eng/">services</a> offering Dynamic DNS, however, some didn't fit my needs. Also they all cost money, and my preference would be to not spend any money if I don't have to.</p><p>I found some projects on Github that communicate with the <a href="https://open-api.netlify.com/#tag/dnsZone">Netlify API</a> using an access token to update the domain entry dynamically, however, I had issues with the <a href="https://github.com/lytedev/netlify-ddns">projects</a> <a href="https://github.com/oscartbeaumont/netlify-dynamic-dns">I</a> <a href="https://github.com/lukehsiao/netlify-ddns-rs">tried</a>. I wanted to stick to apt for installing software, I didn't want to install Docker, and some of the domain updates were leaving duplicates domain entries. Since I've been playing with my Plex Media Server, I've been on a Bash script kick, so I figured I would try to create a Bash script for this I could run through cron.</p><p>The main tool for this job, other than Bash and the Netlify API, is <a href="https://stedolan.github.io/jq/">jq</a>. It is a lightweight command-line tool for handling everything JSON-related. This script requires jq is installed, but shouldn't have any other dependencies. If you try it out, let me know what you think.</p>

</div></div>]]>
            </description>
            <link>https://blog.skylerlewis.io/2020/12/diy-dynamic-dns-using-netlify-api.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384968</guid>
            <pubDate>Fri, 11 Dec 2020 12:25:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Journey with Elixir and Flow-Based Programming]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384954">thread link</a>) | @allanmacgregor
<br/>
December 11, 2020 | https://preslav.me/2020/12/10/elixir-community-voices-allan-macgregor/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/12/10/elixir-community-voices-allan-macgregor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body"><p><em>I first met Allan over a Zoom call about a week ago. I have been following <a href="https://allanmacgregor.com/">his blog</a> for some time and wanted to know more about his book draft about design patterns in Elixir. It wasn't until the call itself that I found out how many ideas we share - about the future of Elixir, its role as an alternative to present-day distributed solutions, and last but not least, its potential for the next generation of e-commerce solutions. </em></p><h2 id="who-are-you">Who are you?</h2><p><strong>Allan:</strong> I'm a software engineer with 15 years of experience, based in Toronto, Ontario. I was born and grew up in Mexico, and over the last 11 years, I have been able to build a career and life in Canada.</p><p>Most of my professional career has been focused on e-commerce development, which I would say can be broken down into three main categories:</p><ul><li>Building user-facing experiences</li><li>Building e-commerce engines to map the business logic</li><li>Integrations with third-party systems</li></ul><p>Over ten years of e-commerce development, I had the opportunity to work with many notable brands in Canada and the US and solve many challenges in the space. I have also dabbled working with product companies in multiple capacities - from CTO to currently a Senior Engineering Manager at <a href="https://www.humi.ca/" rel="noopener noreferrer">Humi</a>.</p><p>In terms of technologies, I have had a chance to work with many different stacks and programming languages, notably PHP (LAMP), some Ruby on Rails, some Scala during my time at Hopper, and a bit of Elixir to tackle quick prototypes and transparent proxy for an e-commerce project.</p><p>Currently, I'm a Senior Engineering Manager at Humi, a great company in the HR and payroll space. I am also building a couple of micro-SaaS projects - the first one being <a href="https://siteguardian.dev/" rel="noopener noreferrer">SiteGuardian</a>, intended to be a complete solution for website monitoring and security. It should be close to beta release later this month.</p><figure><a href="https://siteguardian.dev/"><div><p>Siteguardian · Better Site Monitoring</p></div><p><img src="https://siteguardian.dev/images/siteguardian_logo-4a1bbe5ed6d4c7832ee675694a7aed47.svg?vsn=d"></p></a></figure><h2 id="what-brought-you-to-elixir">What brought you to Elixir?</h2><p><strong>Allan: </strong>I stumbled into Elixir in a bit of a weird way, going back to one of the problems that I mentioned on the e-commerce space — integration with third-party systems like ERP, OMS, and the like, — for that kind of problems, the idea of <a href="https://jpaulm.github.io/fbp/index.html">Flow-based programming</a> made a lot of sense.</p><p>In essence, you structure your application to be a pipeline of black boxes that transform, filter, or handle the data in some way or another. Looking for implementations of this library, I landed on a library called <a href="https://github.com/antonmi/flowex">FlowEx</a>, which is written in Elixir. As I started diving deeper into the language, I honestly fell in love with it.</p><p>Elixir to me seems like this almost perfect mix of all the right qualities:</p><ul><li>Flexibility and power</li><li>Low Learning curve</li><li>Extensibility</li><li>Expressiveness</li></ul><p>If I had to pinpoint any particular quality of Elixir that caught my attention, it would be the expressiveness of the language - how much you can achieve with very little code.</p><p><strong>Allan: </strong>For me, the biggest challenge was adapting to a new paradigm and getting rid of the "bad" habits I picked up from working with Object-Oriented Languages. It is not the syntax that is different, but how you reason and think about the data flows in your program.</p><p>I guess the other challenging bit, which seems fairly common, was grasping the use of the Enum variable, Map, reduce, and the like. But once those things click, you are off to the races.</p><p>The other challenge that is still somewhat applicable is getting buying for the business or clients to use Elixir as a solution; however, I'm happy to see that it is gaining popularity and is being adopted by larger companies and teams.</p><p><strong>Allan: </strong>First, it is important to clarify what this next generation of e-commerce solutions looks like. We are currently in transition from the traditional catalog/search &gt; product page &gt; shopping cart &gt; checkout experience; and moving into a stage where e-commerce becomes ubiquitous, for example, integrated into an Instagram post or inside content.</p><p>This kind of change will present a couple of interesting challenges, both in terms of scalability / performance and architectures. The current generation of e-commerce platforms is fairly monolithic, or in the case of some of the SaaS offerings, fairly restrictive.</p><p>I can see an interesting future for Elixir and similar technologies to be used to develop the next generation e-commerce platforms and services; this is especially applicable when talking about integrations between OMS, Inventory systems, and Product Information Management systems.</p><p><strong>Allan: </strong>Absolutely! Right now, I'm working on a small SaaS project called <a href="https://siteguardian.dev/">SiteGuardian</a>, which aims to provide a robust solution for website site security and availability monitoring.</p><p>I chose Elixir for this project because first, I wanted to validate some architectural ideas and patterns that I'm researching for a book; and second, the Elixir stack allows me to build robust features and do so very efficiently.</p><p>To me, it is that perfect combination of development speed, robustness, and low operating costs that enables me to build a competitive micro-SaaS. Not to mention that my ability to iterate and build in this stack has been incredible compared to if was doing this in Laravel, or Ruby on Rails.</p><p>The second thing that I have in progress right now is a book on Elixir and design patterns. The idea is to explore and do a deep dive into the multiple variations of architectural and behavioral patterns that are relevant to functional programming and Elixir.</p><p>For anyone interested in the progress of the book, you can subscribe to my newsletter here: <a href="https://allanmacgregor.com/newsletter/">https://allanmacgregor.com/newsletter/</a></p><p><strong>Allan: </strong>For people considering using Elixir / Erlang, my word of advice is to give things time to sink in. Functional programming is likely to be a new idea and paradigm and might take a while to grok the concepts, but once you do, the time invested is going to pay off ten-fold.</p><hr><h2 id="references">References</h2><figure><a href="https://allanmacgregor.com/"><div><p>Hi, I’m Allan, this is where I write. - Allan MacGregor</p><p>Expert Software Engineer and Manager • Writer • Functional Programming Advocate</p><p><span>Allan MacGregor</span></p></div><p><img src="https://allanmacgregor.com/static/logo-white-3bbb2d0ba72789f13cdee16471616911.png"></p></a></figure><figure><a href="https://siteguardian.dev/"><div><p>Siteguardian · Better Site Monitoring</p></div><p><img src="https://siteguardian.dev/images/siteguardian_logo-4a1bbe5ed6d4c7832ee675694a7aed47.svg?vsn=d"></p></a></figure><figure><a href="https://github.com/antonmi/flowex"><div><p>antonmi/flowex</p><p>Flow-Based Programming framework for Elixir. Contribute to antonmi/flowex development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars3.githubusercontent.com/u/835853?s=400&amp;v=4"></p></a></figure><figure><a href="https://jpaulm.github.io/fbp/index.html"><div><p>Flow-based Programming</p><p>Official website for flow-based programming</p><p><img src="https://jpaulm.github.io/fbp/images/favicon.ico"></p></div><p><img src="https://jpaulm.github.io/fbp/bottling_factory.png"></p></a></figure></div>
</div></div>]]>
            </description>
            <link>https://preslav.me/2020/12/10/elixir-community-voices-allan-macgregor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384954</guid>
            <pubDate>Fri, 11 Dec 2020 12:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Crawling with Python]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384774">thread link</a>) | @daolf
<br/>
December 11, 2020 | https://www.scrapingbee.com/blog/crawling-python/ | <a href="https://web.archive.org/web/*/https://www.scrapingbee.com/blog/crawling-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://d33wubrfki0l68.cloudfront.net/0ace011709806f528c970a43a82d2905e536aced/0c7a2/images/authors/ari.png" alt="Ari Bajo">
            
            <span>
                
                
                
                <span>
                    <small> ● </small>
                    
                    
                    <span>11 December, 2020</span>
                    
                    <small> ● </small>
                    <span> 13 min read </span>
                </span>
                <p> Ari is an expert Data Engineer and a talented technical writer. He wrote the entire Scrapy integration for ScrapingBee and this awesome article.
                        
                        <a href="https://twitter.com/ari_bajo" target="_blank">
                        <svg style="height: 14px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                            <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" fill="currentColor"></path>
                        </svg>
                        </a>
                        
                        
                    </p>
            </span>
        </p><div property="articleBody">
          





















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/ec113f2bdce1bd490836cf9b4a48bf623d1038e4/f3edd/blog/crawling-python/python_crawl_huc3299db23da91c71a01641e8130027ed_40687_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/9b928b664ed803937fcd03fd8a1d933dbec2ed21/cb134/blog/crawling-python/python_crawl_huc3299db23da91c71a01641e8130027ed_40687_1200x0_resize_catmullrom_2.png 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/5868bb8e66c49ac2ce5428289f43fe12e77f1a59/1f7da/blog/crawling-python/python_crawl.png" width="1200" height="628" alt="Blog post header" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/ec113f2bdce1bd490836cf9b4a48bf623d1038e4/f3edd/blog/crawling-python/python_crawl_huc3299db23da91c71a01641e8130027ed_40687_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/9b928b664ed803937fcd03fd8a1d933dbec2ed21/cb134/blog/crawling-python/python_crawl_huc3299db23da91c71a01641e8130027ed_40687_1200x0_resize_catmullrom_2.png 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/5868bb8e66c49ac2ce5428289f43fe12e77f1a59/1f7da/blog/crawling-python/python_crawl.png">
  
</p></div>




<p>Web crawling is a powerful technique to collect data from the web by finding all the URLs for one or multiple domains. Python has several popular web crawling libraries and frameworks.</p>
<p>In this article, we will first introduce different crawling strategies and use cases. Then we will build a simple web crawler from scratch in Python using two libraries: requests and Beautiful Soup. Next, we will see why it’s better to use a web crawling framework like Scrapy. Finally, we will build an example crawler with Scrapy to collect film metadata from IMDb and see how Scrapy scales to websites with several million pages.</p>
<h2 id="what-is-a-web-crawler">What is a web crawler?</h2>
<p><a href="https://en.wikipedia.org/wiki/Web_crawler">Web crawling</a> and <a href="https://en.wikipedia.org/wiki/Web_scraping">web scraping</a> are two different but related concepts. Web crawling is a component of web scraping, the crawler logic finds URLs to be processed by the scraper code.</p>
<p>A web crawler starts with a list of URLs to visit, called the seed. For each URL, the crawler finds links in the HTML, filters those links based on some criteria and adds the new links to a queue. All the HTML or some specific information is extracted to be processed by a different pipeline.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/f294e8de9a7fe601fbf262d904c7b669c5b8696f/5e7ba/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_825x0_resize_q75_catmullrom.jpg 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/c5ceb8078645ba6d68e1c456916872c6d6301237/83b29/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_1200x0_resize_q75_catmullrom.jpg 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/fd2fbb0ec91131c342888def031d4335bbd6755d/dcfcb/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_1500x0_resize_q75_catmullrom.jpg 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/b4162831034444f8813eb39bec97bddc885cfeab/4c624/blog/crawling-python/diagram1.jpg" width="1668" height="2154" alt="Web crawling diagram" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/f294e8de9a7fe601fbf262d904c7b669c5b8696f/5e7ba/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_825x0_resize_q75_catmullrom.jpg 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/c5ceb8078645ba6d68e1c456916872c6d6301237/83b29/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_1200x0_resize_q75_catmullrom.jpg 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/fd2fbb0ec91131c342888def031d4335bbd6755d/dcfcb/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_1500x0_resize_q75_catmullrom.jpg 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/b4162831034444f8813eb39bec97bddc885cfeab/4c624/blog/crawling-python/diagram1.jpg">
  
</p></div>

<br>


<h2 id="web-crawling-strategies">Web crawling strategies</h2>
<p>In practice, web crawlers only visit a subset of pages depending on the crawler budget, which can be a maximum number of pages per domain, depth or execution time.</p>
<p>Most popular websites provide a <a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard">robots.txt</a> file to indicate which areas of the website are disallowed to crawl by each user agent. The opposite of the robots file is the <a href="https://en.wikipedia.org/wiki/Sitemaps">sitemap.xml</a> file, that lists the pages that can be crawled.</p>
<p>Popular web crawler use cases include:</p>
<ul>
<li>Search engines (Googlebot, Bingbot, Yandex Bot…) collect all the HTML for a significant part of the Web. This data is indexed to make it searchable.</li>
<li>SEO analytics tools on top of collecting the HTML also collect metadata like the response time, response status to detect broken pages and the links between different domains to collect backlinks.</li>
<li>Price monitoring tools crawl e-commerce websites to find product pages and extract metadata, notably the price. Product pages are then periodically revisited.</li>
<li>Common Crawl maintains an <a href="https://commoncrawl.org/the-data/get-started/">open repository of web crawl data</a>. For example, the archive from October 2020 contains 2.71 billion web pages.</li>
</ul>
<p>Next, we will compare three different strategies for building a web crawler in Python. First, using only standard libraries, then third party libraries for making HTTP requests and parsing HTML and finally, a web crawling framework.</p>
<h2 id="building-a-simple-web-crawler-in-python-from-scratch">Building a simple web crawler in Python from scratch</h2>
<p>To build a simple web crawler in Python we need at least one library to download the HTML from a URL and an HTML parsing library to extract links. Python provides standard libraries <a href="https://docs.python.org/3.9/library/urllib.html">urllib</a> for making HTTP requests and <a href="https://docs.python.org/3/library/html.parser.html">html.parser</a> for parsing HTML. An example Python crawler built only with standard libraries can be found on <a href="https://github.com/xukai92/crawlerfromscratch/blob/master/spider.py">Github</a>.</p>
<p>The standard Python libraries for requests and HTML parsing are not very developer-friendly. Other popular libraries like <a href="https://requests.readthedocs.io/en/master/">requests</a>, branded as HTTP for humans, and <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup</a> provide a better developer experience. You can install the two libraries locally. \</p>
<p><code>pip install requests bs4</code></p>
<p>A basic crawler can be built following the previous architecture diagram.</p>
<div><pre><code data-lang="python">



<span>import</span> logging
<span>from</span> urllib.parse <span>import</span> urljoin
<span>import</span> requests
<span>from</span> bs4 <span>import</span> BeautifulSoup

logging<span>.</span>basicConfig(
    format<span>=</span><span></span><span>'</span><span>%(asctime)s</span><span> </span><span>%(levelname)s</span><span>:</span><span>%(message)s</span><span>'</span>,
    level<span>=</span>logging<span>.</span>INFO)

<span>class</span> <span>Crawler</span>:

    <span>def</span> __init__(self, urls<span>=</span>[]):
        self<span>.</span>visited_urls <span>=</span> []
        self<span>.</span>urls_to_visit <span>=</span> urls

    <span>def</span> <span>download_url</span>(self, url):
        <span>return</span> requests<span>.</span>get(url)<span>.</span>text

    <span>def</span> <span>get_linked_urls</span>(self, url, html):
        soup <span>=</span> BeautifulSoup(html, <span></span><span>'</span><span>html.parser</span><span>'</span>)
        <span>for</span> link <span>in</span> soup<span>.</span>find_all(<span></span><span>'</span><span>a</span><span>'</span>):
            path <span>=</span> link<span>.</span>get(<span></span><span>'</span><span>href</span><span>'</span>)
            <span>if</span> path <span>and</span> path<span>.</span>startswith(<span></span><span>'</span><span>/</span><span>'</span>):
                path <span>=</span> urljoin(url, path)
            <span>yield</span> path

    <span>def</span> <span>add_url_to_visit</span>(self, url):
        <span>if</span> url <span>not</span> <span>in</span> self<span>.</span>visited_urls <span>and</span> url <span>not</span> <span>in</span> self<span>.</span>urls_to_visit:
            self<span>.</span>urls_to_visit<span>.</span>append(url)

    <span>def</span> <span>crawl</span>(self, url):
        html <span>=</span> self<span>.</span>download_url(url)
        <span>for</span> url <span>in</span> self<span>.</span>get_linked_urls(url, html):
            self<span>.</span>add_url_to_visit(url)

    <span>def</span> <span>run</span>(self):
        <span>while</span> self<span>.</span>urls_to_visit:
            url <span>=</span> self<span>.</span>urls_to_visit<span>.</span>pop(<span>0</span>)
            logging<span>.</span>info(f<span></span><span>'</span><span>Crawling: {url}</span><span>'</span>)
            <span>try</span>:
                self<span>.</span>crawl(url)
            <span>except</span> <span>Exception</span>:
                logging<span>.</span>exception(f<span></span><span>'</span><span>Failed to crawl: {url}</span><span>'</span>)
            <span>finally</span>:
                self<span>.</span>visited_urls<span>.</span>append(url)

<span>if</span> __name__ <span>==</span> <span></span><span>'</span><span>__main__</span><span>'</span>:
    Crawler(urls<span>=</span>[<span></span><span>'</span><span>https://www.imdb.com/</span><span>'</span>])<span>.</span>run()
</code></pre></div><p>The code above defines a Crawler class with helper methods to download_url using the requests library, get_linked_urls using the Beautiful Soup library and add_url_to_visit to filter URLs. The URLs to visit and the visited URLs are stored in two separate lists. You can run the crawler on your terminal.</p>
<p>python crawler.py</p>
<p>The crawler logs one line for each visited URL.</p>
<div><pre><code data-lang="bash">
2020-12-04 18:10:10,737 INFO:Crawling: https://www.imdb.com/
2020-12-04 18:10:11,599 INFO:Crawling: https://www.imdb.com/?ref_<span>=</span>nv_home
2020-12-04 18:10:12,868 INFO:Crawling: https://www.imdb.com/calendar/?ref_<span>=</span>nv_mv_cal
2020-12-04 18:10:13,526 INFO:Crawling: https://www.imdb.com/list/ls016522954/?ref_<span>=</span>nv_tvv_dvd
2020-12-04 18:10:19,174 INFO:Crawling: https://www.imdb.com/chart/top/?ref_<span>=</span>nv_mv_250
2020-12-04 18:10:20,624 INFO:Crawling: https://www.imdb.com/chart/moviemeter/?ref_<span>=</span>nv_mv_mpm
2020-12-04 18:10:21,556 INFO:Crawling: https://www.imdb.com/feature/genre/?ref_<span>=</span>nv_ch_gr
</code></pre></div><p>The code is very simple but there are many performance and usability issues to solve before successfully crawling a complete website.</p>
<ul>
<li>The crawler is slow and supports no parallelism. As can be seen from the timestamps, it takes about one second to crawl each URL. Each time the crawler makes a request it waits for the request to be resolved and no work is done in between.</li>
<li>The download URL logic has no retry mechanism, the URL queue is not a real queue and not very efficient with a high number of URLs.</li>
<li>The link extraction logic doesn’t support standardizing URLs by removing URL query string parameters, doesn’t handle URLs starting with #, doesn’t support filtering URLs by domain or filtering out requests to static files.</li>
<li>The crawler doesn’t identify itself and ignores the robots.txt file.</li>
</ul>
<p>Next, we will see how Scrapy provides all these functionalities and makes it easy to extend for your custom crawls.</p>
<h2 id="web-crawling-with-scrapy">Web crawling with Scrapy</h2>
<p>Scrapy is the most popular web scraping and crawling Python framework with 40k stars on <a href="https://github.com/scrapy/scrapy">Github</a>. One of the advantages of Scrapy is that requests are scheduled and handled asynchronously. This means that Scrapy can send another request before the previous one is completed or do some other work in between. Scrapy can handle many concurrent requests but can also be configured to respect the websites with custom <a href="https://docs.scrapy.org/en/latest/topics/settings.html">settings</a>, as we’ll see later.</p>
<p>Scrapy has a multi-component architecture. Normally, you will implement at least two different classes: <a href="https://docs.scrapy.org/en/latest/topics/spiders.html">Spider</a> and <a href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html">Pipeline</a>. Web scraping can be thought of as an ETL where you extract data from the web and load it to your own storage. Spiders extract the data and pipelines load it into the storage. Transformation can happen both in spiders and pipelines, but I recommend that you set a custom Scrapy pipeline to transform each item independently of each other. This way, failing to process an item has no effect on other items.</p>
<p>On top of all that, you can add spider and downloader middlewares in between components as it can be seen in the diagram below.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/9ec6172a2d9d57f9d3d935ce7ef9f25878ca9509/4e2cb/blog/crawling-python/image2_hu2c5c023b068fe63956b3eac3483ae818_71063_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/acdcf2034b0684bb719531d883ad3e0879dcc338/dd6fb/blog/crawling-python/image2_hu2c5c023b068fe63956b3eac3483ae818_71063_1200x0_resize_catmullrom_2.png 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/76867f9d2c73d7e0def2e2a38a1671bedf2afa1a/fcc2c/blog/crawling-python/image2.png" width="1400" height="940" alt="Scrapy architecture diagram" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/9ec6172a2d9d57f9d3d935ce7ef9f25878ca9509/4e2cb/blog/crawling-python/image2_hu2c5c023b068fe63956b3eac3483ae818_71063_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/acdcf2034b0684bb719531d883ad3e0879dcc338/dd6fb/blog/crawling-python/image2_hu2c5c023b068fe63956b3eac3483ae818_71063_1200x0_resize_catmullrom_2.png 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/76867f9d2c73d7e0def2e2a38a1671bedf2afa1a/fcc2c/blog/crawling-python/image2.png">
  
</p></div>




<p>Scrapy Architecture Overview [<a href="https://docs.scrapy.org/en/latest/topics/architecture.html#data-flow">source</a>]</p>
<p>If you have used Scrapy before, you know that a web scraper is defined as a class that inherits from the base Spider class and implements a parse method to handle each response. If you are new to Scrapy, you can read this article for <a href="https://www.scrapingbee.com/blog/web-scraping-with-scrapy/">easy scraping with Scrapy</a>.</p>
<div><pre><code data-lang="python"><span>from</span> scrapy.spiders <span>import</span> Spider

<span>class</span> <span>ImdbSpider</span>(Spider):
    name <span>=</span> <span></span><span>'</span><span>imdb</span><span>'</span>
    allowed_domains <span>=</span> [<span></span><span>'</span><span>[www.imdb.com](www.imdb.com)</span><span>'</span>]
    start_urls <span>=</span> [<span></span><span>'</span><span>[https://www.imdb.com/](https://www.imdb.com/)</span><span>'</span>]

<span>def</span> <span>parse</span>(self, response):
    <span>pass</span>
</code></pre></div><p>Scrapy also provides several <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#generic-spiders">generic spider classes</a>: CrawlSpider, XMLFeedSpider, CSVFeedSpider and SitemapSpider. The <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#crawlspider">CrawlSpider</a> class inherits from the base Spider class and provides an extra rules attribute to define how to crawl a website. Each rule uses a <a href="https://docs.scrapy.org/en/latest/topics/link-extractors.html#topics-link-extractors">LinkExtractor</a> to specify which links are extracted from each page. Next, we will see how to use each one of them by building a crawler for IMDb, the Internet Movie Database.</p>
<h2 id="building-an-example-scrapy-crawler-for-imdb">Building an example Scrapy crawler for IMDb</h2>
<p>Before trying to crawl IMDb, I checked <a href="https://www.imdb.com/robots.txt">IMDb robots.txt</a> file to see which URL paths are allowed. The robots file only disallows 26 paths for all user-agents. Scrapy reads the robots.txt file beforehand and respects when the <a href="https://docs.scrapy.org/en/latest/topics/settings.html#robotstxt-obey">ROBOTSTXT_OBEY</a> setting is set to true. This is the case for all projects generated with the Scrapy command startproject.</p>
<p>scrapy startproject scrapy_crawler</p>
<p>This command creates a new project with the default Scrapy project folder structure.</p>
<div><pre><code data-lang="bash">scrapy_crawler/

├── scrapy.cfg
└── scrapy_crawler
    ├── __init__.py
    ├── items.py
    ├── middlewares.py
    ├── pipelines.py
    ├── settings.py
 …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.scrapingbee.com/blog/crawling-python/">https://www.scrapingbee.com/blog/crawling-python/</a></em></p>]]>
            </description>
            <link>https://www.scrapingbee.com/blog/crawling-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384774</guid>
            <pubDate>Fri, 11 Dec 2020 11:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Small Habits Count]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384459">thread link</a>) | @KlimYadrintsev
<br/>
December 11, 2020 | https://klimy.co/blog/why-small-habits-11-12-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/why-small-habits-11-12-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <p>My problem in life is that if I am doing something, I tend to try to get the most out of it. That is what people call maximalism.</p>
<p>It has been present in the habits that I tried implementing as well. It has been present in a gym membership. It has been present in learning a new language. Basically, I couldn’t do anything a healthy amount and tried to do as much as I could straight away.</p>
<p>As you might have guessed it, even though in the potential that would allow me to get the most amount of results out of the action, it would also cause me to burn out very fast. Usually so fast, that the first results just started showing when I quit.</p>
<p>After reading <a href="https://jamesclear.com/atomic-habits">James Clear Atomic Habits</a>, I understood that the biggest problem with positive habit-forming is exactly what I have been doing. It said that starting with a hard habit is what will make it less likely to stick. While on the other hand, making a habit small and easy is exactly what would make a habit stick and would allow you to scale it after a period of time potentially.</p>
<p>Going to the gym every day, 7 days a week for one hour was the initial goal I would usually set. Now it's: put running shoes and walk outside of your house for 10 minutes.</p>
<p>Reading 50 books in a year, now became read a page per day.</p>
<p>Learn how to build Facebook. Now is: learn how to make this button blue.</p>
<p>Everything became smaller and much easier to do. The result? I have been in the habit of doing things for more than 3 months, and I would never go back.</p>
<h2>Why Maximalism is not always bad</h2>
<p>The good news for me is that I only have to battle with my inner understanding of the world when I start as long as I have started and the habit in the motion of slowly integrating with my life, I can also start to scale it slowly. That is how I started with everything so far and to be completely honest, I don’t see a reason to do it any other way.</p>
<p>The main issue of why positive habits are so much harder to integrate in comparison to the negative habits is because the rewards and the dopamine hits are postponed to some time in the future. Actually so far, that our short term brain doesn’t see it.</p>
<p>That is why by making a habit easy and maybe even pairing with some positive reward for yourself, would make the habit sticking more likely. </p>
<p>Make sure that what you do is good for you, before putting down the reward. <a href="https://klimy.co/blog/nano-problems-09-12-2020">Don’t reward yourself for doing yourself worse.</a></p>
<h2>Why small habits count</h2>
<p>Even though some habits have stayed for me <a href="https://klimy.co/blog/practice-makes-perfect-30-11-2020">very small</a>, the presence of that small habit in my life has <a href="https://klimy.co/blog/front-page-hn">changed me completely</a>.</p>
<p>I didn’t understand why spending 10 minutes per day doing something can improve me so much, then I remembered James Clear maths example.</p>
<p>1.01^365 = 37.8</p>
<p>Which is crazy to think about, and it turns out it is also true in practice.</p>
<p>Even if you can only do 5 minutes of something per day, don’t postpone it. In a month or even a year, you will look back, and you will be a completely different, better person.</p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/why-small-habits-11-12-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384459</guid>
            <pubDate>Fri, 11 Dec 2020 11:14:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A practical guide on generating hellishly good ideas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25384443">thread link</a>) | @paus
<br/>
December 11, 2020 | https://www.sobieckipioneering.com/creativity-guide | <a href="https://web.archive.org/web/*/https://www.sobieckipioneering.com/creativity-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-ix="row-5"><div><div><p>Over 200 business, science and productivity books, studies on the subject.</p><p>My personal experience in theoretical physics and business.<br></p><p>Private discussions with top businessman and scientists - I had an incredible privilege to discuss this issue with billionaires and a Nobel Price laureat.<br></p><p>Methods used by 43 people being at the top of their fields, including<br><em>Elon Musk, Steve Jobs, Bill Gates, Warren Buffett, Richard Branson, Larry Page and Sergey Brin, Sam Walton, Andrew Carnegie, Vincent van Gogh, Pablo Picasso, Leonardo da Vinci, Roger Penrose, Stephen Hawking</em><br></p></div></div></div><div data-ix="row-6"><div><h2>Wide spectrum</h2><p>Our methods are exceptional as they were not only based on how hyper-productive people think and work, but also how the most innovative companies operated to get where they are now. Among them are</p><h2>Why</h2><p>Our business is based on creativity. It required going thorugh historic and presently practiced solutions to build a compendium of creativity.<em> </em></p><p><em>So we did it. </em></p><p>Now we, as a team, decided to share with you the pinnacle - the strategies most consistent in generating results. Working with this methodology we are able to suprisingly frequently help businesses to get onto an exponential growth path and scientists to come up with breakthrough experimets and theories.</p><p>We believe in simplicity. Having that in mind, the process was distilled to a Triple Pareto state - that is to the 1% that can give you half of the results you would be likely to get after years of training. Read our 20 page guide to acquire the proficiency you would expect to get in a half of a 2000 page finest quality manuscript.</p></div></div></div>]]>
            </description>
            <link>https://www.sobieckipioneering.com/creativity-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384443</guid>
            <pubDate>Fri, 11 Dec 2020 11:12:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Python object system works]]>
            </title>
            <description>
<![CDATA[
Score 322 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25384433">thread link</a>) | @r4victor
<br/>
December 11, 2020 | https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>As we know from the previous parts of this series, the execution of a Python program consists of two major steps:</p>
<ol>
<li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">The CPython compiler</a> translates Python code to bytecode.</li>
<li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">The CPython VM</a> executes the bytecode.</li>
</ol>
<p>We've been focusing on the second step for quite a while. In <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">part 4</a> we've looked at the evaluation loop, a place where Python bytecode gets executed. And in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/">part 5</a> we've studied how the VM executes the instructions that are used to implement variables. What we haven't covered yet is how the VM actually computes something. We postponed this question because to answer it, we first need to understand how the most fundamental part of the language works. Today, we'll study the Python object system.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h2>Motivation</h2>
<p>Consider an extremely simple piece of Python code:</p>



<p>To compute the function <code>f</code>, CPython must evaluate the expression <code>x + 7</code>. The question I'd like to ask is: How does CPython do that? Special methods such as <code>__add__()</code> and <code>__radd__()</code> probably come to your mind. When we define these methods on a class, the instances of that class can be added using the <code>+</code> operator. So, you might think that CPython does something like this:</p>
<ol>
<li>It calls <code>x.__add__(7)</code> or <code>type(x).__add__(x, 7)</code>.</li>
<li>If <code>x</code> doesn't have <code>__add__()</code>, or if this method fails, it calls <code>(7).__radd__(x)</code> or <code>int.__radd__(7, x)</code>.</li>
</ol>
<p>The reality, tough, is a bit more complicated. What really happens depends on what <code>x</code> is. For example, if <code>x</code> is an instance of a user-defined class, the algorithm described above resembles the truth. If, however, <code>x</code> is an instance of a built-in type, like <code>int</code> or <code>float</code>, CPython doesn't call any special methods at all.</p>
<p>To learn how some Python code is executed, we can do the following:</p>
<ol>
<li>Disassemble the code into bytecode.</li>
<li>Study how the VM executes the disassembled bytecode instructions.</li>
</ol>
<p>Let's apply this algorithm to the function <code>f</code>. The compiler translates the body of this function to the following bytecode:</p>
<div><pre><span></span>$ python -m dis f.py
...
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (7)
              4 BINARY_ADD
              6 RETURN_VALUE
</pre></div>


<p>And here's what these bytecode instructions do:</p>
<ol>
<li><code>LOAD_FAST</code> loads the value of the parameter <code>x</code> onto the stack.</li>
<li><code>LOAD_CONST</code> loads the constant <code>7</code> onto the stack.</li>
<li><code>BINARY_ADD</code> pops two values from the stack, adds them and pushes the result back onto the stack.</li>
<li><code>RETURN_VALUE</code> pops the value from the stack and returns it.</li>
</ol>
<p>How does the VM add two values? To answer this question, we need to understand what these values are. For us, <code>7</code> is an instance of <code>int</code> and <code>x</code> is, well, anything. For the VM, though, everything is a Python object. All values the VM pushes onto the stack and pops from the stack are pointers to <code>PyObject</code> structs (hence the phrase "Everything in Python is an object").</p>
<p>The VM doesn't need to know how to add integers or strings, that is, how to do the arithmetic or concatenate sequences. All it needs to know is that every Python object has a type. A type, in turn, knows everything about its objects. For example, the <code>int</code> type knows how to add integers, and the <code>float</code> type knows how to add floats. So, the VM asks the type to perform the operation.</p>
<p>This simplified explanation captures the essence of the solution, but it also omits a lot of important details. To get a more realistic picture, we need to understand what Python objects and types really are and how they work.</p>
<h2>Python objects and types</h2>
<p>We've discussed Python objects a little in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-3-stepping-through-the-cpython-source-code/">part 3</a>. This discussion is worth repeating here.</p>
<p>We begin with the definition of the <code>PyObject</code> struct:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>_object</span> <span>{</span>
    <span>_PyObject_HEAD_EXTRA</span> <span>// macro, for debugging purposes only</span>
    <span>Py_ssize_t</span> <span>ob_refcnt</span><span>;</span>
    <span>PyTypeObject</span> <span>*</span><span>ob_type</span><span>;</span>
<span>}</span> <span>PyObject</span><span>;</span>
</pre></div>


<p>It has two members:</p>
<ul>
<li>a reference count <code>ob_refcnt</code> that CPython uses for garbage collection; and</li>
<li>a pointer to the object's type <code>ob_type</code>.</li>
</ul>
<p>We said that the VM treats any Python object as <code>PyObject</code>. How is that possible? The C programming language has no notion of classes and inheritance. Nevertheless, it's possible to implement in C something that can be called a single inheritance. The C standard states that a pointer to any struct can be converted to a pointer to its first member and vice versa. So, we can "extend" <code>PyObject</code> by defining a new struct whose first member is <code>PyObject</code>.</p>
<p>Here's, for example, how the <code>float</code> object is defined:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_HEAD macro</span>
    <span>double</span> <span>ob_fval</span><span>;</span>
<span>}</span> <span>PyFloatObject</span><span>;</span>
</pre></div>


<p>A <code>float</code> object stores everything <code>PyObject</code> stores plus a floating-point value <code>ob_fval</code>. The C standard simply states that we can convert a pointer to <code>PyFloatObject</code> to a pointer to <code>PyObject</code> and vice versa:</p>
<div><pre><span></span><span>PyFloatObject</span> <span>float_object</span><span>;</span>
<span>// ...</span>
<span>PyObject</span> <span>*</span><span>obj_ptr</span> <span>=</span> <span>(</span><span>PyObject</span> <span>*</span><span>)</span><span>&amp;</span><span>float_object</span><span>;</span>
<span>PyFloatObject</span> <span>*</span><span>float_obj_ptr</span> <span>=</span> <span>(</span><span>PyFloatObject</span> <span>*</span><span>)</span><span>obj_ptr</span><span>;</span>
</pre></div>


<p>The reason why the VM treats every Python object as <code>PyObject</code> is because all it needs to access is the object's type. A type is also a Python object, an instance of the <code>PyTypeObject</code> struct:</p>
<div><pre><span></span><span>// PyTypeObject is a typedef for "struct _typeobject"</span>

<span>struct</span> <span>_typeobject</span> <span>{</span>
    <span>PyVarObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_VAR_HEAD macro</span>
    <span>const</span> <span>char</span> <span>*</span><span>tp_name</span><span>;</span> <span>/* For printing, in format "&lt;module&gt;.&lt;name&gt;" */</span>
    <span>Py_ssize_t</span> <span>tp_basicsize</span><span>,</span> <span>tp_itemsize</span><span>;</span> <span>/* For allocation */</span>

    <span>/* Methods to implement standard operations */</span>

    <span>destructor</span> <span>tp_dealloc</span><span>;</span>
    <span>Py_ssize_t</span> <span>tp_vectorcall_offset</span><span>;</span>
    <span>getattrfunc</span> <span>tp_getattr</span><span>;</span>
    <span>setattrfunc</span> <span>tp_setattr</span><span>;</span>
    <span>PyAsyncMethods</span> <span>*</span><span>tp_as_async</span><span>;</span> <span>/* formerly known as tp_compare (Python 2)</span>
<span>                                    or tp_reserved (Python 3) */</span>
    <span>reprfunc</span> <span>tp_repr</span><span>;</span>

    <span>/* Method suites for standard classes */</span>

    <span>PyNumberMethods</span> <span>*</span><span>tp_as_number</span><span>;</span>
    <span>PySequenceMethods</span> <span>*</span><span>tp_as_sequence</span><span>;</span>
    <span>PyMappingMethods</span> <span>*</span><span>tp_as_mapping</span><span>;</span>

    <span>/* More standard operations (here for binary compatibility) */</span>

    <span>hashfunc</span> <span>tp_hash</span><span>;</span>
    <span>ternaryfunc</span> <span>tp_call</span><span>;</span>
    <span>reprfunc</span> <span>tp_str</span><span>;</span>
    <span>getattrofunc</span> <span>tp_getattro</span><span>;</span>
    <span>setattrofunc</span> <span>tp_setattro</span><span>;</span>

    <span>/* Functions to access object as input/output buffer */</span>
    <span>PyBufferProcs</span> <span>*</span><span>tp_as_buffer</span><span>;</span>

    <span>/* Flags to define presence of optional/expanded features */</span>
    <span>unsigned</span> <span>long</span> <span>tp_flags</span><span>;</span>

    <span>const</span> <span>char</span> <span>*</span><span>tp_doc</span><span>;</span> <span>/* Documentation string */</span>

    <span>/* Assigned meaning in release 2.0 */</span>
    <span>/* call function for all accessible objects */</span>
    <span>traverseproc</span> <span>tp_traverse</span><span>;</span>

    <span>/* delete references to contained objects */</span>
    <span>inquiry</span> <span>tp_clear</span><span>;</span>

    <span>/* Assigned meaning in release 2.1 */</span>
    <span>/* rich comparisons */</span>
    <span>richcmpfunc</span> <span>tp_richcompare</span><span>;</span>

    <span>/* weak reference enabler */</span>
    <span>Py_ssize_t</span> <span>tp_weaklistoffset</span><span>;</span>

    <span>/* Iterators */</span>
    <span>getiterfunc</span> <span>tp_iter</span><span>;</span>
    <span>iternextfunc</span> <span>tp_iternext</span><span>;</span>

    <span>/* Attribute descriptor and subclassing stuff */</span>
    <span>struct</span> <span>PyMethodDef</span> <span>*</span><span>tp_methods</span><span>;</span>
    <span>struct</span> <span>PyMemberDef</span> <span>*</span><span>tp_members</span><span>;</span>
    <span>struct</span> <span>PyGetSetDef</span> <span>*</span><span>tp_getset</span><span>;</span>
    <span>struct</span> <span>_typeobject</span> <span>*</span><span>tp_base</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_dict</span><span>;</span>
    <span>descrgetfunc</span> <span>tp_descr_get</span><span>;</span>
    <span>descrsetfunc</span> <span>tp_descr_set</span><span>;</span>
    <span>Py_ssize_t</span> <span>tp_dictoffset</span><span>;</span>
    <span>initproc</span> <span>tp_init</span><span>;</span>
    <span>allocfunc</span> <span>tp_alloc</span><span>;</span>
    <span>newfunc</span> <span>tp_new</span><span>;</span>
    <span>freefunc</span> <span>tp_free</span><span>;</span> <span>/* Low-level free-memory routine */</span>
    <span>inquiry</span> <span>tp_is_gc</span><span>;</span> <span>/* For PyObject_IS_GC */</span>
    <span>PyObject</span> <span>*</span><span>tp_bases</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_mro</span><span>;</span> <span>/* method resolution order */</span>
    <span>PyObject</span> <span>*</span><span>tp_cache</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_subclasses</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_weaklist</span><span>;</span>
    <span>destructor</span> <span>tp_del</span><span>;</span>

    <span>/* Type attribute cache version tag. Added in version 2.6 */</span>
    <span>unsigned</span> <span>int</span> <span>tp_version_tag</span><span>;</span>

    <span>destructor</span> <span>tp_finalize</span><span>;</span>
    <span>vectorcallfunc</span> <span>tp_vectorcall</span><span>;</span>
<span>};</span>
</pre></div>


<p>By the way, note that the first member of a type is not <code>PyObject</code> but <code>PyVarObject</code>, which is defined as follows:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span>
    <span>Py_ssize_t</span> <span>ob_size</span><span>;</span> <span>/* Number of items in variable part */</span>
<span>}</span> <span>PyVarObject</span><span>;</span>
</pre></div>


<p>Nevertheless, since the first member of <code>PyVarObject</code> is <code>PyObject</code>, a pointer to a type can still be converted to a pointer to <code>PyObject</code>.</p>
<p>So, what is a type and why does it have so many members? A type determines how the objects of that type behave. Each member of a type, called slot, is responsible for a particular aspect of the object's behavior. For example:</p>
<ul>
<li><code>tp_new</code> is a pointer to a function that creates new objects of the type.</li>
<li><code>tp_str</code> is a pointer to a function that implements  <code>str()</code> for objects of the type.</li>
<li><code>tp_hash</code> is a pointer to a function that implements  <code>hash()</code> for objects of the type.</li>
</ul>
<p>Some slots, called sub-slots, are grouped together in suites. A suite is just a struct that contains related slots. For example, the <code>PySequenceMethods</code> struct is a suite of sub-slots that implement the sequence protocol:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>lenfunc</span> <span>sq_length</span><span>;</span>
    <span>binaryfunc</span> <span>sq_concat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_repeat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_item</span><span>;</span>
    <span>void</span> <span>*</span><span>was_sq_slice</span><span>;</span>
    <span>ssizeobjargproc</span> <span>sq_ass_item</span><span>;</span>
    <span>void</span> <span>*</span><span>was_sq_ass_slice</span><span>;</span>
    <span>objobjproc</span> <span>sq_contains</span><span>;</span>

    <span>binaryfunc</span> <span>sq_inplace_concat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_inplace_repeat</span><span>;</span>
<span>}</span> <span>PySequenceMethods</span><span>;</span>
</pre></div>


<p>If you count all the slots and sub-slots, you'll get a scary number. Fortunately, each slot is very well <a href="https://docs.python.org/3/c-api/typeobj.html">documented</a> in the Python/C API Reference Manual (I strongly recommend you to bookmark this link). Today we'll cover only a few slots. Nevertheless, it shall give us a general idea of how slots are used.</p>
<p>Since we're interested in how CPython adds objects, let's find the slots responsible for addition. There must be at least one such slot. After careful inspection of the <code>PyTypeObject</code> struct, we find that it has the "number" suite <code>PyNumberMethods</code>, and the first slot of this suite is a binary function called <code>nd_add</code>:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>binaryfunc</span> <span>nb_add</span><span>;</span> <span>// typedef PyObject * (*binaryfunc)(PyObject *, PyObject *)</span>
    <span>binaryfunc</span> <span>nb_subtract</span><span>;</span>
    <span>binaryfunc</span> <span>nb_multiply</span><span>;</span>
    <span>binaryfunc</span> <span>nb_remainder</span><span>;</span>
    <span>binaryfunc</span> <span>nb_divmod</span><span>;</span>
    <span>// ... more sub-slots</span>
<span>}</span> <span>PyNumberMethods</span><span>;</span>
</pre></div>


<p>It seems that the <code>nb_add</code> slot is what we're looking for. Two questions naturally arise regarding this …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384433</guid>
            <pubDate>Fri, 11 Dec 2020 11:11:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI and Design Inspiration for Developers]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25384428">thread link</a>) | @kitsao
<br/>
December 11, 2020 | https://tipjarr.net/post/7-web-and-ui-design-inspiration-websites | <a href="https://web.archive.org/web/*/https://tipjarr.net/post/7-web-and-ui-design-inspiration-websites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img alt="5 website to get UI and design inspiration as a developer" data-srcset="https://images.unsplash.com/photo-1523726491678-bf852e717f6a?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80"></p><p>User Interface (UI) and Web design is the the process of planning the  overall feel of your website, how itâ€™s presented, how it looks, and how people can interact with it. This is important because a successful UI design contributes to a positive user experience, which is a competitive advantage.
Below are some of the  websites that might inspire your web/UI design eye as a web developer</p><h2><a href="https://dribbble.com/">Dribbble</a></h2><p><img alt="dribbble image" data-srcset="https://cdn.dribbble.com/assets/pro/landing-page/profile-desktop-x2-01baa8faad0be1942d913c0751648e13cc4d19228dcbb0d4e3abb2cb8f26b90a.png" src="https://cdn.dribbble.com/assets/pro/landing-page/profile-desktop-x2-01baa8faad0be1942d913c0751648e13cc4d19228dcbb0d4e3abb2cb8f26b90a.png"></p><p><strong>Dribbble</strong> is an online community for showcasing user-made artwork. It functions as a self-promotion and networking platform for:</p><ul><li>graphic design,</li><li>web design,</li><li>illustration,</li><li><p>photography</p></li></ul><p>Creative professionals such as illustrators, web designers, graphic designers and icon artists use Dribbble to promote their work and meet colleagues. As a web developer or UI designer dribbble is a great place to find inspiration for your next design. Dribbbble also offers amazing filter tools you can filter designs by color, Tags, Timeframe, and many other attributes Dribbble also has a pro subscription where you  get to email the designer of a particular shot you like. Overall its a neat platform to get inspiration from.</p><h2><a href="https://dribbble.com/">Behance</a></h2><p><img alt="Behance image" data-srcset="https://mir-s3-cdn-cf.behance.net/project_modules/1400/165af265485593.5af5bf8eae575.jpg" src="https://mir-s3-cdn-cf.behance.net/project_modules/1400/165af265485593.5af5bf8eae575.jpg"></p><p>Just like Dribbble <strong>Behance</strong> is also a social network owned by Adobe for creatives of just about every field and discipline. It's a place to connect, inspire, and get hiredâ€”a portfolio site that's so much more. 
As a developer, you can utilize Behance advanced  tools to search for design and get inspired
Behance  offers great filter tools like color, location, Layouts, and more...</p><h2><a href="https://www.awwwards.com/">Awwwards</a></h2><p><img alt="Awwwards image" data-srcset="https://assets.awwwards.com/awards/submissions/2019/02/5c54795c58ddb236387697.jpg" src="https://assets.awwwards.com/awards/submissions/2019/02/5c54795c58ddb236387697.jpg"></p><p><strong>Awwwards</strong> is a platform that recognizes the talent and effort of the best web designers, developers and agencies in the world.
It is a website competition that developers can submit to. The best year-round submissions are awarded at the Awwwards conference and prize-giving ceremony, which take place in various cities across the United States and Europe.
Awwwards also features a rating system for the websites featured and selects a new site each day to showcase.</p><h2><a href="https://www.frontendmentor.io/">Frontend Mentor</a></h2><p><img alt="Frontend mentor image" data-srcset="https://res.cloudinary.com/dz209s6jk/image/upload/v1585172856/Meta/meta-homepage.png" src="https://res.cloudinary.com/dz209s6jk/image/upload/v1585172856/Meta/meta-homepage.png"></p><p>Unlike Dribbble and Behance <strong>Frontend Mentors</strong> Gives You real-world HTML, CSS and JavaScript challenges whilst working to professional designs. Its a community of over 81,559 developers building projects, reviewing code, and helping each other get better.</p><h3>HOW IT WORKS</h3><ul><li><strong>Choose your challenge</strong><ul><li>Have a look through different collections of web designs. Pick one that you feel will be a nice challenge for you at this stage.</li></ul></li><li><strong>Code the design</strong><ul><li>Start the challenge and download all the starter files. They provide all the files you'll need to complete the challenge. Building it is up to you!</li></ul></li><li><strong>Submit your solution</strong><ul><li>Post your solution on the platform for everyone to see and get feedback on your code from other developers in the community.</li></ul></li><li><strong>Give others feedback</strong><ul><li>Thinking critically about other people's code is a crucial skill. Help others while deepening your own knowledge by giving feedback on solutions.</li></ul></li></ul><p>Frontend Masters helps you gain real experience of building websites and providing code reviews. Build your portfolio and help others achieve their goals.</p><h2><a href="https://www.pinterest.com/">Pinterest</a></h2><p><img alt="Pinterest image" data-srcset="https://s.pinimg.com/images/facebook_share_image.png" src="https://s.pinimg.com/images/facebook_share_image.png"></p><p><strong>Pinterest</strong> is a visual discovery engine for finding ideas like recipes, home and style inspiration, and more.
Pinterest is can be a great source for all kinds of design inspiration. You can use the â€˜Exploreâ€™ link to view categories like photography and illustration, or plug in â€˜web designâ€™ to filter images of various websites.</p><h3>Pins</h3><p>Pins are bookmarks that people use to save ideas they love on Pinterest.</p><p>With billions of Pins on Pinterest, you'll always find ideas to spark inspiration. When you discover Pins you love, save them to boards to keep your ideas organized and easy to find.
If you click through the Pin, you can visit the website to learn how to make it or where to buy it. As you discover Pins you love, click the red Save button to save them to your boards.</p><h2><a href="https://land-book.com/">Land book</a></h2><p><img alt="Landbook image" data-srcset="https://land-book.com/images/facebook-ad.png" src="https://land-book.com/images/facebook-ad.png"></p><p><strong>Land-book</strong> is a Design gallery  carefully collected websites. Landbook seeks to help creatives find inspiration &amp; motivation to make really cool stuff on the internet
Overall its a great place to find inspiration</p><h2><a href="https://httpster.net/">Httpster</a></h2><p><img alt="Httpster image" data-srcset="https://armory.visualsoldiers.com/wp-content/uploads/2017/08/httpster.jpg" src="https://armory.visualsoldiers.com/wp-content/uploads/2017/08/httpster.jpg"></p><p><strong>Httpster</strong> is an inspiration resource showcasing totally rocking websites made by people from all over the world.
Its simple design lets you easily discover and possibly get inspired by designs from around
the world</p><h2>Conclusion</h2><p>Finding design inspiration as a developer can be challenging, but hopefully the resources above might
come in handy whenever you face a design block. Happy hacking .</p></div></div>]]>
            </description>
            <link>https://tipjarr.net/post/7-web-and-ui-design-inspiration-websites</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384428</guid>
            <pubDate>Fri, 11 Dec 2020 11:10:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decoding the Language of Genomes]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25384412">thread link</a>) | @srom
<br/>
December 11, 2020 | https://caltechletters.org/science/decoding-the-language-of-genomes | <a href="https://web.archive.org/web/*/https://caltechletters.org/science/decoding-the-language-of-genomes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">

<p><img src="https://caltechletters.org/media/posts/2020-11-03-decoding-the-genome/wilson_dna.jpg" alt=""></p>

<p><a href="https://sarahzeichner.weebly.com/" target="_blank">Illustration by Sarah Zeichner for Caltech Letters</a></p>
<p><span>T</span>he year was 2003, and the first human genome had been <a href="https://www.genome.gov/human-genome-project" target="_blank">sequenced</a>.</p>
<p>By almost every metric, it was an extraordinary achievement. The completion of the Human Genome Project provided a starting point for scientists to study the “<a href="https://medlineplus.gov/genetics/" target="_blank">blueprint for building a person</a>”. Pharmaceutical companies suddenly possessed a genetic chart to design more targeted medicines. Archaeologists gained a roadmap to compare human genomes through the ages. Biologists acquired a lodestar to locate the genes governing health and behavior. The floodgates of the genomic era had officially opened. But the project also revealed a mystery.</p>
<p>In the 1990s, scientists <a href="https://web.ornl.gov/sci/techresources/Human_Genome/project/5yrplan/index.shtml" target="_blank">estimated</a> that the Human Genome Project would unveil 100,000 human genes. But the sequencing results revealed a stark reality: humans only have 20,000 genes—<a href="https://www.nsf.gov/news/news_summ.jsp?cntn_id=118530" target="_blank">10,000 fewer than a water flea</a>. It seems remarkable that humans—with our fancy bipedalism and oversized brains—could have fewer genes than a microscopic crustacean.</p>
<p>A lot has changed in the two decades since the Human Genome Project. The technology to sequence genes has gotten cheaper and faster. The first human genome sequence cost three billion dollars, involved thousands of scientists, and took 13 years to complete. Today, sequencing machines can read a human genome in less than a day for a few hundred dollars. But technology is not a substitute for knowledge, and scientists still don’t fully understand how the genome works.</p>
<p><img src="https://caltechletters.org/media/posts/2020-11-03-decoding-the-genome/broad_center.jpg" alt=""></p>
<p>The Broad Center for the Biological Sciences at Caltech.</p>
<p>Photo by Suzy Beeler</p>
<p>Nestled in the back corner of the <a href="https://broadfoundation.org/grantees/the-broad-center-for-biological-science-at-caltech/" target="_blank">Broad Center for the Biological Sciences</a> at Caltech, our research laboratory aims to understand how genomes encode and express information. To find us on campus, look for the cubic building made from metal and travertine, with sweeping views of the San Gabriel mountains. On a clear day many months ago, before the pandemic confined us to untidy apartments, we could see Mt. Wilson Observatory from our offices. Its white telescopes dot the mountain’s summit, silhouetted against the rising sun. Inside the lab, our benches are cluttered with liquid-filled bottles and metal pipettes.</p>
<p>We study genomes, in part, because of the impact on our impressionable young minds when the Human Genome Project made national news back in 2003. The structure of DNA had been <a href="https://www.nature.com/scitable/topicpage/discovery-of-dna-structure-and-function-watson-397/" target="_blank">established</a> fifty years earlier, thanks to herculean efforts from Rosalind Franklin, James Watson, Francis Crick, and others. Our understanding of genomes came a long way in those 50 years, from structure to sequence. But we know that there is more to learn.</p>
<p>About <a href="https://www.forbes.com/sites/matthewherper/2017/01/09/illumina-promises-to-sequence-human-genome-for-100-but-not-quite-yet/#14098b8f386d" target="_blank">500,000 human genomes</a> have been sequenced since 2003. Sequencing machines are now commonplace at universities. Humming on tables, they look like space-age computer systems, with touch screens and tiny, pneumatic tubes. DNA is extracted from living cells, trillions of copies are made using a technique called <a href="https://www.youtube.com/watch?v=matsiHSuoOw&amp;vl=en" target="_blank">PCR</a>, and the copied molecules are loaded (carefully!) into the machine. A few hours later, after the humming subsides, an interminable string of characters appears on the screen, made up of four letters: A, T, C, and G.</p>
<p>All genomes on earth are made up of these letters, called nucleotides. Each letter is a unique molecule—adenine, thymine, cytosine, and guanine—that links up to the others, forming a minimal alphabet. With these four letters, our cells construct words, or—in the context of biology—genes.</p>
<p>Much as a Xerox machine can make thousands of copies from a single document, genes are converted to messenger RNA in a process called <a href="https://www.youtube.com/watch?v=whV_CkKT7F0" target="_blank">transcription</a>, which then serves as a template to build proteins. The human genome encodes about 20,000 genes, which in turn produce proteins that fend off viral invaders, manage blood sugar levels, and everything in between.</p>
<iframe width="280" height="156" src="https://www.youtube.com/embed/8M198uHJd_8?start=0" frameborder="0" allowfullscreen=""></iframe>
<p>This short animation shows how transcription happens.</p>

<p>But we cannot “see” these dynamic changes with a DNA sequence. The order of letters in a genome tells us nothing about how a gene is controlled in the molecular confines of a cell. Gene expression is dynamic and changing. Genes are turned on and off as proteins are needed, and these changes over time may explain how genomes can give rise to the most beautiful of lifeforms. In other words, it may explain how we are human, despite a trifling 20,000 genes.</p>
<p>We study how genomes are controlled because we want to understand ourselves. In doing so, we are building upon more than 80 years of experimental history.</p>
<hr>
<p>In the 1940s, Jacques Monod and François Jacob, frantically working in a little laboratory in the Necker neighborhood of Paris, found that cells control protein numbers by turning genes “on” or “off”. Though their results seem obvious today (the best results always do), they shared the <a href="https://www.nobelprize.org/prizes/medicine/1965/summary/" target="_blank">1965 Nobel Prize</a> in Physiology or Medicine for their work.</p>
<p>Genes are regulated by proteins called transcription factors, of which there are two types: activators, which bind to DNA near the start of a gene and increase the amount of mRNA copies made from a gene, much like loading more paper into a Xerox tray, and repressors, which decrease the amount of mRNA copies. Transcription factors hold dominion over the genome, controlling when each gene gets to make its Xerox copies.</p>
<p>Jacob and Monod’s findings provided a potential solution to the question that arose from the first human genome sequence, 60 years later. Perhaps an organism’s complexity is dictated not by how many genes are present in a genome, but rather by how those genomes are controlled, over time, by transcription factors.
To build upon the work of our scientific heroes, our lab at Caltech wanted to determine which type of transcription factor—activator or repressor—regulates each and every gene. To test our experiments, we decided to start with a small genome. We turned to a bacterium, <em>Escherichia coli</em>.</p>
<p>In the grand order of nature, <em>E. coli</em> is relatively simple, containing 4,000 genes and 200 transcription factors. But, despite its meager size, we still do not know how two-thirds of its genes are regulated.</p>
<p><img src="https://caltechletters.org/media/posts/2020-11-03-decoding-the-genome/ecoli_genome.png" alt=""></p>
<p>The <i>E. coli</i> genome contains about 4.6 million nucleotides and 4,000 genes. In this diagram, genes that have known regulation (which means that we know which transcription factors regulate them) are marked in blue. For most genes (roughly two-thirds), we have no idea which transcription factors regulate or control them (marked in red).</p>
<p>Diagram by Niko McCarty</p>
<p>We knew that if we ever wanted to understand how even a small bacterial genome is regulated, a new experimental method would be needed. So we <i>created</i> one.</p>
<hr>
<p>When <a href="https://sites.uw.edu/theriotlab/members/" target="_blank">Nathan Belliveau</a> joined the lab, a few years ago, his objective was simple: find an easy way to determine how genes in <em>E. coli</em> are regulated.</p>
<p>Sitting at the bench, he harvested genetic material from <em>E. coli</em> and loaded the DNA into a sequencer. After a few years—and hundreds of trials—he <a href="https://www.pnas.org/content/115/21/E4796" target="_blank">reported</a> the foundations of a radical method that would eventually enable our laboratory to figure out which transcription factors regulate hundreds, or thousands, of genes at a time. Nathan left the group in 2017, PhD in hand, and flew to colder climates. Bill Ireland and Suzy Beeler (an author of this article) took over the project.</p>
<p>They, too, spent years agonizing over the method. After using thousands of tubes of DNA and covering their benches in teetering stacks of bacteria-streaked agar plates, Bill and Suzy managed to extend Nathan’s findings to more than a hundred genes. In the process, they refined a powerful method that lends deep insights into the intricate, molecular machines that regulate genomes.</p>
<p>Here’s how the method works.</p>
<p>We begin by literally mail ordering short sequences of DNA—the regions immediately in front of a gene—where transcription factors typically bind. A computer helps us design mutated versions of each DNA sequence, randomly changing the letters until we have thousands of variants for each sequence. A company in San Francisco takes our digital letters, creates physical copies, and ships them in a little plastic tube to our laboratory. We then place these synthetic pieces of DNA inside of <em>E. coli</em> cells, and use a modified version of DNA sequencing to determine whether each “letter” change made a gene produce more or fewer Xerox copies.</p>
<p>If a DNA sequence produces very little RNA inside of the cell, this suggests that the letter change (or mutation) blocked transcription; it choked up the Xerox machine. It also indicates that an activator was probably binding to that DNA sequence, and the mutation prevented it from doing its job. Some mutations, however, increase the amount of RNA produced from a DNA sequence, suggesting that the mutation is preventing a repressor from binding.</p>
<p>By analyzing this data and running it through mathematical models, we can determine whether each gene is regulated by an activator or repressor, how many transcription factors regulate each gene, and where those transcription factors actually bind.</p>
<p>In other words, we can map the genome’s regulatory networks.</p>
<p><img src="https://caltechletters.org/media/posts/2020-11-03-decoding-the-genome/lab.jpg" alt=""></p>
<p>A bench in our laboratory, where this work was performed</p>
<p>Photo by Suzy Beeler</p>
<p>After performing this experiment on more than one hundred genes, we made some startling discoveries. In one case, we found a transcription factor with dual activity: it activated the transcription of one gene while repressing the transcription of another. We also identified transcription factors that are only active in certain environments; when <em>E. coli</em> is grown in the presence of a sugar, for example, a transcription factor called GlpR represses a handful of genes. Without the sugar, GlpR doesn’t work at all.</p>
<p>In our opinion, this <a href="https://elifesciences.org/articles/55308" target="_blank">study</a> marks a major advancement in genomic research. But it didn’t come for free.</p>
<p>Throughout the last five years, we have failed repeatedly. We have mislabeled tubes and used ethanol instead of water to dilute DNA. We have dropped flasks, shattering glass and spilling bacteria on the floor. We have been frustrated, again and again. But we continued on, inching closer …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://caltechletters.org/science/decoding-the-language-of-genomes">https://caltechletters.org/science/decoding-the-language-of-genomes</a></em></p>]]>
            </description>
            <link>https://caltechletters.org/science/decoding-the-language-of-genomes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384412</guid>
            <pubDate>Fri, 11 Dec 2020 11:08:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Slowest Computer Programs Illuminate Math’s Fundamental Limits]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25384333">thread link</a>) | @dnetesn
<br/>
December 11, 2020 | http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>P</span>rogrammers normally want to minimize the time their code takes to execute. But in 1962, the Hungarian mathematician Tibor RadÃ³ posed the opposite problem. He asked: How long can a simple computer program possibly run before it terminates? RadÃ³ nicknamed these maximally inefficient but still functional programs â€œbusy beavers.â€�</p>

<p>Finding these programs has been a fiendishly diverting puzzle for programmers and other mathematical hobbyists ever since it was popularized in Scientific Americanâ€™s&nbsp;<a href="https://www.scientificamerican.com/article/computer-recreations-1984-08/" target="_blank">â€œComputer Recreationsâ€� column</a>&nbsp;in 1984. But in the last several years, the busy beaver game, as itâ€™s known, has become an object of study in its own right, because it has yielded connections to some of the loftiest concepts and open problems in mathematics.</p>
<p>â€œIn math, there is a very permeable boundary between whatâ€™s an amusing recreation and what is actually important,â€� said&nbsp;<a href="https://www.cs.utexas.edu/people/faculty-researchers/scott-aaronson" target="_blank">Scott Aaronson</a>, a theoretical computer scientist at the University of Texas, Austin who published a&nbsp;<a href="https://dl.acm.org/doi/10.1145/3427361.3427369" target="_blank">survey</a>&nbsp;of progress in â€œBusyBeaverology.â€�<br></p>
<p>The recent work suggests that the search for long-running computer programs can illuminate the state of mathematical knowledge, and even tell us whatâ€™s knowable. According to researchers, the busy beaver game provides a concrete benchmark for evaluating the difficulty of certain problems, such as the unsolved Goldbach conjecture and Riemann hypothesis. It even offers a glimpse of where the logical bedrock underlying math breaks down. The logician Kurt GÃ¶del proved the existence of such mathematical terra incognita nearly a century ago. But the busy beaver game can show where it actually lies on a number line, like an ancient map depicting the edge of the world.</p><p><strong>An Uncomputable Computer Game</strong></p>
<p>The busy beaver game is all about the behavior of Turing machines—the primitive, idealized computers&nbsp;<a href="https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf" target="_blank">conceived by Alan Turing in 1936</a>. A Turing machine performs actions on an endless strip of tape divided into squares. It does so according to a list of rules. The first rule might say:</p>
<blockquote>If the square contains a 0, replace it with a 1, move one square to the right and consult rule 2. If the square contains a 1, leave the 1, move one square to the left and consult rule 3.</blockquote>
<p>Each rule has this forking choose-your-own-adventure style. Some rules say to jump back to previous rules; eventually thereâ€™s a rule containing an instruction to â€œhalt.â€� Turing proved that this simple kind of computer is capable of performing any possible calculation, given the right instructions and enough time.</p>
<p>As Turing noted in 1936, in order to compute something, a Turing machine must eventually halt—it canâ€™t get trapped in an infinite loop. But he also proved that thereâ€™s no reliable, repeatable method for distinguishing machines that halt from machines that simply run forever—a fact known as the halting problem.</p>
<p>The busy beaver game asks: Given a certain number of rules, whatâ€™s the maximum number of steps that a Turing machine can take before halting?</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/abstractions_448ca98db9d7b1349758c6545cdf7237.jpg" alt="nautilus tibor rado"><figcaption><span>Tibor RadÃ³, shown here in an undated photo, invented the busy beaver game as a way of making the theoretical notion of uncomputability concrete. </span><br><span>Courtesy of The Ohio State University Archives</span></figcaption></figure>
<p>For instance, if youâ€™re only allowed one rule, and you want to ensure that the Turing machine halts, youâ€™re forced to include the halt instruction right away. The busy beaver number of a one-rule machine, or BB(1), is therefore 1.</p>
<p>But adding just a few more rules instantly blows up the number of machines to consider. Of 6,561 possible machines with two rules, the one that runs the longest—six steps—before halting is the busy beaver. But some others simply run forever. None of these are the busy beaver, but how do you definitively rule them out? Turing proved that thereâ€™s no way to automatically tell whether a machine that runs for a thousand or a million steps wonâ€™t eventually terminate.</p>
<p>Thatâ€™s why finding busy beavers is so hard. Thereâ€™s no general approach for identifying the longest-running Turing machines with an arbitrary number of instructions; you have to puzzle out the specifics of each case on its own. In other words, the busy beaver game is, in general, â€œuncomputable.â€�</p>
<p>Proving that BB(2) = 6 and that BB(3) = 107 was difficult enough that RadÃ³â€™s student Shen Lin earned a doctorate for the work in 1965. RadÃ³ considered BB(4) â€œentirely hopeless,â€� but&nbsp;the case was&nbsp;<a href="https://www.ams.org/journals/mcom/1983-40-162/S0025-5718-1983-0689479-6/S0025-5718-1983-0689479-6.pdf" target="_blank">finally solved in 1983</a>. Beyond that, the values virtually explode; researchers have identified a five-rule Turing machine, for instance, that runs for 47,176,870 steps before stopping, so BB(5) is at least that big. BB(6) is at least 7.4 Ã— 1036,534.&nbsp;&nbsp;Proving the exact values â€œwill need new ideas and new insights, if it can be done at all,â€� said Aaronson.</p>
<p><strong>Threshold of Unknowability</strong></p>
<p><a href="https://www.cs.umd.edu/users/gasarch/" target="_blank">William Gasarch</a>, a computer scientist at the University of Maryland, College Park, said heâ€™s less intrigued by the prospect of pinning down busy beaver numbers than by â€œthe general concept that itâ€™s actually uncomputable.â€� He and other mathematicians are mainly interested in using the game as a yardstick for gauging the difficulty of important open problems in mathematics—or for figuring out what is mathematically knowable at all.</p>
<p>The Goldbach conjecture, for instance, asks whether every even integer greater than 2 is the sum of two primes. Proving the conjecture true or false would be an epochal event in number theory, allowing mathematicians to better understand the distribution of prime numbers. In 2015, an anonymous GitHub user named Code Golf Addict&nbsp;<a href="https://gist.github.com/anonymous/a64213f391339236c2fe31f8749a0df6" target="_blank">published code</a>&nbsp;for a 27-rule Turing machine that halts if—and only if—the Goldbach conjecture is false. It works by counting upward through all even integers greater than 4; for each one, it grinds through all the possible ways to get that integer by adding two others, checking whether the pair is prime. When it finds a suitable pair of primes, it moves up to the next even integer and repeats the process. If it finds an even integer that canâ€™t be summed by a pair of prime numbers, it halts.</p>
<p>Running this mindless machine isnâ€™t a practical way to solve the conjecture, because we canâ€™t know if it will ever halt until it does. But the busy beaver game sheds some light on the problem. If it were possible to compute BB(27), that would provide a ceiling on how long weâ€™d have to wait for the Goldbach conjecture to be settled automatically. Thatâ€™s because BB(27) corresponds to the maximum number of steps this 27-rule Turing machine would have to execute in order to halt (if it ever did). If we knew that number, we could run the Turing machine for exactly that many steps. If it halted by that point, weâ€™d know the Goldbach conjecture was false. But if it went that many steps and didnâ€™t halt, weâ€™d know for certain that it never would—thus proving the conjecture true.</p>
<p>The rub is that BB(27) is such an incomprehensibly huge number that even writing it down, much less running the Goldbach-falsifying machine for that many steps, isnâ€™t remotely possible in our physical universe. Nevertheless, that incomprehensibly huge number is still an exact figure whose magnitude, according to Aaronson, represents â€œa statement about our current knowledgeâ€� of number theory.</p>
<p>In 2016, Aaronson established a similar result in collaboration with Yuri Matiyasevich and Stefan Oâ€™Rear. They identified a 744-rule Turing machine that halts if and only if the Riemann hypothesis is false. The Riemann hypothesis also concerns the distribution of prime numbers and is one of the Clay Mathematics Instituteâ€™s&nbsp;<a href="https://www.claymath.org/millennium-problems/riemann-hypothesis" target="_blank">â€œMillennium Problemsâ€�</a>&nbsp;worth $1 million. Aaronsonâ€™s machine will deliver an automatic solution in BB(744) steps. (It works by essentially the same mindless process as the Goldbach machine, iterating upward until it finds a counterexample.)</p>
<p>Of course, BB(744) is an even more unattainably large number than BB(27). But working to pin down something easier, like BB(5), â€œmay actually turn up some new number theory questions that are interesting in their own right,â€� Aaronson said. For instance, the mathematician Pascal Michel&nbsp;<a href="https://link.springer.com/article/10.1007/BF01409968" target="_blank">proved</a>&nbsp;in 1993 that the record-holding five-rule Turing machine exhibits behavior similar to that of the function described in the Collatz conjecture, another&nbsp;<a href="https://www.quantamagazine.org/why-mathematicians-still-cant-solve-the-collatz-conjecture-20200922/" target="_blank">famous open problem</a>&nbsp;in number theory.</p>
<p>â€œSo much of math can be encoded as a question of, â€˜Does this Turing machine halt or not?â€™â€� Aaronson said. â€œIf you knew all the busy beaver numbers, then you could settle all of those questions.â€�</p>
<p>More recently, Aaronson has used a busy-beaver-derived yardstick to gauge what he calls â€œthe threshold of unknowabilityâ€� for entire systems of mathematics. GÃ¶delâ€™s famous&nbsp;<a href="https://www.quantamagazine.org/how-godels-incompleteness-theorems-work-20200714/" target="_blank">incompleteness theorems</a>&nbsp;of 1931 proved that any set of basic axioms that could serve as a possible logical foundation for mathematics is doomed to one of two fates: Either the axioms will be inconsistent, leading to contradictions (like proving that 0 = 1), or theyâ€™ll be incomplete, unable to prove some true statements about numbers (like the fact that 2 + 2 = 4). The axiomatic system underpinning almost all modern math, known as Zermelo-Fraenkel (ZF) set theory, has its own GÃ¶delian boundaries—and Aaronson wanted to use the busy beaver game to establish where they are.</p>
<p>In 2016, he and his graduate student Adam Yedidia specified a 7,910-rule Turing machine that would only halt if ZF set theory is inconsistent. This means BB(7,910) is a calculation that eludes the axioms of ZF set theory. Those axioms canâ€™t be used to prove that BB(7,910) represents one number instead of another, which is like not being able to prove that 2 + 2 = 4 instead of 5.</p>
<p>Oâ€™Rear subsequently devised a much simpler 748-rule machine that halts if ZF is inconsistent—essentially moving the threshold of unknowability closer, from BB(7,910) to BB(748). â€œThat is a kind of a dramatic thing, that the number [of rules] is not completely ridiculous,â€� said&nbsp;<a href="https://math.osu.edu/people/friedman.8" target="_blank">Harvey Friedman</a>, a mathematical …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits">http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits</a></em></p>]]>
            </description>
            <link>http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384333</guid>
            <pubDate>Fri, 11 Dec 2020 10:49:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fruits of the Deep]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384321">thread link</a>) | @dnetesn
<br/>
December 11, 2020 | http://oceans.nautil.us/feature/649/the-hidden-fruits-of-the-deep | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/649/the-hidden-fruits-of-the-deep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>I</span>n the sheltered lagoons of the Great Barrier Reef lie sandy flats the size of Switzerland where reef-building corals refuse to grow. Much of the seafloor here resembles a moonscape hewn with small eruptions—the modest houses of timid crustacean architects.&nbsp;</p><p>Each year, however, when the sunlight filters through in just the right way, thousands of stout, spoon-shaped leaves encrusted with silvery hairs begin to emerge. Linked by spindly runners, they cover the seafloor within a few weeks, forming a fine herbage that dots the sediment. For several months they cling to the seabed, blossoming with tiny flowers that fruit and float below the tide. Soon they will shed their seeds into the sandy banks and lay in wait for the right sunlight to filter through once again.<br></p>
<p>Growing in interstitial spaces too deep for SCUBA-diving scientists and too shallow for deep-sea exploration vehicles, deep-water seagrasses are hidden powerhouses that have sprouted silently on the peripheries for tens of millions of years. Yet even as seagrasses are globally recognized as among Earthâ€™s most important and productive ecosystems, studies have largely focused on shallow meadows found at depths of 15 meters or less.&nbsp;</p>
<p>Deeper meadows like those in the Great Barrier Reef lagoons have long been overlooked, in part because theyâ€™re literally difficult to see: as depth increases, light loses certain wavelengths, and colors are quickly muted. By the early 1990s, though, scientists had calculated that, based on physiological limitations, seagrasses should survive to around 90 meters below the surface. Potentially vast meadows remained to be discovered.</p>
<p>These meadows are the focus of Michael Rasheed and Paul York, biologists at James Cook University in Australia. Rasheed started studying these important yet obscure habitats in the mid-1990â€™s, when he was part of a team that towed cameras behind research vessels to map habitats across vast areas of ocean. Waiting in vain to catch an on-screen glimpse of the leafy meadows amongst the watery moonscape, the limitations of the technology quickly became apparent.</p>
<p>York, Rasheed and their colleagues took a different approach. In their part of the world, fat, nine-foot-long dugongs—a member of the taxonomic order that includes manatees—munch up to 35 kilograms of seagrasses a day. By following dugongs, the researchers discovered more than 30,000 square kilometers of seagrass meadows growing on the margins of their biological limits.&nbsp;</p>
<p>Among these were the largest continuous seagrass meadow mapped in Australian waters, covering some 8,750 square kilometers and consisting mostly of deep-water grasses. These new beds represented a huge increase in the potential area across which seagrasses, already known to sequester up to twice as much carbon per acre as terrestrial forests, and at dramatically faster rates, may buffer against climate change.&nbsp;</p>
<p>Another group of researchers led by Nicole Esteban from Swansea University in Wales also followed animals to deep-water seagrasses. By tracking GPS-tagged green sea turtles thousands of kilometers, Esteban and her colleagues discovered significant feeding territories on the remote Chagos Archipelago in the Western Indian Ocean. In 2016, Estebanâ€™s team were the first scientists to dive these new sites; they expected to find the meadows at depths of 10 meters, but soon realized they extended far deeper.</p><figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_b958b97b3ad6d40d9b35e81f06058619.jpg" alt="Screen Shot 2020-12-08 at 11.48.24 PM"><figcaption><span>Life teems above a carpet of deep-water Thalassodendron ciliatum seagrass. In the foreground is a baited camera. </span><br><span>Nicole Esteban</span></figcaption></figure><p><span>B</span>eneath the waves licking the edge of the worldâ€™s largest atoll, the Great Chagos Bank, a white calcium carbonate hill leads down to the depths. Against the current, shadows of glistening, scaled bodies wash over the seabed. Grasping coralline rubble, tangles of forty-centimeter long leaves shoot towards the filtered sunlight. Like lime green fingers waving to the shattered ceiling of water, they briefly interlock before sighing away in new directions as the swell rolls on across the slope.&nbsp;</p>
<p>In stark contrast to the system where York and Rasheed work, Estebanâ€™s plunge took her to gardens where <i>Thalassodendron ciliatum</i>, one of the largest seagrasses on the planet, covers up to 90 percent of the seabed and has hundreds of fish like the large predatory grey reef shark, African white-spotted rabbitfish and red snapper swimming overhead.&nbsp;</p>
<p>Because of safety restrictions on diving below 25 meters, Estebanâ€™s team deployed underwater cameras. They revealed that seagrasses were abundant down to at least 29 meters depth. The discovery there suggested that seagrasses could extend across hundreds—possibly even thousands—of kilometers of the Chagos Archipelago, completely changing existing maps.&nbsp;</p>
<p>The presence of such expansive canopies suggests that, in addition to sequestering carbon, deep-water seagrass meadows provide an important safe haven of food and habitat for countless marine species, including many that are currently endangered.
</p>
<p>Updated with findings like these, estimates now suggest that the real global seagrass-meadow footprint could be 35 times greater than previous estimates of 150,000 to 600,000 square kilometers, covering an area roughly the size of the United States. These meadows may be critical refuges, for in the darker, cooler parts of the ocean these seagrasses may escape the worst of climate change and ocean-warming effects.</p>
<p>Now the seagrass research community is planning to follow still more marine megaherbivores to find and understand new seagrass habitats. The West Indies, Kenya and Mozambique are high on the list.&nbsp;</p>
<p>Shallow-water seagrass meadows have already been recognized as a powerful nature-based climate solution by the United Nations. They stabilize sediments and prevent erosion, protect corals, and provide critical food and habitat for thousands of species. They suck in carbon dioxide, locking it into sediment up to 40 times faster than the typical terrestrial forest, and release oxygen in return. Deep-water seagrasses likely sequester less carbon per acre than their shallow-water brethren but occupy a larger area, meaning their sequestration potential is likely vast as well.</p>
<p>Shallow-water seagrass meadows are rapidly disappearing, though, killed by pollution and dredging and ecosystem-disrupting human activity—and deep-water seagrasses may be threatened, too.</p>
<p>Without knowing exactly where deep-water meadows lie, though, we are limited in our ability to understand their value or protect them. Without exploration our knowledge is restricted to chance discoveries and anecdotal evidence. The most extreme examples suggest that seagrasses may grow even deeper than our best estimates: in 2003 some tendrils of <i>Halophila stipulacea, </i>a particularly hardy species adapted to low light, were collected while dredging at depths of 145 meters off the Cyprus coast.&nbsp;</p>
<p>Such discoveries of deep-water meadows radically expand our knowledge of seagrasses. They provide much-needed optimism that pristine places still exist, and remind us that there is still so much we have yet to learn.</p>
<ul><li> (<a href="https://twitter.com/GeorgeValentin_">@GeorgeValentin_</a>) is a science writer and researcher based in New South Wales, Australia. She is currently a Postdoctoral Research Associate at the University of Sydney, where she focuses on the restoration and future-proofing of underwater forests.</li></ul>
<p><em>Research by Nicole Esteban was funded by the&nbsp;</em><a href="http://www.fndation-bertarelli.org/" target="_blank"><strong><em>BERTARELLI FOUNDATION</em></strong></a><em>.&nbsp; You can find out more about its marine science programme at&nbsp;</em><a href="http://www.marine.science/" target="_blank"><em></em></a><em><a href="http://www.marine.science/">www.marine.science</a></em></p>
<p>Lead image:&nbsp;Deep-water <em>Halophila</em> seagrasses. Credit:&nbsp;JCU Seagrass Ecology Lab</p>
    </article></div>]]>
            </description>
            <link>http://oceans.nautil.us/feature/649/the-hidden-fruits-of-the-deep</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384321</guid>
            <pubDate>Fri, 11 Dec 2020 10:46:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Start a Podcast in 2021 – A Step by Step Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384162">thread link</a>) | @tomhuntio
<br/>
December 11, 2020 | https://www.bcast.fm/blog/how-to-start-a-podcast | <a href="https://web.archive.org/web/*/https://www.bcast.fm/blog/how-to-start-a-podcast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><strong><em>This is the first post in the three-part series. Part two focuses on </em></strong><a href="https://www.bcast.fm/blog/how-to-launch-a-podcast" target="_blank"><strong><em>how to launch a podcast</em></strong></a><strong><em>, and part three focuses on how to grow a podcast.</em></strong></p><p>The podcast industry is snowballing.&nbsp;</p><p>But don’t worry, the number of listeners is growing faster than the number of podcasts. </p><p>All the BIG tech businesses are investing heavily in the podcast space, bringing bigger and better audio tools, which in turn bring more people to podcasts.</p><ul role="list"><li>Apple - Apple Podcasts and AirPods</li><li>Google - Google Podcasts and Google Podcast Manager</li><li>Spotify - Spotify for Podcasters</li><li>Amazon - Amazon Music and Alexa</li></ul><p>We’re talking billions of dollars being spent on enabling more and more people to flood into podcasts… you just have to be there to mop them up :)</p><figure id="w-node-f4cfd1480d0a-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf93b331b3c358913488_4X1o_362OKLNxFY5BysBQvm9-hmMKWsrZaYwN-X3atvqRXHV361ktXo_hXBJN6mXC1rcbQHcBBZFbUFOMmLssnfNVUcMlMpj6fuFnM6sFzOiVmQ2lzBMzssQmMlu-AgzVQtfxVz2.gif" alt=""></p></figure><p>Research has shown that over <a href="https://www.statista.com/statistics/786826/podcast-listeners-in-the-us/" target="_blank">103 million Americans have at least one podcast</a> they listen to every month in the US – this number will keep growing. Despite this... there are still over 600 blogs for every podcast in the world ;)</p><figure id="w-node-a4cc97581060-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf92a6071203f4bd93fc_s-So6SEwWD4eheC2_twd61hX0idTzHglF81LuQoxdwe3gACuUrSqGmx5PPGKQkwEaZ5d_iWW9BsNFTCyJ8JUodSpf5Qoyk6lnOHAlFA3ODwgO1SO4jvmFBofVKLD4lsVuIu4aigH.png" alt=""></p><figcaption><em>Source: Statista.com</em></figcaption></figure><p><strong>A podcast will grow your brand.</strong></p><p>Whether that be you as a person or you for your business. There are many reasons why you should start a podcast.</p><p>And fortunately, if you want to know the right steps to make to start a successful podcast, you are in the right place.</p><p>In this easy-to-understand step-by-step guide, we will break down everything you need to start your podcast for free from developing a plan to securing the right equipment and software to use.&nbsp;</p><p>Bookmark this page and keep referring back to as you move through the process of starting your first (or next!) podcast, and when you launch make sure you ping us a link by email to <a href="mailto:support@bcast.fm">support@bcast.fm</a> - we will subscribe!</p><figure id="w-node-e9418c7b6c75-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf93154cd636df1dd20b_QUaPSMMrdnQRcLu0jfIP-o-iLKto34jtuaLiEPQDSJSu_4NBmW8vDPuKaMumd-4VF51oguynh0RW81UeQZxtwWyfiC0zuL0wQBmwBpBM-GP81DiWV9UUle1Jr44v-JSw_CB6HxYs.gif" alt=""></p></figure><h2><strong>STEP 1: DEVELOP A PLAN</strong></h2><p>Of course... you need a solid plan before starting a podcast. </p><p>Your podcast is a result of your thoughts and actions, and this is why you need a plan. You need to be deliberate about what you create. Your podcast gets its uniqueness from you, as you are the creator and director. </p><p>Your podcast is a result of your<strong> imagination</strong> and your <strong>ability to execute</strong>.</p><p>You must have a reason for starting your podcast, and this where the “WHY” and “WHAT” questions come in. The answer to these questions will help you create a podcast that is both unique to you but will also be able to add massive value to anyone that subscribes.&nbsp;</p><h3><strong>Why Do You Want To Start A Podcast?</strong></h3><p>There are various reasons for starting a podcast, and it varies per person. This question can have a lot of answers, but your conviction is the most important factor.</p><p><em>How much do you want to start a podcast?</em></p><p>Because if your answer is not a firm yes, then you may have challenges putting in the consistent effort to make it grow.</p><p><em>Why do you want to start a podcast?</em></p><p>There could be various reasons...<br></p><ul role="list"><li>To promote your business</li><li>To talk about your passion</li><li>To preach to the world</li><li>To share your message</li><li>To establish yourself as an authority</li><li>To have fun</li></ul><p>Whatever your reason is, you must be convinced.</p><p>This conviction will help you create a lasting relationship with your audience as you continue to execute over time when others fail to be consistent.</p><p>If&nbsp;you look at all the most popular podcasts... you will see that they have been running for years and even decades. This is what you must be prepared to do to generate a sizeable audience.</p><h3><strong>What Is The Topic Of Your Podcast?</strong></h3><p>It's now time to choose a theme/topic for your podcast. </p><p>This is the BIG one. It's make or break.</p><p>You MUST consider:</p><ul role="list"><li>Your passion on the topic</li><li>Your expertise and experience of the topic</li><li>The ability for your to monetise the topic</li></ul><p>Here at bCast, we are all about podcast profitability. We're not hobbyists. We know you need to get paid if you're going to do this for the long term and build a podcast worth listening to.</p><p>Now monetisation can come from advertising... so you don't necessarily need to have products or services in the niche or topic of your podcast... but you will need an intense passion.</p><p>Once you have spent a long time sitting in a dark room thinking about this... you then need to understand the #1 thing that will define the success or failure of your podcast:</p><p><strong><em>How are you different or better for a specific group of people?</em></strong></p><p>As if you are not... and you don't have a load of money to spend on Facebook Ads, it's going to be hard to make your podcast grow. Trust me... we know.</p><p>Maybe you only ask specific types of questions; perhaps you focus on a particular niche, perhaps you only interview three people at a time… it can be anything as long as it makes you different or better for a specific group of people.</p><p>If you are VERY particular about this… you will more than double your chances of succeeding.</p><h3><strong>Who Are Your Listeners?</strong></h3><p>Now that you have answered the WHY and WHAT, it is time to answer the WHO question.</p><p>Every podcast needs listeners, and in order for your podcast to grow... you must know exactly who your listeners are and where to find them.&nbsp;</p><figure id="w-node-08046cb77a20-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf937aa690314e79dafd__co8aVE5evZ3_Tzk8ZugkGqAFkT8oBN3HT-ksoEWq5FNU4yYXhOaV3P8uJZ27GaH8Ha-aIdbGh3PPQqOLLXsAZ-K6sSfKjXfmjcmVJW5xRfolNsufXY7OnFRKVLn4GMako-ZIAM_.gif" alt=""></p></figure><p>You need to find out:</p><ul role="list"><li>Where they are&nbsp;</li><li>How old they are</li><li>What catches their attention</li><li>What they eat for breakfast</li><li>Who they hate</li><li>Who they love</li></ul><p>This is why it's normally a great strategy for you to actually BE&nbsp;YOUR&nbsp;PERFECT&nbsp;LISTENER. This is a shortcut through this stage of the process as if this is the case, you should know the answers to all of those questions ;)</p><p>Once this is defined you then need to list out a number of places where these people hang out online:</p><ul role="list"><li>Blogs</li><li>Other podcasts</li><li>Facebook Groups</li><li>subReddits</li><li>Linkedin Groups</li><li>YouTube Channels</li></ul><p>We will need this list later in the process when we move through the launch and grow stages.</p><h3><strong>How Do You Name Your Podcast?</strong></h3><p>There are a number of strategies to follow here...</p><ul role="list"><li><strong><em>Make it concise</em></strong></li></ul><p>Succinct podcast names land better as they convey the message most strongly.</p><ul role="list"><li><strong><em>Do not neglect the relevant keyword</em></strong></li></ul><p><strong><em>‍</em></strong>If your podcast is about soccer, let the name convey that; this is important in searches, as your podcast name will pop up in searches related to your industry.</p><ul role="list"><li>‍<strong><em>Make it easy on the tongue</em></strong></li></ul><p><strong><em>‍</em></strong>You don’t want a twisted name, as you will mention it time and again on your podcast – it should be smooth to say.</p><ul role="list"><li><strong><em>Keep it simple</em></strong></li></ul><p><strong><em>‍</em></strong>You don’t want the stress of explaining your podcast name every time. Embrace simplicity</p><ul role="list"><li><strong><em>Look out for rhyme and alliteration opportunities</em></strong></li></ul><p>The best names of anything normally incorporate rhyme and/or alliteration... be on the look out for these opportunities and incorporate them if they arise.</p><p>To make this clearer... here are some great examples along with an explanation for why:</p><p><a href="https://podcasts.bcast.fm/sales-ops-demystified" target="_blank"><strong>Sales Ops Demystified</strong></a>: We include the core key word AND the value proposition of the show. It's clear and concise and succinctly tells the potential listener why they should listen.</p><p><a href="https://podcasts.bcast.fm/mobile-growth-pancakes" target="_blank"><strong>Mobile Growth and Pancakes</strong></a>: Keyword conscious and not boring. This podcast name is exciting, and a listener will want to hear what they have to say. It lays a foundation for what to expect, which is discussing mobile growth in a fun and slightly... different way.&nbsp;</p><p><a href="https://podcasts.bcast.fm/shine-a-podcast-by-star" target="_blank"><strong>Shine: a Podcast by Star</strong></a>: Simple and short. The host already directs the listener's thought from the first word. It also promotes the host, as a name is attached to the podcast and conveys an aspect of the hosts brand: shining through technology.</p><p><a href="https://podcasts.bcast.fm/be-more-a-podcast-by-peakon" target="_blank"><strong>Be More - a podcast by Peakon</strong></a>: If you want to be more, you have to listen. Everyone wants to be more, and this podcast name exploits that emotional aspect with this name: it's aspirational. The listener wants to know how they can "be more".&nbsp;</p><h3><strong>How Do You Describe Your Podcast?</strong></h3><p>Research has shown that your <a href="https://www.thepodcasthost.com/promotion/podcast-discoverability/" target="_blank">podcast description</a> is the number one factor that new listeners consider when deciding whether to subscribe. When describing your podcast, you must be able to offer value to the listener quickly. You must tell in precise terms, what they stand to gain by listening to your show.</p><p>You also have to consider search engines as you construct e your podcast description. Your show description must be able to rank to stand a chance of getting any free exposure from Google. Include relevant keywords in the industry you cover.&nbsp;</p><p>When writing your description, you should consider attention span. You need to grab listeners' attention by putting the juicy points first. You also need to make fair use of the description by avoiding repetition.&nbsp;</p><p>Be concise, offer value, and grab attention with the first lines.&nbsp;</p><h3><strong>How Do You Pick The Right Category For Your Podcast?</strong></h3><p>The primary way podcast listeners discover podcasts is through searching within podcast listening apps. They navigate through different categories and topics and look for the best shows in that category – <strong>this is why</strong> you need to place your podcast in the right category. It will increase the chance that your perfect listener will discover your podcast.</p><p>You get three chances:</p><ul role="list"><li>1 Primary category</li><li>2 Sub categories</li></ul><p>I won't share much more on this as I assume you know the category in which your podcast should reside!</p><h3><strong>What Podcast Format Should You Adopt?</strong></h3><p>There are different formats for podcasts. The good thing is, you have creative control over the structure of your podcast. In most cases, the format you choose depends on the message you are trying to convey to your audience.&nbsp;</p><p>There are different types of formats:</p><ul role="list"><li><strong>Interview podcast:</strong> this format involves a host that brings guests on the show, and interviews them. These guests are usually experts in their field, and the host asks them relevant questions in their industry.&nbsp;</li><li><strong>Monologue podcast:</strong> this format involves the host alone. The host will run solo and speak about their experiences and area of expertise. It is mostly educational and a teaching type of format.</li><li><strong>Co-hosted podcast:</strong> this format will involve two hosts that will have conversations. They share their experiences and have a back and forth when needed.&nbsp;</li><li><strong>Story-based podcast:</strong> this format involves a host that tells a story like a drama to the audience. The story could be fiction or non-fiction. The host finds ways to spice it up through the use of different effects.</li></ul><p>That said, there is room for more than one format on your podcast. You could adopt different forms for different episodes, depending on the message you are trying to pass.</p><p>So why not start out with one... test, gather …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bcast.fm/blog/how-to-start-a-podcast">https://www.bcast.fm/blog/how-to-start-a-podcast</a></em></p>]]>
            </description>
            <link>https://www.bcast.fm/blog/how-to-start-a-podcast</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384162</guid>
            <pubDate>Fri, 11 Dec 2020 10:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We can have democracy or we can have Facebook]]>
            </title>
            <description>
<![CDATA[
Score 280 | Comments 479 (<a href="https://news.ycombinator.com/item?id=25383976">thread link</a>) | @imartin2k
<br/>
December 11, 2020 | https://the.ink/p/we-can-have-democracy-or-we-can-have | <a href="https://web.archive.org/web/*/https://the.ink/p/we-can-have-democracy-or-we-can-have">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg&quot;,&quot;height&quot;:798,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:277616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Being on the phone with <a href="https://twitter.com/matthewstoller">Matt Stoller</a> when a giant antitrust case is announced against Facebook is like texting with the pope when the Second Coming, you know, comes.</p><p>It’s a little on the nose. A little exciting.</p><p>I’d been wanting to talk to Matt for a while, in part because the pope actually turned down my recent interview request (someone please tell him how book tours work).</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png&quot;,&quot;height&quot;:264,&quot;width&quot;:1308,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:51146,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>And in part because I consider him (Matt) one of the more interesting, iconoclastic, morally committed, unpredictable, critics-may-care thinkers today. In the course of a typical Twitter day, which is a week in human time, I agree with Matt, disagree with him, wish I had thought of something he said, regret something he said on his behalf, retweet something he wrote, and make a mental note to talk with him soon. So I did.</p><p>And there we were, talking about everything — his political education, why he goes back and forth between thinking of himself as a progressive and not, his highly influential recent book, “<a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501182891">Goliath: The 100-Year War Between Monopoly Power and Democracy</a>” — when my phone began to crackle with <a href="https://www.nytimes.com/2020/12/09/technology/facebook-antitrust-monopoly.html">news of an historic antitrust case against Facebook</a>.</p><p>Naturally, I began to ask Matt about it. What he said was so compelling that I’ve decided to break our interview into two issues of the newsletter. Today: Matt Stoller on Facebook, this important case, and how monopoly is mistaken as a policy issue when in fact it represents an existential question of whether we are actually a democracy.</p><p>Then, before long, <a href="https://www.imdb.com/title/tt0107144/">part deux</a>, the political education of Matt Stoller — thinker, writer, civil servant, trustbuster, Twitter beefer, and, presently, aspiring political philosopher.</p><p>Without shame, I’ll add, in the spirit of Matt’s ideas, that if you want to do your part to support small, independent media, and haven’t yet, consider subscribing to The Ink.</p><h3>“The way we do business is the way we do justice”: a conversation with Matt Stoller, part one</h3><p>ANAND: Right as we're talking, I get a news alert: “<a href="https://www.nytimes.com/2020/12/09/technology/facebook-antitrust-monopoly.html">Facebook illegally crushed competition by buying up its rivals, according to lawsuits filed by 48 states and federal regulators</a>.” So this is the big case that we've been waiting for. Can you explain to a person who has never focused on this issue before in their life, and who just uses Facebook to try to get with their high-school ex, why is this a big deal? What does this mean?</p><p>MATT: So Facebook is a financial conglomerate. People think of Facebook as that website you use or the app that you use, but really Facebook, as a political institution, is a financial conglomerate and owns dozens of different companies, including Instagram and WhatsApp and Facebook, the social network. And it's a giant advertising company. So they have roughly three billion users. And they try to get their users to do things that their advertisers want them to do, because that's how you sell advertising.</p><p>The business model is to divert revenue that used to go to newspapers and publishers to themselves. And so by manipulating people in this specific way that they do, which is to keep them using their system and keep surveilling them so that they can target them with ads, they are, in the process, crushing newspapers and publishers, who no longer have any financing, particularly local newspapers and niche publications like Black-owned newspapers.</p><p>So increasingly those kinds of publications don't exist. You don't have reporters covering state houses and city halls and whatnot. Instead, people are now consuming things that Facebook likes them to consume because it keeps them using, and it keeps them available to sell ads to them, which are anti-social publications or posts, like anti-vax stuff or QAnon or whatever it is.</p><p>So that's the basic problem. It's a $70-, $80-, $100-billion-a-year revenue company that's destroying newspapers and publishers all over the world and getting people to pass conspiracy theories to each other so that Facebook can make money on advertising.</p><p>ANAND: You're an anti-monopoly guy. If there were three or five companies in healthy competition with each other, all doing exactly what you just described, wouldn't it still be problematic? Is the issue here that there's only one of them of that heft, or would a competitive market with five such players still be incredibly troubling?</p><p>MATT: There's a lot more that you have to do than just break them up. But the answer is, it would improve things dramatically if they were broken up, and you don't have to imagine it.</p><p>There used to be a bunch of social networks. Facebook's main competitor was Myspace, but there were a bunch of others. There was BlackPlanet; there was Friendster. And the way that Facebook actually defeated Myspace was by promising a safer, more private experience. They defeated Myspace by saying, We will treat your data carefully; in fact, when we change the terms of service, we will let our users vote on the terms of service.</p><p>This was back in 2007, 2008, 2009. And once they killed their competition, and then they bought up nascent competitors like Instagram and WhatsApp, then they didn't have to compete by offering a higher-quality service, a.k.a one that was less intrusive in terms of surveillance. They could just surveil anybody they wanted, and you didn't really have a choice.</p><p>ANAND: Where do you think this case is going?</p><p>MATT: They’re going to aim to break up the company. The House Antitrust Subcommittee did this long investigation of big tech, which includes Facebook. And one of the things they found is that Mark Zuckerberg was writing emails saying they were buying these companies to block competition. And so that's evidence that the mergers were illegal, because you're not supposed to buy companies to block competition. That's a violation of the Clayton Act. My guess is that they're going to have a pretty good complaint.&nbsp;</p><p>ANAND: Based on the history of such cases, would your assumption be that Facebook is broken up within a period of years?</p><p>MATT: Yes.</p><p>However, we haven't enforced the law for 20 years, so it’s not entirely clear. The law at this point is crazy and incoherent because we haven't done enforcement, and to the extent that we have, judges have just made wildly inconsistent rulings.</p><p>ANAND: This kind of action that's being announced today is the epitome of a systemic, public response to a problem. And when I, like you, advocate for those types of things, I often hear this response that I'm sure you do, too, which is, “OK, that's fine, but what about individual actions?” A lot of people are like, “Yes, let’s delete Facebook.” Or: “Why aren't you supporting the Facebook boycott?”, and there are different views on it.</p><p>There are some people who make the argument that those kind of small personal things are sideshows, distractions, maybe even unhelpful, because they reduce the perceived need for bigger systemic change. I fall more into that camp. There are others who say it's a gateway drug, it's a waystation, like: “Delete Facebook and then work yourself up to a political response." How do you weigh in on that?</p><p>MATT: I think it's a bad vision of politics. It's not doing politics to say, “Me, as a consumer, I can change power arrangements based on what I consume or don’t.” That's a real 1970s consumer-rights Democrat vision of the world, and that's one in which you as a citizen are irrelevant.</p><p>A boycott is only political if the goal is a policy change. If you go in and you say, "Well, I don't like Facebook, I want to change Facebook, so I'm going to delete Facebook," that's not going to do anything. If it's part of some larger political action saying, "Well, I'm going to delete Facebook, and then I'm going to push policymakers to break it up," I mean, I guess that makes sense.</p><p>But the general view of these boycotts is that just not using Facebook is the political action. But that's actually not a political action.</p><p>ANAND: An issue like monopoly is different from, say, healthcare, where you don't have to explain to most people the problem with our healthcare system. How do you think about making the issue of monopoly real to people and vivid and relevant to their lives?</p><p>MATT: I'm going to challenge the premise. I don't think monopoly is an <em>issue</em>. I think monopoly is a worldview.</p><p>My book is called “<a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501182891">Goliath: The 100-Year War Between Monopoly Power and Democracy</a>.” Anti-monopolism is a lens through which you understand power, and particularly commercial power. That’s the lens that I see the world through. And I don't just focus on Facebook or Google. I’m focused on anti-monopolism in general. How you use business institutions to coerce and bully — or liberate — other people in your society.</p><p>There's a monopolist who controls the cheerleading industry, which is very weird. I just learned there is a private-equity company that is trying to monopolize the software that churches run. There is a monopoly of Ultimate Fighting Championship-style contests. And then in healthcare there are endless numbers of monopolists. Ultimately, what a monopolist is is a person or institution that is controlling and governing a market. It's a private government versus a public government.</p><p>ANAND: You’re saying it’s incompatible with democracy.</p><p>MATT: Right. It’s a different system. When Mark Zuckerberg says he’s going to arrange electoral discourse in this particular way, or going to start a <a href="https://www.businessinsider.com/meet-the-first-20-members-of-facebook-supreme-court-2020-5">Supreme Court</a>, or going to ban this or allow that, he is operating as the global privacy commissioner. <a href="https://www.vox.com/the-big-idea/2018/4/9/17214752/zuckerberg-facebook-power-regulation-data-privacy-control-political-theory-data-breach-king">He even said</a>, "In a lot of ways Facebook is more like a government than a traditional company." That's a direct quote.</p><p>As a society, the way we do business is the way we do justice.</p><p>ANAND: Understanding how these platforms work, do you think that if Mark Zuckerberg wanted to tip an election, he could? Would that even be illegal under our current system?</p><p>MATT: I don't know if it's possible, but it's certainly legal if he decided to.</p><p>I listened to this podcast with Zuckerberg where he said — this was right before he became unpopular, so he was still being relatively …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://the.ink/p/we-can-have-democracy-or-we-can-have">https://the.ink/p/we-can-have-democracy-or-we-can-have</a></em></p>]]>
            </description>
            <link>https://the.ink/p/we-can-have-democracy-or-we-can-have</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383976</guid>
            <pubDate>Fri, 11 Dec 2020 09:48:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, engineers don't suck at time estimates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383838">thread link</a>) | @bbu
<br/>
December 11, 2020 | https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/ | <a href="https://web.archive.org/web/*/https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><p>No, engineers don’t suck at time estimates - and generally speaking humans are better estimators than what most people believe. This seems rather surprising given all we’ve heard about the problems of bad time estimations, projects going overboard, etc and of course, your personal experience with software time estimates. But if people are really bad at estimation, how does that fit with our obvious evolutionary need to make quick decisions based on partial data? if we can’t estimate well how did we decide if a gap is wide enough to jump over, if an animal is worth the hunt, if a certain area is more likely to have water and shade? Without estimation skills we wouldn’t survive. So what’s going on?</p><p>One obvious explanation is that we are only good at estimating physical things such as sizes and distances. However, this does not seem likely given the large number of non-physical decisions we needed to make, like selecting a mate.
Another, more likely explanation is that the estimates are good, but the interpretation and usage of the estimates is flawed. In other (slightly cynical) words: the engineers are good at estimating, it’s the project managers who suck at using the estimates.</p><p>Let me explain.</p><p>“your estimate was wrong” - is something i’ve heard many times. But this sentence doesn’t make any sense… after all, an estimate is by definition not exact; in fact, if the results would always agree with estimates foul play would be immedialy suspected. If I estimated one day and the actual time was 1.5 days, was I “wrong”? most people would say I wasn’t. But if if the actual time was 20 days most people would argue I was wrong. Somewhere between one and 20 days there is an implicit “reasonable error” threshold we never discussed! I never gave an error margin for my estimate, did I?</p><p>Since we don’t expect an estimate to be an exact guess of the actual value, what do we expect from an estimate? When we make decisions based on estimates, we can only be right or wrong in our decision, you can’t be “a lot more right”. We need to guess a value beyond a certain threshold and within a certain tolerance, with high probability of being right because that our lives depend on that gap being just short enough for us to jump over. Decisions are almost always non-linear like that and it should not be surprising given the nature of knowledge and learning. We take in examples and extrapolate patterns and behaviours. Which means we are dealing with groups, and probability distributions. This may be surprising at first, because when you are estimating this one <em>particular</em> job, you don’t think of a distribution of a million other <em>different</em> jobs. An estimate is predicting the future in which we see the actual value.
</p><div><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><p><img itemprop="thumbnail" src="https://blog.nukemberg.com/img/time-estimate.jpg" alt="/img/time-estimate.jpg"></p><a href="https://blog.nukemberg.com/img/time-estimate.jpg" itemprop="contentUrl"></a></figure></div><p>What we need to know, is that in a certain number of futures, say 90% of them, a value won’t be over or under a certain threshold. Or phrased mathematically, that the 90th percentile of the distribution of futures will be over (or under) a certain number. An estimate is a percentile! but which percentile? is it the median? the 99th?
For software time estimates it has been <a href="https://erikbern.com/2019/04/15/why-software-projects-take-longer-than-you-think-a-statistical-model.html">observed to be the median</a> (50th percentile), meaning to be right about half the times. Is this inherent? Estimates can desmonstrably be calibrated to higher percentiles by as little as <a href="https://www.tonym-v.com/blog/2019/10/2/improve-your-estimations-with-the-equivalent-bet-test">brief emotional self manipulation</a>; You could easily estimate the 90th percentile of many things - just read <a href="https://www.amazon.com/How-Measure-Anything-Intangibles-Business-ebook/dp/B00INUYS2U">How to measure anything</a>.</p><p>Usally when I tell this to people, they often respond with “we’ll train to estimate the average”. Sadly, this is not possible. The mean is a statistically “unstable” or “unrobust” aggregate, where as percentiles are “stable” or “robust”. Consider a group of task completion times [73, 67, 12, 38, 18, 11, 42]. The mean is ~37.29 and the median is pretty close, 38. But as soon as we get another measurement, say 293, the mean changes significantly to 69.25 while the median changes only slightly to 42. The mean is sensitive to outliers, and the more skewed and high variance the distribution the less robust and stable it will be.</p><p>Having estimated tasks, what do we do with them? We sum them up.</p><p>Either for project budget or for by enqueuing with the next tasks, we sum them. But wait, we know that percentiles are not additive! how can this ever work? it never does. Summing up percentiles compounds errors and with skewed distributions, and in particular heavy tailed distributions, the errors are very large. Let’s have a look at what a task completion time distribution would look like:</p><div><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><p><img itemprop="thumbnail" src="https://blog.nukemberg.com/img/task-time-distribution.png" alt="/img/task-time-distribution.png"></p><a href="https://blog.nukemberg.com/img/task-time-distribution.png" itemprop="contentUrl"></a></figure></div><p>A task has some minimum time it has to take, but beyond that it can pretty much take as long as inifinity. We all know from experience, that when things get out of control they go wayyyy out of control. Once you hit a rare bug, you might be chasing a wild goose for two months. That 10% over the estimate might be a day late or a year, the higher percentile you pick the more extreme the errors relatively.</p><p>To be honest, it’s old news; This has been known for a long time. Percentile based project predictions have been done as early as World War II, perhaps even before that - yet they remain fairly unknown in the industry. Not only are we ignorant of proven methods, we invent new ones which are outright harmful. Remember that burn down chart? the <em>backlog</em> is nothing more than a sum of time estimates! And every two weeks, sitting in the famous sprint retrospective people work to calibrate their estimates to the random walk sum of task completion times on the burndown chart. How do you calibrate a percentile to a sum? If the distribution is something like a log-normal distribution, the random walk sum will converge to the mean, and the median is relatively close to the mean - which is summable, and both are pretty stable. So by repeatedly calibrating estimates to the running-sum of task completion times (the backlog) you will converge close to the median. Now go tell your project manager there is a 50% chance of their project running late, anywhere between a day and eternity, and see how they respond. A 50% chance of uncapped delay is a useless estimate.</p><p><strong>Scrum is a training method for useless time estimates</strong>. It actively destroys your ability to manage your project.</p><p>Don’t get me wrong, I’m not against Agile; The spirit of Agile, some of the methods and ceremonies of Scrum have value. But Scrum <em>as a system</em> is actively harmful, especially in high variance situations where the work is far from the nice log-normal distribution. If you <a href="https://blog.nukemberg.com/post/the-burndown-chart-fallacy/">optimize for an arbitrary metric</a>, you will get arbitrary results. In ops/SRE and pure research many people have intuitive sense that Scrum and traditional project management are wrong, although they can’t quite articulate why. The reasons become very clear when we consider what happens to sum based project management methods if the task distribution becomes heavy tailed. A task that is one week late is likely to take <em>at least</em> one more week - is a common thumb rule in such domains; This is called a “Power law” and can be modeled by the famous Pareto distribution. The thing about the Pareto distribution is that its mean does not converge! In other words, using sum based planning methods with such distributions is equivalent to managing by rolling dice. A little worse actually, as dice are a cheap method of generating random numbers where as time estimates are intrusive and sometimes expensive. This isn’t a problem unique to Scrum, nor does it originate from it. The problem is the assumption of determinism and accuracy which is the prevaling “machine age” mindset. Pretty much all of the common project management tools have the same issue - have a look at a Gantt chart, it has no probability intervals or error ranges. They are all worse than useless. It shouldn’t be a surprise that despite people being bad at estimating large tasks naive estimates are reliably more accurate than project management tools.</p><p>Recognizing the probabilistic nature of the world is key. Probability isn’t a tool for making predictions, it is a tool for quantifiying uncertainty. Instead of managing resources (which are usually highly certain) we should be managing uncertainty, with probabilistic methods appropriate for the task. With this mindset, the first thing to do is understand the business context and the distributions involed: are you in a low or high variation domain? Industrial methods which aim to improve throughput and efficiency all assume low variance, sometimes actively force low variance by getting rid of outliers; this isn’t necessarily possible in your business context. Industrial methods are good when used in context, but horrible when used in high variability and unpredictable domains. For those we have other methods, which emphasize low latency and rapid adaptation. Instead of Scrum, you could try:</p><ul><li><a href="https://www.joelonsoftware.com/2007/10/26/evidence-based-scheduling/">Monte-Carlo simulations based on time estimates</a></li><li><a href="https://basecamp.com/shapeup/2.1-chapter-07">Time boxing and bets</a></li><li>Latency optimizing methods which dispense with time estimates, like Kanban</li></ul><p>I’ve listed the methods above in order of rising uncertainty, Monte-Carlo simulations or time boxing would probably be easiest to start with. The biggest obstacle in implementing these is convincing managers that “predictability” isn’t so important as they imagine. For high variation domains it’s nothing more than a fantasy anyway.</p><p>So there you have it: people don’t suck at estimation. They suck at management 🤷</p><hr></article></div></div></div></div>]]>
            </description>
            <link>https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383838</guid>
            <pubDate>Fri, 11 Dec 2020 09:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes Operators 101]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383807">thread link</a>) | @evenh
<br/>
December 11, 2020 | https://thecloud.christmas/2020/11 | <a href="https://web.archive.org/web/*/https://thecloud.christmas/2020/11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://i.imgur.com/PRCyBqa.jpg" alt=""><div><section><p>Kubernetes has become the <em>de facto</em> container orchestrator since it's initial release in 2014. It is a great tool for managing diverse workloads in clusters of machines, possibly spanning multiple availability zones. As the usage grows, new requirements for how to deploy and operate specialized software emerges. The Operator pattern is one of the more prominent responses to these new requirements.</p>
</section><article><section><p>The Operator pattern is best described in the <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">official Kubernetes documentation</a>:</p>
<blockquote>
<p>The Operator pattern aims to capture the key aim of a human operator who is managing a service or set of services. Human operators who look after specific applications and services have deep knowledge of how the system ought to behave, how to deploy it, and how to react if there are problems.</p>
<p>People who run workloads on Kubernetes often like to use automation to take care of repeatable tasks. The Operator pattern captures how you can write code to automate a task beyond what Kubernetes itself provides.</p>
</blockquote>
<p><strong>TL;DR</strong> Operators automate operation of applications and services with human know-how.</p>
<h2>How does an Operator work?</h2>
<p>An Operator consists at a minimum of one Custom Resource Definition (<code>CRD</code>) and a Controller. The <code>CRD</code> describes the various configuration options for this kind of resource. Given a custom resource for a <code>PostgresDatabase</code>, one might find options for specifying custom <code>StorageClass</code>es, resource allocation, backup schedule/destinations, authentication methods, etc.</p>
<p>Given an instance (<code>CR</code>) of <code>PostgresDatabase</code>, it's now the job of the controller to ensure that the desired state is reconciled with the cluster. In this example one can assume that the controller will create a <code>StatefulSet</code> for running the database itself, along with needed configuration in a <code>ConfigMap</code>, certificates for mutual TLS in a <code>Secret</code>. Backup can be done by either mounting and writing to a volume defined in the <code>CR</code> or injecting a sidecar for sending backups to another location.</p>
<p>Patching, reboots and failovers can be specified in the <code>CR</code> and taken care of by the controller, using methods recommended by experienced DBA's. The fact that complex operational knowledge can be encoded into the controller is a key enabler for many organizations that would like to run complex software, but not necessarily invest countless hours into learning the nitty-gritty details on how to operate it.</p>
<p>Like any other software there will be bugs and abstractions will leak. There's no silver bullet.</p>
<h2>How do I create my own Operator?</h2>
<p>As with the rest of the Kubernetes community, multiple solutions exists.</p>
<ul>
<li>For a declarative experience, check out <a href="https://kudo.dev/">KUDU</a></li>
<li>If you'd like a more official way to do it, see <a href="https://github.com/kubernetes-sigs/kubebuilder">kubebuilder</a></li>
<li>The most popular option seems to be <a href="https://github.com/operator-framework/operator-sdk">Operator SDK</a></li>
</ul>
<p>As with most cloud native software, Go seems to be the lingua franca. There is nothing stopping you from writing an Operator in Java, C#, Python or any other language that can communicate with the Kubernetes APIs.</p>
<h2>Examples of known Operators</h2>
<p>The community has produced a lot of Operators for about everything one can imagine. These are some popular examples:</p>
<ul>
<li><a href="https://github.com/argoproj/argo-cd">Argo CD</a> – a  declarative, GitOps continuous delivery tool for Kubernetes.</li>
<li><a href="https://github.com/jetstack/cert-manager">cert-manager</a> – automatically provisions TLS certificates via the ACME protocol. Can be used with certificate issuers such as <a href="https://letsencrypt.org/">Let's Encrypt</a>, <a href="https://www.buypass.no/ssl/resources/acme-free-ssl">Buypass</a> and <a href="https://zerossl.com/documentation/acme/">ZeroSSL</a>.</li>
<li><a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus Operator</a> – often used in combination with <a href="https://github.com/prometheus-operator/kube-prometheus">kube-prometheus</a> for a batteries included monitoring suite</li>
<li><a href="https://kubedb.com/">KubeDB</a> – a real-life implementation of the <code>PostgresDatabase</code> example, plus support for MySQL/MariaDB/MongoDB/Redis/Memcached and more</li>
</ul>
<p><small>Header image: RIA Novosti archive, image #305015 / Alexey Danichev / CC-BY-SA 3.0</small></p></section></article></div></article><section><ul><li></li><li></li></ul></section></main></div></div>]]>
            </description>
            <link>https://thecloud.christmas/2020/11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383807</guid>
            <pubDate>Fri, 11 Dec 2020 09:13:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life in the Baby Universe: The Physics of Babies (2014)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25383711">thread link</a>) | @philshem
<br/>
December 11, 2020 | https://smalldata.dev/posts/physics-of-babies/ | <a href="https://web.archive.org/web/*/https://smalldata.dev/posts/physics-of-babies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><sub><em>This article was originally published in</em>
<a href="https://physicsworld.com/a/the-september-2013-issue-of-physics-world-is-out-now/" target="_blank" rel="noopener"><em>Physics World</em></a> <em>September 2013, copyright IOP Publishing, reproduced here with permission.</em></sub></p><p><img src="https://smalldata.dev/images/baby_physics/header.jpeg" alt="header image - baby with avocado face"></p><hr><p><strong>I became a first-time father</strong> around the same time my postdoc contract ended. My wife had another year to finish her PhD, so I took a sabbatical to be a stay-at-home dad. My months away from research were intended to be full of fun projects. And relaxation. It was to be the Year of Naps – or so I thought.</p><p>Unfortunately, while physics problems have solutions that are constant, baby-related problems have solutions that are random and change from day to day. What had worked yesterday will not work today. Maybe it will work tomorrow. This is the gist of the Baby Universe. In this universe, time only means a start and a finish, and contains no information in-between. If the physicist-dad discovers a method to get the baby to eat her breakfast, it is unlikely to work by dinner. This is significant because eating is one of four fundamental dimensions of the Baby Universe, and the same principle of random solutions also applies to the other three: playing, crying and sleeping. (Some scientists consider pooping to be a separate dimension. However, I can assure you that this is always included as part of one of the other four.)</p><p><img src="https://smalldata.dev/images/baby_physics/sarah_photo.jpeg" alt="baby - who me?">
<sup>Photo credit :
<a href="https://www.sarahperryphotography.com/" target="_blank" rel="noopener">Sarah Perry</a></sup></p><p><strong>The first challenge</strong> in my physicist-to-dad transition came with my inability to feed my daughter naturally. My thesis-writing wife’s fresh-pumped milk was in demand and its administration required complex algorithms for its optimal, timely use. Solid food, once introduced, posed a whole new set of problems, as each spoonful required extensive parental coercion. This may have had its upsides: recent research shows that the more you talk to your child, the higher the child’s IQ will be. The fine print that the researchers don’t mention is that this IQ boost comes at your expense, as you must donate those IQ points to the child via non-stop one-way conversations: “Look. Yams. Mmmmm. You like yams. You liked yams yesterday. Oooh, yaaaaaams.”</p><p>Later, my daughter acquired a rudimentary ability to feed herself, and the physics of the eating dimension became more complex. If I offer her a spoonful of food, she comes running to see what is on the spoon. If the food is not to her liking, she is scattered like a charged particle from a similarly charged hard sphere. But when, instead, a sticky ball of white rice is presented to her, it triggers a primal urge to make chaos. The “entropy of rice” principle dictates that the dispersion of rice across a 2D “table” is sudden, yet erratic. After adequate time, every grain of rice is scattered into a circle with a radius equal to one baby arm. Given infinite time, it is predicted that babies would not rest until every grain of rice was at every end of the universe.</p><p><img src="https://smalldata.dev/images/baby_physics/yogurt_face.jpeg" alt="baby - yogurt face">
<sup>Photo credit : Debby Shemella, aka Grandma (2012)</sup></p><p>As the preceding paragraph indicates, the “eating” dimension of the Baby Universe is closely coupled to the “playing” dimension. Before she could crawl or walk, my daughter would nevertheless want to change her position during playtime. She employed the theory of relativity to satisfy this urge: by moving her playmat from underneath her, she could therefore move herself off the mat. Once mobile, she liked to increase her potential energy by dragging herself up and onto whatever obstacle she could find. If stairs existed, that obstacle was most definitely stairs. This is unfortunate, because although babies understand gravity if they are dropping something (and can even anticipate the “Boom!” the object makes upon impact), they have no comprehension of gravity if they are the body upon which it is acting. It is therefore the physicist-parent’s job to decrease the baby’s potential energy whenever it grows too large, and it is the baby’s work to regain what was taken away.</p><p><iframe src="https://www.youtube.com/embed/RbAYEdjcyjc" allowfullscreen="" title="YouTube Video"></iframe></p><p><sup><em>The
<a href="http://www.pechakucha.org/" target="_blank" rel="noopener">PechaKucha</a> talk that started this research.</em></sup></p><p>The two remaining dimensions of the Baby Universe – crying and sleeping – are also tightly coupled. To deal with daytime crying sessions, I devised a “terror threat level” system of graded responses, with passivation techniques such as singing, dancing, guitar and something I copied from
<a href="https://www.youtube.com/watch?v=eCLp7zodUiI" target="_blank" rel="noopener">Monty Python’s “Ministry of Silly Walks”</a>. For inducing sleep, I adopted similarly complex patterns of rocking, bouncing, walking, singing, shushing and waiting. Some of these patterns involved a Swiss ball – a large, inflated exercise ball that serves as a rocking chair for the 21st century. This ball has harmonic degrees of freedom in the side-to-side and front-to-back directions as well as the primary up-and-down one, and is essential for bouncing and rocking a baby to sleep. In addition, it is good for the physicist-parent’s core strength, and can be easily deflated and packed up before relocating for yet another postdoc.</p><p>Once the baby is asleep, the physicist-parent is faced with the challenge of escaping the room – in my case over creaky hardwood floors. Doing this before my daughter realizes she is asleep requires knowledge of the “path of least noise”. Once I have exited the room, though, I have a dilemma. No sounds come from the crib. Is my daughter asleep or awake? A measurement is required. As I silently slide on my socks into the dark room, my measurement wakes her and her original state remains unknown. This is Schrödinger’s baby.</p><p><strong>My time at home</strong> has been a great period in my life and I know I will miss this when I’m back at work. As I write this essay in my head, my daughter rests on my shoulder. Her breathing turns to snoring and I synchronize my own breathing to be in phase with hers. Together we plan all the things I need to do during her naptime. I definitely don’t have time for a nap of my own.</p><hr><p><img src="https://smalldata.dev/images/baby_physics/author_muse.jpeg" alt="author and muse">
The author and his muse (2013)</p><hr><p><sup>This article is also available on
<a href="https://medium.com/@philshem/life-in-the-baby-universe-f52561c4a8ae" target="_blank" rel="noopener">Medium</a>.</sup></p></div></div>]]>
            </description>
            <link>https://smalldata.dev/posts/physics-of-babies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383711</guid>
            <pubDate>Fri, 11 Dec 2020 08:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise and Fall of Ambrosia Software (2019)]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 136 (<a href="https://news.ycombinator.com/item?id=25383485">thread link</a>) | @kaptain
<br/>
December 11, 2020 | https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>While I'm away on my honeymoon, here's my complete talk from PAX Australia 2019, on the rise and fall of legendary shareware publisher Ambrosia Software.</p><p>For Mac gamers in the 90s, the people of Ambrosia Software were rockstars. Heroes. And with brilliant games like Maelstrom, Escape Velocity, Harry the Handsome Executive, Apeiron, and more, plus a company newsletter that spoke directly to the fans, they could do no wrong. In light of Ambrosia's recent closure (finally!), Secret History of Mac Gaming author Richard Moss recounts the studio's high and lowpoints and tells the stories behind its best games.</p><p>Thanks as always to my supporters on Patreon — especially my $10+ backers Vivek Mohan, Simon Moss, Wade Tregaskis, Eric Zocher, and Seth Robinson. And a very big thank you (and warm welcome!) to my five new patrons this month. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames" target="_blank">my Patreon page</a> and sign up.</p><p>There'll be no regular episode of The Life &amp; Times of Video Games this week because I'm off on my honeymoon. But to tide you by until I'm back, I thought you might enjoy listening to my talk from PAX Australia 2019 about the lesser-known of the indie game publishing giants from before the time of Braid and Steam and all that other stuff we've had over the past 15 years.</p><p>The talk was called The Rise &amp; Fall of Ambrosia Software, '90s Mac Legends, and you can find accompanying slides at <a href="https://tinyurl.com/paxausambrosiatalk" target="_blank">https://tinyurl.com/paxausambrosiatalk</a> as well as my full script on the accompanying blog post at lifeandtimes.games. So please, enjoy, and I'll see you in a couple of weeks.</p><div><p><em>[note that this won't correspond exactly to the audio, as it was my written script rather than what I actually said. If you're looking at the slides, "[NEXT]" means go to the next slide.]]<br></em><br>Hello everyone. My name is Richard Moss, and today I'm going to talk to you about a company that's pretty near and dear to my heart, not only as someone who grew up playing some of their games — [NEXT] but also as the author of a book called The Secret History of Mac Gaming, which covers their history, along with lots of other games and game developers from the 1980s and 90s Mac gaming scene. [NEXT]</p><p>If you were a Mac gamer in the late 90s, chances are pretty high that you would have had at least one game in your collection that came from Ambrosia Software. [NEXT] They were heroes among the Macintosh faithful, one of only a few companies that made its games exclusive to the Mac. And arguably the best among them in terms of the quality of its output.</p><p>Games like [NEXT] Maelstrom, [NEXT] Escape Velocity, [NEXT] Ferazel's Wand, [NEXT] Apeiron, and [NEXT] Bubble Trouble were hallmarks of quality, even if most of them were essentially just jazzed-up versions of classic 80s games. And they had top-drawer offbeat gaming options, too, with titles like [NEXT] Avara, a kinda abstract-looking arena-style first-person shooter, and [NEXT] Harry the Handsome Executive, where you guide a middle management executive through an office electronics apocalypse while scooting around in a swivel chair.</p><p>For about 15 years or so, from 1993 to around 2008, the Ambrosia Software name was inseparable from quality Macintosh games. But then it faded rapidly into the background, for reasons I'll get to later, and finally the company closed its doors at the end of last year.</p><p>***</p><p>So in recognition of Ambrosia's achievements, which have slipped a bit under the radar outside of the old-school Mac faithful, I wanted to give you a tour through the company's rise and fall. </p><p>There's not enough time to cover everything, but I'll try to get to all the key stuff and you'll hopefully come away with a good sense of a) why Ambrosia Software matters to the history of computer games and b) what made Ambrosia special to the Macintosh flock. </p><p>I've got some interview clips, a bit of gameplay footage, some photos and old documents to help us along the way. I wanted to set up an emulator as well but just ran out of time unfortunately. And hopefully there'll be plenty of time at the end for questions and stories from you in the audience.</p><p>But before we go into rise and fall of Ambrosia, let's do some quick background. First, on Ambrosia founder Andrew Welch. Then second on the Mac gaming scene in the early 90s.</p><p>[NEXT] So, Andrew Welch. His dad owned a marketing company, and it was through that business that young Andrew planted the seed for what would become Ambrosia. When he was something like 12 or 13 years old, he found the company's library of books and documents on typography. He thought it was cool, so he learnt how to design his own typefaces on his Macintosh. Then, starting from age 14 or so, he sold them on America OnLine.</p><p>But most people doing this sold their fonts without any documentation at all, so there was no way to know after the fact who made it, how to pay for it, who to contact for support, and so on. So Andrew taught himself how to code a utility program that could wrap his fonts in a simple document reader thing.</p><p>He enjoyed coding so much that he kept doing it, and made various other utilities for his relatives. Then he went off to college to study photojournalism and in his spare time he created [NEXT] his first game, a Wheel of Fortune clone called Wacky Wheel.</p><p>[NEXT] [show it in action]</p><p>This was kind of par for the course with small Mac games at the time. There were lots of people putting out crappy little games as freeware or shareware, but even the rare good ones weren't really making anything more than pizza and beer money.</p><p>[NEXT] Or literally beer.</p><p>Quick definition of shareware: [NEXT] it's software that you give away, free, but you ask that if someone likes it they pay you a registration fee — which, depending on the exact implementation, might get that person customer support or free updates or maybe just remove the nag screen from the boot-up process.</p><p>[NEXT] This is a pretty typical shareware notice, taken from an early DOS game.</p><p>Over on the PC side, shareware had already taken off. [NEXT] Apogee Software and Epic MegaGames were making a fortune working with independent developers and selling their games in a clever twist of the standard shareware model called The Apogee Model. Instead of giving away the whole thing for free and requesting that people pay if they like it, Apogee and Epic's games were [NEXT] episodic — episode one distributed freely over the internet and BBSs and through mail-order floppy disks, and all subsequent episodes available to order for a set fee.</p><p>I'm actually writing a book about this stuff, so if you're curious to learn more ask me about it later.</p><p>And id Software were just starting to make their name at this point as well. [NEXT] Wolfenstein 3D dropped in 92, then [NEXT] Doom in 93, both published as shareware on PC through Apogee. </p><p>So the time was ripe for shareware to step up and hit the big time on the Mac side, too. The Mac was at the peak of its [NEXT] pre-iMac popularity. College kids across the United States had Macs set up in their dorm rooms, while creative professionals all around the world had taken up the Mac mantle and were keen for more time-wasters to get them through the lulls in their output.</p><p>But there weren't many games coming out — the porting industry, which took PC games and put them on Mac, was still in its infancy after struggling with the [NEXT] peculiarities of adapting games for the Mac's multi-window mouse and menu-driven interface. Truly cross-platform commercial computer games that had concurrent Mac and PC releases were still rare (though there were a few special ones like [NEXT] SimCity 2000), and Mac-first development had gone into a bit of a lull (for a variety of reasons) at the end of the 1980s — from which it had yet to fully recover.</p><p>So there was lots of room for a great new Mac-native game to stand out.</p><p>And, crucially for our story here, someone was wrong on the Internet. I'll let you hear this bit straight from Andrew: [NEXT]</p><p><em>AW: I think it was the summer after maybe my freshman year of college that someone had said — I think it was called the Mac IIci or something like that. It was one of the colour Macs that came out. And someone had said something about the fact that while it was too slow to do decent animation on — and by that point in time I had actually taught myself for Assembly language, as well. So I set out to prove this guy wrong, because it's always fun to try to prove someone on the Internet that they're wrong. <p>*laughs* So, yeah, so that's how I started writing — and I really wasn't sure what I was going to do yet — but I started writing some kind of animation stuff. I grew up going to a lot of the arcades where we played games like Asteroids and Centipede and that type of thing where after school I would get dropped off there and play. So I decided to make an Asteroids-based game.</p></em></p><p>[NEXT]<br>He asked a couple of friends to help him out with the graphics, and got together with a few of his college buddies and a microphone to make a bunch of silly noises and record stuff off the TV for sound effects.</p><p>They pulled liberally from pop culture, drawing tiny clips and references (without permission) from all over the place, kind of like the wall of sound that early hip-hop and remix culture had.[NEXT]</p><p>He called the game Maelstrom and put it online as shareware, published under the name Ambrosia Software — a name he pulled from Greek mythology. You could play it and share it freely, but it'd nag you to send in a cheque to register every time you booted the game. And a lot of people did. [NEXT]</p><p><em>everyday we would go to the mailbox and there'd be letters from all over the world. I just had a blast. I thought it was really really cool that I could do something just sitting in my room in upstate New York, which was where I was at the time. And I got these contacts from all over the world. I thought that was really really cool, and it was at a time where people were just starting to get connected online.<p>Like now it's no big deal — you can go on …</p></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk">https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383485</guid>
            <pubDate>Fri, 11 Dec 2020 08:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ever-elusive riddle: What's the best way to cut Christmas cookies?]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25383265">thread link</a>) | @helstegt
<br/>
December 10, 2020 | https://di.ku.dk/english/news/2020/the-ever-elusive-riddle-whats-the-best-way-to-cut-christmas-cookies/ | <a href="https://web.archive.org/web/*/https://di.ku.dk/english/news/2020/the-ever-elusive-riddle-whats-the-best-way-to-cut-christmas-cookies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-area">
        <div>
          <!-- Content with right menu -->

<div>
  
    





  

    <p>
        7 December 2020
    </p>

    


    <div>
        <p><span>algorithms</span></p><p>At some point in life, most people have stood over a rolled-out slab of cookie dough and pondered just how to best cut out cookies with as little waste as possible. Now, even math experts have given up on finding a computer algorithm to answer this type of geometric problem.
</p>
    </div> 
        <figure>
            <img alt="Photo: Getty Images" src="https://www.science.ku.dk/english/press/news/2020/the-ever-elusive-riddle-whats-the-best-way-to-cut-christmas-cookies/billedinformationer/Sm_kagedej_1100x600.jpg" title="Photo: Getty Images">
            <figcaption>Photo: Getty Images</figcaption>
        </figure>

<p>How can we maximize dough while cutting out Christmas cookies? How do we pack a suitcase or fill a kitchen cabinet while making the best use of space? One may have thought, “there <em>must</em> be a best way to do this.” Pondering such questions too deeply now appears to be a complete waste of time. The science is now here to support that it is impossible, for the time being, to figure out what works best for more than four or five spicy gingerbread men or Christmas tree cookies.</p>
<p>Assistant Professor Mikkel Abrahamsen of the Department of Computer Science and two research colleagues studied how difficult it is to figure out the optimal way to pack objects in two dimensions without overlap — a conundrum that computer scientists have plugged away at for decades.</p>
<p>"While algorithms let us solve seriously complex problems, this is one that remains too much of a mouthful for today’s computers. For now, it isn’t possible to pack more than 5-10 objects optimally. And, our result suggests that this number probably won’t increase much for the time being," explains Mikkel Abrahamsen.</p>
<p>Packing things optimally isn’t just an occasional problem at home, but in a variety of industries, including clothing manufacturing and metal processing. In each case, it is important to cut out materials with as little waste possible. In shipping, it applies to the packing of containers.</p>
<h2>Only four gingerbread cookies</h2>
<p>We know the size of the smallest square container in which we can pack up to 10 square 1x1 meter pallets. But by simply adding one additional pallet, it becomes impossible to calculate the optimal size of the container. Abrahamsen explains:</p>
<p>“As more pallets are added, the calculation time increases beyond exponentially. Not even the best computers can keep up. Theoretically it's possible. But based upon the speed at which computing power is growing, it will probably take millions of years before we are able to optimize the handling of a few additional objects."&nbsp;&nbsp;&nbsp;</p>
<p>Furthermore, if one is working with more complicated shapes, like Christmas tree-shaped gingerbread, Mikkel Abrahamsen says that optimal solutions can only be found for up to four objects today.&nbsp;</p>
<figure><img alt="Left: Optimal packing of five squares. Right: The currently best known packing of eleven unit squares into a larger square." src="https://www.science.ku.dk/english/press/news/2020/the-ever-elusive-riddle-whats-the-best-way-to-cut-christmas-cookies/billedinformationer/Figur_2_1100.png">
<figcaption>Left: Optimal packing of five squares. Right: The currently best known packing of eleven unit squares into a larger square.</figcaption>
</figure>

<h2>An infinite number of options</h2>
<p>What makes it so difficult? Abrahamsen explains that the problem is similar to solving equations of degree five or higher, and with many unknowns. Here, it is known that such a solution cannot always be written down using regular arithmetic operations.</p>
<p>"Our study proves that the problem has a nature that we in mathematics refer to as continuous — which in a nutshell, means that one must know all of the coordinates at which the cookies can be placed and all of the angles at which they can be rotated," explains Abrahamsen.</p>
<p>As the possible combinations are infinite, there is no way to create a list of all the locations needed to try in order to find an optimal packing solution. Instead, algorithms that solve packing problems optimally need to be more analytical, which is time consuming. This contrasts with many other known algorithmic problems, where one can try a limited number of combinations before finding one that is optimal. Thus, packing problems are much more difficult.</p>
<p>So in practice, there are no better solutions to packing problems than the ones we humans can come up with.</p>
<p>"In both industry and over the kitchen counter we must continue to be satisfied with our less-than-optimal solutions and rest assured that we humans are still better than computers for these types of tasks — for the time being," concludes Mikkel Abrahamsen.&nbsp;&nbsp;&nbsp;</p>





  

</div>
<div>

  
    
    
        	

	


        <div>
    <p>
        <h2>Facts</h2>
    </p>
    <div>
        <ul>
<li>In computer science and mathematics, packing problems are a class of optimization problems which involve attempting to pack a number of objects as closely as possible in either two or three dimensions. Mathematicians have been addressing packing problems for hundreds of years.</li>
<li>With the new result, the two-dimensional packing problem has graduated to a higher class of computational complexity, which is denoted ∃ℝ. It was previously believed that the question belonged to the class NP together with the famed "travelling salesman problem", which deals with calculating the shortest tour for visiting all cities on a given list.</li>
<li>The research was conducted by Mikkel Abrahamsen of the University of Copenhagen’s BARC Centre, at the Department of Computer Science; Tillmann Miltzow from Utrecht University in the Netherlands and Nadja Seiferth from Freie Universität Berlin in Germany. The research has received funding from the VILLUM Foundation, among others. </li>
<li>The study has been presented at the prestigious conference FOCS 2020 (IEEE Symposium on Foundations of Computer Science), running from 16-19 November. <a href="https://arxiv.org/abs/2004.07558">Read the article here.</a></li>
</ul>

    </div>
</div>






  
</div>

        </div>
      </div></div>]]>
            </description>
            <link>https://di.ku.dk/english/news/2020/the-ever-elusive-riddle-whats-the-best-way-to-cut-christmas-cookies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383265</guid>
            <pubDate>Fri, 11 Dec 2020 07:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware – A Devastating Form of Digital Extortion]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383148">thread link</a>) | @roberla
<br/>
December 10, 2020 | https://security.christmas/2020/11 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We live in a digital era where the most precious commodity no longer is oil or gold, but data. But what if this data, including personal files, customer lists and company data, flight traffic information, or even sensitive hospital records were stolen? What would you do, or pay, to get it back?</p>
</section><article><section><p>Ransomware has been on the rise the past years, where criminals effectively take all the data on your computer hostage and demand a ransom to give it back to you. Refusing to pay may result in your data being lost permanently. </p>
<p>Everyone is a potential target for ransomware, including single individuals, small to large companies, and even public institutions. A disconcerting trend is the targeting of hospitals and the public sector. Only last year the Hollywood Presbyterian Medical Center in Los Angeles was <a href="https://sanfrancisco.cbslocal.com/2016/02/18/california-hospital-ransomware-attack-hackers/">attacked by ransomware</a>, blocking the company’s access to their own network and crucial patient data for 10 whole days. The hospital ended up paying the ransom of $17 000 in bitcoin to decrypt the data. </p>
<p>The demands have also increased drastically the last few years, where the <a href="https://www.coveware.com/blog/q2-2020-ransomware-marketplace-report">average ransom payment</a> having increased to an exorbitant $178 000 in Q2 of 2020. Some bigger companies also receive very high demands. For instance, Garmin was attacked in 2020 with an initial ransom demand of $10 million, which some <a href="https://www.bleepingcomputer.com/news/security/confirmed-garmin-received-decryptor-for-wastedlocker-ransomware/">sources</a> claim they chose to pay. And this does not include the costs of other factors such as downtime, loss of revenue, mistrust from consumers, and resources used to get everything up and running again. </p>
<p>Clearly, ransomware is a growing problem with an increase in both attacks and in the ransom demands themselves, as well as the targeting of sectors with the possible consequence of directly endangering lives. </p>
<p>But how to the criminals make their attacks so successful, either forcing a victim to pay or having to accept the loss of their data? The main principle of ransomware is that attackers will encrypt all the files rendering them unreadable, and only by buying the key to decrypt the files will they be accessible again. The first step to achieve this, is to obtain access to a computer or network in order to install the ransomware. </p>
<h2>How does ransomware get installed on my computer?</h2>
<p>Ransomware is a type of malware, which is a malicious piece of software that installs itself without permission on someone’s computer or even an organization’s whole system. The most common ways the attackers get access to your computer are:</p>
<ol>
<li>Phishing – a cyber-attack imitating a trusted source, where an employee or private person is tricked into installing the malware without knowing it. This can be through clicking a link or downloading an attachment in a seemingly legit email.</li>
<li>Drive by downloads – visiting compromised websites that then installs the malware on your computer.</li>
<li>Security vulnerabilities – if systems are not up to date and are known to have weaknesses, then attackers will exploit these to install their malware. </li>
</ol>
<h2>How does ransomware encrypt my files?</h2>
<p>Once the ransomware is installed, it encrypts all the data on your computer. Unfortunately, the encryption methods used now are so complex that it is unfeasible to decrypt the files without the decryption key, which is known only to the attackers. To achieve a secure encryption of your data, the attackers use a combination of symmetric and asymmetric encryption. </p>
<h4>Symmetric encryption</h4>
<p>One of the oldest ciphers in history is the shift cipher, which shifts each letter a set number of times back or forth in the alphabet. Knowing this set number, also referred to as the “key”, is therefore enough to both encrypt and decrypt a text. Julius Caesar was believed to use a shift cipher, substituting each letter with the one 3 spaces to the right. This is one of the simplest examples of a symmetric encryption. </p>
<p>Today, there are more advanced versions, which can be broadly categorized as block ciphers (encrypts in byte-sized blocks) or stream ciphers (encrypts single digits). These methods are fast and only require the same key to encrypt and decrypt. </p>
<h4>Asymmetric encryption</h4>
<p>Asymmetric encryption is slower and uses two keys instead of one: one public and one private. The private key is only in the possession of the key pair owner, whereas the public one is widely distributed. When using the public key to encrypt a message it can only be decrypted using the private key, and vice versa.  </p>
<h4>Ransomware take advantage of both encryption methods.</h4>
<p>One of the most common ways a ransomware takes over your computer, is through the following steps:</p>
<ol>
<li>When the ransomware is installed on a computer, it comes with an asymmetric public key, which it used to establish contact with the attackers’ server. All communication is encrypted using this asymmetric encryption, making it impossible to intercept and interpret the communication between the affected computer and the server. </li>
<li>The ransomware will then request a new asymmetric public key from the server, which is specific for the victim’s computer (making it impossible to share a key with other victims). </li>
<li>Once received, the ransomware also creates a symmetric key, which quickly encrypts all the files. </li>
<li>The symmetric key is then encrypted using the asymmetric key specific to the victim. This means that only the private key on the attackers’ server can be used to unlock the symmetric key, which again will decrypt all the files. </li>
</ol>
<p>This makes the whole process fast and yet very secure, and almost impossible to decrypt without paying the ransom. </p>
<h2>Victims of ransomware</h2>
<p>Originally, ransomware was used to target individuals, with a low enough ransom so most people would choose to pay. While individuals are still affected, organizations are targeted on a more regular basis, and can offer a more lucrative pay-off if successful. In fact, <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">one study</a> showed that over half of the companies had been subjected to a ransomware attack in the past year, and that 73% of these attacks were successful. A recent trend also shows an increase in attacks targeting <a href="https://edition.cnn.com/2020/10/28/politics/hospitals-targeted-ransomware-attacks/index.html">government institutions and hospitals</a>.  </p>
<h2>Costs and solutions</h2>
<p>An estimate shows that total ransom demands will reach a staggering <a href="https://cybersecurityventures.com/global-ransomware-damage-costs-predicted-to-reach-20-billion-usd-by-2021/">20 billion USD by 2021</a>. </p>
<p>While paying the ransom is strongly discouraged as it helps create a marked for extorting money in this manner, some still choose to pay the ransom to retrieve their data. One recent <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">study</a> of 5000 IT people showed that about 26% chose to pay and that of these, 95% did actually get the decryption key needed to unlock their files again. Over half chose not to pay and instead used backups of their data, while the rest used other methods.</p>
<p>However, even though paying up may seem like the best way to get things restored again, it may actually double the costs of being affected. All organizations attacked by ransomware had a high cost due to downtime, network costs, lost opportunity etc. even without paying the ransom. In fact, the authors of this <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">study</a> argue that the organizations that chose to pay  had the same costs as those who did not with getting their systems back online, except they also had the cost of removing the encryption in addition to their other expenses.</p>
<p>As most attacks are successful and as it is nearly impossible to decrypt your files after an attack, it’s best to try and prevent an attack in the first place. Good strategies include having regular and off-site backup of data, installing anti-ransomware on your system, training employees in recognizing phishing, and closing any technological vulnerabilites that could be exploited. Stay tuned for more on this and other good preventative measure in our next article.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383148</guid>
            <pubDate>Fri, 11 Dec 2020 06:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Dothraki Horde, Part II: Subsistence on the Hoof]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25382899">thread link</a>) | @parsecs
<br/>
December 10, 2020 | https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the second part of a four part (<a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">I</a>, III, IV) look at the Dothraki, the fictional horse-borne nomads of the <em>A Song of Ice and Fire</em> / <em>Game of Thrones</em> series.  We’re looking at, in particular, the degree to which George R.R. Martin’s claim that the Dothraki are “an amalgam of a number of steppe and plains cultures” holds up in the face of research.  Our last part, “<a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">Barbarian Couture</a>” looked at the influences that shaped the visual depiction of the Dothraki and found them badly wanting, more based in stereotypes and misconceptions than historical reality.</p>



<p>This week, we’re turning to the foundation of social structures: <strong>patterns of subsistence</strong> (<strong>which, to be clear, means in plain English: “how do they get food and basic resources?” </strong> That’s all subsistence is – how do you get enough resources to survive.)  Originally this was going to fit into a larger argument about culture, but I decided to break it out because we are <em>at long last</em> looking at the logistics and subsistence strategies of nomadic peoples.  Every time we have covered the <a href="https://acoup.blog/2019/05/10/collections-the-siege-of-gondor/">logistics </a>of <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">agrarian </a><a href="https://acoup.blog/2019/10/04/collections-the-preposterous-logistics-of-the-loot-train-battle-game-of-thrones-s7e4/">armies </a>and <a href="https://acoup.blog/2019/07/12/collections-the-lonely-city-part-i-the-ideal-city/">societies</a>, there has been a request to do a deeper dive into the way that Steppe nomads in particular, and nomads more generally, are different.  <strong>Well here it is!</strong></p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>(Bibliography note before we dive in.  I am not going to run through everything I’ve glanced at here, but for those looking to read more on this or retrace my steps more generally, a good starting place on the Steppe peoples is T. May, <em>The Mongol Art of War</em> (2007).  There’s also more than a dash here of bits from K. Chase, <em>Firearms: A Global History to 1700</em> (2008) as well as T. Ratchnevsky, <em>Genghis Khan: His Life and Legacy</em>, trans. T.N Haining (1991).  For the Native Americans of the Great Plains, I have relied principally on A.R. McGinnis, <em>Counting Coup and Cutting Horses: Intertribal Warfare on the Northern Plains, 1738-1889</em> (1990), F.R. Secoy, <em>Changing Military Patterns of the Great Plains Indians (17th Century through Early 19th Century)</em> (1958), and A.C. Isenberg, <em>The Destruction of the Bison: An Environmental History, 1750-1920</em> (2020))</p>



<p><strong>As with the past essay, the key statement we are really assessing here is <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">this one by George R.R. Martin</a>:</strong></p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also Alans, Sioux, Cheyenne, and various other Amerindian tribes… seasoned with a dash of pure fantasy.</p></blockquote>



<p>A statement which claims, quite directly, that the Dothraki are modeled primarily off of both Eurasian Steppe nomads and Great Plains Native Americans (with a ‘dash’ of fantasy).  Last time, we found that the <em>appearance</em> of the Dothraki fit almost entirely within the ‘dash’ of fantasy.  So this time we will begin to ask the same question about Dothraki culture –<strong> to what degree may it be said to be based in any <em>actual</em> historical horse-nomad cultures?</strong></p>



<h2>A Feast For People</h2>



<p>Now ‘culture’ is such a huge topic, it may well be asked why start with subsistence strategies. <strong> The answer is that in the pre-modern world, subsistence was one of, if not the, most dominant factor shaping culture</strong>.  After all, most people before the industrial revolution spent most of their time just doing the basic activities (herding, farming, spinning, weaving, cooking, etc.) that made survival possible!  Government structures, military organization, cultural values, marriage and fertility patterns, social structures all flow out of those things which most people were doing to survive, shaped by the needs of those subsistence strategies.</p>



<p>(A brief pedantic note: this sort of approach to history, beginning with big, slow changing patterns (what I often call here ‘structures’ – not a term I made up, by any means) like climate, geography, subsistence strategies, culture, etc. is generally associated with what is called the <em>Annales</em> school of history, which is a <em>method</em> of history.  This framework is often more interested in <em>La longue durée</em> (lit: ‘the (really) long term’) which is just a fancy French way of saying ‘a focus on the long-term historical structures (like those listed above) instead of short-term events (like wars, rulers, that sort of thing).’  As always, this sort of historical theory is a toolbox, not a dogma; different approaches to answer different questions.  But in this case, it is handy because of the way that the basic activities necessary for survival in a given climate form a sort of ‘bounding box’ for cultural possibility.)</p>



<p>What is particularly notable is with <em>A Song of Ice and Fire</em> and <em>Game of Thrones</em> is that our viewpoint character for Dothraki culture is a young woman who spends her time with the Dothraki in the <em>khalassar’s</em> (the Dothraki word for a tribe or clan) moving encampment.  Daenerys can only really view warfare second hand (at least in the books we get; the show is another matter), <strong>but she ought to be able to witnesses the subsistence system directly</strong>.  Even if she wasn’t involved in it directly (because she’s a high status queen), the daily work of survival would be going on all around her and in practice much of it would likely be at her direction as she exercises authority over lower-status individuals in the camp.</p>



<p>Now normally we would start this by looking at how subsistence strategies are represented in the books and show, but I think in this case it is going to be more helpful to begin with the historical subsistence systems <em>first</em>, since they are complex and we’re going to have several of them.  We’re actually going to start at the ending as well, with subsistence strategies of Native Americans on the Great Plains, for reasons that will be clearer once we’ve discussed it.</p>



<h2>A Changing of Patterns</h2>



<p><strong>The domesticated horse is not native to the Americas</strong>.  There is perhaps no more important fact when trying to understand how the horse-borne nomadic cultures of the Eurasian Steppe relate to those of the Great Plains.  The first domesticated horses arrived in the Americans with European explorer/conquerors and the settler-colonists that followed them.  Eventually enough of those horses escaped to create a self-reproducing wild (technically feral, since they were once domesticated) horse population, the <a href="https://en.wikipedia.org/wiki/Mustang">mustangs</a>, but they are not indigenous and mustangs were never really the primary source of new horses the way that wild horses on the Steppe were (before someone goes full nerd in the comments, yes I am aware that there were some early equines in the Americas at very early dates, but they were extinct before there was any chance for them to be domesticated).</p>



<div><figure><img data-attachment-id="5517" data-permalink="https://acoup.blog/horsescd1l-095/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg" data-orig-size="524,344" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="horsescd1l-095" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=524" src="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=524" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg 524w, https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=300 300w" sizes="(max-width: 524px) 100vw, 524px"><figcaption><a href="https://en.wikipedia.org/wiki/Mustang">Via Wikipedia</a>, American mustangs.  Mustangs are descendants mostly of Spanish horse breeds.  Notably, they tend to be smaller than many other breeds of European horses, even in cases where their domesticated forebears were larger breeds of draft horses or destriers.  This is because big stable-fed horses can’t survive on grass alone.</figcaption></figure></div>



<p><strong>Horses arrived in the Great Plains form the south via the Spanish and moving through Native American peoples west of the Rocky Mountains by both trade and eventually raiding in the early 1700s</strong>.  Notably firearms <em>also</em> began moving into the region in the same period, but from the opposite direction, coming from British and French traders to the North and West (the Spanish had regulations against trading firearms to Native Americans, making them unavailable as a source).  Both were thus initially <em>expensive trade goods</em> which could only be obtained from outside and then percolated unevenly through the territory; unlike firearms, which remained wholly external in their supply, horses were bred on the plains, but raiding and trade were still essential sources of supply for most peoples on the plains.  We’ll get to this more when we talk about warfare (where we’ll get into the four different military systems created by this diffusion), but being in a position where one’s neighbors had either the horse or the gun and your tribe did not was an <em>extreme</em> military disadvantage and it’s clear that the ‘falling out’ period whereby these two military innovations distributed over the area was very disruptive.</p>



<p><strong>But unlike guns</strong>, which seem to have had massive military impacts but only minimal subsistence impacts (a bow being just as good for hunting bison as a musket, generally), <strong>the arrival of the horse had <em>massive</em> subsistence impacts</strong> because it made hunting <em>wildly</em> more effective.  But the key thing to remember here is: the horse was <em>introduced</em> to the Great Plains no earlier than 1700, horse availability expanded only slowly over the area, but by 1877 (with the end of the <a href="https://en.wikipedia.org/wiki/Great_Sioux_War_of_1876">Black Hills War</a>), true Native American independence on the Great Plains was functionally over.  <strong>Consequently, unlike the Steppe, where we have a fairly ‘set’ system that had already been refined for centuries, <em>all</em> we see of the Plains Native American horse-based subsistence system is rapid change</strong>.  There was no finally reached stable end state, as far as I can tell.</p>



<p>Though there is considerable variation and also severe limits to the evidence, it seems that prior to the arrival of the horse, most Native peoples around the Great Plains practiced two major subsistence systems: <strong>nomadic hunter-gathering on foot </strong>(distinct from what will follow in that it places much more emphasis on the gathering part)<strong> on the one hand and a mixed subsistence system of small-scale farming mixed seasonally with plains hunting seems to have been the main options pre-horse</strong>, based on the degree to which the local area permitted farming in this way (for more on those, note Isenberg, <em>op. cit.</em>, 31-40).  Secoy …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/">https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25382899</guid>
            <pubDate>Fri, 11 Dec 2020 06:18:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some doctors, therapists get Health Canada permission to use magic mushrooms]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25382497">thread link</a>) | @billyharris
<br/>
December 10, 2020 | https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Four months after it allowed a handful of palliative care patients to use psilocybin as a way to relieve end-of-life suffering, Health Canada has cleared the way for more than a dozen health professionals to use the psychedelic drug themselves to help develop therapies for future use.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4039727.1492805330!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/63883228.jpg"></p></div><figcaption>Psilocybin is the ingredient in magic mushrooms that causes hallucinations, but in medically supervised settings, can also potentially help people overcome depression.<!-- --> <!-- -->(Shutterstock / gsplanet)</figcaption></figure><p><span><p>Four months after it allowed a handful of palliative care patients to use psilocybin as a way to relieve end-of-life suffering, Health Canada has cleared the way for more than a dozen health professionals to use the psychedelic drug themselves to help develop therapies for future use.&nbsp;</p>  <p>Health Canada says it granted 16 exemptions to a selection of nurses, doctors, therapists and social workers, allowing them to possess and use&nbsp;psilocybin&nbsp;for personal training without fear of prosecution under the country's drug laws.&nbsp;</p>  <p>"This is not a small step. This is a seismic step," said Dr. Sean O'Sullivan, a Tillsonburg, Ont., doctor and medical director of TheraPsil, a non-profit group that advocates for the therapeutic use of psilocybin.&nbsp;</p>  <p>"This is permission from the Ministry of Health and the Minister of Health to allow therapists to forward their own training in psychedelic medicine."&nbsp;</p>  <p><span><span><div><div role="button" tabindex="0" title="Mushrooms: The Magic Medicine"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/337/291/Sickboy-640x360.jpg" alt=""></p><p><span>Sickboy</span><span>1:02:33</span><span>Mushrooms: The Magic Medicine</span></p></div></div></div><span>Thomas Hartle never used drugs before his Stage IV cancer diagnosis. That’s changed thanks to Therapsil. A couple months ago, he became the first Canadian to legally use psychedelic mushrooms to treat end of life anxiety and depression. Take a listen to his story with an open mind.<!-- --> <!-- -->1:02:33</span></span></span><span><ul><li><a href="https://www.cbc.ca/news/health/microdosing-pschedelics-study-1.4771647" data-contentid="" flag="" text="How and why people 'microdose' tiny hits of psychedelic drugs"><span>How and why people 'microdose' tiny hits of psychedelic drugs</span></a></li></ul></span></p>  <p>The move comes after Health Canada&nbsp;gave <a href="https://www.cbc.ca/news/canada/british-columbia/magic-mushrooms-therapy-1.5675637" target="_blank">four exemptions to palliative care patients</a> to use the drug&nbsp;for end-of-life psychotherapy in August. Since then, other exemptions have been given to patients who want to use magic mushrooms.&nbsp;</p>  <p>The exemptions for health professionals will allow those who want to treat patients with psilocybin&nbsp;to understand what it would feel like and how best to use it.&nbsp;</p>  <p>They are good for one year.&nbsp;</p>  <p>"Psychedelic substances and treatment using these substances, such as&nbsp;psilocybin, is a growing area of scientific study and research. Because&nbsp;psilocybin&nbsp;is not an authorized therapeutic substance, the availability of rigorous scientific evidence demonstrating its safety and efficacy is limited," Health Canada said in a statement to CBC News.&nbsp;</p>  <p>"The exemptions do not permit the health care professionals to prescribe or provide mushrooms containing&nbsp;psilocybin&nbsp;to another person. There are no drugs containing&nbsp;psilocybin&nbsp;that have been authorized&nbsp; by Health Canada. Health Canada's decision to grant these exemptions does not constitute an opinion or endorsement from Health Canada on&nbsp;psilocybin-assisted psychotherapy, training, or the safety, effectiveness, or quality of&nbsp;psilocybin."</p>  <h2>Psychiatrists, nurses given exemptions</h2>  <p>"This is an immense step that the minister has taken, and a very wise step, a step that is totally congruent with the science and the published literature and is a very courageous move on her part and on our government's part," O'Sullivan said.&nbsp;</p>  <p>Psychedelic therapies such as psilocybin and LSD have had negative reputations, in part because of the war on drugs, O'Sullivan said.&nbsp;</p>    <p>"The war on drugs has been an unmitigated disaster worldwide. It has criminalized behaviour that does not need to be criminalized. Cannabis has been legalized, and the sky has not fallen," O'Sullivan said.&nbsp;</p>  <p>Those who have been given exemptions include psychiatrists associated with the University of Toronto, a community psychiatrist in Hamilton and his partner, as well as health professionals in Calgary and British Columbia.&nbsp;</p>  <p>O'Sullivan and his wife both got an exemption. He is a general practitioner and she is a therapist. He said it's important for doctors who could eventually prescribe psychedelics to be well versed in their effects.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/dr-sean-o-sullivan.JPG 300w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/dr-sean-o-sullivan.JPG 460w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/dr-sean-o-sullivan.JPG 620w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/dr-sean-o-sullivan.JPG 780w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/dr-sean-o-sullivan.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/dr-sean-o-sullivan.JPG"></p></div><figcaption>Dr. Sean O'Sullivan is one of 16 health professionals who has been granted an exemption from Canada's drug laws to use magic mushrooms. <!-- --> <!-- -->(Submitted by Sean O'Sullivan)</figcaption></figure></span></p>  <p>"You would not expect a guide to take any journey over any terrain with&nbsp;which the guide was not familiar. When it comes to psychedelics, the terrain is so unusual and so outlandish that it is absolutely imperative that the therapist have familiarity with the realms of the human unconscious that are visited under psychedelics because they can help guide the patient through situations that might seem utterly bizarre, even psychotic to an untrained therapist," O'Sullivan said.</p>  <p>"Great information can be obtained if you dissect and unpack that material that comes up under these medications."</p>  <p>Psilocybin&nbsp;allows the brain to put away the "default mode network," the part of our brain that worries about taxes and dinner and the shopping list, and dive deeper.&nbsp;</p>    <p>"If you look at your <a href="https://www.cbc.ca/news/health/seeking-seat-of-consciousness-in-dark-side-of-brain-1.1415607" target="_blank">default mode network</a>, you will find that the themes that come up are the same themes that came up last year and the year before and the decade before," O'Sullivan said. "Psychedelics disassemble the default mode network and they allow a person to have new experiences in a carefully controlled clinical setting. When the default mode network is put back together, it's not put back together in the same way as it was previously."</p>  <p>That's why a single dose of a psychedelic medicine can have more effect than years of talk therapy or medication, he said.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485</link>
            <guid isPermaLink="false">hacker-news-small-sites-25382497</guid>
            <pubDate>Fri, 11 Dec 2020 05:03:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Economics of Software Performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25381748">thread link</a>) | @ivanmontillam
<br/>
December 10, 2020 | https://www.ivanmontilla.com/2020/12/economics-of-software-performance/ | <a href="https://web.archive.org/web/*/https://www.ivanmontilla.com/2020/12/economics-of-software-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em><strong>Disclaimer:</strong> I’m presenting this post without any figures or math, so it’s just my opinion based on professional past eye-witnessed experiences. This post will not be about hate, but rather on the weaknesses of delivery of recent trending technologies.</em></p>



<p>Recently I’ve seen a dangerous trend in software development, more specifically about web and desktop technologies. I wish not to bash on software frameworks such as Electron, but I think there are hidden costs for both junior developers and enterprises are ignoring. Let’s dig a bit deeper ahead.</p>



<p>Whenever you take the technical choice to abstract your codebase with a multiplatform framework, you need to be sure about the hidden costs of using it, and I’m not talking just about the implied costs of software performance. If you provide a poor user experience because your app feels <em>crap</em> to use, that’s a potential paying user that you’ll lose or at least will be upfront harder to acquire. </p>



<p>Sometimes software development teams are on a budget and need to make a choice like this, in order to increase market access and in that way, achieve faster market-product fit. I can understand that, but what is hard to reconcile to me, is the cost you save equals the cost your customers end up paying. Ideally, you’d not cut costs on this because after all, you need to provide the <em>best-in-class</em> experience to your users if you’re to retain them over several billing renewal cycles.</p>



<p>To put it bluntly: As a company, you might mistakenly think to save on software development costs, but your users actually don’t. What actually happens is: They end up paying the costs you <em>attempted</em> to save (more on this later), exponentially. It’s inversely proportional.</p>



<p>Did you deliver an app to the marketplace quickly? Yes. Does your app solve the problem? To some degree. Does the app perform <em>painlessly fast</em>? Muddy waters my friend. Can it run Crysis? I don’t think so.</p>



<p>The expected outcome is that you save on costs and have a greater runway for your startup to live, but let’s not forget: <em><a href="https://stackoverflow.com/questions/30490018/can-poor-performance-be-considered-as-a-software-bug" target="_blank" rel="noreferrer noopener">Poor software performance can be considered a bug</a></em>. If you’ve read <em>Steve McConnell’s Code Complete 2nd. Ed.</em>, you’ll notice <strong>proper software development is hard</strong>, and most of the time: with 5, 6 or even 7 figures on costs. And if your ideal resource-saving scenario doesn’t realize (time and money), your company will eventually find themselves reimplementing the app again in the latest technology-fad of that moment, feeding the vicious cycle.</p>



<p>Conversely, paying high costs on software development, while doesn’t guarantee business success, certainly helps in capturing better engineering for your product or service. So you had to have a team on iOS development, another one for Android development, another one for Windows, macOS, and Linux, but you delivered a superior experience. You might need to strike a balance between these two tug-of-war situations, to meet both business requirements and good engineering.</p>



<p>Imagine a world where mobile devices and personal computers ran on public clouds (much like Google Stadia), such as AWS or Azure. In such a scenario, your users would have to provision more expensive compute instances to actually run your 300 Mb social media application (without accounting for the data it stores locally). Storage and RAM are evergrowing, but here’s a little secret nobody tells you: <strong>There’s no need to take it up in its entirety!</strong></p>



<p><a href="https://mcfunley.com/choose-boring-technology" target="_blank" rel="noreferrer noopener">Boring technology is really great</a> not only because of its predictability, but it’s also great because most of the time it has been battle-tested for performance. The vulnerability of bloated technologies lies in the trend that some applications seem to be running really fast, but these are very few. So few they can be counted with the fingers of a single hand. All other applications range from overweight to really heavy on the OSes they run on. Maybe the framework is an easy “abusable” trap to create underperforming applications. Hat tip to these engineers of these few applications, these are a great feat of debugging, profiling, and engineering to achieve these results.</p>



<p>Yes, I can hear you… “<em>money talks</em>,” but if that’s the case, then consider technologies that overall reduce the cost to implement and to run. Example: <a href="https://sciter.com/" target="_blank" rel="noreferrer noopener">Sciter</a>‘s learning curve is harder than Electron’s, it actually requires you to learn a native or intermediate language to implement your business logic, and it also has <a href="https://www.kickstarter.com/projects/c-smile/open-source-sciter-engine" target="_blank" rel="noreferrer noopener">5 times less carbon footprint</a>, but hey! You’re a proper engineer shipping some serious code to production environments, after all, you choose what’s best for your customers, or do you? <strong>😉</strong></p>



<p>On a side note: I consider the origin of this dangerous trend to be from the specific situation when junior software developers skip computer, software architecture, and software design classes irresponsibly delivering bloated software to the marketplace.</p>



<p>Ignorance is the root and stem of all evils, Plato once said.</p>



<p>Source of inspiration: <a href="https://cr.yp.to/bib/1995/wirth.pdf" target="_blank" rel="noreferrer noopener">A Plea for Lean Software (Niklaus Wirth, 1995)</a></p>
		</div></div>]]>
            </description>
            <link>https://www.ivanmontilla.com/2020/12/economics-of-software-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25381748</guid>
            <pubDate>Fri, 11 Dec 2020 02:57:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clubhouse Conversation with Dylan Field]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25381458">thread link</a>) | @giacaglia
<br/>
December 10, 2020 | https://www.joinclubhouse.com/event/9mW6WaMX | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/event/9mW6WaMX">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.joinclubhouse.com/event/9mW6WaMX</link>
            <guid isPermaLink="false">hacker-news-small-sites-25381458</guid>
            <pubDate>Fri, 11 Dec 2020 02:15:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Alternatives]]>
            </title>
            <description>
<![CDATA[
Score 280 | Comments 224 (<a href="https://news.ycombinator.com/item?id=25380999">thread link</a>) | @yepgwer
<br/>
December 10, 2020 | https://justprivacy.org/google-alternatives/ | <a href="https://web.archive.org/web/*/https://justprivacy.org/google-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span color="000000"><p>We may earn a small commission if you choose to purchase from our links <strong>(at no extra cost to you!)</strong></p></span></p><div data-elementor-type="wp-post" data-elementor-id="989" data-elementor-settings="[]"><div><div><section data-id="10b593b" data-element_type="section"></section><section data-id="c631736" data-element_type="section"><div><div><div data-id="72201ec" data-element_type="column"><div><div><div data-id="e877a4b" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg" alt="Google Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Alternatives-2048x1152.jpg 2048w" data-srcset="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Alternatives-2048x1152.jpg 2048w" sizes="(max-width: 992px) 100vw, 992px" title="Google Alternatives Google Alternatives: Protecting Your Data"></p></div></div></div></div></div></div></div></section><section data-id="c32dc21" data-element_type="section"><div><div><div data-id="af9583c" data-element_type="column"><div><div><div data-id="797f602" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>The purpose of this guide is to be the most in-depth list of the best alternatives to Google and its products.</p><p>Privacy and security of personal data online has become more of an issue, this means people are trying to find alternatives to Google.</p><p>The way Google makes money is by data collection and advertisements, with both affect your online privacy. The more data Google has on you the better they can find out what you’re interested in (target you) and therefore make more money off you. Did you know Google had over <a href="https://www.statista.com/statistics/267606/quarterly-revenue-of-google/" target="_blank" rel="noopener">$159 billion dollars in revenue</a> in 2019?</p><p>However, there is a growing amount of people who are looking for alternatives to Google.</p><p><span>Note:</span> None of these alternatives are in order, it depends on you’re specific needs.</p></div></div></div></div></div></div></div></div></section><section data-id="8997902" data-element_type="section"><div><div><div data-id="b2c7c82" data-element_type="column"><div><div><div data-id="a225dd3" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Search Engine Alternatives</h2></p></div><div data-id="6838ece" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="519" src="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg" alt="Google Search Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-300x157.jpg 300w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-768x402.jpg 768w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives.jpg 1200w" data-srcset="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-300x157.jpg 300w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-768x402.jpg 768w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives.jpg 1200w" sizes="(max-width: 992px) 100vw, 992px" title="Google Search Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="4d6be8b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Privacy and Google search don’t go hand in hand. When you use Google search, they will record your IP address, your search terms, and usually a unique ID.</p><p>Here are some good alternatives to Google search.</p><ol><li><a href="https://duckduckgo.com/" target="_blank" rel="noopener">DuckDuckGo</a> – An internet search engine whose goal is to protect users’ privacy and avoiding personalized search results (tracking).</li><li><a href="https://www.qwant.com/" target="_blank" rel="noopener">Qwant</a> – Is a French search engine that doesn’t track users.</li><li><a href="https://searx.me/" target="_blank" rel="noopener">SearX</a> – Is a free metasearch engine, intended to protect the privacy of its users.</li><li><a href="https://startpage.com/" target="_blank" rel="noopener">Startpage</a> – a search engine extension that allows users to browse while not being tracked.</li><li><a href="https://swisscows.com/" target="_blank" rel="noopener">SwissCows</a> – Is a Swiss search engine that was launched in 2014. They don’t keep track of the searches done on their site.</li><li><a href="https://www.mojeek.com/" target="_blank" rel="noopener">Mojeek</a> – Is a UK-based search engine, they are independent and have unbiased results which means no user tracking.</li><li><a href="https://info.ecosia.org/" target="_blank" rel="nofollow noopener">ecosia</a> – Berlin-based search engine whose profits go into planting trees to fight against climate change! They are also privacy-friendly and ethical.</li><li>&nbsp;</li><li><a href="https://metager.org/" target="_blank" rel="noopener">MetaGer</a> – Is a search engine based on protecting users’ privacy, it’s also based in Germany.</li><li><a href="https://yandex.com/" target="_blank" rel="noopener">Yandex Search</a> – Is a search engine based in Russia and owned by a Russian corporation <a href="https://en.wikipedia.org/wiki/Yandex" target="_blank" rel="noopener">Yandex</a>.</li><li><a href="https://yacy.net/" target="_blank" rel="noopener">YaCy</a> – Is a free search engine built on principles of P2P (peer-to-peer) networks.</li></ol><p>Most of the search engines above are metasearch engines (except Mokeej and Yandex) meaning they source their search results from larger search engines like Google and Bing.</p></div></div></div></div></div></div></div></div></section><section data-id="56efb89" data-element_type="section"><div><div><div data-id="1091847" data-element_type="column"><div><div><div data-id="653fe9a" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Chrome Alternatives</h2></p></div><div data-id="0470836" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg" alt="Chrome Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Chrome-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Chrome-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Chrome Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="25f82ad" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Chrome is an extremely popular web browser and billions of searches are done monthly.</p><p>As you can see Google has 92.07% of the Search Engine Market Share Worldwide as of February 2020!</p></div></div></div><div data-id="e99d120" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://gs.statcounter.com/search-engine-market-share" target="_blank" rel="noopener"> <img width="992" height="269" src="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png" alt="Market Share Chrome" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png 1024w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-300x81.png 300w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-768x208.png 768w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-1536x417.png 1536w, https://justprivacy.org/media/2020/03/Market-Share-Chrome.png 1629w" data-srcset="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png 1024w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-300x81.png 300w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-768x208.png 768w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-1536x417.png 1536w, https://justprivacy.org/media/2020/03/Market-Share-Chrome.png 1629w" sizes="(max-width: 992px) 100vw, 992px" title="Market Share Chrome Google Alternatives: Protecting Your Data">		</a></p></div></div><div data-id="2d8725f" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Remember that Google Chrome is not only a search engine but a super successful data collection tool! More and more people are noticing this. There are many articles saying that Google Chrome has become spyware!</p><p>If you want to read more about this you can read this forum on <a href="https://www.reddit.com/r/BATProject/comments/c3q51d/goodbye_chrome_googles_web_browser_has_become_spy/?utm_source=share&amp;utm_medium=web2x" target="_blank" rel="noopener">Reddit</a> and an article on <a href="https://www.washingtonpost.com/technology/2019/06/21/google-chrome-has-become-surveillance-software-its-time-switch/" target="_blank" rel="noopener">Washington Post.</a></p><p>Here are some good alternatives to Chrome:</p><ol><li><a href="https://www.torproject.org/projects/torbrowser.html.en" target="_blank" rel="noopener">Tor Browser</a> – Is a global and decentralized computer network. This allows you to hide from tracking and surveillance.</li><li><a href="https://www.mozilla.org/fr/firefox/new/" target="_blank" rel="noopener">Firefox</a> – Is a free and open-source web browser, it was developed by Mozilla Foundation and help from thousands of volunteers!</li><li><a href="https://brave.com/fr/" target="_blank" rel="noopener">Brave</a> – Is an open-source web browser whose goal is to protect the privacy of their users by blocking trackers or preferring pages in HTTPS.</li><li><a href="https://iridiumbrowser.de/" target="_blank" rel="noopener">Iridium Browser</a> – Is based on the Chromium codebase. All modifications enhance privacy for the user.</li><li><a href="https://ungoogled-software.github.io/ungoogled-chromium-binaries/" target="_blank" rel="noopener">Ungoogled Chromium</a> – Is an open-source version of Chromium that has been modified to enhance users’ privacy.</li><li><a href="https://www.waterfox.net/" target="_blank" rel="noopener">Waterfox</a> – Is an open-source web browser that is based on Mozilla Firefox. Its purpose is to be speedy and ethical.</li><li><a href="https://www.epicbrowser.com/" target="_blank" rel="noopener">Epic Browser</a> – Is a “Privacy Browser” that is a secure chromium-based web browser.</li><li><a href="https://www.gnu.org/software/gnuzilla/" target="_blank" rel="noopener">GNUzilla</a> – Its a GNU version of the Mozilla suite. Its main advantage is that it’s ethical and entirely free!</li></ol><p>There are other alternatives to Google Chrome like Apple’s Safari and Microsoft’s Edge but many of these have serious privacy issues.</p></div></div></div></div></div></div></div></div></section><section data-id="0f232f2" data-element_type="section"><div><div><div data-id="dcd92ec" data-element_type="column"><div><div><div data-id="c5b213d" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg" alt="Gmail Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Gmail Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="acb282e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Your inbox is where the most important information is sent. You can find a lot of information on a person based on your inbox.</p><p>The unfortunate thing is that Google and its partners have access to all your information and they can <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" target="_blank" rel="noopener">collect data</a>, they can display ads inside your inbox, and the contents of your inbox are shared with random <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" target="_blank" rel="noopener">third parties</a>.</p><p>Here are some more secure Gmail alternatives:</p><ol><li><a href="https://protonmail.com/" target="_blank" rel="noopener">ProtonMail</a> – Is an encrypted email service created in 2013 by CERN and MIT scientists.</li><li><a href="https://tutanota.com/" target="_blank" rel="noopener">Tutanota</a> – Is a German-based email provider that is open-sourced with end-to-end email software. Tutanota also offers a web messaging service.</li><li><a href="https://posteo.de/en/" target="_blank" rel="noopener">Posteo</a> – Is a German email provider whose IT foundation is based on open-source software. They also use green energy from Greenpeace Energy and is also ad-free! The service costs € 1 per month.</li><li><a href="https://runbox.com/" target="_blank" rel="noopener">Runbox</a> – Is a company that provides email and web hosting services. It was founded in March 2011 and its headquarters are located in Oslo.</li><li><a href="https://mailbox.org/en/" target="_blank" rel="noopener">Mailbox.org</a> – Its an ad-free and secure email provider based in Germany, they offer a calendar, contacts lists and more.</li><li><a href="https://www.startmail.com/" target="_blank" rel="noopener">StartMail</a> – Is created by the people who created StartPage (a secure search engine).&nbsp;</li><li><a href="https://mailfence.com/en/" target="_blank" rel="noopener">Mailfence</a> – Is an encrypted email service based in Belgium. It offers free accounts.</li><li><a href="https://countermail.com/" target="_blank" rel="noopener">CounterMail</a> – Is a secure email provider that is based in Sweden.&nbsp;</li></ol></div></div></div></div></div></div></div></div></section><section data-id="9dd4dfa" data-element_type="section"><div><div><div data-id="5d3cd03" data-element_type="column"><div><div><div data-id="6d29af4" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Calendar Alternatives</h2></p></div><div data-id="fc23717" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg" alt="Gmail Alternatives 1" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Gmail Alternatives 1 Google Alternatives: Protecting Your Data"></p></div></div><div data-id="a3398d3" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Calendar is amazing it helps users manage their time, set goals, and remember things.</p><p>There are many upsides to Google’s Calendar app but there are some major privacy issues and many people are looking for alternatives.</p><p>Here are multiple Google Calendar alternatives:</p><ol><li><a href="https://www.simplemobiletools.com/" target="_blank" rel="noopener">Simple Calendar</a> – It’s an ad-free app without any unnecessary permissions.</li><li><a href="https://fruux.com/" target="_blank" rel="noopener">Fruux</a> – Offers a free account, supports many operating systems, and is open-source.</li><li><a href="https://timetreeapp.com/intl/en/" target="_blank" rel="noopener">TimeTree</a> – It offers a free account and supports Android, iOS, and browser.</li><li><a href="https://protonmail.com/blog/protoncalendar-beta-announcement/" target="_blank" rel="noopener">ProtonCalendar</a> – Created by the same people who made ProtonMail!</li><li><a href="https://github.com/Kartones/flask-calendar#introduction" target="_blank" rel="noopener">Flask-Calendar</a> – Basic, self-hosted Calendar, has a few features as well</li></ol><p>There are a few services that offer both email and calendar services in one:</p><ul><li><a href="https://tutanota.com/" target="_blank" rel="noopener">Tutanota</a></li><li><a href="https://mailbox.org/en/" target="_blank" rel="noopener">Mailbox.org</a></li><li><a href="https://posteo.de/" target="_blank" rel="noopener">Posteo</a></li><li><a href="https://mailfence.com/" target="_blank" rel="noopener">Mailfence</a></li><li><a href="https://outlook.live.com/" target="_blank" rel="noopener">Outlook</a></li></ul></div></div></div></div></div></div></div></div></section><section data-id="c72fb6b" data-element_type="section"><div><div><div data-id="f3c4b93" data-element_type="column"><div><div><div data-id="021a025" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Drive Alternatives</h2></p></div><div data-id="a27452e" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg" alt="Google Drive Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Drive Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="067a2fa" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Drive is a popular option because it’s free and extremely convenient, but Google doesn’t care about users’ privacy that much. It collects your data and uses it for their own purposes.</p><p>Here are some good Drive Alternatives:</p><ol><li><a href="https://www.dropbox.com/" target="_blank" rel="noopener">Dropbox</a> – Is a file hosting service owned by the American company Dropbox.</li><li><a href="https://www.sync.com/" target="_blank" rel="noopener">Sync.com</a> – Is based in Canada. They offer secure and encrypted cloud storage for both businesses and individuals.</li><li><a href="https://mega.nz/" target="_blank" rel="noopener">Mega</a> – Is a secure cloud storage service that offers free 50 GB of storage.</li><li><a href="https://nextcloud.com/" target="_blank" rel="noopener">Nextcloud</a> – This is a free and open-source file sharing platform that is based in Germany.</li><li><a href="https://github.com/syncthing/syncthing/tree/master" target="_blank" rel="noopener">Syncthing</a> – Peer-to-peer, an open-sourced cloud storage platform.</li><li><a href="https://tresorit.com/" target="_blank" rel="noopener">Tresorit</a>d Hungary that is serious about en<span>&nbsp;– Is a storage service based in Switzerland enhanced</span>&nbsp;security and data encryption.&nbsp;</li><li><a href="https://owncloud.org/" target="_blank" rel="noopener">ownCloud</a> – This is an open-source file sharing platform based in Germany.</li><li><a href="http://www.infomaniak.com/" target="_blank" rel="noopener">Infomaniak</a> – Switzerland-based privacy-friendly service that offers drive, calendar, and more services.</li></ol><p>Some of my recommendations above (Dropbox, Mega) aren’t the best for privacy but are much more privacy-friendly than Google Drive.</p></div></div></div></div></div></div></div></div></section><section data-id="560065d" data-element_type="section"><div><div><div data-id="473c144" data-element_type="column"><div><div><div data-id="f1693c6" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg" alt="Google Docs Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Docs Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="98b5c8d" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Docs offers users to create documents easily online. But Google makes its money through data collection and Google’s bots have been caught crawling through users’ documents.</p><p>Here are some good alternatives to Google Drive:</p><ol><li><a href="https://www.zoho.com/docs/" target="_blank" rel="noopener">Zoho Office</a> – This is a good Google alternative for docs since it has a good interface and works well.</li><li><a href="https://etherpad.org/" target="_blank" rel="noopener">EtherPad</a> – Is an online free text editor that allows users to work collaboratively and in real-time.</li><li><a href="https://cryptpad.fr/" target="_blank" rel="noopener">CryptPad</a> – Is a great privacy-focused alternative to Google Docs.</li><li><a href="https://www.openoffice.org/" target="_blank" rel="noopener">Apache OpenOffice</a> – Is a good office suite platform that is also available <span>offline.</span></li><li><a href="https://personal.onlyoffice.com/" target="_blank" rel="noopener">OnlyOffice</a> – Is a multifunctional online office suite.</li><li><a href="https://www.nuclino.com/" target="_blank" rel="noopener">Nuclino</a> – Is a cloud-based collaboration software that allows teams to work on projects together and share information in real-time.</li><li><a href="https://flibreoffice.org/" target="_blank" rel="noopener">LibreOffice</a> – Is a good free and open-sourced office suite that is also available <span>offline.</span></li></ol></div></div></div></div></div></div></div></div></section><section data-id="46d2732" data-element_type="section"><div><div><div data-id="c3a000e" data-element_type="column"><div><div><div data-id="2f0a056" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg" alt="YouTube Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/YouTube-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/YouTube-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="YouTube Alternatives Google Alternatives: Protecting Your Data"></p></div></div></div></div></div></div></div></section><section data-id="46501a2" data-element_type="section"><div><div><div data-id="ce19e75" data-element_type="column"><div><div><div data-id="8f49f0c" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Photos Alternatives</h2></p></div><div data-id="3b7c0a6" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg" alt="Google Photos Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Photos Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="9979111" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google offers unlimited storage for photo’s but Google isn’t doing it to be nice. They will use your photos to scan your pictures and track things you do. I don’t think Google or any company needs to know that much about you.</p><p>Here are a few good Google Photo’s alternatives:</p><ol><li><a href="https://piwigo.org/" target="_blank" rel="noopener">Piwigo</a> – Is an open-source photo gallery software.&nbsp;</li><li><a href="https://zyl.ai/" target="_blank" rel="noopener">Zyl</a> – Is a great mobile app that cares about privacy.</li><li><a href="https://crypt.ee/" target="_blank" rel="noopener">Cryptee</a> –&nbsp; Is a great option if you’re serious about your privacy. They offer many services as well as not just photos.</li><li><a href="https://cluster.co/" target="_blank" rel="noopener">Cluster</a> – A free app that’s allows you to create photo albums and share them with people you choose.</li><li><a href="https://photostructure.com/" target="_blank" rel="noopener">PhotoStructure</a> – relatively new self-hosted privacy-friendly photo manager</li></ol></div></div></div></div></div></div></div></div></section><section data-id="e855368" data-element_type="section"><div><div><div data-id="205ce2f" data-element_type="column"><div><div><div data-id="2236d87" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Analytics Alternatives</h2></p></div><div data-id="643d0e7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg" alt="Google Analytics Alternative" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Analytics Alternative Google Alternatives: Protecting Your Data"></p></div></div><div data-id="fc58c6b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>If you’re running a website there are good reasons to use alternatives to Google Analytics. One, you’re respecting your visitor’s privacy and there are more friendly alternatives.</p><p>Websites who run Google Adsense campaigns are the ones who usually use Google Analytics because it would be much more difficult to track your results without it.</p><p>Here are a few Analytics alternatives:</p><ol><li><a href="https://plausible.io/" target="_blank" rel="nofollow noopener">Plausible</a> – A simple and privacy-friendly alternative to Google Analytics. It’s also lightweight, open-source, and has no cookies.</li><li><a href="https://matomo.org/" target="_blank" rel="noopener">Matomo</a> – It was formerly Piwik, and is an open-sourced platform that understands the privacy of the users. It also allows website admins to import historic Google Analytics data to Matomo.</li><li><a href="https://usefathom.com/" target="_blank" rel="noopener">Fathom Analytics</a> – Is an open-sourced website analytics platform that is efficient and fast. (<a href="https://github.com/usefathom/fathom" target="_blank" rel="noopener">GitHub</a>)</li><li><a href="https://clicky.com/" target="_blank" rel="noopener">Clicky</a> – Is a good alternative to Google Analytics because it keeps the user’s privacy by making their IP anonymous. It’s also efficient and user-friendly. It is also certified by <a href="https://www.privacyshield.gov/welcome" target="_blank" rel="noopener">Privacy Shield</a>!</li><li><a href="https://www.atinternet.com/en/" target="_blank" rel="noopener">AT Internet</a> – Is a French company that was created in 1996. It’s good for performance measurement or sites, and applications.</li><li><a href="https://www.foxmetrics.com/" target="_blank" rel="noopener">FoxMetrics</a> – Is a platform that allows you to understand and analyze your customer’s actions from your desktop and mobile device.</li></ol></div></div></div></div></div></div></div></div></section><section data-id="9f07b94" data-element_type="section"><div><div><div data-id="5b063df" data-element_type="column"><div><div><div data-id="dafc60c" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Translate Alternatives</h2></p></div><div data-id="eb7e8e7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg" alt="Google Translate Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Translate Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="bae68a8" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google has many privacy issues and Google Translate is no exception. Google …</p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justprivacy.org/google-alternatives/">https://justprivacy.org/google-alternatives/</a></em></p>]]>
            </description>
            <link>https://justprivacy.org/google-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380999</guid>
            <pubDate>Fri, 11 Dec 2020 00:59:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a Kubernetes Pod Gets an IP Address]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380898">thread link</a>) | @freedomben
<br/>
December 10, 2020 | https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/ | <a href="https://web.archive.org/web/*/https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the core requirements of the
<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#the-kubernetes-network-model" target="_blank" rel="noopener">Kubernetes networking model</a> is that every pod should get its own IP address and that every pod in the cluster should be able to talk to it using this IP address. There are several network providers (flannel, calico, canal, etc.) that implement this networking model.</p><p>As I started working on Kubernetes, it wasn’t completely clear to me how every pod is assigned an IP address. I understood how various components worked independently, however, it wasn’t clear how these components fit together. For instance, I understood what CNI plugins were, however, I didn’t know how they were invoked. So, I wanted to write this post to share what I have learned about various networking components and how they are stitched together in a kubernetes cluster for every pod to receive an IP address.</p><p>There are various ways of setting up networking in kubernetes and various options for a container runtime. For this post, I will use
<a href="https://github.com/coreos/flannel" target="_blank" rel="noopener">Flannel</a> as the network provider and
<a href="https://github.com/containerd/containerd" target="_blank" rel="noopener">Containerd</a> as the container runtime. Also, I am going to assume that you know how container networking works and only share a very brief overview below for context.</p><h2 id="some-background-concepts">Some Background Concepts</h2><h3 id="container-networking-a-very-brief-overview">Container Networking: A Very Brief Overview</h3><p>There are some really good posts explaining how container networking works. For context, I will go over a very high level overview here with a single approach that involves linux bridge networking and packet encapsulation. I am skipping details here as container networking deserves a blog post of itself. Some of the posts that I have found to be very educational in this space are
<a href="#container-networking">linked in the references below</a>.</p><h4 id="containers-on-the-same-host">Containers on the same host</h4><p>One of the ways containers running on the same host can talk to each other via their IP addresses is through a linux bridge. In the kubernetes (and docker) world, a
<a href="https://man7.org/linux/man-pages/man4/veth.4.html" target="_blank" rel="noopener">veth (virtual ethernet)</a> device is created to achieve this. One end of this veth device is inserted into the container network namespace and the other end is connected to a
<a href="https://wiki.archlinux.org/index.php/Network_bridge" target="_blank" rel="noopener">linux bridge</a> on the host network. All containers on the same host have one end of this veth pair connected to the linux bridge and they can talk to each other using their IP addresses via the bridge. The linux bridge is also assigned an IP address and it acts as a gateway for egress traffic from pods destined to different nodes.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/bridge-networking.png" alt="bridge networking"></p><h4 id="containers-on-different-hosts">Containers on different hosts</h4><p>One of the ways containers running on different hosts can talk to each other via their IP addresses is by using packet encapsulation. Flannel supports this through
<a href="https://vincent.bernat.ch/en/blog/2017-vxlan-linux" target="_blank" rel="noopener">vxlan</a> which wraps the original packet inside a UDP packet and sends it to the destination.</p><p>In a kubernetes cluster, flannel creates a vxlan device and some route table entries on each of the nodes. Every packet that’s destined for a container on a different host goes through the vxlan device and is encapsulated in a UDP packet. On the destination, the encapsulated packet is retrieved and the packet is routed through to the destined pod.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/flannel-networking.png" alt="flannel networking"></p><p><em>NOTE: This is just one of the ways how networking between containers can be configured.</em></p><h3 id="what-is-cri">What Is CRI?</h3><p><a href="https://github.com/kubernetes/cri-api" target="_blank" rel="noopener">CRI (Container Runtime Interface)</a> is a plugin interface that allows kubelet to use different container runtimes. Various container runtimes implement the CRI API and this allows users to use the container runtime of their choice in their kubernetes installation.</p><h3 id="what-is-cni">What is CNI?</h3><p><a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">CNI project</a> includes a
<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">spec</a> to provide a generic plugin-based networking solution for linux containers. It also consists of various
<a href="https://github.com/containernetworking/plugins" target="_blank" rel="noopener">plugins</a> which perform different functions in configuring the pod network. A CNI plugin is an executable that follows the CNI spec and we’ll discuss some plugins in the post below.</p><h2 id="assigning-subnets-to-nodes-for-pod-ip-addresses">Assigning Subnets To Nodes For Pod IP Addresses</h2><p>If all pods are required to have an IP address, it’s important to ensure that all pods across the entire cluster have a unique IP address. This is achieved by assigning each node a unique subnet from which pods are assigned IP addresses on that node.</p><h3 id="node-ipam-controller">Node IPAM Controller</h3><p>When <code>nodeipam</code> is passed as an option to the
<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/" target="_blank" rel="noopener">kube-controller-manager’s</a> <code>--controllers</code> command line flag, it allocates each node a dedicated subnet (podCIDR) from the cluster CIDR (IP range for the cluster network). Since these podCIDRs are disjoint subnets, it allows assigning each pod a unique IP address.</p><p>A kubernetes node is assigned a podCIDR when the node first registers with the cluster. To change the podCIDR allocated to nodes in a cluster, nodes need to be de-registered and then re-registered with any configuration changes first applied to the kubernetes control plane. <code>podCIDR</code> for a node can be listed using the following command.</p><pre><code>$ kubectl get no &lt;nodeName&gt; -o json | jq '.spec.podCIDR'
10.244.0.0/24
</code></pre><h2 id="kubelet-container-runtime-and-cni-plugins---how-its-all-stitched-together">Kubelet, Container Runtime and CNI Plugins - how it’s all stitched together</h2><p>When a pod is scheduled on a node, a lot of things happen to start up a pod. In this section, I’ll only focus on the interactions that relate to configuring network for the pod.</p><p>Once a pod is scheduled on the node, the following interactions result in configuring the network and starting the application container.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-flowchart.png" alt="kubelet-cri-cni-flowchart"></p><p>Ref:
<a href="https://github.com/containerd/cri/blob/v1.11.1/docs/architecture.md" target="_blank" rel="noopener">Containerd cri plugin architecture</a></p><h2 id="interactions-between-container-runtime-and-cni-plugins">Interactions between Container Runtime and CNI Plugins</h2><p>Every network provider has a CNI plugin which is invoked by the container runtime to configure network for a pod as it’s started. With containerd as the container runtime,
<a href="https://github.com/containerd/cri" target="_blank" rel="noopener">Containerd CRI plugin</a> invokes the CNI plugin. Every network provider also has an agent that’s installed on each of the kubernetes node to configure pod networking. When the network provider agent is installed, it either ships with the CNI config or it creates one on the node which is then used by the CRI plugin to figure out which CNI plugin to call.</p><p>The location for the CNI config file is configurable and the default value is <code>/etc/cni/net.d/&lt;config-file&gt;</code>. CNI plugins need to be shipped on every node by the cluster administrators. The location for CNI plugins is configurable as well and the default value is <code>/opt/cni/bin</code>.</p><p>In case of containerd as the container runtime, path for CNI configuration and CNI plugin binaries can be specified under <code>[plugins."io.containerd.grpc.v1.cri".cni]</code> section of the
<a href="https://github.com/containerd/cri/blob/master/docs/config.md" target="_blank" rel="noopener">containerd config</a>.</p><p>Since we are referring to Flannel as the network provider here, I’ll talk a little about how Flannel is set up. Flanneld is the Flannel daemon and is typically installed on a kubernetes cluster as a daemonset with <code>install-cni</code> as an
<a href="https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml#L172" target="_blank" rel="noopener">init container</a>. The <code>install-cni</code> container creates the
<a href="https://gist.github.com/ronaknnathani/957a56210bd4fbd8e11120273c6b4ede" target="_blank" rel="noopener">CNI configuration file</a> - <code>/etc/cni/net.d/10-flannel.conflist</code> - on each node. Flanneld creates a vxlan device, fetches networking metadata from the apiserver and watches for updates on pods. As pods are created, it distributes routes for all pods across the entire cluster and these routes allow pods to connect to each other via their IP addresses. For details on how flannel works, I recommend the
<a href="#how-flannel-works">linked references below</a>.</p><p>The interactions between Containerd CRI Plugin and CNI plugins can be visualized as follows:
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-interactions.png" alt="kubelet-cri-cni-interactions"></p><p>As described above, kubelet calls the Containerd CRI plugin in order to create a pod and Containerd CRI plugin calls the CNI plugin to configure network for the pod. The network provider CNI plugin calls other base CNI plugins to configure the network. The interactions between CNI plugins are described below.</p><h3 id="interactions-between-cni-plugins">Interactions Between CNI Plugins</h3><p>There are various CNI plugins that help configure networking between containers on a host. For this post, we will refer to 3 plugins.</p><h4 id="flannel-cni-plugin">Flannel CNI Plugin</h4><p>When using Flannel as the network provider, the Containerd CRI plugin invokes the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel" target="_blank" rel="noopener">Flannel CNI plugin</a> using the CNI configuration file - <code>/etc/cni/net.d/10-flannel.conflist</code>.</p><pre><code>$ cat /etc/cni/net.d/10-flannel.conflist
{
  "name": "cni0",
  "plugins": [
    {
      "type": "flannel",
      "delegate": {
		 "ipMasq": false,
        "hairpinMode": true,
        "isDefaultGateway": true
      }
    }
  ]
}
</code></pre><p>The Fannel CNI plugin works in conjunction with Flanneld. When Flanneld starts up, it fetches the podCIDR and other network related details from the apiserver and stores them in a file - <code>/run/flannel/subnet.env</code>.</p><pre><code>FLANNEL_NETWORK=10.244.0.0/16 
FLANNEL_SUBNET=10.244.0.1/24
FLANNEL_MTU=1450 
FLANNEL_IPMASQ=false
</code></pre><p>The Flannel CNI plugin uses the information in <code>/run/flannel/subnet.env</code> to configure and invoke the bridge CNI plugin.</p><h4 id="bridge-cni-plugin">Bridge CNI Plugin</h4><p>Flannel CNI plugin calls the Bridge CNI plugin with the following configuration:</p><pre><code>{
  "name": "cni0",
  "type": "bridge",
  "mtu": 1450,
  "ipMasq": false,
  "isGateway": true,
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24"
  }
}
</code></pre><p>When
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/main/bridge" target="_blank" rel="noopener">Bridge CNI plugin</a> is invoked for the first time, it creates a linux bridge with the <code>"name": "cni0"</code> specified in the config file. For every pod, it then creates a veth pair - one end of the pair is in the container’s network namespace and the other end is connected to the linux bridge on the host network. With Bridge CNI plugin, all containers on a host are connected to the linux bridge on the host network.</p><p>After configuring the veth pair, Bridge plugin invokes the host-local IPAM CNI plugin. Which IPAM plugin to use can be configured in the CNI config CRI plugin uses to call the flannel CNI plugin.</p><h4 id="host-local-ipam-cni-plugins">Host-local IPAM CNI plugins</h4><p>The Bridge CNI plugin calls the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/ipam/host-local" target="_blank" rel="noopener">host-local IPAM CNI plugin</a> with the following configuration:</p><pre><code>{
  "name": "cni0",
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24",
    "dataDir": "/var/lib/cni/networks"
  }
}
</code></pre><p>Host-local IPAM (IP Address Management) plugin returns an IP address for the container from the <code>subnet</code> and stores the allocated IP locally on the host under the directory specified under <code>dataDir</code> - <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code>. <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code> file contains the container ID to which the IP is assigned.</p><p>When invoked, the host-local IPAM plugin returns the following payload</p><pre><code>{
  "ip4": {
    "ip": "10.244.4.2",
    "gateway": "10.244.4.3"
  },
  "dns": {}
}
</code></pre><h2 id="summary">Summary</h2><p>Kube-controller-manager assigns a podCIDR to each node. Pods on a node are …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</a></em></p>]]>
            </description>
            <link>https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380898</guid>
            <pubDate>Fri, 11 Dec 2020 00:44:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplify, batch, and cache: how Shopify optimized storefront response times]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380697">thread link</a>) | @vaillancourtmax
<br/>
December 10, 2020 | https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering | <a href="https://web.archive.org/web/*/https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><em><strong>On December 16, 2020 Shipit! presents: Performance Tips from the Storefront Renderer Team.&nbsp;Celso and Maxime will share how the&nbsp;team optimized this Ruby application for the particular use case of serving storefront traffic. <a href="#Register">Please Register!</a></strong></em></p>
<p><strong>By Celso Dantas and Maxime Vaillancourt</strong></p>
<p>In the previous post about <a href="https://shopify.engineering/how-shopify-reduced-storefront-response-times-rewrite" target="_blank" title="How Shopify Reduced Storefront Response Times with a Rewrite" rel="nofollow noopener noreferrer">our new storefront rendering engine</a>, we described how we went about the rewrite process and smoothly transitioned to serve storefront requests with the new implementation. As a follow-up and based on readers’ comments and questions, this post dives deeper into the technical details of how we built the new storefront rendering engine to be faster than the previous implementation.</p>
<p>To set the table, let’s see how the new storefront rendering engine performs:</p>
<ul>
<li>It generates a response in less than ~45ms for 75% of storefront requests;</li>
<li>It generates a response in less than ~230ms for 90% of storefront requests;</li>
<li>It generates a response in less than ~900ms for 99% of storefront requests.</li>
</ul>
<p>Thanks to the new storefront rendering engine, the average storefront response is nearly 5x faster than with the previous implementation. Of course, how fast the rendering engine is able to process a request and spit out a response depends on two key factors: the shop’s Liquid theme implementation, and the number of resources needed to process the request. To get a better idea of where the storefront rendering engine spends its time when processing a request, try using the <a href="https://shopify.engineering/in-depth-liquid-render-analysis-shopify-theme-inspector-chrome-extension" target="_blank" title="How to Do an In-depth Liquid Render Analysis with Theme Inspector" rel="nofollow noopener noreferrer">Shopify Theme Inspector</a>: this tool will help you identify potential bottlenecks so you can work on improving performance in those areas.</p>
<figure><img alt="A data scheme diagram showing that the Storefront Renderer and Redis instance are contained in a Kubernetes node. The Storefront Renderer sends Redis data. The Storefront Renderer sends data to two sharded data stores outside of the Kubernetes node: Sharded MySQL and Sharded Redis" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema_c5f379b7-619f-4ddb-8064-d093550c4731.jpg?v=1607636250" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema_c5f379b7-619f-4ddb-8064-d093550c4731.jpg?v=1607636250">
<figcaption>A simplified data schema of the application</figcaption>
</figure>
<p>Before we cover each topic, let’s briefly describe our application stack. As mentioned in the previous post, the new storefront rendering engine is a Ruby application. It talks to a sharded MySQL database and uses Redis to store and retrieve cached data.</p>
<p>Optimizing how we load all that data is extremely important. As one of our requirements was to improve rendering time for Storefront requests. Here are some of the approaches that we took to accomplish that.</p>

<p>To reduce the number of network round trips to the database, we use <a href="https://dev.mysql.com/doc/internals/en/multi-statement.html" target="_blank" title="MySQL - 14.8.2 Multi-Statement" rel="nofollow noopener noreferrer">MySQL’s multi-statement feature</a> to allow sending multiple queries at once. With a single request to the database, we can load data from multiple tables at once. Here’s a simplified example:</p>
<figure>

</figure>
<p>This request is especially useful to batch-load a lot of data very early in the response lifecycle based on the incoming request. After identifying the type of request, we trigger a single multi-statement query to fetch the data we need for that particular request in one go, which we’ll discuss later in this blog post. For example, for a request for a product page, we’ll load data for the product, its variants, its images, and other product-related resources in addition to information about the shop and the storefront theme, all in a single round-trip to MySQL.</p>

<p>As shown above, the new storefront rendering engine uses handcrafted, optimized SQL queries. This allows us to easily write fine-tuned SQL queries to select only the columns we need for each resource and leverage JOINs and sub-SELECT statements to optimize data loading based on the resources to load which are sometimes less straightforward to implement with a full-service object-relational mapping (ORM) layer.</p>
<p>However, the main benefit of this approach is the tiny memory footprint of using a raw MySQL client compared to using an object-relational mapping (ORM) layer that’s unnecessarily complex for our needs. Since there’s no unnecessary abstraction, forgoing the use of an ORM drastically simplifies the flow of data. Once the raw rows come back from MySQL, we effectively use the simplest ORM possible: we create plain old Ruby objects from the raw rows to model the business domain. We then use these Ruby objects for the remainder of the request. Below is an example of how it’s done.</p>

<p>Of course, not using an ORM layer comes with a cost: if implemented poorly, this approach can lead to more complexity leaking into the application code. Creating thin model abstractions using plain old Ruby objects prevents this from happening, and makes it easier to interact with resources while meeting our performance criteria. Of course, this approach isn’t particularly common and has the potential to cause panic in software engineers who aren’t heavily involved in performance work, instead worrying about schema migrations and compatibility issues. However, when speed is critical, we accept to take on that complexity.</p>

<p>An HTTP request for a Shopify storefront may end up requiring many different resources from data stores to render properly. For example, a request for a product page could lead to requiring information about other products, images, variants, inventory information, and a whole lot of other data not loaded on multi-statement select. The first time the storefront rendering engine loads this page, it needs to query the database, sometimes making multiple requests, to retrieve all the information it needs. This usually happens during the request at any given time.</p>
<figure><img alt="A flow diagram showing the Storefront Renderer's requests from  the data stores and how it uses a Query Book Keeper Middlewear to eager-load data" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-request-bookeeping-solution_adbd68eb-cc30-4be5-9bdf-104011224ad2.jpg?v=1607636269" src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-request-bookeeping-solution_adbd68eb-cc30-4be5-9bdf-104011224ad2.jpg?v=1607636269">
<figcaption>Flow of a request with the Book-keeping solution</figcaption>
</figure>
<p>As it retrieves this data for the first time, the storefront rendering engine keeps track of the queries it performed on the database for that particular product page and stores that list of queries in a key-value store for later use. When an HTTP request for the same product page comes in later (which it knows when the cache key matches), the rendering engine looks up the list of queries it performed throughout the previous request of the same type and performs those queries all at once, at the very beginning of the current request, because we’re pretty confident we’ll need them for this request (since they were used in the previous request).</p>
<p>This book-keeping mechanism lets us eager-load data we’re pretty confident we’ll need. Of course, when a page changes, this may lead to over-fetching and/or under-fetching, which is expected, and the shape of the data we fetch stabilizes quickly over time as more requests come in.</p>
<p>On the other side, some liquid models of Shopify’s storefronts are not accessed as frequently, and we don’t need to eager-load data related to them. If we did, we’d increase I/O wait time for something that we probably wouldn’t use very often. What the new rendering engine does instead is lazy-load this data by default. Unless the book-keeping mechanism described above eager-loads it, we’ll defer retrieving data to only load it if it’s needed for a particular request.</p>

<p>Much like a CPU’s caching architecture, the new rendering engine implements multiple layers of caching to accelerate responses.</p>
<p>A critical aside before we jump into this section: adding caching should never be the first step towards building performance-oriented software. Start by building a solution that’s extremely fast from the get go, even without caching. Once this is achieved, then consider adding caching to reduce load on the various components on the system while accelerating frequent use cases. Caching is like a sharp knife and can introduce hard to detect bugs.</p>
<h2>In-Memory Cache</h2>
<figure><img alt="A data scheme diagram showing that the Storefront Renderer and Redis instance are contained in a Kubernetes node. Within the Storefront Renderer is an In-memory cache. The Storefront Renderer sends Redis data. The Storefront Renderer sends data to two sharded data stores outside of the Kubernetes node: Sharded MySQL and Sharded Redis" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema-in-memory-cache.jpg?v=1607636398" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema-in-memory-cache.jpg?v=1607636398">
<figcaption>A simplified data schema of the application with an in-memory cache for the Storefront Renderer</figcaption>
</figure>
<p>At the frontline of our caching system is an in-memory cache that you can essentially think of as a global hash that’s shared across requests within each web worker. Much like the majority of our caching mechanisms, this caching layer uses the LRU caching algorithm. As a result, we use this caching layer for data that’s accessed very often. This layer is especially useful in high throughput scenarios such as flash sales.</p>
<h2>Node-local Shared Caching</h2>
<p>As a second layer on top of the in-memory cache, the new rendering engine leverages a node-local Redis store that’s shared across all server workers on the same node. Since the database is available on the same machine as the rendering engine process itself, this node-local data transfer prevents network overhead and improves response times. As a result, multiple Ruby processes benefit from sharing cached data with one another.</p>
<h2>Full-page Caching</h2>
<p>Once the rendering engine successfully renders a full storefront response for a particular type of request, we store the final output (most often an HTML or JSON string) into the local Redis for later retrieval for subsequent requests that match the same cache key. This full-page caching solution lets us prevent regenerating storefront responses if we can by using the output we previously computed.</p>
<h2>Database Query Results Caching</h2>
<p>In a scenario where the full-page output cache, the in-memory cache, and the node-local cache doesn’t have a valid entry for a given request, we need to reach all the way to the database. Once we get a result back from MySQL, we transparently cache the results in Redis for later retrieval based on the queries and their parameters. As long as the cache keys don’t change, running the same database queries over and over always hit Redis instead of reaching all the way to the database.</p>
<h2>Liquid Object Memoizer</h2>
<p>Thanks to the Liquid templating language, merchants and partners may build custom storefront themes. When loading a particular storefront page, it’s possible that the Liquid template to render includes multiple references to the same object. This is common on the product page for example, where the template will include many references to the product object: <br><code>{{ product.title }}</code>, <code>{{ product.description }}</code>, <code>{{ product.featured_media }}</code>, and others.</p>
<p>Of course, when each of these are executed, we don’t fetch the product over and over again from the database—we fetch it once, then keep it in memory for later use throughout the request lifecycle. This means that if the same product object is required multiple times at different locations during the render process, we’ll always use the same one and only instance of it throughout the entire request …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering">https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380697</guid>
            <pubDate>Fri, 11 Dec 2020 00:20:57 GMT</pubDate>
        </item>
    </channel>
</rss>
