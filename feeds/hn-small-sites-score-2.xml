<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 12 Dec 2020 20:28:36 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 12 Dec 2020 20:28:36 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to Start a Podcast in 2021 – A Step by Step Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384162">thread link</a>) | @tomhuntio
<br/>
December 11, 2020 | https://www.bcast.fm/blog/how-to-start-a-podcast | <a href="https://web.archive.org/web/*/https://www.bcast.fm/blog/how-to-start-a-podcast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><strong><em>This is the first post in the three-part series. Part two focuses on </em></strong><a href="https://www.bcast.fm/blog/how-to-launch-a-podcast" target="_blank"><strong><em>how to launch a podcast</em></strong></a><strong><em>, and part three focuses on how to grow a podcast.</em></strong></p><p>The podcast industry is snowballing.&nbsp;</p><p>But don’t worry, the number of listeners is growing faster than the number of podcasts. </p><p>All the BIG tech businesses are investing heavily in the podcast space, bringing bigger and better audio tools, which in turn bring more people to podcasts.</p><ul role="list"><li>Apple - Apple Podcasts and AirPods</li><li>Google - Google Podcasts and Google Podcast Manager</li><li>Spotify - Spotify for Podcasters</li><li>Amazon - Amazon Music and Alexa</li></ul><p>We’re talking billions of dollars being spent on enabling more and more people to flood into podcasts… you just have to be there to mop them up :)</p><figure id="w-node-f4cfd1480d0a-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf93b331b3c358913488_4X1o_362OKLNxFY5BysBQvm9-hmMKWsrZaYwN-X3atvqRXHV361ktXo_hXBJN6mXC1rcbQHcBBZFbUFOMmLssnfNVUcMlMpj6fuFnM6sFzOiVmQ2lzBMzssQmMlu-AgzVQtfxVz2.gif" alt=""></p></figure><p>Research has shown that over <a href="https://www.statista.com/statistics/786826/podcast-listeners-in-the-us/" target="_blank">103 million Americans have at least one podcast</a> they listen to every month in the US – this number will keep growing. Despite this... there are still over 600 blogs for every podcast in the world ;)</p><figure id="w-node-a4cc97581060-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf92a6071203f4bd93fc_s-So6SEwWD4eheC2_twd61hX0idTzHglF81LuQoxdwe3gACuUrSqGmx5PPGKQkwEaZ5d_iWW9BsNFTCyJ8JUodSpf5Qoyk6lnOHAlFA3ODwgO1SO4jvmFBofVKLD4lsVuIu4aigH.png" alt=""></p><figcaption><em>Source: Statista.com</em></figcaption></figure><p><strong>A podcast will grow your brand.</strong></p><p>Whether that be you as a person or you for your business. There are many reasons why you should start a podcast.</p><p>And fortunately, if you want to know the right steps to make to start a successful podcast, you are in the right place.</p><p>In this easy-to-understand step-by-step guide, we will break down everything you need to start your podcast for free from developing a plan to securing the right equipment and software to use.&nbsp;</p><p>Bookmark this page and keep referring back to as you move through the process of starting your first (or next!) podcast, and when you launch make sure you ping us a link by email to <a href="mailto:support@bcast.fm">support@bcast.fm</a> - we will subscribe!</p><figure id="w-node-e9418c7b6c75-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf93154cd636df1dd20b_QUaPSMMrdnQRcLu0jfIP-o-iLKto34jtuaLiEPQDSJSu_4NBmW8vDPuKaMumd-4VF51oguynh0RW81UeQZxtwWyfiC0zuL0wQBmwBpBM-GP81DiWV9UUle1Jr44v-JSw_CB6HxYs.gif" alt=""></p></figure><h2><strong>STEP 1: DEVELOP A PLAN</strong></h2><p>Of course... you need a solid plan before starting a podcast. </p><p>Your podcast is a result of your thoughts and actions, and this is why you need a plan. You need to be deliberate about what you create. Your podcast gets its uniqueness from you, as you are the creator and director. </p><p>Your podcast is a result of your<strong> imagination</strong> and your <strong>ability to execute</strong>.</p><p>You must have a reason for starting your podcast, and this where the “WHY” and “WHAT” questions come in. The answer to these questions will help you create a podcast that is both unique to you but will also be able to add massive value to anyone that subscribes.&nbsp;</p><h3><strong>Why Do You Want To Start A Podcast?</strong></h3><p>There are various reasons for starting a podcast, and it varies per person. This question can have a lot of answers, but your conviction is the most important factor.</p><p><em>How much do you want to start a podcast?</em></p><p>Because if your answer is not a firm yes, then you may have challenges putting in the consistent effort to make it grow.</p><p><em>Why do you want to start a podcast?</em></p><p>There could be various reasons...<br></p><ul role="list"><li>To promote your business</li><li>To talk about your passion</li><li>To preach to the world</li><li>To share your message</li><li>To establish yourself as an authority</li><li>To have fun</li></ul><p>Whatever your reason is, you must be convinced.</p><p>This conviction will help you create a lasting relationship with your audience as you continue to execute over time when others fail to be consistent.</p><p>If&nbsp;you look at all the most popular podcasts... you will see that they have been running for years and even decades. This is what you must be prepared to do to generate a sizeable audience.</p><h3><strong>What Is The Topic Of Your Podcast?</strong></h3><p>It's now time to choose a theme/topic for your podcast. </p><p>This is the BIG one. It's make or break.</p><p>You MUST consider:</p><ul role="list"><li>Your passion on the topic</li><li>Your expertise and experience of the topic</li><li>The ability for your to monetise the topic</li></ul><p>Here at bCast, we are all about podcast profitability. We're not hobbyists. We know you need to get paid if you're going to do this for the long term and build a podcast worth listening to.</p><p>Now monetisation can come from advertising... so you don't necessarily need to have products or services in the niche or topic of your podcast... but you will need an intense passion.</p><p>Once you have spent a long time sitting in a dark room thinking about this... you then need to understand the #1 thing that will define the success or failure of your podcast:</p><p><strong><em>How are you different or better for a specific group of people?</em></strong></p><p>As if you are not... and you don't have a load of money to spend on Facebook Ads, it's going to be hard to make your podcast grow. Trust me... we know.</p><p>Maybe you only ask specific types of questions; perhaps you focus on a particular niche, perhaps you only interview three people at a time… it can be anything as long as it makes you different or better for a specific group of people.</p><p>If you are VERY particular about this… you will more than double your chances of succeeding.</p><h3><strong>Who Are Your Listeners?</strong></h3><p>Now that you have answered the WHY and WHAT, it is time to answer the WHO question.</p><p>Every podcast needs listeners, and in order for your podcast to grow... you must know exactly who your listeners are and where to find them.&nbsp;</p><figure id="w-node-08046cb77a20-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf937aa690314e79dafd__co8aVE5evZ3_Tzk8ZugkGqAFkT8oBN3HT-ksoEWq5FNU4yYXhOaV3P8uJZ27GaH8Ha-aIdbGh3PPQqOLLXsAZ-K6sSfKjXfmjcmVJW5xRfolNsufXY7OnFRKVLn4GMako-ZIAM_.gif" alt=""></p></figure><p>You need to find out:</p><ul role="list"><li>Where they are&nbsp;</li><li>How old they are</li><li>What catches their attention</li><li>What they eat for breakfast</li><li>Who they hate</li><li>Who they love</li></ul><p>This is why it's normally a great strategy for you to actually BE&nbsp;YOUR&nbsp;PERFECT&nbsp;LISTENER. This is a shortcut through this stage of the process as if this is the case, you should know the answers to all of those questions ;)</p><p>Once this is defined you then need to list out a number of places where these people hang out online:</p><ul role="list"><li>Blogs</li><li>Other podcasts</li><li>Facebook Groups</li><li>subReddits</li><li>Linkedin Groups</li><li>YouTube Channels</li></ul><p>We will need this list later in the process when we move through the launch and grow stages.</p><h3><strong>How Do You Name Your Podcast?</strong></h3><p>There are a number of strategies to follow here...</p><ul role="list"><li><strong><em>Make it concise</em></strong></li></ul><p>Succinct podcast names land better as they convey the message most strongly.</p><ul role="list"><li><strong><em>Do not neglect the relevant keyword</em></strong></li></ul><p><strong><em>‍</em></strong>If your podcast is about soccer, let the name convey that; this is important in searches, as your podcast name will pop up in searches related to your industry.</p><ul role="list"><li>‍<strong><em>Make it easy on the tongue</em></strong></li></ul><p><strong><em>‍</em></strong>You don’t want a twisted name, as you will mention it time and again on your podcast – it should be smooth to say.</p><ul role="list"><li><strong><em>Keep it simple</em></strong></li></ul><p><strong><em>‍</em></strong>You don’t want the stress of explaining your podcast name every time. Embrace simplicity</p><ul role="list"><li><strong><em>Look out for rhyme and alliteration opportunities</em></strong></li></ul><p>The best names of anything normally incorporate rhyme and/or alliteration... be on the look out for these opportunities and incorporate them if they arise.</p><p>To make this clearer... here are some great examples along with an explanation for why:</p><p><a href="https://podcasts.bcast.fm/sales-ops-demystified" target="_blank"><strong>Sales Ops Demystified</strong></a>: We include the core key word AND the value proposition of the show. It's clear and concise and succinctly tells the potential listener why they should listen.</p><p><a href="https://podcasts.bcast.fm/mobile-growth-pancakes" target="_blank"><strong>Mobile Growth and Pancakes</strong></a>: Keyword conscious and not boring. This podcast name is exciting, and a listener will want to hear what they have to say. It lays a foundation for what to expect, which is discussing mobile growth in a fun and slightly... different way.&nbsp;</p><p><a href="https://podcasts.bcast.fm/shine-a-podcast-by-star" target="_blank"><strong>Shine: a Podcast by Star</strong></a>: Simple and short. The host already directs the listener's thought from the first word. It also promotes the host, as a name is attached to the podcast and conveys an aspect of the hosts brand: shining through technology.</p><p><a href="https://podcasts.bcast.fm/be-more-a-podcast-by-peakon" target="_blank"><strong>Be More - a podcast by Peakon</strong></a>: If you want to be more, you have to listen. Everyone wants to be more, and this podcast name exploits that emotional aspect with this name: it's aspirational. The listener wants to know how they can "be more".&nbsp;</p><h3><strong>How Do You Describe Your Podcast?</strong></h3><p>Research has shown that your <a href="https://www.thepodcasthost.com/promotion/podcast-discoverability/" target="_blank">podcast description</a> is the number one factor that new listeners consider when deciding whether to subscribe. When describing your podcast, you must be able to offer value to the listener quickly. You must tell in precise terms, what they stand to gain by listening to your show.</p><p>You also have to consider search engines as you construct e your podcast description. Your show description must be able to rank to stand a chance of getting any free exposure from Google. Include relevant keywords in the industry you cover.&nbsp;</p><p>When writing your description, you should consider attention span. You need to grab listeners' attention by putting the juicy points first. You also need to make fair use of the description by avoiding repetition.&nbsp;</p><p>Be concise, offer value, and grab attention with the first lines.&nbsp;</p><h3><strong>How Do You Pick The Right Category For Your Podcast?</strong></h3><p>The primary way podcast listeners discover podcasts is through searching within podcast listening apps. They navigate through different categories and topics and look for the best shows in that category – <strong>this is why</strong> you need to place your podcast in the right category. It will increase the chance that your perfect listener will discover your podcast.</p><p>You get three chances:</p><ul role="list"><li>1 Primary category</li><li>2 Sub categories</li></ul><p>I won't share much more on this as I assume you know the category in which your podcast should reside!</p><h3><strong>What Podcast Format Should You Adopt?</strong></h3><p>There are different formats for podcasts. The good thing is, you have creative control over the structure of your podcast. In most cases, the format you choose depends on the message you are trying to convey to your audience.&nbsp;</p><p>There are different types of formats:</p><ul role="list"><li><strong>Interview podcast:</strong> this format involves a host that brings guests on the show, and interviews them. These guests are usually experts in their field, and the host asks them relevant questions in their industry.&nbsp;</li><li><strong>Monologue podcast:</strong> this format involves the host alone. The host will run solo and speak about their experiences and area of expertise. It is mostly educational and a teaching type of format.</li><li><strong>Co-hosted podcast:</strong> this format will involve two hosts that will have conversations. They share their experiences and have a back and forth when needed.&nbsp;</li><li><strong>Story-based podcast:</strong> this format involves a host that tells a story like a drama to the audience. The story could be fiction or non-fiction. The host finds ways to spice it up through the use of different effects.</li></ul><p>That said, there is room for more than one format on your podcast. You could adopt different forms for different episodes, depending on the message you are trying to pass.</p><p>So why not start out with one... test, gather …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bcast.fm/blog/how-to-start-a-podcast">https://www.bcast.fm/blog/how-to-start-a-podcast</a></em></p>]]>
            </description>
            <link>https://www.bcast.fm/blog/how-to-start-a-podcast</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384162</guid>
            <pubDate>Fri, 11 Dec 2020 10:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We can have democracy or we can have Facebook]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25383976">thread link</a>) | @imartin2k
<br/>
December 11, 2020 | https://the.ink/p/we-can-have-democracy-or-we-can-have | <a href="https://web.archive.org/web/*/https://the.ink/p/we-can-have-democracy-or-we-can-have">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg&quot;,&quot;height&quot;:798,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:277616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Being on the phone with <a href="https://twitter.com/matthewstoller">Matt Stoller</a> when a giant antitrust case is announced against Facebook is like texting with the pope when the Second Coming, you know, comes.</p><p>It’s a little on the nose. A little exciting.</p><p>I’d been wanting to talk to Matt for a while, in part because the pope actually turned down my recent interview request (someone please tell him how book tours work).</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png&quot;,&quot;height&quot;:264,&quot;width&quot;:1308,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:51146,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>And in part because I consider him (Matt) one of the more interesting, iconoclastic, morally committed, unpredictable, critics-may-care thinkers today. In the course of a typical Twitter day, which is a week in human time, I agree with Matt, disagree with him, wish I had thought of something he said, regret something he said on his behalf, retweet something he wrote, and make a mental note to talk with him soon. So I did.</p><p>And there we were, talking about everything — his political education, why he goes back and forth between thinking of himself as a progressive and not, his highly influential recent book, “<a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501182891">Goliath: The 100-Year War Between Monopoly Power and Democracy</a>” — when my phone began to crackle with <a href="https://www.nytimes.com/2020/12/09/technology/facebook-antitrust-monopoly.html">news of an historic antitrust case against Facebook</a>.</p><p>Naturally, I began to ask Matt about it. What he said was so compelling that I’ve decided to break our interview into two issues of the newsletter. Today: Matt Stoller on Facebook, this important case, and how monopoly is mistaken as a policy issue when in fact it represents an existential question of whether we are actually a democracy.</p><p>Then, before long, <a href="https://www.imdb.com/title/tt0107144/">part deux</a>, the political education of Matt Stoller — thinker, writer, civil servant, trustbuster, Twitter beefer, and, presently, aspiring political philosopher.</p><p>Without shame, I’ll add, in the spirit of Matt’s ideas, that if you want to do your part to support small, independent media, and haven’t yet, consider subscribing to The Ink.</p><h3>“The way we do business is the way we do justice”: a conversation with Matt Stoller, part one</h3><p>ANAND: Right as we're talking, I get a news alert: “<a href="https://www.nytimes.com/2020/12/09/technology/facebook-antitrust-monopoly.html">Facebook illegally crushed competition by buying up its rivals, according to lawsuits filed by 48 states and federal regulators</a>.” So this is the big case that we've been waiting for. Can you explain to a person who has never focused on this issue before in their life, and who just uses Facebook to try to get with their high-school ex, why is this a big deal? What does this mean?</p><p>MATT: So Facebook is a financial conglomerate. People think of Facebook as that website you use or the app that you use, but really Facebook, as a political institution, is a financial conglomerate and owns dozens of different companies, including Instagram and WhatsApp and Facebook, the social network. And it's a giant advertising company. So they have roughly three billion users. And they try to get their users to do things that their advertisers want them to do, because that's how you sell advertising.</p><p>The business model is to divert revenue that used to go to newspapers and publishers to themselves. And so by manipulating people in this specific way that they do, which is to keep them using their system and keep surveilling them so that they can target them with ads, they are, in the process, crushing newspapers and publishers, who no longer have any financing, particularly local newspapers and niche publications like Black-owned newspapers.</p><p>So increasingly those kinds of publications don't exist. You don't have reporters covering state houses and city halls and whatnot. Instead, people are now consuming things that Facebook likes them to consume because it keeps them using, and it keeps them available to sell ads to them, which are anti-social publications or posts, like anti-vax stuff or QAnon or whatever it is.</p><p>So that's the basic problem. It's a $70-, $80-, $100-billion-a-year revenue company that's destroying newspapers and publishers all over the world and getting people to pass conspiracy theories to each other so that Facebook can make money on advertising.</p><p>ANAND: You're an anti-monopoly guy. If there were three or five companies in healthy competition with each other, all doing exactly what you just described, wouldn't it still be problematic? Is the issue here that there's only one of them of that heft, or would a competitive market with five such players still be incredibly troubling?</p><p>MATT: There's a lot more that you have to do than just break them up. But the answer is, it would improve things dramatically if they were broken up, and you don't have to imagine it.</p><p>There used to be a bunch of social networks. Facebook's main competitor was Myspace, but there were a bunch of others. There was BlackPlanet; there was Friendster. And the way that Facebook actually defeated Myspace was by promising a safer, more private experience. They defeated Myspace by saying, We will treat your data carefully; in fact, when we change the terms of service, we will let our users vote on the terms of service.</p><p>This was back in 2007, 2008, 2009. And once they killed their competition, and then they bought up nascent competitors like Instagram and WhatsApp, then they didn't have to compete by offering a higher-quality service, a.k.a one that was less intrusive in terms of surveillance. They could just surveil anybody they wanted, and you didn't really have a choice.</p><p>ANAND: Where do you think this case is going?</p><p>MATT: They’re going to aim to break up the company. The House Antitrust Subcommittee did this long investigation of big tech, which includes Facebook. And one of the things they found is that Mark Zuckerberg was writing emails saying they were buying these companies to block competition. And so that's evidence that the mergers were illegal, because you're not supposed to buy companies to block competition. That's a violation of the Clayton Act. My guess is that they're going to have a pretty good complaint.&nbsp;</p><p>ANAND: Based on the history of such cases, would your assumption be that Facebook is broken up within a period of years?</p><p>MATT: Yes.</p><p>However, we haven't enforced the law for 20 years, so it’s not entirely clear. The law at this point is crazy and incoherent because we haven't done enforcement, and to the extent that we have, judges have just made wildly inconsistent rulings.</p><p>ANAND: This kind of action that's being announced today is the epitome of a systemic, public response to a problem. And when I, like you, advocate for those types of things, I often hear this response that I'm sure you do, too, which is, “OK, that's fine, but what about individual actions?” A lot of people are like, “Yes, let’s delete Facebook.” Or: “Why aren't you supporting the Facebook boycott?”, and there are different views on it.</p><p>There are some people who make the argument that those kind of small personal things are sideshows, distractions, maybe even unhelpful, because they reduce the perceived need for bigger systemic change. I fall more into that camp. There are others who say it's a gateway drug, it's a waystation, like: “Delete Facebook and then work yourself up to a political response." How do you weigh in on that?</p><p>MATT: I think it's a bad vision of politics. It's not doing politics to say, “Me, as a consumer, I can change power arrangements based on what I consume or don’t.” That's a real 1970s consumer-rights Democrat vision of the world, and that's one in which you as a citizen are irrelevant.</p><p>A boycott is only political if the goal is a policy change. If you go in and you say, "Well, I don't like Facebook, I want to change Facebook, so I'm going to delete Facebook," that's not going to do anything. If it's part of some larger political action saying, "Well, I'm going to delete Facebook, and then I'm going to push policymakers to break it up," I mean, I guess that makes sense.</p><p>But the general view of these boycotts is that just not using Facebook is the political action. But that's actually not a political action.</p><p>ANAND: An issue like monopoly is different from, say, healthcare, where you don't have to explain to most people the problem with our healthcare system. How do you think about making the issue of monopoly real to people and vivid and relevant to their lives?</p><p>MATT: I'm going to challenge the premise. I don't think monopoly is an <em>issue</em>. I think monopoly is a worldview.</p><p>My book is called “<a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501182891">Goliath: The 100-Year War Between Monopoly Power and Democracy</a>.” Anti-monopolism is a lens through which you understand power, and particularly commercial power. That’s the lens that I see the world through. And I don't just focus on Facebook or Google. I’m focused on anti-monopolism in general. How you use business institutions to coerce and bully — or liberate — other people in your society.</p><p>There's a monopolist who controls the cheerleading industry, which is very weird. I just learned there is a private-equity company that is trying to monopolize the software that churches run. There is a monopoly of Ultimate Fighting Championship-style contests. And then in healthcare there are endless numbers of monopolists. Ultimately, what a monopolist is is a person or institution that is controlling and governing a market. It's a private government versus a public government.</p><p>ANAND: You’re saying it’s incompatible with democracy.</p><p>MATT: Right. It’s a different system. When Mark Zuckerberg says he’s going to arrange electoral discourse in this particular way, or going to start a <a href="https://www.businessinsider.com/meet-the-first-20-members-of-facebook-supreme-court-2020-5">Supreme Court</a>, or going to ban this or allow that, he is operating as the global privacy commissioner. <a href="https://www.vox.com/the-big-idea/2018/4/9/17214752/zuckerberg-facebook-power-regulation-data-privacy-control-political-theory-data-breach-king">He even said</a>, "In a lot of ways Facebook is more like a government than a traditional company." That's a direct quote.</p><p>As a society, the way we do business is the way we do justice.</p><p>ANAND: Understanding how these platforms work, do you think that if Mark Zuckerberg wanted to tip an election, he could? Would that even be illegal under our current system?</p><p>MATT: I don't know if it's possible, but it's certainly legal if he decided to.</p><p>I listened to this podcast with Zuckerberg where he said — this was right before he became unpopular, so he was still being relatively …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://the.ink/p/we-can-have-democracy-or-we-can-have">https://the.ink/p/we-can-have-democracy-or-we-can-have</a></em></p>]]>
            </description>
            <link>https://the.ink/p/we-can-have-democracy-or-we-can-have</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383976</guid>
            <pubDate>Fri, 11 Dec 2020 09:48:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes Operators 101]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383807">thread link</a>) | @evenh
<br/>
December 11, 2020 | https://thecloud.christmas/2020/11 | <a href="https://web.archive.org/web/*/https://thecloud.christmas/2020/11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://i.imgur.com/PRCyBqa.jpg" alt=""><div><section><p>Kubernetes has become the <em>de facto</em> container orchestrator since it's initial release in 2014. It is a great tool for managing diverse workloads in clusters of machines, possibly spanning multiple availability zones. As the usage grows, new requirements for how to deploy and operate specialized software emerges. The Operator pattern is one of the more prominent responses to these new requirements.</p>
</section><article><section><p>The Operator pattern is best described in the <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">official Kubernetes documentation</a>:</p>
<blockquote>
<p>The Operator pattern aims to capture the key aim of a human operator who is managing a service or set of services. Human operators who look after specific applications and services have deep knowledge of how the system ought to behave, how to deploy it, and how to react if there are problems.</p>
<p>People who run workloads on Kubernetes often like to use automation to take care of repeatable tasks. The Operator pattern captures how you can write code to automate a task beyond what Kubernetes itself provides.</p>
</blockquote>
<p><strong>TL;DR</strong> Operators automate operation of applications and services with human know-how.</p>
<h2>How does an Operator work?</h2>
<p>An Operator consists at a minimum of one Custom Resource Definition (<code>CRD</code>) and a Controller. The <code>CRD</code> describes the various configuration options for this kind of resource. Given a custom resource for a <code>PostgresDatabase</code>, one might find options for specifying custom <code>StorageClass</code>es, resource allocation, backup schedule/destinations, authentication methods, etc.</p>
<p>Given an instance (<code>CR</code>) of <code>PostgresDatabase</code>, it's now the job of the controller to ensure that the desired state is reconciled with the cluster. In this example one can assume that the controller will create a <code>StatefulSet</code> for running the database itself, along with needed configuration in a <code>ConfigMap</code>, certificates for mutual TLS in a <code>Secret</code>. Backup can be done by either mounting and writing to a volume defined in the <code>CR</code> or injecting a sidecar for sending backups to another location.</p>
<p>Patching, reboots and failovers can be specified in the <code>CR</code> and taken care of by the controller, using methods recommended by experienced DBA's. The fact that complex operational knowledge can be encoded into the controller is a key enabler for many organizations that would like to run complex software, but not necessarily invest countless hours into learning the nitty-gritty details on how to operate it.</p>
<p>Like any other software there will be bugs and abstractions will leak. There's no silver bullet.</p>
<h2>How do I create my own Operator?</h2>
<p>As with the rest of the Kubernetes community, multiple solutions exists.</p>
<ul>
<li>For a declarative experience, check out <a href="https://kudo.dev/">KUDU</a></li>
<li>If you'd like a more official way to do it, see <a href="https://github.com/kubernetes-sigs/kubebuilder">kubebuilder</a></li>
<li>The most popular option seems to be <a href="https://github.com/operator-framework/operator-sdk">Operator SDK</a></li>
</ul>
<p>As with most cloud native software, Go seems to be the lingua franca. There is nothing stopping you from writing an Operator in Java, C#, Python or any other language that can communicate with the Kubernetes APIs.</p>
<h2>Examples of known Operators</h2>
<p>The community has produced a lot of Operators for about everything one can imagine. These are some popular examples:</p>
<ul>
<li><a href="https://github.com/argoproj/argo-cd">Argo CD</a> – a  declarative, GitOps continuous delivery tool for Kubernetes.</li>
<li><a href="https://github.com/jetstack/cert-manager">cert-manager</a> – automatically provisions TLS certificates via the ACME protocol. Can be used with certificate issuers such as <a href="https://letsencrypt.org/">Let's Encrypt</a>, <a href="https://www.buypass.no/ssl/resources/acme-free-ssl">Buypass</a> and <a href="https://zerossl.com/documentation/acme/">ZeroSSL</a>.</li>
<li><a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus Operator</a> – often used in combination with <a href="https://github.com/prometheus-operator/kube-prometheus">kube-prometheus</a> for a batteries included monitoring suite</li>
<li><a href="https://kubedb.com/">KubeDB</a> – a real-life implementation of the <code>PostgresDatabase</code> example, plus support for MySQL/MariaDB/MongoDB/Redis/Memcached and more</li>
</ul>
<p><small>Header image: RIA Novosti archive, image #305015 / Alexey Danichev / CC-BY-SA 3.0</small></p></section></article></div></article><section><ul><li></li><li></li></ul></section></main></div></div>]]>
            </description>
            <link>https://thecloud.christmas/2020/11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383807</guid>
            <pubDate>Fri, 11 Dec 2020 09:13:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware – A Devastating Form of Digital Extortion]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383148">thread link</a>) | @roberla
<br/>
December 10, 2020 | https://security.christmas/2020/11 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We live in a digital era where the most precious commodity no longer is oil or gold, but data. But what if this data, including personal files, customer lists and company data, flight traffic information, or even sensitive hospital records were stolen? What would you do, or pay, to get it back?</p>
</section><article><section><p>Ransomware has been on the rise the past years, where criminals effectively take all the data on your computer hostage and demand a ransom to give it back to you. Refusing to pay may result in your data being lost permanently. </p>
<p>Everyone is a potential target for ransomware, including single individuals, small to large companies, and even public institutions. A disconcerting trend is the targeting of hospitals and the public sector. Only last year the Hollywood Presbyterian Medical Center in Los Angeles was <a href="https://sanfrancisco.cbslocal.com/2016/02/18/california-hospital-ransomware-attack-hackers/">attacked by ransomware</a>, blocking the company’s access to their own network and crucial patient data for 10 whole days. The hospital ended up paying the ransom of $17 000 in bitcoin to decrypt the data. </p>
<p>The demands have also increased drastically the last few years, where the <a href="https://www.coveware.com/blog/q2-2020-ransomware-marketplace-report">average ransom payment</a> having increased to an exorbitant $178 000 in Q2 of 2020. Some bigger companies also receive very high demands. For instance, Garmin was attacked in 2020 with an initial ransom demand of $10 million, which some <a href="https://www.bleepingcomputer.com/news/security/confirmed-garmin-received-decryptor-for-wastedlocker-ransomware/">sources</a> claim they chose to pay. And this does not include the costs of other factors such as downtime, loss of revenue, mistrust from consumers, and resources used to get everything up and running again. </p>
<p>Clearly, ransomware is a growing problem with an increase in both attacks and in the ransom demands themselves, as well as the targeting of sectors with the possible consequence of directly endangering lives. </p>
<p>But how to the criminals make their attacks so successful, either forcing a victim to pay or having to accept the loss of their data? The main principle of ransomware is that attackers will encrypt all the files rendering them unreadable, and only by buying the key to decrypt the files will they be accessible again. The first step to achieve this, is to obtain access to a computer or network in order to install the ransomware. </p>
<h2>How does ransomware get installed on my computer?</h2>
<p>Ransomware is a type of malware, which is a malicious piece of software that installs itself without permission on someone’s computer or even an organization’s whole system. The most common ways the attackers get access to your computer are:</p>
<ol>
<li>Phishing – a cyber-attack imitating a trusted source, where an employee or private person is tricked into installing the malware without knowing it. This can be through clicking a link or downloading an attachment in a seemingly legit email.</li>
<li>Drive by downloads – visiting compromised websites that then installs the malware on your computer.</li>
<li>Security vulnerabilities – if systems are not up to date and are known to have weaknesses, then attackers will exploit these to install their malware. </li>
</ol>
<h2>How does ransomware encrypt my files?</h2>
<p>Once the ransomware is installed, it encrypts all the data on your computer. Unfortunately, the encryption methods used now are so complex that it is unfeasible to decrypt the files without the decryption key, which is known only to the attackers. To achieve a secure encryption of your data, the attackers use a combination of symmetric and asymmetric encryption. </p>
<h4>Symmetric encryption</h4>
<p>One of the oldest ciphers in history is the shift cipher, which shifts each letter a set number of times back or forth in the alphabet. Knowing this set number, also referred to as the “key”, is therefore enough to both encrypt and decrypt a text. Julius Caesar was believed to use a shift cipher, substituting each letter with the one 3 spaces to the right. This is one of the simplest examples of a symmetric encryption. </p>
<p>Today, there are more advanced versions, which can be broadly categorized as block ciphers (encrypts in byte-sized blocks) or stream ciphers (encrypts single digits). These methods are fast and only require the same key to encrypt and decrypt. </p>
<h4>Asymmetric encryption</h4>
<p>Asymmetric encryption is slower and uses two keys instead of one: one public and one private. The private key is only in the possession of the key pair owner, whereas the public one is widely distributed. When using the public key to encrypt a message it can only be decrypted using the private key, and vice versa.  </p>
<h4>Ransomware take advantage of both encryption methods.</h4>
<p>One of the most common ways a ransomware takes over your computer, is through the following steps:</p>
<ol>
<li>When the ransomware is installed on a computer, it comes with an asymmetric public key, which it used to establish contact with the attackers’ server. All communication is encrypted using this asymmetric encryption, making it impossible to intercept and interpret the communication between the affected computer and the server. </li>
<li>The ransomware will then request a new asymmetric public key from the server, which is specific for the victim’s computer (making it impossible to share a key with other victims). </li>
<li>Once received, the ransomware also creates a symmetric key, which quickly encrypts all the files. </li>
<li>The symmetric key is then encrypted using the asymmetric key specific to the victim. This means that only the private key on the attackers’ server can be used to unlock the symmetric key, which again will decrypt all the files. </li>
</ol>
<p>This makes the whole process fast and yet very secure, and almost impossible to decrypt without paying the ransom. </p>
<h2>Victims of ransomware</h2>
<p>Originally, ransomware was used to target individuals, with a low enough ransom so most people would choose to pay. While individuals are still affected, organizations are targeted on a more regular basis, and can offer a more lucrative pay-off if successful. In fact, <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">one study</a> showed that over half of the companies had been subjected to a ransomware attack in the past year, and that 73% of these attacks were successful. A recent trend also shows an increase in attacks targeting <a href="https://edition.cnn.com/2020/10/28/politics/hospitals-targeted-ransomware-attacks/index.html">government institutions and hospitals</a>.  </p>
<h2>Costs and solutions</h2>
<p>An estimate shows that total ransom demands will reach a staggering <a href="https://cybersecurityventures.com/global-ransomware-damage-costs-predicted-to-reach-20-billion-usd-by-2021/">20 billion USD by 2021</a>. </p>
<p>While paying the ransom is strongly discouraged as it helps create a marked for extorting money in this manner, some still choose to pay the ransom to retrieve their data. One recent <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">study</a> of 5000 IT people showed that about 26% chose to pay and that of these, 95% did actually get the decryption key needed to unlock their files again. Over half chose not to pay and instead used backups of their data, while the rest used other methods.</p>
<p>However, even though paying up may seem like the best way to get things restored again, it may actually double the costs of being affected. All organizations attacked by ransomware had a high cost due to downtime, network costs, lost opportunity etc. even without paying the ransom. In fact, the authors of this <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">study</a> argue that the organizations that chose to pay  had the same costs as those who did not with getting their systems back online, except they also had the cost of removing the encryption in addition to their other expenses.</p>
<p>As most attacks are successful and as it is nearly impossible to decrypt your files after an attack, it’s best to try and prevent an attack in the first place. Good strategies include having regular and off-site backup of data, installing anti-ransomware on your system, training employees in recognizing phishing, and closing any technological vulnerabilites that could be exploited. Stay tuned for more on this and other good preventative measure in our next article.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383148</guid>
            <pubDate>Fri, 11 Dec 2020 06:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some doctors, therapists get Health Canada permission to use magic mushrooms]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25382497">thread link</a>) | @billyharris
<br/>
December 10, 2020 | https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Four months after it allowed a handful of palliative care patients to use psilocybin as a way to relieve end-of-life suffering, Health Canada has cleared the way for more than a dozen health professionals to use the psychedelic drug themselves to help develop therapies for future use.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4039727.1492805330!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/63883228.jpg"></p></div><figcaption>Psilocybin is the ingredient in magic mushrooms that causes hallucinations, but in medically supervised settings, can also potentially help people overcome depression.<!-- --> <!-- -->(Shutterstock / gsplanet)</figcaption></figure><p><span><p>Four months after it allowed a handful of palliative care patients to use psilocybin as a way to relieve end-of-life suffering, Health Canada has cleared the way for more than a dozen health professionals to use the psychedelic drug themselves to help develop therapies for future use.&nbsp;</p>  <p>Health Canada says it granted 16 exemptions to a selection of nurses, doctors, therapists and social workers, allowing them to possess and use&nbsp;psilocybin&nbsp;for personal training without fear of prosecution under the country's drug laws.&nbsp;</p>  <p>"This is not a small step. This is a seismic step," said Dr. Sean O'Sullivan, a Tillsonburg, Ont., doctor and medical director of TheraPsil, a non-profit group that advocates for the therapeutic use of psilocybin.&nbsp;</p>  <p>"This is permission from the Ministry of Health and the Minister of Health to allow therapists to forward their own training in psychedelic medicine."&nbsp;</p>  <p><span><span><div><div role="button" tabindex="0" title="Mushrooms: The Magic Medicine"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/337/291/Sickboy-640x360.jpg" alt=""></p><p><span>Sickboy</span><span>1:02:33</span><span>Mushrooms: The Magic Medicine</span></p></div></div></div><span>Thomas Hartle never used drugs before his Stage IV cancer diagnosis. That’s changed thanks to Therapsil. A couple months ago, he became the first Canadian to legally use psychedelic mushrooms to treat end of life anxiety and depression. Take a listen to his story with an open mind.<!-- --> <!-- -->1:02:33</span></span></span><span><ul><li><a href="https://www.cbc.ca/news/health/microdosing-pschedelics-study-1.4771647" data-contentid="" flag="" text="How and why people 'microdose' tiny hits of psychedelic drugs"><span>How and why people 'microdose' tiny hits of psychedelic drugs</span></a></li></ul></span></p>  <p>The move comes after Health Canada&nbsp;gave <a href="https://www.cbc.ca/news/canada/british-columbia/magic-mushrooms-therapy-1.5675637" target="_blank">four exemptions to palliative care patients</a> to use the drug&nbsp;for end-of-life psychotherapy in August. Since then, other exemptions have been given to patients who want to use magic mushrooms.&nbsp;</p>  <p>The exemptions for health professionals will allow those who want to treat patients with psilocybin&nbsp;to understand what it would feel like and how best to use it.&nbsp;</p>  <p>They are good for one year.&nbsp;</p>  <p>"Psychedelic substances and treatment using these substances, such as&nbsp;psilocybin, is a growing area of scientific study and research. Because&nbsp;psilocybin&nbsp;is not an authorized therapeutic substance, the availability of rigorous scientific evidence demonstrating its safety and efficacy is limited," Health Canada said in a statement to CBC News.&nbsp;</p>  <p>"The exemptions do not permit the health care professionals to prescribe or provide mushrooms containing&nbsp;psilocybin&nbsp;to another person. There are no drugs containing&nbsp;psilocybin&nbsp;that have been authorized&nbsp; by Health Canada. Health Canada's decision to grant these exemptions does not constitute an opinion or endorsement from Health Canada on&nbsp;psilocybin-assisted psychotherapy, training, or the safety, effectiveness, or quality of&nbsp;psilocybin."</p>  <h2>Psychiatrists, nurses given exemptions</h2>  <p>"This is an immense step that the minister has taken, and a very wise step, a step that is totally congruent with the science and the published literature and is a very courageous move on her part and on our government's part," O'Sullivan said.&nbsp;</p>  <p>Psychedelic therapies such as psilocybin and LSD have had negative reputations, in part because of the war on drugs, O'Sullivan said.&nbsp;</p>    <p>"The war on drugs has been an unmitigated disaster worldwide. It has criminalized behaviour that does not need to be criminalized. Cannabis has been legalized, and the sky has not fallen," O'Sullivan said.&nbsp;</p>  <p>Those who have been given exemptions include psychiatrists associated with the University of Toronto, a community psychiatrist in Hamilton and his partner, as well as health professionals in Calgary and British Columbia.&nbsp;</p>  <p>O'Sullivan and his wife both got an exemption. He is a general practitioner and she is a therapist. He said it's important for doctors who could eventually prescribe psychedelics to be well versed in their effects.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/dr-sean-o-sullivan.JPG 300w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/dr-sean-o-sullivan.JPG 460w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/dr-sean-o-sullivan.JPG 620w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/dr-sean-o-sullivan.JPG 780w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/dr-sean-o-sullivan.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/dr-sean-o-sullivan.JPG"></p></div><figcaption>Dr. Sean O'Sullivan is one of 16 health professionals who has been granted an exemption from Canada's drug laws to use magic mushrooms. <!-- --> <!-- -->(Submitted by Sean O'Sullivan)</figcaption></figure></span></p>  <p>"You would not expect a guide to take any journey over any terrain with&nbsp;which the guide was not familiar. When it comes to psychedelics, the terrain is so unusual and so outlandish that it is absolutely imperative that the therapist have familiarity with the realms of the human unconscious that are visited under psychedelics because they can help guide the patient through situations that might seem utterly bizarre, even psychotic to an untrained therapist," O'Sullivan said.</p>  <p>"Great information can be obtained if you dissect and unpack that material that comes up under these medications."</p>  <p>Psilocybin&nbsp;allows the brain to put away the "default mode network," the part of our brain that worries about taxes and dinner and the shopping list, and dive deeper.&nbsp;</p>    <p>"If you look at your <a href="https://www.cbc.ca/news/health/seeking-seat-of-consciousness-in-dark-side-of-brain-1.1415607" target="_blank">default mode network</a>, you will find that the themes that come up are the same themes that came up last year and the year before and the decade before," O'Sullivan said. "Psychedelics disassemble the default mode network and they allow a person to have new experiences in a carefully controlled clinical setting. When the default mode network is put back together, it's not put back together in the same way as it was previously."</p>  <p>That's why a single dose of a psychedelic medicine can have more effect than years of talk therapy or medication, he said.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485</link>
            <guid isPermaLink="false">hacker-news-small-sites-25382497</guid>
            <pubDate>Fri, 11 Dec 2020 05:03:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Economics of Software Performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25381748">thread link</a>) | @ivanmontillam
<br/>
December 10, 2020 | https://www.ivanmontilla.com/2020/12/economics-of-software-performance/ | <a href="https://web.archive.org/web/*/https://www.ivanmontilla.com/2020/12/economics-of-software-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em><strong>Disclaimer:</strong> I’m presenting this post without any figures or math, so it’s just my opinion based on professional past eye-witnessed experiences. This post will not be about hate, but rather on the weaknesses of delivery of recent trending technologies.</em></p>



<p>Recently I’ve seen a dangerous trend in software development, more specifically about web and desktop technologies. I wish not to bash on software frameworks such as Electron, but I think there are hidden costs for both junior developers and enterprises are ignoring. Let’s dig a bit deeper ahead.</p>



<p>Whenever you take the technical choice to abstract your codebase with a multiplatform framework, you need to be sure about the hidden costs of using it, and I’m not talking just about the implied costs of software performance. If you provide a poor user experience because your app feels <em>crap</em> to use, that’s a potential paying user that you’ll lose or at least will be upfront harder to acquire. </p>



<p>Sometimes software development teams are on a budget and need to make a choice like this, in order to increase market access and in that way, achieve faster market-product fit. I can understand that, but what is hard to reconcile to me, is the cost you save equals the cost your customers end up paying. Ideally, you’d not cut costs on this because after all, you need to provide the <em>best-in-class</em> experience to your users if you’re to retain them over several billing renewal cycles.</p>



<p>To put it bluntly: As a company, you might mistakenly think to save on software development costs, but your users actually don’t. What actually happens is: They end up paying the costs you <em>attempted</em> to save (more on this later), exponentially. It’s inversely proportional.</p>



<p>Did you deliver an app to the marketplace quickly? Yes. Does your app solve the problem? To some degree. Does the app perform <em>painlessly fast</em>? Muddy waters my friend. Can it run Crysis? I don’t think so.</p>



<p>The expected outcome is that you save on costs and have a greater runway for your startup to live, but let’s not forget: <em><a href="https://stackoverflow.com/questions/30490018/can-poor-performance-be-considered-as-a-software-bug" target="_blank" rel="noreferrer noopener">Poor software performance can be considered a bug</a></em>. If you’ve read <em>Steve McConnell’s Code Complete 2nd. Ed.</em>, you’ll notice <strong>proper software development is hard</strong>, and most of the time: with 5, 6 or even 7 figures on costs. And if your ideal resource-saving scenario doesn’t realize (time and money), your company will eventually find themselves reimplementing the app again in the latest technology-fad of that moment, feeding the vicious cycle.</p>



<p>Conversely, paying high costs on software development, while doesn’t guarantee business success, certainly helps in capturing better engineering for your product or service. So you had to have a team on iOS development, another one for Android development, another one for Windows, macOS, and Linux, but you delivered a superior experience. You might need to strike a balance between these two tug-of-war situations, to meet both business requirements and good engineering.</p>



<p>Imagine a world where mobile devices and personal computers ran on public clouds (much like Google Stadia), such as AWS or Azure. In such a scenario, your users would have to provision more expensive compute instances to actually run your 300 Mb social media application (without accounting for the data it stores locally). Storage and RAM are evergrowing, but here’s a little secret nobody tells you: <strong>There’s no need to take it up in its entirety!</strong></p>



<p><a href="https://mcfunley.com/choose-boring-technology" target="_blank" rel="noreferrer noopener">Boring technology is really great</a> not only because of its predictability, but it’s also great because most of the time it has been battle-tested for performance. The vulnerability of bloated technologies lies in the trend that some applications seem to be running really fast, but these are very few. So few they can be counted with the fingers of a single hand. All other applications range from overweight to really heavy on the OSes they run on. Maybe the framework is an easy “abusable” trap to create underperforming applications. Hat tip to these engineers of these few applications, these are a great feat of debugging, profiling, and engineering to achieve these results.</p>



<p>Yes, I can hear you… “<em>money talks</em>,” but if that’s the case, then consider technologies that overall reduce the cost to implement and to run. Example: <a href="https://sciter.com/" target="_blank" rel="noreferrer noopener">Sciter</a>‘s learning curve is harder than Electron’s, it actually requires you to learn a native or intermediate language to implement your business logic, and it also has <a href="https://www.kickstarter.com/projects/c-smile/open-source-sciter-engine" target="_blank" rel="noreferrer noopener">5 times less carbon footprint</a>, but hey! You’re a proper engineer shipping some serious code to production environments, after all, you choose what’s best for your customers, or do you? <strong>😉</strong></p>



<p>On a side note: I consider the origin of this dangerous trend to be from the specific situation when junior software developers skip computer, software architecture, and software design classes irresponsibly delivering bloated software to the marketplace.</p>



<p>Ignorance is the root and stem of all evils, Plato once said.</p>



<p>Source of inspiration: <a href="https://cr.yp.to/bib/1995/wirth.pdf" target="_blank" rel="noreferrer noopener">A Plea for Lean Software (Niklaus Wirth, 1995)</a></p>
		</div></div>]]>
            </description>
            <link>https://www.ivanmontilla.com/2020/12/economics-of-software-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25381748</guid>
            <pubDate>Fri, 11 Dec 2020 02:57:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clubhouse Conversation with Dylan Field]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25381458">thread link</a>) | @giacaglia
<br/>
December 10, 2020 | https://www.joinclubhouse.com/event/9mW6WaMX | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/event/9mW6WaMX">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.joinclubhouse.com/event/9mW6WaMX</link>
            <guid isPermaLink="false">hacker-news-small-sites-25381458</guid>
            <pubDate>Fri, 11 Dec 2020 02:15:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Alternatives]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 170 (<a href="https://news.ycombinator.com/item?id=25380999">thread link</a>) | @yepgwer
<br/>
December 10, 2020 | https://justprivacy.org/google-alternatives/ | <a href="https://web.archive.org/web/*/https://justprivacy.org/google-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span color="000000"><p>We may earn a small commission if you choose to purchase from our links <strong>(at no extra cost to you!)</strong></p></span></p><div data-elementor-type="wp-post" data-elementor-id="989" data-elementor-settings="[]"><div><div><section data-id="10b593b" data-element_type="section"></section><section data-id="c631736" data-element_type="section"><div><div><div data-id="72201ec" data-element_type="column"><div><div><div data-id="e877a4b" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg" alt="Google Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Alternatives-2048x1152.jpg 2048w" data-srcset="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Alternatives-2048x1152.jpg 2048w" sizes="(max-width: 992px) 100vw, 992px" title="Google Alternatives Google Alternatives: Protecting Your Data"></p></div></div></div></div></div></div></div></section><section data-id="c32dc21" data-element_type="section"><div><div><div data-id="af9583c" data-element_type="column"><div><div><div data-id="797f602" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>The purpose of this guide is to be the most in-depth list of the best alternatives to Google and its products.</p><p>Privacy and security of personal data online has become more of an issue, this means people are trying to find alternatives to Google.</p><p>The way Google makes money is by data collection and advertisements, with both affect your online privacy. The more data Google has on you the better they can find out what you’re interested in (target you) and therefore make more money off you. Did you know Google had over <a href="https://www.statista.com/statistics/267606/quarterly-revenue-of-google/" target="_blank" rel="noopener">$159 billion dollars in revenue</a> in 2019?</p><p>However, there is a growing amount of people who are looking for alternatives to Google.</p><p><span>Note:</span> None of these alternatives are in order, it depends on you’re specific needs.</p></div></div></div></div></div></div></div></div></section><section data-id="8997902" data-element_type="section"><div><div><div data-id="b2c7c82" data-element_type="column"><div><div><div data-id="a225dd3" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Search Engine Alternatives</h2></p></div><div data-id="6838ece" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="519" src="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg" alt="Google Search Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-300x157.jpg 300w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-768x402.jpg 768w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives.jpg 1200w" data-srcset="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-300x157.jpg 300w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-768x402.jpg 768w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives.jpg 1200w" sizes="(max-width: 992px) 100vw, 992px" title="Google Search Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="4d6be8b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Privacy and Google search don’t go hand in hand. When you use Google search, they will record your IP address, your search terms, and usually a unique ID.</p><p>Here are some good alternatives to Google search.</p><ol><li><a href="https://duckduckgo.com/" target="_blank" rel="noopener">DuckDuckGo</a> – An internet search engine whose goal is to protect users’ privacy and avoiding personalized search results (tracking).</li><li><a href="https://www.qwant.com/" target="_blank" rel="noopener">Qwant</a> – Is a French search engine that doesn’t track users.</li><li><a href="https://searx.me/" target="_blank" rel="noopener">SearX</a> – Is a free metasearch engine, intended to protect the privacy of their users.</li><li><a href="https://swisscows.com/" target="_blank" rel="noopener">SwissCows</a> – Is a Swiss search engine that was launched in 2014. They don’t keep track of the searches done on their site.</li><li><a href="https://www.mojeek.com/" target="_blank" rel="noopener">Mojeek</a> – Is a UK based search engine, they are independent and have unbiased results which means no user tracking.</li><li><a href="https://metager.org/" target="_blank" rel="noopener">MetaGer</a> – Is a search engine based on protecting users’ privacy, it’s also based in Germany.</li><li><a href="https://yandex.com/" target="_blank" rel="noopener">Yandex Search</a> – Is a search engine based in Russia and owned by a Russian corporation <a href="https://en.wikipedia.org/wiki/Yandex" target="_blank" rel="noopener">Yandex</a>.</li><li><a href="https://yacy.net/" target="_blank" rel="noopener">YaCy</a> – Is a free search engine built on principles of P2P (peer-to-peer) networks.</li></ol><p>Most of the search engines above are metasearch engines (except Mokeej and Yandex) meaning they source their search results from larger search engines like Google and Bing.</p></div></div></div></div></div></div></div></div></section><section data-id="56efb89" data-element_type="section"><div><div><div data-id="1091847" data-element_type="column"><div><div><div data-id="653fe9a" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Chrome Alternatives</h2></p></div><div data-id="0470836" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg" alt="Chrome Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Chrome-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Chrome-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Chrome Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="25f82ad" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Chrome is an extremely popular web browser and billions of searches are done monthly.</p><p>As you can see Google has 92.07% of the Search Engine Market Share Worldwide as of February 2020!</p></div></div></div><div data-id="e99d120" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://gs.statcounter.com/search-engine-market-share" target="_blank" rel="noopener"> <img width="992" height="269" src="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png" alt="Market Share Chrome" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png 1024w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-300x81.png 300w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-768x208.png 768w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-1536x417.png 1536w, https://justprivacy.org/media/2020/03/Market-Share-Chrome.png 1629w" data-srcset="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png 1024w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-300x81.png 300w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-768x208.png 768w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-1536x417.png 1536w, https://justprivacy.org/media/2020/03/Market-Share-Chrome.png 1629w" sizes="(max-width: 992px) 100vw, 992px" title="Market Share Chrome Google Alternatives: Protecting Your Data">		</a></p></div></div><div data-id="2d8725f" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Remember that Google Chrome is not only a search engine but a super successful data collection tool! More and more people are noticing this. There are many articles saying that Google Chrome has become spyware!</p><p>If you want to read more about this you can read this forum on <a href="https://www.reddit.com/r/BATProject/comments/c3q51d/goodbye_chrome_googles_web_browser_has_become_spy/?utm_source=share&amp;utm_medium=web2x" target="_blank" rel="noopener">Reddit</a> and an article on <a href="https://www.washingtonpost.com/technology/2019/06/21/google-chrome-has-become-surveillance-software-its-time-switch/" target="_blank" rel="noopener">Washington Post.</a></p><p>Here are some good alternatives to Chrome:</p><ol><li><a href="https://www.torproject.org/projects/torbrowser.html.en" target="_blank" rel="noopener">Tor Browser</a> – Is a global and decentralized computer network. This allows you to hide from tracking and surveillance.</li><li><a href="https://www.mozilla.org/fr/firefox/new/" target="_blank" rel="noopener">Firefox</a> – Is a free and open-source web browser, it was developed by Mozilla Foundation and help from thousands of volunteers!</li><li><a href="https://brave.com/fr/" target="_blank" rel="noopener">Brave</a> – Is an open-source web browser whose goal is to protect the privacy of their users by blocking trackers or preferring pages in HTTPS.</li><li><a href="https://iridiumbrowser.de/" target="_blank" rel="noopener">Iridium Browser</a> – Is based on the Chromium codebase. All modifications enhance privacy for the user.</li><li><a href="https://ungoogled-software.github.io/ungoogled-chromium-binaries/" target="_blank" rel="noopener">Ungoogled Chromium</a> – Is an open-source version of Chromium that has been modified to enhance users’ privacy.</li><li><a href="https://www.waterfox.net/" target="_blank" rel="noopener">Waterfox</a> – Is an open-source web browser that is based on Mozilla Firefox. Its purpose is to be speedy and ethical.</li><li><a href="https://www.epicbrowser.com/" target="_blank" rel="noopener">Epic Browser</a> – Is a “Privacy Browser” that is a secure chromium-based web browser.</li><li><a href="https://www.gnu.org/software/gnuzilla/" target="_blank" rel="noopener">GNUzilla</a> – Its a GNU version of the Mozilla suite. Its main advantage is that it’s ethical and entirely free!</li></ol><p>There are other alternatives to Google Chrome like Apple’s Safari and Microsoft’s Edge but many of these have serious privacy issues.</p></div></div></div></div></div></div></div></div></section><section data-id="0f232f2" data-element_type="section"><div><div><div data-id="dcd92ec" data-element_type="column"><div><div><div data-id="c5b213d" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg" alt="Gmail Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Gmail Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="acb282e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Your inbox is where the most important information is sent. You can find a lot of information on a person based on your inbox.</p><p>The unfortunate thing is that Google and its partners have access to all your information and they can <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" target="_blank" rel="noopener">collect data</a>, they can display ads inside your inbox, and the contents of your inbox are shared with random <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" target="_blank" rel="noopener">third parties</a>.</p><p>Here are some more secure Gmail alternatives:</p><ol><li><a href="https://protonmail.com/" target="_blank" rel="noopener">ProtonMail</a> – Is an encrypted email service created in 2013 by CERN and MIT scientists.</li><li><a href="https://tutanota.com/" target="_blank" rel="noopener">Tutanota</a> – Is a German-based email provider that is open-sourced with end-to-end email software. Tutanota also offers a web messaging service.</li><li><a href="https://posteo.de/en/" target="_blank" rel="noopener">Posteo</a> – Is a German email provider whose IT foundation is based on open-source software. They also use green energy from Greenpeace Energy and is also ad-free! The service costs € 1 per month.</li><li><a href="https://runbox.com/" target="_blank" rel="noopener">Runbox</a> – Is a company that provides email and web hosting services. It was founded in March 2011 and its headquarters are located in Oslo.</li><li><a href="https://mailbox.org/en/" target="_blank" rel="noopener">Mailbox.org</a> – Its an ad-free and secure email provider based in Germany, they offer a calendar, contacts lists and more.</li><li><a href="https://www.startmail.com/" target="_blank" rel="noopener">StartMail</a> – Is created by the people who created StartPage (a secure search engine).&nbsp;</li><li><a href="https://mailfence.com/en/" target="_blank" rel="noopener">Mailfence</a> – Is an encrypted email service based in Belgium. It offers free accounts.</li><li><a href="https://countermail.com/" target="_blank" rel="noopener">CounterMail</a> – Is a secure email provider that is based in Sweden.&nbsp;</li></ol></div></div></div></div></div></div></div></div></section><section data-id="9dd4dfa" data-element_type="section"><div><div><div data-id="5d3cd03" data-element_type="column"><div><div><div data-id="6d29af4" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Calendar Alternatives</h2></p></div><div data-id="fc23717" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg" alt="Gmail Alternatives 1" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Gmail Alternatives 1 Google Alternatives: Protecting Your Data"></p></div></div><div data-id="a3398d3" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Calendar is amazing it helps users manage their time, set goals, and remember things.</p><p>There are many upsides to Google’s Calendar app but there are some major privacy issues and many people are looking for alternatives.</p><p>Here are multiple Google Calendar alternatives:</p><ol><li><a href="https://www.simplemobiletools.com/" target="_blank" rel="noopener">Simple Calendar</a> – It’s an ad-free app without any unnecessary permissions.</li><li><a href="https://fruux.com/" target="_blank" rel="noopener">Fruux</a> – Offers a free account, supports many operating systems, and is open-source.</li><li><a href="https://timetreeapp.com/intl/en/" target="_blank" rel="noopener">TimeTree</a> – It offers a free account and supports Android, iOS, and browser.</li></ol><p>There are a few services that offer both email and calendar services in one:</p><ul><li><a href="https://tutanota.com/" target="_blank" rel="noopener">Tutanota</a></li><li><a href="https://mailbox.org/en/" target="_blank" rel="noopener">Mailbox.org</a></li><li><a href="https://posteo.de/" target="_blank" rel="noopener">Posteo</a></li><li><a href="https://mailfence.com/" target="_blank" rel="noopener">Mailfence</a></li><li><a href="https://outlook.live.com/" target="_blank" rel="noopener">Outlook</a></li></ul></div></div></div></div></div></div></div></div></section><section data-id="c72fb6b" data-element_type="section"><div><div><div data-id="f3c4b93" data-element_type="column"><div><div><div data-id="021a025" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Drive Alternatives</h2></p></div><div data-id="a27452e" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg" alt="Google Drive Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Drive Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="067a2fa" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Drive is a popular option because it’s free and extremely convenient, but Google doesn’t care about users’ privacy that much. It collects your data and uses it for their own purposes.</p><p>Here are some good Drive Alternatives:</p><ol><li><a href="https://www.dropbox.com/" target="_blank" rel="noopener">Dropbox</a> – Is a file hosting service owned by the American company Dropbox.</li><li><a href="https://www.sync.com/" target="_blank" rel="noopener">Sync.com</a> – Is based in Canada. They offer secure and encrypted cloud storage for both businesses and individuals.</li><li><a href="https://mega.nz/" target="_blank" rel="noopener">Mega</a> – Is a secure cloud storage service that offers free 50 GB of storage.</li><li><a href="https://nextcloud.com/" target="_blank" rel="noopener">Nextcloud</a> – This is a free and open-source file sharing platform that is based in Germany.</li><li><a href="https://github.com/syncthing/syncthing/tree/master" target="_blank" rel="noopener">Syncthing</a> – Peer-to-peer, an open-sourced cloud storage platform.</li><li><a href="https://tresorit.com/" target="_blank" rel="noopener">Tresorit</a>d Hungary that is serious about en<span>&nbsp;– Is a storage service based in Switzerland enhanced</span>&nbsp;security and data encryption.&nbsp;</li><li><a href="https://owncloud.org/" target="_blank" rel="noopener">ownCloud</a> – This is an open-source file sharing platform based in Germany.</li></ol><p>Some of my recommendations above (Dropbox, Mega) aren’t the best for privacy but are much more privacy-friendly than Google Drive.</p></div></div></div></div></div></div></div></div></section><section data-id="560065d" data-element_type="section"><div><div><div data-id="473c144" data-element_type="column"><div><div><div data-id="f1693c6" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg" alt="Google Docs Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Docs Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="98b5c8d" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Docs offers users to create documents easily online. But Google makes its money through data collection and Google’s bots have been caught crawling through users’ documents.</p><p>Here are some good alternatives to Google Drive:</p><ol><li><a href="https://www.zoho.com/docs/" target="_blank" rel="noopener">Zoho Office</a> – This is a good Google alternative for docs since it has a good interface and works well.</li><li><a href="https://etherpad.org/" target="_blank" rel="noopener">EtherPad</a> – Is an online free text editor that allows users to work collaboratively and in real-time.</li><li><a href="https://cryptpad.fr/" target="_blank" rel="noopener">CryptPad</a> – Is a great privacy-focused alternative to Google Docs.</li><li><a href="https://www.openoffice.org/" target="_blank" rel="noopener">Apache OpenOffice</a> – Is a good office suite platform that is also available <span>offline.</span></li><li><a href="https://personal.onlyoffice.com/" target="_blank" rel="noopener">OnlyOffice</a> – Is a multifunctional online office suite.</li><li><a href="https://www.nuclino.com/" target="_blank" rel="noopener">Nuclino</a> – Is a cloud-based collaboration software that allows teams to work on projects together and share information in real-time.</li><li><a href="https://flibreoffice.org/" target="_blank" rel="noopener">LibreOffice</a> – Is a good free and open-sourced office suite that is also available <span>offline.</span></li></ol></div></div></div></div></div></div></div></div></section><section data-id="46d2732" data-element_type="section"><div><div><div data-id="c3a000e" data-element_type="column"><div><div><div data-id="2f0a056" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg" alt="YouTube Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/YouTube-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/YouTube-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="YouTube Alternatives Google Alternatives: Protecting Your Data"></p></div></div></div></div></div></div></div></section><section data-id="46501a2" data-element_type="section"><div><div><div data-id="ce19e75" data-element_type="column"><div><div><div data-id="8f49f0c" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Photos Alternatives</h2></p></div><div data-id="3b7c0a6" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg" alt="Google Photos Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Photos Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="9979111" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google offers unlimited storage for photo’s but Google isn’t doing it to be nice. They will use your photos to scan your pictures and track things you do. I don’t think Google or any company needs to know that much about you.</p><p>Here are a few good Google Photo’s alternatives:</p><ol><li><a href="https://piwigo.org/" target="_blank" rel="noopener">Piwigo</a> – Is an open-source photo gallery software.&nbsp;</li><li><a href="https://zyl.ai/" target="_blank" rel="noopener">Zyl</a> – Is a great mobile app that cares about privacy.</li><li><a href="https://crypt.ee/" target="_blank" rel="noopener">Cryptee</a> –&nbsp; Is a great option if you’re serious about your privacy. They offer many services as well as not just photos.</li><li><a href="https://cluster.co/" target="_blank" rel="noopener">Cluster</a> – A free app that’s allows you to create photo albums and share them with people you choose.</li></ol></div></div></div></div></div></div></div></div></section><section data-id="e855368" data-element_type="section"><div><div><div data-id="205ce2f" data-element_type="column"><div><div><div data-id="2236d87" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Analytics Alternatives</h2></p></div><div data-id="643d0e7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg" alt="Google Analytics Alternative" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Analytics Alternative Google Alternatives: Protecting Your Data"></p></div></div><div data-id="fc58c6b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>If you’re running a website there are good reasons to use alternatives to Google Analytics. One, you’re respecting your visitor’s privacy and there are more friendly alternatives.</p><p>Websites who run Google Adsense campaigns are the ones who usually use Google Analytics because it would be much more difficult to track your results without it.</p><p>Here are a few Analytics alternatives:</p><ol><li><a href="https://matomo.org/" target="_blank" rel="noopener">Matomo</a> – It was formerly Piwik, and is an open-sourced platform that understands the privacy of the users. It also allows website admins to import historic Google Analytics data to Matomo.</li><li><a href="https://usefathom.com/" target="_blank" rel="noopener">Fathom Analytics</a> – Is an open-sourced website analytics platform that is efficient and fast. (<a href="https://github.com/usefathom/fathom" target="_blank" rel="noopener">GitHub</a>)</li><li><a href="https://clicky.com/" target="_blank" rel="noopener">Clicky</a> – Is a good alternative to Google Analytics because it keeps the user’s privacy by making their IP anonymous. It’s also efficient and user-friendly. It is also certified by <a href="https://www.privacyshield.gov/welcome" target="_blank" rel="noopener">Privacy Shield</a>!</li><li><a href="https://www.atinternet.com/en/" target="_blank" rel="noopener">AT Internet</a> – Is a French company that was created in 1996. It’s good for performance measurement or sites, and applications.</li><li><a href="https://www.foxmetrics.com/" target="_blank" rel="noopener">FoxMetrics</a> – Is a platform that allows you to understand and analyze your customer’s actions from your desktop and mobile device.</li></ol></div></div></div></div></div></div></div></div></section><section data-id="9f07b94" data-element_type="section"><div><div><div data-id="5b063df" data-element_type="column"><div><div><div data-id="dafc60c" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Translate Alternatives</h2></p></div><div data-id="eb7e8e7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg" alt="Google Translate Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Translate Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="bae68a8" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google has many privacy issues and Google Translate is no exception. Google may gather information on what you’re translating and use it for their own purposes.</p><p>Here are some Google Translate alternatives:</p><ol><li><a href="https://www.deepl.com/translator" target="_blank" rel="noopener">DeepL</a> – Is an online translation service that was launched on August 28 and available for Windows. (Good for translating large blocks of text)</li><li><a href="https://swisscows.ch/translate" target="_blank" rel="noopener">Swisscows Translate</a> – Is the data-safe Google alternative for translating languages.</li><li><a href="https://www.bing.com/translator" target="_blank" rel="noopener">Microsoft Translator</a> (Not the most privacy-conscious) – An online translator created by Microsoft&nbsp;</li><li><a href="https://fanyi.baidu.com/" target="_blank" rel="noopener">Baidu Translate</a> – Good for voice translation and pretty accurate.</li><li><a href="https://www.linguee.fr/" target="_blank" rel="noopener">Linguee</a> – Allows you to translate one word at a time not like Google translate where they will translate full paragraphs and sentences.</li></ol></div></div></div></div></div></div></div></div></section><section data-id="6afe49e" data-element_type="section"><div><div><div data-id="3b27360" data-element_type="column"><div><div><div data-id="10c4063" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Maps-Alternative-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Maps-Alternative-1024x576.jpg" alt="Google Maps Alternative" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Maps-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Maps-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Maps-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Maps-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Maps-Alternative.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Maps-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Maps-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Maps-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Maps-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Maps-Alternative.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Maps Alternative Google Alternatives: Protecting Your Data"></p></div></div><div data-id="07e196e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Maps isn’t the best …</p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justprivacy.org/google-alternatives/">https://justprivacy.org/google-alternatives/</a></em></p>]]>
            </description>
            <link>https://justprivacy.org/google-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380999</guid>
            <pubDate>Fri, 11 Dec 2020 00:59:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a Kubernetes Pod Gets an IP Address]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380898">thread link</a>) | @freedomben
<br/>
December 10, 2020 | https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/ | <a href="https://web.archive.org/web/*/https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the core requirements of the
<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#the-kubernetes-network-model" target="_blank" rel="noopener">Kubernetes networking model</a> is that every pod should get its own IP address and that every pod in the cluster should be able to talk to it using this IP address. There are several network providers (flannel, calico, canal, etc.) that implement this networking model.</p><p>As I started working on Kubernetes, it wasn’t completely clear to me how every pod is assigned an IP address. I understood how various components worked independently, however, it wasn’t clear how these components fit together. For instance, I understood what CNI plugins were, however, I didn’t know how they were invoked. So, I wanted to write this post to share what I have learned about various networking components and how they are stitched together in a kubernetes cluster for every pod to receive an IP address.</p><p>There are various ways of setting up networking in kubernetes and various options for a container runtime. For this post, I will use
<a href="https://github.com/coreos/flannel" target="_blank" rel="noopener">Flannel</a> as the network provider and
<a href="https://github.com/containerd/containerd" target="_blank" rel="noopener">Containerd</a> as the container runtime. Also, I am going to assume that you know how container networking works and only share a very brief overview below for context.</p><h2 id="some-background-concepts">Some Background Concepts</h2><h3 id="container-networking-a-very-brief-overview">Container Networking: A Very Brief Overview</h3><p>There are some really good posts explaining how container networking works. For context, I will go over a very high level overview here with a single approach that involves linux bridge networking and packet encapsulation. I am skipping details here as container networking deserves a blog post of itself. Some of the posts that I have found to be very educational in this space are
<a href="#container-networking">linked in the references below</a>.</p><h4 id="containers-on-the-same-host">Containers on the same host</h4><p>One of the ways containers running on the same host can talk to each other via their IP addresses is through a linux bridge. In the kubernetes (and docker) world, a
<a href="https://man7.org/linux/man-pages/man4/veth.4.html" target="_blank" rel="noopener">veth (virtual ethernet)</a> device is created to achieve this. One end of this veth device is inserted into the container network namespace and the other end is connected to a
<a href="https://wiki.archlinux.org/index.php/Network_bridge" target="_blank" rel="noopener">linux bridge</a> on the host network. All containers on the same host have one end of this veth pair connected to the linux bridge and they can talk to each other using their IP addresses via the bridge. The linux bridge is also assigned an IP address and it acts as a gateway for egress traffic from pods destined to different nodes.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/bridge-networking.png" alt="bridge networking"></p><h4 id="containers-on-different-hosts">Containers on different hosts</h4><p>One of the ways containers running on different hosts can talk to each other via their IP addresses is by using packet encapsulation. Flannel supports this through
<a href="https://vincent.bernat.ch/en/blog/2017-vxlan-linux" target="_blank" rel="noopener">vxlan</a> which wraps the original packet inside a UDP packet and sends it to the destination.</p><p>In a kubernetes cluster, flannel creates a vxlan device and some route table entries on each of the nodes. Every packet that’s destined for a container on a different host goes through the vxlan device and is encapsulated in a UDP packet. On the destination, the encapsulated packet is retrieved and the packet is routed through to the destined pod.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/flannel-networking.png" alt="flannel networking"></p><p><em>NOTE: This is just one of the ways how networking between containers can be configured.</em></p><h3 id="what-is-cri">What Is CRI?</h3><p><a href="https://github.com/kubernetes/cri-api" target="_blank" rel="noopener">CRI (Container Runtime Interface)</a> is a plugin interface that allows kubelet to use different container runtimes. Various container runtimes implement the CRI API and this allows users to use the container runtime of their choice in their kubernetes installation.</p><h3 id="what-is-cni">What is CNI?</h3><p><a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">CNI project</a> includes a
<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">spec</a> to provide a generic plugin-based networking solution for linux containers. It also consists of various
<a href="https://github.com/containernetworking/plugins" target="_blank" rel="noopener">plugins</a> which perform different functions in configuring the pod network. A CNI plugin is an executable that follows the CNI spec and we’ll discuss some plugins in the post below.</p><h2 id="assigning-subnets-to-nodes-for-pod-ip-addresses">Assigning Subnets To Nodes For Pod IP Addresses</h2><p>If all pods are required to have an IP address, it’s important to ensure that all pods across the entire cluster have a unique IP address. This is achieved by assigning each node a unique subnet from which pods are assigned IP addresses on that node.</p><h3 id="node-ipam-controller">Node IPAM Controller</h3><p>When <code>nodeipam</code> is passed as an option to the
<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/" target="_blank" rel="noopener">kube-controller-manager’s</a> <code>--controllers</code> command line flag, it allocates each node a dedicated subnet (podCIDR) from the cluster CIDR (IP range for the cluster network). Since these podCIDRs are disjoint subnets, it allows assigning each pod a unique IP address.</p><p>A kubernetes node is assigned a podCIDR when the node first registers with the cluster. To change the podCIDR allocated to nodes in a cluster, nodes need to be de-registered and then re-registered with any configuration changes first applied to the kubernetes control plane. <code>podCIDR</code> for a node can be listed using the following command.</p><pre><code>$ kubectl get no &lt;nodeName&gt; -o json | jq '.spec.podCIDR'
10.244.0.0/24
</code></pre><h2 id="kubelet-container-runtime-and-cni-plugins---how-its-all-stitched-together">Kubelet, Container Runtime and CNI Plugins - how it’s all stitched together</h2><p>When a pod is scheduled on a node, a lot of things happen to start up a pod. In this section, I’ll only focus on the interactions that relate to configuring network for the pod.</p><p>Once a pod is scheduled on the node, the following interactions result in configuring the network and starting the application container.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-flowchart.png" alt="kubelet-cri-cni-flowchart"></p><p>Ref:
<a href="https://github.com/containerd/cri/blob/v1.11.1/docs/architecture.md" target="_blank" rel="noopener">Containerd cri plugin architecture</a></p><h2 id="interactions-between-container-runtime-and-cni-plugins">Interactions between Container Runtime and CNI Plugins</h2><p>Every network provider has a CNI plugin which is invoked by the container runtime to configure network for a pod as it’s started. With containerd as the container runtime,
<a href="https://github.com/containerd/cri" target="_blank" rel="noopener">Containerd CRI plugin</a> invokes the CNI plugin. Every network provider also has an agent that’s installed on each of the kubernetes node to configure pod networking. When the network provider agent is installed, it either ships with the CNI config or it creates one on the node which is then used by the CRI plugin to figure out which CNI plugin to call.</p><p>The location for the CNI config file is configurable and the default value is <code>/etc/cni/net.d/&lt;config-file&gt;</code>. CNI plugins need to be shipped on every node by the cluster administrators. The location for CNI plugins is configurable as well and the default value is <code>/opt/cni/bin</code>.</p><p>In case of containerd as the container runtime, path for CNI configuration and CNI plugin binaries can be specified under <code>[plugins."io.containerd.grpc.v1.cri".cni]</code> section of the
<a href="https://github.com/containerd/cri/blob/master/docs/config.md" target="_blank" rel="noopener">containerd config</a>.</p><p>Since we are referring to Flannel as the network provider here, I’ll talk a little about how Flannel is set up. Flanneld is the Flannel daemon and is typically installed on a kubernetes cluster as a daemonset with <code>install-cni</code> as an
<a href="https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml#L172" target="_blank" rel="noopener">init container</a>. The <code>install-cni</code> container creates the
<a href="https://gist.github.com/ronaknnathani/957a56210bd4fbd8e11120273c6b4ede" target="_blank" rel="noopener">CNI configuration file</a> - <code>/etc/cni/net.d/10-flannel.conflist</code> - on each node. Flanneld creates a vxlan device, fetches networking metadata from the apiserver and watches for updates on pods. As pods are created, it distributes routes for all pods across the entire cluster and these routes allow pods to connect to each other via their IP addresses. For details on how flannel works, I recommend the
<a href="#how-flannel-works">linked references below</a>.</p><p>The interactions between Containerd CRI Plugin and CNI plugins can be visualized as follows:
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-interactions.png" alt="kubelet-cri-cni-interactions"></p><p>As described above, kubelet calls the Containerd CRI plugin in order to create a pod and Containerd CRI plugin calls the CNI plugin to configure network for the pod. The network provider CNI plugin calls other base CNI plugins to configure the network. The interactions between CNI plugins are described below.</p><h3 id="interactions-between-cni-plugins">Interactions Between CNI Plugins</h3><p>There are various CNI plugins that help configure networking between containers on a host. For this post, we will refer to 3 plugins.</p><h4 id="flannel-cni-plugin">Flannel CNI Plugin</h4><p>When using Flannel as the network provider, the Containerd CRI plugin invokes the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel" target="_blank" rel="noopener">Flannel CNI plugin</a> using the CNI configuration file - <code>/etc/cni/net.d/10-flannel.conflist</code>.</p><pre><code>$ cat /etc/cni/net.d/10-flannel.conflist
{
  "name": "cni0",
  "plugins": [
    {
      "type": "flannel",
      "delegate": {
		 "ipMasq": false,
        "hairpinMode": true,
        "isDefaultGateway": true
      }
    }
  ]
}
</code></pre><p>The Fannel CNI plugin works in conjunction with Flanneld. When Flanneld starts up, it fetches the podCIDR and other network related details from the apiserver and stores them in a file - <code>/run/flannel/subnet.env</code>.</p><pre><code>FLANNEL_NETWORK=10.244.0.0/16 
FLANNEL_SUBNET=10.244.0.1/24
FLANNEL_MTU=1450 
FLANNEL_IPMASQ=false
</code></pre><p>The Flannel CNI plugin uses the information in <code>/run/flannel/subnet.env</code> to configure and invoke the bridge CNI plugin.</p><h4 id="bridge-cni-plugin">Bridge CNI Plugin</h4><p>Flannel CNI plugin calls the Bridge CNI plugin with the following configuration:</p><pre><code>{
  "name": "cni0",
  "type": "bridge",
  "mtu": 1450,
  "ipMasq": false,
  "isGateway": true,
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24"
  }
}
</code></pre><p>When
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/main/bridge" target="_blank" rel="noopener">Bridge CNI plugin</a> is invoked for the first time, it creates a linux bridge with the <code>"name": "cni0"</code> specified in the config file. For every pod, it then creates a veth pair - one end of the pair is in the container’s network namespace and the other end is connected to the linux bridge on the host network. With Bridge CNI plugin, all containers on a host are connected to the linux bridge on the host network.</p><p>After configuring the veth pair, Bridge plugin invokes the host-local IPAM CNI plugin. Which IPAM plugin to use can be configured in the CNI config CRI plugin uses to call the flannel CNI plugin.</p><h4 id="host-local-ipam-cni-plugins">Host-local IPAM CNI plugins</h4><p>The Bridge CNI plugin calls the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/ipam/host-local" target="_blank" rel="noopener">host-local IPAM CNI plugin</a> with the following configuration:</p><pre><code>{
  "name": "cni0",
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24",
    "dataDir": "/var/lib/cni/networks"
  }
}
</code></pre><p>Host-local IPAM (IP Address Management) plugin returns an IP address for the container from the <code>subnet</code> and stores the allocated IP locally on the host under the directory specified under <code>dataDir</code> - <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code>. <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code> file contains the container ID to which the IP is assigned.</p><p>When invoked, the host-local IPAM plugin returns the following payload</p><pre><code>{
  "ip4": {
    "ip": "10.244.4.2",
    "gateway": "10.244.4.3"
  },
  "dns": {}
}
</code></pre><h2 id="summary">Summary</h2><p>Kube-controller-manager assigns a podCIDR to each node. Pods on a node are …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</a></em></p>]]>
            </description>
            <link>https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380898</guid>
            <pubDate>Fri, 11 Dec 2020 00:44:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplify, batch, and cache: how Shopify optimized storefront response times]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380697">thread link</a>) | @vaillancourtmax
<br/>
December 10, 2020 | https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering | <a href="https://web.archive.org/web/*/https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><em><strong>On December 16, 2020 Shipit! presents: Performance Tips from the Storefront Renderer Team.&nbsp;Celso and Maxime will share how the&nbsp;team optimized this Ruby application for the particular use case of serving storefront traffic. <a href="#Register">Please Register!</a></strong></em></p>
<p><strong>By Celso Dantas and Maxime Vaillancourt</strong></p>
<p>In the previous post about <a href="https://shopify.engineering/how-shopify-reduced-storefront-response-times-rewrite" target="_blank" title="How Shopify Reduced Storefront Response Times with a Rewrite" rel="nofollow noopener noreferrer">our new storefront rendering engine</a>, we described how we went about the rewrite process and smoothly transitioned to serve storefront requests with the new implementation. As a follow-up and based on readers’ comments and questions, this post dives deeper into the technical details of how we built the new storefront rendering engine to be faster than the previous implementation.</p>
<p>To set the table, let’s see how the new storefront rendering engine performs:</p>
<ul>
<li>It generates a response in less than ~45ms for 75% of storefront requests;</li>
<li>It generates a response in less than ~230ms for 90% of storefront requests;</li>
<li>It generates a response in less than ~900ms for 99% of storefront requests.</li>
</ul>
<p>Thanks to the new storefront rendering engine, the average storefront response is nearly 5x faster than with the previous implementation. Of course, how fast the rendering engine is able to process a request and spit out a response depends on two key factors: the shop’s Liquid theme implementation, and the number of resources needed to process the request. To get a better idea of where the storefront rendering engine spends its time when processing a request, try using the <a href="https://shopify.engineering/in-depth-liquid-render-analysis-shopify-theme-inspector-chrome-extension" target="_blank" title="How to Do an In-depth Liquid Render Analysis with Theme Inspector" rel="nofollow noopener noreferrer">Shopify Theme Inspector</a>: this tool will help you identify potential bottlenecks so you can work on improving performance in those areas.</p>
<figure><img alt="A data scheme diagram showing that the Storefront Renderer and Redis instance are contained in a Kubernetes node. The Storefront Renderer sends Redis data. The Storefront Renderer sends data to two sharded data stores outside of the Kubernetes node: Sharded MySQL and Sharded Redis" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema_c5f379b7-619f-4ddb-8064-d093550c4731.jpg?v=1607636250" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema_c5f379b7-619f-4ddb-8064-d093550c4731.jpg?v=1607636250">
<figcaption>A simplified data schema of the application</figcaption>
</figure>
<p>Before we cover each topic, let’s briefly describe our application stack. As mentioned in the previous post, the new storefront rendering engine is a Ruby application. It talks to a sharded MySQL database and uses Redis to store and retrieve cached data.</p>
<p>Optimizing how we load all that data is extremely important. As one of our requirements was to improve rendering time for Storefront requests. Here are some of the approaches that we took to accomplish that.</p>

<p>To reduce the number of network round trips to the database, we use <a href="https://dev.mysql.com/doc/internals/en/multi-statement.html" target="_blank" title="MySQL - 14.8.2 Multi-Statement" rel="nofollow noopener noreferrer">MySQL’s multi-statement feature</a> to allow sending multiple queries at once. With a single request to the database, we can load data from multiple tables at once. Here’s a simplified example:</p>
<figure>

</figure>
<p>This request is especially useful to batch-load a lot of data very early in the response lifecycle based on the incoming request. After identifying the type of request, we trigger a single multi-statement query to fetch the data we need for that particular request in one go, which we’ll discuss later in this blog post. For example, for a request for a product page, we’ll load data for the product, its variants, its images, and other product-related resources in addition to information about the shop and the storefront theme, all in a single round-trip to MySQL.</p>

<p>As shown above, the new storefront rendering engine uses handcrafted, optimized SQL queries. This allows us to easily write fine-tuned SQL queries to select only the columns we need for each resource and leverage JOINs and sub-SELECT statements to optimize data loading based on the resources to load which are sometimes less straightforward to implement with a full-service object-relational mapping (ORM) layer.</p>
<p>However, the main benefit of this approach is the tiny memory footprint of using a raw MySQL client compared to using an object-relational mapping (ORM) layer that’s unnecessarily complex for our needs. Since there’s no unnecessary abstraction, forgoing the use of an ORM drastically simplifies the flow of data. Once the raw rows come back from MySQL, we effectively use the simplest ORM possible: we create plain old Ruby objects from the raw rows to model the business domain. We then use these Ruby objects for the remainder of the request. Below is an example of how it’s done.</p>
<figure>

</figure>
<p>Of course, not using an ORM layer comes with a cost: if implemented poorly, this approach can lead to more complexity leaking into the application code. Creating thin model abstractions using plain old Ruby objects prevents this from happening, and makes it easier to interact with resources while meeting our performance criteria. Of course, this approach isn’t particularly common and has the potential to cause panic in software engineers who aren’t heavily involved in performance work, instead worrying about schema migrations and compatibility issues. However, when speed is critical, we accept to take on that complexity.</p>

<p>An HTTP request for a Shopify storefront may end up requiring many different resources from data stores to render properly. For example, a request for a product page could lead to requiring information about other products, images, variants, inventory information, and a whole lot of other data not loaded on multi-statement select. The first time the storefront rendering engine loads this page, it needs to query the database, sometimes making multiple requests, to retrieve all the information it needs. This usually happens during the request at any given time.</p>
<figure><img alt="A flow diagram showing the Storefront Renderer's requests from  the data stores and how it uses a Query Book Keeper Middlewear to eager-load data" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-request-bookeeping-solution_adbd68eb-cc30-4be5-9bdf-104011224ad2.jpg?v=1607636269" src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-request-bookeeping-solution_adbd68eb-cc30-4be5-9bdf-104011224ad2.jpg?v=1607636269">
<figcaption>Flow of a request with the Book-keeping solution</figcaption>
</figure>
<p>As it retrieves this data for the first time, the storefront rendering engine keeps track of the queries it performed on the database for that particular product page and stores that list of queries in a key-value store for later use. When an HTTP request for the same product page comes in later (which it knows when the cache key matches), the rendering engine looks up the list of queries it performed throughout the previous request of the same type and performs those queries all at once, at the very beginning of the current request, because we’re pretty confident we’ll need them for this request (since they were used in the previous request).</p>
<p>This book-keeping mechanism lets us eager-load data we’re pretty confident we’ll need. Of course, when a page changes, this may lead to over-fetching and/or under-fetching, which is expected, and the shape of the data we fetch stabilizes quickly over time as more requests come in.</p>
<p>On the other side, some liquid models of Shopify’s storefronts are not accessed as frequently, and we don’t need to eager-load data related to them. If we did, we’d increase I/O wait time for something that we probably wouldn’t use very often. What the new rendering engine does instead is lazy-load this data by default. Unless the book-keeping mechanism described above eager-loads it, we’ll defer retrieving data to only load it if it’s needed for a particular request.</p>

<p>Much like a CPU’s caching architecture, the new rendering engine implements multiple layers of caching to accelerate responses.</p>
<p>A critical aside before we jump into this section: adding caching should never be the first step towards building performance-oriented software. Start by building a solution that’s extremely fast from the get go, even without caching. Once this is achieved, then consider adding caching to reduce load on the various components on the system while accelerating frequent use cases. Caching is like a sharp knife and can introduce hard to detect bugs.</p>
<h2>In-Memory Cache</h2>
<figure><img alt="A data scheme diagram showing that the Storefront Renderer and Redis instance are contained in a Kubernetes node. Within the Storefront Renderer is an In-memory cache. The Storefront Renderer sends Redis data. The Storefront Renderer sends data to two sharded data stores outside of the Kubernetes node: Sharded MySQL and Sharded Redis" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema-in-memory-cache.jpg?v=1607636398" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema-in-memory-cache.jpg?v=1607636398">
<figcaption>A simplified data schema of the application with an in-memory cache for the Storefront Renderer</figcaption>
</figure>
<p>At the frontline of our caching system is an in-memory cache that you can essentially think of as a global hash that’s shared across requests within each web worker. Much like the majority of our caching mechanisms, this caching layer uses the LRU caching algorithm. As a result, we use this caching layer for data that’s accessed very often. This layer is especially useful in high throughput scenarios such as flash sales.</p>
<h2>Node-local Shared Caching</h2>
<p>As a second layer on top of the in-memory cache, the new rendering engine leverages a node-local Redis store that’s shared across all server workers on the same node. Since the database is available on the same machine as the rendering engine process itself, this node-local data transfer prevents network overhead and improves response times. As a result, multiple Ruby processes benefit from sharing cached data with one another.</p>
<h2>Full-page Caching</h2>
<p>Once the rendering engine successfully renders a full storefront response for a particular type of request, we store the final output (most often an HTML or JSON string) into the local Redis for later retrieval for subsequent requests that match the same cache key. This full-page caching solution lets us prevent regenerating storefront responses if we can by using the output we previously computed.</p>
<h2>Database Query Results Caching</h2>
<p>In a scenario where the full-page output cache, the in-memory cache, and the node-local cache doesn’t have a valid entry for a given request, we need to reach all the way to the database. Once we get a result back from MySQL, we transparently cache the results in Redis for later retrieval based on the queries and their parameters. As long as the cache keys don’t change, running the same database queries over and over always hit Redis instead of reaching all the way to the database.</p>
<h2>Liquid Object Memoizer</h2>
<p>Thanks to the Liquid templating language, merchants and partners may build custom storefront themes. When loading a particular storefront page, it’s possible that the Liquid template to render includes multiple references to the same object. This is common on the product page for example, where the template will include many references to the product object: <br><code>{{ product.title }}</code>, <code>{{ product.description }}</code>, <code>{{ product.featured_media }}</code>, and others.</p>
<p>Of course, when each of these are executed, we don’t fetch the product over and over again from the database—we fetch it once, then keep it in memory for later use throughout the request lifecycle. This means that if the same product object is required multiple times at different locations during the render process, we’ll always use the same one and only instance of it throughout the entire …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering">https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380697</guid>
            <pubDate>Fri, 11 Dec 2020 00:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Older patients 23% more likely to die if surgery occurs on surgeon's birthday]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380320">thread link</a>) | @Bologo
<br/>
December 10, 2020 | https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5563" role="main">
						<div>
							<div>
																																								<div>

								
<p>A <a href="https://www.bmj.com/content/371/bmj.m4381" target="_blank" rel="noreferrer noopener">new study has found</a> that elderly patients who underwent emergency surgery on their surgeon’s birthday had significantly higher 30-day mortality rates than patients whose surgery took place on any other day of the year. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p>



<p>The 30-day mortality rate (defined as death within 30 days after surgery)&nbsp;for the “surgeon’s birthday” group was 6.9%. This was 23% higher than the 5.6% rate for the “other day” group.</p>



<p>The study, which appears today in the <em>British Medical Journal</em> (<a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener">BMJ</a>),&nbsp;looked at 980,876 procedures performed in US hospitals by 47,489 surgeons.&nbsp;Of those procedures, 2,064 (0.2%) took place on a surgeon’s birthday.&nbsp;The patients were all Medicare beneficiaries aged 65 to 99. They had all undergone one of 17 common emergency surgical procedures between 2011 and 2014.</p>



<h2>Distractions during the most common emergency surgery types </h2>



<p>Examples of those 17 procedures included cardiovascular surgeries, hip and femur fracture, appendectomy, and small bowel resection. The study focused on&nbsp;emergency surgery, so as to&nbsp;minimize the potential selection bias. For example, surgeons might otherwise choose patients based on their illness severity, or patients might choose their surgeon.</p>



<p>As the authors write, “The effect size of surgeons’ birthday observed in our analysis (1.3 percentage point increase or a 23% increase in mortality), though substantial, is comparable to the impact of other events, including holidays (e.g., Christmas and New Year) and weekends.” <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p>



<p>In fact, the <a href="https://amzn.to/3m5rimG" target="_blank" rel="noreferrer noopener">history of surgery</a> has often demonstrated that external factors can influence surgical outcomes. The authors refer to a 2014 study showing that <a href="https://pubmed.ncbi.nlm.nih.gov/23345314/" target="_blank" rel="noreferrer noopener">patients admitted to Scottish emergency rooms on&nbsp;public holidays had a 27% increase</a> in 30-day mortality.&nbsp;Other research has found, for example,&nbsp;that doctors are more likely to <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1910546" target="_blank" rel="noreferrer noopener">prescribe antibiotics</a> and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2749268" target="_blank" rel="noreferrer noopener">opioids</a> — and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2733171" target="_blank" rel="noreferrer noopener">less likely to order&nbsp;cancer screening tests</a> — as the workday progresses. This is most likely because the “cumulative cognitive demand” of such decisions gradually takes its toll.&nbsp;</p>



<p>Research on judges has yielded similar results. It has found, for example, that external factors as diverse as outdoor temperatures and sports results can influence judges’ decisions.&nbsp;</p>



<h2>A natural experiment: ER surgery on the doctor’s birthday</h2>



<p>But the authors say the “natural experiment” in the present study is more revealing than, for example, holiday-related mortality rates. That is because “those events not only affect physicians’ performance but also influence patients’ decision to seek care (i.e., patients seeking care on these special days might be sicker than those seeking care on other days), as well as hospital staffing.” Unless, of course, the patients know their surgeon’s birthday, which is unlikely (though that may change if this study becomes widely known).&nbsp;</p>



<p>The 1.3% effect size was the result after a very through series of controls. These included, for example, excluding those surgeons with the highest patient mortality rates. Other controls included assigning a random “pseudo-birthday” to surgeons to see whether the results still held up, or checking whether the surgeon did an above-average number of procedures on their birthday. <span data-ez-name="psychnewsdaily_com-box-4"></span></p>



<p>Likewise, the researchers controlled for “milestone” birthdays (such as 40 or 50). They also controlled for whether a birthday fell on a Friday, which might make after-work birthday festivities more likely.&nbsp;Their findings also held up when the analysis was restricted to procedures with the highest average mortality, or to only the most ill patients.&nbsp;In fact, without these adjustments, the 30-day mortality rate difference between the birthday and non-birthday groups (the unadjusted rate) was even higher (7.0% vs. 5.6%, or a 1.4% difference).</p>



<h2><strong>Why</strong> does emergency surgery suffer on surgeon’s birthday?</h2>



<p>The authors propose a few potential explanations for this “birthday effect.”&nbsp;</p>



<p>These include hurrying through an emergency surgery to be on time for after-work birthday events; <a href="https://www.psychnewsdaily.com/study-finds-users-not-notifications-initiate-89-of-smartphone-interactions/" target="_blank" rel="noreferrer noopener">distracting</a> birthday-related phone calls or text messages; more conversations with well-wishing staff members; and a decreased likelihood to go back to the hospital that evening if a patient’s condition deteriorates.</p>



<p>They also found that some surgeons did not work on their birthdays. While 2,144 surgeons in this study performed procedures one day before their birthday, and 2,027 did so one day after their birthday, only 1,805 surgeons carried out procedures on their actual birthday. This does not affect the results of the study’s analyses. But it does suggest “that birthdays are an important enough factor for some surgeons to choose not to operate on that day, which supports the credibility of our assumption that a birthday could be a distracting factor for those surgeons who choose to operate on that day,” the authors write.&nbsp;</p>



<h2><strong>Limitations</strong> <strong>and future directions</strong></h2>



<p>The researchers emphasized that this study focused on common procedures, and on older Medicare patients. This means that the findings may not apply to other types of patients, or to other surgical procedures.</p>



<p>Still, the authors write, these results may lead to “additional support for surgeons who have potentially distracting events,” such as birthdays, “to make sure that patients receive high quality surgical care regardless of when undergo surgery.”</p>



<hr>



<p><strong>Study: </strong>“<a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">Patient mortality after surgery on the surgeon’s birthday: observational study</a>“<br><strong>Authors:</strong> Hirotaka Kato, Anupam B. Jena, and Yusuke Tsugawa<br><strong>Published in:</strong> <a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener"><em>The BMJ</em></a> <br><strong>Publication date: </strong>December 10, 2020<br><strong>DOI:</strong> <a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">https://dx.doi.org/10.1136/bmj.m4381</a><br><strong>Photo: </strong>by&nbsp;<a href="https://pixabay.com/users/theshiv76-1022681/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Jason Shivers</a>&nbsp;from&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Pixabay</a>&nbsp;</p>
<p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p>  
  
  
  

  
																</div><!-- .entry-content -->

								
								
																</div>

						</div>

					</article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380320</guid>
            <pubDate>Thu, 10 Dec 2020 23:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Mutual TLS]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25380003">thread link</a>) | @dogecoinbase
<br/>
December 10, 2020 | https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f | <a href="https://web.archive.org/web/*/https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380003</guid>
            <pubDate>Thu, 10 Dec 2020 23:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeBSD Remote Process Plugin: Final Milestone Achieved]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379737">thread link</a>) | @fcambus
<br/>
December 10, 2020 | https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Moritz Systems have been <a href="https://www.moritz.systems/blog/lldb-debugger-improvements-for-freebsd/">contracted</a>
by the <a href="https://freebsdfoundation.org/">FreeBSD Foundation</a> to modernize the
<a href="https://lldb.llvm.org/">LLDB</a> debugger’s support for
<a href="https://www.freebsd.org/">FreeBSD</a>.  We are working on a new plugin
utilizing the more modern client-server layout that is already used
by Darwin, Linux, NetBSD and (unofficially) OpenBSD.  The new plugin is
going to gradually replace the legacy one.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/LLVM_Logo.svg" alt="LLVM">
</p><center><small><small>This dragon image is owned by Apple Inc.</small></small></center>

<p>The Project Schedule was divided into three milestones, each taking
approximately one month:</p>

<ul>
<li>M1 Introduce new FreeBSD Remote Process Plugin for x86_64 with
basic support and upstream to LLVM.</li>
<li>M2 Ensure and add the mandated features in the project (process
launch, process attach (pid), process attach (name), userland
core files, breakpoints, watchpoints, threads, remote debugging)
for FreeBSD/amd64 and FreeBSD/i386.</li>
<li>M3 Iterate over the LLDB tests. Detect and as time permits fix bugs.
Ensure bug reports for each non-fixed and known problem. Add missing
man pages and update the FreeBSD Handbook.</li>
</ul>

<p>In the <a href="https://www.moritz.systems/blog/freebsd-remote-plugin-is-now-the-default-in-lldb/">previous report</a>
we have announced the completion of the second project’s milestone,
that is achieving the feature parity with the legacy plugin and enabling
the new plugin by default on 32 and 64-bit x86.  We have explained how different
platforms express process and thread identifiers and how <code>SIGTRAP</code> is used
to deliver event notifications to the debugger.  We have also described
the two alternative approaches on hooking the debugger up to the process -
either via launching it, or attaching to a running process.</p>

<p>The third milestone was focused on fixing bugs, updating the test suite
state and documentation.  We are proud to announce that this stage
is finished as well, and therefore <strong>the whole contract is accomplished
timely and successfully</strong>.
In this article, we would like to shortly summarize our work
and describe some of the more interesting areas of focus in detail.</p>

<h2 id="a-race-condition-while-copying-watchpoints-to-new-threads">A race condition while copying watchpoints to new threads</h2>

<p>The primary goal in the third milestone was to go through failing tests
and either fix them, or at least document the failures and mark
the respective tests as expected to fail.  The first really interesting
problem we’ve found while investigating the
<a href="https://github.com/llvm/llvm-project/blob/7e2ef84fe7232368f92ec0835c3eda869c85a445/lldb/test/API/commands/watchpoints/multiple_threads/main.cpp">commands/watchpoints/multiple_threads</a>
test.
The purpose of the test is to verify that watchpoints work when
the respective variables are altered by a non-main thread.</p>

<p>Originally, the test was done in two variants: with the watchpoint being
set before starting the new thread, and after starting it.  The first
variant was supposed to verify whether LLDB correctly copies existing
watchpoints to new threads as they are being started.  The second
variant verified whether the <code>watchpoint</code> command correctly adds
the new watchpoint to all running threads.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/debug_regs_copying.svg" alt="Debug Registers in threading application"></p>

<p>What’s important here is that hardware-assisted watchpoints on x86
are configured via altering the state of Debug Registers.  Like other
register sets, the values of DRs are thread-local, and therefore
the debugger needs to set them separately for every thread.
Furthermore, new threads inherit the DR state from parent threads
on FreeBSD, and our original watchpoint code relied on new threads
having the correct DR at start.</p>

<p>However, there is a catch.  The new thread is not reported to
the debugger until it is actually ready to start.  During this time,
the DRs are copied from the parent thread and it continues execution.
In fact, it is entirely feasible that the process is stopped due
to breakpoint in the parent thread before the new thread is actually
reported ready.  This creates an ample opportunity for the user to set
a new watchpoint, and this is precisely what happened to us during
the test.</p>

<p>At this point, the debugger is not yet aware that another thread
is being created.  However, the kernel has already copied the Debug
Register values from the parent thread.  As a result, the new thread
is created with the old DR values, while the debugger assumed that it
had the new values instead.</p>

<p>We have <a href="https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=250954">reported this confusing behavior</a>
to the FreeBSD Bugzilla.  For the time being, we’ve changed the plugin
to explicitly copy DRs when a new thread is reported, therefore
guaranteeing that any changes during the problematic period are
propagated.  We have also extended the original test to cover three
scenarios: watchpoint set before requesting the new thread, watchpoint
set immediately after requesting it (i.e. falling into our race
condition) and watchpoint set after waiting for the new thread
to actually start running (i.e. covering the original intent).</p>

<h2 id="simplifying-the-register-reading-and-writing-logic">Simplifying the register reading and writing logic</h2>

<p>The original register reading and writing logic in the new plugin
has been inspired by the code present in the NetBSD plugin.  It roughly
consisted of <a href="https://github.com/llvm/llvm-project/commit/58abbf821ce88f4d35cdfa36cdb486e2d56a04e2#diff-fe8211dffcb3e79e018065063ac970a718e5905c699517348d80c61859fcd989L538">a large switch-case construct</a>
that mapped enumeration values into appropriate operations on system
structures.  There were three large switches in total: one for reading
register values, one for writing register values and one for mapping
enumeration values from i386 to amd64 platform.  Furthermore, the first
two needed large separate variants for i386 and amd64.</p>

<p>At the same time, LLDB already carried another set of register
information that was created via macros by inspecting struct field
offsets and sizes.  Unlike the plugin logic, it did not use system
structures but instead <a href="https://github.com/llvm/llvm-project/blob/58abbf821ce88f4d35cdfa36cdb486e2d56a04e2/lldb/source/Plugins/Process/Utility/RegisterContextFreeBSD_x86_64.cpp#L17">inlined them</a>.
This is because the same structures are used to access core dumps,
and avoiding system headers makes it possible to compile the code
and inspect FreeBSD core dumps on other systems.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/register_mode.svg" alt="LLDB Registers"></p>

<p>Unlike NetBSD, the Linux plugin actually reused the offsets and sizes
from this data to access register sets.  We have decided to follow suit,
and replace the aforementioned custom logic with accesses based
on offset and size values, and this allowed us to reduce code
duplication significantly.  We have also added platform-specific <a href="https://github.com/llvm/llvm-project/blob/6adb55877c4bae6c75ab0d2c0374fab6787bff2d/lldb/unittests/Process/Utility/RegisterContextFreeBSDTest.cpp">tests
that verify that the offsets and sizes are correct, compared to system
structures</a>.</p>

<p>What’s even more important is that this change improved maintainability
a lot.  We have had hit cryptic bugs that turned out to be caused
by wrong integer type being used inside the switch-case.  Storing
the sizes inside a list makes it possible to easily verify their
correctness and avoid future bugs due to size mismatches.</p>

<h2 id="fixing-cases-of-the-legacy-plugin-being-wrongly-used">Fixing cases of the legacy plugin being wrongly used</h2>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/lldb_plugins.svg" alt="LLDB plugins"></p>

<p>The process plugins in LLDB are split into two kinds: client plugins
and server plugins.  Client plugins are used by the LLDB client, while
server plugins are used by <code>lldb-server</code> to implement the remote
protocol.  The legacy FreeBSD plugin is a client plugin - it is loaded
by LLDB and used to debug a program.  The modern FreeBSD plugin is
a server plugin - it is loaded by the LLDB server and used to implement
the GDB remote protocol.  Another plugin called <code>gdb-remote</code> provides
a glue between the client and server.  It is loaded by the client,
it spawns lldb-server and fulfills client’s requests by communicating
with the server.</p>

<p>Therefore, by switching between the legacy and remote FreeBSD plugins,
we are actually switching between using the legacy client plugin
and the <code>gdb-remote</code> plugin that spawns lldb-server with the remote
FreeBSD plugin.  Our original switching logic (based on the prior art
from the Windows plugin) consisted of two pieces: <a href="https://github.com/llvm/llvm-project/blob/2c2eb5e6702bf3bbb8fb8f09790b1ab7b139e879/lldb/source/Plugins/Platform/FreeBSD/PlatformFreeBSD.cpp#L250">a boolean switch in
PlatformFreeBSD</a>
and a code blocking the legacy plugin from being loaded when the new
plugin should be used.  However, we have established that the latter
is not really necessary, and we have removed the latter part as we
changed the preferred plugin.</p>

<p>During the final testing period, we’ve found and fixed two cases where
this was not correct: when choosing plugin for <code>process connect</code>,
and when attaching to a running process.</p>

<p>The <code>process connect</code> command is supposed to iterate through all
available process plugins, find one that initializes successfully
and use it to establish a connection to the server.  However, it lacked
any means of actually determining whether the plugin in consideration
supported remote connections at all.  This was acceptable for
non-transitional platforms that had only one candidate client plugin.
However, on FreeBSD it could randomly choose either the legacy plugin,
or the <code>gdb-remote</code> plugin.  To resolve this, we have added <a href="https://github.com/llvm/llvm-project/commit/18e4272a4fe4667a44f4d323140645a83ddfd864">explicit
filtering for remote connection support</a>,
using similar approach as for determining core file support.</p>

<p>The plugin used for launching and attaching processes was supposed
to be controlled by the aforementioned boolean switch.  If the new
plugin was to be used, the method returned true and the launch/attach
implementation from
<a href="https://github.com/llvm/llvm-project/blob/1a1cc0ba7db549025ab1a504633ae4554042fd60/lldb/source/Plugins/Platform/POSIX/PlatformPOSIX.cpp#L359">PlatformPOSIX</a>
was being used.  Otherwise, it returned false and the legacy plugin
kicked in.</p>

<p>The <code>PlatformPOSIX::DebugProcess()</code> method used to launch programs
explicitly forced the <code>gdb-remote</code> plugin.  However,
the <code>PlatformPOSIX::Attach()</code> method did not specify the plugin name
and could therefore use either.  To fix this, we’ve updated it to force
<code>gdb-remote</code> consistently within the class.</p>

<h2 id="the-interaction-between-dynamic-loader-and-the-debugger">The interaction between dynamic loader and the debugger</h2>

<p>The dynamic loader is the system component responsible for loading
shared libraries that are used by the program.  This includes both
loading the linked libraries as specified by <code>DT_NEEDED</code> ELF header,
and loading additional modules at runtime via <code>dlopen(3)</code>.</p>

<p>The dynamic linker provides a <code>r_debug</code> structure that can be used
by the debugger to inspect its state, as well as monitor events - that
is, loading and unloading shared libraries.  The <code>r_debug</code> structure
is consistent across most of the Unix systems (with Solaris being
an exception).  On FreeBSD, it is declared in <code>&lt;sys/link_elf.h&gt;</code> as:</p>

<div><pre><code data-lang="c"><span>struct</span> r_debug {
        <span>int</span>             r_version;      <span>/* Currently '1' */</span>
        <span>struct</span> link_map <span>*</span>r_map;         <span>/* list of loaded images */</span>
        <span>void</span>            (<span>*</span>r_brk)(<span>struct</span> r_debug <span>*</span>, <span>struct</span> link_map <span>*</span>);
                                        <span>/* pointer to break point */</span>
        <span>enum</span> {
                RT_CONSISTENT,          <span>/* things are …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/">https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379737</guid>
            <pubDate>Thu, 10 Dec 2020 22:37:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast Feedback Pyramid]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379658">thread link</a>) | @atomkirk
<br/>
December 10, 2020 | https://atomkirk.com/2020-07-27-fast-feedback-pyramid/ | <a href="https://web.archive.org/web/*/https://atomkirk.com/2020-07-27-fast-feedback-pyramid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>July 27, 2020</p></header><section><p>I wrote before about the importance of <a href="https://atomkirk.com/2020-07-01-fast-feedback-loops/">fast feedback loops</a> and
the <a href="http://localhost:8000/2020-07-16-the-5-categories-of-bugs/">5 categories of bugs</a> and today I thought about how
this could be represented as a pyramid, much like the <a href="https://martinfowler.com/articles/practical-test-pyramid.html#:~:text=The%20%22Test%20Pyramid%22%20is%20a,put%20it%20into%20practice%20properly.">Test Pyramid</a>.</p>
<p><span>
      <a href="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e16ee/pyramid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Fast feedback pyramid" title="Fast feedback pyramid" src="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/fcda8/pyramid.png" srcset="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/12f09/pyramid.png 148w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e4a3f/pyramid.png 295w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/fcda8/pyramid.png 590w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/efc66/pyramid.png 885w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/c83ae/pyramid.png 1180w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e16ee/pyramid.png 1963w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Toward the bottom are the mistakes we make as programmers most frequently. They are also typically the fastest to catch
and correct.</p>
<p>Syntax errors happen as soon as you save the file and try to build. It’s even the very first thing a compiler
will do: parse your files. If it can’t parse it, you’ll get a syntax error.</p>
<p>Second, we type function/variable names wrong or we forget the shape of data in a variable and use it wrong. If you’ve
got a good test pyramid, your tests will run fast and often and hopefully catch these problems quickly. But it requires
that your tests are thorough and optimized. Let’s face it, this is hard and most test suites aren’t. That’s why a
lot of teams
are turning to type safety, because you can collapse the second level into the first so that both syntax and
reference/type errors are caught immediately when you try to compile/build.</p>
<p>Type safety also allows powerful tooling that can tighten feedback loops further by offering relevant suggestions, information
on hover &amp; descriptive inline errors.</p>
<p>And, once again, with languages with value type errors and exhaustive results handling (i.e. Elm, Rust, etc.), you can
even make the third layer of this pyramid provide immediate feedback at build time, further tightening your feedback
loop.</p></section><hr></article></div>]]>
            </description>
            <link>https://atomkirk.com/2020-07-27-fast-feedback-pyramid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379658</guid>
            <pubDate>Thu, 10 Dec 2020 22:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reddit is down (10th Dec 2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379256">thread link</a>) | @mystcb
<br/>
December 10, 2020 | https://www.redditstatus.com/incidents/qr5vky5kwn3r | <a href="https://web.archive.org/web/*/https://www.redditstatus.com/incidents/qr5vky5kwn3r">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <div>
    

    <div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <p>
            Resolved
          </p>
          <div>
            <p>
              This incident has been resolved.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642418000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:20</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              We are continuing to monitor for any further issues.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642044000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:14</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Monitoring
          </p>
          <div>
            <p>
              A fix has been implemented and we are monitoring the results.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642008000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:13</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              We are continuing to work on a fix for this issue.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642004000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:13</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              Systems are slowly recovering, but we are still seeing elevated error rates and degradation in our mobile clients.
            </p>
            <p>
              Posted <span data-datetime-unix="1607640732000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">14:52</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Identified
          </p>
          <div>
            <p>
              reddit.com is currently down. A fix has been identified and is in the process of being applied.
            </p>
            <p>
              Posted <span data-datetime-unix="1607637872000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">14:04</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Investigating
          </p>
          <div>
            <p>
              We are currently investigating this issue.
            </p>
            <p>
              Posted <span data-datetime-unix="1607637171000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">13:52</var> PST
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affected: reddit.com (Desktop Web, Mobile Web, Native Mobile Apps).
        </p>
    </div>

    
  </div>

  
</div></div>]]>
            </description>
            <link>https://www.redditstatus.com/incidents/qr5vky5kwn3r</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379256</guid>
            <pubDate>Thu, 10 Dec 2020 21:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeepMind’s AlphaFold 2–An Impressive Advance with Hyperbolic Coverage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25379061">thread link</a>) | @andreyk
<br/>
December 10, 2020 | https://www.skynettoday.com/briefs/alphafold2 | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/briefs/alphafold2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="summary">Summary</h2>

<ul>
  <li>DeepMind’s AlphaFold 2, a deep-learning model that predicts protein structures, achieved significant improvements over other methods in the biannual CAPS protein folding prediction competition.</li>
  <li>The improvements are so large that some claim protein folding is a solved problem. However, while almost all applaud the impressive advancement, many note the caveats and limitations of AlphaFold 2 in both the problem of protein folding and downstream uses in biology.</li>
  <li>After weighing the opinions of many experts, we take the view that while AlphaFold 2 should be celebrated, it is still just one step (though a big one!), and will not significantly advance practical applications like drug discovery.</li>
</ul>

<h2 id="what-happened">What Happened</h2>

<p>On the last day of November 2020, Critical Assessment of Structure Prediction (CASP), a biennial challenge for computational biologists on the problem of “protein folding”, released its results, showing DeepMind’s AI-driven <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">Alphafold 2</a> outperforming its competitors by a large margin. 
The pace of Alphafold’s improvement came as a shock to many researchers and mainstream media publications, <a href="https://www.bbc.com/news/science-environment-55133972">who heralded the development as a game-changer for biology</a>. 
Others acknowledged the uses of the tool, but <a href="http://occamstypewriter.org/scurry/2020/12/02/no-deepmind-has-not-solved-protein-folding/">cautioned that there were many more challenges </a>in the protein-folding prediction space that may warrant a tempering of expectations, let alone the broader field of biology.</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/alphafold2/image1.png" alt="AlphaFold 2's CAPS results.">
  <figcaption>
    Left: AlphaFold 2’s impressive score on the CAPS protein folding competition. Right: Examples of predicted (blue) vs. actual (green) protein structures.
    Source: <a href="https://www.deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">DeepMind</a>
  </figcaption>
</figure>

<p>In the world of proteins, form determines function. 
Thus, the ability to look forward and predict protein structures would help all kinds of biology subfields, from the more basic science work to drug discovery. 
Historically, attempts to model proteins have failed due to exponentially increasing computing costs, but <a href="https://dl.acm.org/doi/pdf/10.5555/3433701.3433707">specialized computational hardware</a> appears well-equipped to address this issue.</p>

<p>Alphafold made some waves with its 2018 CASP win, but the <a href="https://www.sciencemag.org/news/2018/12/google-s-deepmind-aces-protein-folding">media coverage was decidedly more muted then</a>. 
The pace of Alphafold’s 2020 improvement on top of its own success in 2018 was shocking for many experts, who felt that a solution to the <a href="https://scitechdaily.com/major-scientific-advance-deepmind-ai-alphafold-solves-50-year-old-grand-challenge-of-protein-structure-prediction/">50-year old protein-solving problem </a>was finally in sight. 
One important note is that AlphaFold 2, like other methods submitted to CASP, doesn’t actually model <em>how</em> proteins fold - it just predicts the final structure of the protein after it has folded.</p>

<p>There are a number of quality blog posts that explain protein folding and AlphaFold 2. <a href="https://twitter.com/jasoncrawford">Jason Crawford</a> at Roots of Progress gives an accessible review of protein folding in <a href="https://rootsofprogress.org/alphafold-protein-folding-explainer">What is the “protein folding problem”? A brief explanation.</a> It is also summarized in this excellent Twitter thread:</p>

<blockquote><div lang="en" dir="ltr"><p>Today Google <a href="https://twitter.com/DeepMind?ref_src=twsrc%5Etfw">@DeepMind</a> announced that their deep learning system AlphaFold has achieved unprecedented levels of accuracy on the “protein folding problem”, a grand challenge problem in computational biochemistry.</p><p>What is this problem, and why is it hard?<a href="https://t.co/OjbP3RBPEi">https://t.co/OjbP3RBPEi</a></p></div>— Jason Crawford (@jasoncrawford) <a href="https://twitter.com/jasoncrawford/status/1333576221418930176?ref_src=twsrc%5Etfw">December 1, 2020</a></blockquote>


<p>For a more technical explanation of AlphaFold 2 itself, we refer readers to the blog posts by <a href="https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/">Mohammed AlQuraishi</a> and <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">Carlos Outeiral</a>. In summary, DeepMind trained a neural network model on 170k known protein structures in the publicly available <a href="https://www.rcsb.org/">Protein Data Bank dataset (PDB)</a>. In addition to its many novel architecture designs, one important aspect of this neural network seems to be its use of attention mechanisms, a similar kind of architecture used by recent state-of-the-art language models like GPT-3.</p>

<blockquote><p lang="en" dir="ltr">An attention-based technique was used, which has shown promise across ML in language/vision/etc. This allows for efficient learning (ie capturing relations between elements) and uncovering broader principles: <a href="https://t.co/hKTcb5mTkr">https://t.co/hKTcb5mTkr</a></p>— Ali Madani (@thisismadani) <a href="https://twitter.com/thisismadani/status/1333481997210161160?ref_src=twsrc%5Etfw">November 30, 2020</a></blockquote>


<blockquote><div lang="en" dir="ltr"><p>Very exciting results this week from AlphaFold in CASP14. An incredible and inspiring achievement by the DeepMind team. Many new possibilities.</p><p>*Attention* mechanism is key to the result. Interestingly we find the exact same in our work on *unsupervised* learning for proteins.</p></div>— Alex Rives (@alexrives) <a href="https://twitter.com/alexrives/status/1334942570682716163?ref_src=twsrc%5Etfw">December 4, 2020</a></blockquote>


<h2 id="the-reactions">The Reactions</h2>

<h3 id="from-the-press">From the Press</h3>

<p>The press was very optimistic about AlphaFold 2’s progress in protein folding and its broader implications in biology and beyond, with headlines like:</p>

<ul>
  <li>Nature: <a href="https://www.nature.com/articles/d41586-020-03348-4">‘It will change everything’: DeepMind’s AI makes gigantic leap in solving protein structures</a></li>
  <li>Science: <a href="https://www.sciencemag.org/news/2020/11/game-has-changed-ai-triumphs-solving-protein-structures">‘The game has changed.’ AI triumphs at solving protein structures</a></li>
  <li>MIT Tech Review: <a href="https://www.technologyreview.com/2020/11/30/1012712/deepmind-protein-folding-ai-solved-biology-science-drugs-disease/">DeepMind’s protein-folding AI has solved a 50-year-old grand challenge of biology</a></li>
  <li>IEEE Spectrum: <a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/medical-ai/alphafold-proves-that-ai-can-crack-fundamental-scientific-problems">AlphaFold Proves That AI Can Crack Fundamental Scientific Problems</a></li>
</ul>

<h3 id="from-the-experts">From the Experts</h3>

<p><a href="https://twitter.com/c_outeiral/status/1334779365280903169">Carlos Outeiral</a>, Computational Biology research scientist at Oxford, also highlighted the “astoundingly” impressive results of AlphaFold 2, in the post <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">CASP14: what Google DeepMind’s AlphaFold 2 really achieved, and what it means for protein folding, biology and bioinformatics</a>:</p>

<blockquote>
  <p>After three decades of competitions, the assessors declared that AlphaFold 2 had succeeded in solving a challenge open for 50 years: to develop a method that can accurately, generally and competitively predict a protein structure from its sequence (or, well, a multiple sequence alignment, as we will see later). There are caveats and edge cases, as in any application — but the magnitude of the breakthrough, as well as its potential impact, are undeniable.</p>
</blockquote>

<p>Comparing AlphaFold 2’s results to those of other methods: “AlphaFold 2’s accuracy is simply on a whole different level.”</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/alphafold2/image2.png" alt="Comparing AlphaFold 2’s score (left most) to other methods in this year’s CAPS competition.">
  <figcaption>
  Comparing AlphaFold 2’s score (left most) to other methods in this year’s CAPS competition.
  Source: <a href="https://predictioncenter.org/casp14/zscores_final.cgi">CAPS</a>
  </figcaption>
</figure>

<p>Similarly, <a href="https://twitter.com/MoAlQuraishi">Mohammed AlQuraishi</a>, Professor of Systems Biology at Columbia, gave praise to DeepMind’s achievements:</p>

<blockquote><p lang="en" dir="ltr">CASP14 <a href="https://twitter.com/hashtag/s?src=hash&amp;ref_src=twsrc%5Etfw">#s</a> just came out and they’re astounding—DeepMind looks to have solved protein structure prediction. Median GDT_TS went from 68.5 (CASP13) to 92.4!!!! Cf. their 2nd best CASP13 struct scored 92.8 (out of 100). Median RMSD is 2.1Å. I think it's over <a href="https://t.co/dQ1BOJWuwn">https://t.co/dQ1BOJWuwn</a></p>— Mohammed AlQuraishi (@MoAlQuraishi) <a href="https://twitter.com/MoAlQuraishi/status/1333383634649313280?ref_src=twsrc%5Etfw">November 30, 2020</a></blockquote>


<p>In his detailed blog post last year on the first iteration of AlphaFold, <a href="https://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/#s2.2">AlphaFold @ CASP13: “What just happened?”</a>, Professor AlQuraishi discussed what DeepMind’s progress meant for academia and pharmaceutical companies:</p>

<ul>
  <li>This is “an indictment of academic science” - “There are dozens of academic groups, with researchers likely numbering in the (low) hundreds, working on protein structure prediction. […] For DeepMind’s group of ~10 researchers, with primarily (but certainly not exclusively) ML expertise, to so thoroughly route everyone surely demonstrates the structural inefficiency of academic science.”</li>
  <li>This is also “an indictment of pharma” - “What is worse than academic groups getting scooped by DeepMind? The fact that the collective powers of Novartis, Pfizer, etc, with their hundreds of thousands (~million?) of employees, let an industrial lab that is a complete outsider to the field, with virtually no prior molecular sciences experience, come in and thoroughly beat them on a problem that is, quite frankly, of far greater importance to pharmaceuticals than it is to Alphabet.”</li>
</ul>

<p>Responding to this year’s AlphaFold 2 is his new post <a href="https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/">AlphaFold2 @ CASP14: “It feels like one’s child has left home.”</a>:</p>

<ul>
  <li>While AlphaFold 2 still has a lot of caveats, Professor AlQuraishi defends using “solved” to describe protein folding, at least in the scientific sense. He argues the remaining deficiencies of AlphaFold 2 are not scientific problems, but rather engineering ones. While engineering problems can still be exceedingly difficult, “competent domain experts know the pieces that need to fall into place to solve them.”</li>
  <li>As for AlphaFold 2’s potential applications to advance biology as a whole: “It won’t happen overnight. None of what I’m saying here will. It will take years and maybe decades, but now that protein structure prediction has become an engineering exercise, we know that many of these ideas can be realized.”</li>
</ul>

<p>Specifically for drug development:</p>
<blockquote>
  <p>I will end this section with the question that gets asked most often about protein structure prediction—will it change drug discovery? Truthfully, in the short term, the answer is most likely no. But it’s complicated. 
One important thing to note is that, of the entire drug development pipeline, the early discovery stage is just that, an early stage. Even if crystallography were to become fast and routine, it would still not fundamentally alter the dynamics of drug discovery as it is practiced today, as most of the cost is in the later stages of drug development beyond medicinal chemistry and well into biology and physiology. Reliable protein structure prediction doesn’t change that.</p>
</blockquote>

<p>However, not everyone saw the same magnitude of advancement in AlphaFold 2.
In the post <a href="http://occamstypewriter.org/scurry/2020/12/02/no-deepmind-has-not-solved-protein-folding/">No, DeepMind has not solved protein folding</a>, <a href="https://twitter.com/Stephen_Curry">Stephen Curry</a>, Professor of Structural Biology at Imperial College London, cautioned against using the word “solved” to describe protein folding:</p>

<blockquote>
  <p>But we are not yet at the point where we can say that protein folding is ‘solved’. For one thing, only two-thirds of DeepMind’s solutions were comparable to the experimentally determined structure of the protein. This is impressive but you have to bear in mind that they didn’t know which two-thirds of their predictions were correct until the comparison with experimental solutions was made. Would you buy a satnav that was only 67% accurate?
So a dose of realism is required. It is also difficult to see right now, despite DeepMind’s impressive performance, that this will immediately transform biology.</p>
</blockquote>

<p>Despite AlphaFold 2’s average accuracy of 1.6 Å:</p>
<blockquote>
  <p>it’s still not nearly good enough for delivering reliable insights into protein chemistry or drug design. To do that, we want to be confident of atomic positions to …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/briefs/alphafold2">https://www.skynettoday.com/briefs/alphafold2</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/briefs/alphafold2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379061</guid>
            <pubDate>Thu, 10 Dec 2020 21:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Making of “The Godfather” – Sort of a home movie (1971)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25378576">thread link</a>) | @dadt
<br/>
December 10, 2020 | http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/ | <a href="https://web.archive.org/web/*/http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>As was his custom before the drive home from work with his son, the old man walked across the narrow, tenement‐lined street in Manhattan’s Little Italy to buy some fresh fruit. The grocer, who had known him for many years, helped the old man sort out some prize oranges and, as a gift, handed him a perfectly ripened, home‐grown fig. The old man smiled, accepted the backyard offering with a slight nod and started toward his car. It was then that he spotted two gunmen.</p>
<p>He called out to his son and began to sprint toward the safety of his car with surprising speed for a man of his age, but the gunmen were too quick. As they opened fire, the old man seemed caught in a great leap, suspended momentarily in the air, his arms thrown protectively around his head. Loud shots hammered through the street, bright oranges rolled across the gray pavement and the old man crashed onto the fender of his car and collapsed. The people of Mott Street watched in silence from tenement windows, fire escapes and rooftops as the gunmen slipped away. Then, to spontaneous applause, the grim street tableau came to life, and the old man—the godfather, <a href="http://www.thestacksreader.com/brando/">Marlon Brando</a>—lifted himself slowly from the ground, smiled at the cheering crowd and bowed.</p>
<p>At 11 o’clock on April 12, just as Brando was getting shot on Mott Street, Carlo Gambino, one of New York’s real godfathers, sat around the corner in a Grand Street cafe, sipping black coffee from a glass and holding 18th‐century Sicilian court in 20th‐century New York. He had arrived moments earlier in the company of his brother, Paul, and five bodyguards. It was his custom, as well as his duty as head of a Mafia family, to hear at regular intervals the endless woes of racketeers, dishonored fathers and deportable husbands. They were ushered before him, one at a time, from a waiting area in a restaurant across the street. He was the final judge to people still willing to accept his decisions as law.</p>
<hr>
<p>Back on Mott Street, two Mafiosi assigned to observe the movie production were unaware of his arrival. For hours, they had been watching Brando getting shot. They had had innumerable cups of coffee and had adjusted their open‐throat, hand ironed shirts so often that their collars had begun to wilt. Neither of them had been impressed when they heard Brando was to play the godfather, so they watched his performance critically. They volunteered to grips, cameramen and extras that they would have preferred Ernest Borgnine or Anthony Quinn.</p>
<p>“A man of that stature,” one of them said, pointing to Brando, “would never wear a hat like that. They never pinched them in the front like that. Italian block, that’s the way they wore them, Italian block.”</p>
<p>They did not like Brando’s wearing his belt below his trouser loops, either.</p>
<p>“He makes the old man look like an iceman. That’s not right. A man like that had style. He should have a diamond belt buckle. They all had diamond belt buckles. And a diamond ring and tie clasp. Those old bosses loved diamonds. They all wore them. Brando makes the guy look like an iceman.”</p>
<p>In truth, Brando did not look like the traditional double‐breasted, wide lapeled, blue‐serge racketeer. He had accepted the advice of an Italian American friend, rather than the Mafiosi themselves, and made himself look old and bent. He wore a sack shaped suit of an undistinguished brown stripe and an outsize over coat. He wore a cardboard‐stiff white shirt with a collar at least two sizes too large and a striped tie so indifferently knotted that its back, label and all, faced front. The makeup man, who was never very far away, had fixed Brando with an elaborate mouth plate that made his jaw heavy and extended his jowls. Brando’s complexion was sallow, his eyes were made to droop on the side and with his graying temples and mustache many people on Mott Street that day did not recognize him until the filming began.</p>
<h5>There was an aura about the production that was unmistakable, just as there is an aura of real and imagined power around the honored society itself.</h5>
<p>The two Mafiosi did approve the vintage cars and were amused by the streetlamps, pushcarts and prices, circa 1940, tacked up in store windows. But they did not like the way the godfather’s assassins fired their guns.</p>
<p>“They hold pieces like flowers,” one said.</p>
<p>Shortly before noon a third man came up behind the pair and whispered:</p>
<p>“The old man’s around the corner.” The two men were stunned. “You kidding?” one asked. “Believe me, he’s around the corner.”</p>
<p>“Kee‐rist!”</p>
<p>“Shooo!”</p>
<p>Without further hesitation—and with the same pitch of excitement most neighborhood people saved for a peek at Brando—the trio left the movie set. They walked quickly toward the intersection and stopped. One of them darted his head around the corner of the building for a quick peek and shot back to his friends: “He’s there. He’s there. I see his car. I see Paul’s guy.”</p>
<hr>
<p>Mario Puzo’s best seller may have started out to be just another multimillion‐dollar movie for Paramount, but it wasn’t long before its producers realized that to the Mafiosi themselves the making of <em>The Godfather</em> was like the filming of a home movie. Before Puzo’s book, cops‐and‐robbers novels and films about organized crime left the mobsters cold. <em>The Godfather</em> was different. When it was published in 1969 word quickly spread across the country’s most regularly tapped telephone wires about this different book on the “honored society.” It was their <em>Forsyte Saga</em>. It was filled with bits of underworld gossip and its characters could be compared to live dons, singers, movie moguls and hit men. It depicted not only their lives, but the lives of their children, wives, enemies and friends. It emphasized their peculiar code of honor rather than their seedy, greedy little maneuverings. It dealt with their strong sense of family and their passionate loyalties. It romanticized and exaggerated their political power, wealth and influence in legitimate business. But most important, it humanized rather than condemned them.</p>
<p>The godfather himself, for instance, was shot because he refused to deal in the dirty business of narcotics. Sonny Corleone, his impetuous heir, was killed in an ambush because he tried to save his pregnant sister from a brutal husband. Michael Carleone, the godfather’s college educated war‐hero son, assumed his father’s Mafia mantle not out of greed, but from a sense of responsibility to his father, who, for all his illegal activities, was a far more honorable man than all the crooked cops, venal judges, corrupt politicians and perverted businessmen who peppered the plot.</p>
<p>Though certain Italian‐American politicians and organizations condemned Puzo for defaming all Italians, the author heard no such criticism from the society about which he had written. In fact, shortly after his book’s publication, Puzo found that some Mafiosi were anxious to meet him. They wanted to compare notes with the author of <em>The Godfather.</em> They, like other fans, refused to believe that the book was all fiction. In Las Vegas he found that a gambling debt he had run up was somehow marked paid. When Puzo protested he was told, “It’s a certain party’s pleasure.” On other occasions, bottles of champagne would arrive at his table unordered. Multisyllabic names were whispered in his ear by reverential headwaiters, and men with sunglasses and diamond rings waved at him across darkened restaurants.</p>
<hr>
<p>Six weeks before the Mott Street shooting of Brando, Albert Ruddy, the film’s producer, was uncertain whether he would be able to make the movie at all. Paramount had been deluged with letters describing the project as anti‐Italian and threatening demonstrations, boycotts and wildcat strikes by everyone from maintenance men to electricians. Letters had come from Congressmen in New York, New Jersey, Connecticut, Louisiana and Pennsylvania, as well as from dozens of New York State legislators, judges, civic leaders and businessmen.</p>
<p>One of them began: “A book like <em>The Godfather</em> leaves one with the sickening feeling that a great deal of effort and labor to eliminate a false image concerning Americans of Italian descent and also an ethnic connotation to organized crime has been wasted …. There are so many careers and biographies that could be made into constructive and intellient movies, such as the life of Enrico Fermi, the great scientist; Mother Cabrini; Colonel Ceslona, a hero of the Civil War; Garibaldi, the great Italian who unified Italy; William Paca, a signer of the Declaration of Independence; Guglielmo Marconi, and many, many others.”</p>
<p>The letter was signed by “the Grand Venerable of the Grand Council of the Grand Lodge of New York State’s Sons of Italy.” It also informed Paramount that the studio could expect an economic boycott of the film, petitions of protest from all Sons of Italy lodges, regional meetings to plan protests, a complaint filed with the State Human Rights Division and demands that no governmental authorities give the production any cooperation whatever.</p>
<p>And as if this were not enough, there were rumors of union walkouts, work stoppages and boycotts. Ruddy could envision costly delays. He had already run into trouble trying to negotiate with householders in Manhasset, L.I., for a site that looked like a godfather’s compound. The entire community and its bureaucrats had ganged up to sabotage his efforts.</p>
<p>“First, they’d complain that we would bring additional cars into the area and take up parking space,” Ruddy said. “So we’d promise to bus our people to the locations. Then they’d say they didn’t want buses in the area. Some said that if we did use their homes for the mall and the wedding the newspapers couldn’t know about it. How could we guarantee that? We were ready to pay, rent, replant, repaint, replace everything in the area for them. We were ready to make all kinds of concessions, but in the end I realized that they just didn’t want us. They never flat came out and said no, but it amounted to the same thing.</p>
<p>“For …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/">http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/</a></em></p>]]>
            </description>
            <link>http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378576</guid>
            <pubDate>Thu, 10 Dec 2020 20:59:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inuttitut, a language shaped by humility, poetry, and the land]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25378558">thread link</a>) | @diaphanous
<br/>
December 10, 2020 | https://beside.media/new-narratives/nuna/ | <a href="https://web.archive.org/web/*/https://beside.media/new-narratives/nuna/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>
                          <p>Text — Juliana Léveillé-Trudel<br>
Photos — Alexi Hobbs</p>
                                                


      

                  <div>
        <p>“She’s away on vacation for two weeks,” said Bobby, manager of the village of Quaqtaq.</p>
<p>He was talking about the head of the recreation department, who had all of the keys, most importantly the one for the Isummasarvik School’s storage room. We needed it to get the sports equipment to keep the kids occupied at day camp: balls, badminton racquets, nets, and hockey sticks.</p>
<p>I sighed inwardly. Ever since I’d been working in Nunavik, finding a key had been a recurring nightmare. I had already given up hope.</p>
<p>“Maybe you could ask the caretaker,” Bobby suggested.</p>
<p>Anne, my colleague, nodded and waved me on. We got back into the truck. On the other side of the windows, the June sun was beating down on the frozen bay that it could not crack. We stopped in front of a house near the footbridge spanning the river. The caretaker was out, but her husband exchanged a few words with Anne in Inuttitut, then disappeared and returned with the miraculous key. I pinched myself. It had taken all of five minutes.</p>
<p>That was back in 2015, my fifth summer in Nunavik. If it had happened a few years earlier, I would have probably told the story on my blog, joking about how even a simple task can be so immensely complicated in the North.</p>
<p>But as the old man held out the keys, it hit me: it was my fault that it was complicated. I had begun setting up day camps in the North in 2011. Everything that I had found difficult then was difficult because I was trying to make things work my way: planning activities and appointments in advance, holding daily meetings, requiring long-term commitment from the camp’s employees. There was another problem too: I didn’t know the people or the language well enough. I didn’t know who the caretaker was or where she lived. I wouldn’t have been able to speak with her husband, who spoke only in Inuttitut.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
          <div>
            <p><img src="https://content.beside.media/beside_/app/www/2020/10/B09_Nuna_Alexis-Hobbs-02.jpg" alt="">
                        </p>
          </div>
        </figure>
      </div>

      
    
      

                  <div>
        <p>I’d learned a few words, of course, especially words useful for working with children: <em>come here, sit down, do you understand, hurry up, are you ready, stop, wait, again, a little, a lot, yesterday, today, tomorrow, yes, no, maybe, what’s your name, and how old are you.</em> We’d played Twister once, so I also knew the names of body parts, colours, left and right. I knew the names of all the animals. It was a start, but not enough to converse with the caretaker’s husband.</p>
<p>Many of the <em>Qallunaat</em> (whites) I met among the Inuit described Inuttitut as “impossible to learn.” It did indeed seem complicated, with all those qs, ks, and js, but I loved its rough sonority. Moreover, I could never feel at ease with this linguistic one-sidedness. Some of my friends were taking online courses with Professor Marc-Antoine Mahieu at INALCO (Institut National des Langues et Civilisations Orientales), affiliated with the Sorbonne in Paris. They all spoke about the class with the same blissful smile. In 2016 I signed up too. I had just quit my job to devote myself to writing. It meant that I would no longer be travelling to Nunavik but that I had more time—and I very much wanted to learn Inuttitut and keep a foot in the North.</p>
<p>In our first class, Marc-Antoine made a point of destroying our hopes. Inuttitut is a highly unfamiliar language, not nearly as easily learned as English or Spanish. Acquiring competence would take years of study and practice, and despite all that effort, we would very likely never be able to really converse.</p>
<p>Strangely, this bleak prospect soon seemed irrelevant. Little by little, I discovered a spectacular language, immensely creative and full of humour. A language that had to invent all sorts of slightly eccentric ways of naming the elements of modern life, but that described the land and hunting techniques with staggering precision. A language that seemed made for poetry with its constructed words and love of repetition; a language that taught me so many things about people that I’d been among for years without ever really knowing.</p>

      </div>
      

            
    
      

            
        

      
    
      

                  <div>
        






<p>Don’t believe everything you’ve heard, however: there are not hundreds of words for snow.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
          <div>
            <p><img src="https://content.beside.media/beside_/app/www/2020/10/B09_Nuna_Alexis-Hobbs-06.jpg" alt="">
                        </p>
          </div>
        </figure>
      </div>

      
    
      

                  <div>
        <p>Over and over, I’d said what so many others have: that the Inuit have a very liberal concept of time. I learned that it could be as structured as my own; it was just structured around other things. For example, the months are defined by animal behaviours.</p>
<p>September, October, November: <em>amiraijaut, arnalirnguutivik, natjuijarvik.</em></p>
<p>Time when antlers lose their velvet. Time when the males compete for females. Time when caribou shed their antlers.</p>
<p>Places that I had known by their French or English names regained their original appellations: I now dared to utter the word <em>Kangiqsualujjuaq</em>; I no longer needed to say <em>George River</em>. I was unlearning my geography, just as so many Indigenous people have had to unlearn theirs. Even the idea of “the Arctic” once hadn’t existed for the Inuit. They had to invent a word for it that suited a Western geographical perspective: <em>Ukiurtatuq</em>, which translates as “repeated winter.”</p>
<p>I found that the language had a harmonious relationship with the environment—despite the occasionally ruthless climate. In the very first Inuttitut dictionary, written by Taamusi Qumaq in 1991, Nunavik is defined as “a large country occupied by animals.” I admired this humility, this awareness that a place is shared with other species, that one is living, in a way, on <em>their</em>&nbsp; land.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
                      <img src="https://content.beside.media/beside_/app/www/2020/10/AWH_2318.jpg" alt="">
                            </figure>
       </div>

              
    
      

                  <div>
        <p>It’s perhaps precisely because of this humility that one should never speak ill of <em>sila</em>, the weather. This was a blessing for a snow lover like me, tired of the eternal whinging about winter.</p>
<p>All of these words for different kinds of snow and ice, for Northern hunting and fishing techniques, show the extent to which the Inuit were at one with their land. Some people have bandied about the idea that the ancestors of the <em>Nunavimmiut</em>&nbsp; found themselves stuck in the North, blocked from going south by the Cree in the west and Innus in the east, but this is false. Research has concluded that the ancient peoples of the Arctic in fact moved even further north during a period of warming around the year 1000, because they did not know how to survive without the cold. Today, climate change has had particularly devastating consequences for the populations of Nunavik and Nunavut.</p>
<p>In the land that would become Canada, European explorers (<em>tariup akiani</em>, “from across the sea”) saw a vast reservoir of natural resources for exploitation. Our current climate crisis is the direct result of this unbridled exploitation, our stubborn insistence on doing things our way, our belief that we can draw a hermetic border between us and <em>nuna</em>, the great land, when in fact we live in each other.</p>
<p>Our language navigates modern urbanity with much more ease than Inuttitut, but it reflects a far more distant relationship with the environment, often stuck in the idea of fighting against the elements. Could the rich vocabulary of the Inuit inspire us to redefine our relationship with nature? <span>■</span></p>

      </div>
      

            
    
      

                    <div>
          <p>Born in Montréal in 1985, <strong>Juliana Léveillé-Trudel</strong> writes in various genres: fiction (<em>Nirliit</em>, La Peuplade, 2015, translated by Anita Anand, Véhicule Press, 2018), children’s literature (<em>How to Catch a Bear Who Loves to Read</em>, Chouette, 2018, coauthored with Andrew Katz), blogs, and plays. She has presented many of her theatrical and literary creations on stage. In 2018 she founded Productions de Brousse.</p>
        </div>

            
                
        </section>
      </div></div>]]>
            </description>
            <link>https://beside.media/new-narratives/nuna/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378558</guid>
            <pubDate>Thu, 10 Dec 2020 20:57:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“The tragedy of the commons” in software development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378442">thread link</a>) | @mcrittenden
<br/>
December 10, 2020 | https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-4179">

	
<!-- .entry-header -->

	<div>

		<div>

			
<blockquote><p>The&nbsp;<strong>tragedy of the commons</strong>&nbsp;is a situation in a shared-resource system where individual users, acting independently according to their&nbsp;own self-interest, behave contrary to the common good of all users by depleting or spoiling the shared resource through their&nbsp;collective action.&nbsp;</p><cite><a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">Wikipedia</a></cite></blockquote>



<p>Remind you of anything? Toilet paper in 2020, perhaps?</p>



<p>I’m struck by how often this pops up in software development:</p>



<ul><li>Hitting refresh over and over when your test environment won’t load because everyone is overloading the dev server by hitting refresh.</li><li>Teams don’t volunteer to upgrade dependencies because they all have their own milestones to meet, and eventually an upgrade would be a nightmare because they waited too long. </li><li>Disk space, disk space, disk space. “A few extra MB won’t hurt” repeated thousands of times until the drive is chock full.</li><li>One vaguely named variable ain’t no thing, but 5 years of vaguely named variables equals <a href="https://critter.blog/2020/09/08/2-things-ive-learned-from-reading-refactoring-by-martin-fowler/">one unmaintainable codebase</a>. </li></ul>



<p>The classic <a href="https://blog.codinghorror.com/the-broken-window-theory/">broken window theory</a> is a part of this. Once someone sets the precedent, it’s hard to walk it back. Another part is <a href="https://critter.blog/2020/11/06/all-self-help-boils-down-to-choose-long-term-over-short-term/">choosing short term over long term</a>, the enemy of growth.</p>



<p>Those two plus a healthy dose of regular old human greed adds up to <em>the tragedy of the commons</em>. </p>



<p>I have no useful insight here other than to say that it exists, and sometimes naming a thing is enough to prevent it.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378442</guid>
            <pubDate>Thu, 10 Dec 2020 20:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing and Using Docker and Kubernetes on FreeBSD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25378236">thread link</a>) | @mikece
<br/>
December 10, 2020 | https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html | <a href="https://web.archive.org/web/*/https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><article role="main"><p><strong>These configuration have been tested only on FreeBSD 12.1-RELEASE.</strong></p><h2 id="1-introduction">1. Introduction</h2><p>Wait… what? FreeBSD does not have Docker! Doesn’t it?</p><p>Well of course not really, but you can still install Docker using FreeBSD, it won’t just be FreeBSD in Docker since FreeBSD is not supported as Docker images.</p><p>In this blog post, I won’t discuss exactly how to install a few things, I will mostly point to blog posts and documentations so that you know what to do to install Docker and Kubernetes <strong>using</strong> FreeBSD.</p><p>I will not be using Minikube or Kind, not that I don’t like it, but my opinion is that Minikube is nice for quick and dirty small tests and it’s using VirtualBox which is like a big problem to me, but also Bhyve + VirtualBox … choice?!. And Kind is also mostly for tests, it’s closer to an installation with kubeadm, but I really prefer to try things as close to production as possible.</p><p>All these have been tested on a PC installed with FreeBSD 12.1-RELEASE. It has a 6 cores cpu, and 32GB of memory.</p><p>Here is a quick summary:</p><ul><li><a href="#1-introduction">1. Introduction</a></li><li><a href="#2-details">2. Details</a><ul><li><a href="#21-install-sysutilsvm-bhyve-packages">2.1 Install <code>sysutils/vm-bhyve</code> packages</a></li><li><a href="#22-configure-freebsd-sysctls-to-easily-bridge-out">2.2 Configure FreeBSD sysctls to easily bridge out</a></li><li><a href="#23-install-docker">2.3 Install Docker</a></li><li><a href="#24-install-kubernetes">2.4 Install Kubernetes</a></li></ul></li><li><a href="#the-end-is-the-beginning">The end is the beginning…</a></li></ul><h2 id="2-details">2. Details</h2><h3 id="21-install-sysutilsvm-bhyve-packages">2.1 Install <code>sysutils/vm-bhyve</code> packages</h3><p><a href="https://github.com/churchers/vm-bhyve"><code>sysutils/vm-bhyve</code></a> is a shell based, minimal dependency bhyve manager. And <a href="https://www.freebsd.org/doc/handbook/virtualization-host-bhyve.html">Bhyve</a> is a BSD licenced hypervisor. It’s being heavily developped with FreeBSD, and honestly it’s really well integrated to FreeBSD.</p><p>To install <code>vm-bhyve</code> on FreeBSD, you have to be root ofc for good reasons:</p><div><pre><code data-lang="shell"><span># 'sysrc -f /boot/loader.conf vmm_load="YES"'</span>
<span># Load the 'vmm' kernel module</span>
kldload vmm
<span># 'sysrc -f /boot/loader.conf nmdm_load="YES"'</span>
<span># Load the 'nmdm' kernel module</span>
kldload nmdm
<span># vm on bridge is using tap interface</span>
sysctl net.link.tap.up_on_open<span>=</span><span>1</span>
<span># edit '/etc/sysctl.conf', add 'net.link.tap.up_on_open=1'</span>
pkg install sysutils/vm-bhyve
</code></pre></div><p>I’m inviting you to go to the <code>vm-bhyve</code> GitHub page and to review its README, it has a lot of interesting informations. Just do not forget to create a switch (vm-bhyve term) and also to add your network interface to that switch.</p><p>The next thing is mostly the handling of this package. But one thing about this project is that it’s using bridge. I personaly like to have my bridge free of use, and to use firewall when it’s needed, and to be able to address my VM to my needs, which are generaly to have internet access to ease installations. Which is leading to my next point.</p><h3 id="22-configure-freebsd-sysctls-to-easily-bridge-out">2.2 Configure FreeBSD sysctls to easily bridge out</h3><p>I’m usually using PF for firewall, and to be able to have my best use of the bridge you can create with <code>vm-bhyve</code>. To this goal, I’m deciding not to firewall the bridge in any way, and to tell PF not to care about bridge it’s quite easy, it’s even a configuration I’m using for VNET jails.</p><p>So let’s change the PF behavior with bridge with these sysctls, descriptions:</p><div><pre><code data-lang="text">net.link.bridge.pfil_bridge: Packet filter on the bridge interface
net.link.bridge.pfil_onlyip: Only pass IP packets when pfil is enabled
net.link.bridge.pfil_member: Packet filter on the member interface
</code></pre></div><p>commands:</p><div><pre><code data-lang="shell">sysctl net.link.bridge.pfil_bridge<span>=</span><span>0</span>
sysctl net.link.bridge.pfil_onlyip<span>=</span><span>0</span>
sysctl net.link.bridge.pfil_member<span>=</span><span>0</span>
</code></pre></div><p>You can put these sysctls directly in your <code>/etc/sysctl.conf</code> so that at reboot it’s already configured.</p><p>Now you can only care for what’s important, and if you want to firewall your VM, you can always add one inside the VM itself.</p><h3 id="23-install-docker">2.3 Install Docker</h3><p>Just follow this blog: <a href="https://www.gamsjager.nl/2019/01/11/How-to-run-Docker-on-FreeBSD-12/">How to run Docker on FreeBSD 12</a></p><p>In this blog, the author is telling to get Debian 9 ISO, but you can also get Debian 10, it’s working as well.
Once the debian is installed, just don’t forget to follow these two links, I’ve followed them and it’s working:</p><ul><li><a href="https://docs.docker.com/install/linux/docker-ce/debian/">Install Docker Engine on Debian</a></li><li><a href="https://success.docker.com/article/how-do-i-enable-the-remote-api-for-dockerd">How do I enable the remote API for dockerd</a></li></ul><p>When you are finished with this section, you should be able to use docker inside the VM, and outside, so on your host.</p><h3 id="24-install-kubernetes">2.4 Install Kubernetes</h3><p>Honestly, it should be as simple as search in your favorite Search Engine <code>Install Kubernetes</code>, but the first link you get is this one: <a href="https://kubernetes.io/docs/setup/">Getting started</a>.
So… yes you could follow this link but, this is not the goal!</p><p>Instead we want the <strong>R</strong>eal thing, to get closer to a production environment, even if that’s for testing. So you can get there: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">Installing kubeadm</a>. You can follow everything on this page, it’s not hard at all. But the page only tells you to install <code>kubeadm</code>, <code>kubelet</code> and <code>kubectl</code>.</p><p>The hardest part comes with: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">Creating a single control-plane cluster with kubeadm</a>. And here are my tips:</p><ul><li>When you install docker inside your vm, you installed it with <code>containerd.io</code>. This Kubernetes page tells you about what’s possible, either <code>Containerd.io</code>, or <code>CRI-o</code>, just do not install CRI-o, it’s not needed.</li><li>Do not forget to enable Docker in <code>systemd</code> so it’s launched when you’re VM is started</li><li>Do not forget to disable swap<ul><li><code>swapoff -a</code></li><li>edit your <code>/etc/fstab</code> to comment out the swap line</li></ul></li><li>You have to configure Docker to use the systemd cgroup and restart it, here’s my <code>/etc/docker/daemon.json</code>:</li></ul><div><pre><code data-lang="json"><span>{</span>
        <span>"dns"</span><span>:</span> <span>[</span><span>"8.8.8.8"</span><span>,</span> <span>"8.8.4.4"</span><span>],</span>
        <span>"exec-opts"</span><span>:</span> <span>[</span><span>"native.cgroupdriver=systemd"</span><span>],</span>
        <span>"log-driver"</span><span>:</span> <span>"json-file"</span><span>,</span>
        <span>"log-opts"</span><span>:</span> <span>{</span>
                <span>"max-size"</span><span>:</span> <span>"100m"</span>
        <span>},</span>
        <span>"storage-driver"</span><span>:</span> <span>"overlay2"</span>
<span>}</span>
</code></pre></div><ul><li>You have to reconfigure <code>containerd.io</code> so that it will use systemd cgroup<ul><li>reconfigure <code>containerd.io</code> with defaults, as root:</li></ul></li></ul><div><pre><code data-lang="shell">containerd config default &gt; /etc/containerd/config.toml
</code></pre></div><ul><li>then edit the <code>/etc/containerd/config.toml</code> file and change <code>systemd_cgroup = false</code> to <code>systemd_cgroup = true</code></li><li>restart <code>containerd.io</code>:</li></ul><div><pre><code data-lang="shell">systemctl restart containerd
</code></pre></div><ul><li>You should create a <code>/etc/sysctl.d/k8s.conf</code>, with these values:</li></ul><div><pre><code data-lang="text">net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
</code></pre></div><ul><li>and reload sysctl with:</li></ul><ul><li>If you do not care about default values, you can initialize the control-plane mode with just: <code>sudo kubeadm init</code></li><li>I’ve install Calico as the Network Pod, since I don’t know a thing for now about the pod network, I’ve installed the first one, also it seems to be tested with <code>e2e</code>, which seems to be CNCF standards.</li><li>Skip <code>Joining nodes</code> if you do not plane to install many nodes.</li><li>At this point, you should have a single control-plane cluster installed.</li><li>If you want to <code>kubectl run</code> images, you will need to untaint the master:</li></ul><div><pre><code data-lang="shell">kubectl taint nodes --all node-role.kubernetes.io/master-
</code></pre></div><h2 id="the-end-is-the-beginning">The end is the beginning…</h2><p>So here we are at the end of this post, thank you if you’ve read me up until now. My feelings are that Docker is easy to install, it’s really well integrated with Linux, even if I prefer FreeBSD. Also, Kubernetes is really nice, I’m just peeling the onion slowly.</p><p>At this point, I’ve already tried 2 (3 in fact…) other products installations with Kubernetes:</p><ul><li><a href="https://github.com/kubernetes/dashboard">Kubernetes Dashboard</a>: This one is nice to have a Web UI to watch what’s in your Kubernetes cluser</li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-kubernetes-monitoring-stack-with-prometheus-grafana-and-alertmanager-on-digitalocean">How To Set Up a Kubernetes Monitoring Stack with Prometheus, Grafana and Alertmanager on DigitalOcean</a>: And this one, although it’s about DigitalOcean Kubernetes… I’ve managed to install in my Kubernetes cluster, that was a lot of searching and testing because they are using DigitalOcean Kubernetes capabilities such as creating DO Block Storage. To that end, I had to install a <a href="https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner">Static provisioner of local volumes</a> (the 3rd product 😋), and a Kubernetes Storage Class that would mimics at least the <code>do-block-storage</code> storage class in a very “simple” way.</li></ul><p>Clearly, that was a lot of time invested, but I’m quite happy since I’ve discovered and learnt quite some informations. I’m really well aware that it’s a lot of informations to handle, but if you’ve got some time to kill, it’s really worth the trip.</p><p>Eye Candy:
<a href="https://yom.iaelu.net/Screenshot-2020-05-31-20-59-35.png"><img src="https://yom.iaelu.net/Screenshot-2020-05-31-20-59-35.png" alt="kubectl get all -A"></a></p></article></div></div></div></div>]]>
            </description>
            <link>https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378236</guid>
            <pubDate>Thu, 10 Dec 2020 20:34:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deploy an Alexa Skill and Get an Echo]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378078">thread link</a>) | @rolldeez
<br/>
December 10, 2020 | https://www.stackery.io/blog/reinvent-alexa-quiz-challenge | <a href="https://web.archive.org/web/*/https://www.stackery.io/blog/reinvent-alexa-quiz-challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We are excited to announce that if you <strong>deploy our AWS Trivia Alexa Skill from Stackery</strong>  we will send you $100 AWS credits and an Amazon Echo!</p>
<h2>Details</h2>
<ol>
<li>Build an Alexa Skill (tutorial below)using Stackery to deploy into your AWS account.</li>
<li>You can deploy the code as-is out of Stackery, or modify the content of the quiz.</li>
<li><a href="https://twitter.com/stackeryio">Tweet us</a> a screenshot of your deployed backend. It'll look something like this:</li>
</ol>
<p><img src="https://media.graphcms.com/AB6B8KcTGKPiTL4gqi99" alt="alexa1.png"></p>
<h2>Q&amp;A</h2>
<h4>What is an Alexa Skill?</h4>
<p>A Skill is a voice app that can be opened on an Alexa-enabled device, such as a smart speaker, a smart home device that's Alexa-enabled, a smartwatch.</p>
<h4>What does this Skill do?</h4>
<p>This Skill asks users questions about AWS services, such as Lambda, Cognito or EC2, in a 10-question quiz game. It also gives users facts about certain AWS services.</p>
<h4>Do I need to be an AWS expert to follow this tutorial?</h4>
<p>Nope! Stackery makes it easy for <em>anyone</em> to deploy serverless apps on AWS, and adding infrastructure is as simple as dragging and dropping! You just need an AWS account, a modern browser, and a computer connected to the Internet.</p>
<h4>Do I need a lot of programming experience to follow this tutorial?</h4>
<p>No! If you can copy-paste, you can build and deploy this app. If you want to customize the quiz, you will need to know basic JavaScript.</p>
<h4>Do I need an Alexa-enabled device to test my Skill?</h4>
<p>No. The Alexa developer console includes an in-browser Alexa simulator for testing.</p>
<h4>What does it cost?</h4>
<p>Everything should fit easily within AWS's free tier, and the AWS account and Amazon Developer account are free.</p>
<h4>Can I make Alexa speak in a sarcastic tone?</h4>
<p>Sadly, no (believe me, I tried). But there are some cool things you can do with <a href="https://developer.amazon.com/en-US/docs/alexa/custom-skills/speech-synthesis-markup-language-ssml-reference.html">SSML</a>, the markup language used to dictate how Alexa generates phrases.</p>
<h4>Resources</h4>
<ul>
<li><a href="https://developer.amazon.com/en-US/docs/alexa/ask-overviews/build-skills-with-the-alexa-skills-kit.html">Alexa Developer docs</a></li>
<li><a href="https://github.com/alexa/skill-sample-nodejs-quiz-game">Skill sample</a></li>
<li><a href="https://github.com/stackery/alexa-reinvent-quiz">Git repo</a></li>
</ul>
<h2>Tutorial</h2>
<h4>Prerequisites:</h4>
<ol>
<li><a href="https://developer.amazon.com/en-US/alexa/alexa-skills-kit">Free Amazon Developer account</a></li>
<li><a href="https://stackery.io/sign-up">Free Stackery Account </a></li>
</ol>
<h3>1. Create an Alexa Skill</h3>
<ol>
<li>Log in to the <a href="https://developer.amazon.com/alexa/console/ask">Alexa Developer Console</a>, and click the <strong>Create Skill</strong> button</li>
<li>Name your skill whatever you'd like</li>
<li>Choose <strong>Custom</strong> as your model</li>
<li>Choose <strong>Provision your own</strong> as the method to host your skill's backend resources</li>
<li>Scroll back up, make sure everything looks right, and click <strong>Create skill</strong></li>
</ol>
<p>You'll now see your newly-created skill in a list of all skills:</p>
<p><img src="https://media.graphcms.com/XNpSqCP6SlGhz2Nq1Yh5" alt="alexa2.png"></p>
<ol start="6">
<li>Click on the skill name, and navigate to <strong>Interaction Model</strong> -&gt; <strong>JSON editor</strong></li>
</ol>
<p>This is where you will paste a JSON file that describes the different forms of interactions your Skill will have with users, as well as the custom data that serves as the allowable answers to quiz questions.</p>
<ol start="7">
<li>Copy the entire contents of <a href="https://raw.githubusercontent.com/stackery/alexa-reinvent-quiz/master/src/models/en-US.json">this JSON file</a> from our <a href="https://github.com/stackery/alexa-reinvent-quiz">alexa-reinvent-quiz repo</a></li>
<li>Paste the copied contents into the Alexa JSON editor, then click <strong>Save Model</strong> at the top, followed by <strong>Build Model</strong></li>
</ol>
<p><img src="https://media.graphcms.com/6AXcts9JREKAOzGB68Ts" alt="alexa3.png"></p>
<p>Once you save, you will see that your Intents were auto-populated. Feel free to poke around and view the sample utterances and <a href="https://developer.amazon.com/en-US/docs/alexa/custom-skills/slot-type-reference.html">slot types</a> that are there now. When you're done, return to the main console where all of your skills are listed, as you'll need to get your Skill ID in a few moments, so be sure to leave this browser tab open.</p>
<h3>2. Build your backend in Stackery</h3>
<p><em>For this step you'll need a <a href="https://www.stackery.io/sign-up/">free Stackery account</a>, a Git provider, and a code editor. If you're a first-time Stackery user, you'll need to link your Git provider and AWS account the first time you commit and deploy a stack. Don't worry, the process is fairly quick and simple and the app will walk you through it.</em></p>
<ol>
<li>In a new tab, log in to Stackery, and create a new stack with a new repo</li>
</ol>
<p><img src="https://media.graphcms.com/AfJ27NQSjmRwqGjrlWL8" alt="alexa-step1.gif"></p>
<ol start="2">
<li>In the Visual edit mode, add a function and give it the name <code>AlexaHandler</code> and change its code source directory to <code>src/AlexaHandler</code>. Scroll down and hit <strong>Save</strong></li>
</ol>
<p><img src="https://media.graphcms.com/aH74Msn0QDOMZ1AzVGpk" alt="alexa-step2.gif"></p>
<ol start="4">
<li>Flip to the Template edit mode, and add the following YAML as part of the <code>Properties</code> of your <code>AlexaHandler</code> function:
<deckgo-highlight-code terminal="carbon" theme="one-light" language="yaml">
                    <code slot="code">   Events:
     AlexaSkillEvent:
       Type: AlexaSkill
       SkillId: [your-skill-id]
</code>
        </deckgo-highlight-code></li>
<li>Replace <code>[your-skill-id]</code> with the <code>Skill ID</code> you noted above<sup>1</sup></li>
</ol>
<p>This is what allows your Lambda function to be accessed by the specific skill you are building, and not any other.</p>
<p>Your template should look now something like this:</p>
<deckgo-highlight-code terminal="carbon" theme="one-light" language="yaml">
                    <code slot="code">AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Resources:
  AlexaHandler:
    Type: AWS::Serverless::Function
    Properties:
      FunctionName: !Sub ${AWS::StackName}-AlexaHandler
      ...
      Policies:
        - AWSXrayWriteOnlyAccess
      Events:
        AlexaSkillEvent:
          Type: AlexaSkill
          SkillId: amzn1.ask.skill.some-long-numbers-and-letters
Parameters:
  ...
</code>
        </deckgo-highlight-code><p>If you want to double-check your formatting, you can refer to our <a href="https://github.com/stackery/alexa-reinvent-quiz/blob/master/template.yaml">SAM template</a> in the tutorial repo.</p>
<ol start="8">
<li>If everything looks right, click the <strong>Commit...</strong> button to commit your changes to your Git repository</li>
<li>Follow the repo link below the stack name to access your newly-created repository</li>
</ol>
<p><img src="https://media.graphcms.com/p6X5aC2jQcqDDmuQyjcQ" alt="alexa4.png"></p>
<ol start="10">
<li>Clone your repo to your computer and open it in your favorite (or least-favorite, we're not particular) IDE</li>
</ol>
<h3>3. Add function code</h3>
<p>When you created a function in Stackery, it stubbed out some function code for you in the chosen runtime, which is Node 12 in this case. We're going to replace the function code with the Alexa backend from the <a href="https://github.com/stackery/alexa-reinvent-quiz/">tutorial repo</a>, as well as its <code>package.json</code> contents to add the required dependencies.</p>
<ol>
<li>Open <code>your-repo/src/AlexaHandler/index.js</code> and replace its contents with the contents of <a href="https://raw.githubusercontent.com/stackery/alexa-reinvent-quiz/master/src/AlexaHandler/index.js">Stackery's Alexa Skill code</a>. Save the file</li>
<li>Open <code>your-repo/src/AlexaHandler/package.json</code> and replace its contents with the following and save:</li>
</ol>
<deckgo-highlight-code terminal="carbon" theme="one-light" language="javascript">
                    <code slot="code">{
  "name": "alexahandler",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "author": "Stackery",
  "license": "MIT",
  "devDependencies": {
    "aws-sdk": "^2.796.0"
  },
  "dependencies": {
    "ask-sdk-core": "^2.9.0",
    "ask-sdk-model": "^1.34.1"
  }
}
</code>
        </deckgo-highlight-code><ol start="3">
<li>Commit the changes and push to your Git repo</li>
</ol>
<p>If you kept your Stackery tab open, you'll have noticed that it detected the changes you pushed up. Go ahead and hit the refresh link:</p>
<p><img src="https://media.graphcms.com/kV2cc64TQ2XcWfsWT1f6" alt="alexa5.png"></p>
<h3>4. Deploy to AWS</h3>
<ol>
<li>In the Stackery app, navigate to the <strong>Deploy</strong> tab</li>
<li>Select an environment to deploy to (if this is your first time deploying with Stackery, you'll be guided through linking to AWS first). Click <strong>Prepare new deployment</strong> and then <strong>Prepare Deployment</strong> to start your deployment</li>
</ol>
<p><img src="https://media.graphcms.com/rQ8rAzWASfG0eKVF3Fd4" alt="alexa-step3.gif"></p>
<ol start="3">
<li>Once the deployment is prepared (which will take about a minute), click <strong>Deploy</strong>. A tab will open in your AWS Console, where you'll need to click <strong>Execute</strong> to kick off the deployment<sup>2</sup></li>
</ol>
<p><img src="https://media.graphcms.com/GEnQASVcTrqah2nExmAf" alt="alexa-step4.gif"></p>
<p>This will take a few minutes - get yourself a coffee and a pat on the back, because you're 90% done with deploying your first Alexa Skill!</p>
<ol start="4">
<li>You'll get a notification when your stack has deployed. Click the <strong>View</strong> tab to see your live stack</li>
<li>Grab your screenshot for Twitter!</li>
<li>Double-click the <code>AlexaHandler</code> function to pull up some handy data and links.</li>
<li>Copy the function's ARN, as you'll need it for the final step</li>
</ol>
<p><img src="https://media.graphcms.com/N2pitl1jQwe6gs28hxmY" alt="alexa-step5.gif"></p>
<h3>5. Connect your backend to your Skill</h3>
<p>This is it: the final stage, when we connect all the dots and test our Alexa Skill!</p>
<ol>
<li>Back in the Amazon Developer Console, select <strong>Endpoint</strong> from the menu</li>
<li>Enter the ARN you copied in the previous step like so:</li>
</ol>
<p><img src="https://media.graphcms.com/oWHUCWAYQeLTiyXCeFx1" alt="alexa6.png"></p>
<ol start="3">
<li>Click <strong>Save Endpoints</strong></li>
</ol>
<p>Now you're ready to test your Skill! Navigate to <strong>Test</strong>, and say or type "Start Stackery re:Invent Quiz" to kick off the quiz. You can try the quiz yourself, or get some trivia information about specific AWS services. Knock yourself out - this is the fun part!</p>
<p><img src="https://media.graphcms.com/0JO6s23ZRjqStQh6y42u" alt="alexa7.png"></p>
<p>Return to the Stackery Dashboard, notice that your function was successfully invoked while you were testing!</p>
<p><img src="https://media.graphcms.com/Xl8eDGDQRy7TSQCCrxdd" alt="alexa8.png"></p>
<h2>Next steps</h2>
<p>Hopefully, this tutorial piqued your interests in building Alexa Skills. With a Lambda backend, you can build skills in just about any runtime, and Stackery helps you deploy changes quickly (and automatically with our <a href="https://docs.stackery.io/docs/using-stackery/dashboard#deployment-pipeline">Deployment Pipelines</a>).<br>
I'd love to see what you build - feel free to send your projects <a href="https://twitter.com/annaspies">my way on Twitter</a>, and  don't forget to send your deployed stack to <a href="https://twitter.com/stackeryio">Stackery on Twitter</a>.</p>
<p><em><sup>1</sup> For the sake of this tutorial, we are hard-coding the Skill ID. <strong>If you are saving your Skill ID directly in the template, make sure your repo is private.</strong> Alternatively, you can use Stackery's <a href="https://docs.stackery.io/docs/using-stackery/environments#setting-parameter-store-values">Environments and Parameter Store</a> to follow best practices and store your Skill ID as in AWS's <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html">Systems Manager Parameter Store</a> and reference it at build time.</em></p>
<p><em><sup>2</sup> This tutorial walks you through deploying manually in the browser, but there are other ways to deploy that will likely suit your workflow better. You can deploy with the <a href="https://docs.stackery.io/docs/using-stackery/cli">Stackery CLI</a> with just one command, or completely automate this process upon a merge to the repo's main branch, including automated test runs, with Stackery's <a href="https://docs.stackery.io/docs/using-stackery/dashboard#deployment-pipeline">Deployment Pipelines</a>.</em></p>
</div></div>]]>
            </description>
            <link>https://www.stackery.io/blog/reinvent-alexa-quiz-challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378078</guid>
            <pubDate>Thu, 10 Dec 2020 20:22:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving River Crossing Puzzles with MiniZinc]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378057">thread link</a>) | @rsas
<br/>
December 10, 2020 | https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/ | <a href="https://web.archive.org/web/*/https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>The objective of river crossing puzzles is to bring items from one river bank to the other in the fewest possible steps.
One prominent puzzle is the <strong>wolf, goat and cabbage problem</strong>.
From Wikipedia:</p>
<blockquote>
<p>“Once upon a time a farmer went to a market and purchased a wolf, a goat, and a cabbage.
On his way home, the farmer came to the bank of a river and rented a boat.
But crossing the river by boat, the farmer could carry only himself and a single one of his purchases: the wolf, the goat, or the cabbage.
If left unattended together, the wolf would eat the goat, or the goat would eat the cabbage.</p>
</blockquote>
<blockquote>
<p>The farmer’s challenge was to carry himself and his purchases to the far bank of the river, leaving each purchase intact. How did he do it?”</p>
</blockquote>
<h3 id="minizinc">MiniZinc</h3>
<p><a href="https://www.minizinc.org/">MiniZinc</a> is a high-level constraint modeling language.
It allows you to model optimization and constraint satisfaction problems.
In the backend, one is free to choose from a wide range of solvers.</p>
<h3 id="structure-of-minizinc-models">Structure of MiniZinc Models</h3>
<p>A MiniZinc model consists of <em>parameters</em>, <em>decision variables</em>, <em>constraints</em>, <em>objective</em>, and <em>output</em>.
They all can be specified in any order.</p>
<h4 id="parameters">Parameters</h4>
<p>Parameters define the concrete inputs for the model.
In our river crossing puzzle, the parameters can be defined as follows:</p>
<div><pre><code data-lang="minizinc"><span>enum</span> <span>PASSENGER</span> <span>=</span> <span>{</span><span>Farmer</span><span>,</span> <span>Wolf</span><span>,</span> <span>Goat</span><span>,</span> <span>Cabbage</span><span>};</span>
<span>enum</span> <span>LOC</span> <span>=</span> <span>{</span><span>bankA</span><span>,</span> <span>bankB</span><span>};</span>

<span>int</span><span>:</span> <span>maxstep</span> <span>=</span> <span>10</span><span>;</span>
<span>set</span> <span>of</span> <span>int</span><span>:</span> <span>STEP0</span> <span>=</span> <span>0</span><span>..</span><span>maxstep</span><span>;</span>
<span>set</span> <span>of</span> <span>int</span><span>:</span> <span>STEP</span> <span>=</span> <span>1</span><span>..</span><span>maxstep</span><span>;</span>
</code></pre></div><p>Apart from the enumerations, the only parameter in this puzzle is <code>maxstep</code>.
It is always a good idea to specify some upper bound for the search space during modeling.
<code>STEP0</code> and <code>STEP1</code> are two helper arrays.
We will need these later.</p>
<h4 id="decision-variables">Decision Variables</h4>
<p>A decision variable represents the unknown solution space.
In our puzzle, we are looking for the farmer’s concrete steps to carry the purchases to the far bank of the river.
In MiniZinc, we can use arrays or <code>var</code> variables to represent the unknown locations at each step:</p>
<div><pre><code data-lang="minizinc"><span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>farmerLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>wolfLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>goatLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>cabbageLoc</span><span>;</span>

<span>% Helper type: two-dimensional array of the unknown locations.
</span><span></span><span>array</span><span>[</span><span>PASSENGER</span><span>,</span> <span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>loc</span> <span>=</span>
    <span>array2d</span><span>(</span><span>PASSENGER</span><span>,</span> <span>STEP0</span><span>,</span>
            <span>farmerLoc</span> <span>++</span> <span>wolfLoc</span> <span>++</span> <span>goatLoc</span> <span>++</span> <span>cabbageLoc</span><span>);</span>

<span>var</span> <span>STEP</span><span>:</span> <span>end</span><span>;</span>
</code></pre></div><p>The <code>end</code> variable represents the unknown number of steps to solve the puzzle.</p>
<h4 id="constraints">Constraints</h4>
<p>The constraints define the restrictions on the decision variables:</p>
<blockquote>
<p>“the farmer could carry only himself and a single one of his purchases: the wolf, the goat, or the cabbage. If left unattended together, the wolf would eat the goat, or the goat would eat the cabbage.”</p>
</blockquote>
<p>Modeling constraints is the most challenging (and fun) part of MiniZinc.
Fortunately, you can use established techniques for modeling common problems.
In the following, we will constrain the farmer’s locations and his purchases at each step to represent the boat crossing the river.</p>
<div><pre><code data-lang="minizinc"><span>% The farmer arrives at the river with his purchases.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>)(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>0</span><span>]</span> <span>=</span> <span>bankA</span><span>);</span>
<span>% The farmer crosses the river with his purchases after end steps.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>,</span> <span>s</span> <span>in</span> <span>STEP</span> <span>where</span> <span>s</span> <span>&gt;=</span> <span>end</span><span>)</span>
                 <span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>]</span> <span>=</span> <span>bankB</span><span>);</span>
<span>constraint</span> <span>end</span> <span>&lt;=</span> <span>maxstep</span><span>;</span>
</code></pre></div><p>How should we model the crossing of the river?
We can simply iterate over the <code>loc</code> array and constrain the previous and the next location of the farmer and his items.
To avoid code duplication, we can create a <em>predicate</em>.</p>
<div><pre><code data-lang="minizinc"><span>% If the location of a passenger changes from one river bank
</span><span>% to the other, so should change the location of the farmer too.
</span><span>% Note that STEP is 1..maxtep allowing us to access s-1.
</span><span></span><span>predicate</span> <span>passenger_moves</span><span>(</span><span>var</span> <span>PASSENGER</span><span>:</span> <span>p</span><span>,</span> <span>var</span> <span>STEP</span><span>:</span> <span>s</span><span>)</span> <span>=</span>
    <span>let</span> <span>{</span> <span>var</span> <span>LOC</span><span>:</span> <span>farmer_last_pos</span> <span>=</span> <span>loc</span><span>[</span><span>Farmer</span><span>,</span><span>s</span><span>-</span><span>1</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>farmer_new_pos</span> <span>=</span> <span>loc</span><span>[</span><span>Farmer</span><span>,</span><span>s</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>last_pos</span> <span>=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>-</span><span>1</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>new_pos</span> <span>=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>];</span> <span>}</span> <span>in</span>
          <span>last_pos</span> <span>!=</span> <span>new_pos</span>
          <span>-&gt;</span>
          <span>farmer_last_pos</span> <span>=</span> <span>last_pos</span> <span>/\</span> <span>farmer_new_pos</span> <span>=</span> <span>new_pos</span><span>;</span>
<span>% Constrain all passengers (farmer and his purchases).
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>,</span> <span>s</span> <span>in</span> <span>STEP</span><span>)(</span><span>passenger_moves</span><span>(</span><span>p</span><span>,</span> <span>s</span><span>));</span>
</code></pre></div><p>Done!
Let’s finish by adding the two remaining constraints.</p>
<div><pre><code data-lang="minizinc"><span>% Never leave the wolf with the goat or the goat with the cabbage alone.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>s</span> <span>in</span> <span>STEP</span><span>)</span>
                 <span>(</span><span>wolfLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>goatLoc</span><span>[</span><span>s</span><span>]</span> <span>\/</span> <span>goatLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>cabbageLoc</span><span>[</span><span>s</span><span>]</span> 
                  <span>-&gt;</span>
                  <span>farmerLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>goatLoc</span><span>[</span><span>s</span><span>]);</span>

<span>% The farmer can carry only himself and a single one of his purchases.
</span><span>% If the location of the farmer changes, at most one purchase can
</span><span>% change its location as well.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>s</span> <span>in</span> <span>STEP</span><span>)</span>
                 <span>(</span><span>farmerLoc</span><span>[</span><span>s</span><span>-</span><span>1</span><span>]</span> <span>!=</span> <span>farmerLoc</span><span>[</span><span>s</span><span>]</span>
                  <span>-&gt;</span>
                  <span>sum</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>p</span> <span>!=</span> <span>Farmer</span><span>)</span>
                     <span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>-</span><span>1</span><span>]</span> <span>!=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span>
                  <span>&lt;=</span> <span>1</span><span>);</span>
</code></pre></div><h4 id="objective">Objective</h4>
<p>The objective function can be either constraint satisfaction or minimization/maximization of the decision variables.
We are looking for the least number of steps to cross the river.</p>
<h4 id="output">Output</h4>
<p>Printing custom output of the solution is optional and a bit tricky.
There are built-in MiniZinc functions for that, and together with the support of emojis, we can craft the explanation of the solution found by MiniZinc.</p>
<div><pre><code data-lang="minizinc"><span>% Our emojis.
</span><span></span><span>array</span><span>[</span><span>PASSENGER</span><span>]</span> <span>of</span> <span>string</span><span>:</span> <span>emoji</span> <span>=</span> <span>[</span><span>"👨‍🌾"</span><span>,</span><span>"🐺"</span><span>,</span><span>"🐐"</span><span>,</span><span>"🥬"</span><span>]</span> <span>::</span><span>output_only</span><span>;</span>

<span>output</span>
<span>[</span> <span>"Step \(s): "</span> <span>++</span> <span>% step prefix
</span><span></span>  <span>show</span><span>([</span> <span>emoji</span><span>[</span><span>p</span><span>]</span> <span>|</span> <span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>fix</span><span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span> <span>=</span> <span>bankA</span> <span>])</span> <span>++</span>
  <span>" &lt;-&gt; "</span> <span>++</span>
  <span>show</span><span>([</span> <span>emoji</span><span>[</span><span>p</span><span>]</span> <span>|</span> <span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>fix</span><span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span> <span>=</span> <span>bankB</span> <span>])</span> <span>++</span>
  <span>"\n"</span>
  <span>|</span> <span>s</span> <span>in</span> <span>1</span><span>..</span><span>fix</span><span>(</span><span>end</span><span>)</span> <span>];</span> <span>% generator
</span></code></pre></div><p>It’s time to put the pieces together and run our model.
Assuming you have MiniZinc available in your <code>PATH</code>, pass the model file to the executable.</p>
<div><pre><code data-lang="plain">$ minizinc --version
MiniZinc to FlatZinc converter, version 2.5.3, build 220798393
Copyright (C) 2014-2020 Monash University, NICTA, Data61

$ time minizinc farmer-wolf-goat-cabbage.mzn
Step 1: ["🐺", "🥬"] &lt;-&gt; ["🧑🏻‍🌾", "🐐"]
Step 2: ["🧑🏻‍🌾", "🐺", "🥬"] &lt;-&gt; ["🐐"]
Step 3: ["🥬"] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🐐"]
Step 4: ["🧑🏻‍🌾", "🐐", "🥬"] &lt;-&gt; ["🐺"]
Step 5: ["🐐"] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🥬"]
Step 6: ["🧑🏻‍🌾", "🐐"] &lt;-&gt; ["🐺", "🥬"]
Step 7: [] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🐐", "🥬"]
----------
==========

real	0m0.850s
user	0m0.072s
sys	0m0.059s
</code></pre></div><p>We need 7 steps to cross the river, and this is provably the minimal solution!
<a href="https://github.com/rsas/minizinc-examples/blob/main/farmer-wolf-goat-cabbage.mzn">Grab the model from GitHub</a> and try it yourself.</p>
<h3 id="conclusion">Conclusion</h3>
<p>This post was inspired by the <a href="https://www.youtube.com/watch?v=kiX1FOw1GUU">MiniZinc tutorial of Lucas DiCioccio</a>.
There are many ways to model this problem.
I used the techniques from the two MiniZinc courses available in Coursera, <a href="https://www.coursera.org/learn/basic-modeling">Basic Modeling for Discrete Optimization</a> and <a href="https://www.coursera.org/learn/advanced-modeling">Advanced Modeling for Discrete Optimization</a>, which I highly recommend.</p>
</article>

        </div></div>]]>
            </description>
            <link>https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378057</guid>
            <pubDate>Thu, 10 Dec 2020 20:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tee in Haskell using streaming-bytestring]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377939">thread link</a>) | @anardil
<br/>
December 10, 2020 | https://anardil.net/2020/haskell-coreutils-tee.html | <a href="https://web.archive.org/web/*/https://anardil.net/2020/haskell-coreutils-tee.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>I've implemented some <a href="https://github.com/Gandalf-/coreutils">Unix core utilities in Haskell</a>, and want to start a series of
posts going through the details - starting with simple programs like <code>cat</code>,
<code>seq</code>, and <code>which</code>, and then moving on towards more featureful programs like
<code>uniq</code>, <code>tr</code> and maybe <code>grep</code>.</p>
<p>You can find the full source from this post
<a href="https://github.com/Gandalf-/coreutils/blob/master/Coreutils/Tee.hs">here</a>.
Let's implement <code>tee</code> in Haskell!</p>

<p>What does <code>tee</code> do? From the man page, "read from standard input and write to
standard output and files". Seems simple enough; <code>tee</code> is like <code>cat</code> except
that it additionally writes whatever passes between <code>stdin</code> and <code>stdout</code> to any
number of files along the way. Like the majority of coreutils, this is done in
a streaming fashion for performance and to reduce memory usage. It's
unacceptable, for instance, to read all of stdin, then write it to stdout and
each output file in turn. We need to <em>stream</em> the data to each output, or sink,
as it becomes available.</p>

<p>Let's sketch out the program in types to see what we need. We'll use this as a
reference for each section below:</p>
<div><pre><span></span><span>teeMain</span> <span>::</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ parse arguments with defaults, look for errors, call runTee</span>

<span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ open handles for each filepath according to provided options, call tee</span>

<span>tee</span> <span>::</span> <span>[</span><span>Handle</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ read from stdin, write to each provided handle and stdout</span>
</pre></div>
<p>Let's work our way top down, starting with argument parsing, then down to
our runtime, and lastly the business logic.</p>

<p>Our main concern is streaming data, for which Haskell has a couple libraries.
We'll be using <code>streaming</code> and <code>streaming-bytestring</code> which provide
<code>Data.ByteString.Streaming</code>. ByteStrings are the way to go since <code>tee</code> must
behave itself with binary input, and besides we don't need to concern ourselves
with the content of stdin means to move it around. <code>System.Console.GetOpt</code> will
handle argument parsing, while the other <code>System</code> and <code>Control</code> libraries
provide some basics: <code>bracket</code>, <code>unless</code>, <code>die</code>, <code>openBinaryFile</code>, open flags,
and <code>Handle</code>. We'll see how these are each used in the following sections.</p>
<div><pre><span></span><span>module</span> <span>Coreutils.Tee</span> <span>where</span>

<span>import</span>           <span>Control.Exception</span>
<span>import</span>           <span>Control.Monad</span>
<span>import</span> <span>qualified</span> <span>Data.ByteString.Streaming</span> <span>as</span> <span>Q</span>
<span>import</span>           <span>System.Console.GetOpt</span>
<span>import</span>           <span>System.Exit</span>
<span>import</span>           <span>System.IO</span>
</pre></div>

<p>BSD <code>tee</code> has just two options</p>
<ul>
<li><code>-a</code> to append to output files rather than overwriting them</li>
<li><code>-i</code> to ignore SIGINT</li>
</ul>
<p>GNU tee has some more options related to error path behavior, but let's ignore
those and BSD's <code>-i</code> for the time being. This leaves us with three things to do
in our argument parsing:</p>
<ul>
<li>look for help flags to show usage</li>
<li>look for <code>-a</code> or <code>--append</code> to indicate append mode for writing</li>
<li>collect everything else as output file names</li>
</ul>
<p><code>System.Console.GetOpt</code> provides a simple pattern to describe this exactly, we
provide a data type describing our options (in this case, just one), the
defaults, and some help text and it'll figure out the details internally.</p>
<div><pre><span></span><span>newtype</span> <span>Options</span> <span>=</span> <span>Options</span> <span>{</span> <span>optMode</span> <span>::</span> <span>IOMode</span> <span>}</span>

<span>defaults</span> <span>::</span> <span>Options</span>
<span>defaults</span> <span>=</span> <span>Options</span> <span>{</span> <span>optMode</span> <span>=</span> <span>WriteMode</span> <span>}</span>

<span>options</span> <span>::</span> <span>[</span><span>OptDescr</span> <span>(</span><span>Options</span> <span>-&gt;</span> <span>Either</span> <span>String</span> <span>Options</span><span>)]</span>
<span>options</span> <span>=</span>
    <span>[</span> <span>Option</span> <span>"a"</span> <span>[</span><span>"append"</span><span>]</span>
        <span>(</span><span>NoArg</span>
            <span>(</span><span>\</span><span>opt</span> <span>-&gt;</span> <span>Right</span> <span>opt</span> <span>{</span> <span>optMode</span> <span>=</span> <span>AppendMode</span> <span>}))</span>
        <span>"append to given files, do not overwrite"</span>

    <span>,</span> <span>Option</span> <span>"h"</span> <span>[</span><span>"help"</span><span>]</span>
        <span>(</span><span>NoArg</span>
            <span>(</span><span>\</span><span>_</span> <span>-&gt;</span> <span>Left</span> <span>$</span> <span>usageInfo</span> <span>"tee"</span> <span>options</span><span>))</span>
        <span>"show this help text"</span>
    <span>]</span>
</pre></div>
<p><code>getOpt</code> automatically tracks which arguments aren't parsed and provides those
separately, perfect for our usecase. Let's plug this all together in our pseudo
main function.</p>
<div><pre><span></span><span>teeMain</span> <span>::</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>teeMain</span> <span>args</span> <span>=</span> <span>do</span>
        <span>unless</span> <span>(</span><span>null</span> <span>errors</span><span>)</span> <span>$</span>
            <span>die</span> <span>$</span> <span>unlines</span> <span>errors</span>

        <span>either</span> <span>die</span> <span>(`</span><span>runTee</span><span>`</span> <span>filenames</span><span>)</span> <span>$</span>
            <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span> <span>opts</span>
    <span>where</span>
        <span>(</span><span>opts</span><span>,</span> <span>filenames</span><span>,</span> <span>errors</span><span>)</span> <span>=</span> <span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>args</span>
</pre></div>
<p>The real driver here is:</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>getOpt</span>
<span>getOpt</span>
  <span>::</span> <span>ArgOrder</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>OptDescr</span> <span>a</span><span>]</span> <span>-&gt;</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>([</span><span>a</span><span>],</span> <span>[</span><span>String</span><span>],</span> <span>[</span><span>String</span><span>])</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>someArgs</span> <span>=</span> <span>[</span><span>"-a"</span><span>,</span> <span>"out.txt"</span><span>]</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>someArgs</span>
<span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>someArgs</span>
  <span>::</span> <span>([</span><span>Options</span> <span>-&gt;</span> <span>Either</span> <span>String</span> <span>Options</span><span>],</span> <span>[</span><span>String</span><span>],</span> <span>[</span><span>String</span><span>])</span>
</pre></div>
<p>where <code>options</code> describes the flags we're looking to parse, and <code>args</code> are the
command line arguments, as per <code>System.Environment.getArgs</code>. Once parsed, we
check for errors, apply defaults with <code>foldM (flip id) defaults opts</code>, and run.
The <code>foldM</code> has a bit going on, let's break that down by specializing the
arguments one at a time.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span>
<span>foldM</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>(</span><span>b</span> <span>-&gt;</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>b</span> <span>-&gt;</span> <span>t</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>b</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span>
<span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>b</span> <span>-&gt;</span> <span>t</span> <span>(</span><span>b</span> <span>-&gt;</span> <span>m</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>m</span> <span>b</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span>
<span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>t</span> <span>(</span><span>Options</span> <span>-&gt;</span> <span>m</span> <span>Options</span><span>)</span> <span>-&gt;</span> <span>m</span> <span>Options</span>
</pre></div>
<p>What about <code>opts</code>? We can see the types align with <code>getOpt</code>'s first tuple if
our Foldable is a list and Monad is Either. This makes sense from a higher
level too; we have multiple "combine-able" operations (parsing flags) that can
succeed (provide an <code>Option</code>) or fail (provide a <code>String</code> error message). All
together, this executes the parsing functions <code>opts</code> in turn to build an
<code>Either String Options</code>, filling in the blanks with our defaults as necessary.</p>
<p>When we're all done, we have <code>Options</code> and a list of everything else not parsed
which we can use as the list of output filenames.</p>

<p>Let's take a look back and see what we're supposed to do next.</p>
<div><pre><span></span><span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ open handles for each filepath according to provided options, call tee</span>
</pre></div>
<p>So we have our options and filenames, and need to convert those into handles to
call the next layer. To properly manage our resources (these handles), we need
to close them too. Breaking these steps out in a <code>do</code> block would work most of
the time, but would leak if we hit an exception. On Linux, this isn't such a
big deal - the process exiting will close all the handles. However on Windows
(which we can support for free thanks to Haskell's IO libraries), not closing
the handles can mean that data doesn't get written. To that point, Haskell uses
exceptions to communicate IO errors, the exact type of errors we're likely to
encounter opening and writing to files. Luckily, <code>bracket</code> is perfect for this
situation; let's check it out.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>bracket</span>
<span>bracket</span> <span>::</span> <span>IO</span> <span>a</span> <span>-&gt;</span> <span>(</span><span>a</span> <span>-&gt;</span> <span>IO</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>(</span><span>a</span> <span>-&gt;</span> <span>IO</span> <span>c</span><span>)</span> <span>-&gt;</span> <span>IO</span> <span>c</span>
</pre></div>
<p>Provided some IO computation that produces resources, a function that uses
those resources, and a function that releases those resources, <code>bracket</code> will
run everything together, ensuring that the resources are released even if
there's an exception while they're being used.</p>
<div><pre><span></span><span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>runTee</span> <span>o</span> <span>fs</span> <span>=</span>
        <span>bracket</span> <span>acquire</span> <span>release</span> <span>tee</span>
    <span>where</span>
        <span>acquire</span> <span>=</span> <span>mapM</span> <span>(`</span><span>openBinaryFile</span><span>`</span> <span>optMode</span> <span>o</span><span>)</span> <span>fs</span>
        <span>release</span> <span>=</span> <span>mapM_</span> <span>hClose</span>
</pre></div>
<p>Pretty easy!</p>

<p>So now we have our collection of handles, time to use them to do some real
work. Let's see it all together, then break it down.</p>
<div><pre><span></span><span>tee</span> <span>::</span> <span>[</span><span>Handle</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- build up n computations that copy the stream and write it a file</span>
<span>tee</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>foldr</span> <span>(</span><span>\</span><span>h</span> <span>-&gt;</span> <span>Q</span><span>.</span><span>toHandle</span> <span>h</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
</pre></div>
<p><code>Data.ByteString.Streaming</code> usage works right to left, where the right side is
the source of the stream, and the left side is the sink, where the data ends
up. The space between is where we can mutate the stream. The simplest <code>tee</code> is
with no files, in which it's just a simplified <code>cat</code> that only reads from
<code>stdin</code>. To describe that with these streams, that'd be:</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>cat</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>Q</span><span>.</span><span>stdin</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>cat</span>
<span>cat</span> <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>m</span> <span>()</span>
</pre></div>
<p>Take everything from stdin and stream it to stdout. For our purposes, <code>m</code> is
<code>IO</code>, nothing else is needed here. We can specialize our types to see this
ourselves, and that we're going to fit into the prototype we sketched out
initially for <code>tee</code>.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>cat</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>Q</span><span>.</span><span>stdin</span> <span>::</span> <span>IO</span> <span>()</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>cat</span>
<span>cat</span> <span>::</span> <span>IO</span> <span>()</span>
</pre></div>
<p>Now, for writing streams to handles we have <code>Q.toHandle</code>, but this has a
problem - it acts like a sink, consuming all of the input stream. This won't
work, since the input from <code>stdin</code> will never make it to <code>stdout</code>. We can't
read the stream twice either; for a file we could read everything twice, it
would just be wasteful, but for <code>stdin</code> it's not possible - the data only
exists once.</p>
<p>The library has something for us though: <code>Q.copy</code> forks a stream, allowing you
to do two separate, independent computations on it. Internally, this is
essentially sending the chunks that make up the input stream two different
places, creating two streams from one.</p>
<p>Let's build up a <code>cat</code> the preserves the input stream beyond writing to stdout
rather than consuming it.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>copy</span>
<span>Q</span><span>.</span><span>copy</span>
  <span>::</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>(</span><span>Q</span><span>.</span><span>ByteString</span> <span>m</span><span>)</span> <span>r</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>copy</span> <span>Q</span><span>.</span><span>stdin</span>
<span>Q</span><span>.</span><span>copy</span> <span>Q</span><span>.</span><span>stdin</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span>
     <span>Q</span><span>.</span><span>ByteString</span> <span>(</span><span>Q</span><span>.</span><span>ByteString</span> <span>m</span><span>)</span> <span>()</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>(</span><span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
<span>(</span><span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>()</span>
</pre></div>
<p>While we're here thinking about stdout, let's note that <code>Q.stdout</code> isn't doing
anything magical compared to <code>Q.tohandle</code>, just sparing us some typing. This is
useful, because it let's us treat stdout as "just another output", the same as
the handles we're creating.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>toHandle</span> <span>stdout</span>
<span>Q</span><span>.</span><span>toHandle</span> <span>stdout</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>m</span> <span>r</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>stdout</span>
<span>Q</span><span>.</span><span>stdout</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>m</span> <span>r</span>
</pre></div>
<p>With our stream copying ability, we can create a waterfall of streams! stdin to
the first handle + new stream 1, new stream 1 to the second handle + new stream
2, and so on until the last stream, which just goes to stdout.</p>
<p>Good old <code>foldr</code> matches this pattern well; take some initial value, run a
computation on it with the first input to produce an output, then use that as
the new initial value for the second input value, and so on.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>T…</span></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anardil.net/2020/haskell-coreutils-tee.html">https://anardil.net/2020/haskell-coreutils-tee.html</a></em></p>]]>
            </description>
            <link>https://anardil.net/2020/haskell-coreutils-tee.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377939</guid>
            <pubDate>Thu, 10 Dec 2020 20:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick guide to the security features of euro banknotes [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377645">thread link</a>) | @dt3ft
<br/>
December 10, 2020 | https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf | <a href="https://web.archive.org/web/*/https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377645</guid>
            <pubDate>Thu, 10 Dec 2020 19:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Non-Dilutive Funding for SaaS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377563">thread link</a>) | @tacon
<br/>
December 10, 2020 | https://www.trypaper.io/funders | <a href="https://web.archive.org/web/*/https://www.trypaper.io/funders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.trypaper.io/funders</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377563</guid>
            <pubDate>Thu, 10 Dec 2020 19:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning about Elixir's generic server processes with a real-world example]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377107">thread link</a>) | @areichert
<br/>
December 10, 2020 | https://papercups.io/blog/genserver | <a href="https://web.archive.org/web/*/https://papercups.io/blog/genserver">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/genserver</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377107</guid>
            <pubDate>Thu, 10 Dec 2020 19:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Take on RSS]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25376849">thread link</a>) | @jacobobryant
<br/>
December 10, 2020 | https://findka.com/blog/new-take-on-rss/ | <a href="https://web.archive.org/web/*/https://findka.com/blog/new-take-on-rss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Findka now includes an RSS aggregator.</p><p><img src="https://findka.com/img/subscriptions-example.png" alt="Example of subscribing to RSS feeds on Findka"></p><p>If you subscribe to any feeds, then 50% of the articles in your regular Findka
emails will be sampled from those feeds.
I added this because, <a href="https://findka.com/blog/2020-12-05/">as I mentioned</a>,
I'm going to start doing more manual curation to make sure that Findka has a
steady stream of new, great essays. I also think it's a valuable feature for
anyone who wants a little more control over their Findka recommendations.</p><p>How's this different from existing RSS aggregators? For one thing, since this
is built into Findka, any articles that you like will start to be recommended
to other users, too. But there's more.</p><p>Most RSS aggregators keep your feeds separate. Findka instead merges them into
a single feed using a bandit algorithm. If you've subscribed to three
feeds—A, B and C—Findka will start out picking articles from the
feeds uniformly. 1/3 of the articles will come from feed A, etc. As time goes
on, Findka will adjust the distribution based on your usage data. If you never
click on articles from feed A and you always click on articles from feed B,
then Findka will show you fewer articles from A and more articles from B.</p><p>On top of that, the number of articles in your feed is controlled by you, not
by the feeds you subscribe to.</p><p><img src="https://findka.com/img/frequency-setting.png" alt="Example of subscribing to RSS feeds on Findka"></p><p>The result is that using RSS now takes extremely little effort. You get a
single, small feed that improves itself automatically.</p><p>I'm planning to add more RSS-related features—stay tuned.</p></div></div>]]>
            </description>
            <link>https://findka.com/blog/new-take-on-rss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376849</guid>
            <pubDate>Thu, 10 Dec 2020 18:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Blog from Emacs via magit-forge backed by GitHub issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25376755">thread link</a>) | @sgrove
<br/>
December 10, 2020 | https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues | <a href="https://web.archive.org/web/*/https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><a href="https://twitter.com/sgrove"><p><img alt="Sean Grove" src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly9hdmF0YXJzMy5naXRodWJ1c2VyY29udGVudC5jb20vdS8zNTI5Nj9zPTk2JnU9OTc1M2U1MmU2NjRkYmEyYWI4M2IyYzA4YjlhNmNjOTBhNWNhYzdiYiZ2PTQ"></p></a></div></div><p><span><p>So @dwwoelfel and I have been working on a powerful blogging system that keeps all of your data inside of GitHub issues - you can see the result (and post yourself) live on <a href="https://essay.dev/">essay.dev</a> - or you can fork the open-source repo and deploy your instance, and all the instructions below will work just fine on your own repo.</p><h4 id="watch-me-create-a-blog-post-from-inside-magit-forge">Watch me create a blog post from inside magit-forge</h4><p><iframe title="https://www.youtube.com/watch?v=VVOd1yOKVqQ" type="text/html" width="100%" height="360" src="https://www.youtube.com/embed/VVOd1yOKVqQ" frameborder="0"></iframe></p><h3 id="github-issue-powered-blogging-and-commenting">GitHub-issue powered blogging and commenting</h3><p>The entire site is powered by GitHub issues and next.js (and hosted on Vercel). Any issue with a <code>Publish</code> tag will be made publicly available immediately (and can be similarly unpublished by removing the <code>Publish</code> label).</p><p>That's pretty fantastic for lots of reasons - your posts are now in an API that's easy to slice and dice so there's no lock-in to your content or comments, it's a familiar place for devs to work, etc.</p><p>There are hundreds of features and polish in essay.dev, but importantly for me, it's compatible with emacs' <code>magit-forge</code>!</p><h3 id="magit-forge-i-choose-you"><code>magit-forge</code>, I choose you!</h3><p><code>magit</code> is the famous git control system for emacs, and it has an equally powerful integration to manage GitHub issues called <code>magit-forge</code>.</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwMzI3LTgyNTg3ZDAwLTM1NWQtMTFlYi04MmFiLTQwZTI0MGZlYWY3Ni5wbmc" alt="Preview of reading a rich post on `essay.dev` in `magit-forge`"></span></p><p>You can do all the normal CRUD operations on GitHub issues inside a familiar emacs workflow - which means we can do the same for our posts<sup>1</sup>!</p><h3 id="creating-a-post-on-essaydev">Creating a post on essay.dev</h3><p>First make sure you've installed <a href="https://magit.vc/"><code>magit</code></a> and <a href="https://magit.vc/manual/forge.html"><code>magit-forge</code></a> (or for spacemacs users, just add the <a href="https://develop.spacemacs.org/layers/+source-control/github/README.html"><code>GitHub layer</code></a>).</p><p>Now, let's clone the <code>essay.dev</code> repo:</p><div><pre><code><span>git clone https://github.com/OneGraph/essay.dev.git</span>
<span>cd essay.dev</span>
<span>emacs README.md</span></code></pre></div><p>Next we'll connect <code>forge</code> with our GitHub repository via <code>M-x forge-add-repository</code> - and now we're ready to see a list of all of the posts, so run <code>M-x forge-list-issues</code>:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwMDkxLTMxNDg4OTAwLTM1NWQtMTFlYi05MDgyLTMzYzMxYzQ3NmFiMy5wbmc" alt="`magit-forge` listing posts on `essay.dev`"></span></p><p>If we hit <kbd>Enter</kbd> on any of the issues, we'll see the content and the comments:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwNDM2LWE2YjQ1OTgwLTM1NWQtMTFlYi04ZDUzLTQ5Y2JhMTBhMmNlYy5wbmc" alt="Look at this excellent post - we'll have to up our game from now on"></span></p><h4 id="create-a-new-post">Create a new post</h4><p>Running <code>M-x forge-create-issue</code> will create a new buffer pre-filled via the default <code>new-post</code> template:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwODYxLTJhNmU0NjAwLTM1NWUtMTFlYi04YTU0LTczNmE0ZDExOWYyYS5wbmc" alt="We're ready to write our next great post"></span></p><p>Simply fill out the title and the body, and when you're ready, "commit" the new post via <code>C-c C-c</code>. Forge will commit it to a local database first for safe-keeping, and then create an issue on GitHub! Back in the <code>*forge-issue-list...*</code> buffer, hit <kbd>g</kbd> to refresh the lists of posts, with your newest one at the top. Hit <kbd>Enter</kbd> on it to view the contents.</p><h4 id="your-post-is-ready">Your post is ready!</h4><p>A few seconds later, run <code>M-x forge-pull</code> to update your local copy - you should find there's a new comment waiting for you from <code>onegraph-bot</code>:</p><span><blockquote><p>View your post at https://<username></username>.essay.dev/post/<issue-number></issue-number>/<issue-title></issue-title></p></blockquote></span><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwOTE3LTQyZGU2MDgwLTM1NWUtMTFlYi05ODAwLWFmM2M3MTFhYjY5MC5wbmc" alt="Our post is all grown up and ready for the world"></span></p><p>That's it, your post is available to the world.</p><p>You can also leave comments on your posts (and others) with <code>M-x forge-create-post</code>:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgxMDUwLTY5MDQwMDgwLTM1NWUtMTFlYi04ODU2LTUzNzRkMGE1NjRiOC5wbmc" alt="Why leave emacs to leave a comment?"></span></p><p>It'll show up instantly on your post (both in forge and on the site):</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgxMTE4LTdmMTFjMTAwLTM1NWUtMTFlYi05M2ZkLWMzMDJiOGYyNGNiZC5wbmc" alt="Thanks to the API-based backend (and some clever engineering), posts and comments show up everywhere seamlessly"></span></p><h3 id="whats-next">What's next?</h3><p>Your content belongs to you, and is easily accessible through the GitHub API - here's an example query that'll pull out the posts for you:</p><div><pre><code><span>query</span><span> MyPostsOnGitHub(</span>
<span>  $owner: String = </span><span>"onegraph"</span>
<span>  $name: String = </span><span>"essay.dev"</span>
<span>  $createdBy: String = </span><span>"sgrove"</span>
<span>) {</span>
<span>  gitHub {</span>
<span>    repository(name: $name, owner: $owner) {</span>
<span>      issues(</span>
<span>        first: </span><span>10</span>
<span>        orderBy: { </span><span>field</span><span>: CREATED_AT, </span><span>direction</span><span>: DESC }</span>
<span>        filterBy: { </span><span>createdBy</span><span>: $createdBy }</span>
<span>      ) {</span>
<span>        edges {</span>
<span>          node {</span>
<span>            body</span>
<span>            number</span>
<span>            title</span>
<span>          }</span>
<span>        }</span>
<span>      }</span>
<span>    }</span>
<span>  }</span>
<span>}</span></code></pre></div><p>Try it out <a href="https://www.onegraph.com/graphiql?shortenedId=R8KXQM&amp;snippetKey=JavaScript%3Areact-apollo">here</a></p><p>And again, note that this setup will work with any repo, so if you want to self-host your content it's as easy as using the <a href="https://vercel.com/new/git/external?repository-url=https%3A%2F%2Fgithub.com%2FOneGraph%2Foneblog%2Ftree%2Fnext&amp;env=NEXT_PUBLIC_ONEGRAPH_APP_ID,NEXT_PUBLIC_TITLE,OG_GITHUB_TOKEN,OG_DASHBOARD_ACCESS_TOKEN,VERCEL_URL,VERCEL_GITHUB_ORG,VERCEL_GITHUB_REPO&amp;envDescription=Variables%20needed%20to%20build%20your%20OneBlog&amp;envLink=https%3A%2F%2Fgithub.com%2FOneGraph%2Foneblog%2Ftree%2Fnext%23environment-variables&amp;project-name=oneblog&amp;repo-name=oneblog">deploy on vercel</a> link.</p></span></p></div></div>]]>
            </description>
            <link>https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376755</guid>
            <pubDate>Thu, 10 Dec 2020 18:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Docker to Manage Your Test Database(s)]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25376621">thread link</a>) | @craigkerstiens
<br/>
December 10, 2020 | https://www.tonic.ai/post/using-docker-to-manage-your-test-database | <a href="https://web.archive.org/web/*/https://www.tonic.ai/post/using-docker-to-manage-your-test-database">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-b46f52e7cc86-94242d82"><p><img src="https://uploads-ssl.webflow.com/5f0ae1534d32e5a91598eb9c/5fb81ee39c9c19251287e848_Docker%20for%20Test%20DB.png" loading="lazy" alt=""></p></figure><p><em>TL;DR: Docker is a great tool for packaging and distributing test databases among your team and testing environment. We’ve created </em><a href="https://github.com/TonicAI/docker-testdb" target="_blank"><em>a starter repository</em></a><em> to show these concepts in PostgreSQL and MySQL </em><a href="https://github.com/TonicAI/docker-testdb" target="_blank"><em>on Github</em></a><em> if you’d like to dig in immediately while reviewing our process below.</em></p><p>Containers are a valuable resource for us developers. They give you the ability to package your production code, dependencies, and assets into a standardized unit. Once conveniently packaged, running your application in a variety of environments is a breeze. And yet despite containerization’s immense value, we often see teams overlook containers entirely when it comes to managing test databases. At Tonic, whether we’re helping our customers improve testing with high-quality test databases or building our own testing environments, we rely on Docker as a key part of the pipeline. Our customers are finding a lot of value in the approach, so we thought we’d share our strategy.</p><h2>The Trouble With Test Databases</h2><p>Let’s take a look at the typical growth of a test database for a team:</p><ol role="list"><li>You and your team realize that testing in production is a bad idea. You’ve heard about it or you’ve felt the pain yourself: mistakes that lead to data loss and time spent restoring from backups; poor reliability in production due to increased database load; the security team raising their eyebrows at giving too many people access to sensitive data; and the omnipresent anxiety that testing might take down production.</li><li>You decide you need data that’s similar to your production environment, so you write some scripts to generate some fake data (like<a href="https://www.tonic.ai/post/how-to-generate-simple-test-data-with-faker" target="_blank"> faker</a>), use some free or paid services to generate some random data for you (like<a href="https://www.tonic.ai/post/tonic-mockaroo" target="_blank"> Mockaroo</a>), or extract data from production and attempt to anonymize it later (dealing with the mess of maintaining referential integrity).</li><li>You shove either those scripts or data files into your code repo.</li><li>You write in a README the loader command to get it into your database of choice, and like a rite of passage, everyone on the team struggles through getting it to work during onboarding.</li></ol><p>And struggle you will! Databases are notorious for requiring large installations with a multitude of dependencies, navigating arcane configuration, and the extensive work of establishing the test dataset: creating schemas, creating tables, and finally loading your generated data.</p><p>Many teams will have a separate installation process for each operating system their developers use, each of which usually takes a good bit of trial and error after poring over database documentation. Others will set up a staging or test server for their team to use, but it risks becoming out-dated without a regular rebuild, it means a lot of coordination between team members, and there is rarely a one-size-fits-all test environment. For example, when you want to test the scale of your application, your entire team is saddled with a giant database that slows everyone down; likewise, too small of a database can limit effective testing for certain projects.</p><p>Wouldn’t it be great if there were a tool that made it easy to package a database, its dependencies, loader scripts, and its data for any operating system? That any team member could use to easily test their code against a test environment, be it on their local machine or on a quickly spun-up test server in the cloud?</p><h2>Doing Better with Docker</h2><p>Good news, everyone! There is a better way! The many benefits that Docker provides for shipping your code in production work likewise for testing. You can create a database that is easy to distribute, deploy, and reset so that individuals and teams can work effectively without stepping on each other’s toes. For larger organizations, you can even package multiple test databases that each contain different tables or amounts of data, easily available to everyone in your engineering org. Best of all, you don’t need a different local installation README for each operating system—developers can just use the OS they feel most productive in without the headaches of the past.</p><h3>The Basics</h3><p>The simplest way to get started is to use a vanilla database image for your database of choice. By using docker-compose, you can set up the configuration once, and it’s just a<tt> docker-compose up -d </tt>to start the database. Here’s a basic configuration below:</p><h5>version: '3'<br>services:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;testdb_postgres:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image: postgres:12<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;restart: always<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ports:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 5432:5432<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;environment:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_USER: user<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_PASSWORD: password<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_DB: test_data<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;container_name: testdb_postgres<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;volumes:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- /tmp:/tmp<br></h5><p>This configuration does the following:</p><div><ul role="“list”">
<li>Creates a container named<tt> testdb_postgres </tt>that runs off of a PostgreSQL 12 image</li>
<li>Opens up Postgres’ default port of 5432 to 5432 on your host machine</li>
<li>Attaches the<tt> /tmp </tt>folder to your host machine’s<tt> /tmp </tt>folder</li>
<li>Creates a new user with credentials<tt> user/password</tt>, and a new database called<tt> testdb_postgres</tt>.</li></ul></div><p>Right off the bat, we’ve removed a lot of work from the README, and if you have data or data-generating scripts in your repo, you’ve made it much easier to get up and running quickly by simply pointing them to load into the database via the host part. Many databases have official images, including <a href="https://hub.docker.com/_/postgres/" target="_blank">Postgres</a>, <a href="https://hub.docker.com/_/mysql" target="_blank">MySQL</a>, <a href="https://hub.docker.com/_/microsoft-mssql-server" target="_blank">MS SQL Server</a>, <a href="https://hub.docker.com/_/oraclelinux" target="_blank">Oracle</a>, and <a href="https://hub.docker.com/_/mongo" target="_blank">Mongo</a>, among others.</p><h3>Even Better: Packaging Your Data &amp; Scripts with Docker</h3><p>Instead of just using the available database image and calling it a day, you can easily create a new Docker image based off of your database’s official image. Many official images have an entry point folder that allows you to run scripts upon initialization, enabling the container to be immediately useful as soon as it’s up. To do this, you’ll likely need to add a Dockerfile and a build script, and potentially any data import scripts.</p><h4>Dockerfile</h4><p>Making a basic Dockerfile is not hard at all, in fact it’s only two lines:</p><h5>FROM postgres:12<br>COPY sql/*.sql /docker-entrypoint-initdb.d/</h5><p>Here we did the following:<br></p><div><ol role="list">
<li>We started by defining a<tt> Dockerfile </tt>with a<tt> FROM </tt>declaration pointing to the base image of your database.</li>
<li>We copied over all of our data import scripts (defined in a subdirectory named sql) to the<tt> /docker-entrypoint-initdb.d/ </tt>directory. Postgres <a href="https://hub.docker.com/_/postgres/">defines this folder</a> for SQL scripts to be run during initialization.</li>
</ol></div><p>In our <a href="https://github.com/TonicAI/docker-testdb" target="_blank">code repository</a>, you’ll see we’ve commented out additional options to consider for your use case, such as:</p><ul role="list"><li>Adding any additional dependencies, like database extensions or certificates using typical package manager commands.</li><li>Adding data files to an accessible directory for use with data import scripts.</li><li>Adding custom scripts to import data outside of the container, e.g. via S3 or other data storage.</li></ul><h4>Build Script</h4><p>Here we simply create a shell script to make it easier to build the container. Our build.sh contains the following command which merely tags the new container as<tt> testdb_postgres </tt>and specifies the Dockerfile to use.</p><h5>docker build -f Dockerfile -t testdb_postgres .<br></h5><p>If you were building this in a CI environment, we’d recommend giving the tag a unique version for each build and release as a script argument, such as<tt> testdb_postgres:1.0.4</tt>.</p><h4>SQL Scripts</h4><p>Next, you’ll need to create SQL loader scripts that create your schema and load in your data. Typically the easiest way to do this is by using database dump commands with an existing test database. We recommend three scripts: the first one creates your schema without constraints, the second one loads your data, and the third one adds your constraints to all of your tables. This way, you’re able to load your data without worrying about the order in which it’s loaded (which would matter if foreign key constraints were already in place).</p><p>Some databases will turn off constraints using a data import tool until the import is complete, which means you can just keep your constraints in the schema script. For simplicity, in <a href="https://github.com/TonicAI/docker-testdb" target="_blank">our example code</a> we only use two scripts since our data script loads tables in order and doesn’t break referential integrity.</p><p>Sticking with PostgreSQL as our example, you can run the following command to get a dump of your existing schema and constraints:</p><h5>pg_dump -U user -s -f 1_schema.sql [YOUR DATABASE NAME];</h5><p>Followed by a similar command to get just the data:<br></p><h5>pg_dump -U user -a -f 2_data.sql test_data;<br></h5><p>Notably, we’ve added numbers to the beginning of each filename to ensure that the schema script is run before the data load script. (Postgres runs the scripts in this folder in alphabetical order.)</p><p>Take a look at our code to see the full output of both of these files. Feel free to modify these files as you like or write them from scratch, especially if you plan to load your data using a COPY or LOAD command.</p><h4>Modifying your docker-compose.yml</h4><p>Lastly, update the image you’re using to the name of your newly tagged one: image: testdb_postgres. If you’re versioning your container when you build it, we recommend specifying a stable release tag such as<tt> testdb_postgres:stable </tt>so that users can pull the latest update to that tag with<tt> docker-compose pull</tt>.</p><h4>Setting up CI</h4><p>Now you can check your Dockerfile, scripts, and data files into a code repo, and create a build for the Docker container in your CI service of choice using your build script. Any time the scripts or data files are changed, we recommend triggering a new release build for the container and pushing it to your container repository for use by your entire team (of course, after you’ve checked that nothing new caused the build to break 😉).</p><p>If everything is set up, it should be as simple as distributing the docker-compose.yml file to your team and running a<tt> docker-compose up</tt>.</p><h2>Next Level Test Data Management</h2><p>If you’ve followed the steps thus far, you’ll likely find that your testing setup is much more reliable and useful to your entire team, and it’s a big leap forward in efficiency.</p><p>From here, there are a lot of ways …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tonic.ai/post/using-docker-to-manage-your-test-database">https://www.tonic.ai/post/using-docker-to-manage-your-test-database</a></em></p>]]>
            </description>
            <link>https://www.tonic.ai/post/using-docker-to-manage-your-test-database</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376621</guid>
            <pubDate>Thu, 10 Dec 2020 18:19:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mystery illness in India found excessive levels of lead, nickel in blood]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375917">thread link</a>) | @gmays
<br/>
December 10, 2020 | https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Indian health officials have found traces of nickel and lead in a few of the blood samples taken from hundreds of patients who have been hospitalized by a mysterious illness in a southern state, the state government says.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5834017.1607524630!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/india-mystery-illness.jpg"></p></div><figcaption>Health officials and experts in India are investigating a mysterious illness linked to the death of one person and the hospitalization of 585 others. In this photo, taken Tuesday, a patient is assisted out of an ambulance at the district government hospital in Eluru, Andhra Pradesh state. <!-- --> <!-- -->(The Associated Press)</figcaption></figure><p><span><p>Indian health officials have found traces of nickel and lead in a few of the&nbsp;blood samples taken from hundreds of patients who have been hospitalized by a mysterious illness in a southern state, officials said.</p>  <p>The Andhra Pradesh state government said in a statement Tuesday night that investigations by experts from the All India Institute of Medical Sciences have&nbsp;not been able to determine&nbsp;the source of excessive nickel and lead particles in the patients' blood.</p>  <p>The government was still waiting for results of other tests, including toxicology reports and blood cultures, being conducted by experts at the Indian Institute of Chemical Technology, the statement said&nbsp; &nbsp;</p>  <p>Health officials and experts appeared to be baffled&nbsp;by how the heavy metals got into the patients' blood, and whether those metals&nbsp;caused the mysterious illness linked&nbsp;to the death of one person&nbsp;and the hospitalization of&nbsp;more than 585 others.</p>    <p>The illness was first detected Saturday evening in Eluru, an ancient city famous for its handwoven products.</p>  <p>People with the illness started convulsing without any warning, said Geeta Prasadini, a state health official.</p>  <p>Andhra Pradesh Chief Minister Y.S. Jaganmohan Reddy held a virtual meeting Wednesday with officials who included experts from India's top scientific institutes.</p>  <p>Reddy said 502 of the people who went to hospital were&nbsp;discharged after showing improvement.</p>  <h2>No apparent common link</h2>  <p>The patients showed symptoms ranging from nausea and anxiety to loss of consciousness.</p>  <p>What is confounding experts is that there doesn't seem to be any common link among the hundreds of people who have fallen sick.</p>  <p>All of the patients have tested negative for the coronavirus and other viral diseases such as dengue, chikungunya and herpes.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/india-mystery-illness.jpg 300w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/india-mystery-illness.jpg 460w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/india-mystery-illness.jpg 620w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/india-mystery-illness.jpg 780w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/india-mystery-illness.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/india-mystery-illness.jpg"></p></div><figcaption>A man carries a young patient at the district government hospital in Eluru on Monday. About 70 children are among those stricken by the mystery illness.<!-- --> <!-- -->(The Associated Press)</figcaption></figure></span></p>  <p>Those who became ill aren't related to each other and don't all live in the same area. They represent different age groups, including about 70 children, but very few are elderly.</p>  <p>Initially, officials suspected contaminated water. But the chief minister's office confirmed that people who don't use the municipal water supply have also fallen ill, and that initial tests of water samples didn't reveal any harmful chemicals.</p>  <p>A 45-year-old man who goes by the single name Sridhar went to hospital with symptoms resembling epilepsy and died Sunday evening, doctors said. Prasadini said his autopsy didn't shed any light on the cause of death.</p>  <p>Andhra Pradesh state is among those worst-hit by the coronavirus, with over 800,000 detected cases. The health system in the state, like the rest of India, has been frayed by the virus.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375917</guid>
            <pubDate>Thu, 10 Dec 2020 17:19:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double fetches, scheduling algorithms, and onion rings]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25375637">thread link</a>) | @markmossberg
<br/>
December 10, 2020 | https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/ | <a href="https://web.archive.org/web/*/https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most people thought I was crazy for doing this, but I spent the last few months of my gap year working as a short order cook at a family-owned fast-food restaurant. (More on this <a href="https://offlinemark.com/2020/11/12/gap-year-restaurant/">here</a>.) I’m a programmer by trade, so I enjoyed thinking about the restaurant’s systems from a programmer’s point of view. Here’s some thoughts about two such systems.</p>



<h2>Double, triple, and even quadruple fetching</h2>



<p>Human systems, at first glance, can appear broken, but due to subtle human factors, they might actually work just fine.</p>



<p>My best example is the system for taking and fulfilling orders. We never wrote anything down, and would re-ask orders multiples times, including when ringing customers up. (In computer security, this is known as a <a href="https://ctf-wiki.github.io/ctf-wiki/pwn/linux/kernel/double-fetch/">double fetch</a>.) Not great service and can theoretically let customers lie and pay less. </p>



<p>In practice most customers didn’t mind too much, liars are rare, and we can loosely detect when something seems off with an order.</p>



<p>Writing orders down and asking strictly once seems optimal but has subtle flaws. For one thing, there’s not enough space behind the counter for everyone to walk to the written order, so it requires more internal communication. This will fail during a rush when you’re blocked on order details and coworkers are too busy for questions. <strong>Customers are always idle; coworkers aren’t</strong>.</p>



<p>It can increase confusion if order slips aren’t thrown out when orders are finished and is also logistically (and literally) messy if you have greasy gloves and want to avoid touching a pen, then food. Lastly, many of my coworkers were older and very used to the existing system. <strong>A major transition to a new system would have generated more confusion than it’s worth</strong>.</p>



<h2>Scheduling algorithms for the fry cook</h2>



<p>While I covered a range of duties including the cash register, milkshake machine, and grill, I spent the most time on the deep fryer. I’m delighted to present this overanalysis of life as a fry cook, from a programmer’s point of view.</p>



<p>This is what deep fryers look like (<a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.nachi.org%2Fdeep-fryer-inspection.htm&amp;psig=AOvVaw1D90dsceyn1wmU-KOGAEuy&amp;ust=1605391502547000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCNCq-sPDgO0CFQAAAAAdAAAAABAE">source</a>):</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;ssl=1" alt="Deep Fryer" width="360" height="352" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>This picture has 2 fryers, each with 2 baskets that can be submerged to sit in the vats of hot oil below. At work, only 1 fryer would be active on any given day which effectively allows 2 items to be fried at the same time.</p>



<p><strong>Fry cooks have a lot in common with operating systems in that they are both responsible for scheduling</strong>. Operating systems schedule threads to run on a limited number of cores; fry cooks schedule food to be fried in a limited number of fryers. Different food items have different priorities, and different lengths of time to cook.</p>



<p>French fries, curly fries, and onion rings (collectively, “fries”) are the main menu items from the deep fryer. Each fry order could be large or small (except for rings which were only large) and eat-in or to-go. The job of the fry cook is to:</p>



<ul><li>Accept fry orders from the greeter.</li><li>Allocate portions of fries from the big bags of raw fries</li><li>Cook them in the fryers</li><li>Put them into the appropriate eat-in/to-go container</li><li>Serve them onto the customer’s tray on the counter, or their to-go bag</li></ul>



<p>The goal is to do this with maximum speed and accuracy and without dropping orders. You’ll ideally minimize the number of times you ask customers and coworkers for order details. In addition, there are a few sources of complexity to handle:</p>



<ul><li><strong>Incomplete information</strong>: Depending on the greeter, they may forget to specify if it’s eat-in or to-go. You can always ask the customer, but the grill chef will likely ask the same question in a little bit. You might be able to save a customer ask if you can eavesdrop on that interaction.</li><li><strong>Timing requirements</strong>: You need to finish orders by the time the grill chef finishes the burgers/hot dogs, but you shouldn’t finish too early. If you put the fries on the counter way before the burgers are ready, they’ll get cold. This matters less for to-go orders, which you can serve into the bag immediately.</li><li><strong>Scale</strong>: During a rush, you might receive many orders per minute, while only being able to process 1-2 per minute. Once the greeter relays the order, they forget it, so it’s up to you to remember. And remember: no writing things down.</li><li><span><strong>Waste avoidance</strong>: </span>Sometimes you or another cook will make too many fries. To avoid wasting them, you can use the excess towards a future order by refreshing them with a splash later and adding them to a fresh batch.</li><li><strong>Changing orders</strong>: Customers sometimes change their order after you’ve started cooking (e.g. regular fry to curly fry). Now you have to figure out what to do with the partially cooked portion currently in the fryer.</li><li><strong><strong>Misc items</strong></strong>: In addition to fries, there other items that need to be scheduled for time in the fryer, including chicken patties, bacon, clam strips, and fish fillets. </li></ul>



<p>A few techniques to manage all this:</p>



<ul><li><strong>Batching orders together</strong>. If a large and small fry order are in the queue, you can cook them in the same basket at the same time.<ul><li>Some customers request their fries “well done”, meaning cooked extra long. This makes batching more complicated.</li></ul></li><li><strong>“Wait n Splash”</strong>: If a fry order is done cooking far before the rest of the grill items and you don’t have pressing items that need fryer time, you can raise the basket from the oil, but leave the food in it. When the grill items finish, you can quickly splash the food back in the oil to refresh it, then serve it. This will prevent it from getting cold on the counter.</li><li><strong>Inactive fryer baskets</strong>: It can be handy to have extra storage space for cooked food. If you have a “wait n splash” order waiting, but you have more orders to fry, you can use the 2 spare baskets from the inactive fryer to store the waiting order and free up the fryer slot. This is also useful when customers change their order and you need to quickly stash the half cooked portion somewhere and start the adjusted order.</li><li><strong>“The tong dip”</strong>: If both fryers are in use and the grill chef hands you bacon to be urgently cooked, you can hold the bacon in tongs and dip it into one of the submerged baskets. This lets you effectively cook more than 2 things at the same time.</li></ul>



<p>Here’s the system I ended up using. When a new order came in, I’d stop whatever I was doing and grab the appropriate container and place it in the corresponding fry bucket. This captures all 3 pieces of information about the order (fry type, size, to-go?) letting me forget it. If I strictly follow this, I can just process the containers in the buckets like a queue. However, I still need to keep a sense of order memorized because the system doesn’t capture global ordering – if I have containers in the fry, curly fry, and onion ring buckets, I can’t tell which order came in first.</p>



<p>I don’t have a solution for this. On a super busy day, this system falls apart and I drop orders. Extreme load like that has only happened a few times and in that case, I just make large batches, forget about syncing up with the grill items, and hope I don’t have too much excess at the end. Generally, the system worked nicely.</p>



<h2>Conclusion</h2>



<p>It’s fun to think about human systems, like those in a restaurant, from a programmer’s point of view. A fry cook’s job closely resembles that of an operating system scheduler, complete with optimization points and edge cases. One can try to optimize human systems as if they were computer systems, but it’s critical to understand the subtle human aspects of the system when evaluating improvements.</p>



<div><div>
<div><div>
<div><div>
<hr>



<h3>Learn something new? Let me know!</h3>



<p>Did you learn something from this post? I’d love to hear what it was — tweet me <a href="https://twitter.com/offlinemark">@offlinemark</a>! </p>



<p>I also have a mailing list if you want to know when I write new posts:</p>






<hr>
</div></div>
</div></div>
</div></div>
					</div></div>]]>
            </description>
            <link>https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375637</guid>
            <pubDate>Thu, 10 Dec 2020 16:53:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a tool to visualise pathfinding algorithms (Desktop only)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25375391">thread link</a>) | @anthonyatp
<br/>
December 10, 2020 | https://anthonyatp.github.io/pathfinder-visualiser/ | <a href="https://web.archive.org/web/*/https://anthonyatp.github.io/pathfinder-visualiser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://anthonyatp.github.io/pathfinder-visualiser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375391</guid>
            <pubDate>Thu, 10 Dec 2020 16:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Relic to open-source Pixie’s eBPF observability platform]]>
            </title>
            <description>
<![CDATA[
Score 326 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25375170">thread link</a>) | @htroisi
<br/>
December 10, 2020 | https://blog.pixielabs.ai/pixie-new-relic/ | <a href="https://web.archive.org/web/*/https://blog.pixielabs.ai/pixie-new-relic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We are excited to announce that we signed a <a href="http://blog.newrelic.com/product-news/pixie-developer-first-observability" target="_blank" rel="noopener noreferrer">definitive agreement</a> to join New Relic -- an outcome we certainly never predicted after only just two years.</p><p>New Relic’s focus on the developer is legendary. When New Relic's Founder/CEO, Lew Cirne, first started tinkering around with Pixie and participating in our community, we noticed an alignment in our visions for the future of observability, as well as echoes of New Relic’s developer-centric roots in Pixie. Joining New Relic will provide us with an unprecedented opportunity to reach millions of developers faster by open-sourcing a self-managed version of Pixie in the upcoming months.</p><p>When we started Pixie in 2018, Kubernetes was rapidly gaining traction. We felt that a new approach to observability was needed due to the new, fundamental challenges in observing distributed, ephemeral systems. We founded Pixie in order to provide instant, flexible observability for developers like ourselves who were building applications on Kubernetes.</p><p>However, we knew that the most developer-friendly version of Pixie must be open-source. In a forward-looking move, New Relic is giving us the opportunity to open-source Pixie and focus on providing world-class observability to all developers. The developer community is a core element of New Relic’s vision, and Pixie’s open-source offering will be a key part of that initiative and the primary area of focus for the Pixie team going forward.</p><p>We are so excited to begin working with New Relic on our shared vision for the future of observability. In the coming months, we’ll be jointly committing our roadmap in the following initiatives:</p><ul><li><p><strong>Pixie Core</strong>: An open-source and self-managed version of Pixie which we will release to the CNCF sandbox early next year. As part of the process, we look forward to speaking with you about this at Kubecon-EU on May’21. Due to Pixie’s and New Relic’s commitment to open standards, we also plan to build out integrations with OpenTelemetry, Prometheus, and Grafana.</p></li><li><p><strong>Pixie By New Relic</strong>: Our current Pixie Community offering will continue as a hosted version of Pixie Core and existing New Relic One customers will soon get instant access to Pixie data with a few clicks. Their existing experiences will be augmented with the metrics, logs, events, and application traces that Pixie automatically provides.</p></li><li><p><strong>Pixie by New Relic, Enterprise Edition</strong>: Industry-specific solutions for sectors such as Media, Telecommunications, and Government that allow enterprise customers to install Pixie entirely inside production clusters while meeting compliance, data security, support, and performance requirements.</p></li></ul><p>Finally, our journey is just beginning. We are a team of 12 people with a huge vision to reach every Kubernetes developer. As we embark on this part of our journey, we encourage anyone passionate about open source, Kubernetes, and observability to apply to join us <a href="https://pixielabs.ai/careers/" target="_blank" rel="noopener noreferrer">here</a>.</p><p>You can try out Pixie <a href="https://work.withpixie.ai/auth/signup?UTM=PXNR" target="_blank" rel="noopener noreferrer">here</a>, learn more about us <a href="https://pixielabs.ai/" target="_blank" rel="noopener noreferrer">here</a> and ping us anytime on our Pixienaut community slack.</p></div></div></div></div>]]>
            </description>
            <link>https://blog.pixielabs.ai/pixie-new-relic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375170</guid>
            <pubDate>Thu, 10 Dec 2020 16:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A guide to product analytics tools for startups]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25375148">thread link</a>) | @Fission
<br/>
December 10, 2020 | https://satchel.com/web-analytics/ | <a href="https://web.archive.org/web/*/https://satchel.com/web-analytics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content"><div><div><p>Last Updated </p><!-- --><p>May 30, 2020</p></div><div><p>Reading Times:</p><p>Summary only: 1 minute</p></div></div><h2 id="introduction">Introduction</h2><p>Every YC batch, Michael Seibel gives a talk about building product. He'll ask: "<a href="https://youtu.be/C27RVio2rOs?t=1677">How many of you are using Google Analytics as your primary source of metrics?</a>" But it's a trick question. When the majority of the audience eventually raises their hands, he'll fake a sigh and tell everyone that they're doing it wrong, and that they should instead by relying on an event-based analytics tool.<span></span><span>The linked video is from Startup School, but the same talk is given at YC Core as well.</span></p><p>It's a perennial favorite, but don't let the humor distract you. Michael's got a
good point. Without using an event-based analytics tool, which tracks the interactions your users have with your product, you won't know <em>how</em> your
users are using your product. This is arguably just as important as actually
building out the product. There are a lot of event-based analytics tools out
there, but we think that if you're an early-stage startup, Heap makes the best tradeoffs.</p><div><p><a target="_blank" href="https://heap.io/"><img src="https://d33wubrfki0l68.cloudfront.net/b6fae69c970dbd3257184ea4d909f5d858810bdc/35c24/logos/heap.svg"></a></p><div><p>Our Recommendation</p><p><a target="_blank" href="https://heap.io/">Heap</a></p><p>Highest benefit-to-effort ratio</p><p>Gave us auto-tracking functionality, which we think is an exceptionally good safety net for an early-stage startup with rapidly-changing features and limited engineering resources, although it lacks some of the extensibility and more advanced analysis capabilities of its competitors. That said, we think this tradeoff best suits an early-stage startup.</p><p><a target="_blank" href="https://heap.io/">heap.io</a></p></div></div><summary><h2 id="summary">Summary</h2><ul><li>"Setting up event-based metrics is something that's super important very early in your company, because it's how you know whether your product is being used or not. And it's the number one source of new product ideas and inspiration." - Michael Seibel</li><li>Google Analytics by itself is insufficient to figure out how your users are using your product, although it is useful to complement an event-based analytics tool.</li><li>Event-based analytics help you figure out what actions a user took on your website.</li><li>We are primarily focused on evaluating the three main event-based analytics tools: Mixpanel, Amplitude, and Heap.</li><li>We found that event-based analytics is a category of SaaS with some of the most feature parity.</li><li>The core analytics functionality of all three tools is more or less equivalent.</li><li>The key considerations for an early-stage startup are the amount of maintenance and discipline required to maintain useful analytics, and the ability to go far without spending a lot of money.</li><li>We found that defining events in code while having auto-track as a safety net is a near-ideal setup for an early stage startup.</li><li>We recommend Heap, because it is the only major analytics tool that offers this capability. The main downside for an early-stage startup is that you can't get as far on a free plan on Heap compared to Mixpanel or Amplitude.</li><li>If pricing is the main consideration, then we recommend Amplitude. Even though its product is oriented towards later-stage companies, Amplitude has the most generous free plan of the major event-based analytics providers.</li></ul></summary><h2 id="ratings-matrix">Ratings Matrix</h2><h2 id="context">Context</h2><h3 id="what-is-event-based-analytics">What is event-based analytics?</h3><p>Pageview-based analytics tools like Google Analytics and event-based analytics tools such as Mixpanel, Amplitude, and Heap are typically grouped together under the heading of analytics tools. However, we think that lumping them all under the same heading is misleading, because they fundamentally do different things. To better understand what event-based analytics are, we need to understand what exactly Google Analytics does, figure out where its gaps are, and then use that context to motivate event-based analytics tools. </p><p>Google Analytics uses a pageview-driven paradigm, a holdover from what was important in the early 2000s. Its focus on pageviews helps answer questions such as how many users came to your website, what pages they visited, and how they found your website. Unfortunately, it isn't able to help you figure out which specific actions a user performed on any given page of your website. For example, it doesn't answer whether a user clicked on a CTA button, if they abandoned their cart, how far they got into signing up, or what part of the page they were looking at before they converted. Answering these kinds of questions can be quite informative to early-stage startups' decision-making, and can be accomplished quite easily by using an event-based analytics tool.</p><p>An event-based tool will provide two things: an interface to collect "events", and an interface to analyze those events. You can define and implement your events (commonly referred to as instrumenting) by calling the API of the event-based analytics tool you're using.</p><p>To illustrate, let's say you run an ecommerce store. You want to figure out what types of items people checkout without hesitation, and what types of items often result in abandoned carts. This isn't something that can be accomplished with pageview-based analytics tools such as Google Analytics. However, this can be performed quite easily with an event-based analytics tool. If you track two events — when someone adds something to their cart, and when someone checks out their cart — you can figure out which SKUs lead to a high checkout rate, and which SKUs lead to abandoned carts. This is implemented by calling two functions: </p><ol><li><p>a function <code>track('add-to-cart', {&lt;metadata&gt;})</code>, including metadata about the item added (e.g. SKU, name, price) in your code that executes when someone adds something to cart, and </p></li><li><p>a similar function <code>track('checkout', {&lt;metadata&gt;})</code> in your code that runs when someone checkouts. Data from these events will be sent to your analytics provider, which will provide an interface to analyze and draw conclusions from your data.</p></li></ol><p>This is a simple example, but is already quite a powerful tool to understand your users, and can be easily extended. The same power generalizes beyond an ecommerce store to any startup's web product, helping one answer essential questions such as: Is your CTA convincing? What are the characteristics of products that customers are the most hesitant about buying? What part of the signup process needs to be improved to prevent potential users from dropping off? Which portion of your product page was the most engaging and persuaded customers to take the next step?</p><h3 id="early-stage-startups-and-their-analytics-dilemma">Early-stage startups and their analytics dilemma</h3><p>If event-based analytics are so important for early-stage startups, one might rightly wonder why so many YC startups, whose founders are quite sharp in aggregate, rely primarily on Google Analytics?</p><p>It turns out that this is a rather illuminating question. The main contributor to this phenomenon is easy to understand and empathize with. Startups are busy and overworked, and analytics are often ostensibly seen as orthogonal to the priorities of understanding their users and building product<span></span><span>The <a href="https://blog.ycombinator.com/ycs-essential-startup-advice/">canonical priorities</a> for early-stage startups.</span>. Therefore, event-based analytics often fall to the wayside as they typically require engineering time and discipline to maintain. If you forget to update an event, or don't have time to implement analytics for a new feature, then you can't get any benefit out of it at all.</p><p>Yet, in reality, event-based analytics are one of the best sources of new product insights and inspiration and are a fantastic way to understand how your users are using your product. This is one of our main motivations for writing this particular guide. Early-stage startups have a unique set of challenges to face, particularly around prioritizing their time and engineering resources. That said, we think that there's an approach that can make event-based analytics require a lot less discipline, and therefore make it a lot more attainable for an early-stage startup.</p><h2 id="methodology">Methodology</h2><p>Based on a few years of first-hand experience using and testing event-based analytics tools, in addition to aggregating feedback from other founders, we have found the following factors matter most for early-stage startups choosing an analytics tool:</p><ul><li><p><strong>Core Analytics Functionality</strong> refers to the standard analytics features that are critical for an early-stage startup to understand their users. These include standard analysis tools, such as funnel analysis (i.e. figuring out when users drop out in each step of a process), retention analysis (i.e. figuring out how many users churn, and when), and cohort analysis (i.e. figuring out how different user segments interact with your product). </p></li><li><p><strong>Robustness / Ease of Maintenance:</strong> Early-stage startups need to use analytics just as much as larger companies, but also have to be a lot more resourceful and focused with their time and energy. What happens if you change a component, and don't update the tracking code? What happens if you're under time pressure from a customer and make the conscious decision to launch a complex product without tracking? While large companies have the ability to implement strict QA processes and are okay with extended deadlines, early-stage startups don't have these options. Therefore, we've kept a close eye out for how each analytics tool performs under less-than-ideal situations.</p></li><li><p><strong>Affordability:</strong> Web analytics tools are somewhat notable/notorious for giving generous free plans, attaining lock-in, and then making things more expensive once your company starts becoming successful <span></span><span>This is one of the reasons why <a href="#consider-using-segment-as-a-wrapper">we suggest using Segment</a>, since it helps you avoid vendor lock-in and gives you more negotiating power.</span>. That said, several analytics tools have generous free tiers or deals that can last you quite a long time without paying. Therefore, we've split this criterion into two subcriteria: <strong>How far you can get without paying</strong>, and <strong>Paid Plan Affordability</strong>. The latter is actually somewhat non-trivial to evaluate, because most analytics providers hide their pricing behind a Contact Us gate, even for early-stage startups. That said, we got our hands on a decent amount of data on the actual cost of each service, and we have also compiled a list of typical discounts and deals that you can reasonably expect to get from each analytics provider.</p></li><li><p><strong>Ease…</strong></p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://satchel.com/web-analytics/">https://satchel.com/web-analytics/</a></em></p>]]>
            </description>
            <link>https://satchel.com/web-analytics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375148</guid>
            <pubDate>Thu, 10 Dec 2020 16:06:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A typical day as an engineering manager]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375100">thread link</a>) | @karlhughes
<br/>
December 10, 2020 | https://www.karllhughes.com/posts/engineering-manager | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/engineering-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/engineering-manager-time.png" alt="A Day in the Life of an Engineering Manager">
</p> 

<p>
2020, Nov 01&nbsp;&nbsp;&nbsp;—&nbsp;
7 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>During the eight years I spent as an engineering manager, I regularly tracked how I spent my time. As a startup engineering manager, I was responsible for a wide range of duties, so keeping track of which areas I spent the most time on helped me plan and schedule appropriately.</p>
<p>For example, I knew that I typically spent about 1/3rd of my time helping my team solve technical problems or pairing with teammates. Knowing this, I reserved some free blocks of time for them. If my whole week were full of meetings and big-picture planning, I’d become a blocker for my team who needed my input on specific issues.</p>
<p>Since many prospective software engineering managers ask me about my job and what it entails, I decided to create this detailed look at how I spent my time. While every company and role is different, I hope this post gives you some first-hand insight into a day in the life of an engineering manager.</p>
<p><em>Note: If you’re looking for some books to help you on your journey as a software engineering manager, <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some of my favorites</a>.</em></p>
<h2 id="what-does-an-engineering-manager-do">What Does an Engineering Manager Do?</h2>
<p>First, a little bit about my roles as an engineering manager: my first management role was at <a href="https://www.packback.co/">Packback</a>, a question and answer platform for college professors.</p>
<p>I joined the team when there were just four people in the company - it was essentially myself and the founders. In the intervening three years, I saw the company raise close to $5 million and grow to almost 30 people. My engineering team was pretty lean - there were five when I left in 2016 - but my role changed quite a bit over my years with the company.</p>
<p>After <a href="https://www.karllhughes.com/posts/joining-the-graide-network">I left Packback to join The Graide Network</a>, I started over as an engineering manager. Initially, my team was just a contractor and me, but over my four years at Graide, I <a href="https://www.karllhughes.com/posts/hiring-process">hired three other engineers</a> and <a href="https://www.karllhughes.com/posts/product-management-process">took on more of the product management duties</a>.</p>
<p>While my day-to-day work changed a lot over the years, <strong>as a software engineering manager, I was ultimately responsible for helping my team ship software that worked as expected on schedule and within budget.</strong></p>
<p>The tricky word there is “helping.” What does that mean exactly? Does it mean that an engineering manager writes code? Or do they just make sure everyone on their team is writing code?</p>
<p>The short answer is: it depends.</p>
<h3 id="engineering-managers-must-be-technical">Engineering Managers Must be Technical</h3>
<p>Generally, engineering managers write less code than the senior developers on their team, but <a href="https://medium.com/swlh/do-engineering-managers-need-to-write-code-d89903d68e8d">they should write some code to keep their skills sharp</a>. They also need to be good at helping their team members get “unstuck.” Sometimes this means answering technical questions, and sometimes it means solving disputes between team members.</p>
<p>They’re likely to play a role in <a href="https://www.karllhughes.com/posts/developing-talent">training new engineers</a> as well as evaluating candidates on a technical and interpersonal basis.</p>
<h3 id="engineering-managers-have-to-be-good-with-people">Engineering Managers Have to be Good with People</h3>
<p>Being “good with people” is a tough label to nail down.</p>
<p><img src="https://i.imgur.com/e7ML5PR.gif" alt="I have people skills! - Office Space"></p>
<p>Many people assume that you have to be an extrovert to be an effective manager, <a href="https://www.inc.com/john-brandon/are-extroverts-the-best-leaders-maybe-not.html">but that’s not necessarily true</a>. Having empathy for your team and helping them through challenges - both technical and personal - is one of an engineering manager’s primary mandates.</p>
<p>But, engineering managers have to “manage up” as well. This means they need to look out for their team’s best interests when their boss asks them for feedback, and it means they might have to let a team member go if they’re not getting the job done.</p>
<h3 id="the-hardest-part-about-engineering-management">The Hardest Part About Engineering Management</h3>
<p>As I moved into my first management role, the most challenging part was adjusting my method for self-evaluation. Nickolas Means says it well in his <a href="https://leaddev.com/self-care-burnout/learning-love-meta-productivity">fantastic piece on meta productivity for managers</a>:</p>
<blockquote>
<p>“Every so often, I have a day where I look up after the last meeting has ended and feel like I’ve gotten absolutely nothing done. I’ve been busy all day long: having conversations, reading documents, and checking in with peers and team members. I’m exhausted, but I’ve accomplished nothing.” - Nickolas Means</p>
</blockquote>
<p>It was <em>relatively</em> easy for me to tell how productive I had been as a software engineer. I usually made progress on shipping a feature or opened up a pull request, but as a manager, I had a really hard time telling whether my day was productive or not.</p>
<p>That’s why I started tracking my time. While time spent on a task is not a perfect measurement of productivity, it helped me make sure I was investing enough time into each area of my job.</p>
<h2 id="how-does-an-engineering-manager-spend-their-time">How Does an Engineering Manager Spend Their Time?</h2>
<p>Engineering managers tend to have a wide range of responsibilities, and these responsibilities vary based on the employer’s size and organizational structure. To help you see how an engineering manager spends their time, I broke my time down into four categories:</p>
<ul>
<li><strong>Technical</strong> (35%)</li>
<li><strong>Managerial</strong> (35%)</li>
<li><strong>Recruiting</strong> (15%)</li>
<li><strong>Administrative</strong> (15%)</li>
</ul>
<p>In this section, you’ll see how I spent my time as an engineering manager. I’ll offer a little bit about the specific tasks encompassed in each area and why it was an important part of my daily work.</p>
<p>While I tracked my time pretty rigidly for periods of my 8-year management career, I decided to round each category to a nice round number for the sake of simplicity. Exact hours spent on each task aren’t the point here, but I found it helpful to know if one area spiked in one week or dropped sharply in another.</p>
<p><img src="https://i.imgur.com/Tx9pTaz.png" alt="engineering-manager-time"></p>
<h3 id="technical">Technical</h3>
<p><em>35% of my time.</em></p>
<p>Technical work includes writing code, code reviews, hunting down bugs, pairing with teammates, and reading software updates and best practices. As my teams grew, the amount of time I devoted to writing and reviewing code dwindled, but I do think it’s important for engineering managers to spend at least <a href="http://www.drdobbs.com/architecture-and-design/engineering-managers-should-code-30-of-t/240165174">some of their time elbows deep in the code</a>.</p>
<h3 id="managerial">Managerial</h3>
<p><em>35% of my time.</em></p>
<p>This includes direct people management, creating timelines, strategic planning, and meetings with technical and non-technical team members. Making sure my team was happy, advocating for them in business meetings, and helping our product team create technical specs were all part of my engineering manager duties at Packback.</p>
<p>At The Graide Network, I took a more strategic role by consulting with the founders on software choices and jumping in on important sales calls. Interestingly, while the tasks I took on were different, the time breakdown was pretty similar.</p>
<h3 id="recruiting">Recruiting</h3>
<p><em>15% of my time.</em></p>
<p>Recruiting time included going to conferences, meetups, and coding bootcamps, writing blog posts, meeting with job candidates, and evaluating technical screenings.</p>
<p>While I spent more of my time on recruiting when I had an open engineering job, smart engineering managers are <em>always</em> hiring. The best candidates are usually the passive ones who rarely look for a job, so I spent a portion of my time getting in front of them each week.</p>
<h3 id="administrative">Administrative</h3>
<p><em>15% of my time.</em></p>
<p>Finally, I spent a few hours per week reading and writing emails, answering questions in Slack, random conversations, and “other” day-to-day things to support my team. As the manager, I tried to keep these kinds of distractions away from my engineering team, but I’d schedule time with team members when necessary.</p>
<p>If an engineering manager’s job is to make their team as productive as possible, it stands to reason that most of the administrative work will fall to them.</p>
<h2 id="what-makes-a-good-engineering-manager">What Makes a Good Engineering Manager?</h2>
<p>I don’t think I can give you <em>everything</em> you need to know about being a good engineering manager in just one blog post (<a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some good books on the topic though</a>), so I’ll just pick the three things that I focus on first.</p>
<h3 id="1-empower-your-team">1. Empower Your Team</h3>
<p>Being a good manager is all about <a href="http://www.jrothman.com/articles/1999/01/successful-engineering-management-7-lessons-learned/">helping others achieve great things</a>.</p>
<p>This means that as a manager, your <a href="https://leaddev.com/self-care-burnout/learning-love-meta-productivity">impact is much less direct</a>, and therefore, you can’t spend all your time heads down in the code. It was frustrating for me to see my weekly accomplishments list shrink, but once I learned to accept that my team was getting more done without my individual contributions, I started to really enjoy the role.</p>
<h3 id="2-overcommunicate">2. Overcommunicate</h3>
<p>Whether your team is working in one room or working <a href="https://www.karllhughes.com/posts/managing-remote-engineering">remotely across the world</a>, communication is one of your most crucial roles as a manager. In marketing, there’s an idea that <a href="https://www.linkedin.com/pulse/its-nagging-repetition-effective-communication-marton-jojarth/">people must hear your message seven times before they internalize it</a>, and I think this applies to team communication as well.</p>
<p>I’m not saying you should repeat everything seven times in the same meeting, but think about reiterating significant changes in one-on-ones, group settings, via email, and in passing. Change is scary, but the more people hear about something, the less scary it tends to be.</p>
<h3 id="3-be-the-source-of-calm">3. Be the Source of Calm</h3>
<p>Finally, as the engineering manager, your role is to “<a href="https://staysaasy.com/management/2020/07/07/dont-create-chaos.html">vacuum up chaos</a>:”</p>
<blockquote>
<p>“Any room that you enter should have more certainty and a firmer plan by the time that you leave it. Good leaders can walk into a situation where people have lost track of their goals and get everyone aligned on a clear path forward.”</p>
</blockquote>
<p>Don’t create or perpetuate drama, divide your team from the rest of the company, or pit team members against each other. Instead, be the one who absorbs uncertainty and stress so your team can get sh** done.</p>
<hr>
<p>If you’re an aspiring engineering manager or you’re just wondering what your boss does all day, I hope this helps you.</p>
<p>Interested in more great reading material? Here are some of the <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">books that helped me on my journey to become an engineering manager</a>.</p>

<section id="mc_embed_signup">

</section>
</div> 
</article> 
</section></div>]]>
            </description>
            <link>https://www.karllhughes.com/posts/engineering-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375100</guid>
            <pubDate>Thu, 10 Dec 2020 16:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Justice Against a Cable Company: Step-by-Step]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375034">thread link</a>) | @KaiserSanchez
<br/>
December 10, 2020 | https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/ | <a href="https://web.archive.org/web/*/https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
            <section>
                <div>
                    <p><span><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg" alt="" width="500" height="286" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1024x585.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-768x439.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1536x877.jpg 1536w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header.jpg 2022w" sizes="(max-width: 500px) 100vw, 500px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1024x585.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-768x439.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1536x877.jpg 1536w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header.jpg 2022w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">How many times have you heard someone in your life </span><a href="https://fairshake.com/consumer-news/comcast-customer-service-complaint/"><span>complaining about their cable company</span></a><span>?</span></p>
<p><span>Even worse, how many times have </span><i><span>you</span></i><span> been the one complaining about a cable provider?</span></p>
<p><span>Complaints about cable companies might sound like cliches. But cable providers aren’t like the DMV or the post office —&nbsp;services that draw a lot of consumer ire but ultimately tend to be doing their best to get their jobs done. On the contrary, cable companies have actually been </span><a href="https://fairshake.com/consumer-news/comcast-biggest-scams-claim-cash/"><span>caught engaging in a lot of shady behaviors</span></a><span> that fully justify their customers’ complaints.</span></p>
<p><span>But what if you want to take your dispute with your cable company further than your watercooler chat? What do you do if you have a legitimate complaint about your cable company that you need resolved? Where do you go if you need help getting justice against a cable company that’s gone beyond just providing an unpleasant customer service experience —&nbsp;but has actually wronged you?</span></p>
<p><span>These are questions that a lot of consumers have, and we’re here to help. In this article, we’ll discuss some of the common reasons people might want to seek justice against their cable companies. Then, we’ll explain, step-by-step, how to file a complaint against a cable company, and point you toward some resources that will be on your side if you need help getting justice.&nbsp;</span></p>
<h2><span>Why Do So Many People Have Complaints About Their Cable Companies?</span></h2>
<p><span>Let’s start at the beginning: Why do so many people complain about cable companies? And, more importantly, are people complaining about just annoyances, or actual injustices?</span></p>
<p><span>The American Consumer Satisfaction Index </span><a href="https://www.theacsi.org/index.php?option=com_content&amp;view=article&amp;id=148&amp;Itemid=213"><span>surveys consumers</span></a><span> and scores industries based on how well they provide satisfactory services at fair prices. Consistently, year after year, the cable TV industry ranks lowest out of the dozens of industries the ACSI tracks.</span></p>
<p><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg" alt="Graph of American Consumer Satisfaction Index Scores for the Cable TV Industry" width="2022" height="1825" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-300x271.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1024x924.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-768x693.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1536x1386.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-300x271.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1024x924.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-768x693.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1536x1386.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>In 2020, the cable industry has scored </span><a href="https://www.theacsi.org/index.php?option=com_content&amp;view=article&amp;id=149&amp;catid=&amp;Itemid=212&amp;i=Subscription+Television+Service"><span>64 out of 100 points on the ACSI index</span></a><span>, which is actually a 3.2 percent increase over last year. But the industry still has the lowest score in the ACSI rankings, reflecting more dissatisfied customers than ISPs, cell phone providers, online news media, and many other industries that consumers love to complain about. Additionally, this year is the first time since 2016 that the cable industry saw an increase in its ACSI ranking.</span></p>
<p><span>ACSI rankings aren’t even the worst evidence against the cable industry, though.</span></p>
<p><span>News reports reveal that some of what cable companies have been up to goes beyond just bad customer service. For example,</span></p>
<ul>
<li><span>Some AT&amp;T customers found they were </span><a href="https://fairshake.com/consumer-news/att-overcharging-customers-complaints"><span>being charged three times the rate</span></a><span> the company promised them. The situation was so bad, one legal expert called AT&amp;T’s policies “a license to steal.”</span></li>
<li><span>Comcast </span><a href="https://fairshake.com/consumer-news/comcast-biggest-scams-claim-cash"><span>wrongly charged a small business owner $1,800 in cancelation fees</span></a><span>, and then spent </span><i><span>two years</span></i><span> fighting against returning that wronged customer’s money.</span></li>
<li><span>Cox employees were found to be </span><a href="https://wjla.com/features/7-on-your-side/cox-communications-complaints-fake-accounts"><span>creating customer accounts without permission</span></a><span> so they could charge users more.</span></li>
<li><span>Optimum got caught advertising a $99 promotion rate, but </span><a href="https://www.thehour.com/business/article/After-profitable-2017-Altice-USA-hikes-Optimum-12885236.php"><span>actually billed users more than $160 for it</span></a><span>.</span></li>
<li><span>DirecTV </span><a href="https://fairshake.com/consumer-news/feds-sue-direct-tv-claim-money"><span>broke its contracts with 33 million customers</span></a><span> by wrongly raising their rates.</span></li>
</ul>
<p><span>These are just some examples of how cable companies have done shady (or even outright illegal) things to their customers. In all these cases (and any others like them), the customers deserve justice. But it can be difficult to figure out how to get it.</span></p>
<h2><span>How to File a Complaint Against a Cable Company</span></h2>
<p><span>The exact process for filing a complaint might vary from one cable company to the next. For more detailed advice about taking on a specific company, visit our consumer guides.</span></p>
<p><span>But no matter what cable company your dispute is with, there are certain steps you can take to file and escalate your complaint. Here’s what you need to know.</span></p>
<h3><span>Step 1: Contact the Cable Company</span></h3>
<p><span>For anyone who’s suffered through an unproductive customer service call, this probably won’t be welcome news. But any time you have a complaint against a company, before taking it to any outside agencies, you need to try to resolve it with the company itself. This is important, because if you end up escalating your complaint to the FTC, FCC, or a local franchising authority, they’ll expect that you’ve already tried to resolve your dispute with the company directly.</span></p>
<p><span>Some best practices to keep in mind here: Try to address the complaint with your cable company in writing, whenever possible. Email is a great option for this. This ensures that you have a record of exactly what’s said by both parties, and you have proof that you attempted to resolve the complaint directly with the cable company, as well as proof of why that didn’t work.</span></p>
<p><span>If you’ve tried this and your cable company was unable or unwilling to help you reach a resolution, it’s time for step two.</span></p>
<h3><span>Step 2: Find the Right Regulatory Agency</span></h3>
<p><span>If your cable company is unable or unwilling to help you, you can escalate your complaint to a regulatory agency. However, finding the right one can be a challenge.</span></p>
<p><span>Cable companies are overseen by a number of entities: The Federal Communications Commission, the Federal Trade Commission, public utility commissions, and local franchising authorities are the ones that are likely to be most relevant to any dispute you might have. Here’s where this gets complicated: Each of them has different jurisdiction and can only help with certain issues.</span></p>
<p><span>Here’s who you should contact, depending on your complaint.</span></p>
<p><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg" alt="Where to File a Complaint against Your Cable Company" width="1881" height="2560" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg 1881w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-220x300.jpg 220w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-752x1024.jpg 752w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-768x1045.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1129x1536.jpg 1129w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1505x2048.jpg 1505w" sizes="(max-width: 1881px) 100vw, 1881px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg 1881w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-220x300.jpg 220w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-752x1024.jpg 752w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-768x1045.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1129x1536.jpg 1129w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1505x2048.jpg 1505w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<h4><span>Local Franchising Authorities</span></h4>
<p><span>Local franchising authorities are government organizations that regulate cable TV service at a municipal, county, or other local level. You can usually find the name of your local franchising authority on your cable bill. If not, you can contact your cable company or your local town or city hall to request that information.</span></p>
<p><span>Local franchising authorities can help you with these issues:</span></p>
<ul>
<li><span>Rates for basic service and equipment, and service charges related to basic cable.</span></li>
<li><span>Rates for cable service tiers, particularly if rates for your cable service have been increased within the past 90 days.</span></li>
<li><span>Customer service problems, like availability of customer service representatives, office hours, timeliness of service visits, and outages.</span></li>
<li><span>Franchise fees.</span></li>
<li><span>Signal quality.</span></li>
<li><span>Use of public or informational channels that are required as part of your cable company’s franchise agreement.</span></li>
</ul>
<h4><span>Public Utility Commissions</span></h4>
<p><span>In some states, public utility commissions oversee certain issues related to cable or satellite TV services.</span></p>
<p><span>To find out more about your state’s public utility commission, check the </span><a href="https://www.naruc.org/about-naruc/regulatory-commissions/"><span>National Association of Regulatory Utility Commissioners</span></a><span>. If your state has one, PUCs can help you with these issues:</span></p>
<ul>
<li><span>Rates and programming for stand-alone satellite TV services.</span></li>
<li><span>Rates and programming for stand-alone cable TV services (not including basic tier plans).</span></li>
<li><span>Installation of cable or satellite TV services that are not bundled with other services.</span></li>
<li><span>Burial of phone or cable TV wires.</span></li>
</ul>
<h4><span>Federal Communications Commission</span></h4>
<p><span>The FCC is a department of the federal government that exists to regulate businesses and prevent them from taking advantage of or unfairly treating consumers.</span></p>
<p><span>There are a number of ways you can contact the FCC if you have a complaint about a cable company that falls under its jurisdiction. You can visit the </span><a href="https://consumercomplaints.fcc.gov/hc/en-us"><span>FCC Complaint Center</span></a><span> to file your complaint online or get the right information to mail it, or you can call 1-888-225-5322 for information and general questions.&nbsp;</span></p>
<p><span>The FCC can help with these kinds of complaints:</span></p>
<ul>
<li><span>Equal Opportunity Employment complaints.</span></li>
<li><span>Signal leakage that might affect other spectrum users.</span></li>
<li><span>Cable companies that violate rules about home cable wiring.</span></li>
<li><span>Cable companies that violate commercial limits during kids’ programming.</span></li>
<li><span>Indecency or obscenity on a cable TV program.</span></li>
</ul>
<h4><span>Federal Trade Commission</span></h4>
<p><span>And finally, the right entity to receive your complaint might be the FTC, which is another department of the federal government. It has similar goals to the FCC, but oversees different things.&nbsp;</span></p>
<p><span>Also similarly to the FCC, you have a few options for contacting the FTC about your complaint. You can use an </span><a href="https://www.ftccomplaintassistant.gov/"><span>online complaint portal</span></a><span>, or you can reach the agency by phone at 1-877-FTC-HELP.&nbsp;</span></p>
<p><span>Here are some of the types of complaints that would fall under the jurisdiction of the FTC:</span></p>
<ul>
<li><a href="https://fairshake.com/consumer-guides/false-advertising-and-misleading-marketing/"><span>False advertising</span></a><span>.</span></li>
<li><span>Deceptive business practices.</span></li>
<li><span>Scams.</span></li>
<li><span>Problems with debt collection.</span></li>
</ul>
<h2><span>What to Expect After Filing a Complaint Against a Cable Company</span></h2>
<p><span>After filing a complaint with any of the entities listed above, you might be wondering what comes next. The answer, unfortunately, is that it depends.</span></p>
<p><span>Regulatory agencies, particularly at the federal level, will typically investigate a company if they receive complaints about it. If they find that the company did, in fact, do something wrong, they may impose fines or other punishments. But typically, a federal agency like the FTC or the FCC </span><a href="https://fairshake.com/consumer-guides/getting-your-refund/"><span>won’t help you get a refund</span></a><span>, get charges reversed, or get justice in any other, similar way. For that, you have other resources.</span></p>
<h2><span>How to Get Justice Against a Cable Company</span></h2>
<p><span>If resolving your dispute means getting a refund, a zero balance, other compensation, or some other form of justice, you might feel like you have a long, uphill road to climb.</span></p>
<p><span>Most cable companies have clauses built into their contracts that say you can’t sue them, unless it’s in small claims court. But what you can do is </span><a href="https://fairshake.com/how-it-works/"><span>take advantage of consumer arbitration</span></a><span>.</span></p>
<p><span>Arbitration works a little bit like small claims: You’ll send a legal demand to your cable company, and then collect any evidence you have and present it to an independent third party, or arbitrator. The arbitrator will hear both sides of the dispute and make a legally binding decision.</span></p>
<p><span>But even that might sound overwhelming. And if you’ve never been through the process of arbitration before, we don’t blame you if you feel intimidated by the paperwork, the process, or just the thought of taking on a big company with major legal resources.</span></p>
<p><span>So let us help. </span><a href="https://fairshake.com/"><span>Fai…</span></a></p></div></section></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/">https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/</a></em></p>]]>
            </description>
            <link>https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375034</guid>
            <pubDate>Thu, 10 Dec 2020 15:56:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem with Corporate Innovation]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25375013">thread link</a>) | @nicotesla
<br/>
December 10, 2020 | https://blog.codelitt.com/corporate-innovation/ | <a href="https://web.archive.org/web/*/https://blog.codelitt.com/corporate-innovation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
      

      
      <section id="Post__Main-Content">
        <div>
          <h2 id="discovering-the-problem">Discovering the Problem</h2><p>Startups are swallowing corporations' markets. This is mainly because corporations struggle with innovation, regardless of how much they use that word in press releases and PPT presentations. About 7 years ago we started <a href="http://www.codelitt.com/">Codelitt</a>, a corporate skunkworks and product incubator company. We build startups for corporations and invest 20% of our time in building products, tools, and <a href="https://github.com/codelittinc">open source projects</a> for the web. </p><p>In the beginning, we didn't set out to discover a specific problem. Put another way, we weren't being purposeful about searching for a problem to solve. This post is half about the problem with corporate innovation and half about our discovery process that led us to where we are today:</p><h2 id="eye-opening">Eye-opening</h2><p>In the beginning of my career I worked for investors in Latin America helping to build and launch startups before later moving to corporate America. Although I'm often critical of corporate culture, it was really eye opening and integral to my career. Really this is one of the best pieces of advice I can give to entrepreneurs looking for problems to solve:</p><blockquote>If you are smart and ambitious but can't find a problem to solve, go work for a large (preferably traditional) corporation. You'll find plenty there.</blockquote><p>Large enterprises succeed <em>in spite</em> of themselves. It really is a wonder that they get anything done at all. I can't speak for every single large company, but I've worked with quite a few. In one way or another they all have systemic issues. This is not to say that startups or more modern tech companies don't have their own issues. We do. But the proof is in the pudding and startups are launching products monthly that will take a huge chunk of traditional companies' markets or even render them completely irrelevant.</p><p>Some large enterprises have realized that their biggest threat isn't another corporate giant, it's some unknown kid building something. In order to compete, they have to create new value, do a little disruption of their own, and start shipping.</p><blockquote>However, traditional companies spend millions in R&amp;D and take several years to come to market.</blockquote><p>So the question is, why are they at such a disadvantage when their seemingly endless budgets should afford them a solid advantage? The answer is that the same tools, systems, and culture that they rely on to manage their large organization don't work for innovation and skunkworks teams.</p><h2 id="decisions-by-consensus">Decisions by Consensus</h2><p>Traditionally the vast majority make decisions by consensus. Note: there is a difference between collaboration and consensus. Collaboration takes different points into account but can still have one decision maker, whereas consensus decision making requires every single person to have input and be onboard. This is crippling to organizations. Teams should have a single decision maker.</p><p>Any startup who has experienced the sales cycle of a large company can attest to this first hand. While many sales people focus on identifying "the decision maker level," this person is rarely the only decision maker and they'll likely have an entire team to convince. When making a sales pitch (even for a $1,000 a month SaaS product) you'll very likely spend time in a room of 12 or so people from different areas of the company. Most of those people will likely have different needs and agendas. The same is true when it comes to developing new products, processes, or strategy. Decision making time is multiplied by an exponential factor.</p><blockquote>In the time it takes a large organization to make a decision just to move forward with something, a startup could have built, launched, and validated a new feature or model.</blockquote><h2 id="corporate-it">Corporate IT</h2><p>There are a number of reasons why normal innovation processes, product prototyping, and building new business models is so costly inside a large organization. Time is a huge factor. A close second is the cost of actual development. As with everything, I'm sure there are reasons for why things are done the way they are done. But from a product development perspective and coming from the startup world, they are nearly impossible to understand.</p><p>Corporate IT departments have a hard time looking at a product as something that develops. They see a project as having a start date, an end date, and a full set of features. There is no iterative development. They plan for every possible scenario and build to the full spec. Version releases begin with 1.0.0 launch and following releases are security patches at best.</p><p>Instead of using open source tools, large IT teams are locked in to Microsoft and Oracle products. I've never been able to understand why this is completely. It could be the fact that they spend a solid chunk of time earning Oracle or Microsoft Certifications. It could be the comfort of having support just a phone call away. Or it could even be an unwillingness to learn something new. </p><p>From a security perspective, it's like looking for a babysitter to watch your kids, asking for her recommendations, and she tells you, "Just trust me. I promise your child is secure. But just so you know, we'll be doing things my way; your house rules don't apply."</p><p>From a time perspective, there are open source technologies that allow you to whip up an MVP in much less time. Even with complaints about Rail's "magic under the hood," you can't deny that it's a powerful tool to quickly build a prototype.</p><p>From a cost perspective, licenses are expensive and they add up quickly. Millions of dollars are spent on IT licensing every year by large orgs. Imagine if that money was spent on employing core devs for the respective clients like we've seen with Red Hat, Bitpay, and Google.</p><blockquote>Developing a new product or business can often cost millions to develop with the traditional IT infrastructure and business processes. Timelines, again, are measured in years, not weeks.</blockquote><h2 id="risk-averse">Risk-averse</h2><p>The final piece to the puzzle which impedes progress and innovation is often a risk-averse nature. Being risk-averse is 'consultant speak' inside a large organization. Entire teams are dedicated to mitigating risk. I've heard a lot of different theories for why this is from insiders and outsiders over the years:</p><p><strong>Job security</strong> is one that gets floated around a lot. The 25 year Rolex, the benefits, and the cushy salary really don't require a whole lot. Don't upset the status quo, don't argue with the wrong people, play the politics, and work well with others. Do those 4 things and you have very little to worry about. Large companies rarely fire people who do those things. It's easy for anyone to become complacent when basic needs are taken care of. Unfortunately for them however, disruption requires risk. There's always the risk of being wrong. Being wrong is rarely celebrated in corporate culture and that stigma can follow someone around for the rest of their career preventing any sort of upward mobility. In our world, many of us have failed a few times, succeeded a couple, and worked for several companies. Our entire attitude towards failure and opportunity is a completely different perspective.</p><p>Another is the <strong>high visibility</strong> that corporations have in the public eye. Because of their size, most things they do are considered <a href="http://www.mediacollege.com/journalism/news/newsworthy.html">newsworthy</a> due to the impact it could have on their customers, employees, or investors. In the startup world, we have the luxury of being able to fail relatively quietly. Our customers and beta users are usually very understanding of certain degrees of failures to the point they even expect them. Remember those corporate departments dedicated to risk management? These often include legal, public relations, and marketing communications teams. They all have the responsibility to keep the public face of the company as free from blemishes as possible.</p><blockquote>Disruption requires risk. No great invention, change, or innovation ever came from doing the same thing over and over. <a href="https://blog.codelitt.com/not-innovating/">You have to be ready to break things along the way</a>.</blockquote><h2 id="their-disadvantage">Their Disadvantage</h2><p>When you begin to understand the issues that are faced by teams tasked with innovation projects, skunkworks programs, or disrupting old models you can see how simple objectives for us turn into difficult ones for them. While many of us perhaps envy their resources, they're actually at a huge disadvantage to us in every other way. They have a massive problem, one that we set out to solve:</p><blockquote>For them innovation, product development, and skunkworks is expensive, slow, regulated, ineffective, and swimming against the current.</blockquote>
        </div>
      </section>


        <div>
  <h3>Stay up to date!</h3>
  <p>
    Get all the latest &amp; greatest information delivered straight to your inbox
  </p>

  
</div>

    </article>
  </div></div>]]>
            </description>
            <link>https://blog.codelitt.com/corporate-innovation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375013</guid>
            <pubDate>Thu, 10 Dec 2020 15:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CentOS Stream, or Debian?]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25374783">thread link</a>) | @pabs3
<br/>
December 10, 2020 | https://jonathancarter.org/2020/12/10/centos-stream-or-debian/ | <a href="https://web.archive.org/web/*/https://jonathancarter.org/2020/12/10/centos-stream-or-debian/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>It’s the end of CentOS as we know it</strong></p><p>Earlier this week, the CentOS project announced the shift <a href="https://blog.centos.org/2020/12/future-is-centos-stream/">to CentOS stream</a>. In a nutshell, this means that they will discontinue being a close clone of RHEL along with security updates, and instead it will serve as a development branch of RHEL.</p><p>As you can probably imagine (or gleam from the comments in that post I referenced), a lot of people are unhappy about this.</p><p>One particular quote got my attention this morning while catching up on this <a href="https://lwn.net/Articles/838889/">week’s edition of Linux Weekly News</a>, under the distributions quotes section:</p><blockquote><p>I have been doing this for 17 years and CentOS is basically my life’s work. This was (for me personally) a heart wrenching decision. However, i see no other decision as a possibility. If there was, it would have been made.</p><cite><a href="https://lwn.net/Articles/839521/">Johnny Hughes</a></cite></blockquote><p>I feel really sorry for this person and can empathize, I’ve been in similar situations in my life before where I’ve poured all my love and energy into something and then due to some corporate or organisational decisions (and usually poor ones), the project got discontinued and all that work that went into it vanishes into the ether. Also, 17 years is really long to be contributing to any one project so I can imagine that this must have been especially gutting.</p><p><strong>Throw me a freakin’ bone here</strong></p><p>I’m also somewhat skeptical of how successful CentOS Stream will really be in any form of a community project. It seems that Red Hat is expecting that volunteers should contribute to their product development for free, and then when these contributors actually want to use that resulting product, they’re expected to pay a corporate subscription fee to do so. This seems like a very lop-sided relationship to me, and I’m not sure it will be sustainable in the long term. In <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux">Red Hat’s announcement of CentOS Stream</a>, they kind of throw the community a bone by saying “In the first half of 2021, we plan to introduce low- or no-cost programs for a variety of use cases”- it seems likely that this will just be for experimental purposes similar to the <a href="https://insider.windows.com/">Windows Insider program</a> and won’t be of much use for production users at all.</p><p>Red Hat does point out that their <a href="https://developers.redhat.com/products/rhel/ubi">Universal Base Image</a> (UBI) is free to use and that users could just use that on any system in a container, but this doesn’t add much comfort to the individuals and organisations who have contributed huge amounts of time and effort to CentOS over the years who rely on a stable, general-purpose Linux system that can be installed on bare metal.</p><p><strong>Way forward for CentOS users</strong></p><p>Where to from here? I suppose CentOS users could start coughing up for RHEL subscriptions. For many CentOS use cases that won’t make much sense. They could move to another distribution, or fork/restart CentOS. The latter is already happening. One of the original founders of the CentOS project, Gregory Kurtzer, is now working on <a href="https://rockylinux.org/" data-type="URL" data-id="https://rockylinux.org/">Rocky Linux</a>, which aims to be a new free system built from the RHEL sources.</p><p>Some people from Red Hat and Canonical are often a bit surprised or skeptical when I point out to them that binary licenses are also important. This whole saga is yet another data point, but it proves that yet again. If Red Hat had from the beginning released RHEL with free sources and unobfuscated patches,  then none of this would’ve been necessary in the first place. And while I wish Rocky Linux all the success it aims to achieve, I do not think that working for free on a system that ultimately supports Red Hat’s selfish eco-system is really productive or helpful.</p><p>The fact is, Debian is already a free enterprise-scale system already used by huge organisations like Google and many others, which has stable releases, LTS support and ELTS offerings from external organisations if someone really needs it. And while RHEL clones have come and gone through the years, Debian’s <a href="https://www.debian.org/social_contract">mission and contract to its users</a> is something that stays consistent and I believe Debian and its ideals will be around for as long as people need Unixy operating systems to run anywhere (i.e.  a very long time).</p><p>While we sometimes fall short of some of our technical goals in Debian, and while we don’t always agree on everything, we do tend to make great long-term progress, and usually in the right direction. We’ve proved that our method of building a system together is sustainable, that we can do so reliably and timely and that we can collectively support it. From there on it can only get even better when we join forces and work together, because when either individuals or organisations contribute to Debian, they can use the end result for both private or commercial purposes without having to pay any fee or be encumbered by legal gotchas.</p><p>Don’t get caught by greedy corporate motivations that will result in you losing years of your life’s work for absolutely no good reason. Make your time and effort count and either contribute to Debian or give your employees time to do so on company time. Many already do and reap the rewards of this, and don’t look back.</p><p>While Debian is a very container and virtualization friendly system, we’ve managed to remain a good general-purpose operating system that manages to span use cases so vast that I’d have to use a blog post longer than this one just to cover them.</p><p>And while learning a whole new set of package build chain, package manager and new organisational culture and so on can be uhm, really rocky at the start, I’d say that it’s a good investment with Debian and unlikely to be time that you’ll ever felt was wasted. As Debian project leader, I’m personally available to help answer any questions that someone might have if they are interested in coming over to Debian. Feel free to mail leader_AT_debian.org (replace _AT_ with @) or find me on the oftc IRC network with the nick <em>highvoltage</em>. I believe that together, we can make Debian the <em>de facto</em> free enterprise system, and that it would be to the benefit of all its corporate users, instead of tilting <em>all</em> the benefit to just one or two corporations who certainly don’t have your best interests in mind.</p></div></div></div>]]>
            </description>
            <link>https://jonathancarter.org/2020/12/10/centos-stream-or-debian/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374783</guid>
            <pubDate>Thu, 10 Dec 2020 15:36:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One-off scripts: DevOps last mile]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25374731">thread link</a>) | @andriosr
<br/>
December 10, 2020 | https://andrios.co/articles/oneoffs | <a href="https://web.archive.org/web/*/https://andrios.co/articles/oneoffs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Companies chasing DevOps have an internal team dedicated to automation. Developers use tools built by this team to run and operate their code. They have many names, but let’s call them Platform, which most companies do.</p><p>Platform teams create abstractions on top of the infrastructure. The goal is to increase developer speed and make systems reliable. They increase speed by simplifying infrastructure APIs and reliability by automating manual tasks. <strong>Automation lowers the risk of service disruptions, but companies aren’t automating the highest-risk tasks.</strong></p><p><strong>What should we automate?</strong></p><p>We used to ship software by accessing servers and running commands inside boxes to pull new code. Now code goes from Git to servers without human intervention. Developers define what they need with code. Platform teams build the tools to make code changes become running systems.</p><p>The goal is doing this for everything, from business code to infrastructure like networking, databases, and queues. But this is hard. Platform teams have a lengthy backlog; they focus on items demanded with higher frequency.</p><p>Developers make manual changes for things not yet automated. Some companies have compliance, regulations, and other constraints. <strong>It’s hard to get developers direct access to production. So they have the Platform team running these changes for developers.</strong></p><p>It’s what makes the higher frequency items get priority. Engineers want to write software, not run repetitive manual tasks. But this backlog is never decreasing. The business changes and adopts new technologies. Headcount grows, adding new items to the automation backlog. And this mysterious type of task is always left behind.</p><p><strong>One-offs.</strong></p><p>Sometimes a bug in software messes with a customers' money, time, health, or ego. They won’t wait for three iterations of code reviews, tests, code analysis, and gradual rollouts. It takes time. Someone will access the database and update it. These are one-off scripts. <strong>They solve a problem for one or a few customers before the team creates a definitive fix.</strong></p><p>One-off scripts have a terrible reputation. When this happens too much, it’s a sign that the software is not stable. In the ideal world, it would never happen. Engineers would spot such time-critical problems during the design and code review phases. Production issues should be light and wait for regular software delivery flow.</p><p>Almost every company lives under the illusion that one-offs should not exist. Or that they will stop happening at some point. Yes, one should not do this every day. <strong>But having a few senior engineers run manual scripts in production because it’s an exceptional case is a mistake.</strong></p><blockquote><p>Almost every company lives under the illusion that one-offs should not exist.</p></blockquote><p><strong>Am I doing one-offs?</strong></p><p>Here are some common one-off solutions companies use in production:</p><ul><li>Call Raketasks using Rails console.</li><li>Use IEx to call Elixir functions.</li><li>Exec into servers/containers/pods and make localhost calls to an HTTP API</li><li>Make DML queries against the database.</li><li>Run bash/Python scripts through VPNs.</li></ul><p><strong>A myth.</strong></p><p>One-offs won’t go away, and companies need to embrace it. Avoiding them will drive the company to the wrong path. Centralizing execution with experienced engineers; or creating a team dedicated to analyzing and running them isn’t reasonable. It’s the opposite of DevOps.</p><blockquote><p>One-offs won’t go away, and companies need to embrace it.</p></blockquote><p>Most big companies solve this problem with a slow and manual Change Management workflow. Developers find the problem and add a script to a ticketing system. <strong>Someone from the operations team runs it without all the context</strong> of what she is doing. Avoiding one-offs is the shortest path to this model.</p><p><strong>What about Runbooks?</strong></p><p>Runbooks are great. Tools like <a href="https://www.rundeck.com/" target="_blank" rel="noreferrer noopener">Rundeck</a>
and <a href="https://stackstorm.com/" target="_blank" rel="noreferrer noopener">StackStorm</a>
automate fixing problems you know exist. They remove manual operations for routine tasks. But 1) creating Runbooks takes time, and 2) Runbook tools focus on infrastructure. One-off solutions need a faster track and application layer changes.</p><p>One-offs are the most challenging piece to automate. When you don’t know what problems will happen, it’s hard to build a solution upfront. Few companies I know 1) embrace one-offs, and 2) and try to automate them.</p><p><strong>For unknown unknowns, pre-existing solutions won’t work.</strong> The automation supporting this flow needs to be open-ended. The fastest is using direct access to resources and running ad-hoc solutions manually. But we can do better. It won’t get to the level of regular code, but we can get close.</p><blockquote><p>When you don’t know what problems will happen, it’s hard to build a solution upfront.</p></blockquote><p><strong>Isn’t this a bad incentive?</strong></p><p>A common misconception about one-offs is that formalizing them will increase their usage. They are faster to build than regular code. So it makes sense to think developers will prefer them over traditional pipelines. But this couldn’t be further from the truth. <strong>By making one-offs first-class citizens, you start to measure them. You can only change what you measure.</strong></p><p>One-offs must link to tasks with definitive fixes. Teams running them too much should decrease the number of features in the next sprint. Product prioritization should take into account what types of one-offs happen the most. All this is only possible with measurements. There is no upside in making one-offs hard to build and run.</p><blockquote><p>There is no upside in making one-offs hard to build and run.</p></blockquote><p><strong>One-offs as first-class citizens</strong></p><p>I built automations to support one-off scripts at previous jobs. It took a few months for the team as we had other duties, and the solution was not perfect. But <strong>developers were happy with the autonomy</strong> to build and run all solutions to their problems. Security and compliance were happier with audit trails &amp; logs. SREs were happy with fewer manual interventions in production. It was hard but paid off.</p><p>Today, I’m the founder of <a href="http://runops.io/" target="_blank" rel="noreferrer noopener">RunOps</a>
, a tool that automates one-offs. It lets you run scripts as if you had direct access to resources. Still, transparent controls and reviews make them safe, compliant, and reliable. It takes minutes to set up, our early users are very excited. Feel free to reach out on<a href="https://twitter.com/andriosrobert" target="_blank" rel="noreferrer noopener"> Twitter</a>
or shoot me an <a href="mailto:first@runops.io" target="_blank">e-mail</a>
to learn more.</p><p>I’m writing a few other articles exploring the topic. Subscribe to get the next in your inbox.</p><br></article></div>]]>
            </description>
            <link>https://andrios.co/articles/oneoffs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374731</guid>
            <pubDate>Thu, 10 Dec 2020 15:32:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building 5G Edge Clouds for Containers with OpenNebula and AWS Wavelength]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374553">thread link</a>) | @amarti
<br/>
December 10, 2020 | https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/ | <a href="https://web.archive.org/web/*/https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-29317">

    <!-- .entry-header -->

    <div>

		
<div><div id="kt-layout-id_df94ee-55"><div>
<div><p>🌎 OpenNebula’s new <a href="https://opennebula.io/true-hybrid/" target="_blank" rel="noopener noreferrer">True Hybrid Cloud Architecture</a> enables true hybrid and edge cloud computing by combining <strong>public and private</strong> cloud operations with <strong>workload portability</strong> and <strong>unified management</strong> of your IT infrastructure and applications.</p></div>



<div><p>Since the release of version 5.8 ‘Edge’ in February 2019, OpenNebula comes with a number of innovative features that provide organizations with a truly simple way to create and manage <strong>highly distributed cloud infrastructures</strong>. Thanks to these tools—developed in the context of our <a href="https://oneedge.io/">ONEedge</a> initiative—companies can easily deploy and manage remote clusters outside their premises in <strong>cloud and edge locations</strong> that are geographically dispersed or in close proximity to their end-users and customers.</p></div>
</div></div></div>



<p>By using <strong>OpenNebula’s new provisioning tools</strong>, cloud admins can now expand their private clouds in an incredibly flexible way using resources offered by <strong>third-party cloud providers like AWS and Equinix Metal</strong>, incorporating when necessary the distributed dedicated infrastructure they need to satisfy their users’ requirements for fault tolerance, capacity or low latency.&nbsp;</p>



<p>OpenNebula users can <strong>automatically allocate resources when needed</strong>, deploying and controlling edge nodes based on the current demand at those specific geographical locations. This approach simplifies significantly the process of <strong>provisioning and managing edge resources</strong>, without the organization that’s using this solution having to provide or own those underlying resources at all.</p>



<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers.jpg" alt="" width="750" height="263" srcset="https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers.jpg 1000w, https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers-300x105.jpg 300w, https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers-768x269.jpg 768w" sizes="(max-width: 750px) 100vw, 750px"></figure></div>



<p>OpenNebula also offers a simple, but powerful approach for <a href="https://opennebula.io/mastering-containers/">running containerized applications and workflows</a>—both <strong>on-premises and on cloud or edge locations</strong>—by directly using Docker official images from the <a href="https://support.opennebula.pro/hc/en-us/articles/360046667892-Using-the-Docker-Hub-Marketplace-to-Deploy-Container-based-Applications">Docker Hub</a> and running them as lightweight <a href="https://opennebula.io/firecracker/">Firecracker</a> microVMs. For those cases where Kubernetes is required or is the best fit, OpenNebula also provides a <a href="https://opennebula.io/certified-kubernetes-appliance/">Certified Kubernetes</a> Virtual Appliance available from the OpenNebula Public Marketplace, although for <strong>Kubernetes deployments at the edge</strong> we normally recommend a lighter solution based on <a href="https://k3s.io/">K3s</a> clusters 😉</p>



<h2>The New AWS Wavelength Service</h2>



<p>Recently, Amazon Web Services (AWS), in collaboration with <strong>Verizon, Vodafone and other 5G telecommunication providers</strong>, has presented its new <a href="https://aws.amazon.com/wavelength/">AWS Wavelength</a> service (read <a href="https://aws.amazon.com/blogs/aws/aws-wavelength-zones-are-now-open-in-boston-san-francisco/">here</a> the full announcement by AWS Chief Evangelist Jeff Barr back in August). <strong>Wavelength Zones</strong> bring AWS compute and storage capabilities and services to the edge of existing 5G networks, embedding AWS hardware and software within their data centers. This enables developers to innovate and build a new class of edge applications that can exploit <strong>high bandwidth and ultra-low latencies</strong> as offered by the new 5G networks.</p>



<figure><p>
<iframe title="AWS Wavelength - Edge Computing for 5G Networks" width="640" height="360" src="https://www.youtube.com/embed/EhMqwPqPzcY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Thanks to AWS Wavelength, application traffic from 5G devices can reach the servers running in Wavelength Zones <strong>without leaving the telecommunications network</strong>, thus avoiding having to traverse multiple hops across the Internet to reach their final destination, as it happens with a traditional approach based on a centralized cloud solution. This new service enables both developers and end-users to finally take full advantage of the latency and bandwidth benefits offered by 5G networks 📱</p>



<p>At OpenNebula, we have already started <strong>testing the new AWS Wavelength resources</strong> as part of our <a href="https://oneedge.io/">ONEedge</a> initiative. Eventually, this new service will be incorporated into our <strong>catalogue of cloud and edge providers</strong> available for OpenNebula users. We expect this integration to really simplify the process of provisioning and managing resources close to 5G devices, helping organizations using OpenNebula to <strong>build and quickly deploy edge applications</strong> that can benefit from 5G high bandwidth and ultra-low latency, including machine learning, video streaming, multiplayer gaming, Internet of Things, augmented reality, and real-time analytics.&nbsp;</p>



<h2>OpenNebula’s First 5G Edge Architecture based on AWS Wavelength</h2>



<p>As part of our first tests of this new AWS service, we’ve adapted the scenario described by AWS Senior Developer Mike Coleman in a <a href="https://aws.amazon.com/blogs/compute/deploying-your-first-5g-enabled-application-with-aws-wavelength/">post on AWS Wavelength</a> published in early August. In our case, a company with an OpenNebula private cloud wants to <strong>deploy a multi-container application at the edge</strong> (i.e a Machine Learning solution), closer to the 5G devices of their end-users. The following diagram describes how this would be implemented based on the features provided by OpenNebula and on the new resources made available by AWS Wavelength:</p>



<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-1024x563.png" alt="" srcset="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-1024x563.png 1024w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-300x165.png 300w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-768x422.png 768w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture.png 1500w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>AWS Wavelength is designed to provide access to services and applications that require low latency, but it’s important to remember that you don’t need to deploy your entire application in a Wavelength Zone. You only need to deploy those<strong> latency-sensitive parts of your application</strong> that are really going to benefit from being deployed at the 5G edge. In our demo scenario, the API server and inference engine are located on the Wavelength Zone because one of the design goals of the application is low-latency processing of the inference requests. On the other hand, given that the web server doesn’t have those latency requirements, it doesn’t really need to be hosted on the Wavelength Zone.</p>



<p>Each Wavelength Zone is <strong>associated with a specific AWS Region, known as the “parent region”</strong>. For our experiment we have picked the Boston area, which is one of the first regions—along with San Francisco—in which the new Wavelength service was made available. Also, Wavelength instances are only accessible from 5G devices on a specific telecom provider network, in this case from those of <strong>Verizon customers in the Boston area</strong> 🧱</p>







<figure><img src="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-1024x189.png" alt="" srcset="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-1024x189.png 1024w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-300x55.png 300w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-768x142.png 768w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal.png 1319w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>For the deployment of a multi-container application that benefits from this approach, we have used a number of <strong>well-known open source technologies</strong>. One of them has been <a href="https://k3s.io/">K3s</a>, a certified Kubernetes distribution originally developed by <strong>Rancher Labs</strong> and now hosted by the <a href="https://rancher.com/press/rancher-labs-k3s-joins-cloud-native-computing-foundation-sandbox-project">Cloud Native Computing Foundation</a> (CNCF). K3s is a lightweight, production-grade distribution designed for organizations looking to run Kubernetes in resource-constrained environments, which makes it ideal for deployments at the edge. We have used a customized K3s image for this demo, but in the near future users will be able to deploy a K3s cluster by simply using its public Docker image 🤩</p>



<p>When <strong>bare-metal resources</strong> are available, OpenNebula users can also benefit from our latest, super-cool integration with <a href="https://opennebula.io/firecracker/">Firecracker</a>. Firecracker is a new open source virtualization technology—widely used by AWS as part of its <strong>Fargate and Lambda</strong> services—especially designed for <strong>serverless deployments</strong>. By running application containers (e.g. the K3s Docker image) as a <strong>Firecracker microVM</strong>, we immediately obtain the enhanced security and workload isolation of a traditional VM, but without undermining the speed and resource efficiency of a container.</p>



<p>Unfortunately, right now, bare-metal instances are not available in the current Wavelength zones, so we cannot use Firecracker for our 5G edge deployment, only at the associated AWS parent region (i.e. us-east-1). Thus, for Wavelength instances, and thanks to another great feature of OpenNebula, we can use <strong>Ubuntu</strong>’s <a href="https://linuxcontainers.org/lxd/getting-started-opennebula/">LXD system containers</a> to deploy K3s agents on the Wavelength resources.</p>



<p>As show in the figure, in order to deploy a containerized application composed of different components, OpenNebula allows to <strong>instantiate a K3s cluster across multiple hosts with mixed hypervisors</strong> and then let the customer deploy the application (e.g. using an helm chart or kubectl) by scheduling the components on the right resources, typically deploying the latency-sensitive components (i.e. the Inference Engine and the API server) on the Wavelength Zone, and the rest of components (i.e. Web Server) on the AWS parent region.</p>



<h2>Integration of AWS Wavelength Resources within OpenNebula</h2>



<p>OK, let’s get into some more detail… 🤓 The first step required to set up AWS Wavelength resources is the deployment of an <strong>AWS Virtual Private Cloud</strong> (VPC) with two zones: one is related to the associated AWS parent region, and one is related to the Wavelength Zone. We have then to associate to the VPC an Internet Gateway that is used to assign public IPs to resources that are deployed within the parent region, plus a Carrier Gateway that is used to assign carrier public IPs to the resources deployed on the Wavelength Zone.</p>



<p>In the VPC we have to define two subnets: one for the resources at the parent region and one for Wavelength Zone resources. The parent region subnet will be associated with the Internet Gateway to get public IPs, whereas the Wavelength subnet will be associated with the Carrier Gateway to get public IPs from the 5G carrier network.</p>



<p>The Carrier Gateway in a Wavelength Zone only allows access from the carrier’s 5G network. So, since the Wavelength zone resources cannot be accessed by using the internet, it is not possible to provision, configure and set up those resources by directly accessing them. In order to integrate Wavelength Zone resources with OpenNebula, we have to <strong>use the parent zone’s servers as “bastion hosts”</strong> to access Wavelength Zone resources via SSH, since they are only reachable through the private VPC subnet. Resources in the parent region can also be used to deploy those parts of our application that are not latency-sensitive or require high-bandwidth.&nbsp;</p>



<p>Provisioning resources on regular AWS zones for deploying application parts that are not latency-sensitive is already possible for OpenNebula and can be performed by using its standard <a href="https://docs.opennebula.io/5.8/advanced_components/ddc/overview.html">OneProvision</a> tool. By using a bastion host and customized SSH configuration files, it is then possible to <strong>provision and configure instances on the Wavelength Zone</strong> and to add them as hosts to the OpenNebula front-end. Since OpenNebula uses SSH to perform any operation on the hosts, once bastion and Wavelength resources are set up, it is possible to <strong>deploy containerized applications</strong> (i.e. a K3s cluster) both on the parent region and on the …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/">https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/</a></em></p>]]>
            </description>
            <link>https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374553</guid>
            <pubDate>Thu, 10 Dec 2020 15:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem with Acronyms]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25374486">thread link</a>) | @thismodernlife
<br/>
December 10, 2020 | https://headey.net/the-problem-with-acronyms | <a href="https://web.archive.org/web/*/https://headey.net/the-problem-with-acronyms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  <p><em>Reducing the use of unnecessary acronyms in your business will increase productivity and employee happiness, and reduce cynicism as you grow. Here's how.<br></em><br>
</p>
<div>
<action-text-attachment sgid="BAh7CEkiCGdpZAY6BkVUSSI1Z2lkOi8vYmxvZ2xpbmUvQWN0aXZlU3RvcmFnZTo6QmxvYi83OT9leHBpcmVzX2luBjsAVEkiDHB1cnBvc2UGOwBUSSIPYXR0YWNoYWJsZQY7AFRJIg9leHBpcmVzX2F0BjsAVDA=--492323e7f82eed9da3abe777946f97eda1fea850" content-type="image/jpeg" url="https://blogline.co/rails/active_storage/blobs/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--ad4630a4a9904956efb76f599a435812aa947e98/choose-your-words.jpg" filename="choose-your-words.jpg" filesize="47482" width="800" height="600" previewable="true" presentation="gallery"><figure>
    <img src="https://headey.net/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--ad4630a4a9904956efb76f599a435812aa947e98/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdDRG9MWm05eWJXRjBTU0lJYW5CbkJqb0dSVlE2RkhKbGMybDZaVjkwYjE5c2FXMXBkRnNIYVFJQUJHa0NBQU02QzJ4dllXUmxjbnNHT2dsd1lXZGxNQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--a716ef5bd361b6dfee383a3ae715134b65b59d48/choose-your-words.jpg">

  <figcaption>
  </figcaption>
</figure></action-text-attachment><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwiRlcKCp5jtAhWNQEEAHfPgCOYQFjAAegQIBBAC&amp;url=https%3A%2F%2Fheadey.net%2Fspectacular-vernacular&amp;usg=AOvVaw0rJ08bs82T25D_W2oBjORi">Confusing vernacular</a> isn’t a new thing to me, but I’ve noticed that an acronym[1] population steadily increases as projects, or entire companies, expand. I can sort of understand. When a company is bigger, there are more people and more things going on. More projects, more meetings, more presentations. Typing “Engaged User Growth Hack” becomes tedious the 14th time you write it in your proposal, so someone initialises it (EUGH) the first time and uses the acronym there on in. Once the document is circulated, it’s inevitable that at some point – it might take a few meetings, but eventually – it becomes common parlance. "How is the EUGH rate looking this week, Ted?"</p></div>
<div><p>One of the many problems you’re going to encounter in a growing business is a lack of clarity among staff. A successful business is one where employees understand things, and when they don’t it's okay because they know where to go to find the information required to understand things.&nbsp;</p><p>Whether you’re a new hire reviewing an onboarding guide on your first day, or a seasoned employee reading the latest project proposal, you’re probably going to be faced with a sea of acronyms. The more there are, the more confused you'll be. This is bad for morale and bad for business, so it's your job as a leader in an organisation to spare everyone from this misery by eliminating acronyms as much as possible in your organisation. Here are my top tips.</p></div>


<div><p>Some acronyms are so universally understood and accepted that it would be weird not to use them (HTML, RAM). There are some acronyms where the majority of people know what they mean, even if they don't know specifically what the abbreviation stands for. There are some that are <strong>very dependent on context</strong> so proceed with caution unless they are truly universal or if you really know your specific audience. For instance:</p></div>
<ul>
<li>NHS. Everyone in Britain will know what this means, but many people from other countries might be confused.</li>
<li>FBI. You know what it is, but what does it stand for?&nbsp;</li>
<li>UFO. People of a certain age will know about UFOs, but has anyone talked about them since 1989?&nbsp;</li>
</ul>


<div><p>If we accept the premise that more acronyms means more confusion, why would we add to this? Writing Average Page Load Time is tedious for the author, but creates clarity and removes any confusion about what it means (given the appropriate context). APLT does neither. Adopting universal acronyms into your organisation isn't necessarily a bad thing, but inventing your own probably is.</p><p>One exception to this rule is code names. Calling your new internal app <strong>PERSI</strong> is better than calling it Predictive Enterprise Relationship System Integration, and it's fun to ask the team "How is PERSI doing this morning?". Personality goes a long way.<br>.</p></div>

<div><p>Even if we're not creating any new acronyms, there will always be a heap in common use already. When you’re writing a document, always write the words in full on first use and put the acronym in brackets after it. For example, don't write:</p></div>
<blockquote>In our company, we live and die by OKRs and KPIs.</blockquote>

<blockquote>In our company, we live and die by Objectives and Key Results (OKRs) and Key Performance Indicators (KPIs).&nbsp;</blockquote>
<div>
<p>Given that everything is likely to be in digital form you should also, wherever possible, link to even more information. Context is king. So your document should look more like this:</p></div>
<blockquote>In our company, we live and die by <a href="https://www.youtube.com/watch?v=mJB83EZtAjc">Objectives and Key Results</a> (OKRs) and <a href="https://en.wikipedia.org/wiki/Performance_indicator">Key Performance Indicators</a> (KPIs).&nbsp;</blockquote>
<div>
<p>Do this always. Even if you think it's unnecessary, it's really not. It is helping communication, not hindering.</p></div>


<blockquote><em>To maximize clarity, use abbreviations sparingly<p>— American Psychological Association</p></em></blockquote>
<div>
<p>Just because everyone else does, you don't actually have to use acronyms yourself. You can assume everyone knows what KPI means, and perhaps they do know that it stands for Key Performance Indicator, but do they know what a "performance indicator" actually is? Wouldn't it be better to ditch the acronym entirely and say "measure of success"? You could say the same thing about OKRs (goals), CTR (ad click rate), and CRM (customer database). </p><p><a href="http://www.plainenglish.co.uk/">Plain English</a> is liberating.&nbsp;</p></div>

<div><p>You need to write down all the acronyms being used in your daily business so, at the very least, people can look things up rather than sit there silently and fearfully in ignorance. Doing this is a fun company crowdsourcing exercise where you can talk about the perils of acronyms and get this front and centre so people actually know about it and use it.&nbsp;</p><p>This glossary should be reasonably short. If it's not, you're probably using too many acronyms in your business and you need to go on a diet. You could write an OKR for that.</p></div>
<div>
<p>The intention of this article is to make you think about how acronyms are being used in your business, and for you to keep a sharper eye on new ones appearing. You should feel empowered to question their invention, and you should call it out when a document lands in your inbox that is populated with unreferenced jargon. </p><p>You could even go all Elon Musk, <a href="https://gist.github.com/klaaspieter/12cd68f54bb71a3940eae5cdd4ea1764">berate the entire company</a> and demand sign-off of any new acronyms. Extreme behaviour, perhaps, but it goes to show the negative impact acronyms have on a business and the secret power of that liberating feeling of clarity when they're eliminated from use.</p><p><a href="https://en.wikipedia.org/wiki/TTFN">TTFN</a>.<br><em><br>[1] I only learned this recently but an acronym is a word formed from the first letters of other words and is pronounceable, for example </em><strong><em>laser</em></strong><em> or </em><strong><em>radar</em></strong><em> (🤯 I know, right), whereas an initialism is an abbreviation in which each letter is pronounced separately, such as OMG or NHS. In this article I only use the word acronym because I'm pretty sure no-one ever uses the word initialism.</em></p></div>
</div>

  </div><div data-controller="email-subscribers">
    <p>Subscribe to Email Updates</p>

    

      </div></div>]]>
            </description>
            <link>https://headey.net/the-problem-with-acronyms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374486</guid>
            <pubDate>Thu, 10 Dec 2020 15:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting our first thousand users in one day]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25374319">thread link</a>) | @frankdilo
<br/>
December 10, 2020 | https://francescodilorenzo.com/typefully-launch | <a href="https://web.archive.org/web/*/https://francescodilorenzo.com/typefully-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Yesterday we launched <a href="https://typefully.app/">Typefully</a>, a write-only interface for Twitter, after weeks of work and refinement. I documented the whole story on Twitter <a href="https://twitter.com/frankdilo">@frankdilo</a>.</p>
<p>Not much deep work happened on launch day and for good reasons. It was a bigger launch than <a href="https://francescodilorenzo.com/mailbrew-launch-numbers">Mailbrew's</a>.</p>
<p>Here the numbers:</p>
<ul>
<li>16,400 Pageviews </li>
<li>1,432 Signups </li>
<li>1,843 Drafts created</li>
<li>256 Threads published</li>
<li>$155 Revenue (more on this at the end).</li>
</ul>
<p>The traffic breakdown reveals what happened:</p>
<ul>
<li>Hacker News: 6.3k</li>
<li>Twitter: 2.1k</li>
<li>ProductHunt: 1.9k</li>
</ul>
<p>Yeah, we finally managed to hit the <a href="https://news.ycombinator.com/item?id=25358108">Hacker News frontpage</a>. </p>
<p>The perfect formula was:</p>
<ul>
<li>interesting product</li>
<li>no-bullshit title</li>
<li>sparking a controversial discussion in the comments.</li>
</ul>
<p>When it comes to Twitter, we have been building a following there for some time, so it was a matter of publishing the <a href="https://twitter.com/frankdilo/status/1336589322670268416?s=21">right tweet</a>, at the right time, and getting the right people to retweet it.</p>
<p>For Product Hunt, we partnered with our friend <a href="https://twitter.com/chrismessina">Chris</a>. His followers got a notification when he hunted us, but we also did our part and emailed our lists.  That helped to get fast on the front page and to kickstart the discussion.</p>
<p>Once we were in front of enough people, the product did the rest.</p>
<p>Servers did hold up without a sweat. </p>
<p>It's crazy what you can do these days with a couple of well-configured dynos on Heroku and a Django app! We peaked at 8 RPS when we hit the HN frontpage.</p>
<p>Typefully was born as <a href="https://twitter.com/linuz90">Fabrizio</a>'s personal side-project. I jumped in to make the editor crazy-fast, and write the server-side code. When <a href="https://twitter.com/meseali">Ali</a> helped us refine positioning and copy, we knew we had a winner and promoted it to an official <a href="https://mailbrew.com/">Mailbrew</a> project.</p>
<p>Plans for the future? Implement all the great feature requests we got, and monetize this thing. </p>
<p>We launched with a tip-jar system where people could become <em>patrons</em> by tipping us, but with $150 earned after a crazy launch day like this, it's clear that this is not going to pay the bills. </p>
<p>We are thinking of adding some paid features. What's free is gonna stay free though, because this was first and foremost a labor of love.</p>
</article></div>]]>
            </description>
            <link>https://francescodilorenzo.com/typefully-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374319</guid>
            <pubDate>Thu, 10 Dec 2020 14:59:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A list of small teams behind billion dollar start-ups]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374145">thread link</a>) | @maxejennings
<br/>
December 10, 2020 | https://stevepulec.com/posts/small/ | <a href="https://web.archive.org/web/*/https://stevepulec.com/posts/small/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Patrick Collison has a <a href="https://patrickcollison.com/fast">great list</a> of people quickly accomplishing ambitious things. Inspired by that, I created a page of impressive things accomplished by small teams.</p>
<ul>
<li>
<p><strong>Instagram</strong> had 13 employees when they were acquired by Facebook for $1 billion. They had 30 millions users at the time. <a href="https://www.cnbc.com/2019/09/24/facebook-bought-instagram-because-it-was-scared-of-twitter-and-google.html">Source</a></p>
</li>
<li>
<p><strong>Mojang</strong> (the company behind Minecraft) had 37 employees when they were acquired by Microsoft for $2.5 billion. At that time, Mojang had revenue of about $290 million annually with profits of over $100 million. <a href="https://www.ft.com/content/6eb85da4-38f4-11e4-9526-00144feabdc0">Source</a></p>
</li>
<li>
<p><strong>WhatsApp</strong> had 55 employees when they were acquired by Facebook for $19 billion. <a href="https://www.wired.com/2015/09/whatsapp-serves-900-million-users-50-engineers/">Source</a></p>
</li>
<li>
<p><a href="https://www.notion.so/"><strong>Notion</strong></a> has raised money at a $2 billion valuation with under 50 employees. <a href="https://techcrunch.com/2020/04/01/notion-hits-2-billion-valuation-in-new-raise/">Source</a></p>
</li>
<li>
<p><strong>BuiltWith</strong> generates $14 million/year with a single employee. <a href="https://twitter.com/theSamParr/status/1257819248484745216">Source</a> (an investor in the business)</p>
</li>
<li>
<p>The <strong>Gartman Letter</strong> had a single employee and was rumored to be doing $25M/year</p>
</li>
<li>
<p>Kylie Jenner sold a 51% stake in the <strong>Kylie Cosmetics</strong> for $600 million with just seven full-time and five part-time employees. <a href="https://www.forbes.com/sites/forbesdigitalcovers/2018/07/11/how-20-year-old-kylie-jenner-built-a-900-million-fortune-in-less-than-3-years/">Source</a></p>
</li>
<li>
<p><strong>Craigslist</strong> generates around $1 billion/year with about 50 employees. <a href="https://www.cnbc.com/2019/01/24/craigslist-posts-annual-revenue-of-1-billion-study.html">Source</a></p>
</li>
<li>
<p><strong>Plenty of Fish</strong> sold for $575 million with 75 employees. <a href="https://www.businessinsider.com/how-markus-frind-bootstrapped-plentyoffish-and-sold-it-for-575-million-2015-7">Source</a></p>
</li>
<li>
<p><strong>Liberty Media</strong> had 16 employees and was worth multi-billions in the 90s. <a href="https://www.amazon.com/Not-Fade-Away-Short-Lived/dp/006073731X">Source</a></p>
</li>
<li>
<p><strong>Joe Rogan</strong> is making between $30-$50 million/year with a handful of employees. <a href="https://www.forbes.com/sites/arielshapiro/2020/05/19/the-new-howard-stern-podcast-giant-joe-rogan-inks-exclusive-deal-with-spotify/">Source</a></p>
</li>
<li>
<p>The progress that the <strong>Wright brothers</strong> made on powered flight was so unbelievable that they had to spend two years convincing the US and French governments that it was true. <a href="http://wrightbros.org/History_Wing/Wright_Story/Showing_the_World/Prize_Patrol/Prize_Patrol.htm">Source</a></p>
</li>
</ul>
<p>This list is very business heavy right now, but I would love to add some non-business examples too! Have more? Please <a href="https://stevepulec.com/about/">reach out</a>.</p>
<p><em><a href="https://twitter.com/spulec">Follow me</a> on Twitter for more updates</em></p>
<p>Related resources:</p>
<ul>
<li><a href="https://www.theguardian.com/technology/2018/apr/24/the-two-pizza-rule-and-the-secret-of-amazons-success">Two pizza rule</a></li>
<li>Something something Margaret Mead quote something something.</li>
<li><a href="https://en.wikipedia.org/wiki/Ringelmann_effect">Ringelmann effect</a></li>
</ul>
</article>

        </div></div>]]>
            </description>
            <link>https://stevepulec.com/posts/small/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374145</guid>
            <pubDate>Thu, 10 Dec 2020 14:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Data You Give]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374120">thread link</a>) | @henrikwm
<br/>
December 10, 2020 | https://security.christmas/2020/10 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>He sees you when you’re sleeping, he knows when your awake, he knows if you ‘we been bad or good so be good for goodness sake. This is a line of a popular Christmas song. It obviously refers to Santa Claus. However… What if this is true, not only for Santa, but for large companies worldwide. We’ll take a closer look on the data you give and the repercussions.</p>
</section><article><section><p>In today’s modern world, our phones are an integral part of our lives. We carry it everywhere, whether it is at work, when we are out and about or in the hospital. In every situation, our phone is nearby. The phone gives us easy access to information, communication and you might say there is an app for everything. If you need to see the local weather, it is right there in your phone, the same goes for the directions to the cinema or if you want to know what your friends are up to – check your phone. And it is all free of charge. Well, not exactly, nothing is free.</p>
<h2>The payment</h2>
<p>Although you might not spend any money on an app, the app still collect a form of payment from you. Your information is the currency and it is collected through every action you make on the internet and in the apps on your phone. Your device information, your likes and dislikes and your email is just some of the data they might collect. And the hottest commodity is your location data. You might say the phone is a tracking device you wear 24/7.</p>
<p>Some of this data, we give willingly. This can be photos, statuses, interests and in some cases, who your friends are, where you live and so on. It is easy to believe that the information you give to a specific app will be contained within the app. This is often not the case. Selling consumer data is a multi-billion-dollar industry and your data is sold for targeted marketing, to analytics companies and to research. </p>
<p>You might not know what you do online every day, but the 50 apps you have on your phone does and what you do says a lot about you.</p>
<h2>I have nothing to hide</h2>
<p>You might not know why you should care about the fact that your data is collected, you have nothing to hide. A couple of emails with “special offers” in terms of marketing might not be the worst thing. But here is why you should care. </p>
<p>There are no restrictions on who can by this data and more parties are showing interest. In fact, earlier this year the Wall Street Journal found that the <a href="https://www.wsj.com/articles/federal-agencies-use-cellphone-location-data-for-immigration-enforcement-11581078600">U.S government bought commercially available location data</a> and used if for detecting undocumented immigrants or others trying to get across the U.S border. It also played a part in discovering a drug smuggling tunnel beneath the border between USA and Mexico in an abandoned KFC restaurant. </p>
<p>The police usually must acquire warrants to get this kind of information on your phone, but what if they can just buy it commercially? When is it ok to use these data and when is it surveillance? <a href="https://privacy-pc.com/interviews/bruce-schneier-nsa-is-wasteful-and-dangerous.html">Like the comparisons the cryptographer Bruce Sneider draws:</a> If the government said: “Whenever you make a new friend, you must inform the police”. We would laugh, but we willingly tell Facebook and Facebook informs the government. Or if the government says: ”Whenever you send a message or write a letter or send a note to somebody, send us a copy, please”. That would never happen, we would not do that. However, Google does it for you.</p>
<p>Throughout your days of using your phone or computer, you give pieces of information to each application or website, and although this data is supposed to be anonymous, it is not hard to connect the missing pieces. When seeing all the data from different sources together and by adding simple searches on specific information, your name and identity will be found and the data will no longer be anonymous. This was illustrated when <a href="https://www.nytimes.com/interactive/2018/12/10/business/location-data-privacy-apps.html">The New York Times</a> bought commercially sold location data. With this data they could easily find the person to whom the data belonged. Even though the name of the woman they were tracking, was not among the bought information, they deduced a lot about her. They could see that she was at a weight watchers meeting, doing a procedure at the dermatologist and by the amount of time she was spending at a school, she was most likely a teacher. The phone tracked her every two seconds and giving information about her she found disturbing.</p>
<p><a href="https://www.nrk.no/norge/xl/avslort-av-mobilen-1.14911685">NRK</a>, a TV-channel in Norway did the same. By analysing the person’s patterns, they could see where he spent his days and where he spent his nights. By this information alone one can easily find out who lives at the address he slept at and who works at the address he was during the day, to find the name of the person using the phone. They even found that the person was going to interviews with another company, which he had not told anyone. And some time after these interviews he change his place of work.</p>
<p>All your data collected is a foundation for through analysis of you as a person. They can put you in boxes and make assumptions about you. Sometimes they are right, and sometimes they are not. If you are classified as likely to become a gambler, could it get in the way of you getting a loan in the future? Or could marketing pray on your weaknesses to get you to buy something you don’t need? You can easily be manipulated by companies gaining in-depth knowledge about you. This was proven by “Folkeopplysningen”, a show in Norway that informs the public about different topics. In one episode they <a href="https://www.nrk.no/dokumentar/xl/ble-manipulert-etter-nrk-spionering-pa-hans-digitale-liv-1.14759796">manipulate an intelligent man to give up his company, his life’s work, purely based off of information found on him online</a>. By his likes on Facebook, they could perform a personality test. By the pictures on Instagram they could see that he liked to work out, that he loved superheroes and all kind of other information. They staged a day for him to be considered for a super hero-part in a Hollywood production. All he had to do was give up his business. This is something he probably would never do if it wasn't for being manipulated for an entire day based on the information the TV-show could find on his social media and other online accounts.</p>
<h2>What about GDPR</h2>
<p>If you live in Europe, you have probably heard of General Data Protection Regulation or GDPR. <a href="https://www.investopedia.com/terms/g/general-data-protection-regulation-gdpr.asp">GDPR</a>&nbsp;is a legal framework that sets guidelines for the collection and processing of personal information from people who live in the EU. It is there to give consumers of the internet more right as to what data is collected.</p>
<p>As a consumer, you notice it best by having to accept the use of cookies on the web or by giving permissions to the apps of which data they can have access to. However, the government can only do so much if consumers keep accepting the usage. The web or phone applications often make it hard not to accept by writing the terms incomprehensible or too long. In some cases, you must even go to completely different applications to turn it all the way off.&nbsp;<em>As long as it is easier to accept, we will accept.</em>&nbsp;It can also be difficult to investigate where the commercially sold data comes from because not all companies are located in Europe and in some cases the terms does not specify all the different ways your data can be spread. </p>
<h2>Off the grid</h2>
<p>By highlighting some downsides of sharing data, you might feel the need to stop sharing data all together, but it is important to state that data sharing is not all bad. First of all, getting commercials tailored for you can be a good thing as you can get offers based off of previous purchases and get more effective services. Another great thing about sharing your data is that it can benefit scientists. Research on cancer be done studying patient data, why we are the way we are can be explored by looking at data from Facebook and so on. Looking at large sets of data can give us a better understanding of the world today.</p>
<p>The thing to think about is that you do not have to share your data all the time and to every app or website. For instance, a flashlight app does not need permissions to track your location. There are ways of sharing less data by limiting the apps on your phone to only sharing location data when the app is used or turning it completely of when you are not active on your phone.&nbsp;</p>
<p>When it is all said and done it is&nbsp;<em>your</em>&nbsp;data.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374120</guid>
            <pubDate>Thu, 10 Dec 2020 14:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding native integrations to your app with FusionAuth and Xkit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374028">thread link</a>) | @mooreds
<br/>
December 10, 2020 | https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>FusionAuth and Xkit came together for this blog post to share how you can use our services to boost your engineering team’s productivity. If you’re working on growing your SaaS business, you know just how much your engineers have on their plates. At both FusionAuth and Xkit, we believe that outsourcing what you can – like authentication and integration infrastructure – lets your team focus on the products and services that drive your business.</p>

<!--more-->

<p>We’ve written this post to lay out how you can use our services together to simplify your auth and build native integrations into your app faster. No more telling your customers that the integrations they’ve been asking for are “on the roadmap”. Follow the steps below and you can ship them in no time.</p>

<h2 id="what-is-xkit">What is Xkit</h2>

<p>Xkit is a SaaS platform which makes integrating third party systems a snap. Suppose you are writing a recipe management application and are going to sell it for big money to all the cooks of the world. After some market research, you realize that you want to integrate with other services. Your users are clamoring for the ability to export the steps of a recipe to a Trello board for sharing and Dropbox for backups. These are all services with APIs.</p>

<p>End users can give your application access to their accounts with these services, but that takes some coding. There’s also a fair bit of hoop jumping: setting up API keys and OAuth consent screens, among other things.</p>

<p>This is the problem which Xkit solves. Xkit has built connections to many services; <a href="https://docs.xkit.co/docs/connecting-with-apps-overview">here’s a current list</a>. Once configured, your application can connect a user’s account with an external service to your application. I (Dan) was able to connect Trello and my app in about an hour. The user experience of connecting the external application is smooth and far better than something I could whip up in a day, let alone an hour.</p>

<h2 id="xkit-and-fusionauth-integration">Xkit and FusionAuth integration</h2>

<h3 id="install-fusionauth">Install FusionAuth</h3>

<p>FusionAuth offers <a href="https://fusionauth.io/docs/v1/tech/installation-guide/">a number of different methods you can use to install the service</a>. Once you’ve installed it, there’s a Setup Wizard to walk you through the next steps. You’ll need to create your application in the FusionAuth interface and then add a few elements to your application code base to fully implement the FusionAuth login flow. A <a href="https://fusionauth.io/docs/v1/tech/5-minute-setup-guide/">full, detailed setup guide</a> is also available. Feel free to create additional <a href="https://fusionauth.io/docs/v1/tech/core-concepts/users/">users via the FusionAuth administrative user interface</a>.</p>

<p>Once FusionAuth is installed and configured, you have a full featured user management system, ready to go. APIs to control everything, multi factor authentication, consent management, SAML, OIDC, and more, hosted wherever you want. There’s also FusionAuth Cloud, a managed services offering, if you don’t want to host FusionAuth yourself.</p>

<h3 id="install-xkit">Install Xkit</h3>

<p>After you’re set up with FusionAuth you’ll want to head over and <a href="https://app.xkit.co/sign-up">create your Xkit account</a>. Upon sign-up, Xkit will also prompt you with some basic information needed to set up the environment. Fill out those details and you’re good to go there.</p>

<p>To set up Xkit in your code base, you’ll need to add the script tag for <code>xkit.js</code> on your front-end:</p>

<div><div><pre><code><span>&lt;script </span><span>src=</span><span>"https://&lt;your-slug&gt;.xkit.co/xkit.js"</span><span>&gt;&lt;/script&gt;</span>
</code></pre></div></div>

<p>In addition, your users need a place to actually sign in to their apps, such as Dropbox for your cooking recipe sharers. The easiest way to do this is to direct users to the hosted integration catalog Xkit has set up for you:</p>

<div><div><pre><code><span>&lt;a</span> <span>href=</span><span>"https://&lt;your-slug&gt;.xkit.co"</span><span>&gt;</span>Integration Catalog<span>&lt;/a&gt;</span>
</code></pre></div></div>
<p>Alternatively, if you need more customization, you can embed Xkit’s catalog on your site and customize its styling to fit your look and feel (<a href="https://docs.xkit.co/docs/self-hosted-catalog">details here</a>). If you still need more flexibility, you can use the SDK.</p>

<h3 id="connect-fusionauth-with-xkit">Connect FusionAuth with Xkit</h3>

<p>Now that you have both FusionAuth and Xkit set up, you’ll need to connect the two. We do this by collecting some information from your FusionAuth dashboard and inputting it into Xkit.</p>

<p>Specifically, you’ll need to generate an RSA key and then add your “iss” claim, “aud” claim and JWKS URL into your Xkit account. This setup is <a href="https://docs.xkit.co/docs/fusionauth">fully documented</a>.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/xkit-fusionauth-integration/rsa-keypair.png" alt="The generated RSA key for use with Xkit."></p>

<p>Once you’ve done that and clicked save, FusionAuth and Xkit will be connected. Huzzah!</p>

<p>You can now have your users log in using FusionAuth’s Login API. You’ll get a JWT from FusionAuth on successful user authentication. This JWT can then be sent to Xkit to authenticate the user in Xkit, and therefore grant them access to integrations you’ve configured.</p>

<p>In your code base you can log your user into Xkit simply by using your FusionAuth ID token:</p>

<div><div><pre><code><span>//...</span>
<span>xkit</span><span>.</span><span>ready</span><span>(()</span> <span>=&gt;</span> <span>{</span>
  <span>xkit</span><span>.</span><span>login</span><span>(</span><span>'</span><span>eyJhbGciOi...</span><span>'</span><span>)</span>
<span>})</span>
<span>//...</span>
</code></pre></div></div>

<p>This easy JWT-based connection saves you the trouble of dealing with API keys and provisioning users for Xkit; you can instead maintain them in FusionAuth. You can also use FusionAuth for all your other applications, providing one view of all your users.</p>

<p>The security minded among you will notice that this JWT is available in the DOM, and therefore exposed to cross site scripting attacks, should any malicious JavaScript be executed on the same page. To minimize the risks, lock the permissions associated with this JWT down and don’t allow its use as a bearer token for any other more sensitive APIs or services.</p>

<h2 id="add-an-integration">Add an integration</h2>

<p>Now to actually set up your first integration! Say you want your users to be able to connect their Trello accounts with your app. To do this, you’ll first need to get an <a href="https://trello.com/app-key">Trello API key</a>.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/xkit-fusionauth-integration/xkit-trello-screenshot.png" alt="The Xkit Trello integration screen."></p>

<p>Next you’ll need to add Trello as a connector in your Xkit platform and provide Xkit with the API key. After filling out a bit more information in the Xkit Trello connector page to set the permissions you require and what your users see when they’re connecting the app, you’ll click save.</p>

<p>You’re now ready to retrieve access tokens! You simply make one API call to retrieve a user’s fresh access token:</p>

<div><div><pre><code><span>const</span> <span>trelloToken</span> <span>=</span> <span>await</span> <span>xkit</span><span>.</span><span>getConnectionToken</span><span>(</span><span>"</span><span>trello</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>If the token isn’t available, you should send the user to the appropriate place in your integration catalog to connect it.</p>

<div><div><pre><code><span>//...</span>
<span>if</span> <span>(</span><span>!</span><span>trelloToken</span><span>)</span> <span>{</span>
  <span>window</span><span>.</span><span>location</span><span>.</span><span>href</span> <span>=</span> <span>xkit</span><span>.</span><span>connectorUrl</span><span>(</span><span>"</span><span>trello</span><span>"</span><span>)</span>
<span>}</span>
<span>//...</span>
</code></pre></div></div>

<p>Behind the scenes here, Xkit handles all the complicated parts of managing the access tokens — dealing with each SaaS app’s protocol differences, token expirations, refresh tokens, protection against CSRF attacks, token encryption and more — so that it’s as simple as one API call for you. This setup also makes it easy to retrieve the token anywhere in your stack, be it in Cloud Functions, on the front-end, from your web server, etc. You can then use the token to make calls to the Trello API.</p>

<p>To add integrations to other apps, you follow essentially the same steps and retrieve the token with the same API call. Specific guides for different apps <a href="https://docs.xkit.co/docs/connecting-with-apps-overview">can be found here</a>.</p>

<p>We’re always looking for feedback and suggestions so let us know your thoughts! Thanks for reading.</p>

<p>This post can also be found on the <a href="https://xkit.co/post/adding-native-integrations-to-your-app-with-xkit-and-fusionauth">Xkit blog</a>.</p>

            
          </div></div>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374028</guid>
            <pubDate>Thu, 10 Dec 2020 14:31:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top React libraries you need to know in 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25373927">thread link</a>) | @oczek
<br/>
December 10, 2020 | https://blog.graphqleditor.com/react-libs-2021/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/react-libs-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last time we looked a bit at the background and some built-in features of React. As promised it’s now time to look at some optional tools. Just like with Vue and Angular, components play a big role here and as usual you can create your own or use some of those made by the rapidly growing community. Let’s take a look at React libraries you should check before 2020 ends.</p>
<h2>React based frameworks</h2>
<p>If you’re planning on working with React most likely you’re going to have to pick between two starter frameworks, Gatsby.js and Next.js. React by itself works only on the client side and does not provide server side rendering, while those two build on top of React and provide SSR/SSG. Both also follow JAMStack architecture and provide you with a boilerplate which helps speed up and simplify the development process. That’s enough about similarities and let’s look at what the choice boils down to:</p>
<ul>
<li><strong><a href="https://www.gatsbyjs.com/">Gatsby.js</a>:</strong> generates HTML via server side generator during the build time, this means you don’t need a Node.js server to handle rendering and you’ll have HTML files ready right after build.  Data fetching is handled via GraphQL which has its benefits (you only fetch what you need which saves resources and time) but also ties you to GraphQL which not everyone likes or wants to use. Prominent uses of Gatsby.js include Figma.com, React’s official site and State of Javascript.</li>
<li><strong><a href="https://nextjs.org/">Next.js</a>:</strong> renders pages via server side rendering, this requires a Node.js server to run applications and handle dynamic HTML rendering. If you don’t like that Next.js also supports SSG since version 9.3. What you use for data fetching is up to you, hell you can even use GraphQL. Prominent uses of Next.js include TikTok, Hulu and Twitch mobile.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/00d43/base.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="React based frameworks" title="React based frameworks" src="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/fcda8/base.png" srcset="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/12f09/base.png 148w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/e4a3f/base.png 295w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/fcda8/base.png 590w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/efc66/base.png 885w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/00d43/base.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>State management</h2>
<p>State management is the most crucial part of any modern React app. Most of the time it is the biggest challenge any developer faces while working on their frontend project, especially when it comes to large and complex enterprise-grade commercial apps. Managing state is such a complex task that proper handling requires using external libraries, as at some point React itself will no longer be able to provide a satisfactory solution.</p>
<ul>
<li><strong><a href="https://redux.js.org/">Redux</a>:</strong> a predictable, standalone state container for JavaScript apps which helps you write applications that behave consistently and run in different environments. Being a standalone library means you can use Redux even if you don’t have a UI setup yet. Redux can be used with any UI framework i.e React, where you can describe your UI as a function of your state and make Redux keep track of your components state and update them accordingly in response to UI actions. Redux is definitely the most popular choice when it comes to state management with React with almost 5 million weekly downloads on NPM.</li>
<li><strong><a href="https://mobx.js.org/README.html">MobX</a>:</strong> a simple, scalable state management solution. It’s easier to learn and simpler to use than Redux and focuses on helping develop simpler apps with less boilerplate code. The main focus is reducing the number of bugs by mapping the relations between state and derivatives while maintaining referential integrity. Another plus is that it can be used either client side or server side and, as a JavaScript library, lets you keep the existing utilities of JS.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/00d43/state.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="State management" title="State management" src="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/fcda8/state.png" srcset="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/12f09/state.png 148w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/e4a3f/state.png 295w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/fcda8/state.png 590w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/efc66/state.png 885w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/00d43/state.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Forms</h2>
<p>Forms are present in most web and mobile apps.  Unlike Angular and Vue, which both give you a way to validate forms out of the box, React requires you to handle them all by yourself. Fortunately there are some libraries rushing to help you out.</p>
<ul>
<li><strong><a href="https://formik.org/">Formik</a>:</strong> is the most popular form library for React (and React Native). Formik is packed with dozens of micro features like different types of validation, handling API errors, auto-saving forms data and many more. It’s the result of the React community’s years of experience in terms of UI, security, accessibility etc. With Formik you can focus on developing your product instead of battling with all aspects of forms. It’s a well-tested and highly optimized solution, using which will leave you with less chances for unexpected errors and edge cases in your forms.</li>
<li><strong><a href="https://react-hook-form.com/">React Hook Forms</a>:</strong>  a light-weight form library for React, allowing you to achieve astonishing results with a minimal amount of code, which makes it very performance oriented. React Hook Forms is optimized to remove any unnecessary re-renders of your components by providing the developer a way to isolate component re-renders, improving performance of your mobile or web application. It is a great way to empower your applications with highly-performant, flexible, easy to use and manage forms.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/00d43/forms.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Forms" title="Forms" src="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/fcda8/forms.png" srcset="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/12f09/forms.png 148w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/e4a3f/forms.png 295w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/fcda8/forms.png 590w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/efc66/forms.png 885w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/00d43/forms.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Testing</h2>
<p>Test-driven development (TDD) is now one of the leading approaches to application development. It’s becoming more and more popular as it reduces the chance of major bugs occurring in the future. An obvious downside of test-driven development is that it usually takes longer to bring a product to market than while using a behavior-driven development approach. Fortunately there are some useful React libraries that can make writing tests a much easier task.</p>
<ul>
<li><strong><a href="https://enzymejs.github.io/enzyme/">Enzyme</a>:</strong> a JS testing utility that makes testing your React components super easy. You can manipulate, traverse and in some ways simulate runtime given the output. Enzyme was created internally at AirBnB and released as an open source project in 2015. The tool aims to be as easy as possible by providing an intuitive API inspired by jQuery’s API for DOM manipulation and traversal.</li>
<li><strong><a href="https://testing-library.com/docs/react-testing-library/intro/">React Testing Library</a>:</strong> a tool that lets you test React components without relying on their implementation details. This approach helps focus on accessibility as it basically puts you in the shoes of the end-user of the React app. The guiding principle here is that the more your tests look like the way your software is supposed to be used, the more confidence running them can give you. It’s much lighter and easier to get started with than Enzyme (which on the other hand has a lot more functions) and is the recommended testing app according to React’s docs.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/00d43/test.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tests" title="Tests" src="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/fcda8/test.png" srcset="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/12f09/test.png 148w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/e4a3f/test.png 295w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/fcda8/test.png 590w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/efc66/test.png 885w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/00d43/test.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>UI</h2>
<p>If it goes for out of the box React components there’s a bunch of useful libraries made by the community to check out. Using these can help you in a variety of ways by providing practical and reusable solutions, which really impact the time and effort development takes.</p>
<ul>
<li><strong><a href="https://react-bootstrap.github.io/">React Bootstrap</a>:</strong> a UI kit which replaces Bootstrap’s JavaScript with React code. Arguably the best way to quickly start building UI as it has thousands of ready to use themes and resources. No wonder it’s among the most popular component libraries with over 700k weekly downloads on NPM.</li>
<li><strong><a href="https://material-ui.com/">Material UI</a>:</strong> a set of components created by Google based on their famous material design protocols. The components are self-sustaining in nature and only inject the styles they need to display. It also provides a lot of accessible and configurable UI widgets and ready to use site templates. This makes for a pretty significant performance boost especially considering the library is regularly updated and has very strong community support with over 60k stars on GitHub and is probably the most popular component library with over 1,6 mln weekly downloads on NPM.</li>
<li><strong><a href="https://rebassjs.org/">Rebass</a>:</strong> a tiny component library that packs a punch. Rebass contains only 8 components and weighs only 4 KBs but can be used to create a robust set of themable UI elements. It’s based on the Styled System library and focuses on providing a quick start for your development process. It’s really handy if you don’t want to rely too much on community component libraries or you intend to create your own custom UI.</li>
<li><strong><a href="https://react.semantic-ui.com/">Semantic UI React</a>:</strong> the official React integration for Semantic UI. This offers all the extra functions of the jQuery based re-scripted in React code. Comes with tons of prebuilt components designed specifically to make it easier to work with and produce Semantic-friendly code.</li>
<li><strong><a href="https://ant.design/">Ant Design</a>:</strong> a design system for enterprise level products. Based on the Ant Design project it provides you with over 60 high quality components crafted based on a design language developed by the creators. The components are customizable and include support for dozens of languages. The focus is on helping build rich, interactive UIs for internal desktop applications (no worries there’s also Ant Design Mobile for mobile apps)</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/00d43/ui.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="UI" title="UI" src="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/fcda8/ui.png" srcset="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/12f09/ui.png 148w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/e4a3f/ui.png 295w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/fcda8/ui.png 590w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/efc66/ui.png 885w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/00d43/ui.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Join up!</h2>
<p>Obviously that’s just a few popular libraries, there’s a myriad more and everyone will easily find some useful ones. Most of them aren’t complicated and take a short while to get a hang of, which is time well invested considering they usually speed up and simplify the development process by quite a bit. Creating everything yourself has its benefits, but all in all the rapidly growing and already sizable React community is probably the biggest advantage using it provides.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/react-libs-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373927</guid>
            <pubDate>Thu, 10 Dec 2020 14:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A DIY particle detector kit developed at CERN]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25373912">thread link</a>) | @kasbah
<br/>
December 10, 2020 | https://shop.kitspace.org/buy/electron-detector/ | <a href="https://web.archive.org/web/*/https://shop.kitspace.org/buy/electron-detector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A kit to make the electron detector variant of the DIY Particle Detector project.</p><p>This open hardware project is a mobile low-cost detector for measuring ionising radiation like electrons from beta radiation (plus some gamma photons). It's an educational tool and citizen science device made for exploring natural and synthetic sources of radioactivity such as stones, airborne radon, potassium-rich salt or food and every-day objects (Uranium glass, old Radium watches etc.).</p><p>This project is developed by Oliver Keller at CERN, see full project details <a href="https://kitspace.org/boards/github.com/ozel/diy_particle_detector/electron-detector/">here.</a></p><p>This is a kit to make your own electron detector. A required metal enclosure (see the<!-- --> <a href="https://github.com/ozel/DIY_particle_detector/wiki/Enclosures">wiki</a>) and a 9V battery are not included.</p><div><p><span>Worldwide Shipping (estimated delivery by Monday, December 21, 2020)</span></p><p><span>€15.00</span></p></div><p><b>Total: </b><b>€45.00</b></p></div></div>]]>
            </description>
            <link>https://shop.kitspace.org/buy/electron-detector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373912</guid>
            <pubDate>Thu, 10 Dec 2020 14:18:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercepting system calls to fix broken software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25373860">thread link</a>) | @todsacerdoti
<br/>
December 10, 2020 | https://yairchu.github.io/posts/intercept-to-fix | <a href="https://web.archive.org/web/*/https://yairchu.github.io/posts/intercept-to-fix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Apple sure like to change things, so when my new computer shipped with the new macOS 11.0, some things didn't work - specifically the Haskell compiler, GHC, failed linking my programs with OpenGL and other system libraries.</p>
<p><a href="https://gitlab.haskell.org/ghc/ghc/-/issues/18446">The problem</a> is already fixed in the GHC git repository, and I could try building it, but that might send me on new adventures due to more new-version behaviours, so instead I looked into working around the problem by making macOS 11 behave like macOS 10 did in the way that GHC expects!</p>
<h3 id="short-problem-description">Short problem description</h3>
<p>When linking with OpenGL, GHC verifies that the file <code>/System/Library/Frameworks/OpenGL.framework/OpenGL</code> exists, but it no longer does!</p>
<p>We can't add the file there (not even with <code>sudo</code>) because macOS's <code>/System</code> folder is special.</p>
<h3 id="solution">Solution</h3>
<p>We can trick GHC to believe that the file exist, and then everything would work!</p>
<p>This can be done by hijacking its calls to the <a href="https://en.wikipedia.org/wiki/Stat_(system_call)"><code>stat</code></a> system call and returning fake results.</p>
<p>MacOS lets us inject additional code into programs using the <code>DYLD_INSERT_LIBRARIES</code> environment variable, and it also supports special pragmas to tell it to replace library functions (aka "interpose" or "hook").</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>int</span> my_stat (<span>const</span> <span>char</span>* <span>restrict</span> path, <span>struct</span> stat* <span>restrict</span> buf)</span>
<span id="cb1-2">{</span>
<span id="cb1-3">    <span>if</span> (STARTS_WITH (<span>"/System/Library/Frameworks/"</span>, path))</span>
<span id="cb1-4">    {</span>
<span id="cb1-5">        <span>// Pretend that the file exists</span></span>
<span id="cb1-6">        <span>return</span> <span>0</span>;</span>
<span id="cb1-7">    }</span>
<span id="cb1-8">    <span>return</span> stat (path, buf);</span>
<span id="cb1-9">}</span>
<span id="cb1-10"></span>
<span id="cb1-11">DYLD_INTERPOSE (my_stat, stat)</span></code></pre></div>
<p>The above injected code tricks GHC to believe that any file inside <code>/System/Library/Frameworks/</code> exists, and that makes it work!</p>
<p>To work around the problem when executing <code>ghc</code> from a build system, it takes a bit more work to make sure that the injection propagates to it, but my complete solution isn't too long, see: <a href="https://github.com/yairchu/macos11-haskell-workaround/">github.com/yairchu/macos11-haskell-workaround</a></p>
<ul>
<li><img src="https://yairchu.github.io/images/reddit.svg" alt="reddit"> <a href="https://www.reddit.com/r/haskell/comments/k9r2cy/workaround_for_haskell_woes_on_macos_11_big_sur/">r/haskell discussion</a> on this work-around</li>
<li>I want to get this workaround into the Haskell build tool <code>stack</code>, if you want that too then please share your opinion on <a href="https://github.com/commercialhaskell/stack/issues/5456">the issue</a>!</li>
<li>FYI: The Linux equivalent of <code>DYLD_INSERT_LIBRARIES</code> is called <a href="https://tbrindus.ca/correct-ld-preload-hooking-libc/"><code>LD_PRELOAD</code></a>, and it can do similar things on Linux.</li>
<li>Image by <a href="https://pixabay.com/illustrations/vaccine-syringe-antidote-cure-3314164/">LillyCantible</a> from PixaBay.</li>
</ul>

    <!--Share buttons-->
    
</article></div>]]>
            </description>
            <link>https://yairchu.github.io/posts/intercept-to-fix</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373860</guid>
            <pubDate>Thu, 10 Dec 2020 14:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never work as a software engineer in a startup]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25373431">thread link</a>) | @veebuv
<br/>
December 10, 2020 | https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup | <a href="https://web.archive.org/web/*/https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I'm speaking in front of 200 people tomorrow on the topic around software development for startups. There are hundreds of books written on this so I'll try to condense my learnings from most.</p><p>Even though we're a startup company at <a href="#"></a><a href="#"></a><a href="#"></a><a href="#"></a>, I stopped hiring software engineers, hell I tried to unlearn and relearn a few things in the journey as well.</p><p>Confusing I know - I still have to grapple around the entirety of it all but the honest truth is being a software engineer alone will get you easily fired or unvalued in a startup.</p><p>You need to fire yourself from that role and re-hire yourself as a product engineer. I've referenced this point multiple times in my previous articles and I really stand by this.</p><p>I don't think this necessarily applies for larger companies when they're hiring specialists and algo heavy engineers, however in a startup you need to think about the product, the marketing and most important the customer.</p><p>There is a significant disconnect in larger firms from the creator (developer) to the end user, all the way from hierarchy, to Project Managers, to Product Managers, to Marketers, to Execs etc - but in a startup, if you push code up... it's up.</p><p>So whats so special about being a product engineer that a software engineer can't do? A few things:</p><h3>1. They carry a get shit done attitude</h3><p>Sure some engineers carry that too, these statements aren't binary or exclusive but address the vast majority. When you look at github discussions or you look at conference events where people share their discoveries, it's all based around the engineer - not as much around the customer.</p><p>So yes, product engineers have a get shit done attitude, keeping in mind that they need to push good work out, but are quick on their feet to understand how much of debt some technical decisions will be vs others. This will be understood better over time, and even after a decade of programming, I can confirm that there is no right or wrong answer, its extremely situational based.</p><h3>2. Business first, software second</h3><p>You should toughen up and realise that building on the latest and greatest tech will not make you a better engineer. You almost NEVER have as much a good reputation for being the engineer for a bad startup as you may of a good startup, even though your code in the bad startup might be worthy of awards and your code in the good startup might be worthy of firing. It's inherent you see - good code isn't coincidentally in good companies, its because the companies made the smart decision of hiring mini-CTOs, people who understood that their customer mattered as much as their code.</p><p>This doesn't mean you give up all morals and build on PHP(I'M JOKING :p), but it kinda does. Not PHP but any language that is deemed unfit just because it's popular or not. You do a direct risk analysis on what will get me to my next goal ASAP. Whether that's faster iteration, more features or modularised code bases.</p><h3>3. Customer first, business second</h3><p>It should all come down to how you can make the life of the customer as easy as possible when you're solving the problem for them. Sometimes business requirements become business requirements and not customer requirements, and if you're just a software engineer by title, you will be doing what you're told to do because thats the limitation you have, at least the limitation I had a couple of years ago.</p><p>By stepping out of that box and understanding that if the business requirements step outside of the customer requirements, you get to voice your opinion and more importantly add the kicker to your "opinion" by justifying it with your technical abilities, techies are badass, we're the makers, so in the end if we have the knowledge around consumerism AS well as execution, it'll make us bulletproof.</p><p>So yes, if you're in a startup - don't work as a software engineer, work as a product engineer. Your impact will be 10X I kid you not.</p><p>People will take you ALOT more seriously, you'll climb the ranks faster, your code will matter a lot more, and the impact will be at scale. Your work matters and there should be no reason why more people shouldn't experience your genius code, the way you can make that happen is by being product focused and ensuring your customers are having the best time of their life.</p><p>As with any post, I'm always always looking to learn and become better at what I do, so I'd love to hear what you have to say, good or bad 🙌</p><p>If you liked this, definitely follow me on for the similar stuff:</p><p>twitter: twitter.com/<a href="https://dev.to/veebuv">@veebuv</a><br>linkedin: linkedin.com/in/vaibhavnamburi<br>instagram:_veebuv</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373431</guid>
            <pubDate>Thu, 10 Dec 2020 13:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AR with SceneKit and Metal]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25373105">thread link</a>) | @emllnd
<br/>
December 10, 2020 | https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/ | <a href="https://web.archive.org/web/*/https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recently I found myself needing to process and visualize both point clouds and meshes in an iOS application utilizing ARKit, with the point cloud being gathered using the 2020 iPad “LiDAR” sensor. To enable maximum performance and content creation convenience I thought it would be nice to have both custom shaders and a regular, easy-to-work-with 3D hierarchy available. The best options available seemed to be Metal and SceneKit, which required some initial setup to get working together. That setup is detailed in this post.</p>
<p><em>If all this sounds unfamiliar see <a href="https://blog.halide.cam/lidar-peek-into-the-future-with-ipad-pro-11d38910e9f8">here</a>, <a href="https://developer.apple.com/metal/">here</a> and <a href="https://www.raywenderlich.com/2243-scene-kit-tutorial-getting-started">here</a> for introductions to these technologies.</em></p>












<a href="https://emillindfors.com/img/blog/2020-12/sceneKitAndPointCloud.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/sceneKitAndPointCloud.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/sceneKitAndPointCloud.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/sceneKitAndPointCloud.jpg">
    </picture>
</a>

<p>To help you recreate what I did, the post is accompanied by a GitHub repository showing the specifics: <a href="https://github.com/emllnd/ar-with-scenekit-and-metal">github.com/emllnd/ar-with-scenekit-and-metal</a>.</p>

<p><em>Note that the repo uses slightly confusing naming. XCode project name is “smTest” (for “SceneKit Metal test”), which leads to combinations such as smTestTest for the auto-generated unit testing project… not the best choice, but bear with me.</em></p>
<p><em>Also note that this is not really beginner level stuff, nor is having both SceneKit and Metal rendering usually required. If you just want to do some 3D+AR on iOS, good tech to start with would likely be either <a href="https://developer.apple.com/documentation/realitykit/">RealityKit</a>+<a href="https://developer.apple.com/documentation/realitykit/creating_3d_content_with_reality_composer">RealityComposer</a>, the more widely applicable tool <a href="https://tutorialsforar.com/creating-an-ar-app-for-ios-using-unity-and-arkit/">Unity</a> or just plain <a href="https://blog.pusher.com/building-an-ar-app-with-arkit-and-scenekit/">SceneKit</a>.</em></p>

<p>RealityKit seems like the future, but I was interested in custom shaping of meshes at runtime with e.g. geometry shaders and there did not (yet?) seem to be hooks for integrating that kind of processing in RealityKit.</p>
<p>Turns out those hooks do exist in SceneKit, which is an older and more mature technology. They can be used to implement custom render steps either before or after regular rendering. A helpful blog post with details that aided me with the ‘<strong>renderer didRenderScene</strong>’ hook can be found here: <a href="https://rozengain.medium.com/custom-metal-drawing-in-scenekit-921728e590f1">Custom Metal Drawing in SceneKit</a>. Thanks for the writeup Mr. Ippel!</p>
<p>I chose to get started with combining ARKit, SceneKit and custom Metal rendering by mashing two of Apple’s example applications together:</p>
<ul>
<li>The Scene Depth demo app (<a href="https://developer.apple.com/documentation/arkit/visualizing_a_point_cloud_using_scene_depth">Visualizing a Point Cloud Using Scene Depth</a>)</li>
<li>The default SceneKit AR project created by the XCode project wizard (creation steps depicted below)</li>
</ul>












<a href="https://emillindfors.com/img/blog/2020-12/newSceneKitARProj.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/newSceneKitARProj.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/newSceneKitARProj.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/newSceneKitARProj.jpg">
    </picture>
</a>


<p>The trickiest part was to get the depth blending working correctly. SceneKit and the custom Metal renderer of the Point Cloud demo use different depth buffer conventions, which caused a few moments of initial confusion before realizing I would have to adjust depth settings to make them compatible.</p>
<p>Initial depth buffer ranges <em>(from memory, might be incorrect)</em>:</p>
<ul>
<li>
<p>SceneKit:</p>
<ul>
<li>empty = zero</li>
<li>growing towards camera</li>
<li>range around 0.00-0.05</li>
</ul>
</li>
<li>
<p>SceneDepthPointCloud Metal renderer</p>
<ul>
<li>empty = negative infinity(?)</li>
<li>shrinking towards camera</li>
<li>range around 1.0-9.9995</li>
</ul>
</li>
</ul>
<p>To make the depth blending behave nicely and consistently, it was needed to set the proper depth blending mode (<em>shown as DepthStencilState –&gt; DepthCompareFunction in the XCode Frame Debugger</em>), to find matching value ranges for both depth buffers and to keep the 3D scenes of both renderers in their respective camera frustums (having good values for znear and zfar) so that they would not get culled off by being too near or too far.</p>












<a href="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameDebug.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/xcodeGPUFrameDebug.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameDebug.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/xcodeGPUFrameDebug.jpg">
    </picture>
</a>


<p>If you’re working in a recent Apple dev environment in a fairly empty project, there’s a good chance you can get started with GPU debugging right away. You just need to build and run your app and press the camera icon (and wait a bit):</p>












<a href="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/xcodeGPUFrameCaptureButton.jpg">
    </picture>
</a>

<p><em>(from here: <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools/viewing_your_frame_graph">Viewing Your Frame Graph</a>)</em></p>
<p>If you crave more in-depth GPU debug options or have trouble getting started, more info can be found on the page about <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools">Frame Capture Debugging Tools</a> as well as the guide page for <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools/enabling_frame_capture">Enabling Frame Capture</a>.</p>

<p>For more specific details on how I combined the two renderers, see the changes included in the first few commits (Nov 24th &amp; 28th) on the <a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commits/main">commits page</a> of the example repository. It shows the history of how I:</p>
<ul>
<li>started with a blank SceneKit AR project using the Project Wizard (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/3d5358507d2824d0d57335d6988ec81d20291b9d">Initial commit</a>)</li>
<li>added custom Metal rendering as per Mr. Ippel’s <a href="https://rozengain.medium.com/custom-metal-drawing-in-scenekit-921728e590f1">post</a> (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/75ad32f2012594ba3c09df9f351299d64f0ecb59">draws simple triangle, …</a>)</li>
<li>copied in the <a href="https://developer.apple.com/documentation/arkit/visualizing_a_point_cloud_using_scene_depth">SceneDepthPointCloud</a> demo and made sure the application still builds (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/cbcdaf130a288a7ad68cd2a848ddd671269b93d6">builds with SceneDepthPointCloud …</a>)</li>
<li>fiddled with accumulation settings etc confusedly to get the thing closer to working (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/39ba6d28e7f22ae202e20344c503a2136932f3ff">almost works …</a>)</li>
<li>and finally adjusted the depth blending, depth range and camera frustum settings to be able to see both scenes together (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/4a60df6c60b380d72ec740171c3440ffa09ddc23">improved …</a>, <a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/39c9a0e7a997567ca978e1190b67cd2af9790666">draws both …</a>)</li>
</ul>

<p>The end result of all these steps can be seen in motion below. It is of course merely the starting point for a more interesting application that leverages the ease and speed of regular 3D asset workflows and selectively applies the power of customized GPU processing as needed.</p>



<p><iframe src="https://player.vimeo.com/video/485931370?title=0&amp;byline=0&amp;portrait=0" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>



<p>At the time of first publication of this post (Dec 2020) I’m not sure if the depth buffer is entirely in sync between the two renderers, even though they both do render simultaneously. The point cloud looks alright behind the rocketplane(? 😄), but I’m not sure whether they behave correctly in overlap situations. However, the fix should be just a matter of adjusting camera and depth buffer parameters and possibly scene scale (<em>famous last words…</em>).</p>
<p>If and when time permits, I will update the post and the repository with improved details.</p>
<p>Thanks for reading!</p>


    	</div></div>]]>
            </description>
            <link>https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373105</guid>
            <pubDate>Thu, 10 Dec 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons from Running a Sale That Earned 3 Month's Profit in a Week]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25372636">thread link</a>) | @czue
<br/>
December 10, 2020 | https://www.coryzue.com/writing/black-friday/ | <a href="https://web.archive.org/web/*/https://www.coryzue.com/writing/black-friday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
                <p>A few weeks ago I was in a bad place.</p>

<p>My product Pegasus—a <a href="https://www.saaspegasus.com/">Django boilerplate for SaaS applications</a>—was 
having its worst sales slump in recent history.
Meanwhile, my other product, Place Card Me—an <a href="https://www.placecard.me/">online place card maker</a>—continued
to be hit hard by the pandemic, with sales down almost $10,000 from 2019.
It looked like I was going to fall short on my targets for the month. 
<em>Again</em>.</p>

<p><img src="https://www.coryzue.com/images/black-friday/place-card-me-2020.png" alt="Place Card Me"></p>

<p>The grey line is Place Card Me’s profits in 2019. The purple line is 2020. Thanks, Covid.</p>

<p>And then on a lark I thought, “well maybe I’ll try running a Black Friday sale.”</p>

<p><strong>And my month’s trajectory completely changed.</strong></p>

<p>A few hours of work and a week later, and I had shattered my previous earnings for any month—earning
more than 3 months’ worth of typical profit in a single week.</p>

<p>Through the process, I learned a lot about running sales—lessons I thought I should share.
Because Black Friday <em>is</em> a huge opportunity for online creators and indie hackers. 
One that—if you’re anything like me—you’re probably not taking full advantage of.</p>

<p>Here’s what I did and what I learned along the way.</p>

<h2 id="deciding-to-run-a-sale-by-overcoming-the-ickiness-factor">Deciding to run a sale by overcoming the “ickiness factor”</h2>

<p>If you’re like me, your first reaction to the idea of a Black Friday sale might be something along the lines of 
“ugh, those are so overdone and spammy”.
And it’s true, Black Friday and Cyber Monday sales have become ubiquitous online.</p>

<p><em>But Black Friday sales aren’t inherently bad.</em></p>

<p>Many consumers, including myself, happily take place in Black Friday deals.
They’re a great way to support creators and pick up products you’ve long considered buying.</p>

<p>To get over my fear of “Black Friday ickiness”, I decided to turn to other successful creators who were also running deals.
Adam Wathan and Steve Shoger of <a href="https://tailwindui.com/">Tailwind UI</a> / <a href="https://refactoringui.com/">Refactoring UI</a>;
online educator extraordinaire <a href="https://wesbos.com/">Wes Bos</a>;
fellow solopreneur <a href="https://mtlynch.io/">Mike Lynch</a> for his product <a href="https://tinypilotkvm.com/">TinyPilot</a>.
How were they doing Black Friday and what could I learn from them?</p>

<p>My favorite example came from Wes Bos, which <a href="https://marketingexamples.com/">Harry’s Marketing Examples</a>
did a great job analyzing:</p>

<p><img src="https://www.coryzue.com/images/black-friday/wes-bos-black-friday.jpeg" alt="Wes Bos Black Friday"></p>

<p>Wes Bos’s “masterful” Black Friday email. Image and analysis from <a href="https://twitter.com/GoodMarketingHQ/status/1331573176405536769">Harry’s Marketing Examples</a></p>

<p>This email and the others I looked at all shared similar qualities.
They were <em>genuine</em>, they <em>put the reader first</em>, and they <em>weren’t too pushy</em>.
It was “hey, here’s a great deal in case you’re interested, if not, sorry to bug you.”</p>

<p>Seeing that it was possible to run a deal in a classy way was enough to get me over the “ickiness” factor,
and provided a framework for crafting my own sales communications.</p>

<p><strong>Lesson: Running a sale doesn’t have to be “icky” if you do it right.</strong></p>

<h2 id="choosing-the-right-sale-structure-by-adding-value">Choosing the right sale structure by <em>adding value</em></h2>

<p>People expect Black Friday deals to offer a huge discount from normal prices—particularly 
for online products. Here’s a typical deal I received, with bundle of fonts being offered at 95% off 
the normal price:</p>

<p><img src="https://www.coryzue.com/images/black-friday/wild-ones-black-friday.png" alt="Wild Ones Font Bundle"></p>

<p>A typical Black Friday deal—offering 95%-off a bundle of commercial fonts.</p>

<p>Offering a huge discount is a great way to drive sales, but it comes with a huge cost. 
<em>Literally</em>. A big discount will substantially reduce your revenue-per-customer and 
leave money on the table.</p>

<p>And that’s not the only problem.</p>

<p>In addition to the lost revenue, <em>massive discounts devalue your product</em>.
If your customers know that you sometimes sell your product for 95% off, they’re likely 
to think it’s only worth 5% of it’s price.
<em>You’ve just turned your valuable good into a commodity.</em></p>

<p>So how do you run a sale without reducing your prices? <strong><em>You add value.</em></strong></p>

<p>Take Adam Wathan and Steve Shoger’s deal.
They took their two products, <a href="https://tailwindui.com/">Tailwind UI</a> (normally $249) and 
<a href="https://refactoringui.com/">Refactoring UI</a> (normally $149), and bundled them together for $279.
Their customers are simultaneously <em>saving $120</em> while <em>paying more than the price of either individual product.</em>
This is adding value at its finest.</p>

<p><img src="https://www.coryzue.com/images/black-friday/refactoring-ui.jpg" alt="Refactoring UI Black Friday"></p>

<p>The Tailwind UI / Refactoring UI deal—which used bundling to offer 30% off while simultaneously increasing prices.</p>

<p><em>Bundling</em>—what Adam and Steve did by offering two products together at a discount—is a great way to 
add value while not lowering prices.
A similar approach is to <em>offer increased benefits on a lower pricing tier</em>. 
This is the approach I took with my own product.</p>

<p>My product, <a href="https://www.saaspegasus.com/">SaaS Pegasus</a>, is designed to help people launch new web applications quickly.
Pegasus has two pricing tiers, a <em>single-site</em> version for $295, and an <em>unlimited</em> version for $750.
The product is the same, but the single-site version is only able to be used on—well—a single site,
while the unlimited version can be used on—you guessed it—unlimited sites.
The unlimited version also comes with lifetime updates to Pegasus itself, instead of just a year.</p>

<p>Anyway, the details aren’t important, but what <em>is</em> important is that more than 90% of my customers 
opt—at least initially—for single-site. 
So for my Black Friday deal I decided to offer the unlimited version at price of single-site. 
This allowed me to offer a 60% discount without significantly reducing my revenue per customer
or devaluing my product.</p>

<p>Whether you use bundling, the “increased benefits on a lower tier” approach, or something else, 
adding value is a great way to create a “Black Friday deal” feeling while not incurring 
some of the financial and psychological costs associated with heavy discounting.</p>

<p><strong>Lesson: Don’t lower prices, add value.</strong></p>



<p>Ok, you’ve gotten over the ickiness factor and you’ve chosen a sale structure that adds value.
Now’s the most important part: <em>spreading the word</em>.</p>

<p>When considering how best to get the word out, think of the following breakdown.
Everyone is either <em>interested</em> or <em>not interested</em> in your sale.
Likewise everyone will either <em>find out</em> or <em>not find out</em> about it.
This creates four buckets that any person might fall into:</p>

<p><img src="https://www.coryzue.com/images/black-friday/sale-matrix.png" alt="Sale Categorization Breakdown"></p>

<p>Breakdown of the possible ways people can experience your sale.</p>

<p>The two green boxes are what you’re aiming for. 
Of course, you want everyone who might be interested in the sale to find out about it—these are your potential customers!
Also, you want everyone who <em>isn’t</em> interested in the sale to not get spammed by it—the blissfully unaware.</p>

<p>The tradeoffs and mistakes happen in the red boxes.
What you really want to prevent is <em>lost customers</em>—people who would have been interested in the deal
but never knew it was happening.
You also want to annoy as few people as possible, but <em>it’s generally better to promote the deal to someone who wasn’t interested
than to have someone who was interested miss it</em>. 
The upside of a potential sale clearly outweighs the downside of mildly annoying someone.</p>

<p><strong>Lesson: Default to promoting everywhere that the signal-to-noise ratio isn’t terrible.</strong></p>

<h3 id="where-to-promote-your-sale">Where to promote your sale</h3>

<p>The key avenues for promotion—in order of importance—are your <em>website</em>, your <em>email list</em>, and <em>other online marketing channels</em>.</p>

<p><strong>Your website is your best source of potential customers.</strong></p>

<p>No one is more likely to be interested in your deal than someone who is already browsing your product website,
so you should do everything you can to ensure all website visitors see your deal.</p>

<p>I used the common technique of splashing a big-ass colorful banner on every page of the site.
Here’s what it looked like.</p>

<p><img src="https://www.coryzue.com/images/black-friday/pegasus-sale.png" alt="Pegasus Sale"></p>

<p>Don’t be shy promoting your sale on your website. These are the people most likely to benefit from it.</p>

<p>Your goal is to make it impossible for someone visiting your website to not hear of the sale,
so err on the side of flashy, even if it seems a bit much.</p>

<p><strong>Your email list is your next best source of potential customers.</strong></p>

<p>People on your email list were interested in your product at one point, and so are more likely
than almost anyone else to still be interested, so make sure to let them know!</p>

<p>My email sequence consisted of two mails:</p>

<ol>
  <li>An email at the start of the sale telling people about it.</li>
  <li>An email with 24 hours left in the sale telling people it was about to end.</li>
</ol>

<p>Some people add a third email in the middle—often with 48 hours to go. 
I don’t recommend more than 3 emails as you seriously risk pushing people 
further into the “annoyed” category.</p>

<p>In terms of email copy—you can’t do better than the Wes Bos example above.
But for the sake of transparency, here’s the mail I used:</p>

<p><img src="https://www.coryzue.com/images/black-friday/pegasus-email.png" alt="Pegasus Email"></p>

<p>The first email in my sequence announcing the Pegasus Black Friday deal.</p>

<p>One difference between Wes and I is that my email list is <em>cold</em>—I almost never use it.
So I added a reminder for people who might be wondering what Pegasus even was.
I also included details on some new features to show that I’m still improving the product.</p>

<p><strong>All other channels besides your website and email list are a distant third in terms of usefulness.</strong></p>

<p>For this reason, I severely limited promotion in other places unless they were 
specifically aggregating Black Friday deals—and therefore unlikely to annoy anyone.</p>

<p>Depending on your product and audience, social media can be a good channel, though it’s not for Pegasus
so I didn’t bother promoting there.<sup id="fnref:2"><a href="#fn:2">1</a></sup></p>



<p>It’s important to realize that unless you did something very wrong, 
<strong><em>people will be more likely to purchase your product during a sale than at any other time.</em></strong></p>

<p>Now, if you’ve taken the advice above and are still getting good revenue-per-customer during
the sale, there is an interesting side-effect:
<strong>website traffic <em>during a sale</em> is more valuable than at any other time</strong>.</p>

<p>I’ll show you just how much more valuable it was for me in the next section <em>(preview: it was way more than I expected)</em>.</p>

<p>In practice, this means that any additional effort you can expend to get people to your website—for any reason—will 
have a higher payoff during a sale.</p>

<p>How you leverage this information depends on your marketing strategy.
If you’re running ads, consider increasing your budget while the sale is running;
if you do content marketing, consider publishing your next big article during the sale, etc.
These efforts—while not necessarily directly related to the sale—will have the side-effect of getting
more eyes on your site at the exact moment your …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.coryzue.com/writing/black-friday/">https://www.coryzue.com/writing/black-friday/</a></em></p>]]>
            </description>
            <link>https://www.coryzue.com/writing/black-friday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372636</guid>
            <pubDate>Thu, 10 Dec 2020 11:47:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eisenhower Matrix – How to Prioritise and Master Tasks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25372423">thread link</a>) | @rossnoel
<br/>
December 10, 2020 | https://productive.fish/blog/eisenhower-matrix/ | <a href="https://web.archive.org/web/*/https://productive.fish/blog/eisenhower-matrix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>30 Oct 2020 • 5 min read</p><p>Throughout his life, President Dwight D. Eisenhower was well known as a man of productivity. Before he was president, he was a five start general of the US Army, being a key strategist for many invasions against the Nazis in World War II. On becoming President, he launched many of the significant projects and departments that are still integral to the USA today, such as the interstate highway system, NASA and DARPA. His productivity became well-renowned and researched, and by far one of the most useful strategies he's credited for devising is the Eisenhower Matrix. A simple method to deploy in our everyday lives, it can help you increase productivity, avoid procrastination, and order your workflow. So, what exactly is it and how does it work?</p><picture><source type="image/webp" media="(min-width: 1100px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix@2x.webp 2x"><source type="image/webp" media="(max-width: 1099px) and (min-width: 421px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md@2x.webp 2x"><source type="image/webp" media="(max-width: 420px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm@2x.webp 2x"><source media="(min-width: 1100px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix@2x.jpg 2x"><source media="(max-width: 1099px) and (min-width: 421px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md@2x.jpg 2x"><source media="(max-width: 420px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm@2x.jpg 2x"><img src="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.jpg" alt="Illustration of person watching on Eisenhower Matrix and thinking"></picture><h2 id="what-is-the-eisenhower-matrix%3F">What is the Eisenhower Matrix?</h2><p>The method begins by creating a 2x2 matrix. On the X axis of our matrix we have Urgent and Not Urgent. On the Y axis, we have Important and Not Important. With these different boxes, we have four quadrants, each with a different value, and as such, each to be handled very differently.</p><p>The four quadrants are essentially divided into the following categories:</p><ul><li>Urgent and important - <strong>do it</strong></li><li>Important, but not urgent - <strong>schedule it</strong></li><li>Urgent, but not important - <strong>delegate i</strong>t</li><li>Neither urgent, nor important - <strong>eliminate it</strong></li></ul><p>The Eisenhower Matrix teaches us to swiftly recognise the importance and urgency of tasks on our to-do lists. By categorising the tasks in the above way we can figure out which ones to prioritise, which to put on the back-burner for later, which to delegate, and which to eliminate. This will both put your to-do list in an order of priority, and shrink it down.</p><p>But how do we distinguish between “urgent and important” and everything in between?</p><h2 id="what-are-%22urgent%22-and-%22important%22-activities%3F">What Are "Urgent" and "Important" Activities?</h2><p>Important things are, well, important.They are the things that move us closer to our defined goals, dreams, and aspirations in life. They have meaning and impact to what actually matters to us in our lives. Running in alignment with your values, important things include, going to the gym, spending time with your family, or coming up with a strategic plan for your business.</p><p>On the other hand, we have urgent things. Urgent things require your immediate attention like a call from an angry customer, or picking up your kid from the nurse's office at school.</p><p>More often than not, things don’t tend to be both important and urgent. A lot of the time we mistake urgent tasks as being inherently important, with their acute timeframe masking the true value of what they actually represent in our lives.</p><p>The Eisenhower Matrix is an amazing tool to combat this frequent “mislabelling” of tasks in our workflow, and by mapping out a matrix of urgency and importance, we get a clearer picture of what’s on our slate.</p><h2 id="how-to-use-the-eisenhower-matrix-effectively">How to Use the Eisenhower Matrix Effectively</h2><p>In order to implement the Eisenhower Matrix effectively, one must identify which of the four quadrants a task or a project sits in, and then give it the appropriate action. So what are the traits that come with each category, and (having filed the task appropriately) what should you do with it?</p><h3 id="quadrant-one%3A-urgent-and-important">Quadrant One: Urgent and Important</h3><p>These are tasks that are not only important, but also time sensitive. These might include taking care of a sick relative, addressing an order-dispute for your biggest customer or fixing a crucial bug on the company website. Hopefully you shouldn’t have too many of these but something landing in this box should be done immediately with everything else put aside to make space for it.</p><h3 id="quadrant-two%3A-important%2C-but-not-urgent">Quadrant Two: Important, But Not Urgent</h3><p>This is where some of the most important things in our lives live, and yet many people will see tasks piling up here. Why? Because these jobs are not urgent we often let them slide or delay into the indefinite. Whilst they might not have the immediacy of Quadrant One tasks, it’s important to recognise they are truly no less important.</p><p>These tasks include long-term strategy and planning meetings with your team, performing regular website maintenance, exercising, spending quality time with your friends and family, meditating, and sleeping enough.</p><p>These things won't pop out at you with red flashing lights, but there's no denying that they are extremely important. Indeed if not taken care of, they could soon turn into a hoard of urgent jobs bashing on the door of Quadrant One.</p><p>When it comes to Quadrant Two tasks, stop procrastinating and make a decision. Ask yourself, “When will I sit down and do these things?”. If you're a business owner or a manager in a company, these tasks are probably the most significant part of your job. It’s tempting to ignore Quadrant Two for the sake of addressing Quadrant Ones and Quadrant Threes, but come under no illusions, these need to be tackled, so schedule them in and stick to those deadlines.</p><h3 id="quadrant-three%3A-urgent%2C-but-not-important">Quadrant Three: Urgent, But Not Important</h3><p>We all hate to admit it, but a lot of the stuff we do, whilst urgent, is actually not important at all. For example, monitoring comments on your website or social media, attending a quarterly business update, or scheduling a Zoom meeting. Of course these are worth doing, but they’re just not important. Certainly not enough for you to actually do them yourself. That's why the answer to Quadrant Three tasks is a simple one: delegate. Find a technological solution, an automation, or a human being who can help you with this task and pass it off to them. Ideally you want to spend as little of your time as possible in Quadrant Three.</p><h3 id="quadrant-four%3A-not-urgent%2C-and-not-important">Quadrant Four: Not Urgent, and Not Important</h3><p>These represent a large category of tasks that aren't worth your time or anyone else’s for that matter (not even that programme or person you got to help you out in Quadrant Three). Some of these may be enjoyable, but they're not moving you towards your desired goals in any way, shape, or form. Things like watching television or scrolling through social media for example. While Quadrant Four tasks inevitably pervade our lives, look to try and eliminate these activities as much as possible.</p><h2 id="how-to-use-the-eisenhower-matrix-to-increase-productivity">How to Use the Eisenhower Matrix To Increase Productivity</h2><p>The Eisenhower Matrix is especially useful if you find yourself dealing with excessive amounts of work. With an overabundance of tasks, taking a bit of time to categorise your jobs into the four quadrants above can restore order to an otherwise chaotic workflow.</p><p>It’s also good to incorporate the overarching philosophy of this time management matrix into your daily workflow. Whether it’s on a daily or weekly basis, the Eisenhower Matrix will help prioritise the items on your to-do list. Look to commit to scheduling or prioritising your tasks as per the above, and you’ll find yourself with a clearer and more effective work-day</p><h2 id="conclusion">Conclusion</h2><p>The nature of our work-environment today, as shaped by email, instant messaging and the like, means we feel constantly in need of prioritising our requests in order of when the message was received. However, this approach often leaves us with a feeling of dissatisfaction with our own productivity, finding that the majority of the day has been spent handling items we could have delegated or just eliminated, and jobs that don’t progress our life-goals or objectives.</p><p>Instead, the Eisenhower Decision Matrix provides an excellent framework to help you cut through the clutter and finish your most important work in record time, whilst making sure you’re not wasting precious hours and minutes on things that can either be done elsewhere or just not at all. By giving you the skill of distinguishing between which tasks truly demand your attention, and those that don’t, the Eisenhower Box will keep you focused on what’s important, and in doing so change not just the output you see in your day or your week, but also your life.</p></article></div>]]>
            </description>
            <link>https://productive.fish/blog/eisenhower-matrix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372423</guid>
            <pubDate>Thu, 10 Dec 2020 11:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnt $72k testing Firebase and Cloud Run and almost went bankrupt]]>
            </title>
            <description>
<![CDATA[
Score 249 | Comments 347 (<a href="https://news.ycombinator.com/item?id=25372336">thread link</a>) | @bharatsb
<br/>
December 10, 2020 | https://blog.tomilkieway.com/72k-1/ | <a href="https://web.archive.org/web/*/https://blog.tomilkieway.com/72k-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>                
			<blockquote>
  <p>This is the story of how close we came to shutting down before even launching our first product, how we survived, and the lessons we learnt.</p>
</blockquote>

<p>In March, 2020, when COVID hit the world, our startup Milkie Way too was hit with a big blow and almost shut down. <strong>We burnt $72,000 while exploring and internally testing Cloud Run with Firebase within a few hours.</strong></p>

<p>In November 2019, after having the idea, I started developing <strong>Announce <a href="https://annc.in/">https://announce.today</a></strong>. The goal was to create an “MVP”, a functional V1 of the  product, and for this reason our code was based on a simple stack. We used JS, Python and deployed our product on Google App engine.</p>

<center>
<em>Announce on Desktop</em>
<img src="https://blog.tomilkieway.com/assets/images/post_images/anc-first-look.png" width="100%"><br>
</center>

<p>Having a very small team, our focus was on writing code, designing the UI and getting product ready. I spent minimal time in Cloud management, just enough to make us go live, and have basic development flow (cicd) going.</p>

<p>In the V1 web application, user experience was not the smoothest, but we just wanted to make a product that some of our users could experiment with, while we built a better version of Announce. With Covid hitting the world, we thought it was the best time to make a difference as Announce could be used by the governments to make announcements world wide.</p>

<p>Wouldn’t it be cool to have some rich data on the platform even if users don’t create content to begin with? This thought that led to another project, called <strong>Announce-AI</strong>. It’s purpose was to create rich content for Announce automatically. Rich data == events, safety warnings like earthquakes, and possibly local relevant news.</p>

<h3 id="some-technical-details">Some Technical Details</h3>
<p>To begin developing Announce-AI, we used Cloud Functions. As our bot scraping the web was fairly young, we believed light weight Cloud functions were the way to go. However, as we decided to scale, we ran into troubles because Cloud Functions have a timeout of ~9 minutes.</p>

<p>At this time we learn about Cloud Run, which then had a big free usage tier! Without understanding it completely, I asked my team to deploy a “test” Announce AI function on Cloud Run, and see it’s performance. The goal was to play around with Cloud Run, so we can learn and explore it really fast.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/cloud-run.jpg" width="80%"><br>
<em>Google Cloud Run</em></center>

<p>To keep it simple, as our experiment was for a very small site, we used Firebase for database, as Cloud Run doesn’t have any storage, and deploying on SQL server, or any other DB for a test run would have been an over kill.</p>

<p>I created a new GCP project ANC-AI Dev, set up $7 Cloud Billing budget, kept Firebase Project on the Free (Spark) plan. The worst case we imagined was exceeding the daily free Firestore limits if we faltered.</p>

<p>After some code modifications, we deployed the code, ran it by making few requests in middle of the day manually and then left it.</p>

<h3 id="nightmare-begins">Nightmare Begins</h3>
<p>Everything went fine on the day of test, and we got back to developing Announce. Next day after working, I went for a quick nap in late afternoon. On waking up I read few emails from Google Cloud, all sent within few minutes of each other.</p>

<center>
<em>First Email: Auto upgrade of our Firebase Project</em>
<img src="https://blog.tomilkieway.com/assets/images/72K/auto-upgrade.jpg" width="80%"><br>
</center>

<center>
<em>Second Email: Budget Exceeded</em>

<img src="https://blog.tomilkieway.com/assets/images/72K/budget.jpg" width="80%"><br>
</center>

<p>Luckily my card had a spending limit of $100 preset. This led to declining the charges, and Google suspending all our accounts with it.</p>

<center>
<em>Third email: Card was declined</em>

<img src="https://blog.tomilkieway.com/assets/images/72K/card-declined.jpg" width="80%"><br>
</center>

<p>I jumped out of the bed, logged into Google Cloud Billing, and saw a bill for ~$5,000. Super stressed, and not sure what happened, I clicked around, trying to figure out what was happening. I also started thinking of what may have happened, and how we could “possibly” pay the $5K bill.</p>

<p>The problem was, every minute the bill kept going up.</p>

<p>After 5 minutes, the bill read $15,000, in 20 mins, it said $25,000. I wasn’t sure where it would stop. Perhaps it won’t stop?</p>

<p>After two hours, it settled at a little short of $72,000.</p>

<p>By this time, my team and I were on a call, I was in a state of complete shock and had absolutely no clue about what we would do next. We disabled billing, closed all services.</p>

<p>Because we used same company card across all our GCP Projects, all our accounts and projects were suspended by Google.</p>

<h3 id="nightmare-continues">Nightmare Continues</h3>
<p>This happened on Friday evening, March 27th, 3 days before we had planned V1 of Announce to go live. Our product development was dead as Google suspended all our projects as they were tied to same credit card. My morale was as low as it could be, and the future of our company was unsure.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/suspended.jpg" width="80%"><br>
<em>All our Cloud Projects were suspended; development stopped</em></center>

<p>Once my mind made peace with this new reality, at midnight I sat down to actually investigate what happened. I started writing a document detailing all the investigations… I called this document: “Chapter 11”.</p>

<p>Two of my team members who were in this experiment also stayed up all night investigating and trying to make sense of what had happened.</p>

<p>The next morning on Saturday, March 28th, I called and emailed over a dozen law firms to book an appointment / have a chat with some attorney. All of them were away, but I was able to get response from one of them over email. Because the details of the incident are so complicated even for engineers, explaining this to an attorney in plain english was a challenge of its own.</p>

<blockquote>
  <p>As a bootstrapped company, there was no way for us to come up with $72K.</p>
</blockquote>

<p>By this time, I was well versed with Chapter 7 and Chapter 11 of Bankruptcy and mentally prepared of what could come next.</p>

<h3 id="some-breather--gcp-loopholes">Some Breather : GCP Loopholes</h3>

<p>On the Saturday after sending emails to lawyers, I started reading more and going through every single page in GCP Documentation. We did make mistakes, but it didn’t make sense that Google let us spend $72K without even making a payment on the project before!</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/firebasegcp.jpg" width="80%"><br>
<em>GCP and Firebase</em></center>

<h4 id="1-automatic-upgrade-of-firebase-account-to-paid-account">1. Automatic Upgrade of Firebase Account to Paid Account</h4>
<p>We never anticipated this, nor was this ever displayed while signing up for Firebase. Our GCP project had billing connected to have Cloud Run execute, but Firebase was under Free plan (Spark). GCP just out of the blue upgraded it, and charged us for the amount it needed to.</p>

<p>It turns out this is their process as “Firebase and GCP are deeply integrated”.</p>

<h4 id="2-billing-limits-dont-exist-budgets-are-at-least-a-day-late">2. Billing “Limits” don’t exist. Budgets are at least a day late.</h4>
<p>GCP Billing is actually delayed by at least a day. In most of their documentation Google suggests using Budgets and auto shut-off cloud function. Well guess what, by the time the cut off function would trigger, or the Cloud Users be notified, the damage would’ve probably been done.</p>

<p>Billing takes about a day to be synced, and that’s why we noticed the charges the next day.</p>

<h4 id="3-google-was-supposed-to-charge-us-100-not-72k">3. Google was supposed to charge us $100, not $72K!</h4>
<p>As our account had not made any payment thus far, GCP should’ve first made charge for $100 as <a href="https://cloud.google.com/billing/docs/how-to/billing-cycle#find-threshold-amount">per billing info</a>, and on non-payment, stopped the services. But it didn’t. I understood the reason later, but it’s still not the user’s fault!</p>

<p>The first billing charge made to our account was of ~ $5,000. The next one for $72,000.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/automatic-payments.jpg" width="100%">
<em>Billing threshold for our account was $100</em>

</center>

<h4 id="4-dont-rely-on-firebase-dashboard">4. Don’t rely on Firebase Dashboard!</h4>
<p>Not just Billing, but even Firebase Dashboard took more than 24 hours to update.</p>

<p>As per Firebase Console documentation, the Firebase console dashboard numbers may differ ‘slightly’ from Billing reports.</p>

<p>In our case, it differed by <strong>86,585,365.85 %</strong>, or 86 million percentage points. Even when the bill was notified to us, Firebase Console dashboard still said 42,000 read+writes for the month (below the daily limit).</p>

<h3 id="new-day-new-challenge">New Day, New Challenge</h3>
<p>Having been a Googler for ~6.5 years and written dozens of project documents, postmortem reports, and what not, I started a document to share with Google outlining the incident, and adding the loopholes from Google’s side in a postmortem. Google team would come back to work in 2 days.</p>

<p>EDIT: Some readers suggested that I used my internal contacts at Google. The truth is that I haven’t been in touch with anyone, and I used the path that any normal developer / company would take. Like any other small developer, I spent countless hours on chat, in consults, lengthy emails, and bugs. In one of my next posts on how to look at incidents, I’d like to share the doc/postmortem I sent to Google during this incident.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/googleplex.jpg" width="40%"><br>
<em>Last day at Google</em></center>

<p>Another task was to understand our mistake, and devise our product development strategy. Not everyone on the team knew what was going on, but it was quite clear that we were in some big trouble.</p>

<p>As a Googler I had experienced teams making mistakes costing Google millions of dollars, but the Google culture saves the employees (except engineers have to write a long incident report). This time, there was no Google. Our own limited capital and our hard work, was at complete stake.</p>

<hr>

<p>This post is already getting long, so I’ll continue the details of how we managed to make this blunder, how we survived, and what did we learn.</p>

<p>See you in <strong><a href="https://blog.tomilkieway.com/72k-2/">Part 2</a></strong>.</p>
                
			</article></div>]]>
            </description>
            <link>https://blog.tomilkieway.com/72k-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372336</guid>
            <pubDate>Thu, 10 Dec 2020 10:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deutsche Post to support DIY postal stamps (via handwritten code)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25372252">thread link</a>) | @tosh
<br/>
December 10, 2020 | https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327 | <a href="https://web.archive.org/web/*/https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Kunden sollen früh wissen, welche Briefe für sie unterwegs sind und wo sich Pakete befinden. Das Unternehmen will sich damit auch auf junge Kunden einstellen und sucht einen zeitgemäßen Weg für seine sehr analogen Produkte.</p><div itemprop="articleBody" data-testid="article-body"><p>Zwischen den Managern in schwarzen Anzügen strahlt ein Paketbote in gelb-roter DHL-Montur hervor. Wenn er nicht gerade bei der Vorstellung der neuen Digitalstrategie der Deutschen Post Modell steht, dann fährt Maik Berkholz mit einem 3,5-Tonner durch Berlin-Mitte. Seit zehn Jahren liefert Berkholz Pakete aus. Und neuerdings trägt er neben seinem Unterschriftgerät einen kleinen Drucker am Hosenbund. Denn Berkholz ist nicht mehr nur Paketbote, er frankiert auch Pakete und Briefe und nimmt sie im Lieferwagen mit. "Die Kunden finden das super", sagt er mit abgehacktem Berliner Zungenschlag, "wenn sie mir das mitgeben können und nicht bei der nächsten Filiale anstehen&nbsp;müssen."</p><p>Der kleine Drucker ist eine der vielen Ideen, mit der die Post eine dreifache Herausforderung meistern will: Ihre Kunden versenden von Jahr zu Jahr weniger Briefe, wenngleich die Menge in Deutschland bislang nicht so stark eingebrochen ist wie in anderen Staaten. Zugleich transportiert die Post immer mehr Pakete durchs Land, vor allem wegen des boomenden Onlinehandels. Die Bundesnetzagentur meldet freilich auch, dass sich immer mehr Menschen über die Post&nbsp;beschweren.</p><div><div data-hydration-component-name="ImageAsset"><figure><div><div><picture><source type="image/webp"><img alt="20 Jahre Briefzentrum Gera" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></picture></div></div><figcaption><p>Eine Mitarbeiterin arbeitet an der Briefsortierungsanlage im Briefzentrum in Gera, Thüringen.</p> <small>(Foto: Martin Schutt/dpa)</small></figcaption></figure></div></div><p>"Wir wollen die sichere Zustellung von Paketen und Briefen beibehalten, diese aber mit der Digitalisierung koppeln", sagt Tobias Meyer, der Brief- und Paketchef der Post in&nbsp;Deutschland.</p><p>Dass Kunden Boten wie Berkholz Pakete mitgeben, das ging zwar schon früher. Neu ist aber, dass der Kunde das Adress- und Frankierfeld nicht mehr aufkleben muss. Stattdessen kann Berkholz ein selbstklebendes Adressfeld und eine Marke aus seinem mobilen Drucker ausdrucken. Dafür scannt der Bote einen Code vom Handy des Kunden ein. Der Code wurde erstellt, nachdem der Kunde via Post-App auf seinem Smartphone das Porto bezahlt und die Adresse eingegeben hat. Die "mobile Paketmarke" für die "mobile Retour", so nennt es Manager&nbsp;Meyer.</p><p>Mit der Digitalstrategie will die Post neuen Bedürfnissen der Kunden gerecht werden, aber auch Geld sparen. Das Versenden, das Empfangen, das Nachverfolgen von Sendungen - selbst Vorabbenachrichtigungen, was morgen im heimischen Briefkasten ankommen soll: All das soll effizienter werden. Bei der Vorstellung in Berlin erklären Männer in schwarzen Anzügen und eine Frau die neuen&nbsp;Services.</p><h4>Abfotografierte Briefe</h4><p>Einer der Männer in schwarz zeigt an seiner Station ein E-Mail-Postfach, in dem lauter gelbe Mails von der DHL lagern. Denn vom kommenden Sommer an wird es für Nutzer von GMX und Web.de möglich sein, Fotos von ihren Briefen zu sehen, bevor sie ausgeliefert&nbsp;werden.</p><p>Dazu scannt die Post eintreffende Briefe ein, ohne sie zu öffnen, und der Empfänger bekommt eine Mail mit dem Foto der Umschläge. Damit kennt man zwar beispielsweise noch nicht die Höhe des Bußgeldbescheids, aber weiß, dass ein solcher auf dem Weg&nbsp;ist.</p><p>Kunden müssen sich für dieses Angebot anmelden. Eine weitere Station präsentiert den Prototypen einer künftigen App-Funktion, die es im Laufe dieses Jahres ermöglichen soll, nachzusehen, wo sich ein erwartetes Paket gerade befindet. Damit reagiert die Post nicht nur auf die vielen Beschwerden über verspätete oder verloren gegangene Sendungen. Experten gehen auch davon aus, dass die sogenannte letzte Meile zu den Adressaten etwa die Hälfte der Kosten von Paketdiensten ausmachen. Konzerne wie die Post können also viel Geld sparen, wenn sie erfolglose Zustellversuche verhindern. Das neue Tracking zeigt den Kunden, wie viele Stopps noch zwischen dem Paketboten und der eigenen Haustüre liegen. Außerdem will die Post künftig am Tag vor der Auslieferung ein Zeitfenster von 90 Minuten angeben, in dem der Paketbote vorbei kommt. Empfänger könnten auch kurzfristig noch mitteilen, falls das Paket beim Nachbarn abgegeben werden soll, im Hausflur abgelegt werden soll, oder in der nächsten&nbsp;Packstation.</p><h4>Erweiterte Packstation</h4><p>Zudem führt ein Postvertreter die Packstation der Zukunft vor, die im Videochat mit dem Kunden kommunizieren soll und ebenfalls Adressfelder und Portosticker drucken kann. Die Post möchte die Zahl der Packstationen von 4000 im Laufe des Jahres auf 7000&nbsp;erhöhen.</p><p>Politisch interessant ist diese Ankündigung, da das Bundeswirtschaftsministerium derzeit an einer Reform des alten Postgesetzes von 1997 arbeitet. Ein Streitpunkt dabei: Wie viele Filialen muss die Post künftig noch aufrechterhalten? Sollte der Gesetzgeber die erweiterten Packstationen als Verkaufsstellen auf dem Land akzeptieren, hätte es der Konzern künftig einfacher, die Vorgaben zu&nbsp;erfüllen.</p><h4>Selbstgemachte Briefmarken</h4><p>An der letzten Station führt die Post vor, wie sie das Briefgeschäft auch für sogenannte Digital Natives - also junge Leute, die mit dem Internet großgeworden sind - attraktiv halten will. Über eine App kann der Kunde die Höhe des Portos wählen, diese spuckt dann einen Code aus Zahlen und Buchstaben aus. Der Kunde schreibt den Code auf das Kuvert mit dem Zusatz "#Porto" - und fertig ist die selbstgemalte Briefmarke. Aber Moment, die Handschrift als Teil einer&nbsp;Digitalisierungsoffensive?</p><p>Was paradox anmutet, soll es Kunden von Ende 2020 an ermöglichen, mit ihrem Handy eine Marke zu generieren. Bezahlt wird die "mobile Briefmarke" über die App mittels dem verbreiteten Bezahldienst Paypal. Ist dies das Ende der bunten Bildchen auf randgezackten Briefmarken? "Nein, nein", wiegelt Post-Vorstand Meyer ab. Es würden nach wie vor Briefmarken angeboten. Zudem glaubt er, dass die Code-Briefmarke aus dem Smartphone nur eine Ergänzung sein&nbsp;wird.</p><div><div><p><span>Streetscooter-Aus verstimmt Zulieferer</span></p><div><p>Die Deutsche Post hat mit dem angekündigten Aus ihrer Produktion des Streetscooters offenbar wichtige Vertragspartner überrumpelt. So erfuhr der Zulieferer Neapco nach eigenen Angaben "überraschend aus den Medien von dieser Nachricht". Neapco stellt der Post in Düren Produktionsflächen sowie etwa 120 Beschäftigte für die Montage der batteriebetriebenen Nutzfahrzeuge zur Verfügung. "Geplant war ein Anstieg der Mitarbeiterzahlen auf etwa 200 in den kommenden Monaten", heißt es von dem Dienstleister.</p>
<p>Die Post hat vorige Woche die Suche nach einem Käufer oder Investor für Streetscooter aufgegeben. Der Konzern verweist auf Millionenverluste seiner Autotochter. Er will die mehr als 11 000 bereits hergestellten E-Fahrzeuge zwar weiterbetreiben, doch soll die Produktion in Aachen und Düren in diesem Jahr auslaufen. Streetscooter beschäftigt selbst etwa 500 Menschen; hinzu kommen Mitarbeiter bei Dienstleistern wie Neapco. Die Post erklärt, dass sie das Aus von Streetscooter ad hoc kommunizieren musste, da es auch für den Kapitalmarkt relevant sei. Der Konzern geht davon aus, dass sich die Abschreibungen auf Streetscooter sowie die Kosten für den Personalabbau und die Abwicklung der Verträge auf bis zu 400 Millionen Euro summieren werden.</p>
<p>Unterdessen kritisiert der Streetscooter-Gründer Günther Schuh, die Post habe nach der Übernahme des Start-ups 2014 "Amateure eingesetzt, jegliche Verbesserung verboten und auf eine Gelegenheit gewartet, das Geschäft unter einem Vorwand einzustellen". Die Post habe Streetscooter weder ausreichend finanziert noch einen Zugang zum Kapitalmarkt gewährt, moniert der Aachener Professor in einem Handelsblatt-Gastbeitrag. Schuh war nach der Übernahme bei Streetscooter ausgeschieden. <span>Benedikt Müller</span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372252</guid>
            <pubDate>Thu, 10 Dec 2020 10:46:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Week in Rust 368]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25371862">thread link</a>) | @todsacerdoti
<br/>
December 10, 2020 | https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/ | <a href="https://web.archive.org/web/*/https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Hello and welcome to another issue of <em>This Week in Rust</em>!
<a href="http://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta: safety, concurrency, and speed.
This is a weekly summary of its progress and community.
Want something mentioned? Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> or <a href="https://github.com/rust-lang/this-week-in-rust">send us a pull request</a>.
Want to get involved? <a href="https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md">We love contributions</a>.</p>
<p><em>This Week in Rust</em> is openly developed <a href="https://github.com/rust-lang/this-week-in-rust">on GitHub</a>.
If you find any errors in this week's issue, <a href="https://github.com/rust-lang/this-week-in-rust/pulls">please submit a PR</a>.</p>

<h3 id="official">Official</h3>
<ul>
<li><a href="https://blog.rust-lang.org/2020/12/07/the-foundation-conversation.html">The Foundation Conversation</a></li>
</ul>
<h3 id="newsletters">Newsletters</h3>
<ul>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-016/">This Month in Rust GameDev #16 - November 2020</a></li>
<li><a href="https://www.reddit.com/r/rust/comments/k6cka7/rib_newsletter_18_on_to_the_ribbles/">RiB Newsletter #18 - On to the Ribbles</a></li>
</ul>
<h3 id="tooling">Tooling</h3>
<ul>
<li><a href="https://rust-analyzer.github.io/thisweek/2020/12/07/changelog-54.html">Rust Analyzer Changelog #54</a></li>
<li><a href="https://ferrous-systems.com/blog/knurling-changelog-9/">Knurling-rs Changelog #9</a></li>
<li><a href="https://blog.jetbrains.com/clion/2020/12/intellij-rust-updates-for-2020-3/">IntelliJ Rust: Updates for 2020.3</a></li>
</ul>
<h3 id="observationsthoughts">Observations/Thoughts</h3>
<ul>
<li><a href="https://www.fpcomplete.com/blog/monads-gats-nightly-rust/">Monads and GATs in Nightly Rust</a></li>
<li><a href="https://fanf.dreamwidth.org/134024.html">Vanishing zeroes for geometric algebra in Rust</a></li>
<li><a href="https://blog.thomasheartman.com/posts/on-generics-and-associated-types">On Generics and Associated Types</a></li>
<li><a href="https://vector.dev/blog/adaptive-request-concurrency/">Adaptive Request Concurrency. Resilient observability at scale.</a></li>
<li><a href="https://blog.logrocket.com/rust-compression-libraries/">Rust compression libraries</a></li>
<li><a href="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/">Rust makes cross compilation child's play</a></li>
<li><a href="https://jmmv.dev/2020/12/builder-pattern-for-tests.html">Using the builder pattern to define test scenarios</a></li>
<li><a href="https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html">Measuring Memory Usage in Rust</a></li>
<li><a href="https://www.tag1consulting.com/blog/saving-time-switching-users-async-support-goose">Saving time by switching users: Async support in Goose</a></li>
<li><a href="https://evrone.com/rust-vs-c">Why Rust is meant to replace C</a></li>
</ul>
<h3 id="rust-walkthroughs">Rust Walkthroughs</h3>
<ul>
<li><a href="https://subvisual.com/blog/posts/real-time-video-processing-with-rust-ffmpeg-opencv/">Real-time video processing with Rust, FFmpeg and OpenCV</a></li>
<li><a href="https://dev.to/creativcoder/merge-k-sorted-arrays-in-rust-1b2f">Merge k sorted arrays in Rust</a></li>
<li><a href="https://arzg.github.io/lang/13/">Make A Language - Part Thirteen: Whitespace &amp; Events</a></li>
<li><a href="https://jmmv.dev/2020/12/unit-testing-a-console-app.html">Unit-testing a console app (a text editor)</a></li>
<li><a href="https://blog.drogue.io/rust-and-async/">Rust and Async (on embedded devices)</a></li>
<li><a href="https://www.fpcomplete.com/blog/avoiding-duplicating-strings-rust/">Avoiding Duplicating Strings in Rust</a></li>
<li><a href="https://blog.knoldus.com/os-in-rust-custom-target-to-build-kernel-for-a-bare-metal-part-3/">OS in Rust: Custom target to build kernel for bare metal: Part-3</a></li>
<li><a href="https://blog.knoldus.com/os-in-rust-building-kernel-for-custom-target-part-4/">OS in Rust: Building kernel for custom target: Part-4</a></li>
<li>[video] <a href="https://youtu.be/lLWchWTUFOQ">Introduction to Rust Part 2</a></li>
</ul>
<h3 id="project-updates">Project Updates</h3>
<ul>
<li><a href="https://github.com/EmbarkStudios/rust-gpu/releases/tag/v0.2">rust-gpu v0.2</a></li>
<li><a href="https://ibraheem.ca/posts/rust-interior-mutability-understanding-cell">Interior Mutability in Rust: Understanding The Cell Type</a></li>
</ul>
<h3 id="miscellaneous">Miscellaneous</h3>
<ul>
<li><a href="https://www.infoq.com/news/2020/12/cpp-rust-interop-cxx/">Safe Interoperability between Rust and C++ with CXX</a></li>
<li><a href="https://opensource.googleblog.com/2020/12/expanding-fuchsias-open-source-model.html">Expanding Fuchsia's open source model</a></li>
<li><a href="https://www.reddit.com/r/rust/comments/k75tez/miri_can_now_detect_data_races/">Miri can now detect data races</a></li>
</ul>

<p>This week's crate is <a href="https://github.com/not-a-seagull/breadx">breadx</a>, a X-windows protocol implementation in 100% safe and mutex-free Rust.</p>
<p>Thanks to <a href="https://users.rust-lang.org/t/crate-of-the-week/2704/851">Willi Kappler</a> for the suggestion!</p>
<p><a href="https://users.rust-lang.org/t/crate-of-the-week/2704">Submit your suggestions and votes for next week</a>!</p>

<p>Always wanted to contribute to open-source projects but didn't know where to start?
Every week we highlight some tasks from the Rust community for you to pick and get started!</p>
<p>Some of these tasks may also have mentors available, visit the task page for more information.</p>
<p>If you are a Rust project owner and are looking for contributors, please submit tasks <a href="https://users.rust-lang.org/t/twir-call-for-participation/4821">here</a>.</p>
<ul>
<li><a href="https://github.com/AaronErhardt/Triox/labels/good%20first%20issue">Triox - Good First Issues</a></li>
<li><a href="https://github.com/libssh2/libssh2/pull/517">libssh2 - Pull Request Needs Windows Reviewer</a></li>
</ul>

<p>279 pull requests were <a href="https://github.com/search?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2020-11-30..2020-12-07">merged in the last week</a></p>
<ul>
<li><a href="https://github.com/rust-lang/rust/pull/78684">add wasm32 support to inline asm</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79509">improve attribute message error spans</a></li>
<li><a href="https://github.com/rust-lang/chalk/pull/659">chalk: always relate with Invariant to non-General inference vars</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79680">fix perf regression caused by match exhaustiveness split</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79623">pass around Symbols instead of Idents in doctree</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79620">tweak diagnostics on shadowing lifetimes/labels</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/78122">avoid panic_bounds_check in <code>fmt::write</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79650">fix incorrect <code>io::Take</code>'s limit resulting from <code>io::copy</code> specialization</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79600"><code>std::io</code>: use sendfile for UnixStream</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/8937">cargo: slightly optimize `cargo vendor</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/8725">cargo: add "--workspace" to update command</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79539">rustdoc: JSON backend experimental impl</a></li>
</ul>
<h2 id="rust-compiler-performance-triage">Rust Compiler Performance Triage</h2>
<ul>
<li><a href="https://github.com/rust-lang/rustc-perf/blob/master/triage/2020-12-08.md">2020-12-08</a>:
0 Regressions, 2 Improvements, 1 Mixed</li>
</ul>
<p>Triage done by @simulacrum.</p>
<p>See the <a href="https://github.com/rust-lang/rustc-perf/blob/master/triage/2020-12-08.md">full report</a> for more.</p>
<h2 id="approved-rfcs">Approved RFCs</h2>
<p>Changes to Rust follow the Rust <a href="https://github.com/rust-lang/rfcs#rust-rfcs">RFC (request for comments) process</a>. These
are the RFCs that were approved for implementation this week:</p>
<p><em>No RFCs were approved this week.</em></p>

<p>Every week <a href="https://www.rust-lang.org/team.html">the team</a> announces the
'final comment period' for RFCs and key PRs which are reaching a
decision. Express your opinions now.</p>
<h3 id="rfcs"><a href="https://github.com/rust-lang/rfcs/labels/final-comment-period">RFCs</a></h3>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/pull/3007">RFC: Plan to make core and std's panic identical</a></li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2992">RFC: Add <code>target_abi</code> configuration</a></li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2859">added secret types rfc</a></li>
</ul>
<h3 id="tracking-issues-prs"><a href="https://github.com/rust-lang/rust/labels/final-comment-period">Tracking Issues &amp; PRs</a></h3>
<ul>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79642">rustdoc: stabilise --default-theme command line option</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79502">Implement <code>From&lt;char&gt;</code> for u64 and u128.</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79485">Stabilize <code>unsafe_cell_get_mut</code></a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79473">Move <code>{f32,f64}::clamp</code> to core</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79342">Stabilize all stable methods of <code>Ipv4Addr</code>, <code>Ipv6Addr</code> and <code>IpAddr</code> as const</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79270">Acknowledge that <code>[CONST; N]</code> is stable</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79261">Deprecate atomic compare_and_swap method</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79213">Stabilize <code>core::slice::fill</code></a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/79188">Made matches! more useful by adding mapping support</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79073">passes: prohibit invalid attrs on generic params</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79022">stabilize deque_range</a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/78367">Apply <code>unused_doc_comments</code> lint to inner items</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/78242">Rename <code>overlapping_patterns</code> lint</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/78083">Stabilize or_insert_with_key</a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/77688">Add built-in implementations of <code>Default</code> for function definition and… </a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/74699">Mark <code>-1</code> as an available niche for file descriptors</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/74304">Stabilize the Wake trait</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/63514">Tracking issue for map_ok and map_err method for <code>Poll&lt;Option&lt;Result&lt;T, E&gt;&gt;&gt;</code></a></li>
</ul>
<h2 id="new-rfcs">New RFCs</h2>
<p><em>No new RFCs were proposed this week.</em></p>

<h3 id="online">Online</h3>
<ul>
<li><a href="https://www.meetup.com/de-DE/Rust-Community-Stuttgart/events/274892215/">December 10, Stuttgart, DE - Hack &amp; Learn - Directions for 2021 - Rust Community Stuttgart</a></li>
<li><a href="https://www.meetup.com/San-Diego-Rust/events/274757235/">December 10, San Diego, CA, US - San Diego Rust December 2020 Tele-Meetup - San Diego Rust</a></li>
<li><a href="https://www.meetup.com/RustDC/events/274460587">December 10, Washington, DC, US - How oso built a runtime reflection system for Rust—Rust DC</a></li>
<li><a href="https://www.meetup.com/Rust-%D0%B2-%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B5/events/274924961/">December 15, Russia - Russian Rust Online Meetup</a></li>
<li><a href="https://www.meetup.com/Vancouver-Rust/events/npqfbsybcqbvb/">December 16, Vancouver, BC, US - Are Results just Checked Exceptions? - Vancouver Rust</a></li>
</ul>
<h3 id="north-america">North America</h3>
<ul>
<li><a href="https://www.meetup.com/utah-rust/events/273530244/">December 10, Provo, UT, US - Mob Programming: Add <code>--tree -d</code> to <code>lsd</code></a></li>
</ul>
<p>If you are running a Rust event please add it to the <a href="https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com">calendar</a> to get
it mentioned here. Please remember to add a link to the event too.
Email the <a href="mailto:community-team@rust-lang.org">Rust Community Team</a> for access.</p>

<p><em>Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> to get your job offers listed here!</em></p>
<ul>
<li><a href="https://www.pathai.com/careers/?gh_jid=4983568002">Software Engineer, Systems at PathAI (Boston, MA, US)</a></li>
<li><a href="https://www.welcometothejungle.com/fr/companies/meilisearch/jobs/software-developer-rust_paris">Software Developer (Rust) at MeiliSearch (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4019a818-4a7b-46ef-9225-c53c7a7f238c">Backend Engineer - Rust at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://jobs.lever.co/kraken/fe1e07f4-6d7c-4f65-9a8f-27cf3b3fd2b1">Backend Engineer, Kraken Futures - Rust at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/2442ee5c-56b6-4a73-a477-8cdda2b218d5">Rust Engineer, Desktop GUI - Cryptowatch at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4c864c8f-bde6-443d-b521-dd90df0e9105">Senior Backend Engineer - Rust at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://jobs.lever.co/kraken/2863623f-13c9-4f50-992d-7c25736a60f9">Senior Banking Engineer - Rust at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4485f672-dc5f-4e49-a10b-2b0399e28a8d">Software Engineer - Trading Technology (Rust) at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://stackoverflow.com/jobs/294502/rust-for-embedded-environments-ockam">Rust for Embedded Environments at Ockam (Remote)</a></li>
<li><a href="https://stackoverflow.com/jobs/400828/messaging-protocol-architect-in-elixir-and-rust-ockam">Messaging protocol architect in Elixir (and Rust) at Ockam (Remote)</a></li>
<li><a href="https://nzxt.bamboohr.com/jobs/view.php?id=259">Senior Software Engineer (Rust &amp; C++) at NZXT (Remote)</a></li>
<li><a href="https://www.notion.so/Embedded-Firmware-Engineer-in-C-Rust-a9c741c539454ee7b8bbb969d8e90da2">Embedded Firmware Engineer in C &amp; Rust at Astropad (Remote, US)</a></li>
</ul>

<blockquote>
<p>Writing rust for me is a gradual process of the compiler patiently guiding me towards the program I should have written in the first place, and at the end I take all the credit.</p>
</blockquote>
<p>– <a href="https://discord.com/channels/442252698964721669/448238009733742612/783395725991084074">@felixwatts on Discord</a></p>
<p>Thanks to <a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328/972">Joshua Nelson</a> for the suggestion.</p>
<p><a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328">Please submit quotes and vote for next week!</a></p>
<p><em>This Week in Rust is edited by: <a href="https://github.com/nellshamrell">nellshamrell</a>, <a href="https://github.com/llogiq">llogiq</a>, and <a href="https://github.com/cdmistman">cdmistman</a>.</em></p>
<p><small><a href="https://www.reddit.com/r/rust/comments/ka8fvg/this_week_in_rust_368/">Discuss on r/rust</a></small></p>
  </article></div>]]>
            </description>
            <link>https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371862</guid>
            <pubDate>Thu, 10 Dec 2020 09:54:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Web Service to Manage Scientific Simulation Data Using GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25371580">thread link</a>) | @felipez
<br/>
December 10, 2020 | https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9 | <a href="https://web.archive.org/web/*/https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@f.zapata?source=post_page-----a0bbf1c3f6e9--------------------------------" rel="noopener"><img alt="Felipe" src="https://miro.medium.com/fit/c/96/96/1*f7WZ93VZ5pv2qgIxOhxJUA.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="77c2">Scientific simulations generate large volume of data that needs to be stored and processed by multidisciplinary teams across different geographical locations. Distributing computational expensive simulations among the available resources, avoiding duplication and keeping the data safe are challenges that scientists face every day.</p><p id="8d66">In this post we present our web service <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico</a> and its command line interface <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a>. Insilico solves the problem of <em>computing</em>, <em>storing</em> and <em>securely sharing</em> computationally <em>expensive</em> simulation results. Researchers can save significant time and resources by easily computing new data and reusing existing simulation data to answer their questions.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9856/0*bI9DbwobcmYvOYyk" width="4928" height="3280" srcset="https://miro.medium.com/max/552/0*bI9DbwobcmYvOYyk 276w, https://miro.medium.com/max/1104/0*bI9DbwobcmYvOYyk 552w, https://miro.medium.com/max/1280/0*bI9DbwobcmYvOYyk 640w, https://miro.medium.com/max/1400/0*bI9DbwobcmYvOYyk 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bI9DbwobcmYvOYyk?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@publicpowerorg?utm_source=medium&amp;utm_medium=referral" rel="noopener">American Public Power Association</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><blockquote><p id="71c5">At the <a href="https://www.esciencecenter.nl/" rel="noopener">Netherlands eScience Center</a> we empower academic researchers by building together simulation tools, data pipelines, etc. A common goal among several tools that we develop for projects in different scientific fields, is to reduce the calculation time of computationally expensive physical simulations (e.g. molecular processes) by applying statistical methods to previously simulated data.</p></blockquote><p id="204c">The aforementioned methodology can potentially save us significant human and computational resources by easily generating high value data using previous computations. But before we are ready to apply any statistical method we of course need the data and for doing so, we need to ask ourselves questions like:</p><blockquote><p id="7c69">What input is required?</p><p id="75eb">Who is going to perform the simulation?</p><p id="a35c">What facilities are going to be used?</p><p id="93ec">Where is the resulting data going to be stored?</p><p id="6091">How to access the available data?</p></blockquote><p id="6fb9">Physical simulations usually require intricate input that takes into consideration several aspects and parameters used by different models to approximate the phenomena under consideration. Also, scientific simulations are computationally demanding tasks, so they are usually run in (inter)national supercomputers or very specialized facilities. We also want to maximize the impact of the data in the scientific community, therefore we want other scientists to be able to access the data and even add their own, but we need some security layers to protect such valuable data.</p><p id="bcb8">There is no silver bullet to address all the previous questions, but there are amazing initiatives like the <a href="https://foldingathome.org/" rel="noopener">folding at home project</a> that distributes some computational tasks among volunteers around the world who give away some time in their computers to simulate protein dynamics.</p><p id="6858">It seems that if we want to collaborate on the distribution of computational tasks and the assemblage of the resulting data, we need a central “entity” that (1) allows users to request new tasks, (2) receives the task’s results to be stored and (3) returns some available data when requested. It sounds like we need a web service!</p><blockquote><p id="6a2b">Writing a web service is a nontrivial task, you need to be aware of different technologies, libraries, etc. while making sure that your data is going to be safe and of course you need some infrastructure to host your service. This post goal is to give you some hints about building a web service for scientific applications and it is by no means a complete guide to writing web applications.</p></blockquote><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9662/0*HnAn4y-BQGmvGjGZ" width="4831" height="3221" srcset="https://miro.medium.com/max/552/0*HnAn4y-BQGmvGjGZ 276w, https://miro.medium.com/max/1104/0*HnAn4y-BQGmvGjGZ 552w, https://miro.medium.com/max/1280/0*HnAn4y-BQGmvGjGZ 640w, https://miro.medium.com/max/1400/0*HnAn4y-BQGmvGjGZ 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*HnAn4y-BQGmvGjGZ?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@johnschno?utm_source=medium&amp;utm_medium=referral" rel="noopener">John Schnobrich</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="a44e">Before entering into the web service technical details, let’s explore what its behavior should be.</p><p id="74cc">So, once it has been decided what are the best approximations and models to perform the simulations, we can compile all the simulation metadata into different jobs. For instance, a job can be a single molecular simulation under some specific conditions. We would like to make all these jobs available to the users, in such a way that they can run one or more jobs at a time but avoiding that the same job is run by more than one user.</p><p id="2b33">It would be great that when the simulation is done a user can send the results to the web service or ask for already available results. We also want to be able to call the web service from our local computer, specialized infrastructure or wherever we want to perform the computation, without worrying about where the service is running.</p><p id="be30">It seems, that we want a <a href="https://en.wikipedia.org/wiki/Git" rel="noopener">Git</a>-like behavior where we can pull jobs (or available data) and push results.</p><p id="ba78">With these requirements in mind, I have developed an open source web service called <a href="https://github.com/nlesc-nano/insilico-server" rel="noopener">Insilico-server</a>. Let’s see how it works!</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7296/0*P4hHvh84YZQLPGgi" width="3648" height="2432" srcset="https://miro.medium.com/max/552/0*P4hHvh84YZQLPGgi 276w, https://miro.medium.com/max/1104/0*P4hHvh84YZQLPGgi 552w, https://miro.medium.com/max/1280/0*P4hHvh84YZQLPGgi 640w, https://miro.medium.com/max/1400/0*P4hHvh84YZQLPGgi 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*P4hHvh84YZQLPGgi?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@andrew_gook?utm_source=medium&amp;utm_medium=referral" rel="noopener">Andrew Gook</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="773a">The web service consists of two parts: a small command line interface (CLI) that communicates with the service and the <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico web service</a> that handles all the data.</p><p id="0fa0">Our CLI is called <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> and it offers several actions to interact with the service, like logging in, computing, querying, etc. as shown in the following snippet:</p><pre><span id="4e44">&gt;&gt;&gt; moka --help<br>usage: moka [-h] [--version] {login,compute,report,query,add,manage} ...</span><span id="84c2">positional arguments:<br>  {login,compute,report,query,add,manage}<br>                        Interact with the properties web service<br>    login               Log in to the Insilico web service<br>    compute             Compute available jobs<br>    report              Report the results back to the server<br>    query               Query some properties from the database<br>    add                 Add new jobs to the database<br>    manage              Change jobs status</span><span id="6b00">optional arguments:<br>  -h, --help            show this help message and exit<br>  --version             show program's version number and exit</span></pre><p id="b5c4">Using <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> we can compute some jobs using a command like:</p><pre><span id="f521">moka compute -c collection_name -j number_of_jobs_to_compute</span></pre><p id="8e50">The previous command handles the communication with the web service, fetches the requested jobs from a given collection (or dataset) and runs them directly or invokes a <a href="https://en.wikipedia.org/wiki/Job_scheduler" rel="noopener">job scheduler</a> like <a href="https://slurm.schedmd.com/documentation.html" rel="noopener">Slurm</a>. To communicate with the service, <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> invokes the <a href="https://requests.readthedocs.io/en/master/" rel="noopener">Python Requests library</a> that handles the communication.</p><p id="54f9">Once the jobs are done we can report the computed data like:</p><pre><span id="2183">moka report</span></pre><p id="eafc">You may be wondering how does the client know what data it needs to send/receive. Well, that is the subject of the next section!</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/8064/0*o_Zzwgbaexr6Fz8y" width="4032" height="3024" srcset="https://miro.medium.com/max/552/0*o_Zzwgbaexr6Fz8y 276w, https://miro.medium.com/max/1104/0*o_Zzwgbaexr6Fz8y 552w, https://miro.medium.com/max/1280/0*o_Zzwgbaexr6Fz8y 640w, https://miro.medium.com/max/1400/0*o_Zzwgbaexr6Fz8y 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*o_Zzwgbaexr6Fz8y?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@tofi?utm_source=medium&amp;utm_medium=referral" rel="noopener">Tobias Fischer</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="e270">The main goal of the web service is to minimize the interaction between the users and the data. If the client requests some read-only action you just return the data (if available) and if the client wants to change something, you need to ensure that (1) the client has permissions to mutate the data (2) only the mutations specified by the client are carried out but nothing more. I will skip authentication in this post.</p><p id="2b72">Therefore, the <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico</a> web service needs to handle two kinds of requests by the client: read-only queries and mutations on the datasets. These “queries” and “mutations” can be easily describe with <a href="https://graphql.org/" rel="noopener">GraphQL</a>.</p><p id="0dbe">In a nutshell, <a href="https://graphql.org/" rel="noopener">GraphQL</a> defines a contract (known as a schema) between the actions that a client can perform with the web service and the possible outcomes of those actions. More formally, <a href="https://graphql.org/" rel="noopener">GraphQL</a> is a query language that allows you to specify an application Programming interface (API) using different programming languages. If you have previous experience with <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" rel="noopener">RESTful API</a> have a look at a comparison between <a href="https://www.howtographql.com/basics/1-graphql-is-the-better-rest/" rel="noopener">GraphQL and REST</a>.</p><p id="ecf0">But how does GraphQL work? First, you need to define a schema using the <a href="https://graphql.org/" rel="noopener">GraphQL</a> schema language. The following code snippet defines a schema to query a job using its status,</p><figure><div></div><figcaption>Schema definition for job query</figcaption></figure><p id="2045">The <strong>Query</strong> schema specifies that in order to request some <strong><em>jobs</em></strong> you need to provide a <em>Status</em> argument, where <em>Status</em> can be one of four possibilities: <em>AVAILABLE, DONE, FAILED</em> and <em>RUNNING. </em>The exclamation mark (!) indicates that the argument cannot be <em>Null</em> (a.k.a <em>None</em> in Python).</p><p id="5870">The following <strong>Mutation</strong> schema defines the required arguments to update a given job status.</p><figure><div></div><figcaption>Schema definitation for Job status mutation</figcaption></figure><p id="9dd2">The <strong><em>updateJob</em></strong> action specifies that you must provide an <em>id</em> and a <em>new_status</em> in order to be able to update a job. You will receive a <em>Reply</em> specifying whether the update action has succeeded.</p><p id="54d3">Have a look at the Insilico <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/sdl/Query.graphql" rel="noopener">queries</a> and <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/sdl/Mutation.graphql" rel="noopener">mutations</a> schemas. They are slightly more complex than the aforementioned schemas but follow the same rationale as the previous examples. You can also have a look at the official <a href="https://graphql.org/learn/" rel="noopener">introduction to GraphQL</a>.</p><p id="33f0">We have just defined the schemas that specify the actions that we want to perform. We still need to implement the actions and for doing so, we need a GraphQL engine: a library that takes the schemas together with the code that implements the actions and generates an API.</p><p id="39ea">We have chosen the <a href="https://tartiflette.io/" rel="noopener">Tartiflette GraphQL engine</a> to implement our web service mostly because it is easy to use and open source. The following snippet shows a possible implementation for querying jobs based on their status using <a href="https://tartiflette.io/" rel="noopener">Tartiflette</a>.</p><figure><div></div></figure><p id="affa">the <strong><em>Resolver</em></strong> decorator indicates that the <strong><em>resolver_query_jobs</em></strong> function corresponds to the implementation of the <strong><em>query jobs</em></strong> schema. The function takes 4 arguments of which I only use <strong><em>args</em></strong> and <strong><em>ctx</em></strong><em> </em>(You can refer to <a href="https://tartiflette.io/" rel="noopener">Tartiflette</a> for further details). <strong><em>args </em></strong>contains the arguments given by the client code, while <strong><em>ctx </em></strong>contains the context for running the current function, for example the handler to access the database that is called <strong><em>mongodb</em></strong> in this code snippet.</p><p id="9242">Notice that the definition of the aforementioned function starts with the <em>async</em> keyword. <a href="https://docs.python.org/3/library/asyncio.html" rel="noopener">Asyncio</a> is a popular built-in Python library to write concurrent code. It is extensively used to write high performance web services.</p><p id="fb0a">In the Insilico web service implementation of the <a href="https://github.com/nlesc-nano/insilico-server/tree/master/provisioning" rel="noopener"><strong>queries</strong></a> and <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/mutation_resolvers.py" rel="noopener"><strong>mutations</strong></a>, there are definitions for all the Python functions that perform the actions specified in the GraphQL schemas. For each query and mutation, there is a corresponding function.</p><p id="632b">We need a database not only for storing the interesting data but also to store the jobs metadata, like what jobs are available. For the Insilico web service we use <a href="https://www.mongodb.com/" rel="noopener">MongoDB</a>.</p><p id="1b90">My personal opinion is that a <a href="https://en.wikipedia.org/wiki/NoSQL" rel="noopener">NoSQL database</a> like <a href="https://www.mongodb.com/" rel="noopener">MongoDB</a> gives a significant advantage over traditional SQL databases on research projects where up-front design of the schemas to store data is unfeasible. The research priorities can change as the project evolves and having dynamic …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9">https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9</a></em></p>]]>
            </description>
            <link>https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371580</guid>
            <pubDate>Thu, 10 Dec 2020 09:19:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ProtoPie 5.2: Turn Figma designs into realistic, conditional prototypes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25371555">thread link</a>) | @heytmt
<br/>
December 10, 2020 | https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58 | <a href="https://web.archive.org/web/*/https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="72bc">A far better Figma import for ProtoPie. Lightning speed and flexibility at your fingertips.</h2><div><div><div><p><a href="https://medium.com/@fredotan?source=post_page-----5758892c4c58--------------------------------" rel="noopener"><img alt="Fredo Tan" src="https://miro.medium.com/fit/c/96/96/1*6aaH5nx9yHmC7KcdczcZTg@2x.jpeg" width="48" height="48"></a></p></div></div></div><blockquote><p id="e08d">We are on <a href="https://www.producthunt.com/posts/protopie-for-figma" rel="noopener"><strong>Product Hunt</strong></a> today! We’d love to receive your feedback and support there :)</p></blockquote></div></div><div><div><p id="ebd5">We are beyond excited that today we can finally introduce the <a href="https://www.figma.com/community/plugin/908870217222043020/ProtoPie-Plugin" rel="noopener"><strong>ProtoPie plugin for Figma</strong></a>—a far better Figma import for ProtoPie.</p><p id="7ead">The introduction of this plugin goes hand-in-hand with the <a href="https://protopie.io/?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin" rel="noopener"><strong>ProtoPie 5.2</strong></a> release.</p><p id="f675">ProtoPie plugins for Adobe XD and Sketch are coming soon.</p><p id="95c4">A lot of you have been using the Figma integration we introduced in early 2019. Many designers, since then, rely on a Figma + ProtoPie workflow on a daily basis—designing, prototyping, iterating, and anything in between.</p><p id="588e">As this workflow became essential for many rapidly, we received tons of feedback on how we could make this particular workflow better.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2616/1*35ZGJ7gZQN-LKqgbRZZj9Q.png" width="1308" height="262" srcset="https://miro.medium.com/max/552/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 276w, https://miro.medium.com/max/1104/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 552w, https://miro.medium.com/max/1280/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 640w, https://miro.medium.com/max/1400/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*35ZGJ7gZQN-LKqgbRZZj9Q.png?q=20"></p></div></div></div><figcaption>A better Figma import was one of the top <a href="https://protopie.canny.io/" rel="noopener">feature requests</a>.</figcaption></figure><p id="2208">Quickly we realized that we needed to provide a better workflow in which designers can merely focus on what they need ProtoPie for: making realistic, highly interactive prototypes.</p><p id="e4fd">So, we decided to build something new, entirely from scratch.</p><p id="1618">The new import experience is completely different from the previous one, which we now call the legacy Figma import.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3840/1*rINB-qGSruwy8te26r1hlA.gif" width="1920" height="1080" srcset="https://miro.medium.com/max/552/1*rINB-qGSruwy8te26r1hlA.gif 276w, https://miro.medium.com/max/1104/1*rINB-qGSruwy8te26r1hlA.gif 552w, https://miro.medium.com/max/1280/1*rINB-qGSruwy8te26r1hlA.gif 640w, https://miro.medium.com/max/1400/1*rINB-qGSruwy8te26r1hlA.gif 700w" sizes="700px" data-old-src="https://miro.medium.com/freeze/max/60/1*rINB-qGSruwy8te26r1hlA.gif?q=20"></p></div></div></div><figcaption>ProtoPie plugin for Figma: a revamped import experience to boost productivity.</figcaption></figure><p id="ffdc">With the new <a href="https://www.figma.com/community/plugin/908870217222043020/ProtoPie-Plugin" rel="noopener"><strong>ProtoPie plugin for Figma</strong></a>, you have lightning speed and flexibility at your fingertips. Import your designs from Figma into ProtoPie, all done locally—without any latency.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1280/1*xLg44E8hgKI01r3ML45Jjg.gif" width="640" height="360" srcset="https://miro.medium.com/max/552/1*xLg44E8hgKI01r3ML45Jjg.gif 276w, https://miro.medium.com/max/1104/1*xLg44E8hgKI01r3ML45Jjg.gif 552w, https://miro.medium.com/max/1280/1*xLg44E8hgKI01r3ML45Jjg.gif 640w" sizes="640px" data-old-src="https://miro.medium.com/freeze/max/60/1*xLg44E8hgKI01r3ML45Jjg.gif?q=20"></p></div></div><figcaption>Control what you import. At lightning speed.</figcaption></figure><p id="29cc">Control what you import. Import top-level frames as scenes, and objects with the same layer hierarchy, positioning, and constraints as in Figma.</p><p id="9ce9">The ProtoPie plugin for Figma requires ProtoPie 5.2 or higher.</p><h2 id="d98b">Differences with the legacy Figma import?</h2><p id="6d13">Spend less time on bringing your designs from Figma into ProtoPie. With the new plugin, you save time and can spend more time on prototyping.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/1*P_QobAhiTx_KYU4fFHnwUw.png" width="1600" height="1006" srcset="https://miro.medium.com/max/552/1*P_QobAhiTx_KYU4fFHnwUw.png 276w, https://miro.medium.com/max/1104/1*P_QobAhiTx_KYU4fFHnwUw.png 552w, https://miro.medium.com/max/1280/1*P_QobAhiTx_KYU4fFHnwUw.png 640w, https://miro.medium.com/max/1400/1*P_QobAhiTx_KYU4fFHnwUw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*P_QobAhiTx_KYU4fFHnwUw.png?q=20"></p></div></div></div><figcaption>The legacy Figma import on the left, the new ProtoPie plugin for Figma on the right.</figcaption></figure><ul><li id="b8f3">Import one or multiple frames and objects.</li><li id="9195">Import top-level frames as scenes.</li><li id="5eed">Import what you selected.</li><li id="e346">Import vector layers as SVG.</li><li id="ea4c">Import text layers as SVG that can be converted to text layers.</li><li id="7d1e">Import constraints as constraints.</li></ul><p id="9549"><a href="https://protopie.io/learn/docs/basic-features/import#import?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin" rel="noopener"><strong>Learn more</strong></a> about the ProtoPie plugin for Figma.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*6R6YL9UkyU9bwS3PBqaSag.jpeg" width="600" height="300" srcset="https://miro.medium.com/max/552/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 276w, https://miro.medium.com/max/1104/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 552w, https://miro.medium.com/max/1200/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 600w" sizes="600px" data-old-src="https://miro.medium.com/max/60/1*6R6YL9UkyU9bwS3PBqaSag.jpeg?q=20"></p></div></div></figure><p id="f67c">ProtoPie is the tool that helps you to bring your Figma designs come to life, indistinguishable from the end product.</p><p id="feec">It’s simply a matter of adding powerful interactions to your designs. Think of dynamic interactions involving conditions, formulas, and variables. Add another level of realism by including text input, camera, voice, media playback to your prototypes. Or even make prototypes that can communicate with each other. The possibilities are endless.</p><h2 id="9d2a">New to ProtoPie?</h2><p id="45a6">Try the ProtoPie plugin for Figma with this <a href="https://r.protopie.io/en/figma-plugin/marketing-file/" rel="noopener"><strong>example file</strong></a>.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2160/1*4kJjwUMw6iXIJVcYmy7Asw.png" width="1080" height="540" srcset="https://miro.medium.com/max/552/1*4kJjwUMw6iXIJVcYmy7Asw.png 276w, https://miro.medium.com/max/1104/1*4kJjwUMw6iXIJVcYmy7Asw.png 552w, https://miro.medium.com/max/1280/1*4kJjwUMw6iXIJVcYmy7Asw.png 640w, https://miro.medium.com/max/1400/1*4kJjwUMw6iXIJVcYmy7Asw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*4kJjwUMw6iXIJVcYmy7Asw.png?q=20"></p></div></div></div></figure><p id="0d0d">Join our live event as our Head of Product Design, David Lee shares the journey of how we revamped the Figma import experience.</p><p id="6329">👉 <a href="https://www.eventbrite.com/e/protopies-journey-behind-revamping-the-figma-import-tickets-130748563473" rel="noopener"><strong>Register now</strong></a>.</p><ul><li id="f42c">Single sign-on (SSO) for ProtoPie Enterprise</li><li id="2c31">Auto line height</li><li id="6898">Duplicate with same distance</li><li id="2993">App icon for macOS Big Sur</li><li id="74e3">Trigger &amp; response names for voice prototyping</li></ul><figure><a href="https://protopie.io/?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3336/0*PwpFUw9I5BCcmPr0.png" width="1668" height="390" srcset="https://miro.medium.com/max/552/0*PwpFUw9I5BCcmPr0.png 276w, https://miro.medium.com/max/1104/0*PwpFUw9I5BCcmPr0.png 552w, https://miro.medium.com/max/1280/0*PwpFUw9I5BCcmPr0.png 640w, https://miro.medium.com/max/1400/0*PwpFUw9I5BCcmPr0.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*PwpFUw9I5BCcmPr0.png?q=20"></p></div></div></a></figure><p id="cdbd"><em>Thanks for reading! :) If you enjoyed this article, hit that clap button below </em>👏<em>. Feel free to </em><a href="https://protopie.io/support" rel="noopener"><em>contact us</em></a><em> with your feedback and/or questions.</em></p></div></div></div>]]>
            </description>
            <link>https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371555</guid>
            <pubDate>Thu, 10 Dec 2020 09:14:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Twins, a Requirement for Industrial AI]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25371343">thread link</a>) | @MorganeR
<br/>
December 10, 2020 | https://blog.senx.io/digital-twins-requirement-for-industrial-ai/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/digital-twins-requirement-for-industrial-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Using AI to make industrial assets more efficient and reduce their downtime is on many agendas. Learn how digital twins and time series data play a major role in this plan.</p><article>
      
<p><strong>When interviewed, CEOs across industries all state that AI is part of their top priorities.</strong> But when it comes to actual implementation AI projects are not very glamorous. Past simple proofs of concept and the hiring of a team of data scientists, there is usually no sign of the highly anticipated digital transformation wished by the CEOs.</p>



<p>There are multiple reasons for this disenchantment, far too many to list here. But among those, some are directly related to what we focus on at <a href="https://senx.io/" target="_blank" rel="noreferrer noopener">SenX</a>, data, and the way industries introduce them in their environment.</p>



<h2>No digital transformation without data</h2>



<p>The willingness to transform is genuine in many organizations, driven by ambitious visions or just the consciousness that the competitive landscape is evolving.</p>



<p>The next step is usually for those businesses to pick some quick wins to prove that the transformation can be initiated and comfort everyone that it does not mean changing teams or radically modifying their way of working.</p>



<p>Those short projects aim at demonstrating the methodology for transforming limited operational perimeters. They often involve solving a problem with approaches to leveraging new technologies. Those technologies, 100% digital, need fuel to work, and that fuel is data. <strong>So the first step is to ensure data are available</strong>.</p>



<p>The firms hired to help in building those quick wins will then wander among departments. They will harvest datasets here and there until they have sufficient matter for implementing their solutions.</p>



<p>This step can sometimes take time if the data is not well identified and distributed across the organization. But it is a mandatory path to follow as without data no digital transformation will happen.</p>



<figure></figure>



<h2>No AI without big data</h2>



<p>Past the simple quick wins done to bootstrap the transformation comes a time when more ambitious projects are brought on the table, and that is when AI (Artificial Intelligence) comes into the conversation. The hype around AI is so strong that projects around AI and ML (Machine Learning) cannot be neglected.</p>



<p>The problem with the current hype is that very few people really understand what AI actually implies. <strong>For many</strong>,<strong> you buy an AI like you buy a Microsoft Office 365 subscription</strong>, this is just not true. The promise of AI is to bring new, automatic, ways to use data to help in or even completely assume the decision process. This promise can only be fulfilled if the actual AI put to work, otherwise called the model, is actually trained on the data in your very own organization, and this requires once again the same digital transformation fuel, data. The difference is that this time you need more of it. You are no longer trying to light a fondue burner but a rocket engine!</p>



<p>Training a model does indeed require a lot of data covering the various aspects of your business operations you want the model to focus on, also covering a long period of time so trend and seasonality can be modeled. </p>



<h4>This has several impacts</h4>



<ul><li>The first is that you cannot expect to train a model and efficiently introduce AI in your operations until you actually have collected enough meaningful data. And if your organization has not done so so far you need to start as soon as possible. </li><li>The second impact is that this data collection process is not a one time job. It does not stop once you have enough data for training a model. It needs to go on and on so you keep on accumulating signals on how your business operates to retrain your models in the future if their performance starts to degrade. This means that prior to your journey into the core of AI you need to plan for big data to be collected, stored and made available to teams across your organization so they can start looking at the data and imagine possible uses and models.</li></ul>



<h2>No industrial AI without Digital Twins</h2>



<p>Among verticals, industrial organizations face the hardest problems of data collection. Industries whose data mainly relates to users using their services are lucky. In the end, their data are not that massive. Sure we have all heard stories of banks or retailers hoarding piles of data. But we are talking about a few thousand interactions per year per user. So even with a billion users, which not that many banks or retailers have, we are talking a few trillion events per year.</p>



<p>In the industrial world, things are different, the assets producing data do not eat or sleep. They work day and night and sometimes produce thousands of measurements per second.</p>



<h3>For example...</h3>



<p>Take for example the CERN experiments at the LHC. They produced 600 million events per second during the campaigns for the quest of the Higgs boson. That is 51 trillion events per day. Luckily for the CERN, not all events needed to be retained. With highly efficient AI-based detectors, which needed to be trained with massive data themselves, they were able to limit the production to 100 000 events per second sent for digital reconstruction and ultimately 200 events persisted per second. </p>



<p>But other sectors need to retain more data. Synchro phasors (or PMUs, phase monitoring units) monitoring electrical grids, for example. They each produce several 1000s measures per second, and there are thousands of those at the scale of a country like France. This means millions of C37.118.2 messages sent every second, not to mention the IEC61850 messages sent to supervise the substations. </p>



<p>Same thing in aeronautics where aircraft typically produce 5 000 to 15 000 data points per second they are operating, or industrial assets whose PLC (Programmable Logic Controllers) track the state of many sensors and actuators.</p>



<p>The use of AI in those verticals requires that those truly massive data be collected and organized. Since they are data related to physical assets, it is wise to use an approach which mimics these assets in a digital form, this approach is called Digital Twins. </p>



<figure></figure>



<h3>What are Digital Twins?</h3>



<p>The Digital Twin of an asset is the set of measures coming from its sensors and actuators. Those measures need to be tracked in time to catch the dynamics of the assets' operations. And the technology of choice to do so is a <a href="https://blog.senx.io/which-time-series-database-suited-to-your-needs/" target="_blank" rel="noreferrer noopener">Time Series Database</a>. Indeed Digital Twins are nothing else than time series, some for the sensors, some for the actuators with their states. And if you want more advanced digital twins, some with the control commands sent to the assets to modify how it behaves.</p>



<p>Once you start collecting the data from your assets in a Time Series Database, you can easily access the state of those assets at any point in time. More importantly, you can start extracting features to train models to detect anomalies and perform predictive maintenance.</p>



<h2>Takeaways</h2>



<p>AI is on every business' agenda, but the importance of data is too often overlooked. <strong>When it comes to industrial AI, the first step towards a successful implementation is the collection of all sensor data to build Digital Twins of the physical assets involved.</strong> This approach needs to leverage a Time Series Database, the kind of database SenX offers with the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10 Time Series Platform</a>.</p>



<p><a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">Contact us</a> to learn how SenX and its technologies can help you master your industrial AI adventure.</p>








<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/digital-twins-requirement-for-industrial-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371343</guid>
            <pubDate>Thu, 10 Dec 2020 08:45:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A Rust-Based Fast Static Site Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25371125">thread link</a>) | @camsjams
<br/>
December 10, 2020 | https://camsjams.github.io/rust-coal/ | <a href="https://web.archive.org/web/*/https://camsjams.github.io/rust-coal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img src="https://camsjams.github.io/rust-coal/assets/images/favicon.png" alt="Coal in a mine cart"></p><div>
<p><strong>Coal</strong> is a command-line interface (CLI) to speed up your ability to create static HTML
websites
without having to setup dependencies or install other libraries.</p><p>

Just install <strong>Coal</strong> once on your machine, and get building!
</p></div>
</div></div>]]>
            </description>
            <link>https://camsjams.github.io/rust-coal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371125</guid>
            <pubDate>Thu, 10 Dec 2020 08:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts about Mapbox GL JS moving to a NON-OS License]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25371037">thread link</a>) | @D_Guidi
<br/>
December 9, 2020 | http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html | <a href="https://web.archive.org/web/*/http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>09 Dec 2020</span></p><p>Yesterday, Mapbox announced that they were moving their <a href="https://github.com/mapbox/mapbox-gl-js">Mapbox GL JS</a> library from a standard BSD license to a new very much <a href="https://github.com/mapbox/mapbox-gl-js/blob/main/LICENSE.txt">non-open source license</a>.</p>

<p><a href="https://joemorrison.medium.com/death-of-an-open-source-business-model-62bc227a7e9b">Joe Morrison said</a> the news “shook” him (and also the readers of the Hacker News front page, well done Joe). It did me as well. Although apparently for completely different reasons.</p>

<blockquote>
  <p>Mapbox is the protagonist of a story I’ve told myself and others countless times. It’s a seductive tale about the incredible, counterintuitive concept of the “open core” business model for software companies.
<br>– Joe Morrison</p>
</blockquote>

<p>There’s a couple things wrong with Joe’s encomium to Mapbox and “open core”:</p>

<ul>
  <li>first, Mapbox was <strong>never</strong> an open core business;</li>
  <li>second, open core is a <strong>pretty ugly model</strong> that has very little to do with the open source ethos of shared intellectual pursuit.</li>
</ul>

<p><img src="http://blog.cleverelephant.ca/images//2020/core.jpg" alt="Open Core"></p>

<h2 id="mapbox-was-never-open-core">Mapbox was never Open Core</h2>

<p>From the very start (well, at least from the early middle), Mapbox was built to be a location-based services business. It was to be the Google Maps for people who were unwilling to accept the downsides of Google Maps.</p>

<p>Google Maps will track you. They will take your data exhaust and ruthlessly monetize it. They will take your data and use it to build a better Google Maps that they will then re-sell to others.</p>

<p>If you value your data at all (if you are, say, a major auto maker), you probably don’t want to use Google Maps, because they are going to steal your data while providing you services. Also, Google Maps is increasingly the “only game in town” for location based services, and it seems reasonable to expect price increases (<a href="https://housesigma.com/blog-en/2018/06/07/google-map-price-hike/">it has already happened once</a>).</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/google-location-history.png" alt="Google is Tracking You"></p>

<p>Nobody can compete with Google Maps, can they? Why yes, they can! Mapbox fuses the collaborative goodness of the <a href="https://openstreemap.org/">OpenStreetMap</a> community with clever software that enables the kinds of services that Google sells 
(<a href="https://docs.mapbox.com/api/maps/#raster-tiles">map tiles</a>, 
<a href="https://docs.mapbox.com/#search">geocoding</a>, 
<a href="https://docs.mapbox.com/#navigation">routing</a>, 
<a href="https://docs.mapbox.com/help/troubleshooting/access-elevation-data/">elevation services</a>), and a bunch of services Google doesn’t sell (like <a href="https://www.mapbox.com/mapbox-studio/">custom map authoring</a>) or won’t sell (like <a href="https://www.mapbox.com/vision/">automotive vision</a>).</p>

<p>But like Google, the value proposition Mapbox sells isn’t in the software, so much as the data and the platform underneath. Mapbox has built a unique, scalable platform for handling the huge problem of turning raw OSM data into usable services, and raw location streams into usable services. They sell access to that platform.</p>

<p>Mapbox has never been a software company, they’ve always been a data and services company.</p>

<p>The last company I worked for, <a href="https://carto.com/">CARTO</a>, had a similar model, only moreso. All the parts of their value proposition (PostgreSQL, PostGIS, the CARTO UI, the tile server, the upload, everything) are <a href="https://github.com/cartodb">open source</a>. But they want you to pay them when you load your data into their service and use their software there. How can that be? Well, do you want to assemble all those open source parts into a working system and keep it running? Of course not. You just want to publish a map, or run an analysis, or add a spatial analysis to an existing system. So you pay them money.</p>

<p>Is Mapbox an “open core” company? No, is there a “Mapbox Community Edition” everyone can have, but an “Enterprise Edition” that is only available under a proprietary license? No. Does Mapbox even sell <strong>any software at all</strong>? No. (Yes, some.) They (mostly) sell services.</p>

<p>So what’s with the re-licensing? I’ll come back to that, but first…</p>

<h2 id="open-core-is-a-shitty-model">Open Core is a Shitty Model</h2>

<p>Actually, no, it seems to be a passable <strong>monetization</strong> model, for some businesses. It’s a shitty open source model though.</p>

<ul>
  <li>MongoDB has an open source core, and sells a bunch of proprietary enterprise add-ons. They’ve grown very fast and might even reach sufficient velocity to escape their huge VC valuation (or they may yet be sucked into the singularity).</li>
  <li>Cloudera before them reached huge valuations selling proprietary add-ons around the open Hadoop ecosystem.</li>
  <li>MySQL flirted with an open core model for many years, but mostly stuck to spreading FUD about the GPL in order to get customers to pay them for proprietary licenses.</li>
</ul>

<p>Easily the strangest part of the MySQL model was trash-talking the very open source license <strong>they chose</strong> to place their open source software under.</p>

<p>All those companies have been quite succesful along the axes of “getting users” and “making money”. Let me tell you why open core is nonetheless a shitty model:</p>

<ul>
  <li>Tell me about the MongoDB developer community. Where do they work? Oh right, Mongo.</li>
  <li>Tell me about the Cloudary developer community? Where do they work?</li>
  <li>Tell me about the MySQL developer community? Where to they work? Oh right, <strong>Oracle</strong>. (There’s a whole other blog post to be written about why sole corporate control of open source projects is a <strong>bad idea</strong>.)</li>
</ul>

<p>A good open source model is one that promotes heterogeneity of contributors, a sharing of control, and a rising of all boats when the software succeeds. Open core is all about centralizing gain and control to the sponsoring organization.</p>

<p>This is going to sound precious, but the leaders of open core companies don’t “care” about the ethos of open source. The CEOs of open core companies view open source (correctly, from their point of view) as a “sales channel”. It’s a way for customers to discover their paid offerings, it’s not an end in itself.</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/funnel.png" width="75%" alt="Sales Funnel"></p>

<blockquote>
  <p>We didn’t open source it to get help from the community, to make the product better. We open sourced as a freemium strategy; to drive adoption. 
<br>– Dev Ittycheria, CEO, MongoDB</p>
</blockquote>

<p>So, yeah, open core is a way to make money but it doesn’t “do” anything for open source as a shared proposition for building useful tools anyone can use, for anything they find useful, anytime and anywhere they like.</p>

<p>Check out <a href="https://www.youtube.com/watch?v=8q5o-4pnxDQ">Adam Jacob’s take</a> on the current contradictions in the world of open source ethics; there are no hard and fast answers.</p>

<h2 id="mapbox-shook-me-too">Mapbox Shook Me Too</h2>

<p>I too was a little shook to learn of the <a href="https://news.ycombinator.com/item?id=25347310">Mapbox GL JS relicensing</a>, but perhaps not “surprised”. This had happened before, with <a href="https://news.ycombinator.com/item?id=14734589">Tilemill</a> (open) morphing into <a href="https://www.mapbox.com/mapbox-studio/">Mapbox Studio</a> (closed).</p>

<p>The change says nothing about “open source” in the large as a model, and everything about “single vendor projects” and whether you should, strategically, believe their licensing.</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/empty-promise.jpg" alt="Empty Promises"></p>

<p>I (and others) took the licensing (incorrectly) of Mapbox GL JS to be a promise, not only for now but the future, and made decisions based on that (incorrect) interpretation. I integrated GL JS into <a href="https://github.com/CrunchyData/pg_tileserv/blob/master/assets/preview-table.html">an open source project</a> and now I have to revisit that decision.</p>

<p>The license change also says something about the business realities Mapbox is facing going forward. The business of selling location based services is a competitive one, and one that is perhaps not panning out as well as their venture capital valuation (<a href="https://blog.mapbox.com/softbank-mapbox-series-c-be207b866b27">billions?</a>) would promise.</p>

<p>No doubt the board meetings are fraught. Managers are casting about for future sources of revenue, for places where more potential customers can be <strong>squeeeeezed</strong> into the sales funnel.</p>

<p>I had high hopes for Mapbox as a counterweight to Google Maps, a behemoth that seems <a href="https://www.justinobeirne.com/google-maps-moat">likely to consume us all</a>. The signs that the financial vice is beginning to close on it, that the promise might not be fulfilled, they shake me.</p>

<p>So, yeah, Joe, this is big news. Shaking news. But it has nothing to do with “open source as a business model”.</p>


</div></div>]]>
            </description>
            <link>http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371037</guid>
            <pubDate>Thu, 10 Dec 2020 07:54:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Restore pictures for free with deep learning tool]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370708">thread link</a>) | @panabee
<br/>
December 9, 2020 | https://hotpot.ai/restore-picture | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBoxWrapper">
			<div id="controlBox">

				<div>
					<p><img src="https://hotpot.ai/images/site/transparent.gif">
					</p>
				</div>

				<p>Upload</p>

				

				<p><span>Restore</span>
				</p>

			</div>
		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			If the image has scratches, enabling the "Has Scratches" option instructs our AI to remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370708</guid>
            <pubDate>Thu, 10 Dec 2020 07:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Measuring page performance – Learn Puppeteer and Playwright]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370533">thread link</a>) | @kiyanwang
<br/>
December 9, 2020 | https://theheadless.dev/posts/basics-performance/ | <a href="https://web.archive.org/web/*/https://theheadless.dev/posts/basics-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>The need for fast and responsive applications has never been greater because of the move from <a href="https://gs.statcounter.com/platform-market-share/desktop-mobile-tablet/worldwide/2019" target="_blank" rel="noopener noreferrer">desktop to mobile</a>. Still, web applications have been increasing in <a href="https://httparchive.org/reports/page-weight" target="_blank" rel="noopener noreferrer">complexity and size</a>, with rising load times. It is therefore clear why the topic of webpage performance is more popular today than it likely ever was.</p> <p>This article aims at giving a practical introduction to the whys and hows of web performance, without getting lost in the depth or breadth of this massive topic.</p> <h2 id="why-performance-matters"><a href="#why-performance-matters">#</a> Why performance matters</h2> <p>The time it takes for a service to become usable, as well as its general responsiveness, bear a lot of weight on the user's perception of that service. Helpful features, great design and other prominent characteristics all become irrelevant when an online service is so slow that users navigate away.</p> <p>You can build the best web application in the world, but be mindful that each user will have a specific amount of time they are willing to invest in your service to solve their problems. Exceed that amount, and you risk losing them to a different, more performant solution. This is even truer for new users, who haven't yet been given proof of the quality of your service, and are essentially investing their time up-front, hoping for a return.</p> <h3 id="a-competitive-differentiator"><a href="#a-competitive-differentiator">#</a> A competitive differentiator</h3> <p>There is a brighter side to the topic: if low performance can sink an online platform, high performance can very well help it rise to the top. Speed and responsiveness can be a differentiating characteristic for a service, prompting users to choose it over the competition. Therefore an investment in this area will almost always pay off. Some notorious real-world examples from known businesses include:</p> <ol><li>Pinterest decreasing wait time for their users, <a href="https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7" target="_blank" rel="noopener noreferrer">increasing both traffic and conversions</a>.</li> <li>Zalando applying small improvements in load time and finding a direct correlation with <a href="https://engineering.zalando.com/posts/2018/06/loading-time-matters.html" target="_blank" rel="noopener noreferrer">increased revenue per session</a>.</li> <li>The BBC discovering that every extra second that a page took to load led to 10% of <a href="https://www.creativebloq.com/features/how-the-bbc-builds-websites-that-scale" target="_blank" rel="noopener noreferrer">users leaving the page</a>.</li></ol> <h2 id="measuring-performance"><a href="#measuring-performance">#</a> Measuring performance</h2> <p>Given the importance of page performance, it is no coincidence that browsers expose a ton of insights into <a href="https://web.dev/metrics/" target="_blank" rel="noopener noreferrer">performance metrics</a>. Being aware of how your application scores against these <em>across time</em> will provide you the feedback you need to keep it performant for your users. There are several approaches that can be combined to achieve the best results:</p> <ol><li><em>Real user monitoring</em> to understand what performance actual end-users of your service are experiencing.</li> <li><em>Synthetic monitoring</em> to proactively gather intel on service performance, as well as to find issues before users stumble into them.</li> <li><em>Performance testing</em> to avoid releasing performance regression to production in the first place.</li> <li><em>Regular audits</em> to get an overview of your page's performance and suggestions on how to improve it, e.g. with tools such as <a href="https://developers.google.com/web/tools/lighthouse" target="_blank" rel="noopener noreferrer">Google Lighthouse</a>.</li></ol>  <p>As much as we should be striving to build performant applications, we should commit to monitoring and testing performance to enable continuous feedback and rapid intervention in case of degradation. Puppeteer and Playwright give us a great toolkit to power both synthetic monitoring and performance testing.</p> <ol><li>Access to the Web Performance APIs, especially <a href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceNavigationTiming" target="_blank" rel="noopener noreferrer">PerformanceNavigationTiming</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceResourceTiming" target="_blank" rel="noopener noreferrer">PerformanceResourceTiming</a>.</li> <li>Whenever testing against Chromium, access to the Chrome DevTools Protocol for traffic inspection, network emulation and more.</li> <li>Easy interoperability with performance libraries from the Node.js ecosystem.</li></ol> <h3 id="web-performance-apis"><a href="#web-performance-apis">#</a> Web Performance APIs</h3> <p>The <a href="https://www.w3.org/TR/navigation-timing/" target="_blank" rel="noopener noreferrer">Navigation Timing</a> and the <a href="https://www.w3.org/TR/resource-timing-1/" target="_blank" rel="noopener noreferrer">Resource Timing</a> performance APIs are <a href="https://www.w3.org/" target="_blank" rel="noopener noreferrer">W3C</a> specifications. The <a href="https://developer.mozilla.org/en-US/docs/Web/Performance/Navigation_and_resource_timings" target="_blank" rel="noopener noreferrer">MDN docs</a> very clearly define the scope of both:</p> <blockquote><p>Navigation timings are metrics measuring a browser's document navigation events. Resource timings are detailed network timing measurements regarding the loading of an application's resources. Both provide the same read-only properties, but navigation timing measures the main document's timings whereas the resource timing provides the times for all the assets or resources called in by that main document and the resources' requested resources.</p></blockquote> <p>We can use the Navigation Timing API to retrieve timestamps of key events in the page load timeline.</p>  <p>The Resource Timing API allows us to zoom in to single resources and get accurate information about how quickly they are being loaded. For example, we could specifically look at our website's logo:</p>  <h3 id="chrome-devtools-for-performance"><a href="#chrome-devtools-for-performance">#</a> Chrome DevTools for performance</h3> <p>The Chrome DevTools Protocol offers many great performance tools for us to leverage together with Puppeteer and Playwright.</p> <p>One important example is network throttling, through which we can simulate the experience of users accessing our page with different network conditions.</p>  <p>The DevTools Protocol is quite extensive. We recommend exploring the <a href="https://chromedevtools.github.io/devtools-protocol/" target="_blank" rel="noopener noreferrer">documentation</a> and getting a comprehensive overview of its capabilities.</p> <h3 id="additional-performance-libraries"><a href="#additional-performance-libraries">#</a> Additional performance libraries</h3> <p>Lighthouse can easily be used programmatically with Playwright and Puppeteer to gather values and scores for different metrics, like <a href="https://web.dev/interactive/" target="_blank" rel="noopener noreferrer">Time To Interactive (TTI)</a>:</p>  <h2 id="further-reading"><a href="#further-reading">#</a> Further reading</h2> <ol><li>The comprehensive <a href="https://developer.mozilla.org/en-US/docs/Web/Performance" target="_blank" rel="noopener noreferrer">MDN Web Performance documentation</a></li> <li><a href="https://web.dev/learn/#performance" target="_blank" rel="noopener noreferrer">web.dev's performance section</a></li> <li><a href="https://addyosmani.com/blog/puppeteer-recipes/" target="_blank" rel="noopener noreferrer">Web Performance Recipes With Puppeteer</a> by Addy Osmani</li> <li><a href="https://github.com/aslushnikov/getting-started-with-cdp" target="_blank" rel="noopener noreferrer">Getting started with Chrome DevTools Protocol</a> by Andrey Lushnikov</li> <li><a href="https://developers.google.com/web/tools/lighthouse#get-started" target="_blank" rel="noopener noreferrer">Get Started with Google Lighthouse</a></li></ol></div></div>]]>
            </description>
            <link>https://theheadless.dev/posts/basics-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370533</guid>
            <pubDate>Thu, 10 Dec 2020 06:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up OBS Studio for Screen Recording – Step-by-Step Procedure]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25369651">thread link</a>) | @ponderingfish
<br/>
December 9, 2020 | https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/ | <a href="https://web.archive.org/web/*/https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

		<div>

		

	<div id="primary">

		
					<main id="main">

				
					
					

<article id="post-2893" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

		
	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>So, you’ve downloaded and installed <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS Studio</a> on your computer and you want to start recording your screen, but you’re lost?</p>



<p>Well, simply <strong>follow this step-by-step tutorial and you will be ready to start recording high-quality videos of your screen in no time with OBS Studio</strong>. </p>



<p>Let’s get started.</p>



<hr>



<h2>A Brief Overview of OBS Studio</h2>



<p>Before we go further, let’s get an idea of the GUI layout of OBS Studio. To keep things simple, we will divide OBS Studio into 6 sections.</p>



<div><figure><img width="1024" height="550" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=300%2C161&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=768%2C412&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1536%2C825&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1200%2C644&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?w=1598&amp;ssl=1 1598w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20550'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=300%2C161&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=768%2C412&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1536%2C825&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1200%2C644&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?w=1598&amp;ssl=1 1598w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1"></figure></div>



<h3>1. Scenes</h3>



<p>If OBS is a canvas, <code>Scenes</code> would be a place that stores various pictures you can switch at any time. Each scene is used for different purposes. For example, a streamer would use different ones to signify when he is playing, waiting in a lobby, or taking a break.</p>



<h3>2. Sources</h3>



<p>You can think of <code>Sources</code> like a set of colors, you use to paint a scene. These are all of the elements shown on your screen during a recording. A good example of Sources are your logo, webcam, and chat window.</p>



<h3>3. Audio Mixer</h3>



<p>The mixer is where you will set up everything audio-related. More on that later.</p>



<h3>4. Scene Transitions</h3>



<p>Transitions provide you with animations you can play while switching up the scenes.</p>



<h3>5. Controls</h3>



<p>This houses the most important controls you will use to manipulate your recording.</p>



<h3>6. Preview Window</h3>



<p>Finally, there is a Preview Window. This shows exactly what you will see after you’ve recorded your video.</p>



<p>And don’t forget that OBS Studio is really customizable. You can drag and drop all of these windows and re-organize them to create a unique layout that suits your workflow.</p>



<p>Great, now that you have an idea of what hte OBS Studio layout looks like, let’s get started with setting up OBS Studio for recording.</p>



<hr>



<h2>Setup OBS Studio for Recording Your Screen</h2>



<p>Now let’s follow this step-by-step procedure to setup OBS Studio and start recording! </p>



<h3>1. Add Audio Sources</h3>



<p>Let’s start by setting up the audio. First, go to the <code>Controls &gt; Settings &gt; Audio</code>. Set both <code>Desktop Audio</code> and <code>Mic Audio</code> to <code>default</code>. Everything else should be disabled.</p>



<div><figure><img width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<p>Let’s quickly add some filters to make your voice sound more professional. Click on the gear icon next to <code>Mic/Aux</code> in <code>Audio Mixer</code>.</p>



<div><figure><img width="742" height="431" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=742%2C431&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?w=742&amp;ssl=1 742w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=300%2C174&amp;ssl=1 300w" sizes="(max-width: 742px) 100vw, 742px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20742%20431'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?w=742&amp;ssl=1 742w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=300%2C174&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=742%2C431&amp;ssl=1"></figure></div>



<p>Here we have 3 options: <code>Noise Suppression</code>, <code>Noise Gate</code>, and <code>Gain</code>.</p>



<div><figure><img width="598" height="257" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=598%2C257&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?w=598&amp;ssl=1 598w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=300%2C129&amp;ssl=1 300w" sizes="(max-width: 598px) 100vw, 598px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20598%20257'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?w=598&amp;ssl=1 598w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=300%2C129&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=598%2C257&amp;ssl=1"></figure></div>



<ul><li><strong>Noise Suppression</strong> will remove most of your background noise. Start from -10 dB and drop lower until you can’t hear the noise.</li><li><strong>Noise Gate</strong> will turn off your microphone when the volume drops below the Close Threshold. This way you won’t record your breathing. Settings will vary depending on your type of mic, so play with it until it feels natural.</li><li><strong>Gain</strong> is used for changing the volume of your mic.</li></ul>



<h3>2. Choose Recording Quality</h3>



<p>Go to the <code>Output</code> tab on the left and under <code>Recording</code> choose the path where OBS will save all your videos. By default, it’s set to <code>\Users\OBS\Videos</code>.</p>



<div><figure><img width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<p>Next, click on <code>Recording Quality</code>.</p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=874%2C675&amp;ssl=1" alt="Set up OBS Studio for Recording" width="874" height="675" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?w=985&amp;ssl=1 985w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=768%2C593&amp;ssl=1 768w" sizes="(max-width: 874px) 100vw, 874px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20874%20675'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?w=985&amp;ssl=1 985w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=768%2C593&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=874%2C675&amp;ssl=1"></figure></div>



<p>If you are just beginning to record your videos, we recommend that you choose <code>High Quality</code>. This will provide you with pretty good quality and reasonable file size.</p>



<p>Others should pick <code>Indistinguishable Quality</code>. This will give you a fully professional video that you can later edit in post-processing.</p>



<p>We can’t really recommend <code>Lossless</code> as it will eat up your storage without providing a perceptible difference.</p>



<p>Under <code>Recording Format</code> choose either <code>MKV</code> or <code>FLV</code> as they are very stable container formats. In case your PC or PBS crashes, you will likely be able to save your recording. </p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=864%2C666&amp;ssl=1" alt="Set up OBS Studio for Recording" width="864" height="666" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?w=979&amp;ssl=1 979w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=300%2C231&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=768%2C592&amp;ssl=1 768w" sizes="(max-width: 864px) 100vw, 864px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20864%20666'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?w=979&amp;ssl=1 979w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=300%2C231&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=768%2C592&amp;ssl=1 768w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=864%2C666&amp;ssl=1"></figure></div>



<p>You can easily convert your files later, by going to <code>File &gt; Remux Recording</code>.</p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=942%2C530&amp;ssl=1" alt="Set up OBS Studio for Recording" width="942" height="530" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 942px) 100vw, 942px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20942%20530'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=942%2C530&amp;ssl=1"></figure></div>



<h3>3. Add Scenes</h3>



<p>Now, you will want to create a game scene by clicking on the plus sign in <code>Scenes</code>. A new window will pop up where you can name it.</p>



<div><figure><img width="1024" height="576" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<h3>4. Capture Your Game</h3>



<p>After creating an in-game scene, keep it selected and click on the <code>+</code> sign in <code>Sources</code>, and select <code>Game Capture</code>. This will open up the properties and let you pick which game you want to record.</p>



<div><figure><img width="562" height="380" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=562%2C380&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?w=562&amp;ssl=1 562w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=300%2C203&amp;ssl=1 300w" sizes="(max-width: 562px) 100vw, 562px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20562%20380'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?w=562&amp;ssl=1 562w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=300%2C203&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=562%2C380&amp;ssl=1"></figure></div>



<p>For <code>Mode</code> make sure it’s set to <code>Capture</code> any fullscreen application. Once you start playing your game, OBS will automatically focus on it.</p>



<p>Nowadays, many games have an anti-cheat system that might affect OBS Studio. For this reason, you should select <code>Use anti-cheat compatibility hook</code>. Don’t worry, you won’t get banned for it.</p>



<p>If you enable 3rd party overlays like Discord or Steam, OBS will try and capture them as well. However, this does not always work, so make sure to check the preview window.</p>



<div><figure><img width="717" height="605" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=717%2C605&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?w=717&amp;ssl=1 717w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=300%2C253&amp;ssl=1 300w" sizes="(max-width: 717px) 100vw, 717px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20717%20605'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?w=717&amp;ssl=1 717w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=300%2C253&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=717%2C605&amp;ssl=1"></figure></div>



<p>Once you are done with the setup, click OK and exit. Your game should now be displayed in the OBS.</p>



<h3>5. Add your Webcam</h3>



<p>Go back to the <code>+</code> sign in <code>Sources</code> and select <code>Video Capture Device</code>.</p>



<div><figure><img width="500" height="393" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=500%2C393&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?w=500&amp;ssl=1 500w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=300%2C236&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20500%20393'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?w=500&amp;ssl=1 500w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=300%2C236&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=500%2C393&amp;ssl=1"></figure></div>



<p>That will take you to the <code>Properties</code>. Make sure that you select the right webcam and OBS will set it up. By default, <code>Resolution Type</code> is set to custom. If you want to change it, we recommend choosing either <code>1080p</code> or <code>720p</code>. Hit <code>OK</code> and your webcam will appear under <code>Scenes</code>. Just drag it where you want and resize if needed.</p>



<p>And that’s it! You are now ready to start recording videos in OBS Studio.</p>



<p>Hope you were able to follow this guide and set up your computer to record using <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS Studio</a>. Have fun recording your screen, or games! Let us know if you have any tips for setting up your OBS Studio installation and we’ll publish it. Thanks! </p>



<hr>

<!-- MOLONGUI AUTHORSHIP PLUGIN 4.2.11 -->
<!-- https://www.molongui.com/authorship/ -->

<div id="mab-9771553109" data-plugin-release="4.2.11" data-plugin-version="free" data-box-layout="slim" data-box-position="below" data-multiauthor="false" data-author-type="user" itemscope="" itemtype="https://schema.org/Person">

	
    <!-- Author headline -->
    <p>
        <h3>
            <span>About The Author</span>
        </h3>
    </p>

    <div>

        <div data-profile-layout="layout-1" data-author-ref="user-194568617">
            
<!-- End of .m-a-box-content-top -->

<div>

    <!-- Author picture -->
    
	<p><a href="https://ottverse.com/author/vkr2020/">
                    <img alt="" src="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=150&amp;d=mp&amp;r=g" srcset="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=300&amp;d=mp&amp;r=g 2x" height="150" width="150" itemprop="image" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </a>
                	</p>

    <!-- Author social -->
    
    <!-- Author data -->
    <div>

        <!-- Author name -->
        

        <!-- Author metadata -->
        

        <!-- Author bio -->
        
<div itemprop="description">
	<p>I’m Dr. Krishna Rao Vijayanagar, and I am the Founder and Editor of OTTVerse.com. I've spent several years working hands-on with Video Codecs (AVC, HEVC, MultiView Plus Depth), ABR streaming, and Video Analytics (QoE, Content &amp; Audience, and Ad). I hope to use my experience and love for video streaming to bring you information and insights into the OTT universe. Please use the Contact Page to get in touch with me.</p>
</div>

        
            <!-- Author related posts -->
            <!-- End of .m-a-box-related -->

        
    </div><!-- End of .m-a-box-data -->

</div><!-- End of .m-a-box-content-middle -->

<!-- End of .m-a-box-content-bottom -->        </div><!-- End of .m-a-box-profile -->

        
    </div><!-- End of .m-a-box-container -->

	
</div><!-- End of .m-a-box -->

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article><!-- #post-## -->


<!-- #comments -->

					
					
				
			</main><!-- #main -->
			
		
	</div><!-- #primary -->


	<!-- #secondary -->


			
			</div> <!-- ast-container -->

		</div></div>]]>
            </description>
            <link>https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25369651</guid>
            <pubDate>Thu, 10 Dec 2020 04:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Crossminds.ai – A knowledge graph indexed AI research video library]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25369075">thread link</a>) | @tecresearch
<br/>
December 9, 2020 | https://crossminds.ai/explore/ | <a href="https://web.archive.org/web/*/https://crossminds.ai/explore/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://crossminds.ai/explore/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25369075</guid>
            <pubDate>Thu, 10 Dec 2020 02:54:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Google Firestore Locally]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368698">thread link</a>) | @adrianancona
<br/>
December 9, 2020 | https://ncona.com/2020/12/running-google-firestore-locally/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/12/running-google-firestore-locally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In a previous article, <a href="https://ncona.com/2020/12/introduction-to-google-firestore/">we started playing with Google Firestore</a>. In this article we are going to learn how we can test our applications without the need to talk to Google Cloud.</p>

<p>Note that the local version of Google Firestore is intended for testing only and shouldn’t be used for production systems. It doesn’t provide the reliability or scalability features that the real Firestore does.</p>

<h2 id="firebase-emulator-suite">Firebase emulator suite</h2>

<p>Google provides this suite to help developers test applications without having to use production data or incur cost. The suite doesn’t only emulate the database, but also cloud functions and real-time functionality, to name a couple. In this article we’re only going to focus on the Firestore database.</p>

<!--more-->

<h2 id="firebase-cli">Firebase CLI</h2>

<p>We start by installing the <a href="https://firebase.google.com/docs/cli">Firebase CLI</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl -sL https://firebase.tools | bash
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can then start an instance of Firestore:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>firebase emulators:start --only firestore
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As part of the output we will get something like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>┌───────────┬────────────────┐
│ Emulator  │ Host:Port      │
├───────────┼────────────────┤
│ Firestore │ localhost:8080 │
└───────────┴────────────────┘
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Port <code>8080</code> is the default for Firestore. When the emulator starts it will look for a file named <code>firebase.json</code> where we can override the port:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>{</span><span>
  </span><span>"emulators"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"firestore"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"port"</span><span>:</span><span> </span><span>"9999"</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>One important thing to keep in mind about the emulator is that the data will be lost every time the emulator is stoped.</p>

<h2 id="connecting-to-the-emulator">Connecting to the emulator</h2>

<p>In <a href="https://ncona.com/2020/12/introduction-to-google-firestore/">Introduction to Google Firestore</a> we learned how to create a firestore client:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td><pre><span>// Constants necessary to create the firestore client</span>
<span>const</span> <span>GcpCredentialsFile</span> <span>=</span> <span>"/tmp/my-key.json"</span>
<span>const</span> <span>ProjectId</span> <span>=</span> <span>"project-12345"</span>

<span>// When done with the client, close it using:</span>
<span>// defer client.Close()</span>
<span>func</span> <span>createClient</span><span>(</span><span>ctx</span> <span>context</span><span>.</span><span>Context</span><span>)</span> <span>*</span><span>firestore</span><span>.</span><span>Client</span> <span>{</span>
  <span>client</span><span>,</span> <span>err</span> <span>:=</span> <span>firestore</span><span>.</span><span>NewClient</span><span>(</span><span>ctx</span><span>,</span> <span>ProjectId</span><span>,</span> <span>option</span><span>.</span><span>WithCredentialsFile</span><span>(</span><span>GcpCredentialsFile</span><span>))</span>

  <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"Failed to create client: %v"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>

  <span>return</span> <span>client</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To tell our app that we want to use the emulator, we need to set an environment variable:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>export </span><span>FIRESTORE_EMULATOR_HOST</span><span>=</span>localhost:8080
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will cause the credentials to be ignored, and the client will connect to the emulator instead.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This was a quick article to show how we can easily start a local version of Google Firestore that can be used for testing. The emulator provides a lot of advanced features, but I haven’t had the need for them, so I haven’t dived into them.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/12/running-google-firestore-locally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368698</guid>
            <pubDate>Thu, 10 Dec 2020 02:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming the ATtiny10]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368633">thread link</a>) | @taf2
<br/>
December 9, 2020 | http://www.technoblogy.com/show?1YQY | <a href="https://web.archive.org/web/*/http://www.technoblogy.com/show?1YQY">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>11th November 2017</p>
<p>This article describes how to program the ATtiny10, Microchip's diminuitive 6-pin processor, using the Arduino IDE. It's a great chip for building small gadgets and wearables, or designing interface logic for other projects, and it really lives up to its "tiny" name:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10.jpg" alt="ATtiny10.jpg" width="250" height="300"></p>
<p>The following sections explain how to program the ATtiny10 in C, and how to download programs using a low-cost ISP programmer. It also illustrates some simple applications with example programs.</p>
<p>For a couple of projects based on the ATtiny10 see&nbsp;<a href="http://www.technoblogy.com/show?201J">ATtiny10 POV Pendant</a>&nbsp;and&nbsp;<a href="http://www.technoblogy.com/show?2G8A">ATtiny10 Thermometer</a>.</p>
<h3><span>Introduction</span></h3>
<p>If, like me, you like using the simplest possible chip for each application, the ATtiny10 will appeal to you&nbsp;<sup id="cite_ref1"><a href="#cite_note1">[1]</a></sup>; it's a 6-pin processor, about the same size as an 0805 SMD resistor, and it costs about 35p/35¢. It packs in the following features:</p>
<ul>
<li>Internal 8MHz clock, by default prescaled to 1MHz.</li>
<li>Three I/O lines.</li>
<li>Two 16-bit PWM analogue outputs.</li>
<li>Three 8-bit analogue inputs.</li>
<li>An analogue comparator.</li>
<li>A 16-bit timer with input capture and an event counter.</li>
<li>A watchdog timer.</li>
<li>1024 bytes of program memory, 32 bytes of RAM, and no EEPROM.</li>
</ul>
<p>All of these features will be familiar to users of the larger AVR chips. Here's the pinout (using Spence Konde's design conventions):</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10pinout.gif" alt="ATtiny10Pinout.gif" width="701" height="159"></p>
<p>The internal oscillator is accurate to within 10%, but you can calibrate it in software to within 1%. You can configure RESET as a fourth I/O line, which prevents further programming, but I don't cover that in this article.</p>
<p>To work with the ATtiny10 on a breadboard you can mount it on a SOT23 breakout board, such as the one available from Sparkfun <sup id="cite_ref2"><a href="#cite_note2">[2]</a></sup>.</p>
<h3>Programming the ATtiny10</h3>
<p>Unlike the SPI protocol used to program the larger AVR chips, such as the ATmega328 in the Arduino Uno, the ATtiny10 uses a programming protocol called TPI (Tiny Programming Interface) which needs only five wires. Fortunately Thomas Fischl's excellent USBasp programmer supports this protocol&nbsp;<sup id="cite_ref3"><a href="#cite_note3">[3]</a></sup>; you can build your own, order one from his site, or they are widely available on eBay&nbsp;<sup id="cite_ref4"><a href="#cite_note4">[4]</a></sup>, Banggood&nbsp;<sup id="cite_ref5"><a href="#cite_note5">[5]</a></sup>, etc. I recommend getting one with a 10-pin to 6-pin adapter for ISP programming. The current versions of the Arduino IDE support the ATtiny10, so you can program it in C and upload programs as easily as with the other AVR chips. Since an Arduino core would use up almost half of the available program memory the best way to program it is to access the registers directly, and I give an overview of how to do this in the section&nbsp;<a href="#Alternatives">Alternatives to core functions</a>&nbsp;below.</p>
<p>Here are step-by-step instructions for programming the ATtiny10.</p>
<p>NOTE: There is a problem with compiling for the ATtiny10 with versions of the Arduino IDE 1.8.9 and higher. If necessary, run version 1.8.8 to do this, or for a workaround see the Disqus comments below.</p>
<ul>
<li>Download the <strong>ATtiny10Core</strong> hardware configuration from my repository on GitHub <a href="https://github.com/technoblogy/attiny10core" target="_blank">ATtiny10Core</a>.</li>
<li>Copy it to the&nbsp;<strong>hardware</strong>&nbsp;folder in your&nbsp;<strong>Arduino</strong>&nbsp;folder in your <strong>Documents</strong> folder. If there isn't already a <strong>hardware</strong> folder there, create one first.</li>
<li>Restart the Arduino IDE.</li>
</ul>
<p>This should add an&nbsp;<strong>ATtiny10Core</strong>&nbsp;heading to the <strong>Board</strong> menu.</p>
<ul>
<li>Enter your program into the Arduino IDE editor.</li>
</ul>
<p>For example, try the&nbsp;<strong>Blink</strong>&nbsp;example program given below.</p>
<ul>
<li>Connect the USBasp to the ATtiny10 as shown in the following diagram:</li>
</ul>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp.gif" alt="ATtiny10USBasp.gif" width="203" height="157"></p>
<p><em>Connecting the USBasp programmer to an ATtiny10.</em></p>
<ul>
<li>Choose&nbsp;<strong>Board</strong>&nbsp;from the&nbsp;<strong>Tools</strong>&nbsp;menu, and select the&nbsp;<strong>ATtiny10/9/5/4</strong>&nbsp;option under the <strong>ATtiny10Core</strong> heading; it's the only option.</li>
<li>Choose the chip you want from the <strong>Chip</strong> menu; for example&nbsp;<strong>ATtiny10</strong>.</li>
<li>Choose <strong>USBasp</strong> from the&nbsp;<strong>Programmer&nbsp;</strong>option on the&nbsp;<strong>Tools</strong>&nbsp;menu.</li>
<li>Choose&nbsp;<strong>Upload</strong>&nbsp;to upload the program.</li>
</ul>
<p>The LED should blink at 0.5Hz.</p>
<p>Here's my test setup on a mini breadboard:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/usbasp.jpg" alt="USBasp.jpg" width="680" height="324"></p>
<p><em>Testing the ATtiny10 Blink program on a mini breadboard, using the USBasp programmer.</em></p>
<h3>Examples</h3>
<p>Here are a couple of examples using the ATtiny10:</p>
<h4>Blink</h4>
<p>This is the ubiquitous Blink program:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;

int main (void) {
  DDRB = 1;                       // PB0 as an output
  TCCR0A = 1&lt;&lt;COM0A0 | 0&lt;&lt;WGM00;  // Toggle OC0A, CTC mode
  TCCR0B = 1&lt;&lt;WGM02 | 3&lt;&lt;CS00;    // CTC mode; use OCR0A; /64
  OCR0A = 15624;                  // 1 second; ie 0.5Hz
  while (1);
}</pre>
<p>To run it connect an LED to PB0 as follows:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp2.gif" alt="ATtiny10USBasp2.gif" width="157" height="128"></p>
<p><em>Circuit using an ATtiny10 to blink an LED.</em></p>
<p>It uses Timer/Counter0 to divide the 1MHz system clock by a prescaler value of 64, and then by 15625, toggling the output PB0 with a period of 1 second.</p>
<h4>Analogue frequency generator</h4>
<p>The following program reads the voltage from a potentiometer on analogue input ADC1 (PB1), and then uses this to set the compare match register OCR0A of Timer/Counter0, to generate a square wave on PB0 whose frequency you can control with the potentiometer:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;

int main (void) {
  DDRB = 1;                       // PB0 as an output
  // Set up ADC on PB2
  ADMUX = 1&lt;&lt;MUX0;                // ADC1 (PB1)
  ADCSRA = 1&lt;&lt;ADEN | 3&lt;&lt;ADPS0;    // Enable ADC, 125kHz clock
  // Set up waveform on PB0
  TCCR0A = 1&lt;&lt;COM0A0 | 3&lt;&lt;WGM00;  // Toggle OC0A, Fast PWM
  TCCR0B = 3&lt;&lt;WGM02 | 4&lt;&lt;CS00;    // Fast PWM with OCR0A as TOP; /256
  // Main loop
  for (;;) {
    ADCSRA = ADCSRA | 1&lt;&lt;ADSC;    // Start
    while (ADCSRA &amp; 1&lt;&lt;ADSC);     // Wait while conversion in progress
    OCR0A = ADCL;                 // Copy result to frequency output
  }
}</pre>
<p>Note that because we're changing the compare match value, we need to use Fast PWM mode in this application, because it double-buffers the compare match value. Here's the circuit:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp3.gif" alt="ATtiny10USBasp3.gif" width="247" height="132"></p>
<p><em>Circuit using a potentiometer to adjust the frequency of a square wave generated by an ATtiny10.</em></p>
<p>It generates a frequency between 1MHz/256/256, or about 15Hz, and 1MHz/256/1, or 3.9kHz.</p>
<h3 id="Alternatives">Alternatives to core functions</h3>
<p>The following sections give some tips on programming the ATtiny10 to achieve some of the things provided by the Arduino core functions.</p>
<h4>includes</h4>
<p>You need to add these includes at the start of your program to include the AVR register definitions and standard C++ routines:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;</pre>
<h4>setup and loop</h4>
<p>Arduino programs are normally written with the initialization in&nbsp;<strong>setup()</strong>&nbsp;and the main program in&nbsp;<strong>loop()</strong>, rather than the standard&nbsp;<strong>int&nbsp;main()</strong>&nbsp;function required by C. If you want to keep to this convention you'll need to add the following definition at the end of your program:</p>
<pre>int main() {
  setup();
  for(;;) loop();
}</pre>
<h4>pinMode</h4>
<p>To specify whether pins are inputs or outputs you set the corresponding bits in the <strong>DDRB</strong> register to 0 or 1 respectively. For example, to define pins 1 and 3 as outputs (and leave the other pins as inputs):</p>
<pre>DDRB = 0b0101; &nbsp; &nbsp;     // Equivalent to pinMode(1, OUTPUT); pinMode(3, OUTPUT);</pre>
<h4>Input pullups</h4>
<p>Unlike the older AVR chips, such as the ATmega328 and ATtiny85, the ATtiny10 enables pullup resistors using a separate pullup register, <strong>PUEB</strong>. To set pullups on input pins you set the corresponding bits in this&nbsp;register. For example, to set a pullup resistor on input pin 2:</p>
<pre>PUEB = 0b0010;         // Equivalent to pinMode(2, INPUT_PULLUP);</pre>
<p>Note that it doesn't make sense to set a pullup on an output.</p>
<h4>digitalWrite</h4>
<p>To set the state of an output you set the corresponding bits in the <strong>PORTB</strong> register. For example, to set bit 1 low and bit 3 high (assuming they have been defined as outputs):</p>
<pre>PORTB = 0b0100;        // Equivalent to&nbsp;digitalWrite(1, LOW);&nbsp;digitalWrite(3, HIGH);</pre>
<p>Changing the state of&nbsp;an input has no effect.</p>
<h4>digitalRead</h4>
<p>To read the state of the I/O pins you read the <strong>PINB</strong> register:</p>
<pre>int temp = PINB;</pre>
<h4>analogWrite</h4>
<p>You can use OC0A (PB0) and OC0B (PB1) for analogue output using PWM. You first need to configure the Timer/Counter into PWM mode for that pin; for example, using PB0:</p>
<pre>TCCR0A = 2&lt;&lt;COM0A0 | 3&lt;&lt;WGM00; // 10-bit PWM on OC0A (PB0), non-inverting mode
TCCR0B = 0&lt;&lt;WGM02 | 1&lt;&lt;CS00;   // Divide clock by 1
DDRB = 0b0001;                 // Make PB0 an output</pre>
<p>To write an analogue value we then need to write the value to the appropriate output compare register, OCR0A:</p>
<pre>OCR0A = 1000;                  // Equivalent to analogWrite(0, 1000)</pre>
<p>With a 5V supply this will set PB0 to 1000/1024 * 5V, or 4.88V.</p>
<h4>analogRead</h4>
<p>To use an I/O pin for analogue input you first need to configure the Analogue-to-Digital Converter. For example, to use ADC0:</p>
<pre>ADMUX = 0&lt;&lt;MUX0;               // ADC0 (PB0)
ADCSRA = 1&lt;&lt;ADEN | 3&lt;&lt;ADPS0;   // Enable ADC, 125kHz clock</pre>
<p>To read an analogue value from the pin we then need to start a conversion, and when the conversion is ready read the ADC register:</p>
<pre>ADCSRA = ADCSRA | 1&lt;&lt;ADSC;     // Start
while (ADCSRA &amp; 1&lt;&lt;ADSC);      // Wait while conversion in progress
int temp = ADCL;               // Copy result to temp
</pre>
<h4>delay</h4>
<p>For a simple substitute for&nbsp;<strong>delay()</strong>&nbsp;you can use a loop adjusted to give roughly the right timing:</p>
<pre>void delay (int millis) {
  for (volatile unsigned int i = 34*millis; i&gt;0; i--);
}</pre>
<p>This would provide an alternative way of writing the Blink program. Note that the counter variable&nbsp;<strong>i</strong>&nbsp;must be defined as&nbsp;<strong>volatile</strong>&nbsp;or the compiler will optimise it out of the loop, eliminating the delay.</p>
<p>For more accurate delays, and to implement timers like&nbsp;<strong>millis()</strong>, you could set up Timer/Counter0 as a timer, or use the Watchdog Timer.</p>
<h3>Update</h3>
<p>30th December 2019: Added a note about problems compiling for the ATtiny10 with versions of the Arduino IDE 1.8.9 or later. Use 1.8 to 1.8.8.</p><hr>
<ol>
<li id="cite_note1"><a href="#cite_ref1">^</a> <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-8127-AVR-8-bit-Microcontroller-ATtiny4-ATtiny5-ATtiny9-ATtiny10_Datasheet.pdf">ATtiny10 Datasheet</a> on Microchip.</li>
<li id="cite_note2"><a href="#cite_ref2">^</a> <a href="https://www.sparkfun.com/products/717" target="_blank">Sparkfun SOT23 to DIP Adapter</a> on Sparkfun.</li>
<li id="cite_note3"><a href="#cite_ref3">^</a> <a href="http://www.fischl.de/usbasp/" target="_blank">USBasp - USP programmer for Atmel AVE controllers</a>&nbsp;on www.fischl.de.</li>
<li id="cite_note4"><a href="#cite_ref4">^</a> <a href="https://www.ebay.co.uk/itm/USBASP-USBISP-ISP-Programmer-Cable-Adapter-KK2-0-KK2-1-Atmel-AVR-ATMega-ARDUINO/131241223483" target="_blank">USBASP ISP Programmer Cable Adapter</a>&nbsp;from Boos Bits on eBay.</li>
<li id="cite_note5"><a href="#cite_ref5">^</a> <a href="https://www.banggood.com/USBASP-USBISP-3_3-5V-AVR-Downloader-Programmer-With-ATMEGA8-ATMEGA128-p-934425.html" target="_blank">USBASP 3.3 5V AVR Downloader Programmer</a>&nbsp;on Banggood.</li>
</ol>

<hr>


<p><a href="http://disqus.com/">blog comments powered by </a></p></div></div>]]>
            </description>
            <link>http://www.technoblogy.com/show?1YQY</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368633</guid>
            <pubDate>Thu, 10 Dec 2020 02:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behind the scenes photos of YC S20]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368499">thread link</a>) | @cheeseblubber
<br/>
December 9, 2020 | https://papercups.io/blog/what-remote-demo-day-looked-like | <a href="https://web.archive.org/web/*/https://papercups.io/blog/what-remote-demo-day-looked-like">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/what-remote-demo-day-looked-like</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368499</guid>
            <pubDate>Thu, 10 Dec 2020 01:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How eBPF Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25367728">thread link</a>) | @gk1
<br/>
December 9, 2020 | https://goteleport.com/blog/what-is-ebpf/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/what-is-ebpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-header.png" width="100%" alt="what is ebpf"></p>

<p>About a year ago, a friend of mine decided to build an <a href="https://medium.com/mycrypto/the-ethereum-virtual-machine-how-does-it-work-9abac2b7c9e">EVM</a> (Ethereum Virtual Machine) assembler in Rust. After some prodding from him, I began to help by writing unit tests. At the time, I knew very little about operating systems and started to read about lexical and symbolical analyzers. I was quickly in way over my head. What I did retain, however, was a newfound appreciation for the OS as a whole. So, when he started raving about eBPF, I knew I was in for a treat.</p>

<p>The bar for understanding what eBPF is and what it can do is high. Finding a good foothold to start was difficult for me. On the spectrum of basic 500-word mini-blogs to <a href="https://cilium.io/">Cilium’s</a> overwhelming documentation, material certainly skews towards documentation. My goal here is to provide a thorough entrypoint into this nascent technology, preparing you for progressively technical deep dives, like <a href="https://lwn.net/Articles/740157/">Linux Weekly News</a>, <a href="http://www.brendangregg.com/index.html">Brendan Gregg’s</a> website, and Cilium’s <a href="https://docs.cilium.io/en/stable/bpf/">documentation</a>. Together, we will explore:</p>

<ul>
<li>What eBPF does</li>
<li>How eBPF works</li>
<li>An example of eBPF in use</li>
<li>How to start using eBPF</li>
</ul>

<h2 id="what-does-ebpf-do">What Does eBPF Do?</h2>

<p>eBPF lets programmers execute custom bytecode within the kernel <em>without</em> having to change the kernel or load kernel modules. Exciting? Maybe not yet. eBPF is closely intertwined with the Linux kernel. For context, let’s briefly review some fundamental concepts.</p>

<p>Linux divides its OS into two distinct areas: kernel space and user space. Kernel space is where the core of the operating system resides. It has full and unrestricted access to all hardware - memory, storage, CPU, etc. Due to the privileged nature of kernel access, the space is protected and allowed to run only the most trusted code. User space is where anything that is not a kernel process runs - I/O, file system manipulation, etc. These programs have limited access to hardware and must make syscalls through an API exposed by the kernel. In other words, user space programs must be filtered through the kernel space.</p>

<p>While the system call interface was sufficient in most cases, developers need more flexibility to add support for new hardware, filesystems, network protocols, or even custom system calls. There had to be a way for custom programs to access hardware directly, a way to extend the base kernel without adding directly to the kernel source code. <a href="https://tldp.org/LDP/lkmpg/2.6/html/lkmpg.html">Linux Kernel Modules</a> (LKMs) serve this function. Unlike system calls, whereby requests traverse from the user space to kernel space, LKMs are loaded directly into the kernel, making them a part of it. Perhaps the most valuable feature of LKMs is that it can be loaded at runtime, removing the need to recompile the entire kernel and reboot the machine.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-1.png" width="60%" alt="LKMs in kernel space"></p>

<p>Figure 1 - LKMs can be dynamically loaded and unloaded as part of kernel space (<a href="http://derekmolloy.ie/writing-a-linux-kernel-module-part-1-introduction/">Source</a>)</p>

<p>As helpful as LKMs are, they do introduce a lot of risk to the system. The division of kernel and user spaces added a number of security measures to the OS. The kernel space is meant to run only a privileged OS kernel. The layer between, connected by the system call interface, separated user space programs that could mess with finely tuned hardware. In other words, LKMs could certainly crash the kernel. Aside from the wide blast radius of security vulnerabilities, modules incur a large overhead maintenance cost in that kernel version upgrades could break the module.</p>

<h4 id="what-is-ebpf">What is eBPF</h4>

<p>eBPF programs are a more recent invention for accessing services and hardware from the Linux kernel space. Already these programs have been used for networking, debugging, tracing, firewalls, and more.</p>

<p>Born out of a need for better Linux tracing tools, eBPF drew inspiration from <code>dtrace</code>, a dynamic tracing tool available primarily for Solaris and BSD operating systems. Unlike <code>dtrace</code>, Linux could not get a global overview of running systems, it was limited to specific frameworks for system calls, library calls, and functions. Building on the Berkeley Packet Filter (BPF), a tool for writing packer-filtering code using an in-kernel VM, a small group of engineers began to extend the BPF backend to provide a similar set of features as <code>dtrace</code>. First released in limited capacity in 2014 with Linux 3.18, making full use of eBPF requires at least Linux 4.4 or above.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-2.png" width="100%" alt="simplified visualization of eBPF architecture"></p>

<p>Figure 2</p>

<p>In Figure 2, we see a simplified visualization of eBPF architecture. Before being loaded into the kernel, the eBPF program must pass a certain set of requirements. Verification involves executing the eBPF program within the virtual machine. Doing so allows the <a href="https://github.com/torvalds/linux/blob/master/kernel/bpf/verifier.c">verifier</a>, with 10,000+ lines of code, to perform a series of checks. The verifier will traverse the potential paths the eBPF program may take when executed in the kernel, making sure the program does indeed run to completion without any looping that would cause a kernel lockup. Other checks, from valid register state, program size, to out of bound jumps, must also be met. Almost immediately, eBPF sets itself apart from LKMs with important safety controls in place.</p>

<p>If all checks are passed, the eBPFprogram is loaded and compiled into the kernel at a point in a code path and listens for the right signal. That signal comes in the form of an event that passes where the program is loaded in the code path. Once triggered, the bytecode executes and collects information as per its instructions.</p>

<p>So what does eBPF do? It lets programmers safely execute custom bytecode within the Linux kernel without modifying or adding to kernel source code. While still a far cry from replacing LKMs as a whole, eBPF programs introduce custom code to interact with protected hardware resources with minimal threat to the kernel.</p>

<h2 id="how-ebpf-works">How eBPF Works</h2>

<p>So far, I’ve reduced eBPF to its bare architecture. But, there are more components working together, each of which has layers of complexity of their own.</p>

<h3 id="anatomy-of-an-ebpf-program">Anatomy of an eBPF Program</h3>

<h4 id="events-and-hooking">Events and Hooking</h4>

<p>eBPF programs are triggered by events that pass a particular location in the kernel. These events are captured at hooks when a specific set of instructions are executed in a single run. When triggered, these hooks will execute an eBPF program, letting us capture or manipulate data. The diversity of hook locations is one of the many aspects that makes eBPF so useful. A quick sampling of these locations include:</p>

<ul>
<li>System Calls - Inserted when user space functions transfer execution to the kernel</li>
<li>Function Entry and Exit - Intercepts calls to pre-existing functions</li>
<li>Network Events - Executes when packets are received</li>
<li>Kprobes and uprobes - Attach to probes for kernel or user functions</li>
</ul>

<h4 id="helper-calls">Helper Calls</h4>

<p>When eBPF programs are triggered at their hook points, they make calls to helper functions. These special functions are what makes eBPF feature-rich in accessing memory. For example, helpers can perform a wide variety of tasks:</p>

<ul>
<li>Search, update, and delete key-value pairs in tables</li>
<li>Generate a pseudo-random number</li>
<li>Collect and flag tunnel metadata</li>
<li>Chain eBPF programs together, known as tail calls</li>
<li>Perform tasks with sockets, like binding, retrieve cookies, redirect packets, etc.</li>
</ul>

<p>These helper functions must be defined by the kernel, meaning there is a whitelist of calls eBPF programs can make. But the <a href="https://man7.org/linux/man-pages/man7/bpf-helpers.7.html">number</a> is large and continues to grow.</p>

<h4 id="maps">Maps</h4>

<p>To store and share data between the program and kernel or user spaces, eBPF makes use of maps. As implied by the name, maps are key-value pairs. Supporting a number of different data structures, like hash tables, arrays, and tries, programs are able to send and receive data in maps using helper functions.</p>

<h3 id="executing-an-ebpf-program">Executing an eBPF Program</h3>

<h4 id="loading-and-verifying">Loading and Verifying</h4>

<p>The kernel expects all eBPF programs to be loaded as bytecode, so unless bytecode is being written, we need a way to compile higher level languages. To build out this compiler, eBPF uses <a href="https://llvm.org/">LLVM</a> as its back-end infrastructure on which a front-end for any programming language can be built. Because eBPF programs are written in C, that language front end is <a href="https://clang.llvm.org/">Clang</a>. But before compiled bytecode can be hooked anywhere, it must pass a series of checks. By simulating the program in a VM-like construct, an <a href="https://elixir.bootlin.com/linux/latest/source/kernel/bpf/verifier.c">in-kernel verifier</a> can prevent programs that loop, do not have the right permissions, or crash the kernel. If the program passes all checks, program bytecode will be loaded onto the hook point using a <code>bpf()</code> system call</p>

<h4 id="just-in-time-jit-compiler">Just-In-Time (JIT) Compiler</h4>

<p>After verification, eBPF bytecode is JIT’d into native machine code. eBPF has a modern design, meaning it has been upgraded to be 64-bit encoded with 11 total registers. This closely maps eBPF to hardware for x86_64, ARM, and arm64 architecture, amongst others. Fast compilation at runtime makes it possible for eBPF to remain performant even as it must first pass through a VM.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-3.png" width="100%" alt="eBPF architecture"></p>

<p>eBPF Architecture (<a href="https://lucid.app/invitations/accept/0096e31e-14f9-47d4-a1a0-57e82b3bc6f5">Raw LucidChart</a>)</p>

<h3 id="summary">Summary</h3>

<p>Putting this conceptual jigsaw together, eBPF programs are inserted into a hook point after passing a number of safety checks. When they are triggered by an event, programs execute immediately, using a combination of helper functions and maps to manipulate and store data. We’ll take a closer look at how these components work together in the next section</p>

<h2 id="example-ebpf-in-action">Example: eBPF in Action</h2>

<p>At Teleport, we’ve used a few eBPF programs in one of our open source projects, Teleport, for tracing and networking. For some necessary context: <a href="https://goteleport.com/teleport">Teleport</a> gives developers secure server access via SSH. Because organizations want to know what happens during a session, Teleport records user actions. Yet there are ways to bypass session recording entirely by obfuscating behavior within encoded commands, commands run in shell scripts, or even terminal commands like disabling <code>echo</code>.</p>

<p>Earlier this year with our <a href="https://goteleport.com/blog/teleport-release-4-2">Teleport 4.2 release</a>, we introduced <em>enhanced</em> session recording, which uses three eBPF programs (for now!) to take unstructured SSH sessions and transform them into a stream of structured events.</p>

<p>Consider <code>echo Y3VybCBodHRwOi8vd3d3LmV4YW1wbGUuY29tCg== | base64 --decode | sh</code>. Though we can capture this command printed in the terminal, it means nothing to us as the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goteleport.com/blog/what-is-ebpf/">https://goteleport.com/blog/what-is-ebpf/</a></em></p>]]>
            </description>
            <link>https://goteleport.com/blog/what-is-ebpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367728</guid>
            <pubDate>Thu, 10 Dec 2020 00:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOSBox-X 0.83.8 Released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25367662">thread link</a>) | @fm77
<br/>
December 9, 2020 | https://dosbox-x.com/release-0.83.8.html | <a href="https://web.archive.org/web/*/https://dosbox-x.com/release-0.83.8.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
            <tbody><tr>
            <td></td>
            <td>
            <p>1. Notable New Features</p>
<ul>
<li><p>Scalable TrueType font (TTF) output for DOS applications</p>With the new TrueType font (TTF) output, you will get nice high resolution DOS screen rendered using a TrueType font (either the built-in one or a TTF font of your choice), and the window can be set to almost any usable number of lines and columns. This feature greatly improved DOSBox-X's support for DOS applications. Set "output=ttf" (or from the "Video" menu) to enable this output.</li>

<li><p>On-screen text styles for DOS applications</p>With the TrueType font output, DOSBox-X now supports on-screen text styles for DOS applications including WordPerfect, WordStar, and XyWrite. With this feature you will visually see fonts in bold for bold text, and fonts in italics for italicized text, and so on. Set a DOS word processor (WP/WS/XY) to enable this feature.</li>

<li><p>Support for Apple M1 Mac and macOS Big Sur</p>DOSBox-X now supports the new Apple ARM-based M1 MacBooks! The dynamic core now works on the new ARM-based macOS systems. The audio also works once again when compiled and run on macOS 11 Big Sur.</li>

<li><p>Pasting clipboard text in macOS SDL1 builds</p>Pasting text from the host system clipboard is now supported in the macOS SDL1 build, similar to the Linux SDL1 build. On all other platforms (Windows SDL1/SDL2, Linux SDL2, and macOS SDL2) both copying to and pasting from the clipboard are supported.</li>

<li><p>System menu in Windows SDL2 builds</p>The system menu that was available in Windows SDL1 builds is now also
available for Windows SDL2 builds, which includes a few common menu options such as the configuration tool and the mapper editor.</li>

<li><p>Select common host keys from the menu</p>You can now select a host key from the "Main" menu, which now includes common key combinations such as Ctrl+Alt, Ctrl+Shift, and Alt+Shift, or you may just use the mapper-defined host key (which default to F11 on Windows and F12
otherwise). The default shortcuts for a few items are changed to use the host key style.</li>

<li><p>Switch OpenGL (GLSL) shaders at run-time</p>With the OpenGL outputs (opengl/opengnb/openghq), you can now select and switch to a different GLSL shader at the run-time by selecting the menu item "Select OpenGL (GLSL) shader..." from the "Video" menu, similar to the function for Direct3D pixel shaders for the Direct3D output.</li>

<li><p>Display IDE disk or CD status</p>There is now a menu option under "DOS" menu which allows you to see the current assignments (disk or CD image) of the IDE controllers.</li>

<li><p>Support for mounting MAME CHD CD images</p>Mounting the MAME CHD images is now supported in DOSBox-X! You can mount CHD files as CD images with IMGMOUNT command, or from the "Drive" menu.</li>

<li><p>Support for saving your files for the save-state feature</p>There is a now a FLAGSAVE command which allows you to mark files to be saved and loaded by the save-state feature. Type "FLAGSAVE /?" at the DOSBox-X shell for more usage information.</li>

<li><p>Enhanced MODE command to change screen dimensions</p>You can now change the number of columns and lines on the screen with the
MODE command, similar to real DOS systems. Alternatively, this can be done from the "Video" menu (within "Text-mode" menu group).</li>

<li><p>Improved LOADFIX command to auto-allocate memory</p>The LOADFIX command now has an -a option which will automatically allocate enough memory to fill lowest 64KB memory instead of using exactly 64KB memory. This will let some memory-demanding DOS programs or games to run with this command.</li>

<li><p>Improved automatic fix for the "Packed file corrupt" error</p>The handler for the "Packed file corrupt" error has been greatly improved so that it will likely automatically handle the error more efficiently. There is now also an option to silence the messages during the automatic fix.</li>

</ul>

            <p>2. Notable Usability Improvements</p>
<ul>
<li><p>Improved mapper editor interface</p>The mapper editor interface has been enhanced! The texts for the shortcut functions are now longer and clearer, and there are now multiple pages in the mapper, navigable with the "Previous Page" and "Next Page" buttons.</li>

<li><p>Load DOSBox-X mapper files from menu</p>You can now select and load DOSBox-X mapper files at run-time from the "Main" menu. Previously it was possible to load a mapper file dynmically from the command line, but now you can do so from the menu too.</li>

<li><p>List network interfaces from menu</p>There is now a "List network interfaces" menu option under the "Help" menu that will list the current network interfaces for the NE2000 networking feature. Previously you can only see the network interface list from the log file.</li>

<li><p>Display DOS command help from menu</p>You can now find a "DOS commands" menu group under the "Help" menu, which allows you to select a DOS shell command (DIR, CD, etc) to see its help messages. Alternatively you can type "[COMMAND] /?" (e.g. "DIR /?") for help information for the command.</li>

<li><p>Searching for config file and mapper file in DOSBox-X executable path</p>DOSBox-X will now look for the config file (e.g.
dosbox-x.conf) and the mapper file in the directory containing the DOSBox-X executable too if they cannot be found in the DOSBox-X working directory. This makes DOSBox-X even more portable.</li>

<li><p>More saving options for the built-in configuration tool</p>The graphical configuration tool now provides the option to save
to the primary or user config files, not just the dosbox-x.conf file.</li>

<li><p>New config options for save state options</p>The config options "saveremark" and "forceloadstate" are added to [dosbox]
section which can be used to control the save state-related options from the config file. In the previous section these can only be done from the "Capture" menu.</li>

</ul>

            <p>3. Bugfixes and Other Improvements</p>
There are also many bugfixes and other improvements, such as fixing the CD audio issue with the game "The Secret of Monkey Island" when talking to the pirate in Scumm Bar. Please see the full changelogs below for more information.
<p>4. Full Changelog In This Version</p>
<ul>
<li>
Added support for scalable TrueType font (TTF)
output for text-mode programs. Set "output=ttf"
and optionally a monospaced TTF font (such as
consola) with config option "ttf.font" to use it.
Lines and columns can be specified with config
options "ttf.lins" and "ttf.cols", and the cursor
can be made blinking with the option "ttf.blinkc".
The config options "ttf.ptsize" and "ttf.winperc"
can be used to set the TTF font size and window
percentage respectively. If you specify a TTF font
size with "ttf.ptsize" then "ttf.winperc" will be
ignored. You can also specify a word processor
(WP=WordPerfect, WS=WordStar, XY=XyWrite) for the
on-screen text-style and 512-character font (WP)
features. When using the TTF output DOSBox-X will
temporarily switch to a different output when a
graphical mode is requested (or when trying to take
a screenshot); the TTF output will be auto-switched
back later), which can be customized via config
option "ttf.outputswitch" (which defaults to auto).
Menu items in the "Text-mode" menu group (under
"Video" menu) have been expanded to support TTF
options such as increasing/decreasing the TTF font
sizes and on-screen text style toggling (including
bold, italics, underline and strikeout). You can
also select a TTF font to use at run-time with the
"Select TrueType font (TTF)" menu option. (Wengier)
</li><li>
Added the "Load mapper file..." menu option (under
"Main") to select and load a DOSBox-X mapper file
at run-time. Be sure to select a SDL1 mapper file
for SDL1 builds, and similar for SDL2. (Wengier)
</li><li>
You can now select a host key from the menu (under
"Main") including Ctrl+Alt, Ctrl+Shift, Alt+Shift,
or use the mapper-defined host key as in previous
versions (which default to F11 on Windows and F12
otherwise). A config option "hostkey" is added so
that you can specify it from config file. (Wengier)
</li><li>
Pasting text from the clipboard on macOS SDL1 build
is now supported like Linux SDL1 build. (Wengier)
</li><li>
Added support for ARM-based Apple M1 MacBook. The
dynamic core now works on ARM-based macOS systems.
SDL1 builds updated to use newer audio APIs on the
macOS platform so that the audio works once again
when compiled and run on macOS 11 (Big Sur). Prior
to the change, ancient versions of the API dating
back to the mid 2000s were used which no longer
work on Big Sur.
</li><li>
DOSBox-X will now look for the config file (i.e.
dosbox-x.conf/dosbox.conf) and the mapper file in
the directory containing the DOSBox-X executable
too if the config or mapper file cannot be found
in the DOSBox-X working directory. (Wengier)
</li><li>
The system menu in Windows SDL1 builds is now also
available for Windows SDL2 builds, and menu items
"Reset font size", "Increase TTF font size" and
"Decrease TTF font size" are added. (Wengier)
</li><li>
Enhanced the mapper editor interface to allow more
keyboard shortcuts to be added, shown in multiple
pages in the mapper, navigable with the "Previous
Page" and "Next Page" buttons. The text in the
grids are now longer and clearer too. The default
shortcuts for a few items are changed to use the
Host key style (e.g. Host+S and Host+L for saving
and loading states respectively). (Wengier)
</li><li>
Added menu item "List network interfaces" under
"Help" menu to list network interfaces in the host
system for the NE2000 feature. (Wengier)
</li><li>
Added menu group "DOS commands" under "Help" menu
to display the help content for the selected DOS
shell command (DIR, CD, etc). (Wengier)
</li><li>
Configuration Tool now provides the option to save
to the primary or user config files. (Wengier)
</li><li>
Certain config options (e.g. doublescan) that were
marked as advanced options are now general config
options and will appear in dosbox-x.reference.conf
apart from dosbox-x.reference.full.conf. (Wengier)
</li><li>
Added config options "saveremark" (default: true)
and "forceloadstate" (default: false) in [dosbox]
section which can be used to control if DOSBox-X
should ask users to enter remarks when saving a
state or show warnings when loading a saved state
if there is a mismatch found. (Wengier)
</li><li>
The config option "pixelshader" is moved from the
section [gui] to [render] …</li></ul></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dosbox-x.com/release-0.83.8.html">https://dosbox-x.com/release-0.83.8.html</a></em></p>]]>
            </description>
            <link>https://dosbox-x.com/release-0.83.8.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367662</guid>
            <pubDate>Thu, 10 Dec 2020 00:22:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Filmbox – Physically accurate motion picture film emulation]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25367371">thread link</a>) | @wilg
<br/>
December 9, 2020 | https://videovillage.co/filmbox/ | <a href="https://web.archive.org/web/*/https://videovillage.co/filmbox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://videovillage.co/images/filmbox/hero-ee5486c3.jpg" alt="Hero"></p><p><h2>A complete reproduction of photochemical motion picture imaging.</h2><h2>Driven by empirical data and tailored to specific digital sensors.</h2><h2>Built for high-end production. Right in DaVinci Resolve.</h2></p><div><div><p><h2>The look and feel of motion picture film defines a century of art.</h2><h2>As we move beyond the photochemical process, we need not leave behind its aesthetic quality.</h2></p><div><div><div><p><h2>Film negative has a unique response to light intensity and wavelength. Filmbox reproduces this behavior using rich empirical datasets to transform digital sensor values to exhibit the same non-linearities.</h2></p></div></div></div><div><div><div><p><h2>As light strikes color film negative, different wavelengths scatter to different degrees within the layers of emulsion and affect neighboring image regions. Filmbox convolves the digital image data to recreate the soft yet detailed quality of the negative.</h2></p></div></div></div><div><div><div><p><h2>The perceptual intensity of film grain varies with the density of the developed negative. Filmbox reproduces the quality and tonal distribution of grain as well as other subtle effects of the development process.</h2></p></div></div></div><div><div><div><p><h2>Film camera transport mechanisms are not perfectly stable, and labs are not perfectly clean. If desired, Filmbox can model the subtle instability of real 35mm and 16mm cameras, and procedurally place samples of real dust.</h2></p></div></div></div><div><div><div><p><h2>The look of projected film is the combination of the characteristics of the negative and the print.</h2><h2>Filmbox maps the emulated negative to the light output of the digital display using a characterization of the combined photometric response of an actual contact printed negative.</h2></p></div></div></div></div></div><div><div><video autoplay="" data-sources="W3sic3JjIjoiL2ltYWdlcy9maWxtYm94L3ZpZGVvL2NvbXBhcmlzb24vdmlk
ZW8ubXA0IiwidHlwZSI6InZpZGVvL21wNDsgY29kZWNzPVwiYXZjMVwiIn1d
" loop="" muted="" playsinline="" poster="https://videovillage.co/images/filmbox/video/comparison/poster-c124bf44.jpg"><img alt="Comparison of Filmbox and actual film" src="https://videovillage.co/images/filmbox/video/comparison/poster-c124bf44.jpg"></video></div></div><div><div><p><h2>Built for simplicity, no tweaking necessary.</h2><h2>Consistent, predictable, understandable by the whole creative team.</h2><h2>Plenty of knobs under the hood if you want to tinker.</h2></p><div><p><img src="https://videovillage.co/images/filmbox/features/default-17385d13.jpeg" alt="Default"></p></div></div></div><div><div><p><img src="https://videovillage.co/images/filmbox/workflow_fb-f68b50df.jpg" alt="Workflow fb"></p><p>Pro Workflows</p><div><p>Profiled for Alexa, Venice, RED, Varicam, Blackmagic URSA, C300II</p><p>Work in the camera's native space, Resolve Intermediate, or ACES</p><p>Set looks between the Negative and Print to simulate DI and printer lights</p><p>Output as negative, or as print to standard display spaces or ACES</p></div></div><div><p><img src="https://videovillage.co/images/scatter/gpu-52db23e1.jpg" alt="Gpu"></p><p>Fast</p><div><p>Built for DaVinci Resolve using GPU acceleration</p><p>Realtime performance at DCI 4K</p></div></div></div><section><div><p><img width="128" height="128" src="https://videovillage.co/images/filmbox-6cdfa86d.png" alt="Filmbox"></p><p>Filmbox</p><p>Really good film emulation</p></div><div><div><p>Filmbox is still in early access so we can make sure it works great.</p>

<p>Plugin for DaVinci Resolve. Requires macOS 10.15 or later and DaVinci Resolve 16 or later.</p>
</div></div></section><section id="footer"><p>© &amp; ™ 2014-2020 Video Village, LLC</p><p>Made in California by <a href="http://gregcotten.com/">Greg Cotten</a> &amp; <a href="http://wilgieseler.com/">Wil Gieseler</a> &amp; <a href="http://afinch.com/">Andrew Finch</a>.</p></section></div></div>]]>
            </description>
            <link>https://videovillage.co/filmbox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367371</guid>
            <pubDate>Wed, 09 Dec 2020 23:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Own Your Email]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25367035">thread link</a>) | @fabienpenso
<br/>
December 9, 2020 | https://pen.so/2020/12/10/own-your-email/ | <a href="https://web.archive.org/web/*/https://pen.so/2020/12/10/own-your-email/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
		<p>Using <em>@gmail.com</em> for your email address is like living at someone’s house
without rent and potentially being kicked out any day without warning. All your
belongings inside, without any access.</p>

<p>One of my first jobs around 1997 was being a sysadmin and managing email
servers, writing <code>sendmail.cf</code> configuration files without M4, and I should
have known better.</p>

<p>Someone who used Gmail for over 10 years <a href="https://www.businessinsider.fr/us/google-users-locked-out-after-years-2020-10">recently got locked
out</a>
without explanation. When all services you use, tools, and all your life are
connected to your <em>@gmail.com</em> address, you can imagine how much of a nightmare
scenario this is.</p>

<blockquote>
  <p>“It feels like getting baited by all the convenience that Google offers, only for Google to use your data as it pleases and possibly takes it all away with no prior notice.”</p>

  <p><cite>— <a href="https://www.businessinsider.fr/us/google-users-locked-out-after-years-2020-10">What it’s like to get locked out of Google indefinitely</a></cite></p>
</blockquote>

<p>Gmail has been here for so long it’s hard to imagine they can take it away from
you just as quickly. And good luck to get it back once that happens… Therefore
I highly recommend using their <a href="https://takeout.google.com/">Takeout</a> feature
to back up all your data and move away from using their domain <em>@gmail.com</em> in
your email address.</p>

<p>The unit of Internet space ownership is the domain name, get yours now.</p>

<p>I also use my <em>@gmail.com</em> too much because it’s easy, and its spam filtering
is so good. But I’ve reconsidered it, moved away, and use a non-public address
on my own domain when registering for new services. The following is a detail
of what I did and what I used to implement it.</p>

<h4 id="email-portability">Email portability</h4>

<p>Mobile phone numbers are so critical to everyday life that France has a law
allowing you to keep your phone number using a <a href="https://fr.wikipedia.org/wiki/Relev%C3%A9_d%27identit%C3%A9_op%C3%A9rateur">Relevé d’identité
opérateur</a>
(carrier identity number) when changing carrier. This service must be provided
free of charge.</p>

<p>Email addresses are essential, and portability is as key for them as for phone
numbers. But you can’t keep the same address when switching from one provider
to another. Once you start using <em>something@gmail.com</em>, it is painful to move
to a new one as you have to change it on every service you use, confirming each
one, one by one.</p>

<p><a href="https://twitter.com/dhh/status/1323582505065320448">@dhh says</a> <em>Hey!</em> will
forward your email for life once you paid for the first year. That should be
mandatory for all providers, so you don’t have this Gmail life single point of
failure. It’s best to own your own domain name, but this is a lesser evil than
most other email providers.</p>

<p>I believe email providers should be legally obliged to forward your email
address for life to a new email address. A routing system similar to
<a href="https://fr.wikipedia.org/wiki/Relev%C3%A9_d%27identit%C3%A9_op%C3%A9rateur">RIO</a>
preventing the old provider from having to forward them to the new one would be
best, but this is not technically possible with the SMTP Protocol.</p>

<p>Some people went as far as <a href="https://kevq.uk/de-googling-my-life-2-years-on/">De-Googling their
life</a> completely with success.</p>



<p>I created my <a href="https://www.hey.com/">hey</a> account for both making sure
fabienAThey.com would be mine if I ever wanted to use it, and for trying it
after viewing <a href="https://www.youtube.com/watch?v=UCeYTysLyGI&amp;t=175s">this video</a>
about the service. Some of the features really make sense, like editing email
subjects <em>after</em> you received them or grouping multiple threads, but I still
prefer classic email interfaces.</p>

<p>After looking at a few options, I opted for
<a href="https://www.fastmail.com/">Fastmail</a> for their pricing, security disclaimer,
and overall good reputation. I used <a href="https://kolabnow.com/">Kolab</a> for years
but decided to move away. I also quickly tried Zoho but had a bad experience
with their UI trying to set things up.</p>

<p>I also used FM import feature to get all my old emails from Kolab back to FM.</p>

<p>I enabled catch-all emails on FM, meaning any email to my domain is redirected
to me. Anywhere I register, I use a different email address based on the
service’s name (service@my_domain_com). I can easily set specific filters like
anything sent to service@mydomain goes to its folder and skip the inbox, or
find who resell my email.</p>

<p>It used to be a real pain to do that, but the password manager included in
Safari (or 1Password) now remembers which email you used to register to a
service. You don’t have to remember that yourself anymore.</p>

<p>I added a server filter. Anything matching /unsubscribe/ goes to a specific
/unsub/ folder and skip the inbox. All newsletters usually get caught in this.
I enabled server-side spam filtering on FM and installed
<a href="https://c-command.com/spamsieve/">Spamsieve</a> on my laptop for a local bayesian
filter, moving detected spam to a Junk folder.</p>

<p>I use <a href="https://freron.com/">Mailmate</a> to read emails, which is by far the best
email client I ever found on macOS (a long way from Linux and in order Elm,
Pine, Mutt, Gnus). I now remember why I started using Gmail… Because I was
coming from those MUA!</p>

	</div></div>]]>
            </description>
            <link>https://pen.so/2020/12/10/own-your-email/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367035</guid>
            <pubDate>Wed, 09 Dec 2020 23:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to think about clean power generation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25367014">thread link</a>) | @nitiniyer
<br/>
December 9, 2020 | https://climaticthoughts.com/clean-power-generation | <a href="https://web.archive.org/web/*/https://climaticthoughts.com/clean-power-generation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://climaticthoughts.com/content/images/size/w300/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png 300w,
                                https://climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png 600w,
                                https://climaticthoughts.com/content/images/size/w1200/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png 1000w,
                                https://climaticthoughts.com/content/images/size/w2000/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://climaticthoughts.com/content/images/size/w2000/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png" alt="Clean power generation: A 24 x 365 endeavor">
            </figure>
            <section>
                <div>
                    <h3 id="every-hour-of-every-day-of-every-year">Every hour of every day of every year</h3><p>A framework I’ve found helpful for understanding what it means to get to 100% carbon-free electricity generation is a 24 x 365 grid. Each of the 8,760 squares represents an hour of power generation in the year that needs to be emissions free. I first came across this diagram reading <a href="https://storage.googleapis.com/gweb-sustainability.appspot.com/pdf/24x7-carbon-free-energy-data-centers.pdf">Google’s 2019 discussion paper</a> on their corporate efforts to match 100% of their data center’s electricity demand with zero-carbon sources at every hour. In Google’s version of the diagram (shown below), green indicates a 100% clean energy match and grey means a 0% match. The gradation across each day and throughout the year reveals where there’s progress and where difficulties remain. More organizations in the private sector and in government should adopt this method of thinking about power generation for themselves or the region in which they are responsible. This framework makes the problem tractable and makes the end goal clear. Every hour of every day of every year must be 100% clean — each square needs to be solid green.</p><figure><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png 1600w, https://www.climaticthoughts.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png 2400w" sizes="(min-width: 1200px) 1200px"><figcaption>Example of 24 x 365 grid from Google's 2019 discussion paper</figcaption></figure><p>A benefit of the 24 x 365 diagram is the breakdown along the axes of time of day and time of year. Both are critical because the pathway to 100% clean energy runs through massively increasing solar and wind energy generation which are highly time dependent. While this framework makes visualizing the utilization of those two technologies easier, it also puts emphasis on the most important objective: Achieving 0 emissions from power generation at all times. The goal isn't just deploying 500 more megawatts of solar or closing down a specific natural gas plant, it’s about bringing each hour to 100% clean energy generation. Tactics should stay tactics while strategy is created to bring portions of the day or year to 100% zero emissions through any number of methods.</p><p>While useful on its own, the 24 x 365 grid is even better when paired with the ability to zoom in and observe the quantity and mix of power generated each day. These types of charts are common today among grid operators. <a href="https://www.nyiso.com/real-time-dashboard">NY ISO</a> and <a href="https://www.caiso.com/TodaysOutlook/Pages/supply.html">CA ISO</a> both have real-time dashboards of energy mix on their respective websites.</p><p>With the 24 x 365 grid and the per day breakout in hand, we can reason about what improvements would happen if specific actions are taken. Consider the following two examples.</p><p><strong>Example 1: Adding more solar generation</strong></p><p>Building a new solar farm would immediately allow afternoon hours during the summer to achieve a higher level of carbon free generation. Using the two visuals we can quickly see where a solar farm would provide benefits during the year as well as a specific day.</p><figure><div><div><p><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png" width="2000" height="1097" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png 1600w, https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png 2282w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png" width="1772" height="1268" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png 1600w, https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png 1772w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Visualizations made using 2019 NY ISO data</figcaption></figure><p><strong>Example 2: Building a closed loop pumped hydro system</strong></p><p><a href="https://www.energy.gov/eere/water/pumped-storage-hydropower">Closed loop pumped hydro systems</a> can be thought of as very large water batteries. During the day water is pumped from a lower reservoir to a higher one using renewable or other energy sources. Then in the night water is piped down leveraging &nbsp;gravity to spin a turbine thereby generating power. This system enables providing non-intermittent power in the evenings across the year but especially in the winter months when shorter days make solar infeasible during the late afternoon and early evening.</p><figure><div><div><p><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png" width="2000" height="1092" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png 1600w, https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png 2292w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png" width="1742" height="1262" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png 1600w, https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png 1742w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Visualizations made using 2019 NY ISO data</figcaption></figure><p>Even tactics such as <a href="https://www.energy.gov/eere/solar/articles/solar-plus-storage-101">short duration battery storage</a> and <a href="https://nest.com/energy-solutions/#rush-hour">demand response programs</a> can be visualized with this framework. Batteries can extend the window of operation for solar and wind by storing excess electricity production. A 4-hour capacity of battery storage can enable solar and wind to take on peak demand in the evening hours. Residential demand response programs, where customers are paid to use less energy during certain parts of the day, when mapped onto the 24 x 365 grid would also serve to make certain hours cleaner as fewer <a href="https://en.wikipedia.org/wiki/Peaking_power_plant#:~:text=Peaking%20power%20plants%2C%20also%20known,as%20peak%20demand%2C%20for%20electricity.">peaker plants</a> would be needed to meet consumer demand. The per day breakout would similarly show a lower total quantity demanded and a cleaner mix of energy generation. These two visuals provide an easy way to conceptualize the effects of many different solutions all while keeping focus on the singular goal, 0 emissions at every single moment.</p><p>We collectively need to solve for 8,760 hours each year. Making each individual hour 100% clean will take a combination of technologies. What this visual framework provides is a map to gauge how far we’ve come and what remains. There’s a satisfaction that comes when checking off an item on a to-do list, we should consider this the same. 8,760 to-dos, some harder than others, but all equally necessary. I hope these visuals are used more broadly across the climate space both in the private and public sector.</p><p>Below I’ve created an <a href="https://public.tableau.com/profile/nitin.iyer#!/vizhome/shared/48H8ZRNTC">interactive version of the 24 x 365 grid</a> and per day demand graphs using data from the NY ISO in 2019. Hover the cursor over the 24 x 365 grid to see the breakout for an individual day.</p><p>Carbon Free and Fossil Fuel generation in the data:</p><ul><li>Carbon Free consists of: Hydro, Nuclear, Wind, and Other Renewables</li><li>Fossil generation consists of: Dual Fuel, Natural Gas, and Other Fossil Fuels</li></ul><!--kg-card-begin: html-->                <!--kg-card-end: html--><h3 id="low-hanging-hours-first">Low hanging hours first</h3><p>For any organization to have the most impact, the next step after constructing a snapshot of their 24 x 365 grid is to identify the low-hanging hours currently available. Low hanging hours are those hours of the day or year which are the easiest and cheapest to convert from fossil energy to clean energy. Depending on the geographic area that could be afternoons in July when the sun is always out and PV panels are readily available, or evenings in October when the wind blows continuously and turbines are relatively the cheapest. Not all hours of the day will be as easy or cheap to convert but emissions averted at 9 AM are the same as emissions averted at 12 PM. And in mitigating climate change, reducing emissions is of utmost importance.</p><p>On that last point, the advantages of tackling the low-hanging hours first are two-fold. One is that tackling those hours first preserves more of the <a href="https://www.carbonbrief.org/analysis-how-much-carbon-budget-is-left-to-limit-global-warming-to-1-5c#:~:text=The%20models%2C%20labelled%20%E2%80%9CIPCC%20AR5,until%20the%20budget%20is%20exhausted.">“budget” of allowable emissions</a> for the harder to clean hours of the day. The nature of climate mitigation is that emissions averted sooner are much more valuable than emissions averted later. A <a href="https://ourworldindata.org/grapher/co2-mitigation-2c">great illustration</a> of this concept comes from Robbie Andrew who shows how far emissions must fall in each subsequent year depending on when we hit peak emissions in order to stay under 2°C of warming. Assuming priority can only be given to one initiative at a time, the low hanging hours are the place to begin. This isn’t exactly like a to-do list where the common advice is tackle the hardest task of your day first. In that sense it's the complete opposite, clean the easiest parts of the day first and leave the difficult parts of the day for later.</p><p>The second advantage builds off of the first. As the low-hanging hours run out, demand for fossil energy will only exist for those harder to convert hours of the day. As a result, costs for fossil generation will increase as the fixed costs of those plants become spread across reduced hours of operation. Higher costs for fossil generation will make more expensive clean generation technologies such as <a href="https://www.eia.gov/energyexplained/geothermal/geothermal-power-plants.php#:~:text=Geothermal%20power%20plants%20use%20hydrothermal,or%20from%20hot%20water%20wells.&amp;text=The%20hot%20water%20or%20steam%20powers%20a%20turbine%20that%20generates%20electricity.">geothermal</a> more competitive. Without this demand reduction based cost increase or a price on carbon, these farther out zero-carbon baseload technologies may take too long to become cost competitive. This advantage could be hobbled by factors such as contract terms, political lobbying, or subsidies to fossil power generators. All of which may limit how fast fossil generation costs go up. But at some point the market overrides all barriers. Cheap energy is cheap energy.</p><p>Armed with the 24 x 365 framework and a strategy of addressing low hanging hours first, any organization is properly equipped to start the daunting task of getting to 100% clean energy. With climate change every solution is needed, but at the same time we cannot forget the power of prioritization. Tackling low hanging hours first provides some sense of direction in a flood of possible actions.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://climaticthoughts.com/clean-power-generation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367014</guid>
            <pubDate>Wed, 09 Dec 2020 23:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Your Monolith Last]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25366680">thread link</a>) | @atomkirk
<br/>
December 9, 2020 | https://atomkirk.com/2020-12-09-make-monolith-last/ | <a href="https://web.archive.org/web/*/https://atomkirk.com/2020-12-09-make-monolith-last/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>December 09, 2020</p></header><section><p>In Martin Fowler’s essay “Microservice Premium” he makes the argument that as
the complexity of a system increases, the productivity of a monolith architecture
starts out as very productive, but decreases in productivity faster than a service oriented
architecture (SOA), until a SOA is more productive than the monolith.</p>
<p>Here’s a chart he provides to illustrate:</p>
<p><span>
      <a href="https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/98b29/productivity.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Productivity" title="Productivity" src="https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/fcda8/productivity.png" srcset="https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/12f09/productivity.png 148w,
https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/e4a3f/productivity.png 295w,
https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/fcda8/productivity.png 590w,
https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/efc66/productivity.png 885w,
https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/98b29/productivity.png 937w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>But, come on, when you add all the drawbacks of an SOA, the costs are enormous and they get worse.
Data syncing, backfilling, inconsistencies, progogation of bad data. Books upon books on how to
deal with the problems specific to using an SOA. It takes a truly terribly designed monolith
and a fantastically designed SOA for those lines to cross. The chart should really look like this:</p>
<p><span>
      <a href="https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/98b29/reality.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Reality" title="Reality" src="https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/fcda8/reality.png" srcset="https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/12f09/reality.png 148w,
https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/e4a3f/reality.png 295w,
https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/fcda8/reality.png 590w,
https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/efc66/reality.png 885w,
https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/98b29/reality.png 937w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>As a project grows, most languages (Java, C++, Elixir)<sup id="fnref-1"><a href="#fn-1">1</a></sup> take longer and longer to compile. Death
by a thousand slow-ish tests build up. CI pipelines take 20+ minutes. With 50 engineers trying
to get their code into master, it takes days to get merged. The vast majority of that
time spent waiting for CI (compiling, tests, linting). You have two options: make all of that
faster, or harken back to the good old days when your project was smaller by splitting it up.</p>
<p>The problem is, in the good old days, all your data was still in one database. That’s a terrible
idea in a SOA. Now you’re sacrificing all kinds of simplicity and safety to make your project
compile and test faster in smaller pieces. Invalid data being the root of all evil,
giving up foreign key constraints is selling your soul.</p>
<p>Or, you could make things faster:</p>
<p><span>
      <a href="https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/98b29/ideal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Ideal" title="Ideal" src="https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/fcda8/ideal.png" srcset="https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/12f09/ideal.png 148w,
https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/e4a3f/ideal.png 295w,
https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/fcda8/ideal.png 590w,
https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/efc66/ideal.png 885w,
https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/98b29/ideal.png 937w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Seeing as making all of this fast once your project is already huge is very hard to do, I think
there are a few actionable points of advice I would like to leave with people starting new projects:</p>
<ul>
<li>Pick a language and ecosystem that prioritizes fast compiles and a fast feedback loop dev experience. i.e. Go.</li>
<li>Keep your tests fast from day one.</li>
<li>Do not preoptimize for microservices. Don’t over-engineer your code to work like an SOA. If you follow the first two points of advice, you may never have to go there at all. Boundaries are great, so theres a lot of gray area here, but I think its important to keep things <a href="https://atomkirk.com/2020-12-04-simple-as-possible-as-long-as-possible/">as simple as possible as long as possible</a>.</li>
</ul>
</section><hr></article></div>]]>
            </description>
            <link>https://atomkirk.com/2020-12-09-make-monolith-last/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25366680</guid>
            <pubDate>Wed, 09 Dec 2020 23:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales tax creates more unnecessary pain than value added tax]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25366136">thread link</a>) | @dyno-might
<br/>
December 9, 2020 | https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 9, 2020</strong></p>
            
            <p>It turns out that sales tax has a huge, gigantic, terrible flaw: It punishes specialized businesses. A value added tax (VAT) has no such problems.</p>

<p>The US has sales tax. Most of the planet has VAT.</p>

<p><img src="https://dyno-might.github.io/img/vat/VAT_map_updated.png" alt="VAT map"></p>

<p>Maybe it’s not the most important issue in the world, but it’s just so <em>clear</em>. Sales tax is dumb and VAT is better.</p>



<p>Many people apparently believe that in the US today, sales tax is only paid by final consumers. <strong><a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">THIS IS FALSE</a></strong>. It varies hugely by state, but the current situation is a hybrid between a “pure final retail consumer only” sales tax and what the toy model below describes. You can debate if it’s “sales tax” or “gross receipts tax” or whatever, but it’s a fact that <em>businesses pay tax on business inputs</em> all the time. You can find proof of this <a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">here</a> or <a href="https://www.ncsl.org/documents/standcomm/sccomfc/Business-Inputs-Study.pdf">here</a> or <a href="https://www.jstor.org/stable/41788786">here</a> or <a href="https://en.wikipedia.org/wiki/Gross_receipts_tax#United_States">here</a>.</p>

<p>I emphasize that the explanation below is a toy, intended to illustrate in the simplest possible way how specialization gets punished when transfers are taxed in proportion to their values. The current reality not <em>nearly</em> this bad due to many complex exemptions, as I discuss at the end. But the flaw described <em>does</em> exist and <em>does</em> punish specialization. I beg you: <strong><a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">IF YOU THINK THE US DOESN’T HAVE TAXES WHERE THE SAME UNIT OF VALUE IS TAXED MULTIPLE TIMES PLEASE READ THIS LINK.</a></strong></p>

<p>OK, let’s continue.</p>



<p>Say you decide to get into the decorative <a href="https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/(https://dyno-might.github.io/2020/09/11/comparative-advantage-and-when-to-blow-up-your-island/)">coconut</a> manufacturing business.</p>

<p>You’re good at painting coconuts. You find a friend who is good at picking them, and another who’s good at making coconut paint. You find a third friend who’s a genius with applying finishing lacquer and a fourth who runs a store.</p>

<p>You buy coconuts and paint, apply the paint, then sell to the finisher. He applies lacquer and sells to a retailer.</p>

<p><img src="https://dyno-might.github.io/img/vat/supply_chain.jpg" alt="supply chain"></p>

<p>After negotiating prices, you settle on $1 for a raw coconut, $1 for a coconut’s worth of paint, $3 for a painted coconut, $4 for a finished coconut, and $5 retail. This works out to everyone making $1 of profit.</p>

<p><img src="https://dyno-might.github.io/img/vat/market.jpg" alt="market"></p>

<p>Here’s a table showing the accounts:</p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconuts</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2 (raw coconut+paint)</td>
      <td>$1</td>
      <td>$3</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$3 (painted coconut)</td>
      <td>$1</td>
      <td>$4</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$4 (finished coconut)</td>
      <td>$1</td>
      <td>$5</td>
    </tr>
  </tbody>
</table>



<p>For a while, everything runs beautifully. Every day you wake eager to help capture more beauty in coconut form — and then the government announces a 20% sales tax. Whenever you sell something, you need to pay 20% of the sale price to the government.</p>

<p>You talk it over. Everyone feels they still deserve to make the same $1 profit as before. Since you now pay $1.20 for a raw coconut and $1.20 for paint, you need to mark up to $3.40 before tax, and $4.08 after.</p>

<p>After everyone marks up their prices in this way, here are the results:</p>

<p><img src="https://dyno-might.github.io/img/vat/sales_tax.jpg" alt="sales tax"></p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
      <th>Price after tax</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconut</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2.4</td>
      <td>$1</td>
      <td>$3.40</td>
      <td>$4.08</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$4.08</td>
      <td>$1</td>
      <td>$5.08</td>
      <td>$6.10</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$6.10</td>
      <td>$1</td>
      <td>$7.10</td>
      <td>$8.52</td>
    </tr>
  </tbody>
</table>

<p>Your customers aren’t thrilled about the increase in price, but what are they going to do — live <em>without</em> painted coconuts? So they pay the higher price, the government gets its tax, and life continues.</p>



<p>A few months later, your unscrupulous  cousin hears about your business. He’s the jealous type and decides to try stealing your customers. He opens a store and finds four friends to help make coconuts. Unlike you, however, he hires everyone as <em>employees</em>. He sells the coconuts for $6 ($5 plus tax) and gives everyone $1 per coconut in wages.</p>

<p><img src="https://dyno-might.github.io/img/vat/integrated.jpg" alt="integrated"></p>

<p>Your cousin and friends don’t appreciate the subtle art of coconut decoration. Everyone agrees yours are better but they start to complain: Why are you charging $8.52 when a slightly worse product is available for only $6? Slowly, your loyal customers drift away and you go out of business.</p>

<p>How could this happen? Your team was asking for the same profit while doing a better job! Yet everyone is left with your cousin’s knock-off coconuts.</p>



<p>Suppose the government had instead announced a 20% VAT. With a VAT, whenever you sell something, you only pay tax on the sale price <em>minus the price of the stuff you bought to make it</em>.</p>

<p>As before, you’ll need to pay $1.20 for raw coconuts and $1.20 paint. You charge $3.40 for painted coconuts, now you’re only taxed on the profit of $3.40-$2.40=$1.00. The price with tax is now $3.60.</p>

<p>Here are the final prices as they go through through the system. Everyone is making a profit of $1, so everyone pays a tax of $0.20.</p>

<p><img src="https://dyno-might.github.io/img/vat/vat.jpg" alt="vat"></p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
      <th>Price after tax</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconut</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2.4</td>
      <td>$1</td>
      <td>$3.40</td>
      <td>$3.60</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$3.60</td>
      <td>$1</td>
      <td>$4.60</td>
      <td>$4.80</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$4.80</td>
      <td>$1</td>
      <td>$5.80</td>
      <td>$6.00</td>
    </tr>
  </tbody>
</table>

<p>The final price is $6.00. Since your coconuts are better, your cousin won’t be able to drive you out of business with his low-grade stuff.</p>



<p>What happened? Your cousin created a <em>vertically integrated</em> business. A sales tax is collected every time someone buys something. If you just do it yourself, no tax is collected.</p>

<p>Are vertically integrated businesses bad? Not necessarily.</p>

<p>However, take your chain of independent independent artisans making and selling coconut products. Imagine someone invents a paint that customers prefer. You almost <em>have</em> to switch, or some other painter will drive you out of business. Contrast this with cousin’s integrated business making all coconuts. In theory, the inventor could convince your cousin to hire him or license the paint process. If he won’t be convinced, the only way for that paint to get to customers is if the inventor develops an entire independent coconut manufacturing chain. Vertical integration means there are price signals at fewer points during production, which tends to make it harder for innovations to thrive.</p>

<p>There are times where vertical integration is better. (If everyone is independent, a lot of time is spent on negotiations!) That’s perfectly fine. What we <em>don’t</em> want is to artificially encourage vertical integration even when it’s less efficient, which sales tax does.</p>



<p>Another advantage of the VAT is it tends to be easier to enforce. When I sell something, I need to provide certificates proving I paid VAT on my inputs. This gives everyone an incentive to ensure compliance in the previous layer of the chain. With a sales tax, the government needs to watch every single transaction.</p>

<p>Of course, people know sales tax is distortionary. Many exceptions exist to minimize the worst distortions. For example, a retailer usually won’t pay sales tax on a manufactured good they intend to a consumer in the same form. Without this exception, we’d probably have a crazy economy where manufacterers sell directly to consumers. The messy patchwork of exceptions reduces the problems with sales tax but doesn’t eliminate them.</p>

<p>I think there are two major reasons to oppose replacing sales tax with VAT. The first is a Leninist “worse is better” attitude. If you think <em>all taxes are bad</em> then you’d want to keep them painful and visible so people will be maximally annoyed by them. The second is that VAT is complicated to administer, particularly when sales tax can be different in each local area. This might be true, but I find it a bit hard to believe. VAT is more self-enforcing and sales taxes are <em>already</em> a nightmare, particularly for anyone selling to different cities/states. If we’re keeping the sales tax to keep things simple, where’s the payoff?</p>

<p><img src="https://dyno-might.github.io/img/vat/lenin_text_small.png" alt="lenin"></p>

<h3 id="notes">Notes</h3>

<ul>
  <li>The initial map is based on Wikipedia, but found that many places (<a href="https://taxsummaries.pwc.com/thailand/corporate/other-taxes">Thailand</a>, <a href="https://home.kpmg/us/en/home/insights/2020/05/tnf-saudi-arabia-vat-rate-to-increase-to-15-percent-covid-19.html">Saudi Arabia</a>, <a href="https://en.wikipedia.org/wiki/Taxation_in_Iran#Value_added_tax_(VAT)">Iran</a>, <a href="https://www2.deloitte.com/om/en/pages/tax/articles/oman-to-implement-vat-from-2021.html">Oman</a>, <a href="https://u.ae/en/information-and-services/finance-and-investment/taxation/valueaddedtaxvat">UAE</a>, <a href="https://www.reuters.com/article/us-kuwait-economy-tax-idUSKCN1IG0OW">Kuwait</a>, <a href="https://news.bloombergtax.com/daily-tax-report-international/insight-early-days-for-angola-value-added-tax">Angola</a>, <a href="https://www.avalara.com/vatlive/en/vat-news/liberia-to-introduce-vat-2019.html">Liberia</a>) have recently implemented VAT. I checked that most of the others (<a href="https://taxsummaries.pwc.com/jordan/corporate/other-taxes">Jordan</a>, <a href="https://en.wikipedia.org/wiki/Taxation_in_Greenland">Greenland</a>, <a href="https://www.tradecommissioner.gc.ca/france/market-facts-faits-sur-le-marche/7685.aspx?lang=eng#valuetax">French Guinana</a>, <a href="https://www.nordeatrade.com/en/explore-new-market/cuba/taxes">Cuba</a>, <a href="https://taxsummaries.pwc.com/libya/individual/other-taxes">Libya</a>, Hong Hong) still do not have a VAT.</li>
  <li>To be sure, if you could implement a sales tax that only applied to final consumers, that would be economically equivalent to VAT. Is that how state taxes work in the US? It’s hard to make simple generalizations because (1) it’s sometimes hard to say what a “final consumer” is (2) there are different laws in each state and (3) the relevant tax is sometimes called a “gross receipts” tax. The important question is: <strong>Does the US have taxes on intermediate products</strong> that “cascade” like described in the above model? The answer to that question is <a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">YES</a>.</li>
</ul>

        </div>

        

        
        
    </div>
</div></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25366136</guid>
            <pubDate>Wed, 09 Dec 2020 22:24:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir as a Competitive Advantage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25366105">thread link</a>) | @stanislavb
<br/>
December 9, 2020 | https://underjord.io/elixir-as-competitive-advantage.html | <a href="https://web.archive.org/web/*/https://underjord.io/elixir-as-competitive-advantage.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        
<p>Choosing a stack is most often more of a tribal endeavor than a something done on merit. Developers often mistakenly
    think that their favorite language is somehow measurably better than others. They feel that using it will make for
    clean code or better productivity. I think there is fairly little support for any of that. What I think matters are
    <strong>the capabilities of the language</strong> and its runtime, <strong>the culture of its ecosystem</strong> and
    community and <strong>the history of proven performance</strong>. My intent with this post is to underline what I
    see as pure business advantages with working with Elixir. By necessity I will also touch on a wide selection of
    other languages to set the baseline.</p>
<h2 id="java--net---the-corporate-baseline">Java &amp; .Net - The corporate baseline</h2>
<p>In the enterprise there is a strong tendency to Java &amp; C#. Why? Because no one ever got fired for choosing them.
    They are stable workhorse languages with mostly identical featuresets, the same level of abstraction, solid
    performance and all the ecosystem that you'd ever want. They both provide a mid-to-high level of abstraction for the
    common case, are strict at the core but aspire to be more dynamic and place some correctness constraints on your
    developer with types. Applications can be written to be very strict and quite formal. Culturally they are well
    suited to a risk-averse business.</p>
<p>Choosing Java or .Net is not a competitive advantage. You are not innovating with this choice, you also aren't
    chosing something that guarantees reliability or safety. These languages aren't inherently more safe, secure or
    reliable. It is a risk-averse and uninteresting choice and it assumes you can compete elsewhere. It gives you no
    advantage, it poses no large drawbacks. It is the default for this class of business.</p>
<h2 id="ruby--node---the-agile-baseline">Ruby &amp; Node - The agile baseline</h2>
<p>In the startup world the stacks vary a bit more but Ruby was the darling and Node.js is the currently dominant
    life-form. Also worth mentioning are Python and PHP. Which are all roughly equivalent. High level of abstraction,
    highly dynamic, minimal restraint. To a venture-backed, forward-leaning or experimental and fast business, these are
    all desirable traits and a good culture fit.</p>
<p>Choosing these are not a competitive advantage. Maybe some mobility versus the corporate baseline because there is no
    strictness at the language level. These languages are all largely equivalent. You have no real advantage, you have
    no special drawbacks. You are using the default for your type of business.</p>
<h2 id="no-advantage-in-the-default">No advantage in the default</h2>
<p>By choosing the default for either type of business you are making a very small choice between dynamic or a bit
    stricter and between compiled and interpreted. These are technical concerns that mostly do not affect business
    outcomes but are popular for developers to rant about. <strong>Your choice of language among these options is not
        giving you any distinguishable advantage. Because they are basically the same.</strong></p>
<h2 id="specialist-languages">Specialist languages</h2>
<p>It is worth mentioning that some languages own certain domains and dominate them in a way that just means choosing
    them makes sense. Primarily this is Python for data and machine learning. The alternatives here are all
    significantly less common languages. Swift or Obj-C are for iOS. Kotlin for Android. Then you have projects where
    you need C/C++/Rust level speeds which steers you to those languages. Or maybe you are trying to embed a language in
    your system, then I hear Lua is good.</p>
<p>But <em>most development projects today are general-purpose</em>. They are <strong>distributed systems</strong> with
    some amount of Web APIs or Web UIs. They often have some semi-real-time going on via WebSockets. They require
    integration with other parties via APIs. And what do you want?</p>
<ul>
<li>Fast response times</li>
<li>Uptime</li>
<li>Scalability</li>
<li>Maintainable architecture</li>
<li>Decent efficiency from the hardware</li>
</ul>
<p>So what is Elixir's specialty? Distributed systems with high reliability and soft real-time response times. This maps
    incredibly tightly to what most systems need these days.</p>
<h2 id="unopinionated-generic">Unopinionated, generic</h2>
<p>The baseline languages offer no particular opinions about what a good system design should look like. They are
    generic languages, mostly OOP, with every paradigm they can fit thrown in for good measure. There is no direction to
    be found. Your developers can build as well or poorly as their skills and patience allows.</p>
<p>In this I think Elixir distinguishes itself. It builds on the needs of some of the <em>really early distributed
        systems</em>,
    which were telecom switches, that were developed at Ericsson. They built Erlang, which Elixir builds on top of. It
    implements the Actor model. The Actor model + the Functional Programming paradigm are combined not just because they
    sound cool but because <strong>they give certain guarantees</strong> and <em>they constrain the way you build
        code</em> in a way that <strong>makes it
        significantly easier to build distributed systems</strong> without screwing it up too bad.</p>
<p>They developed an approach called supervision trees that is used to provide a core level of resiliency for the
    simplest casest and a toolset to create the serious level of resiliency needed for a piece of telecom
    infrastructure. The idea being that if your system can drop a call, which any system can, it should not cause
    failures for other callers and it should not bring the entire node down with it.</p>
<p>It is a design <strong>built to achieve nines</strong>.</p>
<h2 id="recruitment">Recruitment</h2>
<p>Staying with baseline languages you get the default pool of candidates. It is a vast pool with a very wide level of
    experience, quality and skill. The average is .. quite average. There are many people invested and excited about
    each of these languages and there are people that absolutely do not care and trudge on through. The whole range is
    there.</p>
<p>Most people come to Elixir from other languages because it is still comparatively niche. Very few people start their
    career in Elixir today. So the pool is smaller and the average developer did not learn this in a boot camp a few
    months ago. So the average Elixir developer has previous experience and it seems like the general reasons people are
    attracted to the language is that it allows building things in a more reliable fashion. These are concerns that I
    firmly believe are more common with experienced developers because they generally mean you have been burned before.
    For some numbers that indicate this experience difference you can see that <a href="https://insights.stackoverflow.com/survey/2019#top-paying-technologies">Elixir is the 5th highest paid</a>
    language worldwide. This is a decent marker for experience.</p>
<p>When you bring on an Elixir developer, the chance that you are bringing on valuable experience is high, even if you
    interview poorly the statistics are in your favor. I see developers that actively strive to transition into Elixir
    on a daily basis. This increases the chance of getting highly motivated developers, self-driven who are invested in
    their Elixir skills. It hits <a href="https://insights.stackoverflow.com/survey/2019#most-loved-dreaded-and-wanted">8th most Loved
        languages</a>.</p>
<h2 id="unique-selling-points">Unique Selling Points</h2>
<p>Elixir can do all the normal things you expect from high abstraction level dynamic language. Culturally it has become
    the spiritual successor to Ruby. Startups are flocking to it. So it can do all the uninteresting work-horse stuff
    that you need in the line of business. The competitive advantage is in what it brings beyond the baseline.</p>
<p>Elixir runs on the BEAM virtual machine. It <strong>provides uncommon guarantees and capabilities</strong> since it
    is built to
    provide soft real-time, which means a <em>very low latency</em>, <em>strong concurrency</em> and distribution
    without all the traps
    and errors common in concurrent code. It even provides the possibility to <strong>update the system without stopping
        it</strong> if your use-case is so critical that application restarts are unacceptable. You might not need these
    starting out. But retrofitting
    any of these capabilities is in the range of very costly to impossible.</p>
<p>You get the power to do clustered applications basically for free. You get strong multi-core performance without any
    further concern. Legend tells of the numerous Ruby instances that were scaled down into a few lonely nodes as the
    code transitioned to Elixir. You might even save money on your cloud bills.</p>
<p>Elixir and the Phoenix web framework come with strong developer ergonomics, providing a less mysterious approach that
    is reminiscent of the productivity monster that is Ruby on Rails (or Django, or Laravel).</p>
<p>Phoenix LiveView is probably the most interesting project at this moment where UI work can be done without touching
    Javascript which allows an incredibly tight, simplified and pragmatic approach to UI/UX development for many, many
    use-cases. For many applications this can quite simply remove a few programmers from payroll. For others it can
    simplify things significantly.</p>
<p>Web systems aside there is an entirely unique IoT and connected smart devices story with the Nerves project which
    solves not just tooling for building IoT devices. It also implements an incredible solution for maintaining your
    fleet of devices with updates and maintenance via NervesHub.</p>
<p>And when you need native performance there are a number of ways in which you can achieve this. Just like in all other
    languages there are escape hatches to getting closer to the metal and pressing the computer for all its worth.</p>
<h2 id="proven-performance--historical-record">Proven performance &amp; historical record</h2>
<p>Do you dare using something new and .. unproven?</p>
<p>You probably should. But you don't have to. <strong>Elixir is not unproven.</strong></p>
<p>Elixir is a recent language, certainly but it has been around for years and is stable. More importantly, Elixir is
    built on top of Erlang and the BEAM virtual machine. These were <strong>established in 1986</strong>. They were
    <em>open sourced in 1998</em>. Since then they've been used with great but quiet success in many places. <strong>The
        reputation of Erlang is that it is battle-hardened and proven to be reliable.</strong> It has always had …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/elixir-as-competitive-advantage.html">https://underjord.io/elixir-as-competitive-advantage.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/elixir-as-competitive-advantage.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25366105</guid>
            <pubDate>Wed, 09 Dec 2020 22:22:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is SRE (Site Reliability Engineering?)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25365965">thread link</a>) | @anishdhar
<br/>
December 9, 2020 | https://www.getcortexapp.com/post/what-is-sre-site-reliability-engineering | <a href="https://web.archive.org/web/*/https://www.getcortexapp.com/post/what-is-sre-site-reliability-engineering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Historically, development teams and operations teams have been at odds.<br></p><p>Development teams wanted to add slick new features to products. Operations teams wanted to make sure these features didn’t cause dysfunction.<br></p><p>This began to change in 2003 when software engineer Benjamin Treynor invented site reliability engineering (SRE) while working at Google. He made his software engineering team responsible for some ops tasks, creating the concept of SRE and helping to resolve issues between development and operations.</p><h2>How does SRE work?</h2><p>SRE is performed by site reliability engineers, also known as service reliability engineers. These professionals are typically software developers who have gained some operations experience. They can also be IT professionals who have development skills.<br></p><p>SRE teams set service-level agreements (SLAs) for each service in a system. The SLAs define the system’s required reliability, helping teams figure out which features they can implement.&nbsp;<br></p><p>Within each SLA are service-level indicators (SLIs) and service-level objectives (SLOs).<br></p><p>SLIs are metrics that measure a specific aspect of a service level. Examples of SLIs you might want to monitor could be availability, error rate, or system throughput.<br></p><p>An SLO is simply the target you want to hit for an SLI. For example, you might shoot for a 99.9% availability over the course of a year.<br></p><p>The difference is the downtime level. The downtime level is known as the “error-budget,” which is the maximum amount of error allowed in the system.&nbsp;<br></p><p>By acknowledging the error is inevitable, you can then plan for the errors, making it easier for the development team to release new features. See, the development team can release whatever features they want—whenever they want—as long as they stay within the error budget. As soon as they step outside of it, they must reign in errors before moving forward with new features.<br></p><p>A vital part of an SRE’s work is automation. SREs often have to automate away repetitive manual tasks, called “toil,” so they can focus on long-term, value-adding work. <a href="https://www.getcortexapp.com/post/understanding-kubernetes">Kubernetes</a> can be helpful with this.</p><h2>DevOps vs. SRE</h2><p><a href="https://aws.amazon.com/devops/what-is-devops/">DevOps</a> is a philosophy and set of practices that combines software development and IT operations. It consists of <a href="https://www.overops.com/blog/devops-vs-sre-whats-the-difference-between-them-and-which-one-are-you/">five pillars</a>. Google defines these pillars as:<br></p><ul role="list"><li>Reducing organizational silos</li><li>Accepting failure as normal</li><li>Implementing gradual changes</li><li>Leveraging tooling and automation</li><li>Measuring everything<br></li></ul><p>If DevOps is the “what,” SRE is the “how.” It’s simply an implementation of the DevOps philosophy. In fact, SRE meets all five pillars of DevOps:<br></p><ul role="list"><li><strong>Reducing organizational silos:</strong> SREs share ownership with the developers, and they use the same tools and techniques.</li><li><strong>Accepting failure as normal:</strong> SREs quantify failure using SLIs and SLOs. They assume that errors will happen, but set a maximum allowable amount to balance failure against new releases.</li><li><strong>Implementing gradual changes:</strong> SREs encourage smaller, more iterative deployments of new features in order to reduce the cost of failure.</li><li><strong>Leveraging tooling and automation:</strong> SREs automate away manual tasks, as mentioned above.</li><li><strong>Measuring everything:</strong> SREs use metrics (SLIs) to quantify service levels. Consequently, they can keep errors down.</li></ul><h2>Benefits of SRE</h2><p>Let’s take a look at a few of the ways SRE can offer some major advantages to your organization.&nbsp;</p><h3>Provides clear metrics</h3><p>Clear metrics allow SRE teams to highlight areas of improvement, such as reducing security vulnerabilities.<br></p><p>SRE teams can also use metrics to calculate impact in other areas, such as revenue. For example, they could look at how much revenue they lose per minute of downtime.</p><h3>Improves code</h3><p>The development and SRE teams share the same talent pool. If the development team writes poor code, more talent is allocated to the SREs to fix these issues—leaving fewer people available for the development team.<br></p><p>As a result, the development team is incentivized to write better code. When their code works well, they could gain more teammates, bringing them the resources they need to create better features.</p><h3>Frees up time and resources to add value</h3><p>Better code, fewer bugs, and more efficiency creates more time to add value to the product.&nbsp;<br></p><p>The developers can create better and more exciting features that are less likely to cause problems. On the other side, operations can spend more time testing and performing upkeep.<br></p><p>Put these together, and you have a better product for the customer.</p><h2>The bottom line</h2><p>SRE is quickly taking hold as an essential part of many organizations. It can help close the gap between operations and development. Consequently, you can deliver better applications faster—without sacrificing the reliability of those applications.&nbsp;</p><p><br>Cortex can help your SRE team track service quality better so they can find more areas where service can be improved.<a href="https://www.getcortexapp.com/"> Schedule your demo today</a> to learn more about what we can do.</p></div></div>]]>
            </description>
            <link>https://www.getcortexapp.com/post/what-is-sre-site-reliability-engineering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25365965</guid>
            <pubDate>Wed, 09 Dec 2020 22:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to give feedback to a developer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25365651">thread link</a>) | @thellimist
<br/>
December 9, 2020 | https://www.usehaystack.io/blog/5-steps-for-giving-developer-feedback | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/5-steps-for-giving-developer-feedback">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>Feedback can be so easy to get wrong...</p><p>It sounds like an easy part of the job but it can be a task filled with dread, anxiety, or worry. <strong>Engineering leaders tend to be overly sympathetic and cautious</strong> when it comes to giving feedback.</p><p>Of course, no body wants to hurt anyone's feelings or upset the team but leaving problems unaddressed can boil up to much larger issues.</p><p>Unfortunately, <strong>it's not uncommon in engineering for feedback to go undelivered</strong>, causing problems to fester and performance to degrade - leaving managers wishing they spoke up sooner.</p><p>In this article <strong>we'll be sharing</strong> <strong>ways you can deliver feedback to your team effectively without being overbearing</strong>, seeming like a micromanager, or taking feedback too far and de-motivating your team.</p><p>‍</p><h2>How NOT to give feedback to engineers</h2><figure id="w-node-cef329f9e82f-35f34600"><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5fd12d7b5075de2a084ec607_poor-feedback-example.png" loading="lazy" alt=""></p></figure><p>Woof. Tough day at the office.</p><p>‍</p><p>Let's break down <strong>what went wrong:</strong></p><ol role="list"><li>Bill <strong>didn't have time to prepare</strong> for receiving feedback</li><li>"Andre isn't going to be happy" <strong>sounds threatening</strong></li><li>The feedback is vague and <strong>doesn't include specific examples</strong></li></ol><p>‍</p><p>Lastly, the last sentence <strong>doesn't leave room to discuss</strong> or problem solve - leaving Bill feeling pretty defensive.</p><p>‍</p><p>He probably doesn't feel great after that interaction.</p><p>‍</p><h2>How to give feedback to engineers</h2><p>Inspired by <a href="http://www.martykaplanphd.com/blog/preparing-for-giving-and-receiving-feedback-a-guide-to-doing-it?utm_swu=9766" target="_blank">this classic post</a>, we use this framework at Haystack:</p><h3><strong>1)&nbsp;Seek permission</strong></h3><div><p><strong>‍</strong>Before giving feedback, make sure the person is ready to receive it. Most of the time, this won't be an issue. But if they are having a bad day, they can delay. This helps both of you: they can take the time to prepare, and you can give feedback when they will be the most receptive.</p><p><strong>"Hey Bill, is now a good time to share some feedback with you?"</strong><br>‍</p></div><h3><strong>2)&nbsp;Describe observable behavior with data</strong></h3><div><p><strong>‍</strong>While it's fine to identify observable behavior batters, make sure to give concrete examples. Telling someone they "often" or "always" do something is vague, sounds an accusation, and puts them on the defensive. If you give examples, it's easier to discuss solutions.</p><p><strong>"I've noticed that the shared component refactor may miss our original estimation - but during standups this week everything sounded on track."</strong><br>‍</p></div><h3><strong>3)&nbsp;Describe the impact</strong></h3><div><p><strong>‍</strong>Be very specific when you describe the impact. This is important. Did it affect anyone on the team? Did it cause a larger issue or sour a client relationship? If you predict issues down the line, then you can note that impact.</p><p><strong>"This didn't give Product much time to coordinate with marketing. I'm concerned that if this happens again, we could hold back company wide growth goals due to this miscommunication"</strong><br>‍</p></div><h3><strong>4)&nbsp;Own your feelings </strong></h3><p><strong>‍</strong>Share how this made you feel. This shows that you're invested too. Make sure to make this its own step so it doesn't get confused with the previous steps.</p><p><br><strong>"I felt frustrated because I couldn't understand why these changes came at the last minute. It made me wonder if my expectations weren't clear, or whether I had misunderstood our progress."</strong></p><p>‍</p><h3><strong>5)&nbsp;Come with questions, not conclusions</strong></h3><p><strong>‍</strong>Be careful not to make too many assumptions. Present questions and be genuinely curious about the situation. Often you may find yoursef as a contributing factor to the behavior. Ask questions and understand the root cause.</p><p>‍</p><p><strong>"I'm curious: what do you think caused the last minute changes? I wonder if there's something that I'm doing which is contributing to this. How can we prevent this in the future?"</strong></p><p>‍</p><p>At <a href="https://usehaystack.io/">Haystack</a> <strong>this framework helps us get better, faster</strong>. We're constantly looking for ways to improve. You shouldn't have to worry about giving or receiving feedback on your team. It should be a safe place to air issues, brainstorm solutions, and get everyone working better together.</p><p>‍</p><p>Did we miss something? Email us at <a href="mailto:hello@usehaystack.io">hello@usehaystack.io</a>!</p><p>‍</p></div><div data-w-id="edf9fcce-8bb0-5aee-9560-d439cd0fdf41"><div><div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb363122d5a8_newsletter-image-saasy-template.svg" alt=""></p><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/5-steps-for-giving-developer-feedback</link>
            <guid isPermaLink="false">hacker-news-small-sites-25365651</guid>
            <pubDate>Wed, 09 Dec 2020 21:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't call it tech debt]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25365570">thread link</a>) | @acconrad
<br/>
December 9, 2020 | https://adamconrad.dev/blog/dont-call-it-tech-debt/ | <a href="https://web.archive.org/web/*/https://adamconrad.dev/blog/dont-call-it-tech-debt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>

            <p>I think we, as a profession, shot ourselves in the foot when we coined the term <em>tech debt</em>. This <a href="https://daverupert.com/2020/11/technical-debt-as-a-lack-of-understanding/">recent post</a> (though my browser’s search bar found no less than 3 recent articles I read on the subject in Hacker News) got me thinking that the term tech debt is an exercise in bad marketing.</p>

<p>Debt is evil. It’s the stuff that can <a href="https://money.com/student-loan-forgiveness-death-discharge/">live on</a> longer than you do. There’s never been an instance where calling something “debt” elicited a positive response. So why do we tell our Product Managers we have to <em>tackle</em> tech debt?</p>

<p>Is it to create urgency? I hope not. Everyone believes their priorities are the most important priorities. So an engineer’s tech debt will never seem more important than a PM’s product backlog.</p>

<p>Is it to create gravity around the seriousness of the work involved? Then why is it that PMs always bucket “20% time” for making room for tech debt that is never fully paid off?</p>

<p>I loved this analogy I saw on Hacker News about this concept:</p>

<blockquote>
  <p>If you run a commercial kitchen and you only ever cook food, because selling cooked food is your business – if you never clean the dishes, never scrape the grill, never organize the freezer – the health inspector will shut your shit down pretty quickly.</p>

  <p>Software, on the other hand, doesn’t have health inspectors. It has kitchen staff who become more alarmed over time at the state of the kitchen they’re working in every day, and if nothing is done about it, there will come a point where the kitchen starts failing to produce edible meals.</p>

  <p>Generally, you can either convince decision makers that cleaning the kitchen is more profitable in the long run or you can dust off your resume and get out before it burns down.</p>
</blockquote>

<p>On the flip side, if you ever have the luxury of getting ahead of your technical debt then you can contribute things called <a href="https://www.stillbreathing.co.uk/2016/10/13/technical-credit">technical credits</a>. As you can imagine, technical credits are the opposite of tech debt: things that <em>pay dividends</em> to your code rather than incur a cost and drag it down. <a href="https://gomakethings.com/progressive-enhancement-graceful-degradation-and-asynchronously-loading-css/">Progressive enhancement</a> is touted as an example of technical credit.</p>

<p>Marrying these two concepts, I actually think a way around the horrible marketing of tech debt can be resolved with Agile terminology that is already familiar to our product-positive counterparts: <strong>engineering-driving work.</strong></p>

<h2 id="engineering-driven-work-over-tech-debt">Engineering-driven work over tech debt</h2>

<p>At the end of the day, whether they be debt or credit, the work engineers want to accomplish to make their code better is something personal to them and them alone. Similarly, your product team has their own vision of what your code can become for your customers. So if we segment on the <em>owner</em> instead of the <em>outcome</em> we remove the negative connotations of the work involved.</p>

<p>On my teams, we make this distinction painfully simple in Jira:</p>

<ol>
  <li><strong>Was the work engineering-driven?</strong> Create a task.</li>
  <li><strong>Was the work product-driven?</strong> Create a story; use sub-tasks to create the work the engineers will do to complete that story.</li>
</ol>

<p>Everything lives on the same playing field and is up for grabs to assign priority. So rather than bucket 20% time for debt, if all engineering-driven tasks (whether they be credits, debts, or something else) are the most important work to be done this week, they take up 100% of the sprint. Similarly, if product’s work is the most important, it can dominate or completely own a sprint.</p>

<p>The important thing is that <strong>the owner of the ticket sells why their work should be as important as it is</strong>. If you can’t sell why a critical security upgrade is vital to the health of your application then you need to learn how to sell and influence others. But then again, you might think that switching from Formik to React Hook Forms would be awesome but if it’s based on personal bias and no tangible value creation for developer productivity you’re dead on arrival.</p>

<p>So I encourage all of my engineers to read sales books. Learn how to sell and influence others. Convincing someone that what you want to do matters is a much better message than starting things off on the wrong foot by calling your work debt that needs to be repaid. Debt makes people wince. Creating value makes people smile. Paying down tech debt adds value so lead with that and focus on why your work is important instead of giving it the Scarlet Letter from the onset.</p>


            <hr>

            

            <!-- Begin Substack Signup Form -->
            <div id="mc_embed_signup">
                <h4>Get the FREE UI crash course</h4>
                <p>
                    Sign up for our newsletter and receive a free UI crash course to help you build beautiful applications without needing a design background. Just enter your email below and you'll get a download link instantly.
                </p>
                
            </div>
            <!--End Substack Signup Form-->

        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://adamconrad.dev/blog/dont-call-it-tech-debt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25365570</guid>
            <pubDate>Wed, 09 Dec 2020 21:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Course of Pure Mathematics (1921)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25365318">thread link</a>) | @dvfjsdhgfv
<br/>
December 9, 2020 | https://avidemia.com/pure-mathematics/ | <a href="https://web.archive.org/web/*/https://avidemia.com/pure-mathematics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap">

			
			
<!-- #site-header -->


			
			<main id="main" role="main">

				

<!-- .page-header -->


	
	<div id="content-wrap">

		
		<div id="primary">

			
			<div id="content">

				
				
<article>

	
<div itemprop="text">
		<div class="page" title="Page 5">
<div>
<div>
<p><a href="https://avidemia.com/pure-mathematics/attachment/puremathematics-2/" rel="attachment wp-att-7057"><img loading="lazy" src="https://avidemia.com/wp-content/uploads/PureMathematics-1.png" alt="" width="1200" height="675" srcset="https://avidemia.com/wp-content/uploads/PureMathematics-1.png 1200w, https://avidemia.com/wp-content/uploads/PureMathematics-1-1024x576.png 1024w, https://avidemia.com/wp-content/uploads/PureMathematics-1-100x56.png 100w" sizes="(max-width: 1200px) 100vw, 1200px"></a></p>

<p>by</p>
<h2>G. H. Hardy, M.A., F.R.S.</h2>
<p>FELLOW OF NEW COLLEGE <br>
SAVILIAN PROFESSOR OF GEOMETRY IN THE UNIVERSITY OF OXFORD<br>
LATE FELLOW OF TRINITY COLLEGE, CAMBRIDGE</p>
</div>

<p>Third Edition</p>
</div>
</div>
<p><span>Cambridge at the University Press</span></p>
<p><span>1921</span></p>


<h3 id="id5fd4808305bcf" tabindex="0" title="Read the preface ">Read the preface </h3><div id="target-id5fd4808305bcf">
<p><span><strong>Preface to the third edition</strong></span></p>
<div class="page" title="Page 7">
<div>
<div>
<p>No extensive changes have been made in this edition. The most important are in §§ 80–82, which I have rewritten in accordance with suggestions made by Mr S. Pollard.</p>
<p>The earlier editions contained no satisfactory account of the genesis of the circular functions. I have made some attempt to meet this objection in § 158 and Appendix III. Appendix IV is also an addition.</p>
<p>It is curious to note how the character of the criticisms I have had to meet has changed. I was too meticulous and pedantic for my pupils of fifteen years ago: I am altogether too popular for the Trinity scholar of to-day. I need hardly say that I find such criticisms very gratifying, as the best evidence that the book has to some extent fulfilled the purpose with which it was written.</p>
<p>G. H. H.</p>
<p><em>August</em> 1921</p>
</div>
<div class="page" title="Page 7">
<div>
<div>
<p><span><strong>Extract from the preface to the second edition</strong></span></p>
<p>The principal changes made in this edition are as follows. I have inserted in Chapter I a sketch of Dedekind’s theory of real numbers, and a proof of Weierstrass’s theorem concerning points of condensation; in Chapter IV an account of ‘limits of indetermination’ and the ‘general principle of convergence’; in Chapter V a proof of the ‘Heine-Borel Theorem’, Heine’s theorem concerning uniform continuity, and the fundamental theorem concerning implicit functions; in Chapter VI some additional matter concerning the integration of algebraical functions; and in Chapter VII a section on differentials. I have also rewritten in a more general form the sections which deal with the definition of the definite integral. In order to find space for these insertions I have deleted a good deal of the analytical geometry and formal trigonometry contained in Chapters II and III of the first edition. These changes have naturally involved a large number of minor alterations.</p>
<div class="page" title="Page 8">
<div>
<div>
<p>G. H. H.</p>
<p><em>October</em> 1914</p>
<p><span><strong>Extract from the preface to the first edition</strong></span></p>
<p>This book has been designed primarily for the use of first year students at the Universities whose abilities reach or approach something like what is usually described as ‘scholarship standard’. I hope that it may be useful to other classes of readers, but it is this class whose wants I have considered first. It is in any case a book for mathematicians: I have nowhere made any attempt to meet the needs of students of engineering or indeed any class of students whose interests are not primarily mathematical.</p>
<p>I regard the book as being really elementary. There are plenty of hard examples (mainly at the ends of the chapters): to these I have added, wherever space permitted, an outline of the solution. But I have done my best to avoid the inclusion of anything that involves really difficult ideas. For instance, I make no use of the `principle of convergence’: uniform convergence, double series, infinite products, are never alluded to: and I prove no general theorems whatever concerning the inversion of limit-operations—I never even define $\dfrac{\partial^{2} f}{\partial x\, \partial y}$ and $\dfrac{\partial^{2} f}{\partial y\, \partial x}$. In the last two chapters I have occasion once or twice to integrate a power-series, but I have confined myself to the very simplest cases and given a special discussion in each instance. Anyone who has read this book will be in a position to read with profit Dr Bromwich’s <em>Infinite Series</em>, where a full and adequate discussion of all these<br>
points will be found.</p>
<p><em>September </em>1908</p>
</div>
</div>


</div>
</div>
</div>
</div>
</div>
</div>
</div>
<h2>CONTENTS</h2>
<p><strong id="ch1">CHAPTER I</strong></p>
<p><strong>REAL VARIABLES</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/rational-numbers/">1-2. Rational numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/irrational-numbers/">3-7. Irrational numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/real-numbers/"> 8. Real numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/relations-of-magnitude-between-real-numbers/">9. Relations of magnitude between real numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/algebraical-operations-with-real-numbers/">10-11. Algebraical operations with real numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-number-sqrt2/">12. The number $\sqrt{2}$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/quadratic-surds/">13-14. Quadratic surds</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-continuum/">15. The continuum</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-continuous-real-variable/">16. The continuous real variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/sections-of-the-real-numbers/">17. Sections of the real numbers. Dedekind’s Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/points-of-accumulation/">18. Points of condensation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/weierstrass-theorem/">19. Weierstrass’s Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-i/"><span>Miscellaneous Examples</span></a></span></p>
<p><strong id="ch2">CHAPTER II</strong></p>
<p><strong>FUNCTIONS OF REAL VARIABLES</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-idea-of-a-function/">20. The idea of a function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-graphical-representation-of-functions/">21. The graphical representation of functions. Coordinates</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/polar-coordinates/"> 22. Polar coordinates</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/polynomials/">23. Polynomials</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/rational-functions/">24-25. Rational functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/algebraical-functions/">26-27. Algebraical functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/transcendental-functions/">28-29. Transcendental functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/graphical-solution-of-equations/">30. Graphical solution of equations</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/functions-of-two-variables-and-their-graphical-representation/">31. Functions of two variables and their graphical representation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/curves-in-a-plane/">32. Curves in a plane</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/loci-in-space/">33. Loci in space</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-ii/"><span>Miscellaneous Examples</span></a></span></p>
<p><strong id="ch3">Chapter III</strong></p>
<p><strong>FUNCTIONS OF REAL VARIABLES</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/displacements/">34-38. Displacements</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/complex-numbers/">39-42. Complex numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-quadratic-equation-with-real-coefficients/">43. The quadratic equation with real coefficients</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/argands-diagram/">44. Argand’s diagram</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/de-moivres-theorem/">45. De Moivre’s Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/rational-functions-of-a-complex-variable/">46. Rational functions of a complex variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/roots-of-complex-numbers/">47-49. Roots of complex numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-iii/"><span>Miscellaneous Examples</span></a></span></p>
<p><strong id="ch4">Chapter IV</strong></p>
<p><strong>LIMITS OF FUNCTIONS OF A POSITIVE INTEGRAL VARIABLE</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/functions-of-a-positive-integral-variable/">50. Functions of a positive integral variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/interpolation/">51. Interpolation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/finite-and-infinite-classes/">52. Finite and infinite classes</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/properties-possessed-by-a-function-of-n-for-large-values-of-n/">53-57. Properties possessed by a function of n for large values of n</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/definition-of-a-limit-and-other-definitions/">58-61. Definition of a limit and other definitions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/oscillating-functions/">62. Oscillating functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/general-theorems-concerning-limits/">63-68. General theorems concerning limits</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/steadily-increasing-or-decreasing-functions/">69-70. Steadily increasing or decreasing functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/alternative-proof-of-weierstrasss-theorem/">71. Alternative proof of Weierstrass’s Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-limit-of-x-power-n/">72. The limit of $x^n$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-limit-of-1-plus-1-n-power-n/">73. The limit of $(1 + \frac{1}{n})^n$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/some-algebraical-lemmas/">74. Some algebraical lemmas</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-limit-of-n-sqrt-nx-1/">75. The limit of $(n(\sqrt[n]{x}-1)$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/infinite-series/">76-77. Infinite series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-infinite-geometrical-series/">78. The infinite geometrical series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-representation-of-functions-of-a-continuous-real-variable-by-means-of-limits/">79. The representation of functions of a continuous real variable by means of limits</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-bounds-of-a-bounded-aggregate/">80. The bounds of a bounded aggregate</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-bounds-of-a-bounded-function/">81. The bounds of a bounded function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-limits-of-indetermination-of-a-bounded-function/">82. The limits of indetermination of a bounded function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-general-principle-of-convergence/">83-84. The general principle of convergence</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/limits-of-complex-functions-and-series-of-complex-terms/">85-86. Limits of complex functions and series of complex terms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/applications-to-z-power-n-and-the-geometrical-series/">87-88. Applications to $z^n$ and the geometrical series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-iv/"><span>Miscellaneous Examples</span></a></span></p>
<p><strong id="ch5">Chapter V</strong></p>
<p><strong>LIMITS OF FUNCTIONS OF A CONTINUOUS VARIABLE. CONTINUOUS AND DISCONTINUOUS FUNCTIONS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/limits-as-x-to-inf-or-x-to-%e2%88%92inf/">89-92. Limits as $x \to \infty$ or $x \to −\infty$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/limits-as-x-to-a/">93-97. Limits as $x \to a$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/continuous-functions-of-a-real-variable/">98-99. Continuous functions of a real variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/properties-of-continuous-functions-bounded-functions-the-oscillation-of-a-function-in-an-interval/">100-104. Properties of continuous functions. Bounded functions. The oscillation of a function in an interval</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/sets-of-intervals-on-a-line-the-heine-borel-theorem/">105-106. Sets of intervals on a line. The Heine-Borel Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/continuous-functions-of-several-variables/">107. Continuous functions of several variables </a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/implicit-and-inverse-functions/">108-109. Implicit and inverse functions</a></span></p>
<p><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-v/"><span>Miscellaneous Examples</span></a></p>
<p><strong id="ch6">Chapter VI</strong></p>
<p><strong>DERIVATIVES AND INTEGRALS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/derivatives/">110–112. Derivatives</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/general-rules-for-differentiation/">113. General rules for differentiation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/derivatives-of-complex-functions/">114. Derivatives of complex functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-notation-of-the-differential-calculus/">115. The notation of the differential calculus</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-polynomials/">116. Differentiation of polynomials</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-rational-functions/">117. Differentiation of rational functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-algebraical-functions/">118. Differentiation of algebraical functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-transcendental-functions/">119. Differentiation of transcendental functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/repeated-differentiation/">120. Repeated differentiation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/general-theorems-concerning-derivatives-rolles-theorem/">121. General theorems concerning derivatives. Rolle’s Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/maxima-and-minima/">122–124. Maxima and minima</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-mean-value-theorem/">125–126. The Mean Value Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-the-logarithmic-function/">127–128. Integration. The logarithmic function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-of-polynomials/">129. Integration of polynomials</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-of-rational-functions/">130–131. Integration of rational functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-of-algebraical-functions-integration-by-rationalisation-integration-by-parts/">132–139. Integration of algebraical functions. Integration by rationalisation. Integration by parts</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-of-transcendental-functions/">140–144. Integration of transcendental functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/areas-of-plane-curves/">145. Areas of plane curves</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/lengths-of-plane-curves/">146. Lengths of plane curves</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-vi/">Miscellaneous Examples</a></span></p>
<p><strong id="ch7">Chapter VII</strong></p>
<p><strong>ADDITIONAL THEOREMS IN THE DIFFERENTIAL AND INTEGRAL </strong><strong>CALCULUS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/taylors-theorem/">147. Taylor’s Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/taylors-series/">148. Taylor’s Series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/applications-of-taylors-theorem-to-maxima-and-minima/">149. Applications of Taylor’s Theorem to maxima and minima</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/applications-of-taylors-theorem-to-the-calculation-of-limits/">150. Applications of Taylor’s Theorem to the calculation of limits</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-contact-of-plane-curves/">151. The contact of plane curves</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-functions-of-several-variables/">152–154. Differentiation of functions of several variables</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentials/">155. Differentials</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/definite-integrals-areas-of-curves/">156–161. Definite Integrals. Areas of curves</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/alternative-proof-of-taylors-theorem/">162. Alternative proof of Taylor’s Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/application-to-the-binomial-series/">163. Application to the binomial series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integrals-of-complex-functions/">164. Integrals of complex functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-vii/">Miscellaneous Examples</a></span></p>
<p><strong>Chapter VIII</strong></p>
<p><strong>THE CONVERGENCE OF INFINITE SERIES AND INFINITE INTEGRALS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/series-of-positive-terms-cauchys-and-dalemberts-tests-of-convergence/">165–168. Series of positive terms. Cauchy’s and d’Alembert’s tests of convergence</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/dirichlets-theorem/">169. Dirichlet’s Theorem</a></span></p>
<p><span><a href="https://avidemia.com/multiplication-of-series-of-positive-terms/">170. Multiplication of series of positive terms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/further-tests-of-convergence-abels-theorem-maclaurins-integral-test/">171–174. Further tests of convergence. Abel’s Theorem. Maclaurin’s integral test</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-series-sum-n-s/">175. The series $\sum n^{-s}$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/cauchys-condensation-test/">176. Cauchy’s condensation test</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/infinite-integrals/">177–182. Infinite integrals</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/series-of-positive-and-negative-terms/">183. Series of positive and negative terms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/absolutely-convergent-series/">184–185. Absolutely convergent series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/conditionally-convergent-series/">186–187. Conditionally convergent series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/alternating-series/">188. Alternating series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/abels-and-dirichlets-tests-of-convergence/">189. Abel’s and Dirichlet’s tests of convergence</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/series-of-complex-terms/">190. Series of complex terms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/power-series/">191–194. Power series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/multiplication-of-series/">195. Multiplication of series in general</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-viii/">Miscellaneous Examples</a></span></p>
<p><strong>Chapter IX</strong></p>
<p><strong>THE LOGARITHMIC AND EXPONENTIAL FUNCTIONS OF A REAL VARIABLE</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-logarithmic-function/">196–197. The logarithmic function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-functional-equation-satisfied-by-log-x/">198. The functional equation satisfied by $\log x$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-behaviour-of-log-x-as-x-tends-to-infinity-or-to-zero/">199–201. The behaviour of $\log x$ as $x$ tends to infinity or to zero</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/scales-of-infinity/">202. The logarithmic scale of infinity</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-number-e/">203. The number $e$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-exponential-function/">204–206. The exponential function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-general-power-ax/">207. The general power $a^x$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-representation-of-ex-as-a-limit/">208. The exponential limit</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-representation-of-log-x-as-a-limit/">209. The logarithmic limit</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/common-logarithms/">210. Common logarithms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/logarithmic-tests-of-convergence/">211. Logarithmic tests of convergence</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-exponential-series/">212. The exponential series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-logarithmic-series/">213. The logarithmic series</a></span></p>
<p><span><a href="https://avidemia.com/the-series-for-the-inverse-tangent/">214. The series for $\arctan x$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-binomial-series/">215. The binomial series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/alternative-development-of-the-theory/">216. Alternative development of the theory</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-ix/">Miscellaneous Examples</a></span></p>
<p><strong>Chapter X</strong></p>
<p><strong>THE GENERAL THEORY OF THE LOGARITHMIC, EXPONENTIAL, AND CIRCULAR FUNCTIONS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/functions-of-a-complex-variable/">217–218. Functions of a complex variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/curvilinear-integrals/">219. Curvilinear integrals</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/definition-of-the-logarithmic-function/">220. Definition of the logarithmic function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-values-of-the-logarithmic-function/">221. The values of the logarithmic function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-exponential-function-ch-x/">222–224. The exponential function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-general-power-az/">225–226. The general power $a^z$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-trigonometrical-and-hyperbolic-functions/">227–230. The trigonometrical and hyperbolic functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-connection-between-the-logarithmic-and-inverse-trigonometrical-functions/">231. The connection between the logarithmic and inverse trigonometrical functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-power-series-for-exp-z/">232. The exponential series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-series-for-cos-z-and-sin-z/">233. The series for $\cos z$ and $\sin z$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-logarithmic-series-2/">234–235. The logarithmic series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-exponential-limit/">236. The exponential limit</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-binomial-series-ch-x/">237. The binomial series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-x/">Miscellaneous Examples</a></span></p>

<p><span><a href="https://avidemia.com/pure-mathematics/appendix-i/"><strong>Appendix I.</strong> The proof that every equation has a root</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/appendix-ii/"><strong>Appendix II.</strong> A note on double limit problems</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/appendix-iii/"><strong>Appendix III.</strong> The circular functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/appendix-iv/"><strong>Appendix IV.</strong> The infinite in analysis and geometry</a></span></p>
	</div>
</article>
				
			</div><!-- #content -->

			
		</div><!-- #primary -->

		

<!-- #right-sidebar -->


	</div><!-- #content-wrap -->

	

    …</main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://avidemia.com/pure-mathematics/">https://avidemia.com/pure-mathematics/</a></em></p>]]>
            </description>
            <link>https://avidemia.com/pure-mathematics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25365318</guid>
            <pubDate>Wed, 09 Dec 2020 21:26:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Tailwind UI and Next.js Together]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25364901">thread link</a>) | @hkhanna
<br/>
December 9, 2020 | https://www.khanna.law/blog/using-tailwind-ui-and-next-js-together | <a href="https://web.archive.org/web/*/https://www.khanna.law/blog/using-tailwind-ui-and-next-js-together">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>This process has gotten much easier with the <a href="https://blog.tailwindcss.com/tailwindcss-v2">release of TailwindCSS 2.0</a>. These instructions have been updated to reflect the installation process for TailwindCSS 2.0 and Next.js 10.</em></p>
<hr>
<p><a href="https://nextjs.org/">Next.js</a> is an incredible framework for building server-side React applications. <a href="https://tailwindcss.com/">Tailwind CSS</a> is a utility-first CSS framework that makes designing and building websites a breeze. And <a href="https://tailwindui.com/">Tailwind UI</a> is a commercial set of pre-baked components made in Tailwind CSS by two incredible designers, Adam Wathan and Steve Schoger. Using these tools together, I can develop whole web applications that look beautiful, from scratch, in record time.</p>
<p>To figure out the right way to set them up together, I pulled the relevant pieces of documentation from each of Next.js, Tailwind CSS and Tailwind UI and synthesized them into this guide. I reference and link to those parts of documentation where appropriate.</p>
<ol>
<li>Set up Next.js with Tailwind CSS in development</li>
<li>Add Tailwind UI</li>
<li>Optimize for production with PurgeCSS</li>
</ol>
<h2>1. Set Up Next.js and Tailwind CSS in Development</h2>
<p>The <a href="https://tailwindcss.com/docs/guides/nextjs">Next.js-specific TailwindCSS installation instructions</a> do an excellent job of getting you setup with both of these in a project. Complete the steps there and come back here when you're done.</p>
<p>Confirm it works by running <code>npm run dev</code> and navigating in your browser to <code>localhost:3000</code>, where you should see a page that looks something like this:</p>
<p><img src="https://www.khanna.law/assets/blog/using-tailwind-ui-and-next-js-together/next-js-screenshot.png" alt="Next.js Default Page"></p>
<p>Edit <code>pages/index.js</code> to use some Tailwind CSS classes to make sure its working:</p>
<pre><code>// pages/index.js
import Head from 'next/head'

export default function Home() {
  return (
    &lt;div&gt;
      &lt;Head&gt;
        &lt;title&gt;Next.js TailwindCSS&lt;/title&gt;
        &lt;link rel="icon" href="/favicon.ico"/&gt;
      &lt;/Head&gt;

      &lt;div className="container mx-auto"&gt;
        &lt;h1 className="text-lg text-center m-4"&gt;TailwindUI/Next.js&lt;/h1&gt;
        &lt;p className="bg-green-600"&gt;This is a test of the tailwind next integration.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  )
}
</code></pre>
<p>If Next.js has put a <code>Home.module.css</code> file in the <code>styles/</code> directory, you should delete that since that file just has the styling for the Next.js example page and should not be used anymore.</p>
<p>If it doesn't look like it working, you may need to stop the Next.js dev server and restart it because it may not pick up the changes to the <code>postcss.config.js</code> file unless you do a manual restart.</p>
<p>If you're still stuck, Next.js publishes an <a href="https://github.com/vercel/next.js/tree/canary/examples/with-tailwindcss">example app with Tailwind CSS</a> so you can see how your matches up.</p>
<p>One thing that may have noticed that may throw you off is that since this process creates a <code>postcss.config.js</code> file, it <a href="https://nextjs.org/docs/advanced-features/customizing-postcss-config">completely overwrites the implicit defaults used by Next.js</a>. On first glance, the defaults have a lot of stuff in it like <code>postcss-flexbox-fixes</code> and <code>postcss-preset-env</code> along with some configuration that we seem to have ignored. This is intentional.</p>
<p>Since by and large you won't be using CSS directly but will be using Tailwind CSS utility classes, you don't need that stuff and can just use the minimal <code>postcss.config.js</code> config from above.</p>
<h2>2. Add Tailwind UI</h2>
<p>The newest version of TailwindCSS and TailwindUI doesn't specifically require you to install TailwindUI-specific packages until you encounter that requirement by a particular TailwindUI component. For example, if you encounter a component that requires the <code>@tailwindcss/forms</code> plugin, you'll need to install it in your project with a <code>npm install --save @tailwindcss/forms</code> before you can use it.</p>
<p>There are some general and React-specific tips and tricks in the <a href="https://tailwindui.com/documentation">TailwindUI documentation</a>.</p>
<p>If things don't seem to be working and you've installed a new package or updated your <code>tailwind.config.js</code> file, you may need to stop and restart the Next.js dev server for it to pick up the changes.</p>
<p>If you are going to use the recommended <code>Inter var</code> font <a href="https://tailwindui.com/documentation#optional-add-the-inter-font-family">recommended by the TailwindUI documentation</a>, you'll need to put the <code>&lt;link&gt;</code> tag that it suggests in the <code>index.js</code> file <code>&lt;Head&gt;</code> tag:</p>
<pre><code>...
&lt;Head&gt;
  &lt;title&gt;Next.js TailwindCSS&lt;/title&gt;
  &lt;link rel="icon" href="/favicon.ico" /&gt;
  &lt;link rel="stylesheet" href="https://rsms.me/inter/inter.css" /&gt;
&lt;/Head&gt;
...
</code></pre>
<p>To test that Tailwind UI is working properly, in <code>pages/index.js</code>, copy and paste in an element that does not have any Javascript (e.g., the Marketing Blog Section component).</p>
<p>You may need find-and-replace the <code>class</code> attribute to <code>className</code> if your IDE doesn't do this for your automatically.</p>
<p>That's it! Integrating TailwindUI with Next.js has gotten much simpler since TailwindCSS 2.0 arrived on the scene.</p></div></div></div>]]>
            </description>
            <link>https://www.khanna.law/blog/using-tailwind-ui-and-next-js-together</link>
            <guid isPermaLink="false">hacker-news-small-sites-25364901</guid>
            <pubDate>Wed, 09 Dec 2020 21:01:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating realtime weather-data in Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25364877">thread link</a>) | @nanayaw1221
<br/>
December 9, 2020 | https://www.pythonstacks.com/blog/generating-realtime-weather-data-python/ | <a href="https://web.archive.org/web/*/https://www.pythonstacks.com/blog/generating-realtime-weather-data-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>In this short tutorial, you will learn to obtain the realtime/current weather conditions of any city in python. We are going to make use of the weather API from <a href="https://www.weatherapi.com/" target="_blank"><span>www.weatherapi.com</span></a>.</p>

<p>WeatherAPI is a service that provides weather data, including realtime weather data, forecasts, and historical data to developers for use in applications and other services.</p>

<p>Before using their API, you have to signup for a free account and generate an API key. You will need the API key for accessing their service.</p>

<p>We will use the Python Requests module for accessing the API. If you are not familiar with Requests, checkout Introduction to <a href="https://www.pythonstacks.com/blog/making-requests-python-requests-library/">Python's Requests library</a>.</p>

<p>Install the requests module by running:</p>

<pre><code>pip install requests</code></pre>



<h2>Retrieving the Current weather data</h2>

<p>Before we make the request, first we will create these variables:</p>

<ol>
	<li>
	<p><code>base_url </code>, which stores the API's URL which is <span>http://api.weatherapi.com/v1.</span></p>
	</li>
	<li>
	<p><code>api_key</code>, stores your API key</p>
	</li>
	<li>
	<p><code>city</code>, the city whose weather data is needed.</p>
	</li>
</ol>



<pre><code>import requests

api_key = "your_API_key"
base_url = "http://api.weatherapi.com/v1"
city = "london"

parameters = {"key":api_key, "q":city}         # URL parameters
r = requests.get(f"{base_url}/current.json", params=parameters)

data = r.json()         # retrieve the json data

print(data)</code></pre>

<p><strong>output:</strong></p>

<pre><code>{'location': {'name': 'London', 'region': 'City of London, Greater London', 'country': 'United
Kingdom', 'lat': 51.52, 'lon': -0.11, 'tz_id': 'Europe/London', 'localtime_epoch': 1606304125,
'localtime': '2020-11-25 11:35'}, 'current': {'last_updated_epoch': 1606302905, 'last_updated': 
2020-11-25 11:15', 'temp_c': 13.0, 'temp_f': 55.4, 'is_day': 1, 'condition': {'text': 'Partly
cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 8.1,
'wind_kph': 13.0, 'wind_degree': 200, 'wind_dir': 'SSW', 'pressure_mb': 1011.0, 'pressure_in': 30.3,
'precip_mm': 0.1, 'precip_in': 0.0, 'humidity': 82, 'cloud': 75, 'feelslike_c': 11.9, 'feelslike_f':
53.5, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 3.0, 'gust_mph': 11.9, 'gust_kph': 19.1}}</code></pre>

<p>The output is a python dictionary therefore, we can easily get the data we want from it by indexing.</p>

<p>Now let's parse this data into a nice piece of information</p>

<pre><code>import requests

api_key = "your_API_key"
base_url = "http://api.weatherapi.com/v1"
city = "london"

parameters = {"key":api_key, "q":city}         # URL parameters
r = requests.get(f"{base_url}/current.json", params=parameters)

data = r.json()         # retrieve json


# retriving Data

location = data['location']['name']
time = data['location']['localtime']

condition = data['current']['condition']['text']     
temperature_celcius = data['current']['temp_c']
temperature_farenheit = data['current']['temp_f']
feelslike_celcius = data['current']['feelslike_c']
wind_direction = data['current']['wind_dir']


# printing data
print(f"Location: {location}")
print(f"Current Time: {time}")
print()
print(f"Weather Condition: {condition}")
print(f"Temperature in Celcius: {temperature_celcius}")
print(f"Temperature in farenheit: {temperature_farenheit}")
print()
print(f"Temperature feels like: {feelslike_celcius} Celcius")
print(f"Wind Direction: {wind_direction}")</code></pre>

<p><strong>Output:</strong></p>

<pre><code>Location: London
Current Time: 2020-11-25 11:53

Weather Condition: Light rain
Temperature in Celcius: 14.0
Temperature in farenheit: 57.2

Temperature feels like: 13.1 Celcius
Wind Direction: SSW
</code></pre>


        </div></div>]]>
            </description>
            <link>https://www.pythonstacks.com/blog/generating-realtime-weather-data-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25364877</guid>
            <pubDate>Wed, 09 Dec 2020 21:00:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Statement Regarding Cyber Attack on European Medicines Agency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25364862">thread link</a>) | @mudil
<br/>
December 9, 2020 | https://investors.biontech.de/news-releases/news-release-details/statement-regarding-cyber-attack-european-medicines-agency | <a href="https://web.archive.org/web/*/https://investors.biontech.de/news-releases/news-release-details/statement-regarding-cyber-attack-european-medicines-agency">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="block-nir-pid3469-content">
  
    
      <h2>

</h2>





<article role="article">

  <div>
                <p>Today, we were informed by the European Medicines Agency (EMA) that the agency has been subject to a cyber attack and that some documents relating to the regulatory submission for Pfizer and BioNTech’s COVID-19 vaccine candidate, BNT162b2, which has been stored on an EMA server, had been unlawfully accessed. It is important to note that no BioNTech or Pfizer systems have been breached in connection with this incident and we are unaware that any study participants have been identified through the data being accessed. At this time, we await further information about EMA’s investigation and will respond appropriately and in accordance with EU law. EMA has assured us that the cyber attack will have no impact on the timeline for its review.</p>

<p>Given the critical public health considerations and the importance of transparency, we continue to provide clarity around all aspects of the vaccine development and regulatory processes. Our focus remains steadfast on working in close partnership with governments and regulators to bring our COVID-19 vaccine to people around the globe as safely and as efficiently as possible to help bring an end to this devastating pandemic.</p>
  
      </div>
</article>
  </div></div>]]>
            </description>
            <link>https://investors.biontech.de/news-releases/news-release-details/statement-regarding-cyber-attack-european-medicines-agency</link>
            <guid isPermaLink="false">hacker-news-small-sites-25364862</guid>
            <pubDate>Wed, 09 Dec 2020 20:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upcoming ARM Chip That's Faster Than Apple Silicon M1]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25364112">thread link</a>) | @singhkays
<br/>
December 9, 2020 | https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/ | <a href="https://web.archive.org/web/*/https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The release of Apple M1 Silicon has laid to rest many questions about whether ARM CPUs can go toe-to-toe with the best of the bunch from Intel and AMD. The question now is not whether ARM chips can perform better than Intel/AMD but whether others can build similarly powerful ARM CPUs. Today, companies like Marvell, Ampere and AWS are shipping ARM CPUs that keep getting better with each generation and close to the level of performance of top-end X86 CPUs. It only feels like a matter of time before ARM CPUs will provide tough competition to the X86 CPUs from Intel and AMD. This feels a bit like standing on the Florida coast and watching the first bands of a hurricane arrive. This reminds me of the iconic scene in the movie “The Dark Knight Rises” when Selina Kyle (<em>Catwoman</em>) tells Bruce Wayne (<em>Batman</em>) that there’s a storm (<em>Bane</em>) coming. The full dialogue goes something like:</p>
<blockquote>
<p>Selina Kyle (Catwoman): There’s a storm coming, Mr. Wayne. You and your friends better batten down the hatches, because when it hits, you’re all gonna wonder how you ever thought you could live so large and leave so little for the rest of us.</p>
<p><em>—The Dark Knight Rises (2012)</em></p>
</blockquote>
<p>If you read between the lines, there are many parallels that you can draw from the characterization in the movie to real life.</p>
<ol>
<li>
<p>Batman and Catwoman are frenemies, which is not much different from Intel and AMD’s relationship. They are often competitors, just like Batman &amp; Catwoman. Still, they managed to work together once and ship this baby - <a href="https://ark.intel.com/content/www/us/en/ark/products/130409/intel-core-i7-8809g-processor-with-radeon-rx-vega-m-gh-graphics-8m-cache-up-to-4-20-ghz.html">Intel® Core i7-8809G</a> - a rare Intel CPU with AMD integrated graphics.</p>
</li>
<li>
<p>Intel has dominated a large part of the CPU market’s profits for a very long time. In contrast, everyone else has had to contend with using lower cost as a vector to compete against Intel’s hegemony. For e.g. <a href="https://venturebeat.com/2020/02/05/amd-gained-share-against-intel-in-x86-processor-market-in-q4/">Intel dominates about 95.5% of the server chip market</a>.</p>
</li>
<li>
<p><strong>(<em>SPOILER ALERT</em>)</strong> Selina ends up joining up with Bane by giving up Batman. This might be very similar to the rumors that AMD is planning its own ARM CPUs in real life.</p>
<blockquote><p lang="en" dir="ltr">AMD has an M1 competitor in prototype stages, one version with integrated RAM, and one without it<br>he said "almost ready"<br>but -imo- idk<br>leak is only a few days old, the chip idk</p>— Mauri QHD (@MauriQHD) <a href="https://twitter.com/MauriQHD/status/1332601734565416962?ref_src=twsrc%5Etfw">November 28, 2020</a></blockquote>

</li>
</ol>

<p>Apple Silicon M1 has taken the CPU market by storm and, in doing so, answered every doubt whether it can compete with the best of the best. The M1 is currently sitting at the top of Geekbench’s <a href="https://browser.geekbench.com/mac-benchmarks">single-core throne</a>, all while using less power than competing CPUs. The M1 has completely reset the Performance per Watt expectations. It’s even more astonishing to think that as Apple has introduced the M1 for only the lowest-end Macs, this is the slowest SoC that Apple will ever make (<em>for Macs</em>). Based on Apple’s history of consistently delivering year-over-year performance improvements, the follow-ups to the M1 will likely improve upon the current single-core performance very rapidly. It is not clear whether Intel and AMD have something in the pipeline that could shift the balance back in X86’s favor.</p>
<p><img src="https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/mac-mini-geekbench-anandtech.png" alt="Apple M1 Geekbench Benchmark"></p>
<p><em>From: <a href="https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested/2">https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested/2</a></em></p>
<p>However, this could change soon.</p>


<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-logo_hu7acda768cb08e21c8112331e97f9c4f0_28389_480x0_resize_box_2.png 480w,
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-logo_hu7acda768cb08e21c8112331e97f9c4f0_28389_800x0_resize_box_2.png 800w,
            
                   
            
                   
            " src="https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-logo_hu7acda768cb08e21c8112331e97f9c4f0_28389_800x0_resize_box_2.png" alt="Nuvia Logo">
</figure>
<p><strong>Nuvia</strong> is a startup founded in early 2019 that is building an ARM CPU for the server market. The company was founded by John Bruno, Manu Gulati, and Gerard Williams III. They bring a breadth of experience in system engineering and silicon design for more than 20 chips and more than 100 patents. Nuvia’s leadership team holds an impressive resume with various architect and leadership roles at Google, Apple, ARM, Broadcom, and AMD (<a href="https://nuviainc.com/leadership"><em>See here for the leadership team’s full details</em></a>). It is quite possible that Nuvia’s leadership was involved with the previous Apple Silicon designs and bring with them the ideas and strategies that have made Apple’s chips a market-leader.</p>
<p>Here is <a href="https://medium.com/silicon-reimagined/performance-delivered-a-new-way-8f0f5ed283d5">more on Nuvia’s design goals and philosophy</a> (<em><strong>emphasis</strong> on key talking points mine</em>):</p>
<blockquote>
<p>Our focus at NUVIA is to develop an SoC that will deliver industry-leading performance with the highest levels of efficiency, at the same time. To do this, <strong>we are creating a server CPU that is built in a new way, with a complete overhaul of the CPU pipeline</strong>. Our first-generation CPU, code-named “<strong>Phoenix</strong>” will be a custom core based on the ARM architecture and central to our “<strong>Orion</strong>” SoC.</p>
</blockquote>
<blockquote>
<p>With X86 solutions claiming most of the market, only a small percentage of niche customers are willing to accept a lower per-core performance, high core count product. Arguably the most successful ARM-based design today is Amazon’s Graviton. Graviton is a captive design, aimed solely for a limited portion of AWS that values cost over performance. While there will likely be additional growth in this area, <strong>the heart of the market clearly demands the highest single-thread performance at TDP and the highest all-core performance at TDP</strong>. This is the fastest way to improve Performance/TCO for the most demanding hyperscale customers.</p>
</blockquote>
<blockquote>
<p>While these new entrant’s products show improvements, they still fall short of disrupting their X86 incumbents. At NUVIA, we are taking a different approach, with a clean-sheet CPU design that will deliver an elegant balance of performance leadership and power efficiency that maximizes memory bandwidth and core utilization. <strong>Our solution does not need to add extraneous cores to try and make up for a single-threaded performance deficit</strong>. Also, there would be <strong>no need to employ marketing-inflated boost clocks</strong> that are not achievable in any real-world applications of server SoCs, due to running into TDP constraints. In real-world scenarios, server SoCs are designed to be heavily loaded to make the best use of the capitalized hardware and allocated power and cooling budgets. The optimal solution is one where a workload finishes in the shortest time possible while consuming the least possible power.</p>
</blockquote>
<p>I’ve highlighted the key design goals, but the gist of it is that:</p>
<ol>
<li>Nuvia is likely working on a custom ARM design like Apple rather than reusing ARM’s reference architecture like some other ARM licensees.</li>
<li>The goal is the highest single-thread performance possible without the use of boost or turbo clocks.</li>
</ol>

<p>Nuvia recently <a href="https://medium.com/silicon-reimagined/performance-delivered-a-new-way-8f0f5ed283d5">published their findings</a> on how their Phoenix CPU fares against the latest X86 and ARM CPUs. Here are the systems that were tested:</p>
<table>
<thead>
<tr>
<th>Device</th>
<th>SoC</th>
<th>Process Technology</th>
<th>CPU Microarchitecture</th>
<th>Frequency</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020 Apple 13" MacBook Pro</td>
<td>Intel Core i7 -1068NG7</td>
<td>Intel 10nm</td>
<td>Sunny Cove</td>
<td>2.3GHz Base <br>4.1GHz Boost</td>
</tr>
<tr>
<td>2018 Apple 15" MacBook Pro</td>
<td>Intel Core i7 - 8750H</td>
<td>Intel 14nm</td>
<td>Skylake</td>
<td>2.2GHz Base <br>4.1GHz Boost</td>
</tr>
<tr>
<td>2020 Lenovo 14" Flex 5</td>
<td>AMD Ryzen 7 - 4700U</td>
<td>TSMC 7nm</td>
<td>Zen 2</td>
<td>2.OGHz Base <br>4.1GHz Boost</td>
</tr>
<tr>
<td>Samsung Galaxy S20</td>
<td>Qualcomm Snapdragon 865</td>
<td>TSMC 7nm</td>
<td>ARM A77, ARM A55</td>
<td>2.84GHz (xl-A77) <br>2.42GHz (x3-A77) <br>1.8GHz (x4-A55)</td>
</tr>
<tr>
<td>2020 Apple iPad Pro</td>
<td>Apple A12Z Bionic</td>
<td>TSMC 7nm</td>
<td>Vortex, Tempest</td>
<td>2.5GHz (x4-Vortex) <br>1.59GHz (x4-Tempest)</td>
</tr>
<tr>
<td>Apple iPhone 11</td>
<td>Apple A13 Bionic</td>
<td>TSMC 7nm</td>
<td>Lightning, Thunder</td>
<td>2.66 GHz (x2- Lightning) <br>1.73 GHz (x4-Thunder)</td>
</tr>
</tbody>
</table>
<p>The reasons for choosing these CPUs were as follows:</p>
<blockquote>
<p>The devices tested demonstrate the current state of the art from the majority of the major players, both ARM and X86 based platforms. Intel’s Core i7–1068NG7 Ice Lake based SoC is the highest performance variant currently available utilizing the new Sunny Cove CPU microarchitecture, based on Intel’s 10nm process node. We are also assuming that Intel’s next-generation Ice Lake Server will utilize a CPU core built upon a similar base architecture as Sunny Cove. The Intel Core i7–8750H is the last generation of the Skylake microarchitecture and is more closely related to the CPU core shipping in today’s latest Xeon processors. AMD’s Ryzen 4700U utilizes the latest Zen 2 CPU core on TSMC’s 7nm process node. AMD uses the same Zen 2 CPU core within the CCX chiplet in the Rome EPYC family of processors. Qualcomm’s Snapdragon 865 utilizes ARM’s latest A77 as its performance core and is implemented on TSMC’s 7nm process node. The latest announced Ampere Altra and Amazon Graviton 2 both use an ARM N1 CPU core that is more closely related to the older A76, and both are built upon TSMC’s 7nm process node. Lastly, the Apple A13 and A12Z demonstrate the current fastest ARM-based processors, also both built upon TSMC’s 7nm process node.</p>
</blockquote>

<p>Nuvia released the expected single-core Performance-Per-Watt curve of their upcoming CPU. To get an idea of how this ranks against the M1, I’ve added the <a href="https://browser.geekbench.com/v5/cpu/5197838">single-core Geekbench score for M1 based Mac Mini</a> to Nuvia’s graph. Nuvia is not disclosing the actual score, just giving estimates for now. The actual scores will be released at a later date. My best estimate based on their current projections is that these are higher than Apple M1’s single-core score. Based on the posted graph, I would put the single-core score between <strong>1900</strong> to <strong>2250</strong> range which is about a <strong>10-30%</strong> improvement on single-core performance.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_480x0_resize_box_2.png 480w,
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_800x0_resize_box_2.png 800w,
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_1200x0_resize_box_2.png 1200w,
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_1500x0_resize_box_2.png 1500w,
            " src="https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_800x0_resize_box_2.png" alt="Nuvia Phoenix CPU performance against Apple Silicon M1, A13 Bionic, Intel Sunny Cove, Snapdragon 865"> <figcaption>
<p>Nuvia Phoenix CPU performance compared to X86 and ARM CPUs</p>
</figcaption>
</figure>

<h3 id="how-to-read-these-results">How to read these results?</h3>
<p>From Nuvia:</p>
<blockquote>
<p>When measured against current products available in-market in the 1W-4.5W power envelope (<em>per core</em>), the Phoenix CPU core performs up to 2X faster than the competition.</p>
</blockquote>
<p>The 2X claim should now change since the results were published in August before the Apple M1 and the Zen 3 launch. These products now have higher single-core performance than the products Nuvia tested.</p>
<p>Nuvia did, however, expect such a scenario:</p>
<blockquote>
<p>We realize the companies we have measured against in these tests are not standing still and will have new products in the market over the next 18 months. That said, we believe that even with significant performance gains (20%+) with new CPU architectures, we will continue to hold a clear position of leadership in performance-per-watt.</p>
</blockquote>
<h3 id="why-is-nuvia-focusing-on-this-1w-45w-per-core-power-envelope">Why is Nuvia focusing on this 1W-4.5W per core power envelope?</h3>
<p>I’ll let Nuvia answer this:</p>
<blockquote>
<p>All current and future flagship server SoCs are power constrained, very much like mobile SoCs. As core count increases, what is not increasing is the TDP. TDPs are likely going to remain in the 250W — 300W …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/">https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/</a></em></p>]]>
            </description>
            <link>https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25364112</guid>
            <pubDate>Wed, 09 Dec 2020 20:15:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Problems in Financial Services Reconciliation]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25363650">thread link</a>) | @kunle
<br/>
December 9, 2020 | https://kunle.app/dec-2020-financial-reconciliation.html | <a href="https://web.archive.org/web/*/https://kunle.app/dec-2020-financial-reconciliation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  				
  				 <p>December 2020</p>

<p>If your product moves money on behalf of customers, and you manage the ledger, you need reconciliation. You can think of recon as the process of making sure every transaction in your system matches one in the external world. For every dollar you’ve moved, an external entity agrees with the amount and direction, and has provided “documentation” to that effect.</p>
<p>I’ve seen a few performant recon systems that came under stress as they scaled, and I’ve worked with startups at early enough stages that getting recon right was not existential. I’ve also never built a recon system from scratch. Everything I'll say here is from the perspective of a user of recon systems rather than a maker of them. I’ve been a customer of a couple, and their performance impacted my output so I have strong opinions about what I wish would exist. Since I'm not sure what a perfect recon system would look like, I'm writing this to flesh out the thought, and to smoke out anyone who already knows.</p>
<p>I’ve interacted with reconciliation systems aimed at two types of problems:</p>
<h2>Reconciliation of transactions</h2>
<p>Transaction oriented recon makes sure that some external party agrees with every money movement in your ledger. I saw this philosophy in the recon systems I interacted with at Cash App &amp; Square in general. In this model, the objective is to make sure that every money movement action matches your intention. This means the state of the transaction, the direction, and the amount are what you expect. A secondary objective is ensuring the timing matches your intention. This is secondary because in a lot of cases, the actual precise timing doesn't matter as long as it happens&nbsp; "soon", and as long as the underlying accounts aren’t run at a $0 balance. In this case reconciliation solves an accounting problem, ensuring money movements are correct. It also helps ensure that the company's receivables and payables are complete, is useful for regulatory &amp; financial audits, and empowers your treasury team to make good cash management decisions. I suspect most acquirers (Stripe, Square, Adyen, etc.) at least start by pursuing transaction oriented recon.</p>
<p>Typically in an acquiring world, you construct the “internal” ledger from the settlement/capture messages generated by the card networks. This is what product teams look at to inform customer facing features. You construct the “external” ledger from settlement files generated by the acquiring bank. Accounting teams look at the external ledger (technically accounting teams look at both ledgers, but product teams rarely look at the external ledger on an ongoing basis).</p>
<p>A recon system often includes an engineering team paired with an operations team, working together. In cases where the internal and external ledgers disagree, a human (on the ops team) reviews the data. They determine what’s causing the exception, whether it's systematic, how frequently it occurs, and what to do to fix it. The eng team continually optimizes the process to reduce the exception rate over time. Transaction oriented recon primarily solves accounting problems. You’re typically working towards SLAs designed for monthly/quarterly earnings close, and your outputs feed into income/cash flow statements.</p>
<h2>Reconciliation of balances</h2>
<p>Balance oriented recon ensures precise amounts in bank or customer accounts on a periodic basis. You use the same internal and external ledgers as in transaction oriented recon. However, you're comparing not only the amounts, state and direction of a transaction, but also its timing. This type of recon system can be useful for accounting, but is ideal for building systems that report a balance at a point in time. One example is a banking system of record. In the case of a system of record, a balance oriented recon system informs customer-facing balances and FDIC insurance.</p>
<p>Balance oriented recon systems are required for organizations that issue instruments and are the final source of truth for their own ledger. Most financial technology companies today rely on the ledgers managed by their infrastructure providers. For instance, if you issue cards, the banking as a service platform typically connects to the bank’s core, and most traditional bank cores have a balance oriented recon framework built in.</p>
<p>For context - in order to provide FDIC insurance to customers, banks are required to provide an auditable record of customer balances at any point in time. This is usually solved by being able to provide a daily snapshot of customer balances. This function is one of several provided by core processors, and as a result most core processors have a balance oriented recon process built in by default.</p>
<p>However if you’re the rare card issuer managing your own ledger (or really building any kind of financial product where you’re responsible for your own ledger, such as a digital wallet where you own the money transmission licenses), you’ll need to build a balance oriented recon system eventually. It's the way you’ll be sure you have the money that you’re telling customers you have.</p>
<h2>Common Problems in Recon</h2>
<h3>Adding a new money movement type to a single balance</h3>
<p>One overarching problem that affects all recon systems is what happens when new types of money movement impact a balance. For instance, imagine you run a digital wallet where your primary funding and cash-out transaction types are ACH debits and credits. Also, imagine you’ve built a perfect reconciliation system, with the combination of technology and human process that allows you to tie out balances and payments with zero failures (this is super unlikely). The moment you add payment cards as funding/cash out instruments, you now have a different external ledger to integrate with. It will have different edges than you're used to. You'll deal with potentially different organizations, who have different processes for resolving exceptions. No matter what you do, this will take time to get right, and long after your new feature is launched, you’ll probably discover new, undocumented quirks. Some of these quirks will only be clear when you’re processing money movements at scale. I’ve seen cases where the incorrect MID set with a card network resulted in hundreds of millions of dollars routed to the wrong (internal) account. Survivable error as the transactions were reconciled in aggregate, but bad for accounting and distraction caused to cross functional team members pulled in to swarm the problem.</p>
<h3>Timing differences between authorization and settlement</h3>
<p>For balance oriented reconciliation systems in particular, solving timing problems is critical. Timing problems typically occur when a) the payment authorization time and the settlement time are different, and your system’s not necessarily aware, b) you’re dealing with payment types where the settlement amount can be adjusted multiple times c) your ledger updates customers balances when a new payment authorization comes in, rather than a settlement message. In all these cases you’re grappling with a few questions (I don’t actually know the right answers to these):</p>
<ul>
<li>When should you update a customer’s balance? When you know there is a transaction (when the auth comes in) or when amount is finalized (when the settlement comes in)</li>
<li>When the authorization and settlement amounts are different, do you retroactively adjust the balance for the day the authorization came in? Or do you fix that in place and only adjust the balance with the delta on the day the settlement arrives?</li>
<li>Is your snapshot on a particular day immutable (i.e. it can never be adjusted) and if so, how do you handle changes in amounts between the authorization and the settlement?</li>
<li>Traditional core systems will have an available balance (which is how much you can access, with pending transaction amounts removed), and an account balance (which includes pending transactions, and is typically higher than the available balance).</li>
</ul>
<h3>Relying on aged systems for exception handling</h3>
<p>Very often you work with a wholesale bank whose systems are seasoned and handle the majority of exceptions using manual workflows. This can be frustrating; you’re faced with either adopting their manual processes, which bind your cost structure to theirs, or accepting a higher exception rate temporarily while you build technical systems around their process. There’s no easy trade-off here.</p>
<h3>Early prototyping and float problems</h3>
<p>In the course of product development you’ll often prototype by adding new money movement types to your ledger. A lot of these prototypes (as should happen) will be discarded. Despite this, they will have moved real money and affected your real ledger, and (at least for your accounting team's sanity) you’ll need a stateful way to reconcile the money that moved to your ledger. While at Cash I once spent a year integrating into 6 card issuer processor systems while prototyping the Cash Card. With each integration we needed a float (depositing funds with the card issuer so we could test transactions in the real world) which meant our accounting team now had 6 new banking relationships to monitor, 4 of which lasted less than 6 months, but all of which required material floats amounts. In a few cases, the issuer processor didn’t actually enable us to manage our own ledger, so we’d have a parallel ledger (one on our databases and a mirror on theirs) that we’d have to keep in sync. There was at least one integration that we ultimately discarded, which took us several months to reconcile, long after we’d walked away from the partnership. How you handle these cases will depend on what’s financially “material” for your organization. In our cases, prototype floats were all sub $100k, so survivable at our scale. But tracking these down repeatedly was an insane level of tedium.</p>
<h3>Managing ledgers across many internal bank accounts</h3>
<p>Sometimes you’ll contract with multiple banks for different financial services. For instance one bank for merchant acquiring and another for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kunle.app/dec-2020-financial-reconciliation.html">https://kunle.app/dec-2020-financial-reconciliation.html</a></em></p>]]>
            </description>
            <link>https://kunle.app/dec-2020-financial-reconciliation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25363650</guid>
            <pubDate>Wed, 09 Dec 2020 19:50:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned on an Engineering Manager job search]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25363559">thread link</a>) | @mcrittenden
<br/>
December 9, 2020 | https://critter.blog/2020/12/09/lessons-learned-on-an-engineering-manager-job-search/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/09/lessons-learned-on-an-engineering-manager-job-search/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-4009">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p><strong>Lesson 1: Even if the role doesn’t involve coding, you may have to prove you can code.</strong> Half of the companies I interviewed with put me through a coding challenge of some sort, even though the role is management and team building. Companies want to make sure you can understand what your team is talking about and maybe help out during crunch time. </p>



<p>My advice for those challenges is:</p>



<ol><li>Add a lot of debug output and run your code often. Interviewers seem to love that.</li><li>Talk your way through everything that you do, and feel free to Google as needed.</li><li>You want a quick and dirty solution, not a beautiful one. Aim for the crappiest thing that works, and then ask if there’s value in <a href="https://critter.blog/2020/09/08/2-things-ive-learned-from-reading-refactoring-by-martin-fowler/">cleaning it up</a>. Usually they’ll say no.</li></ol>



<p><strong>Lesson 2: It’s a numbers game.</strong> I applied to about 20 places and only ended up getting interviews with 4. I got offers from 2 of those so my offer-to-application ratio is 1 in 10. I ended up accepting an offer from a company that I almost didn’t bother applying to. They won me over during the interview process. So apply anywhere and everywhere, because you never know which company may surprise you.</p>



<p><strong>Lesson 3: Start with the ones you don’t care about.</strong> Your first few interviews may be rough, especially if you <a href="https://critter.blog/2020/09/22/interviewing-just-because/">haven’t done it in a while</a>. Make sure to get those out of the way with companies that you don’t have your heart set on. That way you’ll have rehearsed answers to common questions and you’ll be free of the nerves by the time you get to the companies you want.</p>



<p><strong>Lesson 4: Remember it’s an interview. </strong>This is one of the rare situations where <a href="https://critter.blog/2020/11/05/respond-to-vulnerability-with-vulnerability/">vulnerability</a> and <a href="https://critter.blog/2020/11/23/death-to-small-talk/">being 100% authentic</a> can get you into trouble. I had a couple interviews where I was a little too relaxed and treated it like a casual conversation. The point of an interview is for a company and a perspective employee to sell themselves to each other, not to <a href="https://critter.blog/2020/11/17/stop-trying-to-be-impressive-start-trying-to-be-warm/">build a strong relationship</a> with your interviewer. <a href="https://critter.blog/2020/11/10/death-to-just-add-water-team-jelling/">My habits</a>, which help me in <a href="https://critter.blog/2016/10/27/the-whys-and-hows-of-jelling-teams/">building teams</a>, failed me in interviewing.</p>



<p><strong>Lesson 5: Read a few good leadership books.</strong> You want them to be fresh in your mind when you interview. I am not sure if I would have gotten the offer I accepted if not for the ideas I stole from <a href="https://critter.blog/2020/11/13/be-the-trampoline/">The Culture Code</a>, <a href="https://critter.blog/2020/11/16/the-2-responsibilities-of-a-manager/">The Effective Manager</a>, <a href="https://critter.blog/2020/08/26/extreme-ownership-book-notes/">Extreme Ownership</a>, <a href="https://critter.blog/2020/09/25/if-you-want-to-be-heard-listen/">Difficult Conversations</a>, and <a href="https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/">Dare To Lead</a>.</p>



<p><strong>Lesson 6: Always ask these two specific questions</strong>:</p>



<ol><li>“<em>What is the worst thing about working at Company XYZ?</em>” People are surprisingly willing to be honest here. I got some enlightening answers about <a href="https://critter.blog/2020/10/15/the-hero-culture-conundrum/">hero culture</a>, lack of senior engineers, and corporate red tape.</li><li>“<em>What, if anything, concerns you about whether I’m a good fit for this role?</em>” Only 2 or 3 people said “nothing” to that question. Everyone else had something to say. Sometimes I was able to clarify a misconception they had about my experience, and sometimes it was a <a href="https://critter.blog/2020/11/11/good-feedback-is-pokey/">fair and justified concern</a>. Either way, that’s valuable.</li></ol>



<p><strong>Lesson 7: Negotiate your salary! </strong>Read <a href="https://www.amazon.com/Fearless-Salary-Negotiation-step-step/dp/0692568689?sa-no-redirect=1&amp;pldnSite=1">Fearless Salary Negotiation</a> and follow the steps it describes. It’s not hard when you know what you’re doing. When I average it out, I made about $1,000 per minute that I spent reading that book. </p>



<p>Good luck!</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/09/lessons-learned-on-an-engineering-manager-job-search/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25363559</guid>
            <pubDate>Wed, 09 Dec 2020 19:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open source Internet-less IRC using LoRa, for disaster resilience]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25363427">thread link</a>) | @spiritplumber
<br/>
December 9, 2020 | http://f3.to/cellsol/ | <a href="https://web.archive.org/web/*/http://f3.to/cellsol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
    


    








    <article>
        
        



    



<p>Welcome to CellSol!</p>
<p>This website and its associated project are now in beta! Come take a look at our <a href="https://github.com/RbtsEvrwhr-Riley/CellSol/">GitHub</a></p>
<p><img src="http://f3.to/cellsol/media/cellsol_large_236.png" alt="CellSol Logo - Large"></p>

<div><hr>
<h2 id="lastmod-2020-11-24">publishdate: 2019-11-17
lastmod: 2020-11-24</h2>

<p>What if the internet and cell phone towers went down for more than a few hours - or during an emergency situation? No communication could lead to lost lives.</p>

<p>The end goal of the project is to have a widespread network able to handle low-bandwidth traffic (text, compressed images) for a large number of users, to fill gaps when the larger Internet is unavailable.</p>
<p>In the event of an emergency, the CellSol network, much like the Internet, can be used as a knowledge base, as well as a rally point, giving people a tool to use to coordinate and organize even if 
other communication systems go down. We intend to scale the design, with long-haul routing capabilities, so that regional networks can intercommunicate and interoperate, allowing for a wider breadth of use cases.</p>

<p>The overall design is a <a href="https://en.wikipedia.org/wiki/Mesh_networking">mesh network</a> of <a href="https://www.semtech.com/lora/what-is-lora">LoRa</a> devices, called “Pylons”
that act as repeaters (extending the range of the network). Terminals (devices that users access the network with) also repeat packets, so that a network
made up entirely of end users is possible.</p>
<p>The two basic types of pylons are the ESP32 WiFi Pylon (a terminal device) and the Ardunio Repeater Pylon (a pure repeater, but can have bluetooth to use as a terminal).</p>
<p>Pylons with more specialized uses, such as data repositories for local emergency resources (phone numbers, shelter locations, etc.) and knowledge bases (such as a Wikipedia mirror) are also intended to be
developed in the future, to add to the overall usefulness of the network.</p>
</div>



    </article>

                








    
    

    







            </div></div>]]>
            </description>
            <link>http://f3.to/cellsol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25363427</guid>
            <pubDate>Wed, 09 Dec 2020 19:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Elixir's GenServer with a real-world example from open source]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25363291">thread link</a>) | @areichert
<br/>
December 9, 2020 | https://papercups.io/blog/genserver | <a href="https://web.archive.org/web/*/https://papercups.io/blog/genserver">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/genserver</link>
            <guid isPermaLink="false">hacker-news-small-sites-25363291</guid>
            <pubDate>Wed, 09 Dec 2020 19:30:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Native JavaScript Document API for Cassandra]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25362944">thread link</a>) | @Gulthor
<br/>
December 9, 2020 | https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html | <a href="https://web.archive.org/web/*/https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
        
        <h4>Level-up your app dev with fast and easy data APIs for the world’s most battle tested database.</h4>
      </p>
    </div><div>
      <div>
        <p><img data-src="/assets/images/stargate-profile.png" alt="Denise Gosnell" width="32" height="32" src="https://stargate.io/assets/images/stargate-profile.png">
          <span>By <span>Denise Gosnell</span></span>
          •
          <span>Dec 9, 2020</span>
        </p>
      </div>
    </div><div>
      <div>
        <div>
          <p>It is a really great time to be a developer.</p>

<p>We have tons of APIs integrated within great tools for building dynamic, full stack apps. If you are a developer, you probably are using technologies like schemaless data stores, serverless architectures, JSON APIs, and/or the GraphQL language.</p>

<p>Further, there are a bunch of cool frameworks like the <strong>Jam</strong>stack (<strong>J</strong>avaScript, <strong>A</strong>PIs, and <strong>M</strong>arkup) and services like Netlify to make it fast to deploy a serverless app.</p>

<p>And now, for the first time ever, Apache Cassandra is a part of this stack because <a href="https://astra.datastax.com/">Stargate is now live on Astra</a> as the official data API.</p>

<p>The modern apps we build need data APIs which integrate into our toolset and work with native data shapes (JSON, REST, GraphQL, etc). These data APIs need to support schemaless JSON, while simultaneously providing speed and scalability.</p>

<p>Most importantly, it better only take a few minutes for us to use them within our project.</p>

<p>DataStax built <a href="https://stargate.io/">Stargate</a> into Astra to give us, app developers, a natural data API stack which meshes with the Jamstack (or serverless stack of your choice). Stargate in Astra is built on the rock solid NoSQL data engine (Apache Cassandra) which powers Netflix, Instagram, Yelp, iCloud and other apps we all use everyday.</p>

<h2 id="what-exactly-is-stargate">What exactly is Stargate?</h2>
<p>Stargate is an <a href="https://stargate.io/2020/09/14/init-stargate.html">open source data gateway</a> that sits between your app server and your databases. Stargate brings together an API platform and data request coordination code into one OSS project.</p>

<p>Multiple successful app companies - like Netflix and Yelp - built their own data gateways to help internal app developers create features using simple APIs, without needing to learn the underlying database or mess with schema.</p>

<p>DataStax integrated Stargate into Astra to give you the same power and ease of access to your data.</p>

<p>What does this mean for you?</p>

<ul>
  <li>No upfront data modelling needed for Documents.</li>
  <li>Less custom code to maintain.</li>
  <li>More time to build what you care about.</li>
</ul>

<p><img alt="" data-src="/assets/images/stargate-astra/stargate-astra.png" src="https://stargate.io/assets/images/stargate-astra/stargate-astra.png"></p>

<p>You can work with your data the way you want – JSON via schemaless document APIs or database schema aware GraphQL and RESTful APIs – while Stargate serves as the proxy that coordinates these requests to different flavors of Cassandra.</p>

<p>To see it in action, let’s see how this works by using JSON with Stargate’s schemaless Document API in a TikTok clone. Because, if Instagram and Snapchat have a TikTok clone, we should have one, too. Right?</p>

<h2 id="real-quick-note-first">Real Quick Note First</h2>

<p>Slinging JSON to and from Apache Cassandra without data modeling is just too much fun. You gotta <a href="http://astra.datastax.com/">try this out in Astra for yourself</a>. You can get <a href="https://www.datastax.com/dev/documents-api">hands on with it right away</a> or check out our <a href="https://astra.datastax.com/sample-app-gallery">sample app gallery</a> to see schemaless Cassandra in action.</p>

<p>We are stoked to have engineers from Netflix, Burberry, Macquarie Bank, USAA, and Yelp creating Stargate with us. They are already hard at work battletesting the APIs and collaborating on new features.</p>

<p>Ok, onto the code!</p>

<h2 id="posts-in-tiktok">Posts in TikTok</h2>

<p>We are going to walk through using Stargate’s APIs in Astra for creating and updating posts within a TikTok clone. We’re walking through examples that are ready to be pasted into your latest Jamstack app.</p>

<p>To use Stargate in Astra in your app, first install and set up our <a href="https://www.npmjs.com/package/@astrajs/collections">JavaScript SDK</a>. You can learn about storing environment <a href="https://www.youtube.com/watch?v=vSmzEGZQI5A">variables in your .env file here</a>.</p>

<p>Let’s start with a basic TikTok post: a video with a caption, like:</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>postData</span> <span>=</span> <span>{</span>
  <span>"</span><span>postId</span><span>"</span><span>:</span> <span>0</span><span>,</span>
  <span>"</span><span>video</span><span>"</span><span>:</span> <span>"</span><span>https://i.imgur.com/FTBP02Y.mp4</span><span>"</span><span>,</span>
  <span>"</span><span>caption</span><span>"</span><span>:</span> <span>"</span><span>These ducks are cute</span><span>"</span><span>,</span>
  <span>"</span><span>timestamp</span><span>"</span><span>:</span> <span>"</span><span>2020-12-09T09:08:31.020Z</span><span>"</span><span>,</span>
  <span>"</span><span>likes</span><span>"</span><span>:</span> <span>0</span><span>,</span>
<span>}</span></code></pre></figure>

<p>After connecting to Stargate in Astra with a nodejs client, let’s create a new collection in our app and add the post with:</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>postsCollection</span> <span>=</span> <span>astraClient</span><span>.</span><span>namespace</span><span>(</span><span>"</span><span>tikTokClone</span><span>"</span><span>).</span>
  <span>collection</span><span>(</span><span>"</span><span>posts</span><span>"</span><span>);</span>

<span>const</span> <span>post</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>create</span><span>(</span><span>postData</span><span>);</span></code></pre></figure>

<p>If you’ve ever used Cassandra before, you know this is amazing. Look at what we didn’t do: no data modeling, no table creation, no configuration code, no partition keys, no clustering columns. I think you get my drift.</p>

<p>Stargate in Astra allows you to add data to Apache Cassandra in one line of code.</p>

<p>This level of ease of use hasn’t previously been possible with Cassandra. Insert JSON and move on.</p>

<p>Next up, let’s say you want to find all posts about ducks. You can do that via:</p>

<figure><pre><code data-lang="javascript"><span>// find all posts about ducks</span>
<span>const</span> <span>posts</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>find</span><span>({</span> <span>caption</span><span>:</span> 
  <span>{</span> <span>$in</span><span>:</span>  <span>[</span><span>"</span><span>ducks</span><span>"</span><span>]</span> <span>}</span> <span>});</span></code></pre></figure>

<p>And boom. Now you have your ducks channel all set up for your users. Because who doesn’t want a stream fully dedicated to ducks?</p>

<p>Now, your app isn’t going to <a href="https://www.newsweek.com/twitter-fleets-reactions-memes-edit-button-1548037">be like Twitter</a>. We can edit stuff here. Let’s show how to edit your post’s caption. Stories tho? That’s on you</p>

<figure><pre><code data-lang="javascript"><span>// update the post’s caption</span>
<span>const</span> <span>post</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>update</span><span>(</span><span>post</span><span>.</span><span>documentId</span><span>,</span> <span>{</span>
  <span>caption</span><span>:</span> <span>"</span><span>These ducks are MEGA cute</span><span>"</span><span>,</span>
<span>});</span></code></pre></figure>

<p>The above was just a quick tour on how to do a few data API calls for a basic TikTok clone. Want to see the full thing? Check out <a href="https://www.youtube.com/watch?v=IATOicvih5A">Ania Kubow</a>’s tutorial to see how to wire this up into a full React app with Netlify.</p>

<h2 id="whats-next">What’s next?</h2>

<p>For more examples, we have hands-on tutorials for using <a href="https://www.datastax.com/dev/rest">Stargate’s REST</a>, <a href="https://www.datastax.com/dev/documents-api">Document</a> and <a href="https://www.datastax.com/dev/graphql">GraphQL APIs</a>. Check ‘em out and let us know what you think.</p>

<p>Have an app idea or want to join the fun? <a href="https://discord.gg/2Xt8QNyFZA">You can join the Stargate community, too</a>.</p>

<p>We would love to see how you customize your TikTok clone to show off more ways to feature data in your app. Or, you can create your own non-TikTok example. We would love to showcase your example in our <a href="https://astra.datastax.com/sample-app-gallery">sample app gallery</a>, so tell us about it in <a href="https://discord.gg/33mKDHHFUE">our contribute channel</a>.</p>

<h2 id="so-you-are-down-here-looking-for-a-few-more-details">So, you are down here looking for a few more details</h2>
<p>If you came down here, maybe you are looking for a few more lines of code.</p>

<p>No problem.</p>

<p>Let’s show how to set up the node JS client and a few more data API calls. For starters, let’s take a look at how to set up your client to connect to Stargate in Astra.</p>

<figure><pre><code data-lang="javascript"><span>// npm install @astrajs/collections</span>
<span>const</span> <span>{</span> <span>createClient</span> <span>}</span> <span>=</span> <span>require</span><span>(</span><span>"</span><span>@astrajs/collections</span><span>"</span><span>);</span>

<span>// create an Astra client</span>
<span>const</span> <span>astraClient</span> <span>=</span> <span>await</span> <span>createClient</span><span>(</span>
<span>{</span>   <span>astraDatabaseId</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_ID</span><span>,</span>
    <span>astraDatabaseRegion</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_REGION</span><span>,</span>
    <span>username</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_USERNAME</span><span>,</span>
    <span>password</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_PASSWORD</span><span>,</span>
<span>});</span></code></pre></figure>

<p>Easy enough.</p>

<p>Then, let’s create a users collection in our database to store documents about our TikTok users:</p>

<figure><pre><code data-lang="javascript"><span>// create the users collection in the app</span>
<span>const</span> <span>usersCollection</span> <span>=</span> <span>astraClient</span><span>.</span><span>namespace</span><span>(</span><span>"</span><span>tikTokClone</span><span>"</span><span>).</span><span>collection</span><span>(</span><span>"</span><span>users</span><span>"</span><span>);</span></code></pre></figure>

<p>A TikTok user in our app will have the basics: a unique id, a name, username, etc.</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>userData</span> <span>=</span> <span>{</span>
  <span>"</span><span>id_3</span><span>"</span><span>:</span> <span>"</span><span>0</span><span>"</span><span>,</span>
  <span>"</span><span>name</span><span>"</span><span>:</span> <span>"</span><span>Mo Farooq</span><span>"</span><span>,</span>
  <span>"</span><span>username</span><span>"</span><span>:</span> <span>"</span><span>mofarooq32</span><span>"</span><span>,</span>
  <span>"</span><span>avatar</span><span>"</span><span>:</span> <span>"</span><span>https://i.imgur.com/9KYq7VG.png</span><span>"</span>
<span>};</span></code></pre></figure>

<p>So, let’s add our user into our collection:</p>

<figure><pre><code data-lang="javascript"><span>// create a new user</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>create</span><span>(</span><span>userData</span><span>);</span></code></pre></figure>

<p>You can check to make sure your user was stored in the database by reading the user back by any of their properties, like their username.</p>

<figure><pre><code data-lang="javascript"><span>// find our user by username</span>
<span>const</span> <span>users</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>find</span><span>({</span> <span>username</span><span>:</span> <span>{</span> <span>$eq</span><span>:</span> 
  <span>"</span><span>mofarooq32</span><span>"</span> <span>}</span> <span>});</span></code></pre></figure>

<p>Or, you can lookup a user by their <strong>documentId</strong>:</p>

<figure><pre><code data-lang="javascript"><span>// get the user by document id</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>get</span><span>(</span><span>user</span><span>.</span><span>documentId</span><span>);</span></code></pre></figure>

<p>And, lastly, if you need to delete that user:</p>

<figure><pre><code data-lang="javascript"><span>// delete the post</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>delete</span><span>(</span><span>user</span><span>.</span><span>documentId</span><span>);</span></code></pre></figure>

<p>Want to see the full code? Check out <a href="https://github.com/kubowania/stargate-tik-tok">Ania Kubow’s app</a> to get all the goodness and start customizing it on your own. Let me know when you have stories up and I can subscribe to your ducks channel.</p>

<p>Thank you for following along all the way down here.</p>

<p>Happy building!</p>


        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362944</guid>
            <pubDate>Wed, 09 Dec 2020 19:11:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using targeted microbubbles to administer toxic cancer drugs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25362909">thread link</a>) | @finphil
<br/>
December 9, 2020 | https://nuadox.com/post/637052199365754880/microbubbles-to-administer-cancer-drugs | <a href="https://web.archive.org/web/*/https://nuadox.com/post/637052199365754880/microbubbles-to-administer-cancer-drugs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="637052199365754880">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/637052199365754880/microbubbles-to-administer-cancer-drugs"><h2>Using targeted microbubbles to administer toxic cancer drugs</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1427"><img src="https://64.media.tumblr.com/e8e08c021c8929b23df911cfdcb4ea05/8fb509913ffeb1da-07/s1280x1920/45b467280c3b670994284ac789da1d0b15cb14be.png" alt="image" data-orig-width="1920" data-orig-height="1427" width="1280" height="951"></figure><p><b>- <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.leeds.ac.uk%2F&amp;t=Nzk0ZmY5NWI2MzlmNDFkNTQxYzIxZTg5ZTcyM2Q0OGNjYWJhYzgxMCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961">By University of Leeds</a> -</b></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.leeds.ac.uk%2F&amp;t=Nzk0ZmY5NWI2MzlmNDFkNTQxYzIxZTg5ZTcyM2Q0OGNjYWJhYzgxMCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961">University of Leeds</a>&nbsp;(UK) research has shown how microbubbles carrying powerful cancer drugs can be guided to the site of a tumour using antibodies.</p><p>Microbubbles are small manufactured spheres half the size of a red blood cell - and scientists believe they can be used to transport drugs to highly specific locations within the body. &nbsp;</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.thno.org%2Fv10p10973.htm&amp;t=NmJkNzIyNjg2MzY5NDM0ZTZhZWQ0NzJmYTU1Y2Y4N2ZhYjZlOTlmMCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961" title="The findings">The findings</a> are published in the journal <i><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.thno.org%2Fv10p10973.htm&amp;t=NmJkNzIyNjg2MzY5NDM0ZTZhZWQ0NzJmYTU1Y2Y4N2ZhYjZlOTlmMCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961">Theranostics</a></i>. </p><p>The lead authors, Drs Nicola Ingram and Laura McVeigh from the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicinehealth.leeds.ac.uk%2Fmedicine&amp;t=N2M4MzIyNjY3MDY5YmU5ZGFlZTQwMjA2N2I0MjNkODE5ODllZTA3ZSxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961" title="School of Medicine">School of Medicine</a>, describe how they targeted microbubbles through the use of a ‘navigational aid’ - antibodies attracted to the growth hormone found in high levels in the blood vessels supplying a tumour. </p><p>The antibodies were attached to the microbubbles. As a result of being attracted to the growth hormone, the microbubbles became concentrated at the site of the tumour. A pulse from an ultrasound device was used to burst open the microbubbles, and that released the anti-cancer agent. </p><p>The study was conducted on animals, which were used as a model to try and develop this technique for use in humans.</p><p>Dr Ingram said being able to deliver anticancer drugs in a very targeted fashion would be a major advance in cancer therapy. &nbsp;</p><p>She added: “One of the big problems with cancer drugs is that they are highly toxic to the rest of the body too. Microbubble technology could allow us to use these very powerful drugs with precision and that reduces the risk of the drug damaging healthy cells nearby. </p><p>“It is about finely focused drug delivery.” </p><p>The study also revealed that by attaching the drug directly to the microbubbles allowed it to circulate in the body for longer, increasing delivery into the tumour - in effect making the drug more potent. &nbsp; </p><p>As a result, the scientists were able to slow cancer growth with a much smaller drug dose. &nbsp;</p><p>Professor Stephen Evans, head of the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmnp.leeds.ac.uk%2F&amp;t=ZWFmZWY5ZWIwZWMwNzhhY2FkODBhMjk4OGQ0MWRiZjY1MmJhNzU0MixiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961" title="Molecular and Nanoscale Physics Group">Molecular and Nanoscale Physics Group</a> at Leeds and one of the paper’s authors, said: “The results of this study are exciting because we not only show the very precise and targeted way microbubbles can be guided to cancer sites but that the efficacy of drug delivery is substantially improved, opening the way to use highly toxic drugs to fight cancer, without the harmful side effects. </p><p>“Put simply: you get more bang for your buck.” </p><p>Watch the video where <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmicrobubbles.leeds.ac.uk%2Fabout%2F&amp;t=ZmEwM2Q2NTMwMTlhNGIwNjNiNDkyMWM4OWZlZGJhOTA5YWE0MTZkYSxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961">Professor Evans describes the potential benefit of microbubble technology</a>. </p><p>The next stage of the research is to look at using microbubbles to develop targeted, triggered, delivery systems in patients for the diagnosis and treatment of advanced <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.cancerresearchuk.org%2Fabout-cancer%2Fbowel-cancer&amp;t=MDIzZDliMWViOWVlNDA1Y2IxMGMwMzg4NmMzMDJlNDJhZWRjNzM5NixiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961" title="colorectal cancer explainer">colorectal cancer</a>, the third most common cancer in the UK. &nbsp;</p><p>Co-author Professor Peter Simpson, Chief Scientific Officer at <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmd.catapult.org.uk%2F&amp;t=NjM1NDEwYjc2OWZhN2IyZDVjMWQwMTkyMTUzOTZlY2E0NTI2Y2EzMSxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961" title="Medicines Discovery Catapult">Medicines Discovery Catapult</a> said: “Complex medicines have the potential to be the third wave of medicines, addressing patients’ problems which conventionally administered small molecules and monoclonal antibodies cannot. &nbsp;</p><p>“This project is a very encouraging example of exploring how using an advanced drug delivery technology could improve biodistribution, targeting and efficacy of a potentially toxic therapeutic.” </p><p>This study involved a research team from the universities of Leeds, Bradford, Manchester, and the Medicines Discovery Catapult in Cheshire. The study and a follow-on study were funded by the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fepsrc.ukri.org%2F&amp;t=ODdhZDk0Yzc3NDEzZGEzNTMwYjU1NjU5ZWU0NGI2OTViYzFhMjJiZCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961" title="Engineering and Physical Sciences Research Council">Engineering and Physical Sciences Research Council</a>. In addition, several PhD students are also developing microbubbles for treatment of other diseases and have been funded by University of Leeds alumni.</p><p>–</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.leeds.ac.uk%2Fnews%2Farticle%2F4735%2Fusing_targeted_microbubbles_to_administer_toxic_cancer_drugs&amp;t=NWU1NzUyNjBjZWY4MjY2ZTNhZDdkNzY3MjI5NjQ4ODcyODYxN2ViMyxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961">University of Leeds</a></b></p><p><b>Full study:</b>&nbsp;“Ultrasound-triggered therapeutic microbubbles enhance the efficacy of cytotoxic drugs by increasing circulation and tumor drug accumulation and limiting bioavailability and toxicity in normal tissues”,&nbsp;<i>Theranostics</i>.</p><p>doi:<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.thno.org%2Fv10p10973.htm&amp;t=NmJkNzIyNjg2MzY5NDM0ZTZhZWQ0NzJmYTU1Y2Y4N2ZhYjZlOTlmMCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607804961">10.7150/thno.49670</a></p><h2><b>Read Also</b></h2><p>A number of non-oncology drugs could potentially kill cancer cells</p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/cancer">cancer</a>
                                    
                                        <a href="https://nuadox.com/tagged/oncology">oncology</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/pharma">pharma</a>
                                    
                                        <a href="https://nuadox.com/tagged/pharmaceuticals">pharmaceuticals</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/637052199365754880/microbubbles-to-administer-cancer-drugs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362909</guid>
            <pubDate>Wed, 09 Dec 2020 19:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Review Best Practices – Lessons from the Trenches]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25362375">thread link</a>) | @eric_cartman
<br/>
December 9, 2020 | https://blogboard.io/blog/code-review-best-practices | <a href="https://web.archive.org/web/*/https://blogboard.io/blog/code-review-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Code Review Best Practices - Lessons from the Trenches">
            </figure>

            <section>
                <div>
                    <p>There's a ton of resources scattered around the web dealing with code review fundamentals, best practices, tools, etc. In this article we'll summarize the lessons from a dozen of official company engineering blogs. You can find links to the original articles in <a href="http://localhost:8080/blog/code-reviews"></a><a href="https://blogboard.io/search?searchQuery=code%20review">this blogboard search</a>.</p><h2 id="what-s-in-this-article">What's in this article?</h2><p>We'll cover several topics:</p><ol><li>Why do code reviews?<br>Besides the obvious, quality assurance, there are other benefits to code reviews</li><li>Code reviews as quality assurance<br>We'll cover the general recommendations on what to look for in a code review, why having a review checklist is beneficial, and you'll get a fairly long checklist that you can use as a base for your own list</li><li>Code reviews as a team improvement tool<br>If you've done more than a few code reviews, you know they're useful for more than just preventing bugs. We'll summarize common views on how reviews are beneficial as a learning and team bonding tool</li><li>Preparing a pull request for review<br>Lessons for pull request authors. There are rules of thumb consistently pointed out that help to prepare a PR for a smooth review</li><li>Reviewing code - Be human!<br>Lessons for reviewers on how wording and tone of your comments can make a huge difference in effectiveness of the whole review effort.</li></ol><p>The topics are covered fairly independently, so if you're curious about a particular topic feel free to skip ahead.</p><h2 id="why-do-code-reviews">Why do code reviews?</h2><p>It should be obvious that the primary purpose of code review is to assess quality of the changes being introduced. I mean, the dictionary definition of <em>review </em>says precisely that</p><blockquote><strong>review</strong> <em>(noun) - </em>a formal assessment of something with the intention of instituting change if necessary.</blockquote><p>Of course, code being code, there's a lot of things that can be checked and tested automatically, so there's nuance to what actually needs to be checked in an actual code review. We cover that in the next section.</p><p>On the other hand, code review is a form of communication between the <em><strong>author</strong> </em>of the change (these days usually <em>a pull request</em>) and one or several <em><strong>reviewers</strong>. </em>So it has side effects that go beyond preventing bugs from slipping in or keeping the codebase consistent in terms of style and architecture. </p><p>When done well, code reviews help accelerate learning across the team, create psychological safety for all team members, help establish and communicate best practices, teach proper communication and improve team dynamics. When done poorly, they can help deteriorate all of the above.</p><h2 id="code-reviews-as-quality-assurance">Code reviews as quality assurance </h2><p>There are a bunch of ways in which code reviews help maintain the quality bar for the codebase and the product. In the end it comes down to catching mistakes at the level which can hardly be automatically tested, such as architectural inconsistencies. Also, the code for automated tests should be reviewed, so there's a meta level at which reviews help with QA. </p><p>In <a href="https://engineering.gusto.com/high-leverage-code-reviews/">Giving High Leverage Code Reviews</a>, Casey Rollins advocates for having a checklist with all the usual things that need attention. </p><blockquote>When I’m reviewing a pull request, I often do multiple “passes” where I focus on one attribute at a time. I start at the beginning and review the pull request with a single attribute in mind before moving on to the next. When I’ve worked through the checklist, I submit the review.<p>This checklist moves from general to specific checks because it’s important to focus on the high-level attributes first. It doesn’t make sense to offer a variable name suggestion if you’re also suggesting that an entire class or function be refactored.</p></blockquote><p>You can have your own checklist or make it a shared list for the team or a project. There's a ton of material written on the usefulness of checklists. In <em><a href="https://en.wikipedia.org/wiki/Getting_Things_Done">Getting Things Done</a>, </em>David Allen puts forward a simple idea -<em> </em>our minds are great at processing information, but terrible at storing and recalling it. That's why checklists are a great way of externally storing and breaking down a planned or repetitive task.</p><p>Compiled from several articles (<a href="https://medium.com/paypal-engineering/effective-code-reviews-53d62a203b2f">1</a>, <a href="https://engineering.gusto.com/high-leverage-code-reviews/">2</a>, <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">3</a>) here's a high-level list of things to be concerned about when reviewing a code change:</p><ul><li>Story alignment - does the change meet the requirements of the task at all; ie. does the code implement any and all of the specified functionalities?</li><li>Consistency across the codebase</li><li>Architectural considerations - how does the new piece of code fit the existing architecture. Can the new feature architecture be improved, is it too generic or not extensible enough?</li><li>Simplicity/over-engineering</li><li>Performance concerns - are there specific cases (eg. peak load times) when the code will break? Do the queries pull more data than necessary? Could new queries benefit from adding new indexes to the database?</li><li>Accidental errors such as typos or errors in math formulas - these can be either obvious or really tricky to notice, especially with math heavy code</li><li>Compliance with laws and regulations - depending on the business this might be the most important thing</li><li>Security concerns - are there any exploitable pieces of code being introduced? Are any secrets being shared or stored unsafely?</li><li>Readability and style - a seemingly perfect piece of code might not be immediately understandable and readable to a different pair of eyes. Is it possible to understand the changes without the author explaining them?</li><li>Best practices - programming languages usually have their best practices - are they met in the pull request? Also, with time any project, team and company will evolve their own set of best practices - code reviews are a way to enforce and spread knowledge about them</li><li>Localization - are all language dependent resources localized properly?</li><li>Dependencies - are there external libraries or APIs being introduced? Are there other simpler/faster/better ways to do this with different dependencies or without any?</li><li>Interactions and side effects - how does the new piece of code interact with the rest of the codebase; does the new function implementation break any existing functionality; are all relevant unit tests updated/added</li><li>Logging - it's practically impossible to debug server code properly without good logging. Is everything logged/traced correctly</li><li>Error handling - how are the errors handled on the backend; how are they communicated to the user; are fallbacks activated where possible?</li><li>Testability/Test coverage - is the new piece of code covered with automated tests? Have all the suspicious test cases been checked either automatically or manually? Is the code written in a way that's suitable for unit testing?</li><li>External documentation - in case it's necessary is the external documentation updated to reflect the change?</li></ul><p>It's a pretty long list. In addition to it, a recurring piece of advice is not to use code reviews in place of static code analysis tools. If your review is mostly about code formatting, variable naming and alphabetical ordering, it might be a good time to include an automated code analysis tool into your development workflow.</p><p>In <em><a href="https://medium.com/paypal-engineering/effective-code-reviews-53d62a203b2f">Effective Code Reviews: Bettering Products, Teams, and Engineers</a> </em>from PayPal engineering<em>, </em>Gabriel McAdams points out several important benefits of code reviews related to team dynamics:</p><ul><li>Team cohesion - by making everyone's code subject to peer review, code review process promotes <em>individual accountability, healthy conflict</em> and the idea that everyone's<em> working together</em> to make the product better. As said in <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">Code Review Best Practices</a>: <em>Code reviews are classless: being the most senior person on the team does not imply that your code does not need review.</em><br>In summary, McAdams puts it nicely: <em>Trust + healthy conflict + individual accountability + working together to better the team = team cohesion.</em></li><li>Free career improvement training - simply by virtue of reviewing other people's code you become more skilled at reading and understanding new code. I've heard it said that one of the foremost traits of great engineers is the ability to dive into and dissect a completely unfamiliar piece of code. Over time you learn how to spot common practices, little tricks, pieces of syntactic sugar, architectural abstractions and how to appreciate different mental models used to solve the same problem.</li></ul><p>In <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">Code Review Best Practices</a> from the Palantir Blog, Robert Fink lists several ways in which knowledge sharing and social side-effects happen via code reviews:</p><ul><li>Authors are motivated by the peer review process to do all the necessary pre-checks, tighten the loose ends and generally tidy up the code before sending to review</li><li>A code review explicitly communicates changes made to product functionality to team members</li><li>The author maybe used a technique, abstraction or an algorithm that reviewers are unfamiliar with. The opposite can also be the case - reviewers might be aware of a more appropriate way to solve a given problem</li><li>Positive communication strengthens social bonds within the team (might especially be true for remote teams)</li></ul><h2 id="preparing-a-pull-request-for-review-help-the-reviewer">Preparing a pull request for review - help the reviewer</h2><p>Code reviews should be seen as a team effort. Once you view them that way it becomes clear that both sides - the author and the reviewers - have their distinct sets of responsibilities.</p><p>In <a href="https://medium.engineering/the-code-review-mindset-3280a4af0a89">this short post</a> on Medium Engineering blog, Xiao Ma describes how a different perspective changes the way code reviews are done, how feedback is taken and how people on each side benefit by adopting a <em>positive mindset</em> about code reviews.</p><p>When we talk about the responsibilities of the pull request author, there are several key things recurring in all code review guides.</p><ol><li><strong>Make pull requests as atomic as possible</strong><br><a href="https://shopify.engineering/great-code-reviews">At Shopify</a> they advise to keep <em>your pull requests small </em>- it helps the reviewer dive into it and finish it as an atomic piece of work in their workday. In practice this can mean keeping your pull requests limited to <em>a single concern. </em>A single concern here means a single bug fix, a feature, an API change etc. Don't mix refactoring that doesn't alter behavior with bug fixes or new features. This is …</li></ol></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blogboard.io/blog/code-review-best-practices">https://blogboard.io/blog/code-review-best-practices</a></em></p>]]>
            </description>
            <link>https://blogboard.io/blog/code-review-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362375</guid>
            <pubDate>Wed, 09 Dec 2020 18:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Marketing Tips for People with No Friends]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25362292">thread link</a>) | @kjcharles
<br/>
December 9, 2020 | http://keenen.xyz/marketing-for-people-with-no-friends/ | <a href="https://web.archive.org/web/*/http://keenen.xyz/marketing-for-people-with-no-friends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>When you're just getting started building your own projects marketing seems like a daunting task, especially if your background is in development. You spend some time learning what you can about marketing but a lot of advice relies on utilising your "network".</p><p>That assumes you have a network.</p><p>If you're like me and few of your friends are interested in the products you build, that advice is completely useless.</p><p>Next, they'll suggest you reach out to your wider network and get their support in sharing your project. You'll read articles on "how I got 1000 signups for my product in two weeks" that fail to mention their 5000 followers on Twitter.</p><p>What I've learnt is that you have to look past these tips and focus on scalable and automated methods of growth when you're friendless. Is it harder? Definitely. Does it take a lot longer? 100%. Will you look on enviously as others with networks instantly launch to thousands of signups and acclaim? Absolutely.</p><p>But there is a bright side. Scalable methods are sustainable. They have long-term value while a large network can provide a false indicator of success. If your product is solving a real problem you'll get more rewards from focusing on sustainable methods of growth early on.</p><p>For every new project, I focus on creating small but steady streams of traffic and optimising how I capture that traffic for long-term growth.</p><h3 id="1-seo">1. SEO</h3><p>The first step is setting up your product pages or landing page perfectly for SEO. This means meta tags, titles with keywords, sub-pages that target niche keywords, and so on. You can find specific tips on this everywhere and if you're building a directory site <a href="http://keenen.xyz/seo-tips-for-online-directories/">these tips</a> might be even more helpful.</p><h3 id="2-submit-to-aggregators">2. Submit to Aggregators </h3><p>Next, you want to submit your project to aggregation sites to drive some traffic to your page. Product Hunt, Reddit, Hacker News, etc are all great for this. Submit to as many as you can and let the traffic flow in. Chances are without a network your project won't be number one on any of these sites but you're likely to get a decent bit of traffic and some initial users. Check out this <a href="https://github.com/mmccaff/PlacesToPostYourStartup">comprehensive list here</a>.</p><p>It's also a great way for getting backlinks that will compound the effect of the initial SEO work you did. I try to submit to as many startup directories and Product Hunt clones as I find and hope they use dofollow links. If you get a backlink great. If they don't but you get some traffic that's fine too. If you get nothing 🤷‍♀️, it was free anyway (you definitely shouldn't pay to be listed on the majority of those sites, it's not worth it).</p><h3 id="3-email-signups">3. Email signups</h3><p>Whatever you're doing you should be collecting emails in some form. You want to be able to communicate with users of your product even if you don't require signup to use it. Create an account on Mailchimp or some other email service provider, embed a signup form on your page, and you're sure to get some signups.</p><p>As traffic trickles in from aggregators and SEO you'll begin to capture some emails. Once you do have a handful of signups you can start sharing regular updates with them. Chances are some of them will be drawn back to your product with each issue you send.</p><h3 id="4-reuse-content">4. Reuse Content</h3><p>If your product generates content you should find some way to share it on social media. Preferably in an automated way. Add relevant hashtags to each post and they can drive another bit of traffic to your product. With InboxReads I share every new submission to its' Twitter &amp; Facebook accounts and that results in a steady stream of traffic.</p><p>Emails you send can also be reused for future traffic. When picking an email service provider I would find one that creates indexable blog posts from each email you send. This means each issue becomes a piece of content that links back to your main product.</p><h3 id="5-optimize-repeat">5. Optimize &amp; Repeat</h3><p>Chances are you won't get everything right the first time. You might have misconfigured some meta tags or your social media work is just not getting any attention. It's important to be constantly analysing your results and testing new ideas to improve these steps. As you better understand your audience you'll be able to finetune this process to capture even more traffic.</p><p>These steps aren't likely to make you instantly rich or famous. You shouldn't expect a profile in TechCrunch or an influx of new followers. But they can give you a small but reliable and organic stream of traffic that lets you determine your product's viability. If it is viable then you would have invested time into sustainable and scalable marketing methods from the beginning. </p><p>And maybe you'll make some friends along the way.</p>
                </div>
            </section></div>]]>
            </description>
            <link>http://keenen.xyz/marketing-for-people-with-no-friends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362292</guid>
            <pubDate>Wed, 09 Dec 2020 18:41:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeepMind’s AlphaFold 2 – An Impressive Advance with Hyperbolic Coverage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25362134">thread link</a>) | @andreyk
<br/>
December 9, 2020 | https://www.skynettoday.com/briefs/alphafold2 | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/briefs/alphafold2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="summary">Summary</h2>

<ul>
  <li>DeepMind’s AlphaFold 2, a deep-learning model that predicts protein structures, achieved significant improvements over other methods in the biannual CAPS protein folding prediction competition.</li>
  <li>The improvements are so large that some claim protein folding is a solved problem. However, while almost all applaud the impressive advancement, many note the caveats and limitations of AlphaFold 2 in both the problem of protein folding and downstream uses in biology.</li>
  <li>After weighing the opinions of many experts, we take the view that while AlphaFold 2 should be celebrated, it is still just one step (though a big one!), and will not significantly advance practical applications like drug discovery.</li>
</ul>

<h2 id="what-happened">What Happened</h2>

<p>On the last day of November 2020, Critical Assessment of Structure Prediction (CASP), a biennial challenge for computational biologists on the problem of “protein folding”, released its results, showing DeepMind’s AI-driven <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">Alphafold 2</a> outperforming its competitors by a large margin. 
The pace of Alphafold’s improvement came as a shock to many researchers and mainstream media publications, <a href="https://www.bbc.com/news/science-environment-55133972">who heralded the development as a game-changer for biology</a>. 
Others acknowledged the uses of the tool, but <a href="http://occamstypewriter.org/scurry/2020/12/02/no-deepmind-has-not-solved-protein-folding/">cautioned that there were many more challenges </a>in the protein-folding prediction space that may warrant a tempering of expectations, let alone the broader field of biology.</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/alphafold2/image1.png" alt="AlphaFold 2's CAPS results.">
  <figcaption>
    Left: AlphaFold 2’s impressive score on the CAPS protein folding competition. Right: Examples of predicted (blue) vs. actual (green) protein structures.
    Source: <a href="https://www.deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">DeepMind</a>
  </figcaption>
</figure>

<p>In the world of proteins, form determines function. 
Thus, the ability to look forward and predict protein structures would help all kinds of biology subfields, from the more basic science work to drug discovery. 
Historically, attempts to model proteins have failed due to exponentially increasing computing costs, but <a href="https://dl.acm.org/doi/pdf/10.5555/3433701.3433707">specialized computational hardware</a> appears well-equipped to address this issue.</p>

<p>Alphafold made some waves with its 2018 CASP win, but the <a href="https://www.sciencemag.org/news/2018/12/google-s-deepmind-aces-protein-folding">media coverage was decidedly more muted then</a>. 
The pace of Alphafold’s 2020 improvement on top of its own success in 2018 was shocking for many experts, who felt that a solution to the <a href="https://scitechdaily.com/major-scientific-advance-deepmind-ai-alphafold-solves-50-year-old-grand-challenge-of-protein-structure-prediction/">50-year old protein-solving problem </a>was finally in sight. 
One important note is that AlphaFold 2, like other methods submitted to CASP, doesn’t actually model <em>how</em> proteins fold - it just predicts the final structure of the protein after it has folded.</p>

<p>There are a number of quality blog posts that explain protein folding and AlphaFold 2. <a href="https://twitter.com/jasoncrawford">Jason Crawford</a> at Roots of Progress gives an accessible review of protein folding in <a href="https://rootsofprogress.org/alphafold-protein-folding-explainer">What is the “protein folding problem”? A brief explanation.</a> It is also summarized in this excellent Twitter thread:</p>

<blockquote><div lang="en" dir="ltr"><p>Today Google <a href="https://twitter.com/DeepMind?ref_src=twsrc%5Etfw">@DeepMind</a> announced that their deep learning system AlphaFold has achieved unprecedented levels of accuracy on the “protein folding problem”, a grand challenge problem in computational biochemistry.</p><p>What is this problem, and why is it hard?<a href="https://t.co/OjbP3RBPEi">https://t.co/OjbP3RBPEi</a></p></div>— Jason Crawford (@jasoncrawford) <a href="https://twitter.com/jasoncrawford/status/1333576221418930176?ref_src=twsrc%5Etfw">December 1, 2020</a></blockquote>


<p>For a more technical explanation of AlphaFold 2 itself, we refer readers to the blog posts by <a href="https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/">Mohammed AlQuraishi</a> and <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">Carlos Outeiral</a>. In summary, DeepMind trained a neural network model on 170k known protein structures in the publicly available <a href="https://www.rcsb.org/">Protein Data Bank dataset (PDB)</a>. In addition to its many novel architecture designs, one important aspect of this neural network seems to be its use of attention mechanisms, a similar kind of architecture used by recent state-of-the-art language models like GPT-3.</p>

<blockquote><p lang="en" dir="ltr">An attention-based technique was used, which has shown promise across ML in language/vision/etc. This allows for efficient learning (ie capturing relations between elements) and uncovering broader principles: <a href="https://t.co/hKTcb5mTkr">https://t.co/hKTcb5mTkr</a></p>— Ali Madani (@thisismadani) <a href="https://twitter.com/thisismadani/status/1333481997210161160?ref_src=twsrc%5Etfw">November 30, 2020</a></blockquote>


<blockquote><div lang="en" dir="ltr"><p>Very exciting results this week from AlphaFold in CASP14. An incredible and inspiring achievement by the DeepMind team. Many new possibilities.</p><p>*Attention* mechanism is key to the result. Interestingly we find the exact same in our work on *unsupervised* learning for proteins.</p></div>— Alex Rives (@alexrives) <a href="https://twitter.com/alexrives/status/1334942570682716163?ref_src=twsrc%5Etfw">December 4, 2020</a></blockquote>


<h2 id="the-reactions">The Reactions</h2>

<h3 id="from-the-press">From the Press</h3>

<p>The press was very optimistic about AlphaFold 2’s progress in protein folding and its broader implications in biology and beyond, with headlines like:</p>

<ul>
  <li>Nature: <a href="https://www.nature.com/articles/d41586-020-03348-4">‘It will change everything’: DeepMind’s AI makes gigantic leap in solving protein structures</a></li>
  <li>Science: <a href="https://www.sciencemag.org/news/2020/11/game-has-changed-ai-triumphs-solving-protein-structures">‘The game has changed.’ AI triumphs at solving protein structures</a></li>
  <li>MIT Tech Review: <a href="https://www.technologyreview.com/2020/11/30/1012712/deepmind-protein-folding-ai-solved-biology-science-drugs-disease/">DeepMind’s protein-folding AI has solved a 50-year-old grand challenge of biology</a></li>
  <li>IEEE Spectrum: <a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/medical-ai/alphafold-proves-that-ai-can-crack-fundamental-scientific-problems">AlphaFold Proves That AI Can Crack Fundamental Scientific Problems</a></li>
</ul>

<h3 id="from-the-experts">From the Experts</h3>

<p><a href="https://twitter.com/c_outeiral/status/1334779365280903169">Carlos Outeiral</a>, Computational Biology research scientist at Oxford, also highlighted the “astoundingly” impressive results of AlphaFold 2, in the post <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">CASP14: what Google DeepMind’s AlphaFold 2 really achieved, and what it means for protein folding, biology and bioinformatics</a>:</p>

<blockquote>
  <p>After three decades of competitions, the assessors declared that AlphaFold 2 had succeeded in solving a challenge open for 50 years: to develop a method that can accurately, generally and competitively predict a protein structure from its sequence (or, well, a multiple sequence alignment, as we will see later). There are caveats and edge cases, as in any application — but the magnitude of the breakthrough, as well as its potential impact, are undeniable.</p>
</blockquote>

<p>Comparing AlphaFold 2’s results to those of other methods: “AlphaFold 2’s accuracy is simply on a whole different level.”</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/alphafold2/image2.png" alt="Comparing AlphaFold 2’s score (left most) to other methods in this year’s CAPS competition.">
  <figcaption>
  Comparing AlphaFold 2’s score (left most) to other methods in this year’s CAPS competition.
  Source: <a href="https://predictioncenter.org/casp14/zscores_final.cgi">CAPS</a>
  </figcaption>
</figure>

<p>Similarly, <a href="https://twitter.com/MoAlQuraishi">Mohammed AlQuraishi</a>, Professor of Systems Biology at Columbia, gave praise to DeepMind’s achievements:</p>

<blockquote><p lang="en" dir="ltr">CASP14 <a href="https://twitter.com/hashtag/s?src=hash&amp;ref_src=twsrc%5Etfw">#s</a> just came out and they’re astounding—DeepMind looks to have solved protein structure prediction. Median GDT_TS went from 68.5 (CASP13) to 92.4!!!! Cf. their 2nd best CASP13 struct scored 92.8 (out of 100). Median RMSD is 2.1Å. I think it's over <a href="https://t.co/dQ1BOJWuwn">https://t.co/dQ1BOJWuwn</a></p>— Mohammed AlQuraishi (@MoAlQuraishi) <a href="https://twitter.com/MoAlQuraishi/status/1333383634649313280?ref_src=twsrc%5Etfw">November 30, 2020</a></blockquote>


<p>In his detailed blog post last year on the first iteration of AlphaFold, <a href="https://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/#s2.2">AlphaFold @ CASP13: “What just happened?”</a>, Professor AlQuraishi discussed what DeepMind’s progress meant for academia and pharmaceutical companies:</p>

<ul>
  <li>This is “an indictment of academic science” - “There are dozens of academic groups, with researchers likely numbering in the (low) hundreds, working on protein structure prediction. […] For DeepMind’s group of ~10 researchers, with primarily (but certainly not exclusively) ML expertise, to so thoroughly route everyone surely demonstrates the structural inefficiency of academic science.”</li>
  <li>This is also “an indictment of pharma” - “What is worse than academic groups getting scooped by DeepMind? The fact that the collective powers of Novartis, Pfizer, etc, with their hundreds of thousands (~million?) of employees, let an industrial lab that is a complete outsider to the field, with virtually no prior molecular sciences experience, come in and thoroughly beat them on a problem that is, quite frankly, of far greater importance to pharmaceuticals than it is to Alphabet.”</li>
</ul>

<p>Responding to this year’s AlphaFold 2 is his new post <a href="https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/">AlphaFold2 @ CASP14: “It feels like one’s child has left home.”</a>:</p>

<ul>
  <li>While AlphaFold 2 still has a lot of caveats, Professor AlQuraishi defends using “solved” to describe protein folding, at least in the scientific sense. He argues the remaining deficiencies of AlphaFold 2 are not scientific problems, but rather engineering ones. While engineering problems can still be exceedingly difficult, “competent domain experts know the pieces that need to fall into place to solve them.”</li>
  <li>As for AlphaFold 2’s potential applications to advance biology as a whole: “It won’t happen overnight. None of what I’m saying here will. It will take years and maybe decades, but now that protein structure prediction has become an engineering exercise, we know that many of these ideas can be realized.”</li>
</ul>

<p>Specifically for drug development:</p>
<blockquote>
  <p>I will end this section with the question that gets asked most often about protein structure prediction—will it change drug discovery? Truthfully, in the short term, the answer is most likely no. But it’s complicated. 
One important thing to note is that, of the entire drug development pipeline, the early discovery stage is just that, an early stage. Even if crystallography were to become fast and routine, it would still not fundamentally alter the dynamics of drug discovery as it is practiced today, as most of the cost is in the later stages of drug development beyond medicinal chemistry and well into biology and physiology. Reliable protein structure prediction doesn’t change that.</p>
</blockquote>

<p>However, not everyone saw the same magnitude of advancement in AlphaFold 2.
In the post <a href="http://occamstypewriter.org/scurry/2020/12/02/no-deepmind-has-not-solved-protein-folding/">No, DeepMind has not solved protein folding</a>, <a href="https://twitter.com/Stephen_Curry">Stephen Curry</a>, Professor of Structural Biology at Imperial College London, cautioned against using the word “solved” to describe protein folding:</p>

<blockquote>
  <p>But we are not yet at the point where we can say that protein folding is ‘solved’. For one thing, only two-thirds of DeepMind’s solutions were comparable to the experimentally determined structure of the protein. This is impressive but you have to bear in mind that they didn’t know which two-thirds of their predictions were correct until the comparison with experimental solutions was made. Would you buy a satnav that was only 67% accurate?
So a dose of realism is required. It is also difficult to see right now, despite DeepMind’s impressive performance, that this will immediately transform biology.</p>
</blockquote>

<p>Despite AlphaFold 2’s average accuracy of 1.6 Å:</p>
<blockquote>
  <p>it’s still not nearly good enough for delivering reliable insights into protein chemistry or drug design. To do that, we want to be confident of atomic positions to …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/briefs/alphafold2">https://www.skynettoday.com/briefs/alphafold2</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/briefs/alphafold2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362134</guid>
            <pubDate>Wed, 09 Dec 2020 18:36:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New York Times Best Seller Business Book]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25361439">thread link</a>) | @dubeyaayush07
<br/>
December 9, 2020 | https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/ | <a href="https://web.archive.org/web/*/https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>December 08, 2020</p></header><section itemprop="articleBody"><h3>Oversimplified, Overgeneralized Rules to Make <del>Me</del> You Rich</h3>
<ul>
<li>It is good to be a contrarian but do you know what is even better? To be a contrarian contrarian and since according to an unrelated mathematical rule inverse of an inverse is equal to the same thing you should do what everyone is doing, that is buying my book.</li>
<li>Steve Jobs, Elon musk.</li>
<li><strong>PASSION</strong>, Do what you want, Quit your Job.</li>
<li>Case studies of why I am right based on misinterpretations of what really happened.</li>
<li>Correlation == Causation.</li>
<li>Cliched  general advice: Exercise, Brush Your teeth before bed, work hard to succeed, clean your room, etc.</li>
<li>Filler                 </li>
<li>Confirmation Bias, Anecdotal evidence.</li>
<li>Graphs, Plots(Who needs axes and scales), Math is on my side.</li>
<li>Random Philosophy detour which has nothing to do with my thesis</li>
<li>Arguments that look logical on paper but are just superficial overgeneralizations  targeted towards inexperienced individuals.</li>
<li>My life and how I applied these principles to get rich. People disagreed with me. I succeeded and now I am rich.</li>
</ul>
<hr>
<p>I wrote this post as a result of my frustration with popular business books and with non-fiction books in general. I am not saying every book is like this, some books are insightful and bring new ideas and perspectives to the table. But I have noticed that some authors have an idea and without fleshing it out and properly researching it they decide to write a book about it. Throw in cognitive dissonance, confirmation bias and an incompetent publishers and you have got yourself a popular non-fiction book. There is no peer review and if you sensationalize things you can earn a lot of money. </p>
<p>You cannot even trust books by experts in the field. I bought into the hype of the book Why We Sleep  by Matthew Walker the author seemed legit and well respected within his field. He even appeared on the Joe Rogan Experience. After reading the book I  began espousing the benefits of 8 hour sleep until I read <a href="https://guzey.com/books/why-we-sleep/">this</a> wonderful article by Alexey Guzey. So who should you trust? Should you stop reading non-fiction altogether? I suggest doing the opposite, read as much as you can and be wary of any broad sweeping statements. Even though some books might get something wrong, the good ideas are still valuable. And as with business you can only get better at it (i.e. filtering signal) by exposing yourself to more of it.</p></section><hr></article></div>]]>
            </description>
            <link>https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361439</guid>
            <pubDate>Wed, 09 Dec 2020 17:57:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Health Canada approves Pfizer Covid-19 vaccine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25361431">thread link</a>) | @vhodges
<br/>
December 9, 2020 | https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The federal government has given the green light to the Pfizer-BioNTech's COVID-19 vaccine, a key step toward launching the largest inoculation campaign in Canada's history.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5826792.1607723934!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/health-coronavirus-britain-vaccine.JPG"></p></div><figcaption>A person in Mainz, Germany gets a dose of the Pfizer/BioNTech vaccine as part of the product's clinical trial.<!-- --> <!-- -->(Reuters)</figcaption></figure><p><span><p>The federal government has given the green light to the Pfizer-BioNTech's COVID-19 vaccine, a key step toward launching the largest inoculation campaign in Canada's history.</p>  <p>Health Canada&nbsp;announced the approval Wednesday after scientists finished a two-month review of the company's clinical trial data.</p>  <p>"The data provided supports favourably the efficacy of Pfizer-BioNTech COVID-19 vaccine as well as its safety," the department said in its report authorizing&nbsp;use of the vaccine&nbsp;in Canada for people over the age of 16.</p>  <p>"The efficacy of the vaccine was established to be approximately 95 per cent. The vaccine was well tolerated by participants and has no important safety concerns. The benefit-to-risk assessment for Pfizer-BioNTech COVID-19 vaccine is considered favourable."</p>  <p>Canada is just the third country in the world to authorize the vaccine, after the United Kingdom and Bahrain. The U.S. Food and Drug Administration will hear tomorrow from an advisory panel on whether the vaccine is safe for use in the United States and&nbsp;authorization&nbsp;is&nbsp;expected in "a matter of days," U.S. Health Secretary Alex Azar said Wednesday.</p>  <p>Dr. Howard Njoo, Canada's deputy chief public health officer, said&nbsp;249,000 doses of the two-dose Pfizer vaccine will be on hand by year's end — shots primarily earmarked&nbsp;for long-term care home residents and the staff working there.</p>  <p>Maj.-Gen. Dany Fortin, the military commander leading vaccination logistics at the national operations centre,&nbsp;said 30,000 doses out of the&nbsp;initial run&nbsp;will be shipped from a Pfizer plant in Belgium on Friday.</p>  <p>"We expect&nbsp;vaccines to arrive as early as Monday," Fortin&nbsp;said, adding it's "totally possible" some&nbsp;Canadians could get their&nbsp;shots&nbsp;by mid-week.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/covid-cda-vaccine-20201209.jpg 300w,https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/covid-cda-vaccine-20201209.jpg 460w,https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/covid-cda-vaccine-20201209.jpg 620w,https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/covid-cda-vaccine-20201209.jpg 780w,https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-cda-vaccine-20201209.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/covid-cda-vaccine-20201209.jpg"></p></div><figcaption>Maj.-Gen. Dany Fortin, left, said some Pfizer COVID-19 vaccine doses could arrive as early as Monday.<!-- --> <!-- -->(Adrian Wyld/Canadian Press)</figcaption></figure></span></p>  <p>Njoo said as many as six million doses will arrive&nbsp;in the first three months of 2021. Assuming other&nbsp;promising vaccine candidates from companies like Moderna and AstraZeneca secure regulatory approvals, millions more shots will come online in the months to follow, he said.</p>  <p>The Public Health Agency of Canada (PHAC) said today the country will begin immunizing non-priority populations — people other than the elderly, health care workers and some adults in Indigenous communities —&nbsp;in April 2021. The vaccination campaign is expected to end next December.</p>  <p>"At last, we have a reason to feel optimistic and excited about returning to the lives we led pre-COVID," Njoo said. "Things are happening quickly."</p>  <p>Speaking in question period today, Prime Minister Justin Trudeau called the Pfizer-BioNTech approval a "big deal" because it signals that the end of this destructive pandemic is in sight.</p>  <p>"It's a good news day for Canadians but we are not through this yet. We have a tough winter to go through," Trudeau said, urging Canadians to respect public health measures&nbsp;even as shots start to arrive.</p>  <h2>Long-term care homes to be among first to get vaccine</h2>  <p>The Pfizer trial had&nbsp;more than 43,000 participants — one of the largest such trials ever conducted — and regulators found that the vaccine's efficacy was consistent across age, gender, race and ethnicity demographics.</p>  <p>The vaccine is&nbsp;based on&nbsp;groundbreaking&nbsp;messenger RNA technology, or mRNA, which essentially directs cells in the body to make proteins to prevent or fight disease.</p>  <p>The shot was found to be 94.7 per cent effective among clinical&nbsp;trial subjects who were over the age of 65 and who had no prior COVID-19 infection — a significant finding, given most&nbsp;novel coronavirus-related deaths in Canada have been reported among the elderly.</p>    <p>While the&nbsp;Pfizer vaccine has been given the necessary approvals, regulators conceded that the clinical&nbsp;trial data could not establish&nbsp;the long-term efficacy of the vaccine.</p>  <p>It is not yet known how long the vaccine-induced immunity will last but Health Canada said it will implement a robust "risk management plan"&nbsp;to monitor immunity and gather data on when it begins to wane. The regulator will also track any&nbsp;"adverse events" that follow immunization.</p>  <p>Cole Pinnow, the president of Pfizer Canada, said Health Canada's approval means the country can start to return to a sense of "normalcy," with&nbsp;millions of Canadians&nbsp;set to be vaccinated over the coming months.</p>  <p>"This is historic. We couldn't be more proud that Pfizer and BioNTech were able to bring to Canada the first COVID-19 vaccine. We think this represents a monumental change in the way that we are fighting the pandemic, and hopefully represents the first big step towards normalcy," Pinnow said in an interview with CBC Radio's&nbsp;<em>The Current</em>.</p>  <p>With recent polls showing that a sizeable number of Canadians will refuse a vaccine altogether, or will wait some time before lining up for a shot, Pinnow said he wants Canadians to be assured the product is safe.</p>  <p>"I would reassure Canadians that the scientific rigour and regulatory oversight that went into this product is as robust, if not more robust, than any other vaccine that's been brought to market," he said.</p>  <p><em><strong>WATCH: Pfizer addresses vaccine concerns:</strong></em></p>  <p><span><span><div><div title="Dr. Sharma calls the approval of the Pfizer vaccine a 'critical milestone' in the fight against COVID-19." role="button" tabindex="0"><div><div aria-labelledby="1829647939789-metadata-" title="Dr. Sharma calls the approval of the Pfizer vaccine a 'critical milestone' in the fight against COVID-19."><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1017/255/ftr_SHARMA_approval_frame_3575_corrected.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Health Canada chief medical adviser Dr. Supriya Sharma briefed reporters on the vaccine's approval during a briefing on Wednesday.<!-- --> <!-- -->2:19</span></span></span></p>  <p>Dr. Supriya Sharma, the chief medical adviser at Health Canada, also sought to reassure Canadians that her department conducted a "rigorous" review of all the product's&nbsp;clinical trial and technical information.</p>  <p>She said&nbsp;scientists&nbsp;found "strong evidence"&nbsp;that the vaccine's potential benefits far outweigh any risks.</p>  <p>"Canadians can have confidence ... the vaccine was authorized only after a thorough assessment of the evidence demonstrated it had met Health Canada's strict standards for efficacy, safety and quality," she said.</p>  <p>"It's an exceptional day for Canada. In a year when we haven't had a lot of good news, this is a bit of good news and we should acknowledge that."</p>  <p><em><strong>WATCH: Health Canada calls Pfizer approval a 'critical milestone' in fight against COVID-19:</strong></em></p>  <p><span><span><div><div title="Pfizer Canada addresses concerns over Bell's palsy in U.S. vaccine trials" role="button" tabindex="0"><div><div aria-labelledby="1829670467550-metadata-" title="Pfizer Canada addresses concerns over Bell's palsy in U.S. vaccine trials"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/14/750/CP2459909.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Pfizer Canada president Cole Pinnow said the four occurrences of facial paralysis among close to 22,000 subjects in U.S. clinical trials who received the Pfizer-BioNTech COVID-19 vaccine represented a frequency not above what is expected in the general population.<!-- --> <!-- -->0:18</span></span></span></p>  <p>British regulators warned Wednesday that people who have a history of serious allergic reactions shouldn't receive the new Pfizer vaccine as they investigate two adverse reactions that occurred on the&nbsp;first day of the country's mass vaccination program.</p>  <p>Asked about those warnings, Sharma said Canada is in&nbsp;constant communication with British authorities.</p>  <p>"We are always on the lookout for more serious adverse events," she said. "It is still a vaccine and there are potential risks even if they are rare. That's why it's important that we still continue to monitor it.</p>  <p>"Because these vaccines will be used in otherwise healthy people ... our tolerance for safety issues is very, very low."</p>  <p><em><strong>WATCH: Health Canada discusses allergic reactions to the Pfizer vaccine:</strong></em></p>  <p><span><span><div><div title="Dr. Sharma discusses allergic reactions to Pfizer's&nbsp;vaccine and how it was approved" role="button" tabindex="0"><div><div aria-labelledby="1829669443969-metadata-" title="Dr. Sharma discusses allergic reactions to Pfizer's&nbsp;vaccine and how it was approved"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/13/775/ftr_SHARMA_how_it_was_approved_frame_1960_corrected.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Health Canada chief medical adviser Dr. Supriya Sharma briefed reporters on the vaccine's approval during a briefing on Wednesday.<!-- --> <!-- -->2:38</span></span></span></p>  <p>Sharma said Health Canada is recommending individuals with allergies to any of the vaccine's components avoid the shot.</p>  <p>Sharma noted that there were few serious medical incidents&nbsp;reported among the 43,000 clinical trial participants. The most common side effects were soreness at the site of injection, joint pain and fatigue, she said.</p>  <h2>Inoculation to take months</h2>  <p>Canada is expected to take delivery of vaccines produced in Puurs, a small town in the north of Belgium&nbsp;that will be churning out hundreds of millions of doses of the co-developed Pfizer-BioNTech&nbsp;vaccine for the European Union, Canada, Japan and the United Kingdom over the next 12 months.</p>  <p>Maj.-Gen.&nbsp;Fortin&nbsp;has been leading a series of dry-runs with the provinces and territories to ensure they are prepared to distribute the extremely heat-sensitive Pfizer shot, which must be stored at temperatures between –80 C and –60 C.</p>  <p>Because the Pfizer product is so temperature-sensitive, Pfizer is shipping it directly from its plants to 14 points of use throughout Canada to limit movement and keep the vaccine stable.</p>  <p><strong><em>WATCH | Canada approves 1st COVID-19 vaccine for Pfizer-BioNTech:</em></strong></p>  <p><span><span><div><div title="Canada approves 1st COVID-19 vaccine from Pfizer-BioNTech" role="button" tabindex="0"><div><div aria-labelledby="1829907523663-metadata-" title="Canada approves 1st COVID-19 vaccine from Pfizer-BioNTech"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/240/827/covid-pfizer-approved-cochrane-091220.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Health Canada has approved the first COVID-19 vaccine for Canadians. Priority populations could start getting the Pfizer-BioNTech vaccine as early as next week, with rollout for the general population slated tentatively for the spring.<!-- --> <!-- -->2:35</span></span></span></p>  <p>Those sites&nbsp;have the necessary cold storage in place and are ready for the "imminent arrival" of the shots, Fortin said.&nbsp;</p>  <p>"We're undertaking a mobilization effort of massive proportions.&nbsp;Never in modern memory have we seen such an unprecedented level of collaboration and cooperation," he said. "It&nbsp;really makes me proud to be a Canadian and proud to serve."</p>  <p>The vaccines will be distributed to jurisdictions on a per-capita basis, meaning each province&nbsp;will receive&nbsp;vaccine doses&nbsp;in numbers&nbsp;proportionate&nbsp;to its share of the population.&nbsp;The vaccine will not be sent&nbsp;to&nbsp;the territories for the time being&nbsp;as they now lack&nbsp;the capacity to safely store the Pfizer product.</p>  <p>While the exact location of each of the 14 distribution centres has not yet been disclosed, some provinces, including Newfoundland &amp; Labrador, have said the Pfizer vaccine will be stored at major hospitals in urban areas.</p>  <p>The national advisory committee on immunization (NACI) said last week the limited&nbsp;initial&nbsp;quantity of doses should be reserved for people who are most at risk of contracting …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912">https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361431</guid>
            <pubDate>Wed, 09 Dec 2020 17:56:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualising Co-Occurring Pokémon Types with Chord Diagrams]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25361381">thread link</a>) | @DataCrayon
<br/>
December 9, 2020 | https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
            <div>
                <div>
                <div>
                    <h2>Data is Beautiful</h2>
                    <p>
                    A practical book on data visualisation that shows you how to
                    create static and interactive visualisations that are engaging and
                    beautiful.
                    </p>
                    <p><a href="https://datacrayon.com/shop/product/data-is-beautiful/">Get the book</a>
                </p></div>
                <p><img src="https://datacrayon.com/images/datacrayon/shop/covertop_dib.jpg">
</p>
                </div>
            </div>
            </div>
        </div><div itemprop="articleBody text">
    <!--% if post.meta('has_toc'):-->
    

        

        
            

            
<div id="support-this-work-top">
                                <p>Made with Chord Pro</p>
                                <p>
                        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.</p>
                            </div>

            

    


                    <div id="support-this-work-bottom">
                                    <p>Made with Chord Pro</p>
                                    <p>
        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.
        </p>
                                </div>
                            </div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361381</guid>
            <pubDate>Wed, 09 Dec 2020 17:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Install and Compress Videos Using Handbrake – A Step-by-Step Guide]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25361189">thread link</a>) | @ponderingfish
<br/>
December 9, 2020 | https://ottverse.com/install-and-compress-videos-using-handbrake/ | <a href="https://web.archive.org/web/*/https://ottverse.com/install-and-compress-videos-using-handbrake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

		<div>

		

	<div id="primary">

		
					<main id="main">

				
					
					

<article id="post-3018" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

		
	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>Handbrake is an open-source video transcoder that’s widely regarded as the best tool for video conversion. It’s effortless to use, multi-platform, and it covers a vast range of presets and devices as well. This means you will find it easier than ever to compress videos quickly without having to spend money on a conversion or transcoding tool. Instead, you can compress video using Handbrake very quickly, and the results will be great.</p>



<h2>Download and Install Handbrake on Windows</h2>



<p>The application is available free of charge at <a href="https://handbrake.fr/" target="_blank" rel="noopener">https://handbrake.fr/</a>, all you have to do is to visit the site and then select the platform you need the app for. They have multiple versions, including Mac, Windows, or Linux. In addition, you can access nightly builds and a command-line version too. </p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=876%2C362&amp;ssl=1" alt="install handbrake on windows" width="876" height="362" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=1024%2C423&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=1200%2C496&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?w=1340&amp;ssl=1 1340w" sizes="(max-width: 876px) 100vw, 876px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20876%20362'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=1024%2C423&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=1200%2C496&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?w=1340&amp;ssl=1 1340w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=876%2C362&amp;ssl=1"></figure></div>







<p>Begin the installation procedure by opening the <code>exe</code> file from the Download location. You should see a screen as follows – </p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?resize=494%2C406&amp;ssl=1" alt="install handbrake on windows" width="494" height="406" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?w=581&amp;ssl=1 581w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 494px) 100vw, 494px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20494%20406'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?w=581&amp;ssl=1 581w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?resize=494%2C406&amp;ssl=1"></figure></div>



<p>Agree to the License Terms and Conditions and hit “Next”.</p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?resize=490%2C402&amp;ssl=1" alt="install handbrake on windows" width="490" height="402" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?w=581&amp;ssl=1 581w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 490px) 100vw, 490px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20490%20402'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?w=581&amp;ssl=1 581w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?resize=490%2C402&amp;ssl=1"></figure></div>







<p>Choose an installation location and hit “Next”. </p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?resize=489%2C402&amp;ssl=1" alt="install handbrake on windows" width="489" height="402" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?w=581&amp;ssl=1 581w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 489px) 100vw, 489px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20489%20402'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?w=581&amp;ssl=1 581w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?resize=489%2C402&amp;ssl=1"></figure></div>



<p> And, that’s it. Handbrake should be installed on your Windows computer. </p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?resize=498%2C408&amp;ssl=1" alt="install handbrake on windows" width="498" height="408" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?w=581&amp;ssl=1 581w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 498px) 100vw, 498px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20498%20408'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?w=581&amp;ssl=1 581w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?resize=498%2C408&amp;ssl=1"></figure></div>











<h2>Select the source file and open it</h2>



<p>Once you finish installing the app, open it.</p>



<p>Go to the left side of the app, choose the Source Selection and then flick File. Then you can choose the file you want to compress and click Open. Once the file is loaded, you can choose where to save it simply by clicking Browse. Make sure that you create a name for the video so you can identify it with ease. Add whatever name you are comfortable with, and then press Save.</p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=843%2C539&amp;ssl=1" alt="compress video using handbrake" width="843" height="539" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=1200%2C768&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 843px) 100vw, 843px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20843%20539'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=1200%2C768&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=843%2C539&amp;ssl=1"></figure></div>



<h2>Picking the container type and video codec</h2>



<p>Right under the output settings, you can select the container. Ideally, you want to go with the <code>MP4</code> container format, unless you have any specific containers in mind. Under that you have the Video tab, here you want to select the H.264 codec.</p>



<div><figure><img width="1024" height="656" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1024%2C656&amp;ssl=1" alt="compress video using handbrake" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1024%2C656&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=300%2C192&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=768%2C492&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1200%2C768&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20656'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1024%2C656&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=300%2C192&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=768%2C492&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1200%2C768&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1024%2C656&amp;ssl=1"></figure></div>



<p>Here you can also select the desired framerate and quality types. The app has options for different video qualities, such as web, HD, and so on. Or you can go with an average bitrate instead of a certain quality. The framerate can be <code>30</code> FPS or more. It all depends on the initial framerate of your video. Most of the time, settling for <code>30</code> FPS will do just fine.</p>



<h2>Selecting a preset</h2>



<p>One of the main benefits of Handbrake is that it has a vast range of presets. You can browse the list of presets on the right side of the user interface. </p>



<div><figure><img width="1024" height="656" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=1024%2C656&amp;ssl=1" alt="compress video using handbrake" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?w=1032&amp;ssl=1 1032w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20656'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?w=1032&amp;ssl=1 1032w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=1024%2C656&amp;ssl=1"></figure></div>



<p>Normally you can go for <code>Fast 1080p 30</code>, as this is of great quality. But you can easily experiment with a variety of presets and see how the results turn out in the end. The average bitrate for a video should be anywhere from <code>5000</code> to <code>10000</code> kbps. Normally the higher the bitrate is, the better the video quality, but this will take a longer time to process and upload.</p>



<h2>Modifying the resolution and picture options</h2>



<p>In the Dimensions panel, you can see the source resolution and you can keep that or choose whatever resolution you find ok. Here you can also change the Anamorphic mode to None. Ideally, you want to have the modulus option to <code>16</code>. A good rule of thumb is to maintain the aspect ratio, you can do that simply by ticking the option with the same name right near the picture size.</p>



<div><figure><img width="1024" height="656" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1024%2C656&amp;ssl=1" alt="compress video using handbrake" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1024%2C656&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=300%2C192&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=768%2C492&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1200%2C768&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20656'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1024%2C656&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=300%2C192&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=768%2C492&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1200%2C768&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1024%2C656&amp;ssl=1"></figure></div>



<h2>Modifying audio information</h2>



<p>Go to the Audio tab, here you can modify the sample rate and other options the way you want. A lot of people use <code>48</code> or <code>64</code> kbps as the ideal sample rate, and the mixdown is Stereo. You can also change the audio codec, not to mention you can modify the bitrate. You may want to stick with a <code>320</code> bitrate, as it delivers the best quality.</p>



<div><figure><img width="1024" height="656" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1024%2C656&amp;ssl=1" alt="compress video using handbrake" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1200%2C768&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20656'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1200%2C768&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1024%2C656&amp;ssl=1"></figure></div>



<h2>Start the encoding process</h2>



<p>Once you fully customized everything, you want to press the Start Encode button. Then you can leave or do something else, as Handbrake will work on the video compression. </p>



<p>You will receive a notification when everything is fully completed.</p>



<h2>Conclusion</h2>



<p>Compressing any video using Handbrake helps a lot, and this free tool does bring in front incredible results. It does take a bit to get used to the interface, but with a little experimentation, you will have no problems. We recommend you to give Handbrake a try today, and you will be incredibly impressed with its ease of use and incredible compression quality!</p>

<!-- MOLONGUI AUTHORSHIP PLUGIN 4.2.11 -->
<!-- https://www.molongui.com/authorship/ -->

<div id="mab-7458456679" data-plugin-release="4.2.11" data-plugin-version="free" data-box-layout="slim" data-box-position="below" data-multiauthor="false" data-author-type="user" itemscope="" itemtype="https://schema.org/Person">

	
    <!-- Author headline -->
    <p>
        <h3>
            <span>About The Author</span>
        </h3>
    </p>

    <div>

        <div data-profile-layout="layout-1" data-author-ref="user-194568617">
            
<!-- End of .m-a-box-content-top -->

<div>

    <!-- Author picture -->
    
	<p><a href="https://ottverse.com/author/vkr2020/">
                    <img alt="" src="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=150&amp;d=mp&amp;r=g" srcset="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=300&amp;d=mp&amp;r=g 2x" height="150" width="150" itemprop="image" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </a>
                	</p>

    <!-- Author social -->
    
    <!-- Author data -->
    <div>

        <!-- Author name -->
        

        <!-- Author metadata -->
        

        <!-- Author bio -->
        
<div itemprop="description">
	<p>I’m Dr. Krishna Rao Vijayanagar, and I am the Founder and Editor of OTTVerse.com. I've spent several years working hands-on with Video Codecs (AVC, HEVC, MultiView Plus Depth), ABR streaming, and Video Analytics (QoE, Content &amp; Audience, and Ad). I hope to use my experience and love for video streaming to bring you information and insights into the OTT universe. Please use the Contact Page to get in touch with me.</p>
</div>

        
            <!-- Author related posts -->
            <!-- End of .m-a-box-related -->

        
    </div><!-- End of .m-a-box-data -->

</div><!-- End of .m-a-box-content-middle -->

<!-- End of .m-a-box-content-bottom -->        </div><!-- End of .m-a-box-profile -->

        
    </div><!-- End of .m-a-box-container -->

	
</div><!-- End of .m-a-box -->

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article><!-- #post-## -->


<!-- #comments -->

					
					
				
			</main><!-- #main -->
			
		
	</div><!-- #primary -->


	<!-- #secondary -->


			
			</div> <!-- ast-container -->

		</div></div>]]>
            </description>
            <link>https://ottverse.com/install-and-compress-videos-using-handbrake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361189</guid>
            <pubDate>Wed, 09 Dec 2020 17:36:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A bookmark manager that uses GitHub Gist as data back end]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25361175">thread link</a>) | @clebert
<br/>
December 9, 2020 | https://bookmark.wtf/9803bde974539a8992c0515b28db439b | <a href="https://web.archive.org/web/*/https://bookmark.wtf/9803bde974539a8992c0515b28db439b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bookmark.wtf/9803bde974539a8992c0515b28db439b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361175</guid>
            <pubDate>Wed, 09 Dec 2020 17:35:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BashML: Why Spark when you can bash?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25360983">thread link</a>) | @aleclm
<br/>
December 9, 2020 | https://rev.ng/blog/bashml/post.html | <a href="https://web.archive.org/web/*/https://rev.ng/blog/bashml/post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<p>In one of our many research projects here at rev.ng, we are dealing with <strong>Big Data</strong> (is a 1..10 TB compressed database dump big? Well, probably not, but it is for us).
Our first approach was to extract the data and store it in an SQL database, then run a bunch of queries and finally export the processed tables for other purposes.
See the problem there? We used to use the database just like a, err... data processing tool?
Unfortunately this wasn't working very well: we were having all kinds of performance bottlenecks since we were doing bulk inserts and bulk selects.</p>
<p>We then thought of using <a href="https://spark.apache.org/"><strong>Spark</strong></a> or some other fancy stuff like that in order to stream process everything and just use text files.
But, you know, we are a binary analysis company so most of the people here don't like garbage collectors (except me, the author of this blogpost, who like them very much).
Anyway, we went from using MySQL to MongoDB+MySQL to MongoDB+PostgreSQL to, you guessed it, text <strong>files + good ol' Bash</strong>.</p>
<p>In this article I will persuade you, CEO at a brand-new Spark'ing startup that, sometimes, <strong>Bash'ing is all you need</strong>.</p>
<p><img src="https://rev.ng/blog/bashml/edited.svg"></p>
<p><strong>Note:</strong> If you haven't checked out our Big Match post, <a href="https://rev.ng/blog/big-match/post.html">go read it</a>.</p>

          
          
            <h2>An example dataset</h2>
<p>For this tutorial we will be using a simplified version of our internal <strong>Big Match</strong> dataset of github repositories. It consists of a set of txt files and each of them contains a newline-separated list of sha256 hashes of strings found in a repo.</p>
<p>So for example, in file <code>torvalds,linux.hashes.txt</code> we have all the hashes of all the strings found in the linux kernel. They are also sorted for ease of use. It's clear that we use commas in place of <code>'/'</code> as a separator between username and repo name.
So, in this case, <code>torvalds,linux.hashes.txt</code> refers to the GitHub repo <code>torvalds/linux</code>.</p>
<p>Let's take a quick look at one of our files:</p>
<div><pre><span></span>head -n <span>5</span> ./dataset/torvalds,linux.hashes.txt
</pre></div>
<div><pre><span></span>0000130323884123bd36b3460e2311191fb0663dc7765e2781b62e1bb4fb1694
000020f8aa6016e534263f726778ea7ed6f8bdc6eaad4db703200b37ae6cf00b
000050a6f4869b1ccb3dc2f76f857561d3bae7c1d01e7153c1a6ef543abbd3ff
000052d246cfb78ed0a80bd74071664dc6cb76e3b5586dfed18d8613251fdeba
00006711c3893c6716caeb147e8894ed5bd9a02d1b8743ac5b207ffcf4508494
</pre></div>
<div><pre><span></span>wc -l ./dataset/torvalds,linux.hashes.txt
</pre></div>
<div><pre><span></span>540297 ./dataset/torvalds,linux.hashes.txt
</pre></div>
<p>But before delving into the fun part, let's fix locale issues between tools. Trust me, you do want to do this, otherwise you will get all sorts of error when piping together different commands (e.g.: <code>sort</code> and <code>join</code> don't like each other very much).</p>

<h2>Building blocks</h2>
<p>Bash tools have all kinds of different options and there seem to be little to no consistency between them. We all know that: I know it, you know it, everybody knows it.
So before starting we are going to create some <strong>helper functions</strong> for the most useful bashML operations out there.</p>
<p>We will start with a <a href="https://hackage.haskell.org/package/base-4.14.0.0/docs/Prelude.html#v:fst">haskell-inspired</a> helper, <code>fst</code>:</p>
<div><pre><span></span><span># a b =&gt; a</span>
fst<span>()</span> <span>{</span>
    cut -d <span>' '</span> -f <span>1</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>
</pre></div>
<p>It's pretty simple: it takes the first column of a given file. By using <code>$@</code>, we can either give it a file argument or use it without arguments (think pipes) and it will <strong>Just Work™</strong>:</p>
<div><pre><span></span><span>echo</span> -e <span>'ciao mondo\nhello world'</span> <span>|</span> fst
</pre></div>

<div><pre><span></span>fst &lt;<span>(</span><span>echo</span> -e <span>'ciao mondo\nhello world'</span><span>)</span>
</pre></div>

<p>If you are wondering what bash does on <code>&lt;(...)</code>, look no further:</p>


<p>Long story short, bash replaces the argument with a file descriptor that's connected to the output of the command inside <code>&lt;(...)</code>.
In fact, you can also <code>cat</code> it:</p>


<p>With that out of the way, let's create some additional helpers:</p>
<div><pre><span></span><span># Like `fst`, but returns the second column:</span>
<span># a b =&gt; b</span>
snd<span>()</span> <span>{</span>
    cut -d <span>' '</span> -f <span>2</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span># Same as `snd`, but can handle multi-character separators:</span>
<span># a     b =&gt; b</span>
snd_awk<span>()</span> <span>{</span>
    awk <span>'{ print $2 }'</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span># Turn whitespaces into newlines:</span>
<span># a b</span>
<span># c</span>
<span># =&gt;</span>
<span># a</span>
<span># b</span>
<span># c</span>
flat<span>()</span> <span>{</span>
    tr <span>' '</span> <span>'\n'</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span># Similar to python `enumerate()`:</span>
<span># a</span>
<span># b</span>
<span># =&gt;</span>
<span># 0 a</span>
<span># 1 b</span>
enumerate<span>()</span> <span>{</span>
    nl -v0 -w1 -s<span>' '</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span># Swap the first two columns in a file (and ignore the other columns):</span>
<span># a b =&gt; b a</span>
swap<span>()</span> <span>{</span>
    awk <span>'{ print $2 " " $1 }'</span>
<span>}</span>
</pre></div>
<p>For the few of you unfamiliar with <code>tr</code>, it's a little nice utility that can <em>translate</em> single characters (aka, map one character to another) or delete a character from a stream.</p>
<p>Another nice utility is <code>nl</code>, which counts the number of lines in a file.
Don't worry too much about the options: they are just there to output the format we want.</p>
<h2>Example pipelines</h2>
<p>It's now time to test our crazy bash skills to actually do something useful.</p>
<h3>Repository similarity</h3>
<p>Let's say we want to query our repos to <strong>find Linux forks</strong> just using common strings.
We can use a scoring formula called <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard index</a> (also called Jaccard similarity):</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi>A</mi><mo>∩</mo><mi>B</mi><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>A</mi><mo>∪</mo><mi>B</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi>A</mi><mo>∩</mo><mi>B</mi><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>A</mi><mi mathvariant="normal">∣</mi><mo>+</mo><mi mathvariant="normal">∣</mi><mi>B</mi><mi mathvariant="normal">∣</mi><mo>−</mo><mi mathvariant="normal">∣</mi><mi>A</mi><mo>∩</mo><mi>B</mi><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">
J(A,B) = \frac{|A \cap B|}{|A \cup B|} = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}
</annotation></semantics></math></span></span></span></p>
<p>So, if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> are our repositories, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">J(A, B)</annotation></semantics></math></span></span> is a measure of how many strings they share, divided by the total number of their strings.
How can you do this in bash?
Using <code>comm</code> and some basic <code>awk</code>.</p>
<p>If you are unfamiliar with <code>comm</code>, it's a simple command that is able to compare sorted files line by line.
If you run it without any specific option it will output 3 columns formatted like this:</p>
<div><pre><span></span>&lt;lines unique to file 1&gt; &lt;lines unique to file 2&gt; &lt;common lines&gt;
</pre></div>
<p>Remember to <strong>sort its input files</strong> otherwise <code>comm</code> will complain!</p>
<p>Anyway, if you run it with <code>--total</code>, it will also write a final line with the total count of lines for each column:</p>
<div><pre><span></span>mkdir -p ./tmp/

<span># a.txt</span>
cat &gt; ./tmp/a.txt <span>&lt;&lt;EOF</span>
<span>a</span>
<span>b</span>
<span>c</span>
<span>EOF</span>

<span># b.txt</span>
cat &gt; ./tmp/b.txt <span>&lt;&lt;EOF</span>
<span>c</span>
<span>d</span>
<span>e</span>
<span>EOF</span>

<span># Compare the lines in a.txt and b.txt (they are already sorted!)</span>
comm --total --check-order ./tmp/a.txt ./tmp/b.txt
</pre></div>

<p>See that last line?
It's the count we were talking about.
We can throw away everything <strong>except that last line</strong>, do some simple math in <code>awk</code>, and get the Jaccard index of the input files:</p>
<div><pre><span></span>jaccard<span>()</span> <span>{</span>
    <span># We don't need to sort because our input files are already sorted</span>
    comm --total --check-order <span>"</span><span>$@</span><span>"</span> <span>|</span> tail -n <span>1</span> <span>|</span> awk <span>'{ print ($3 / ($3 + $2 + $1)) }'</span>
<span>}</span>
jaccard ./tmp/a.txt ./tmp/b.txt
</pre></div>

<p>Same thing, but with a different file:</p>
<div><pre><span></span><span># c.txt</span>
cat &gt; ./tmp/c.txt <span>&lt;&lt;EOF</span>
<span>b</span>
<span>c</span>
<span>d</span>
<span>EOF</span>

jaccard ./tmp/a.txt ./tmp/c.txt
</pre></div>

<p>In this examples, the first two files have only one line in common out of 5 unique strings, so <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>5</mn></mfrac><mo>=</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">J(A, B) = \frac{1}{5} = 0.2</annotation></semantics></math></span></span>.
In the second example, they share 2 lines out of 4 unique strings, so <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>2</mn><mn>4</mn></mfrac><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">J(A, B) = \frac{2}{4} = 0.5</annotation></semantics></math></span></span>.</p>
<p>Yes, this is what data scientists get paid to do by the way.</p>
<p>Now let's say we want to find the Jaccard similarity between Linux and the biggest repos in our dataset.
We need to start by getting the list of such big files:</p>
<div><pre><span></span><span># Get list of (size, filename)</span>
biggest_files<span>()</span> <span>{</span>
    find ./dataset/ -name <span>"*.hashes.txt"</span> -print0 <span>\</span>
    <span>|</span> xargs -0 du -a <span>\</span>
    <span>|</span> sort -t <span>' '</span> -nr <span>\</span>
    <span>|</span> head -n <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span>echo</span> <span>'== Biggest files =='</span>
biggest_files <span>5</span>
<span>echo</span> <span>'...'</span>
</pre></div>
<div><pre><span></span>== Biggest files ==
103288  ./dataset/mirror,dd-wrt.hashes.txt
66824   ./dataset/kishikawakatsumi,Mozc-for-iOS.hashes.txt
57564   ./dataset/mirek190,x86-android-5.0.hashes.txt
51008   ./dataset/CyberGrandChallenge,samples.hashes.txt
47068   ./dataset/AndreyPopovNew,asuswrt-merlin-rt-n.hashes.txt
...
</pre></div>
<p>We now want to use the same <code>jaccard()</code> function we defined above <strong>but</strong> we want to run it faster by exploiting <strong>parallel processing</strong>.
We can do that with GNU <code>parallel</code>.</p>
<p>GNU <code>parallel</code> has a metric ton of options.
Yes, that is 1000-kilograms-many options.
Unless you voted for Brexit or play football with your hands: in that case it's ~2205 pounds.
Since we are Europeans and are not here to start a debate about our (superior) measurement system, we will just use 2 options and ignore the others:</p>
<div><pre><span></span>cat ./tmp/a.txt <span>|</span> parallel -j<span>$(</span>nproc<span>)</span> -k -- <span>echo</span> <span>{}</span>
</pre></div>

<p>What's happening here? Quite a bit actually: <code>parallel</code> just ran <code>echo {}</code> 3 times, every time substituting <code>{}</code> with a line from the input.
Remember: the calls to <code>echo</code> happen <strong>in parallel</strong> using multiple processes!</p>
<p>GNU <code>parallel</code> allows you to use <code>{}</code> multiple times if you want:</p>
<div><pre><span></span>cat ./tmp/a.txt <span>|</span> parallel -j<span>$(</span>nproc<span>)</span> -k -- <span>echo</span> <span>{}</span> <span>{}</span> <span>{}</span>
</pre></div>

<p>The options we give to <code>parallel</code> are very important: <code>-j$(nproc)</code> is for using as many processes as the processing units on the system (returned by the command <code>nproc</code>), while <code>-k</code> tells <code>parallel</code> to <strong>honor the input order</strong> when printing the output (so we don't get, e.g., <code>c c c</code> then <code>b b b</code> then <code>a a a</code>).</p>
<p>We can now use our previous <code>jaccard</code> function inside <code>parallel</code> to get the <strong>similarity between Linux and the other repos</strong>.
However, we also want a nice output so we throw in a call to <code>printf</code>.
The command gets a little messy due to string formatting, but just focus on the <code>jaccard</code> part:</p>
<div><pre><span></span>similarity<span>()</span> <span>{</span>
    <span># Export the `jaccard` function so that it's available to `parallel`</span>
    <span>export</span> -f jaccard

    <span>echo</span> -e <span>'\n== Similarity to torvalds/linux =='</span>

    <span># Find most linux-like repos</span>
    biggest_files <span>30</span> <span>\</span>
        <span>|</span> snd_awk <span>\</span>
        <span>|</span> parallel -j<span>$(</span>nproc<span>)</span> -k -- <span>printf</span> <span>\'</span>%0.5f %s<span>\\</span>n<span>\'</span> <span>'$(jaccard ./dataset/torvalds,linux.hashes.txt {})'</span> <span>'{}'</span>
<span>}</span>
similarity
</pre></div>
<div><pre><span></span>== Similarity to torvalds/linux ==
0.27157 ./dataset/mirror,dd-wrt.hashes.txt
0.00068 ./dataset/kishikawakatsumi,Mozc-for-iOS.hashes.txt
0.22947 ./dataset/mirek190,x86-android-5.0.hashes.txt
0.00447 ./dataset/CyberGrandChallenge,samples.hashes.txt
0.16675 ./dataset/AndreyPopovNew,asuswrt-merlin-rt-n.hashes.txt
0.21503 ./dataset/ChrisP-Android,BananaPi-Android-4.2.2-Liab.hashes.txt
0.01760 ./dataset/scs,uclinux.hashes.txt
0.22131 ./dataset/xdtianyu,android_04.01.01_msm7627a.hashes.txt
0.03125 ./dataset/IIJ-NetBSD,netbsd-src.hashes.txt
0.17406 ./dataset/Mazout360,asuswrt-maz.hashes.txt
0.14198 ./dataset/labx-technologies-llc,mb-linux-labx.hashes.txt
0.03072 ./dataset/freebsd,freebsd.hashes.txt
0.03224 ./dataset/opnsense,src.hashes.txt
0.02743 ./dataset/Stichting-MINIX-Research-Foundation,netbsd.hashes.txt
0.25569 ./dataset/andy-padavan,rt-n56u.hashes.txt
0.25605 ./dataset/moonman,rt-n56u.hashes.txt
0.03061 ./dataset/CTSRD-CHERI,cheribsd.hashes.txt
0.64101 ./dataset/sonyxperiadev,kernel.hashes.txt
0.39307 ./dataset/beastix,beastix.hashes.txt
0.99817 ./dataset/srikard,linux.hashes.txt
0.99851 ./dataset/RobertCNelson,linux-stable-rcn-ee.hashes.txt
0.99705 ./dataset/lzto,linux.hashes.txt
0.99705 …</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rev.ng/blog/bashml/post.html">https://rev.ng/blog/bashml/post.html</a></em></p>]]>
            </description>
            <link>https://rev.ng/blog/bashml/post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360983</guid>
            <pubDate>Wed, 09 Dec 2020 17:20:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking Hacker News sentiment towards Big Tech companies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25360761">thread link</a>) | @greatwave1
<br/>
December 9, 2020 | https://www.quiverquant.com/sources/hackernews | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://www.quiverquant.com/">
						<img src="https://www.quiverquant.com/static/img/logo.png" alt="">
					</a></p><p>Quiver scrapes alternative stock data from across the internet and aggregates it in a free, easy-to-use web dashboard.</p>
					<div>
						<p><span>Copyright © 2020 Quiver Quantitative, Inc. All rights reserved.</span></p><ul>
							<li><a href="https://www.quiverquant.com/privacypolicy">Privacy Policy</a></li>
							<li><a href="https://www.quiverquant.com/termsofservice">Terms of Service</a></li>
						</ul>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/sources/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360761</guid>
            <pubDate>Wed, 09 Dec 2020 17:01:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A modest proposal to save the world]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25360668">thread link</a>) | @donohoe
<br/>
December 9, 2020 | https://restofworld.org/2020/saving-the-world-through-tequiology/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/saving-the-world-through-tequiology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>I</span>t is a myth of the West’s choosing: perpetual economic growth, advancing through a digestive system of sorts, one that uses technology as one of its core components. In its churn,<strong> </strong>ecosystems became goods; people, mere consumers. The myth turned the world into a place increasingly inhospitable to human life.</p>



<p>I write these words from the periphery of the metropolises that command this global digestive system — an enclave that resists the myth’s logic. In these parts, resistance begins with a name. Here, Latin America is neither Latin nor America; it is Abya Yala, a term the Guna people of Panama use to describe the Western Hemisphere’s largest landmass as it existed before<strong> </strong>1492. This is a territory that comprises an array of Indigenous nations, Afro-descendant communities, and societies created by political projects of miscegenation. As a whole, the history of this diverse group of peoples is inextricable from the ravages of colonialism. Yet that history has also been defined by those peoples’ ingenious use of new technologies — not as consumable goods, but as means of resisting colonial imposition in the midst of an unprecedented climate crisis.</p>



<p><a href="https://www.cepal.org/en/publications/40840-science-technology-and-innovation-digital-economy-state-art-latin-america-and">To metropolitan eyes,</a> Latin America, with its minimal patent production and negligible investment in science and technology, lags behind. The Silicon Valleys springing up in different parts of the world — more an ideological concept than a geographic location — have long dismissed the region as a passive receptor for technology. But Abya Yala challenges that narrative. Here on the periphery, technology, when repurposed for resistance, can bolster the autonomy of peoples and communities.<strong> </strong>In Abya Yala, digital technologies have created virtual spaces to be shared — woven webs of sustainable<strong> </strong>collaboration among the continent’s subaltern voices.</p>



<p>This form of collaborative effort has ancient roots. To many peoples in Mexico, it is known as <em>tequio</em> (from the Náhuatl <em>tequitl</em>) or, farther south, as <em>faena</em>, <em>kol</em>, or <em>minga</em>. Through tequio, schools have been built, potable-water systems have been installed, and art has been made. Tequio has also become a strategy for meeting everyday needs. Just as the modern-day technology of free, open-source code has enabled collective progress in the digital sphere, the communal labor of tequio raises the possibility of resistance in Abya Yala — and survival of the world at large.</p>



<p>But as is true in every struggle against power, hegemonic narratives — those dominant myths that determine how we see the world<strong> </strong>— must first be confronted in order to avoid what Nigerian writer Chimamanda Ngozi Adichie has called “<a href="https://www.youtube.com/watch?v=D9Ihs241zeg&amp;ab_channel=TED">the danger of a single story</a>,” the all-encompassing Western mythology flooding our distant territories.&nbsp;</p>



<p>Since 2008, the Wayuu Film and Video Showcase, for instance, has given voice to the Wayuu, an indigenous people living in what<strong> </strong>is now<strong> </strong>Venezuela and Colombia. Similarly, the <a href="http://www.videonasaldeias.org.br/2009/">Vídeo Nas Aldeias</a> streaming platform, created by Vincent Carelli and the Nambiquara, has enabled Indigenous peoples in Brazil to learn to make films and tell their stories in their own narrative formats. The purpose of these initiatives, according to Wayuu director and film curator David Hernández Palmar, is to “close the digital gap that exists between these peoples and technology.” But “closing the gap” doesn’t only mean bringing film to the Wayuu: It also means building a bridge to the West to foster intercultural exchange.</p>



<p>Abya Yala, by repurposing imported technologies, is far ahead of the West in understanding how digital technology can burst out from the realm of the intangible into the “real world.” The West has recently witnessed how “fake news” and online interference in political disputes can spill over into its streets and ballot boxes. But Abya Yala has spent decades waging its struggles in digital spaces, particularly in defense of its native languages:<strong> </strong>Within the next hundred years, experts estimate that up to 80% of the world’s approximately 7,000 languages will have disappeared. Meanwhile, digital knowledge is accessible through just a few Portuguese-, <a href="https://restofworld.org/2020/saving-the-world-through-tequiology/">English</a>-, and <a href="https://restofworld.org/2020/tecnologia-tequio-cambio-climatico/">Spanish</a>-language<strong> </strong>gateways, inaccessible to non-hegemonic language communities in the periphery. But groups like<strong> </strong><a href="https://rising.globalvoices.org/lenguas/"><em>Activismo Digital de Lenguas Indígenas</em></a><em> </em>are filling the void. This continent-wide digital indigenous-language movement has forged a network of activists from all over Abya Yala, including Wikipedians, app developers, and programmers, among others. Collectives like the one created in the <a href="https://rising.globalvoices.org/lenguas/2020/02/16/mozilla-en-triqui/">Triqui region of southern Mexico</a> have worked together to ensure that they have access to browsers in their own language. In this way,<strong> </strong>we see<strong> </strong>digitally underrepresented peoples appropriating technology<strong> </strong>as a tool of linguistic resistance<strong>.</strong>&nbsp;</p>



<p>Abya Yala’s technological struggle<strong> </strong>also<strong> </strong>extends to the vindication of material sovereignty. In Mexico, <a href="https://www.redesac.org.mx/telefoniacomunitaria">Community Cellular Technology</a>, through which cell phone systems are locally owned, administered, and operated, has been built against a backdrop that has started to crumble: As proprietors of their own cell company, these communities defy the slogan of the conglomerate that controls 70% of the country’s mobile communication services: “All of Mexico is Telcel territory.” The response from these communities is No: Not all of Mexico is the territory of Carlos Slim, one of the wealthiest men in the world. They strive for technological sovereignty.</p>



<p>Technology has also tapped into ancient collective philosophies to resist the metropole. Rodrigo Pérez Ramírez, better known in Mexico as Zapoteco 3.0, is part of the <a href="https://mozillanativo.org/involucrate">Mozilla Nativo</a> movement, which seeks to empower indigenous peoples online. He told me that he had found in open-source software a natural ally to his local Zapotec-language activism. There is a serendipitous affinity between the logic of collective effort and free cooperation that defines open-source software like Linux and the philosophy of many indigenous communities who built structures to survive the harshness of colonial rule. Both rely on<strong> </strong>mutual support and small-scale, community-level labor linked into a circuit of larger tasks.<strong> </strong>Such tequio is an essential “social technology” common<strong> </strong>across Abya Yala. It has been<strong> </strong>for a long time, including back when indigenous peoples, organized into small communities, created networks to resist paying taxes or to plan rebellions against the Iberian crowns.&nbsp;</p>



<p>However, this form of scalable Abya Yalan tequio could be a crucial asset to the entire world in the years ahead. When technologies are deployed in forms<strong> </strong>that resemble<strong> </strong>tequio,<strong> </strong>rather than in pursuit of insatiable competitive growth, we may indeed get a true solution to the dire climate emergency we are facing. Even so-called green capitalism has raised hopes that some technological invention will solve our ecological emergency. But we in Abya Yala can see how even some forms of renewable energy wind up as just another pollutant. Here, we have seen<strong> </strong>rare earths violently <a href="https://restofworld.org/2020/niobium-the-mighty-element-youve-never-heard-of/">extracted from our territories</a> in order to create “green technologies,” which are then installed on “empty land” by dispossessing our communities.<strong> </strong>This phenomenon was explored at the Wayuu Film and Video Showcase in a documentary called “Tatuushi”<em> </em>(My Grandfather). Through traditional Wayuu singing, it tells the story of a grandfather who travels to the city in search of food. On his return, he finds that coal companies have devastated his land and destroyed his home. Faced with dispossession, the grandfather responds with a traditional prayer.</p>



<p>An alternative, offered by Abya Yala, lies in separating economic development and the development of new technologies from consumerism. This would place technological creation and ingenuity once again at the service of the common good, not of the market. Technology as tequio; technological creation and innovation as a common good. A kind of open-source software we can all participate in, just as we have participated in the construction of our lives as the colonized peoples of this continent, resisting genocide and extinction.&nbsp;In the face of our current global climate emergency, we need to foster forms of technological development that emphasize living with dignity, not infinite economic growth as an end in itself. We must focus on technologies based on collaborative labor more than on competition. As peoples of Abya Yala, we’re experienced in this strategy, which I call <em>tequiology</em>. If the world were to listen to the people of Abya Yala and adopt this new tequiological vision, we could perhaps escape the digestive system that so threatens our world’s climate and endangers human life.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/saving-the-world-through-tequiology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360668</guid>
            <pubDate>Wed, 09 Dec 2020 16:53:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Automatic Customer Data Cleaning API]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25360553">thread link</a>) | @asharma327
<br/>
December 9, 2020 | https://www.cleanspreadsheets.com/api-docs | <a href="https://web.archive.org/web/*/https://www.cleanspreadsheets.com/api-docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cleanspreadsheets.com/api-docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360553</guid>
            <pubDate>Wed, 09 Dec 2020 16:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tyler Slide Rule]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25360450">thread link</a>) | @AlphaGeekZulu
<br/>
December 9, 2020 | https://osgalleries.org/collectors/davis/info_and_image.cgi?string1=weemsandplath&string2=2910 | <a href="https://web.archive.org/web/*/https://osgalleries.org/collectors/davis/info_and_image.cgi?string1=weemsandplath&string2=2910">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"> 


<p>
<span color="#000000"><img src="https://osgalleries.org/collectors/davis/oslogo.jpg" name="graphics1" width="150" height="63"></span></p>


<p>
<span color="#333399"><span face="Arial"><span size="6"><b>Archive
</b></span></span></span><span color="#333399"><span face="Arial"><span size="4"><b>of</b></span></span></span><span color="#333399"><span face="Arial"><span size="6"><b>
Collections </b></span></span></span>
</p>

<center>
<span>Details and Image</span>
</center>
    <center><table>
	<tbody><tr>
	<th>Type</th><th>Model No.</th><th>Maker</th><th>Country</th><th>Construction<br>Material</th><th>Date</th><th>Scale Length</th><th>Area of Use</th>
	</tr><tr>
			<td>Disk / Plate</td><td><center>Tyler Slide Rule</center></td><td>Weems and Plath</td><td>U.S.A.</td><td><center>Plastic</center></td><td>est. 1955</td><td>21.5 cm x 21.5 cm</td><td>General Purpose</td>
			</tr></tbody></table></center><br><b>Notes: </b>"1) Unusual slide rule designed by John Tyler 2) Interesting design using non-linear curved scales to determine answers 3) Reference Rodger Shepherd's Article ""Log Spiral"" Devices, JOS Vol 9, no. 1 4) Has a spiral C scale and A, T, T2, S, S2, LN scales"<center><b>Image 1</b></center><p><img src="https://osgalleries.org/collectors/davis/weemsandplath/images/2910a.jpg"></p><center><b>Image 2</b></center><p><img src="https://osgalleries.org/collectors/davis/weemsandplath/images/2910b.jpg"></p></div>]]>
            </description>
            <link>https://osgalleries.org/collectors/davis/info_and_image.cgi?string1=weemsandplath&amp;string2=2910</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360450</guid>
            <pubDate>Wed, 09 Dec 2020 16:36:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Old Are These Keys?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25360323">thread link</a>) | @breck
<br/>
December 9, 2020 | https://breckyunits.com/how-old-are-these-keys.html | <a href="https://web.archive.org/web/*/https://breckyunits.com/how-old-are-these-keys.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://breckyunits.com/files/keyboard/"><img src="https://breckyunits.com/files/keyboard/screenshot.png"></a></p>

<p>One of the questions I often come back to is this: how much of our collective wealth is inherited by our generations versus created by our generations?</p>

<p>I realized that the keys on the keyboard in front of me might make a good dataset to attack that problem. So I built a small little <a href="https://breckyunits.com/files/keyboard/">experiment to explore the history of the keys on my keyboard</a>.</p>

<h2 id="the-five-waves-of-symbols">The Five Waves of Symbols</h2>

<p>Painting with broad strokes, there were approximately five big waves of inventions that have left their mark on the keyboard. The first wave was the invention of the phonetic alphabet letters. The second wave was the Hindu-Arabic Numerals. The third wave was the mathematical punctuation of the Enlightenment period. The fourth wave was the invention of the typewriter. And the fifth and most recent wave was the invention of the personal computer.</p>

<p>I haven’t made any traditional charts yet with this dataset, but you can roughly make out these waves in the interactive visualization by moving the slider around.</p>

<h2 id="concentric-circles">Concentric Circles</h2>

<p>An interesting pattern that I never saw before is how the five waves above are roughly arranged in circles. The oldest symbols (letters) are close to the center, followed by the Hindu-Arabic Numbers, surrounded by the punctuation of the Englightenment, surrounded by the keys of the keyboard, surrounded by the recent additions in the P.C. era. Again, painting with broad strokes, but I found that to be an interesting pattern.</p>

<h2 id="standing-on-the-shoulders-of-giants">Standing on the Shoulders of Giants</h2>

<p>All of these waves happened invented before my generation. Almost all of them before any generation alive today. The keyboard dataset provides strong evidence that most of our collective wealth is inherited.</p>

<h2 id="build-notes">Build Notes</h2>

<p>I got this idea last week and couldn’t get it out of my head. Yesterday I took a quick crack at it. I didn’t have much time to spare, just enough to explore the big ideas. I started by typing all the characters on my keyboard into a Tree Notation document. Then I dug up some years for a handful of the symbols. Then I found the great Apple CSS keyboard. I stitched together the two and it seemed to be at least mildly interesting so I opted to continue. I then flushed out most of the dataset. Finally I played around with a number of visualization effects. At first I thought heatmaps would work well, and tried a few variations on that, but wasn’t happy with anything. I posted my work-in-progress to a few friends last night and called it a day. Today I switched to the “disappearing keys” visualization. That definitely felt like a better approach than the heatmap. I made the thing as fun as I could given time constraints and then shipped.</p>

<p>Published 2/25/2020</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://breckyunits.com/how-old-are-these-keys.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360323</guid>
            <pubDate>Wed, 09 Dec 2020 16:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to model your data in a visual tool]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25360319">thread link</a>) | @vivek9209
<br/>
December 9, 2020 | https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          <p>In this post, I will guide you through the steps needed to design your database schema using TerminusDB 4.0 Console and its model builder.</p>

<p>Having your data in the right format makes it easier to analyze the data properly but you can model your data in more than one way. This is a reality for all the databases, so how to make the right decision?</p>

<p>The model builder is a tool that lets you visualize and edit your database schema. It is very useful for designing and understanding complex data models.
I’ll show you how you can start from a simple model and build out something more complex in no time.</p>

<p>if you have never used TerminusDB before, this article includes everything you need to get started with TerminusDB. <a href="https://terminusdb.com/blog/2020/09/01/my-first-terminusdb-3-0-graph-bike-share-data/">My First TerminusDB Graph Visualisation — Bike Share Data</a>.</p>

<hr>

<h3 id="the-dataset">The Dataset</h3>

<p>In our examples we use the collection of data about the bike journeys between stations in Washington D.C., USA.</p>

<p>We have used this data in other blogs, where with woql.js, a javascript layer that help you to compose <a href="https://terminusdb.com/docs/reference/server/woql/"><strong>WOQL query</strong> (Web Object Query Language)</a>, we have created our database scheme.</p>

<p><img src="https://terminusdb.com/blog/assets/images/bike_table.png" alt="data about the bike journeys between stations in Washington D.C"></p>

<p>The CSV data used this tutorial is available at <a href="https://terminusdb.com/t/data/bike_tutorial.csv">https://terminusdb.com/t/data/bike_tutorial.csv</a></p>

<hr>

<h3 id="how-do-i-model-my-schema-using-the-model-builder">How do I model my schema using the model builder?</h3>

<p>I assume you already have TerminusDB and Console running in your system 
and you have created a db named <strong>myBikes</strong>.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-02.png" alt="Go to model builder"></p>

<p>Form the <strong>myBikes</strong> main page.</p>

<ol>
  <li>Select the menu <strong>Schema-&gt;Schema Builder</strong> to arrive at the model builder interface.</li>
  <li>In the whiteboard select the node <strong>myBikes Schema</strong>, the list of all available node types will show up.</li>
</ol>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-03.png" alt="See the whiteboard"></p>

<p>Let’s see the different nodes in detail.</p>

<p><strong>Object</strong> contains a piece of the graph and can be accessed by a unique url.
An Object can have multiple properties and can be contained inside other objects.</p>

<p><strong>Document</strong> is a special type of Object. Documents are always top-level objects, never embedded inside other objects, using the Link Property you can link documents to each other.</p>

<p><strong>Enum</strong> or Enumerated is a special data type that enables a property to be a set of predefined constants. The property must be equal to one of the values that have been predefined for it. To use this set of values you’ll need to create an Enum Property and link it to an Emun Element.</p>

<p>Let’s use these elements in practice.</p>

<hr>

<h3 id="add-nodes">Add Nodes</h3>

<p>For storing our data we have to create 3 different Documents  <strong>Bicycle</strong>, <strong>Station</strong> and <strong>Journey</strong></p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-04.png" alt="Node List"></p>

<p>Follow the steps and start to build your schema graph.</p>

<ol>
  <li>Select the <strong>myBikes Schema</strong> node in the whiteboard and click the + icon</li>
  <li>Select <strong>Add Document</strong> from the menu. A new node will be added under the node <strong>Documents</strong></li>
  <li>We start to add <strong>Bicycle</strong> Document. Fill the form in the right sidebar with the data from the image above. (Unique Id:Bicycle..)</li>
  <li>Follow the same steps above for adding the other Documents <strong>Station</strong> and <strong>Journey</strong></li>
  <li>Click on the <strong>Save</strong> icon button in the tools bar to save your work.</li>
</ol>

<p><strong>At this point our documents are completely unrelated.</strong></p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-05.png" alt="Documents"></p>

<hr>

<h3 id="add-properties">Add Properties</h3>

<p>To descrive your Documents and to link them with each other, we need to add properties to our documents.
We have various different type of properties identified by datatypes</p>

<p>DataProperty : String/Numeric/Geo/Temporal Property refers to the format of data storage</p>

<p>ObjectProperty : Enum/Link Property refers to a relationship between elements</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-06.png" alt="Property list"></p>

<p>Let’s add the property <strong>start_station</strong>.</p>

<ol>
  <li>Select the node <strong>Journey</strong> in the whiteboard, in the right panel click on the <strong>Properties</strong></li>
  <li>In the properties panel, click <strong>Add Property</strong> in the pop up menu you can see the list of the available property types.</li>
  <li>Select <strong>Property Link</strong> after the form shows up, fill the fields with the value reported in the table above (Unique ID/Label/Description).</li>
  <li>Click on the <strong>Link to Type</strong> menu and Select <strong>Bike Station</strong> 
  <em>Links to Type is a list with all the node that you can linked</em></li>
  <li>Follow the step 1 to 4 for adding the others properties <strong>end_station</strong>, <strong>journey_bicycle</strong></li>
</ol>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-07.png" alt="Property start_station"></p>

<ol>
  <li>Click on the <strong>Save</strong> icon button in the tools bar to save your work.</li>
  <li>Select <strong>Relationships</strong> in the right panel top bar to see the links.</li>
</ol>

<p><strong>We have created our relationship beetween Documents.</strong></p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-08.png" alt="Property start_station"></p>

<hr>

<h3 id="schema-evolution-and-compatibility">Schema Evolution and Compatibility</h3>

<p>An important aspect of data management is schema evolution. 
My initial schema is defined, but my application now need to change it, what can I do?</p>

<p>Let’s see.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-09.png" alt="Property start_station"></p>

<p>Now we need to model the Document <strong>Station</strong> as Object, so we have to delete the Document <strong>Station</strong> and create a new node type.</p>

<p>The database doesn’t allow you to delete a node if it is related with another node.
More precisely the node can not have children and it can not be the range of a Link Property/Enum 
Property.
This constraint is used to prevent actions that would destroy the integrity of the data model.</p>

<hr>

<h3 id="delete-a-node">Delete a Node</h3>

<p>Here the step for doing this.
First we have to remove all the relationship related to our node.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-10.png" alt="Property start_station"></p>

<ol>
  <li>Select the Document <strong>Journey</strong> node in the whiteboard, in the right panel Select <strong>Properties</strong>. the list of the properties will show up.</li>
  <li>Select <strong>End Station</strong> Property and delete it using the red delete icon.</li>
  <li>Follow the above steps for deleting <strong>Start Station</strong> Property too.</li>
  <li>All the <strong>Station</strong> node constraints have been removed</li>
  <li>Select the <strong>Station</strong> node in the whiteboard, in the right panel, Click the delete red icon.</li>
</ol>

<p>Deleting a node is easy at this stage because we don’t have any data in the database.</p>

<hr>

<h3 id="add-an-object-type">Add an Object Type</h3>

<p>Now we add the <strong>Station</strong> node as Object Type.</p>

<ol>
  <li>Select the <strong>Schema myBikes</strong>, click on the + icon, from the menu Select <strong>Add Object</strong> a new node will be add in the whiteboard.</li>
  <li>As we did before we have to add the Unique ID/Station and the Label/Description Bike Station in the fields in the right panel.</li>
  <li>Select the Node <strong>Journey</strong> and add the Link Property <strong>Start Station</strong> <strong>End Station</strong> again (Follow the add property steps above).</li>
</ol>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-11.png" alt="Property start_station"></p>

<hr>

<h3 id="difference-between-object-and-document-types">Difference between Object and Document Types</h3>

<p>The difference in Linking a Property to a Document than a Object is in how this data will be represented and managed in document form.</p>

<p>Here is an example with bike data</p>

<p>If <strong>Station</strong> is a Document Type you have to create a <strong>Station</strong> Document <br>
and link the id of the Document <strong>Station</strong> with the <strong>Journey</strong> Document</p>

<p>This means that if you remove one <strong>Journey</strong> Document 
it removes the link but not the data in the related <strong>Station</strong> document.</p>

<p>If, on the other hand, the <strong>Station</strong> is an Object Type, its data will be embedded in the <strong>Journey</strong> Document 
So if you remove one Journey Document entry it will be remove the related <strong>Station</strong>
Object.</p>

<hr>

<h3 id="add-an-enum-node">Add an Enum Node</h3>

<p>We continue our Schema evolution by adding the <strong>Type Bike</strong> enum node</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-12.png" alt="Property start_station"></p>

<ol>
  <li>Select the <strong>Schema myBikes</strong>, Select the + icon, from the menu Select <strong>Add Enum</strong></li>
  <li>The Enum node will be added in the whiteboard</li>
  <li>Fill the fields in the right panel (Unique Id:Bike_Type..)</li>
  <li>Select values, Fill the fields and click the button <strong>Add a value</strong> for adding the list of possible values</li>
</ol>

<hr>

<h3 id="link-the-enum-node-with-the-enum-property">Link the Enum Node with the Enum Property</h3>

<p>We are going to create our Enum property for the <strong>Bicycle</strong> Documents</p>

<ol>
  <li>Select the <strong>Bicycle</strong> node</li>
  <li>In the right panel, Select the <strong>Properties</strong> tab</li>
  <li>Select the <strong>Add Property</strong> menu and Click <strong>Enum Property</strong></li>
  <li>Fill the Property fields in the Property panel (Unique ID:bicycle_type ….)</li>
  <li>From the <strong>Enum Type</strong> menu Select <strong>Bike Type</strong></li>
</ol>

<p>We said that the property <strong>Bicycle Type</strong> in <strong>Bicycle</strong> Document is a string with a value chosen from a list of permitted values.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-13.png" alt="Property start_station"></p>

<hr>

<h3 id="add-children">Add Children</h3>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-14.png" alt="Property start_station"></p>

<p>We are going to add other elements to create a more complex hierarchy</p>

<p>At this point in our project we need to add information about the bike user, we suppose we can have 2 types of user that rent the bike, a registered user and a guest user.</p>

<p>First we create an abstract Document <strong>User</strong> for grouping the different type of user.</p>

<p>An Abstract Document is a completely “abstract class” that is used to group related properties.</p>

<p>Abstract Documents cannot be used to create Data directly, you cannot add data in a <strong>User</strong>
Document. An abstract Document can have children, all the children will inherit all the parent’s properties and if the children are not abstract, you can insert data as children.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-15.png" alt="Property start_station"></p>

<p>Let’s see all the steps for creating an abstract document and its children.</p>

<ol>
  <li>Select the <strong>Document</strong> node in the whiteboard, Select the + icon and from the menu that show up, Choose <strong>Add Document</strong>.</li>
  <li>A new node Document will be added.</li>
  <li>In the right panel fill the fields for the new Document (Unique ID:User, Label:Bike User….)</li>
  <li>Check the <strong>Abstract</strong> checkbox.</li>
  <li>Select the tab <strong>Properties</strong>, from the menu <strong>Add Property</strong> Choose <strong>String Property</strong></li>
  <li>The String Property Panel will show up, fill the fields (Unique ID: email, Label:Email)
<img src="https://terminusdb.com/blog/assets/images/schema_builder-16.png" alt="Property start_station"></li>
  <li>Choose <strong>Email</strong> from the <strong>String Type</strong> menu.</li>
  <li>In the <strong>Cardinality Min</strong> field add 1 (this means that if you add an User Document, the email property must have a value in it).</li>
</ol>

<p><em>we added the Abstract <strong>User</strong> Document with its properties, now let’s add the children.</em></p>

<ol>
  <li>Select the node <strong>Bike User</strong> in the whiteboard, Click on the + icon, from the menu Select <strong>Add Child</strong></li>
  <li>A new Node will be added, in the right panel fill all the fields (Unique Id:Guest ….)</li>
  <li>Follow the above steps for add the <strong>Member</strong> Document too</li>
</ol>

<p>We can decide to not add new properties in the Guest document so the guest user will be identified by the email, but for the <strong>Member</strong> Document we need to add at least the String property Password.</p>

<p>We have to create a Link Property <strong>Bicycle User</strong> in the <strong>Bike Journey</strong> Document for link the <strong>User</strong> Document with the <strong>Bike Journey</strong> Document.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-17.png" alt="Property start_station"></p>

<hr>

<h3 id="add-a-parent">Add a Parent</h3>

<p>At this point of our project we want to reorganize our nodes.</p>

<p>We have to create an element that can be <strong>a Parent</strong> for an Object node and a Document node. 
Objects can only be children of Object types, Documents can be children of Object Types and Document Types, so we have to create a <strong>New Object Node</strong></p>

<p>We can call this node <strong>Entity</strong>. The <strong>Entity</strong> node is abstract and has a Geo Property  <strong>Position</strong></p>

<p>I am sure you already know all the steps for doing this 😊.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-18.png" alt="Add Parent"></p>

<p>Let’s group <strong>Bike Station</strong> and <strong>Bicycle</strong> under this new node.</p>

<ol>
  <li>Select the node <strong>Bicycle</strong> in the whiteboard, in the right panel Select <strong>Relationships</strong></li>
  <li>Under <strong>Add/Remove Parents</strong> panel from the menu …</li></ol></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/">https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/</a></em></p>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360319</guid>
            <pubDate>Wed, 09 Dec 2020 16:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Online News Isn't Sustainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25360153">thread link</a>) | @jaredwiener
<br/>
December 9, 2020 | https://blog.nillium.com/news-was-never-meant-for-social-platforms/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/news-was-never-meant-for-social-platforms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="News was never meant for social platforms">
            </figure>

            <section>
                <div>
                    <p>Yesterday, my cofounder wrote a <a href="https://blog.nillium.com/its-time-to-remove-news-from-facebook-and-google/">controversial post on this blog</a>, presenting a case for news publishers to limit -- or remove -- their reporting from Facebook and Google. &nbsp;The responses were immediate and plentiful, but fascinatingly different depending on the audience.</p><p>On Hacker News, a tech- and startup-focused forum, the link rose to the top of the list before being “flagged” and removed from the front page. &nbsp;The<a href="https://news.ycombinator.com/item?id=25249414"> comments there</a> took a more pragmatic, technical approach to the problem, from “<a href="https://news.ycombinator.com/item?id=25249553">The technical capability already exists in the form of robots.txt and the referer header,</a>” to constant reminders that news organizations <em>need</em> this traffic.</p><p>On the <a href="https://www.reddit.com/r/Journalism/comments/k3kmg9/its_time_to_remove_news_from_facebook_and_google/">r/journalism subreddit</a>, we were hit from the other side. &nbsp;Why not just “<a href="https://www.reddit.com/r/Journalism/comments/k3kmg9/its_time_to_remove_news_from_facebook_and_google/ge3zqq2/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">nationalize the press so we can quit with the hand-wringing</a>?” suggested one commenter, while another lamented that “<a href="https://www.reddit.com/r/Journalism/comments/k3kmg9/its_time_to_remove_news_from_facebook_and_google/ge51kko/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">this idea disenfranchises young journalists who don’t have any name credibility and recognition and need an established platforms [sic] gravitas to help establish them</a>.”</p><p>If ever there was a good illustration of the disconnect we face in trying to make journalism sustainable again, this is it. &nbsp;The tech side that constantly proclaims “information wants to be free,” and sees pay-for-journalism as a solved problem through Substack, and the jaded newsroom audience who sees another tech platform trying to come in and get them financially hooked.</p><p>The problem, of course, is that it is not a problem equally felt across these camps. &nbsp;The Hacker News crowd is absolutely correct when they say that news organizations need the traffic coming from social media and aggregators -- they do! -- but that is a sign of addiction, not a healthy ecosystem. &nbsp;And the journalist demographic has every reason to assume the worst, because they have been hurt before.</p><p>The economics of this are simple. &nbsp;</p><p>A few decades ago, people subscribed to newspapers, written on paper, that were delivered every morning. &nbsp;The subscription fee never fully covered the cost of running a newspaper; ads appeared between articles, and that subscription base guaranteed an audience for the sponsors. &nbsp;These publications naively started putting their articles online for free -- if advertising could buoy their business up until this point, why would the web be any different? &nbsp;As the ad market matured, CPMs increased, and slowly, internet advertising started to represent real money.</p><p>But then things went viral. &nbsp;Lots of things. &nbsp;People started sharing news articles they read (or <a href="https://www.washingtonpost.com/news/the-intersect/wp/2016/06/16/six-in-10-of-you-will-share-this-link-without-reading-it-according-to-a-new-and-depressing-study/%20Show%20less">didn’t read</a>) on social media. &nbsp;Tech companies tweaked their sorting algorithms to get content to eyeballs -- and did so incredibly successfully. But, this created our first problem.</p><h3 id="problem-1-hard-news-doesn-t-trend">Problem 1: Hard news doesn't trend</h3><p>Admittedly, this is only a problem depending on what side of the fence you sit.</p><p>If your goal -- like that of any number of tech companies -- is to get content in front of your users that they will engage with -- then this has been an unmitigated success. &nbsp;However, if you are reporting out a story for a specific audience, not being able to reach them is problematic. &nbsp;</p><p>At this point, the tech side may wonder why if your articles are so great, the audience isn’t seeking it out. &nbsp;The answer, I suspect, is that the audience does not know it is there.</p><p>Virtually any digital editor will tell you that most traffic bypasses the homepage. &nbsp;Users rarely think &nbsp;“I wonder what is happening today?” and seek out the news site; rather, they are told what is happening by the sorting algorithms and walk away feeling like they are updated. &nbsp;That works to a degree, except that hard news -- especially local news -- does not trend.</p><p>No one shares the summary of last night’s city council meeting. &nbsp;Even the most damning investigative report will only get so far if it is focused on a small area; users outside the area just won’t amplify it.</p><h3 id="problem-2-fake-news">Problem 2: Fake News</h3><p>What <em>does</em> trend? &nbsp;The outrageous, crazy things that you want to share with the world. &nbsp;Of course, that’s not to say all viral headlines are fake, but at this point it seems pretty well accepted that many are.</p><p>Because anyone can write and post anything, these wholly fabricated, or hyper-partisan stories are usually placed in the same regard as those that are rigorously reported and fact-checked. They are then forced to compete against each other for attention.</p><p>Worse yet, these posts can be so malignant that it impugns the reputation of “the media” -- because now you cannot believe what you read.<br></p><h3 id="problem-3-clickbait">Problem 3: Clickbait</h3><p>How do you compete then? &nbsp;By stooping lower. &nbsp;It means publishers resort to writing clickbait headlines to grab a second or two of user attention, and then covering the article page in more clickbait links to keep them there. &nbsp;</p><p>It can even creep into the editorial decisions: Knowing what people are searching for or clicking on can shape what reporters are assigned. <br></p><h3 id="problem-4-all-the-ads">Problem 4: All the ads</h3><p>Why do drivers in your area need to know about that new law? &nbsp;What celebrity finally “broke [their] silence?” &nbsp;I <em>know</em> I won’t believe what happens next. &nbsp;</p><p>These ads are annoying. These ads are detrimental to the user experience that any publication wants. &nbsp;But these ads are needed -- they are a symptom of the addiction. &nbsp;When the flow of users becomes constricted, these organizations have no other choice but to exploit their traffic for as much as it is worth; it’s survival.</p><p>Those ads in between articles in the print newspaper? &nbsp;They still exist, but they are now sold by Facebook, Twitter, and Google. &nbsp;Money is still being made off of the reader, it just is not going to the people doing the reporting. &nbsp;And partnerships between newsrooms and tech giants are generally for big, national outlets, leaving the local newsroom to suffer.</p><h3 id="problem-5-brain-drain">Problem 5: Brain drain</h3><p>As awful as this all is for the casual news consumer, it is worse for the people working on it all day everyday. &nbsp;No one wants assignment-by-SEO. No one wants the ads all over the place. And most of all, no one wants the layoffs. &nbsp;So those that can are fleeing to Substack, or creating their own publications.</p><p>That is great for them, and I wish them all the best. &nbsp;But as that Reddit commenter pointed out, that only works for reporters who have made a name for themselves. &nbsp;It is much more common to follow someone because you like their ideas than someone who you think reports out a story well. &nbsp;</p><p>What about all of those wide eyed, young, idealistic reporters <em>looking </em>to make a name for themselves? &nbsp;What about all of the important stories <em>they</em> are covering? &nbsp;Will now fewer people go to the legacy publications once the big names jump ship?<br></p><h3 id="what-we-re-doing">What we're doing</h3><p>This is why Xana wrote what she did, and made the case firms should pay up. &nbsp;First, it got your attention enough to rise above the noise (a requirement, as discussed above). And it also presented this point: The traffic coming from big tech, while needed for local news’ survival, is also killing it. The answer cannot be found in robots.txt -- it comes from rethinking the model of how we find our users, and how we interact with them.</p><p>Forth is our answer. &nbsp; </p><p>We want to take what is appealing about discovering news on social, and replicate it, but with reporters we know and trust. &nbsp;We want to help them build personal brands because we know younger generations tend to trust real people over companies or institutions (think: influencers). &nbsp;We want to rev-share, not because we think it is a selling point, but to align our incentives with those of the newsrooms; we both succeed together.</p><p>We will be launching soon in markets where we feel we have enough reporters to make using our app worthwhile. &nbsp;If you are a reporter or represent a newsroom, we would love to hear from you at <a href="mailto:hello@nillium.com">hello@nillium.com</a>. &nbsp;If you want to read what our partners are writing, please sign up for the <a href="https://www.forthapp.com/list.html">waiting list</a> -- we will let you know as soon as we are live in your area.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.nillium.com/news-was-never-meant-for-social-platforms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360153</guid>
            <pubDate>Wed, 09 Dec 2020 16:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Goodbye to CentOS]]>
            </title>
            <description>
<![CDATA[
Score 179 | Comments 153 (<a href="https://news.ycombinator.com/item?id=25359951">thread link</a>) | @notadeveloper
<br/>
December 9, 2020 | https://www.clementchiew.me/blog/blog-013 | <a href="https://web.archive.org/web/*/https://www.clementchiew.me/blog/blog-013">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<hr>
<header>
		
</header>

<p>The traditional CentOS Linux distribution as we know it is dead. Here is another drop in the ocean of opinion pieces that follow the news of its death. After cooling down from the initial rush of blood to my head, here is my take on this event.</p>

<h2>Why Did This Probably Happen</h2>
<p>With the advent of DevOps and SRE, businesses and startups are moving away from the old-school concept of traditional server clusters to running their applications on disposable containers. The trend is clear and true. Developers are increasingly less reliant on a tried-and-true Linux distribution that lasts for a decade. With containers, developers can develop, test, deploy, and rollback with blazing fast velocity.

</p><h2>How It Will Affect All of Us</h2>
<p>Without a doubt one of the most popular Linux distributions to ever exist, CentOS was prevalent among all kinds of computing systems ranging from simple database servers to billion-dollar computer clusters. There are countless organizations have made the business decision to keep using the traditional model, or organizations that do not require microservices at all. With CentOS drawn from below their feet, a lot of organizations will be forced to migrate to another option, or fork out a pretty penny for RHEL. Besides, on-prem deployment of any container orchestration tool still requires a stable Linux distribution.</p>

<p>The second ripple effect it will have is towards the skilled professionals who have spend decades on CentOS. Not every company is willing to pay up for RHEL or risk using CentOS Stream. For those who migrate to Debian or OpenSUSE, they will have to retrain and adapt with different tools.</p>

<h2>Questioning IBM/Red Hat Decisions</h2>
<p>The most obvious of them all was, was it necessary for CentOS to die? With CentOS Stream to track ahead of RHEL, it is still possible for CentOS to remain functional and serve its purpose. This is clearly a business decision to increase profits. It used to be that developers wanted to write for RHEL but did not want pay for it; CentOS filled that need. What also happened was that some companies decided that they wanted the free experience all the way. Red Hat now provides free use of the Red Hat Universal Base Image for developers. With this, companies no longer have an excuse.</p>

<p>Secondly, why the PR disaster? In hindsight, there is no way to deliver this news gently to the public. However, I felt that Red Hat gave the bird to the open source community, especially those who contributed to CentOS, by pulling the plug on Centos 8 towards the end of 2021. There wasn't even a courtesy to end it later then CentOS 7's EOL date, June 30th 2024. A raw-dogged "Pay up, now" to everyone. </p>

<p>Last of all, what is the next move from Red Hat/IBM? With CentOS gone, there is a huge vacuum for another to take its place. RHEL sources are still available and can still be repackaged. While Red Hat currently has massive influence over Linux in general, is this a arrogant statement proclaiming "Hey, you can't live without me"? Another ominuous take with conspiratorial undertones would be that Red Hat plans to eventually scrap the FOSS model, but I would have to wear my tin hat for this one.

</p><h2>So, What Happens Now?</h2>
<p>Almost immediately after the release, all the attention is now directed to towards filling the space that CentOS will leave behind. Undoubtedly, Ubuntu and SUSE would try to assert their presence with their open source alternatives. Debian, the largest behemoth of them all, hopefully will receive funding and participation like never before. A silver lining of this event would perhaps be the buzzing excitement of what will be and can be. It is time to be excited about Linux again. I, for one, have to begin migrating my CentOS containers and virtual machines to Debian.</p>

<p>CentOS's founder, Gregory Kurtzer, is working with the community to establish Rocky Linux. Join them at https://webchat.freenode.net/#rockylinux .</p>
<hr>
<blockquote>
I doubt that the imagination can be suppressed. If you truly eradicated it in a child, he would grow up to be an eggplant.
<br>
- Ursula K. Le Guin
</blockquote>
</div>]]>
            </description>
            <link>https://www.clementchiew.me/blog/blog-013</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359951</guid>
            <pubDate>Wed, 09 Dec 2020 15:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elm, Meet Streamlit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25359906">thread link</a>) | @kantuni
<br/>
December 9, 2020 | https://blog.streamlit.io/elm-meet-streamlit/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/elm-meet-streamlit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2020/12/Version3-1.gif 300w,
                            https://blog.streamlit.io/content/images/size/w600/2020/12/Version3-1.gif 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2020/12/Version3-1.gif 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2020/12/Version3-1.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2020/12/Version3-1.gif" alt="Elm, meet Streamlit">
            </figure>

            <section>
                <div>
                    <p>Let me start this article by saying - I love Elm!</p><p>I enjoy learning new programming languages, and Elm has been my favorite language for almost 2 years now. I like everything about it - compiler error messages, type system soundness, <a href="https://guide.elm-lang.org/architecture/" rel="noopener noreferrer">The Elm Architecture</a>, pure functions, immutability, performance, etc. Around the time I discovered Elm, I got a job at <a href="https://www.streamlit.io/" rel="noopener noreferrer">Streamlit</a>, and I immediately saw the potential for how Elm and Streamlit could work together to supercharge apps. With the release of the Streamlit components architecture earlier this year, this was finally possible, and I'm excited to show you how! To get a taste, check out this awesome Elm <a href="https://terezka.github.io/line-charts/" rel="noopener noreferrer">line charts</a> library embedded into a Python <a href="https://share.streamlit.io/kantuni/streamlit-elm-chart/app.py" rel="noopener noreferrer">data app</a>.</p><p>Before we start, if you're new to Streamlit and would like to learn more about it - check out these two articles "<a href="https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace?sk=f7774c54571148b33cde3ba6c6310086">Intro to Streamlit</a>" and "<a href="https://blog.streamlit.io/introducing-streamlit-components/">Intro to Streamlit components</a>".</p><h2 id="ready-player-one">Ready Player One</h2><p>Here's the "<a href="https://guide.elm-lang.org/">Hello World</a>" of Elm examples:</p><pre><code>
import Browser
import Html exposing (Html, button, div, text)
import Html.Events exposing (onClick)

main =
  Browser.sandbox { init = 0, update = update, view = view }

type Msg = Increment | Decrement

update msg model =
  case msg of
    Increment -&gt;
      model + 1

    Decrement -&gt;
      model - 1

view model =
  div []
    [ button [ onClick Decrement ] [ text "-" ]
    , div [] [ text (String.fromInt model) ]
    , button [ onClick Increment ] [ text "+" ]
    ]

</code></pre><p>It is a simple counter app that demonstrates the simplicity, robustness, and beauty of The Elm Architecture. </p><p>We're going to build a Streamlit app that will use the above example as a Streamlit component. Streamlit components let you expand the functionality provided in the base Streamlit package. You can use Streamlit components to share any web-based UI, widget, or data visualization code with the broader Python data science community.</p><p>Creating a Streamlit component takes - literally - 2 lines of Python.</p><pre><code>
import streamlit as st
import streamlit.components.v1 as components

counter_component = components.declare_component(
    "counter",
    url="http://localhost:3000/",
)

count = counter_component(key="count", default=0)
st.markdown(f"The value of the counter is **{count}**.")

</code></pre><ul><li>We declare a new component by passing the name and the location of the component front-end files (or the URL of your development server).</li><li>We provide the default value for the counter.</li><li>We make sure that the component does not re-render unnecessarily by providing the <code>key</code>.</li></ul><h2 id="brave-new-world">Brave New World</h2><p>To establish a two-way connection between our app and the component, we are going to add <a href="https://guide.elm-lang.org/interop/ports.html" rel="noopener noreferrer">ports</a> to our Elm app.</p><p>To send a message from Elm to Streamlit, let's define a port that receives a number and produces a command.</p><pre><code>
port fromElm : Int -&gt; Cmd msg

</code></pre><p>We will need to send the new value back to Streamlit on <code>Increment</code> and <code>Decrement</code> events. So let's modify our update function to reflect that.</p><pre><code>
Increment -&gt;
    ( { model | count = model.count + 1 }
    , fromElm (model.count + 1)
    )

Decrement -&gt;
    ( { model | count = model.count - 1 }
    , fromElm (model.count - 1)
    )

</code></pre><!--kg-card-begin: markdown--><h2 id="thereandbackagain">There and Back Again</h2>
<!--kg-card-end: markdown--><p>To send a message from Streamlit to Elm, let's define a port that receives a number and produces a subscription.</p><pre><code>
port fromJS : (Int -&gt; msg) -&gt; Sub msg

</code></pre><p>Firstly, we will define a new message type.</p><pre><code>
type Msg
    = Default Int
    | Increment
    | Decrement

</code></pre><p>Secondly, we will add a handler for that message type to update.</p><pre><code>
Default value -&gt;
    ( { model | count = value }
    , Cmd.none
    )

</code></pre><p>And finally, we will subscribe to the messages on that port.</p><pre><code>
subscriptions : Model -&gt; Sub Msg
subscriptions _ =
    fromJS Default

</code></pre><p>When a message from JavaScript is sent to that port, the <code>Default</code> event will get a number and set the counter value to that number.</p><p>And that's <a href="https://share.streamlit.io/kantuni/streamlit-elm-counter/app.py">it</a>!</p><figure><img src="https://blog.streamlit.io/content/images/2020/12/Screen-Recording-2020-12-08-at-03.30.25-PM.gif" alt=""></figure><!--kg-card-begin: markdown--><h2 id="foundation">Foundation</h2>
<!--kg-card-end: markdown--><p>I hope this tutorial will help you build dazzling components in Elm. I believe there are a lot of incredible Elm packages that would boost the look and feel of Python data apps. To give you an idea, <a href="https://package.elm-lang.org/packages/gampleman/elm-visualization/latest/">elm-visualization</a> would make a fantastic Streamlit Component - and there are many, many more. I'm excited to see more people discover the awesomeness of Elm, and I look forward to seeing what you create!</p><p>P.S. <a href="https://share.streamlit.io/kantuni/streamlit-elm-chart/app.py">Both</a> <a href="https://share.streamlit.io/kantuni/streamlit-elm-counter/app.py">apps</a> are available on GitHub and have been deployed using <a href="https://www.streamlit.io/sharing-sign-up">Streamlit sharing</a>.</p>
                </div>
            </section>

            <div>

                <section>

                    <ul>
                        <li>


                            <a href="https://blog.streamlit.io/author/kantuni/">
                                <img src="https://blog.streamlit.io/content/images/size/w100/2020/12/kantuni.jpg" alt="Henrikh Kantuni">
                            </a>

                        </li>
                    </ul>

                    <section>
                        
                        <p><time datetime="2020-12-08">8 Dec 2020</time>
                            <span><span>•</span> 3 min read</span>
                        </p>
                    </section>

                </section>
            </div>



            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.streamlit.io/elm-meet-streamlit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359906</guid>
            <pubDate>Wed, 09 Dec 2020 15:55:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DAML: A Haskell-Based Language for Blockchain]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25359249">thread link</a>) | @NaeosPsy
<br/>
December 9, 2020 | https://serokell.io/blog/daml-interview | <a href="https://web.archive.org/web/*/https://serokell.io/blog/daml-interview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Digital Asset is a fintech company that helps companies design and run the next generation of business applications. One of their products is <a href="https://daml.com/">DAML</a>, a functional smart contract language.</p><p>While we have already covered Digital Asset in our <a href="https://serokell.io/blog/functional-programming-in-fintech">functional programming in fintech overview</a>, I recently got a chance to talk with Anthony Lusardi, a developer advocate at DAML, and delve deeper into the product. In the interview, we talk about DAML, the benefits and downsides of functional programming languages, and their practical experience while building DAML.</p><p><strong>Hi! Could you shortly explain what DAML is?</strong></p><p>Sure! DAML is an open-source smart contract language with roots firmly planted in Haskell. It’s designed so multiple parties/business entities can perform workflows with high assurances and consistency between parties. So you have this transactional language that is atomic with every update, high level, portable across data persistence backends, and with strongly enforced permissions over who can update data when.</p><p>In more practical terms, imagine you’re managing an operationally complex workflow where multiple different stakeholders (ie. parties) need to see and interact with different parts of the workflow, definitely should not see other parts, and have a complex tree of dependencies. Today implementing such a thing is truly hard to manage with complex access control schemes implemented at a level outside of your program, and substantial difficulties maintaining data privacy. DAML treats these concerns as first-class elements of every class (what DAML calls templates) and thus makes it much easier to implement and manage these types of workflows.</p><p><strong>Why should customers choose DAML over building their project on Ethereum, Tezos, or other public blockchains?</strong></p><p>This really boils down to their needs. If you’re building something that truly needs permissionless, censorship-resistant, and entirely public transactions, then a public blockchain might be a good fit despite what would be substantial tradeoffs for most real-world applications in terms of low data storage, poor privacy, and high cost. DAML, on the other hand, won’t give you a permissionless architecture but will allow you to have high data storage, strong privacy, and significantly lower costs.</p><p>In practice, very few use cases actually need the properties of a permissionless public blockchain. The one that comes to mind for me where a public blockchain is a better fit would be Bitcoin for permissionless value storage/transfer.</p><p>While I think there are some interesting projects on Ethereum, I’m not personally convinced most use cases need Ethereum’s architecture as, with a few exceptions, most have components that in practice are replaceable and centrally administered by their development team. In such cases, these teams are trading off ease of operation for decentralized architectures and really getting neither. That is, of course, open for extensive theoretical debate that is well beyond the scope of this interview :)</p><p><strong>What’s the main thing that separates DAML from other enterprise blockchain platforms like Corda and Hyperledger Fabric?</strong></p><p>DAML applications can be written once and deployed on any supported platform without changing a single line of code. In this way, your code written in DAML is decoupled from the underlying backend allowing for much greater architectural flexibility.</p><p>In fact, DAML actually runs on these platforms (and many others) with a runtime that runs alongside them and uses them for data persistence and consensus. It’ll even run on PostgreSQL. It’s truly platform-agnostic.</p><p><strong>What’s the benefit of basing DAML on functional programming languages like Haskell and Scala?</strong></p><p>Simple. Functional programmers are the best programmers.</p><p>More seriously, though, the language is based on Haskell but has conventions and differences that make it uniquely its own language. The general benefits are a high degree of composability, as anyone who writes in functional languages knows, when your types match your functions and components can easily work together and extend each other. Functional languages are also beneficial for the more distributed applications that DAML is designed for because they reduce bugs and allow for better ensuring that operations will or won’t complete; both of which are big concerns whenever you’re writing a distributed application.</p><p><strong>Are there any features of the language that really help smart contract language development?</strong></p><p>Most definitely. DAML has two features that really help. The first is that all data concerns are laid out in templates and strongly typed. In a lot of ways, these templates are much like classes in imperative languages <strong><em>but</em></strong> they will always do what you expect them to.</p><p>The other feature (and this is really smart-contract specific) is that DAML treats permissions as first-class citizens, so we have observers, signatories, and choices which you can consider respectively akin to UNIX’s <code>rwx </code>permissions. Every template specifies ahead of time who has the authority to read, write, and execute functions on a given instance of that template (what we call a contract in DAML).</p><p><strong>Have you seen any non-technical benefits? ( e.g. is it easier to hire good developers, etc.)</strong></p><p>Reductions in codebase size and operational complexity are definitely benefits. It’s really designed from the ground up to allow developers to focus solely on business logic without having to worry about the backend. These factors, in turn, make DAML applications cheaper to maintain and easier to extend. Basically, all the benefits functional programmers have been touting for a long time.</p><p>One other great benefit is readability. While it takes a programmer to write DAML, many non-programmers can comprehend much of a DAML contract with just a little bit of familiarization. This really comes as a direct consequence of how explicit DAML is about data concerns and permissions. You can check out an example of this readability at <a href="https://beer.woah.xyz/">https://beer.woah.xyz</a>.</p><p><strong>What about downsides? Are there any downsides to choosing a programming language for your project that is not that popular?</strong></p><p>There certainly are, but if you’re reading this blog post, then you probably already use non-mainstream programming languages that are still wonderful and let you get your work done in effective ways that mainstream languages don’t support. Innovation happens at the edges so I think DAML’s benefits in the smart contract space and its enthusiastic and supportive engineers on our forum more than outweigh the tradeoffs.</p><p>Really the biggest concern people have is essentially “if I choose to invest time in learning this language, will it still be there next year?” and for that, the answer is yes. DAML is an open-source language maintained by Digital Asset, which is a company of 140+ people currently and growing. DAML will be here for years to come.</p><p><strong>Do you feel happy about your choice to create an FP language for your project?</strong></p><p>I don’t think you could build a non-functional language that accomplished what DAML does. It’s really a prerequisite for the rest of the stack. So in that sense, yes, and also the decision was made well before I joined Digital Asset.</p><p><strong>If you had to give one tip to customers looking to come into the blockchain/DLT space, what would it be?</strong></p><p>If the app needs you to first buy a token to use it, then run away.</p><hr><p>I would like to thank Anthony for the interview and wish DAML the best of luck in conquering the private blockchain market!</p><p>If you wish to get more details on DAML, go straight to their <a href="https://daml.com/">homepage</a>. You can also follow DAML on <a href="https://twitter.com/damldriven">Twitter</a> for updates and cool blog articles.</p><p>For more interviews with interesting projects in the functional programming space, be sure to check out the <a href="https://serokell.io/blog/interviews">interview</a> section of our blog.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/daml-interview</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359249</guid>
            <pubDate>Wed, 09 Dec 2020 15:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Social media was tool to subvert the powerful. When did it become the other way?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25359045">thread link</a>) | @CapitalistCartr
<br/>
December 9, 2020 | https://restofworld.org/2020/when-humor-becomes-horror/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/when-humor-becomes-horror/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>F</span>eel-good moments are difficult to come by on Twitter in Pakistan. In between the political infighting and trolls, though, there was a brief moment where the ugliness the platform often brings out in people gave way to the app’s potential for humanity.&nbsp;</p>



<p>In October, a Karachi school teacher, Aimun Faisal, tweeted questions from her students about space and space travel. “Do you get scared that your space shuttle might get lost?” one 10-year-old asked. Ms. Faisal tagged NASA and other space agencies in the post, encouraging readers to retweet it and bring it to their attention. <a href="https://gulfnews.com/world/asia/pakistan/nasa-astronauts-scientists-answer-pakistani-fourth-graders-science-questions-on-twitter-1.1602755591289">It worked</a>.</p>



<p>A Canadian astronaut who has flown in a space shuttle twice replied that he wasn’t scared because Earth was nearby, and he could use the stars to find his way. “I felt especially comforted when I flew over home,” <a href="https://twitter.com/Cmdr_Hadfield/status/1316390465277767682?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1316390465277767682%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fgulfnews.com%2Fworld%2Fasia%2Fpakistan%2Fnasa-astronauts-scientists-answer-pakistani-fourth-graders-science-questions-on-twitter-1.1602755591289">he tweeted</a>. “Here’s a photo I took of Karachi — can you find your school?”</p>



<p>It’s the kind of interaction that leads one to believe that perhaps all you need in life is a Twitter account and a heart that still beats. The media ate it up too: Ms. Faisal and her tweet were in all the major newspapers and even on TV. We were gushy over Ms. Faisal; we wished there were more teachers like her.&nbsp;</p>



<p>Just a few weeks later, people were suggesting that Ms. Faisal should go jump into a river or move to another country.&nbsp;</p>



<p>It all turned after — what else? — a series of tweets.&nbsp;</p>



<p>One evening this past September, a woman set out in her car on a motorway outside Lahore, her two children in tow. Motorways in Pakistan are safer than most roads there; they have their own police, who have a reputation, unlike other police units, for being well-dressed and resistant to corruption.&nbsp;</p>



<p>That evening, the woman’s car ran out of fuel. She locked her car doors and made some phone calls, but the rescue service didn’t answer, and she couldn’t get through to her family. By now, it was past midnight. She made more calls and waited for a friend to come pick her up. While she waited, two men emerged from the darkness, broke her car window, and when she fought back, took her children into some nearby bushes. She scrambled to save them, and while she fought, she was gang-raped.&nbsp;</p>



<p>In the pre–social media age, if a rape story ever got more than a couple of column inches on the inside pages of a newspaper, the victim not only had asked for it but, by reporting it and making it public, was asking for something more.&nbsp;</p>



<p>In an interview with the <em>Washington Post</em>, Pakistan’s former president and army chief Pervez Musharraf (now absconded from the country) once said <a href="https://www.washingtonpost.com/archive/politics/2005/09/19/musharraf-denies-rape-comments/5f2e0d4c-5ff2-4273-81e5-878cd59a1744/">Pakistani women get themselves raped so they can get a Canadian visa</a>. He probably thought he was being funny or insightful. When his office denied his having said it, the <em>Post</em> made the audio public. You can hear one of his aides laughing in the background.&nbsp;</p>



<p>Attitudes toward rape haven’t changed much since the Musharraf days, but there was something about the awfulness of a woman trapped with her children on a motorway at night that struck a chord with the Pakistani public. As the news rippled through Twitter, #LahoreMotorwayIncident became a trending hashtag. The details of the crime were so grotesque that, for a few days, it <a href="https://www.bbc.com/news/world-asia-54186609">seemed the nation actually believed that rape was a crime</a> and that the woman hadn’t asked for it.&nbsp;</p>



<p>Pakistan’s traditional and social media go into this kind of outrage cycle when children get raped, or get raped and then killed, which happens more often than one can stomach. There was genuine fury across the country when a 7-year-old girl was raped, strangled, and left in a rubbish heap two years ago. <a href="https://www.dawn.com/news/1439587">Her name was Zainab</a>. On Twitter and Facebook, users argued over whether her rapist and killer should be hanged in public, quartered, doused in acid, or just locked up for life.</p>



<p>After the motorway incident, the usual bloodlust was on display. There were calls for public hangings and for chopping up the culprits. Prime Minister Imran Khan even appeared on a TV interview saying <a href="https://www.cnn.com/2020/09/16/asia/imran-khan-chemical-castration-rapists-intl/index.html">he has been contemplating chemical castration as a punishment for such crimes</a>.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="People protesting in Karachi after the gang rape of a woman on a motorway near Lahore.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Rizwan Tabassum/AFP via Getty Images</span>
			</figcaption>
		</figure>


<p>And while the Lahore rapists were still on the loose, the newly appointed Lahore police chief appeared on one of the nightly news shows during the wall-to-wall media coverage. In effect, he said he was surprised that a mother of two had decided to take the motorway when another road would have sufficed for her journey. And if she had to take the motorway, he went on to ask, couldn’t she at least have checked her gas tank?&nbsp;</p>



<p>Ms. Faisal, the teacher we had fawned over just weeks prior for her tweets about space travel, was outraged. On Twitter, she was one of many to demand the police chief’s resignation, tweeting in disgust at the craven responses to the news she and others were seeing, rhetorical questions as to why the woman had failed to prevent her own assault.&nbsp;</p>



<p>In return, our beloved Ms. Faisal was met with a flood of insults; trolls suggested she leave Pakistan if she had a problem with it. Being stuck on the motorway without gas became an internet meme that small-time politicians and social media trolls lobbed at one another. Somewhere along the way, “Why didn’t she check her petrol tank before leaving her home?” replaced the original question: “What kind of beasts would rape a woman in front of her children?”&nbsp;</p>



<p>How did this horror morph into a meme? Does every one of us carry inside us a bit of General Musharraf, smirking while his aides giggle?&nbsp;</p>



<p>Long before we had social media, Pakistan swam through its sea of miseries on the backs of jokes. The mausoleum of Pakistan’s longest-serving dictator, General Zia’ul Haq, is jokingly referred to as Jaws Square. Guess why? Because, after ruling over us for 11 years, he died in a plane crash, and only his teeth survived.&nbsp;</p>



<p>Jokes back then went viral before we ever began to call them “viral.” You would hear one about the dictator in Urdu in Karachi one day, and the next day in Peshawar, someone would tell you it in Pashto. Jokes eased us out of our terror.&nbsp;</p>



<p>But now the jokes themselves have become the terror. You can make a joke about a dead dictator, or Osama bin Laden becoming fish food, but how do you laugh at a joke about a woman raped in front of her children on the side of the motorway in the dead of night? Jokes were meant to subvert the powerful, not kick the poor to the ground.&nbsp;</p>



<p>For a brief moment, social media in Pakistan made it easy to laugh at despots and oppressors. They answered with troll farms, indoctrinating the youth to be subservient to power. Even in the midst of incidents so nauseating that they capture the attention of our fractured social media, the horrors of which seem undeniable, the trolls find ways to mock and belittle.&nbsp;</p>



<p>In November, another shocking piece of news roiled Pakistan’s social media: A 4-year-old rape survivor told her gut-wrenching story in a video that went viral. It was so harrowing, I couldn’t bring myself to watch it, even for reporting purposes. In another video, also shared widely online, the doctor who treated her after the assault broke down crying.&nbsp;</p>



<p>On Twitter, it’s easy to find redemption in the narrative too. In the middle of the outrage cycle, social media made a hero of the policeman <a href="https://www.gulftoday.ae/news/2020/11/14/pakistani-policeman-uses-own-daughter-as-bait-to-nab-rapists">who had found the girl’s rapist by enlisting his own daughter to lure him</a>. The rapist was killed in a police encounter.&nbsp;</p>



<p>The policeman and his underage daughter were forced to take this extreme step because there were no women officers in his district. The prime minister called to congratulate the man, and his daughter was awarded a million rupees as a prize along with a guaranteed college scholarship.&nbsp;</p>



<p>Ms. Faisal, who by now has endured a litany of abuses online, questioned the collective satisfaction on social media. As proud as we are of the police officer, she tweeted, the story said more about the country’s broken system than it did about heroism. “No police officer should be forced to risk his family to perform his duty,”<a href="https://twitter.com/bluemagicboxes/status/1327209635594588165"> she wrote</a>.</p>



<p>“Tum kabhi khush na hona,” someone tweeted back. “You’ll never be happy.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/when-humor-becomes-horror/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359045</guid>
            <pubDate>Wed, 09 Dec 2020 14:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube to remove content that alleges widespread election fraud]]>
            </title>
            <description>
<![CDATA[
Score 1156 | Comments 2957 (<a href="https://news.ycombinator.com/item?id=25359003">thread link</a>) | @1cvmask
<br/>
December 9, 2020 | https://blog.youtube/news-and-events/supporting-the-2020-us-election | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/supporting-the-2020-us-election">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="-1">
            
  <article>
    
    


<div>

<section>
    
    <div>
      
      
      <p>
        <article>
          Updates to our work supporting the integrity of the 2020 U.S. election.
        </article>
      </p>
    </div>
  </section>
</div>


    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the past weeks and months, we’ve seen people coming to YouTube to learn more about where and how to vote or learning more about a candidate or an issue. We’ve seen news organizations grow their audience. And we’ve seen people turn to YouTube for the latest election results or simply to follow an historic event with the highest voting turnout in over a century in the U.S.&nbsp;&nbsp;</p><p>Our main goal going into the election season was to make sure we’re connecting people with authoritative information, while also limiting the reach of misinformation and removing harmful content. The work here is ongoing and we wanted to provide an update.&nbsp;&nbsp;</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><h2>Removing content that violates our policies</h2><p>Our <a href="https://www.youtube.com/howyoutubeworks/policies/community-guidelines/">Community Guidelines</a> prohibit spam, scams, or other manipulated media, coordinated influence operations, and any content that seeks to incite violence. Since September, we've terminated over 8000 channels and thousands of harmful and misleading elections-related videos for violating our existing policies. Over 77% of those removed videos were taken down before they had 100 views.&nbsp;</p><p>We also work to make sure that the line between what is removed and what is allowed is drawn in the right place. Our policies prohibit misleading viewers about where and how to vote. We also disallow content alleging widespread fraud or errors changed the outcome of a historical U.S. Presidential election. However in some cases, that has meant allowing controversial views on the outcome or process of counting votes of a current election as election officials have worked to finalize counts.&nbsp;</p><p>Yesterday was the safe harbor deadline for the U.S. Presidential election and enough states have certified their election results to determine a President-elect. Given that, we will start removing any piece of content uploaded today (or anytime after) that misleads people by alleging that widespread fraud or errors changed the outcome of the 2020 U.S. Presidential election, in line with our approach towards historical U.S. Presidential elections. For example, we will remove videos claiming that a Presidential candidate won the election due to widespread software glitches or counting errors. We will begin enforcing this policy today, and will ramp up in the weeks to come. As always, news coverage and commentary on these issues can remain on our site if there’s sufficient <a href="https://blog.youtube/inside-youtube/look-how-we-treat-educational-documentary-scientific-and-artistic-content-youtube/">education, documentary, scientific or artistic</a> context.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/MostViewed-Elections-Blog_Lists_AddedBorder.png" alt="most viewed u.s. election-related content">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><h2>Connecting people to authoritative information</h2><p>While only a small portion of watch time is election-related content, YouTube continues to be an important source of election news. On average 88% of the videos in top 10 search results related to elections came from authoritative news sources (amongst the rest are things like newsy late-night shows, creator videos and commentary). And the most viewed channels and videos are from news channels like NBC and CBS.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Election_Results_Blog_437_x_879_1.gif" alt="election results gif">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>We also showed information panels linking both to Google’s election results feature, which sources election results from The Associated Press, and to the Cybersecurity &amp; Infrastructure Security Agency’s (CISA) “Rumor Control” page for debunking election integrity misinformation, alongside these and over 200,000 other election-related videos. Collectively, these information panels have been shown over 4.5 billion times. Starting today, we will update this information panel, linking to the “2020 Electoral College Results” page from the Office of the Federal Register, noting that as of December 8, states have certified Presidential election results, with Joe Biden as the President-elect. It will also continue to include a link to CISA, explaining that states certify results after ensuring ballots are properly counted and correcting irregularities and errors.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Fact_Check_Dominion_voting__Michigan_recount.png" alt="fact check">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>Additionally, since Election Day, relevant <a href="https://blog.youtube/news-and-events/expanding-fact-checks-on-youtube-to-united-states">fact check information panels</a>, from third party fact checkers, were triggered over 200,000 times above relevant election-related search results, including for voter fraud narratives such as “Dominion voting machines” and “Michigan recount.”</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Recommended-Elections-Blog_Lists_AddedBorder.png" alt="most recommended u.s. election-related content">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>Now let’s look at recommendations, one of the main ways our viewers find content. Limiting the reach of borderline content and prominently surfacing authoritative information are important ways we protect people from problematic content that doesn’t violate our Community Guidelines. Over 70% of recommendations on election-related topics came from authoritative news sources and the top recommended videos and channels for election-related content were primarily authoritative news. In fact, the top 10 authoritative news channels were recommended over 14X more than the top 10 non-authoritative channels on election-related content.&nbsp;</p><p>Despite these encouraging results, we recognize there's always more to do. For example, while problematic misinformation represents a fraction of 1% of what's watched on YouTube in the U.S., we know we can bring that number down even more. And some videos, while not recommended prominently on YouTube, continue to get high views, sometimes coming from other sites. We're continuing to consider this and other new challenges as we make ongoing improvements.&nbsp;</p><p>We understand the need for intense scrutiny on our elections-related work. Our teams work hard to ensure we are striking a balance between allowing for a broad range of political speech and making sure our platform isn't abused to incite real-world harm or broadly spread harmful misinformation. We welcome ongoing debate and discussion and will keep engaging with experts, researchers and organizations to ensure that our policies and products are meeting that goal. And as always, we'll apply learnings from this election to our ongoing efforts to protect the integrity of elections around the world.<br></p></div>
      </div>
      
    </div>
  </div>
</section>

      
    

    


<section>
  <article>
    
  </article>
</section>


    
    
  


  </article>


        </div></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/supporting-the-2020-us-election</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359003</guid>
            <pubDate>Wed, 09 Dec 2020 14:50:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steps to Designing Better Data Structures]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358738">thread link</a>) | @todsacerdoti
<br/>
December 9, 2020 | https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/ | <a href="https://web.archive.org/web/*/https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <!--kg-card-begin: html--><p><span><small>Photo by <a href="https://unsplash.com/@alexas_fotos?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexas_Fotos</a> on <a href="https://unsplash.com/t/nature?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></small></span></p><!--kg-card-end: html--><p>As developers, one of the most valuable things we can do before we get to the keyboard and start coding, is to figure out what types of data structures our functions and modules will operate on. Why? As you will see below, when we use the right data structures it becomes much easier to write functions that operate on them, which in turn leads to fun and profit!</p><p>The goal of this article is to show you an example of how to approach coming up with good data structures. We'll do this by comparing three different data structures for a <a href="https://en.wikipedia.org/wiki/Tic-tac-toe">Tic Tac Toe</a> board.</p><p>Here's a sneak peek at them. Which one would you bet your lunch money on?</p><figure><img src="https://monicao.s3.amazonaws.com/blog/2020-11-25/tic_tac_toe_boards_elixir.png" alt="boards"></figure><h2 id="a-quick-real-world-example">A quick real-world example</h2><p>But first, let me describe a problem I ran into in the past. I was building an Elixir/Phoenix application that served as a backend to a React client. One of the API endpoints was designed to serve up a large chunk of the current user's state, because &nbsp; &nbsp;we wanted the React application to be very fast after the initial page load. The initial JSON payload looked something like this:</p><pre><code>{
  "user": {
    "id": 1,
    "full_name": "Bob Dobolina",
    "email": "bob@dobo.inc",
    "projects": [
      {
        "id": 1,
        "name": "Project 1",
        "proofs": [
          {
            "id": 1, 
            "title": "A design proof",
            "comments": [...]
          }
        ]
      }
    ]
  }
}
</code></pre><p>On the user's dashboard we show a list of projects, and that's fairly easy to do with this structure. Where things get hairy, is when we render the page that displays a proof along with the comments for that proof. With this deeply nested data structure it would have been a real pain for the React client to traverse the tree and pull the data for a specific proof. The solution was to flatten this data structure and make look-up by id easier. The data structure had to make sense for the main operation we were performing on it, which was data lookup by id.</p><h2 id="the-three-steps">The three steps</h2><p>The examples below are in Elixir, but the general approach applies to any programming language. Here is the general approach:</p><ol><li>Make a list of the operations you will need to perform on the data structure</li><li>Brainstorm some data structures</li><li>Evaluate each data structure by going over the operations you need to perform on them</li></ol><p>At this stage you want to get a sense of whether or not the code will be easy to write and the performance is OK in terms of CPU and memory usage.</p><p>If you are thinking: "I work on web applications for businesses. What could I possibly learn from a Tic Tac Toe game?", I ask for your patience. The takeaways from this article are very relevant to the algorithmic problems we have to solve in our day-to-day work.</p><h2 id="what-are-the-operations-that-will-be-performed-on-the-board">What are the operations that will be performed on the board?</h2><p>First, let's put together a list of the operations that we will perform on the data structure, because without knowing this, we cannot evaluate if the data structures we're coming up with are any good. There are many ways we could represent a 3x3 board, but which one is a good fit for a Tic Tac Toe board? Well, what are some things we need to do with a Tic Tac Toe board?</p><ul><li>Read and write the value at a given coordinate</li><li>Display the board as a 3 x 3 grid in the terminal</li><li>Check the 8 different positions that indicate a win</li><li>Know if the board is full, so we can see if the game is over</li></ul><h2 id="brainstorm-data-structures-and-evaluate-them">Brainstorm data structures and evaluate them</h2><p>For the rest of the article we will be starting off with this board:</p><pre><code>X _ _
_ O _
_ X _
</code></pre><p>Let's try out some data structures and evaluate the pros and cons.</p><h3 id="first-attempt-nested-tuples-of-rows-and-columns">First attempt: Nested tuples of rows and columns</h3><p>Intuitively, when you think of a 3x3 grid you might think of a matrix or two-dimensional array. One way to implement that in Elixir is by using nested <a href="https://hexdocs.pm/elixir/Tuple.html#content">Tuples</a>.</p><p>Side note: Why not use nested Lists here? For functional data structures, it's recommended to use tuples in situations where the position of a value means something. In this case, the position of the outer tuples represents rows, and the inner tuples represent columns.</p><pre><code>{
  {"X", nil, nil},
  {nil, "O", nil},
  {nil, "X", nil}
}
</code></pre><p>Seems like a good start.</p><p>Let's look at our list of operations and get a sense of how easy it will be to write these as functions.</p><p><strong>Reading and writing the value at a given coordinate.</strong></p><p>It's the second player's turn and they want to write an O in the top corner of the board at row 1, col 3.</p><p>To do this we might write a function like <code>write(board, row: 1, col: 3, move: "O")</code>.</p><p>How would you implement this function?</p><p>Since data structures in Elixir are immutable, it means we have to re-create the tuple for row 1 and re-create the board tuple to return an updated board. This is not hard to do, but it's clunky and the code is not very readable.</p><p>We don't have to write out the function to know that this would be unwieldy to implement.</p><p><strong>Displaying the board as a 3x3 grid</strong></p><p>This seems like it will be pretty straightforward if we flatten the nested tuples into a list and iterate over each element.</p><p><strong>Checking the 8 different positions that indicate a win</strong></p><p>Thanks to Elixir's pattern matching, checking if a board has a winning line is fairly easy to read and implement. For example, if you wanted to check if the middle row has a winning line you could write.</p><pre><code>def find_winner(
  {
    {_, _, _},
    {a, b, c},
    {_, _, _},
  }
) when a == b and b == c and !is_nil?(a), do: a</code></pre><p><strong>Knowing if the board is full</strong></p><p>To check if the board is full we can count up all the free tiles, which are represented as <code>nil</code>:</p><pre><code>def board_full?(board)
  num_free_tiles = board
    |&gt; Tuple.to_list
    |&gt; Enum.reduce(0, fn(row, free_spots) -&gt;
      free_in_row = row |&gt; Tuple.to_list |&gt; Enum.count(&amp;is_nil/1)
      free_in_row + free_spots
    end)
  num_free_tiles == 0
end</code></pre><p>Maybe there's a better implementation here, but so far, the code above is not looking very easy to read and maintain.</p><p>Overall, one of the weaknesses of this data structure seems to be that it is nested and accessing a value requires reading two tuples. Also tuples are not that easy to iterate over as we have to convert them to lists, if we want to use those juicy <code>Enum</code> functions.</p><h3 id="second-attempt-map-with-coordinates-as-keys">Second attempt: Map with coordinates as keys</h3><p>In the tuple data structure our biggest issue seemed to be making it easy to access values at a given row and column. Let's try making that easier by creating a <a href="https://hexdocs.pm/elixir/Map.html#content">Map</a> where the keys are the <code>{row, col}</code> coordinate.</p><pre><code>{
  {1, 1} =&gt; "X",
  {1, 2} =&gt; nil,
  {1, 3} =&gt; nil,
  {2, 1} =&gt; nil,
  {2, 2} =&gt; "O",
  {2, 3} =&gt; nil,
  {3, 1} =&gt; nil,
  {3, 2} =&gt; "X",
  {3, 3} =&gt; nil
}
</code></pre><p><strong>Reading and writing to a position</strong></p><p>This becomes easier with this data structure.</p><p>For reading the item at row 1, column 1 we can simply do a lookup by key:</p><pre><code>%{{1, 1} =&gt; val} = board
</code></pre><p>To update the value at row 1, column 3 we can use <code>Map.put</code>:</p><pre><code>Map.put(board, {1, 3}, "O")
</code></pre><p><strong>Checking the 8 different positions to win</strong></p><p>We can apply the same strategy for reading a single value to reading a group of values. For example, here's what it would look like if we used pattern matching to check if the first row had equal values.</p><pre><code>@doc ~S"""
  Takes in a board and returns either "X" or "O" if there is a winner or nil.
  
  Example
  
  iex&gt; TicTacToe.find_winner(
      {
        {1, 1} =&gt; "X", {1, 2} =&gt; "O", {1, 3} =&gt; nil,
        {2, 1} =&gt; nil, {2, 2} =&gt; "X", {2, 3} =&gt; nil,
        {3, 1} =&gt; nil, {3, 2} =&gt; "O", {3, 3} =&gt; "X"
      }
    )
  "X"

"""
# checks if the first row has the same tile 
def find_winner(%{{1, 1} =&gt; a, {1, 2} =&gt; b, {1, 3} =&gt; c})
  when a == b and b == c and !is_nil(a), do: a # check first row
def find_winner(%{{1, 1} =&gt; a, {2, 2} =&gt; b, {3, 3} =&gt; c})
  when a == b and b == c and !is_nil(a), do: a # check \ diagonal
def find_winner(%{{1, 3} =&gt; a, {2, 2} =&gt; b, {3, 1} =&gt; c})
  when a == b and b == c and !is_nil(a), do: a # check / diagonal
# ... and so on for the remaining 5 cases
def find_winner(_board), do: nil
</code></pre><p>This is easy enough to implement, but the code itself is not all that easy to read, in my opinion. From reading the first clause, it's not that easy to see that it deals with checking if the first row has the same tiles. It's always a bit of &nbsp;a code smell to me when I have to add a comment to explain what a line does. Also, the board itself is not very readable in the doctest, not to mention that when you <code>IO.inspect</code> it in IEx it will be even less readable, because each key will be printed on a new line.</p><p><strong>Displaying the board as a 3x3 grid</strong></p><p>Maps in Elixir are not ordered, <a href="https://stackoverflow.com/questions/40392012/is-ordering-of-keys-and-values-preserved-in-elixir-when-you-operate-on-a-map">even though it seems like they are because IEx displays them in order</a>. This means we can't just iterate over the keys and print out the values.</p><p>To display the board we can use a nested loop of row and column ids and look up the values that way.</p><p>This is not ideal. Let's see if we can come up with something better.</p><h4 id="third-attempt-list-of-positions">Third attempt: List of positions</h4><p>Instead of thinking of the board in terms of rows and columns, what if we think of the board with positions from 0 to 8?</p><pre><code>0 1 2
3 4 5
6 7 8
</code></pre><p>In Elixir, we could use a <a href="https://hexdocs.pm/elixir/List.html#content">List</a> to represent this.</p><pre><code>[
  "X", nil, nil,
  nil, "O", nil,
  nil, "X", nil
]
</code></pre><p>This feels like a better fit than the other two! Are your intuition butterflies fluttering yet? Let's double check this intuition by reviewing the operations.</p><p><strong>Reading and writing to a position</strong></p><p>Instead of saying <em>"Player 1 marked X at row 1 column 3"</em>, we would think of it as <em>"Player 2 marked O at position 2"</em>, which is as simple as <code>List.update_at(board, 2, "X")</code>.</p><p>To check if position 2 has already been taken, it's as easy as <code>Enum.at(board, 2)</code>, which is an O(n) operation, but we don't need to worry about the time complexity for this problem at all, because we are dealing with such a small data set.</p><p><strong>Checking the 8 different positions to win</strong></p><p>Just as with the nested tuple example, checking if there is a winning line on the board we can use pattern matching. Let's say you wanted to check if the second row has all the same numbers:</p><pre><code>[
  _, _, _,
  a, b, c,
  _, _, _
] = board
</code></pre><p>How about a diagonal?</p><pre><code>[
  a, _, _,
  _, b, _,
  _, _, c
] = board
</code></pre><p><strong>Knowing if the board is full &amp; Displaying …</strong></p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/">https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/</a></em></p>]]>
            </description>
            <link>https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358738</guid>
            <pubDate>Wed, 09 Dec 2020 14:24:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How redundant is your dataset?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25358726">thread link</a>) | @isusmelj
<br/>
December 9, 2020 | https://lightly.ai/post/how-redundant-is-your-dataset | <a href="https://web.archive.org/web/*/https://lightly.ai/post/how-redundant-is-your-dataset">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>‍<em>Lots of interesting Deep learning applications rely on the use of complex architectures fueled by large datasets. With the growing storage capacities and ease of data collection [1], it is very easy to build a large dataset. However, when doing so, one ends up with lots of redundancies within the dataset. Many of these redundancies are systematically introduced by the data collection process: consecutive frames extracted from a video, very similar images collected from the web.</em></p><p>‍</p><p><em>In this blog post, we present the results of a benchmark study showing the benefits of filtering redundant data.</em></p><p>‍</p><p>Redundancies can take multiple forms, the simplest one is having exact image duplicates. Another form is near-duplicates, i.e images shifted with few pixels across some direction or images having slight light changes. These redundancies not only lead to biased results of the model’s performance, be it accuracy or mean average precision mAP score, but also lead to high annotation costs. In addition, redundancies have also been observed in very known academic datasets: CIFAR-10, CIFAR-100, and ImageNet [2,3].</p><p><em>This benchmark study investigates the effect of redundancies in the image-based datasets collected by AI Retailer Systems (AIRS), an innovative start-up developing a checkout-free solution for retailers, which concentrates to answer “who picks up what?”. In this study, we consider an object detection task. An intelligent vision system recognizes products on a shelf or on a customer’s hand. This study was done as part of my role as a machine learning engineer at Lightly, a tech-based start-up that provides a solution to improve the Machine Learning workflow by finding and removing redundancies in unlabeled data.</em></p><p>This blog post will be structured as follow, we start by describing the dataset, we list the methods used in this study. We present the results obtained and finally, we discuss the importance of filtering redundant data.</p><p>‍</p><h3>AI Retailer System dataset</h3><figure id="w-node-fb91938a7325-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc116f1e87ac1_1*d-3gi2AuKFbrOm7UnfCIQg.gif"></p><figcaption>Short video sample extracted from AIRS video.</figcaption></figure><p>‍</p><p>The dataset used consists of images extracted from short videos capturing a customer grabbing different products. There are two different cameras recording videos of the shelf, each camera has a different angle of view. There are 12 different kinds of products -12 classes.</p><p>The dataset has been manually annotated using the open-source annotation tool Vatic, we measured the annotation rate: number of frames per time unit. In our case this was 2.3 ± 0.8 frames per minute, given that there are 51 objects on average in each image, this is equivalent to 0.51 seconds for each bounding box.</p><figure id="w-node-16a5839147a8-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc10ddee87ac3_1*Yzs8PZV1FB_MJ5b38ngf-A.png"></p><figcaption>Sample image from Camera 1 with annotations: the box color does not represent the article class.</figcaption></figure><p>‍</p><figure id="w-node-ff8edff111f8-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1e0c0e87ac4_1*_dvPbzOu1xxvWH3otGcalA.png"></p><figcaption>Sample image from Camera 2 with annotations: the box color does not represent the article class.</figcaption></figure><p>‍</p><p>The annotated dataset has 7909 images. The training dataset has 2899 images, 80% of these images are from camera 2 and 20% from camera 1. For the test dataset, it has 5010 images and all of them from camera 1.</p><figure id="w-node-da318627f465-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1f6afe87ad4_1*bI7L8tkO5M0ohX70o-MqYg.png"></p><figcaption>Visualization of the train-test setting for AIRS dataset.</figcaption></figure><p>‍</p><p>This specific design of the train and test datasets was motivated by the following points: First, we build an imbalanced dataset with a high fraction of images coming from one camera. Second, we make the object detection task hard for the model. With this train-test setting, we can calculate the fraction of images from Camera 1 in the filtered data. Therefore, we can see if there is any re-balancing that is introduced by the different filtering methods used.</p><p>Next, we present the methods used in this case study.</p><p>‍</p><h3>Active learning and Sampling methods</h3><p>To probe the effects of filtering the dataset, we borrowed ideas from the field of <strong>Active learning</strong>.</p><figure id="w-node-04f7b8ea6774-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1a186e87ae5_1*OQsiXePTV5fesdkxPB-sIw.png"></p><figcaption>Active learning loop used in this case study.</figcaption></figure><p>‍</p><p>Active learning aims at finding a subset of the training data achieving the highest possible performance. In this study, we used the pool-based active learning loop that works as follows: Start with a small fraction of the training dataset called the labeled pool. Train a model on this labeled pool. Then, use the model along with a filtering method to select new data points that should be labeled. Add the newly selected samples to the labeled pool and finally train the model from scratch on the updated labeled pool. After each cycle, we report the model’s performance on the test dataset for each filtering method used. In our case, we used 5% of the training data as the initial labeled pool, we trained the model for 50 epochs, and we added 20% of the training data in each active learning loop.</p><p>The object detection model used in this benchmark study is YOLO V3 (You Only Look Once) [4]. We used the implementation provided by the Ultralytics Github repository. The code was slightly modified in order to introduce the active learning loop.</p><p>As for the filtering methods, we used four different filtering methods provided by Lightly:</p><ul role="list"><li>“<strong>RSS</strong>”: Refers to random sub-sampling which will be used as a baseline.</li><li>“<strong>WTL_unc</strong>”: This method refers to Lightly uncertainty based sub-sampling, it selects difficult images that the model is highly uncertain about. The uncertainty is assessed using the model’s predictions.</li><li>“<strong>WTL_CS</strong>”: This method uses image representations to select images that are both diverse and difficult. It combines uncertainty-based sub-sampling with diversity selection. The image representations are obtained using state-of-the-art self-supervised learning methods using the PIP package Boris-ml. The advantage of self-supervised learning methods is that they don’t require annotations to generate image representations.</li><li>“<strong>WTL_pt</strong>”: Relies on pre-trained models to learn image representations, the filtering is performed by removing the most similar images. Similarity in this case is given by the L2 distance between image representations.</li></ul><p>Both methods “<strong>WTL_unc</strong>” and “<strong>WTL_CS</strong>” use active learning since they use the deep learning model to decide which data points to filter. Whereas the “<strong>WTL_pt</strong>” method does require neither labels nor a deep learning model to filter the dataset. For curious readers, this article presents a comprehensive overview of different sampling strategies used in active learning.</p><p>‍</p><h3>Benchmark study results</h3><p>We present the results of these experiments below.</p><figure id="w-node-08c3a0c158ed-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc18dece87ae7_1*e7rBEziO4Nc3Ci_SqTlAjQ.png"></p><figcaption>Averaged mAP score for different fractions of the training dataset using 4 seeds.</figcaption></figure><p>‍</p><p>We see that the mAP score is low at small fractions of the training dataset. We observe that mAP score saturates when using only 25% of the training data and reaches a value of 0.8. Above the saturation point, the mAP score increases very slowly until it reaches its highest value of 0.84. The saturation at low fractions of the training dataset indicates that there are lots of redundancies in the dataset.</p><p>We notice that for small fractions, i.e 5%, the “<strong>WTL_CS</strong>” filtering method is significantly better than the random baseline. As for high fractions, i.e 85%, the “WTL_pt” is able to <strong>achieve the same performance achieved when using the full training dataset</strong>. The “<strong>WTL_unc</strong>” method is on par or worse with the random sub-sampling method “<strong>RSS</strong>”.</p><p>Given that the saturation is reached within a small fraction of the training dataset, we perform a “Zoom-in” experiment where we evaluate the model’s performance using fractions of the training dataset between 5% and 25%. In this experiment, we drop the “<strong>WTL_unc</strong>” for its poor performance.</p><figure id="w-node-21c991b3b9ce-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1bf0be87ae9_1*7MHwyOMtGEauLxja2J9LjA.png"></p><figcaption>Zoom-in experiment: Averaged mAP score for different fractions of the training dataset using 4 seeds.</figcaption></figure><p>‍</p><p>We see in the results above that the sampled subsets using “<strong>WTL_CS</strong>” and “<strong>WTL_pt</strong>” methods consistently outperform random sub-sampling. In addition, using only 20% of the training dataset, the “<strong>WTL_CS</strong>” sampling method is able to achieve a mAP score of 0.80. <strong>We achieve 90% of the highest mAP score using only 20% of the training dataset</strong>.</p><p>‍</p><h3>Why “WTL_CS” and “WTL_pt” perform better than random sub-sampling “RSS”</h3><p>To answer this question, we make a simple comparison between the images selected with the “<strong>RSS</strong>” method with the images selected with “<strong>WTL_CS</strong>” and “<strong>WTL_pt</strong>”. For this purpose, we compute the fraction of images from camera 1 in the selected samples for different fractions of the training dataset and for different filtering methods. This comparison is done in both the normal and the zoom-in experiments. Note that in the training dataset, the original fraction of images from Camera 1 is around 20%.</p><p>‍</p><figure id="w-node-75ccc62a0fd7-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1ea99e87aeb_1*lQiGxxeXL_KGcJHNKR1FSQ.png"></p><figcaption>The fraction of Camera 1 images in the sampled images as a function of fraction of the training dataset.</figcaption></figure><figure id="w-node-d81505eb589c-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1624be87aea_1*6qU_7ccA6-ic0C4ZgQWuNg.png"></p><figcaption>Zoom-in experiment: Fraction of Camera 1 images in the sampled images as a function of the fraction of the training dataset.</figcaption></figure><p>‍</p><p>We see that the sampling methods “<strong>WTL_CS</strong>” and “<strong>WTL_p</strong>t” select more samples from Camera 1 and therefore, they re-balance the sub-sampled training dataset. This explains the gain in performance obtained using different samplings other than random sub-sampling. Since both “<strong>WTL_CS</strong>” and “<strong>WTL_p</strong>t” methods select non-redundant data, they choose more images from camera 1, and therefore the sub-sampled dataset is more diverse.</p><p>‍</p><h3>Summary and outlook</h3><p>In this case study, we have seen the importance of filtering the redundancies within a dataset. We have found the following results:</p><ul role="list"><li>The AIRS dataset contains lots of redundant images.</li><li>Achievement of the highest mAP score using only 85% of the training dataset.</li><li>Achievement of 90% of the highest mAP using only 20% of the training dataset.</li><li>Filtering re-balanced the AIRS dataset.</li></ul><p>This benchmark study showed the importance of filtering redundant data. With Lightly filtering methods, it was possible to achieve <strong>annotation costs reductions between 15% and 80%</strong>. We found lots of redundancies in the AIRS dataset even though it was collected in a controlled environment: There is at least one customer in each video and the customer grabbed different products. We expect the redundancies to be more pronounced in a general uncontrolled case where different customers grab products at a supermarket.</p><p>Anas, Machine Learning Engineer,<br>lightly.ai</p><p>‍</p><p>‍</p><p>[…</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lightly.ai/post/how-redundant-is-your-dataset">https://lightly.ai/post/how-redundant-is-your-dataset</a></em></p>]]>
            </description>
            <link>https://lightly.ai/post/how-redundant-is-your-dataset</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358726</guid>
            <pubDate>Wed, 09 Dec 2020 14:23:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Ruby 3 Three Times Faster?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358524">thread link</a>) | @todsacerdoti
<br/>
December 9, 2020 | https://codefol.io/posts/is-ruby-3-actually-three-times-faster/ | <a href="https://web.archive.org/web/*/https://codefol.io/posts/is-ruby-3-actually-three-times-faster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <!-- .post-header -->
            <div>
                  
<figure>
    <p><img src="https://codefol.io/img/RadioRepair_aside_216_162.png" alt="A chalk figure kneeling to repair (possibly) a radio." width="216" height="162" title="We're Still Mid-Upgrade">
    </p>

      <figcaption>
        We're Still Mid-Upgrade
        
        
      </figcaption>
</figure>

                <p>Ruby 3x3 announced that Ruby 3.0 would be three times as fast as Ruby 2.0. It was an audacious goal, especially for <a href="https://en.wikipedia.org/wiki/Ruby_(programming_language)">a language released in 1995</a>.</p>

<p>Ruby 3 is due to be released in less than a month. They’re hard at work on some of the features, but non-JIT performance is pretty close to release speed. If they pull another 5%-10% speed increase at the last minute (which <a href="https://bugs.ruby-lang.org/issues/14104">happened for Ruby 2.5</a>!) it’ll be surprising. The current performance is basically the “real” Ruby 3 performance.</p>

<p>So… Did it happen? Is Ruby 3 really three times the speed?</p>

<p>The answer is a little complicated, but overall it’s “yes.”</p>

<p>Now: let’s hit the <strong><em>real</em></strong> answer and the details. That’s the fun part.</p>

<h2>Who’s This Guy?</h2>

<p>Why listen to me? Well, I wrote <a href="https://github.com/noahgibbs/rails_ruby_bench">one of the two official Ruby 3 benchmarks</a>. I <a href="https://engineering.appfolio.com/appfolio-engineering/2016/6/3/ruby-fellow-hired">worked for AppFolio on Ruby 3</a> for about three years. I keep track of this stuff pretty closely. But mostly I’ll be linking to other posts I wrote for <a href="https://engineering.appfolio.com/">AppFolio</a> and on <a href="https://fastruby.io/blog">FastRuby</a> and maybe elsewhere. They all have open source code. Feel free to check me!</p>

<h2>What’s Performance, Exactly?</h2>

<p>A language doesn’t have one speed. When somebody says “language X is 2.5 times as fast as language Y,” that’s always an approximation. All languages run “sleep” at exactly the same speed, and two of them may use the exact same regexp library. But maybe variable assignment is way faster in one language than another, while the second language is better at optimising away stack variables.</p>

<p>In other words, performance is a million little things that are faster… or they’re slower or they’re the same. We take an average and hand-wave. That’s okay. It’s how humans deal with complicated things.</p>

<p>Benchmarks are all lies because of this. <a href="https://engineering.appfolio.com/appfolio-engineering/2019/1/7/microbenchmarks-vs-macrobenchmarks-ie-whats-a-microbenchmark">Little operations make for dramatic benchmarks, and big operations make (if you’re lucky) representative “workload benchmarks.”</a> We can’t make a benchmark <strong><em>not</em></strong> lie. We can only pick our favourite lie.</p>

<h2>What’s Our Favourite Lie?</h2>

<p>Here are two favourite lies, embodied by my benchmark (Rails Ruby Bench) and <a href="https://twitter.com/mametter">Mame-san’s</a> benchmark, <a href="https://github.com/mame/optcarrot">OptCarrot</a>.</p>

<p>One favourite lie is this: Ruby performance means Rails performance. How is Ruby 3’s Rails performance?</p>

<p>It turns out it <a href="https://www.fastruby.io/blog/rails/performance/ruby/hows-the-performance-of-ruby-3.0.0-preview1.html">hasn’t changed significantly</a> <a href="https://engineering.appfolio.com/appfolio-engineering/2019/12/27/ruby-270s-rails-ruby-bench-speed-is-unchanged-from-260">since Ruby 2.6</a>. It also turns out <a href="https://engineering.appfolio.com/appfolio-engineering/2019/3/7/ruby-speed-roundup-20-through-26">it <strong><em>got far better</em></strong> from Ruby 2.0 to 2.6</a>.</p>

<p>We don’t know the exact final performance of Ruby 3.0. Watch for a benchmark from me in January! But it’s going to look a lot like Ruby 2.6 and Ruby 2.7.</p>

<p>And that means a large Rails app’s performance has increased by over 70% since Ruby 2.0.</p>

<p>Let’s be clear: <strong><em>that’s a lot</em></strong>.</p>

<p>That’s total end-to-end performance to handle HTTP requests in parallel. It uses the same exact Ruby code with the same exact SQL queries, attached to Redis and Postgres and real service with a <a href="https://github.com/discourse/discourse">real big open-source Rails app</a> that people actually use.</p>

<p>In other words, <strong><em>the Ruby part of that performance has increased by a lot more than 70%</em></strong>, because everything that isn’t Ruby is the exact same in my tests.</p>

<p>A lot of a Rails app isn’t Ruby time. It’s waiting for the database. It’s waiting for the disk. The web server is serving static files. A Rails app does a lot of non-Ruby stuff, and it should.</p>

<p>A Rails app wasn’t going to triple in speed. It’s doing too much non-Ruby stuff. Realistically, the Ruby part hasn’t tripled in speed. I don’t have exact numbers, but it would be fair to estimate around 2.5x. It would be very hard to get an accurate only-the-Ruby-parts number, for all kinds of good reasons.</p>

<p>Still, 2.5x is very, very good. Ruby 3.0 will have a big jump in Rails performance, but most people are already using it.</p>

<p>Ractors (a new Ruby 3 concurrency primitive) will also pave the way for later speedups if Rails takes advantage of them. Like threads, it’ll take time and changes to the framework. And right now, <a href="https://www.fastruby.io/blog/ruby/performance/how-fast-are-ractors.html">Ractors’ performance is underwhelming</a>. But they’re also a not-yet-released new feature, so there’s a lot of room to improve.</p>

<h2>Our Other Favourite Lie</h2>

<p>Other than Rails performance, what matters?</p>

<p>One other answer is “straight-line CPU performance on a CPU-intensive benchmark.” And for that we’ll turn to OptCarrot, an <a href="https://engineering.appfolio.com/appfolio-engineering/2017/9/22/optcarrot-an-excellent-cpu-benchmark-for-ruby-3x3">excellent Ruby 3 benchmark</a>. It runs a headless Nintendo (NES) emulator as fast as it can, which is a fun way to measure.</p>

<p>Rails didn’t benefit from <a href="https://engineering.appfolio.com/appfolio-engineering/2019/7/18/jit-and-rubys-mjit">Ruby’s new-ish opt-in JIT system</a>. MJIT is <a href="https://engineering.appfolio.com/appfolio-engineering/2019/7/19/how-mjit-generates-c-from-ruby-a-deep-dive">a complicated beast</a> with interesting trade-offs. If you turn it on then Rails Ruby Bench gets slower, not faster.</p>

<p>But OptCarrot is exactly what MJIT was designed for and it does really well with it.</p>

<p><a href="https://speakerdeck.com/k0kubun/ruby-3-dot-0-jit-on-rails?slide=9">Ruby 3.0 recently hit 3x Ruby 2.0’s performance with JIT</a>. We’re there. Assuming they can keep performance that good for the actual release, Ruby 3.0 manages 3x the frames that Ruby 2.0 did.</p>

<p>The answer, then, is a straightforward “yes.”</p>

<p>Note that JIT does <strong><em>not</em></strong> “make Ruby three times faster.” It’s that Ruby 3.0, which is already a lot faster than Ruby 2.0, is three times as fast <strong><em>as Ruby 2.0</em></strong> with JIT turned on. It’s fast without JIT, but not a full three times the speed of Ruby 2.0.</p>

<p>Make sense?</p>

<h2>What’s the Score, Then?</h2>

<p>It’s been nearly eight years since Ruby 2.0. There have been a lot of performance changes. The generational garbage collection in Ruby 2.4 is <strong><em>hugely</em></strong> faster than the much simpler 2.0 GC. <a href="https://github.com/Shopify/bootsnap">BootSnap</a> has made bootup in Rails far faster. If you remember back to Ruby 1.8.7 in 2008, Ruby has more-than-doubled in speed to Ruby 2.0, and then tripled again for Ruby 3.0. The OptCarrot results are more like 10x from Ruby 1.8.7 to Ruby 3. A 10x speedup in 10 years? Not bad for a language that just turned 25.</p>

<p>It’s been a long trip. And that’s without going into the other two parts of Ruby 3 — concurrency and type safety, both of which are separate major efforts.</p>

<p>Is Ruby 3 really three times the speed of eight-years-ago Ruby? Day-to-day, yes, it absolutely is. The Rails speedup is more like double than triple in practice since a lot of Rails time isn’t Ruby. But double isn’t bad! And CPU-intensive code is now solidly three times the speed.</p>

<p>You can judge the concurrency and type-safety of Ruby 3 for yourself. But <em>I’m going to call the performance goal a solid success</em>.</p>

<p>Sure, we have to wait a month. Ruby 3 will actually be released on 25th December of 2020. But all the signs are good.</p>

<p>You can also play with <a href="https://www.ruby-lang.org/en/news/2020/09/25/ruby-3-0-0-preview1-released/">Ruby 3.0.0-preview1</a> right now, and I’m sure there will be at least one more before the final release.</p>

            </div>
            
        </article></div>]]>
            </description>
            <link>https://codefol.io/posts/is-ruby-3-actually-three-times-faster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358524</guid>
            <pubDate>Wed, 09 Dec 2020 14:04:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NumPy – Ndarray Object]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358495">thread link</a>) | @Eyssant
<br/>
December 9, 2020 | https://www.alphacodingskills.com/numpy/numpy-ndarray.php | <a href="https://web.archive.org/web/*/https://www.alphacodingskills.com/numpy/numpy-ndarray.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  

<hr>

<hr>
<p>Ndarray is the n-dimensional array object defined in the numpy. It stores the collection of elements of the same type. Elements in the collection can be accessed using a zero-based index. Each element in an ndarray takes the same size in memory.</p>
<h2>Create a Numpy ndarray object</h2>
<p>A Numpy ndarray object can be created using <span>array()</span> function. A list, tuple or any array-like object can be passed into the array() function to convert it into an ndarray. The syntax for using the function is given below:</p>
<h3>Syntax</h3>
<div>
<pre>numpy.array(object, dtype=None, copy=True, order='K', subok=False, ndmin=0)
</pre>
</div>
<br><h3>Parameters</h3>
<table>
<tbody><tr><td><code>object</code></td>
<td><code>Required. </code>Specify the collection object to be converted into ndarray. It can be list, tuple, set, dictionary etc.</td></tr>    
<tr><td><code>dtype</code></td>
<td><code>Optional. </code>Specify the desired data type. It is used to change the data type of the array element.</td></tr>
<tr><td><code>copy</code></td>
<td><code>Optional. </code>Specify True to copy the object, False otherwise.</td></tr>
<tr><td><code>order</code></td>
<td><code>Optional. </code>Specify order. It can take four possible values.
<ul>
	<li>'C' - for C order (row major).</li>
	<li>'F' - for F order (column major).</li>
	<li>'A' - unchanged if copy=False. If copy=True, F and C order preserved.</li>
	<li>'K' - unchanged if copy=False. If copy=True, When the input is F and not C then F order otherwise C order.</li>
</ul>
</td></tr>
<tr><td><code>subok</code></td>
<td><code>Optional. </code>Specify True to make the returned array sub-classes pass through. By default, the returned array forced to be base class array.</td></tr>
<tr><td><code>ndmin</code></td>
<td><code>Optional. </code>Specify the minimum dimension of the array.</td></tr>
</tbody></table><br>

<h3>Example: Create 1-D Array</h3>
<p>In the below example, a list is used to create a 1-D numpy array.</p>

<div>
<pre>import numpy as np
MyList = [1, 2, 3, 4, 5]
npArray = np.array(MyList)
print(npArray)
</pre>
</div>
<p>The output of the above code will be:</p>

<br>

<h3>Example: Create 2-D Array</h3>
<p>In this example, a list of lists is used to create a 2-D numpy array. </p>
<div>
<pre>import numpy as np
MyList = [[1, 2, 3], [4, 5, 6]]
npArray = np.array(MyList)
print(npArray)
</pre>
</div>
<p>The output of the above code will be:</p>

<br>

<h3>Example: Create 2-D Array using ndmin parameter</h3>
<p>A n-dimensional array can be created using <span>ndmin</span> parameter of the array function. Like, in this example, it is used to create 2-D array. </p>
<div>
<pre>import numpy as np
MyList = [1, 2, 3, 4, 5]
npArray = np.array(MyList, ndmin=2)
print(npArray)
</pre>
</div>
<p>The output of the above code will be:</p>

<br>

<h3>Example: Create 1-D Array with dtype parameter</h3>
<p>The <span>dtype</span> argument is used to change the data type of elements of the ndarray object. </p>
<div>
<pre>import numpy as np
MyList = [1, 0, 0, 1, 0]
npArray = np.array(MyList, dtype=bool)
print(npArray)
</pre>
</div>
<p>The output of the above code will be:</p>
<div>	
<pre>[ True False False  True False]
</pre>
</div>


<hr>



<!-- 2nd column end -->
</div></div>]]>
            </description>
            <link>https://www.alphacodingskills.com/numpy/numpy-ndarray.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358495</guid>
            <pubDate>Wed, 09 Dec 2020 14:01:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring Business in the UK]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358471">thread link</a>) | @logikblok
<br/>
December 9, 2020 | https://logikblok.github.io/sketches/ukbusiness/index.html | <a href="https://web.archive.org/web/*/https://logikblok.github.io/sketches/ukbusiness/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

  <!-- Primary Page Layout –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
  <!-- Introduction –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
  <!-- 1. What is a business in the UK? –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div>
    <section>
      <a name="question1"></a>
      <h3>1. What does it mean to be a business in the UK?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> A business is a legally recognised unit producing goods or services and usually paying taxes. They are categorised by a series of defined codes. Business statistics make use of a register, referenced as
          <em>enterprises</em> or they are <em>estimated</em>, this is because some are too small to be registered.
        </p>
      </blockquote>
      <p>Being a business first invovles a type of registration or formation. There are three common ways people go about doing this in the UK:</p>
      <ul>
        <li>Individuals can do business by registering as a <em>sole trader</em>.</li>
        <li>Individuals or groups can incorporate a <em>company</em>.</li>
        <li>Groups can come together and register as a <em>partnership</em>.</li>
      </ul>
      <p>There are lots more business structures available. People choose a structure that works best how they plan to operate, how many people are responsible and other considerations.</p>
      <p>Due to the variety of ways a business can operate and the need for alignment to the same concepts, the core sets of UK statistics make use of two elements the Inter-Departmental Business Register (<a href="https://www.ons.gov.uk/aboutus/whatwedo/paidservices/interdepartmentalbusinessregisteridbr">IDBR</a>) and the Business
              Population Estimates <a href="https://www.gov.uk/government/statistics/business-population-estimates-2019">(BPE)</a> to <em>analyse</em> businesses as a whole.</p>
      <p>When using data that uses the IDBR in particular and refering to a single business in the UK, we are actually
        refering to an <em>enterprise unit</em>.</p>
      <blockquote cite="https://www.ons.gov.uk/businessindustryandtrade/business/activitysizeandlocation/bulletins/ukbusinessactivitysizeandlocation/2019">
        <p>
          The term “business” is used to represent an enterprise. An enterprise can be defined as the smallest combination of legal units (generally based on VAT and/or PAYE records) that is an organisational unit producing goods or services, which
          benefits from a certain degree of autonomy in decision-making, especially for the allocation of its current resources. <a href="https://www.ons.gov.uk/businessindustryandtrade/business/activitysizeandlocation/bulletins/ukbusinessactivitysizeandlocation/2019">via ONS</a>
        </p>
      </blockquote>
      <p>However businesses can be so small that the register may not include them, which is where we can make use of the <a href="https://www.gov.uk/government/statistics/business-population-estimates-2019">Business
          Population Estimates</a> (BPE):</p>
      <blockquote cite="https://www.gov.uk/government/statistics/business-population-estimates-2019">
        <p>[As] there is no single database in the UK which contains details of every active
          business. The [BPE] takes data on businesses on the IDBR, and then <em>estimates the number of additional very small businesses
            unregistered for VAT or PAYE</em> <a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/836574/METHODOLOGY___QUALITY_NOTE_BPE.pdf">via BEIS</a></p>
      </blockquote>
      <p>So we can use <em>both</em> these data sets to get a general picture of what's happening in the UK. For more on the differences <a href="https://www.gov.uk/government/statistics/guide-to-business-statistics">this guide</a> offers a good overview. More detail on the data used is available <a href="https://logikblok.github.io/sketches/ukbusiness/data.html#IDBRandBPE">here</a>.</p>
      <p>Next, we also need to consider Standard Industrial Classifications or (<a href="https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007">SIC codes</a>). Just like
        the variety of structures there are a large number of things a business can do to meet the needs of it's customers. So to capture what businesses typically do, SIC codes are used to classify economic activites.</p>
      <blockquote cite="https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007">
        <p>A Standard Industrial Classification (SIC) was first introduced into the UK in 1948 for use in classifying business establishments and other statistical units by the type of economic activity in which they are engaged.<a href="https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007">via ONS</a></p>
      </blockquote>
      <p>Let's explore some of these now. Press the button below to see an example SIC code and it's description.</p>
      
      <code>
        <p id="sicCode">1110,Growing of cereals (except rice), leguminous crops and oil seeds</p>
      </code>
      
      <p>As you can see the codes have a number and a description. The number code can be used to identify the activities of a business into an area and the descriptions can provide further context.</p>
      <p>These activities are organised into <em>classes or subclasses</em>, <em>groups</em>, <em>divisions</em>, <em>sections</em> and <em>broad industry groups (BIG)</em>. The chart below provides an outline of the breakdown with the number of each
        categorisation level and an example
        using <em>25.91 Manufacture of steel drums and similar containers</em>.</p>
      
      
      <p>Complex businesses can apply multiple SICs to themselves. For example, a software firm might list themselves engaging in design, software
        development, professional services and more. Here's another example using a popular UK super market store:</p>
      <blockquote cite="https://beta.companieshouse.gov.uk/company/00519500">
        <p> <em>TESCO STORES LIMITED Company number 00519500</em></p>
        <p>
          Nature of business (SIC):
        </p><ul> 47110 - Retail sale in non-specialised stores with food, beverages or tobacco predominating </ul>
        <ul>47290 - Other retail sale of food in specialised stores</ul>
        <ul>47710 - Retail sale of clothing in specialised stores</ul>
        <ul>47750 - Retail sale of cosmetic and toilet articles in specialised stores</ul>
        <a href="https://beta.companieshouse.gov.uk/company/00519500">via Companies House</a>
        
      </blockquote>
      <p>For the majority of our purposes, we'll mainly be looking at things at the <em>Broad Industry group</em> level which is the highest categorisation available.</p>
      <p>The chart below shows all the Broad Industry Groups (BIG) and their breakdown composition below them. Most BIGs have one <em>section</em> and a number of <em>divisions</em> below them. As you can see Production is the most complex, with two
        layers structured below it.</p>
      
      <p>This higlights an overall indication of how the UK business landscape is structured, at least statistically speaking.
        The SIC hierarchy can be explored <a href="https://onsdigital.github.io/dp-classification-tools/standard-industrial-classification/ONS_SIC_hierarchy_view.html">further here</a>.</p>
    </section>
  </div>
  <!-- 2. How many businesses are there? –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div>
    <section>
      <a name="question2"></a>
      <h3>2. How many businesses are there?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> As of 2019 over 5.8 million business are estimated to be present in the UK.
        </p>
      </blockquote>
      <p>The estimation is called out specifically because there are are a vast number of businesses too small to be registered using the IDBR, more detail on the data differences is available <a href="https://logikblok.github.io/sketches/ukbusiness/data.html#IDBRandBPE">here</a></p>
      <p>The chart below shows the difference between the data sets of registered enterprises versus the estimated numbers by industry groups. </p>
      
      <p>The differences above are expected as each data set serves different purposes. However overall both correlate to show similar patterns that the UK has prominent numbers of businesses in industries related to construction and proffesional services.</p>
      
      <p>The chart above shows the total estimated number of businesses highlighting the growth of the UK business population across a six year range.</p>
    </section>
  </div>
  <!-- 3. Where are they in the UK? –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div>
    <section>
      <a name="question3"></a>
      <h3>3. Where are businesses located in the UK?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> There is a concentration of businesses towards the south of the UK. The highest number in London with the lowest in Northern Ireland.
        </p>
      </blockquote>
      <p>As a quick reminder the The United Kingdom of Great Britain and Northern Ireland (UK) is shaped liked the below. The UK consists of four countries: England, Scotland, Wales and Northern Ireland.</p>
      <p>England is split into smaller 9 regions whilst Scotland, Wales and Northern Ireland are treated as individual regions, bringing up the total number of regions to be <em>12</em>.</p>
      
      <p>The chart below shows the number of businesses by region. It highlights the  higher number of businesses towards the south of the UK with London first, followed by the South East and the East of England.</p>
      
      <p>The chart below shows a time series of the numbers of businesses by their region. Click on any of legend items to hide them on the chart.</p>
      
      <p>It shows how consistently those regions maintain the highest number of businesses in the UK.</p>
    </section>
  </div>
  <!-- 4. What are the most popular business activites? –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div>
    <section>
      <a name="question4"></a>
      <h3>4. What are the most popular business activities?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> The UK's highest buisness activities are typically those related to construction or proffesional activites. In order at the SIC Division level they are:
          </p><li>43 Specialised construction activities</li>
          <li>41 Construction of buildings</li>
          <li>85 Education</li>
          <li>47 Retail trade, except of motor vehicles and motorcycles</li>
          <li>81 Services to buildings and landscape activities</li>
        
      </blockquote>
      <p>The chart below tries to show the regional differences in the concentraion of <em>enterprises</em>. It's using 2019 ONS data on activity and size.
</p>
      
      <p>Couple of interesting points above:
        </p><ul>
          <li>Construction and professional services are fairly consistently spread across the UK.</li>
          <li>Notice the more common aspects for Northern Ireland and Scotland in Agriculture &amp; Fishing.</li>
          <li>Education and Arts concentraion in London.</li>
        </ul>
        
      <p>The chart below shows a treemap of the number of estimated businesses by their broad industry group and their SIC industry division, allowing us to see a little more detail into the most popular business activites.</p>
      

    </section>
  </div>
  <!-- 5. Who invests in these businesses? –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div>
    <section>
      <a name="question5"></a>
      <h3>5. Who is investing into the UK?</h3>
      <blockquote>
        <p>
          <b>In summary:</b>  Historically the largest amount of investment into the UK has come from Europe followed by the Americas, however in recent years the overall net flow of investment has decreased from Europe with the Americas taking the lead.
        </p>
      </blockquote>
      <p>Businesses can take on debt or investment or alternative financial approaches to meet their needs. Here we're looking at Foreign Direct Investment (FDI) as a whole.</p>
      <p>The chart below shows the net flow of FDI by continent. These are net values showing investments minus disinvestments. It shows a shift from Europe to the Americas between 2016-2018.</p>
      
      <p>Considering overall positions, which we mean to be the value of a stock of investment held at a point in time, the UK continues to see an increase overall. The chart below shows the <em>World Total</em> of International investment positions
        in the UK by industrial activity.</p>
      <p>Click on any of the items in the legend to hide them from view.</p>
      <p>Financial services continues to be the highest, food and drink along with mining activites have seen the largest changes in international investment positions.</p>
      
    </section>
  </div>
  <!-- 6. UK businesses internationally? –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div>
    <section>
      <a name="question6"></a>
      <h3>6. How are UK business trading internationally?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> An estimated total of 2,424,700 enterprises carried out exporting or importing activity, with a slightly larger number importing. For most it's either exporting or importing rather than doing both activities.
        </p>
        <p>The largest number of enterprises trading internationally was …</p></blockquote></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://logikblok.github.io/sketches/ukbusiness/index.html">https://logikblok.github.io/sketches/ukbusiness/index.html</a></em></p>]]>
            </description>
            <link>https://logikblok.github.io/sketches/ukbusiness/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358471</guid>
            <pubDate>Wed, 09 Dec 2020 13:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Question That Got Google’s Timnit Gebru Fired: Can an AI Model Be Too Big?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358384">thread link</a>) | @nibbleshift
<br/>
December 9, 2020 | https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><a href="https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/">Last week, news broke that Google fired the co-lead of its ethical AI team, Dr. Timnit Gebru</a>. Since then, the artificial intelligence community has been taking stock of a host of issues. Chief among them is the intersection of corporate power and research institutions: can a company effectively question its own products? Under the surface of this firing are long-standing and intensifying questions about the ethical implications of artificial intelligence that have yet to fully translate to the wider public.</p>
<p>Dr. Gebru’s departure was precipitated by a paper she co-authored with four other Google employees. The draft paper, titled “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” examines the potential multifaceted hazards of a new class of large machine learning models that are widely used by Google and other large technology companies.</p>
<figure id="attachment_1633" aria-describedby="caption-attachment-1633"><img src="https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1024x599.jpeg" alt="Timnit Gebru" width="1024" height="599" srcset="https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1024x599.jpeg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-300x176.jpeg 300w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-768x449.jpeg 768w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-770x451.jpeg 770w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1400x819.jpeg 1400w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021.jpeg 1504w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1024x599.jpeg 1024w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-300x176.jpeg 300w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-768x449.jpeg 768w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-770x451.jpeg 770w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1400x819.jpeg 1400w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021.jpeg 1504w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1024x599.jpeg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-1633">Dr. Timnit Gebru. Image: Last Futurist</figcaption></figure>
<p><a href="https://twitter.com/JeffDean/status/1334953632719011840">Jeff Dean, head of Google AI, stated that the paper was submitted for review with little notice and that it “didn’t meet our bar for publication.”</a> Further, Dean claimed that the paper had overlooked scholarship that mitigated the concerns detailed by Dr. Gebru and her co-authors. The conflict eventually led Dr. Gebru to request a set of specific conditions in order to continue her employment at Google. Dean ultimately declined and interpreted her message as an immediate resignation. Gebru has since explained that she was effectively terminated before she had an opportunity to negotiate the timing of her exit.</p>
<p>The news of her departure has sparked an intense reaction in the tech community.<a href="https://googlewalkout.medium.com/standing-with-dr-timnit-gebru-isupporttimnit-believeblackwomen-6dadc300d382"> As of the time of writing, nearly 2,000 Google employees and 3,000 others have signed a letter of protest to Dr. Gebru’s firing</a>. The letter accuses Google of retaliatory practices and of censoring a line of research that is critical of some of its core products.</p>
<p>Since her firing, Dr. Gebru and her colleagues’ paper has leaked online. Unlike recent years, where we have seen public fretting <a href="https://www.oreilly.com/radar/maximizing-paper-clips/">from figures like Elon Musk</a> that<a href="https://www.economist.com/special-report/2016/06/23/frankensteins-paperclips"> rogue AI would somehow turn the world into paper clips,</a> the paper by Gebru et al. is grounded in present-tense issues. Throughout, I will occasionally refer to Dr. Gebru in the singular for the sake of simplicity; please keep in mind that she had several co-authors on this paper. Their identities are being protected as current employees of Google.</p>
<p>The paper centers around problems that are inherent in a quickly evolving class of artificial intelligence techniques that attempt to model human language. In simplified terms, these models are designed to do one of two tasks: they either predict what comes next after a string of text, or they predict what should go in the middle of a sentence. While this may sound less than exciting, it is massively important—it is a core part of the technology that powers machine translation, automated speech recognition, and virtually anything else to do with language. Imagine something like a sophisticated statistical “Mad Lib” solver and you’re on the right path.</p>
<p>In recent years, these technologies have grown vastly more powerful due to a confluence of factors that constitute a familiar story: ever-larger datasets help to train bigger and more complex models enabled by radical improvements in computer infrastructure.</p>
<p>At present, the largest of these models is OpenAI’s GPT-3. The model uses some 175 billion parameters, and each must be tuned or “trained” on example data via an iterative process. In the case of GPT-3, that data is 570 gigabytes of text data drawn from a variety of sources from the Internet. The previous largest model, Microsoft’s T-NLG announced in February of this year, used less than 10% of the parameters and 30% of the training data. In short, this is a very quickly moving space.</p>
<p>Dr. Gebru and her colleagues ask a straightforward but provocative question: How big is too big? To understand that, we have to look closely at what it means to train a machine learning model.</p>
<p>Machine learning researchers and computer scientists tend to divide calculation of costs between “training” time and “inference” time. Training refers to the process of “teaching” the model on the basis of large datasets. That process is typically iterative; it takes many cycles of repetition to develop a robust model. Researchers must also be careful that the training data is diverse enough that models don’t “overtrain” and become fixated on idiosyncratic patterns.</p>
<p>For example, imagine you have a set of “noisy” points like the black dots below:</p>
<p><img src="https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data.png" alt="" width="377" height="256" srcset="https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data.png 377w,https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data-300x204.png 300w" sizes="(max-width: 377px) 100vw, 377px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data.png 377w, https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data-300x204.png 300w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Your goal is to come up with a function that will predict a new set of points in the future from the same underlying process — recognizing that this particular collection of black dots has some measurement error and uncertainty in it.</p>
<p>The two lines show two possible solutions. The first is a very simple line. While it doesn’t perfectly “fit” the dots, it captures the basic trend. The second is the blue line, which perfectly fits each and every dot, and relies on a more complicated function. If you measure the accuracy of these two models on just this data, the blue line is better. In fact, it is technically perfect.</p>
<p>But is it? You can imagine that over time, with new datasets that won’t have the dots in exactly the same place, the simple line will actually be more accurate. The simple line is less complex, but actually captures the data better by not being overly influenced by just one example.</p>
<p>Finding the right balance in model complexity is difficult work. Too simple, and the model can’t capture important nuances—too complex and it becomes fragile, or at worst a mere portrait of the training data. The goal, as in so many things, is to find the sweet spot in the middle: a tool that is general enough to handle the messiness of the real world without sacrificing too much in terms of accuracy.</p>
<p>Finding that sweet spot often requires vast computational resources, particularly in the modern context. This is partly due to the inherent need for repetition in “teaching” the model, and also the need to ensure that the model doesn’t become too dependent on one narrow slice of training data.</p>
<p>In comparison to training, “inference” — that is, actually using the model to make a prediction — is much cheaper. The expensive part is finding the right values for all those parameters discussed above. Once you have them, making predictions with the model is relatively easy.</p>
<p>If you squint, a rough analogy can be made to raising children. The cost of raising an infant to school age is profound in comparison to babysitting a kid for a day. The hard part is teaching an infant all the basics of human life: not to touch the stove and stick fingers in the electrical sockets. Once the child, or the model, has reached maturity, it “operates” relatively cheaply in comparison to the cost of its upbringing.</p>
<p>This brings us back to Dr. Gebru’s work. One of her arguments is that “raising” AI is expensive in terms of raw energy. She cites the work of<a href="https://arxiv.org/abs/1906.02243"> Dr. Emma Strubell and others</a>, who<a href="https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/"> demonstrated that training big models can emit as much carbon as five cars</a> do over their full lifetime of use. That fantastically powerful computer infrastructure comes at a cost.</p>
<p><img src="https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1024x1024.jpg" alt="Google fired Timnit Gebru" width="1024" height="1024" srcset="https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1024x1024.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-300x300.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-150x150.jpg 150w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-768x768.jpg 768w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1536x1536.jpg 1536w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-70x70.jpg 70w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-120x120.jpg 120w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-240x240.jpg 240w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-360x360.jpg 360w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-540x540.jpg 540w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-720x720.jpg 720w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-770x770.jpg 770w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1400x1401.jpg 1400w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-125x125.jpg 125w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1024x1024.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-300x300.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-150x150.jpg 150w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-768x768.jpg 768w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1536x1536.jpg 1536w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-70x70.jpg 70w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-120x120.jpg 120w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-240x240.jpg 240w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-360x360.jpg 360w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-540x540.jpg 540w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-720x720.jpg 720w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-770x770.jpg 770w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1400x1401.jpg 1400w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-125x125.jpg 125w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash.jpg 1920w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1024x1024.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Google and others contend that innovation has helped to offset these costs and prevent them from becoming another worrying source of carbon pollution. However, Dr. Gebru rightly points out that the wider enterprise of cloud computing is not necessarily carbon neutral, whatever Google’s particular commitments may be.</p>
<p>She further argues that the benefits and costs of these models are lopsided. Is it fair to ask residents of the Maldives, expected to be underwater before the end of the century, to foot the environmental bill for marginally improved language models — particularly when those language models don’t include Dhivehi? In short, the people most exposed to the risks of climate change are some of the least positioned to benefit from technologies like Google Home or Amazon’s Alexa.</p>
<p>Put more pointedly: What good is a Siri that doesn’t understand your language when the water is rising?</p>
<p>Should we hasten the flood so that gadgets become slightly less stupid? How about when such machines do other more important work,<a href="https://thedebrief.org/deepminds-ai-makes-history-by-solving-protein-folding-problem/"> like predicting the structure of medically relevant proteins</a>? To be sure, these are not easy questions — but they are important ones, and ones that should be widely assessed.</p>
<p>Next among Dr. Gebru’s concerns is “unfathomable” training data. Those 570 gigabytes of Internet data referenced above largely come from sources that represent a very narrow slice of society. In the analogy above between training a model and raising a child, imagine a child raised largely by Reddit or Twitter, with occasional babysitting from Wikipedia. Are you confident that a well-rounded, tolerant person would result? Would you take that teenager to an important company dinner, trusting that they wouldn’t say anything offensive or laughably wrong?</p>
<p>The deeper problem Dr. Gebru raises is that the training datasets themselves are too large to effectively audit or even fully understand as a researcher. How can we assess the ethics of something so vast we can’t effectively explore it? The risk, Gebru’s team and others argue, is that by averaging together such sources, models will come to “encode hegemonic worldviews.”</p>
<p>The risk only becomes more pronounced as the models become increasingly convincing. Advances in language models have enabled automated text that seems coherent across sentences and even paragraphs.</p>
<p>Take this example of GPT-3 answering questions about the Russian private military company, the Wagner Group:</p>
<p><img src="https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai.png" alt="AI GPT3" width="633" height="598" srcset="https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai.png 633w,https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai-300x283.png 300w" sizes="(max-width: 633px) 100vw, 633px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai.png 633w, https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai-300x283.png 300w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><div><div id="block-wrap-52141" data-id="52141"><div><div><div>		<article>
					<p><a href="https://thedebrief.org/pope-francis-calls-for-prayers-as-ai-research-progresses/">
				<img width="120" height="80" src="https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis.jpg" alt="Pope Francis" srcset="https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis.jpg 1500w,https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-1024x683.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-768x512.jpg 768w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis.jpg 1500w, https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-300x200.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-1024x683.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-768x512.jpg 768w" data-src="https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div></div></div></div></div>
<p>The model does an admirable job of answering basic questions. The responses feel logically and intentionally composed.</p>
<p>The example comes from a paper earlier this year by two researchers from the Middlebury Institute of International Studies. They …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/">https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/</a></em></p>]]>
            </description>
            <link>https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358384</guid>
            <pubDate>Wed, 09 Dec 2020 13:50:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Everything Up? Monitoring 29,302 Points In-the-Loop in the FlightAware Stack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358284">thread link</a>) | @jsulak
<br/>
December 9, 2020 | https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/ | <a href="https://web.archive.org/web/*/https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><em>Take lessons from high stakes monitoring in the physical world (electrical grids, nuclear power plants, oil rigs, data centers) and apply them to a pure software stack.</em></p><p><em>Karl Lehenbauer is FlightAware</em>’<em>s Chief Technology Officer. </em></p><p>Little is worse for someone committed to providing reliable service than to have your customer call you to tell you your service isn’t working. It’s a double whammy. You’re broken and you don’t know you’re broken. You hate that. So do we. Worse, we have service level agreements with many of our customers— if a service isn’t working for long enough, we have to start dishing out refunds.</p><p>But far more important than that, if we’re down our customers don’t know where their airplanes are. This can be a regulatory violation. It can also mean that the line service technicians aren’t available to meet the plane (if you travel much at all you’ve heard the pilot come on the PA and announce, “Well folks, we’ve arrived but the ground crew isn’t here to help get us into the gate”). Then you sit on the plane in the alleyway until the wing walkers, jetway driver, baggage handlers, etc., show up to guide the plane in.</p><p>But more than that, we provide Global Aviation Distress and Signaling System (GADSS) <a href="https://globalbeacon.aero/">surveillance</a> to lots of airlines as mandated by the International Civil Aviation Organization. They might literally not know that one of their airplanes is in distress or has some kind of incident or even has crashed if our stuff isn’t working properly. People’s lives are on the line.</p><p>Let’s go back in time a bit.</p><h2 id="monitoring-the-real-world">Monitoring the Real World</h2><p><br>I got my start in control systems, first at a power company, monitoring and controlling electrical power generation, transmission and distribution. Later, I went to work at a vendor of those systems, followed by a stint at GE Aircraft Instruments working on turbine engine monitoring.</p><p>By the early 1990s I was leading the engineering team for a very early Internet Service Provider.</p><p>One day, our air conditioning failed. The computer room overheated, we lost some disk drives, and I resolved that we should be alerted if it ever started happening again.</p><p>This was before you could read the air inlet temperature off of your high-end router or from your fancy air conditioner or from one of the inexpensive SNMP-enabled temperature monitoring solutions of today.</p><p>So we came up with a clever solution. We’d use an old school thermostat, wire the transmit pin of a computer’s serial port through the thermostat’s mercury switch to the port’s receive pin, and we’d send a character through the serial port every few seconds. If the computer room went above a threshold temperature, the blob of mercury would complete the circuit and we’d start reading the characters back from the serial port. Then our little program would recognize this and start sending messages to peoples’ pagers using a modem.</p><figure><img src="https://flightaware.engineering/content/images/2020/12/Image-1-.png" alt="" srcset="https://flightaware.engineering/content/images/size/w600/2020/12/Image-1-.png 600w, https://flightaware.engineering/content/images/size/w1000/2020/12/Image-1-.png 1000w, https://flightaware.engineering/content/images/size/w1600/2020/12/Image-1-.png 1600w, https://flightaware.engineering/content/images/2020/12/Image-1-.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Fine.</p><p>Lo and behold, one day we partially lost cooling in the data center, only we didn’t get any callouts. An investigation revealed that one of the wires had gotten janked, and though the blob of mercury made contact, no characters were received by the monitoring program.</p><p>Meditating on this led to a critical insight. <em>We had it backwards! </em>Rather than completing the circuit when there was a problem, we needed instead to make the circuit normally closed and open it when there was a problem. Instead of wiring into the air conditioning contacts of the thermostat we would wire into the heating ones. We would receive the characters we were sending as long as everything was OK. If the temperature rose past a threshold, the blob of mercury would pull away from the contacts, breaking the circuit, so whenever our program <strong>stopped</strong> seeing the characters, the alarm would be raised.</p><p>By flipping it like this, if one of the wires got inadvertently pulled or whatever, we’d immediately get the alarm.</p><p>In other words, <strong>the lack of a signal telling you everything is OK means something is wrong.</strong></p><h2 id="on-the-trail-of-monitoring-your-applications">On the Trail of Monitoring Your Applications</h2><p>Now, consider we have a service and we want to make sure it’s working. Can I ping the machine or machines? Great. The machine is up. Or is it? Ping is pretty basic in the network stack; ping packets are typically responded to directly from the kernel. We’ve seen machines that are pretty crashed and won’t run programs that will still ping.</p><p>OK, so we’ll ping the machine, but we’ll have some kind of agent program that runs on the machines that we’ll talk to over the network. If we can talk to the agent, then we know a little more that the machine is working. But does the machine have enough storage? Does it have enough memory? OK, we’ll make our agent check and alert us if the machine is low on storage or memory, if the swap utilization is abnormally high, etc.</p><p>But is the program running? Sure, no problem. We’ll add some code to our agent to read the process table and see if the program shows up there. If it doesn’t, we’ll alarm.</p><p>But is the program getting work done? The process might exist, but it might not be doing anything. Well we could read the program’s CPU time repeatedly and see if it’s accumulating time.</p><p>But does that mean it’s working? No, it doesn’t. Maybe it’s lost its database connection. Maybe it’s accumulating CPU time but because it wasn’t written defensively enough, it’s trying to do database updates and failing and logging errors but not reconnecting to the database.</p><p>Maybe it’s got a good connection to the database server but it’s not receiving any messages.</p><p>You can keep increasing the sophistication of your agent. You can keep adding new checks as you discover (usually the hard way) new failure modes you missed, but with this approach you’re vulnerable to any new or unanticipated breakdowns. You might never be completely sure work is getting done.</p><h3 id="in-the-loop-monitoring">In-the-Loop Monitoring</h3><p>I assert that you can’t know your program is doing the work it’s supposed to be doing unless it’s telling you that it is. Call this “in-the-loop” monitoring. If a program is expected to repeatedly receive input messages and update a table in a database, then every time it has done this it should send a message to monitoring software reporting that it has successfully done it.</p><p>It should only send the success message to the monitoring program upon completion of the work. So once an input message has been received, successfully processed, and the database updated, a separate message is sent to the monitoring software saying it has succeeded. If no input message is received or the database update fails, the message should not be sent to the monitoring software.</p><p>To reiterate, you make a call from inside the program to send a message to your monitoring software every time the program succeeds in doing a parcel of work.</p><p>Meanwhile, if a certain amount of time passes without the monitoring program receiving a “work completed” message, it raises an alarm that something is wrong.</p><p>The beautiful thing here is that the monitoring program doesn’t have to know why it didn’t receive a message. We don’t have to try to check for every possible reason. All we have to do is recognize that we stopped being told it was OK. The machine may have crashed, the router may have failed, the program may have lost its receive socket or its database connection. The program feeding data to our program may have stopped sending, the ethernet cable may have gotten pulled, a circuit breaker may have tripped, the program may have divided by zero or gotten a memory protection violation, there could have been an earthquake, a flood… locusts! We don’t have to check for all those things. All we have to do is recognize that the program stopped telling us it was OK.</p><h3 id="watchdog-timers">Watchdog Timers</h3><p>What I’m describing is a variation of a <a href="https://en.wikipedia.org/wiki/Watchdog_timer">watchdog timer</a>, technology common in real-time systems, space probes, satellites, etc., where software on a computer periodically resets a hardware timer. The hardware timer counts down, but every time the reset signal is received the counter is reset. If for any reason the software stops resetting the hardware timer, the counter eventually reaches zero and triggers a reboot or some other corrective action. Our variation is much more granular and is software-based, but the principle is the same.</p><h2 id="on-the-trail-of-watchdog-resets-in-the-modern-production-software-stack">On the Trail of Watchdog Resets in the Modern Production Software Stack</h2><p>Now, if your program is processing 40,000 messages a second, it needn’t send 40,000 messages a second to your monitoring system saying it’s completed work. So the watchdog reset subroutine can have a threshold and only send a completion message once a second or whatever, regardless of how many messages it processed. Fine.</p><p>Also, the watchdog reset subroutine must never break the program! So if it can’t reach the monitoring server, the program should keep going regardless. The program shouldn’t freeze if the monitoring software stops responding. For this reason our in-the-loop code has been kept very simple, and uses UDP datagrams to send watchdog resets to the monitoring software. It also makes sure that even if there is an error returned, which can happen even with UDP if the sender and recipient are on the same LAN, that it doesn’t stop or break the program.The watchdog reset message should identify the program, the machine (typically), and perhaps the activity within the program that has succeeded. Examples include the receipt of a message from the FAA, from Aireon’s Space-Based ADS-B network, from our provider of airline schedules, from each of our multiplexing agents that aggregate data from our tens of thousands of ADS-B ground stations, or from <a href="https://flightaware.com/about/datasources/">HyperFeed</a>®, our suite of programs that process all the input data to produce our coherent feed of what is happening with all the aircraft that are in the air or moving on the ground in the world.</p><figure><img src="https://flightaware.engineering/content/images/2020/12/Image-2-4.png" alt="" srcset="https://flightaware.engineering/content/images/size/w600/2020/12/Image-2-4.png 600w, https://flightaware.engineering/content/images/size/w1000/2020/12/Image-2-4.png 1000w, https://flightaware.engineering/content/images/2020/12/Image-2-4.png 1330w" sizes="(min-width: 720px) 720px"><figcaption>Watchdog reset call in Python – If one of our 12M+ users hasn’t logged into the website in the last 15 minutes, something’s wrong.</figcaption></figure><p>Creation of watchdog entries in the monitoring software should be zero config. That is to say on the first receipt by the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/">https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/</a></em></p>]]>
            </description>
            <link>https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358284</guid>
            <pubDate>Wed, 09 Dec 2020 13:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Ethereum Keys Are the Core of Space Accounts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358155">thread link</a>) | @itsnicoggi
<br/>
December 9, 2020 | https://blog.space.storage/posts/why-ethereum-keys-are-the-core-of-space-accounts | <a href="https://web.archive.org/web/*/https://blog.space.storage/posts/why-ethereum-keys-are-the-core-of-space-accounts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://fleek-team-bucket.storage.fleek.co/thumbnails-blog/Space%20Ethereum.jpg" alt="Ethereum keys in Space Storage"></p>
<p>In our last piece, we talked about the <a href="https://blog.space.storage/posts/the-dweb-protocols-behind-space" target="_blank" rel="nofollow noopener noreferrer">Dweb protocols </a>behind the building of Space, and how each of them allows us to take our platform further away from Web 2.0 and into Web 3.0.</p>
<p>One of those protocols is Ethereum, which we think of as the centerpiece of our user’s accounts. We want to tie each user to an ETH key/address, whether they sign up using email and social accounts (via Torus); or by linking their own ETH wallet (via MetaMask or Wallet Connect).</p>
<p>Why? There are many reasons behind this choice. The first and most immediate one is that we think Ethereum keys are the future of authentication. The second one is a long term one. When we think about the future of Space and the Dweb, we see Ethereum as the main connection point for a wide array of tools and use cases that benefit from pairing with a user-owned platform.</p>
<p>Let’s go over a couple reasons and what they mean for us…</p>
<h2 id="exploring-the-future-of-authentication"><a href="#exploring-the-future-of-authentication" aria-label="exploring the future of authentication permalink"></a>Exploring the Future of Authentication</h2>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/Enter%20Password.gif" alt="Authentication"></p>
<p>At Space, we’ve discussed several times about what the future of authentication looks like. Whether you sign up using email, social media, or an ETH wallet, we all agree with one thing: public/private key pairs proved to be a solid alternative to passwords, and an overall better authentication model.</p>
<p>So far, key pairs have addressed key issues in the authentication process, and many core negative aspects of the Web 2.0 auth paradigm.</p>
<p>We can see this from the get go if we compare both models. With passwords, authentication is handled from the platform’s end, with the user having to expose their main credentials every time to the platform, who also keeps these credentials on their end.</p>
<p>Key pairs, on the other hand, allow for blind verification of a user’s identity, since they don’t need to expose their private key but sign proof that the platform can verify by just knowing the user’s public key.</p>
<p>This means there’s a lot less instances the user has to worry about when it comes to their credential’s security.</p>
<p>However, we do also understand that key pairs fundamentally change the user’s experience entirely. Generating, saving, and safekeeping keys is not the standard experience everyone, and making a hard switch would mean exposing users to a new model that has its own security needs, and ways of handling/storing/backuping than passwords.</p>
<p>Convenience is a known security killer, and we don’t want users to make sacrifices either in their safety, or their experience.</p>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/Change.gif" alt="Experience changes"></p>
<p>That’s why we’re focusing on finding a place in-between for users to leverage the best aspects of key-pair based authentication, and still maintain a seamless and known login experience. We want to provide a wide selection to cover the spectrum, for both those who simply want to use their email as a login, for example, and those who want to handle their ETH keys with a crypto wallet.</p>
<p>Torus helps us achieve that for the first group, by abstracting key management and letting us provide users with a known sign in experience in the front (using Twitter, or Email magic links, etc.), while abstracting and securely retrieving the users Ethereum private key in the background, via a distributed, non-custodial, sharded key network (the Torus network) that a user can authenticate to with any of their usual, and quick login options.</p>
<p>That way, we can provide a flexible flow for each user without having to grandfather the platform to an authentication model that we think is not the future, and we can build the platform from the ground up so that every user can transition to key-pair auth more easily.</p>
<h2 id="rethinking-account-ownership"><a href="#rethinking-account-ownership" aria-label="rethinking account ownership permalink"></a>Rethinking Account Ownership</h2>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/Account%20Ownership.jpg" alt="user-owned accounts"></p>
<p>There’s another reason, other than security, behind our choice to work with Ethereum key pairs.</p>
<p>Today, accounts in services are usually centralized, and tied in exclusivity/ownership to the platform itself, and not to the user. That’s why in Web2 we have an endless stream of different accounts for each service, all bound to the platform’s existence.</p>
<p>We see Ethereum keys as the opportunity to switch accounts from entity/platform controlled to completely user owned and controlled. Where instead of a platform authorizing you to use their platform internally, you -as your own entity- would authorize different platforms to access your own personal account and permission each platform to access just the specific data it needs in order for you to use the service.</p>
<p>In the storage world itself this has a special connotation, because today not only is your account tied to a specific storage platform, but your storage/files/data are as well.</p>
<p>As we move forward towards distributing storage (on IPFS, Textile, Filecoin, etc), we want to give users the chance to truly own their account and storage, and be able to choose how they want to access it, and where.</p>
<p>We view files stored in Space as platform and interface agnostic, and in that vision, Ethereum keys play a part in building user-owned accounts that are not siloed or specific to the Space interface itself, but rather existing on an open global data network (or the user’s hands) for the user to own.</p>
<p>It’s an ever evolving and improving concept, but we are looking to break the traditional way of handling storage, where companies own the data/accounts, and move towards a place where platforms just become interfaces for a user to surface, manage, and interact with their files/data that live on this open global file/data layer (powered by IPFS and Textile).</p>
<h2 id="opening-up-to-ethereum-use-cases"><a href="#opening-up-to-ethereum-use-cases" aria-label="opening up to ethereum use cases permalink"></a>Opening up to Ethereum Use Cases</h2>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/Ethereum%20Keys.jpg" alt="ethereum use cases"></p>
<p>The final and longer term reason for using Ethereum keys in our architecture, is to serve as a seamless bridge between Ethereum based use cases, and their potential data/file storage, hosting and access needs.</p>
<p>Ethereum is a melting pot of decentralized use cases and possibilities that benefit a lot from integrating with each other.</p>
<p>From tokens, DAOs, NFTs, to the wonderful array of Dapps that are growing each day, it’s simply natural to think that any of these could benefit from being able to interact directly with distributed and user-owned (or ETH wallet or contract owned) files/data.</p>
<p>For us, Ethereum is the base layer that everything will be controlled from in the future (using ETH wallets or contracts), and so having an ETH key/wallet associated with each user allows us to explore combining and integrating different ETH use cases (tokens, DAO’s, NFT’s, etc.) into Space without having to rebuild the wheel and isolate our platform from an already thriving decentralized environment.</p>
<p>For example, by enabling ETH and ERC20 payments, in the future that could evolve into users being able to seamlessly create paywalls or different access token based mechanisms in front of files or content stored in Space.</p>
<p>Or by taking the “user-owned” nature of NFTs to a new level, and allowing users to store/serve the image/file related to their NFT (which lives on IPFS) in the same account as the token itself (which lives on Ethereum) - rather than just relying on NFT platforms to keep the NFT image/file pinned and existing on IPFS forever.</p>
<p>There’s definitely a lot of exciting opportunities for Space to grow, and for the developer community to build on Space and take some of these ideas to the next level (using the SpaceSDK for web or mobile apps or Space Daemon for desktop apps).</p>
<p>Storage is the cornerstone, and from there, there’s a lot of Space to explore! 🚀🚀</p>
<ul>
<li>Sign up for <a href="https://space.storage/" target="_blank" rel="nofollow noopener noreferrer">Space Beta</a></li>
<li>Follow us on <a href="https://twitter.com/spacestorage" target="_blank" rel="nofollow noopener noreferrer">Twitter</a></li>
<li>Reach out at <a href="https://blog.space.storage/cdn-cgi/l/email-protection" data-cfemail="ee8687ae9d9e8f8d8bc09d9a819c8f898b">[email&nbsp;protected]</a></li>
<li>Check out our <a href="https://docs.fleek.co/space-daemon/overview/" target="_blank" rel="nofollow noopener noreferrer">Tech Docs</a></li>
<li>Spread the word</li>
</ul></div></div>]]>
            </description>
            <link>https://blog.space.storage/posts/why-ethereum-keys-are-the-core-of-space-accounts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358155</guid>
            <pubDate>Wed, 09 Dec 2020 13:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unit-testing a console app]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25358087">thread link</a>) | @jmmv
<br/>
December 9, 2020 | https://jmmv.dev/2020/12/unit-testing-a-console-app.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/12/unit-testing-a-console-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article><p>The most notable feature in <a href="https://jmmv.dev/2020/11/endbasic-0.3.html">EndBASIC 0.3</a> is its new full-screen console-based text editor. It took longer than I wanted to start developing this, in part because I was busy moving, and in part because I <em>dreaded the thought of having to unit test the text editor</em>. (Yes, EndBASIC is a personal project and I develop it in my free time, but that doesn’t mean I don’t want it to be properly engineered!)</p>
<figure>
  <img src="https://jmmv.dev/images/2020-12-08-endbasic-welcome.gif">
  <figcaption>The text editor we will be unit-testing, in action.</figcaption>
</figure>
<p>In the end, I rolled up my sleeves, got to work, and achieved reasonable test coverage. In fact, the tests have already paid off by uncovering various bugs and inefficiencies, so the effort was well-spent. Developing these tests was non-trivial, though, so here is an overview on <em>why</em> it is worthwhile to unit-test a full-screen console app and <em>how</em> to go about it.</p>
<blockquote>
<p>The key insight, unsurprisingly, is to <strong>design for testability</strong>. I knew I wanted to unit-test the text editor from the beginning, so I had to come up with a design that allowed for this. Retrofitting tests into code that never considered testing is very difficult.</p>
</blockquote>
<p>As usual, while the specific code I’m going to show you is in Rust, you can easily apply these ideas to your favorite language. All you need is a mechanism to express an abstraction layer between your app and the console manipulation code—and you could do that even in the shell.</p>

<p>Command-line applications typically interact with the console by reading from their standard input (stdin) and writing to their standard output (stdout). Both stdin and stdout are “streams”: you can read from and write to them, but these I/O operations are sequential. The streams do not know anything about where the cursor is or how to change colors or anything like that. And this makes sense because if stdin and stdout are connected to files, what does it mean to “clear the screen”?</p>
<p>If that’s the case, though, how does a console program manipulate the screen to, for example, clear it and position the cursor at an arbitrary location? Well, the answer is that… it depends.</p>
<p>On Unix-like systems, the application writes special collections of bytes, known as <strong>escape sequences</strong>, to stdout. How the escape sequences look like and what they mean depends completely on what stdout is attached to. Again, if stdout is attached to a file, these sequences mean nothing more than a sequence of bytes. Contrariwise, if stdout is attached to a terminal, then the terminal interprets them and performs certain actions.</p>
<p>The most obvious escape sequence you can think of is the line terminator, or <code>\n</code>. On its own, <code>\n</code> is nothing more than ASCII byte 10. But when the terminal sees this byte, the terminal knows that it has to advance the cursor to the next line <em>and</em> move it to the first column. But the semantics of what <code>\n</code> does vary across systems: Windows interprets <code>\n</code> as <em>just</em> moving the cursor one line down, not rolling it back go the first column.</p>
<p>There are more complex escape sequences, of course. This is why you can trivially (assuming you know what terminal type you are talking to) embed escape sequences in <code>printf</code> or <code>echo -e</code> invocations to control how things look like. You essentially use escape sequences as a way to mark up the text:</p>
<figure>
  <img src="https://jmmv.dev/images/2020-12-08-escape-sequences.png">
  <figcaption>Two `printf(1)` command invocations showing how escape sequences change the color of the printed text.</figcaption>
</figure>
<p>For completeness, I’ll also mention that the terminal emulator is usually in the kernel, which is what allows you to have full-screen text apps in the text mode console, but it can also be implemented in <em>hardware</em> (where the concept originated), and thus also in user space, which is what graphical programs like <code>xterm</code> used to do before PTYs (and is why they are called terminal <em>emulators</em>).</p>
<p>If you haven’t connected the dots yet, this is precisely what the ancient <code>TERM</code> environment variable is about: it tells the console applications what specific terminal it is talking to so that the application itself can generate the correct escape sequences to control it. Nowadays, the <a href="https://en.wikipedia.org/wiki/ANSI_escape_code">ANSI escape sequences</a> are almost universal, but they weren’t always. <code>terminfo</code>/<code>termcap</code> and <code>(n)curses</code> are libraries to abstract all these details away and offer the programmer a generic console-manipulation interface that works across <code>TERM</code> variants.</p>
<p>This is all about Unix though. On Windows, things are different (and my knowledge is very limited). Command-line applications communicate with the Console Window Host (<code>conhost.exe</code>) by means of <code>ioctl</code>-like calls. In other words: console manipulation happens out of band and isn’t part of what goes into stdout. Or at least that’s the only way it used to be: the new console host supports ANSI escape sequences too, presumably to facilitate interop with WSL.</p>
<p>Anyhow. We don’t care about how the console is updated from a testing perspective: we want to know how the console changes, but not exactly how that’s done by the OS. Therefore, I’m going to refer to the escape sequences and/or the <code>ioctl</code>s sent to the console as <strong>console manipulation commands</strong> or <strong>console commands</strong> in the text below.</p>

<p>Testing a full-screen console app—which some people refer to as a <strong>Text User Interface</strong> or <strong>TUI</strong> for short—exposes essentially the same difficulties as testing a GUI:</p>
<blockquote>
<p>We are trying to write tests for something that <strong>responds to user input</strong>, and every user interaction causes <strong>changes that are inherently visual</strong> and require the human eye for interpretation.</p>
</blockquote>
<p>Let’s break these problems down into pieces and see how we can approach them.</p>
<p>First and foremost: we have to ensure that the <em>outcome</em> of our input (key presses) has the right effect on the program <em>state</em>. Given that we are testing a text editor, this is easy: we can populate the editor’s buffer with some text, let the editor process a set of key presses, and then verify that the contents of the editor’s buffer match a golden text. Not very different from other, more traditional tests.</p>
<p>Second, we need to worry about user input. After all, the TUI is interactive and reacts to user key presses, so our tests will have to drive the TUI. This is easier than dealing with the visual console updates, as all we have to do is represent the sequence of key presses to send to the app and then feed those to it in some way. Again, this is not very different from other tests: we have an algorithm and we inject some input.</p>
<p>And third, we have to worry about how things look like, which is the most interesting part of this problem. Because, after all… we can write a test to verify that a piece of code selects the blue color and then clears the screen, but unless we <em>see</em> the result, we don’t know if the screen was all emptied with a blue background or not.</p>
<p>Well, we <em>could</em>. Presumably, we could capture the raw screen contents (or poke at them if we were in the DOS era; <code>0xB8000</code> anyone?) and compare those against golden “screenshots” after every key press. This would do the trick and would result in tests that are completely decoupled form the way the screen is updated… which actually sounds like a good idea. The problem with this approach of comparing screen contents is that we would need a terminal emulator to “render” the console from the console commands that the application emits, and a terminal emulator isn’t a trivial piece of software.</p>
<p>The alternative to this idea of comparing screen <em>contents</em> is to capture the console commands that the app emits and compare those to expectations. This is easier to implement but has different fidelity tradeoffs as we shall see below.</p>

<p>If we follow the ideas presented above, we will end up with a bunch of tests that inject key presses into the TUI and, for each of them, we will capture which console manipulation commands were emitted and we will compare them against expectations.</p>
<p>Which… sounds fragile and not particularly useful, doesn’t it? As mentioned earlier, a sequence of commands is meaningless <em>unless we humans see the visual results</em> once a terminal emulator has processed the commands. You could then say that these tests are pointless. But these tests provide three separate benefits:</p>
<ol>
<li>
<p><strong>Corner-case and regression validation.</strong> In the scenario we are looking at, a lot of the editor behavior is obvious: if we press the right arrow key, we know that the cursor has to move one position to the right if the line of text permits. If we break the way this works, the breakage will be extremely visible once we do any kind of manual test.</p>
<p>But… what happens if the cursor is located in the middle of the last visible line of text, with the viewport scrolled to the right because the line was extremely long, and we press enter to split it? That’s not something you usually do, so what’s the expected behavior there? We need to make sure that, once this works as we intend, it doesn’t unexpectedly break, and we don’t want to have to manually verify this every time we change the editor logic.</p>
</li>
<li>
<p><strong>Behavior documentation.</strong> The collection of test cases for the TUI will serve us as the documentation of all cases we must care about in the code if we are doing any kind of refactoring, for example. As illustrated above, there are a lot of corner cases to deal with, and unless they are tracked somewhere, it’s too easy to forget about them.</p>
</li>
<li>
<p><strong>Efficiency measures.</strong> The last benefit these tests give us is a way to measure efficiency. By capturing the sequence of commands emitted by the TUI logic, we can see if those commands are <em>minimal</em>. Because if they are not, the TUI will flicker.</p>
<p>For example: an easy way to implement the TUI is to refresh the whole screen after every key press—and while that will yield updates that <em>look</em> correct (and that would pass a testing model where we verify screen contents), the app will be doing too much work to update the screen. We need to worry about only doing partial screen updates (clearing a single line, using terminal scrolling features, etc.), and to that end, capturing the sequence of commands lets us do that.</p>
</li>
</ol>
<p>The downside of this testing approach is that, again, we …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/12/unit-testing-a-console-app.html">https://jmmv.dev/2020/12/unit-testing-a-console-app.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/12/unit-testing-a-console-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358087</guid>
            <pubDate>Wed, 09 Dec 2020 13:09:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prisma Migrate is now ready]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25357937">thread link</a>) | @sorenbs
<br/>
December 9, 2020 | https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a | <a href="https://web.archive.org/web/*/https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><h2 id="contents"><a href="#contents" aria-label="contents permalink"></a>Contents</h2><ul><li><a href="#schema-migrations-with-prisma-migrate">Schema migrations with Prisma Migrate</a></li><li><a href="#how-does-prisma-migrate-work">How does Prisma Migrate work?</a></li><li><a href="#what-has-changed-since-the-experimental-version">What has changed since the Experimental version?</a></li><li><a href="#whats-next">What's next</a></li><li><a href="#try-prisma-migrate-and-share-your-feedback">Try Prisma Migrate and share your feedback</a></li></ul><h2 id="schema-migrations-with-prisma-migrate"><a href="#schema-migrations-with-prisma-migrate" aria-label="schema migrations with prisma migrate permalink"></a>Schema migrations with Prisma Migrate</h2><p>Today we're excited to share the new version of Prisma Migrate! 🎊</p><p>Prisma Migrate is a data modeling and migrations tool that simplifies evolving the database schema with the application in-tandem. Migrate is based on the <a href="https://www.prisma.io/docs/concepts/components/prisma-schema#example">Prisma schema</a> – a declarative data model definition that codifies your database schema.</p><p>This Preview release is the evolution of the Experimental version of Migrate that we released last year. Since then, we've been gathering feedback from the community and incorporating it into Prisma Migrate.</p><h3 id="making-schema-migrations-predictable"><a href="#making-schema-migrations-predictable" aria-label="making schema migrations predictable permalink"></a>Making schema migrations predictable</h3><p>Database schema migrations play a crucial role in software development workflows and affect the most critical component in your application – the database. We've built Migrate to be predictable while allowing you to control how database schema changes are carried out.</p><p>Prisma Migrate generates migrations as plain SQL files based on changes in your Prisma schema. These SQL files are fully customizable and allow you to use any feature of the underlying database, such as manipulating data supporting a migration, setting up triggers, stored procedures, and views.</p><p>Prisma Migrate treads the balance between productivity and control by automating the repetitive and error-prone aspects of writing database migrations while giving you the final say over how they are executed.</p><h3 id="integration-with-prisma-client"><a href="#integration-with-prisma-client" aria-label="integration with prisma client permalink"></a>Integration with Prisma Client</h3><p>Prisma Migrate integrates with Prisma Client using the Prisma schema as their shared source of truth. In other words, both Prisma Client and migrations are generated based on the Prisma schema. This makes synchronizing and verifying database schema changes in your application code easier by leveraging Prisma Client's type safety.</p><h3 id="prisma-migrate-is-ready-for-broader-testing"><a href="#prisma-migrate-is-ready-for-broader-testing" aria-label="prisma migrate is ready for broader testing permalink"></a>Prisma Migrate is ready for broader testing</h3><p>Prisma Migrate has passed rigorous testing internally and is now ready for broader testing by the community. You can use it with PostgreSQL, MySQL, SQLite, and SQL Server. <strong>However, as a Preview feature, it is not fully production-ready yet.</strong> To read more about what Preview means, check out the <a href="https://www.prisma.io/docs/more/releases#preview">maturity levels</a> in the Prisma docs.</p><p>Thus, we're inviting you to try it out and <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/4531">give us feedback</a> so we can bring Prisma Migrate to General Availability. 🚢</p><p>Your feedback and suggestions will help us shape the future of Prisma Migrate. 🙌</p><hr><h2 id="how-does-prisma-migrate-work"><a href="#how-does-prisma-migrate-work" aria-label="how does prisma migrate work permalink"></a>How does Prisma Migrate work?</h2><p>Prisma Migrate is based on the <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema">Prisma schema</a> and works by generating <code>.sql</code> migration files that are executed against your database.</p><p>The Prisma schema is the starting point for schema migrations and provides an overview of your desired end-state of the database. Prisma Migrate inspects changes in the Prisma schema and generates the necessary <code>.sql</code> migration files to apply.</p><p>Applying migrations looks very different depending on the stage of development. For example, during development, there are scenarios where resetting the database can be tolerated for quicker prototyping, while in production, great care must be taken to avoid data loss and breaking changes.</p><p>Prisma Migrate accommodates for this with workflows for local development and applying migrations in production.</p><h3 id="evolving-the-schema-in-development"><a href="#evolving-the-schema-in-development" aria-label="evolving the schema in development permalink"></a>Evolving the schema in development</h3><p>To use the new version of Prisma Migrate, you should have at least version <code>2.13.0</code> of the <a href="https://www.prisma.io/docs/concepts/components/prisma-cli/installation"><code>@prisma/cli</code></a> package installed.</p><p>During development, you first define the Prisma schema and then run the <code>prisma migrate dev --preview-feature</code> command, which generates the migration, applies it, and generates Prisma Client:</p><p><span><img src="https://d33wubrfki0l68.cloudfront.net/9dee8cc50b930a017447904d95e15e0e82f9a3bf/426d4/blog/posts/2020-12-migrate-development-workflow.png" alt="Development workflow"><span>Development workflow</span></span></p><p>Here is an example showing it in action:</p><p><strong>1. Define your desired database schema using the Prisma schema:</strong></p><pre><code><span>datasource</span> <span>db</span> <span>{</span>
  provider <span>=</span> <span>"postgresql"</span>
  url      <span>=</span> <span>env</span><span>(</span><span>"DATABASE_URL"</span><span>)</span>
<span>}</span>

<span>model</span> <span>User</span> <span>{</span>
  id    <span>Int</span>      <span>@id</span> <span>@default</span><span>(</span><span>autoincrement</span><span>(</span><span>)</span><span>)</span>
  name  <span>String</span>
  posts <span>Post</span><span>[</span><span>]</span>
<span>}</span>

<span>model</span> <span>Post</span> <span>{</span>
  id        <span>Int</span>     <span>@id</span> <span>@default</span><span>(</span><span>autoincrement</span><span>(</span><span>)</span><span>)</span>
  title     <span>String</span>
  published <span>Boolean</span> <span>@default</span><span>(</span><span>true</span><span>)</span>
  authorId  <span>Int</span>
  author    <span>User</span>    <span>@relation</span><span>(</span><span>fields:</span> <span>[</span>authorId<span>]</span><span>,</span> <span>references:</span> <span>[</span>id<span>]</span><span>)</span>
<span>}</span>
</code></pre><p><strong>2. Run <code>prisma migrate dev --preview-feature</code> to create and execute the migration.</strong></p><div><div><svg width="6" height="9" viewBox="0 0 6 9" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M7.3273 0C7.88605 0 8.20036 0.653318 7.85732 1.1017L4.53001 5.45076C4.26119 5.80213 3.73881 5.80213 3.46999 5.45076L0.142684 1.1017C-0.200356 0.653318 0.113948 0 0.672698 0H7.3273Z" transform="rotate(-90 4.5 4.357)" fill="#8FA6B2"></path></svg><p><label for="tab-1">Expand to view the SQL contents of the generated migration</label></p><div><pre><code>
<span>CREATE</span> <span>TABLE</span> <span>"User"</span> <span>(</span>
  <span>"id"</span> <span>SERIAL</span><span>,</span>
  <span>"name"</span> <span>TEXT</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>"id"</span><span>)</span>
<span>)</span><span>;</span>

<span>CREATE</span> <span>TABLE</span> <span>"Post"</span> <span>(</span>
  <span>"id"</span> <span>SERIAL</span><span>,</span>
  <span>"title"</span> <span>TEXT</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>"published"</span> <span>BOOLEAN</span> <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>true</span><span>,</span>
  <span>"authorId"</span> <span>INTEGER</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>"id"</span><span>)</span>
<span>)</span><span>;</span>

<span>ALTER</span> <span>TABLE</span> <span>"Post"</span> <span>ADD</span> <span>FOREIGN</span> <span>KEY</span><span>(</span><span>"authorId"</span><span>)</span><span>REFERENCES</span> <span>"User"</span><span>(</span><span>"id"</span><span>)</span> <span>ON</span> <span>DELETE</span> <span>CASCADE</span> <span>ON</span> <span>UPDATE</span> <span>CASCADE</span><span>;</span>
</code></pre></div></div></div><p>After the migration has been executed, the migration files are typically committed to the repository so that the migration can be applied in other environments.</p><p>Further changes to the database schema follow the same workflow and begin with updating the Prisma schema.</p><h3 id="customizing-sql-migrations"><a href="#customizing-sql-migrations" aria-label="customizing sql migrations permalink"></a>Customizing SQL migrations</h3><p>You can customize the migration SQL with the following workflow:</p><ol><li>Run <strong><code>prisma migrate dev --create-only --preview-feature</code></strong> to create the SQL migration without applying it.</li><li>Edit the migration SQL.</li><li>Run <strong><code>prisma migrate dev --preview-feature</code></strong> to apply it.</li></ol><h3 id="applying-migrations-in-production-and-other-environments"><a href="#applying-migrations-in-production-and-other-environments" aria-label="applying migrations in production and other environments permalink"></a>Applying migrations in production and other environments</h3><p>To apply migrations to other environments such as production, you pull changes to the repository containing the migrations and run the <code>prisma migrate deploy</code> command:</p><p><span><img src="https://d33wubrfki0l68.cloudfront.net/5d9831941c87b7e24646bca3d96f91d4b799af6a/b7004/blog/posts/2020-12-migrate-production-workflow.png" alt="Production workflow"><span>Production workflow</span></span></p><hr><h2 id="what-has-changed-since-the-experimental-version"><a href="#what-has-changed-since-the-experimental-version" aria-label="what has changed since the experimental version permalink"></a>What has changed since the Experimental version?</h2><p>The most significant change since the Experimental version is the use of SQL as the format for migrations, making migrations <strong>deterministic</strong>. In other words, the exact steps of the migration are determined when the migration is created, allowing you to inspect the SQL (and make changes if necessary) before running.</p><p>This approach has the following benefits:</p><ul><li>The generated SQL is editable, thereby allowing you to control the exact schema changes.</li><li>The migration is predictable with the exact SQL that will be applied.</li><li>You don't need to write SQL unless you want to change a migration.</li><li>You can perform data migrations using SQL as part of a migration.</li></ul><p>Editable SQL for migrations is useful in scenarios where there are multiple ways to map changes in the Prisma schema to the database, and the desired path cannot be automatically determined.</p><p>For example, when you rename a field in the Prisma schema, that can be interpreted as either deleting the column and adding an unrelated new one or as you renaming the column. By allowing you to inspect and edit the migration SQL, you can decide whether to rename the column (and retain the data in the column) or drop it and add a new one.</p><p>If you're upgrading Prisma Migrate from the Experimental version, check out the <a href="https://www.prisma.io/docs/guides/prisma-guides/prisma-migrate-guides/add-prisma-migrate-to-a-project">upgrade guide</a>.</p><hr><h2 id="whats-next"><a href="#whats-next" aria-label="whats next permalink"></a>What's next</h2><p>This Preview version of Prisma Migrate lays the foundations for the upcoming General Availability release. Some of the improvements we are considering are improved support for native database types, seeding functionality, and finding a way to make database resets in development less disruptive.</p><h3 id="native-database-types"><a href="#native-database-types" aria-label="native database types permalink"></a>Native database types</h3><p>One of the most requested features in Prisma is support for the database's native types. This release is a step closer to that – however, there's still more work to be done for native types to be fully supported.</p><p>Currently, the Prisma schema can only represent a limited set of types: <code>String</code>, <code>Int</code>, <code>Float</code>, <code>Boolean</code>, <code>DateTime</code>, and <code>Json</code>. Each of these types has a default mapping to an underlying database type that's specified for each database connector (see the mappings for <a href="https://www.prisma.io/docs/concepts/database-connectors/postgresql#prisma-migrate">PostgreSQL</a> and <a href="https://www.prisma.io/docs/concepts/database-connectors/mysql#prisma-migrate">MySQL</a>).</p><p>In version <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/releases/tag/2.11.0">2.11.0</a>, we released the <code>nativeTypes</code> Preview feature – the ability to annotate fields in the Prisma schema with the specific native database type that it should be mapped to. <strong>However, the native types preview feature doesn't work with Prisma Migrate yet</strong>.</p><p>Even so, you can still change the types of columns in the generated SQL as long as they are supported, as documented in the <a href="https://www.prisma.io/docs/concepts/database-connectors/postgresql#prisma-migrate">PostgreSQL</a> and <a href="https://www.prisma.io/docs/concepts/database-connectors/mysql#prisma-migrate">MySQL</a> connector docs.</p><hr><p>We built Prisma Migrate for you and are keen to hear your feedback.</p><p>We want to understand how Prisma Migrate fits into your development workflow and how we can help you stay productive and confident while building and evolving data-centric applications.</p><p>🐛 Tried it out and found that it's missing something or stumbled upon a bug? Please <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/new/choose">file an issue</a> so we can look into it.</p><p>🏗 Share your feedback about how the new Prisma Migrate is working out for you on <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/4531">GitHub</a>.</p><p>🌍 Join us on our <a target="_blank" rel="noopener noreferrer" href="https://slack.prisma.io/">Slack</a> in the <a target="_blank" rel="noopener noreferrer" href="https://app.slack.com/client/T0MQBS8JG/C01ACF1DJ1M"><code>#prisma-migrate</code></a> channel for help.</p><p>👷‍♀️ We are thrilled to finally share the Preview version of Prisma Migrate and can't wait to see what you all build with it.</p></div></div></article></div>]]>
            </description>
            <link>https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357937</guid>
            <pubDate>Wed, 09 Dec 2020 12:47:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games people play with cash flow]]>
            </title>
            <description>
<![CDATA[
Score 369 | Comments 138 (<a href="https://news.ycombinator.com/item?id=25357669">thread link</a>) | @kalonis
<br/>
December 9, 2020 | https://commoncog.com/blog/cash-flow-games/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/cash-flow-games/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <p>In my <a href="https://commoncog.com/blog/how-first-principles-thinking-fails/">last post</a> I examined how first principles thinking fails. This post is going to be about a single, concrete example — about an argument that started me down this path in the first place.</p><p>A couple of months ago, a friend sent me a blog post titled <em><a href="https://ensorial.com/2020/dont-raise-money/">Startups Shouldn’t Raise Money</a></em>, over at a website called ensorial.com. I thought that the post was tightly argued and reasonably put together, with each proposition leading logically and coherently to the next. I also noticed that the author had taken the time to construct their argument from first principles … which meant it was difficult to refute any individual clause in their chain of reasoning.</p><p>But I also thought it was wrong. I told my friend as much.</p><p>“How is it wrong?” he immediately challenged.</p><p>“Well …” I began. And then I stopped. I realised I didn’t have a good argument for <em>why</em> it was wrong. Every axiom and intermediate proposition were ideas that I agreed with. And it wasn’t so simple as the conclusion being flat out mistaken — you <em>could</em> probably run a small, successful internet business using the ideas laid out in the posts’s argument (internet-based businesses tend to be simpler to manage, and there are many niches you can occupy).</p><p>But I felt uneasy because I thought the framing wasn’t as <em>useful</em>. This was a more complex thing to debunk.</p><h2 id="the-setup">The Setup</h2><p>It’s easy to think that arguments have just three terminal truth values: right, maybe, and wrong. In practice, arguments (and in particular, the sort of argument that we use to justify actions) have many possible truth values. These include things like ‘got the details wrong, but is by-and-large correct’, or ‘is correct but for a <a href="https://commoncog.com/blog/the-right-level-of-abstraction/">different level of abstraction</a>; doesn’t apply here’, or ‘is partially correct, but isn’t as useful compared to a different framing of things.’ The ensorial.com piece is interesting because I think it is an instance of that last one. It was what pushed me to start thinking about all the various ways first principles thinking could go wrong.</p><p>The author’s argument unfolds as follows:</p><ol><li>Startups are risky.</li><li>Raising capital to do a startup reduces skin in the game (you’re spending other people’s money, after all).</li><li>Once you have less skin in the game, it is easier to make bad decisions. The author argues this is due to a) having a capital buffer to cushion you, and b) having more time to waste.</li><li>The alternative is to forego raising venture capital and to create a sustainable business from the beginning, ‘growing linearly with the number of people that give you money for your product.’</li><li>This aligns incentives: you grow only by solving customer problems that they would pay you for. And you’ll pick the shortest path, because you don’t have the luxury of time given to you by an infusion of other people’s money.</li><li>Therefore: startups shouldn’t raise money.</li></ol><p>At first glance, there doesn’t seem to be anything that’s explicitly <em>wrong</em> with this argument. I agree with all the base ideas, and I found myself nodding to the intermediate propositions. The logical correctness of the argument wasn’t a problem. No, my unease stemmed from experience: I <em>knew</em> this wasn’t the right way to think about raising capital. But I couldn’t begin to construct an argument that went against it.</p><figure><img src="https://commoncog.com/blog/content/images/2020/12/argument_chain.f369ba07141442ea959636c21f56e207.png" alt=""></figure><p>My friend and I spent no more than 10 minutes discussing this piece. But in the months after our conversation, I continued to return to the author’s argument. I thought it was interesting because it represented a type of thinking error that you and I are likely to encounter in our lives. The form of the error is subtle, and therefore more difficult to detect; the best description I have for it is: ‘perfectly rational, logically constructed, and not really <em>wrong</em> — but not as useful or as powerful as some other framing.’</p><p>Of course, my obsession was for instrumental reasons: how might you recognise a better framing when you found one? I’ll admit that I was a little naive here: I thought that if I could generalise the structure of this argument, I would be better able to recognise similar errors in the future. Alas, I have not been able to do this to my satisfaction.</p><p>(In practice, most of the older entrepreneurs I know seem to understand the problems with such sensemaking. Plausible arguments are dealt with in a simple manner: you try the recommendations that unfold from the analysis, but you remain alert to see if they give you exactly the results you want. If they don’t, you keep the frame for the time being, but you continue to look out for a better explanation. And how would you know if you have found a better way of thinking about your situation? Simple: you listen carefully. In the words of Malaysian magnate Robert Kuok, “you learn to distill wisdom from the air.”)</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>The most I’ve been able to do is to articulate <em>how</em> the author messed up — and therefore how first principles thinking may fail — something that I <a href="https://commoncog.com/blog/how-first-principles-thinking-fails/">explored in my previous post</a>. The core idea is simple: I believe the author started from a limited set of axioms. If you start from a wrong set of axioms, you would eventually end up with a flawed conclusion. In this case, I think the ensorial.com author started from a deficient understanding of business.</p><p>To generalise a little, people with limited understanding of business think that business is all about making profits. But those who actually run businesses know that running a business is all about managing cash flows.</p><p>And the ensorial.com author’s argument fails because he doesn’t appear to understand this.</p><h2 id="john-malone-and-the-invention-of-ebitda">John Malone and the Invention of EBITDA</h2><p>In 1972, a 32 year old man named John Malone was offered the top job at Tele-Communications Inc (TCI), a cable company. He took charge on April Fool’s Day, 1973.</p><p>At the time of his hiring, Malone was president of Jerrold Electronics, a division of General Instrument that supplied cable boxes and credit to the cable systems companies. He had been offered the Jerrold Electronics job when he was 29 years old, just two years earlier. Before JE, he was at McKinsey Consulting. And before McKinsey, he had a job at AT&amp;T’s famed Bell Labs, where he applied operations research to find optimal company strategies in monopoly markets. Malone concluded that AT&amp;T should increase its debt load and aggressively reduce its equity base through share repurchases — a highly unorthodox recommendation at the time. His advice was delivered to AT&amp;T’s board and then promptly ignored.</p><p>Malone had been thinking about the interplay between debt, profit, cash flow, and corporate taxes for some time. In 1972, when he was first offered the TCI job, he had already noticed a number of structural properties in the cable industry that piqued his interest:</p><ol><li>The cable industry had highly predictable subscription revenues. Cable television customers in the 60s — especially those in rural communities — were eager to upgrade to cable for better TV reception. These subscribers paid monthly fees and rarely cancelled.</li><li>Cable franchises were essentially a legal right to a local monopoly, which meant that cable system operators had limited competition once it established itself in a given locale.</li><li>The industry itself had very favourable tax characteristics — smart cable operators could shelter their cash flow from taxes by using debt to build new systems, and by aggressively depreciating the costs of construction. Once the depreciation ran out on particular systems, they could then sell them to another operator, where the depreciation clock would start anew.</li><li>Most importantly, the entire market was growing like a weed: over the course of the 60s and into the start of the 70s, subscriber counts had grown over twentyfold.</li></ol><p>Of course, Malone didn’t have much time to reflect on these observations. He landed at TCI and found the company at the brink of bankruptcy.</p><p>Bob Magness, the founder of TCI, had grown the company over the course of two decades using a ridiculous pile of debt — about 17 times revenues, at the time of Malone’s hiring. Malone spent his first couple of years at TCI fighting to keep the company alive. He flew into New York every couple of weeks, hat in hand, renegotiating <a href="https://www.investopedia.com/terms/c/covenant.asp">covenants</a> and asking for extensions on debt repayments. At one point during a meeting with TCI’s bankers, Malone threw his keys on the table and threatened to walk, leaving the company to the banks. The bankers capitulated, granting TCI a much needed extension.</p><p>Malone and Magness also had to worry about hostile takeovers, given TCI’s low stock price in the early 70s. They executed a series of complicated financial manoeuvres a year or so after Malone took over, placing a large chunk of stock in a holding company to grant them majority control. Later, they created a separate class of voting stock. These moves gave them hard control of the company, allowing Malone the freedom to focus on righting its finances.</p><p>After three years of hell, TCI was finally pulled back from the brink of financial disaster. And then Malone got to work.</p><p>Malone understood a few things about the cable industry that many outsiders didn’t. First, he understood that cable was like real estate: incredibly high fixed costs up front as you built or bought the systems, and then highly predictable, monopoly cash flows for a long time afterwards. He understood that if he used debt to finance acquisitions, he could keep growing the company, and use the depreciation on acquired systems (plus the write-offs from the loans itself) to delay paying taxes on that cash flow. Third, Malone understood that untaxed cash flows from all of those cable subscribers could be used to a) service the debt, b) pay down some of those loans — only when necessary; Malone wanted to keep the debt-to-earnings ratio at a five-to-one level — but more importantly c) demonstrate to creditors that TCI was a worthy debtor. And finally, Malone understood the benefits of size: the larger TCI got, the lower the cost of acquiring programming (i.e. shows and programs), because it could amortise those costs across its entire subscriber …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/cash-flow-games/">https://commoncog.com/blog/cash-flow-games/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/cash-flow-games/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357669</guid>
            <pubDate>Wed, 09 Dec 2020 11:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is the Google Cloud UI so slow?]]>
            </title>
            <description>
<![CDATA[
Score 484 | Comments 376 (<a href="https://news.ycombinator.com/item?id=25357409">thread link</a>) | @mostlystatic
<br/>
December 9, 2020 | https://www.debugbear.com/blog/slow-google-cloud-ui | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/slow-google-cloud-ui">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>Opening a page in the Google Cloud Console always takes a long time.</p>
<p>Here are some metrics I collected on a high-end 2018 MacBook Pro on a UK-based Gigabit internet connection.</p>

<div id="slow-gcp-table">
<table>
<thead>
<tr>
<th>Page</th>
<th>Download</th>
<th>JavaScript</th>
<th>CPU Time</th>
<th>Main Content</th>
<th>Fully Loaded</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloud Functions</td>
<td>4.2 MB</td>
<td>15.7 MB</td>
<td>5.3s</td>
<td>6.7s</td>
<td>8.1s</td>
</tr>
<tr>
<td>Compute Engine</td>
<td>4.5 MB</td>
<td>15.1 MB</td>
<td>6.5s</td>
<td>6.7s</td>
<td>8.1s</td>
</tr>
<tr>
<td>Cloud Storage</td>
<td>4.3 MB</td>
<td>16.2 MB</td>
<td>6.2s</td>
<td>6.5s</td>
<td>8.2s</td>
</tr>
</tbody>
</table>
</div>
<p>Download size is the compressed size, JavaScript size is uncompressed. Main Content is the time when e.g. the Cloud Functions become visible, Fully Loaded is when no more changes are made to the UI.</p>

<p>We can see that each page loads over 15 MB of JavaScript code. A look at the performance timeline in Chrome DevTools confirms that running this code is the primary cause of the poor page performance.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/timeline.png" alt="DevTools CPU timeline showing a large amount of JavaScript work"></p>
<p>This article will take a closer look at the page load process of the Google Cloud Functions page, and examine how it could be sped up.</p>
<p>You can use these strategies to investigate and improve the performance of the apps you're working on.</p>
<h2 id="loading-the-html-document">Loading the HTML document</h2>
<p>The initial HTML request is very fast and only takes about 150ms. It contains an embedded SVG spinner that shows while the first chunk of JavaScript code is loading.</p>
<video autoplay="" muted="" loop="" playsinline="">
    <source src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/gcp-spinner.mp4" type="video/mp4">
</video>
<h2 id="loading-the-initial-java-script-bundles">Loading the initial JavaScript bundles</h2>
<p>These are the first two JavaScript bundles the page starts loading.</p>
<ul>
<li><strong>routemap</strong> 21 KB (103 KB uncompressed)</li>
<li><strong>core,pm_ng1_bootstrap</strong> 1.3 MB (4.8 MB uncompressed)</li>
</ul>
<p>These files don't take too long to download, but running the code freezes the UI for a while. The spinner SVG becomes stuck at this point, until it's replaced by a skeleton UI for Google Cloud Console page.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/gcp-initial-load.png" alt="Filmstrip showing initial rendering of the GCP page"></p>
<p>Here's what happens when the browser wants to run some JavaScript code.</p>
<ol>
<li><strong>Parsing</strong> (done lazily at first, and then as needed later on)</li>
<li><strong>Compilation</strong> (also happens lazily)</li>
<li><strong>Initialization</strong> –&nbsp;the browser runs module initialization code, i.e. code that runs when loading a module rather than when calling one of its functions</li>
<li><strong>Running core app code</strong> – renders the application using the initialized modules</li>
</ol>
<p>For the whole Google Cloud page, just parsing the source code takes 250ms, and compilation takes another 750ms (not including the 113 ms spent on "Compile Script").</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/devtools-profile.png" alt="DevTools profile showing a breakdown of CPU activity"></p>
<p>The initial render of the Angular app takes about 1s.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/initial-bundle.png" alt="JavaScript execution flamechart"></p>
<p>Eventually we start to see a new spinner.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/second-spinner.png" alt="Page frame and new spinner"></p>
<h2 id="loading-page-bundles">Loading page bundles</h2>
<p>Once the generic Google Cloud UI is rendered the page starts loading 18 additional JavaScript files with an overall size of 1.5 MB.</p>
<p>Making a lot of separate requests isn't actually a problem though – it can improve performance by increasing the likelinhood of cache hits, and splitting up bundles makes it easy to load only necessary code.</p>
<p>After loading the first set up bundles the app starts making fetch requests and loads 3 more bundles at a total size of 6 MB.</p>
<p>When loading the page on my normal network the requests all kind of blurred together and it was hard to see which requests were sequential. So this screenshot shows the request chart on a throttled connection.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/more-page-bundles.png" alt="Request waterfall showing three sets of JavaScript being loaded sequentially"></p>
<h2 id="loading-the-list-of-cloud-functions">Loading the list of Cloud Functions</h2>
<p>The request loading the list of Cloud Functions takes about 700ms. But it doesn't start as soon as the bundles are loaded, in part because there's a <code>testIamPermissions</code> request that needs to finish first.</p>
<p>As a result the CPU ends up being idle for half a second –&nbsp;this time could be used better if the request started sooner.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/loading-functions.png" alt="Waterfall showing requests made to load the list of cloud functions"></p>
<p>Finally the app re-renders and we get the list of Cloud Functions we wanted to see.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/cloud-functions.png" alt="Page showing GCP Cloud Functions"></p>

<p>Chrome DevTools has a code coverage tool tracks which parts of the code actually run on the current page. This can help identify code that doesn't have to be loaded.</p>
<p>The Cloud Functions page runs 53% of the JavaScript code it downloads. This is actually a bit disappointing, as it means that even if only necessary code is loaded it would still only cut the total JavaScript size of the page in half.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/code-coverage.png" alt="Chrome DevTools Code Coverage tool"></p>
<h2 id="moving-configuration-into-json">Moving configuration into JSON</h2>
<p>A good amount of the code actually consists of configuration objects. For example, this 200 KB object with 4997 keys.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/configuration.png" alt="Configuration object in a JavaScript bundle"></p>
<p>Loading this as a JSON string with <code>JSON.parse</code> could be faster, as JSON is simpler to parse than a JavaScript object. This would be easy to do, but might not result in a huge performance improvement.</p>
<p>Ideally the app wouldn't need to load the full list on the client, but this would be harder to implement.</p>
<h2 id="reduce-code-duplication">Reduce code duplication</h2>
<p>The 200KB JSON object above is actually included in two of the JavaScript bundles. Breaking it out and reusing it would save download and processing time.</p>
<p>The same seems to apply to a bunch of UI components, like this one.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/code-duplication.png" alt="Duplicate code in DevTools code search"></p>
<h2 id="prioritize-primary-content">Prioritize primary content</h2>
<p>The Google Cloud page loads a large initial JavaScript bundle. The longer it takes to load and initialize this code, the longer it takes to load page-specific code and to render the list of Cloud Functions the user wants to see.</p>
<p>But the initial bundle also contains secondary content, like the complex navigation sidebar. This menu becomes functional before the main page content is loaded, but it should only be loaded after the primary content.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/prioritize-primary-content.png" alt="Sidebar menu is open while main content is still loading"></p>
<p>Google Cloud already does this in some cases. For example, the page initially renders a simpler version of the header and then loads more complex features later on.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/header.png" alt="Header doesn't show project dropdown at first and then shows it later"></p>
<h2 id="conclusion">Conclusion</h2>
<p>While the performance of static pages tends to be dominated by render-blocking network requests, single-page apps are often blocked by JavaScript execution or loading account data.</p>
<p>Downloading large amounts of code can hurt performance on slow connections, but due to compression and caching CPU processing often has a greater impact.</p>
<p>If you want to track the performance of your website, including logged-in pages, <a href="https://www.debugbear.com/">give DebugBear a try</a>.</p>
<blockquote><p lang="en" dir="ltr">Why is the Google Cloud UI so slow? This article looks at the performance of a large JavaScript application and explores how it could be made faster.<a href="https://t.co/HSHhCXYQCi">https://t.co/HSHhCXYQCi</a></p>— DebugBear (@DebugBear) <a href="https://twitter.com/DebugBear/status/1336621651669213186?ref_src=twsrc%5Etfw">December 9, 2020</a></blockquote> 

        

        
        <div>
            <div>
                <p>
                    DebugBear is a website monitoring tool built for front-end teams.
                    Track performance metrics and Lighthouse scores in CI and production.
                    <a href="https://www.debugbear.com/?noredirect&amp;from_blog">Learn more</a>.
                </p>
                
            </div>
        </div>
        <div>
        
                    <!-- Begin Mailchimp Signup Form -->
            
            
            <div>
                <div>
                    
                    <div>
                        
                        <h2>Get new articles on web performance <!-- and debugging --> by email.</h2>
                    </div>
                </div>
                
            </div>
        
            
        
        </div>      </div>
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://www.debugbear.com/blog/slow-google-cloud-ui</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357409</guid>
            <pubDate>Wed, 09 Dec 2020 11:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Python object system works]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25357032">thread link</a>) | @r4victor
<br/>
December 9, 2020 | https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>As we know from the previous parts of this series, the execution of a Python program consists of two major steps:</p>
<ol>
<li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">The CPython compiler</a> translates Python code to bytecode.</li>
<li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">The CPython VM</a> executes the bytecode.</li>
</ol>
<p>We've been focusing on the second step for quite a while. In <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">part 4</a> we've looked at the evaluation loop, a place where Python bytecode gets executed. And in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/">part 5</a> we've studied how the VM executes the instructions that are used to implement variables. What we haven't covered yet is how the VM actually computes something. We postponed this question because to answer it, we first need to understand how the most fundamental part of the language works. Today, we'll study the Python object system.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h2>Motivation</h2>
<p>Consider an extremely simple piece of Python code:</p>



<p>To compute the function <code>f</code>, CPython must evaluate the expression <code>x + 7</code>. The question I'd like to ask is: How does CPython do that? Special methods such as <code>__add__()</code> and <code>__radd__()</code> probably come to your mind. When we define these methods on a class, the instances of that class can be added using the <code>+</code> operator. So, you might think that CPython does something like this:</p>
<ol>
<li>It calls <code>x.__add__(7)</code> or <code>type(x).__add__(x, 7)</code>.</li>
<li>If <code>x</code> doesn't have <code>__add__()</code>, or if this method fails, it calls <code>(7).__radd__(x)</code> or <code>int.__radd__(7, x)</code>.</li>
</ol>
<p>The reality, tough, is a bit more complicated. What really happens depends on what <code>x</code> is. For example, if <code>x</code> is an instance of a user-defined class, the algorithm described above resembles the truth. If, however, <code>x</code> is an instance of a built-in type, like <code>int</code> or <code>float</code>, CPython doesn't call any special methods at all.</p>
<p>To learn how some Python code is executed, we can do the following:</p>
<ol>
<li>Disassemble the code into bytecode.</li>
<li>Study how the VM executes the disassembled bytecode instructions.</li>
</ol>
<p>Let's apply this algorithm to the function <code>f</code>. The compiler translates the body of this function to the following bytecode:</p>
<div><pre><span></span>$ python -m dis f.py
...
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (7)
              4 BINARY_ADD
              6 RETURN_VALUE
</pre></div>


<p>And here's what these bytecode instructions do:</p>
<ol>
<li><code>LOAD_FAST</code> loads the value of the parameter <code>x</code> onto the stack.</li>
<li><code>LOAD_CONST</code> loads the constant <code>7</code> onto the stack.</li>
<li><code>BINARY_ADD</code> pops two values from the stack, adds them and pushes the result back onto the stack.</li>
<li><code>RETURN_VALUE</code> pops the value from the stack and returns it.</li>
</ol>
<p>How does the VM add two values? To answer this question, we need to understand what these values are. For us, <code>7</code> is an instance of <code>int</code> and <code>x</code> is, well, anything. For the VM, though, everything is a Python object. All values the VM pushes onto the stack and pops from the stack are pointers to <code>PyObject</code> structs (hence the phrase "Everything in Python is an object").</p>
<p>The VM doesn't need to know how to add integers or strings, that is, how to do the arithmetic or concatenate sequences. All it needs to know is that every Python object has a type. A type, in turn, knows everything about its objects. For example, the <code>int</code> type knows how to add integers, and the <code>float</code> type knows how to add floats. So, the VM asks the type to perform the operation.</p>
<p>This simplified explanation captures the essence of the solution, but it also omits a lot of important details. To get a more realistic picture, we need to understand what Python objects and types really are and how they work.</p>
<h2>Python objects and types</h2>
<p>We've discussed Python objects a little in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-3-stepping-through-the-cpython-source-code/">part 3</a>. This discussion is worth repeating here.</p>
<p>We begin with the definition of the <code>PyObject</code> struct:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>_object</span> <span>{</span>
    <span>_PyObject_HEAD_EXTRA</span> <span>// macro, for debugging purposes only</span>
    <span>Py_ssize_t</span> <span>ob_refcnt</span><span>;</span>
    <span>PyTypeObject</span> <span>*</span><span>ob_type</span><span>;</span>
<span>}</span> <span>PyObject</span><span>;</span>
</pre></div>


<p>It has two members:</p>
<ul>
<li>a reference count <code>ob_refcnt</code> that CPython uses for garbage collection; and</li>
<li>a pointer to the object's type <code>ob_type</code>.</li>
</ul>
<p>We said that the VM treats any Python object as <code>PyObject</code>. How is that possible? The C programming language has no notion of classes and inheritance. Nevertheless, it's possible to implement in C something that can be called a single inheritance. The C standard states that a pointer to any struct can be converted to a pointer to its first member and vice versa. So, we can "extend" <code>PyObject</code> by defining a new struct whose first member is <code>PyObject</code>.</p>
<p>Here's, for example, how the <code>float</code> object is defined:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_HEAD macro</span>
    <span>double</span> <span>ob_fval</span><span>;</span>
<span>}</span> <span>PyFloatObject</span><span>;</span>
</pre></div>


<p>A <code>float</code> object stores everything <code>PyObject</code> stores plus a floating-point value <code>ob_fval</code>. The C standard simply states that we can convert a pointer to <code>PyFloatObject</code> to a pointer to <code>PyObject</code> and vice versa:</p>
<div><pre><span></span><span>PyFloatObject</span> <span>float_object</span><span>;</span>
<span>// ...</span>
<span>PyObject</span> <span>*</span><span>obj_ptr</span> <span>=</span> <span>(</span><span>PyObject</span> <span>*</span><span>)</span><span>&amp;</span><span>float_object</span><span>;</span>
<span>PyFloatObject</span> <span>*</span><span>float_obj_ptr</span> <span>=</span> <span>(</span><span>PyFloatObject</span> <span>*</span><span>)</span><span>obj_ptr</span><span>;</span>
</pre></div>


<p>The reason why the VM treats every Python object as <code>PyObject</code> is because all it needs to access is the object's type. A type is also a Python object, an instance of the <code>PyTypeObject</code> struct:</p>
<div><pre><span></span><span>// PyTypeObject is a typedef for "struct _typeobject"</span>

<span>struct</span> <span>_typeobject</span> <span>{</span>
    <span>PyVarObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_VAR_HEAD macro</span>
    <span>const</span> <span>char</span> <span>*</span><span>tp_name</span><span>;</span> <span>/* For printing, in format "&lt;module&gt;.&lt;name&gt;" */</span>
    <span>Py_ssize_t</span> <span>tp_basicsize</span><span>,</span> <span>tp_itemsize</span><span>;</span> <span>/* For allocation */</span>

    <span>/* Methods to implement standard operations */</span>

    <span>destructor</span> <span>tp_dealloc</span><span>;</span>
    <span>Py_ssize_t</span> <span>tp_vectorcall_offset</span><span>;</span>
    <span>getattrfunc</span> <span>tp_getattr</span><span>;</span>
    <span>setattrfunc</span> <span>tp_setattr</span><span>;</span>
    <span>PyAsyncMethods</span> <span>*</span><span>tp_as_async</span><span>;</span> <span>/* formerly known as tp_compare (Python 2)</span>
<span>                                    or tp_reserved (Python 3) */</span>
    <span>reprfunc</span> <span>tp_repr</span><span>;</span>

    <span>/* Method suites for standard classes */</span>

    <span>PyNumberMethods</span> <span>*</span><span>tp_as_number</span><span>;</span>
    <span>PySequenceMethods</span> <span>*</span><span>tp_as_sequence</span><span>;</span>
    <span>PyMappingMethods</span> <span>*</span><span>tp_as_mapping</span><span>;</span>

    <span>/* More standard operations (here for binary compatibility) */</span>

    <span>hashfunc</span> <span>tp_hash</span><span>;</span>
    <span>ternaryfunc</span> <span>tp_call</span><span>;</span>
    <span>reprfunc</span> <span>tp_str</span><span>;</span>
    <span>getattrofunc</span> <span>tp_getattro</span><span>;</span>
    <span>setattrofunc</span> <span>tp_setattro</span><span>;</span>

    <span>/* Functions to access object as input/output buffer */</span>
    <span>PyBufferProcs</span> <span>*</span><span>tp_as_buffer</span><span>;</span>

    <span>/* Flags to define presence of optional/expanded features */</span>
    <span>unsigned</span> <span>long</span> <span>tp_flags</span><span>;</span>

    <span>const</span> <span>char</span> <span>*</span><span>tp_doc</span><span>;</span> <span>/* Documentation string */</span>

    <span>/* Assigned meaning in release 2.0 */</span>
    <span>/* call function for all accessible objects */</span>
    <span>traverseproc</span> <span>tp_traverse</span><span>;</span>

    <span>/* delete references to contained objects */</span>
    <span>inquiry</span> <span>tp_clear</span><span>;</span>

    <span>/* Assigned meaning in release 2.1 */</span>
    <span>/* rich comparisons */</span>
    <span>richcmpfunc</span> <span>tp_richcompare</span><span>;</span>

    <span>/* weak reference enabler */</span>
    <span>Py_ssize_t</span> <span>tp_weaklistoffset</span><span>;</span>

    <span>/* Iterators */</span>
    <span>getiterfunc</span> <span>tp_iter</span><span>;</span>
    <span>iternextfunc</span> <span>tp_iternext</span><span>;</span>

    <span>/* Attribute descriptor and subclassing stuff */</span>
    <span>struct</span> <span>PyMethodDef</span> <span>*</span><span>tp_methods</span><span>;</span>
    <span>struct</span> <span>PyMemberDef</span> <span>*</span><span>tp_members</span><span>;</span>
    <span>struct</span> <span>PyGetSetDef</span> <span>*</span><span>tp_getset</span><span>;</span>
    <span>struct</span> <span>_typeobject</span> <span>*</span><span>tp_base</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_dict</span><span>;</span>
    <span>descrgetfunc</span> <span>tp_descr_get</span><span>;</span>
    <span>descrsetfunc</span> <span>tp_descr_set</span><span>;</span>
    <span>Py_ssize_t</span> <span>tp_dictoffset</span><span>;</span>
    <span>initproc</span> <span>tp_init</span><span>;</span>
    <span>allocfunc</span> <span>tp_alloc</span><span>;</span>
    <span>newfunc</span> <span>tp_new</span><span>;</span>
    <span>freefunc</span> <span>tp_free</span><span>;</span> <span>/* Low-level free-memory routine */</span>
    <span>inquiry</span> <span>tp_is_gc</span><span>;</span> <span>/* For PyObject_IS_GC */</span>
    <span>PyObject</span> <span>*</span><span>tp_bases</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_mro</span><span>;</span> <span>/* method resolution order */</span>
    <span>PyObject</span> <span>*</span><span>tp_cache</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_subclasses</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_weaklist</span><span>;</span>
    <span>destructor</span> <span>tp_del</span><span>;</span>

    <span>/* Type attribute cache version tag. Added in version 2.6 */</span>
    <span>unsigned</span> <span>int</span> <span>tp_version_tag</span><span>;</span>

    <span>destructor</span> <span>tp_finalize</span><span>;</span>
    <span>vectorcallfunc</span> <span>tp_vectorcall</span><span>;</span>
<span>};</span>
</pre></div>


<p>By the way, note that the first member of a type is not <code>PyObject</code> but <code>PyVarObject</code>, which is defined as follows:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span>
    <span>Py_ssize_t</span> <span>ob_size</span><span>;</span> <span>/* Number of items in variable part */</span>
<span>}</span> <span>PyVarObject</span><span>;</span>
</pre></div>


<p>Nevertheless, since the first member of <code>PyVarObject</code> is <code>PyObject</code>, a pointer to a type can still be converted to a pointer to <code>PyObject</code>.</p>
<p>So, what is a type and why does it have so many members? A type determines how the objects of that type behave. Each member of a type, called slot, is responsible for a particular aspect of the object's behavior. For example:</p>
<ul>
<li><code>tp_new</code> is a pointer to a function that creates new objects of the type.</li>
<li><code>tp_str</code> is a pointer to a function that implements  <code>str()</code> for objects of the type.</li>
<li><code>tp_hash</code> is a pointer to a function that implements  <code>hash()</code> for objects of the type.</li>
</ul>
<p>Some slots, called sub-slots, are grouped together in suites. A suite is just a struct that contains related slots. For example, the <code>PySequenceMethods</code> struct is a suite of sub-slots that implement the sequence protocol:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>lenfunc</span> <span>sq_length</span><span>;</span>
    <span>binaryfunc</span> <span>sq_concat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_repeat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_item</span><span>;</span>
    <span>void</span> <span>*</span><span>was_sq_slice</span><span>;</span>
    <span>ssizeobjargproc</span> <span>sq_ass_item</span><span>;</span>
    <span>void</span> <span>*</span><span>was_sq_ass_slice</span><span>;</span>
    <span>objobjproc</span> <span>sq_contains</span><span>;</span>

    <span>binaryfunc</span> <span>sq_inplace_concat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_inplace_repeat</span><span>;</span>
<span>}</span> <span>PySequenceMethods</span><span>;</span>
</pre></div>


<p>If you count all the slots and sub-slots, you'll get a scary number. Fortunately, each slot is very well <a href="https://docs.python.org/3/c-api/typeobj.html">documented</a> in the Python/C API Reference Manual (I strongly recommend you to bookmark this link). Today we'll cover only a few slots. Nevertheless, it shall give us a general idea of how slots are used.</p>
<p>Since we're interested in how CPython adds objects, let's find the slots responsible for addition. There must be at least one such slot. After careful inspection of the <code>PyTypeObject</code> struct, we find that it has the "number" suite <code>PyNumberMethods</code>, and the first slot of this suite is a binary function called <code>nd_add</code>:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>binaryfunc</span> <span>nb_add</span><span>;</span> <span>// typedef PyObject * (*binaryfunc)(PyObject *, PyObject *)</span>
    <span>binaryfunc</span> <span>nb_subtract</span><span>;</span>
    <span>binaryfunc</span> <span>nb_multiply</span><span>;</span>
    <span>binaryfunc</span> <span>nb_remainder</span><span>;</span>
    <span>binaryfunc</span> <span>nb_divmod</span><span>;</span>
    <span>// ... more sub-slots</span>
<span>}</span> <span>PyNumberMethods</span><span>;</span>
</pre></div>


<p>It seems that the <code>nb_add</code> slot is what we're looking for. Two questions naturally arise regarding this …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357032</guid>
            <pubDate>Wed, 09 Dec 2020 10:04:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Highly Effective Techniques to Study More Effectively in 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25356878">thread link</a>) | @rossnoel
<br/>
December 9, 2020 | https://productive.fish/blog/how-to-study-effectively/ | <a href="https://web.archive.org/web/*/https://productive.fish/blog/how-to-study-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>16 Aug 2020 • 5 min read</p><p>Have you been struggling to study effectively? Sometimes it seems as if we have more pages to read than time on the clock. However, if you decide to study smart instead of studying hard, you are more likely to get the outcome that you desire. In this article, you will be given strategies on how to study effectively.</p><picture><source media="(min-width: 1100px)" srcset="https://productive.fish/blog/how-to-study-effectively/studying-920.jpg, https://productive.fish/blog/how-to-study-effectively/studying.jpg 2x"><source media="(max-width: 1099px) and (min-width: 421px)" srcset="https://productive.fish/blog/how-to-study-effectively/studying-640.jpg, https://productive.fish/blog/how-to-study-effectively/studying-1280.jpg 2x"><source media="(max-width: 420px)" srcset="https://productive.fish/blog/how-to-study-effectively/studying-420.jpg, https://productive.fish/blog/how-to-study-effectively/studying-840.jpg 2x"><img src="https://productive.fish/blog/how-to-study-effectively/studying.jpg" alt="Illustration of studying person"></picture><h2 id="organize-your-learning-process">Organize your learning process</h2><p>Organizing your entire learning process is the very first step that you need to take in studying more effectively. You will need to assign a particular place in your home where you get your studying done, determine a schedule that guides your study time, and you will need to decide whether or not you will be studying in a group or by yourself. You will also need to determine what study style is best for you. Having this in place helps you to approach your studying in a more systematic and efficient manner.</p><p>Let’s take a look at approaches that can help you to better understand how to learn effectively.</p><h3 id="spaced-repetition">Spaced Repetition</h3><p><a href="https://productive.fish/blog/spaced-repetition">Spaced repetition</a> refers to the practice of allowing space between each study session. By integrating time intervals in your study schedule, you will be able to retain more even if you spend less time studying.</p><p>This works by tapping into the potential of what is called the spacing effect. This speaks to the fact that our brain is better able to learn new concepts by using intervals between exposure to the information.</p><p>How to study more effectively with this method? Let’s say you have an exam scheduled for next week. You should have a study session today. Your next study session would be two days from today. You should then have a final study session the day before the test.</p><h3 id="active-recall">Active recall</h3><p>Another way to learn effectively is to employ the principles of active recall. This approach has been found to be the most effective, efficient, and quickest way to study materials. This approach holds that in order to get the best out of studying, you need to actively stimulate your memory. This moves students from a passive approach to studying such as simply reading silently to an approach where the student interacts with the material.</p><p>This includes asking and answering questions about the material read and many other tactics. You will find that there are a number of different ways to implement active recall. Two popular methods of active learning are the Read-Recite-Review (3R) method and the Feynman Technique.</p><h3 id="pomodoro-technique-and-the-importance-of-study-breaks">Pomodoro Technique and the Importance of Study Breaks</h3><p>The struggle we all have with procrastination is real and should not be overlooked. One of the best strategies for minimizing distractions is the <a href="https://productive.fish/blog/pomodoro-technique">Pomodoro technique</a>. This approach helps to keep you from becoming overwhelmed by studying and from burnouts. It includes stipulated work intervals and breaks.</p><p>An example of studying effectively with the Pomodoro technique is as follows:</p><ul><li>Study for 25 minutes</li><li>Distractions will come. When they do, write them down on a piece of paper.</li><li>At the end of the 25-minute period, place a check mark on your paper.</li><li>Break from studying for 5 minutes.</li><li>After doing this 4 times, take a 30-minute break.</li><li>Repeat the entire process.</li></ul><p>This method was developed by Francesco Cirillo. This time management technique was inspired by the popular tomato-shaped kitchen timer.</p><p>Breaks are critical to learning effectively. These breaks help to maintain performance while studying, reduce the stress associated with studying, increase focus, and help with memory retention.</p><h3 id="bite-sized-learning">Bite-sized learning</h3><p>Another method to consider when trying to uncover how to study better is bite-sized learning. This method means just what the name suggests – studying information in small bits or spending very short periods studying at a time.</p><p>With the constant reduction of attention span among humans in the 21st century, it is becoming more and more important that you spend 1-15 minutes at a time on any given learning objective. The focus that you will have in this short period of time makes learning more effective.</p><h2 id="take-notes-the-right-way">Take notes the right way</h2><p>There are many powerful reasons that all students should actively take notes in class and while studying. These reasons include:</p><p>Taking notes is helpful in keeping your mind alert. By actively writing notes, you are interacting with the information. This helps to reduce drowsiness and prevents distractions. The act of deciphering what information to jot down helps to keep your mind engaged in what you are reading or listening to. Taking notes gives you an opportunity to highlight or emphasize certain bits of information. It also helps with the organization of said information. The highlighted and organized information that you take during class or in a study session helps to make your future study sessions or review of class information much more effective. Taking good notes in class or during a study session provides you with an abbreviated yet potent set of information for effective studying. When it becomes necessary to study for an exam or a test, you can easily draw on your notes and spend less time reinforcing the most important points.</p><p>Let’s look at some note-taking techniques to help you effectively study.</p><h3 id="the-cornell-note-taking-system">The Cornell Note Taking System</h3><p>This system of note-taking was developed by Walter Pauk in the 1940s. This approach to notetaking is systematic and more condensed. It can be used by high school students or students at the college level.</p><p>This method entails a student dividing a page into three sections. A keyword section, the notes section, and a section for a summary of the lesson. In this method, long sentences are avoided while taking notes to reduce the bulk. The keyword section only features words or questions that are most important , which students can easily reflect on when reviewing their notes.</p><h3 id="the-outlining-method">The Outlining Method</h3><p>This method is ideal for you when your are trying to discover how to study more effectively. It includes creating an outline of the course, article or a book. In this method, information is summarized in brief bullet points. The major points are at farthest to the left while minor points are indented.</p><h3 id="the-mapping-method">The Mapping Method</h3><p>The mapping method involves the use of a graphic representation of that which is being studied. It shows how the various pieces of information to be absorbed relates to each other. The <a href="https://productive.fish/blog/mind-mapping-software">mind mapping method</a> can be coupled with the outline method or the Cornell note-taking system quite effectively.</p><h2 id="teach-someone-else">Teach someone else</h2><p>It is always said that the best way to better learn a subject is to teach it to someone else. One of the most effective ways to retain information is to share it with others. You could develop a habit of mentoring students in your class who are having a hard time grasping the concepts being taught.</p><p>Another creative way to deepen your understanding of a subject by teaching others is by starting a blog series on the topic that you are studying. You will be able to edify others while being better prepared to succeed in your next exam.</p><h2 id="conclusion">Conclusion</h2><p>Learning to study more effectively is a critical part of student success. While all of these methods have been proven to be effective, everybody learns differently; therefore, it is best for you to try each of these methods to see which is most effective for you. Fight the temptation to be lazy in this process. By finding the approach that is best for you, your entire academic life can become much smoother.</p></article></div>]]>
            </description>
            <link>https://productive.fish/blog/how-to-study-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356878</guid>
            <pubDate>Wed, 09 Dec 2020 09:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graphcore Sets New AI Performance Standards with Mk2 IPU Systems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25356767">thread link</a>) | @ingve
<br/>
December 9, 2020 | https://www.graphcore.ai/posts/graphcore-sets-new-ai-performance-standards-with-mk2-ipu-systems | <a href="https://web.archive.org/web/*/https://www.graphcore.ai/posts/graphcore-sets-new-ai-performance-standards-with-mk2-ipu-systems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				
				

				<div>
					
					<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>We’re sharing a raft of new performance results for our MK2 IPU-based machine intelligence systems today. You’ll see our IPU-M2000 system significantly outperforms the Nvidia A100 DGX across the board, with orders of magnitude performance improvements for some models.</p>
<!--more-->
<p>Graphcore customers are already making big leaps forward with our second generation IPU systems – whether they prioritise faster time to result, model accuracy, better efficiency, lower TCO (Total Cost of Ownership) or the chance to make new breakthroughs in AI with the IPU.</p>
<p>We’ve chosen a range of the most popular models our customers frequently turn to as proxies for their proprietary production AI workloads in natural language processing, computer vision and more, both in training and inference.</p>
<p>We are also delighted to share results in this blog using our new PyTorch framework support. We are continuing to develop and expand this capability – you can find out more in our blog <a href="https://www.graphcore.ai/posts/introducing-pytorch-for-the-ipu"><span>here</span></a>. <span>&nbsp;</span></p>
<p>The results are measured on IPU-M2000 &amp; IPU-POD<sub>64</sub> platforms. Wherever possible, we compare IPU performance against performance numbers published by NVIDIA for the A100 GPU as part of the DGX A100 platform. It’s notoriously hard to find an exact apples-to-apples comparison for very different products and chip architectures, so we compare against the closest platform in terms of price and power. Where NVIDIA has not published results for a particular model, measured results are used.<span>&nbsp;</span></p>
<p>Code for all of our benchmarks is available from the examples repo on the <a href="https://github.com/graphcore"><span>Graphcore GitHub</span></a> site where you can also find code for many other model types and application examples.<span>&nbsp;</span></p>
<p>We’ve included notes for each chart to explain our methodology and to provide additional information about batch sizes, data sets, floating point arithmetic, frameworks etc. In addition to publishing our benchmarking charts in this blog and on our <a href="https://www.graphcore.ai/benchmarks" rel="noopener" target="_blank">website</a>, we are also publishing performance data in <a href="https://www.graphcore.ai/performance-results" rel="noopener" target="_blank">tabular format </a>for IPU-M2000 and IPU-POD systems on our website. We’ll add more and update the results regularly.</p>
<p>Finally, we’ve also joined <a href="https://mlcommons.org/en/" rel="noopener" target="_blank">MLCommons</a>, the governing body for the independent benchmarking organisation, MLPerf. We will be participating in MLPerf in 2021 – starting with the first training submission in the Spring – as well as continuing to build out our own performance results.</p>
<p><strong><span>Natural Language Processing (NLP)</span>&nbsp;</strong></p>
<p><strong>BERT-Large Training</strong></p>
<p>BERT-Large <span>(Bidirectional Encoder Representations from Transformers)</span> is established as one of the most widely used models for NLP.</p>
<p>The IPU-POD<sub>64 </sub>is over 5x faster than a DGX A100 system for end-to-end BERT-Large Training to convergence to reference accuracies. To provide consistency in the comparisons used in our other charts, we also show time-to-train for a 2x DGX A100 system.<span>&nbsp;</span></p>
<p><span><img src="https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=2000&amp;name=BERT%20Large%20Training_December%202020.jpg" alt="BERT Large Training_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=1000&amp;name=BERT%20Large%20Training_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=2000&amp;name=BERT%20Large%20Training_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=3000&amp;name=BERT%20Large%20Training_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=4000&amp;name=BERT%20Large%20Training_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=5000&amp;name=BERT%20Large%20Training_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=6000&amp;name=BERT%20Large%20Training_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></span></p>
<p><strong>BERT-Large Inference</strong></p>
<p>The goal in inference production systems is typically to achieve the highest possible throughput at the lowest possible latency. For example, search engine companies and many automated services using inference need to respond in near real time.</p>
<p>For BERT-Large Inference, the IPU-M2000 delivers 3.4x higher throughput at the lowest latency compared to the A100.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=2000&amp;name=BERT%20Large%20Inference_December%202020.jpg" alt="BERT Large Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=1000&amp;name=BERT%20Large%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=2000&amp;name=BERT%20Large%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=3000&amp;name=BERT%20Large%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=4000&amp;name=BERT%20Large%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=5000&amp;name=BERT%20Large%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=6000&amp;name=BERT%20Large%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>Computer Vision&nbsp;</strong></p>
<p><strong>ResNet-50 Training</strong></p>
<p>The IPU-M2000 processes 2.6x more images per second vs the A100 for <a href="https://arxiv.org/abs/1512.03385"><span>ResNet-50</span></a>, a common model for image classification used as a baseline performance metric across the industry, which has been highly optimised on GPU architectures. Here we show results for IPU with both TensorFlow and PyTorch.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=2000&amp;name=ResNet%2050%20Training_December%202020.jpg" alt="ResNet 50 Training_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=1000&amp;name=ResNet%2050%20Training_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=2000&amp;name=ResNet%2050%20Training_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=3000&amp;name=ResNet%2050%20Training_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=4000&amp;name=ResNet%2050%20Training_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=5000&amp;name=ResNet%2050%20Training_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=6000&amp;name=ResNet%2050%20Training_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>ResNet-50 Inference</strong></p>
<p>The IPU-M2000 delivers 4.6x higher throughput at lowest latency comparing with published results for the A100 80GB GPU, for both PyTorch and TensorFlow, achieving much higher absolute throughput of 58,112 images per second.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=2000&amp;name=ResNet%2050%20Inference_December%202020.jpg" alt="ResNet 50 Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=1000&amp;name=ResNet%2050%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=2000&amp;name=ResNet%2050%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=3000&amp;name=ResNet%2050%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=4000&amp;name=ResNet%2050%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=5000&amp;name=ResNet%2050%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=6000&amp;name=ResNet%2050%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>EfficientNet Training</strong></p>
<p><span><a href="https://arxiv.org/abs/1905.11946">EfficientNet</a></span> uses innovative techniques like group separable and depth-wise convolutions to deliver far higher accuracy per parameter than legacy image classification models like ResNet-50.<span>&nbsp;</span></p>
<p>Group and depth-wise convolutions use smaller kernels which are not well suited to GPUs and this has limited their adoption to date.<span>&nbsp;</span></p>
<p>By contrast, a fine-grained processor like the IPU, with its unique MIMD architecture, is much better suited to group convolution, depth-wise convolution and more generally sparse models which inherently do not use dense, contiguous data structures.<span>&nbsp;</span></p>
<p><span>For standard EfficientNet-B4 Training for both PyTorch and TensorFlow, the IPU-M2000 achieves 10x throughput advantage versus the latest GPU.</span></p>
<p><span><img src="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=2000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg" alt="EfficientNet Training PyTorch and TensorFlow_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=1000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=2000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=3000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=4000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=5000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=6000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></span></p>
<p>With optimised EfficientNet-B4 Training, the IPU-M2000 achieves 18x throughput advantage versus the latest GPU.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=2000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg" alt="EfficientNet Training IPU optimised_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=1000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=2000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=3000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=4000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=5000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=6000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>EfficientNet-B0 Inference</strong></p>
<p>We see an even greater advantage with inference. The IPU-M2000 achieves more than 60x higher throughput and 16x lower latency than the latest GPU in a lowest latency comparison for both TensorFlow and PyTorch. In fact, the IPU-M2000 delivers higher throughput at its lowest latency than is achievable by the latest GPU at any batch size.<span>&nbsp;</span></p>
<p><span><img src="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=2000&amp;name=EfficientNet%20Inference_December%202020.jpg" alt="EfficientNet Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=1000&amp;name=EfficientNet%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=2000&amp;name=EfficientNet%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=3000&amp;name=EfficientNet%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=4000&amp;name=EfficientNet%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=5000&amp;name=EfficientNet%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=6000&amp;name=EfficientNet%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></span></p>
<p><strong>ResNeXt-101 Training</strong></p>
<p>ResNeXt-101 is an innovative model that delivers higher accuracy for image classification. <a href="https://arxiv.org/abs/1611.05431"><span>ResNeXt</span></a> uses depth-wise separable convolutions which perform far better on the IPU architecture than on the GPU resulting in 3.7x higher throughput on the IPU-M2000 with TensorFlow vs A100 GPU.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=2000&amp;name=ResNeXt%20Training_December%202020.jpg" alt="ResNeXt Training_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=1000&amp;name=ResNeXt%20Training_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=2000&amp;name=ResNeXt%20Training_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=3000&amp;name=ResNeXt%20Training_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=4000&amp;name=ResNeXt%20Training_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=5000&amp;name=ResNeXt%20Training_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=6000&amp;name=ResNeXt%20Training_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>ResNeXt-101 Inference</strong></p>
<p>The IPU-M2000 achieves 40x higher throughput and 10x lower latency for ResNeXt-101 inference using TensorFlow.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=2000&amp;name=ResNeXt%20Inference_December%202020.jpg" alt="ResNeXt Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=1000&amp;name=ResNeXt%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=2000&amp;name=ResNeXt%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=3000&amp;name=ResNeXt%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=4000&amp;name=ResNeXt%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=5000&amp;name=ResNeXt%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=6000&amp;name=ResNeXt%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><span><strong>Probabilistic Learning</strong></span><span>&nbsp;</span></p>
<p>Probabilistic models are used in applications where the underlying system is inherently stochastic. They are widely used in the financial sector and as well as in scientific research. However, many varieties of probabilistic models do not fit well with the SIMD/SIMT architecture of GPUs and run far too slowly to be of use. <span>&nbsp;</span></p>
<p><strong>Markov Chain Monte Carlo (MCMC) Training</strong></p>
<p>Using an off-the-shelf TensorFlow Probability (TFP) library to assess the performance of probabilistic models on IPU, we see that a financial MCMC workload trains in less than 3 hours on the IPU-M2000 platform, 17x faster than the 48 hours measured on the latest GPU.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=2000&amp;name=MCMC%20Training_December%202020.jpg" alt="MCMC Training_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=1000&amp;name=MCMC%20Training_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=2000&amp;name=MCMC%20Training_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=3000&amp;name=MCMC%20Training_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=4000&amp;name=MCMC%20Training_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=5000&amp;name=MCMC%20Training_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=6000&amp;name=MCMC%20Training_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>Speech Processing</strong><span>&nbsp;</span></p>
<p>Converting written text into speech is a challenging but highly valuable area of speech technology research, with a wide variety of use-cases across most industry verticals.<span>&nbsp;</span></p>
<p>A number of text-to-speech models have risen to prominence, including Tacotron from Google, Deep Voice from Baidu and FastSpeech from Microsoft, enabling high-quality, end-to-end speech synthesis.</p>
<p><strong>Deep Voice 3 Training</strong></p>
<p>Here we focus on the third Deep Voice iteration. The <a href="https://arxiv.org/abs/1710.07654"><span>Deep Voice 3</span></a> model is fully convolutional and uses attention blocks to decode the input text sequence to the output audio sequence representation. More details about our Deep Voice 3 implementation are provided in the <a href="https://www.graphcore.ai/posts/accelerating-text-to-speech-models-with-the-ipu"><span>Accelerating Text-To-Speech models with the IPU</span></a> blog.</p>
<p>The chart below highlights the performance advantage of the IPU-M2000 on the Deep Voice 3 model, with over 13x higher throughput versus the latest GPU.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=2000&amp;name=Deep%20Voice%203_December%202020.jpg" alt="Deep Voice 3_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=1000&amp;name=Deep%20Voice%203_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=2000&amp;name=Deep%20Voice%203_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=3000&amp;name=Deep%20Voice%203_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=4000&amp;name=Deep%20Voice%203_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=5000&amp;name=Deep%20Voice%203_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=6000&amp;name=Deep%20Voice%203_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><span><strong>Time Series Analysis</strong></span><span>&nbsp;</span></p>
<p>Time series forecasting models can predict future values based on previous, sequential data. LSTM is one of the most widely used time series analysis models. Financial companies in particular rely on LSTMs for modelling and predicting financial data such as stock prices. The use of LSTM-based methods in the finance industry is highlighted in this <a href="https://arxiv.org/pdf/2007.06848.pdf"><span>arxiv paper</span></a>.</p>
<p><strong>LSTM Inference</strong></p>
<p>The chart below compares throughput vs latency across a range of batch sizes for the IPU-M2000 vs the latest GPU for an LSTM 2-Layer Inference model. Across a range of batch sizes the performance advantage is apparent. At the lowest latency achievable by the GPU, the IPU-M2000 is capable of achieving 600x higher throughput at a lower latency.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=2000&amp;name=LSTM%20Inference_December%202020.jpg" alt="LSTM Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=1000&amp;name=LSTM%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=2000&amp;name=LSTM%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=3000&amp;name=LSTM%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=4000&amp;name=LSTM%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=5000&amp;name=LSTM%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=6000&amp;name=LSTM%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>Future Breakthroughs with the IPU</strong></p>
<p>As we have seen, the IPU delivers state of the art performance on established image processing and language models such as ResNet and BERT.<span>&nbsp;</span></p>
<p>It is also clear that the IPU can deliver huge performance gains in several new or currently under-utilised model types which are indicative of the future trend in machine intelligence, like EfficientNet, ResNeXt and MCMC (Markov Chain Monte Carlo) probability-based methods.</p>
<p>We are also working on some exciting developments with sparse models, and are introducing a preview version of our generalized sparse library support in <a href="https://www.graphcore.ai/posts/introducing-pytorch-for-the-ipu" rel="noopener" target="_blank">Poplar SDK 1.4</a>, which was released today.&nbsp;</p>
<p>Machine intelligence innovation is still in the early stages and we expect to see many new innovations developed over the next few years. The IPU has been designed to help innovators create these new breakthroughs.</p>
<p>Graphcore<a href="https://www.graphcore.ai/products/mk2/ipu-machine-ipu-pod" rel="noopener" target="_blank"> IPU-M2000 and IPU-POD</a> systems are shipping and available to order today through our <a href="https://www.graphcore.ai/partners" rel="noopener" target="_blank">partner network</a>. For more information or to be contacted by one of our AI experts, please register your interest <a href="https://www.graphcore.ai/product_info"><span>here</span></a>.</p>
<p>The products, systems, software, and results are based on configurations existing at the time of the measurements, and as such are subject to change at any time, without notice. For more information regarding methodology or results, please contact us.</p>
</span></p>
				</div>
			</div><div>
    
      
      <div>
        <p><small>© Copyright 2020 Graphcore</small>
        </p>
      </div>
</div></div>]]>
            </description>
            <link>https://www.graphcore.ai/posts/graphcore-sets-new-ai-performance-standards-with-mk2-ipu-systems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356767</guid>
            <pubDate>Wed, 09 Dec 2020 09:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AsyncAPI partners with Postman to boost development of Asynchronous APIs]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25356677">thread link</a>) | @derberg
<br/>
December 9, 2020 | https://www.asyncapi.com/blog/asyncapi-partners-with-postman | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/asyncapi-partners-with-postman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/asyncapi-partners-with-postman.png" alt="Post cover image"><p>I'm proud and honored to let you know that we're partnering with <a href="https://www.postman.com/">Postman</a><undefined> to boost the development of Asynchronous APIs to a new level <span role="img" aria-label="rocket">🚀</span></undefined></p><p>Since the very beginning, I knew the duty we had at hand was challenging. And still is! The specification was just the trigger of a snowball effect. What's the spec for if you can't do anything with it? Tooling is as important as the specification. However, tooling is a number of times more complex than the specification. We engineers don't want to abandon our favorite programming language and framework, therefore, it's AsyncAPI's responsibility to integrate with the existing tools in the market. <strong>The specification (and tools) should work for the user, not the other way around.</strong> Partnering with Postman allows us to boost the development of more and better tools to help engineers create and maintain Asynchronous APIs while using their favorite programming languages and frameworks.</p><p><strong>Our goal is to make Asynchronous APIs as successful and mature as REST APIs.</strong> We are aware this is a long journey but, with Postman's help, we'll be able to grow the team and continue working on the AsyncAPI specification and all the necessary tools to create a delightful developer experience. The AsyncAPI Initiative team is fully committed to open source software (OSS), and the partnership with Postman will help us keep doing our job with freedom and independence.</p><h2 id="next-steps">Next steps</h2><p>We want to make the AsyncAPI Initiative a neutral and independent place for collaborating on defining the future of Asynchronous APIs. Next step for us is to host the project in a neutral foundation to guarantee the long-term success of the initiative. We're currently in conversations with different actors of the OSS world to make sure the initiative remains independent.</p><p>Also, we want you to work with us. <a href="https://www.asyncapi.com/jobs">We are hiring</a> at Postman to work full-time on AsyncAPI. In the first half of 2021, we'll open a bunch of positions, including Software Engineers, Graphic Designers, Technical Writers, and more. Make sure you don't miss them!</p><div><h3>Receive an email when we publish a new job offer:</h3><p>We respect your inbox. No spam, promise ✌️</p></div><p>Before I finish, I would love to thank <a href="https://twitter.com/kinlane/">Kin Lane</a> and <a href="https://twitter.com/a85">Abhinav Asthana</a> for being so supportive. And of course, a huge shout out to <a href="https://twitter.com/derberq">Łukasz Gornicki</a> and <a href="https://twitter.com/e_morcillo">Eva Morcillo</a> for their tireless support. None of these would be possible without their help.</p><p>There's a bright future ahead for Asynchronous APIs. 2021 will be the year of AsyncAPI, the year of you, our beloved open-source community.</p><p><undefined>Cheers! <span role="img" aria-label="clinking beer mugs">🍻</span></undefined></p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/asyncapi-partners-with-postman</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356677</guid>
            <pubDate>Wed, 09 Dec 2020 08:57:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Validate your parking – an introduction to React Hook Form]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25356618">thread link</a>) | @selbekk
<br/>
December 9, 2020 | https://react.christmas/2020/9 | <a href="https://web.archive.org/web/*/https://react.christmas/2020/9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>He couldn't believe it. This certainly couldn't be true. Someone else must have made a mistake here. He read the email a second time. Maybe he missed something and the whole thing was just a big misunderstanding? But he didn't, of course. He is the kind of person who always pays attention to typos, therefore reading it again was quite pointless. Anger started spreading through him. How dare they? It felt so incredibly stupid and unfair. Especially considering he was such a law-abiding citizen. He despised those who didn't follow rules. They couldn't possibly mean that he was one of them? Yet this is exactly what the email was saying: "We can inform you that you unfortunately have used the wrong licence plate in the app, which is why you have been given a fine. In this case the fine is issued on <strong>AB12345</strong>, while parking was activated for <strong>AB1234</strong> in the app.". Filled with rage, he locked his phone and shoved it back into his pocket. He missed one bloody number!</p>
</section><article><section><h2>Validation to the Rescue</h2>
<p>In Norway, license plates for cars follow a certain pattern: they consist of two letters and five digits (there are some exceptions, such as personal license plates). Considering this, we realize that the above scenario could have been avoided merely by adding some form validation! For this, we will utilize <a href="https://react-hook-form.com/">React Hook Form</a>, which has become quite popular over the last year. React Hook Form is easy to use, quite lightweight and very performant. It has built-in validation, but also supports schema-based form validation with other tools such as <a href="https://github.com/jquense/yup">Yup</a>, <a href="https://github.com/ianstormtaylor/superstruct">Superstruct</a> and <a href="https://github.com/sideway/joi">Joi</a>.</p>
<p>Let's assume we have this very basic skeleton for a parking app:</p>
<div data-language="javascript"><pre><code><span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>onFormSubmit</span> <span>=</span> <span>(</span><span>e</span><span>)</span> <span>=&gt;</span> e<span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>h1<span>&gt;</span>Parking App<span>&lt;</span><span>/</span>h1<span>&gt;</span>
      <span>&lt;</span>form onSubmit<span>=</span><span>{</span>onFormSubmit<span>}</span><span>&gt;</span>
        <span>&lt;</span>label<span>&gt;</span>License number<span>&lt;</span><span>/</span>label<span>&gt;</span>
        <span>&lt;</span>input name<span>=</span><span>"licenseNo"</span> placeholder<span>=</span><span>"AA11111"</span> <span>/</span><span>&gt;</span>
        <span>&lt;</span>button<span>&gt;</span>Start parking<span>&lt;</span><span>/</span>button<span>&gt;</span>
      <span>&lt;</span><span>/</span>form<span>&gt;</span>
    <span>&lt;</span><span>/</span><span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>The app contains a form with a text input and a button. We also added an <code>onSubmit</code> method that prevents the form from being submitted and the page from being refreshed. Apart from that, the app doesn't really do anything meaningful. Let's add some validation:</p>
<div data-language="javascript"><pre><code><span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>{</span> handleSubmit<span>,</span> register <span>}</span> <span>=</span> <span>useForm</span><span>(</span><span>)</span><span>;</span>

  <span>const</span> <span>onFormSubmit</span> <span>=</span> <span>(</span><span>data</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span>data<span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>h1<span>&gt;</span>Parking App<span>&lt;</span><span>/</span>h1<span>&gt;</span>
      <span>&lt;</span>form onSubmit<span>=</span><span>{</span><span>handleSubmit</span><span>(</span>onFormSubmit<span>)</span><span>}</span><span>&gt;</span>
        <span>&lt;</span>label<span>&gt;</span>License number<span>&lt;</span><span>/</span>label<span>&gt;</span>
        <span>&lt;</span>input name<span>=</span><span>"licenseNo"</span> placeholder<span>=</span><span>"AA11111"</span> ref<span>=</span><span>{</span>register<span>}</span> <span>/</span><span>&gt;</span>
        <span>&lt;</span>button<span>&gt;</span>Start parking<span>&lt;</span><span>/</span>button<span>&gt;</span>
      <span>&lt;</span><span>/</span>form<span>&gt;</span>
    <span>&lt;</span><span>/</span><span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>As you can see, we don't need to add much code to set up React Hook Form. We have to call the <code>useForm</code> hook which returns a bunch of methods. For the time being, we simply use <code>handleSubmit</code> and <code>register</code>. We then wrap the <code>onFormSubmit</code> method into the <code>handleSubmit</code> method. This will take care of only invoking <code>onFormSubmit</code> and pass the form data when all fields are valid (it also prevents the form from submitting, so we don't need to explicitly call the <code>preventDefault</code> method). Finally, we need to set the <code>register</code> method as the input field's ref attribute. But this is not the end of the story! The form allows any input, even if it is left empty. This is why we have to specify some validation rules:</p>
<div data-language="javascript"><pre><code><span>&lt;</span>input 
  name<span>=</span><span>"licenseNo"</span> 
  placeholder<span>=</span><span>"AA11111"</span> 
  ref<span>=</span><span>{</span><span>register</span><span>(</span><span>{</span>
    required<span>:</span> <span>"You must enter a license number."</span><span>,</span>
    pattern<span>:</span> <span>{</span>
      value<span>:</span> <span>/^[a-z]{2}\d{5}$/i</span><span>,</span>
      message<span>:</span> <span>"The license number must be a combination of two letters and five digits."</span>
    <span>}</span>
  <span>}</span><span>)</span><span>}</span>
<span>/</span><span>&gt;</span></code></pre></div>
<p>When registering the input field, we can add several options to adjust how the field should be validated. In the above example, we tell our form that the field is required and that the value must match a specific regex pattern. We also define some error messages. If we try to submit the form, but validation fails, the error message is returned by <code>useForm</code> as an object called <code>errors</code>. Every form field gets its own error message corresponding to the field's <code>name</code> attribute:</p>
<div data-language="javascript"><pre><code><span>{</span>errors<span>.</span>licenseNo <span>&amp;&amp;</span> errors<span>.</span>licenseNo<span>.</span>message<span>}</span></code></pre></div>
<p>Alternatively, we can use a simple component, <code>ErrorMessage</code> (we must first install a separate NPM package):</p>
<div data-language="javascript"><pre><code><span>&lt;</span>ErrorMessage
  errors<span>=</span><span>{</span>errors<span>}</span>
  name<span>=</span><span>"licenseNo"</span>
<span>/</span><span>&gt;</span></code></pre></div>
<p>This is all we need to avoid registering an invalid license number! However, there are some more concepts we should have a look at.</p>
<h2>Controlled vs. Uncontrolled</h2>
<p>React Hook Form is designed to work best with <em>uncontrolled components</em>. This means that form data is handled by the DOM itself and can be accessed directly using refs (which is why we put the <code>register</code> method there). <em>Controlled components</em> on the other hand, use event handlers such as <code>onChange</code> to update values at state change. Many third-party libraries use controlled components, and luckily there is a way we can use those together with React Hook Form:</p>
<div data-language="javascript"><pre><code><span>&lt;</span>Controller
  <span>as</span><span>=</span><span>{</span>ReactSelect<span>}</span>
  name<span>=</span><span>"fuelType"</span>
  rules<span>=</span><span>{</span><span>{</span> required<span>:</span> <span>"You must select a fuel type."</span> <span>}</span><span>}</span>
  options<span>=</span><span>{</span><span>[</span>
    <span>{</span> value<span>:</span> <span>"electric"</span><span>,</span> label<span>:</span> <span>"Electric"</span> <span>}</span><span>,</span>
    <span>{</span> value<span>:</span> <span>"petrol"</span><span>,</span> label<span>:</span> <span>"Petrol"</span> <span>}</span><span>,</span>
    <span>{</span> value<span>:</span> <span>"diesel"</span><span>,</span> label<span>:</span> <span>"Diesel"</span> <span>}</span>
  <span>]</span><span>}</span>
  isClearable
<span>/</span><span>&gt;</span></code></pre></div>
<p>We add a <a href="https://github.com/JedWatson/react-select">React Select</a> for choosing the cars fuel type by wrapping it inside a <code>Controller</code> component using the <code>as</code> prop. The Controller automatically injects the <code>onChange</code>, <code>onBlur</code> and <code>value</code> props into the wrapped component. The same applies to other props that may be required by the underlying component (in this case the props <code>options</code> and <code>isClearable</code>). Validation rules are applied by setting the <code>rules</code> prop. Although this is the preferred syntax, you sometimes need to use the <code>render</code> prop instead of the <code>as</code> prop, which lets you customize events, value and ref:</p>
<div data-language="javascript"><pre><code><span>&lt;</span>Controller
  name<span>=</span><span>"fuelType"</span>
  rules<span>=</span><span>{</span><span>{</span> required<span>:</span> <span>"You must select a fuel type."</span> <span>}</span><span>}</span>
  render<span>=</span><span>{</span><span>(</span><span><span>{</span> onChange<span>,</span> onBlur<span>,</span> value<span>,</span> ref <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span>
    <span>&lt;</span>ReactSelect
      options<span>=</span><span>{</span><span>[</span>
        <span>{</span> value<span>:</span> <span>"electric"</span><span>,</span> label<span>:</span> <span>"Electric"</span> <span>}</span><span>,</span>
        <span>{</span> value<span>:</span> <span>"petrol"</span><span>,</span> label<span>:</span> <span>"Petrol"</span> <span>}</span><span>,</span>
        <span>{</span> value<span>:</span> <span>"diesel"</span><span>,</span> label<span>:</span> <span>"Diesel"</span> <span>}</span>
      <span>]</span><span>}</span>
      onChange<span>=</span><span>{</span>onChange<span>}</span>
      onBlur<span>=</span><span>{</span>onBlur<span>}</span>
      inputValue<span>=</span><span>{</span>value<span>?.</span>key<span>}</span>
      inputRef<span>=</span><span>{</span>ref<span>}</span>
    <span>/</span><span>&gt;</span>
  <span>)</span><span>}</span>
<span>/</span><span>&gt;</span></code></pre></div>
<h2>Form Context</h2>
<p>When moving input fields to shared components in order to make them reusable, you can of course pass all neccessary methods from <code>useForm</code> as props. In many cases, it would be a more elegant solution to put the whole form into a <code>FormProvider</code> and access the context of the form with <code>useformContext</code>:</p>
<div data-language="javascript"><pre><code><span>const</span> methods <span>=</span> <span>useForm</span><span>(</span><span>)</span><span>;</span>

<span>return</span> <span>(</span>
    <span>&lt;</span>FormProvider <span>{</span><span>...</span>methods<span>}</span><span>&gt;</span>
      <span>&lt;</span>form onSubmit<span>=</span><span>{</span>methods<span>.</span><span>handleSubmit</span><span>(</span>onSubmit<span>)</span><span>}</span><span>&gt;</span>
        <span>&lt;</span>LicenseNoInput <span>/</span><span>&gt;</span>
        <span>&lt;</span>button<span>&gt;</span>Start parking<span>&lt;</span><span>/</span>button<span>&gt;</span>
      <span>&lt;</span><span>/</span>form<span>&gt;</span>
    <span>&lt;</span><span>/</span>FormProvider<span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>The <code>LicenseNoInput</code> component can then access the form methods as simple as this:</p>
<div data-language="javascript"><pre><code><span>const</span> <span>{</span> errors<span>,</span> register <span>}</span> <span>=</span> <span>useFormContext</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>Let's pack it all up, add a little more logic and styling and voilà – we have a parking app with form validation that actually works!</p>

<h2>Like a Swiss Army Knife</h2>
<p>There is so much more you can do with React Hook Form! It's too bad I can't cover it all in a single article. I can recommend a look at the <a href="https://react-hook-form.com/api/">official documentation</a>, which also provides many useful examples. Personally, I have been using this tool for about a year now and have never been in a situation where it couldn't solve a problem. If you are still not convinced, the fact that TypeScript is fully supported will hopefully change your mind.</p></section></article></div>]]>
            </description>
            <link>https://react.christmas/2020/9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356618</guid>
            <pubDate>Wed, 09 Dec 2020 08:44:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress Over Perfection]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25356266">thread link</a>) | @phughes1980
<br/>
December 8, 2020 | https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/ | <a href="https://web.archive.org/web/*/https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article aria-label="My New Side Hustle Mantra: Progress Over Perfection"><div><figure><img loading="lazy" width="1880" height="1249" src="https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1880%2C1249&amp;ssl=1" alt="traffic red blue sign" srcset="https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?w=1880&amp;ssl=1 1880w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=300%2C199&amp;ssl=1 300w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1024%2C680&amp;ssl=1 1024w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=768%2C510&amp;ssl=1 768w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1536%2C1020&amp;ssl=1 1536w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"><figcaption>Photo by Mabel Amber on <a href="https://www.pexels.com/photo/traffic-red-blue-sign-117602/" rel="nofollow">Pexels.com</a></figcaption></figure><p>A Guest Post by Phil Hughes</p><p>“Progress over perfection”. I’ve written this on the whiteboard next to my standing desk in the home office/guitar studio/mancave/junk room.&nbsp;</p><p>I heard this statement earlier on in the year. Must have been around May or June, it instantly struck a chord with me.</p><p>Working full time and trying to get no less than 3 side hustles and a podcast off the ground is a big ask.&nbsp;</p><p>I have used the progress over perfection mantra before. It was worded slightly differently; I can’t remember the exact statement.</p><p>However, I hadn’t fully embraced the concept.&nbsp;</p><p>When it came to my core skill of software development, I could easily apply this principle.&nbsp;</p><p>Every other part of the side hustle lifestyle was still “I got to make sure this is the best it can be”.</p><h2 id="h-already-integrated-into-my-9-5"><span id="Already_Integrated_into_My_95"></span>Already Integrated into My 9-5<span></span></h2><p>Like I’ve just touched on. I’ve used progress over perfection, day to day with my software development ‘hat’ on.</p><p>I’m going to sound arrogant now. Having spent 14+ years developing software, I’m confident in my skills and the fact I can get stuff done and out the door, quicker than a lot of my “development” peers.</p><p>By using this principle, I can get the feature ‘X’ out to the world. Start feature ‘Y’ and deliver that in rapid time. Same too with Feature ‘Z’</p><p>Then go back to feature ‘X’ and make it better. Progress over perfection in action.</p><h3 id="h-progress-over-perfection-a-real-world-app-example"><span id="Progress_Over_Perfection_%E2%80%93_A_Real_World_App_Example"></span>Progress Over Perfection – A Real World App Example<span></span></h3><p>I’m writing this post towards the end of 2020, having gone through the Coronavirus pandemic.</p><p>At the start of lockdown, I had more spare time and I came up with a <a href="https://baitcamp.net/">mobile app idea for a hobby of mine, fishing</a>.&nbsp;</p><p>After doing a bit of product validation and finding out what other fishermen would like to see in the app. I sketched out the features I was going to include in version 1 of the app.</p><p>One of the features was to allow the user to upload photos to the app, linking them to a fishing trip.</p><p>Having never done anything like this before, it was a learning curve, to say the least. I decided to use the “progress over perfection” mantra by making sure the uploading, editing, removing, and retrieving of the photos, from a functionality point of view, was “perfect”</p><p>However, the way the user uploaded the photos and then viewing them was shocking, “perfect” was just a dot on the horizon.&nbsp;</p><p>That said, I went with it as I wanted to get the app published on both the <a href="https://apps.apple.com/us/app/id1519992229">Apple App Store</a> and <a href="https://play.google.com/store/apps/details?id=uk.co.phhdigital.baitcamp">Google Play</a> as quickly as possible.&nbsp;</p><p>5 months after the initial idea came to me, I had published the app on both platforms. WAHOO!</p><p>After feedback from people testing version 1. And the fact I wasn’t happy with the photo upload/viewing features. I have been able to start work on version 1.1 to sort this problem out.</p><p>Another day or two and I will have a slick way of managing the photos. Be able to release an update very quickly. As well as ironing out a few bugs that have come to light.</p><p>I genuinely believe if I had kept on working on the app until I was entirely happy with the photo functionality, I wouldn’t have it published or have people downloading the app and using it.</p><p>The key here was “progress over perfection” to get something live that was usable, then go from there.</p><h2 id="h-side-hustling-and-what-you-need-to-learn"><span id="Side_Hustling_and_What_You_Need_To_Learn"></span>Side Hustling and What You Need To Learn<span></span></h2><p>When it comes to other aspects of side hustling, I’m still “newborn” in a lot of the skills you need.&nbsp;</p><p>Writing blog posts, writing social media posts, copywriting, creating nice-looking webpages, building sales funnels, creating ads, shooting walkthroughs for YouTube, recording video sales letters, editing videos, coming up with offers, researching, scheming and plotting, creating eBooks, creating eBook covers, creating eBook mock-ups, recording podcasts, editing podcasts.</p><p>How did I come up with that list of things to do? I looked at my planner at what tasks I wanted to achieve over the last 2 weeks.&nbsp;</p><p>That’s on top of coding 3 software products by myself. Working 8-4 Monday through Thursday. And, having a life, like spending time with my wife, playing guitar, and going fishing.</p><p>It can be very overwhelming.&nbsp;</p><p>You see how great other people are at all these other things and want your stuff to be as “perfect” as theirs</p><p>That’s why this new mantra has been a bit of a breakthrough for me.</p><h2 id="h-progress-over-perfection-and-switching-your-mindset"><span id="Progress_Over_Perfection_and_Switching_Your_Mindset"></span>Progress Over Perfection and Switching Your Mindset<span></span></h2><p>As I’ve touched upon. For certain aspects of my day to day I would apply “progress over perfection”. Not all aspects though.</p><p>Hearing this really got me thinking about what I wanted to achieve.&nbsp;</p><p>One thing it also did was remove some fear I had around things.&nbsp;</p><p>For example, I had started digging deep into the concept of creating online sales funnels to promote my products and reach my “golden goose” of 350 paying customers.</p><p>My dream is to work for myself running a software product. After a bit of number crunching, I worked out I would need 350 monthly subscribers for me to realize my dream.&nbsp;</p><p>Sales funnels could help me achieve this.</p><h3 id="h-sales-funnel-progress-over-perfection"><span id="Sales_Funnel_Progress_Over_Perfection"></span>Sales Funnel Progress Over Perfection<span></span></h3><p>This is where the fear kicked in. I was worried that I would create a sales funnel, it would completely bomb, and I would feel like a failure.&nbsp;</p><p>I wanted my sales funnels to be successful as soon as I start driving traffic to it. If this were a software product, I wouldn’t think like that. I know they will be some bugs and users would probably want something different than what I had built.</p><p>After consuming a lot of content around the sales funnel process and how even the most experienced “funnel hackers” can’t get their funnel to work out of the gate.&nbsp;</p><p>I decided that I just need to get it out there and see what “feedback” I get.</p><p>So, I continued to put it together as best I could, giving myself a time constraint that it must be done by the end of that week. Then the week after I could drive some paid traffic to it.</p><p>I got the opt-in page up and running, where someone could submit their details and in return get a free eBook user guide.</p><p>Next, I spent most of my time working on the sales page and putting together an offer and pricing.&nbsp;</p><p>Thirdly, I added a “One Time Offer” that the person would be shown if they subscribed to the product I was promoting on the sales page.</p><p>Finally, I put together an email sequence that would be sent to anyone who opted in for the free eBook, as a follow up to get them to revisit my funnel.</p><p>The next week I created a Facebook ad campaign and got loads of people into the funnel. Guess how many sales I made?</p><p>ZERO.</p><h3 id="h-analyzing-the-results"><span id="Analyzing_the_Results"></span>Analyzing the Results<span></span></h3><p>Sounds terrible right? It was, but I wasn’t downhearted.&nbsp;</p><p>Looking into the stats, the opt-in page was working. I was getting almost 45% of the visitors to put in their email address and request a copy of the eBook.</p><p>Yes, no one bought from me. I knew that part of my sales funnel did work. However, I was building an email list of people that I could keep in contact with, which I hadn’t be able to do before.</p><p>“Progress over perfection”.</p><p>I ended up scrapping this funnel as I still didn’t ‘convert’ after a few attempts at rewriting parts of the sales page.</p><p>Taking the learnings from the opt-in success, I created a brand-new funnel. This targeted a different group of people. Again, this funnel wasn’t the success I wanted. My opt-in rate was still high, 35% and I got my first ever paying customer.</p><p>Someone signed up and subscribed to <a href="https://outflash.xyz/">my software product called Outflash</a>. They even took my up one-time offer.</p><p>I was blown away. Yes, it wasn’t the riches you pray for, but I had made progress on this skill.</p><p>Progress! Progress towards what I deem successful.</p><h2 id="h-podcasting-and-getting-yourself-out-there"><span id="Podcasting_and_Getting_Yourself_Out_There"></span>Podcasting and Getting Yourself Out There<span></span></h2><p>A problem with being a developer, is you think it will be like the movie Field of Dreams. “Build it and they will come”. With a software product, this NEVER happens.</p><p>Someone said if you want to get yourself out there to promote your products and services. Use a platform or media that you enjoy yourself. For me this was podcasting.</p><p>I’m an avid podcast listener. Whether it be working out, going for a run, listening while coding. I even put a podcast on while cooking a Sunday Dinner.</p><p>Starting a podcast can be scary though. What do I talk about? Do I have enough content to get past the first 10 episodes? How do I even publish a podcast? Which platforms do I publish to?</p><h3 id="h-excuses-excuses-just-do-it"><span id="Excuses,_Excuses,_Just_Do_It"></span>Excuses, Excuses, Just Do It<span></span></h3><p>Having mild success with the sales funnels gave me a lot of belief in the saying “Just Do It”.</p><p>One of the podcasts I listen to is by two guys that have launched their own podcasting hosting and publishing platform. I know, a bit Inception right!</p><p>So, I decided to use their platform to publish and host <a href="https://www.philliphughes.co.uk/podcast/">my podcast</a>. Which platforms to publish to? Their service had guides on how to publish to <a href="https://podcasts.apple.com/gb/podcast/find-your-side-hustle/id1523991465">Apple</a> and <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy50cmFuc2lzdG9yLmZtL2ZpbmQteW91ci1zaWRlLWh1c3RsZQ?sa=X&amp;ved=0CBUQ27cFahcKEwiIrMe2-eLqAhUAAAAAHQAAAAAQAQ">Google podcasts</a>, <a href="https://open.spotify.com/show/19pwsqTl75RSGrhhrsFIWW">Spotify</a>, and <a href="https://www.stitcher.com/podcast/find-your-side-hustle">Stitcher</a>. I didn’t overthink it, I registered with those 4 providers first and thought, “progress over perfection”, I can publish to more platforms later.</p><p>People also think they need a mass of equipment to record and edit a podcast. I was on a roll; nothing was stopping me from getting my first episode out to the world.&nbsp;</p><p>Quickly opening Amazon and searching for “cheap podcast mic”. I bought the 3<sup>rd</sup> one I saw for £20, with Amazon Prime it was delivered the next day.</p><p>In another quick search for “free podcast editing software,” I found a piece of software that I could do basic audio editing with, like snipping or increasing the volume.&nbsp;</p><h3 id="h-other-people-skills-to-progress-over-perfection"><span id="Other_People_Skills_To_Progress_Over_Perfection"></span>Other People Skills To Progress Over Perfection<span></span></h3><p>The last two pieces of the podcasting puzzle were that I needed a logo/header for the podcast that will be unique to me and my chosen topic.</p><p>I have used Fiverr in the past and thought it would be a good place to find someone to do it for me, quickly.&nbsp;</p><p>If I didn’t like it, I could always change it a few months down the line. I found someone who had a decent portfolio of similar work, that wasn’t too pricy. I put the order in, with a description of what I was looking for, and forgot about it for the rest of the evening.</p><p>While the logo was being designed, I needed to get together a list of episode ideas so I could record a least a handful to get me started.</p><p>This time I turned to Evernote, created …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/">https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/</a></em></p>]]>
            </description>
            <link>https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356266</guid>
            <pubDate>Wed, 09 Dec 2020 07:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Notifications in iTerm2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25355688">thread link</a>) | @CGamesPlay
<br/>
December 8, 2020 | https://cgamesplay.com/post/2020/12/09/iterm-notifications/ | <a href="https://web.archive.org/web/*/https://cgamesplay.com/post/2020/12/09/iterm-notifications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For some reason, I've found that in my career a lot of the work I do ends up involving slow REPL loops: I make a change, run a command, wait for it to finish, and repeat. While I'm sitting there waiting, it's easy to be distracted by things, and I want my task to bring itself back to my attention when it's ready. This desire has led me on a multi-year quest to tailor my notifications perfectly, and in this post I'm going to share what I've come up with.</p>
<p>Here are the features I want my notifications to have:</p>
<ul>
<li>I should be able to activate them from anywhere in the terminal: in bash, from the ruby console, over SSH, or anywhere else I find myself (in the terminal).</li>
<li>They should be subtle so they don't get too annoying, but noticeable enough that I don't miss them.</li>
<li>The should only fire when I want them: too many notifications will cause me to ignore all of them.</li>
</ul>
<h2>The early days</h2>
<p>Back in 2015 or so, my company was writing scrapers to extract detailed, structured information from hundreds of websites. Each website was different and since we needed the information to be structured, we had to write a different scraper for each one. A single site could be scraped in about 5 minutes, and the data only changed a few times each year. Still, the sites would change often enough that I frequently found myself sitting in the office until late at night, mostly waiting for these scrapers to break so I could make one small fix, and repeat. Five minutes for each change really adds up when you have to repeat the entire scraper to test a single-line change.</p>
<p>Fortunately, writing scrapers is pretty easy technically, so I didn't need to be 100% focused as I was working on them. That meant that while I was waiting on the latest change I'd made to a scraper, I was able to focus on other high-value activities like shooting for a high score in Peggle Nights.</p>
<p><img src="https://cgamesplay.com/media/20201201-1309-peggle-small.jpg" alt="Screenshot of Peggle Nights"></p>
<p>But sometimes, when I was planning a tough shot on a high-scoring round, I could forget that I was still at the office waiting for my scraper to crash so I could fix it. That's why I wanted a simple way to get notified when it was waiting for me. My first-ever attempt at building a notifications system used a feature built-in to Mac OS: the <code>say</code> command.</p>
<pre><code>long_running_command<span>;</span> say <span>"done"</span>
</code></pre>
<p>This command uses the system's text-to-speech to play through your computer speakers. The scrapers I was writing were mostly in Ruby, so if I were in IRB I could still get the notification:</p>
<pre><code>my_scraper<span>.</span>run_main <span>rescue</span> ex <span>=</span> $<span>!</span><span>;</span> `say done`
</code></pre>
<p>This will play the notification even if the scraper fails, and preserve the raised exception in the <code>ex</code> variable. Neat!</p>
<p>I used this solution for a few months, but I always felt that the text-to-speech was a little unpleasant. I decided to switch out the <code>say</code> command for the built-in audio file player, <code>afplay</code>, and I used one of the default sounds that comes with Mac OS.</p>
<pre><code><span>function</span> <span>ding</span> <span>{</span>
  afplay /System/Library/Sounds/Glass.aiff
<span>}</span>
long_running_command<span>;</span> ding
</code></pre>
<p>That makes this sound, which is a little more subtle than a robotic voice shouting at me.</p>
<p><audio controls="" src="https://cgamesplay.com/media/20201125-1600-iterm-sounds-glass.aiff"><a href="https://cgamesplay.com/media/20201125-1600-iterm-sounds-glass.aiff">Click to download</a></audio></p>
<p>These two tricks got me along just fine for years. I felt like I had solved the problem and didn't need to think about it any more. Well, except when I started a command that I thought would be fast but it instead took an hour to run. But I developed a trick for that: if you press <code>^Z</code> (Ctrl-Z) to pause the job, then you can use <code>fg; ding</code> to resume it  and ding when it finishes. There. Now it's perfect.</p>
<h2>Improving on perfection</h2>
<p>One day I learned about <a href="https://iterm2.com/documentation-shell-integration.html" target="_blank" rel="noopener">iTerm2 shell integration</a>. This provides a bunch of neat features, and one of them is about notifications! It's not very well documented, but if you use Edit ► Marks and Annotations ► Alerts ► Alert on Next Mark, or the much-easier-to-remember Option-Command-A, you'll get a native notification when the currently running command finishes. I installed the shell integration and to this day I use this feature more than anything else that it provides.</p>
<p>Fast forward to 2020 and I've changed roles again. This time, I find myself automating cloud server provisioners, and waiting for the machines to come up isn't fast. Sadly, the iTerm shell integration has to be installed on each server, and my perfect notification scripts don't work over SSH. Realizing that perfection is a journey and not a destination, I set out to improve my notifications once again. Except this time, I was going to go industrial-strength.</p>
<p>When I was learning about the iTerm2 shell integration, I also found out about <a href="https://cgamesplay.com/post/2020/11/25/iterm-plugins/">a bunch of other features that iTerm2 supports</a>. If you want to follow along with me, read over that post and install <code>PlaySound.py</code>, <code>iterm_notify</code>, <code>iterm_badge</code>, and <code>iterm_bounce</code> on your computer. These new features had already made my notifications more powerful and SSH-compatible, but I had set my sights beyond a simple "ding!" sound. I wanted a smart notification system that would "ding" when the command completed, but "bonk" when it failed. But first I needed to find the right sounds to use.</p>
<p><img src="https://cgamesplay.com/media/20201201-1344-oot-navi.jpg" alt="The Legend of Zelda: Ocarina of Time"></p>
<p>The first sound that came to mind was the iconic "Hey! Listen!" from Ocarina of Time. If you played this game, then you probably know exactly how that sounds. I found a gallery of <a href="http://noproblo.dayjo.org/ZeldaSounds/" target="_blank" rel="noopener">sounds from the Zelda games</a> and searched for some appropriate ones. Eventually I settled on these two, for my "good" and "bad" sounds:</p>
<p><audio controls="" src="https://cgamesplay.com/media/20201201-1347-ootpressstart.wav"><a href="https://cgamesplay.com/media/20201201-1347-ootpressstart.wav">Click to download</a></audio></p>
<p><audio controls="" src="https://cgamesplay.com/media/20201201-1349-mmtatlalarm.wav"><a href="https://cgamesplay.com/media/20201201-1349-mmtatlalarm.wav">Click to download</a></audio></p>
<p>The first thing to do is wrap them up in scripts to make them easy to use. I put them in my sound library (which is listing in <a href="https://github.com/CGamesPlay/dotfiles/blob/bee7d071a7b85f7becc696edc0b328677eb16c40/macos/Library/Application%20Support/iTerm2/Scripts/AutoLaunch/PlaySound.py" target="_blank" rel="noopener">PlaySound.py</a>) and wrote these:</p>
<pre><code><span>function</span> <span>ding</span> <span>{</span>
    iterm_sound OOT_PressStart
<span>}</span>

<span>function</span> <span>bonk</span> <span>{</span>
    iterm_sound MM_Tatl_Alarm.wav
<span>}</span>
</code></pre>
<p>Now I can run my provisioning script like this:</p>
<pre><code>./provision.sh <span>&amp;&amp;</span> ding <span>||</span> bonk
</code></pre>
<p>If the script succeeds, the <code>&amp;&amp; ding</code> will run, resulting in a pleasant chime. Otherwise the <code>|| bonk</code> sound will run and I'll hear a nervous fairy. But I can do better! This is too much to type, and I want to leverage all of my notification channels, not just sound. So I wrote this function:</p>
<pre><code><span>function</span> <span>sound_status</span> <span>{</span>
    <span>local</span> <span>last_status</span><span>=</span><span>$?</span>
    <span>test</span> <span>$last_status</span> -eq <span>0</span> <span>&amp;&amp;</span> ding <span>||</span> bonk
    iterm_bounce
    <span>if</span> <span>test</span> -z <span>"<span>$@</span>"</span><span>;</span> <span>then</span>
        iterm_notify <span>"Command finished with status <span>$last_status</span>"</span>
    <span>else</span>
        iterm_notify <span>"<span>$@</span> finished with status <span>$last_status</span>"</span>
    <span>fi</span>
    <span>return</span> <span>$last_status</span>
<span>}</span>
</code></pre>
<p>This function has 3 important qualities:</p>
<ol>
<li>It automatically chooses the sound to play.</li>
<li>It also shows a system notification, with an optional custom message.</li>
<li>It passes on the exit code, so you can run it in a pipeline.</li>
</ol>
<p>For example, I can use it like this:</p>
<pre><code>./provision.sh<span>;</span> sound_status <span>"provision.sh"</span> <span>&amp;&amp;</span> <span>ssh</span> myhost
</code></pre>
<p>Because it passes on the exit status, the <code>&amp;&amp; ssh</code> will only happen when the command succeeds, just like if the <code>; sound_status</code> hadn't been there at all.</p>
<h2>The little things in life</h2>
<p>This notification script feels great: simple, only when requested, and with just a bit of "fun" flavor. But there is another area where I think that a subtle audio cue would help streamline my workflow. Sometimes I need to type 3 or 4 quick commands back-to-back. Has this ever happened to you?</p>
<pre><code>$ <span>git</span> commit -m <span>"respond to feedback"</span>
no changes added to commit <span>(</span>use <span>"git add"</span> and/or <span>"git commit -a"</span><span>)</span>
$ <span>git</span> push
Everything up-to-date
</code></pre>
<p>I run these commands, see that it succeeded, shut my laptop, and head out to lunch. Later that day I wonder why nobody has reviewed my code, only to find that the second command had failed because I never staged those files, so I never pushed any changes at all. If I had been more careful, this wouldn't have happened. As a substitute for being more careful, I can have the computer tell me when my commands fail!</p>
<p>When I want is a subtle ping to tell me that something bad happened, every time a command fails. A lot of times this notification will be unnecessary. For example, if  <code>make</code> fails with a compile error, I don't really need a sound to tell me about that. So I wanted a "negative" sound that wasn't too distracting. I eventually settled on this one.</p>
<p><audio controls="" src="https://cgamesplay.com/media/20201201-1409-alert-destroyed.wav"><a href="https://cgamesplay.com/media/20201201-1409-alert-destroyed.wav">Click to download</a></audio></p>
<p>Can you recognize it? It's a sound you'll have heard pretty often if you've ever played Factorio: the notification that a building you own has been destroyed. In the game, you'll often hear this sound altering you of an attack while you're working on some other task. Generally, it indicates a problem, but not necessarily an urgent one. I thought it would be perfect. Since I'm a user of <a href="https://fishshell.com/" target="_blank" rel="noopener">Fish shell</a>, I rigged up the notification like this:</p>
<pre><code>
<span>if</span> <span>test</span> -z <span>$beep_command</span>
  <span>set</span> beep_command <span>"printf <span title="\a">\a</span>"</span>
end
<span>set</span> beep_primed <span>""</span>
<span>function</span> beep_preexec --on-event fish_preexec
  <span>set</span> -g beep_primed <span>1</span>
end
<span>function</span> beep_postexec --on-event fish_postexec
  <span>set</span> -l last_status <span>$status</span>
  <span>if</span> <span>test</span> <span>!</span> -z <span>$beep_primed</span> -a <span>!</span> -z <span>$argv</span><span>[</span><span>1</span><span>]</span> -a <span>$last_status</span> -ne <span>0</span>
    <span>eval</span> <span>$beep_command</span>
  end
  <span>set</span> -g beep_primed <span>""</span>
end
</code></pre>
<p>There's a few things worth mentioning here:</p>
<ul>
<li>To set the beep command, I used <code>set -U beep_command "iterm_sound Factorio/alert-destroyed.wav"</code>. This sets a "<a href="https://fishshell.com/docs/current/#variable-scope" target="_blank" rel="noopener">universal variable</a>" in fish, so it's permanent and system-wide. This lets me change the sound easily whenever I want.</li>
<li>The <code>fish_postexec</code> command runs even if you didn't run a command (pressed enter at an empty prompt), so we use the <code>-z $argv[1]</code> to filter that out.</li>
<li>The <code>beep_primed</code> variable is needed to ensure that the sound only happens once when the command fails. This is necessary to avoid some awkward situations that come up when you press Ctrl-C to cancel a command.</li>
</ul>
<p>So that's where I am today. I am very happy with how my notifications work and I'm glad I was able to add a unique bit of flavor to them by sampling from some nostalgic video games. Thanks for reading! If you want to set up something like this and are having problems, feel free to <a href="https://cgamesplay.com/contact">reach out to me</a>.</p></div></div>]]>
            </description>
            <link>https://cgamesplay.com/post/2020/12/09/iterm-notifications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25355688</guid>
            <pubDate>Wed, 09 Dec 2020 05:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transcending the Visual Appearance of a Paper]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25355291">thread link</a>) | @harporoeder
<br/>
December 8, 2020 | https://cr.yp.to/writing/visual.html | <a href="https://web.archive.org/web/*/https://cr.yp.to/writing/visual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="https://cr.yp.to/djb.html">D. J. Bernstein</a>
<br><a href="https://cr.yp.to/writing.html">Notes on writing papers</a>

Here's a quote from the paper "Document Production: Visual or Logical?"
in Notices of the American Mathematical Society (June 1987), pages 621-624,
by LaTeX author Leslie Lamport:
<blockquote>
The purpose of writing is to convey ideas to the reader.
The worst aspect of visual systems
is that they subvert the process of communicating ideas
by encouraging the writer to concentrate on form rather than content.
Ideas are conveyed by the logical structure of the text;
the function of the visual format is to display this structure.
The author should be concerned with the structure,
not any particular visual representation.
</blockquote>
Here's another quote:
<blockquote>
Document design is a skill acquired through training and experience.
A logical system can apply the skill of a trained designer
to the formatting of a document.
</blockquote>
<p>
Let's see how well this worked for one of my papers,
a paper that was forced to switch visual formats.
</p><p>
Originally I had used the American Mathematical Society's "amsart" format:
<table>
<tbody><tr>
<td><a href="https://cr.yp.to/writing/visual/ams-000001.png"><img src="https://cr.yp.to/writing/visual/ams-000001-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000002.png"><img src="https://cr.yp.to/writing/visual/ams-000002-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000003.png"><img src="https://cr.yp.to/writing/visual/ams-000003-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000004.png"><img src="https://cr.yp.to/writing/visual/ams-000004-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000005.png"><img src="https://cr.yp.to/writing/visual/ams-000005-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000006.png"><img src="https://cr.yp.to/writing/visual/ams-000006-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000007.png"><img src="https://cr.yp.to/writing/visual/ams-000007-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000008.png"><img src="https://cr.yp.to/writing/visual/ams-000008-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000009.png"><img src="https://cr.yp.to/writing/visual/ams-000009-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000010.png"><img src="https://cr.yp.to/writing/visual/ams-000010-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000011.png"><img src="https://cr.yp.to/writing/visual/ams-000011-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000012.png"><img src="https://cr.yp.to/writing/visual/ams-000012-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000013.png"><img src="https://cr.yp.to/writing/visual/ams-000013-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000014.png"><img src="https://cr.yp.to/writing/visual/ams-000014-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000015.png"><img src="https://cr.yp.to/writing/visual/ams-000015-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000016.png"><img src="https://cr.yp.to/writing/visual/ams-000016-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000017.png"><img src="https://cr.yp.to/writing/visual/ams-000017-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000018.png"><img src="https://cr.yp.to/writing/visual/ams-000018-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000019.png"><img src="https://cr.yp.to/writing/visual/ams-000019-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000020.png"><img src="https://cr.yp.to/writing/visual/ams-000020-4.png" height="439" width="310"></a>
</td></tr>
</tbody></table>
</p><p>
But then I found out that the book containing my paper
would use the "msripub" format
designed by MSRI book editor Silvio Levy.
Here's what happens when the same document is formatted
with "msripub" rather than "amsart":
<table>
<tbody><tr>
<td><a href="https://cr.yp.to/writing/visual/msripub-000001.png"><img src="https://cr.yp.to/writing/visual/msripub-000001-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000002.png"><img src="https://cr.yp.to/writing/visual/msripub-000002-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000003.png"><img src="https://cr.yp.to/writing/visual/msripub-000003-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000004.png"><img src="https://cr.yp.to/writing/visual/msripub-000004-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000005.png"><img src="https://cr.yp.to/writing/visual/msripub-000005-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000006.png"><img src="https://cr.yp.to/writing/visual/msripub-000006-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000007.png"><img src="https://cr.yp.to/writing/visual/msripub-000007-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000008.png"><img src="https://cr.yp.to/writing/visual/msripub-000008-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000009.png"><img src="https://cr.yp.to/writing/visual/msripub-000009-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000010.png"><img src="https://cr.yp.to/writing/visual/msripub-000010-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000011.png"><img src="https://cr.yp.to/writing/visual/msripub-000011-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000012.png"><img src="https://cr.yp.to/writing/visual/msripub-000012-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000013.png"><img src="https://cr.yp.to/writing/visual/msripub-000013-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000014.png"><img src="https://cr.yp.to/writing/visual/msripub-000014-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000015.png"><img src="https://cr.yp.to/writing/visual/msripub-000015-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000016.png"><img src="https://cr.yp.to/writing/visual/msripub-000016-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000017.png"><img src="https://cr.yp.to/writing/visual/msripub-000017-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000018.png"><img src="https://cr.yp.to/writing/visual/msripub-000018-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000019.png"><img src="https://cr.yp.to/writing/visual/msripub-000019-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000020.png"><img src="https://cr.yp.to/writing/visual/msripub-000020-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000021.png"><img src="https://cr.yp.to/writing/visual/msripub-000021-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000022.png"><img src="https://cr.yp.to/writing/visual/msripub-000022-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000023.png"><img src="https://cr.yp.to/writing/visual/msripub-000023-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000024.png"><img src="https://cr.yp.to/writing/visual/msripub-000024-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000025.png"><img src="https://cr.yp.to/writing/visual/msripub-000025-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000026.png"><img src="https://cr.yp.to/writing/visual/msripub-000026-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000027.png"><img src="https://cr.yp.to/writing/visual/msripub-000027-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000028.png"><img src="https://cr.yp.to/writing/visual/msripub-000028-4.png" height="439" width="310"></a>
</td></tr>
</tbody></table>
</p><p>
Wow, that's a really pleasant document to read!
I love the huge chunks of white space,
the visually stunning bibliography,
the completely non-functional citations to that bibliography,
the entertaining little black boxes everywhere,
and the line on page 24 sticking not merely into the margin but beyond the printed area of the page.
I'm glad that I concerned myself solely with the structure of my document,
and not with any particular visual representation.
</p><p>
This document must have been first seen by Levy,
who was not merely the skilled "msripub" designer
but also the editor of this particular book.
Surely he was inspired by the document's near-perfect beauty
and thought that a few additional tweaks
would produce a truly stunning work of art.
The scientific editors of the book waited for Levy to act.
But Levy did nothing.
Perhaps the explanation lies in Lamport's wise words:
</p><blockquote>
A logical system forces the writer
to think in terms of the document's logical structure;
it doesn't give him the illusion
that he is accomplishing anything with cosmetic formatting changes.
</blockquote>
<p>
In any event,
I wasn't able to see the "msripub" version of the document until April 2007.
Levy never sent me a copy.
You might think that I could simply change "amsart" to "msripub"
in my own copy of the document,
but "msripub" is a proprietary format:
Levy keeps it to himself.
Eventually the scientific editors convinced Levy to send "msripub" to me.
I fed my document through "msripub" and admired the output.
</p><p>
Beautiful!
</p><p>
I returned to Lamport's article
and discovered that he allowed certain minor exceptions to his "illusion":
</p><blockquote>
Achieving the highest possible quality
requires the ability to make changes to the system's output.
This will be a matter of fine tuning,
changing such things as page breaks and figure placement. ...
[However:]
The changes will generally be of such a minor nature
that they are not worth bothering with
in a preliminary version intended for a small audience,
nor for any document that is not widely distributed.
...
I usually spend less than two minutes per page
doing the final formatting to produce camera-ready output.
This is insignificant compared with the two to eight hours per page I spend writing.
</blockquote>
"Highest possible quality" sounds desirable,
and "two minutes" sounds tolerably small,
so I decided to edit the "msripub" version of my document.
<p>
You might like to pause at this point to contemplate the goals of scientific publication.
Isn't it wonderful to see science propelled forward
by something as small and simple as the switch from "amsart" to "msripub"?
</p><p>
Back to the story.
After many, many, many hours of work I had a new version of the document:
<table>
<tbody><tr>
<td><a href="https://cr.yp.to/writing/visual/34-000001.png"><img src="https://cr.yp.to/writing/visual/34-000001-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000002.png"><img src="https://cr.yp.to/writing/visual/34-000002-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000003.png"><img src="https://cr.yp.to/writing/visual/34-000003-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000004.png"><img src="https://cr.yp.to/writing/visual/34-000004-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000005.png"><img src="https://cr.yp.to/writing/visual/34-000005-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000006.png"><img src="https://cr.yp.to/writing/visual/34-000006-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000007.png"><img src="https://cr.yp.to/writing/visual/34-000007-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000008.png"><img src="https://cr.yp.to/writing/visual/34-000008-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000009.png"><img src="https://cr.yp.to/writing/visual/34-000009-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000010.png"><img src="https://cr.yp.to/writing/visual/34-000010-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000011.png"><img src="https://cr.yp.to/writing/visual/34-000011-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000012.png"><img src="https://cr.yp.to/writing/visual/34-000012-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000013.png"><img src="https://cr.yp.to/writing/visual/34-000013-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000014.png"><img src="https://cr.yp.to/writing/visual/34-000014-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000015.png"><img src="https://cr.yp.to/writing/visual/34-000015-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000016.png"><img src="https://cr.yp.to/writing/visual/34-000016-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000017.png"><img src="https://cr.yp.to/writing/visual/34-000017-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000018.png"><img src="https://cr.yp.to/writing/visual/34-000018-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000019.png"><img src="https://cr.yp.to/writing/visual/34-000019-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000020.png"><img src="https://cr.yp.to/writing/visual/34-000020-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000021.png"><img src="https://cr.yp.to/writing/visual/34-000021-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000022.png"><img src="https://cr.yp.to/writing/visual/34-000022-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000023.png"><img src="https://cr.yp.to/writing/visual/34-000023-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000024.png"><img src="https://cr.yp.to/writing/visual/34-000024-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000025.png"><img src="https://cr.yp.to/writing/visual/34-000025-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000026.png"><img src="https://cr.yp.to/writing/visual/34-000026-4.png" height="439" width="310"></a>
</td></tr>
</tbody></table>
I had changed more than 100 separate lines of the main text,
not to mention the introductory figures, the bibliography, etc.
Many of those lines were quite difficult to adjust:
eliminating one bad line break
often meant experimenting with several different wordings and inspecting the output of each.
"Two minutes" is, I regret to report, a rather severe underestimate.
Could it be that Levy had a different reason for doing nothing at all with this paper?
</p><p>
I spent a few more hours carefully checking the paper
against the old "amsart" version
to see whether any bugs had been introduced by this flood of changes.
I ended up fixing two obsolete cross-references and two typos.
And so, finally, the conversion from "amsart" to "msripub" came to an end.


</p></div>]]>
            </description>
            <link>https://cr.yp.to/writing/visual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25355291</guid>
            <pubDate>Wed, 09 Dec 2020 04:16:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Energy-Based Perspective on Attention Mechanisms in Transformers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25355096">thread link</a>) | @wavelander
<br/>
December 8, 2020 | https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews | <a href="https://web.archive.org/web/*/https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
  <a href="https://xkcd.com/793/">XKCD 793: A physicist encountering machine learning for the first time</a>
</p>
<hr>
<ol>
<li><a href="#1-introduction">Introduction</a></li>
<li><a href="#2-a-growing-zoo-of-transformers">A growing zoo of Transformers</a>
<ol>
<li><a href="#vanilla-transformers">Vanilla Transformers</a></li>
<li><a href="#beyond-vanilla-confronting-quadratic-scaling">Beyond vanilla: confronting quadratic scaling</a></li>
</ol>
</li>
<li><a href="#3-from-hopfield-networks-to-transformers">From Hopfield networks to Transformers</a>
<ol>
<li><a href="#classical-discrete-hopfield-networks">Classical discrete Hopfield networks</a></li>
<li><a href="#modern-discrete-hopfield-networks">Modern discrete Hopfield networks</a></li>
<li><a href="#modern-continuous-hopfield-networks">Modern continuous Hopfield networks</a></li>
<li><a href="#modern-continuous-hopfield-networks-as-energy-based-models">Modern continuous Hopfield networks as energy-based models</a>
<ol>
<li><a href="#energy-based-models-a-gentle-introduction">Energy-based models: a gentle introduction</a></li>
<li><a href="#exactly-optimizing-modern-continuous-hopfield-networks">Exactly optimizing modern continuous Hopfield networks</a></li>
</ol>
</li>
<li><a href="#transformers-store-and-retrieve-context-dependent-patterns">Transformers store and retrieve context-dependent patterns</a></li>
<li><a href="#where-are-patterns-stored-in-a-transformer">Where are patterns stored in a Transformer?</a></li>
</ol>
</li>
<li><a href="#4-training-transformers">Training Transformers</a>
<ol>
<li><a href="#pretraining-loss-functions">Pretraining loss functions</a></li>
<li><a href="#stepping-through-the-transformer-implicit-energy-minimization">Stepping through the Transformer: implicit energy minimization</a></li>
<li><a href="#meta-learning-and-few-shot-inference">Meta-learning and few-shot inference</a></li>
</ol>
</li>
<li><a href="#5-beyond-dot-product-attention">Beyond dot-product attention</a>
<ol>
<li><a href="#attention-dynamics-embracing-collective-phenomena">Attention dynamics: embracing collective phenomena</a></li>
<li><a href="#why-very-long-sequences-should-not-be-needed">Why very long sequences should not be needed</a></li>
</ol>
</li>
<li><a href="#6-conclusion">Conclusion</a></li>
<li><a href="#references--footnotes">References &amp; footnotes</a></li>
</ol>
<hr>

<p>In 2017, <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a> <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> demonstrated state-of-the-art performance in neural machine translation by stacking only (self-)attention layers. Compared to recurrent neural networks, Transformer models exhibit efficient parallel processing of tokens, leading to better modeling of long-range correlations and, most importantly, <a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener">favorable scaling in terms of data and compute</a>. Since then, Transformers seem to have taken over natural language processing. Widespread adoption of attention-based architectures seems likely given recent work like <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a> and the flurry of developments addressing the architecture’s quadratic scaling bottlenecks.</p>
<p>Recently, the papers <a href="https://arxiv.org/abs/2008.02217" target="_blank" rel="noopener">Hopfield Networks is All You Need</a> <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> and <a href="https://arxiv.org/abs/2008.06996" target="_blank" rel="noopener">Large Associative Memory Problem in Neurobiology and Machine Learning</a> <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> provided complementary post-facto explanations of some of the success of Transformers from the perspective of energy-based models. In this post, I provide a biased overview of (self-)attention in Transformers and summarize its connections to modern Hopfield networks. Along the way, I look for intuition from physics and indulge in hand-wavy arguments on how an energy-based perspective can shed light on training and improving Transformer models.</p>

<p>Let’s start off with an overview of the components in a vanilla Transformer model. Since our focus is on (self-)attention, I am going to assume some prior knowledge<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> and skip comprehensive architecture descriptions and experimental results. In <a href="#3-from-hopfield-networks-to-transformers">Section 3</a>, we will start from scratch and use Hopfield networks to build back up to the attention module described below.</p>
<h2 id="vanilla-transformers">Vanilla Transformers</h2>
<p>The proto-Transformer was introduced in an encoder-decoder context for machine translation in <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a>. The original motivation seems to have been mostly driven by engineering efforts to model long-range correlations in sequence data and the recent successes of attention mechanisms stacked on top of recurrent neural networks. The main contribution and selling point of the paper was making an attention-only approach to sequence modeling work.</p>
<p><img src="https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/vanilla_transformer.png" alt="alt text" title="Vanilla Transformers encoder-decoder architecture"></p>
<p>Let’s focus on the encoder on the left and ignore the decoder on the right. Transformer models accept (batches of) sets of vectors, which covers most inputs people care about in machine learning. Text can be modelled as a sequence of embedded tokens. Images can be viewed as a snaky sequence of embedded pixels or embedded patches of pixels. Since sets have no notion of ordering, learned or fixed positional information needs to be explicitly added to the input vectors.</p>
<p>The main module in the Transformer encoder block is the multi-head <em>self-attention</em>, which is based on a (scaled) dot-product attention mechanism acting on a set of $d$-dimensional vectors:</p>
<p>\begin{equation}
\mathrm{Attention}\left( \mathbf{Q}, \mathbf{K}, \mathbf{V} \right) = \mathrm{softmax} \left( \frac{\mathbf{Q} \mathbf{K}^T}{\sqrt{d}} \right) \mathbf{V}
\label{eq:vanilla-attention}
\end{equation}</p>
<p>Here, queries $\mathbf{Q}$, keys $\mathbf{K}$, and values $\mathbf{V}$ are matrices obtained from acting with different linear transformations — parametrized respectively by weights $\mathbf{W}_{\mathbf{Q}}$, $\mathbf{W}_{\mathbf{K}}$, and $\mathbf{W}_{\mathbf{V}}$ — on the same set of $d$-dimensional inputs. <em>Cross-attention</em> takes the inputs for its queries from a different source than for its keys and values, as can be glimpsed from the decoder part of the architecture on the right.</p>
<p>For every input query, the updated output query of \eqref{eq:vanilla-attention} is a linear combination of values weighted by an attention matrix quantifying the overlap of the input query with the keys corresponding to these values. Since all objects are vectors and the attention mechanism is just a dot product between vectors, we can think of the attention module as matching query vectors to their “closest” key vectors in latent space and summing up contributions from value vectors, weighted by the “closeness” of their keys to the queries.</p>
<p>The remaining components of the Transformer encoder block are needed to make the module work properly in practice:</p>
<ul>
<li>The <em>multi-headedness</em> of the attention module refers to chunking up the dimension of the vector space and having multiple attention operations running in parallel in the same module, yet with each acting on a lower-dimensional segment of the full space. This is a trick to (1) get around the fact that every input vector only couples to one query at a time to calculate its attention coefficient, and (2) provide multiple starting points in the subspaces for the queries, which might help to avoid bad local minima in parameter space during optimization.</li>
<li>A positional feed-forward network, made up of two linear layers with a non-linearity in between, is inserted at the end of the module. Folklore wisdom tells us that the feed-forward layer needs to blow up the dimension of the latent space by a factor of four for it to be able to “disentangle” the represention. More likely though, it’s a way to increase model capacity and warp latent spaces since the attention modules on their own are pretty much linear apart from the $\mathrm{softmax}$-operator used to obtain the normalized attention coefficients.</li>
<li>Residual connections are added to control the flow of gradients.</li>
<li>Layer normalisation is used to control learning dynamics and keep vector norms from exploding.</li>
</ul>
<h2 id="beyond-vanilla-confronting-quadratic-scaling">Beyond vanilla: confronting quadratic scaling</h2>
<p>Most architectural variations of the vanilla Transformer are targeted at the attention module, which scales poorly with respect to the input sequence length $N$. Since the overlap of all queries with all keys is required, calculating a dense attention matrix scales like $\mathcal{O}(N^2)$ in time and space. Limits on the context window of the attention mechanism during training prevent the model from learning how to deal with long sequences and long-range correlations. The majority of post-vanilla Transformer species can be classified into one of the following buckets<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>:</p>
<ul>
<li>Low-rank approximations: truncate the matrix product $\mathbf{Q} \mathbf{K}^T$ since it’s likely not full rank for structured data</li>
<li>Sparsification: reduce the attention calculation from all query-key pairs to a subset because not all of them feel the need to talk to each other</li>
<li>Recurrence: keep track of a (compressed) history of context</li>
<li>Kernels: approximate the attention operation with kernel methods</li>
</ul>
<p>For the remainder of our discussion, we will focus on vanilla Transformers. One of the goals of this blog post is to explore how a different perspective on the <em>function</em> of attention-based algorithms might lead to qualitatively different improvements beyond what is possible by relying on scaling and reducing computational complexity alone.</p>

<p>In this section, we provide a short history of Hopfield networks and gradually build up intuition until we can recognize the Transformer self-attention mechanism for what it really is. We refer to the <a href="https://ml-jku.github.io/hopfield-layers/" target="_blank" rel="noopener">blog post</a> accompanying <a href="https://arxiv.org/abs/2008.02217" target="_blank" rel="noopener">Hopfield Networks is All You Need</a> for more details and insightful visualizations of pattern storage and retrieval.</p>
<h2 id="classical-discrete-hopfield-networks">Classical discrete Hopfield networks</h2>
<p>A <a href="https://en.wikipedia.org/wiki/Hopfield_network" target="_blank" rel="noopener">Hopfield network</a> is a simple model for associative memory popularized by John Hopfield in his 1982 paper <a href="https://www.pnas.org/content/pnas/79/8/2554.full.pdf" target="_blank" rel="noopener">Neural Networks and Physical Systems with Emergent Collective Computational Abilities</a><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>. The task of an associative memory is to store and retrieve patterns, preferably in a way that allows one to recover stored patterns quickly with a low error rate.</p>
<p>The basic idea of the Hopfield network — and other energy-based models like <a href="https://en.wikipedia.org/wiki/Boltzmann_machine" target="_blank" rel="noopener">Boltzmann machines</a> — is to construct an <em>energy function</em> which defines an <em>energy landscape</em> containing basins of attraction around patterns we want to store. Starting at any pattern, we want to have an update rule pointing towards the closest stored pattern, guided by a scalar “closeness” score provided by the energy function.</p>
<p><a href="https://en.wikipedia.org/wiki/Hopfield_network" target="_blank" rel="noopener"><img src="https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/energy_landscape.png" alt="alt text" title="Toy energy landscape of a Hopfield Network"></a></p>
<p>Let’s make this a bit more formal but not too formal. Consider trying to store a set of $N$ binary patterns $\{\boldsymbol{x}_{i}\}_{i=1}^{N}$ where each pattern $\boldsymbol{x}_{i}$ is a $d$-dimensional vector whose entries are either $-1$ or $1$. For example, in the case of storing black-and-white images, every image would correspond to a string of pixel values, a binary pattern $\boldsymbol{x}_{i}$.</p>
<p>For any query $\boldsymbol{\xi} \in \mathbb{R}^{d}$, or <em>state pattern</em>, we want to find a way to retrieve the closest <em>stored pattern</em>. In his paper, Hopfield considered the energy function</p>
<p>\begin{equation}
E = - \frac{1}{2} \boldsymbol{\xi}^{T} \boldsymbol{W} \boldsymbol{\xi} + \boldsymbol{\xi}^{T} \boldsymbol{b} = - \frac{1}{2} \sum_{i=1}^{d} \sum_{j=1}^{d} w_{ij} \xi_{i} \xi_{j} + \sum_{i=1}^{d} b_{i} \xi_{i} ,
\label{eq:ising}
\end{equation}</p>
<p>where $\boldsymbol{b} \in \mathbb{R}^{d}$ denotes a bias vector and the weights $\boldsymbol{W} \in \mathbb{R}^{d \times d}$ are set to the sum of the outer products of the patterns we want to store</p>
<p>\begin{equation}
\boldsymbol{W} = \sum_{i=1}^{N} \boldsymbol{x}_{i} \otimes …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews">https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews</a></em></p>]]>
            </description>
            <link>https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25355096</guid>
            <pubDate>Wed, 09 Dec 2020 03:48:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm Skeptical of “Experts”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25354995">thread link</a>) | @karlhughes
<br/>
December 8, 2020 | https://www.karllhughes.com/posts/experts | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/experts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://i.imgur.com/Hx2paJy.jpg" alt="The Danger in Listening to Experts">
</p> 

<p>
2020, Oct 27&nbsp;&nbsp;&nbsp;—&nbsp;
11 minute read
</p>
<section id="mc_embed_signup">

</section>
<blockquote>
<p>“Most of all, there is this truth: No matter how great your teachers may be, and no matter how esteemed your academy’s reputation, eventually you will have to do the work by yourself. Eventually, the teachers won’t be there anymore. The walls of the school will fall away, and you’ll be on your own.” - <a href="https://amzn.to/2TtGVsm">Elizabeth Gilbert, Big Magic</a></p>
</blockquote>
<p>I am very intentional about cultivating peers and mentors who I trust. When I <a href="https://www.karllhughes.com/posts/cto-writer">left my job to start a business</a> earlier this year, one of the first things I did was create a list of informal advisors - mostly experienced entrepreneurs who I could count on for candid feedback.</p>
<p>Still, when I meet with one of my mentors to ask them a specific question, I start the conversation with a warning:</p>
<p>“I have a question, but just so you know, you’re not the only person I’m asking. If I don’t take your advice, I don’t want you to take it personally, okay?”</p>
<p>Every one of them appreciates this caveat because <strong>giving advice is really hard.</strong> In fact, I am starting to realize that you should be wary of people who are too quick to offer it.</p>
<p>The further I go in my career, the more skeptical I am of “experts.” While people with experience may generally make better decisions, I don’t know if their advice transfers the way they think it does.</p>
<p>Now, I realize the irony in offering advice to ignore advice, but my goal is to make you reconsider all advice - including the advice I give.</p>
<p>Above all, I hope this makes you think before you blindly follow others.</p>
<h2 id="1-experts-overgeneralize-their-experience">1. Experts Overgeneralize Their Experience</h2>
<p>Many legitimately successful people got lucky once.</p>
<p>You see this a lot in Silicon Valley-style businesses where a single expert or lucky investment might lead to generational wealth. These successful and wealthy people feel that they’ve discovered the “secret” to building a business based on a single runaway success.</p>
<p>This bias is called <a href="http://iameduard.com/overgeneralization/">overgeneralization</a>, and both advice givers and receivers fall into it.</p>
<p>For example, if you’ve read <a href="https://amzn.to/3oy8DSY">Walter Isaacson’s biography</a>, you know that Steve Jobs was a ruthless boss and obsessive about details. Jobs was amazingly successful as an entrepreneur and executive; therefore, you should be ruthless and obsessive if you want to be a successful entrepreneur and executive.</p>
<p>The logical fallacy here is obvious - we can point to dozens of counterpoints - but it illustrates the danger in overgeneralizing an expert’s advice or behavior.</p>
<p>Part of the reason we fall prey to experts who overgeneralize their experience is that as humans, <a href="https://manuel.friger.io/blog/advice">we really like stories</a>:</p>
<blockquote>
<p>“We love anecdotes so much because it’s often much easier for people to believe someone’s testimony as opposed to <strong>understanding complex data and variation across a continuum</strong>. Anecdotes exempt us from having to prove our point: it’s happened once; that’s solid proof as far as I’m concerned.” - <a href="https://manuel.friger.io/blog/advice">Manuel Frigerio</a></p>
</blockquote>
<p>Manuel cites Jeanne Calment, who lived to 116 years old and smoked every day of her adult life. Jeanne Calment is one data point. <strong>What worked for one person one time many years ago will not work for everyone for all time.</strong></p>
<p><img src="https://paper-attachments.dropbox.com/s_11C9E1C44BCB40F0FE12CD8C443C12B2DA5D48417F2028A6D847E5BE71580EB1_1603765436506_ovg.jpg" alt=""></p>
<p>Additionally, many experts <a href="https://twitter.com/KarlLHughes/status/1284104244891721730">rewrite their stories in their minds</a>.</p>
<p>Take Brian Williams, once an upstanding NBC news anchor and respected journalist. He told a complete fabrication of his experience in Iraq multiple times, including in an especially vivid recounting at a hockey game:</p>
<blockquote>
<p>“The story actually started with a terrible moment a dozen years back during the invasion of Iraq when the helicopter we were traveling in was forced down after being hit by an RPG.” - <a href="https://www.vox.com/2015/2/5/7987439/brian-williams-iraq-apology-helicopter">Brian Williams</a></p>
</blockquote>
<p>I don’t know if Williams knew he was lying or not, but if you want to believe his apology, he mistakenly inserted himself into a true story that he had seen:</p>
<blockquote>
<p>“I think the constant viewing of the video showing us inspecting the impact area — and the fog of memory over 12 years — made me conflate the two.” - Brian Williams (later apologizing)</p>
</blockquote>
<p>Whatever the details of Williams’ story, it’s easy to imagine that most professionals with 10+ years of experience will misremember or rewrite parts of their own experience when asked. This problem gets compounded when beginners ask for advice from experts because they can’t discern the misremembering from the truth.</p>
<p>Beginners don’t have enough experience to call bullsh** on experts.</p>
<h2 id="2-inherent-survivorship-bias">2. Inherent Survivorship Bias</h2>
<blockquote>
<p>“<strong>The Misconception:</strong> You should focus on the successful if you wish to become successful.</p>
<p><strong>The Truth:</strong> When failure becomes invisible, the difference between failure and success may also become invisible.” - <a href="https://youarenotsosmart.com/2013/05/23/survivorship-bias/">David McRaney</a></p>
</blockquote>
<p><strong>Survivors become experts</strong>, regardless of their skills, knowledge, or the repeatability of their experience.</p>
<p>Survivorship bias is one of the most dangerous ones in finance, and it’s one of the easiest traps to fall into when you look for advice. By taking only the positive cases (i.e.: people who succeeded in your field), you are unable to tell which factors were vital to their success and which factors were unrelated to it.</p>
<p>You hear the same thing from people who claim, “they sure don’t make ‘em like they used to.”</p>
<blockquote>
<p>“A commonly held opinion in many populations is that machinery, equipment, and goods manufactured in previous generations often is better built and lasts longer…because of the selective pressures of time and use, it is inevitable that only those items that were built to last will have survived into the present day.</p>
<p>Therefore, most of the old machinery still seen functioning well in the present day must necessarily have been built to a standard of quality necessary to survive. All of the machinery, equipment, and goods that have failed over the intervening years are no longer visible to the general population as they have been junked, scrapped, recycled, or otherwise disposed of.” - <a href="https://en.wikipedia.org/wiki/Survivorship_bias">Wikipedia, Survivorship Bias</a></p>
</blockquote>
<p><img src="https://paper-attachments.dropbox.com/s_11C9E1C44BCB40F0FE12CD8C443C12B2DA5D48417F2028A6D847E5BE71580EB1_1603765755896_survivor.jpg" alt=""></p>
<p>When survivors give advice, they conflate correlation and causation. Was the fact that <a href="https://tim.blog/about/">Tim Ferriss</a> executed his book launch a certain way the reason it succeeded? Or was the fact that Tim Ferriss had a massive audience of followers before his latest book launch the real reason?</p>
<p>We can’t know <a href="https://pjrvs.com/survivorship">because Tim Ferriss is a survivor</a>. He is one of the few authors who has “made it” to the level he has. By virtue of surviving this far, we have to take all of his marketing advice with a grain of salt.</p>
<p>The danger of survivorship bias is that it’s tough to combat. People <a href="https://www.inc.com/jeff-haden/want-to-really-help-others-talk-about-your-failures-not-successes.html">don’t like to talk about their failures</a>, and failures are subject to the same overgeneralization biases that successes are. In other words, <strong>even if someone tells you why they think they failed, they’re probably wrong.</strong></p>
<h2 id="3-the-expert-beginner-experience-gulf">3. The Expert-Beginner Experience Gulf</h2>
<p>Knowledge isn’t discrete - it’s a continuum.</p>
<p>Experts tend to forget that they have a considerable base of knowledge that beginners lack. This experience gap means that realizations the expert recently had will be useless (or even harmful) to beginners who lack the same foundational understanding.</p>
<p>For example, a friend of mine recently graduated from a coding bootcamp and asked me what podcasts I listen to.</p>
<p>I thought about it for a while. Are the software architecture and management podcasts I listen to going to help this guy? There weren’t many programming podcasts around when I learned to code, so I can’t tell him which ones helped me when I was just starting out. Should I selfishly send him the podcast that recently invited me on as a guest?</p>
<p>I struggle with advising new programmers because the gulf between my current level of experience and theirs is too broad. I don’t remember what I didn’t know when I was just starting out; plus, the world has changed. The books I read back then are hopelessly out of date, and the books I read now are hopelessly indecipherable to most new programmers.</p>
<p>This chart illustrates the problem. When you’re just starting to learn about a topic, you start in the bottom-left, and over time you move to the top right:</p>
<p><img src="https://i.imgur.com/zxD9C4I.png" alt="Knowledge contimuum"></p>
<p>Beginners need to grasp relationships and patterns, while experts are interested in uncovering principles. The advice experts give often comes from their higher-level understanding.</p>
<p>What’s more insidious about the expert-beginner gulf is that people’s brains actually <a href="https://www.wired.com/2009/03/financebrain/"><em>shut down</em> when given advice from an expert</a>:</p>
<blockquote>
<p>“When thinking for themselves, students showed activity in their anterior cingulate cortex and dorsolateral prefrontal cortex — brain regions associated with making decisions and calculating probabilities. When given advice from Noussair, activity in those regions flat lined. - <a href="https://www.wired.com/2009/03/financebrain/">Brandon Keim, Wired</a></p>
</blockquote>
<p>Even if the advice makes sense given the expert’s current level of understanding, the beginner may not grasp the underlying patterns required to make good use of the advice.</p>
<p>For example, we typically tell new drivers to stop at red lights. This is good generalized advice, but a beginner may not realize that there exceptions to this rule. What if the light is flashing red? What if it’s red, but no traffic is coming, and you want to turn right? What if you have a medical emergency?</p>
<p>Experienced drivers can make judgment calls based on advice and experience, but beginners cannot. They haven’t developed the filters to process and individualize advice.</p>
<h2 id="4-they-might-be-charlatans">4. They Might Be Charlatans</h2>
<p>It’s hard to believe I’ve gotten this far without mentioning experts who are blatantly slanting their advice towards profit, but I’ll get to it now.</p>
<p>First, what is a <em>charlatan?</em></p>
<blockquote>
<p>“A person who pretends or claims to have more knowledge or skill than he or she possesses; quack.” - <a href="https://www.dictionary.com/browse/charlatan">Dictionary.com</a></p>
</blockquote>
<p>Right now, most online courses are sold by charlatans. I’m not saying you can’t learn anything from them, but most people selling them don’t have much more knowledge than you do; they just offer their advice more confidently.</p>
<blockquote>
<p>“We now live in a time where information is becoming less and less commoditized and learning is becoming freer by passing days. So, it’s surprising that institutes and “experts” still exist and charge big money for courses.” - <a href="https://thatnameasif.medium.com/digital-marketing-courses-scam-be96464c12e2">Asif Ali</a></p>
</blockquote>
<p>Ironically, most charlatans don’t even know …</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/experts">https://www.karllhughes.com/posts/experts</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/experts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354995</guid>
            <pubDate>Wed, 09 Dec 2020 03:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Webless Initiative]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25354786">thread link</a>) | @userbinator
<br/>
December 8, 2020 | http://repo.hu/projects/webless/ | <a href="https://web.archive.org/web/*/http://repo.hu/projects/webless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><a href="http://repo.hu/projects/webless/index.html#webless">The Webless Initiative</a> |
Rules: <a href="http://repo.hu/projects/webless/rules-friends.html">Friends</a> /
<a href="http://repo.hu/projects/webless/rules-validated.html">Validated</a> |
<a href="http://repo.hu/projects/webless/index.html#mailinglist">Mailing List</a> |
<a href="http://repo.hu/projects/webless/faq.html">FAQ</a> |
<a href="http://repo.hu/projects/webless/index.html#contact">Contact</a> |
<a href="http://repo.hu/projects/webless/friends.html">The Friends of Webless</a>
<hr>



<p>See the <a href="http://repo.hu/projects/webless/antiweb.html">Anti-web Manifesto</a>

</p><p><b>The Webless Initiative</b> is a campaign to make the modern Web a more
livable place. We aim to accomplish this by:
</p><ul>
	<li>Discouraging useless "style" or "interactive" features
	</li><li>Encouraging fast, portable, readable pages, with simpler HTML
</li></ul>
<p>This should:
</p><ul>
	<li>Make web browsers potentially a lot smaller, faster and comfortable<br>
	(realistically, make it possible to use existing small web browsers)
	</li><li>Drastically lessen the necessary bandwidth, making more room for real content
</li></ul>
<p>We plan to provide a set of rules and recommendations for anyone who wishes
to make their web page conformant. There will be an automatic validator for this
ruleset.
</p><p>We plan to create and maintain <b>two lists of websites</b>, with an appropriate
label or banner site owners can publish to indicate their membership:
</p><ul>
<li><b><a href="http://repo.hu/projects/webless/friends.html">Friends of Webless</a></b>
<p>
Simply by expressing their wish, anyone can be part of this list. The only
condition is that their site is <b>comfortably usable with a small web browser</b>.
</p><p>This might be manually checked, and Webless might refuse to keep the site listed,
if we perceive that it does not meet <a href="http://repo.hu/projects/webless/rules-friends.html">this rule</a>.

</p></li><li><b>Validated Webless</b>
<p>
Membership on this list is per request. The site will be checked
(and may be periodically rechecked) against the <a href="http://repo.hu/projects/webless/rules-validated.html">Webless Rules.</a>
Only sites passing these tests will be listed.
</p></li></ul>
<p>
We ask that listed (friends and validated) sites place a link on this page.
This is not mandatory; and the link might serve as a disclaimer for when
visitors are asking why your page is lacking all the modern whizbang.

</p><h2><a name="mailinglist">Contact</a></h2>

<p>For the moment, if you want to see your site on either the Friends or the
Validated list, please send me a mail (see address below).

</p><h2><a name="extern">Recommended Reading</a></h2>

<ul>
<li><a href="http://www.anybrowser.org/campaign/">Viewable with Any Browser</a>
</li><li><a href="http://www.websiteoptimization.com/speed/tweak/average-web-page/">Average Web Page Size Triples Since 2003</a>
</li><li><a href="http://www.flownet.com/ron/css-rant.html">Why CSS should not be used for layout</a>
</li></ul>

<h2><a name="contact">Contact</a></h2>

<p>You can reach us on IRC: server <code>repo.hu</code>, channel <code>#dev</code>.
</p><p>Via e-mail: <code>webless (at) igor2.repo.hu</code>
</p></div>]]>
            </description>
            <link>http://repo.hu/projects/webless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354786</guid>
            <pubDate>Wed, 09 Dec 2020 02:55:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Survey 2020 Results]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25354551">thread link</a>) | @pama
<br/>
December 8, 2020 | https://emacssurvey.org/2020/ | <a href="https://web.archive.org/web/*/https://emacssurvey.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2>Questions</h2>
      <p>For reference, this was <a href="https://emacssurvey.org/2020/emacs-user-survey-2020.org">the survey questions</a> in org-mode format.</p>
      <h2>Data</h2>
      <ul>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-raw.csv">Raw data</a>
          <ul>
            <li>the reconciled data from both webform and email submissions</li>
            <li>absolutely no change made aside from a few instances where PII and email addresses were redacted</li>
          </ul>
        </li>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-clean.csv">Cleaned up data</a><br>
          It might get updated in the future, but right now it was derived from the raw data in a best-effort attempt:
          <ul>
            <li>removed negative years in "For how many years have you been using Emacs?"</li>
            <li>unified responses for "How did you hear about this survey?" as Hacker News, Emacs China and Emacs News weren't part of the options</li>
            <li>unified responses for "Which theme do you use?", especially around spelling</li>
            <li>general cleanup and unified of responses which only differed by punctuation and casing</li>
          </ul>
        </li>
      </ul>
      <h2>Statistics about the survey</h2>
      
      <h2>Analysis</h2>
      <p>There is a lot of data to look at in many different ways. For now, I performed a simple question-by-question analysis using a <a href="https://github.com/abrochard/emacs-survey/blob/main/2020/Emacs%20User%20Survey%202020.ipynb">Jupyter Notebook</a>.</p>
      <p>Also, since free text was available for most questions, it can be hard to categorize some of the results. For multiple choice questions, I did a best effort attempt to bundle responses with low cardinality into an "other" section, which can get quite big in some cases! I also did not attempt to graph anything for pure free text questions. I encourage anyone who is curious to inspect the full responses, either in the notebook or looking at the data directly. The omitted free text questions are:
        </p><ul>
          <li>If you use org-mode, for what purpose?</li>
          <li>Do you use a language server with lsp-mode or eglot? With what languages?</li>
          <li>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</li>
          <li>What are some of the Emacs improvements you are the most interested in?</li>
          <li>What do you think are Emacs' greatest strengths?</li>
          <li>Can you recall any difficulties you faced initially learning Emacs?</li>
          <li>What is the one thing you would like Emacs to do differently?</li>
          <li>If there is another survey in 2021, would you be opposed to it containing optional &amp; general demographics questions?</li>
          <li>Do you have a preferred platform for filling out the survey in the future?</li>
          <li>Do you have general feedback about the survey process?</li>
        </ul>
      

      <p>Also if you have some cool analysis and want to share it, please <a href="mailto:contact@emacssurvey.org">let us know</a> and we can link to you.</p>
      <p><img src="https://emacssurvey.org/2020/how-would-you-characterize-your-use-of-emacs.png">
      <img src="https://emacssurvey.org/2020/what-do-you-use-emacs-for.png">
      <img src="https://emacssurvey.org/2020/for-how-many-years-have-you-been-using-emacs.png">
      <img src="https://emacssurvey.org/2020/which-version-of-emacs-do-you-primarily-use.png">
      <img src="https://emacssurvey.org/2020/which-os-do-you-primarily-use-emacs-on.png">
      <img src="https://emacssurvey.org/2020/how-do-you-run-emacs.png">
      <img src="https://emacssurvey.org/2020/how-do-you-use-emacs.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-gui-do-you-disable-any-of-the-graphical-elements.png">
      <img src="https://emacssurvey.org/2020/is-your-configuration-based-on-any-starter-kit.png">
      <img src="https://emacssurvey.org/2020/what-keybindings-do-you-use-now.png">
      <img src="https://emacssurvey.org/2020/when-you-started-using-emacs-what-keybindings-did-you-use-then.png">
      <img src="https://emacssurvey.org/2020/prior-to-using-emacs-what-was-your-primary-editor.png">
      <img src="https://emacssurvey.org/2020/describe-your-org-mode-usage.png"></p><!-- <p>If you use org-mode, for what purpose?</p> -->
      <p><img src="https://emacssurvey.org/2020/which-completionselection-framework-do-you-use.png">
      <img src="https://emacssurvey.org/2020/how-do-you-manage-third-party-elisp.png">
      <img src="https://emacssurvey.org/2020/how-do-you-get-emacs-packagesif-applicable.png">
      <img src="https://emacssurvey.org/2020/can-you-list-some-of-your-favorite-packages.png">
      <img src="https://emacssurvey.org/2020/which-theme-do-you-use.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-error-checking.png">
      <img src="https://emacssurvey.org/2020/do-you-use-tramp.png">
      <img src="https://emacssurvey.org/2020/do-you-use-magit.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-project-management.png">
      <img src="https://emacssurvey.org/2020/do-you-use-a-shellterminal-emulator-in-emacs.png">
      <img src="https://emacssurvey.org/2020/do-you-use-an-email-client-in-emacs.png">
      <img src="https://emacssurvey.org/2020/what-is-your-elisp-proficiency.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-for-programming-which-languages-do-you-program-in.png"></p><!-- <p>Do you use a language server with lsp-mode or eglot? With what languages?</p>
           <p>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</p> -->
      <p><img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-gnu-emacs-coreelpa.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-melpa-package.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-financially-to-emacs-development-either-via-fsf-or-directly.png">
      <img src="https://emacssurvey.org/2020/what-emacs-community-forums-have-you-visited-in-the-past-year.png"></p><!-- <p>What are some of the Emacs improvements you are the most interested in?</p>
           <p>What do you think are Emacs' greatest strengths?</p>
           <p>Can you recall any difficulties you faced initially learning Emacs?</p>
           <p>What is the one thing you would like Emacs to do differently?</p> -->
      <p><img src="https://emacssurvey.org/2020/how-did-you-hear-about-this-survey.png"></p><!-- <p>If there is another survey in 2021, would you be opposed to it containing optional & general demographics questions?</p>
           <p>Do you have a preferred platform for filling out the survey in the future?</p>
           <p>Do you have general feedback about the survey process?</p> -->
    </div></div>]]>
            </description>
            <link>https://emacssurvey.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354551</guid>
            <pubDate>Wed, 09 Dec 2020 02:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starlink offers fast internet connections to rural Canadians. But it's not cheap]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25354122">thread link</a>) | @rhschan
<br/>
December 8, 2020 | https://www.cbc.ca/news/technology/starlink-internet-beta-testing-in-canada-1.5831765 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/starlink-internet-beta-testing-in-canada-1.5831765">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The new high-speed internet service from Elon Musk's SpaceX firm recently approved by the CRTC does have drawbacks, including its price tag and the potential impact its satellites will have on stargazing. But it's offering hope to users in rural areas who've long struggled to get high-speed connections.</p><div><p><span><span><div><div title="SpaceX satellite internet Starlink being tested in remote areas of Canada" role="button" tabindex="0"><div><div aria-labelledby="1827994179791-metadata-" title="SpaceX satellite internet Starlink being tested in remote areas of Canada"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/464/103/STARLINK-INTERNET-DAIGLE-041220.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Elon Musk's new satellite internet service is being tested by some Canadians in rural and remote parts of the country. It's supposed to give them a good quality, high-speed internet connection, but it's not cheap and some say the low-orbit Starlink satellites are ruining their view of the night sky.<!-- --> <!-- -->2:06</span></span></span></p><p><span><p>When Vernon Kejick got a first taste of Starlink satellite internet on the Pikangikum First Nation, his initial review was succinct.</p>  <p>"All I can say is it's a lot faster than what I had before," he said. Kejick's response highlights a long-running disparity that may finally have met a resolution.</p>  <p>Starlink, the new high-speed internet service provided by Elon Musk's U.S.-based SpaceX firm, and recently <a href="https://www.cbc.ca/news/canada/new-brunswick/elon-musk-tesla-starlink-low-earth-orbit-high-speed-rural-internet-rockets-satellite-1.5768338"><u>approved</u></a> by the CRTC, does have drawbacks. It's expensive. And stargazers fear it will ruin the night sky.</p>  <p>But for users in rural and remote areas who've long struggled to obtain internet access on equal footing with Canadians in urban areas, Starlink is offering hope. The service was recently made available to select users for "beta testing," with the promise of wider availability in 2021.&nbsp;</p>  <p>In Pikangikum, a fly-in community of 2,800 residents in northwest Ontario, Kejick said he'd become accustomed to download speeds of only 2 megabits per second —&nbsp;a fraction of the 50 megabits per the second the federal government considers a standard minimum for broadband.</p>    <p>At work, Kejick couldn't open large email attachments. He described the service as "deplorable."</p>  <p>At the end of November, Pikangikum became the first Indigenous community to get connected to Starlink, with 60 dishes reserved for homes and businesses in the community in the initial phase of installation, and potentially another 40 by the end of December.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/tesla-musk-germany.JPG 300w,https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/tesla-musk-germany.JPG 460w,https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/tesla-musk-germany.JPG 620w,https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tesla-musk-germany.JPG 780w,https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/tesla-musk-germany.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tesla-musk-germany.JPG"></p></div><figcaption>Elon Musk's SpaceX firm has promised Starlink internet will provide 'near global coverage of the populated world' in 2021.<!-- --> <!-- -->(Hannibal Hanschke/Pool via REUTERS)</figcaption></figure></span></p>  <p>Now, Kejick said his devices have been reaching 144 megabits per second. Not only can he quickly download attachments, Kejick said his wife has finally been able to chat with relatives in the Philippines over FaceTime.&nbsp;</p>  <p>"It's as if you're sitting in the same room," he said.</p>  <p>In Pikangikum, however, Starlink could offer more fundamental changes. Kejick, a victim services advocate with the Ontario Ministry of the Attorney General, said he hopes victims of crime will&nbsp;now be able to testify virtually, lessening the burden on them.</p>  <p>Members of the remote Ojibwe community hope the faster internet will remove barriers to access virtual healthcare services and education, too.</p>    <p>"It's doing everything that people are asking it to do," said David Brown, CEO of FSET Information Technology in Kenora, Ont. His firm had been working with Pikangikum for several years to try to improve their connectivity.&nbsp;</p>  <p>When he heard about Starlink, Brown jokingly promised his staff he would directly contact SpaceX's Musk —&nbsp;who recently surpassed Microsoft founder Bill Gates as one of the world's richest people, second only to Amazon CEO Jeff Bezos.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/spacex-starlink.jpg 300w,https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/spacex-starlink.jpg 460w,https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/spacex-starlink.jpg 620w,https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spacex-starlink.jpg 780w,https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/spacex-starlink.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spacex-starlink.jpg"></p></div><figcaption>A SpaceX craft launches a cluster of 60 Starlink satellites. The company was founded by Tesla carmaker Elon Musk. More than 800 Starlink satellites are in low Earth orbit. <!-- --> <!-- -->(SpaceX, Twitter)</figcaption></figure></span></p>  <p>Brown didn't reach Musk, but he did secure dozens of dishes for Pikangikum. FSET recently helped install the first batch. And the result, Brown said, was better than he expected.</p>  <p>Starlink is "a wonderful thing," he said. "It's going to change the world for people."</p>  <h2>Rural, remote areas lack broadband</h2>  <p>Across Canada, only 40.8 per cent of rural communities have access to adequate broadband, according to federal <a href="https://crtc.gc.ca/eng/internet/internet.htm"><u>data</u></a>.</p>  <p>Greg Rekounas, a database administrator who has long worked from home, said he contacted various service providers and could never find suitable broadband for his house on New Brunswick's Kingston Peninsula, near Saint John.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/greg-rekounas.jpg 300w,https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/greg-rekounas.jpg 460w,https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/greg-rekounas.jpg 620w,https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/greg-rekounas.jpg 780w,https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/greg-rekounas.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/greg-rekounas.jpg"></p></div><figcaption>Greg Rekounas tests download and upload speeds via his newly installed link to Starlink low earth orbit satellites. <!-- --> <!-- -->(Greg Rekounas, submitted)</figcaption></figure></span></p>  <p>The quality of his home connection suffered under the strain of increased streaming and surfing during the pandemic. So when he heard about Starlink, he signed up in November to become one of the company's Canadian beta testers. Rekounas received an email saying he'd been selected, and received the installation kit within days.</p>  <p>"I've been waiting for something like this for a long time," he said. There have been some hiccups with certain streaming apps, but Rekounas said "in general, it's been fantastic."</p>  <p>SpaceX said&nbsp;there are bound to be interruptions while its service is in beta testing, which it describes as "Better Than Nothing Beta."</p>  <p>Not everyone who registers to become a tester is selected to take part. SpaceX did not respond to emailed questions about the number of Canadians testing its service, or when exactly the firm expects to make Starlink available to the general public.</p>  <p>The cost alone is bound to turn off some consumers. Delores Waye of Taymouth, N.B., north of Fredericton, recently received an invitation from Starlink after her son had made the request. She was interested in signing up, until Waye saw the price at the bottom of the email.</p>  <p><em><strong>WATCH |&nbsp;Starlink satellites spotted over New Brunswick:</strong></em></p>  <p><span><span><div><div title="Starlink satellites spotted over New Brunswick" role="button" tabindex="0"><div><div aria-labelledby="1828820035953-metadata-" title="Starlink satellites spotted over New Brunswick"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/227/715/1-STARLINK-OVER-FREDERICTON.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Michael Stemm captured low orbit SpaceX Starlink satellites over Fredericton on the evening of June 4, 2020.<!-- --> <!-- -->0:51</span></span></span></p>  <p>Buying the dish and other gear needed for the Starlink service costs $649, plus tax. Rekounas said he paid $820 in total. Users are expected to install the kit themselves. Then, it's $129 per month for the service.</p>  <p>"I was floored," Waye&nbsp;said. "When you're doing beta testing, you would expect the company to at least provide you with the equipment. It just seems crazy."</p>  <h2>Trouble above</h2>  <p>There's also another kind of cost to consider: the lasting impact of thousands of low Earth orbit satellites sent into the sky. Starlink satellites orbit the Earth at an altitude of 550 kilometres. That's thousands of kilometres lower than conventional satellites — reducing&nbsp;the distance the signal must travel.&nbsp;</p>  <p>SpaceX has been launching up to 60 satellites at a time, with hundreds already in orbit. The firm <a href="https://www.forbes.com/sites/johnkoetsier/2020/01/09/elon-musks-42000-starlink-satellites-could-just-save-the-world/?sh=1cd601f94c2c"><u>reportedly</u></a> plans to launch as many as 42,000 in total.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/spacex-launch.jpg 300w,https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/spacex-launch.jpg 460w,https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/spacex-launch.jpg 620w,https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spacex-launch.jpg 780w,https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/spacex-launch.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spacex-launch.jpg"></p></div><figcaption>The SpaceX Falcon 9 rocket carrying Starlink satellites launched Oct. 6, from the Kennedy Space Center in Florida. <!-- --> <!-- -->(Tim Shortt/Florida Today via AP)</figcaption></figure></span></p>  <p>Stargazers such as University of Regina astronomy professor Samantha Lawler <a href="https://theconversation.com/spacexs-starlink-satellites-are-about-to-ruin-stargazing-for-everyone-149516"><u>anticipate</u></a> a visible impact. "It's going to dramatically change the way the night sky looks for everyone in the world," she said in an interview.</p>  <p>Canadians have already been reporting sightings of the bright Starlink satellites at night, in a distinct train-like formation.&nbsp;</p>  <p>Earlier this year, SpaceX <a href="https://www.spacex.com/updates/starlink-update-04-28-2020/"><u>committed</u></a> to making changes so their satellites wouldn't be so visible. The company pledged to add a visor to each satellite as a way to prevent the sun's reflection.</p>  <p><em><strong>LISTEN&nbsp;|&nbsp;Why the race to deliver better internet service has many astronomers concerned:</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Astronomers are worried about plans for thousands of new satellites"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/926/743/Generic_CBC_Radio_One_640.jpg" alt=""></p><p><span>Columnists from CBC Radio</span><span>3:55</span><span>Astronomers are worried about plans for thousands of new satellites</span></p></div></div></div><span>The space just beyond our planet is quickly becoming more crowded thanks to Elon Musk and his Starlink satellite project. CBC's Blair Sanderson explores why the race to deliver better internet service has many astronomers concerned.<!-- --> <!-- -->3:55</span></span></span></p>  <p>Amazon is planning its own low Earth orbit satellite constellation, too. And Canadian firm Telesat signed an agreement with the federal government to provide high-speed internet with a new low orbit fleet of its own.&nbsp;</p>  <p>Lawler said the satellites will be brightest in places such as Regina, Saskatoon, Calgary and Vancouver. "We're at pretty much the worst latitude for it," she warned.</p>  <p>"For a couple of hours after sunset and a couple of hours before sunrise… you will see more satellites in the sky than stars."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/elon-musk.jpg 300w,https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/elon-musk.jpg 460w,https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/elon-musk.jpg 620w,https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/elon-musk.jpg 780w,https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/elon-musk.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/elon-musk.jpg"></p></div><figcaption>Musk has become one of the richest people on Earth.<!-- --> <!-- -->(Frederic J. Brown/AFP via Getty Images)</figcaption></figure></span></p>  <p>Ottawa recently <a href="https://www.cbc.ca/news/politics/broadband-internet-1.5794901"><u>announced</u></a> plans to ensure 98 per cent of Canadians are connected to high-speed internet by 2026. The announcement included $150 million in funding for quick-turnaround projects to connect more households by next fall.</p>  <p>A government spokesperson&nbsp;told CBC News that Starlink projects aren't excluded from the plans&nbsp;and Canadians may apply for <a href="https://www.ic.gc.ca/eic/site/139.nsf/eng/h_00012.html"><u>funding</u></a> if certain criteria are met.</p>  <p>Rekounas in New Brunswick said he's heard from about five other local&nbsp;residents who received a link to take part in the beta testing. He expects many more will follow once the service is more widely available.</p>  <p>"Everybody's very excited," he said. "It's a game changer."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/starlink-internet-beta-testing-in-canada-1.5831765</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354122</guid>
            <pubDate>Wed, 09 Dec 2020 01:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Process a Moat in SaaS?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25353607">thread link</a>) | @Peteris
<br/>
December 8, 2020 | https://www.peteriserins.com/is-process-a-moat-in-saas/ | <a href="https://web.archive.org/web/*/https://www.peteriserins.com/is-process-a-moat-in-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>In <a href="https://www.saastr.com/whats-your-moat/">What's Your Moat</a>, Jason Lemkin lists several moats (sources of defensibility) that apply to SaaS businesses. I categorised them based on the <a href="https://www.amazon.com/7-Powers-Foundations-Business-Strategy-ebook/dp/B01MRLFFQ7">7 Powers</a> framework by Hamilton Helmer and found two powers missing (Cornered Resource and Process Power).</p><p>While Cornered Resources (such as a strong early team) are commonly considered doctrine rather than a moat, the omission of process power was more interesting.</p><h3 id="what-is-process-power">What is Process Power?</h3><p>Helmer describes companies with Process Power as follows:</p><blockquote>Benefit. A company with Process Power is able to improve product attributes and/or lower costs as a result of process improvements embedded within the organization. For example, Toyota has maintained the quality increases and cost reductions of the TPS over a span of decades; these assets do not disappear as new workers are brought in and older workers retire.<p>Barrier. The Barrier in Process Power is hysteresis: these process advances are difficult to replicate, and can only be achieved over a long time period of sustained evolutionary advance.</p></blockquote><p>He admits that process power is rare and difficult to achieve. But is it too rare to apply to SaaS companies?</p><p>On one hand, the path to growing a SaaS business is <a href="https://stripe.com/gb/atlas/guides/business-of-saas">well benchmarked</a> and there are processes describing anything from finding leads to deploying reliable infrastructure.</p><p>But there are companies that get very different results.</p><h3 id="the-process-outliers">The process outliers</h3><p><a href="https://ahrefs.com/">Ahrefs</a> is a popular SEO tool with a fifth of the engineering resources of their biggest competitor Moz. They <a href="https://ahrefs.com/blog/keywords-explorer-3-0/">claim to achieve this by using an OCaml based stack</a> also favoured by Wall Street traders <a href="https://www.janestreet.com/">Jane Street</a>.</p><p><a href="https://www.tinycapital.com/">Tiny</a> is a start-up conglomerate that uses several ideas like simple positioning and No Code to quickly spin up new businesses in record speed. They also run one of the leading design and development studios <a href="https://www.metalab.com/">Metalab</a>, and one of the earliest No Code agencies <a href="https://www.8020.inc/">8020</a>, ensuring excellence in both areas.</p><p>Does this mean that every SaaS company should use OCaml and Webflow or is there a way to create process advantages organically?</p><p>In an industry that speeds things up traditionally with investment, we have ignored frameworks that build process advantages in a capital-agnostic way.</p><h3 id="improving-process">Improving process</h3><p>I'll offer three examples.</p><p>The first is the Theory of Constraints, a framework introduced in <a href="https://www.amazon.co.uk/Goal-Process-Ongoing-Improvement/dp/0566086654">The Goal</a>. The Theory of Constraints predicts that every company is usually constrained by one bottleneck at a time, called a “constraint” and releasing that constraint is the key for increasing output.</p><p>Another theory, promoted by Douglas Engelbart is the <a href="https://www.dougengelbart.org/content/view/192/165/">ABCs of Organizational Improvement</a>. Engelbart argues that we should manage not only core activities (also known as “A activities” or “Business as usual”) but have explicit roadmaps for both B activities (“improving how we do A”) and C activities (“improving how we improve”). By focusing on process improvement explicitly, we can create compounding leverage for core activities.</p><p>A more modern example of continuous process improvement is described in the <a href="https://medium.com/quantumblack/the-protocol-series-how-formula-1-pitstop-teams-inspired-the-codification-of-our-ways-of-working-7b59b40a8fa1">Protocol Series</a> by QuantumBlack.</p><p>To summarise, having a great process is not the same as having great execution and we should not neglect that, even in SaaS.</p><hr><p><strong>P.S.</strong> Here is the categorization of the SaaS moats I went with. The high-level categories are from 7 Powers, the bullets are from Lemkin.</p><p>Counter-positioning</p><ul><li>“No Contract at all” easy on-boarding</li></ul><p>Network effects</p><ul><li>Data</li><li>Structured Data</li><li>Partners + Ecosystem</li><li>Agencies and Implementation Partners</li></ul><p>Switching costs</p><ul><li>Integrations</li><li>“Most Enterprise” Vendor</li><li>Long Term Contracts</li></ul><p>Economies of scale</p><ul><li>Using massive amounts of capital to play in every segment</li></ul><p>Brand</p><ul><li>Brand</li></ul><p>Cornered resource</p><ul><li>???</li></ul><p>Process power</p><ul><li>???</li></ul>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.peteriserins.com/is-process-a-moat-in-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353607</guid>
            <pubDate>Wed, 09 Dec 2020 00:22:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kite Power for Mauritius]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25353559">thread link</a>) | @usrusr
<br/>
December 8, 2020 | https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius | <a href="https://web.archive.org/web/*/https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353559</guid>
            <pubDate>Wed, 09 Dec 2020 00:16:37 GMT</pubDate>
        </item>
    </channel>
</rss>
