<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 30 Dec 2020 08:46:27 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 30 Dec 2020 08:46:27 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[We successfully pivoted a SaaS business to open-source MLOps tooling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558076">thread link</a>) | @benkoller
<br/>
December 28, 2020 | https://blog.maiot.io/a-most-unusual-year/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/a-most-unusual-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>As this is the end of the year, itâ€™s a great chance to remind yourself: how did we get here?</p>

<p>Let me beginn with a flashback to 2019. As a company, weâ€™re focussed on optimising remaining useful live of industrial assets through clever use of Machine Learning for predictive analysis, root-cause analysis and other forms of reasoning. We managed to secure a few big projects and very promising POCs, and across the board we were able to show good results. One of our projects even got government funding, providing a nice runway going forward.</p>

<p>We got the traditionally lengthy sales cycles with many leading industry players started, and we even hired our first full-time employee.</p>

<p>All was set up for first commercial success of our approach and our â€œasset optimisation platformâ€� in 2020.</p>

<p>Then the pandemic hit. Within a few weeks, all our sales leads fizzled away - millions of euros in deal sizes, disappeared in thin air. By March, we were looking at an empty sales funnel.</p>

<p>We had find a new path. We took stock, and we acted entrepreneurial.</p>

<h2 id="a-look-at-what-weve-got">A look at what weâ€™ve got</h2>

<p>Taking stock of what we actually had, in terms of intellectual property, was a great recap of our journey so far <a href="https://www.youtube.com/watch?v=UDfxoKmc8qc">(if youâ€™re interested, check out a talk I recently gave on what we learned about ML pipelines)</a>. To summarise, we had to our name:</p>

<ul>
  <li>A great team (experienced ML engineers, Ops expertise and a good entrepreneurial fit)</li>
  <li>A purpose-built tech stack for reproducible ML pipelines</li>
  <li>Experience running small and large projects</li>
  <li>A good network of other startups and developers in ML-related positions across the globe</li>
</ul>

<h2 id="talking-to-people">Talking to people</h2>

<p>We saw the economic effects of the pandemic very early - at least from an european perspective. After taking close stock, we had to understand how (and if) Machine Learning would continue to play a role for our leads and network. Taking a page out of the great UX researchers Iâ€™ve had the chance to work with over my career, we decided to do user interviews. Lo and behold, after doing ~30 early interviews, a picture emerged.</p>

<p>Teams engaged in ML projects lost significant chunks of time on unrepeatable projects as well as managing dysfunctional franken-infrastructures. Teams not yet engaged in ML feared it to be a black hole for time and effort to build up a reliable tech stack for getting experiments into production, as existing systems would need integration at many stages of the ML lifecycle.</p>

<p>An interesting side-fact became clear to us, too: there was a lot of scepticism towards ML-based SaaS products, but a lot of trust towards dev-tooling.</p>

<p>More importantly, however - we had solved exactly the problems our interviewees faced for ourselves. We were sitting on something commercially relevant, and we were looking at a great opportunity.</p>

<h2 id="understanding-your-market-part-one">Understanding your market, part one</h2>

<p>With this new-found confirmation we set out to transform our tech-stack from internal-facing supportive tooling to an actual product. Looking at the market, a split was noticeable.</p>

<p>On the one side, open-source tooling like Kubeflow and MLFlow was solving aspects of the MLOps problem space, but posed significant investments to the teams we were talking to in our interviews. Tooling was either missing the point of Data Scientists, or alienated product leads and DevOps teams with convoluted, messy or badly documented paths from experiment to production.</p>

<p>On the other side were very expensive commercial solutions, attempting to solve large chunks of the ML lifecycle with proprietary offerings.</p>

<h2 id="commercial-first">Commercial-first</h2>

<p>Given the layout of the MLOps market, we spotted an opportunity to flip the proverbial table. Donâ€™t get me wrong, weâ€™re not radical geniuses, we much rather are interested observers of entrepreneurial trends. Given the success of Stripe, Segment and others, this constellation of players screamed â€œtransactional business modelâ€� to us. A managed MLOps platform to train models easily in various public clouds, at linearly scaling prices, based on actual usage, not arbitrary license models or per-seat, and at a fraction of the going rates.</p>

<h2 id="understanding-the-market-part-two">Understanding the market, part two</h2>

<p>By now we know: Our hypothesis, teams are just waiting for a managed MLOps solution with usage-based pricing and reproducible pipelines as focus, was off. This was not immediately clear to us, of course.</p>

<p>One of our smartest plays saved us in the end - we never stopped doing user interviews. We demoâ€™ed our product status quo multiple times per week, we had two soft-launches and continuously engaged with the community on conferences, reddit, slack - you name it.</p>

<p>And people loved our take on MLOps. Our vision resonated deeply. All model trainings are guaranteed to be reproducible, tracking is deeply baked-in, integrations to popular tooling are easy and extensible - these are the key concerns of the teams we were talking to.</p>

<p>However, it would have been ludicrous to switch their tech-stacks to a commercial solution. No, if we wanted to drive adoption and actually have an impact on how the world dealt with MLOps, we had to give these teams the option to adopt our vision in their projects on their own terms. We had to open-source.</p>

<p>As Iâ€™ve written in the past, <a href="http://blog.maiot.io/open-source">we are huge proponents of open-source software</a>. Large parts of our own tooling would be possible without the work of open-source giants, on whose shoulders we can stand.</p>

<h2 id="the-jury-is-still-out">The jury is still out</h2>

<p>As of writing this, the jury is still out if weâ€™re leaving the dent in the universe that we want to leave behind. But, and this is a hugely rewarding feeling, we have all the right indications that we nailed it this time. Weâ€™ve breached 200 GitHub stars in less than a week of going public, weâ€™ve been on the front page of Hackernews, weâ€™ve been trending on GitHub, and ZenML is racing to 1000 <code>pip install</code>â€™s.</p>

<p>If youâ€™re running ML projects, or just personally got curious, head over to <a href="https://github.com/maiot-io/zenml">ZenMLâ€™s GitHub page</a> and get started with reproducible Machine Learning!</p>

    </div>
</section></div>]]>
            </description>
            <link>https://blog.maiot.io/a-most-unusual-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558076</guid>
            <pubDate>Mon, 28 Dec 2020 10:17:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Celestial Navigation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557669">thread link</a>) | @blewboarwastake
<br/>
December 28, 2020 | http://www.siranah.de/html/sail040a.htm | <a href="https://web.archive.org/web/*/http://www.siranah.de/html/sail040a.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.siranah.de/html/sail040a.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557669</guid>
            <pubDate>Mon, 28 Dec 2020 08:33:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learning is going real-time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557412">thread link</a>) | @yoquan
<br/>
December 27, 2020 | https://huyenchip.com/2020/12/27/real-time-machine-learning.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/12/27/real-time-machine-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>After talking to machine learning and infrastructure engineers at major Internet companies across the US, Europe, and China, I noticed two groups of companies. One group has made significant investments (hundreds of millions of dollars) into infrastructure to allow real-time machine learning and has already seen returns on their investments. Another group still wonders if there’s value in real-time ML.</p>

<p>There seems to be little consensus on what real-time ML means, and there hasn’t been a lot of in-depth discussion on how it’s done in the industry. In this post, I want to share what I’ve learned after talking to about a dozen companies that are doing it.</p>

<p>There are two levels of real-time machine learning that I’ll go over in this post.</p>
<ul>
  <li>Level 1: Your ML system makes predictions in real-time (online predictions).</li>
  <li>Level 2: Your system can incorporate new data and update your model in real-time (online learning).</li>
</ul>

<p>I use “model” to refer to the machine learning model and “system” to refer to the infrastructure around it, including data pipeline and monitoring systems.</p>

<hr>
<p><b>Table of contents</b><br>
…. <a href="#online_predictions">Level 1: Online predictions - your system can make predictions in real-time</a><br>
…….. <a href="#online_predictions_use_cases">Use cases</a><br>
………… <a href="#problems_batch_predictions">Problems with batch predictions</a><br>
…….. <a href="#online_predictions_solutions">Solutions</a><br>
………… <a href="#fast_inference">Fast inference</a><br>
………… <a href="#stream_pipeline">Real-time pipeline</a><br>
……………. <a href="#stream_processing_vs_batch_processing">Stream processing vs. batch processing</a><br>
……………. <a href="#event_driven_vs_request_driven">Event-driven vs. request-driven</a><br>
…….. <a href="#online_predictions_challenges">Challenges</a><br>
…. <a href="#online_learning">Level 2: Online learning - your system can incorporate new data and update in real-time</a><br>
…….. <a href="#online_learning_definition">Defining “online learning”</a><br>
…….. <a href="#online_learning_use_cases">Use case</a><br>
…….. <a href="#online_learning_solutions">Solutions</a><br>
…….. <a href="#online_learning_challenges">Challenges</a><br>
………… <a href="#online_learning_theoretical_challenges">Theoretical</a><br>
………… <a href="#online_learning_practical_challenges">Practical</a><br>
…. <a href="#mlops_china_vs_us">The MLOps race between the US and China</a><br>
…. <a href="#conclusion">Conclusion</a><br></p>

<hr>

<h2 id="online_predictions">Level 1: Online predictions - your system can make predictions in real-time</h2>
<p><em><b>Real-time</b> here is defined to be in the order of milliseconds to seconds.</em></p>

<h3 id="online_predictions_use_cases">Use cases</h3>
<p>Latency matters, especially for user-facing applications. In 2009, Google’s experiments demonstrated that <a href="https://services.google.com/fh/files/blogs/google_delayexp.pdf">increasing web search latency 100 to 400 ms reduces the daily number of searches per user by 0.2% to 0.6%</a>. In 2019, <a href="https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/">Booking.com found that an increase of 30% in latency cost about 0.5% in conversion rates — “a relevant cost for our business.”</a></p>

<p>No matter how great your ML models are, if they take just milliseconds too long to make predictions, users are going to click on something else.</p>

<h4 id="problems_batch_predictions">Problems with batch predictions</h4>
<p>One non-solution is to avoid making predictions online. You can generate predictions in batch offline, store them (e.g. in SQL tables), and pull out pre-computed predictions when needed.</p>

<p>This can work when the input space is finite – you know exactly how many possible inputs to make predictions for. One example is when you need to generate movie recommendations for your users – you know exactly how many users there are. So you predict a set of recommendations for each user periodically, such as every few hours.</p>

<p>To make their user input space finite, many apps make their users choose from categories instead of entering wild queries. For example, if you go to TripAdvisor, you first have to pick a predefined metropolis area instead of being able to enter just any location.</p>

<p>This approach has many limitations. TripAdvisor results are okay within their predefined categories, such as <b>“Restaurants”</b> in <b>“San Francisco”</b>, but are pretty bad when you try to enter wild queries like <b>“high rating Thai restaurants in Hayes Valley”</b>.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/1_tripadvisor.png">
</figure>
</center>

<p>Limitations caused by batch predictions exist even in more technologically progressive companies like Netflix. Say, you’ve been watching a lot of horrors lately, so when you first log into Netflix, horror movies dominate recommendations. But you’re feeling bright today so you search “comedy” and start browsing the comedy category. Netflix should learn and show you more comedy in your list of their recommendations, right? But it can’t update the list until the next time batch recommendations are generated.</p>

<p>In the two examples above, batch predictions lead to decreases in user experience (which is tightly coupled with user engagement/retention), not catastrophic failures. Other examples are ad ranking, Twitter’s trending hashtag ranking, Facebook’s newsfeed ranking, estimating time of arrival, etc.</p>

<p>There are also many applications that, without online predictions, would lead to catastrophic failures or just wouldn’t work. Examples include high frequency trading, autonomous vehicles, voice assistants, unlocking your phones using face/fingerprints, fall detection for elderly care, fraud detection, etc. Being able to detect a fraudulent transaction that happened 3 hours ago is still better than not detecting it at all, but being able to detect it in real-time can prevent it from going through.</p>

<p>Switching from batch predictions to real-time predictions allows you to use dynamic features to make more relevant predictions. Static features are information that changes slowly or rarely – age, gender, job, neighborhood, etc. Dynamic features are features based on what’s happening right now – what you’re watching, what you’ve just liked, etc. Knowing a user’s interests right now will allow your systems to make recommendations much more relevant to them.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/2_google.png">
</figure>
</center>

<h3 id="online_predictions_solutions">Solutions</h3>
<p>For your system to be able to make online predictions, it has to have two components:</p>

<ol>
  <li>Fast inference: model that can make predictions in the order of milliseconds</li>
  <li>Real-time pipeline: a pipeline that can process data, input it into model, and return a prediction in real-time</li>
</ol>

<h4 id="fast_inference">Fast inference</h4>
<p>When a model is too big and taking too long to make predictions, there are three approaches:</p>

<p><b>1. Make models faster (inference optimization)</b></p>

<p>E.g. fusing operations, distributing computations, memory footprint optimization, writing high performance kernels targeting specific hardwares, etc.</p>

<p><b>2. Make models smaller (model compression)</b></p>

<p>Originally, this family of technique is to make models smaller to make them fit on edge devices. Making models smaller often makes them run faster. The most common, general technique for model compression is quantization, e.g. using 16-bit floats (half precision) or 8-bit integers (fixed-point) instead of 32-bit floats (full precision) to represent your model weights. In the extreme case, some have attempted 1-bit representation (binary weight neural networks), e.g. <a href="https://arxiv.org/abs/1511.00363">BinaryConnect</a> and <a href="https://arxiv.org/abs/1603.05279">Xnor-Net</a>. The authors of Xnor-Net spun off Xnor.ai, a startup focused on model compression which was <a href="https://www.geekwire.com/2020/exclusive-apple-acquires-xnor-ai-edge-ai-spin-paul-allens-ai2-price-200m-range/">acquired by Apple for a reported $200M</a>.</p>

<p>Another popular technique is <a href="https://arxiv.org/abs/1503.02531">knowledge distillation</a> – a small model (student) is trained to mimic a larger model or an ensemble of models (teacher). Even though the student is often trained with a pre-trained teacher, both may also be trained at the same time. One example of a distilled network used in production is <a href="https://arxiv.org/abs/1910.01108"><strong>DistilBERT</strong></a>, which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster.</p>

<p>Other techniques include pruning (finding parameters least useful to predictions and setting them to 0) and low-rank factorization (replacing the over-parametric convolution filters with compact blocks to both reduce the number of parameters and increase speed). See <strong><a href="https://arxiv.org/abs/1710.09282">A Survey of Model Compression and Acceleration for Deep Neural Networks</a></strong> (Cheng et al.. 2017) for a detailed analysis.</p>

<p>The number of research papers on model compression is growing. Off-the-shelf utilities are proliferating. Awesome Open Source has a list of <a href="https://awesomeopensource.com/projects/model-compression"><strong>The Top 40 Model Compression Open Source Projects</strong></a>.</p>

<p><b>3. Make hardware faster</b></p>

<p>This is another research area that is booming. Big companies and startups alike are in a race to develop hardware that allows large ML models to do inference, even training, faster both on the cloud and especially on devices. IDC forecasts that by 2020, the combination of edge and mobile devices doing inferencing will <a href="https://www.arm.com/-/media/global/solutions/artificial-intelligence/ai-ml-on-cpu-whitepaper.pdf?revision=17a2b30b-0f5a-4a42-8681-3d9f3f94e513">total 3.7 billion units, with a further 116 million units doing training</a>.</p>

<h4 id="stream_pipeline">Real-time pipeline</h4>
<p>Suppose you have a ride sharing app and want to detect fraudulent transactions e.g. payments using stolen credit cards. When the true credit owner discovers unauthorized payments, they’ll dispute with their bank and you’ll have to refund the charges. To maximize profits, fraudsters might call multiple rides either in succession or from multiple accounts. In 2019, merchants estimate fraudulent transactions account for an average of <a href="https://network.americanexpress.com/globalnetwork/dam/jcr:09c34553-b4a2-43ca-bf3e-47cbc911ea51/American%20Express%202019%20Digital%20Payments%20Survey_Insights%20Paper.pdf">27% of their annual online sales</a>. The longer it takes for you to detect the stolen credit card, the more money you’ll lose.</p>

<p>To detect whether a transaction is fraudulent, looking at that transaction alone isn’t enough. You need to at least look into the recent history of the user involved in that transaction, their recent trips and activities in-app, the credit card’s recent transactions, and other transactions happening around the same time.</p>

<p>To quickly access these types of information, you want to keep as much of them in-memory as possible. Every time an event you care about happens – a user choosing a location, booking a trip, contacting a driver, canceling a trip, adding a credit card, removing a credit card, etc. – information about that event goes into your in-memory storage. It stays there for as long as they are useful (usually in order of days) then either goes into permanent storage (e.g. S3) or is discarded. The most common tool for this is <a href="https://github.com/apache/kafka">Apache Kafka</a>, with alternatives such as Amazon Kinesis. Kafka is a stream storage: it stores data as it streams.</p>

<p>Streaming data is different from static data – data that already exists somewhere in its entirety, such as CSV files. When reading from CSV files, you know when the job is finished. Streams of data never finish.</p>

<p>Once you’ve had a way to manage streaming data, you want to extract features to input into your ML models. On top of features from streaming data, you might also need features from static data (when was this account created, what’s the user’s rating, etc.). You need a tool that allows you to process streaming data as well as static data and join …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2020/12/27/real-time-machine-learning.html">https://huyenchip.com/2020/12/27/real-time-machine-learning.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2020/12/27/real-time-machine-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557412</guid>
            <pubDate>Mon, 28 Dec 2020 07:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, Vertical Farms Won’t Feed the World]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557407">thread link</a>) | @hannob
<br/>
December 27, 2020 | https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0 | <a href="https://web.archive.org/web/*/https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/8574/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg" width="4287" height="1673" srcset="https://miro.medium.com/max/552/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 276w, https://miro.medium.com/max/1104/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 552w, https://miro.medium.com/max/1280/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 640w, https://miro.medium.com/max/1456/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 728w, https://miro.medium.com/max/1632/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 816w, https://miro.medium.com/max/1808/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 904w, https://miro.medium.com/max/1984/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 992w, https://miro.medium.com/max/2160/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1080w, https://miro.medium.com/max/2700/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1350w, https://miro.medium.com/max/3240/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1620w, https://miro.medium.com/max/3780/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1890w, https://miro.medium.com/max/4320/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 2160w, https://miro.medium.com/max/4800/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg?q=20"></p></div></div><figcaption>Lettuce grown in my garden. Photograph © 2016 Jonathan Foley.</figcaption></figure></div><div><div><h2 id="f47c">While they are well-intentioned, new indoor “farms” won’t help feed the world or reduce the environmental impacts of agriculture. We would be better to focus our efforts elsewhere.</h2><div><div><div><div><a href="https://globalecoguy.medium.com/?source=post_page-----5313e3e961c0--------------------------------" rel="noopener"><div><p><img alt="Jonathan Foley" src="https://miro.medium.com/fit/c/96/96/1*9wBAcVM1jqF9OWCjCOGiuA.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div></div></section><section><div><div><p id="bd54"><span>W</span>e’re beginning to see a new fad in agriculture — so-called “vertical farms” that grow food <em>indoors </em>with energy-intensive, artificial life support systems.</p><p id="498f">In the last few years, a number of tech companies have designed “farms” that utilize artificial lights, heaters, water pumps, and computer controls to grow crops inside. These systems glow with a fantastic magenta light — from LEDs that are specially tuned to provide optimal light for photosynthesis — often with stacked trays of plants, one on top of the other. Some of this technology is new, especially the LEDs, although pot growers have used tools like this for years.</p><p id="db29">Some of the more notable efforts to build indoor “farms” include <a href="http://www.freightfarms.com/" rel="noopener">Freight Farms</a> in Boston. And there is a group at MIT that is trying to create new high-tech platforms for growing food inside, including “<a href="http://openag.media.mit.edu/hardware/" rel="noopener">food computers</a>”. These folks are very smart, and have done a lot to perfect the technology.</p><p id="47bb">At first blush, these “farms” sound great. Why not <em>completely</em> eliminate food miles, and grow food right next to restaurants, cafeterias, or supermarkets? And why not grow crops inside closed systems, where water can be recycled, and pests can (in theory) be managed without chemicals.</p><p id="d5c4">It sounds great, doesn’t it? But there are many challenges.</p></div></div></section><section><div><div><p id="6ba8"><span>F</span><strong>irst, Vertical Farms Cost a Fortune</strong></p><p id="5f2b">But there are costs to these farms. <em>Huge</em> costs.</p><p id="f0bc">First, these systems are <em>really</em> expensive to build. The shipping container systems developed by <a href="http://www.freightfarms.com/faq/" rel="noopener">Freight Farms</a>, for example, cost between $82,000 and $85,000 <em>per container</em> — an astonishing sum for a box that just grows greens and herbs. Just one container costs as much as 10 entire acres of prime American farmland — which is a far better investment, both in terms of food production and future economic value. Just remember: farmland has the benefit of generally <em>appreciating</em> in <a href="http://www.forbes.com/sites/joshuarogers/2014/09/23/dirt-cheap-investors-are-plowing-into-farmland-heres-why" rel="noopener">value over time</a>, whereas a big metal box is likely to only decrease in value.</p><p id="24cf">Second, food produced this way is <em>very</em> expensive. For example, the Wall Street Journal <a href="http://www.wsj.com/articles/are-shipping-containers-the-future-of-farming-1465393797" rel="noopener">reports</a> that mini-lettuces grown by Green Line Growers costs more than <em>twice</em> as much as organic lettuce available in most stores. And this is typical for other indoor growers around the country: it’s very, very expensive, even compared to organic food. Instead of making food <em>more</em>available, especially to poorer families on limited budgets, these indoor crops are only available to the affluent. It might be fine for gourmet lettuce, or fancy greens for expensive restaurants, but regular folks may find it out of reach.</p><p id="e121">Finally, indoor farms use <em>a lot</em> of energy and materials to operate. The container farms from Freight Farms, for example, use about <a href="http://www.freightfarms.com/faq/" rel="noopener">80 kilowatt-hours of electricity a day</a> to power the lights and pumps. That’s nearly 2–3 times as much electricity as a typical (and still very inefficient) American home, or about 8 times the electricity used by an average San Francisco apartment. And on the average American electrical grid, this translates to emitting <em>44,000 pounds of CO2 per container per year</em>, from electricity alone, not counting any additional heating costs. This is <em>vastly</em> more than the emissions it would take to ship the food from someplace else.</p><p id="0e49">And none of it is necessary.</p></div></div></section><section><div><div><p id="1017"><span>B</span><strong>ut, Wait, Can’t Indoor Farms Use Renewable Energy?</strong></p><p id="5bbd">Proponents of indoor techno-farms often say that they can offset the enormous sums of electricity they use, by powering them with renewable energy — especially solar panels — to make the whole thing carbon neutral.</p><p id="5b5d">But just stop and think about this for a second.</p><p id="5f6a">These indoor “farms” would use solar panels to harvest naturally occurring sunlight, and convert it into electricity, so that they can power…<em>artificial sunlight</em>? In other words<em>, </em>they’re<em> trying to use the sun to replace the sun.</em></p><p id="0a0f">But we don’t need to replace the sun. Of all of the things we should worry about in agriculture, the availability of free sunlight is not one of them. Any system that seeks to replace the sun to grow food is probably a bad idea.</p></div></div></section><section><div><div><p id="e3d3"><span>B</span><strong>esides, “Food Miles” Aren’t a Big Climate Problem</strong></p><p id="29a5">Sometimes we hear that vertical farms help the environment by reducing “food miles” — the distance food items travel from farm to table — and thereby reduce fuel consumption and greenhouse gas emissions.</p><p id="0f7a">This sounds logical, but it turns out to be a red herring.</p><p id="c2ec">Strange as it might seem, local food typically uses about the same amount of energy — per pound — to transport as food grown far away. Why? Short answer: volume and method of transport. A larger food operator can ship food more efficiently — even if it travels longer distances — because of the gigantic volumes they work in. Plus, ships, trains, and even large trucks driving on Interstate highways use less fuel, per pound per mile, than small trucks driving around town.</p><p id="a654">Plus it turns out that “food miles” aren’t a very big source of CO2 emissions anyway, whether they’re local or not. In fact, they pale in comparison to emissions from deforestation, methane from cattle and rice fields, and nitrous oxide from over-fertilized fields. And local food systems — especially organic farms that use fewer fertilizers, and grass fed beef that sequesters carbon in the soil — can reduce these more critical emissions. At the end of the day, local food systems are generally better for the environment, including greenhouse gas emissions. Just don’t worry about emissions from food miles too much.</p></div></div></section><section><div><div><p id="6153"><span>A</span><strong>nd These Vertical “Farms” Can’t Grow Much</strong></p><p id="1ac1">A further problem with indoor farms is that a lot of crops could never develop properly in these artificial conditions. While LED lights provide the light needed for <em>photosynthesis</em> to occur, they don’t provide the proper mix of light and heat to trigger plant development stages — like those that tell plants when to put on fruit or seed. Moreover, a lot of crops need a bit of wind to develop tall, strong stalks, needed later when they are carrying heavy loads before harvest. As a result, indoor farms are severely limited, and have a hard time growing things besides simple greens.</p><p id="71b1">Indoor farms might be able to provide some <em>garnish</em> and <em>salads</em> to the world, but forget about them as a means of growing much other <em>food</em>.</p></div></div></section><section><div><div><p id="003c"><strong>A Better Way?</strong></p><p id="bf8f">I’m not the only critic of indoor, high-tech, energy-intensive agriculture. Other authors are starting to point out the problems with these systems too (read very good critiques <a href="http://www.salon.com/2016/02/17/enough_with_the_vertical_farming_partner/" rel="noopener">here</a>, <a href="http://www.counterpunch.org/2012/12/11/the-vertical-farming-scam/" rel="noopener">here</a>, <a href="https://www.theguardian.com/sustainable-business/2015/apr/10/indoor-farming-makes-no-economic-environmental-sense" rel="noopener">here</a>, and <a href="http://news.cornell.edu/stories/2014/02/indoor-urban-farms-called-wasteful-pie-sky" rel="noopener">here</a>).</p><p id="02f4">While I appreciate the enthusiasm and innovation put into developing indoor farms, I think these efforts are, at the end of the day, counterproductive.</p><p id="8dea">Instead, I think we should use the same investment of dollars, incredible technology, and amazing brains to solve other agricultural problems — like developing new methods for drip irrigation, better grazing systems that lock up soil carbon, and ways of recycling on-farm nutrients. Organic farming and high-precision agriculture are doing promising things, and need more help. We also need innovation and capital to help other parts of the food system, especially in tackling food waste, and getting people to shift their diets towards more sustainable directions.</p><p id="9534">An interconnected network of good farms —real farms that provide nutritious food, with social and environmental benefits to their communities — is the kind of innovation we really need.</p></div></div></section><section><div><p id="b135">NOTE: parts of this piece were adapted from an earlier blog article of mine called <em>“Local Food is Great, But Can It Go Too Far?”</em></p></div></section><section><div><div><p id="68aa"><em>Dr. </em><a href="http://globalecoguy.org/" rel="noopener"><em>Jonathan Foley</em></a><em> (@</em><a href="http://twitter.com/@globalecoguy" rel="noopener"><em>GlobalEcoGuy</em></a><em>) is a climate &amp; environmental scientist, writer, and speaker. He is also the Executive Director of </em><a href="http://drawdown.org/" rel="noopener"><em>Project Drawdown</em></a><em>, the world’s leading resource for climate solutions.</em></p><p id="10de"><em>These views are his own.</em></p><p id="db28">Copyright © 2015–2020, Jonathan Foley. All rights reserved.</p></div></div></section></div></div>]]>
            </description>
            <link>https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557407</guid>
            <pubDate>Mon, 28 Dec 2020 07:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’re Rebranding PrestoSQL as Trino]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557321">thread link</a>) | @addisonj
<br/>
December 27, 2020 | https://trino.io/blog/2020/12/27/announcing-trino.html | <a href="https://web.archive.org/web/*/https://trino.io/blog/2020/12/27/announcing-trino.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We’re rebranding PrestoSQL as Trino. The software and the community you have come to love and depend on aren’t 
going anywhere, we are simply renaming. <strong>Trino is the new name for PrestoSQL</strong>, the project supported by the founders 
and creators of Presto® along with the major contributors – just under a shiny new name. And now you can find us here:</p>

<ul>
  <li>GitHub: <a href="https://github.com/trinodb/trino">https://github.com/trinodb/trino</a>. Please give it a <a href="https://github.com/trinodb/trino/blob/master/.github/star.png">star</a>!</li>
  <li>Twitter: <a href="https://twitter.com/trinodb">@trinodb</a></li>
  <li>Slack: <a href="https://trino.io/slack.html">https://trino.io/slack.html</a></li>
</ul>

<p>If you want to learn why we’re doing this, read on…</p>

<!--more-->

<p>In 2012, Dain, David and Martin joined the Facebook data infrastructure team. Together with Eric Hwang, we created 
Presto® to address the problems of low latency interactive analytics over Facebook’s massive Hadoop data warehouse. 
One of our non-negotiable conditions was for Presto® to be an open source project. Open source is in our DNA - we had 
all used and participated in open source projects to various degrees in the past, and we recognized the power of open 
communities and developers coming together to build successful software that can stand the test of time.</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/team.jpg" alt=""></p>

<p>Over the next six years, we worked hard to build a healthy open source community and ecosystem around the project. We 
worked with developers and users all over the world and welcomed them into the Presto® community. Presto® was on a path 
of increasing growth and success, in large part because of the contributions from developers across many fields and all 
over the world.</p>

<p>Unfortunately in 2018, it became clear that Facebook management wanted to have tighter control over the project and its 
future. This culminated with their decision to grant Facebook developers commit rights on the project without any prior 
experience in Presto®. We strongly believe that this kind of decision is not compatible with having a healthy, open 
community. Moreover, they made this decision by fiat without engaging the Presto® community. As a matter of principle, 
we had no choice but to leave Facebook in order to focus on making sure Presto® continued to be a successful project 
with an open, collaborative and independent community. In reality, the choice was easy.</p>

<p>We started the Presto Software Foundation in January 2019 as an independent entity to oversee the development of the 
software and community, continuing the meritocratic system that had been in place over the previous 6 years. The community 
quickly consolidated under this new home. We intentionally stayed unemployed over the next 10 months to focus on expanding 
and strengthening the community by working directly with major users and contributors, as well as reaching out to a wider 
group of users and developers across the globe. This resulted in new use cases and an injection of energy, making the 
project more vibrant than ever before as even more new users and developers became engaged. But, don’t take our word for 
it, let the data speak for itself:</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/commits.png" alt=""></p>

<p>Months after this consolidation, Facebook decided to create a competing community using The Linux Foundation®. As a first 
action, Facebook applied for a trademark on Presto®. This was a surprising, norm-breaking move because up until that point, 
the Presto® name had been used without constraints by commercial and non-commercial products for over 6 years. In September 
of 2019, Facebook established the Presto Foundation at The Linux Foundation®, and immediately began working to enforce this 
new trademark. We spent the better part of the last year trying to agree to terms with Facebook and The Linux Foundation 
that would not negatively impact the community, but unfortunately we were unable to do so. The end result is that we must 
now change the name in a short period of time, with little ability to minimize user disruption.</p>

<p>On a personal note, and as the founders who named the project Presto® in the first place, this is an incredibly sad and 
disappointing turn of events. And while we will always have fondness for the name Presto®, we have come to accept that a 
name is just a name. To be frank, we’re tired of this endless distraction, and we intend to focus on what matters most 
and what we are best at doing – building high quality software everyone can rely on and fostering a healthy community 
of users and developers that build it and support it. We’re not going anywhere – we’re the same people, the same amazing 
software, under a new name: Trino.</p>

<p><strong>If you love this project, you already love Trino. ❤️</strong></p>


<p>Facebook is a registered trademark of Facebook Inc.  The Linux Foundation and Presto are trademarks of The Linux Foundation.</p>


  </div>

  
</article>

</div></div>]]>
            </description>
            <link>https://trino.io/blog/2020/12/27/announcing-trino.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557321</guid>
            <pubDate>Mon, 28 Dec 2020 06:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What the cyberoptimists got wrong – and what to do about it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557229">thread link</a>) | @pdkl95
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=doctorow">doctorow</a>

</p>


<!-- %h3 About -->
<p>They stole our future. Let's take it back.</p>

<p>Here at the end of the world, it's time to take stock. Is technology a force for good? Can it be? Was it ever? How did we end up with a world made up of "five websites, each filled with screenshots of text from the other four" (h/t Tom Eastman)? Should we worry that machine learning will take away our free will through A/B splitting and Big Five Personality Types? Where the fuck did all these Nazis come from? </p>

<h3>Download</h3>
<div>
<p>

Downloads will appear here, once final recordings are released.
</p></div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557229</guid>
            <pubDate>Mon, 28 Dec 2020 06:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HN Readers]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25556990">thread link</a>) | @lgats
<br/>
December 27, 2020 | https://blog.luke.lol/tech/15-hacker-news-alternatives/ | <a href="https://web.archive.org/web/*/https://blog.luke.lol/tech/15-hacker-news-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<h2>News.YCombinator.com Readers</h2>
<p>Ranked by Alexa popularity.</p>
<p><a href="https://hn.algolia.com/">hn.algolia.com</a><br>
HackerNews with a search function and 16.8+ million posts indexed.<br>
Alexa: 8.7k</p>
<p><a href="http://popurls.com/">popurls.com</a><br>
Several news sites combined into a single newspaper-like feed<br>
Alexa: 87k</p>
<p><a href="https://upstract.com/">upstract.com</a><br>
News aggregator with paid features, includes HN<br>
Alexa: 137k</p>
<p><a href="https://hckrnews.com/">hckrnews.com</a><br>
HN posts organized by rolling, quarter-daily timeslots.<br>
Alexa: 178k</p>
<p><a href="https://pxlet.com/">pxlet.com</a><br>
Culmination of HN, Reddit, SlashDot, and other Tech-News Sites<br>
Alexa: 330k</p>
<p><a href="https://hackernewsletter.com/">hackernewsletter.com</a><br>
HN delivered via email<br>
Alexa: 581k</p>
<p><a href="https://old.thenews.im/">thenews.im&nbsp;</a><br>
Designer News, Product Hunt and Hacker News Mashup with easy-access to individual feeds<br>
Alexa: 960k</p>
<p><a href="http://www.daemonology.net/hn-daily/">daemonology.net</a><br>
Daily list of the top HN posts.<br>
Alexa: 971k</p>
<p><a href="http://n-gate.com/%3En-gate.com%3C/a%3E%3Cbr%20/%3EA%20weekly%20[human?]%20annotated%20digest%20of%20the%20top%20%E2%80%9CHacker%E2%80%9D%20%E2%80%9CNews%E2%80%9D%20posts%3Cbr%20/%3EAlexa:%202.5m%3C/p%3E%3Cp%3E%3Ca%20href=" https:="" hn.premii.com"="">hn.premii.com</a><br>
HN Mirror integrated with an on-page reader<br>
Alexa: 3m</p>
<p><a href="http://hnrankings.info/">hnrankings.info</a><br>
HN Ranking Charts<br>
Alexa: 4m</p>
<p><a href="https://hnews.xyz/">hnews.xyz</a><br>
HN Mirror with Webpage Screenshots [similar to tiledhn.com (<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">RIP</a>)]<br>
Alexa: 5m</p>
<p><a href="https://hnsince.com/">hnsince.com</a><br>
Top HN posts since you last visited<br>
Alexa: 5.4m</p>
<p><a href="https://hackerweb.app/">hackerweb.app</a><br>
More mobile-friendly HN<br>
Alexa: 6.3m</p>
<p><a href="https://fullhn.com/">fullhn.com</a><br>
Front page of HN in a single page loaded with all articles. Great for loading up before you jump on a flight without wireless access.<br>
Alexa: 7m</p>
<p><a href="https://hackurls.com/">hackurls.com</a><br>
HN, proggit, reddit, toptal, hackaday, slashdot, techmeme, wired as separate feeds on a single page<br>
Alexa: 8.5m</p>
<p><a href="https://hackernewsmobile.com/">hackernewsmobile.com</a><br>
More mobile-friendly HN<br>
Alexa: 9.5m</p>
<p><a href="https://lopespm.github.io/hackernews-daily/">lopespm HN Daily</a><br>
HackerNews Daily – Culmination of top posts for the day<br>
Alexa: Unavailable</p>
<p><a href="https://www.wolfgangfaust.com/project/paper-hn/">wolfgangfaust HN Newspaper</a><br>
Newspaper themed HN<br>
Alexa: Unavailable</p>
<p><a href="https://thn.rakhim.org/">thn.rakhim.org</a><br>
30 random good HN posts from the past<br>
Alexa: Unavailable</p>
<p><a href="https://zvoid.org/hn">zvoid.org/hn</a><br>
Dark-themed HN reader<br>
Alexa: Unavailable</p>
<p><a href="https://hn.svelte.dev/">hn.svelte.dev</a><br>
mobile and dark mode friendly reader for HN<br>
Alexa: None</p>
<p><a href="https://hackernews.betacat.io/">hackernews.betacat.io</a><br>
Modern HN theme with website preview screenshots<br>
Alexa: None</p>
<p><a href="https://read.hn/">read.hn</a><br>
Another HN Reader view<br>
Alexa: None</p>
<p><a href="https://hnapp.com/">hnapp.com</a><br>
HN Advanced Search and monitoring tool<br>
Alexa: None</p>
<p><a href="http://hnpaper.forge.partlab.io/">hnpaper.forge.partlab.io</a><br>
HNPaper – bootstrap theme simple HN interface<br>
Alexa: Unavailable</p>
<p><a href="https://hack.ernews.info/">hack.ernews.info</a><br>
More mobile-friendly HN<br>
Alexa: None</p>
<p><a href="https://progscrape.com/">progscrape.com</a><br>
HN, Reddit, and Lobste.rs aggregated and merged into a single feed<br>
Alexa: None</p>
<p><a href="http://hn.elijames.org/">hn.elijames.org</a><br>
“Less annoying hacker news” with an even simpler interface<br>
Alexa: None</p>
<p><a href="http://serializer.io/">seralizer.io</a><br>
HN + Related Subreddits + Lobsters + Mac Rumors + Arstechnica<br>
Alexa: None</p>
<p><a href="https://nerdmash.com/">nerdmash.com</a><br>
A nerd’s daily read. Top posts from every nerdy content aggregator.<br>
Alexa: None</p>
<h2>Other Tweaks / Interfaces</h2>
<p><a href="https://old.reddit.com/r/hackernews/">/r/hackernews</a><br>
Subreddit for HN<br>
51,450 readers</p>
<p><a href="https://hnreplies.com/">hnreplies.com</a><br>
Emails on replies to your comments<br>
Alexa: 3.2m</p>
<p><a href="https://apps.apple.com/us/app/id1308885491">Octal iOS App</a><br>
Full-featured HN client with support for posting/voting/comments – iOS only.<br>
4.8/5.0 – 1K Ratings</p>
<p><a href="https://hnrss.github.io/">hnrss.github.io</a><br>
HN RSS Feed<br>
Alexa: None</p>
<p><a href="https://hackerne.ws/">hackerne.ws</a><br>
HN Short Link – redirects to https://news.ycombinator.com<br>
Alexa: None</p>
<p><a href="https://chrome.google.com/webstore/detail/hacker-news-ux/chngbdmhgakoomomnnhfapkpbalpmhid">Hacker News UX</a><br>
Chrome Extension for Improved UI<br>
356 users</p>
<p><a href="https://f5bot.com/">f5bot.com</a><br>
Reddit / HN / Lobsters keyword mention watch tool.<br>
Alexa: 1.1m</p>

<h2>Graveyard</h2>
<p>hackermonthly.com [<a href="https://web.archive.org/web/20160731192600/http://hackermonthly.com/">defunct</a>]<br>
HN in print</p>
<p>quiethn.com [<a href="https://web.archive.org/web/20171001013212/https://quiethn.com/">defunct</a>]<br>
HN with less clutter </p>
<p>hackerblogs.com [<a href="https://web.archive.org/web/20110204021331/http://www.hackerblogs.com/">defunct</a>]<br>
2011-era mobile view</p>
<p>hackernews.im [defunct]<br>
now <a href="https://hackernews.betacat.io/">hackernews.betacat.io</a></p>
<p>tiledhn.com [<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">defunct</a>]<br>
Windows 8-type view for HN</p>
<p>hackerbra.in [<a href="https://web.archive.org/web/20181105131330/http://hackerbra.in/">defunct</a>]<br>
HN with inline top comments </p>
<p>hnwatcher.com [<a href="https://web.archive.org/web/20201125052525/https://www.hnwatcher.com/">defunct</a>]<br>
user/keyword email notification service</p>
<p>hnmobile.herokuapp.com [<a href="https://web.archive.org/web/20180601000346/http://hnmobile.herokuapp.com/">defunct</a>]<br>
HN mobile friendly mirror</p>
<p>hackernewsemail.com [<a href="https://web.archive.org/web/20180826215821/https://hackernewsemail.com/">defunct</a>]<br>
Daily email for posts with minimum set number of points</p>
<p>hacker-newspaper.gilesb.com [<a href="https://web.archive.org/web/20180402131152/https://news.ycombinator.com/">defunct</a>]<br>
HN Mirror</p>
<p>react-hn.appspot.com [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror</p>
<p>hackeroo.co [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror </p>
</div></div>]]>
            </description>
            <link>https://blog.luke.lol/tech/15-hacker-news-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556990</guid>
            <pubDate>Mon, 28 Dec 2020 05:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bloom Filter – Probability and Benchmarks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25556713">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | http://andybui01.github.io/bloom-filter/ | <a href="https://web.archive.org/web/*/http://andybui01.github.io/bloom-filter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Bloom filters are a data structure which allows you to test whether an element exists in a set, with lower memory usage and better access times than other hash table implementations. It is probabilistic, and while it can guarantee negative matches, there is a slight chance it returns a false positive match. Through clever mathematical assumptions, we can produce constraints to minimise the chance of a false positive.</p>





<p><strong>Contents</strong></p>
<ol>
  <li><a href="#description">Description</a></li>
  <li><a href="#proof">Proof</a></li>
  <li><a href="#implementation-and-benchmarks">Implementation and benchmarks</a></li>
</ol>



<h2 id="description">Description</h2>

<p>Let there be a set of elements $N$, and we wish to store each element $e \in N$ in the set $F$. To do this, we introduce the set $K$ which has $k$ number of hash functions which hash the same element to <em>different</em> values.</p>

<p>In the following example, elements $x$ and $y$ are hashed by $k = 3$ hash functions.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure1.png" width="200"></p>

<p>Next, we introduce the bit array $M$ which has $m$ bits. This bit array is the underlying data structure that represents $F$, and we say an element $e$ is in $F$ if all of its corresponding bits (after hashing) in the bit array are set.</p>

<p>In the following image, $x$ is in $F$ hence all of its hashed bits within $M$ are set. Only one of $y$â€™s hashed bits are set so it is not in $F$. $x$ and $y$ are also sharing a bit at $M[4]$.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure2.png" width="400"></p>

<p>As we hash more elements from $N$, more bits are set to 1 in $M$ and eventually we get a <em>false positive</em> when testing set membership. This occurs when all of an elementâ€™s bits are set, although it was never inserted.</p>

<p>Consider the following scenario: $x$ and $y$ are in $F$, $z$ is not. However, $z$â€™s hashed bits are all set, giving the (false) impression that $z$ is in $F$.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure3.png" width="500"></p>

<p>Once an element is placed in $F$, it will remain there, as flipping bits to remove an element introduces the possibility of false negatives. We will show that there exists optimal parameters, $k$ hash functions and $m$ length bit array, to lower the false positive rate $\epsilon$.</p>



<h2 id="proof">Proof</h2>
<p>Note: This section is pretty math heavy, if you just want to look at the cool tables and graphs then you can skip ahead to <a href="#implementation-and-benchmarks">here</a>.</p>

<p>$\newcommand{\pbrac}[1]{\left(#1\right)}$
$\newcommand{\sbrac}[1]{\left[#1\right]}$</p>

<h3 id="first-attempt">First attempt</h3>
<p>Assume that a hash function in $K$ maps to each array position with <em>equal probability</em>. The probability that a bit is not set by a hash function during the insertion of an element is:</p>

<p>\begin{align}
    1 - \frac{1}{m}.
\end{align}</p>

<p>The probability that every hash function in $K$ leaves a certain bit at 0 will be</p>

<p>\begin{align}
    \left( 1 - \frac{1}{m} \right)^k \approx \ e^{-k/m}.
\end{align}</p>

<p>Thus, after inserting $n$ elements, the probability that a bit is <em>still</em> 0 is</p>

<p>\begin{align}
    \left( 1 - \frac{1}{m} \right)^{kn} \approx \ e^{-kn/m} \ = \ p,
\end{align}</p>

<p>and the probability that a bit is 1 after $n$ insertions is</p>

<p>\begin{align}
    \left( 1 - \left[ 1 - \frac{1}{m} \right]^{kn} \right) \approx \left( 1 - p \right).
\end{align}</p>

<p>Next, we test set membership for an element NOT in the set. Following $n$ insertions, each bit in the array has a chance of being set to 1 with the probability above. The probability that $k$ bits are set to 1, which would lead to a false positive result for set membership, is often referred to as the error/false positive rate:</p>

<p>\begin{align}
    \epsilon = \left( 1 - \left[ 1 - \frac{1}{m} \right]^{kn} \right)^k \approx \left( 1 - p \right)^k.
\end{align}</p>

<p>There exists a major problem with this analysis, however. At the start we made an assumption that all bits would be set randomly and independently. <strong>This is not correct</strong> as we have established that <em>all</em> our hash functions in $K$ will not hash an element to the same array position. For example, if we have hashed an element $m-1$ times into $m-1$ different positions, then the remaining $1$ bit in the array is guaranteed to be chosen, if we wish to retain an even spread of hashed values. Concretely, the $k$ bit array positions for each element are in fact <em>dependent</em>.</p>

<h3 id="another-try-using-poisson-approximations">Another try using Poisson approximations</h3>

<p>Consider a â€œballs and binsâ€� scenario where each throw of a ball into a bin is equivalent to hashing an element to an array position.</p>

<p>We have the following 2 cases:</p>
<ul>
  <li><strong>Exact case:</strong> $n$ balls are thrown into $m$ bins independently and uniformly at random</li>
  <li><strong>Poisson case:</strong> number of balls in each bin are taken to be independent Poisson random variables with an expected value</li>
</ul>

<p>Weâ€™ll be using the following corollaries from the book <em>â€œProbability and computing: randomization and probabilistic techniques in algorithms and data analysisâ€�</em> by Mitzenmacher and Upfal.</p>

<p><strong>Corollary 4.6:</strong> Let $X_1,â€¦,X_n$ be independent Poisson trials such that $P(X_i = 1) = p_i$. Let $X = \sum_{i=1}^{n} \text{ and } \mu = E(X)$. For $0 &lt; \delta &lt; 1$. [p. 71]
\begin{align}
    P\left(\left|X - \mu\right| \geq \delta \mu\right) \leq 2\exp{\left(-\frac{\mu\delta^2}{3}\right)}
\end{align}</p>

<p><strong>Corollary 5.9:</strong> any event that takes place with probability $p$ in the Poisson case takes place with probability at most $p e \sqrt{n}$ in the exact case. [p. 109]</p>

<p>Each bin corresponds to an array position and thus a bit being set to 0 is equivalent to an empty bin in our scenario. The fraction of bits being set to 0 after $n$ insertions is therefore equivalent to the fraction of empty bins after $kn$ balls have been thrown into $m$ bins.</p>

<p>We define $X$ as the number of empty bins after the balls have been thrown into $n$ bins, such that</p><p>

\[\begin{align}
    X =&amp; \ \sum_{i=1}^{n} X_i, \\
    \text{where } X_i =&amp; \
    \begin{cases}
        1 &amp; \text{if bin is empty} \\
        0 &amp; \text{otherwise}
    \end{cases}
\end{align}\]

</p><p>then we can define</p><p>

\[\begin{align}
    p' =&amp; \ \left( 1 - \frac{1}{m}\right)^{kn}, \\
    E(X) =&amp; \ mp'.
\end{align}\]

</p><p>In the Poisson case, each bin can be thought of as an independent Poisson random variable with expected value $pâ€™$. Therefore, we can apply \textbf{corollary 4.6} and $E(X) = \ mpâ€™$ to obtain the following:</p>

<p>\begin{align}
    P\left( \left| X - mpâ€™\right| \geq \delta mpâ€™\right) \ \leq&amp; \ 2\exp{\left(-\frac{mpâ€™\delta^2}{3}\right)}
\end{align}
Let $\delta \ = \ \beta / pâ€™, \ $choose small$ \ \beta$
\begin{align}
    \therefore \ P\left( \left| X - mpâ€™\right| \geq \beta m\right) \ \leq&amp; \ 2\exp{\left(-\frac{m\beta^2}{3pâ€™}\right)}
\end{align}</p>

<p>We then apply <strong>corollary 5.9</strong> to obtain</p><p>

\[\begin{align}
    P\left( \left| X - mp'\right| \geq \beta m\right) \ \leq&amp; \ 2e\sqrt{kn} \exp{\left(-\frac{m\beta^2}{3p'}\right)}\\
    \leq&amp; \ 0.000001 \ \text{when $m$ sufficiently large.}
\end{align}\]

</p><p>Essentially, taking the probability of an event using a Poisson approximation for all of the bins and multiplying it by $e\sqrt{kn}$ gives an upper bound for the probability of the event when $kn$ balls are thrown into $m$ bins (the exact case where events are independent).</p>

<p>This result tells us that when $m$ is sufficiently large, the fraction of empty bins $X/m$ is <em>very</em> close to $pâ€™$. And since $pâ€™ \approx p$ we can use $p$ to continue predicting actual performance.</p>

<h3 id="optimal-k">Optimal <em>k</em></h3>

<p>The false positive rate is $\epsilon = (1-p)^k$ and we look for a $k$ that minimizes $\epsilon$. Rearranging $\epsilon$ gives us</p><p>

\[\begin{align}
    \epsilon \ =&amp; \ \pbrac{1-p}^k \\
    =&amp; \ \exp{\pbrac{\ln{\pbrac{\sbrac{1-p}^k}}}} \\
    =&amp; \ \exp{\pbrac{k\ln{\pbrac{\sbrac{1-p}}}}} \\
    =&amp; \ \exp{\pbrac{k\ln{\pbrac{\sbrac{1-e^{-kn/m}}}}}}.
\end{align}\]

</p><p>If we let $g = k\ln{\pbrac{1-e^{-kn/m}}}$ so that $\epsilon = e^g$, then minimizing the false positive $\epsilon$ is equivalent to minimizing $g$ with respect to $k$. We have</p>

<p>\begin{align}
    \frac{dg}{dk}\ =&amp; \ \ln \left(1-e^{-\frac{nk}{m}}\right)+\frac{kn \cdot e^{-\frac{nk}{m}}}{m\left(1-e^{-\frac{nk}{m}}\right)}.
\end{align}</p>

<p>Solving this derivative when it is 0 and finding the global minimum gives us</p>

<p>\begin{align}
    k = \frac{m}{n}\ln\pbrac{2}.
\end{align}</p>

<h3 id="optimal-m">Optimal <em>m</em></h3>
<p>To find an optimal length for our bit-array we substitute $k = \frac{m}{n}\ln\pbrac{2}$ into our false positive equation and get</p><p>

\[\begin{align}
    \epsilon \ =&amp; \ \pbrac{1-e^{-\ln 2}}^{\frac{m}{n}\ln 2} \\
    \ln\epsilon \ =&amp; \ \frac{m}{n}\ln\pbrac{2}\ln\pbrac{1-e^{-\ln 2}} \\
    =&amp; \ \frac{m}{n}\ln\pbrac{2}\ln{\frac{1}{2}} \\
    =&amp; \ -\frac{m}{n}\ln\pbrac{2}^2 \\
    \therefore m \ =&amp; \ \frac{-n\ln\epsilon}{\ln\pbrac{2}^2}.
\end{align}\]

</p><p>This effectively leaves $\epsilon$ as the only unknown variable left. However, when we consider the Bloom filter in a practical context, we will most likely have a false positive rate in mind, and can treat it as a constant.</p>



<h2 id="implementation-and-benchmarks">Implementation and benchmarks</h2>

<h3 id="overview">Overview</h3>
<p>We will be comparing the Bloom filter against 4 popular and efficient implementations of hash tables:</p>

<ul>
  <li>Google Dense Hash Set</li>
  <li>Google Sparse Hash Set</li>
  <li>TSL Robin Set</li>
  <li>STD Unordered Set</li>
</ul>

<p>Implementations were compared based on time performance (insert, read) and memory performance (inserts). Currently, only small strings (15 characters) and medium strings (50 characters) are used for input, with up to $n = 3\times10^6$ elements for each test. Each test was performed 5 times for each implementation and an average-of-5 was used in the final table/graph. The false positive rate is set to 0.01.</p>

<p>Benchmarking was done using gccâ€™s C++ compiler and the following command was run to compile: g++ -Iinclude -std=c++11 -O3. In addition, the tests were performed on a computer with the following specs:</p>

<ul>
  <li>AMD Ryzen 5 2600 3.4GHz 6 core</li>
  <li>8GB DDR4-2666 CL19</li>
</ul>

<p>The tests were run with the false positive rate $\epsilon = 0.01$</p>



<h3 id="insert-small-string-15-bytes">Insert small string (15 bytes)</h3>

<p>Before the test, we generate a vector of $n$ small strings and then insert each string as an entry into the sets, measuring the performance of said insert operation. The Bloom filterâ€™s only overhead during insertion is setting bits to 1.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/insert_small_string.png" width="700"></p>



<h3 id="read-small-string-15-bytes">Read small string (15 bytes)</h3>

<p>Before the test, we generate a vector of $n$ small strings and pre-load the strings into the hash tables. We then traverse the same vector of small strings, testing set membership and timing said read operation.</p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://andybui01.github.io/bloom-filter/">http://andybui01.github.io/bloom-filter/</a></em></p>]]>
            </description>
            <link>http://andybui01.github.io/bloom-filter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556713</guid>
            <pubDate>Mon, 28 Dec 2020 04:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study Demonstrates Seafood Contains the Heaviest Amount of Microplastics]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25556589">thread link</a>) | @voldemort1968
<br/>
December 27, 2020 | https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/ | <a href="https://web.archive.org/web/*/https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In a review <a href="https://ehp.niehs.nih.gov/doi/full/10.1289/EHP7171">published in Environmental Health Perspectives</a>, Microplastics (MPs) are laid out as a serious problem in the marine environment as well as human food consumption.</p><p>The study analyzed 69 experiments across mollusks, crustaceans, fish and echinodermata. The data show that seafood is a major cause of human exposure to MPs. Levels of MP contamination vary significantly in different phylum of organisms. </p><p>Microplastics are tiny pieces of any kind of plastic found in the environment less than 5mm long according to NOAA and the European Chemicals Agency. They often end up in nature from cosmetics, clothing, and industrial processes.</p><figure><img src="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Plastic (PET) bottles collected from the river Tisza. They are ready to be transported and recycled." srcset="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@mihaly_koles?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Mihály Köles</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Two classifications of microplastics exist. Primary microplastics are smaller than 5mm. Polyester, nylon, and rayon fibers are also present (also known as nurdles). Secondary microplastics come from the micro degradation of larger plastic particles after their entrance into the environment through natural weathering processes.</p><p>"No-one yet fully understands the full impact of microplastics on the human body, but early evidence from other studies suggest they do cause harm." said study author, Evangelos Danopoulos, a postgraduate student at Hull York Medical School in an <a href="https://www.sciencedaily.com/releases/2020/12/201223091547.htm">article from Science Daily</a>.</p><p>"A critical step in understanding the full impact on human consumption is in first fully establishing what levels of microplastics humans are ingesting. We can start to do this by looking at how much seafood and fish is eaten and measuring the amount of MPs in these creatures."</p><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1600w, https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1962w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://pubs.acs.org/doi/abs/10.1021/acs.est.9b01517">American Chemical Society; Expert(s) (Cox et al)</a></figcaption></figure><p>The study concludes that there needs to be harmonization and standardization of methods and procedures.</p><!--kg-card-begin: html--><p><a href="https://twitter.com/smosadotcom?ref_src=twsrc%5Etfw" data-show-count="false">Follow @smosadotcom</a></p><!--kg-card-end: html-->
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556589</guid>
            <pubDate>Mon, 28 Dec 2020 04:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25556286">thread link</a>) | @pantalaimon
<br/>
December 27, 2020 | https://justine.lol/cosmopolitan/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>build-once run-anywhere c without devops</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/sources.html">Sources</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» jart's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
echo <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -Os -static -fno-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, and OpenBSD too. For details on how this works, please read
  the <a title="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly pδrταblε εxεcµταblε</a> blog post. This
  novel binary format is also optional: conventional ELF binaries can be
  compiled too by removing the <code>-Wl,--oformat=binary</code> flag.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556286</guid>
            <pubDate>Mon, 28 Dec 2020 02:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Buzzword.engineering Tech Stack]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25556272">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | https://buzzword.engineering/post/blog-tech-stack | <a href="https://web.archive.org/web/*/https://buzzword.engineering/post/blog-tech-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I've been meaning to get around to setting up a blog for a long time. In the past, I've gotten as far as getting halfway through trying out different static site generators before getting depressed about my lack of frontend design chops and given up. </p>
<p>The perfect storm finally came: </p>
<ol>
<li>I took <strong>two weeks off</strong>. After recharging my batteries for a few days, I was ready for a little side project. </li>
<li>I recently discovered <a href="https://obsidian.md/" target="_blank" rel="nofollow noopener noreferrer">Obsidian</a>, which is a dope AF note-taking app. </li>
<li>I've tried a decent number of static site generators to build documentation for various projects and wanted to take a deeper dive into <a href="https://gatsbyjs.com/" target="_blank" rel="nofollow noopener noreferrer">Gatsby</a>. </li>
<li>I recently discovered <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> and wanted to use it for something. </li>
</ol>
<p>I wanted to see if i could use Obsidian as a <a href="https://en.wikipedia.org/wiki/Content_management_system" target="_blank" rel="nofollow noopener noreferrer">content management system (CMS)</a> for a tech blog and Pipedream to automate tweeting out new blog posts. </p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span><strong>Spoiler Alert</strong></h5></p><p>It was, in fact, possible.</p></div>
<p>Anyway, here's Buzzword Engineering's inaugural blog post. If you like it, go give me a github star on the <a href="https://github.com/steven-terrana/steven-terrana.github.io" target="_blank" rel="nofollow noopener noreferrer">blog repo</a> or something. It's a nice dopamine boost and fuels my self-worth. </p>

<p>Let's dive in. Here's a digram for those visual learners out there. </p>
<p><span>
      <a href="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ac56/overview.webp 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d3be9/overview.webp 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e46b2/overview.webp 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e97dc/overview.webp 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ff5a/overview.png 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e85cb/overview.png 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png" alt="This diagram shows an overview of buzzword.engineering tech stack and associated automation" title="This diagram shows an overview of buzzword.engineering tech stack and associated automation" loading="lazy">
      </picture>
  </a>
    </span></p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span><strong>Excalidraw is Dope</strong></h5></p><p>If you haven't heard of it, stop reading this and go play with <a href="https://excalidraw.com/" target="_blank" rel="nofollow noopener noreferrer">Excalidraw</a> and then come back. It's the tool I used to sketch out this diagram.</p></div>
<h2 id="obsidian"><a href="#obsidian" aria-label="obsidian permalink"></a>Obsidian</h2>
<p>I'll keep this short.  Maybe a future blog post will talk about Obsidian in a lot more detail. For now, let me just say that I've tried to get into taking notes for... a long time. I could never do it in college. I struggle to do it for work. I've always found that taking notes takes away from my ability to absorb the content in the moment and make meaningful contributions. </p>
<p>Obsidian was the first app that actually made me <strong>want</strong> to take notes. The general idea is that all your notes are written in markdown. Jumping around is super easy with <code>CMD + O</code> (which also will create pages for you if they don't exist).  Linking between pages to build connections is really easy as can be with a syntax like <code>[[this]]</code>. Obsidian builds a visual graph of the relationships between pages (I'm a sucker for graphs). And finally, you can build templates and insert them with <code>CMD + T</code>. Templates dramatically simplified the boiler plate needed to capture who's attending a meeting, agenda, the date, etc. </p>
<p>Long story short, try it out.  (Or don't, whatever.)  I'm a fan and thought that maybe if I can use it as the interface for writing blog posts that I might <em>actually</em> write some. </p>
<h3 id="automated-backups"><a href="#automated-backups" aria-label="automated backups permalink"></a>Automated Backups</h3>
<p>Obsidian has some 3rd-party plugins that do nifty things.  One of these plugins is called <a href="https://github.com/denolehov/obsidian-git" target="_blank" rel="nofollow noopener noreferrer">Obsidian Git</a> which can automatically backup your notes to a Git repository.</p>
<p>I figured that had to be a way to fetch markdown content from a remote github repository and use it as a content source for Gatsby. There was.</p>
<h3 id="defining-post-information"><a href="#defining-post-information" aria-label="defining post information permalink"></a>Defining Post Information</h3>
<p>Blog post information is defined through the markdown frontmatter.  For example, the frontmatter for this blog post: </p>
<div data-language="yaml"><pre><code><span>---</span>
<span>title</span><span>:</span> The buzzword.engineering Tech Stack
<span>date</span><span>:</span> <span>"12/26/2020"</span>
<span>publish</span><span>:</span> <span>true</span>
<span>template</span><span>:</span> <span>"post"</span>
<span>slug</span><span>:</span> blog<span>-</span>tech<span>-</span>stack
<span>description</span><span>:</span> <span>"I finally got around to putting a blog together that uses Obsidian, Gatsby, and automates tweeting out new posts with Pipedream."</span>
<span>---</span></code></pre></div>
<h2 id="gatsby"><a href="#gatsby" aria-label="gatsby permalink"></a>Gatsby</h2>
<p>I think it's important to start here by saying that I'm <strong>not</strong> a frontend developer. Well, let's rephrase that. I'm writing a blog post that has Gatsby in it.  So it's probably more accurate to say that I'm a <em>very</em> junior frontend developer. </p>
<p>My mental model for Gatsby so far is that it's a framework for building static site generators. There might be a couple frontend purists or gatsby enthusiasts out there who take issue with that definition, please let me know if you've got a better one down in the comments. </p>
<p>There are two main components of Gatsby that drew me to it: </p>
<ol>
<li>It uses <a href="https://reactjs.org/" target="_blank" rel="nofollow noopener noreferrer">React</a>, which is a lot more powerful to me over something like <a href="https://handlebarsjs.com/" target="_blank" rel="nofollow noopener noreferrer">handlebars</a> or go-based html templating. </li>
<li>Gatsby is extensible with a rich plugin ecosystem that contribute to a shared <a href="https://graphql.org/" target="_blank" rel="nofollow noopener noreferrer">GraphQL</a> data layer. When developing your site, you can query the data layer to fetch content for particular pages/components.</li>
</ol>
<p>I like React and I think Gatsby's extensibility framework and GraphQL data layer is <strong>brilliant</strong>. </p>
<h3 id="the-starter"><a href="#the-starter" aria-label="the starter permalink"></a>The Starter</h3>
<p>Another great thing about Gatsby is their concept of Starters. For this blog, I kicked things off with the <a href="https://github.com/alxshelepenok/gatsby-starter-lumen" target="_blank" rel="nofollow noopener noreferrer">gatsby-starter-lumen</a>. </p>
<h3 id="fetching-content"><a href="#fetching-content" aria-label="fetching content permalink"></a>Fetching Content</h3>
<p>The first thing I had to customize was content sources. The Lumen starter fetches content from the same repository as the blog itself. Thankfully, there's a Gatsby plugin called <a href="https://www.gatsbyjs.com/plugins/gatsby-source-git" target="_blank" rel="nofollow noopener noreferrer"><code>gatsby-source-git</code></a> that allows you to fetch content from a remote Git repository. </p>
<p>During development, I wanted to be able to fetch content from the local copy of the Obsidian backup repository. Gatsby plugins are done by exporting a javascript object from a file called <code>gatsby-config.js</code>.  </p>
<p>Here, I toggle between using the <code>gatsby-source-git</code> plugin and the [<code>gatsby-source-filesystem</code>] based on whether a <code>GATSBY_PREVIEW</code> environment variable is set. </p>
<div data-language="js"><pre><code><span>if</span><span>(</span>process<span>.</span>env<span>.</span><span>GATSBY_PREVIEW</span> <span>==</span> <span>"true"</span><span>)</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>using local vault path: </span><span><span>${</span>siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>}</span></span><span>`</span></span><span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span>'gatsby-source-filesystem'</span><span>,</span>
    options<span>:</span> <span>{</span>
      path<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>,</span>
      name<span>:</span> <span>'local_obsidian'</span><span>,</span>
      ignore<span>:</span> <span>[</span> <span>"**/.git/**/*"</span><span>,</span> <span>"**/.obsidian/**/*"</span><span>,</span> <span>"**/Templates/**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span> <span>else</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>"fetching from remote repo: "</span><span>,</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span><span>`</span><span>gatsby-source-git</span><span>`</span></span><span>,</span>
    options<span>:</span> <span>{</span>
      name<span>:</span> <span><span>`</span><span>obsidian</span><span>`</span></span><span>,</span>
      remote<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>,</span>
      patterns<span>:</span> <span>[</span> <span>"!**/Templates/**/*"</span><span>,</span> <span>"**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span></code></pre></div>

<p>Comments on blog posts are made possible through a nifty tool called <a href="https://utteranc.es/" target="_blank" rel="nofollow noopener noreferrer">utteranc.es</a>. It's a GitHub Application that uses GitHub Issue threads per blog post to track comments. </p>
<h3 id="post-filtering"><a href="#post-filtering" aria-label="post filtering permalink"></a>Post Filtering</h3>
<p>In the spirit of premature optimization, I wanted to integrate a way to filter blog posts with fuzzy-searching. To accomplish this, I integrated <a href="https://fusejs.io/" target="_blank" rel="nofollow noopener noreferrer">Fuse.js</a> and added a new <code>Filter</code> component to the blog. </p>
<p>Most of the logic for how this was accomplished can be seen in the <a href="https://github.com/steven-terrana/steven-terrana.github.io/blob/main/src/templates/index-template.js" target="_blank" rel="nofollow noopener noreferrer">Index Template</a>.</p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</h5></p><p>I wanted to insert a gif of the filtering taking place. Apparently that's easier said than done with Gatsby and<code>gatsby-transform-remark</code>.  I'll update this post once I get gifs working 🙄.</p></div>
<h2 id="automation"><a href="#automation" aria-label="automation permalink"></a>Automation</h2>
<p>With the site actually working how I wanted it to, I got to focus on the side of things I'm actually good at: digital duct tape. The goal is for changes in markdown content in the Obsidian backup repository to trigger a deployment of the site and if there is a new blog post, to send out a tweet letting you all know about it. </p>
<h3 id="step-1-github-action-on-the-obsidian-backup-repo"><a href="#step-1-github-action-on-the-obsidian-backup-repo" aria-label="step 1 github action on the obsidian backup repo permalink"></a>Step 1: GitHub Action on the Obsidian Backup Repo</h3>
<p>First things first, the content repository needs to trigger a deployment of the site. The easiest way I could think to accomplish this would be to a GitHub Action on the blog post repository that does the build/deploy logic. </p>
<p>This meant that I needed a way to invoke a GitHub Action on one repository as part of the execution of an Action on another repository. This is where the <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/events-that-trigger-workflows#repository_dispatch" target="_blank" rel="nofollow noopener noreferrer"><code>repository_dispatch</code></a> event comes in handy. Basically, it means that you can use the GitHub API to trigger an Action. </p>
<p>Here's what the GitHub Action workflow looks like for the obsidian repository: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Trigger Build
<span>on</span><span>:</span>
  
  <span>push</span><span>:</span>
    <span>branches</span><span>:</span> <span>[</span> main <span>]</span>
  
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>trigger</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
     <span>-</span> <span>name</span><span>:</span> Trigger Upstream Blog Action
        <span>run</span><span>:</span> <span>|</span><span>
          curl -XPOST \
          -u "${{ secrets.PAT_USERNAME}}:${{secrets.PAT_TOKEN}}" \
          -H "Accept: application/vnd.github.everest-preview+json" \
          -H "Content-Type: application/json" \
          https://api.github.com/repos/steven-terrana/steven-terrana.github.io/dispatches \
          --data '{"event_type": "blog"}'</span></code></pre></div>
<h3 id="step-2-github-action-on-the-blog-repo"><a href="#step-2-github-action-on-the-blog-repo" aria-label="step 2 github action on the blog repo permalink"></a>Step 2: GitHub Action on the Blog Repo</h3>
<p>Sweet. Now commits to the Obsidian backup repository will trigger actions on the blog repository. </p>
<p>The next step was to automate the build and deployment steps using a GitHub Action on the blog repository. Here's what that action looks like: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Build and Publish
<span>on</span><span>:</span>
  <span>repository_dispatch</span><span>:</span>
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>build-deploy-notify</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
      
      <span>-</span> <span>name</span><span>:</span> Checkout Code 🛎
        <span>uses</span><span>:</span> actions/checkout@v2
        <span>with</span><span>:</span> 
          <span>persist-credentials</span><span>:</span> <span>false</span>
       <span>-</span> <span>name</span><span>:</span> Install &amp; Build 🔧
        <span>run</span><span>:</span> <span>|</span><span>
          npm ci
          npm run build
          echo "buzzword.engineering" &gt; public/CNAME</span>
        <span>env</span><span>:</span> 
          <span>PAT_USER</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_USER <span>}</span><span>}</span>
          <span>PAT_TOKEN</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_TOKEN <span>}</span><span>}</span>
      <span>-</span> <span>uses</span><span>:</span> peaceiris/actions<span>-</span>gh<span>-</span>pages@v3
        <span>with</span><span>:</span>
          <span>github_token</span><span>:</span> $<span>{</span><span>{</span> secrets.GITHUB_TOKEN <span>}</span><span>}</span>
          <span>publish_dir</span><span>:</span> public
          <span>force_orphan</span><span>:</span> <span>true</span>  </code></pre></div>
<p>This blog is hosted using GitHub Pages, so you'll notice a few things:</p>
<ol>
<li>I add a custom <code>CNAME</code> file to the <code>public</code> directory so that GitHub Pages knows the custom domain for this blog.  (I should definitely incorporate this into an inherit part of the build of the site using the <code>onPostBuild</code> Gatsby Node API method or something). </li>
<li>I use the <code>peaceiris/actions-gh-pages</code> action to publish the site. </li>
</ol>
<p>All in all, this was a pretty painless setup. </p>
<h3 id="step-3-automating-tweets"><a href="#step-3-automating-tweets" aria-label="step 3 automating tweets permalink"></a>Step 3: Automating Tweets</h3>
<p>So at this point, we've got content changes automatically getting deployed to GitHub Pages. The whole process takes about <strong>three minutes</strong> from commit to publish. </p>
<p>The last piece was to automate letting all of you know about the whatever new insightful thing I had to say! </p>
<p>I had stumbled on <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> before through targeted ads and sort of ignored it until I saw <a href="https://twitter.com/rawkode" target="_blank" rel="nofollow noopener noreferrer">David McKay</a> talk about how much he loves it on <a href="https://rawkode.live/" target="_blank" rel="nofollow noopener noreferrer">rawkode.live</a>. Here's a <a href="https://youtu.be/Q8ZJ_5zxfmo" target="_blank" rel="nofollow noopener noreferrer">link to the stream</a>!</p>
<p>I went into this adventure thinking I was going to have to do all kinds of fancy logic and scripting to make this possible. I was wrong. </p>
<p>After setting up a Pipedream account, starting looking at what event sources were available to trigger a workflow. Well, the Lumen gatsby …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buzzword.engineering/post/blog-tech-stack">https://buzzword.engineering/post/blog-tech-stack</a></em></p>]]>
            </description>
            <link>https://buzzword.engineering/post/blog-tech-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556272</guid>
            <pubDate>Mon, 28 Dec 2020 02:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's the best strategy when playing HORSE? (basketball)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25556148">thread link</a>) | @rishicomplex
<br/>
December 27, 2020 | https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html | <a href="https://web.archive.org/web/*/https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p><strong>TL;DR</strong>: If you want to win at HORSE, it’s generally a much better strategy to attempt high percentage shots. It almost never makes sense to shoot crazy half-court shots or behind-the-back shots. As a general rule of thumb, never attempt shots that you can’t shoot at &gt;50%.</p>

<hr>

<p><br>
<a href="https://en.wikipedia.org/wiki/Variations_of_basketball#H-O-R-S-E">HORSE</a> is a popular basketball shooting game. The main choice a HORSE player must make is which spots on the basketball court to attempt shots from. What’s the best strategy to win at HORSE?</p>

<ul id="markdown-toc">
  <li><a href="#game-rules" id="markdown-toc-game-rules">Game rules</a></li>
  <li><a href="#expected-number-of-turns" id="markdown-toc-expected-number-of-turns">Expected number of turns</a>    <ul>
      <li><a href="#deriving-the-formula" id="markdown-toc-deriving-the-formula">Deriving the formula</a></li>
      <li><a href="#visualizing-the-expected-number-of-turns" id="markdown-toc-visualizing-the-expected-number-of-turns">Visualizing the expected number of turns</a></li>
      <li><a href="#verification-via-simulation" id="markdown-toc-verification-via-simulation">Verification via simulation</a></li>
    </ul>
  </li>
  <li><a href="#analyzing-some-special-cases" id="markdown-toc-analyzing-some-special-cases">Analyzing some special cases</a>    <ul>
      <li><a href="#both-players-are-equally-good-shooters" id="markdown-toc-both-players-are-equally-good-shooters">Both players are equally good shooters</a></li>
      <li><a href="#player-1-is-a-slightly-better-shooter-than-player-2" id="markdown-toc-player-1-is-a-slightly-better-shooter-than-player-2">Player 1 is a slightly better shooter than Player 2</a></li>
      <li><a href="#player-2-is-a-slightly-better-shooter-than-player-1" id="markdown-toc-player-2-is-a-slightly-better-shooter-than-player-1">Player 2 is a slightly better shooter than Player 1</a></li>
    </ul>
  </li>
  <li><a href="#real-world-strategies" id="markdown-toc-real-world-strategies">Real world strategies</a></li>
</ul>

<h3 id="game-rules">Game rules</h3>
<p>The version of HORSE I’m analysing here involves two players. In the beginning, it’s Player 1’s turn. The player whose turn it is will be called “C”, and the other player will be called “O”.</p>
<ol>
  <li>C picks a spot on the basketball court and attempts a shot.
    <ul>
      <li>If C misses the shot, it is O’s turn, and we go back to 1.</li>
    </ul>
  </li>
  <li>If C makes the shot, O must now attempt the same shot.
    <ul>
      <li>If O makes the shot, C’s turn continues, and we go back to 1.</li>
      <li>If O misses the shot, they get a letter. C’s turn continues, and we go back to 1.</li>
    </ul>
  </li>
  <li>Once any player has gotten 5 letters, ie HORSE, they lose the game.</li>
</ol>

<p>On Player 2’s turn, Player 1 has no real strategy - they must simply try their best to make the shots that Player 2 makes. The only strategy a player can control is which shots they attempt when it’s their turn.</p>

<h3 id="expected-number-of-turns">Expected number of turns</h3>

<h4 id="deriving-the-formula">Deriving the formula</h4>

<p>Let us calculate the optimal shot on Player 1’s turn. Note that a “turn” lasts as long as the player whose turn it is does not miss their shot. We will assume that Player 1 will shoot the same optimal shot each time it is their turn. Let \(p_1\) be the probability that Player 1 makes this shot, \(p_2\) be the probability that Player 2 makes the same shot, and \(e_N\) be the expected number of turns for Player 1 to win \(N\) letters.</p>

<p>If Player 1 misses the shot, the expected number of turns going forward is \(1 + e_N\), since Player 1 has used up the current turn, and must restart in the same position next turn. If Player 1 makes the shot, and Player 2 misses the shot, the expected number of turns is \(e_{N-1}\), since the turn continues with one less letter to win. Finally, if Player 1 and Player 2 both make the shot, the expected number of turns is simply \(e_N\). Putting these together, we have</p><p>

\[\begin{equation}
e_N = (1 - p_1) (1 + e_N) + p_1 (1 - p_2) e_{N - 1} + p_1 p_2 e_N
\end{equation}\]

</p><p>Re-arranging and expanding for \(e_{N-1},e_{N-2}\ldots e_0\), we get</p><p>

\[\begin{eqnarray}
e_N - e_{N - 1} &amp;= \frac{1 - p_1}{p_1 (1 - p_2)} \\
\vdots \\
e_1 - e_0 &amp;= \frac{1 - p_1}{p_1 (1 - p_2)}
\end{eqnarray}\]

</p><p>\(e_0\) must be \(1\), since \(p_1=1, p_2=0 \implies e_1=1\). Adding the equations above and re-arranging, we get</p><p>

\[e_N = 1 + N\frac{1 - p_1}{p_1 (1 - p_2)}\]

</p><p>For the game of HORSE, \(N=5\), and so the expected number of turns to win HORSE is</p><p>

\[e_5 = 1 + 5\frac{1 - p_1}{p_1 (1 - p_2)} \tag{1} \label{eq:one}\]

</p><p>Our goal is to minimize \(e_5\). \(e_5\) increases with the inverse of the quantities \(\frac{p_1}{1 - p_1}\) and \((1 - p_2)\). Since the former grows much faster than the latter, we can intuit that increasing \(p_1\) is a lot more important than decreasing \(p_2\).</p>

<h4 id="visualizing-the-expected-number-of-turns">Visualizing the expected number of turns</h4>

<p>Since this is a function of two variables, we can visualize it with a contour plot.</p>

<p><img src="https://rishicomplex.github.io/assets/formula.png" alt="Contour plot of function"></p>

<p>As the color gets darker, the expected number of turns decreases, ie we’re more likely to win. As we would expect, the plot gets darker for higher values of \(p_1\) and lower values of \(p_2\), ie to the right and bottom of the plot. What’s interesting to note is that the contour lines are “squeezed” more toward the right than the bottom, indicating that a high \(p_1\) has a stronger effect than a low \(p_2\). For example, if \(p_2=0\) and \(p_1=0.2\), \(\eqref{eq:one}\) gives us \(e_5=21\), whereas if \(p_1=1\) and \(p_2=0.8\) we get \(e_5=1\).</p>

<h4 id="verification-via-simulation">Verification via simulation</h4>

<p>Another way to calculate \(e_5\) empirically is to simulate \(G\) games for each value of \(p_1\) and \(p_2\), and then average the number of turns the game takes to finish over all the games. Doing this with \(G=1000\), I get this plot:</p>

<p><img src="https://rishicomplex.github.io/assets/simulation.png" alt="Contour plot of simulation"></p>

<p>which matches the previous plot. The squiggles are due to randomness.</p>

<h3 id="analyzing-some-special-cases">Analyzing some special cases</h3>

<p>In reality, \(p_1\) and \(p_2\) tend to be related to one another, since shots that are harder for one player tend to be harder for the other player as well.</p>

<p>Let us analyse some special cases, corresponding to the straight lines in the following plot.</p>

<p><img src="https://rishicomplex.github.io/assets/straight_lines.png" alt="Contour plot with straight lines"></p>

<h4 id="both-players-are-equally-good-shooters">Both players are equally good shooters</h4>
<p>This corresponds to the red line above. Here, \(p_1 = p_2\), and \(\eqref{eq:one}\) simplifies to</p><p>

\[e_5 = 1 + \frac{5}{p_1}\]

</p><p>To minimize this, we should pick shots with a \(p_1\) as high as possible. For example, if we keep making layups at a probability of \(0.9\) each, we’d expect the game to be over in less than \(7\) turns.</p>

<h4 id="player-1-is-a-slightly-better-shooter-than-player-2">Player 1 is a slightly better shooter than Player 2</h4>

<p>Let’s say Player 1 always shoots 10% better than Player 2 for any shot. That is, \(p_2 = min(p_1 - 0.1, 0)\) (yellow line above), and when \(p1&gt;0.1\), \(\eqref{eq:one}\) simplifies to</p><p>

\[e_5 = 1 + 5 \frac{1 - p_1}{p_1 (1.1 - p_1)}\]

</p><p>In the range \(p_1 \in [0, 1]\), this function looks like this:</p>

<p><img src="https://rishicomplex.github.io/assets/player_1_better.png" alt="Player 1 better"></p>

<p>It is minimized at \(p_1=1\), where \(e_5=1\), that is, the game ends in one turn. Again, Player 1 wants to pick their highest probability shot.</p>

<h4 id="player-2-is-a-slightly-better-shooter-than-player-1">Player 2 is a slightly better shooter than Player 1</h4>

<p>Here, we set \(p_2 = p_1 + 0.1\) (orange line above), which gives us for \(p_1 &lt; 0.9\)</p><p>

\[e_5 = 1 + 5 \frac{1 - p_1}{p_1 (0.9 - p_1)}\]

</p><p>In the range \(p_1 \in [0, 1]\), this function looks like this:</p>

<p><img src="https://rishicomplex.github.io/assets/player_1_worse.png" alt="Player 1 worse"></p>

<p>Interestingly, we cannot simply maximize \(p_1\) here, because once \(p_2\) gets closer to \(1\), we can never win. However, the optimal \(p_1\) is still pretty high, at around \(p_1=0.684\), giving \(e_5=11.7\). If Player 2 (for whom \(e_5\) looks like the previous section) shoots shots at \(p_2&lt;0.4\) (eg three-point shots), they will lose the game, despite being a better shooter.</p>

<h3 id="real-world-strategies">Real world strategies</h3>

<p>In the real world, winning is not the only objective. You don’t want the game to take indefinitely long, and you’d be ridiculed if you kept taking layups. You also have no concrete way to estimate \(p_1\) and \(p_2\) (unless you’ve been playing an opponent for a long time and are keeping a tab on their shooting percentages), and so have to rely on intuition. Some general points to keep in mind:</p>

<ul>
  <li>You’re generally better off taking high percentage shots, even if you’re much better at a low-percentage shot than an opponent. As an example, let’s say you’ve been practicing half-court shots all year, and you can shoot a half court shot at an impressive 20% (\(p_1=0.2\)). You’re sure your opponent can’t shoot that shot if you make it (\(p_2=0\)). Your expected number of turns to win is still \(e_5=21\). Compare that to you shooting a 60% shot which your opponent can also make at 60% (eg a free throw), which lets you win in \(e_5=9.3\) turns. This is more than twice as good as the half court shot! This is because if you and your opponent both make the shot, it’s still your turn. Whereas if you miss your shot by attempting a low percentage shot, your turn is over. You can always win the game in 6-7 turns simply by taking layups at the same percentage as your opponent (assuming \(p_1\) of 0.8-0.9). If we set \(p_2=0\), and solve for \(e_5=7\), we get \(p_1 = 0.45\). That is, even if your opponent can’t make the shot you make at all, there’s generally no point in taking shots that have \(p_1 &lt; 0.45\) - you’re better off shooting layups.</li>
  <li>If you can guess \(p_1\) and \(p_2\) for a bunch of candidate shots, plug them into \(\eqref{eq:one}\) to figure out which shots are your best bet to win.</li>
  <li>Instead of practicing low percentage shots (like behind the backboard arc shots), practice your high percentage shots (like free throws or left handed layups) instead. If you and your opponent can both make a behind the backboard arc shot at 10%, and you practice to push yourself to 20%, you still go from winning in 51 turns to 23 turns. Compare that with converting your free throw from 60% to 70% - that pushes your expected turns from 9.3 to 6.4.</li>
  <li>Find novel-looking high percentage shots so that you can use an effective strategy while not getting ridiculed for just attempting layups. Examples are left handed close up shots, floaters, bank shots.</li>
</ul>

<p>I’d also recommend playing HORSE with modified rules, eg</p>
<ul>
  <li>No shots from inside the paint.</li>
  <li>No repeated shots from the same spot in a turn.</li>
  <li>If both players make three shots in a row, it’s Player 2’s turn.</li>
</ul>

<p>This should reduce the effectiveness of the layup strategy and make the game more fun.</p>

<hr>

<p><br>
The code for the plots in this post is <a href="https://colab.research.google.com/drive/18yF27zs80UF9TgFm4p7I5U4cDYn1V6A3?usp=sharing">here</a>.</p>

  </div>
</article>
<!-- Mathjax Support -->


      </div>
    </div></div>]]>
            </description>
            <link>https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556148</guid>
            <pubDate>Mon, 28 Dec 2020 02:27:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal Websites and Internet Writing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555725">thread link</a>) | @healeycodes
<br/>
December 27, 2020 | https://healeycodes.com/personal-websites-and-internet-writing/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/personal-websites-and-internet-writing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I chose five personal websites out of the thirty or so I visit regularly and tried to understand what it is about them that utterly captures me.</p>
<p>Whether or not it is obvious to you, I have stolen many things from the following websites. Be it design tweaks, post ideas, or even turns of phrase. These websites are incredible and you should consume them.</p>
<p>Good artists borrow, great artists <del>steal</del> use the inspect tool.</p>

<p>I have been following Justin Duke’s writing for close to two years. His older page is now <a href="https://jmduke.com/">depreciated</a> and he posts to <em>arcana dot computer</em>, an <a href="https://github.com/jmduke/arcana.computer">open source</a> website filled with catalogs and footnotes and light-touch design. The main framework is Jekyll, with dynamic content powered by Airtable. The <a href="https://arcana.computer/miscellany/this-site.html">About</a> page of Justin’s website explains the development/design/ideas behind the website in rich detail. So in this section I’ll instead focus on how I <em>feel</em> about the website.</p>
<p><span>
      <a href="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The index page of arcana.computer." title="The index page of arcana.computer." src="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png" srcset="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/a8a0d/arcana.computer.png 300w,
https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/dface/arcana.computer.png 600w,
https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png 640w" sizes="(max-width: 640px) 100vw, 640px" loading="lazy">
  </a>
    </span></p>
<p>My philosophy towards personal websites matches Justin’s. He writes:</p>
<blockquote>
<p>Lastly, if there’s anything I can convince you of: you should build a personal site, you should obsess over it, you should meticulously document it, and you should have quite a bit of fun doing so. (It’s worth it.)</p>
</blockquote>
<p>The content throughout these pages is personal and reads true. Although it’s not a journal as such, as I read through the notes and reviews I get a secret feeling that I’m looking somewhere I shouldn’t be — like peeking in a hidden diary.</p>
<p>Justin writes about capturing his <a href="https://arcana.computer/catalogs/media-diet">media diet</a>:</p>
<blockquote>
<p>This started out as a lazy compulsion, but I’ve grown rather found of this habit over time. “You are what you eat”, and all that — I’ve realized that paying more attention to how I’m spending my consumptive time has made me more focused on consuming what I’m interested in, and not simply what’s easiest.</p>
</blockquote>
<p>He talks about reviewing older sections of his media diet and how it helps him recollect that time in his life — “suddenly I am taken back to my old apartment on Capitol Hill, and my three weeks of funemployment before Stripe”. When coming across old words that I have written, I’ve also experienced this almost-olfactory flashback of thoughts.</p>
<p><span>
      <a href="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The catalog listing of arcana.computer." title="The catalog listing of arcana.computer." src="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png" srcset="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png 298w" sizes="(max-width: 298px) 100vw, 298px" loading="lazy">
  </a>
    </span></p>
<p>Overall, I am impressed with the breadth and depth of content on Justin’s website, as well as how he’s made Airtable work for him. I also like that sections are marked as in-progress. I like the personal structure to it. His methods for working on this website are similar to the goals of the <a href="https://en.wikipedia.org/wiki/Long_Now_Foundation">Long Now</a> and that gels with me.</p>

<p>Paul Stamatiou writes long form articles about his life and technology. If someone has a curiosity about a subject that he has covered (e.g. <a href="https://paulstamatiou.com/made-on-an-ipad-pro/">creating with the iPad Pro</a>, or <a href="https://paulstamatiou.com/building-a-windows-10-lightroom-photo-editing-pc/">building a lightroom PC</a>) I wouldn’t hesitate linking one of his articles to them — perhaps without even reading it — because of the consistent high quality I have come to expect.</p>
<p><span>
      <a href="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Paul Stamatiou's website." title="Paul Stamatiou's website." src="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png" srcset="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/a8a0d/paulstamatiou.com.png 300w,
https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/dface/paulstamatiou.com.png 600w,
https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png 750w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy">
  </a>
    </span></p>
<p>However, this quality comes with a cost, as he describes in <a href="https://paulstamatiou.com/writing-more/">Writing more</a>:</p>
<blockquote>
<p>I’m going to try something different and write more short-form posts here.</p>
</blockquote>
<blockquote>
<p>Over the years my focus has been increasing the quality of my articles. They’ve ended up becoming increasingly time-consuming to create.</p>
</blockquote>
<p>Although these articles (which for now he seems to have dubbed “briefs”) are shorter and less researched than his other writing they read as complete entries to me. On another website, by another person, they would be complete blog posts.</p>
<p>The more things I write, the more hesitant I am to actually publish. So the way he talks about blogging in <em>Writing more</em> resonates with me:</p>
<blockquote>
<p>I want to get back to what blogging felt like when I started in 2005. Back when posting a few sentences and publishing it within the same computing session was so easy and fun. Where expectations were low and it didn’t have to be perfect.</p>
</blockquote>
<p>He has written 1210 posts since 2005. My first thought goes to the build times of such a website! In 2011, he migrated from <a href="https://paulstamatiou.com/how-to-wordpress-to-jekyll/">Wordpress to Jekyll</a>. This year he <a href="https://twitter.com/Stammy/status/1307347164599922689">tweeted</a> that he’s looking at moving again:</p>
<blockquote>
<p>really, really want to migrate my jekyll blog to Hugo + Netlify but I have so many weird jekyll hacks and collections and templates/includes that I’m sure the migration would take months of spare time.</p>
</blockquote>
<blockquote>
<p>probably faster to build a new site from the ground up, new CSS and all</p>
</blockquote>
<p>Also this year, he was interviewed about his work (he’s a designer at Twitter) and about his blog on <a href="https://www.thundernerds.io/2019/10/writing-a-blog-and-working-at-twitter-with-paul-stamatiou/">Thunder Nerds</a>. (More people should be interviewed about their technology blogs please.)</p>
<p>Paul is a photographer who generates fantastic photo sets and write ups with little animated maps of the location. His <a href="https://paulstamatiou.com/photos/">photos</a>, and the way they are arranged, is truly fantastic. He has of course written <a href="https://paulstamatiou.com/photos/gear/">thousands of words</a> about his camera gear.</p>

<p>Martin Tournoij is the creator of <a href="https://www.goatcounter.com/">Goat Counter</a> and has posts dating back to 2013. His personal website is Jekyll-based and <a href="https://github.com/arp242/arp242.net">open source</a>. I usually run into his writing on <a href="https://lobste.rs/">lobste.rs</a> (a computing-focused community).</p>
<p><span>
      <a href="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Posts by Martin Tournoij" title="Posts by Martin Tournoij" src="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png" srcset="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/a8a0d/arp242-posts.png 300w,
https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png 427w" sizes="(max-width: 427px) 100vw, 427px" loading="lazy">
  </a>
    </span></p>
<p>I like the one-page layout of the landing page. There’s a list of posts and projects, a picture, and a link to his CV. My favorite post of his is <a href="https://www.arp242.net/personal-analytics.html">Analytics on personal websites</a> — where he argues in part for vanity statistics:</p>
<blockquote>
<p>As for “vanity stats” or “stats to stroke your ego”: I think that’s actually a valid use case as well. After you spent quite a bit of your spare time writing an article it’s just nice to know people are actually reading it. There’s nothing wrong with being validated – it’s a basic psychological need and I’m not a fan of casually dismissing it.</p>
</blockquote>
<p>Later on, he wrestles with the fact that since he’s the creator of an analytics tool, he doesn’t want this website to turn into an advertising channel for it.</p>
<p>Martin doesn’t shy away from controversial subjects on his blog. He writes about freedom and democracy, he pushes for empathy towards those he disagrees with. He writes without restraint which is admirable in itself.</p>
<p>He uses his own CSS template (<a href="https://github.com/arp242/hello-css">arp242/hello-css</a>) which is worth a look. If you’ll allow me to use a vague statement, his website has a unique visual readability to it.</p>

<p>Joel Califa’s website has whimsy. It doesn’t take itself seriously.</p>
<p><span>
      <a href="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The third section of Joel Califa's website" title="The third section of Joel Califa's website" src="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png" srcset="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/a8a0d/joel-buttons.png 300w,
https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/dface/joel-buttons.png 600w,
https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png 636w" sizes="(max-width: 636px) 100vw, 636px" loading="lazy">
  </a>
    </span></p>
<p>Clicking this button makes text spawn and fly away and fade (the snippets are things from the old web like: <code>&lt;i&gt;</code>, <code>&lt;frameset&gt;</code>, <code>&lt;marquee&gt;</code>, etc). There’s an illustration of his head that hides away when you hover near. The writing in the section headers frizzles with energy.</p>
<p>Joel’s website successfully serves as both a work portfolio and a design blog. His <em>Work</em> page describes itself as a “A sample of text-heavy case studies for patient visitors.” The design blog has “Low frequency, high quality design articles.”</p>
<p>My favorite post is <a href="http://joelcalifa.com/blog/tiny-wins/">Tiny Wins</a>:</p>
<blockquote>
<p>I recently shipped two things at GitHub that had an impact beyond my wildest dreams.</p>
</blockquote>
<p>Where he discusses the work involved in designing dynamic favicons for the Pull Request page:</p>
<blockquote>
<p>Now browser tabs will always show a PR’s current build status.</p>
</blockquote>
<p>As well as adding an arrow that signals which branch your changes are “flowing” into:</p>
<blockquote>
<p>Before releasing this, people would regularly confuse which branch would be merged into which.</p>
</blockquote>
<p>He writes with authentic authority. He covers subjects that seem so obvious after you read them. Like in <a href="http://joelcalifa.com/blog/revisiting-visited/">Revisiting :Visited</a>, where research, the web specification, and its practical uses, are combined:</p>
<blockquote>
<p>A Nielsen study summed this up nicely over ten years ago, “People get lost and move in circles when websites use the same link color for visited and new destinations. To reduce navigational confusion, select different colors for the two types of links.”</p>
</blockquote>
<blockquote>
<p>Can’t we, as an industry, get behind that reasoning? A “visited” link isn’t that far off from a “read” email. They both provide the user with the tacit understanding of where they’ve been.</p>
</blockquote>
<p>Joel exists in the wonderful space between technology and design where he is addressing problems that directly relate to me. For example, his website is the first place I read <a href="http://joelcalifa.com/blog/unsolicited-dating-advice/">a serious defense</a> of the <code>month/day/year</code> date ordering system.</p>
<p>It fills me with joy that I have only read half of his content.</p>

<p>Rasmus Andersson has the prettiest website in this list. An elegant three-column layout that perfectly scales to the browser’s width — dropping to two columns then one column. When a page is selected from the top right menu, the background changes to a rich color and shifts the menu up or down. With a wide enough browser, gray bars frame the website on either side.</p>
<p><span>
      <a href="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rsms.me main menu." title="rsms.me main menu." src="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png" srcset="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png 159w" sizes="(max-width: 159px) 100vw, 159px" loading="lazy">
  </a>
    </span></p>
<p>Rasmus is the creator of the <a href="https://rsms.me/inter/">Inter</a> font and uses it to great effect with bold hover colors.</p>
<p><span>
      <a href="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rsms.me hover effects." title="rsms.me hover effects." src="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png" srcset="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png 273w" sizes="(max-width: 273px) 100vw, 273px" loading="lazy">
  </a>
    </span></p>
<p>Even his <a href="https://rsms.me/bad-url">404 page</a> is sharp.</p>
<p>After looking around more, I found a <code>&lt;script&gt;</code> tag that includes <a href="https://rsms.me/res/main.js">main.js</a>, a debug tool that must have been used to develop the grid layout (which I think is based on <a href="https://rsms.me/raster/">rsms/raster</a>). Pressing alt+D or alt+G overlays a system of boxes and dots.</p>
<p><span>
      <a href="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Debug boxes and dots over the post list." title="Debug boxes and dots over the post list." src="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png" srcset="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/a8a0d/rasmus-boxes.png 300w,
https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png 376w" sizes="(max-width: 376px) 100vw, 376px" loading="lazy">
  </a>
    </span></p>
<p>Rasmus’s last post was in 2017 — <a href="https://rsms.me/wasm-intro">Introduction to WebAssembly</a> — but it’s one that I revisit often as it’s a clear and detailed explanation of the technology.</p>
<p>His use of the right arrow symbol (U+2192) as well as the rounded hover effect on titles (e.g. “Projects” and “Thoughts and ideas”) is something that I closely copied for my own website as it is just too perfect.</p>
<p>Like Paul Stamatiou, Rasmus has hundreds of articles and has been blogging for a long time – almost two decades. The earlier posts are more likely to be reblogs, quotes, links, and small thoughts. The kind of things that Twitter is now used for.</p>
<p>Unlike Twitter, the permanence of these small thoughts is poetic. Here, in 2002, a new font is announced next to something like a diary entry without a paragraph break in between:</p>
<blockquote>
<p>I’ve completed a new typeface. It’s a sweet little thing called Hovden Stitch. Yes your guess was correct. It looks like stitches, cross-stitches to be precise. Go get it for your mac or pc right here. Yesterday I hung out on a free festival here in Trollhättan. Laurel Music was great. Paola sucked. Laurel Music is playing …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://healeycodes.com/personal-websites-and-internet-writing/">https://healeycodes.com/personal-websites-and-internet-writing/</a></em></p>]]>
            </description>
            <link>https://healeycodes.com/personal-websites-and-internet-writing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555725</guid>
            <pubDate>Mon, 28 Dec 2020 01:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GKE HTTPS Ingress with LetsEncrypt using cert-manager]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555628">thread link</a>) | @motte
<br/>
December 27, 2020 | https://kosyfrances.github.io/ingress-gce-letsencrypt/ | <a href="https://web.archive.org/web/*/https://kosyfrances.github.io/ingress-gce-letsencrypt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <nav> <ul> <li> <a href="https://kosyfrances.github.io/">Home</a> </li> <li> <a href="https://kosyfrances.github.io/blog">Blog</a> </li> <li> <a href="https://kosyfrances.github.io/memoirs">Memoirs</a> </li> <li> <a href="https://kosyfrances.github.io/about">About</a> </li> </ul> </nav>  <p><span> <time datetime="16-03-2020">Monday. March 16, 2020</time> - <span title="Estimated read time"> 10 mins </span> </span></p> <h2 id="introduction">Introduction</h2> <p><a href="https://cloud.google.com/kubernetes-engine">Google Kubernetes Engine (GKE)</a> provides a built-in and managed Ingress controller called GKE Ingress. When you create an Ingress object, the GKE Ingress controller creates a Google Cloud HTTP(S) load balancer and configures it according to the information in the Ingress and its associated Services.</p> <p>This article describes how to setup Ingress for External HTTP(S) Load Balancing, install cert-manager certificate provisioner and setup up a Let’s Encrypt certificate. This was written based on GKE <a href="https://cloud.google.com/kubernetes-engine/docs/release-notes-stable#february_11_2020">v1.14.10-gke.17</a>, <a href="https://cert-manager.io/">cert-manager</a> v0.13 and <a href="https://helm.sh/">Helm</a> v3.</p> <h2 id="prerequisites">Prerequisites</h2> <ul> <li><a href="https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-cluster">A GKE Kubernetes cluster</a></li> <li><a href="https://helm.sh/docs/intro/install/">Helm</a></li> <li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">Kubectl</a></li> <li><a href="https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address">A global static IP</a> with <a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip#step_4_configure_your_domain_name_records">DNS configured</a> for your domain for example, as example.your-domain.com. Regional IP addresses do not work with GKE Ingress.</li> </ul> <p>Note that a Service exposed through an Ingress must respond to health checks from the load balancer. According to the <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/ingress#health_checks">docs</a>, your app must either serve a response with an HTTP 200 status to GET requests on the / path, or you can configure an HTTP readiness probe, serving a response with an HTTP 200 status to GET requests on the path specified by the readiness probe.</p> <h2 id="create-a-deployment">Create a deployment</h2> <p>Here is an example of a sample deployment manifest.</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sample-deployment</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>1</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>sampleApp</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>sampleApp</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span>-</span> <span>name</span><span>:</span> <span>sampleContainer</span>
        <span>image</span><span>:</span> <span>nginx:1.7.9</span>
        <span>ports</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>http</span>
          <span>containerPort</span><span>:</span> <span>8080</span>
          <span>protocol</span><span>:</span> <span>TCP</span>
        <span>readinessProbe</span><span>:</span>
          <span>httpGet</span><span>:</span>
            <span>path</span><span>:</span> <span>/healthz</span>
            <span>port</span><span>:</span> <span>8080</span>
          <span>initialDelaySeconds</span><span>:</span> <span>5</span>
          <span>periodSeconds</span><span>:</span> <span>5</span>
</code></pre></div></div> <h2 id="create-a-service">Create a service</h2> <p>Here is an example of a sample service manifest.</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-service</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>type</span><span>:</span> <span>NodePort</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>http</span>
      <span>protocol</span><span>:</span> <span>TCP</span>
      <span>port</span><span>:</span> <span>8080</span>
      <span>targetPort</span><span>:</span> <span>8080</span>
</code></pre></div></div> <h2 id="install-cert-manager">Install cert-manager</h2> <p>cert-manager runs within your Kubernetes cluster as a series of deployment resources. It utilizes <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">CustomResourceDefinitions</a> to configure Certificate Authorities and request certificates. The following steps <a href="https://cert-manager.io/docs/installation/kubernetes/">installs cert-manager</a> on your Kubernetes cluster.</p> <ul> <li>Install the CustomResourceDefinition resources separately. <div><div><pre><code>  kubectl apply <span>--validate</span><span>=</span><span>false</span> <span>\</span>
  <span>-f</span> https://raw.githubusercontent.com/jetstack/cert-manager/v0.13.1/deploy/manifests/00-crds.yaml
</code></pre></div> </div> </li> <li>Create the namespace for cert-manager. <div><div><pre><code>  kubectl create namespace cert-manager
</code></pre></div> </div> </li> <li>Add the Jetstack Helm repository. <div><div><pre><code>  helm repo add jetstack https://charts.jetstack.io
</code></pre></div> </div> </li> <li>Update your local Helm chart repository cache.  </li> <li>Install the cert-manager Helm chart. <div><div><pre><code>  helm <span>install</span> <span>\</span>
    cert-manager jetstack/cert-manager <span>\</span>
    <span>--namespace</span> cert-manager <span>\</span>
    <span>--version</span> v0.13.1
</code></pre></div> </div> </li> <li>Verify the installation. <div><div><pre><code>  <span>$ </span>kubectl get pods <span>--namespace</span> cert-manager
  NAME                                       READY   STATUS    RESTARTS   AGE
  cert-manager-5c6866597-zw7kh               1/1     Running   0          2m
  cert-manager-cainjector-577f6d9fd7-tr77l   1/1     Running   0          2m
  cert-manager-webhook-787858fcdb-nlzsq      1/1     Running   0          2m
</code></pre></div> </div> <p>You should see the cert-manager, cert-manager-cainjector, and cert-manager-webhook pod in a Running state. It may take a minute or so for the TLS assets required for the webhook to function to be provisioned.</p> </li> <li>Create an <a href="https://cert-manager.io/docs/concepts/issuer/">Issuer</a> to test the webhook works okay. <div><div><pre><code>  <span>cat &lt;&lt;EOF &gt; test-resources.yaml</span>
  <span>apiVersion</span><span>:</span> <span>v1</span>
  <span>kind</span><span>:</span> <span>Namespace</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>cert-manager-test</span>
  <span>---</span>
  <span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
  <span>kind</span><span>:</span> <span>Issuer</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>test-selfsigned</span>
    <span>namespace</span><span>:</span> <span>cert-manager-test</span>
  <span>spec</span><span>:</span>
    <span>selfSigned</span><span>:</span> <span>{}</span>
  <span>---</span>
  <span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
  <span>kind</span><span>:</span> <span>Certificate</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>selfsigned-cert</span>
    <span>namespace</span><span>:</span> <span>cert-manager-test</span>
  <span>spec</span><span>:</span>
    <span>dnsNames</span><span>:</span>
      <span>-</span> <span>example.com</span>
    <span>secretName</span><span>:</span> <span>selfsigned-cert-tls</span>
    <span>issuerRef</span><span>:</span>
      <span>name</span><span>:</span> <span>test-selfsigned</span>
  <span>EOF</span>
</code></pre></div> </div> </li> <li>Create the test resources. <div><div><pre><code>  kubectl apply <span>-f</span> test-resources.yaml
</code></pre></div> </div> </li> <li>Check the status of the newly created certificate. You may need to wait a few seconds before cert-manager processes the certificate request. <div><div><pre><code>  <span>$ </span>kubectl describe certificate <span>-n</span> cert-manager-test

  ...
  Spec:
    Common Name:  example.com
    Issuer Ref:
      Name:       test-selfsigned
    Secret Name:  selfsigned-cert-tls
  Status:
    Conditions:
      Last Transition Time:  2020-01-29T17:34:30Z
      Message:               Certificate is up to <span>date </span>and has not expired
      Reason:                Ready
      Status:                True
      Type:                  Ready
    Not After:               2020-04-29T17:34:29Z
  Events:
    Type    Reason      Age   From          Message
    <span>----</span>    <span>------</span>      <span>----</span>  <span>----</span>          <span>-------</span>
    Normal  CertIssued  4s    cert-manager  Certificate issued successfully
</code></pre></div> </div> </li> <li>Clean up the test resources. <div><div><pre><code>  kubectl delete <span>-f</span> test-resources.yaml
</code></pre></div> </div> </li> </ul> <p>If all the above steps have completed without error, you are good to go!</p> <h2 id="create-issuer">Create issuer</h2> <p>The Let’s Encrypt production issuer has very strict <a href="https://letsencrypt.org/docs/rate-limits/">rate limits</a>. When you are experimenting and learning, it is very easy to hit those limits, and confuse rate limiting with errors in configuration or operation. Start with <a href="https://letsencrypt.org/docs/staging-environment/">Let’s Encrypt staging</a> environment and switch to Let’s Encrypt production after it works fine. In this article, we will be creating a <a href="https://docs.cert-manager.io/en/release-0.11/reference/clusterissuers.html">ClusterIssuer</a>.</p> <p>Create a clusterissuer definition and update the email address to your own. This email is required by Let’s Encrypt and used to notify you of certificate expiration and updates.</p> <div><div><pre><code><span>cat &lt;&lt;EOF &gt; clusterissuer.yaml</span>
<span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
<span>kind</span><span>:</span> <span>ClusterIssuer</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>letsencrypt-staging</span>
<span>spec</span><span>:</span>
  <span>acme</span><span>:</span>
    <span># The ACME server URL</span>
    <span>server</span><span>:</span> <span>https://acme-staging-v02.api.letsencrypt.org/directory</span>
    <span># Email address used for ACME registration</span>
    <span>email</span><span>:</span> <span>you@youremail.com</span> <span># Update to yours</span>
    <span># Name of a secret used to store the ACME account private key</span>
    <span>privateKeySecretRef</span><span>:</span>
      <span>name</span><span>:</span> <span>letsencrypt-staging</span>
    <span># Enable the HTTP-01 challenge provider</span>
    <span>solvers</span><span>:</span>
    <span>-</span> <span>http01</span><span>:</span>
        <span>ingress</span><span>:</span>
            <span>class</span><span>:</span> <span>ingress-gce</span>
<span>EOF</span>
</code></pre></div></div> <p>Once edited, apply the custom resource:</p> <div><div><pre><code>kubectl apply <span>-f</span> clusterissuer.yaml
</code></pre></div></div> <p>Check on the status of the clusterissuer after you create it:</p> <div><div><pre><code><span>$ </span>kubectl describe clusterissuer letsencrypt-staging

Name:         letsencrypt-staging
...
Status:
  Acme:
    Last Registered Email:  you@youremail.com
    Uri:                    https://acme-staging-v02.api.letsencrypt.org/acme/acct/123456
  Conditions:
    Last Transition Time:  2020-02-24T18:33:56Z
    Message:               The ACME account was registered with the ACME server
    Reason:                ACMEAccountRegistered
    Status:                True
    Type:                  Ready
Events:                    &lt;none&gt;
</code></pre></div></div> <p>You should see the issuer listed with a registered account.</p> <h2 id="deploy-a-tls-ingress-resource">Deploy a TLS Ingress Resource</h2> <p>Create an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">ingress</a> definition.</p> <div><div><pre><code><span>cat &lt;&lt;EOF &gt; ingress.yaml</span>
<span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-ingress</span>
  <span>annotations</span><span>:</span>
    <span># specify the name of the global IP address resource to be associated with the HTTP(S) Load Balancer.</span>
    <span>kubernetes.io/ingress.global-static-ip-name</span><span>:</span> <span>sampleApp-ip</span>
    <span># add an annotation indicating the issuer to use.</span>
    <span>cert-manager.io/cluster-issuer</span><span>:</span> <span>letsencrypt-staging</span>
    <span># controls whether the ingress is modified ‘in-place’,</span>
    <span># or a new one is created specifically for the HTTP01 challenge.</span>
    <span>acme.cert-manager.io/http01-edit-in-place</span><span>:</span> <span>"</span><span>true"</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>tls</span><span>:</span> <span># &lt; placing a host in the TLS config will indicate a certificate should be created</span>
  <span>-</span> <span>hosts</span><span>:</span>
    <span>-</span> <span>example.example.com</span>
    <span>secretName</span><span>:</span> <span>sampleApp-cert-secret</span> <span># &lt; cert-manager will store the created certificate in this secret</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>example.example.com</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>sample/app/path/*</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>sampleApp-service</span>
          <span>servicePort</span><span>:</span> <span>8080</span>
<span>EOF</span>
</code></pre></div></div> <p>Once edited, apply ingress resource.</p> <div><div><pre><code>kubectl apply <span>-f</span> ingress.yaml
</code></pre></div></div> <h2 id="verify">Verify</h2> <p>View certificate.</p> <div><div><pre><code><span>$ </span>kubectl get certificate
NAME                    READY     SECRET                AGE
sampleApp-cert-secret   True      sampleApp-cert-secret   6m34s
</code></pre></div></div> <p>Describe certificate.</p> <div><div><pre><code><span>$ </span>kubectl describe certificate sampleApp-cert-secret
Name:         sampleApp-cert-secret
...
Status:
  Conditions:
    Last Transition Time:  2020-03-02T16:30:01Z
    Message:               Certificate is up to <span>date </span>and has not expired
    Reason:                Ready
    Status:                True
    Type:                  Ready
  Not After:               2020-05-24T17:55:46Z
Events:                    &lt;none&gt;
</code></pre></div></div> <p>Describe secrets created by cert manager.</p> <div><div><pre><code><span>$ </span>kubectl describe secret sampleApp-cert-secret

Name:         sampleApp-cert-secret
...
Type:  kubernetes.io/tls

Data
<span>====</span>
ca.crt:   0 bytes
tls.crt:  3598 bytes
tls.key:  1675 bytes
</code></pre></div></div> <h2 id="switch-to-lets-encrypt-prod">Switch to Let’s Encrypt Prod</h2> <p>Now that we are sure that everything is configured correctly, you can update the annotations in the ingress to specify the production issuer:</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-ingress</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.global-static-ip-name</span><span>:</span> <span>sampleApp-ip</span>
    <span>cert-manager.io/cluster-issuer</span><span>:</span> <span>letsencrypt-prod</span>
    <span>acme.cert-manager.io/http01-edit-in-place</span><span>:</span> <span>"</span><span>true"</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>tls</span><span>:</span>
  <span>-</span> <span>hosts</span><span>:</span>
    <span>-</span> <span>example.example.com</span>
    <span>secretName</span><span>:</span> <span>sampleApp-cert-secret</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>example.example.com</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>sample/app/path/*</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>sampleApp-service</span>
          <span>servicePort</span><span>:</span> <span>8080</span>
</code></pre></div></div> <div><div><pre><code><span>$ </span>kubectl create <span>--edit</span> <span>-f</span> ingress.yaml
ingress.extensions <span>"sampleApp-ingress"</span> configured
</code></pre></div></div> <p>You will also need to delete the existing secret, which cert-manager is watching. This will cause it to reprocess …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kosyfrances.github.io/ingress-gce-letsencrypt/">https://kosyfrances.github.io/ingress-gce-letsencrypt/</a></em></p>]]>
            </description>
            <link>https://kosyfrances.github.io/ingress-gce-letsencrypt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555628</guid>
            <pubDate>Mon, 28 Dec 2020 00:46:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mobile-First (and why it's a bad idea)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555623">thread link</a>) | @taphangum
<br/>
December 27, 2020 | https://planflow.dev/blog/why-mobile-first-is-a-bad-idea | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/why-mobile-first-is-a-bad-idea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>(This article was originally published in </em><a target="_blank" title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>How To Debug CSS</em></a><em>)</em></p><p>While I could always understand the idea behind the mobile-first approach to developing websites. It always felt….off to me.</p><p>Mobile-first, which is a design approach that involves starting with the mobile version of a website before the desktop version, is a great idea in theory.&nbsp;</p><p>The problem comes when it meets reality.</p><p>There are countless stories of developers who, upon hearing about (and even learning how to design with) a mobile first approach, ultimately ended up reverting back to, and starting with the desktop versions of their sites.</p><p>According to a <a target="_blank" title="https://twitter.com/KevinJPowell/status/1244427032957784066" href="https://twitter.com/KevinJPowell/status/1244427032957784066">survey</a> conducted by Kevin Powell (a GREAT frontend tutorial maker), the majority (61.5%) of developers prefer to start with the desktop first:</p><p><img src="https://media.graphcms.com/gkrvHBiXR3ON7pcIkwSG" alt="Screenshot 2020-12-27 at 22.39.13.png" title="Screenshot 2020-12-27 at 22.39.13.png" width="597" height="413"></p><p><em><strong>(this after almost 8 years of the mobile-first approach being championed almost exclusively)</strong></em></p><p>This is a sentiment that I have also found to be true on many message boards and online discussions that I’ve seen around responsive web design.</p><p>It is interesting that despite this clear evidence that the majority of developers simply do not inherently want to design websites with a mobile-first approach, the idea is still being championed as the preferred methodology.</p><p>Let’s explore why this is.</p><h2>Why Mobile-First is often championed</h2><p>There are two main reasons why the mobile-first approach is often touted as the best approach to take for developing a responsive website:</p><p>	<strong>1.	Better UX, at every screen size </strong></p><p>The first is that it provides a better user experience at every screen size, because it best optimizes for the smaller screen sizes as well as the larger ones. The argument is that it does this by focusing on only the most important elements of the layout, as that is all that can fit on the smaller mobile screens. And that this focused approach ‘scales up’.</p><p>The trouble with this is that it simply does not seem to hold up to scrutiny.&nbsp;</p><p>What actually seems to end up happening with mobile-first is that the overall site just becomes less creative in general.&nbsp;</p><p>Most mobile sites (and their subsequent desktop sites) end up simply looking the same as every other website out there.</p><p>We’ll see why this is the case shortly (the diagram at the top of this post will give you an idea).</p><p>	<strong>2.	Better organized (and easier to create) CSS </strong></p><p>The second reason why mobile-first is often regarded as the best way to develop a responsive website is that on most sites, the ‘default’ CSS styles (i.e. the styles that are written outside of the scope of media queries) are often the ones that are aimed at the smaller, mobile screen sizes.&nbsp;</p><p><strong>Typical CSS file organization for a responsive website:</strong></p><p><img src="https://media.graphcms.com/output=format:png/resize=height:748,width:996/sPcNpTKARkKzOUO3KzZ4" alt="typical-css-responsive-file.png" title="typical-css-responsive-file.png" width="996" height="748"></p><p>Because the typical CSS workflow of a responsive website is to add the media query related styles after the fact (because media queries are supposed to be at the bottom of the page, as mentioned above), starting with what would be your ‘default’ styles, which would be your mobile styles, seems to make more sense.</p><p>We will also shortly see why this is not exactly correct.</p><p>Let’s dive into the key reasons why, despite these two decent arguments in favor of a mobile-first approach to responsive web design, it still is not the best way to approach it.</p><h2>Why mobile-first is good in theory but bad in practice</h2><h3>You are optimizing for the sub-optimal experience</h3><p>The mobile experience <em>is</em> sub-optimal. This is not a point that is really debated. The entire point of a mobile version of a site is to deliver a lesser, but still somewhat effective version of the optimal desktop experience.</p><p>The problem with optimizing for the mobile experience, is that it does not make the overall experience optimal. It only scales up sub-optimality. The compromises that start on the mobile experience ultimately become compromises on the desktop end.</p><p><strong>It only degrades the desktop experience.</strong></p><p>The desktop site is the ‘real’ site in most cases, <a target="_blank" title="https://www.reddit.com/r/webdev/comments/d7nj58/how_do_you_deal_with_mobile_first_and/" href="https://www.reddit.com/r/webdev/comments/d7nj58/how_do_you_deal_with_mobile_first_and/">most clients</a> expect to see a desktop site first.</p><p>Desktop-first focuses on the design problem that people actually care about, while mobile-first focuses on the CSS organization problem, which only developers do.</p><p>Instead of starting with the sub-optimal experience (that helps the developer), it’s much better overall to optimize for the optimal experience (that helps the user) and then scale down.</p><h3>It’s an unnatural way to design</h3><p>Because design is an intuitive process fundamentally, any design approach that requires you to have to ‘get over yourself’ is probably a bad idea.</p><p>Design is basically a process of guiding the user, by developing an interface based on what guides <em>you</em>, naturally.</p><p>For this to be effective, context is key, and being able to maximally utilize the scope of experience that the user has, gives you more ‘surface area’ with which to appropriately meet the context and guide the user.</p><p>For this reason, It’s better to start at the ‘largest’ possible context for this.&nbsp;</p><p>For example, for a professional sports match. What has a better chance of delivering the ‘fullest’, more complete experience to you?&nbsp;</p><p><strong>The actual, ‘bigger’, more natural, live game:</strong></p><p><img src="https://media.graphcms.com/p5ESEubnQNKm7eEPdLmR" alt="man-290186_1920.jpg" title="man-290186_1920.jpg" width="1920" height="1275"></p><p><strong>Or the TV experience?</strong></p><p><img src="https://media.graphcms.com/qUwYVApRW22XXnKOCOqd" alt="soccer-3496510_1920.jpg" title="soccer-3496510_1920.jpg" width="1920" height="1280"></p><p><em><strong>What should be optimized for first to deliver the best final result in both cases?</strong></em></p><p>The Desktop experience encompasses what is essential information within a mobile context. Mobile does not necessarily have what is essential to a desktop context.</p><p>This is why desktop-first <a target="_blank" title="https://www.reddit.com/r/webdev/comments/cy1xuk/do_you_feel_like_desktop_web_dev_is_fun_and/" href="https://www.reddit.com/r/webdev/comments/cy1xuk/do_you_feel_like_desktop_web_dev_is_fun_and/">seems to feel more natural</a> to most developers. It’s just enough constraint for the task of navigating a website, but not too much.</p><p>Leaving an ideal amount of room for creativity. Which mobile-first kills.</p><h3>Mobile-first kills creativity</h3><p>With mobile-first, there are too many unanswered questions.</p><p>Questions that should have been answered at the desktop level, ultimately never get answered.</p><p>At the desktop level, the challenges are often much bigger, and require more creativity to solve. Because the questions you need to ask at smaller screens are simply fractals (or subsets) of their larger counterparts, It’s much better to answer them first at the larger sizes, which then makes it easier to answer subsequent smaller size and mobile design questions.</p><p>With a mobile-first approach, you can fall into the trap of getting so fixated on the subsets that you fail in giving people the essence of the page. This essence is what the initial answers to the bigger design questions give you.</p><p>To get that essence, in the same way that you would have to crush grapes at scale, and then gradually go through a distillation process to finally achieve a wine. To get a mobile site that really gets to the core of a site, its best to start with the desktop version. And then gradually filter or scale down.</p><h3>Mobile-First makes design too formulaic</h3><p>Because of the degree of constraint in the mobile-first approach, and the lack of room for creativity that this engenders, developers naturally seek out tried and true patterns that they can follow.&nbsp;</p><p>This isn't a bad thing, as we all use inspiration to a degree. The issue is that, just as we’ve seen with frameworks like Bootstrap. Too much of a formulaic approach often leads to a level of sameness that literally bores everyone.</p><p>Mobile-first may be one the things contributing to the ever increasing ‘sameness’ of the web that we see nowadays.</p><p>This consequently reduces the kind of web activity that we want (such as conversions) across the board. People are simply less engaged, and tuning these websites out.</p><p>Imagine if those ever-quirky and endlessly interesting sites of the late 90’s, early 2000’s like the ones we used to find on GeoCities and Angelfire were thinking about ‘mobile first’.&nbsp;</p><p>Do you think they would have achieved the same level of uniqueness? I doubt it.</p><h2>An alternative (desktop-first) approach</h2><p>The mental shift that we should make is not desktop to mobile first.</p><p>It's not to simply squish things on the desktop either.</p><p>The correct mental shift is to say, once we have a desktop version, what do we need to resize, rearrange, or remove in order to have an optimal yet still equally informative experience on mobile?</p><p>We should be asking how we can make the mobile experience a good fractal of the desktop experience.&nbsp;</p><p>We should ask what we are trying to achieve with our desktop site, and how we can achieve (even if only a little bit) the same on smaller screens.</p><p>The way that we should design our websites should be to start with the desktop first, and then scale down with empathy, asking the big designs questions before we start to ask the smaller ones.</p><p>We should start our web design process at the bottom of the CSS file, with the desktop sized media query, instead of making those first global (mobile-first) styles.&nbsp;</p><p>After that, once we have answered our biggest design questions at the desktop level, we can scale down (and up in the code) with more media queries (in the case of the smaller sizes) and with the default global styles in the case of the absolute smallest mobile size. Taking out all but the necessary.&nbsp;</p><p>Ultimately, this feels like the most natural approach to take.</p><p>--</p><p><em>This is an excerpt from </em><a title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>How To Debug CSS</em></a><em>. A book that’s written to solve the problem outlined in this post. To help take you from a vague level of understanding with CSS, to an intuitive, know it like the back of your hand level of understanding. Enabling you to not only create layouts with ease, but to debug any issues that come up with them as you do so.</em></p><p><em>The book is currently available for pre-order with a temporary (40%!) pre-launch discount on the link above. You may purchase by clicking on the link above! Or by clicking here: </em><a title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>“How To Debug CSS”</em></a><em>.</em></p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/why-mobile-first-is-a-bad-idea</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555623</guid>
            <pubDate>Mon, 28 Dec 2020 00:46:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NZBgeek Hack: Breached Passwords and Credit Cards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555165">thread link</a>) | @w3abhishek
<br/>
December 27, 2020 | https://innovativebeast.com/nzbgeek-hack-breached-passwords-and-credit-cards/ | <a href="https://web.archive.org/web/*/https://innovativebeast.com/nzbgeek-hack-breached-passwords-and-credit-cards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-container">

<main id="main" itemscope="itemscope" itemtype="https://schema.org/CreativeWork">
<div data-sidebar="right" data-v-spacing="top:bottom" data-structure="classic:boxed">
<section>
<article id="post-3843">
<section data-type="type-1">

</section>
<div>
<p>NZBgeek is a very popular community-based indexer of Usenet posts. It is run by using the Newznab Interface. NZBgeek provides paid and free services for its own users, plus so they truly have been reasonable to think about.</p>
<p>On the evening of 27 December 2020, NZBgeek announced that they got hacked and the following details of their users are breached in this hacking attack on their community website:</p>
<ol>
<li>Username</li>
<li>Encrypted passwords</li>
<li>Email Address</li>
<li>Credit Card Numbers</li>
</ol>
<h3 id="rtoc-1">How this Attack was Performed?</h3>
<p>According to the announcement post by @Dangerous_Mummy and @jeeves in their Discord server, this attack and data breach happened because the attacker installed a Keylogger on the website of NZBgeek.</p>
<p>@Dangerous_Mummy written:</p>
<blockquote><p><span tabindex="-1" role="button">@everyone</span> Geeks, it’s with a heavy heart that we must admit that we have had a breach. If you have recently used your card or payment with us we suggest changing your credentials and card info as soon as possible. We still don’t know the extent of the damage but are working to find out and give our members the details as they become available.</p></blockquote>
<p>@jeeves written:</p>
<blockquote><p>@everyone</p>
<p>Hey Geeks,</p>
<p>IMPORTANT!</p>
<p>If you have used your card with us since the 20th November 2020 please take appropriate action.<br>
This includes reporting it to your card issuer as this protects you from any unlawful charges.</p>
<p>What We Know:</p>
<p>The hackers were able to place a keylogger on the website.<br>
The hackers obtained a copy of our database which includes your username, encrypted password, email address &amp; last connected ip address.<br>
During this time we had the hard drive on our indexer fail along with an api server.<br>
PayPal data is not at risk provding you do not use the same username/password for NZBgeek.</p>
<p>Advised Actions:</p>
<p>If you use the same userame/password combination on any other website please change them.<br>
You should use 2FA/two factor authticaition with all your online accounts.</p>
<p>Current Situation:</p>
<p>We have everything offline except for the API while we have external help to investigate.<br>
Additional updates will be made here on discord, including what changes to expect moving forward.</p>
<p>Thanks,<br>
jeeves</p></blockquote>
<p>It is one of the major data breaches because the payment information is breached and is available in the hands of attackers.</p>
<p><img loading="lazy" src="https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113103.jpg" alt="" width="767" height="450" srcset="https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113103.jpg 767w, https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113103-300x176.jpg 300w" sizes="(max-width: 767px) 100vw, 767px"><br>
<img loading="lazy" src="https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113116.jpg" alt="" width="767" height="311" srcset="https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113116.jpg 767w, https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113116-300x122.jpg 300w" sizes="(max-width: 767px) 100vw, 767px"></p>
<h3 id="rtoc-2">What actions users should take?</h3>
<ol>
<li>If you use the same password on multiple accounts, immediately change the passwords of all your accounts</li>
<li>Contact your credit card provider and block your card to stop further unauthorized transactions</li>
<li>Use 2FA on all of your websites/accounts whenever possible.</li>
</ol>
<p><span data-ez-name="innovativebeast_com-medrectangle-1"><span><span><a href="https://www.ezoic.com/what-is-ezoic/" target="_blank" rel="noopener noreferrer nofollow"><img src="https://go.ezoic.net/utilcave_com/img/ezoic.png" alt="Ezoic"></a></span></span></span>
</p> </div>

</article>
</section>

</div>


</main>
</div></div>]]>
            </description>
            <link>https://innovativebeast.com/nzbgeek-hack-breached-passwords-and-credit-cards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555165</guid>
            <pubDate>Sun, 27 Dec 2020 23:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons I’ve learned after 10 years and $10M in sales]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25555137">thread link</a>) | @rookhack
<br/>
December 27, 2020 | https://jamesclift.ca/7-things-ive-learned-after-10-years-of-trying-to-make-it-on-the-internet-2bbd8b60f5a?source=friends_link&sk=fe41337b9e6efa39a7ba9c297338c3b7 | <a href="https://web.archive.org/web/*/https://jamesclift.ca/7-things-ive-learned-after-10-years-of-trying-to-make-it-on-the-internet-2bbd8b60f5a?source=friends_link&sk=fe41337b9e6efa39a7ba9c297338c3b7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://jamesclift.medium.com/?source=post_page-----2bbd8b60f5a--------------------------------" rel="noopener"><img alt="James Clift" src="https://miro.medium.com/fit/c/96/96/1*Ax3-HNLKsss3ruWjpgvpXg.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="9d97">I’ve been playing the technology company game for over a decade now.</p><p id="63cf">In that time, I went from a 20 year old kid who had no idea what he was doing to a man with a good beard who has no idea what he is doing that happened to sell millions of dollars of software.</p><p id="b011">I don’t often reflect on absurdity of it, but it is absurd.</p><p id="36c0">Weirder still, I’m the least impressive of my friends in this world — I’ve had the good fortune of being surrounded by people who started off exactly like I did build massive companies with hundreds of employees.</p><p id="ce22">As a kid, the only jobs I knew of that “rich” people had were doctor, lawyer, and that scary kid who’s dad was probably in the mob. Becoming a millionaire was not discussed, nor even imagined. Yet, here we are.</p><p id="acdf">Here are a few things I’ve learned from a decade of trying to make it on the internet.</p><p id="bcf1">The low point of (one of) my first companies was being so desperate for revenue that we adapted our<em> virtual job fair</em> platform to become a virtual business directory for a small town. For $2000/yr.</p><p id="6385">There is no upside to that. We essentially became a horribly paid consultant for an industry we didn’t care about with a product that didn’t add any value.</p><p id="f2cc">Limping along for years while eating ramen and pitching a VISION isn’t success — you’ll be much worse off than if you had just worked for a startup for a few years to improve your skills and peers.</p><p id="ce0b">To truly bet on yourself while starting a company, everything you do should accelerate any of the following:</p><ul><li id="bc69">Learning new skills: sales, product management, product development, engineering, marketing, design, fundraising</li><li id="12a6">Meeting great people — not in the “I shook Mark Cuban’s hand” sense, but in the “I have 5 equally motivated people in my corner building shit that I can text about the fact that we won’t make payroll next month.”</li><li id="c5c2">Making money on your own time</li><li id="00e0">Travelling or experiencing the world through a different lens (though in 2020 you should just get a remote job)</li></ul><p id="ae33">You don’t need mentors. You don’t need investors. You need 5 friends with similar ambitions trying to figure this shit out with you.</p><p id="537b">You want people that you can call when your world is falling apart. When you want to quit. When you hate your co-founders. When you’re questioning everything. When you’ve made the money, but don’t feel good about it.</p><p id="8018">It is a weird, un-relatable world that we’re playing in. To navigate it, you need people that understand. I’m so lucky I found my people.</p><p id="1451">I don’t have great advice on how to find your people.</p><p id="c46f">Join a co-working space? Get into a startup accelerator? Join a program like <a href="https://www.beondeck.com/" rel="noopener">On Deck</a>? Message people on Twitter?</p><p id="64cd">I know many people who are much more talented than I. They’ve got better ideas, more technical skills, and are just plain smarter.</p><p id="1d7d">What they don’t have is that forcing function that compels me to launch stuff.</p><p id="7bb3">The shamelessness. The not-give-a-fuckery.</p><p id="2ae5">To not quit when I want to quit. I’m not sure that “chip on the shoulder” is all positive, but it’s probably necessary.</p><p id="aaf9">It’s a learned behaviour. I don’t come by it naturally. I hate failing. I suck at getting feedback. I’m overly sensitive. And yet, here we are.</p><p id="cccf">Every successful individual I’ve seen has taken at least 3 years to create something with some hint of product market fit.</p><p id="1a79">Dig deeper into every company that takes off overnight — it’s probably a pivot from something else, the founder’s 8th attempt, or a hail mary. The one thing that truly worked for me was about 3.5 years in.</p><p id="8fb0">That specific thing worked in month 2, but it took 3.5 years of learning to get to that point.</p><p id="2606">My original goal when starting out (Thanks Tim Ferriss!) was to <em>“build a business making 10k a month so I could work from anywhere.”</em></p><p id="b9da">I got there, and enjoyed it — lived in multiple countries, didn’t work too much, drank great wine and ate incredible steak. It wasn’t enough.</p><p id="9d82">Financially, it didn’t matter. The cash was enough, but a life of leisure isn’t a great goal for a 30 year old. I stopped growing, learning.</p><p id="0969">Ironically, that guiding goal held me back. What seemed ambitious at the time led to unambitious decisions, like first building a below average web design company. It also led to coasting when cashflow was (very) good.</p><p id="cdd3">I somehow managed to reverse engineered my version of success, but unfortunately financial success is always a moving target — especially once you have something that works.</p><p id="0d0a">What would have been a better focus is building an exceptional product, an amazing team, and continuing to grow as a leader.</p><p id="65c1">If you can solve for those things, the score (and the cash) takes care of itself.</p><p id="6a9b">That said, if your goal is to build a company that makes 10k/mo that allows you to work from anywhere — go for it, goddamnit.</p><p id="38f1">Building something from scratch is hard, and having a job will often sound very appealing.</p><p id="9e48"><em>Here’s what you need to do today, and here’s your paycheque!</em></p><p id="a7a7">Starting a company has infinite variables. At the early stages, you’re pushing a boulder up every hill you can find. You’re trying to find that one thing that gathers enough momentum to allow you to survive another day.</p><p id="664a">If you’re lucky, you’ll get to a place where you’re no longer trying to survive — you’re trying not to die. There’s a difference.</p><p id="6c93">Every day you will have an infinite to-do list, none of which is certain.Take your best guess at what the most important thing you can work on is.</p><p id="6202">Do that thing, and try to ignore everything else.</p><p id="ee2b">Don’t forget to manage your psychology along the way. At the end of the day no one cares if you fail, and it’s not that important. Have grounding forces in your life (sports, family, knitting) to help keep you sane. Try not to build your whole identity around your company.</p><p id="950c">(You won’t do any of this, but I’m hopeful this will help you realize you’re not the only one.)</p><p id="6c90">Most people who reach unheard of levels of success are probably not that much smarter than you, and they probably don’t work that much harder.</p><p id="d7fd">Granted, there are ridiculously smart driven people that operate on another level (Elon Musk, The Collisons). They’re likely going to be trillionaires.</p><p id="7870">I’ve met many people who have built $100m+ companies that are very smart and work very hard — but probably not that much harder than a Senior Engineer at Amazon. Success is a result of talent, hard work, and luck.</p><p id="3b30">If you’re smart, want to work hard, and care about building a business one day — the best place to put that energy is into creating something new.</p><p id="7ac5">You can’t get lucky if you’re not in the game.</p></div></div></section></div>]]>
            </description>
            <link>https://jamesclift.ca/7-things-ive-learned-after-10-years-of-trying-to-make-it-on-the-internet-2bbd8b60f5a?source=friends_link&amp;sk=fe41337b9e6efa39a7ba9c297338c3b7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555137</guid>
            <pubDate>Sun, 27 Dec 2020 23:27:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking German Elections [video]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554963">thread link</a>) | @manfredz
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11440-hacking_german_elections | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11440-hacking_german_elections">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Johannes">Johannes</a> and
<a href="https://media.ccc.de/search?p=Tobias">Tobias</a>

</p>

<p><a href="https://media.ccc.de/c/rc3/rC3" rel="tag">rC3</a>
<a href="https://media.ccc.de/c/rc3/IT-Security" rel="tag">IT-Security</a>
Playlists:
<a href="https://media.ccc.de/v/rc3-11440-hacking_german_elections/playlist">'rc3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/rc3-11440-hacking_german_elections/audio">audio</a></p>
<!-- %h3 About -->
<p>After the first unsuccessful deployment of voting machines in Germany about ten years ago, elements of electronic voting have reached elections again. Although there is now still a paper-trail, more and more essential steps, such as counting the votes, are moved into electronic systems. This change in the ballot-counting procedure took place mostly unnoticed by the public. We are two very concerned election workers who present our first-hand experience in this talk. We show that the current digital procedure is conceptually and practically flawed in terms of security. First, we give an insight into the role of computers and their interaction with humans during ballot-counting. We show that the underlying system concepts contradict IT-security best-practices. Next, we present an in-depth analysis of one ballot-counting software, deployed for the Bavarian municipal elections ("Kommunalwahlen"). We discovered several severe security vulnerabilities that allow an almost unnoticeable manipulation of local voting results. Finally, we conclude that there is an immediate need for action to re-establish election security and transparency - not only for the government but for everyone of us.</p>

<p>Elections are a key element of every democracy. However, many democratic countries in the world have to face attacks on them, be it by the government or by foreign countries. Even if ballot counting has been finished, election results are often not accepted but questioned due to alleged manipulations. All these aspects pose major threats to democracy as they try to undermine the actual and publicly perceived integrity of elections.</p>

<p>In Germany, elections are usually considered quite secure. Elections are paper-based and the subsequent ballot-counting is open to the public. The infamous introduction of electronic voting machines about ten years ago was finally stopped by the German Federal Constitutional Court. Thus, everything is human-controlled, transparent, and secure – isn’t it?</p>

<p>Unfortunately, these claims are questionable since the silent introduction of electronic vote counting. The election system in Germany is quite complex, for example in the "Kreistagswahlen" (~district elections) workers have to count up to 70 individual votes per ballot, while respecting a special rule set. This process is very labor-intensive and sufficient election workers are often hard to come by. Due to this, electronic systems were introduced that provide support during vote counting. Election workers are no longer required to fill tally sheets, count votes, and sum them up on their own. Each ballot is simply entered into a software that performs all the magic and finally emits a result.</p>

<p>This year, we volunteered again as election workers, but our trust in electronically-assisted elections has been vastly impacted. As IT-security researchers, we consider it our responsibility to share and discuss our concerns. We performed a thorough analysis of the concept and the hard- and software of the electronic vote counting system. We discovered several flaws on a conceptual and practical level, that can severely diminish the integrity of the election and makes it prone to manipulations. To underline the impact of the system’s vulnerabilities, we demonstrate an exemplary attack on an election.</p>

<p>Finally, we propose different options on how to make elections secure again. We do not consider this an entirely technical case, as there are significant legal and societal circumstances that led to the deployment of this insecure system.</p>

<h3>Download</h3>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div></div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11440-hacking_german_elections</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554963</guid>
            <pubDate>Sun, 27 Dec 2020 22:51:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we write Elementary apps in Vala (2014)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554949">thread link</a>) | @silasdb
<br/>
December 27, 2020 | https://blog.elementary.io/why-we-write-elementary-apps-in-vala/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/why-we-write-elementary-apps-in-vala/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   A tremendously effective tool for our&nbsp;needs

</h2>
    

    






    


  </header>

  <section>
    <figure>
  <p><img src="https://cdn-images-1.medium.com/max/2000/1*zqydEido_Yipr0YiJv5hYg.png" alt=""></p>
</figure>

<p>If you follow elementary OS development, you may know that we do not write our applications on C or Python, but rather a language called <a rel="nofollow noopener noreferrer" target="_blank" href="https://wiki.gnome.org/Projects/Vala">Vala</a>. While it is true that a more mainstream language would lower the barrier to entry for new first-party and third-party developers, Vala has proven to be a tremendously effective tool for our needs.</p>

<p>Vala is an object-oriented programming language developed by the <a rel="nofollow noopener noreferrer" target="_blank" href="https://www.gnome.org/">GNOME Foundation</a>, which was first released in 2006. Syntax-wise, Vala looks and acts very similarly to Java or C#, which makes it easy for new contributors to leverage their knowledge and experience from other languages. Vala’s clear syntax and tight coupling with the strongly-typed GObject system promotes highly readable, expressive, and maintainable code, while preventing entire classes of crashes and bugs.</p>

<p>Since Vala compiles to C (and then into binary), we gain access to a large number of bindings for libraries written in C. This is extremely important given the number of C libraries available for the Linux desktop. All of our desktop applications are written using the <a rel="nofollow noopener noreferrer" target="_blank" href="https://www.gtk.org/">GTK</a> toolkit, and many rely heavily on related GObject-based libraries, including Gee, WebKitGTK, VTE, and GStreamer. Bindings for dozens of popular GObject C libraries exist, and writing new ones is easy.</p>

<p>Before we adopted Vala, we wrote our desktop applications in Python. As both a language and a platform, Python made developing apps quick and easy. However, this ease of development came at a serious cost — performance, binding support, and maintainability became major pain points for us with Python. Worse, the slow and fragmented adoption of Python 3 over Python 2, particularly across Linux distributions, made packaging our apps and developer tools for different environments tedious and challenging. Vala’s native binaries have proven to be a better fit for us.</p>

<figure>
  <p><img src="https://cdn-images-1.medium.com/max/2000/1*HjaeSVLblDtdCwOkBR2xcA.png" alt="A Simple GTK Application in&nbsp;Vala"></p>
  <figcaption>A Simple GTK Application in&nbsp;Vala</figcaption>
</figure>

<p>Because Vala is developed by the same incredible folks who make GTK, integration between Vala and GTK is tight. Extending GTK with Vala has also proven successful. In fact, we’ve crafted our own set of widgets that build on and complement what GTK provides by default. This super-set of GTK, called <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/elementary/granite">Granite</a>, is at the heart of nearly every elementary application, and Vala’s excellent object-oriented inheritance system, among other sophisticated language features, have been key to our development.</p>

<p>Vala has excellent documentation, be it in the form of <a rel="nofollow noopener noreferrer" target="_blank" href="https://chebizarro.gitbooks.io/the-vala-tutorial/content/">tutorials</a>, <a rel="nofollow noopener noreferrer" target="_blank" href="https://wiki.gnome.org/Projects/Vala/Examples">code samples</a> or a <a rel="nofollow noopener noreferrer" target="_blank" href="https://valadoc.org/">very easy-to-use API Reference</a>. So if you’re interested in <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved">hacking on our projects</a> (which we very much appreciate — we are always looking for new contributors!), or are planning to release fantastic third-party desktop applications for elementary OS, we can’t recommend Vala enough. Dive in!</p>

  </section>

  
<div>
  <hr>

  <h2>Thank You</h2>
  <p>Thanks to all of our supporters, backers, and customers! Your contributions make elementary possible. If you’d like to help build and improve elementary OS, don’t hesitate to <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved" onclick="plausible('Link: Get Involved')">Get Involved</a>.</p>

  
</div>




</article></div>]]>
            </description>
            <link>https://blog.elementary.io/why-we-write-elementary-apps-in-vala/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554949</guid>
            <pubDate>Sun, 27 Dec 2020 22:49:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2-Acre Vertical Farm Run by AI and Robots Out-Produces 720-Acre Flat Farm]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 233 (<a href="https://news.ycombinator.com/item?id=25554941">thread link</a>) | @wrycoder
<br/>
December 27, 2020 | https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/ | <a href="https://web.archive.org/web/*/https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><a href="https://www.plenty.ag/" target="_blank" rel="noopener">Plenty</a> is an ag-tech startup in San Francisco, co-founded by Nate Storey, that is reinventing farms and farming. Storey, who is also the company’s chief science officer, says the future of farms is vertical and indoors because that way, the food can grow anywhere in the world, year-round; and the future of farms employ robots and AI to continually improve the quality of growth for fruits, vegetables, and herbs. Plenty does all these things and uses 95% less water and 99% less land because of it.</p>
<p>In recent years, farmers on flat farms have been using new tools for making farming better or easier. They’re using drones and robots to improve crop maintenance, while artificial intelligence is also on the rise, with over 1,600 startups and total investments reaching tens of billions of dollars. Plenty is one of those startups. However, flat farms still use a lot of water and land, while a Plenty vertical farm can produce the same quantity of fruits and vegetables as a 720-acre flat farm, but on only 2 acres!</p>
<p>Storey said:</p>
<blockquote><p>Vertical farming exists because we want to grow the world’s capacity for fresh fruits and vegetables, and we know it’s necessary.</p></blockquote>
<p><span><iframe width="1400" height="788" src="https://www.youtube.com/embed/GO0fRU46ZHc?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
<p>Plenty’s climate-controlled indoor farm has rows of plants growing vertically, hung from the ceiling. There are sun-mimicking LED lights shining on them, <a href="https://www.intelligentliving.co/tiny-smart-robots-kill-weeds/">robots</a> that move them around, and artificial intelligence (AI) managing all the variables of water, temperature, and light, and continually learning and optimizing how to grow bigger, faster, better crops. These futuristic features ensure every plant grows perfectly year-round. The conditions are so good that the farm produces 400 times more food per acre than an outdoor flat farm.</p>

<p>Storey said:</p>
<blockquote><p>400X greater yield per acre of ground is not just an incremental improvement, and using almost two orders of magnitude less water is also critical in a time of increasing environmental stress and climate uncertainty. All of these are truly game-changers, but they’re not the only goals.</p></blockquote>
<p>Another perk of vertical farming is locally produced food. The fruits and vegetables aren’t grown 1,000 miles away or more from a city; instead, at a warehouse nearby. Meaning, many transportation miles are eliminated, which is useful for reducing millions of tons of yearly CO2 emissions and prices for consumers. Imported fruits and vegetables are more expensive, so society’s most impoverished are at an extreme nutritional disadvantage. Vertical farms could solve this problem.</p>
<p>Storey said:</p>
<blockquote><p>Supply-chain breakdowns resulting from COVID-19 and natural disruptions like this year’s California wildfires demonstrate the need for a predictable and durable supply of products can only come from vertical farming.</p></blockquote>
<figure id="attachment_39422" aria-describedby="caption-attachment-39422"><img loading="lazy" src="https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=1024%2C576&amp;ssl=1" alt="2-Acre Vertical Farm Run By AI And Robots Out-Produces 720-Acre' Flat Farm'" width="1024" height="576" srcset="https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=960%2C540&amp;ssl=1 960w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=711%2C400&amp;ssl=1 711w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=585%2C329&amp;ssl=1 585w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption id="caption-attachment-39422">(Credit: Reuters)</figcaption></figure>
<p>Plenty’s farms grow non-GMO crops and don’t use herbicides or pesticides. They recycle all water used, even capturing the evaporated water in the air. The flagship farm in San Francisco is using 100% renewable energy too.</p>
<p>Furthermore, all the packaging is 100% recyclable, made of recycled plastic, and specially designed to keep the food fresh longer to reduce food waste.</p>
<p>Storey told <a href="https://www.forbes.com/sites/johnkoetsier/2020/11/20/this-2-acre-vertical-farm-out-produces-750-acre-flat-farms/" target="_blank" rel="noopener">Forbes</a>:</p>
<blockquote><p>The future will be quite remarkable. And I think the size of the global fresh fruit and vegetable industry will be multiples of what it is today.</p></blockquote>
<p>Plenty has already received $400 million in investment capital from SoftBank, former Google chairman Eric Schmidt, and Amazon’s Jeff Bezos. It’s also struck a deal with Albertsons stores in California to supply 430 stores with fresh produce.</p>
<p>Ideally, the company will branch out, opening vertical farms across the country and beyond. There can never be too many places graced by better food growing with a less environmental cost.</p>
<p>Here’s a <a href="https://anchor.fm/techfirst/episodes/The-future-of-farms-is-vertical-400X-more-yield--95-less-water--99-less-space-emesrq/a-a3sf2o5" target="_blank" rel="noopener">TechFirst podcast</a> about the story behind Plenty:</p>

<p><span><iframe width="1400" height="788" src="https://www.youtube.com/embed/0uXdnjXIGjI?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
<!-- AI CONTENT END 2 -->
</div></div>]]>
            </description>
            <link>https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554941</guid>
            <pubDate>Sun, 27 Dec 2020 22:47:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resolving the Time Paradox Implied by Functional Programs]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25554907">thread link</a>) | @jbmilgrom
<br/>
December 27, 2020 | https://softwarefordays.com/post/resolving-the-fp-time-paradox/ | <a href="https://web.archive.org/web/*/https://softwarefordays.com/post/resolving-the-fp-time-paradox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      

<p>Excerpted from <a href="https://softwarefordays.com/post/functional-programming-and-identity-state-and-time/#resolving-the-time-paradox">Functional Programming and the Semantics of Change, State &amp; Time</a>.</p>
<blockquote>
<p>“No man can ever cross the same river twice.” Because what’s a river? I mean, we love this idea of objects; like there’s this thing that changes. Right? There’s no river. Right? There’s water there at one point-in-time. And another point-in-time, there’s other water there. — Rich Hickey, <a href="https://github.com/matthiasn/talk-transcripts/blob/master/Hickey_Rich/AreWeThereYet.md">Are We There Yet</a>, quoting Heraclitus.</p>
</blockquote>
<p>From the perspective of a user, a functional program may appear stateful. Interact with <a href="https://softwarefordays.com/post/functional-programming-and-identity-state-and-time/#stateful-functional-programs">the functional ATM program above</a> and notice the program remembering previous encounters. On the one hand, this is not surprising. We included an imperative layer to remember previous states. Instead of decomposing the state of the program into distinct objects, like <code>bankAccount</code> and <code>withdrawalAmount</code>, we created a single global object, the <code>store</code>. On the other hand, focusing on the “object” portion of the program betrays an object-oriented predisposition. The imperative piece of the program is merely a construct used to facilitate a computation based asynchronously on another. One can even imagine a programming language where such a construct is built into the language itself, hiding any imperative implementation from the programmer’s view. In fact, such a language exists that compiles to JavaScript.<sup><a href="#fn1" id="fnref1">[1]</a></sup> In other words, it is syntax, not semantics. The semantics of the program better align with the semantics of a recursive, iterative function, having state <code>S</code> at a discrete step <code>i</code> — run the functional ATM program with the output of the previous run to produce the input for the next.</p>
<p>That a program with a functional, stateless and timeless core can maintain state is surprising, to say the least. Look around the room, bus, park or wherever you find yourself reading this sentence, and you will likely identify “a collection of distinct objects,” such as dogs, people, and trees, “whose behaviors may change over time.” Look around the functional ATM program, on the other hand, and there are no identifiable objects to be found. Yet, the program appears to have state just like any other object in the room.</p>
<p>However, the ostensible “paradox” dissipates when the augmentation of our conception of time extends beyond the functional program to include the rest of our physical reality.</p>
<blockquote>
<p>One way to resolve this paradox is to realize that it is the user’s temporal existence that imposes state on the system. If the user could step back from the interaction and think in terms of streams of balances rather than individual transactions, the system would appear stateless — <a href="https://web.mit.edu/alexmv/6.037/sicp.pdf">SICP</a> Section 3.5.5</p>
</blockquote>
<p>Instead of viewing the <em>world</em> as the sum of its objects, each reflecting its latest state as time elapses, we may also think in terms of discrete state histories. We may interpret the dog at the park as moving in discrete steps <code>S(i)</code> to <code>S(i+1)</code>, just as we interpret the state of our functional program as moving in discrete steps <code>S(i)</code> to <code>S(i+1)</code>.</p>
<p>Consider video media. To movie scenes, we may attribute the same object-oriented semantics. Character and inanimate objects shift, interact and evolve as time elapses.</p>
<video id="metavideo" poster="https://softwarefordays.com/media/metavideoposter.gif" preload="none" width="480" controls="">
    <source src="https://softwarefordays.com/media/metavideo.mp4" type="video/mp4; codecs=&quot;avc1.42E01E, mp4a.40.2&quot;">
    <img src="https://softwarefordays.com/media/metavideo.mp4" title="Your browser does not support the mp4 video codec.">
</video>
<p>While playing the above video, for example, we may conclude that “a cat is dancing.” Yet, videos are comprised of static frames stitched together in a certain sequence at discrete time intervals. Each frame corresponds to a state of the video at a moment in time and the frames, taken together, a time-denominated series of discrete states. The media chosen above is intentionally meta. The video includes a TV animation of a scene mirrored by a flip-book<sup><a href="#fn2" id="fnref2">[2]</a></sup>, showing static frames strung together at discrete time intervals, which itself is mirrored by a flip-book in “real” life, showing static frames strung together at discrete time intervals. Take another step back to notice that the above gif media (or mp4 if your browser supports html5) being played on <em>your</em> computer is comprised of static frames, strung together at discrete time intervals.</p>
<p>There is nothing stopping us from taking another step back and interpreting the real world in which your computer currently sits as static frames, strung together at discrete time intervals. We <em>may</em> attribute normal object-oriented semantics to the above gif, concluding that “a cat is dancing.” However, we may also attribute functional semantics, concluding that “a cat has arms above its head on frame fᵢ.” At a park in the real world, we may conclude that “a dog is chasing a squirrel.” However, we may also conclude that “a dog is in the running motion behind a squirrel in the running motion on frame fᵢ.” In both cases, we may identify a time-series of states instead of objects that change over time. The functional programming paradigm can be coherently applied to world and program alike.</p>
<p>With a model for discrete time in mind, it is less surprising that functional programs can appear stateful. A user of the program may be viewed as a series of states, just like the program itself. A specific series of user states, for example,</p>
<pre><code>U₀: "Open up this blog post"<br>U₁: “Select 20 option”<br>U₂: “Click withdraw”<br>...<br>U(i): Uᵢ</code></pre>
<p>directly precipitate a series of program states:</p>
<pre><code>S₀: balance:100, amount:10<br>S₁: balance:100, amount:20<br>S₂: balance:80, amount:20<br>...<br>S(i): program(Sᵢ₋₁, Eᵢ)</code></pre>
<p>In both cases, pieces of static information may be listed, one <em>after</em> another. Moreover, both lists can be plotted along the same discrete timeline <code>i</code>. User interactions come in a certain order <code>U(i)</code>, triggering a run of the program function against the result of the previous run <code>S(i-1)</code> and event data <code>E(i)</code>, in order to produce <code>S(i)</code>. Our reality can be viewed as a time-series of states, just as it can be viewed as a collection of objects. Functional programming models a time-series of states, just as as object-oriented programming models objects. When the program and world <em>alike</em> can be viewed as “streams of information that flow in the system,” (<a href="https://web.mit.edu/alexmv/6.037/sicp.pdf">SICP</a> Section 3) the world can flow into the program, and the program back into the world.</p>
<hr>
<section>
<ol>
<li id="fn1"><p><a href="https://guide.elm-lang.org/">Elm</a> programs are trivially made to be stateful, notwithstanding the exclusive use of pure functions <em>and</em> the asynchrony of user interactions! This counter program</p>
<pre><code><span><span>import</span> Browser</span><span><br><span>import</span> Html <span>exposing</span> </span><span>(</span><span>Html</span><span>,</span> <span>button</span><span>,</span> <span>div</span><span>,</span> <span>text</span><span>)</span><br><span><span>import</span> Html.Events <span>exposing</span> </span><span>(</span><span>onClick</span><span>)</span><p><span>main</span> <span>=</span><br><span>Browser.sandbox</span> <span>{</span> <span>init</span> <span>=</span> <span>0</span><span>,</span> <span>update</span> <span>=</span> <span>update</span><span>,</span> <span>view</span> <span>=</span> <span>view</span> <span>}</span></p><p><span>type</span> <span>Msg</span> <span>=</span> <span>Increment</span> <span>|</span> <span>Decrement</span></p><p><span>update</span> <span>msg</span> <span>model</span> <span>=</span><br><span>case</span> <span>msg</span> <span>of</span><br><span>Increment</span> <span>-&gt;</span><br>  <span>model</span> <span>+</span> <span>1</span></p><p><span>Decrement</span> <span>-&gt;</span><br>  <span>model</span> <span>-</span> <span>1</span></p><p><span>view</span> <span>model</span> <span>=</span><br><span>div</span> <span>[</span><span>]</span><br><span>[</span> <span>button</span> <span>[</span> <span>onClick</span> <span>Decrement</span> <span>]</span> <span>[</span> <span>text</span> <span>"-"</span> <span>]</span><br><span>,</span> <span>div</span> <span>[</span><span>]</span> <span>[</span> <span>text</span> <span>(</span><span>String.fromInt</span> <span>model</span><span>)</span> <span>]</span><br><span>,</span> <span>button</span> <span>[</span> <span>onClick</span> <span>Increment</span> <span>]</span> <span>[</span> <span>text</span> <span>"+"</span> <span>]</span><br><span>]</span></p></code></pre>
<p>can be seen <a href="https://elm-lang.org/examples/buttons">here</a> tracking counter state, even though a user may of course click the counter buttons asynchronously. Like garbage collection in JavaScript, Elm hides any imperative code dedicated to communication between asynchronous scripts from the programmer’s view. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>A flip-book <a href="https://softwareengineering.stackexchange.com/a/245409/369472">has been suggested</a> as a valuable mental model for state in functional programming <a href="#fnref2">↩︎</a></p>
</li>
</ol>
</section>




    </div></div>]]>
            </description>
            <link>https://softwarefordays.com/post/resolving-the-fp-time-paradox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554907</guid>
            <pubDate>Sun, 27 Dec 2020 22:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to the Future: Data Engineering Trends 2020 and Beyond]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554883">thread link</a>) | @vananth22
<br/>
December 27, 2020 | https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering | <a href="https://web.archive.org/web/*/https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to the 23rd edition of data engineering weekly. This week's edition is a yearend special edition where we will take a more in-depth look at the trends and emerging patterns in data engineering 2020. I divided the trends into the following categories.</p><ul><li><p>Data Infrastructure</p></li><li><p>Data Architecture</p></li><li><p>Data Management</p></li></ul><p>I hope you enjoy the data engineering trends 2020, and please share your thoughts in the comments.</p><p>I know this is a long article with so many links and references. TL;DR If I had to make a top 3 prediction for 2021 and beyond, here are they.</p><ol><li><p><em><strong>Metadata management will become mainstream. The data lineage, data quality, and data discovery tools will merge into a unified data management platform.</strong></em></p></li><li><p><em><strong>Data Mesh principles will get adopted more and drive a unified data management platform.</strong></em></p></li><li><p><em><strong>Lakehouse systems like Hudi, Iceberg, Deltalake will play a significant role in shaping the data engineering architecture.</strong></em></p></li></ol><p>Now, let’s go deep into each category and see the trends and predictions. Happy reading.</p><h2><em><strong><code>Managed Data Infrastructure &amp; Serverless Computing</code></strong></em></h2><p>In 2020, We saw the cloud platforms continue adopting the open-source data infrastructure solutions—the adoption growing from AWS's EMR, Google Cloud data proc, and Azure HDInsight to the recent AWS managed Airflow.</p><p><a href="https://aws.amazon.com/blogs/aws/introducing-amazon-managed-workflows-for-apache-airflow-mwaa/"><code>Introducing Amazon Managed Workflows for Apache Airflow (MWAA)</code></a></p><p>Though opinions differ on cloud platforms packaging the opensource, the cloud-managed infrastructure certainly carry many advantages for the consumers to quickly adopt complex infrastructure and focus on the business problems.</p><h4>2021 &amp; Beyond</h4><p>The rise of serverless architecture particularly very interesting trend in data engineering. The article summarizes the serverless data ops trend</p><p><a href="https://medium.com/swlh/dawn-of-dataops-can-we-build-a-100-serverless-etl-following-ci-cd-principles-3ca587ba1ec0"><code>Dawn of DataOps: Can We Build a 100% Serverless ETL Following CI/CD Principles?</code></a></p><p>Google Cloud launched a Google Cloud Workflow as a serverless orchestration engine.</p><p><a href="https://cloud.google.com/blog/products/application-development/get-to-know-google-cloud-workflows"><code>Get to know Workflows, Google Cloud’s serverless orchestration engine</code></a></p><blockquote><p><em><code>In 2021, It is an exciting space to watch how managed data infrastructure and the rise of serverless computing merge. </code></em></p></blockquote><h2><em><strong><code>Cloud datawarehouse</code></strong></em></h2><p>At the beginning of 2010, tightly coupled computing and storage is a strategy to run large scale data processing engines. 2019 is when the industry finally declared the old way of thinking data processing no longer working and acknowledge the cloud datawarehouse system is the way to go.</p><p><a href="https://medium.com/@acmurthy/hadoop-is-dead-long-live-hadoop-f22069b264ac"><code>Hadoop is Dead. Long live Hadoop.</code></a></p><p>In 2020, Snowflake's successful IPO reassured the cloud datawarehouse systems are the future. The S3 strong read-after-write consistency guarantee is a significant step in adopting object storage for the cloud datawarehouse system, if not already.</p><p><a href="https://aws.amazon.com/blogs/aws/amazon-s3-update-strong-read-after-write-consistency/"><code>Amazon S3 Update – Strong Read-After-Write Consistency</code></a></p><h4>2021 &amp; Beyond</h4><blockquote><p><em><code>The cloud datawarehouse system will continue to dominate and increase the adoption in 2021 and beyond. It will be interesting to watch how the cloud datawarehouse systems are tightly integrating with the data management systems.</code></em></p></blockquote><h2><em><strong><code>Cost Optimization</code></strong></em></h2><p>The cloud datawarehouse systems and the managed data infrastructure adds pressure on optimizing the cost of operating the datawarehouse systems. Netflix writes about cost optimization strategies for its data warehouse system.</p><p><a href="https://netflixtechblog.com/byte-down-making-netflixs-data-infrastructure-cost-effective-fee7b3235032"><code>Byte Down: Making Netflix’s Data Infrastructure Cost-Effective</code></a></p><p>At the same time, the GPU accelerated workload can provide a strategic business advantage. Pinterest and NVIDIA shared how Pinterest using GPU acceleration for visual search.</p><p><a href="https://blogs.nvidia.com/blog/2020/12/16/pinterest-trains-visual-search-faster-nvidia-gpus/"><code>Pinterest Trains Visual Search Faster with Optimized Architecture on NVIDIA GPUs </code></a></p><h4>2021 &amp; Beyond</h4><p>I added cost optimization as a separate section since cost optimization is often an afterthought. The unpredictability of the object storage engines egress and storage cost, handling cold vs. hot data &amp; the need for specialized hardware for a specific workload will be the norm of 2021 and beyond. </p><p>Alluxio is one solution that I am aware of providing tiered data processing capabilities, though not tuned for cost optimization.</p><p><a href="https://hackernoon.com/accelerate-spark-and-hive-jobs-on-aws-s3-by-10x-with-alluxio-as-a-tiered-storage-solution-5c3s3yes"><code>Accelerate Spark and Hive Jobs on AWS S3 by 10x with Alluxio as a Tiered Storage Solution</code></a></p><blockquote><p><em><code>It will be interesting to see how data processing frameworks like Spark, Flink adopting cost optimization as the first class optimization model, cache frequently used datasets and aware of specialized workloads. </code></em></p></blockquote><h2><em><strong><code>Lakehouse</code></strong></em></h2><p>The separation of computing and storage and the scalable object storage like S3 increased the adoption of data lake principles in early 2019. One of the challenges remains to adopt object storage on the lack of transaction guarantees. The support for ACID transactions, data versioning, auditing, indexing, caching, and query optimization are vital characteristics to build large scale data systems. </p><p>In 2020, We noticed the emerging lakehouse frameworks like DataBricks Delta Lake, Apache Hudi, and Apache Iceberg.</p><p><a href="http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf"><code>Lakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics</code></a></p><p>Adobe shared its Iceberg adoption story <a href="https://medium.com/adobetech/iceberg-at-adobe-88cf1950e866"><code>Iceberg at Adobe</code></a></p><p>Uber writes about its journey with Apache Hudi, and EMR now offers Hudi part of EMR</p><p><a href="https://eng.uber.com/apache-hudi-graduation/"><code>Building a Large-scale Transactional Data Lake at Uber Using Apache Hudi</code></a></p><p><a href="https://aws.amazon.com/blogs/big-data/apply-record-level-changes-from-relational-databases-to-amazon-s3-data-lake-using-apache-hudi-on-amazon-emr-and-aws-database-migration-service/"><code>Apply record level changes from relational databases to Amazon S3 data lake using Apache Hudi on Amazon EMR and AWS Database Migration Service</code></a></p><h4>2021 &amp; Beyond</h4><p><a href="https://github.com/apache/iceberg/milestone/7"><code>Icerbeg’s version 2</code></a> to support row level upsert is another interesting development to watch in 2021.</p><blockquote><p><em><code>The Lakehouse systems continue to mature and will play a major role in shaping the data engineering architecture. It will be interesting to watch how lakehouse complement or compete with the likes of Snowflake and Redshift.</code></em></p></blockquote><h2><em><strong><code>Lambda vs. Kappa vs. Lambda-less</code></strong></em></h2><p>Managing the real-time and batch computing and providing one integrated dataset view remains the main challenge in data processing.</p><p>Pinterest writes about some of the complication of Lambda Architecture and its migration journey to the Kappa architecture</p><p><a href="https://medium.com/pinterest-engineering/pinterest-visual-signals-infrastructure-evolution-from-lambda-to-kappa-architecture-f8f58b127d98"><code>Pinterest Visual Signals Infrastructure: Evolution from Lambda to Kappa Architecture</code></a></p><p>LinkedIn took an interesting approach of Lambda-Less model</p><p><a href="https://engineering.linkedin.com/blog/2020/lambda-to-lambda-less-architecture"><code>From Lambda to Lambda-less: Lessons learned</code></a></p><h4>2021 &amp; Beyond</h4><blockquote><p><em><code>There is no real-time vs. batch, it is all about the window that we process, but that is easier to say than the reality. In 2021 and beyond, I hope we will have a more innovative solution in this space.</code></em></p></blockquote><p>Apache Beam is an excellent attempt to bring the model closer. The development of Spark Streaming and the recent Apache Flink’s&nbsp;<a href="https://flink.apache.org/2020/12/15/pipelined-region-sheduling.html"><code>batch computing support</code></a>&nbsp;are some of the trends to watch.</p><h2><em><strong><code>Streaming SQL Engines &amp; OLAP Engines</code></strong></em></h2><p>Real-time computing and insights are critical for many businesses. Event sourcing is a well-established design pattern, and that brings the question of the decade. Can we join streams and compute business metrics or feed everything into OLAP databases and query it?</p><p>Confluent writes about the KSQL materialization process.</p><p><a href="https://www.confluent.io/blog/how-real-time-materialized-views-work-with-ksqldb/"><code>How Real-Time Materialized Views Work with ksqlDB, Animated</code></a></p><p>Materialize writes about joins in detail</p><p><a href="https://materialize.com/joins-in-materialize/"><code>Joins in Materialize</code></a></p><p>On the OLAP engine space Druid, Click House and Pinot adding multiple OLAP features and improves the operational efficiency. Apache Pinot is an impressive OLAP engine gaining momentum in 2020. Uber shared its experience operating Apache Pinot at scale.</p><p><a href="https://eng.uber.com/operating-apache-pinot/"><code>Operating Apache Pinot @ Uber Scale</code></a></p><h4>2021 &amp; Beyond</h4><p>Though streaming SQL engines and OLAP engines solve similar problems, I think there is a fundamental difference. Streaming SQL engines are good for pre-defined analytics, write once, and run workloads continuously. OLAP engines are good for interactive analytics when analytical queries are unknown while building the datasets.</p><blockquote><p><em><code>In 2021 and beyond I expect tighter integration among the Streaming SQL like KSQL and OLAP engines like Pinot.</code></em></p></blockquote><h2><em><strong><code>Data Quality &amp; Metadata Management</code></strong></em></h2><p>The poor data quality costs an estimated $3.1 trillion per year in the USA alone, equating to 16.5% of the GDP.!! The data quality is critical for developing a data pipeline, and your ML model is as efficient as the quality of the data.</p><p><a href="https://medium.com/@expectgreatdata/why-data-quality-is-key-to-successful-ml-ops-a18d6e373ca9"><code>Why data quality is key to successful ML Ops</code></a></p><p>We’ve seen both Microsoft and Airbnb writes about how data quality effort improved its org decision-making process.</p><p><a href="https://medium.com/data-science-at-microsoft/partnering-for-data-quality-dc9123557f8b"><code>Partnering for data quality</code></a></p><p><a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-e582465f3ef7"><code>Data Quality at Airbnb - Part 1 — Rebuilding at Scale</code></a></p><p><a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-870d03080469"><code>Data Quality at Airbnb - Part 2 — A New Gold Standard</code></a></p><p>We have seen multiple tools and systems emerged on Data Quality, and this is a pretty good summarization f the data quality ecosystem.</p><p><a href="https://medium.com/memory-leak/data-quality-a-primer-f6a945915511"><code>Data Quality — A Primer</code></a></p><p> One of the most remarkable trends of 2020 in data engineering is the emerging tooling and infrastructure to manage metadata at scale. I shared some of my thoughts about the importance of metadata in the past.</p><p>In 2020, we have seen many great articles from companies across the industry that shared their data discovery and metadata management. Data Engineering Weekly dedicated a week’s edition to focus on metadata management.</p><p><a href="https://www.dataengineeringweekly.com/p/data-engineering-weekly-21-metadata"><code>Data Engineering Weekly #21: Metadata Edition</code></a></p><p>LinkedIn organized&nbsp;<a href="https://metadataday2020.splashthat.com/"><code>Metadata Day 2020 - Metaspeak Meetup</code></a>&nbsp;as an attempt to unify people working on metadata management. Datakin announced the&nbsp;<a href="https://datakin.com/2020/12/18/introducing-openlineage/"><code>Open Lineage initiative</code></a><code>&nbsp;</code>to standardize the data lineage and the discovery effects.</p><h4>2021 &amp; Beyond</h4><p>I’ve included the data quality and the metadata management in the same section for a reason. In 2020 we saw isolated solutions to solve data lineage, data quality, and data discovery. Data Pipeline is a complex inter-dependent creation process of one dataset from another. Data lineage and data quality are two tightly coupled metadata systems that power the data discovery system.</p><blockquote><p><em><code>In 2021 and beyond, I expect all three problem spaces to merge and emerge as one unified data management platform that can provide data quality, lineage, and discovery service out of the box.</code></em></p></blockquote><h2><em><strong><code>Data Mesh</code></strong></em></h2><p>In 2020, Data Mesh emerged as de-facto principles for scale data management as the organization grows. Thoughtworks writes about the data mesh principles in the past.</p><p><a href="https://martinfowler.com/articles/data-monolith-to-mesh.html"><code>How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh</code></a></p><p><a href="https://martinfowler.com/articles/data-mesh-principles.html"><code>Data Mesh Principles and Logical Architecture </code></a></p><p>We saw number of companies started to adopt the data mesh principles and wrote …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering">https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering</a></em></p>]]>
            </description>
            <link>https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554883</guid>
            <pubDate>Sun, 27 Dec 2020 22:39:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A gentle intro to MVC frameworks]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554784">thread link</a>) | @musikele
<br/>
December 27, 2020 | https://michelenasti.com/2020/12/27/a-guide-to-mvc-frameworks.html | <a href="https://web.archive.org/web/*/https://michelenasti.com/2020/12/27/a-guide-to-mvc-frameworks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			
			<p>In the last few years Iâ€™ve worked or played with a bunch of MVC frameworks: <strong>Laravel</strong>, <strong>Ruby on Rails</strong>, <strong>Django</strong>, and <strong>AdonisJS</strong>.</p>

<p>With two of them (Laravel and Dango) I also have some experience in production environments. Laravel is the one I know most.</p>

<p>So, what do they all share in common? Whatâ€™s the difference between them and Express, Flask, Sinatra? This article will try to explain the philosophy around those tools.</p>



<p>The web is not only a matter of serving the right file to the user; you usually also want to:</p>

<ul>
  <li>pass arguments, values, cookies, more generally data with the request;</li>
  <li>customize the output: not only in the format (plain html, or json, or â€¦ xml if you are kink enough), but also the data in it (if you are a logged user you may want to see more things than an anonymous user; etc)</li>
  <li>handle security, that is nowadays a first class citizen</li>
  <li>handle authorization, with one of the multiple authorization schemes hat have appeared in the last few years</li>
  <li>be able to scale: in the number of concurrent users, in the size of the handled data, and in the organization of the code itself.</li>
</ul>

<p>The key point here is,<strong>people got tired of solving the same problem over and over and invented a set of tools that standardized/simplified the developerâ€™s job</strong>, allowing to focus more on the business logic than on the details.</p>

<h2 id="so-whats-this-mvc-stuff">So whatâ€™s this MVC stuff?</h2>

<p>M stands for <strong>Model</strong>, and means the data that is manipulated by the framework. In current web frameworks the Model usually corresponds to classes that map to a database (E.g. <code>Person</code> class is linked to the <code>persons</code> table).</p>

<p>V stands for <strong>View</strong> and means the way the data is presented to the user. In my small dev life Iâ€™ve seen many ways to represent this part: JSON responses for example, or plain HTML. Usually, modern MVC tools offer a template system so you can write the <em>products.html</em> page once and then inject the data to be displayed.</p>

<p>C is for <strong>Controller</strong>, the part that will do the dirty job. When a request arrives, the controller will validate the input, fetch the database, apply business rules, and pass it to the right view. Or it will trigger some other systems. <em>This is the part youâ€™ll write in some programming language</em>.</p>

<h2 id="opinionated-vs-unopinionated">Opinionated vs Unopinionated</h2>

<p>Instead of referring to MVC vs Non-MVC frameworks, I think <strong>the best classification is between <em>Opinionated</em> vs <em>Unopinionated</em></strong>. Opinionated frameworks are those that are presented in this article; they give to the dev a lot of pre-made tools with sensible defaults that will do all the heavy lifting. Sad to say, but the developerâ€™s job is sometimes just to configure these tools to make them work as needed.</p>

<p>With <em>unopinionated frameworks</em>, you are alone with a tool that handles requests and responses. You may need to write all the tools you need, and end up creating a framework yourself. An example: you may need to decide how to access the database, or handle authenticationâ€¦ In this category I see <strong>Express</strong>, <strong>Flask</strong>, <strong>Sinatra</strong>.</p>

<h2 id="the-router-in-mvc">The router in MVC</h2>

<p>Almost all the opinionated frameworks expose a functionality called <em>router</em>. Similarly to phisical routers, these pieces of software will understand the URL of a request and will route to the right controller. One can create a route for <code>/products/123</code> and the router will send this request to <code>ProductController</code> calling the appropriate function and passing the parameter <code>123</code> as argument. Isnâ€™t this lovely?</p>

<p>So when I have to debug an application I usually start from here; I try to understand where the router configuration is (usually in <code>routes.php</code> or <code>urls.py</code>), and where the route Iâ€™m interested will point, and follow it.</p>

<h2 id="the-orms">The ORMs</h2>

<p><strong>ORM</strong> stands for <em>Object Relational Mapping</em> and is a framework that allows to express sql queries using class constructs. Almost every major framework ships an ORM that is perfect for simple and sometimes elaborated queries. Basically the Model classes will extend a base class that contains all the boilerplate to read from the DB table and perform queries. For example, in Laravel:</p>

<pre><code>&lt;?php

use Illuminate\Database\Eloquent\Model;

class Flight extends Model
{
    //
}
</code></pre>

<p>The class <code>Model</code> is the base class that will give to <code>Flight</code> all the fancy methods, like:</p>

<pre><code>// Retrieve a model by its primary key...
$flight = Flight::find(1);

// Retrieve the first model matching the query constraints...
$flight = Flight::where('active', 1)-&gt;first();
</code></pre>

<h2 id="template-systems">Template systems</h2>

<p>Almost every MVC framework use a template system, so you can create HTML files with lower effort, even though itâ€™s nowadays very easy to just respond with JSON. Usually it only depends on what you return from the controller.</p>

<h2 id="command-line-utilities">Command line utilities</h2>

<p>Laravel has <strong>artisan</strong>, Python has <strong>manage.py</strong>, Rails has <strong>rake</strong>. These three command line utilities do <em>a lot</em>. They can:</p>

<ul>
  <li><strong>create and execute migrations</strong>, that are operations that will change the structure of your database. You may create a migration to add a new table or change a column., for example. You can also rollback if something doesnâ€™t go as planned. All of that without writing SQLs directly on the DB server. We use this feature on a daily basis during development.</li>
  <li>Likewise the migrations, sometimes you only want to add data in tables, like the values of a select box. This process is called <strong>seeding</strong>.</li>
  <li>Put the server on <strong>maintenance mode</strong> and resume</li>
  <li><strong>create boilerplate</strong> (models, controllers, viewsâ€¦) from command line, so that you only have to fill those generated files</li>
  <li><strong>execute tests</strong></li>
  <li><strong>create custom commands</strong>; for example, we usually create commands for operations that should be triggered by cron, or long-lasting batch commands.</li>
  <li>â€¦and much more! Every tool exposes more or less capabilities.</li>
</ul>



<p>I cannot stress out how important is documentation when using those frameworks. Itâ€™s impossible to remember all the possible commands and configurations. You end up searching through docs, and if those are well written, you donâ€™t need to pay a visit on stack overflow right away. If you write an MVC tool and it doesnâ€™t have an <em>excellent</em> documentation, with a lot of examples, it will probably not be used by anyone.</p>

<h2 id="standardization">Standardization</h2>

<p>Another thing that pays off is that, no matter whoâ€™ll work on what, all the code will look the same, and will be organized the same way. This has some value, since those kind of systems must be maintained over a span of several years, while the average dev only works only 2 years in the same company :)</p>

<h2 id="conclusions">Conclusions</h2>

<p>I hope I donâ€™t have expressed concepts that are too trivial for the average reader; these are the basic info I wish somebody told me at the time.</p>
 
			
			


			<p>Tags: 
    
    
    <a href="https://michelenasti.com/tags/#mvc">mvc</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#web">web</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#laravel">laravel</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#django">django</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#rails">rails</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#artisan">artisan</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#orm">orm</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#documentation">documentation</a>
    
    
</p>

			<h4>Related Posts:</h4>


		</section></div>]]>
            </description>
            <link>https://michelenasti.com/2020/12/27/a-guide-to-mvc-frameworks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554784</guid>
            <pubDate>Sun, 27 Dec 2020 22:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recaf – A modern Java bytecode editor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554497">thread link</a>) | @segfaultbuserr
<br/>
December 27, 2020 | https://www.coley.software/Recaf/ | <a href="https://web.archive.org/web/*/https://www.coley.software/Recaf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div id="content">
        <h3>What is Recaf?</h3>
        <p>Recaf is an open-source Java bytecode editor that simplifies the process of editing compiled Java applications. To make things easier Recaf abstracts away much of the internal class file format. Difficult tasks such as updating stack-frames are done automatically. Along with additional features to assist in the process of editing classes, Recaf is the most feature-rich free bytecode editor available.</p>
        
        <h3>Useful Information</h3>
        <p>While Recaf makes bytecode editing a more simple process it does not mean you should dive head-first into editing compiled Java applications without understanding some basic programming concepts and the Java class file architecture. Here are some references for these topics:</p>
        <ul>
            <li><a href="https://docs.oracle.com/javase/specs/jvms/se14/html/jvms-2.html">Specification: Chapter 2. The Structure of the Java Virtual Machine</a></li>
            <li><a href="https://docs.oracle.com/javase/specs/jvms/se14/html/jvms-4.html">Specification: Chapter 4. The class File Format </a></li>
            <li><a href="https://blog.takipi.com/jvm-architecture-101-get-to-know-your-virtual-machine/">JVM Architecture 101: Get to Know Your Virtual Machine</a></li>
            <li>Java instructions:
                <ul>
                    <li><a href="https://www.coley.software/Recaf/doc-instructions.html">Recaf's simplified instruction format</a></li>
                    <li><a href="https://docs.oracle.com/javase/specs/jvms/se14/html/jvms-6.html">Standard Java instructions</a></li>
                </ul>
            </li>
        </ul>
        <h3>Download &amp; Building</h3>
        <p>Downloadable jar binaries are provided through Github's <a href="https://github.com/Col-E/Recaf/releases">release page</a>.<br>Alternatively you can build from the source by cloning <i>(or downloading)</i> the repository and using maven to build the executable.</p>
        <h3>Requirements</h3>
        <p>Recaf requires Java 8 to run but it is recommended you use Java 11 or higher. Some features require additional setup in Java 8 whereas the process is automatic in Java 11 and above</p>
        <h3>Usage Guide &amp; More Information</h3>
        <ul>
            <li><a href="https://www.coley.software/Recaf/documentation.html">Documentation &amp; usage</a></li>
        </ul>	
        <h3>Contact &amp; Support</h3>
        <p>For reporting bugs and suggesting new features please use the github repo's <a href="https://github.com/Col-E/Recaf/issues">issue page</a> and submit a new issue. For other inquiries, or if you'd just like to chat, join the discord server here: <a href="https://discord.gg/Bya5HaA">discord.gg/Bya5HaA</a></p>
    </div>
</article></div>]]>
            </description>
            <link>https://www.coley.software/Recaf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554497</guid>
            <pubDate>Sun, 27 Dec 2020 21:40:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hyperbezier Pen Tool]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25554205">thread link</a>) | @raphlinus
<br/>
December 27, 2020 | https://www.cmyr.net/blog/hyperbezier.html | <a href="https://web.archive.org/web/*/https://www.cmyr.net/blog/hyperbezier.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
        <h2 id="introduction">Introduction</h2>

<p>This post introduces a new model for a path drawing (pen) tool, with a particular focus on font design.</p>

<p>Although this tool works much like familiar pen tools (which are based on the manipulation of <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve">Bézier curves</a>), it is actually based on a new family of two-control-point curves, which we’ve been calling the <em>hyperbezier</em>.</p>

<p>This work is still in its early stages, and the demo below is quite barebones; my goal here is to get a simple version of this tool into the hands of designers and design-tool makers, so that more people can start to play around and evaluate it.</p>

<h4 id="contents">Contents</h4>



<h3 id="-background--motivation"><a id="background"></a> Background &amp; motivation</h3>

<p>The basis of this tool is a new mathematical model for fitting a curve to a set of points; that work was done earlier in the year by my collaborator <a href="https://raphlinus.github.io/">Raph Levien</a>. For the past year or so Raph has been excitedly talking to me about about things like <em>splines</em> and <em>G2 continuity</em> and the elegance of the <em>Euler spiral</em>, and I have for the most part been smiling politely and nodding. In the last few weeks however I have started trying to implement a simple drawing app around his new model, and the excitement is catching: this new tool feels like the first I have used that is a compelling alternative to traditional Bézier-curve based drawing tools.</p>

<p>It is likely that if you have ever used a computer drawing application then you have, at some point, used a <em>pen tool</em>: a tool that allows you to place a small number of points, which are then connected with a series of curves, the exact curvature being a function of the position of the points.</p>

<p>Tools like this— which take some fixed number of points and calculate a curve based on them— are called <em>splines</em>. If you are curious about the topic (particularly in the context of interactive design tools), a very accessible overview is Raph’s <a href="https://levien.com/phd/thesis.pdf">dissertation</a>; I won’t go into too much detail here, except to say that Raph has been revisiting this subject recently, and the result is the <a href="https://github.com/linebender/spline"><em>hyperbezier spline</em></a>. Like traditional (cubic) Bézier paths, a hyperbezier path is comprised of segments, each defined by two <em>on-curve</em> and two <em>off-curve</em> (or <em>control</em>) points; the curve passes through the two on-curve points, and the curvature itself is determined by the position of the two off-curve points.</p>

<p><img id="simple-cubic" src="https://www.cmyr.net/assets/hyperbez/hyperbez-simple-cubic1.png" alt="A simple cubic Bézier"></p>
<p>A Bézier path, consisting of two segments</p>

<p>If you’re generally curious about Béziers, <a href="https://pomax.github.io/bezierinfo/">A Primer on Béziers Curves</a> is an excellent resource. For our purposes it is enough to note that splines based on direct manipulation of Bézier control points (most pen tools) provide a high degree of control, but are difficult to use well. In particular, it can be tricky to maintain consistent curvature between adjoining segments of a path, which can lead to a ‘lumpy’ look; the following example is  contrived, but in practice consistently getting smooth feeling curves with Béziers is challenging.</p>


<p>A lumpy path. Mouseover to see the filled outline.</p>

<h3 id="-the-hyperbezier"><a id="hyperbezier"></a> The hyperbezier</h3>

<p>The core idea of the hyperbezier is the use of <em>auto-points</em>. These control points are adjusted automatically by the tool in order to maintain a smooth curve between neighbouring curve segments.</p>

<p>Let’s look at an example. With the path below you can drag points around, and double-click points to toggle their type.</p>

<p>The two green squares are <em>corner</em> points; curve segments that join at these points are allowed to change direction sharply. The two blue circles are <em>smooth</em> points; changing the curve on one side of the point can cause changes in the <em>auto</em> points (and hence the curve) on the other side.</p>

<p>The auto-points are indicated with dashed lines and terminating ‘x’s. The manual control points are indicated with solid lines, and terminating ‘o’s.</p>




<h5 id="playing-around">Playing around</h5>
<p>To get a better understanding of the spline’s behaviour, here are some things to try <em>(this requires a mouse)</em>:</p>
<ul>
  <li><em>double-click the bottom point to make it smooth</em>. When this point is smooth, the auto points beside it are adjusted so that the two curve segments join smoothly.</li>
  <li><a href="#" onclick="reloadHeart();return false;">reset,</a> or double-click the bottom point to turn it back into a corner. Now <em>doubleclick the top-left smooth point</em>. Making the top-left point a corner will replace the curve between them with a straight line. Two adjacent corners with only auto-points between them will always form a straight line, because a line is maximally smooth.
    <ul>
      <li>You should notice two small ‘x’s on this line. <em>Drag one of these auto points somewhere to position it manually</em>. You will notice that the remaining auto-point is repositioned as you drag.</li>
      <li><em>Drag the other auto-point</em>. With both control points positioned manually, and with corners at either end, you have full control of this segment.</li>
    </ul>
  </li>
</ul>

<!--(TK: SIMPLIFY ME, JUST INTRODUCE AUTO POINTS)The principal goal of the hyperbezier is to make it easier to maintain consistent curvature between adjoining segments of a path. This is achieved by letting the designer choose to have certain control points positioned automatically. These *auto-points* are adjusted in response to changes in adjoining segments so as to form a [smooth][smoothness] curve.-->

<!--In addition, on-curve points can be either *smooth* points or *corners*; if a point is smooth (marked by a green circle) then any auto points on either side of that point will be adjusted to maintain curvature with the segment on the other side. If a point is a corner (marked by a blue square) then the segment on one side of the point is not influenced by the curvature on the other side.-->

<!--Moving any on-curve point can cause subtle changes to the position of multiple auto-points; the example below is interactive, and you can drag the various points around, or toggle their type. Notice how the behaviour of the auto points changes if you toggle a nearby on-curve point between smooth and corner;

<iframe class="embedded-toy"
    title="Interactive hyperbezier toy"
    width="400"
    height="400"
    src="https://www.cmyr.net/misc/hyperbez/#AAE=eJxVzL0JgDAUBOCcYO8IjvImsFTQMmIpuEGmcJtARnlDpA0ELpCfq46P42BKZjNGkxWWeMhUddk_argeQWPdbrL6t2f3n-TV2WHdXQNsyEpvEhM=">
</iframe>
<div class = "img-caption">This demo requires a fairly recent browser</div>
-->

<h3 id="-the-toy-pen-tool"><a id="the-toy"></a> The toy pen tool</h3>

<p>If you’re curious to try drawing with this tool, <a href="https://cmyr.net/misc/hyperbez">There is a simple web app available here</a> (and embedded below).</p>




<p>Below are some examples of letterforms I’ve sketched in the process of getting this working. These may offend the actual type designers in the room, but I hope they will be useful illustrations.</p>

<p><a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxlkj3OgUEUhWe-fHqFBSiVSuVdwhuFKBQjQUQk3viPv4y8oqBRKpVKpdISLMESLIG4J8xhmkmenDn33Hvn3-hJma_jhvK6pSJ_H-rbStNdsQEWiP2E8GWhONsnHFhb-6YZ83WkrjIXhwnMCKVK5BktFd-aYsJgCXCV1Nc1gnU42ApqxhGwaxC-o6S0gLWXK3Dc0zvnYTqi19mB4vyMsEfTY0_YYGTHJeE0kkVrwjG8y1s2KSo-sfrWQuCERmeqivecxNUU3-c8jFixm_L8Pzu09veP4dEhCTf8_BZqyTF3aOq8IVzAhs-sDqyNtRJWfQBl00gu" onclick="return reloadMain(event, 'g');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-g-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxt0TsKwkAQBuDZWGiZRrEKuYB9OucGRmJhlzQmNiq-QVCCBLFQsLbKUXKUHMDC0lJkJji7ZJssH39mZncbYKyOCUWEtBmhJXhKijEqVZnLOM4Q_jgh7F4Ewpwwugp8rAk9TjqvIHxaK-z1B05bq1kuKZnvBdoHQnchG5240VYmK8xQiTPlXLV1R_gx5SMu-7nRF_wzbexMHN1jdGUf_8i_JAIL7lLsahBibaL3hjmgiYxBcail0xlXDrV0mRCnelq8q7gu1QSxvvatM50=" onclick="return reloadMain(event, 'h');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-h-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxd0rEKwjAQBuCkk2PHjn2EPkJeQQQpqNCCYEWQIiJ0KFTbKuri6NhH6CPkERwdHR0zOgq5K_b3liMfuUtyxBEUnviLYqxsNpVyftrErAclLUu79JfEjz3laE35VijRq25T4qSrpjA1cYj8ZDYZsF5x7xzY3RD7C-CgJNYz4OjMPEe-MofA9wtxMQL-dLuHwIpZxDAjl49UPCtzohykMCOdc_UU38HPe22BQ76Z2uHojsReCdxmxO8aL5wQu7hbT7hJBdxExANs0vsvUgqMLzuHP6M=" onclick="return reloadMain(event, 's');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-s-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJx1kquOAkEQRXs2K1auXNnrECv3A8pssjggEAgKSEgIgWQAA8EM4TEISHj8AgI5EjkSySfwCUgkj6qmq0jTpjInt27Vne539ep8PwMowL3qCrxZGuSRxkXwPANLdYSQAo9pdROxyjCtgccaKKY99hAHabLAhv8xWVSpi77jhuiGOeG0WCBaIfa7bIENwcNYaEdrxF-hwDPCUSgGJhZO_Ev4U5oklnbkY48fA_si8XaKWCWx6gnWoMV6PybODKfQOf5MeHetDwt_YCHTdgk__QYYOhKkhs4EQRux-qNKN659Nv52gbezlwn8tnO8sYx4ApWzkGnjrNOiVHYkMFB3ZFr79K2WzgVbDlNT" onclick="return reloadMain(event, 'm');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-m-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxt0b0OgjAQB_CrA2FkMXH0EXyEDg5OBI1x0YGZOIBGIxETjHysPgKTs4s7j8BkHImLr-Fwld6BXUh-XP-9a3uAy4DWKj2J36UUHdtLaNDyGxQ9vd85Ihdrxr6vY8Wfs0D0od3JDP_CXHcCG20k3Twr9hhXO2R5kEAYYuR7xKqlCjFTxq8EubqwkEmKPEgYXyNkJ_uFPN_GOLiFEqLis32cWDYEWO2G5FZqr0HooMWbG6qAIiO1I4VWTlLBVtPlpDK29XaSWq7UbCl9LIW1y0eYIscLHkEeT0V8Ab6RQUE=" onclick="return reloadMain(event, 'r');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-r-small-fill.png"></a></p>
<p>Some example paths, drawn in the tool.</p>

<!--. This is very much a demo; the idea is to explore the interaction model, and to get a sense for how it feels to draw with the tool, compared to the standard Bézier curves used in most pen tools. Spoiler: I think it feels *really good*. You [can play around with it yourself][hypertoy]; it is pretty rough around the edges, but it works.-->

<h4 id="-using-the-toy-pen-tool"><a id="toy-guide"></a> Using the toy pen tool</h4>

<p>The toy is very rough: you have a select and a pen tool, but there are no rulers or measurement tools, no transforms, no ability to select multiple points. The pen works much like the familiar Bézier pen:</p>

<p>General:</p>

<ul>
  <li><code>V</code> key sets selection (arrow) tool, <code>P</code> key sets pen tool</li>
  <li>holding the space bar hides UI and shows filled path</li>
  <li>the current drawing is stored as part of the URL; copy this somewhere to “save”</li>
</ul>

<p>Pen tool:</p>

<ul>
  <li>click to add a line segment ending in a corner point</li>
  <li>alt + click to add an automatic curve segment ending in a smooth point</li>
  <li>click + drag to add a curve segment ending in a smooth point, with a manual control point</li>
  <li>click on a line segment to insert a point there; alt makes it a smooth point</li>
  <li>alt + click on any existing point to toggle the type of that point</li>
</ul>

<p>Select tool:</p>

<ul>
  <li>drag a control auto-point to move it, converting it to a manual point if necessary</li>
  <li>double-click will toggle an on-curve point between smooth and corner</li>
  <li>alt + click on a line segment to add two auto points</li>
  <li>deleting an off-curve point makes that curve segment into a line segment</li>
  <li>arrow keys nudge the current selection by 1 px; adding shift makes it 10px, and ctrl/cmd makes it 100px.</li>
  <li>shift + any of the above moves all of the points in the current outline (I’m sorry)</li>
</ul>

<h3 id="-next-steps"><a id="next-steps"></a> Next steps</h3>

<p>The code for the spline, including the demo, is <a href="https://github.com/linebender/spline">open source and available on github</a>.</p>

<p>The intent of this demo is twofold: firstly to test out how the curve feels to use, and to start playing around with the UX of the pen tool, and secondly to share this research with the broader community of designers and design-tool creators. Although this work is quite rough, my personal feeling is that this spline shows tremendous promise. Anecdotally, as a mere casual user of design tools, I find it <em>significantly</em> easier to make good looking curves with the hyperbezier than I do with traditional Bézier pen tools.</p>

<p>Perhaps the biggest question will be figuring out the best interaction model: what set of mouse clicks, key presses and modifiers the user issues in order to control the state of the points. This has been a challenge for other new splines; the interaction model we use with Béziers is <a href="https://youtu.be/sT8Y7o-zsVw?t=68">familiar and long-established</a>, and people (especially graphic designers) are deeply comfortable with it. The interaction model used here for the hyperbezier is intentionally designed to feel similar to these existing tools, but other interaction models may be worth exploring.</p>

<p>In the coming weeks I hope to integrating the spline into <a href="https://github.com/linebender/runebender">Runebender</a>, a font editor, which will provide a much richer editing experience and will let us better explore how well the spline is suited to real-world use. In addition, Raph intends to do a more detailed writeup of the spline itself and the associated math, which derives both from the earlier Spiro spline and the classic model of elastica under tension.</p>

<p>If you’re curious about the spline, there are more details in the <a href="https://github.com/linebender/spline">github repo</a>; if you have questions you can open an issue there, ask them in our <a href="https://xi.zulipchat.com/">zulip chat server</a> or reach out on <a href="https://twitter.com/cmyr">on twitter</a>.</p>

<h3 id="thanks">Thanks</h3>

<p>This work was funded by <a href="https://fonts.google.com/about">Google Fonts</a>.</p>

<!--- this is particularly useful for fonts
* fix bug with click-drag
* rebuild example
* revisit "next steps": we want to encourage other folks to adopt this
* explicitly mention that all of this is open source
-->


      </article>

    </div></div>]]>
            </description>
            <link>https://www.cmyr.net/blog/hyperbezier.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554205</guid>
            <pubDate>Sun, 27 Dec 2020 20:59:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Heart Attack Survival Strongly Linked to Socioeconomic Background]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554171">thread link</a>) | @bookofjoe
<br/>
December 27, 2020 | https://smosa.com/heart-attack-survival-strongly-linked-to-socioeconomic-background/ | <a href="https://web.archive.org/web/*/https://smosa.com/heart-attack-survival-strongly-linked-to-socioeconomic-background/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In patients with low socioeconomic status, heart resuscitation is heavily delayed and, according to a recent European Heart Journal report last week, victims of cardiac arrest in hospitals are less likely to recover.</p><p>Researchers analyzed data from the national Swedish cardiopulmonary resuscitation register for 24,217 cardiac arrests in Swedish hospitals between 2005 and 2018 in patients 40 and older. They collected socioeconomic data on patients from a second database and used the highest rate of education and annual income as a socioeconomic status (SES) measure.</p><p>"The good news is that for most of the cardiac arrest cases in this study, socioeconomic status didn't seem to matter." said Professor Jens Agerström of Linnaeus University in Kalmar and Växjö, Sweden, "Nevertheless, there seems to be a significant number of deaths that can still be attributed to socioeconomic factors, even when we take account of things that could affect the results such as gender, age, ethnicity, other health conditions, cause of the cardiac arrest, and the specific hospital providing the treatment."</p><p>Patients with higher SES were slightly better controlled for heart rhythm prior to cardiac arrest. This may partly explain the survival disparities. Most unrecovered combinations between patient SES and the findings studied are minimal. A disparity in SES-related survival chances of around 21 percent shouldn't be overlooked, authors say.</p><figure><img src="https://smosa.com/content/images/2020/12/ehaa954f3.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/ehaa954f3.png 600w, https://smosa.com/content/images/size/w1000/2020/12/ehaa954f3.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/ehaa954f3.png 1600w, https://smosa.com/content/images/2020/12/ehaa954f3.png 1949w" sizes="(min-width: 720px) 720px"><figcaption>Credit: European Heart Journal</figcaption></figure><p>The study investigated several outcomes but looking at survival for 30 days after the cardiac arrest, approximately 280 people in 1000 from a low socioeconomic background will survive; however, for patients from a high socioeconomic background approximately 320 people may survive to 30 days.</p><p>The goal of the new retrospective registry was to investigate SES inequalities in IHCA care and survival. The study looked at significant demographic, clinical, and social problems.</p><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png 1600w, https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png 2136w" sizes="(min-width: 720px) 720px"></figure><p>People with lower SES are less likely to survive a spontaneous heart arrest outside the hospital. Patients in higher-income hospitals and in school are slightly less likely. More likely to recover before hospital discharge and after heart arrest for 30 days.</p><p>"After having studied discrimination in the labour market for many years with Dr. Magnus Carlsson, one of my co-authors," said Prof. Agerström, "we thought that a natural next step would be to look at the health care system and possible treatment discrimination, which is much less researched. My own medical visits also played a role, as I got the impression that the staff often became more thorough after they had asked me about my profession."</p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/heart-attack-survival-strongly-linked-to-socioeconomic-background/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554171</guid>
            <pubDate>Sun, 27 Dec 2020 20:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Short-Range vs. Long-Range Wireless Power Transmission]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554015">thread link</a>) | @NaregK
<br/>
December 27, 2020 | https://emrod.energy/short-range-vs-long-range-wireless-power-transmission/ | <a href="https://web.archive.org/web/*/https://emrod.energy/short-range-vs-long-range-wireless-power-transmission/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Long-range wireless power transmission is a concept that has been a long time coming since Nikola Tesla obtained a patent for the Tesla coil over 120 years ago.&nbsp;&nbsp;</p>



<p>In the recent decade, wireless power has become more of a familiar term, with companies such as Powerbyproxi and WiTricity leading the way with innovation in short-range wireless technology. That is, the ability to transmit electrical power over short distances (up to a few metres), primarily to charge consumer devices like mobile phones. This technology enables us to charge devices without requiring wires within short range, e.g. at home or by driving up to an electric vehicle charging station.</p>



<p>The next evolution in freeing humanity from the restrictions of where wires can go is the ability to transmit large amounts of power over large distances. Instead of charging devices, long-range wireless transmission<strong> </strong>technology<strong> </strong>will allow us to power households, communities and send large quantities of power to places where it is too hard and expensive to reach using wire infrastructure. This is the technology Emrod is working on, which will support the uptake of sustainable energy and decentralizing electric grids.&nbsp;</p>



<p>In this article, we make a comparison between short-range and long-range power transmission, including the difference in technology and use cases.</p>



<p>First, let’s start with getting clear on what wireless power transmission is.</p>



<h3><strong>What is wireless power transmission?</strong></h3>



<p>Wireless power transmission is the act of delivering meaningful amounts of energy without moving or employing mass between transmitter and receiver. Electromagnetic fields convey power across space. It can replace the need for wires and batteries to provide a more convenient, mobile and safer way to provide energy.&nbsp;</p>



<p><em>According to early history, Heinrich Hertz was the first to prove the existence of electromagnetic waves. Hence the name “hertz” as the unit for frequency.</em></p>



<p>The difference between short and long-range power transmission can clearly be defined by the distance across which the power is transmitted. However, what determines the capabilities of these different types of technology?</p>



<figure><img loading="lazy" width="1024" height="576" src="https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-1024x576.jpeg" alt="" srcset="https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-1024x576.jpeg 1024w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-300x169.jpeg 300w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-768x432.jpeg 768w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-1536x864.jpeg 1536w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003.jpeg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3><strong>Short-range wireless power</strong></h3>



<p>Short-range is typically power transmission within centimetres and metres. The most common wireless power transmission technique is with Inductive Power Transfer, where power is transferred utilizing a magnetic field using inductive coupling between two coils of wire.&nbsp;</p>



<p>Examples of short-range power transmission by this definition include powering devices wirelessly within a house or building and charging electric cars using a resonant magnetic induction pad on the ground.</p>



<h3><strong>Long-range wireless power transmission</strong></h3>



<p>Long-range is typically power transmission of 100’s of metres or across kilometres. One technique of power transmission is using antennas to send electromagnetic beams, like microwaves or lasers. The limitation with using inductive coupling power transmission in long-range is that the magnetic field decays quite rapidly when the distance between the transmitter and receiver is increased. Therefore, electromagnetic beaming is more appropriate for this reason.&nbsp;</p>



<p>Long-range power transmission with antennas can be categorised into Near-Field or Far-Field. In the near-field, one can observe plane waves with very little to no beam divergence. Conversely, in the far-field there is significant beam divergence, and inverse squared decay for the power density with distance, something which is not observed in the near-field.&nbsp;</p>



<p>For Emrod’s purpose, we work in the near-field to produce a collimated beam with negligible loss.&nbsp;</p>



<p><br>The use cases for long-range transmission include beaming power from space to earth, charging unmanned aerial vehicles (without requiring the UAV to return to a base for charging) and transmitting power across difficult terrain instead of using wires, which is the problem we are solving at Emrod. Learn more about the use cases for Emrod’s technology <a href="https://emrod.energy/use-cases/">here.</a></p>



<h3><strong>Why are these new developments in long-range technology significant?</strong></h3>



<figure><img loading="lazy" width="1024" height="576" src="https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Emrod-long-range-wireless-energy-transmission.png" alt="" srcset="https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Emrod-long-range-wireless-energy-transmission.png 1024w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Emrod-long-range-wireless-energy-transmission-300x169.png 300w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Emrod-long-range-wireless-energy-transmission-768x432.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For energy to be useful, it needs to move from where it is generated to where it is required. Energy is similar to communication in this sense. For communication services to be useful, they must be able to transmit a message from one person to another. At the moment, our methods for generating energy are dependent on the locations that can be accessed economically using wired infrastructure (lines and pylons, and underwater cables). Many of the best places to generate renewable energy are hard to reach areas, for example high up on hills or mountains or offshore locations, where there is lots of wind, and it’s well out of the way of people.&nbsp;</p>



<p>On the other hand, the people who have access to energy are dependent on the economics of connecting the household or community to a power source. Many communities and dwellings do not have reliable access to electricity because they are in remote, hard to access areas where it is not economically viable to put in and maintain power lines or cables.&nbsp;</p>



<p>By reducing the costs and ease of installing and maintaining the infrastructure that transmits power from one place to another, we can open up our access to and provision of energy.</p>



<h3><strong>Emrod’s long-range wireless technology use cases</strong></h3>



<p>At Emrod, we have developed technology that allows power to be transmitted over many kilometres.&nbsp; It is the worlds first long-range wireless power transmission technology that is commercially viable. We use passive relays to achieve power transmission over a long distance, without the losses that would otherwise make long distance transmissions inefficient and uneconomical for commercial purposes.&nbsp;</p>



<p>The application of Emrod’s technology is wide-reaching, but we are primarily focused on working with energy distribution companies and organizations driving sustainable energy and decentralized grid projects.&nbsp;</p>



<p>Emrod’s wireless system can provide a cost-effective solution for the transmission of power across terrain where it is difficult to lay and maintain power lines and cables. For example across forests or waterways, to alleviate right of passage issues or reduce the ecological impact of pylons, and to provide back up systems when power lines fail, for example, outages or disaster relief.&nbsp;</p>



<p>You can read more about the common use cases for Emrod’s technology on the <a href="https://emrod.energy/use-cases/">Use Cases page of our website</a>.</p>



<h3><strong>Conclusion</strong></h3>



<p>The early modern development of wireless transmission technology used magnetic induction charging pads, which required contact and careful alignment of the device, e.g. a phone. Subsequently, technology developed to charge smartphones and other devices from meters away that works like a strong WiFi. This technology has been considered long-range, in comparison to the previous wireless technology, which required the transmitting and receiving devices to be in contact with one another. We have now entered into the next era of wireless technology, which is the transmission of larger amounts of power over kilometres. It is an exciting next step towards Nikola Tesla’s vision of power everywhere.</p>
</div></div>]]>
            </description>
            <link>https://emrod.energy/short-range-vs-long-range-wireless-power-transmission/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554015</guid>
            <pubDate>Sun, 27 Dec 2020 20:31:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WASM-STREAM, a virtual stage for digital artists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25553839">thread link</a>) | @timdaub
<br/>
December 27, 2020 | https://timdaub.github.io/2020/12/27/wasm-stream/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/12/27/wasm-stream/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><strong>TL;DR:</strong> I built a <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">synthesizer</a> that allows streaming directly to an <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/">internet radio stream</a>. Below is the live stream:</p>
<p><audio controls="" autoplay="" preload="auto">
<source src="https://audio.daubenschuetz.de/stream.ogg" type="audio/ogg">
<source src="https://audio.daubenschuetz.de/stream" type="audio/mpeg">
<p>Your browser does not support the audio element. </p></audio></p>
<hr>
<p>It's that time between Christmas and new year again, where you can usually find me at Leipzig's Congress Zentrum on my computer hacking away. It's chaos congress time. Given this year's pandemic, the "37c3" however, was moved to the internet and renamed to <a target="_blank" rel="noopener" href="https://rc3.world/">"rc3", the Remote Chaos Communication Congress</a>.</p>
<p>Earlier this month, the iconic congress build-up started. This time around, building up didn't involve moving heavy crates of mate tea around. Instead, it meant that everyone started designing, drawing, and building their assembly maps for the "rc3.world". A <a target="_blank" rel="noopener" href="https://events.ccc.de/2020/09/04/rc3-remote-chaos-experience/">2D virtual space</a> that's supposed to replace this year's lack of physical space.</p>
<p>The rc3.world software is a fork of <a target="_blank" rel="noopener" href="https://workadventu.re/">workadventu.re</a>, a 2D game simulating a virtual work environment with avatars. Within this 2D map of the virtual congress, the organizers invited all assemblies to build their own spaces. And so, as the build-up for <a target="_blank" rel="noopener" href="https://www.dist0rtion.com/">Social Dist0rtion Protocol</a> assembly began, I had an idea for a project.</p>
<figure>
<img src="https://timdaub.github.io/assets/images/wasm-synth-screenshot.png" alt=""><figcaption><a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a>, the project I launched at last year's c3</figcaption>
</figure>
<p>At last year's congress in Leipzig, I had launched <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a>, a synthesizer built in WebAssembly. Naturally, this time I was eager to take the project to the next stage. Hence, roughly a week ago, I started to work on a new project called "WASM-STREAM" - an extension to wasm-synth.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/social-dist0rtion-protocol/wasm-stream">WASM-STREAM</a> is a virtual stage for digital artists. Using WASM-STREAM, an artist can broadcast their play with wasm-synth to an internet radio stream. More importantly, though, this means that they can take the stage on the <a target="_blank" rel="noopener" href="https://www.dist0rtion.com/">Social Dist0rtion Protocol</a>'s assembly and jam away to a virtually present audience.</p>
<figure>
<img src="https://timdaub.github.io/assets/images/wasm-stream.png" alt=""><figcaption>Social Dist0rtion Protocol's dance floor in the rc3.world</figcaption>
</figure>
<p>So how did I build it?</p>
<h2 id="a-first-little-demo">A First Little Demo</h2>
<p><a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a> is a project that I built deliberately to showcase the power of the web. At the beginning of the year, I wrote <a href="https://timdaub.github.io/2020/02/19/wasm-synth/">a blog post</a> outlining its technical details. It's using the <code>AudioWorklet</code> and some WebAssembly-transpiled code to render audio in real-time in the user's browser.</p>
<p>Now, workadventure, the software ccc uses to run their rc3.world, is also built on the web and allows embedding audio streams. So I thought, why not take the audio generated in wasm-synth and stream it to everyone in the rc3 world.</p>
<p>In a way, it sounds like not that big of a deal to build an audio streaming client within a website. But remember that a browser's networking ability is limited. While we've come a long way from the <code>XMLRequest</code> API to <code>fetch</code>, <code>WebSocket</code> and <code>WebRTC</code>, these concepts only allow talking upstream if their authors deliberately built their upstream application for supporting them.</p>
<p>Naive as I Am, I started by deploying <a target="_blank" rel="noopener" href="https://icecast.org/">icecast2</a> to a small Hetzner instance. I configured an authorized mount point that allows a streamer to connect using client software. Then I looked for a way to stream audio directly to icecast from a browser. And found... nothing.</p>
<p>Well, I did find something. It's called <a target="_blank" rel="noopener" href="https://webcast.github.io/">webcast</a>, and it's a <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">WebSocket-based subprotocol</a> that allows sending binary audio data between a client and a server. In their <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js#server">README.md</a>, the authors also mention webcast's compatibility with <a target="_blank" rel="noopener" href="https://www.liquidsoap.info/">liquidsoap</a>, a DSL for audio stream processing.</p>
<p>So my first attempt at plugging these things together involved encoding the <code>Float32Array</code> data from the <code>AudioWorklet</code> into an mp3 stream using <a target="_blank" rel="noopener" href="https://github.com/toots/shine/">libshine</a> (that has a wasm JavaScript package) and then sending it to a <a target="_blank" rel="noopener" href="https://www.liquidsoap.info/doc-dev/harbor.html">liquidsoap "harbor"</a> via webcast. Liqidsoap would then convert the mp3 stream to ogg-vorbis, make it stereo, and forward it to the icecast server.</p>
<p>And, to my surprise, it worked. When I hit some keys on the wasm-synth, they got encoded and sent to the audio stream. With a bit of delay, I heard what I had just played. Cool!</p>
<p>Anyways, with my small little demo, I was galvanized and motivated enough to spend more time building something that would work for the congress.</p>
<h2 id="the-wasm-stream-architecture">The WASM-STREAM Architecture</h2>
<p>Ultimately, liquidsoap was not well-suited for my purpose. I also quickly realized that all I had to do was build a proxy between the <a target="_blank" rel="noopener" href="https://gist.github.com/ePirat/adc3b8ba00d85b7e3870">icecast protocol</a> and the <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">webcast protocol</a>. And that's what I ended up building. A small <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">JavaScript application</a> implementing two protocols. It listens for incoming WebSocket connections and calls icecast with a loooooonng PUT request to establish a stream.</p>
<p>WASM-STREAM itself doesn't do any encoding. It can, however, route an <code>audio/ogg</code> or an <code>audio/mpeg</code> stream from webcast to icecast. The encoding from WAV to mp3 takes place on the user's device already when the play the synthesizer.</p>
<h2 id="how-to-use-wasm-stream">How To Use WASM-STREAM</h2>
<p>Whether you have a ticket to rc3 or not, you can tune into the stream at <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/stream">https://audio.daubenschuetz.de/stream</a>. It's an mp3-encoded stream, meaning it won't work in all browsers equally (Firefox works natively; Chrome et al. only support ogg/vorbis natively). If it doesn't, try a desktop application like iTunes or VLC.</p>
<p>The stream is continuously online. But if you don't hear anything then that's because nobody is currently playing the <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">WASM-SYNTH</a>.</p>
<p>Finally, you're able to "dance" on the Social Dist0rtion Protocol's assembly dance floor. The rc3 orga was nice enough to allow us streaming audio on our map. <a target="_blank" rel="noopener" href="https://rc3.world/rc3/room/93840a8f-88f7-4f11-bb61-68800c4d4962/">Click here</a> to visit us directly on the rc3.world map.</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/12/27/wasm-stream/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553839</guid>
            <pubDate>Sun, 27 Dec 2020 20:07:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Lucerne, a Twitter experience tailored to me]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25553815">thread link</a>) | @thesephist
<br/>
December 27, 2020 | https://thesephist.com/posts/lucerne/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/lucerne/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Over the last week, I’ve been working on <a href="https://github.com/thesephist/lucerne">Lucerne</a>, a Twitter “reader” app built to fit my personal needs from Twitter. It’s been an interesting exercise in <a href="https://thesephist.com/posts/tools/">building a tool around workflows</a>, so I wanted to tell you the story of how the design came to be, and what I’ve noticed using Lucerne for my daily escapades into the Twittersphere.</p>
<p><img src="https://thesephist.com/img/lucerne.png" alt="Lucerne in action"></p>
<p>Like many of my personal tools, Lucerne is built with my <a href="https://dotink.co/">Ink programming language</a> on the backend and my <a href="https://github.com/thesephist/torus">Torus</a> UI library on the frontend. It’s made just for me at the moment, but given the interest I’ve gotten about Lucerne online, I might make a version open for anyone to use.</p>
<h2 id="designing-myself-a-better-twitter">Designing myself a better Twitter</h2>
<p>For me, Twitter serves two purposes. First, it’s a <em>learning tool</em>. There are lots of smart folks talking to each other and sharing what they’re thinking about on Twitter from software to economics to writing, and I can find on Twitter opinions or perspectives I can’t find on blogs or books. Second, it’s a <em>place for me to share whatever I’m working on</em> on my blog or on my side projects with my audience. Lucerne is designed around these two primary workflows: learning and sharing.</p>
<p>Twitter’s main user interface, the algorithmic timeline, is bad for using Twitter as a learning tool. It feels like sticking a straw into a firehouse and hoping you’ll suck out enough interesting insights to be worth the effort. I wanted a better way for me to discover and keep track of interesting conversations happening on Twitter about any topic. Twitter does provide decent tools for me to share my work online – things like scheduled tweets, analytics, notifications, and search – but they’re not in one place, so I wanted to consolidate these tools.</p>
<p><img src="https://thesephist.com/img/lucerne-timeline.jpg" alt="A timeline view in Lucerne"></p>
<p>With these two goals in mind, I also wanted Lucerne to be a tool that could <a href="https://thesephist.com/posts/ivy/">grow with me as I used it</a>, so I could mold my experience of Twitter around what I found to be most useful to me over time. More than other tools, Twitter feels organic and constantly changing. I didn’t want to have to bake in all the tools and dials I might ever want to use from the get-go. Instead, I wanted to be able to stumble into interesting use cases as I used Lucerne over time.</p>
<p><img src="https://thesephist.com/img/lucerne-querybar.jpg" alt="Performing a search in Lucerne"></p>
<p>To make it possible to grow Lucerne as a tool gradually around my use cases like this, Lucerne is designed primarily around one important idea: <strong>filtered searches saved as “channels”</strong>. Feeding from the firehose of conversations on Twitter, a “channel” is a small filtered stream of tweets defined by a particular search query. Here are some examples of useful filters.</p>
<ul>
<li>“tweets between A and B about #topic” – <code>(from:A OR from:B) #topic</code></li>
<li>“tweets about abc.com with more than 100 likes” – <code>url:abc.com min_faves:100</code></li>
<li>“tweets by A that include images, but exclude retweets” – <code>from:A filter:images -filter:retweets</code></li>
</ul>
<p>With Lucerne, I can search for interesting conversations happening on Twitter by experimenting with these filters. When any filter seems particular useful, I can save it to check again later, by adding it to the left sidebar with a name. As I use the app, I end up curating an ever-changing personalized collection of these channels in my sidebar that provide multiple different views onto the firehose of Twitter.</p>
<p>“But Linus,” I hear you saying, “you can search and save them as timelines on Twitter’s app and Tweetdeck.” Yes, you’re right, and most of the search filters Lucerne uses are also available on Twitter. But the important thing about Lucerne isn’t just that you can search, but that <strong>playing with filters and saving the good ones is the primary user interface</strong>. On Twitter, you might search once or twice to find something useful, but you’re <em>mostly</em> interacting with a single timeline passively. With Lucerne, most of my use is exploring and adding to a curated list of filters, and exploration and consumption are one and the same activity. As I’ll explain later from my personal experience, this makes a big difference in how much I can get out of Twitter.</p>
<p>I think the most important design lessons in Lucerne is what I <em>didn’t</em> do: I could have made a list of features that I might have wanted in the beginning, and baked it all into the app. Features like “follow specific threads”, “see top tweets from a particular user”, “follow hashtags”, or “hide retweets from the timeline.” But instead of adding a million settings and toggles, I found what I would consider to be the “atoms”, the common building blocks, of all of these use cases, and baked it into the core of the app instead. All these use cases above can be performed just as easily as filtered searches, and because these filters can be saved and referenced later, Lucerne can grow around my exact use cases <em>as I continue using it</em>. I don’t have to design for all my use cases from the start. This is what I mean when I say <a href="https://thesephist.com/posts/ivy/">we need to design tools to grow with us</a>.</p>
<p>In addition to this main idea of channels, Lucerne has a few other design considerations to improve how Twitter works for me. All the engagement stats I care about are present in a single screen, so I don’t have to annoyingly load five different pages every time, but they’re out of the way of the main “timeline” view, because I don’t want them in my face all the time. There’s a small pane on the right showing me my most recent new followers, which is sometimes useful when I see someone particularly interesting and want to reach back out to them. This also saves me a few clicks every time. Lastly, I intentionally didn’t implement <em>infinite scrolling</em>, in lieu of a simple “load more” button. This makes endlessly scrolling a conscious enough action for me that I end up wasting less time scrolling through my timeline. It goes without saying, all of these experiences are also much better because I don’t serve myself ads in between my tweets. My timeline feels cleaner.</p>
<h2 id="how-im-using-lucerne">How I’m using Lucerne</h2>
<p>I reached an “MVP” stage with Lucerne a few days ago, and since then, I’ve used Lucerne more and Twitter’s website less for browsing through Twitter. Lucerne isn’t meant to be a Twitter <em>replacement</em>. Twitter’s web app is still great for writing and following threads, for example, and I don’t want to have to re-create something that’s already fine for my use. But for my two main workflows of <em>learning</em> and <em>tracking my progress</em> on Twitter, Lucerne works better for me.</p>
<p>The biggest change I’ve noticed from using the client is that it turns Twitter from a consumption experience into an exploratory experience. Instead of drinking from a firehose through a straw, the firehose feeds into an evolving castle of infinite fountains, and my job is to look around the castle for the fountains of information that seem more interesting or insightful. For the first time in a long time, I feel like I’m pulling from the firehose of Twitter instead of constantly poking straws into the stream to see what I luck out with.</p>
<p>The real fun of using Lucerne to explore Twitter isn’t just reading tweets in a timeline, but poking around in the <a href="https://en.wikipedia.org/wiki/The_Library_of_Babel">infinite library</a> that Twitter sometimes feels like, collecting the interesting streams of information into my pocket.</p>
<p>Here are a few use cases I stumbled into while using Lucerne that I otherwise couldn’t have.</p>
<p><strong>Following interesting threads.</strong> I often stumble into interesting threads of tweets that I want to track somehow. While using Lucerne, I ran into one tweet about <a href="https://twitter.com/geoffreylitt">@geoffreylitt</a> building a Twitter browser extension called Twemex, and another thread by <a href="https://twitter.com/TZhongg">@TZhongg</a> asking for book recommendations. Normally, I would probably just bookmark it and never check it again, but with Lucerne, I just saved filters for “replies to this tweet” as channels in my sidebar, and I’ve checked them regularly since to find interesting project updates and book recommendations.</p>
<p><strong>Following an account’s tweets on a topic.</strong> <a href="https://twitter.com/Noahpinion">@Noahpinion</a> is one of those accounts that have a lot of interesting ideas to share covering a huge range of topics. Sometimes about foreign policy, sometimes about fiscal policy and economics, sometimes about China. I wanted to be able to follow “just tweets about this account on Japan”, for example, and I could do this trivially by setting up a channel <code>from:Noahpinion Japan</code>.</p>
<p><img src="https://thesephist.com/img/lucerne-usercard.jpg" alt="Lucerne looking at tweets by @devonzuegel"></p>
<p><strong>Following an aesthetic.</strong> I noticed recently that a lot of <a href="https://twitter.com/devonzuegel">@devonzuegel</a>’s tweets about urban design either contain interesting quotes from books or inspiring historical photographs. I follow her, but thought it would be nice to have a separate channel to just keep track of these. So I made a filter for <code>from:devonzuegel filter:images</code>, for “tweets containing images from @devonzuegel” which I’ve been enjoying checking once every one or two days. Through this channel, I also discovered a couple of other accounts that share photographs of urban design that I otherwise would have missed.</p>
<p><strong>“Following” high-noise accounts without following.</strong> There are a few accounts, like @naval, @david_perell, or @paulg that occasionally tweet really interesting ideas, but whom I don’t follow because there’s a lot of noise. With Lucerne, I could create channels like <code>from:david_perell -filter:replies min_faves:100</code> to “follow” the most popular tweets from these accounts without actually following them into my home timeline. I’ve found this so useful that I added a “top” button to profile cards that lets me one-click search a filter for “popular tweets from this person”, which is much more helpful than what Twitter’s web app gets you on a profile page, which are just the latest tweets they happened to have sent.</p>
<p>Over time, I think my curated list of channels is going to become an interesting index into my own interests, perspective, and information consumption habits, which I find a really cool idea. I’m excited about how Lucerne can help me use Twitter to learn and share better going forward, and I"m also curious about how I could apply this idea of “tools that grow as you use it” to other parts of my life, like the web browser or my email experience.</p>
<p>And because I know you’re asking: while I don’t think I’m going to make this current version of Lucerne open for public …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesephist.com/posts/lucerne/">https://thesephist.com/posts/lucerne/</a></em></p>]]>
            </description>
            <link>https://thesephist.com/posts/lucerne/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553815</guid>
            <pubDate>Sun, 27 Dec 2020 20:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golang basics – writing unit tests (2017)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25553779">thread link</a>) | @alexellisuk
<br/>
December 27, 2020 | https://blog.alexellis.io/golang-writing-unit-tests/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/golang-writing-unit-tests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>In the previous post titled <a href="http://blog.alexellis.io/golang-json-api-client/">"Grab JSON from an API"</a> we explored how to interact with a HTTP client and parse JSON. This post is a continuation of that theme, which covers unit testing.</p>
<p>I consider the following book as essential reference and reading for Golang, you can purchase it on Amazon: <a href="https://amzn.to/3biQrWJ">Go Programming Language, Addison-Wesley</a>. I'll cover some other recommendations at the end of the post.</p>
<blockquote>
<p>Book a 1:1 coaching session with me to learn more about Go, unit-testing and how to package your applications with Docker and Kubernetes. <a href="https://calendly.com/alexellis/1-1-discounted-coaching?month=2020-12">Book now</a></p>
</blockquote>
<h2 id="1testingingo">1. Testing in Go</h2>
<p>Go has a built-in testing command called <code>go test</code> and a package <code>testing</code> which combine to give a minimal but complete testing experience.</p>
<p>The standard tool-chain also includes benchmarking and statement-based code coverage similar to NCover (.NET) or Istanbul (Node.js).</p>
<p><strong>Share &amp; follow on Twitter:</strong></p>
<blockquote data-lang="en"><p lang="en" dir="ltr">Master unit testing in <a href="https://twitter.com/golang">@golang</a> - isolating dependencies, using fakes and checking code coverage with built-in tools. <a href="https://t.co/YiuAmrupGC">https://t.co/YiuAmrupGC</a></p>— Alex Ellis (@alexellisuk) <a href="https://twitter.com/alexellisuk/status/830059602742013953">February 10, 2017</a></blockquote> 
<h3 id="12writingtests">1.2 Writing tests</h3>
<p>Unit testing in Go is just as opinionated as any other aspect of the language like formatting or naming. The syntax deliberately avoids the use of assertions and leaves the responsibility for checking values and behaviour to the developer.</p>
<p>Here is an example of a method we want to test in the <code>main</code> package. We have defined an exported function called <code>Sum</code> which takes in two integers and adds them together.</p>
<pre><code>package main

func Sum(x int, y int) int {
    return x + y
}

func main() {
    Sum(5, 5)
}
</code></pre>
<p>We then write our test in a separate file. The test file can be in a different package (and folder) or the same one (<code>main</code>). Here's a unit test to check addition:</p>
<pre><code>package main

import "testing"

func TestSum(t *testing.T) {
    total := Sum(5, 5)
    if total != 10 {
       t.Errorf("Sum was incorrect, got: %d, want: %d.", total, 10)
    }
}
</code></pre>
<p>Characteristics of a Golang test function:</p>
<ul>
<li>The first and only parameter needs to be <code>t *testing.T</code></li>
<li>It begins with the word Test followed by a word or phrase starting with a capital letter.</li>
<li>(usually the method under test i.e. <code>TestValidateClient</code>)</li>
<li>Calls <code>t.Error</code> or <code>t.Fail</code> to indicate a failure (I called t.Errorf to provide more details)</li>
<li><code>t.Log</code> can be used to provide non-failing debug information</li>
<li>Must be saved in a file named <code>something_test.go</code> such as: <code>addition_test.go</code></li>
</ul>
<blockquote>
<p>If you have code and tests in the same folder then you cannot execute your program with <code>go run *.go</code>. I tend to use <code>go build</code> to create a binary and then I run that.</p>
</blockquote>
<p>You may be more used to using the <code>Assert</code> keyword to perform checking, but the authors of <a href="https://www.amazon.co.uk/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440">The Go Programming Language</a> make some good arguments for Go's style over Assertions.</p>
<p>When using assertions:</p>
<ul>
<li>tests can feel like they're written in a different language (RSpec/Mocha for instance)</li>
<li>errors can be cryptic "assert: 0 == 1"</li>
<li>pages of stack traces can be generated</li>
<li>tests stop executing after the first assert fails - masking patterns of failure</li>
</ul>
<blockquote>
<p>There are third-party libraries that replicate the feel of RSpec or Assert. See also <a href="https://github.com/stretchr/testify">stretchr/testify</a>.</p>
</blockquote>
<p><strong>Test tables</strong></p>
<p>The concept of "test tables" is a set (slice array) of test input and output values. Here is an example for the <code>Sum</code> function:</p>
<pre><code>package main

import "testing"

func TestSum(t *testing.T) {
	tables := []struct {
		x int
		y int
		n int
	}{
		{1, 1, 2},
		{1, 2, 3},
		{2, 2, 4},
		{5, 2, 7},
	}

	for _, table := range tables {
		total := Sum(table.x, table.y)
		if total != table.n {
			t.Errorf("Sum of (%d+%d) was incorrect, got: %d, want: %d.", table.x, table.y, total, table.n)
		}
	}
}
</code></pre>
<p>If you want to trigger the errors to break the test then alter the <code>Sum</code> function to return <code>x * y</code>.</p>
<pre><code>$ go test -v
=== RUN   TestSum
--- FAIL: TestSum (0.00s)
	table_test.go:19: Sum of (1+1) was incorrect, got: 1, want: 2.
	table_test.go:19: Sum of (1+2) was incorrect, got: 2, want: 3.
	table_test.go:19: Sum of (5+2) was incorrect, got: 10, want: 7.
FAIL
exit status 1
FAIL	github.com/alexellis/t6	0.013s
</code></pre>
<p><strong>Launching tests:</strong></p>
<p>There are two ways to launch tests for a package. These methods work for unit tests and integration tests alike.</p>
<ol>
<li>Within the same directory as the test:</li>
</ol>
<pre><code>go test
</code></pre>
<p><em>This picks up any files matching packagename_test.go</em></p>
<p>or</p>
<ol start="2">
<li>By fully-qualified package name</li>
</ol>
<pre><code>go test github.com/alexellis/golangbasics1
</code></pre>
<p>You have now run a unit test in Go, for a more verbose output type in <code>go test -v</code> and you will see the PASS/FAIL result of each test including any extra logging produced by <code>t.Log</code>.</p>
<blockquote>
<p>The difference between unit and integration tests is that unit tests usually isolate dependencies that communicate with network, disk etc. Unit tests normally test only one thing such as a function.</p>
</blockquote>
<h2 id="13moreongotest">1.3 More on <code>go test</code></h2>
<p><strong>Statement coverage</strong></p>
<p>The <code>go test</code> tool has built-in code-coverage for statements. To try it with out example above type in:</p>
<pre><code>$ go test -cover
PASS
coverage: 50.0% of statements
ok  	github.com/alexellis/golangbasics1	0.009s
</code></pre>
<p>High statement coverage is better than lower or no coverage, but metrics can be misleading. We want to make sure that we're not only executing statements, but that we're verifying behaviour and output values and raising errors for discrepancies. If you delete the "if" statement from our previous test it will retain 50% test coverage but lose its usefulness in verifying the behaviour of the "Sum" method.</p>
<p><strong>Generating an HTML coverage report</strong></p>
<p>If you use the following two commands you can visualise which parts of your program have been covered by the tests and which statements are lacking:</p>
<pre><code>go test -cover -coverprofile=c.out
go tool cover -html=c.out -o coverage.html 
</code></pre>
<p>Then open coverage.html in a web-browser.</p>
<p><strong>Go doesn't ship your tests</strong></p>
<p>In addition, it may feel un-natural to leave files named <code>addition_test.go</code> in the middle of your package. Rest assured that the Go compiler and linker will not ship your test files in any binaries it produces.</p>
<p>Here is an example of finding the production vs test code in the net/http package we used in the previous Golang basics tutorial.</p>
<pre><code>$ go list -f={{.GoFiles}} net/http
[client.go cookie.go doc.go filetransport.go fs.go h2_bundle.go header.go http.go jar.go method.go request.go response.go server.go sniff.go status.go transfer.go transport.go]

$ go list -f={{.TestGoFiles}} net/http
[cookie_test.go export_test.go filetransport_test.go header_test.go http_test.go proxy_test.go range_test.go readrequest_test.go requestwrite_test.go response_test.go responsewrite_test.go transfer_test.go transport_internal_test.go]
</code></pre>
<p>For more on the basics read the <a href="https://golang.org/pkg/testing/">Golang testing docs</a>.</p>
<h3 id="14isolatingdependencies">1.4 Isolating dependencies</h3>
<p>The key factor that defines a unit test is isolation from runtime-dependencies or collaborators.</p>
<p>This is achieved in Golang through interfaces, but if you're coming from a C# or Java background, they look a little different in Go. Interfaces are implied rather than enforced which means that concrete classes don't need to know about the interface ahead of time.</p>
<p>That means we can have very small interfaces such as <a href="https://golang.org/src/io/io.go?s=4977:5022#L116">io.ReadCloser</a> which has only two methods made up of the Reader and Closer interfaces:</p>
<pre><code>        Read(p []byte) (n int, err error)
</code></pre>
<p><em>Reader interface</em></p>
<pre><code>        Close() error
</code></pre>
<p><em>Closer interface</em></p>
<p>If you are designing a package to be consumed by a third-party then it makes sense to design interfaces so that others can write unit tests to isolate your package when needed.</p>
<p>An interface can be substituted in a function call. So if we wanted to test this method, we'd just have to supply a fake / test-double class that implemented the Reader interface.</p>
<pre><code>package main

import (
	"fmt"
	"io"
)

type FakeReader struct {
}

func (FakeReader) Read(p []byte) (n int, err error) {
	// return an integer and error or nil
}

func ReadAllTheBytes(reader io.Reader) []byte {
	// read from the reader..
}

func main() {
	fakeReader := FakeReader{}
	// You could create a method called SetFakeBytes which initialises canned data.
	fakeReader.SetFakeBytes([]byte("when called, return this data"))
	bytes := ReadAllTheBytes(fakeReader)
	fmt.Printf("%d bytes read.\n", len(bytes))
}
</code></pre>
<p>Before implementing your own abstractions (as above) it is a good idea to search the Golang docs to see if there is already something you can use. In the case above we could also use the standard library in the <a href="https://golang.org/pkg/bytes/">bytes</a> package:</p>
<pre><code>    func NewReader(b []byte) *Reader
</code></pre>
<p>The Golang <a href="https://golang.org/pkg/testing/iotest/">testing/iotest</a> package provides some Reader implementations which are slow or which cause errors to be thrown half way through reading. These are ideal for resilience testing.</p>
<ul>
<li>Golang docs: <a href="https://golang.org/pkg/testing/iotest/">testing/iotest</a></li>
</ul>
<h3 id="15workedexample">1.5 Worked example</h3>
<p>I'm going to refactor the code example from the <a href="http://blog.alexellis.io/golang-json-api-client/">previous article</a> where we found out how many astronauts were in space.</p>
<p>We'll start with the test file:</p>
<pre><code>package main

import "testing"

type testWebRequest struct {
}

func (testWebRequest) FetchBytes(url string) []byte {
	return []byte(`{"number": 2}`)
}

func TestGetAstronauts(t *testing.T) {
	amount := GetAstronauts(testWebRequest{})
	if amount != 1 {
		t.Errorf("People in space, got: %d, want: %d.", amount, 1)
	}
}
</code></pre>
<p>I have an exported method called GetAstronauts which calls into a HTTP endpoint, reads the bytes from the result and then parses this into a struct and returns the integer in the "number" property.</p>
<p>My fake / test-double in the test only returns the bare minimum of JSON needed to satisfy the test, and to begin with I had it return a different number so that I knew the test worked. It's hard to be sure whether a test that passes first time has worked.</p>
<p>Here's the application code where we run our <code>main</code> function. The <code>GetAstronauts</code> function takes an interface as its first argument allowing us to isolate and abstract away any HTTP logic from this file and its import list.</p>
<pre><code>package main

import (
	"encoding/json"
	"fmt"
	"log"
)

func GetAstronauts(getWebRequest GetWebRequest) int {
	url := "http://api.open-notify.org/astros.json"
	bodyBytes := getWebRequest.FetchBytes(url)
	peopleResult := people{}
	jsonErr := json.Unmarshal(bodyBytes, &amp;peopleResult)</code></pre></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/golang-writing-unit-tests/">https://blog.alexellis.io/golang-writing-unit-tests/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/golang-writing-unit-tests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553779</guid>
            <pubDate>Sun, 27 Dec 2020 19:59:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cory Doctorow (CCC): What the cyberoptimists got wrong – and what to do about it]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25553662">thread link</a>) | @aleclm
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=doctorow">doctorow</a>

</p>


<!-- %h3 About -->
<p>They stole our future. Let's take it back.</p>

<p>Here at the end of the world, it's time to take stock. Is technology a force for good? Can it be? Was it ever? How did we end up with a world made up of "five websites, each filled with screenshots of text from the other four" (h/t Tom Eastman)? Should we worry that machine learning will take away our free will through A/B splitting and Big Five Personality Types? Where the fuck did all these Nazis come from? </p>

<h3>Download</h3>
<div>
<p>

Downloads will appear here, once final recordings are released.
</p></div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553662</guid>
            <pubDate>Sun, 27 Dec 2020 19:42:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Matrix: One Chat Protocol to Rule Them All]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25553235">thread link</a>) | @ohjeez
<br/>
December 27, 2020 | https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/ | <a href="https://web.archive.org/web/*/https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>

  

  <article>
    

    <figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/matrix.png" alt="Matrix Logo Surrounded by Logos for Hangouts, Telegram, Messenger and Signal pointing to it">
  
  
</figure>

<p>Once upon a time, there were many chat services. AOL Instant Messenger, Yahoo Messenger, ICQ and others. These messengers had their own desktop clients, and developers reverse engineered their protocol to build custom applications, both open and closed source. Trillian, Audium and Pidgin were applications that let people communicate across all these messengers with one program. Over time the old protocols died, and newer chat services like Facebook Messenger and Google Hangouts started storing your entire history on their servers. People started using the web interfaces and mobile apps, no longer caring about desktop programs.</p>

<p>Matrix is an open source communication protocol. It’s similar to XMPP (formerly Jabber) in the sense that anyone can set up a Matrix server and communicate to people on other Matrix servers. It’s a federated protocol, just like e-mail. Google Hangouts used to support XMPP federation, but silently removed support in 2014. Matrix supports bridging other chat services, so they can appear in a unified view. With my current setup of Matrix and appropriate bridges, I’ve combined my view of Facebook Messenger, Google Hangouts, Telegram and native Matrix chats into one convenient user interface. The path to get to that integration was not as simple.</p>

<!--more-->

<p>The dedicated server I use for <a href="https://battlepenguin.com/tech/a-history-of-personal-and-professional-websites/">this website</a> and other self-hosted web applications, is located in Germany. Logging in to Facebook or Google’s chat system from a country I’m not currently in, can raise all sorts of security flags and lock me out of my account. For those bridges, I purchased a small virtual machine in a Chicago data center. I installed a proxy on that server, accessible only via VPN, to view both Google and Facebook, so they record the IP address I’m connecting from with my web browser. This helps minimize security lockouts. Telegram isn’t hostile to third party developers, and has an official API. It doesn’t care my bridge is connecting to it from Germany, so I host it on the dedicated server.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/server-diagram.png" alt="Server Diagram of Matrix Homeserver and Bridges">
  
  
  <figcaption>
      

      Server Diagram of Matrix Homeserver and Bridges

      
  </figcaption>
  
</figure>

<p>The reference Matrix server is called Synapse. It, as well as the <a href="https://github.com/tulir/mautrix-telegram">mautrix-telegram</a>, <a href="https://github.com/tulir/mautrix-hangouts">mautrix-hangouts</a> and <a href="https://github.com/tulir/mautrix-facebook">mautrix-facebook</a> bridges all have official Docker containers built by their developers. Each bridge must be able to communicate with the Synapse homeserver. Their instructions go through generating configuration and key pairs that are copied over to Synapse in order to form their authentication bridge. The bridges provide chat robots that guide you through getting OAuth tokens or cookies for those respective services.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/element-screenshot.png" alt="Facebook and Hangouts Chats in Element">
  
  
  <figcaption>
      

      Facebook and Hangouts Chats in Element

      
  </figcaption>
  
</figure>

<p>The wiki for each bridge also has instructions for enabling double-puppeting, making each chat look seamless between myself and the accounts on the other side of each respective bridge. Without double-puppeting, each conversation will be in a three person group with the Matrix user, the bridge user (e.g my Google Hangouts user) and the person I’m talking to.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/no-double-puppet.png" alt="Chat Without Double-Puppeting Enabled">
  
  
  <figcaption>
      

      Chat Without Double-Puppeting Enabled

      
  </figcaption>
  
</figure>

<p>Enabling double-puppeting via the <code>curl</code> command in the bridge documentation and calling <code>login-matrix</code> on the bot, removes the creation of three person rooms. The bridged accounts will now show up as regular, two-person conversations.</p>

<p>I use the Element desktop app to connect to my matrix server, but I also have a web version of Element running from its own official Docker container in case I need to access chat from another computer. There are other clients, such as <a href="https://github.com/mirukana/mirage">Mirage</a> which is built using Qt and <a href="https://fluffychat.im/">Fluffychat</a> for mobile. Although I use Synapse for my homeserver, there are other servers that support the Matrix protocol that are in use and under active development.</p>

<p>Setting up all the Matrix components wasn’t too difficult, but it does require knowledge or experience with running services. It took a considerable amount of work and debugging to get each bridge operational, compounded slightly by my complex networking setup. Most people would probably just run all of this on a Raspberry Pi at home. I feel that using Matrix with bridges is still somewhat inaccessible to people who aren’t interested in development or server administration. Still, the satisfaction of having unified chat, plus one more layer of abstraction between myself and Google or Facebook, feels like it was wroth the overall effort.</p>


    

  </article>

</section>



    </div></div>]]>
            </description>
            <link>https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553235</guid>
            <pubDate>Sun, 27 Dec 2020 18:45:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A first look at Ghidra’s Debugger – Game Boy Advance Edition]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25553105">thread link</a>) | @mr_golyadkin
<br/>
December 27, 2020 | https://wrongbaud.github.io/posts/ghidra-debugger/ | <a href="https://web.archive.org/web/*/https://wrongbaud.github.io/posts/ghidra-debugger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src=""></p><h2 id="overview">Overview</h2><p><a href="https://twitter.com/NSACyber/status/1339652646513291264">Yesterday</a> the NSA Twitter account announced that a new branch of Ghidra has been release with the long-awaited debugging capability. This will allow for single-step debugging of a program within <a href="https://hackaday.io/course/172292-introduction-to-reverse-engineering-with-ghidra">Ghidra</a> through a GDB stub or other various debug mechanisms. To celebrate this (and my being stuck at home quarantining…) I wanted to review how to build this version of Ghidra and give an example of how to use this debugger on a fun target.</p><p>This post will explain the following:</p><ul><li>How to build the latest (or any) version of Ghidra using a <a href="https://github.com/dukebarman/ghidra-builder">Docker Container</a></li><li>How to build the Ghidra Eclipse plugins</li><li>How to build a program <a href="https://github.com/SiD3W4y/GhidraGBA">loader</a> for Ghidra</li><li>Debugging a program with Ghidra using the GDB stub</li><li>Use the debugging capability to help us learn about how passwords are processed for a GBA game</li></ul><p>For this post, we’re going to be taking a look at the Game Boy Advance game Spiderman: Mysterio’s Menace. I’ve been very much inspired by all of the awesome work that <a href="https://youtu.be/VVbRe7wr3G4">stacksmashing and Liveoverflow have been doing regarding these topics</a>. This was a game that I spent a lot of time playing and it’s always fun revisiting childhood favorites from an RE perspective. The ultimate goal is to demonstrate how to properly load this ROM using a custom loader, and connect to an emulator’s GDB stub using Ghidra’s debugging features.</p><p><strong>RE Note/Tangent:</strong> When taking on a new reversing project, it’s important to try to compartmentalize goals and targets. For example, if we said we just want to <em>reverse</em> this game, that opens up endless possibilities. We could reverse engineer the collision detection, how enemy AI works, or how level maps are generated. For this post, we will pick a specific target and take a look at the password mechanism in use by this game.</p><p>I am doing all of this work on an Ubuntu 20.04 machine, with the latest updates.</p><h2 id="building-ghidra">Building Ghidra</h2><p>First things first, this debugger branch has not yet been included in an official release so we’re going to have to build it ourselves. Luckily for us <a href="https://github.com/dukebarman/ghidra-builder">dukebarman</a> has put together a docker container for us to do this, all we need to do is modify the <code>build_ghidra.sh</code> script to checkout the debugger branch, see the following line below:</p><div><p><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>git clone https://github.com/NationalSecurityAgency/ghidra -b debugger
</pre></td></tr></tbody></table></code></p></div><p>We are also going to build the Eclipse development extensions for this version of Ghidra, this will help us later on when we build a loader and write our analysis scripts. To do this we add the following line to the <code>build_ghidra.sh</code> script:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gradle prepDev
gradle eclipse -PeclipsePDE
</pre></td></tr></tbody></table></code></p></div><p>Next follow the instructions in the <code>README</code>:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>cd ghidra-builder
sudo docker-tpl/build
cd workdir
sudo ../docker-tpl/run ./build_ghidra.sh
</pre></td></tr></tbody></table></code></p></div><p>This will take some time, so maybe go grab a coffee or two and come back to your freshly built Ghidra. The resulting build can be found in <code>workdir/out</code>:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>wrongbaud@wubuntu:~/blog/gba-re-gbd/ghidra-builder/workdir$ ls out/
ghidra_9.3_DEV_20201218_linux64.zip
</pre></td></tr></tbody></table></code></p></div><p>Unzip this file, and you can launch Ghidra via the <code>./ghidraRun</code> script. For this post, I will unzip this into the <code>ghidra-builder/workdir</code> directory because we’re going to be using the docker container to build a Ghidra loader for this version of Ghidra. If you’re following along, your workdir directory should look like this:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>wrongbaud@wubuntu:~/blog/gba-re-gbd/ghidra-builder/workdir$ ls
build_ghidra.sh  ghidra  ghidra_9.3_DEV out  set_exec_flag.sh
</pre></td></tr></tbody></table></code></p></div><h2 id="building-eclipse-plugins">Building Eclipse Plugins</h2><p>Now that we have a new version of Ghidra built, we also need to build the GhidraDev plugin for Eclipse. The eclipse projects can be found in the <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev</code> directory.</p><ol><li>Install <a href="https://www.eclipse.org/downloads/packages/installer">Eclipse</a><ul><li>Select the Java IDE</li></ul></li><li>Install CDT, PyDev, and Plugin Development Environment<ul><li>This can be done from the Eclipse marketplace</li></ul></li><li>Import the GhidraDevFeature and GhidraDevPlugin projects<ul><li>These can be found in the <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev/</code> directory</li><li><code>File</code> -&gt; <code>Import</code> -&gt; <code>General</code> -&gt; <code>Existing Projects into Workspace</code></li><li>Add <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev</code></li><li>Select “Search for nested projects”</li><li>Import the projects!</li><li><strong>Note:</strong> you may see some build errors when these are imported, you can ignore these as you are just exporting the plugin!</li></ul></li><li>With these projects loaded, we can now <a href="https://github.com/NationalSecurityAgency/ghidra/blob/debugger/GhidraBuild/EclipsePlugins/GhidraDev/GhidraDevPlugin/build_README.txt">export the plugin</a><ul><li><code>File</code> -&gt; <code>Export</code></li><li><code>Plug-in Development</code> -&gt; <code>Deployable Features</code></li><li><code>ghidradev.ghidradev</code></li><li>Select an archive location for the plugin to be exported to</li><li>Click Finish!</li></ul></li></ol><p>Now we have our Ghidra plugin, built for our custom version of Ghidra that we can load via <code>Help</code>-&gt;<code>Install New Software</code>.</p><p>And with that, we have built Ghidra from the <code>debugger</code> branch, and have also built the Eclipse development extensions so we can build plugins for our new version of Ghidra!</p><p><strong>Note:</strong> I just want to take a second to outline just how incredible the <a href="https://github.com/NationalSecurityAgency/ghidra/blob/15c1f43fa51f210836cb451aff587b227dffe0a7/DevGuide.md">help docs</a> are for Ghidra. From the P-Code manuals to the instructions on building and exporting these plugins - the project is very well documented.</p><h2 id="building-the-rom-loader">Building the ROM Loader</h2><p>To properly analyze this ROM in Ghidra, we are going to need to define all of the <a href="https://problemkaputt.de/gbatek.htm#gbamemorymap">memory regions and peripherals</a> for the Game Boy Advance. Luckily for us, <a href="https://github.com/SiD3W4y/GhidraGBA">SiD3W4y</a> on GitHub has already written one.</p><p>If you are a regular reader of this blog, a <a href="https://wrongbaud.github.io/posts/writing-a-ghidra-loader/">ghidra loader</a> may be a familiar subject to you. If not, the purpose of a Ghidra loader is to set up all of the necessary memory regions, identify any debug information or symbols that may be present in the file, and provide as much information as possible about the target file. The loader that was mentioned before outlines all of the basic peripherals of the GBA and is an excellent example loader to work with, let’s start by cloning it into the <code>ghidra-builder/workdir</code> directory. We’re doing this because we’re going to use the same docker container we built Ghidra with to build this loader.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre>cd ghidra-builder/workdir
git clone https://github.com/SiD3W4y/GhidraGBA
sudo ../docker-tpl/run /bin/bash
dockerbot@797eb43ce05f:/files/GhidraGBA$ export GHIDRA_INSTALL_DIR=/files/ghidra_9.3_DEV/
dockerbot@797eb43ce05f:/files/GhidraGBA$ gradle
dockerbot@797eb43ce05f:/files/GhidraGBA$ cp dist/ghidra_9.3_DEV_20201218_GhidraGBA.zip ../ghidra_9.3_DEV/Extensions/Ghidra/
dockerbot@797eb43ce05f:/files/GhidraGBA$ exit
exit
</pre></td></tr></tbody></table></code></p></div><p>In case the above steps are confusing, what we are doing is:</p><ol><li>Launching the docker container</li><li>Building the GhidraGBA extension, providing the path to our installation</li><li>Copying it to Ghidra’s extensions directory (so it will show up under the Install Extensions menu)</li><li>Exiting the docker container</li></ol><p>Launch Ghidra via <code>ghidraRun</code> and go to <code>File</code>-&gt; <code>Install Extensions</code>. Select the GhidraGBA loader and click <code>OK</code>. You will need to restart Ghidra for the change to take effect. Now when you load a GBA ROM you should see the following:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/gba.png" alt="GBA" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/gba.png"></p><p>After running the auto analysis, Ghidra seems to make a pretty quick sense of the ROM. There are a lot of functions defined and things are looking good. So the next step is to figure out some way to narrow down what we care about in this ROM image, in other words, we need to find our needle in the haystack. Let’s start by examining how the password system works in this game by entering a few passwords.</p><h2 id="analyzing-the-rom">Analyzing the Rom</h2><p>As mentioned before, our goal here is to try to understand the password system in use by this game. If we attempt to enter a password, the following screen is displayed:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/rom-1.png" alt="ROM1" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/rom-1.png"></p><p>Note that we have all of the consonants and no vowels and numbers “0-9”, and our passwords are only 5 characters long. This is a nice starting point for us as reverse engineers. We can use this information to help us narrow down functions of interest. For example- let’s look through the strings in the ROM and see if these values are represented in a string somewhere. If we open the strings window, <code>Window</code> -&gt; <code>Defined Strings</code>, and filter for the first 5 characters available to us as password characters we see the following:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/strings-password-characters.png" alt="" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/strings-password-characters.png"></p><p>So far so good - we only have two instances of this string in use. One is located at <code>0x804c11fc</code> and one at <code>0x84b86f0</code>. Upon examination of the first one, we see that this string gets passed to a function in the subroutine located at <code>0x8003358</code>, see below:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>undefined4</span> <span>passwd_1</span><span>(</span><span>int</span> <span>param_1</span><span>,</span><span>int</span> <span>param_2</span><span>)</span>

<span>{</span>
  <span>int</span> <span>iVar1</span><span>;</span>
  <span>uint</span> <span>uVar2</span><span>;</span>
  <span>uint</span> <span>uVar3</span><span>;</span>
  <span>undefined4</span> <span>in_lr</span><span>;</span>
  <span>undefined</span> <span>auStack52</span> <span>[</span><span>36</span><span>];</span>
  <span>undefined4</span> <span>uStack4</span><span>;</span>
  
  <span>uStack4</span> <span>=</span> <span>in_lr</span><span>;</span>
  <span>FUN_080231f4</span><span>(</span><span>auStack52</span><span>,</span><span>"BCDFGHJKLMNPQRSTVWXYZ0123456789-"</span><span>,</span><span>0x21</span><span>);</span>
  <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>param_1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>=</span> <span>0</span><span>;</span>
  <span>FUN_080025f8</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_08002674</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_08002714</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_0800282c</span><span>(</span><span>param_1</span><span>);</span>
  <span>iVar1</span> <span>=</span> <span>0</span><span>;</span>
  <span>uVar3</span> <span>=</span> <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>param_1</span> <span>+</span> <span>0x8c</span><span>);</span>
  <span>uVar2</span> <span>=</span> <span>0</span><span>;</span>
  <span>do</span> <span>{</span>
    <span>*</span><span>(</span><span>undefined</span> <span>*</span><span>)(</span><span>param_2</span> <span>+</span> <span>iVar1</span><span>)</span> <span>=</span> <span>auStack52</span><span>[</span><span>uVar3</span> <span>&gt;&gt;</span> <span>(</span><span>uVar2</span> <span>&amp;</span> <span>0xff</span><span>)</span> <span>&amp;</span> <span>0x1f</span><span>];</span>
    <span>uVar2</span> <span>=</span> <span>uVar2</span> <span>+</span> <span>5</span><span>;</span>
    <span>iVar1</span> <span>=</span> <span>iVar1</span> <span>+</span> <span>1</span><span>;</span>
  <span>}</span> <span>while</span> <span>(</span><span>iVar1</span> <span>&lt;</span> <span>5</span><span>);</span>
  <span>return</span> <span>uStack4</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></p></div><p>Notice also the while loop that is looping while a variable is less than five, this is a good indicator that this function might be useful as we know that the password length is 5! Let’s label it <code>passwd_1</code> and move onto the other uses of our character string. The next one that we can see is in the function at <code>0x8002CEC</code>, the decompilation can be seen below:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
</pre></td><td><pre><span>undefined8</span> <span>passwd_2</span><span>(</span><span>void</span><span>)</span>

<span>{</span>
  <span>int</span> <span>iVar1</span><span>;</span>
  <span>int</span> <span>iVar2</span><span>;</span>
  <span>uint</span> <span>uVar3</span><span>;</span>
  <span>undefined4</span> <span>in_lr</span><span>;</span>
  <span>undefined</span> <span>local_98</span> <span>[</span><span>5</span><span>];</span>
  <span>undefined</span> <span>local_93</span><span>;</span>
  <span>undefined</span> <span>auStack144</span> <span>[</span><span>36</span><span>];</span>
  <span>undefined</span> <span>auStack108</span> <span>[</span><span>8</span><span>];</span>
  <span>undefined</span> <span>auStack100</span> <span>[</span><span>72</span><span>];</span>
  <span>undefined4</span> <span>uStack4</span><span>;</span>
  
  <span>uStack4</span> <span>=</span> <span>in_lr</span><span>;</span>
  <span>FUN_08000b0c</span><span>(</span><span>0</span><span>,</span><span>1</span><span>,</span><span>0</span><span>,</span><span>0</span><span>);</span>
  <span>DAT_03001fd0</span><span>.</span><span>_0_2_</span> <span>=</span> <span>0x1444</span><span>;</span>
  <span>DISPCNT</span> <span>=</span> <span>0x1444</span><span>;</span>
  <span>FUN_0801e330</span><span>(</span><span>&amp;</span><span>DAT_0838277c</span><span>);</span>
  <span>iVar1</span> <span>=</span> <span>DAT_03001fe0</span><span>;</span>
  <span>FUN_080231f4</span><span>(</span><span>auStack144</span><span>,</span><span>"BCDFGHJKLMNPQRSTVWXYZ0123456789-"</span><span>,</span><span>0x21</span><span>);</span>
  <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>iVar1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>=</span> <span>0</span><span>;</span>
  <span>FUN_080025f8</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_08002674</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_08002714</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_0800282c</span><span>(</span><span>iVar1</span><span>);</span>
  <span>iVar2</span> <span>=</span> <span>0</span><span>;</span>
  <span>uVar3</span> <span>=</span> <span>0</span><span>;</span>
  <span>do</span> <span>{</span>
    <span>local_98</span><span>[</span><span>iVar2</span><span>]</span> <span>=</span> <span>auStack144</span><span>[</span><span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>iVar1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>&gt;&gt;</span> <span>(</span><span>uVar3</span> <span>&amp;</span> <span>0xff</span><span>)</span> <span>&amp;</span> <span>0x1f</span>…</pre></td></tr></tbody></table></code></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wrongbaud.github.io/posts/ghidra-debugger/">https://wrongbaud.github.io/posts/ghidra-debugger/</a></em></p>]]>
            </description>
            <link>https://wrongbaud.github.io/posts/ghidra-debugger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553105</guid>
            <pubDate>Sun, 27 Dec 2020 18:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Cyberpunk 2077 Gets Wrong About the Genre]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25552923">thread link</a>) | @kiraleighleigh
<br/>
December 27, 2020 | https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/ | <a href="https://web.archive.org/web/*/https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Though this is a blog for media critiques, side stories for <a href="https://constelisvoss.ml/">CONSTELIS VOSS</a>, news, art posts, etc, I feel like the only place this article can live is <em>here</em>.</p><p>Not on <a href="https://weebtrash.ga/">weebtrash</a>. Not on <a href="https://medium.com/@kiraIeigh">Medium</a>. Not on <a href="https://www.linkedin.com/in/kirakiraleighleigh">LinkedIn</a>. Here, in a space centered on a sci-fi trilogy about robots, corruption, tropes, and what it means to be a person.</p><p>Cyberpunk 2077 was initially framed as an ambitious stab at a genre often overlooked in popular media; this was a promise.</p><p>Sadly, Cyberpunk 2077 misses the mark, despite being an overall very enjoyable game. CD Projekt Red's treatment of the genre is worse than the buggy launch, and I'm going to explain how and why.</p><p>First, let's explore two IPs that do it right. Then, we'll compare Cyberpunk 2077 against their core messaging.</p><p>Let's begin.</p><h2 id="how-ghost-in-the-shell-tackles-cyberpunk">How Ghost in the Shell Tackles Cyberpunk</h2><h3 id="all-barriers-are-moot">All barriers are moot</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/MOSHED-2020-12-4-13-22-6-2.gif" alt=""></figure><p>Wikipedia's explanation of the Cyberpunk genre:</p><blockquote><strong>Cyberpunk</strong> is a <a href="https://en.wikipedia.org/wiki/Subgenre">subgenre</a> of <a href="https://en.wikipedia.org/wiki/Science_fiction">science fiction</a> in a <a href="https://en.wikipedia.org/wiki/Dystopia">dystopian</a> <a href="https://en.wikipedia.org/wiki/Futurism">futuristic</a> setting that tends to focus on a "combination of <a href="https://en.wikipedia.org/wiki/Low-life">low-life</a> and <a href="https://en.wikipedia.org/wiki/High_tech">high tech</a>"<sup><a href="https://en.wikipedia.org/wiki/Cyberpunk#cite_note-1">[1]</a></sup> featuring advanced technological and scientific achievements, such as <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a> and <a href="https://en.wikipedia.org/wiki/Cybernetics">cybernetics</a>, juxtaposed with a degree of breakdown or radical change in the <a href="https://en.wikipedia.org/wiki/Social_order">social order</a>.</blockquote><p>But it's so much more than that. Look no further than <a href="https://en.wikipedia.org/wiki/Ghost_in_the_Shell">Ghost in the Shell</a> for a deeper examination.</p><p>Ghost in the Shell is about a lot of things, but what makes it a great overview of the genre itself is that Motoko Kusanagi—the protagonist—isn't limited by her physical body.</p><p>The body is a tool. The soul (Ghost) is what matters, and even that can be reconfigured, if one chooses.</p><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/OK6W_koKDTOqqqLDbIoPAvKwT3u7zGxQ6vZ1ij2uHr8.gif" alt=""></figure><p>Motoko moves through cyberspace, breaks her body to fight her opponents, and exists as a tour de force in a landscape of corruption.</p><p>As the IP has multiple iterations, different topics take the forefront in different mediums. However, Motoko is always the through-line; a cybernetic warrior who uses a canonically pleasure-district shell, augmented to beat the crap out of her opponents, regardless of the physical costs.</p><p>Furthermore, in the 90s movie, she meets a sentient AI who she merges with to yet again break human barriers (and touch on sentiency).</p><p>Barriers are no object, and choices are fathomless, despite being in a world of corruption. Cyberpunk technology affords this.</p><p>That is the backbone of the Cyberpunk genre, as explained by Ghost in the Shell. </p><h2 id="how-blade-runner-tackles-cyberpunk">How Blade Runner tackles Cyberpunk</h2><h3 id="what-is-sentiency-what-is-agency">What is sentiency? What is agency?</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/f11157d2551ba0894c07a55b5f0dd9aa.gif" alt=""></figure><p>The original <a href="https://en.wikipedia.org/wiki/Blade_Runner">Blade Runner</a> film centers around synthetic beings (replicants) going rogue. Harrison Ford's Deckard is on a mission to reel-in misbehaving androids; that's the low media literacy baby-shit-brain reading.</p><p>You could also read Deckard as possibly being a synth himself. Or, you could read Deckard's attraction to Rachael—a replicant—as a question about love. Can androids truly love?</p><p>You could also read it as a commentary on sentiency via Pris and Roy's (both replicants) existential crises.</p><p>In the new film, <a href="https://en.wikipedia.org/wiki/Blade_Runner_2049">Blade Runner 2049</a>, you could read Gosling's K—another replicant—as experiencing true personhood through the juxtaposition of who he isn't.</p><p>By questioning his place in the narrative when he realizes his memories are fake, he explodes with emotion, and dies with the knowledge that he's challenged what he even is. That's sentiency, baby.</p><p>There are many concepts in the Blade Runner movies, and the <a href="https://en.wikipedia.org/wiki/Do_Androids_Dream_of_Electric_Sheep%3F">novel </a>they're based on, but all of them grapple with these topics:</p><p>Who gets to be a person, who gets to be free, who gets to feel, who gets to live, and who doesn't.</p><p>The backbone of the Blade Runner IP exists to question these aspects of sentiency and agency.</p><p>So what does Cyberpunk 2077 do with GiTS' and Blade Runner's hot-takes?</p><h2 id="cyberpunk-2077-fumbles-barriers-are-moot">Cyberpunk 2077 fumbles "barriers are moot"</h2><h3 id="the-body-is-not-sacred-game-director-adam-badowski">The body is not sacred, game director Adam Badowski</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/MOSHED-2020-12-4-14-50-53-2.gif" alt=""></figure><blockquote>"This is cyberpunk, so people augment their body. So the body is no longer sacrum [sacred]; it's profanum [profane]. Because people modify everything, they are losing their connection to the body, to the meat. And that's why we need to use the nudity in many situations."</blockquote><p>The Cyberpunk genre is about the philosophy of personhood and human existence as juxtaposed to and twisted against technology, set upon a backdrop of corporate dystopia.</p><p>Not only are Badowski's statements ignorant of the genre, but the way Cyberpunk 2077 handles these topics is, too.</p><p>You cannot augment your character within an inch of their life. You cannot even cut their hair after the initial character generation screen. </p><p>You cannot become a 9 foot chrome-lacquered war-machine with a car engine for a crotch. You can't swap your consciousness into something else.</p><p>Because we know other characters <em><strong>can,</strong></em> Cyberpunk 2077 offers the illusion of choice by showing it exists, but barely gives it to the player.</p><p>Speaking of barely; though you can swap voice/junk gender, this doesn't break down gender barriers meaningfully.</p><p>You cannot blur the lines of sexuality, because your romance options are very limited. Have a male voice but a female body? Many routes are off the table. However, the problem isn't so much that characters [to reflect IRL people] have certain 'equipment' preferences. That's valid.</p><p>The problem is that players <em><strong>should</strong></em> be able to have a car engine for a crotch and see how that shakes things up, for example. If it does at all. </p><p>This is the one genre that <em>most</em> benefits from a predominantly bisexual romance roster, or at the very least, it benefits from having the balls to tackle the transhumanism topic.</p><p>When corporations plaster ads inside of your eyeballs, the only thing left is the ability to transform yourself beyond limits. One of those limits is the self. </p><p>The other is grappling with what the self means when you replace it with cyberware, and what flavor of human <em>other </em>people see you as.</p><p>Cyberpunk 2077 does make a stance on this, and it's not as expected; too much self-reconfiguration makes you a Cyberpsycho. NPCs lose their mind if they replace too many parts.</p><p>This shows us that the "flesh as sacrum" aspect is unavoidable. </p><p>Because of all this, Cyberpunk 2077 smacks into the "barriers are moot" genre-point like V's car barrels down roads with the finesse of a bull in a china shop.</p><p>It's nothing but barriers, with the veneer of choice.</p><h2 id="cyberpunk-2077-mishandles-the-sentiency-agency-question">Cyberpunk 2077 mishandles "the sentiency/agency question"</h2><h3 id="despite-the-attention-paid-to-johnny-invading-your-shell">Despite the attention paid to Johnny invading your shell</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/cyberpunk2077-1.jpg" alt=""></figure><p>Does Cyberpunk 2077 address "the sentiency/agency question"? Keanu's Johnny Silverhands invades your shell, which suggests it does, but there's a problem.</p><p>In order to analyze this, we have to talk about the results. There are 5 endings, and all of them are a flavor of "you die because your body is beyond saving", "Johnny takes over" or "go to cyberjail while Arasaka figures out how to ya yeet you." </p><p>Only two routes shake things up, and one is "commit suicide" while the other is "fuck off somewhere to solve the problem, off-screen."</p><p>The issue? There are in-game lore "outs" to suggest personhood doesn't stop at meat suits. Lizzy Wizzy's download into a synth body comes to mind; is she not a person? The game thinks so, yet Johnny robs you of agency histrionically. </p><p>What of Alt, Johnny's past love-interest and now-sentient-AI? A missed opportunity to smash barriers, and also tackle the sentiency question. Alt has lost her "soul".</p><p>There are repercussions to digitization, even if Judy's route later explains she figured out how to dabble in recorded/shared emotions, via BD devices. Even if Arasaka <em>already</em> upgraded the engram system.</p><p>It's almost as though the cast's skills/game lore never applies breakthrough tech to your problem, until it's too late.</p><p>Can players invade the darkweb and chill with the rogue AIs? Yes, but we <em>can't</em> do it to save our own Ghost, because "the flesh is sacrum".</p><p>What of Delamain's rogue AI "children"? Surprisingly, you get to tackle the sentiency angle if you complete the Epistrophy side quests. You can honor the rogue AIs' wishes and merge them with Delamain's main personality.</p><p>Cyberpunk 2077 pretends all this technology is in its infancy to stop the player from questioning narrative choices. What it actually does is show what's possible, but <strong>not for you</strong>.</p><p>Why can't players live in the internet? Why can't they hop into a car? Why can't they download into a synth? Why can't they merge personalities with Johnny in a truly blended version, like Motoko in the GiTS 90s film?</p><p>Cyberpunk 2077 punishes players for the very concepts the Cyberpunk genre grapples with, and the game lore suggests it <em>can</em> tackle.</p><p>Who gets to be a person even if they're inside a fucking toaster? Cars, Lizzy Wizzy, and Johnny. Not the player.</p><h2 id="and-what-of-the-punk-aspect-of-cyberpunk">And what of the Punk aspect of Cyberpunk?</h2><h3 id="well-it-s-lip-service-is-the-thing">Well, it's lip-service, is the thing</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/cyberpunk2077_hand_cmyk_wide-959129cd7f84b90547ac1c88d90ec6bae3b98186.jpg" alt=""></figure><p>As stated: in the genre you have body augmentation, boundary scuttling, and transhumanism as rebellion options. Another is fighting the corporatization of the self and others. That's where the Punk aspect comes in.</p><p>Though Johnny invading your shell is a nice thematic touch, he's mostly concerned with Big Corp Arasaka. He judges your character harshly if they care about plenty of <em>other</em> rebellions. </p><p>For instance, sentient AI cars get more sympathy from Johnny than the dolls of The Clouds (who are human sex workers). That's not very Punk, Johnny.</p><p>Somehow, Takemura's plot is more on-point here, as an examination of Arasaka as child-soldier creators, and yet I don't see him staging some mass "free the kids" rebellion.</p><p>To make matters worse, you can't defy the cops; killing criminals helps the police, as a feature not a bug. In order to get the gear/money you need to progress, this is basically unavoidable. If you do try to avoid it, this cuts a shitload of content out.</p><p>River Ward's side quest examines this, as the one good cop in Night City. However, his quest doesn't let you stage a rebellion against the corrupt police force. His plot-line is ripe for this aspect of Punk.</p><p>Even the 3 initial 'camps' you choose don't tango with the Punk aspect. After the first 20 minutes, all you get are dialog options. There should've been a way to join …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/">https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/</a></em></p>]]>
            </description>
            <link>https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552923</guid>
            <pubDate>Sun, 27 Dec 2020 18:09:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building my own HomeKit Thermostat]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25552889">thread link</a>) | @frenchie4111
<br/>
December 27, 2020 | https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1 | <a href="https://web.archive.org/web/*/https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_area">
    <div>
        
            <h2 id="post_title">Building my own HomeKit Thermostat</h2>
        

        <p>Iâ€™m pretty obsessed with controlling most of the electronics in my house from my
phone. One of the last remaining devices was the thermostat. I donâ€™t want a Nest
because it doesnâ€™t work with HomeKit, and I canâ€™t use an EcoBee because I donâ€™t
have a neutral wire. So I resolved to build my own.</p>

<p>If you are building your own thermostat, or any hardware really, and want some
help or just want to show it off, feel free to shoot me an email at mdl0394@gmail.com. 
Also I plan to continue to expand this project to have a screen and some buttons,
if you want to hear about that signup to my email list and Iâ€™ll let you know when
I do it.</p>



<h2 id="figuring-out-hot-to-turn-on-the-heat">Figuring out hot to turn on the heat</h2>

<p>So I turns out my heater runs on a really simple control protocol. There are just
two wires run from the heater to the current thermostat, when you connect them it
turns on, and when you disconnect it turns off. The only unfortunate part of it is
that the wires are 24vac, so to be safe I need to use a solid state relay for
switching.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/5897a162a777067bc7469e501a50029f58c9efe6/cc305/images/homekit_thermostat/old_thermostat_closeup.jpeg" alt="Old Thermostat Closeup showing two pins that need to be connected"></p>



<h2 id="the-prototype">The prototype</h2>

<p>I am building this whole thing on an esp32, with a big overkill relay I got on
amazon prime. I will link the exact parts below. The current thermometer is an
old tmp102 sparkfun board I had lying around, but itâ€™s off by around 6 degrees,
so in v2 I will be replacing it with hopefully a more accurate one.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/ec16c9863aa710ab4101208bd7eebc89d316fecb/23983/images/homekit_thermostat/breadboard.jpeg" alt="Fully wired breadboard">
<img src="https://d33wubrfki0l68.cloudfront.net/81db446d96ed6124330e190aba1321f981d07adc/8d0da/images/homekit_thermostat/wall_taped.jpeg" alt="Breadboard taped to wall"></p>

<p>After wiring it all together, and taping it to my wall for a day or two, I was
satisfied with the components, and wanted to get started on prettying it up a bit.</p>



<h2 id="the-code">The code</h2>

<p>The thermostat control runs on a pretty simple state machine. I am a big fan of
drawing things out ahead of time, so I drew this diagram for myself before coding.
In C this is implemented as two enums (actions, states) and a bunch of switch case
statements.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/6d7680c909d72c389d076e0390408d1e44382733/c2055/images/homekit_thermostat/state_machine.png" alt="State machine for thermostat control"></p>

<p id="expand_model_code">Click Here to toggle the code</p>
<div id="model_code">
<pre><code>// Enums:

typedef enum {
    TC_HEATER_MODE_OFF,
    TC_HEATER_MODE_ON,
    TC_HEATER_MODE_AUTO_ON,
    TC_HEATER_MODE_AUTO_OFF
} tc_heater_mode_t;

typedef enum {
    TC_HEATER_ACTIONS_SET_TO_AUTO,
    TC_HEATER_ACTIONS_SET_TO_OFF,
    TC_HEATER_ACTIONS_SET_TO_ON,
    TC_HEATER_ACTIONS_TEMPERATURE_CHANGE,
    TC_HEATER_ACTIONS_THRESHOLD_CHANGE
} tc_heater_action_t;

// ... Somewhere else:

switch (s_current_heater_mode) {
    case TC_HEATER_MODE_OFF:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                s_current_heater_mode = TC_HEATER_MODE_AUTO_OFF;
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                s_current_heater_mode = TC_HEATER_MODE_ON;
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                break;
        }
        break;
    case TC_HEATER_MODE_ON:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                s_current_heater_mode = TC_HEATER_MODE_AUTO_ON;
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                s_current_heater_mode = TC_HEATER_MODE_OFF;
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                break;
        }
        break;
    case TC_HEATER_MODE_AUTO_ON:
    case TC_HEATER_MODE_AUTO_OFF:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                s_current_heater_mode = TC_HEATER_MODE_OFF;
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                s_current_heater_mode = TC_HEATER_MODE_ON;
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
        }
        break;
}</code></pre>
</div>

<p>It was very important to me that the thermostat worked on homekit, thankfully
there are already great homekit (hap) resources for the esp32. After some digging
I decided on this homekit package, as itâ€™s a clean port of the expressif homekit
library to arduino. There are about 15 different homekit frameworks for arduino,
so at some point I just had to choose one and start running.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/09e7eb514a6c9878988e3897b1f9377a39d331c7/9fc55/images/homekit_thermostat/homekit.jpeg" alt="Homekit screenshot showing thermostat"></p>

<p>After a whole bunch of fucking around I managed to get my esp32 to show up as a thermostat from my phone.</p>

<p>A few gotchaâ€™s that I encountered along the way: (some specific to this library, some specific to homekit)</p>

<ul>
  <li>With this HomeKit library if you want to factory reset, you have to do it <em>after</em> you initialize. Also be sure to remove the device from homekit on your phone before factory resetting the device</li>
  <li>Be sure that you have unique id and pairing codes for your device, I have another esp32 on my homekit and they kept colliding</li>
  <li>Be sure that your device cid matches with the services you are providing, otherwise you will get annoying silent failures from homekit</li>
</ul>



<h2 id="making-things-pretty">Making things pretty</h2>

<p>After getting the code into a place I liked, all that was left was to make it
look less like a bomb strapped to my living room wall. I 3d printed an enclosure,
and soldered the correct wires in the correct places. Unfortunately my board
requires constant a 5V micro-usb power source, so as of right now I have it
powered off of a huge battery pack. Maybe in vN (for very large values of N)
I will go nest style with an internal LiPo and an AC-DC converter.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/da9845e5838dba97dbae170da8ae49eb191c9b6f/089ad/images/homekit_thermostat/soldered.jpeg" alt="Soldered together">
<img src="https://d33wubrfki0l68.cloudfront.net/a2686592824334db4590b4affc52e706eb1acd91/cfae7/images/homekit_thermostat/enclosure.jpeg" alt="3d printed enclosure">
<img src="https://d33wubrfki0l68.cloudfront.net/3d6c45942a18d64daa989a8b0baf0f3ab706a833/aa250/images/homekit_thermostat/pretty.jpeg" alt="Enclosure mounted to wall and plugged in"></p>



<h2 id="whats-next">Whatâ€™s Next?</h2>

<p>I have already bought a few parts for a planned v2, so stay tuned. In v2 I will be adding:</p>

<ul>
  <li>New thermometer board (Going to use this overpriced adafruit breakout here <a href="https://www.amazon.com/gp/product/B00OKCQX96/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B00OKCQX96/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;psc=1</a>)</li>
  <li>Adding a small status display OLED screen <a href="https://www.amazon.com/gp/product/B0833PF7ML/ref=ppx_yo_dt_b_asin_title_o01_s03?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B0833PF7ML/ref=ppx_yo_dt_b_asin_title_o01_s03?ie=UTF8&amp;psc=1</a></li>
  <li>Add a few buttons to allow non-phone control of the device <a href="https://www.amazon.com/gp/product/B0722LBKV7/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B0722LBKV7/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1</a></li>
</ul>

<div>
    <p>

    Thanks for reading! If you want to stay updated feel free to follow the <a href="https://staycaffeinated.com/feed.xml">RSS feed</a>, if you have any suggestions feel free to email me at <a href="mailto:mdl0394@gmail.com">mdl0394@gmail.com</a></p><p>
    

    You could also submit your email here, and I will personally email you whenever I post new things:

    </p>
</div>

<h2 id="parts-used--other-references">Parts used / Other references</h2>

<ul>
  <li>Way too big of a relay: <a href="https://www.amazon.com/gp/product/B07KXNCL91/ref=ppx_yo_dt_b_asin_title_o08_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B07KXNCL91/ref=ppx_yo_dt_b_asin_title_o08_s00?ie=UTF8&amp;psc=1</a></li>
  <li>ESP32 Doit Devkit v1 boards: <a href="https://www.amazon.com/gp/product/B07Q576VWZ/ref=ppx_yo_dt_b_asin_title_o08_s01?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B07Q576VWZ/ref=ppx_yo_dt_b_asin_title_o08_s01?ie=UTF8&amp;psc=1</a></li>
  <li>HomeKit framework esp-homekit-arduino-sdk <a href="https://github.com/Brawrdon/esp-homekit-arduino-sdk?utm_source=platformio&amp;utm_medium=piohome">https://github.com/Brawrdon/esp-homekit-arduino-sdk?utm_source=platformio&amp;utm_medium=piohome</a></li>
</ul>

    </div>
</div></div>]]>
            </description>
            <link>https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552889</guid>
            <pubDate>Sun, 27 Dec 2020 18:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Gotchas: SortedSet ignores the equals method]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25552829">thread link</a>) | @excerionsforte
<br/>
December 27, 2020 | https://yesday.github.io/blog/2018/java-gotchas-sorted-set-ignores-the-equals-method.html | <a href="https://web.archive.org/web/*/https://yesday.github.io/blog/2018/java-gotchas-sorted-set-ignores-the-equals-method.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
  <p>Consider the below code which creates a <code>SortedSet</code> using a comparator based on string length</p> 
  <div> 
   <div> 
    <pre><code data-lang="java">public class SortedSetTest {
    public static void main(String[] args) {
        SortedSet&lt;String&gt; sortedSet = new TreeSet&lt;&gt;(Comparator.comparing(String::length));
        sortedSet.addAll(Set.of("aa", "bb"));
        System.out.println(sortedSet);
    }
}</code></pre> 
   </div> 
  </div> 
  <p>The output of the above is</p> 
   
  <p>While I would expect</p> 
   
  <p>or</p> 
   
  <p>The <code>bb</code> element disappears, breaking the <code>Set</code> contract. The comparator is supposed to only sort the elements and not distinguish them from one another, which is what equals does in all the collections.</p> 
  <p>On the other hand, if I enhance the comparator to always return non-zero for unequal items like below, only then do I get the correct results.</p> 
  <div> 
   <div> 
    <pre><code data-lang="java">public class SortedSetTest {
    public static void main(String[] args) {
        SortedSet&lt;String&gt; sortedSet = new TreeSet&lt;&gt;(Comparator.comparing(String::length)
            .thenComparing(String::toString));
        sortedSet.addAll(Set.of("aa", "bb"));
        System.out.println(sortedSet);
    }
}</code></pre> 
   </div> 
  </div> 
  <p>The output now is <code>[aa, bb]</code> as I would expect.</p> 
  <p>The question is, why does <code>SortedSet</code> ignore the <code>equals</code> method in first place and removes an unequal object from the set?</p> 
  <p>The <code>comparator</code> method inside the <code>SortedSet</code> interface is <a href="https://docs.oracle.com/javase/10/docs/api/java/util/SortedSet.html">documented</a> as follows:</p> 
  <div> 
   <blockquote>
     Returns the comparator used to order the elements in this set, or null if this set uses the natural ordering of its elements. 
   </blockquote> 
  </div> 
  <p>The above indicates that the comparator is only used to order the elements in the set and not to distinguish them from one another, which is what <code>equals</code> is for in all the collections.</p> 
  <p>Digging into the <a href="https://docs.oracle.com/javase/10/docs/api/java/util/SortedSet.html">javadoc</a> further, it turns out that the above javadoc comment is incorrect, because there is another side note that contradicts it:</p> 
  <div> 
   <blockquote>
     Note that the ordering maintained by a sorted set (whether or not an explicit comparator is provided) must be consistent with equals if the sorted set is to correctly implement the Set interface. (See the Comparable interface or Comparator interface for a precise definition of consistent with equals.) This is so because the Set interface is defined in terms of the equals operation, but 
    <strong>a sorted set performs all element comparisons using its compareTo (or compare) method, so two elements that are deemed equal by this method are, from the standpoint of the sorted set, equal</strong>. The behavior of a sorted set is well-defined even if its ordering is inconsistent with equals; it just 
    <strong>fails to obey the general contract of the Set</strong> interface. 
   </blockquote> 
  </div> 
  <p>Note that, <a href="https://docs.oracle.com/javase/10/docs/api/java/util/Comparator.html">by definition</a>, consistent with equals means:</p> 
  <div> 
   <blockquote>
     The ordering imposed by a comparator c on a set of elements S is said to be consistent with equals if and only if c.compare(e1, e2)==0 has the same boolean value as e1.equals(e2) for every e1 and e2 in S. 
   </blockquote> 
  </div> 
 </div></div>]]>
            </description>
            <link>https://yesday.github.io/blog/2018/java-gotchas-sorted-set-ignores-the-equals-method.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552829</guid>
            <pubDate>Sun, 27 Dec 2020 17:58:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS We Happily Pay For]]>
            </title>
            <description>
<![CDATA[
Score 367 | Comments 175 (<a href="https://news.ycombinator.com/item?id=25552342">thread link</a>) | @frankdilo
<br/>
December 27, 2020 | https://francescodilorenzo.com/saas-we-pay-for | <a href="https://web.archive.org/web/*/https://francescodilorenzo.com/saas-we-pay-for">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>We try to run a lean operation at <a href="https://mailbrew.com/">Mailbrew</a>, but we are suckers for great tools that improve our daily workflows, so we pay for quite a few of them each month.</p>
<p>Being small (just 3 people), the cost of switching services is almost negligible, so we try new stuff regularly and do switch when we see a clear improvement.</p>
<p>Here is a list of everything we <em>happily</em> pay for.</p>
<h3><a href="https://missiveapp.com/">Missive</a></h3>
<p><strong>$15/month ⨉ 3 = $45/month.</strong></p>
<p>Collaborative email on top of G Suite. The main thing we pay for is a comment box below each email thread. It allows us to quickly discuss emails without forwarding or copy/pasting in Slack. It also allows us to edit drafts collaboratively and have multiple team inboxes for invoices, support, and other stuff.</p>
<p>We pay for the Productive plan because of one feature: Rules. They allow us to automatically categorize emails and be more granular with notifications. </p>
<h3><a href="https://www.notion.so/product">Notion</a></h3>
<p><strong>$8/month ⨉ 3 = $24/month.</strong></p>
<p>It's our team wiki. We write memos, meeting notes, drafts for blog posts, and everything that needs to be shared async for feedback. We also used to put tasks here but recently moved to Linear (more on this below).</p>
<p>It's an amazing value, but we were close to ditching it because of how slow it has become. We still have to find something that delivers the same great feature set and flexibility while improving speed and reliability.</p>
<h3><a href="https://linear.app/">Linear</a></h3>
<p><strong>$8/month ⨉ 3 = $24/month.</strong></p>
<p>We put our tasks here. It's a newcomer, but it's so good that we have already committed to it for a year. </p>
<p>It completely revolutionized the way we work with its flexibility, speed, customizability, and great GitHub integration.</p>
<p>If you connect it to GitHub and open a pull request with a task-specific name, task and PR get linked. When the PR is merged, the task is automatically marked as done.</p>
<p>I would invest in this company if I had the chance. It's so much better than everything else I ever tried in this space.</p>
<h3><a href="https://vercel.com/">Vercel</a></h3>
<p><strong>$20/month ⨉ 3 = $60/month.</strong></p>
<p>Vercel deploys and hosts our frontends and serverless functions.</p>
<p>It's a bit pricier than we'd like, and the pricing does not really make sense. Why do we have to pay per team member instead of build minutes, bandwidth, and compute?</p>
<p>With all that being said, we love the product philosophy, simplicity, and integration with GitHub. Having automatic deploys for all commits, together with automatic task-linking to Linear for PRs, is code-review Nirvana.</p>
<h3><a href="https://savvycal.com/">SavvyCal</a></h3>
<p><strong>$12/month ⨉ 2 = $24/month.</strong></p>
<p>We use it to schedule our calls. It's a better Calendly, made by a solo indie developer that we're happy to support.</p>
<p>The product is super-intuitive, and its feature set is increasing at a great pace with features that massively improve our workflows.</p>
<h3><a href="https://plausible.io/">Plausible Analytics</a></h3>
<p><strong>$12/month.</strong></p>
<p>It's a privacy-focused website analytics tool that replaces Google Analytics.</p>
<p>The most impressive thing is how better the insights we get from it are, thanks to some great UX, despite its privacy-respecting stance.</p>
<p>No surprise, they have been <a href="https://www.indiehackers.com/product/plausible-insights">growing like crazy</a>.</p>
<h3><a href="https://mailbrew.com/">Mailbrew</a></h3>
<p><strong>$10/month.</strong></p>
<p>We pay for this, even if we are the ones making it, to test our Stripe Integration.</p>
<p>We use Mailbrew to receive a couple of digests with dedicated Twitter Searches that keep us updated on social mentions of our product.</p>
<h3><a href="https://super.so/">Super</a></h3>
<p><strong>$12/month.</strong></p>
<p>This turns Notion documents into their own websites with a dedicated domain. We use it for our <a href="https://mailbrew.com/press">press kit</a> and <a href="https://help.mailbrew.com/">support docs</a>.  </p>
</article></div>]]>
            </description>
            <link>https://francescodilorenzo.com/saas-we-pay-for</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552342</guid>
            <pubDate>Sun, 27 Dec 2020 16:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remembering the Nanjing Massacre]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25552140">thread link</a>) | @Beggers1960
<br/>
December 27, 2020 | https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/ | <a href="https://web.archive.org/web/*/https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-449">

	<!-- .entry-header -->

	<div>
		


<p><img loading="lazy" data-attachment-id="464" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/ija_10th_army_entering_nanking/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg" data-orig-size="950,633" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IJA_10th_Army_entering_Nanking" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=748" src="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg" alt="Nanjing Massacre" width="748" height="498" srcset="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=748&amp;h=498 748w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=150&amp;h=100 150w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=300&amp;h=200 300w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=768&amp;h=512 768w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg 950w" sizes="(max-width: 748px) 100vw, 748px"></p>
<p>In 1937, before a shot was even fired in Europe, Imperial Japanese forces were engaged in a long, bloody conflict in China – and it is during this period that we catch a glimpse of the atrocities that would stain the 1940s.&nbsp;</p>
<p>The event, or series of events, we are looking at today is the Japanese occupation of Nanjing, commonly referred to as the ‘Rape of Nanjing’.</p>



<p>Anyone with a modicum of knowledge on the Second World War will know of the atrocities committed by Imperial Japanese forces. Their atrocious treatment of PoW’s and civilians throughout South East Asia, Oceania and China are well documented. Several years before those times however, when Japanese forces entered Nanjing, they let loose upon the people there.</p>
<h4>Crashing dominoes&nbsp;</h4>
<p>In the weeks preceding the Japanese occuptation of Nanjing, there had been bloody fighting between Chinese forces and Imperial Japanese troops. Indeed, for several years, the Imperial Japanese Army had been involved in a tit-for-tat conflict against both Communist and nationalist Chinese forces.</p>
<p>In August 1937, the <a href="https://en.wikipedia.org/wiki/Battle_of_Shanghai" target="_blank" rel="noopener">Battle of Shangai</a> set into motion a series of events that would lead to disaster for Chinese forces and civilians throughout the country. The Battle of Shanghai was a visceral, bloody engagement for both sides. However, by mid-November, Imperial Japanese forces had captured and subjugated the area.&nbsp;</p>
<figure data-shortcode="caption" id="attachment_462" aria-describedby="caption-attachment-462"><img loading="lazy" data-attachment-id="462" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/japanese_marines_during_the_battle_of_shanghai_1937/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg" data-orig-size="510,352" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Japanese_marines_during_the_Battle_of_Shanghai,_1937" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=510" src="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg" alt="" width="510" height="352" srcset="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg 510w, https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=150&amp;h=104 150w, https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=300&amp;h=207 300w" sizes="(max-width: 510px) 100vw, 510px"><figcaption id="caption-attachment-462">Japanese marines advance during the Battle of Shanghai.</figcaption></figure>
<p>Despite sustaining heavy casualities after weeks of fighting, Japanese forces of the Central China Area Army and 10th Army were ordered to capture the city of Nanjing and the surrounding area. The subsequent advance prompted hysteria among Chinese civilians and military forces, with thousands of the latter desperately trying to avoid capture.&nbsp;</p>
<h4>Cry havoc! and let slip the dogs of war</h4>







<p>Upon entering the city, Japanese forces appear to enter a feral state, abandoning all reason and humanity and embarking on a campaign of terror, abuse and murder against the people of the old Chinese capital.</p>



<p>A truly ghastly affair, and throughout we see sadistic methods and practices by Japanese troops. Groups of individuals were buried alive, some were burned alive, and the lucky ones were simply executed en-masse.</p>



<p>Beheadings were commonplace throughout this event, and there are accounts (although hotly debated) of ‘contests’ between Japanese officers to see who could behead 100 people in the shortest time.</p>





<p>In 1937, Japanese media covered the story of Toshiaki Mukai and Tsuyoshi Noda of the Japanese 16th Division, who were both vying to reach this goal of 100 beheadings. Throughout the course of the war these two men are alleged to have murdered over 300 people between them, and upon Japan’s surrender in 1945 the officers were tried and executed for war crimes.</p>



<p>While crimes were being committed against the civilian population, scores of Chinese prisoners of war were ruthlessly executed. The execution of prisoners of war were also particularly sadistic and brutal.</p>



<p>Countless PoW’s were hanged, shot and beheaded, with many more being buried alive alongside civilians. To this day the number of Chinese PoW’s executed is still unknown.</p>
<figure data-shortcode="caption" id="attachment_458" aria-describedby="caption-attachment-458"><img loading="lazy" data-attachment-id="458" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/iwane_matsui_rides_into_nanjing/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg" data-orig-size="498,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Iwane_Matsui_rides_into_Nanjing" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=498" src="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg" alt="Nanking Massacre" width="498" height="360" srcset="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg 498w, https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=150&amp;h=108 150w, https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=300&amp;h=217 300w" sizes="(max-width: 498px) 100vw, 498px"><figcaption id="caption-attachment-458">General Iwane Matsui rides into Nanjing.</figcaption></figure>
<h4>Accounts by westerners</h4>



<p>As hostilities had not yet erupted between western nations and Japan, there were a range of western civilians in the city during this event, and their accounts of the actions of Japanese soldiers are harrowing.</p>



<p>A surgeon, Robert O. Wilson, in the university hospital within the US safety zone, wrote home on several occasions detailing the events unfolding before his eyes.</p>



<p>“The slaughter of civilians is appalling. I could go on for pages telling of cases of rape and brutality almost beyond belief,” he wrote. “Two bayoneted corpses are the only survivors of seven street cleaners who were sitting in their headquarters when Japanese soldiers came in without warning and killed five of their number and wounded the two that found their way to the hospital.”</p>
<p>The Minnie Vautrin Diary detailing atrocities provides some of the most compelling and harrowing accounts of the Nanjing Massacre. Excerpts detailing what she witnessed can be found online, or the diary itself can be purchased.</p>



<p>In her diary she details the callous brutality of Japanese soldiers and, in particular, their treatment of Chinese women.</p>



<p>“A woman of almost 50 living down near San Pai Lou.&nbsp;She had three sons and two daughters-in-law. Four nights ago two soldiers came to the door at about 10pm, unable to push the door they forced their way in through a window and found themselves in Liu Lau Tai’s room.</p>





<p>“They demanded her daughters-in-law and when she refused and started to go for a military police they cut two gashes in her face and one in her heart.&nbsp;She died from these wounds.”</p>





<h4>Age old barbarism</h4>



<p>Japanese soldiers employed an age old weapon against the people of Nanjing, rape. Assault on women throughout the Nanjing Massacre were widespread and anywhere up to 20,000 women and girls were raped and brutalised.</p>







<p>John Rabe, leader of the Nanjing Safety Zone details his experiences in dealing with these cases during his time in the city.</p>



<p>“In one of the houses in the narrow street behind my garden wall, a woman was raped, and then wounded in the neck with a bayonet. I managed to get an ambulance so we can take her to Kulou Hospital.</p>





<p>“Last night up to 1,000 women and girls are said to have been raped, about 100 girls at Ginling College alone.</p>



<p>“You hear nothing but rape. If husbands or brothers intervene, they’re shot. What you hear and see on all sides is the brutality and bestiality of the Japanese soldiers.”</p>
<figure data-shortcode="caption" id="attachment_460" aria-describedby="caption-attachment-460"><img loading="lazy" data-attachment-id="460" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/nanking_bodies_1937/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg" data-orig-size="800,559" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nanking_bodies_1937" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=748" src="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg" alt="Nanjing Massacre" width="748" height="523" srcset="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=748&amp;h=523 748w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=150&amp;h=105 150w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=300&amp;h=210 300w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=768&amp;h=537 768w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg 800w" sizes="(max-width: 748px) 100vw, 748px"><figcaption id="caption-attachment-460">Bodies littered the shore of the Qinhuai River.</figcaption></figure>



<h4>Relenting troops</h4>



<p>In January of 1938, after several weeks of bloodletting, refugees within the safety zones were ordered to return to their homes.</p>



<p>Japanese officials claimed at the time that ‘order had been restored’ and that daily life were to continue as normal. For the people of Nanjing subjected to relentless bouts of violence, however, life would never be the same again.</p>



<p>As order was gradually restored, the frequency of attacks and atrocities did dissipate.</p>
<h4>Guilt</h4>



<p>General Iwane Matsui, leader of the Japanese Expeditionary Force in China, began to realise the extent of the atrocities being committed by his men in Nanjing – albeit too late.</p>



<p>Speaking of his knowledge on the atrocities being committed, he is claimed to have stated to an aide:</p>



<p>“I now realise that we have unknowingly wrought a most grievous effect on this city. When I think of the feelings and sentiments of many of my Chinese friends who have fled from Nanjing and of the future of the two countries, I cannot but feel depressed.</p>



<p>“I am very lonely and can never get in a mood to rejoice about this victory … I personally feel sorry for the tragedies to the people, but the Army must continue unless China repents.</p>



<p>“Now, in the winter, the season gives time to reflect. I offer my sympathy, with deep emotion, to a million innocent people.”</p>



<p>Although an apparent admission of guilt on his part, Matsui’s lack of action on the issue, his burying of the head in sand, simply allowed the ordeal to continue far longer than it did.</p>



<p>Matsui was recalled to Japan following the massacre and retired. Upon Japan’s surrender in 1945, he was tried by the International Military Tribunal for the Far East and is executed.</p>



<h4>Aftermath</h4>



<p>The death toll in Nanjing is debated. Contemporary Japanese statistics could be considered laughable, amounting to only several hundred dead. A range of sources estimate that anywhere between 30,000 to 300,000 people were murdered during this month-long tirade of violence.</p>
<p>Modern Chinese sources (in particular the Chinese Government) claim that these numbers range even higher and are, in fact, closer to half-a-million.</p>




<p>The Nanjing War Crimes Tribunal in 1947 stated:</p>



<p>“More than 190,000 mass slaughtered civilians and Chinese soldiers killed by machine gun by the Japanese army, whose corpses have been burned to destroy proof.</p>



<p>“Besides, we count more than 150,000 victims of barbarian acts buried by the charity organisations. We thus have a total of more than 300,000 victims.”</p>



<p>Researchers state that the death toll numbers between 40,000 and 60,000 based on a number of sources from the time, including Red Army statistics and the Nanjing Safety Zone committee.</p>



<p>Regardless of the true number of casualties, the barbarism and horrific nature of this event are beyond comprehension. The callous behaviour of Japanese soldiers is a stain on the tapestry of 20th century history, and this behaviour continued for another several years until Japanese capitulation in the wake of Hiroshima &amp; Nagasaki.</p>


			
			
						</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552140</guid>
            <pubDate>Sun, 27 Dec 2020 16:36:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Google]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25552030">thread link</a>) | @smusamashah
<br/>
December 27, 2020 | https://dcgross.com/a-new-google | <a href="https://web.archive.org/web/*/https://dcgross.com/a-new-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>[TL;DR: Google has gotten bad; we all know it; ideas for a startup making a better Google.]</p> <p>In 2000, Google got popular because hackers realized it was better than Lycos or Excite. This effect is happening again. Early adopters aren’t using Google anymore.</p> <p>They aren’t using DuckDuckGo either. They’re still using Google.com, but differently. To make Google usable, users are adding faux-query modifiers that to supress the “garbage Internet”.</p> <p>You see this in the typeahead logs.</p> <p><img src="https://dcgross.com/assets/new-google/image6.png" alt=""> <em></em></p><center><em>Products (Reddit)</em></center> <p><img src="https://dcgross.com/assets/new-google/image4.png" alt=""> <em></em></p><center><em>Services (Reddit, Yelp)</em></center> <p><img src="https://dcgross.com/assets/new-google/image1.png" alt=""> <em></em></p><center><em>Movies (Rotten Tomatoes)</em></center> <p><img src="https://dcgross.com/assets/new-google/image5.png" alt=""> <em></em></p><center><em>Even code (Github)</em></center> <p>Interestingly, this doesn’t work for all categories. <img src="https://dcgross.com/assets/new-google/image3.png" alt=""> <img src="https://dcgross.com/assets/new-google/image2.png" alt=""> <em></em></p><center><em>Recipes don’t have a “Reddit” equivalent</em></center> <h3 id="query-operators-mean-somethings-broken">Query Operators Mean Something’s Broken</h3> <p>More advanced users use modifiers like <code>site: filetype: intitle:</code> because adding “reddit” isn’t strict enough, as spammy websites often manipulate content to win SEO.</p> <p>How about those websites that stuff the year in the title? “Reviews UPDATED JANUARY 2020” are exploiting the fact that customers suffix queries with the year. What those people are trying to command is freshness, not a title match.</p> <p>Something’s broken, and a tiny share of Google is open for the taking. Obviously attacking incumbents head-on doesn’t work. Here are two alternative ideas for bootstrapping next-generation search:</p> <h3 id="1-boogle-a-query-reformulator">#1 Boogle, A Query Reformulator</h3> <p>Introducing Boogle, a proxy for Google that’s just Better Google Search. It’s a query expander. We predict the correct operators for your query, proxy Google’s results, and serve. For example:</p> <p><code>query("stripe.js example") -&gt; query("stripe.js example (site:github.com OR site:gitlab.com OR site:..."))</code></p> <p><code>query("is anker charger") -&gt; query("is anker charger (inurl:forum OR site:reddit.com OR ...))"</code></p> <p>Query topic modeling is a rich science with plenty of examples.</p> <p>You’d almost as fast as Google, never worse, and occasionally better. This will help build the reflex to use you instead. This approach isn’t that hard to get started with, and might work for the high-end users.</p>  <p>You could go after this vertical by vertical – build the <em>best</em> site for electric product search, for travel, for code, etc. A key question is how to build habitual recall to use your product over Google. Amazon and Airbnb both enjoy a huge amount of direct traffic. Some learnings from those:</p> <ul> <li><strong>Stellar mobile destination.</strong> Using Airbnb directly feels more fluid and fun than using Google for Airbnb.</li> <li><strong>The 90% Rule.</strong> To build reflex you need to give me what I want most of the time.** **With Prime, Amazon made it such that we stopped price comparing across other sites; Amazon would get it to us fastest, and that turns out to matter more than price. Most of the time you open Amazon.app, it satisfies.</li> <li><strong>Come for search, stay for something else.</strong> I don’t think of Airbnb or Amazon as search apps. They help me get things or book homes. You might want to your search app to be a destination for something else. This is where I think community comes in.</li> </ul> <p>Picking a vertical that <em>doesn’t</em> have strong typeahead completions[1] would help you build community around your search engine. Recipes, fitness, fashion, etc. don’t have decacorn conglomerates like Github or Reddit. That might mean it’s easier to build community around them, and put your flagship search engine on top.</p> <hr> <p>If you’re working on this kind of stuff, try out <a href="https://pioneer.app/">Pioneer</a> or just shoot me an email – daniel@pioneer.app.</p> <hr> <p>[1] In reality I’d pick the vertical _I _love most. If you’re a guitar player start with music; a movie buff should build better Rotten Tomatos. Etc.</p> </article></div>]]>
            </description>
            <link>https://dcgross.com/a-new-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552030</guid>
            <pubDate>Sun, 27 Dec 2020 16:23:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unexpected Bad Things Will Happen If You Don’t Read This]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25552016">thread link</a>) | @ropsii
<br/>
December 27, 2020 | https://www.petarperovic.com/blog/friction/ | <a href="https://web.archive.org/web/*/https://www.petarperovic.com/blog/friction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                    <time datetime="2020-12-27T09:10:00+00:00" itemprop="datePublished">Dec 27, 2020
                    </time>
                    ·
                    
                    
                    2 min.
                     read
                </p><div itemprop="articleBody">
                    <p>One of the core ideas of interaction design is to enable users to glide smoothly to their destination with as little friction as possible. To make people experience the software as an extension of their brain, and not something to continually wrestle with and domesticate.</p>

<p>Great products ask nothing from you on the first interaction. They’ll let you in and experiment without requiring anything upfront, not even your email address. Usually, until you need to save something. Hoping that, by that moment, they succeeded at demonstrating their value. That’s how removing friction, or only slightly delaying it, gives you a head start on the competition.</p>

<p><img src="https://www.petarperovic.com/assets/friction-github_delete.png" alt="Delete repository on GitHub screen">
<em>This is the exact copy I borrowed from GitHub for the title of this article. When you try to delete a repository, GitHub will force you to correctly type its name, making sure you know what you’re doing.</em></p>

<p>However, there are situations where you deliberately want to make interaction less convenient for users’ benefit. When you purposely want to make them stop and think. Typically when they’re about to perform a potentially destructive action or/and an operation that affects other people in the system. For example, to prevent them from accidentally deleting a project shared between many people and forever losing everyone’s important work. That’s where adding friction saves you from shooting yourself in the foot. As a rule of thumb, whenever there’s a potential of users harming themselves — add friction.</p>

<p>Friction is, however, often abused to deliberately confuse and exploit human anxiety when interacting with computers. Airlines’ websites will routinely scare you into buying garbage services you don’t need. Facebook will emotionally manipulate you if you try to erase it from your life. They’ll try to change your mind through the multi-page process where they’ll show you photos of the family and friends you’ll be missing as if they’d all be dead the moment you delete the account. Likewise, it’s widespread for products to complicate subscription cancellation for no reason, foolishly making users even more aggravated. These are all examples of adding friction in bad faith.</p>

<p>Physical world is also full of deliberately added friction, usually to prevent people from making dumb mistakes. Streets around schools slow down traffic with physical obstacles and flashing signals to protect little humans from deadly, fast-moving machines. Modern cars will poke you with annoying noise to fasten your seatbelt, dramatically increasing your chances of survival in case of an accident. Automatic sliding doors remove friction to increase the flow of people in high traffic, commercial buildings. Preventing the formation of queues, but also helping to maintain the temperature of the building. And so on…</p>

<p>At every point of human interaction with digital or physical interfaces, there’s friction. I find it incredibly useful to think about interaction design as adjusting friction, thus controlling the heartbeat of communication between humans and machines.</p>

                </div></div>]]>
            </description>
            <link>https://www.petarperovic.com/blog/friction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552016</guid>
            <pubDate>Sun, 27 Dec 2020 16:20:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker and Python]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25551892">thread link</a>) | @jajjarax
<br/>
December 27, 2020 | https://matteoguadrini.github.io/posts/containerized-python-development/ | <a href="https://web.archive.org/web/*/https://matteoguadrini.github.io/posts/containerized-python-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" id="main">
        

<div>
  <div>
    <p>Containerized Python Development</p>
  </div>
  
</div>
<article>
  
  <section>
    <p><img src="https://i.morioh.com/9ccb7b143f.png" alt="docker and python"></p>

<p>When we develop more than one python project, we need to configure our development environment with the dependencies of all the projects. This becomes even more complicated when there are many people on the development of the project.
To do this, you need to create a development environment that is isolated from the others. We can do this thanks to <strong>docker</strong> containers.</p>
<h2 id="prepare-project">Prepare project</h2>
<p>Let’s imagine that our project has this structure:</p>
<pre><code data-lang="console">pydk
├─── requirements.txt
└─── src
     └─── server.py
</code></pre><p>We now think that our project may depend on some external libraries, such as <strong>Flask</strong>. Let’s prepare a file called <em>requirements.txt</em> with a line inside it: <code>Flask==1.1.2</code></p>
<p>While our <em>server.py</em> application, it will be a simple Flask application like the following:</p>
<div><pre><code data-lang="python"><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>
<span>server</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>

<span>@server.route</span><span>(</span><span>"/"</span><span>)</span>
<span>def</span> <span>hello_docker</span><span>():</span>
    <span>return</span> <span>"Hello docker!"</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
   <span>server</span><span>.</span><span>run</span><span>(</span><span>host</span><span>=</span><span>'0.0.0.0'</span><span>)</span>
</code></pre></div><p>Now, we can run and continue to develop this project locally, but if we had other projects with requirements that would conflict, we would break this or other projects.
So, let’s see how we can isolate this project inside a container that is the same for all the developers who are going to develop.</p>
<h2 id="prepare-dockerfile">Prepare dockerfile</h2>
<p>Now we need to create a <em>Dockerfile</em> (<code>pydk/Dockerfile</code>) that contains suitable instructions to build our container so that it can execute our python code.</p>
<div><pre><code data-lang="dockerfile"><span># base image</span><span>
</span><span></span><span>FROM</span><span> python:3.9</span><span>
</span><span>
</span><span></span><span># working directory in the container</span><span>
</span><span></span><span>WORKDIR</span><span> /pydk</span><span>
</span><span>
</span><span></span><span># copy the dependencies file to the working directory</span><span>
</span><span></span><span>COPY</span> requirements.txt .<span>
</span><span>
</span><span></span><span># install dependencies</span><span>
</span><span></span><span>RUN</span> pip install -r requirements.txt<span>
</span><span>
</span><span></span><span># copy the content of the local src directory to the working directory</span><span>
</span><span></span><span>COPY</span> src/ .<span>
</span><span>
</span><span></span><span># command to run on container start</span><span>
</span><span></span><span>CMD</span> <span>[</span> <span>"python"</span><span>,</span> <span>"./server.py"</span> <span>]</span><span>
</span></code></pre></div><p>Now we run the command to build our image. When docker builder kicks in, you can see all the steps we wrote in our dockerfile:</p>
<pre><code data-lang="console">$ docker build -t mypy .
Sending build context to Docker daemon  4.608kB
Step 1/6 : FROM python:3.9
3.9: Pulling from library/python
6c33745f49b4: Pull complete 
ef072fc32a84: Pull complete 
c0afb8e68e0b: Pull complete 
d599c07d28e6: Pull complete 
f2ecc74db11a: Pull complete 
26856d31ce86: Pull complete 
a463ae07b5f3: Pull complete 
54f24c50f14e: Pull complete 
168ee6df05fe: Pull complete 
Digest: sha256:39c16d1a064c0239939d4ed52923b736c25b389e6ea439d5652b8fc9564ede76
Status: Downloaded newer image for python:3.9
 ---&gt; d1eef6fb8dbe
Step 2/6 : WORKDIR /pydk
 ---&gt; Running in ab2f8923ad12
Removing intermediate container ab2f8923ad12
 ---&gt; bad3fb87e418
Step 3/6 : COPY requirements.txt .
 ---&gt; eade175d7095
Step 4/6 : RUN pip install -r requirements.txt
 ---&gt; Running in de2b7fcd2c6d
Collecting Flask==1.1.2
  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)
Collecting click&gt;=5.1
  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
Collecting itsdangerous&gt;=0.24
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting Jinja2&gt;=2.10.1
  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)
Collecting MarkupSafe&gt;=0.23
  Downloading MarkupSafe-1.1.1.tar.gz (19 kB)
Collecting Werkzeug&gt;=0.15
  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)
Building wheels for collected packages: MarkupSafe
  Building wheel for MarkupSafe (setup.py): started
  Building wheel for MarkupSafe (setup.py): finished with status 'done'
  Created wheel for MarkupSafe: filename=MarkupSafe-1.1.1-cp39-cp39-linux_x86_64.whl size=32240 sha256=6fbda6c15fe2abefc6c8f4ec2ac66c421b1cf997c1a53a532a39bbebc8083860
  Stored in directory: /root/.cache/pip/wheels/e0/19/6f/6ba857621f50dc08e084312746ed3ebc14211ba30037d5e44e
Successfully built MarkupSafe
Installing collected packages: MarkupSafe, Werkzeug, Jinja2, itsdangerous, click, Flask
Successfully installed Flask-1.1.2 Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 itsdangerous-1.1.0
Removing intermediate container de2b7fcd2c6d
 ---&gt; 595ceaa19d29
Step 5/6 : COPY src/ .
 ---&gt; 98294355a272
Step 6/6 : CMD [ "python", "./server.py" ]
 ---&gt; Running in 1fb2a61f97ce
Removing intermediate container 1fb2a61f97ce
 ---&gt; 09fd1053a1c1
Successfully built 09fd1053a1c1
Successfully tagged mypy:latest
</code></pre><p>Let’s check the newly created image.</p>
<pre><code data-lang="console">$ docker images
REPOSITORY                         TAG                 IMAGE ID            CREATED             SIZE
mypy                               latest              09fd1053a1c1        15 minutes ago      896MB
python                             3.9                 d1eef6fb8dbe        8 days ago          885MB
</code></pre><h2 id="test-flask-on-docker">Test Flask on docker</h2>
<p>Now we can launch our image and test our application.</p>
<pre><code data-lang="console">$ docker run -d -p 5000:5000 mypy
487c215ec0cc2b44c1612c0aadbd3f1f47c32a0b29273da3dabf77351717852c

$ docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                    NAMES
487c215ec0cc        mypy                "python ./server.py"   28 seconds ago      Up 27 seconds       0.0.0.0:5000-&gt;5000/tcp   crazy_hermann

$ curl http://localhost:5000
Hello docker!
</code></pre><h2 id="conclusion">Conclusion</h2>
<p>We have created a small development environment for <strong>python</strong> application. Now, we can connect to our image and continue the development of the application without affecting our local environment.</p>

  </section>

  
</article>

      </div></div>]]>
            </description>
            <link>https://matteoguadrini.github.io/posts/containerized-python-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551892</guid>
            <pubDate>Sun, 27 Dec 2020 16:04:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[mRNA Vaccines Are Not Going to Affect Your DNA]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25551645">thread link</a>) | @DSingularity
<br/>
December 27, 2020 | https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna | <a href="https://web.archive.org/web/*/https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5f9e10d41e3be610d6196a01" id="sections">
  
    <section data-test="page-section" data-section-theme="white-bold" data-section-id="5f9e10d41e3be610d6196a07" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
      &quot;imageOverlayOpacity&quot;: 0.15,
      &quot;video&quot;: {
        &quot;playbackSpeed&quot;: 0.5,
        &quot;filter&quot;: 1,
        &quot;filterStrength&quot;: 0,
        &quot;zoom&quot;: 0
      },
      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
      &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
      &quot;customSectionHeight&quot;: 10,
      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
      &quot;customContentWidth&quot;: 50,
      &quot;sectionTheme&quot;: &quot;white-bold&quot;,
      &quot;sectionAnimation&quot;: &quot;none&quot;,
      &quot;backgroundMode&quot;: &quot;image&quot;
    }" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5fbbdf03aa206c671633c9e0"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1607217371950_14759"><p><strong>The short version: </strong>There is no plausible way that mRNA vaccines are going to alter your DNA. It would violate basically everything we know about cell biology. </p></div><div data-block-type="5" id="block-yui_3_17_2_1_1606186906941_17376"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <div><p>Lodish H, Berk A, Kaiser C, Krieger M, Bretscher A, Ploegh H, Amon A, Martin K. Molecular cell biology. 8th ed. New York: W.H. Freeman; 2016. Figure 5-1</p><p>This figure is useful because you can clearly see the two compartments we care about: the nucleus, which houses almost all of the DNA (exception discussed), and the cytosol, which is where translation happens. </p></div>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606169203989_12470"><p>Recently, I’ve gotten an influx of questions about how we can really be sure that mRNA vaccines will not affect our DNA. In my <a href="https://www.deplatformdisease.com/blog/mrna-vaccines-and-covid-19">prior post</a> on the subject I wrote:</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1606369575380_12279"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Lodish H, Berk A, Kaiser C, Krieger M, Bretscher A, Ploegh H, Amon A, Martin K. Molecular cell biology. 8th ed. New York: W.H. Freeman; 2016. Figure 13-37B which demonstrates the export of mRNA from the nucleus.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606369635264_11375"><div><blockquote><p>Another concern raised has been the idea that mRNA can somehow alter the host’s genome. That would actually be super cool and be huge for gene therapy (and I could finally give myself the giant bat wings I’ve always wanted) but this is not so. This is ordinarily impossible except if there is also a reverse transcriptase enzyme present that produces DNA from the RNA template, which is how retroviruses work. There is no such risk with any mRNA vaccine candidate. mRNA vaccines act entirely within the cytosol of the cell- they do not go near the nucleus where all the DNA is. That’s actually a major advantage of RNA-based vaccines over DNA ones.</p></blockquote></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606177725054_56388"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Flint S, Racaniello V, Rall G, Skalka A, Enquist L. Principles of virology. Washington, DC: ASM Press; 2015. Figure 5.23C which shows the nuclear import cycle with influenza ribonucleoproteins as an example. Nucleear localization signals are recognized by importin-α which then recruits importin-β which recruits a small GTPase called Ran. When binding GDP, Ran is able to transport the RNP across the nuclear pore complex. The complex of importins and Ran will then dissociate, and a guanine nucleotide exchange factor will exchange GDP for GTP, that allows Ran-GTP to be exported out of the nucleus. RanGAP-1 or RanBPI, 2 can then catalyze hydrolysis of GTP to GDP which allows Ran to bind another importin-β to initiate the import cycle once more. </p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606190121308_43147"><div><p>I gave this response in large part because I felt that the detailed discussion of reverse transcription, nuclear trafficking, the endocytic pathway, and the other 11 or so advanced cell biology topics that I would have to invoke to give this a rigorous answer was too complex to be of benefit to the average person wanting to know simply whether or not this is possible. However, I had a flurry of questions about “what ifs” relating to retroviruses or hepadnaviruses (hepatitis B), and I can grant that this response doesn’t address that, so here I will attempt to answer that as explicitly and with minimal complexity as I am capable. </p><p>To simplify the discussion so as to avoid having to explain the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4377075/">phases of phospholipid bilayers</a> and the molecular composition of the lipid nanoparticle as it relates to stability (discussed in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5439223/pdf/tde-07-319.pdf">1</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6383180/pdf/main.pdf">2</a>, <a href="https://www.cell.com/action/showPdf?pii=S1525-0016%2819%2930041-3">3</a>, <a href="https://www.cell.com/action/showPdf?pii=S1525-0016%2819%2930053-X">4</a>), I will ask readers take for granted that mRNA vaccines are endocytosed and <a href="https://www.nature.com/articles/3301506.pdf">liberated</a> (<a href="https://pubs.acs.org/doi/pdf/10.1021/acsami.8b21398">and this</a>) into the cytoplasm of the cell. </p><p>Firstly, for mRNA to affect your DNA, at a minimum we need to establish that it would need to gain access to the DNA in question. There are two subcellular compartments where this can be accomplished. The first is the nucleus, so let’s start with a discussion of the trafficking of cargo in the nucleus. The nucleus of the cell is an isolated compartment with pore complexes (NPCs) that impose limits on the size of the particles that can freely enter. RNA is readily transported out as transcription occurs within the nucleus but the ribosomes required to produce proteins are in the cytosol or on the rough endoplasmic reticulum. This process is mediated by several accessory proteins which you can see to your right. Note however that there isn’t any physiological circumstance in which one might need RNA from the cytosol to be transported back to the nucleus. RNA is synthesized within the nucleus. Viruses which have a nuclear phase in their replication cycle have to have various tricks to be able to allow their RNA payload to enter. Though RNA is not readily transported into cells, proteins can be. This occurs via a network of proteins called importins (see figure 5-23C on the right). Proteins containing an amino acid sequence called the nuclear localization sequence (NLS; there are 2 common ones) are able to bind the importins, which can then transport them across the nuclear pore complex as shown on the right. RNA viruses often have replication cycles that do not require access to the nucleus, but there are some exceptions. <a href="https://jvi.asm.org/content/jvi/84/3/1254.full.pdf">Influenza viruses for example are RNA viruses that have their genomes associated with ribonucleoproteins, and these ribonucleoproteins express nuclear localization signals that facilitates the entry of their genomic RNA into the nucleus</a>. mRNA vaccines, on the other hand, are not associated with any proteins. Once inside the cytosol, the mRNA is naked and exposed to the harsh environment of ribosomes and exonucleases which destroy the mRNA in a matter of hours (at most). There is no conceivable mechanism by which mRNA can spontaneously be trafficked into the nucleus. Being made of nucleotides, it cannot contain a nuclear localization sequence. </p><p>The other relevant compartment would be the mitochondrion. Mitochondria are actually vestigial bacteria with their own genomes, and it’s thought that billions of years ago an ancient cell (probably an archaean- the cousins of bacteria) tried to consume the ancestor of the mitochondria but lacked the machinery to actually do the digesting and the two established a symbiotic relationship. Since that instance, the mitochondria have been an essential feature of our cell’s biologies. This allowed the mitochondria to develop an extremely reduced genome containing only<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5215404/pdf/PATH-241-236.pdf"> 37 genes</a> (most of the genes relevant to mitochondrial function are still in the nucleus). Mitochondria have their <a href="https://www.pnas.org/content/pnas/116/17/8283.full.pdf">own ribosomes</a> and even their own <a href="https://www.nature.com/articles/282189a0">genetic code</a> (sort of). There is also a specialized process for the clearance of diseased mitochondria called <strong>mitophagy, </strong>which is the subject of many excellent reviews e.g. <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2001265">this</a>, <a href="https://www.nature.com/articles/s41556-018-0176-2">this</a>, and <a href="https://www.cell.com/current-biology/pdf/S0960-9822(18)30006-X.pdf">this</a>. </p><p>The collective conclusion from our understanding of these biological process is that a naked mRNA in the cytosol has no potential to end up in a cellular compartment that contains our own DNA means that, irrespective of the presence or absence of other factors, there is no chance of harm to the DNA from the mRNA vaccine. But still people wanted to ask me about reverse transcriptases so let’s discuss those.</p><p>The process of going from RNA to DNA (the exact opposite of what the central dogma of molecular biology dictates) is known as <strong>reverse transcription</strong>, and it is carried out with an enzyme called a <strong>reverse transcriptase </strong>(which are a really interesting group of enzymes). In general, reverse transcription is performed by a few different genetic entities: <strong>retroviruses</strong>, <strong>hepadnaviruses</strong>, <strong>telomeres</strong>, and <strong>retrotransposons</strong>. These are worth defining. </p><ul data-rte-list="default"><li><p>Retroviruses are viruses who have an RNA genome, from which they create a DNA copy through reverse transcription that then integrates into the cell of the host (by which I mean, literally inserts itself into the host cell’s genome and becomes a permanent part of it, in the form of a sequence called a <strong>provirus</strong>). The proviral sequence itself can then be transcribed in the host cell to produce viral proteins and particles that can go on to spread to the next cell. The most famous retrovirus is HIV-1. </p></li><li><p>Hepadnaviruses are DNA viruses which have gapped genomes (there is one complete DNA strand and another partial DNA strand which is linked to a pregenomic RNA), and unlike retroviruses, do not integrate into the genome of the host cell they infect. The most famous example is Hepatitis B virus, for which multiple effective vaccines exist. </p></li><li><p>Telomeres are structures present at the ends of human chromosomes which are maintained by a protein complex called telomerase that uses a reverse transcriptase called TERT to maintain them. The reasons this is necessary are discussed below. They are about 5-15 kilobases long normally, and shortening results in arrest of cell growth and replication (senescence), or can even trigger cell death by apoptosis. </p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606152858324_15060"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Hartwell L, Goldberg M, Fischer J, Hood L. Genetics. 6th ed. New York: McGraw Hill; 2018. Table 13-2</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606228770446_31321"><div><ul data-rte-list="default"><li><p>Retrotransposons are actually the most abundant component of our genome. The human genome contains about 21,000-27,000 genes (the number you get depends on how precisely you define a gene and which source you consult), which span 40-48 million base pairs, but this accounts for only about 1.5% of the 3.2 billion total base pairs. Retrotransposons account for about …</p></li></ul></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna">https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna</a></em></p>]]>
            </description>
            <link>https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551645</guid>
            <pubDate>Sun, 27 Dec 2020 15:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Digital Todo Lists Better than Pen and Paper]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25551638">thread link</a>) | @vuciv1
<br/>
December 27, 2020 | https://jerseyfonseca.com/projects/bujo | <a href="https://web.archive.org/web/*/https://jerseyfonseca.com/projects/bujo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>
            My first successful open source project was <a href="https://github.com/vuciv/vim-bujo">Vim Bujo</a>, a task manager that you 
            can use straight from any vim session. You can access a general todo list, or a project specific one.
        </p>
        <p><img src="https://jerseyfonseca.com/projects/images/bujo/bujo.png"></p><h2>Coming up with the Idea</h2>
        <p>
            I typically use todo lists, but I've never been able to find anything 
            better than good 'ol pen and paper. I've tried the most popular apps, 
            but I just couldn't get into them. Switching screens from my work to mark 
            something as complete just kind of ruined the flow for me. On top of that, 
            all these apps were bloated with features I didn't want or need.
        </p>
        <p>
            For many years, I just stuck to pen and paper, but I was always looking for
            something digital. There had to be some technology that gave me the satisfaction and 
            organization of marking tasks as completed without interrupting my workflow! Well, I never found it... 
        </p>
        <p>
            I was getting into vim last year. You know how when you're learning about something new, 
            you start to see it everywhere? Like, the first time I learned Mechanics, I would think 
            about all the forces interacting whenever I took a step. Well, I was experiencing that, 
            except for vim. One day, I was jotting my ideas on a todo list  
            and I had an epiphany. "I can open a todo list straight from the file I'm working on!" 
            And so spawned the idea of a Vim Bullet Journal, or, Vim Bujo. 
            It was a vim plugin that I actually wanted to use. 
        </p>
        <h2>Making It</h2>
        <p>
           I had no experience with building vim plugins, or using vimscript, the language vim plugins are written in. 
           My first step was to checkout Steve Losh's "Creating a Full Plugin" from his book, 
           <a href="https://learnvimscriptthehardway.stevelosh.com/">Learn Vimscript the Hard Way</a>. After skimming 
           through, I was able to get a pretty good idea of the file structure, but was still lacking on specifics, and 
           to be frank, did not have the time to read through the other 40+ chapters of Steve Losh's book. 
           To fill this gap in my knowledge, I decided to learn my favorite way: reading other people's code!
        </p>
        <p>
            I find just looking at other people's code is always a great way to get started. I don't mean copying, or 
            anything. I just mean looking at functional code, logic flows, and more high-level components. I decided to 
            check out some of <a href="https://github.com/tpope">Tim Pope's</a> projects. He is one of the most famous 
            and prolific vim plugin creators out there - and all his code is open source! Take advantage of things like this! 
            It's a gold mine!
        </p>
        <p>
            Well, from then on, I built the simplest version I can; it did everything it needed to do. When you typed ":Todo", 
            a new file would open and dock to your window. From here, you can use keybindings to enter a new task, or mark one 
            as completed. I tested it out, and it was exactly what I had been looking for. Okay, I probably overhyped it a little 
            to myself since I'm the one that made it... But it felt good, and was definitely something I wanted to use.
        </p>
        <h3>Adding Git Integration</h3>
        <p>
            So far, I was pretty happy with my project! Someone ended up making a really good feature request, though. 
            They asked if I can have git integration so that a project specific todo list would open up if you are in 
            a git repo. It turned out to be pretty easy!
        </p>
        <p>
            Git has a userful command called <code>git rev-parse --is-inside-work-tree</code>. If this returned <code>true</code>, we would 
            use <code>git rev-parse --show-toplevel</code> to get the name of the toplevel directory and make a todo file named 
            after the project repo you are in.
        </p>
        <p>
            Adding git integration wasn't a challenge at all, but I thought it was cool enough that I should include it! 
            Also, git integration just makes my project sound cooler, and that's what it's all about, right?
        </p>
        <h3>Where do I Store the Todo Files?</h3>
        <p>
            Once git integration existed, I needed to think about where I'd be storing these files on users' computers. 
            I originally just had a dotfile at the root directory of the project, but this wasn't optimal. Luckily, a user 
            presented a solution so simple it made me hit myself in the head. Just make a <code>~/.cache/bujo</code> folder where all 
            this would be stored! It wouldn't bother users at all, and if that wasn't good for them, they can set their 
            own filepath in their vimrc.
        </p>
        <h2>Marketing It</h2>
        <p>
            I gotta admit, I am pretty bad when it comes to marketing. I constantly delete my social medias, and so I never 
            build up an audience to share my creations with. Luckily, I had something genuine to share that communities 
            tend to receive well. I wasn't trying to spam anyone, I wasn't trying to get something from them, I was just 
            sharing what I made. Here were my most successful avenues:
        </p>
        <h3><a href="https://www.reddit.com/r/vim">r/vim</a> on Reddit</h3>
        <p><img src="https://jerseyfonseca.com/projects/images/bujo/reddit.PNG"></p><p>
            My <a href="https://www.reddit.com/r/vim/comments/hf98bu/vimbujo_a_minimalist_todo_list/">reddit post</a> was 
            probably the most successful avenue! I got 300+ upvotes, and engaged with around 20 people in the comments. 
            They offered me feedback, and I implemented it. This was the most important part of getting people to use it.
        </p>
        <h3>Discord</h3>
        <p>
            <a href="https://twitter.com/ThePrimeagen">The Primeagen</a> is the person who got me into vim. 
            His videos and streams are phenomenal and I love following him. I was also in his discord and asked 
            him if I'd be able to share my plugin in his channel. He said yes, and on top of that, he even started 
            using it! This didn't get me many users, but he started using it! Sometimes, when he's going through 
            his .vimrc, I see my plugin! This was by far the coolest part for me.
        </p>
        <h2>Results</h2>
        <p>
            This was the first thing I've ever made that people actually used.
            <a href="https://github.com/vuciv/vim-bujo">On github</a>, people were contributing, logging issues, making feature requests, 
            and even forking the project to expand on it! I ended with over 100 stars, 
            which may not sound like much, but is a huge milestone for me. 
        </p>
        <p>
            The most important thing I learned here was to build things I want to use.
            If I find it useful, odds are somone else finds it useful too!
        </p>
    </div></div>]]>
            </description>
            <link>https://jerseyfonseca.com/projects/bujo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551638</guid>
            <pubDate>Sun, 27 Dec 2020 15:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Conversation with Bruce Schneier [video]]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25551599">thread link</a>) | @sasvari
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11473-conversation_with_bruce_schneier | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11473-conversation_with_bruce_schneier">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Bruce+Schneier">Bruce Schneier</a> and
<a href="https://media.ccc.de/search?p=frank">frank</a>

</p><p>
No content found (yet?).
</p>
<!-- %h3 About -->
<p>Live Conversation with Bruce Schneier. Audience questions can be submitted via chat and have a chance to be asked by moderator Frank Rieger.</p>

<p>Topics:
<br>• Actual and perceived role of cryptography in our world
<br>• The recent latest chapter in the eternal CryptoWars
<br>• Core problems of IT-security and why nobody solves them
<br>• The digital sphere as a freefire battlefield for state and nonstate actors
<br>• Technological, legal and political leverages to prevent total surveillance</p>

<h3>Download</h3>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11473-conversation_with_bruce_schneier</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551599</guid>
            <pubDate>Sun, 27 Dec 2020 15:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become an ETH2 Validator?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25551514">thread link</a>) | @shubidubi
<br/>
December 27, 2020 | https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html | <a href="https://web.archive.org/web/*/https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Ethereum is one of the leading crypto projects (second to bitcoin). In December 2020 Ethereum released the first stage of Ethereum 2.0. The biggest difference is that there is no need for an expensive calculation to validate blockchain transactions, miners can earn money only by staking their coins. This is a shift from proof-of-work to <a href="https://ethereum.org/en/eth2/staking">proof-of-stake</a>. You can read more on the vision <a href="https://ethereum.org/en/eth2/vision">here</a>.</p>

<h3 id="what-does-it-mean-for-you">What does it mean for you?</h3>

<p>If you want to “mine” eth you don’t need to invest in an expensive server farm anymore, all you need is to stake at least 32ETH and run the eth2 clients for as little as $10/month. In return you will earn passive income - currently, <a href="https://docs.google.com/spreadsheets/d/15tmPOvOgi3wKxJw7KQJKoUe-uonbYR6HF7u83LR5Mj4/edit#gid=842896204">around 10%</a>. The more people stake their eth the lower the interest rate will be. You can find the latest rate <a href="https://launchpad.ethereum.org/">here</a>.
In case you have at least 32ETH and you are OK to stake it for at least a year, probably more, until Ethereum reach their <a href="https://docs.ethhub.io/ethereum-roadmap/ethereum-2.0/eth-2.0-phases">next phase</a>, you can use this guide to learn how to do it.
This solution is great if you want to hold your ETH coins for 1-2 years and earn passive income by doing so.
<strong>This guide is for educational purposes only.</strong></p>

<h3 id="install-metamask">Install Metamask</h3>

<p>We will use Metamask as our ethereum wallet. You can install it from <a href="https://metamask.io/">here</a>. Do not lose the password and paraphrase for your wallet.<br>
After you finished installing your wallet, make sure you select the <code>goerli</code> (test) network.
<img src="https://sagivo.com/assets/ethereum-11.png" alt="Metamask Goerli"></p>

<h3 id="get-goerli">Get Goerli</h3>

<p>Since we are using the Goerli test network, we will need some coins to play with. To be a validator you will need ether. You can get test ether coins from <a href="https://faucet.goerli.mudit.blog/">here</a>. All you need is to tweet your <strong>goerli</strong> wallet address. Make sure you ask for at least 32 eth (the minimum for a validator node).</p>

<h3 id="become-eth2-validator">Become eth2 validator</h3>

<p>Go to the Ethereum 2.0 pyrmont (test) <a href="https://pyrmont.launchpad.ethereum.org/">launchpad site</a> and click on <code>GET STARTED</code>. Read all the warnings and information, make sure you understand them all.<br>
The next step is to <a href="https://pyrmont.launchpad.ethereum.org/select-client">select your client</a> - choose <a href="https://github.com/sigp/lighthouse">lighthouse</a>.<br>
Select how much eth you want to stake, 32 eth is the minimum.
You will also need to <a href="https://pyrmont.launchpad.ethereum.org/generate-keys">select your local machine’s operating system</a> to <a href="https://github.com/ethereum/eth2.0-deposit-cli/releases/">download the CLI</a>. In this post I use Mac, but you can choose whatever OS you use. Open and extract the CLI folder you downloaded from GitHub. Inside that folder, you will find a <code>deposit</code> file. Run this file using: <code>/path/to/deposit new-mnemonic --num_validators 1 --chain pyrmont</code>. Please note:<br>
<code>/path/to/deposit</code> is whenever your downloaded <code>deposit</code> file is.<br>
<code>--num_validators</code> has the number of validators you want to have. Each validator is 32ETH.<br>
<code>pyrmont</code> is the test network. You should change it if you want to work on the main network (aka real money).</p>

<p>Here is example of the output you will have:</p>

<div><div><pre><code><span>&gt;</span> /Users/sagivo/Desktop/eth2deposit-cli-ed5a6d3-darwin-amd64/deposit new-mnemonic <span>--num_validators</span> 1 <span>--chain</span> pyrmont
Please choose your mnemonic language <span>(</span>czech, chinese_traditional, chinese_simplified, english, spanish, italian, korean<span>)</span> <span>[</span>english]: english
Type the password that secures your validator keystore<span>(</span>s<span>)</span>:
Repeat <span>for </span>confirmation:
</code></pre></div></div>

<p>You will be asked to choose a validator password. Do not lose this password, you will need it to get your money back at some point. <strong>This is not your wallet password</strong>, select a new password just for the validator client. After selecting the password you will get a seed phrase to store in case you lost your validator password. Store the seed phase in a secure location as well.<br>
If everything went well you should see a hippo(?) image.<br>
<img src="https://sagivo.com/assets/ethereum-4.png" alt="Ethereum CLI validator"></p>

<p>Open the folder with the keys. In this folder you will find a few files:<br>
<code>deposit_data-[some number].json</code> - this is the information for your deposit.<br>
<code>keystore-[some number].json</code> - you will have one or more files based on the number of validators you selected.
In this stage, you have all you need to install the local clients. Keep this window open, we will get back to it after we install the clients.</p>

<h3 id="ethereum-client-components">Ethereum client components</h3>

<p>Now that you staked your eth, you will need 3 nodes to become ETH 2.0 validator:</p>

<ul>
  <li><strong>ETH 1.0 client</strong>: this client will listen to the Ethereum 1.0 network. You can either run a local client or use a free 3rd party node. To save resources and keep this post simple, I’m using a free <a href="https://dashboard.alchemyapi.io/signup?referral=5f4b22ad-1a24-46af-ab1c-4475e8fe177d">alchemyapi.io</a> node. You can find more 3rd party options <a href="https://ethereumnodes.com/">here</a>.</li>
  <li><strong>Beacon node</strong>: ethereume 2.0 client.</li>
  <li><strong>Validator client</strong>: to validate eth2 transactions.</li>
</ul>

<h3 id="create-eth1-client">Create eth1 client</h3>

<p>You can either create a local eth1 client or use a 3rd party node instead. Let’s use a 3rd party today. Open a free <a href="https://dashboard.alchemyapi.io/signup?referral=5f4b22ad-1a24-46af-ab1c-4475e8fe177d">alchemyapi.io</a> and <a href="https://dashboard.alchemyapi.io/apps">create an app</a>. Make sure you select the <code>Goerli</code> network for your eth1 node.</p>

<p><img src="https://sagivo.com/assets/ethereum-9.png" alt="Alchemyapi node"></p>

<p>After the app has been created go to the app’s page and click on <code>VIEW KEY</code>, you will need to copy the HTTP URL for the beacon node.
<img src="https://sagivo.com/assets/ethereum-10.png" alt="Alchemyapi address"></p>

<h3 id="hosting-your-beacon-node-and-validator-client">Hosting your beacon node and validator client</h3>

<p>You can run your beacon node and validator client on a local computer. Beacon nodes are intended to be high-performance, highly available platforms that can support connections to numerous validator clients and maintain ongoing p2p connectivity with other beacon nodes. As such, their hardware requirements are anticipated to be server-grade CPU/SSD/networking connections.<br>
Your server needs to be available 24/7 or you will accrue penalties and lose ETH. This is why I prefer running my nodes on a hosted cloud server. In this tutorial, I choose <a href="https://m.do.co/c/29d9028f31d1">Digitalocean</a>. After playing with multiple specs, I’ve found that you can run your beacon node and validator client for just $10/month. Use <a href="https://m.do.co/c/29d9028f31d1">this link</a> to sign up for digitalocean and get $100 credit! This should cover your Ethereum staking expenses a while :)</p>

<h3 id="creating-a-digitalocean-droplet">Creating a digitalocean Droplet</h3>

<p>From your Digitalocean account, create a <a href="https://cloud.digitalocean.com/droplets/new">new droplet</a>.<br>
Choose the <code>Ubuntu</code> droplet. This will create a UNIX server running Ubuntu. <img src="https://sagivo.com/assets/ethereum-1.png" alt="Ubunto droplet"></p>

<p>Select the $10/mo plan. The $10/month spec is the bare minimum you should choose. If you want to choose a stronger instance go for it.</p>

<p><img src="https://sagivo.com/assets/ethereum-2.png" alt="10 dollar plan"></p>

<p>Setup SSH access under the <code>Authentication</code> section. This is important to be able to access your server from your terminal.<br>
You can leave the other settings as-is.<br>
Once your droplet setup is completed copy the ip address from the dashboard.<br>
<img src="https://sagivo.com/assets/ethereum-3.png" alt="copy ip"></p>

<h3 id="setting-up-your-cloud-server">Setting up your cloud server</h3>

<p>By now you should have a running digital ocean server and you should have generated <code>validator_keys</code> locally using the CLIt. Now let’s access your digital ocean machine to set it up.
First, let’s copy your local <code>validator_keys</code> folder to your hosted server.</p>

<div><div><pre><code>scp <span>-pr</span> /path/to/your/local/validator_keys <a href="https://sagivo.com/cdn-cgi/l/email-protection" data-cfemail="8cfee3e3f8cce8e5ebe5f8ede0">[email&nbsp;protected]</a>_ocean_ip:/validator_keys
</code></pre></div></div>

<ul>
  <li><code>/path/to/your/local/validator_keys</code>: the path for your local folder containing the generated validator keys.</li>
  <li><code>digital_ocean_ip</code>: your digitalocean machine’s IP.</li>
</ul>

<p>Now that we copied the keys to the droplet (digitalocean instance), let’s SSH into this machine.</p>



<ul>
  <li><code>digital_ocean_ip</code>: your new machine’s IP.</li>
</ul>

<p>The first (optional) step is to enable better metrics on the machine to track later in digitalocean. This will let you inspect CPU, memory, disk I/O, and other metrics in the digitalocean dashboard.</p>

<div><div><pre><code>curl <span>-sSL</span> https://repos.insights.digitalocean.com/install.sh | <span>sudo </span>bash
</code></pre></div></div>

<h3 id="install-lighthouse">Install Lighthouse</h3>

<p>In this step, we will install lighthouse on your new server. <a href="https://github.com/sigp/lighthouse">Lighouse</a> is an open-source Ethereum 2.0 client, written in <a href="https://www.rust-lang.org/">Rust</a> and maintained by Sigma Prime.</p>

<ol>
  <li>Go to the <a href="https://github.com/sigp/lighthouse/releases">Lighthouse releases page</a> and select the latest linux release.</li>
  <li>Download the portable binary <code>wget lighthouse-${VERSION}-x86_64-unknown-linux-gnu-portable.tar.gz</code>.</li>
  <li>Extract the archive: <code>tar -xvf lighthouse-${VERSION}-x86_64-unknown-linux-gnu.tar.gz</code></li>
  <li>Test the binary with <code>./lighthouse --version</code> (it should print the version).</li>
  <li>Move the lighthouse binary to a location in your PATH, so the lighthouse command can be called from anywhere: <code>cp lighthouse /usr/bin</code></li>
  <li>
    <p>Clean your downloaded files</p>

    <div><div><pre><code><span>rm </span>lighthouse
<span>rm </span>lighthouse-<span>${</span><span>VERSION</span><span>}</span><span>-x86_64-unknown-linux-gnu</span>.tar.gz
</code></pre></div>    </div>
  </li>
</ol>

<h3 id="import-validator-keys">Import validator keys</h3>

<p>We will import the validator keys so we can use them by the validator.</p>

<div><div><pre><code><span>mkdir</span> <span>-p</span> /var/lib/lighthouse
lighthouse account validator import <span>--directory</span> /validator_keys <span>--datadir</span> /var/lib/lighthouse
</code></pre></div></div>

<ul>
  <li><code>/var/lib/lighthouse</code>: this folder will store our lighthouse data.</li>
  <li><code>--directory /validator_keys</code>: our imported <code>validator_keys</code> folder locaiton.</li>
</ul>

<p>You will be prompted to insert a password. Insert the password for your validator client again.</p>

<h3 id="run-beacon-node">Run beacon node</h3>

<p>We will run the beacon node as a daemon service. This way it will auto-restart if there’s an error. It’s important to have your eth 2.0 service running 24/7 to not accrue penalties and lose eth.</p>

<div><div><pre><code>nano /etc/systemd/system/lighthousebeacon.service
</code></pre></div></div>

<p>Paste this text:</p>

<div><div><pre><code>[Unit]
Description=Lighthouse Eth2 Client Beacon Node
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
Restart=always
RestartSec=5
ExecStart=/usr/bin/lighthouse bn --network pyrmont --staking --datadir /var/lib/lighthouse --eth1-endpoints https://eth-goerli.alchemyapi.io/v2/[your token]

[Install]
WantedBy=multi-user.target
</code></pre></div></div>

<p>This is a new service that will re-start if it fails.</p>

<ul>
  <li><code>--network pyrmont</code>: we use the test network</li>
  <li><code>--eth1-endpoints</code>: comma-separated http addresses of your eth1 client nodes.</li>
</ul>

<p>To reload the daemon use</p>



<p>Now let’s start the beacon daemon service:</p>

<div><div><pre><code>systemctl start lighthousebeacon
</code></pre></div></div>

<p>You can inspect the output using (safe to ctr+c once you’re done):</p>

<div><div><pre><code>journalctl <span>-fu</span> lighthousebeacon.service
</code></pre></div></div>

<p>Also, let’s enable the service to start on server restart:</p>

<div><div><pre><code>systemctl <span>enable </span>lighthousebeacon
</code></pre></div></div>

<h3 id="validator-client">Validator client</h3>

<p>Let’s create a validator service</p>

<div><div><pre><code>nano /etc/systemd/system/lighthousevalidator.service
</code></pre></div></div>

<p>Paste this:</p>

<div><div><pre><code>[Unit]
Description=Lighthouse Eth2 Client Validator Node
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
Restart=always
RestartSec=5
ExecStart=/usr/bin/lighthouse vc --network pyrmont --datadir /var/lib/lighthouse --graffiti "YOLO"

[Install]
WantedBy=multi-user.target
</code></pre></div></div>

<p>This is a new service that will re-start if it fails.</p>

<ul>
  <li><code>--network pyrmont</code>: we use the test network</li>
  <li><code>--graffiti</code>: an optional message you want to include in your validation blocks.</li>
</ul>

<p>To reload the daemons use</p>



<p>Start the validator daemon service.</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html">https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html</a></em></p>]]>
            </description>
            <link>https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551514</guid>
            <pubDate>Sun, 27 Dec 2020 15:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatbuffers in Unity – A 40x Gain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550974">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | http://extrawurst.github.io/gamedev/unity/programming/rust/2020/12/26/unity-flatbuffers.html | <a href="https://web.archive.org/web/*/http://extrawurst.github.io/gamedev/unity/programming/rust/2020/12/26/unity-flatbuffers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>We recently switched from downloading and parsing JSON in our Unity client to a binary format based on Flatbuffers.
In this this article you are going to learn:</p>

<ul>
  <li><em>why</em> we did that</li>
  <li><em>what</em> Flatbuffers is anyway</li>
  <li><em>how</em> you can do that yourself</li>
  <li>what <em>benefit</em> we gained</li>
</ul>

<p><strong>TL;DR</strong></p>

<p>You are looking to simplify your life integrating Flatbuffers in Unity? Look no further: <a href="https://github.com/gameroasters/flatbuffers-unity-docker">gameroasters/flatbuffers-unity</a></p>



<p>Our recent game <em>Wheelie Royale</em> (<a href="https://apps.apple.com/US/app/id1518264893">Appstore</a> / <a href="https://play.google.com/store/apps/details?id=com.gameroasters.wheelieroyale&amp;hl=en&amp;gl=US">Playstore</a>) downloads a lot of replay data by other players. Replay data was transmitted in JSON format. In the most extreme cases up to 15mb of JSON for a single level.
While this is already a problem just because of mobile data usage it manifests even more severly in mid- to low-end devices when deserializing the JSON data.</p>

<p>After digging out my low-end test device (Galaxy S4) it took <a href="https://www.newtonsoft.com/json">Newtonsoft.JSON</a> <strong>20 sec</strong> to deserialize the 15mb. This is bad and for some players it even went up to a minute - an absolute dealbreaker.</p>

<p>Obviously we had to find a better method entirely.</p>



<blockquote>
  <p>FlatBuffers is an efficient cross platform serialization library (<a href="https://google.github.io/flatbuffers/">Flatbuffers website</a>)</p>
</blockquote>

<p>Initially a Google internal project for game development it received some fame when Facebook announced massive performance gains by utilizing it on their mobile app (<a href="https://engineering.fb.com/2015/07/31/android/improving-facebook-s-performance-on-android-with-flatbuffers/">article</a>).</p>

<p>Using Flatbuffers gives us two main advantages:</p>

<ol>
  <li>Data is stored in binary form making it easy on the bandwidth</li>
  <li>Accessing Data is very fast since it is just a lookup from contiguous memory</li>
</ol>

<p>The following graphic visualizes this:</p>

<p><img src="http://extrawurst.github.io/assets/flatbuffers/fb.jpeg" alt="fb"></p>

<p>Flatbuffers store data in a <strong>contiguous</strong> chunk of memory making it also easy on the garbage collector that especially in our use case was trashed with a lot of small allocations.
If you mainly read your data from a buffer and do not need to alter it (our exact use case) it escentially reduces allocations to zero (reusing a static buffer).</p>

<p>Aside the compact memory layout Flatbuffers reduces the memory consumption by expecting both parties to know the schema. We later see how we generate code for client and backend to be able to speak the same <em>language</em>.</p>

<h2 id="comparison">Comparison</h2>

<ul>
  <li><strong>Before</strong>: Deserializing 15mb of Json in <strong>20 secs</strong></li>
  <li><strong>After</strong>: Parsing the same data but using Flatbuffers (4mb) in <strong>0,5 sec</strong></li>
</ul>

<p>This is a speed improvement of <strong>40x</strong>.</p>

<p><strong>Disclaimer</strong>: Of course this is not a proper scientific benchmarking method but it holds true even on our modern iPhones (albeit on a much smaller scale). I leave the more scientific methods of benchmarking to people smarter than me: 
<a href="https://google.github.io/flatbuffers/flatbuffers_benchmarks.html">benchmark</a></p>



<p>Here is a simplified version of our schema file. Keep in mind that we are dealing with playbacks (ghosts) of other players. Each ghost consists of a TON of deltas (Sample) that allow us to replay them.</p>

<pre><code>struct Sample {
  //...
  r: int16;
}

table GhostRecording {
  //...
  deltas: [Sample] (required);
}

table Ghost {
  //...
  recording: [GhostRecording] (required);
}

table Ghosts {
  //...
  items:[Ghost] (required);
}

root_type Ghosts;
</code></pre>

<p>Here you can see why our use case was particularly tough for the garbage collector in Unity since we are dealing with a lot of small individually allocated objects.</p>

<p>If you want to to more about the differences of <code>table</code> and <code>struct</code> you can find all details about the schema here: <a href="https://google.github.io/flatbuffers/flatbuffers_guide_writing_schema.html">Flatbuffers Schema</a></p>

<h2 id="code-generation">Code generation</h2>

<p>When it comes to the pipeline required to get this working I was disappointed at how little was available: no easy docker container to get <code>flatc</code> (the schema transpiler) working cross platform, no ready built .net library for Unity to get started.</p>

<p>So I built this and open sourced it on our company github: <a href="https://github.com/gameroasters/flatbuffers-unity-docker">gameroasters/flatbuffers-unity</a></p>

<p>Using this docker container it is easy to create your serialization/deserialization code using the following snippet:</p>

<div><div><pre><code>docker run <span>-it</span> <span>-v</span> <span>$(</span>shell <span>pwd</span><span>)</span>:/fb gameroasters/flatbuffers-unity:v1.12.0 /bin/bash <span>-c</span> <span>"cd /fb &amp;&amp; </span><span>\</span><span>
	flatc -n --gen-onefile schema.fbs &amp;&amp; </span><span>\</span><span>
	flatc -r --gen-onefile schema.fbs"</span>
</code></pre></div></div>

<p>This will mount your current working directory into the container, it is expecting to find a <code>schema.fbs</code> file in here and generate the necessary code for <em>Rust</em> and <em>CSharp</em> for you in two files called <code>schema.rs</code> and <code>schema.cs</code>.</p>



<p>Flatbuffers is not going to make your code more readable. Here is an example how we read in our ghosts from it:</p>

<div><div><pre><code><span>var</span> <span>fb_ghosts</span> <span>=</span> <span>GR</span><span>.</span><span>WR</span><span>.</span><span>Schema</span><span>.</span><span>Ghosts</span><span>.</span><span>GetRootAsGhosts</span><span>(</span><span>new</span> <span>ByteBuffer</span><span>(</span><span>data</span><span>));</span>

<span>var</span> <span>res</span> <span>=</span> <span>new</span> <span>List</span><span>&lt;</span><span>Ghost</span><span>&gt;(</span><span>fb_ghosts</span><span>.</span><span>ItemsLength</span><span>);</span>
<span>for</span> <span>(</span><span>var</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>fb_ghosts</span><span>.</span><span>ItemsLength</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>var</span> <span>e</span> <span>=</span> <span>fb_ghosts</span><span>.</span><span>Items</span><span>(</span><span>i</span><span>);</span>
    <span>if</span> <span>(!</span><span>e</span><span>.</span><span>HasValue</span><span>)</span> <span>continue</span><span>;</span>
    <span>var</span> <span>recording</span> <span>=</span> <span>e</span><span>.</span><span>Value</span><span>.</span><span>Recording</span><span>.</span><span>Value</span><span>;</span>

    <span>var</span> <span>deltas</span> <span>=</span> <span>new</span> <span>List</span><span>&lt;</span><span>Sample</span><span>&gt;(</span><span>recording</span><span>.</span><span>DeltasLength</span><span>);</span>
    <span>for</span> <span>(</span><span>var</span> <span>j</span> <span>=</span> <span>0</span><span>;</span> <span>j</span> <span>&lt;</span> <span>recording</span><span>.</span><span>DeltasLength</span><span>;</span> <span>j</span><span>++)</span>
    <span>{</span>
        <span>var</span> <span>delta</span> <span>=</span> <span>recording</span><span>.</span><span>Deltas</span><span>(</span><span>j</span><span>);</span>
        <span>var</span> <span>r</span> <span>=</span> <span>delta</span><span>.</span><span>Value</span><span>.</span><span>R</span><span>;</span>
        <span>deltas</span><span>.</span><span>Add</span><span>(</span><span>new</span> <span>Sample</span><span>(</span><span>r</span><span>));</span>
    <span>}</span>

    <span>var</span> <span>ghost</span> <span>=</span> <span>new</span> <span>Ghost</span><span>();</span>
    <span>ghost</span><span>.</span><span>recording</span> <span>=</span> <span>new</span> <span>GhostRecording</span><span>();</span> 
    <span>ghost</span><span>.</span><span>recording</span><span>.</span><span>deltas</span> <span>=</span> <span>deltas</span><span>;</span>
  
    <span>res</span><span>.</span><span>Add</span><span>(</span><span>ghost</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Unlike some alternatives to Flatbuffers it does not create the Plain-Old-Data (POD) objects for you and deserialize into those. But that is by design. You could actually go without them when you only need to access it for reading.</p>

<p>We only create those to keep the code compatible with the previous approach that deserialized JSON into POD objects.</p>



<p>Of course there are alternatives that I do not want to hide:</p>

<ul>
  <li><a href="https://developers.google.com/protocol-buffers">protobuf</a></li>
  <li><a href="https://github.com/capnproto/capnproto">cap’n’proto</a></li>
</ul>

<p>Here is a very nice comparison matrix: https://capnproto.org/news/2014-06-17-capnproto-flatbuffers-sbe.html</p>

<p>The main benefit for <strong>protobuf</strong> is that it does the extra step of creating POD objects for you bringing it even closer to what you are used to in regular JSON deserialization. It is a good tradeoff between speed (Flatbuffers) and convenience (JSON). Another nice thing is: protobuf also speaks JSON which simplifies debugging a lot.</p>

<p>The other alternative - <strong>cap’n’proto</strong> - is actually made by the <a href="https://stackoverflow.com/a/25370932/1397367">same guy</a> who made protobuf and uses the same zero-allocation approach Flatbuffers uses. <strong>cap’n’proto</strong> does not support as many languages yet - thats the only reason I did not consider giving it a try (yet).</p>

<p>Ultimately there is no <em>best</em> solution, everything comes at a cost. If you need raw speed there is not much more you can get compared to Flatbuffers.</p>



<ul>
  <li><a href="https://www.youtube.com/watch?v=YsiQDX20lXI">Bringing FlatBuffers Zero-Copy Serialization to Rust by Robert Winslow</a> (Meetup Video)</li>
</ul>

      </div></div>]]>
            </description>
            <link>http://extrawurst.github.io/gamedev/unity/programming/rust/2020/12/26/unity-flatbuffers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550974</guid>
            <pubDate>Sun, 27 Dec 2020 13:44:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stack Based Virtual Machines]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550776">thread link</a>) | @signa11
<br/>
December 27, 2020 | https://andreabergia.com/stack-based-virtual-machines/ | <a href="https://web.archive.org/web/*/https://andreabergia.com/stack-based-virtual-machines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            

            <div id="container">


<div>
    <article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        <div itemprop="articleBody">
    

    

<p>In this series we’re going to delve a bit into stack based virtual machines. First we’re going to see an overview, then we’ll build our own toy VM. Next, we’re going to see how what we’ll build maps to a real CPU. Finally, we’ll discuss the most famous of all: the JVM.</p>

<h3 id="introduction">Introduction</h3>

<p>What’s a <em>stack based virtual machine</em> then? It’s an abstraction of a computer, that emulates a real machine. Generally it is built as an interpreter of a special <em>bytecode</em>, that translates its in real time for execution on the CPU.</p>

<p>Let’s start with a trivial example: suppose your program needs to add two numbers. To do that in a stack VM, the program will <em>push</em> the first number to the stack, <em>push</em> the second and then execute some form of the special instruction <em>add</em>, that will <em>pop</em> the first two elements of the stack and replace them with their sum. Let’s see it step by step:</p>

<p><img src="https://andreabergia.com/images/2015/03/Stack_1.png" alt="At the beginning"></p>

<p>The <code>SP</code> is the <em>stack pointer</em>, which refers to the head of the stack. The <code>IP</code> is the <em>instruction pointer</em>, which points to the address of the current instruction to execute. Let’s now execute the first instruction:</p>

<p><img src="https://andreabergia.com/images/2015/03/Stack_2.png" alt="After the first instruction"></p>

<p>You can see that the stack now contains <code>1</code> and that the instruction pointer has been moved to the next instruction. Let’s now simulate the second instruction:</p>

<p><img src="https://andreabergia.com/images/2015/03/Stack_3.png" alt="After the second instruction"></p>

<p>Finally we can execute the <code>add</code> instruction:</p>

<p><img src="https://andreabergia.com/images/2015/03/Stack_4.png" alt="After the add"></p>

<p>The head of the stack and the previous element have been popped and replaced with their sum.</p>

<h3 id="centrality-of-the-stack">Centrality of the stack</h3>

<p>As you have seen from the example, the main two data structures for a stack VM are the code listing, with the instruction pointer, and the stack data, which is accessed only via the stack pointer. While these two data structures seem trivial, they are more than enough to implement a lot of complex programs. By adding some external memory area (what is generally known as “memory on the heap”), this structure will become complex enough to form the basis of a real language such as Java or Scala.</p>

<p>The stack will be the central structure. From what we hve seen above you should have some idea on how to use it to implement the basic arithmetic, but it is also going to be the basis of implementing loops and conditional execution (if) and even function calls! We’re going to discuss all of this while building our toy VM.</p>

<h3 id="register-based-virtual-machines">Register based virtual machines</h3>

<p>Closely related to stack based VM are <em>register based virtual machines</em>. They are also interpreters of bytecode, but their design is quite different, since they don’t use the stack for the operands but rather a set of registers. While they tend to be more complex, they are also generally faster at runtime, since they map much more closely to the CPU (which, as we’ll see later, is actually an hardware register machine) and thus they tend to generate and execute better efficient code.</p>

<p>However stack based virtual machines are not just a learning toy. The most successful VM ever, the <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">Java Virtual Machine</a>, is a stack-based virtual machine (and so is the <a href="https://en.wikipedia.org/wiki/Common_Language_Runtime">CLR</a>, the basis of .NET). Furthermore the JVM is <em>extremely</em> high performant, while still quite simple - although that has been achieved more by the <em>immense</em> amount of money that has flown into its development than by some special characteristic of its architecture.</p>

<p>The most famous example of a register based virtual machine is probably <a href="http://www.lua.org/">LUA</a>, which can achieve <a href="http://luajit.org/performance.html">amazing performances</a> and is used in <a href="https://en.wikipedia.org/wiki/Category:Lua-scripted_video_games">many videogames</a> as a scripting language.</p>

<h3 id="links">Links</h3>

<p>I hope this short introduction has stimulated your curiosity. Here are a few links in case you wish to start reading something more:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Stack_machine">Wikipedia page for stack based virtual machines</a></li>
<li><a href="https://en.wikipedia.org/wiki/Comparison_of_application_virtualization_software">Comparision of common VM</a></li>
<li><a href="http://www.lua.org/doc/jucs05.pdf">Design document for LUA</a></li>
</ul>

<p>About the JVM:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Java_bytecode">JVM bytecode introduction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Java_bytecode_instruction_listings">JVM bytecode instructions</a></li>
<li><a href="http://download.forge.objectweb.org/asm/asm4-guide.pdf">Introduction to ASM, a JVM bytecode manipulation library</a></li>
</ul>

<p><strong>Update:</strong> part two is <a href="https://andreabergia.com/stack-based-virtual-machines-2">online</a>.</p>

</div>

        

        
    </article>
</div>

            </div>
        </div></div>]]>
            </description>
            <link>https://andreabergia.com/stack-based-virtual-machines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550776</guid>
            <pubDate>Sun, 27 Dec 2020 13:12:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Central Bank Digital Currencies Are a Bad Idea]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25550443">thread link</a>) | @simonebrunozzi
<br/>
December 27, 2020 | https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea | <a href="https://web.archive.org/web/*/https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1605643941671" id="item-5fb42c70669e655a2de5be01"><div><div><div data-block-type="2" id="block-36140108062efd62704e"><div><p><em>This text was published at </em><a href="https://mises.org/wire/why-central-bank-digital-currencies-are-bad-idea"><em>Mises Institute</em></a></p><p>The Central Banking Digital Currencies (CBDC) are being sold with the narrative of protecting consumers who are increasingly moving to cashless payments and as a result, robbing themselves of the privacy advantages of cash and exposing themselves to bank runs, payment network blackouts, and to foreign financial adversaries.</p><p>While these risks are real, they would be negligible had it not been for the central banking and financial regulators’ interventions into the market (more on that in the last couple of paragraphs), and CBDCs if anything make them worse and introduce some new, much bigger ones.</p><p>While the stated intention behind their design is to keep the commercial banks in the picture, CBDCs will bring the end-users of the future tokens closer to the central banks. This is because blockchains and blockchain-inspired distributed ledger technologies are built on a single, common, ledger, which is distributed either in a permissionless or permissioned manner. The permissionless distribution exposes a lot of information about the network participants, but in combination with proof-of-work verification makes it very difficult for an adversary to attack and overtake the network and e.g. change the inflation rate.</p><p>Permissioned network with no proof-of-work or similar consensus algorithm not only doesn’t provide the immutability feature but by having a single permissioned ledger gives potential control to those who grant the network privileges. As a result, the central bank as the ultimate permission issuer would have much stronger control over the monetary system and payment network than they have right now. This gives the central banks three very dangerous capabilities.</p><h2>Helicopter Money</h2><p>The reason why we’ve seen such an elevated business cycle over the past century is the central banking fiat money system. Unnatural expansion of the money supply causes booms, which are unsustainable and markets try to clear them when they are exposed as such.</p><p>Economists of the Austrian school understand, that the boom is the real problem and the economic crisis is the necessary and positive cleansing mechanism. Unfortunately, the (neo)Keynesian response to such an event is to prop the markets up by further monetary interventions.</p><p>However, the current design of the banking system requires the intermediary role of commercial banks in issuing credit to businesses. Central banks get frustrated when the commercial banks exercise caution in an economy, which hasn’t fully cleared the previous misallocations and hasn’t brought prices of capital goods to more sustainable levels.</p><p>Furthermore, since the predominant Keynesian narrative is that spending drives the economy (hint: it doesn’t - capital investments do), the central banks would like to spur more consumer spending by issuing money supply directly to consumers. Needless to say, commercial banks’ cautious approach to consumer credit in a period of growing unemployment doesn’t align well with the central bank’s goals either. During the COVID crisis, the governments managed to an extent to get around these hurdles by issuing benefits en masse, but those are complicated by logistics, bureaucracy, or legislation.</p><p>By closer integration of the monetary spigot to the end consumers and businesses, the central bank can much more easily issue credit, or just outright cashouts to the private individuals and commercial entities by simply “airdropping” new tokens to the existing token identities. They would not even compromise their stated intention of keeping the commercial banks in the picture - those would still serve as custodians of the token keys, and even have the ability to issue credit along the traditional lines.</p><p>This would lead to disastrous consequences. Economies get easily addicted to central banks’ money dope. With every new crisis, the chief monetarists had to increase intervention doses the same way as junkies have to do with their drug of choice. As with every addiction, the longer it lasts and the stronger it grows, the more difficult it is to cure it. And while monetary overdose such as we’ve seen in Zimbabwe or Venezuela might not come for a long time, if ever, junkies don’t perform well, as Japan’s three lost decades of BOJ’s interventions have demonstrated.</p><h2>Negative Interest Rates</h2><p>Hoarding is evil - or so the modern monetarists’ narrative goes. In the Keynesian framework, there is no space for the function of cash as a hedge in times of uncertainty. Savings accounts, in their minds, are just money that doesn’t work in spurring the miracles of spending- and monetary-driven economic growth. Negative interest rates are then potentially the most effective method of preventing hoarding by incentivizing account holders to spend their depreciating balances.</p><p>Currently, the central banks have to rely on commercial banks to pass the negative interest rates on their customers. Commercial banks instead are trying to convince the account holders to move their deposits from negative yielding accounts to interest yielding products and are consuming the negative rates on most of the outstanding cash balances.</p><p>With the central bank tokens being tied more tightly with their issuance authority, it would be much easier for the monetary interventionists to impose negative interest rates on all tokens in circulation. This would on a margin certainly increase the consumers’ and businesses’ propensity to spend and would also drive asset prices up as people would try to offload their cash savings. But to think of it as something beneficial is foolish. It was massive spending, record-low savings, and unsustainable asset valuations that led to the credit bubbles and crises of the past decades. To think that more of the same recipe would lead to a different, let alone better outcome is ludicrous.</p><h2>Financial Surveillance</h2><p>Third and final major implication of cash tokenization is the potential it creates for financial surveillance. The central banks are ostensibly introducing digital tokens to protect people’s privacy in the face of those reducing their anonymous cash usage. But the idea that any branch of government, let alone the one that imposes KYC/AML rules on the existing crypto token platforms, limits physical cash use to prevent tax avoidance, and uses financial surveillance to catch non-violent “criminals” cares about our privacy is laughable.</p><p>They’re not even hiding the fact, that tokenization of money would allow them to run what they call “data analytics”, but to think that they would not make the leap from aggregate analytics to individual data processing would be naive.</p><p>Of course, it’s not a coincidence, that China is the global leader in CBDCs. The surveillance potential of centralized tokenization is extremely attractive to the government that tries to keep tabs on every aspect of the lives of their underlings.</p><p>The proponents of the central banking tokens argue, that consumers need to be protected against targeted attacks on a country’s payment network. While such a risk exists - for example, if a country like Switzerland tried to provide anonymity for foreign depositors as it used to and as a result Visa and Mastercard would be pressured to shut down their payment networks for the country - if it materializes, the economy can always temporarily revert back to cash, supported by a vast network of local ATMs and bank branches.</p><p>If anything, the biggest attacks on the monetary exchange in the western world came from the governments themselves suspending or limiting cash withdrawals in times of liquidity crises as was the case in Cyprus or Greece, not to mention that those crises themselves were caused by central banking credit bubbles of the preceding periods.</p><p>Finally as was already mentioned, the argument about the protection of consumer privacy doesn’t pass the laugh test considering the history of continuous erosion of financial privacy by central banks and financial regulators.</p><p>In conclusion, the same characteristics for which people should oppose the transition to CDBCs give central banks the strongest reason to champion and implement them. And while the pretense of an investigation into the fiat money tokenization gives an impression of a debate on the topic, the reality is, there will be no debate and the digital currencies will go through and give central banks more control than they had before with all the disastrous consequences such control brings.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550443</guid>
            <pubDate>Sun, 27 Dec 2020 11:57:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multi Tenant Node-Red Using Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550132">thread link</a>) | @hardillb
<br/>
December 27, 2020 | https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/ | <a href="https://web.archive.org/web/*/https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4193">
	
	<!-- .entry-header -->

	<div>
		
<p>Having built a working example of <a href="https://www.hardill.me.uk/wordpress/2020/10/01/multi-tenant-node-red/" data-type="post" data-id="3981">Multi Tenant Node-RED </a>using Docker I thought I’d have a look at how to do the same with Kubernetes as a Christmas project.</p>



<p>I started with installing the 64bit build of Ubuntu Server on a fresh Pi4 with 8gb RAM and then using snapd to install <a href="https://microk8s.io/">microk8s</a>. I had initially wanted to use the 64bit version of Raspberry Pi OS, but despite microk8s <a href="https://microk8s.io/docs">claiming</a> to work on any OS that support snapd, I found that containerd just kept crashing on Raspberry Pi OS.</p>



<p>Once installed I enabled the dns and ingress plugins, this got me a minimal viable single node Kubernetes setup working. <br></p>



<figure><img data-attachment-id="4196" data-permalink="https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/screenshot-from-2020-12-23-20-19-32/" data-orig-file="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?fit=1468%2C976&amp;ssl=1" data-orig-size="1468,976" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-from-2020-12-23-20-19-32" data-image-description="" data-medium-file="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?fit=300%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?fit=660%2C439&amp;ssl=1" loading="lazy" width="660" height="439" src="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=660%2C439&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=1024%2C681&amp;ssl=1 1024w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=300%2C199&amp;ssl=1 300w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=768%2C511&amp;ssl=1 768w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?w=1468&amp;ssl=1 1468w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?w=1320&amp;ssl=1 1320w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=1024%2C681&amp;ssl=1 1024w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=300%2C199&amp;ssl=1 300w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=768%2C511&amp;ssl=1 768w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?w=1468&amp;ssl=1 1468w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?w=1320&amp;ssl=1 1320w" data-lazy-src="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=660%2C439&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>







<p>I also had to stand up a private docker registry to hold the containers I’ll be using. That was just a case of running <code>docker run -d -p 5000:5000 --name registry registry</code> on a local machine e.g <code>private.example.com</code> . This also means adding the URL for this to microk8s as described <a href="https://microk8s.io/docs/registry-private">here</a>.</p>



<p>Since Kubernetes is another container environment I can reuse most of the parts I previously created. The only bit that really needs to change is the Manager application as this has to interact with the environment to stand up and tear down containers.</p>



<h2>Architecture</h2>



<p>As before the central components are a MongoDB database and a management web app that stands up and tears down instances. The MongoDB instance holds all the flows and authentication details for each instance. I’ve deployed the database and web app as a single pod and exposed them both as services</p>


<pre title="">apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-red-multi-tenant
  labels:
    app: nr-mt
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nr-mt
  template:
    metadata:
      labels:
        app: nr-mt
    spec:
      containers:
      - name: node-red-manager
        image: private.example.com/k8s-manager
        ports:
        - containerPort: 3000
        volumeMounts:
        - name: secret
          mountPath: /usr/src/app/config
        env:
        - name: MONGO_URL
          value: mongodb://mongo/nodered
        - name: ROOT_DOMAIN
          value: example.com
      - name: mongodb
        image: mongo
        ports:
        - containerPort: 27017
        volumeMounts:
        - name: mongo-data
          mountPath: /data/db
      - name: registry
        image: verdaccio/verdaccio
        ports:
        - containerPort: 4873
        volumeMounts:
        - name: registry-data
          mountPath: /verdaccio/storage
        - name: registry-conf
          mountPath: /verdaccio/conf
      volumes:
      - name: secret
        secret:
          secretName: kube-config
      - name: mongo-data
        hostPath:
          path: /opt/mongo-data
          type: Directory
      - name: registry-data
        hostPath:
          path: /opt/registry-data
          type: Directory
      - name: registry-conf
        secret:
          secretName: registry-conf

</pre>


<p>This Deployment descriptor basically does all the heavy lifting. It sets up the mangment app, MongoDB and the private NPM registry.</p>



<p>It also binds 2 sets of secrets, the first holds holds the authentication details to interact with the Kubernetes API (the <code>~/.kube/config</code> file) and the <code>settings.js</code> for the management app. The second is the config for the Veraccio NPM registry.</p>



<p>I’m using the <a href="https://kubernetes.io/docs/concepts/storage/volumes/#hostpath">HostPath</a> volume provider to store the MongoDB and the Veraccio registry on the filesystem of the Pi, but for a production deployment I’d probably use the NFS provider or a Cloud Storage option like AWS S3.</p>



<h2>Manager</h2>



<p>This is mainly the same as the <a href="https://github.com/hardillb/multi-tenant-node-red-manager">docker version</a>, but I had to swap out <a href="https://npmjs.com/package/dockerode">dockerode</a> for <a href="https://www.npmjs.com/package/kubernetes-client">kubernetes-client</a>.</p>



<p>This library exposes the full kubernetes API allowing the creation/modification/destructions of all entities.</p>



<p>Standing up a new instance is a little more complicated as it’s now a multi step process.</p>



<ol><li>Create a Pod with the custom-node-red container</li><li>Create a Service based on that pod</li><li>Expose that service via the Ingress addon</li></ol>



<figure><img data-attachment-id="4197" data-permalink="https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/screenshot-from-2020-12-23-20-31-29/" data-orig-file="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?fit=1552%2C382&amp;ssl=1" data-orig-size="1552,382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-from-2020-12-23-20-31-29" data-image-description="" data-medium-file="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?fit=300%2C74&amp;ssl=1" data-large-file="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?fit=660%2C162&amp;ssl=1" loading="lazy" width="660" height="162" src="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=660%2C162&amp;ssl=1" alt="" srcset="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=1024%2C252&amp;ssl=1 1024w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=300%2C74&amp;ssl=1 300w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=768%2C189&amp;ssl=1 768w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=1536%2C378&amp;ssl=1 1536w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?w=1552&amp;ssl=1 1552w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?w=1320&amp;ssl=1 1320w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=1024%2C252&amp;ssl=1 1024w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=300%2C74&amp;ssl=1 300w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=768%2C189&amp;ssl=1 768w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=1536%2C378&amp;ssl=1 1536w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?w=1552&amp;ssl=1 1552w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?w=1320&amp;ssl=1 1320w" data-lazy-src="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=660%2C162&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>I also removed the Start/Stop buttons since stopping pods is not really a thing in Kubernetes.</p>



<p>All the code for this version of the app is on github <a href="https://github.com/hardillb/multi-tenant-node-red-k8s-manager">here</a>.</p>



<h2>Catalogue</h2>



<p>In the Docker-Compose version the custom node `catalogue.json` file is hosted by the management application and had to be manually updated each time a new or updated node was push to the repository. For this version I’ve stood up a separate container.</p>



<p>This container runs a small web app that has 2 endpoints.</p>



<ul><li><code>/catalogue.json</code> – which returns the current version of the catalogue</li><li><code>/update</code> – which is triggered by the the notify function of the Verdaccio private npm registry</li></ul>



<p>The registry has this snippet added to the end of the <code>config.yml</code></p>


<pre title="">notify:
  method: POST
  headers: [{'Content-Type': 'application/json'}]
  endpoint: http://catalogue/update
  content: '{"name": "{{name}}", "versions": "{{versions}}", "dist-tags": "{{dist-tags}}"}'
</pre>


<p>The code for this container can be found <a href="https://github.com/hardillb/node-red-private-catalogue-builder">here</a>. </p>



<h2>Deploying</h2>



<p>First clone the project from github</p>


<pre title="">$ github clone https://github.com/hardillb/multi-tenant-node-red-k8s.git
</pre>


<p>Then run the <code>setup.sh</code> script, passing in the base domain for instances and the host:port combination for the local container registry.</p>


<pre title="">$ ./setup.sh example.com private.example.com:5000
</pre>


<p>This will update some of the container locations in the deployment and build the secrets needed to access the Kubernetes API (reads the content of <code>~/.kube/config</code>)</p>



<p>With all the configuration files updated the containers need building and pushing to the local container registry.</p>


<pre title="">$ docker build ./manager -t private.example.com:5000/k8s-manager
$ docker push private.example.com:5000/k8s-manager
$ docker build ./catalogue -t private.example.com:5000/catalogue
$ docker push private.example.com:5000/catalogue
$ docker build ./custom-node-red -t private.example.com:5000/custom-node-red
$ docker push private.example.com:5000/custom-node-red
</pre>


<p>Finally trigger the actual deployment with <code>kubectl</code></p>


<pre title="">$ kubectl apply -f ./deployment
</pre>


<p>Once up and running the management app should be available on <code>http://manager.example.com</code>, the private npm registry on <code>http://registry.example.com</code> and an instance called “r1” would be on <code>http://r1.example.com</code>.</p>



<p>A wildcard DNS entry needs to be setup to point all <code>*.example.com</code> hosts to the Kubernetes clusters Ingress IP addresses.</p>



<p>As usual the whole solution can be found on github <a href="https://github.com/hardillb/multi-tenant-node-red-k8s">here</a>.</p>



<h2>What’s Next</h2>



<p>I need to work out how to set up Avahi CNAME entries for each deployment as I had working with both <a href="https://www.hardill.me.uk/wordpress/2020/09/22/nginx-proxy-avahi-helper/" data-type="post" data-id="4040">nginx</a> and <a href="https://www.hardill.me.uk/wordpress/2020/10/05/traefik-avahi-helper/" data-type="post" data-id="4107">traefik</a> so I can run it all nicely on my LAN without having to mess with <code>/etc/hosts</code> or the local DNS. This should be possible by using a <code>watch</code> call one the Kubernetes Ingress endpoint.</p>



<p>I also need to back port the new catalogue handling to the docker-compose version.</p>



<p>And finally I want to have a look at generating a Helm chart for all this to help get rid of needing the <code>setup.sh</code> script to modify the deployment YAML files.</p>



<p>p.s. If anybody is looking for somebody to do this sort of thing for them drop me a <a href="https://www.hardill.me.uk/wordpress/about/curriculum-vitae/" data-type="URL" data-id="https://www.hardill.me.uk/wordpress/about/curriculum-vitae/">line</a>.</p>

	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550132</guid>
            <pubDate>Sun, 27 Dec 2020 10:29:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DDC/CI monitor control on Linux (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550112">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | http://blog.tcharles.fr/ddc-ci-screen-control-on-linux/ | <a href="https://web.archive.org/web/*/http://blog.tcharles.fr/ddc-ci-screen-control-on-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>DDC/CI is a protocol for controlling monitor features like brightness, contrast, color temperature, input source, ... over the display cable (VGA, DVI, HDMI, Display port, ...).</p>
<p>It's a quite old protocol that is well supported across many different devices.</p>
<p>I'm currently using it to:</p>
<ul>
<li>Adjust brightness of my two monitors depending on how the room is lighted</li>
<li>Switch monitor inputs between the VM-dedicated graphics card and the host graphics card, replacing the need of a very expensive KVM switch that can WQHD @144Hz.</li>
</ul>

<h2 id="requiredpackages">Required packages</h2>
<p>You must install <code>ddcutil</code> package. The <a href="http://www.ddcutil.com/">official website</a> contains extensive information for troubleshooting.</p>
<h2 id="kernelmodules">Kernel modules</h2>
<p>Ddcutil connects to your screen over an I2C connection, and requires the <code>i2c-dev</code> kernel module to be loaded.</p>
<p>You can load the module at runtime using <code>sudo modprobe i2c-dev</code>.</p>
<p>To make it persistent across reboots, you need to add the module to <code>/etc/modules-load.d/i2c-dev.conf</code>:</p>
<pre><code>i2c-dev
</code></pre>
<p>Once the module is loaded, you should see some files in <code>/dev/i2c-*</code>.</p>
<h2 id="allowtheusertouseddc">Allow the user to use DDC</h2>
<p>By default the i2c dev files are owned by root, and can't be used by other users. One solution to allow your user to control DDC without using sudo is to add a custom udev rule:</p>
<p><code>/etc/udev/rules.d/45-ddcutil-i2c.rules</code></p>
<pre><code>KERNEL=="i2c-[0-9]*", GROUP="your-user", MODE="0660", PROGRAM="/usr/bin/ddcutil --bus=%n getvcp 0x10"
</code></pre>
<p>This rule automatically detects which i2c devices are DDC-capable, and allows members of the group "your-user" to control the file.</p>
<p>You can reload udev rules without rebooting by executing <code>sudo udevadm trigger</code></p>
<p>If you have multiple users, you can create a new group and add your user to the group:</p>
<pre><code>groupadd ddc
usermod -aG ddc $USER
</code></pre>
<h2 id="identifyyourmonitorinfo">Identify your monitor info</h2>
<h3 id="howtoaddressyourmonitor">How to address your monitor</h3>
<p>There are multiple ways to address your monitor, like display number (<code>--display</code>), model name (<code>--model</code>), serial number (<code>--sn</code>), i2c bus ID (<code>--bus</code>).</p>
<p>The bus ID method is way faster than the others, but may be unreliable if your hardware changes often.</p>
<pre><code>ddcutil detect
# You should see entries like:
# Display 1
#    I2C bus:             /dev/i2c-0
#    EDID synopsis:
#       Mfg id:           DEL
#       Model:            DELL U2419H
#       Serial number:    751L2N4
#       Manufacture year: 2018
#       EDID version:     1.4
#    VCP version:         2.1
</code></pre>
<h3 id="whichfeaturescanbecontrolled">Which features can be controlled</h3>
<ul>
<li>Get feature value: <code>ddcutil --bus=0 getvcp $FEAT_ID</code></li>
<li>Set feature value: <code>ddcutil --bus=0 setvcp $FEAT_ID $VALUE</code></li>
</ul>
<pre><code>ddcutil capabilities --bus=0
# You should see something like:
# MCCS version: 2.1
# Commands:
#    Command: 01 (VCP Request)
#    Command: 02 (VCP Response)
#    Command: 03 (VCP Set)
#    Command: 07 (Timing Request)
#    Command: 0c (Save Settings)
#    Command: e3 (Capabilities Reply)
#    Command: f3 (Capabilities Request)
# VCP Features:
#    Feature: 10 (Luminosity)
#    Feature: 12 (Contrast)
#    Feature: 14 (Select color preset)
#       Values:
#          04: 5000 K
#          05: 6500 K
#          06: 7500 K
#          08: 9300 K
#          09: 10000 K
#          0b: User 1
#          0c: User 2
#    Feature: 16 (Video gain: Red)
#    Feature: 18 (Video gain: Green)
#    Feature: 1A (Video gain: Blue)
#    Feature: 60 (Input Source)
#       Values:
#          0f: DisplayPort-1
#          11: HDMI-1
#    Feature: AA (Screen Orientation)
#       Values:
#          01: 0 degrees
#          02: 90 degrees
#          03: 180 degrees
#          04: 270 degrees
</code></pre>
<h2 id="scriptexamples">Script examples</h2>
<h3 id="changebrightness">Change brightness</h3>
<p><code>ddc-setbrightness</code></p>
<pre><code>#!/bin/bash
# Usage: ddc-setbrightness 50
ddcutil --bus=0 setvcp 10 $1 &amp;
ddcutil --bus=1 setvcp 10 $1 &amp;
wait
</code></pre>
<h3 id="switchinputsources">Switch input sources</h3>
<p>Very useful when you need to change input sources very often, and don't have a dedicated button on the monitor (or for automating it).</p>
<p><code>ddc-switch-inputs</code></p>
<pre><code>#!/bin/bash
# Usage: ddc-switch-inputs 1
case $1 in
   1 )
      # Config 1: Main PC
      OUT=("0x0f" "0x20")
      ;;
   2 )
      # Config 2: Virtual machine
      OUT=("0x11" "0x21")
      ;;
   * )
      echo "Unknown input '$1'"
      exit 1
      ;;
esac

ddcutil --bus=0 setvcp 60 ${OUT[0]} &amp;
ddcutil --bus=1 setvcp 60 ${OUT[1]} &amp;
wait
</code></pre>
<h3 id="reduceeyestrain">Reduce eyestrain</h3>
<p><code>ddc-daylight</code></p>
<pre><code>#!/bin/bash
# Usage: ddc-daylight night
case $1 in
   "day" )
      BRIGHTNESS=100
      TEMPERATURE=0x09
      ;;
   "evening" | "morning" )
      BRIGHTNESS=60
      TEMPERATURE=0x06
      ;;
   "night" )
      BRIGHTNESS=30
      TEMPERATURE=0x04
      ;;
   "dark" )
      BRIGHTNESS=0
      TEMPERATURE=0x04
      ;;
   * )
      echo "Unknown time of day '$1'"
      exit 1
      ;;
esac

ddcutil --bus=0 setvcp 10 $BRIGHTNESS &amp;
ddcutil --bus=1 setvcp 10 $BRIGHTNESS &amp;
ddcutil --bus=0 setvcp 14 $TEMPERATURE &amp;
ddcutil --bus=1 setvcp 14 $TEMPERATURE &amp;
wait
</code></pre>
<!--kg-card-end: markdown-->
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>http://blog.tcharles.fr/ddc-ci-screen-control-on-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550112</guid>
            <pubDate>Sun, 27 Dec 2020 10:24:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SciHub commits in court to not upload content from Indian publishers till Jan 6 [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25550058">thread link</a>) | @ghoul2
<br/>
December 27, 2020 | https://www.livelaw.in/pdf_upload/pdf_upload-386427.pdf | <a href="https://web.archive.org/web/*/https://www.livelaw.in/pdf_upload/pdf_upload-386427.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">%PDF-1.5
%âãÏÓ
1 0 obj
&lt;&gt;/Metadata 2 0 R/Pages 3 0 R/StructTreeRoot 5 0 R/Type/Catalog&gt;&gt;
endobj
2 0 obj
&lt;&gt;stream
<!--?xpacket begin="ï»¿" id="W5M0MpCehiHzreSzNTczkc9d"?-->
<x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk="Adobe XMP Core 4.2.1-c041 52.342996, 2008/05/07-20:48:00        ">
   <rdf:rdf xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
      <rdf:description rdf:about="" xmlns:xmp="http://ns.adobe.com/xap/1.0/">
         <xmp:modifydate>2020-12-25T23:22:29+05:30</xmp:modifydate>
         <xmp:createdate>2020-12-25T23:22:29+05:30</xmp:createdate>
         <xmp:metadatadate>2020-12-25T23:22:29+05:30</xmp:metadatadate>
         <xmp:creatortool>MicrosoftÂ® Office Word 2007</xmp:creatortool>
      </rdf:description>
      <rdf:description rdf:about="" xmlns:dc="http://purl.org/dc/elements/1.1/">
         <dc:format>application/pdf</dc:format>
         <dc:creator>
            <rdf:seq>
               <rdf:li>Karan Kumar Khetani</rdf:li>
            </rdf:seq>
         </dc:creator>
      </rdf:description>
      <rdf:description rdf:about="" xmlns:xmpmm="http://ns.adobe.com/xap/1.0/mm/">
         <xmpmm:documentid>uuid:86eaae55-b4e4-4de8-9801-b91cb4241d18</xmpmm:documentid>
         <xmpmm:instanceid>uuid:f88cdb5c-ad54-4b6e-8ba9-f354f505aa8a</xmpmm:instanceid>
      </rdf:description>
      <rdf:description rdf:about="" xmlns:pdf="http://ns.adobe.com/pdf/1.3/">
         <pdf:producer>MicrosoftÂ® Office Word 2007</pdf:producer>
      </rdf:description>
   </rdf:rdf>
</x:xmpmeta>
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                           
<!--?xpacket end="w"?-->
endstream
endobj
3 0 obj
&lt;&gt;
endobj
5 0 obj
&lt;&gt;
endobj
9 0 obj
&lt;&gt;
endobj
10 0 obj
&lt;&gt;
endobj
84 0 obj
&lt;&gt;82 0 R]/P 58 0 R/Pg 8 0 R/S/Link&gt;&gt;
endobj
58 0 obj
&lt;&gt;
endobj
8 0 obj
&lt;&gt;/MediaBox[0 0 595.44 841.68]/Parent 3 0 R/Resources&lt;&gt;/ProcSet[/PDF/Text/ImageB/ImageC/ImageI]&gt;&gt;/StructParents 2/Tabs/S/Type/Page&gt;&gt;
endobj
86 0 obj
&lt;&gt;stream
xœ�ZYoÛH~7àÿÀGraµÙÉLg“ìxv11öÅ³´DÙÚ8²—’�É¿ßª¾È¦ÔTcDàQ]]w}Õtvù¯ì§Ÿ.o®&gt;½ÏÊË_ÛíC–wÛÅ§ßŠŸÎÞ½¿ÊÞÝžŸ]~&nbsp;¤ÙíúüŒf%üƒ'¬"%ËjVo¾�Ÿ•Ùþüýüì.¯ŠÏ	-þ“Ý~&gt;?».ÈÉ¯œH1^{—g1ÚŠMö¹Ëoz’ZUùçBäí~¶¸!&gt;”*ßáuû£&nbsp;Ì\jÚ&amp;ßÙ£~UàÍ@ÿ/:K„×í~ìý=¾ë¶EÈ¼ë�Å›¾Z
´ßÊó
&gt;õ[Å´ŒQ‡ZµšMivøŽrx6leU+Âª�ÕsŒ¶©Ÿ-JB©Ìn—wù:º…ªHÝËJ½•F— à+Ü|+P±ÆÀÆ�Çšª€wÃœ	žpÕ³ö§Èœ�„6ºydX|&lt;1&gt;z�GOÎËÚÛBxwË¼ÅÛÕ1èÓný®î»‹u0Ï�ÇÕàR)C5P�W'Ç*¶üÆU¸0f+ÞpðRHÛ£ÎÿÃ^µq(7ÈZé@ªL=:õã˜‡ÐZ.‹Ú¼A—}+¨½Ó–i5åF¯5®8åÄš‘ÚÊÓõÈGm0¿xN3ö&nbsp;ª$,dåû!²†•
a2X“”QJ*�îM°i£PjnM-hw»®ßÒÚÀ‘)&amp;`+•·+T²Ë6[4õtùf»ÛCœUÖâí-1±)ÖÇXºI�QDµÊ®o®²lT¹i¬rO½$"*ËÑTh6_¡ƒ'*t@ûÑÙ
·{ÓÆê/¢¾a”(rxpæzsù½�+¨L6„Ö!‹!µ1èKŒ{W‚BP6Ã‹¯“õÛ{¼þ�Þ&gt;¸‰æ*%µ
%1ýª¬ò/:OïÝNº@\Øw7žêóP¿D Ä±ÎVMžƒ{Tà{BÞ2�ýÀß~ï
Éò	Ý¶C·KV+[Dð¦it&gt;¿E°È¹E¾¯N²&amp;â±Š’F…"\Di%áuH�H¦1íØŽ¬©uT&gt;:I—�#=GY&lt;èjúÉÆÖB«"ü¬Aáµs®6ðâm´|‰Ùþâc§ß˜rf7ÙGt�%'M•fYÖH”d	8nbòïÎ}ONQk#�|fp‡¡R—mÃìÕUû'-B„ne-,‡8¢ÂtWIM[z3xÎŠÓÞ;™º˜³!Ù
…ˆQ#H¥BÚh5�½¾ã
IýL"ÃUºÂtëÚ­mÂ`�’l}ŠuÞ0Rñ4Ñ9`&lt;6¡�q®8á5/Q�_PMcù?�ÀZ“^£T™_['ûRöÕ[ˆcÑÇãÝ}–\CÉƒæpùA;$U:ÚG&lt;}ÛIŽôˆãŒoŒugÿlÔËº"Ô—1ÈÔ0rë:ˆ~H
•
tóŠn[KD~cR_i‡ÄÝC�Ù†‡èC»nïñ�ƒv¨Ý3`ýÆÒ¶=,A­¹8ä%‚Ý˜ÄÈ„%")¡ð™ðyd¬8�LÚÛìB3FÑåh4¼&nbsp;‘tO†nûyÔðÕL¶ó6o£æb¸q°ÿWÜjkê!8Å¶IäÔ#Jì–zç¬f!"å˜äQ+x‚§z‚Õ¤¦6±HYéÜªcbP^Ù„‹ôŠSÜå¿º4À3¨½§æÞû÷]Ÿ=ƒóŒÝJ¸21ƒ«J¼¢þ–áU	œü§ó±M	Â�h³&amp;©&amp;…f.ÕÄ¤Í)“Ž%™tXp—Ú:H#dƒ™´}·k5�AB ÕÆ¡&amp;5Ý
šž¬Ü¼0'–Bû’Ú41Ú¾*Nª:¤¥v3ÉýAÀ“ÃV°óf5�ä
W¤™p?]ôE%LüäÊï½¯úûñˆ€ÂÚÓ¹öÈÆ¹¢=
°ð|GÔ#´Öû#¦ýtP�!×e‘°ùrXÖÙ0Å*€2Ü=&gt;|)ByHÛw/…�(o7%?�ä£0[ÛÕƒIsÊdÕ3HRÏBN¥TÒö�[Òú¹Æ�Þ¸¢dãê;zÐ[~Û¡SN’ë±Q�‡%H_±QE¦Hù‹h)PÆcÞQ9TMÄ„öC¡Œ¹úñ!WÄ…¼Áã‘`ýp*ÔGñwU¦Âe8Ï6ÊŽ³p1í�ÅBÑi›ç
¦âÝh¦…ç+—n;çUT¸›”s9Ñ+†Ç&nbsp;¥Òì-¸Ä2ÐnÆÑ2¡Ýð!2£Âª’ˆI0µ
¸¼x0Ö‰@lPwŽÑa^3¡]ÛC#æêô	‚À®éÚepFâçamKúqí*îŒ%0œ9¹G«O)H]‡´zânûñ�ÄòÕbå¶6Jck+¯mwÑY
i¶ö/ÚìêRG\Šè¼®‰’!mtVk$ÎJ­�ÕŒ^÷"&lt;ÙÒÓkÊcãš85­•5`%éaÎRíuÒ‘™’ÐŒ'ÊÏ))!*š4‘\|ÂH®Ô8*}�îÂ.aªP‹ègå
Øí\…‰ù/+n4‹e"nÄ¡¿‘Ü¨NàÆ`Q
n-¸ËïNwO“9Ü�	¸Û¾û¯M_éu6õúxÓ˜Ù¥²h7èªP?ˆ¢_™ëµû¦óä�Ï @»÷—:Ú]á§	ó¡gaà£dÔºxrœê6Ä­lï;b\6¤æ!˜4"C$ù“€?ÃáÆ£isô8³Î»¶�ðÆÃ¸¦§Óý|’•�Ž?iÞ©*"x(ýlÜV©qËI™PÇ?9³#'6¬¤ˆ‡8-mžh
�Š'Òšã$Z^6é´B`uO£mÊdZA«ÚßÁÝØ4Øú„?ÿÆPùòñhfÿx×¯"äÒÍ–Ø¨&gt;l£‚)�g£†#Ês}…?7ðóî:Š*¬MÁRÔ c:ôµ"EøñB2`4«•úKÁêO££ü¿¼´Ûá«ÝÌ\;ù¤€Ó8nv:@¨¢©¤Œi&nbsp;•F£y2­RÉ´°4—!í•Ÿ¯—_3¨§LÑ~(¬£AR^55ÖWóÀ~öfÑÆ!çnŒ�^
4�û¶zòãª¤PšPz™¸åÚbŠÊõ»a+ýç2NuˆOt¦[rIjVÔë»ó³õßŽæçh7ÍçÔâèA,Æ³"ª:Î\wÖ!&nbsp;Í—?ò«â'Æüæ±æ*õÛ3~'è#‰iYãÃŸK†TØ&nbsp;ôm4;™&gt;&gt;¶‹×u�Âi´€ÄSií§›4Znªi¡$¤Ò
LúTZ	:‘´©¦¤/ú/aæÎ¼,ü–ÅÎäñÃN¢í$•¡õŒÒ¬Í_ð°ƒMD¨„Q½©â[f@ô\Wtv4þé|9qO=ÆYU¤±Lðïfø§°LEp´Öï•Â2
á¦,¡`©4–©ˆ‚
(i,£í|ÊËqKíÞS–0ÆÝó›Cm 
endstream
endobj
87 0 obj
&lt;&gt;
endobj
88 0 obj
&lt;&gt;
endobj
89 0 obj
&lt;&gt;
endobj
94 0 obj
&lt;&gt;
endobj
95 0 obj
[250 0 0 0 0 0 778 0 333 333 0 0 250 0 250 278 500 500 500 500 500 500 0 500 500 0 0 0 0 0 0 0 0 0 0 667 0 611 0 0 0 0 0 0 0 833 0 722 611 0 0 500 0 0 0 0 611 0 0 0 0 0 0 0 0 500 0 444 500 444 278 500 500 278 0 444 278 722 500 500 500 500 389 389 278 500 444 0 0 444]
endobj
92 0 obj
&lt;&gt;
endobj
93 0 obj
[250 0 0 0 0 1000 833 278 333 333 0 0 250 333 250 278 500 500 500 500 500 500 500 500 500 500 333 0 0 0 0 0 0 722 667 722 722 667 611 778 778 389 500 778 667 944 722 778 611 0 722 556 667 722 722 1000 722 0 0 333 0 333 0 0 0 500 0 444 556 444 333 500 556 278 0 0 0 0 556 500 0 0 444 389 333 556 500]
endobj
90 0 obj
&lt;&gt;
endobj
91 0 obj
[250 0 408 0 500 833 778 180 333 333 500 564 250 333 250 278 500 500 500 500 500 500 500 500 500 500 278 0 0 0 0 0 0 722 667 667 722 611 556 722 722 333 389 722 611 889 722 722 556 0 667 556 611 722 722 944 722 722 0 333 0 333 0 0 333 444 500 444 500 444 333 500 500 278 278 500 278 778 500 500 500 500 333 389 278 500 500 722 500 500 0 0 0 0 541]
endobj
85 0 obj
&lt;&gt;/BS&lt;&gt;/F 4/Rect[153.02 246.36 521.01 274.87]/StructParent 3/Subtype/Link&gt;&gt;
endobj
83 0 obj
&lt;&gt;
endobj
82 0 obj
&lt;&gt;
endobj
48 0 obj
&lt;&gt;
endobj
49 0 obj
&lt;&gt;
endobj
50 0 obj
&lt;&gt;
endobj
51 0 obj
&lt;&gt;
endobj
52 0 obj
&lt;&gt;
endobj
53 0 obj
&lt;&gt;
endobj
54 0 obj
&lt;&gt;
endobj
55 0 obj
&lt;&gt;
endobj
56 0 obj
&lt;&gt;
endobj
57 0 obj
&lt;&gt;
endobj
59 0 obj
&lt;&gt;
endobj
60 0 obj
&lt;&gt;
endobj
61 0 obj
&lt;&gt;
endobj
62 0 obj
&lt;&gt;
endobj
63 0 obj
&lt;&gt;
endobj
64 0 obj
&lt;&gt;
endobj
65 0 obj
&lt;&gt;
endobj
66 0 obj
&lt;&gt;
endobj
67 0 obj
&lt;&gt;
endobj
37 0 obj
&lt;&gt;
endobj
38 0 obj
&lt;&gt;
endobj
39 0 obj
&lt;&gt;
endobj
40 0 obj
&lt;&gt;
endobj
41 0 obj
&lt;&gt;
endobj
42 0 obj
&lt;&gt;
endobj
43 0 obj
&lt;&gt;
endobj
44 0 obj
&lt;&gt;
endobj
45 0 obj
&lt;&gt;
endobj
46 0 obj
&lt;&gt;
endobj
47 0 obj
&lt;&gt;
endobj
7 0 obj
&lt;&gt;/MediaBox[0 0 595.44 841.68]/Parent 3 0 R/Resources&lt;&gt;/ProcSet[/PDF/Text/ImageB/ImageC/ImageI]&gt;&gt;/StructParents 1/Tabs/S/Type/Page&gt;&gt;
endobj
96 0 obj
&lt;&gt;stream
xœ�Z[oÛ¸~�ÿ&nbsp;§é&nbsp;fÄ›.Àb�nv÷ =›nÑæ-ÝÕ‘Ó´®](NÛóïÏÉ¡H9”…¢ˆkIÃáp®ßŒœ]¼É~ùåâúòê÷¬¼ø«ÛÝgy¿[]½.~ý5ûí÷Ëì·›ó³‹?EÆ+Uv³9?ãY	ÿxÆEÅJ‘Õ¢duvóåü¬Ìîñã?çg·ùU±’9{YT9{
{sÉá›ÀoU¡òþ$^\Às·4_üÿOvóêüì�Ç“vâ5k@^²²Ê8“"úó³Í¿ÏÏPJ’KH&nbsp;n§rÝæYÀ6ûãú2Ë‚³óôÙyúìU[¡D¸If„ºYßæ’…‚qL7ñ"³"K-¨Äd—Ûüôµõ_ñKV¬j5½ìŠ&amp;ßÅ—_ñò+�miùº;våþòÍ‘õ°ðÎ=¨tþ¿þ¯àDxÀk#NŸ:„¬J¦d|/Êõ€_v2Söbw7�	~
Ìßê˜_joÅ5Ó&lt;¦}2GUöTý€çÐù»¾hóõ¨
#‘?5‡{/ñ‹=¸!Ù¤öÕªdRÅûÈp¨Ò¤Å�_ÕÂùîm~¹/´¶¢ô{¯oóKeþFFÝ:¹ñá›žòµ7ä~pÕ¿H!jÍ”Ž„HÉ+ðÐ˜uÔR87V˜„gðŠÕ2Z|{ù$¾ü&gt;’«tÃÚ6Zeü¾ï?rt¦û@
xö†æKÁkÒWdlÁ¹Y½÷$îæžønÃ@æ›ž©üËŒÈdUÕ0U9™7FÒ­ó8³?‰¬œ‰‡sE‡J0o¦»ˆyGN&nbsp;—	”�b¸eœappñö0�v¤ƒË=e
Oð8xOtÄý€^µ?�áŠYfýdµvèwøõ$.`ó.ŸBí»#l
™³Œ½í5¼Ü§TgÚÀæ
#†«Õ�M{÷Î0ÈJ}2G+Æ›˜E:Ÿ×¬ªbÚ5*å+IÜ?â‰²‚<n“ fÎ'x¡«Ú˜ë�·­Ónb)Ôl–vÆ*;²ö›3t>XÙRÅMŠ†‰:­‡£Š+Rwjœ²d‚’¨t8"¡_%™VñŠSµ5¤õµÕdÚ¦qeÓÙgKA°ÆÛAþK§¨[Kòh…hjç¼n½1êw4ô*óÚÑ=Çw÷	IL=rO�ëã.‡@ÔDíÒÔÝð€cÝ¥ðˆ“@ºèÖ’µÍ2Íª†YÁ
u”Ÿõ“·¦~†,LÞ£Öl\åDxëºbü™p‹òÙâlQ´•œñ:âyGçš�5Fèh!…ì¥=fÙ÷‚kËÕ›úaô4p›¹’u‹ï 9žªàŠê¦àe&amp;É|w`¢ƒ&amp;’Ñ¬´Éj¡°³Á,³Öœ52
f1ÌÑŠÁÑ^í¬"«a"Ú«ª¼sY±]HøÌ×Bë­©¼	øNÆû…&nbsp;C×ci¬\÷3ÆŽÆ›Òg+MVj¸^÷CQçÓJMéÃÑX—¦
Mg›È0=ç)ëö“÷^ªÉ&gt;‡ÍG–¨YMâŸo"<zØÑ6ý°ˆær‰ylÀ€f£­&ýƒÓåØ?llx§ÐmÍÚ:æ7oµŒi¿Ó.Û�l×*�iÝÛ¦"rym}±+v�ÓtÐh­×Ð¯mÀÃŽÌê{;>þî·ÚYºD^•’‰*&gt;OÐÂ™”pÊä%„eë[Þ
¾éa»!‰� �1—„çÛ^U!L
9ôC1¢ÕCáœ=»£aCöèïa¶×ÃGL‚c¿
V=vE†sä@]‚Ž%’l6/ªŸ©¨ºe‚òÊ%úî½ùïïkøÀ¿÷Åk
_¦kg~fˆ‚gû&lt;Ê®ØK¸ñü&amp;ÕcÕ¬¬c9*jç.Âææ5
ª‡Ôp‚Ìä¼F•‚µ&lt;ÜlÉÀFÿÔÀFiM›Œub`-Z2°	Üæ×ƒmÚü¥O²aÓòü�¹ñ!ª/ì"‹q:¬»ØçÍÊGº·á(:²}ê3ð¥HLAýÈ¿Ç~d‹è"ê^tL¢(K9.[êúÂâÏ|õ)ÒÞ]!d9‘‚”Féë��²ŸÍ©\�øÑçÔÎ&nbsp;Ãotþ¶ûäzÓ{’êë¨q[�x#ó—”Y¿ù
éñ~oˆ µ‡&nbsp;Ÿ×•µªàcdÄ�yb¼ˆÊÞðÝE—,eÎ`œªˆÉÔTkñtc÷Â:ÑNWXRkYá`…*ìJþt‰…m1�GSÃ&amp;Þ”Œ«˜6)h£pžÑZ›£FŒjøßø›*0˜SÜ[­)¯0X&nbsp;l[´�e-³¡ƒHª&gt;Ž},&nbsp;[ÃíÈì“kmyÁ(è¶Tx\v¾ê˜‘¬ojˆ&amp;Õ!AC6Q[ð@Ë×G�7ÁR¼lêÝ:ˆ4ÔhG{¬d™ÍÆ�OHxWh—‡‚dÄ¢áo˜Ø�Ó�‚Ôñè|&gt;PVëÖp~Íñl&lt;]à&nbsp;9ŽNt™`ƒ7×1­Ëª!fp2D™åF!×{×Üû rOmbpIJhsúM�0ùŽìÖ¤�bÙÒà¯Å&gt;¢õ³Nf'óö×
¢ó¦j&amp;&nbsp;½˜ô7x‰Qg�{]×è¤ã\U1“¡ÃÉ‡ªò?&lt;#œt¦Ý5!Ý¥&amp;¤ê´ì»ôDL0.cZo„»9—M‹ý}´ÒŽí7½©ÞêÈ¤ÖK„¬;$=¶Öˆ’"ö©ÖMA=1‚«À&gt;8Ù¶pPÄD-°ô&gt;Qä0ÀÙ‰ê_qãGKÔ©ª3vD;Ž†7C˜îS~[ÖS�šwÁ/ÂnË¬áôdHBô(Ê~*DÒ:¼©X­b~³ðµZ80‘¼d’Þs(‡Þg&amp;ÑŠ@5¢Eà³ž4ŸSEsE‰Ù_[|pä]Ñ’;)÷â…}r %öv‰/±›!Úà™Ý:ÿRÎ¿à:xY[‰yrõ\ŠÇ´Ü¢(ïy¦dÚû¾‡âø…Ÿ�ˆÆŒõ¦®=ŽðMqË6ûÜÔ�áöC¨'�ãå�ô1uHéxÃY«ú˜ËyqS¤O4EÑ¢%MQ°à6¿z$(ðäáCYŽ7V]�ãB»m¿\ji®6+ÛóÄ�V{”É±çØÐ1ñ	¡`ÛN€;&lt;_ûNÉãbïfQ£Ö|ñ/ßPëŽ¦ß)é}…Ö’Ühÿ°?å¨Ò¼ë	½¼çî]rŠ£
z¸ÜàÒ?WØèëâOõLk. 	Ëˆó7*Ýó|žkñ´…ZÆ|¢—/8u³·n7NÉ¨·^ñ“9ÒÑËŠ”j¤6¿Hˆ6^%i5«&amp;B¢³wã›Ëäð©‘GÛÌÆ³4þ¡—¨ëIüW§â?\´(þÇ4Ñšç¯Çqªo|Æ™€Ö"uÆî&amp;v½î¿Ï·jÃ7bjBY«¸a×JMöm€Ã‘Õ~r}GäGØ|ì‘.ÀÓ³mW¤Œ�ËXVôlvG¤3°Ût_öA§Ý¡&gt;ûÛíÆ—	ÔhÆ²®Á}ÓUKòš‰‰dÿÅqä[VhÇú]çË±ïðºn¿§™ß	3NÿH1­cÚÜ§¨MN&gt;„õE¹Ö»¨¹õ5A7±ÕÉ¹ÏièÉ+Í¢nrcf×Ô,¬žu²�áff«¬‘ßö´ñC…</zøñ6ý°ˆær‰ylà€f£­&ýƒóåø?llx§ðmíú:æ7oµœi¿ó.û�l×*�iýû¦"rym}±+v�ótðh­×ð¯màãžìê{;></n“ fî'x¡«ú˜ë�·­ónb)ôl–væ*;²ö›3t></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.livelaw.in/pdf_upload/pdf_upload-386427.pdf">https://www.livelaw.in/pdf_upload/pdf_upload-386427.pdf</a></em></p>]]>
            </description>
            <link>https://www.livelaw.in/pdf_upload/pdf_upload-386427.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550058</guid>
            <pubDate>Sun, 27 Dec 2020 10:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should we say stop to the syntactical growth of Python?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550052">thread link</a>) | @treesciencebot
<br/>
December 27, 2020 | https://tree.science/syntactical-growth-of-python.html | <a href="https://web.archive.org/web/*/https://tree.science/syntactical-growth-of-python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <p>The language has been literally 'evolving' since the version
that many of us have begun (maybe since the initial day, if you
are Guido). I'm not talking about any features in specific,
but rather the whole language. If you compare a code fragment
that you wrote 5 years ago, with the 'refactored' version that
you would write if it were today the difference is obvious. </p>
<p>We've seen a lot of new syntax popping into our lives, in just the
last 5 years (starting from 3.5):</p>
<ul>
<li><a href="https://www.python.org/dev/peps/pep-0448/">PEP 448</a></li>
</ul>
<div><pre><span></span><code><span>&gt;&gt;&gt;</span> <span>*</span><span>range</span><span>(</span><span>4</span><span>),</span> <span>4</span>
<span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>[</span><span>*</span><span>range</span><span>(</span><span>4</span><span>),</span> <span>4</span><span>]</span>
<span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>]</span>
<span>&gt;&gt;&gt;</span> <span>{</span><span>*</span><span>range</span><span>(</span><span>4</span><span>),</span> <span>4</span><span>}</span>
<span>{</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>}</span>
<span>&gt;&gt;&gt;</span> <span>{</span><span>'x'</span><span>:</span> <span>1</span><span>,</span> <span>**</span><span>{</span><span>'y'</span><span>:</span> <span>2</span><span>}}</span>
<span>{</span><span>'x'</span><span>:</span> <span>1</span><span>,</span> <span>'y'</span><span>:</span> <span>2</span><span>}</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0465/">PEP 465</a>, a.k.a matrix operator</li>
</ul>
<div><pre><span></span><code><span>S</span> <span>=</span> <span>(</span><span>H</span> <span>@</span> <span>beta</span> <span>-</span> <span>r</span><span>)</span><span>.</span><span>T</span> <span>@</span> <span>inv</span><span>(</span><span>H</span> <span>@</span> <span>V</span> <span>@</span> <span>H</span><span>.</span><span>T</span><span>)</span> <span>@</span> <span>(</span><span>H</span> <span>@</span> <span>beta</span> <span>-</span> <span>r</span><span>)</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0492/">PEP 492</a>, a.k.a native async syntax</li>
</ul>
<div><pre><span></span><code><span>async</span> <span>def</span> <span>commit</span><span>(</span><span>session</span><span>,</span> <span>data</span><span>):</span>
<span>...</span>

<span>async</span> <span>with</span> <span>session</span><span>.</span><span>transaction</span><span>():</span>
    <span>...</span>
    <span>await</span> <span>session</span><span>.</span><span>update</span><span>(</span><span>data</span><span>)</span>
    <span>...</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0498/">PEP 498</a>, a.k.a f-strings</li>
</ul>
<div><pre><span></span><code><span>&gt;&gt;&gt;</span> <span>f</span><span>'The value is </span><span>{</span><span>value</span><span>}</span><span>.'</span>
<span>'The value is 80.'</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0526/">PEP 526</a></li>
</ul>
<div><pre><span></span><code><span>primes</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>[]</span>

<span>captain</span><span>:</span> <span>str</span>  <span># Note: no initial value!</span>

<span>class</span> <span>Starship</span><span>:</span>
    <span>stats</span><span>:</span> <span>ClassVar</span><span>[</span><span>Dict</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]]</span> <span>=</span> <span>{}</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0570/">PEP 570</a></li>
</ul>
<div><pre><span></span><code><span>def add(x, y, /):</span>
<span>    return x + y</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0572/">PEP 572</a>, a.k.a walrus</li>
</ul>
<div><pre><span></span><code><span># Handle a matched regex</span>
<span>if</span> <span>(</span><span>match</span> <span>:=</span> <span>pattern</span><span>.</span><span>search</span><span>(</span><span>data</span><span>))</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
    <span># Do something with match</span>

<span># A loop that can't be trivially rewritten using 2-arg iter()</span>
<span>while</span> <span>chunk</span> <span>:=</span> <span>file</span><span>.</span><span>read</span><span>(</span><span>8192</span><span>):</span>
    <span>process</span><span>(</span><span>chunk</span><span>)</span>

<span># Reuse a value that's expensive to compute</span>
<span>[</span><span>y</span> <span>:=</span> <span>f</span><span>(</span><span>x</span><span>),</span> <span>y</span><span>**</span><span>2</span><span>,</span> <span>y</span><span>**</span><span>3</span><span>]</span>
</code></pre></div>

<p>This huge list contains some of the (major~) changes that have been implemented since 3.5, there
are also quite a few minor ones (like <code>_</code> separator for numbers, <code>1_000_00</code> or <a href="https://www.python.org/dev/peps/pep-0530/">PEP 530</a>
for async comprehensions or even a new one for 3.9 to extend the decorator syntax, <a href="https://www.python.org/dev/peps/pep-0614/">PEP 614</a>.)</p>
<p>Well, since we all refreshed our memories, let's try to imagine a world where these features don't exist. Imagine
not having access to f-strings, writing weird stuff to deal with your coroutines, or repeating yourself 2 times whenever
you want to read chunks from a file, writing utility functions to merge 2 mappings and more awful cases. Except for maybe
PEP 465 (I never needed it, probably because I don't do scientific programming. But from what I saw by looking at the examples
in the PEP, it is quite good for people who work with data on a daily basis.) every feature in that list literally changed and
actively affected how I write my Python code, right now.</p>
<p>Seems like syntactical additions sounds great, why don't we add everything to the language? Let's start with
adding regex literals, and then move forward to call pipeline operator, blah blah blah. If you are subscribed
to the Python-ideas, then get ready to see tons of different, redundant new syntax proposals (even I, probably
proposed a couple of very obscure and stupid ideas in the past). Though this brings me back to the point of,
whether we should stop the syntactical growth at all or not. </p>
<p>In the last 6 month, 3 different major syntax changes were proposed. I guess everyone is somewhat familiar
with the pattern matching PEPs, PEP 622 (PEP 634, PEP 635, PEP 636). Also, there is PEP 637 for allowing keyword arguments
on the subscript syntax <code>[x=y, z=q]</code> and PEP 638, for syntactic macros. I am not going to criticize any of these PEPs, but
I'd like to ask you to think about them. Think of how they could affect you in 5 years. Think about whether your
coding styles would change because of them, think about how good fit they are to the language, and most importantly think about
whether you 'ACTUALLY' need them. Is there any 'ESSENTIAL' case that would be much better when you pass keyword arguments through
slices instead of just making a call to some sort of <code>get()</code> function? Or can't we have syntactical customization without having an
official definition of it? Does the syntax for 'patterns' (described by PEP 634) is a good fit for the Python language?</p>
<p>There are a lot of blog posts, <a href="https://discuss.python.org/t/gauging-sentiment-on-pattern-matching/5770">poll</a>s and maybe
hundreds of emails out there related to these proposals. I won't expect anyone to read them all, but if you want to get a 
general idea just check some of them out.</p>
<p>Have to say that, I'm extremely overwhelmed by seeing this amount of change proposals every day, in various
places. No one is forcing me to read them, though it is just a burden that I am intentionally or unintentionally taking to see what are people looking for in the language that I (myself) probably will be stuck
with for the next decade. Trying to comprehend what people are aiming with making language so complex with
growing the syntax more and more every day.</p>
<p>Don't forget that adding syntax is much more serious than adding a functionality to the runtime. That syntax
will be the face of the language, and you won't be able to alter it even a little bit. We all saw what happened
when the syntax was changed in a backwards-incompatible manner, and no one wants to go through that again. This
is why I am just asking you to think about whether do you believe these would be good fits for the language, whether
they will worth to their imponderable cost. </p>
<p>This is just me, throwing a bunch of questions into the void. If you want to talk more about these, feel free to
send me an email (batuhan [at] python [dot] org) or reach me through twitter (open DM for all, @isidentical).</p>


             
 
                <hr>
            
        </div></div>]]>
            </description>
            <link>https://tree.science/syntactical-growth-of-python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550052</guid>
            <pubDate>Sun, 27 Dec 2020 10:03:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeing the New Covid Variant Smoke]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549909">thread link</a>) | @imartin2k
<br/>
December 27, 2020 | https://putanumonit.com/2020/12/26/seeing-the-new-covid-variant-smoke/ | <a href="https://web.archive.org/web/*/https://putanumonit.com/2020/12/26/seeing-the-new-covid-variant-smoke/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>There is evidence of a new highly-infectious strain of COVID-19 emerging in the UK and other countries. This post is an elaboration of my current model of it, as promised in my <a rel="noreferrer noopener" href="https://putanumonit.com/2020/12/26/lesswrong-2018-epistemology/" target="_blank">review of LessWrong’s collection on <em>Epistemology</em></a>. Most of the information I have on this new COVID variant comes from <a rel="noreferrer noopener" href="https://www.lesswrong.com/posts/CHtwDXy63BsLkQx4n/covid-12-24-we-re-f-ed-it-s-over" target="_blank">this post by Zvi</a>, the links from it, and comments. Read those if you haven’t yet.</p>



<p>Though I usually strive to have timeless content on my blog, I’m making another COVID exception. Ten months ago I write <em><a rel="noreferrer noopener" href="https://putanumonit.com/2020/02/27/seeing-the-smoke/" target="_blank">Seeing The Smoke</a></em> and dozens of people told me it flipped the switch for them and let them prepare for COVID in time; this post may end up even timelier. I anticipate both my model and the evidence that feeds into it to change rapidly, everything below is a snapshot of what I believe as of Christmas Day 2020. Reminder: I am not an expert on any of this, just the Putanumonit guy putting a num on it.</p>



<hr>



<p>The median prediction on <a rel="noreferrer noopener" href="https://www.lesswrong.com/posts/CHtwDXy63BsLkQx4n/covid-12-24-we-re-f-ed-it-s-over" target="_blank">Zvi’s LW post</a> is around 60% that the new variant is at least 50% more transmissible and same for there being a third COVID wave in the US:</p>



<figure><a href="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png"><img data-attachment-id="30901" data-permalink="https://putanumonit.com/covid-predictions/" data-orig-file="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png" data-orig-size="971,328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="covid-predictions" data-image-description="" data-medium-file="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=300" data-large-file="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=900" src="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=971" alt="" srcset="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png 971w, https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=150 150w, https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=300 300w, https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=768 768w" sizes="(max-width: 971px) 100vw, 971px"></a></figure>



<p>I would add a few things without straying too far from the crowd’s wisdom. </p>



<p>First, I would revise the crowd’s estimate for the first question down for no other reason than that the poll came at the end of a post titled <em>We’re Fucked, It’s Over</em>. If ever there was going to be a framing effect pushing estimates upwards, this would be it. There are also <a rel="noreferrer noopener" href="https://twitter.com/CupOfjoe1986/status/1342386338717458432" target="_blank">more alternative explanations</a> for the information coming out of the UK than Zvi accounted for.</p>



<p>Instead of just saying that that there’s a 60% chance it has a 50% higher transmissibility, I would break it down something like this:</p>



<ul><li>35% that the new strain is a nothingburger.</li><li>30% that it’s <em>slightly </em>more transmissible, say with an effective reproduction rate (r<sub>t</sub>) 20% higher.</li><li>30% that it’s <em>significantly </em>more transmissible, e.g. 70% higher.</li><li>5% in the Captain Malcolm Reynolds probability bucket.</li></ul>



<p>I also believe it very likely that new variant is already present in the US, given that a dozen flights from London have landed in NYC just in the last week. Travel from the UK has been restricted on Christmas eve but the dust from the bolting horse has already settled by the barn door.</p>



<p>A variant that’s just 20% more infectious will still take over exponentially from the old variant resulting in a chart like the one we see.</p>



<figure><a href="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png"><img data-attachment-id="30903" data-permalink="https://putanumonit.com/uk-strain-chart/" data-orig-file="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png" data-orig-size="701,491" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="uk-strain-chart" data-image-description="" data-medium-file="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=300" data-large-file="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=701" src="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=701" alt="" srcset="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png 701w, https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=150 150w, https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=300 300w" sizes="(max-width: 701px) 100vw, 701px"></a></figure>



<p>Several people have tried to explain away the growth of the new variant as being due to things like catching a superspreader, but it doesn’t have to be one or the other. It could have r<sub>t</sub>=1.2 <em>and</em> catch a superspreader event to make it look like r<sub>t</sub>=1.5-1.7. This is why I am giving extra weight to the hypothesis of slightly higher transmissibility.</p>



<p>I also think there’s a <strong>huge </strong>difference between r<sub>tnew</sub>=1.2 and r<sub>tnew</sub>=1.7 (here I mean r<sub>t</sub> relative to the old strain given the same measures of containment) in terms of outcomes. </p>



<p>In the first case, to keep the virus suppressed (i.e. r&lt;1) we need to take measures that would have yielded r<sub>t</sub>=0.8 for the old strain. <a rel="noreferrer noopener" href="https://rt.live/us/NY" target="_blank">New York sustained that number</a> (albeit never dipping below 0.7) for two months running in the spring. Given that ~30% of the state has already been infected, that makes this all the more doable. Gyms and restaurants will close and people will grumble, but we’ll probably survive till the vaccine.</p>



<p>r<sub>tnew</sub>=1.7 is an entirely different case. Suppressing it would require the sort of lockdown that would yield r<sub>t</sub>=0.6 for the old strain, a number that <a rel="noreferrer noopener" href="https://rt.live/" target="_blank"><strong>has never been reached by any US state for any amount of time</strong></a>. I see no way in hell that Americans would agree to a lockdown <em>much stricter than any we’ve had so far,</em> especially after they’ve been promised that the worst is behind them.</p>



<p>Rural red tribers will not agree because Biden is in the White House. Urban blue tribers because containment in cities is much harder anyway. Young people will not agree because the virus harms them less than the lockdown. Dumb people will not agree because they will not understand the science and math and smart people, seeing that, will try to get infected early before the hospitals are overwhelmed.</p>



<p>No one will believe any of the “experts” at the CDC or WHO or Dr. Fauci because they have all repeatedly lied and tried to manipulate people and reversed their positions without admitting that they have. They all have <em>negative </em>credibility at this point with many Americans.</p>



<p>If the new virus is 1.7 times as infectious I believe that Americans will most likely simply give up on containment, the populace if not the government. We’ll have time to vaccinate the most vulnerable 10-20% of the population by April-May, at which point the majority of everyone else will get the new strain. </p>



<p>There is a small chance that the US will get its shit together vaccine-wise and beat the new strain in a race. <a rel="noreferrer noopener" href="https://twitter.com/yashkaf/status/1342569735884517379" target="_blank">Israel, for example</a>, has a simple system in place to vaccinate the vast majority of its 9-million strong population by the end of March. On this timetable, even a virus with r<sub>t</sub>=1.7 will not have time to explode before herd immunity kills it.</p>



<p>The same is not true of the US, which is currently projected to reach majority immunization no earlier than the late summer by refusing to do <a rel="noreferrer noopener" href="https://twitter.com/yashkaf/status/1342546177288527872" target="_blank">basic things to rush the process</a>.</p>



<p>And what’s the Captain Mal bucket?</p>



<figure><div>
<p><span><iframe width="900" height="507" src="https://www.youtube.com/embed/MnQaYGJ5oYs?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
</div></figure>



<p>The new variant being more virulent in addition to being more infectious. Another newer strain that’s even worse. Or, in a nightmare scenario, a highly-transmissible mutation that also renders the Pfizer and Moderna vaccines ineffective. </p>



<p>If COVID has taught us one thing, it’s that it’s all usually worse than we thought.</p>



<p>So the bottom line is that I currently estimate a 30-35% chance of us being truly fucked, in the sense of dozens of millions more Americans getting COVID in 2021 and hundreds of thousands more dead, along with local attempts at extreme lockdowns. I’m not going to speculate on the further implications of this for things like financial markets or the fabric of our civilization. I also anticipate that I’ll be revising these numbers in the next few days. </p>



<p>But rationalists are seeing the smoke again.</p>
		</div><div>
				<p><img alt="" src="https://1.gravatar.com/avatar/7fcedca31995992a0647e573ea62de1a?s=60&amp;d=monsterid&amp;r=G" height="60" width="60">		</p><!-- .author-avatar -->
		
		<!-- .author-heading -->

		<p>
			I tried to be a magazine writer, mathematician, and stand up comedian. Now I just write a blog with math and jokes.			<a href="https://putanumonit.com/author/putanumonit/" rel="author">
				View all posts by Jacob Falkovich			</a>
		</p><!-- .author-bio -->
	</div></div>]]>
            </description>
            <link>https://putanumonit.com/2020/12/26/seeing-the-new-covid-variant-smoke/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549909</guid>
            <pubDate>Sun, 27 Dec 2020 09:27:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Chaos Communication Congress – Streams]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25549762">thread link</a>) | @doener
<br/>
December 27, 2020 | https://streaming.media.ccc.de/rc3/ | <a href="https://web.archive.org/web/*/https://streaming.media.ccc.de/rc3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streaming.media.ccc.de/rc3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549762</guid>
            <pubDate>Sun, 27 Dec 2020 08:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Why You Found Learning Haskell Hard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549742">thread link</a>) | @schooloffp
<br/>
December 27, 2020 | https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html | <a href="https://web.archive.org/web/*/https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Haskell is notoriously famous for having a steep learning curve. A situation that frustrates newcomers to the language, especially newcomers who are experienced developers using other programming languages.</p>

<p>It is not uncommon to see seasoned developers express their frustration by making the point that all of the other languages they have picked up, they have been able to get productive within a reasonable amount of time, but Haskell only manages to remain an impenetrable wall of Egyptian glyphs after the same period of time.</p>

<p>A reason often cited for Haskell’s steep learning curve is the fact that <em>“Haskell is different”</em>. The argument goes: Haskell is not all that difficult, it is just different, and because of this, it is unfamilair. But most of the time, when this argument is made, it is not mentioned how exactly Haskell is different.</p>

<p>Sure, there could be other reasons why learning Haskell may be considered difficult, but we think the <em>difference</em> argument is an interesting one worth exploring. This is exactly what this post is about. The idea is to do more than just mention that Haskell is different but to show how. The hope is that doing this, will prepare newcomers to the language, hence preventing Haskell’s difference from being a stumbling block to learning the language.</p>

<p>So in what ways is Haskell different?</p>

<!--end_excerpt-->

<h2 id="two-axes-of-difference-syntax-and-computation-model">Two Axes of Difference: Syntax and Computation Model</h2>

<p>There are two axes where Haskell is fundamentally different: <em>The syntax and the computation model</em>.</p>

<p>Haskell has a syntax that is different from languages most experienced developers are familiar with. Also, Haskell’s computation model is based on a different paradigm when compared with most mainstream languages. Understanding this will help in developing a better learning strategy.</p>

<p>Most mainstream programming languages inherit the C-like syntax and have imperative semantics. Haskell syntax is not derived from C, and it is not an imperative language, instead, it is a functional language.</p>

<p>This means a programmer who is experienced with an imperative language with a C-like syntax will find it easy to pick up another imperative language with C-like syntax. Attempting to pick up Haskell in such a similar fashion will be harder and if not aware of these differences, Haskell will feel needlessly hard.</p>

<h3 id="syntax-difference-haskell-is-not-a-c-like-language">Syntax Difference: Haskell is not a C-like language</h3>

<p>Most, if not all current mainstream programming languages have a syntax inspired or derived from C. To illustrate this, let’s take a coding problem from <a href="https://www.codewars.com/">Codewars</a> and see the solutions in the first top <a href="https://www.tiobe.com/tiobe-index/">5 programming languages</a> as rated by the Tiobe programming index, which at the moment of writing this post are: C, Java, Python, C++ and C#. <br></p>

<hr>
<p><br>
<em>Problem Statement: Multiples of 3 or 5</em> <a href="https://www.codewars.com/kata/514b92a657cdc65150000006/">source</a></p>

<p>If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6, and 9. The sum of these multiples is 23.</p>

<p>Finish the solution so that it returns the sum of all the multiples of 3 or 5 below the number passed in.</p>

<p>Note: If the number is a multiple of both 3 and 5, only count it once. Also, if a number is negative, return 0(for languages that do have them)
<br></p>
<hr>


<p><strong>Solution in C</strong>. <a href="https://www.codewars.com/kata/reviews/59721a02e3383171bf000057/groups/5974d6018a6e59f62b0001a9">source</a></p>

<div><div><pre><code><span>int</span> <span>solution</span><span>(</span><span>int</span> <span>number</span><span>)</span> <span>{</span>
    <span>int</span> <span>total</span> <span>=</span> <span>0</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>number</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
      <span>if</span> <span>(</span><span>i</span> <span>%</span> <span>3</span> <span>==</span> <span>0</span> <span>||</span> <span>i</span> <span>%</span> <span>5</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>total</span> <span>=</span> <span>total</span> <span>+</span> <span>i</span><span>;</span>
      <span>}</span>
    <span>}</span>
    <span>return</span> <span>total</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><strong>Solution in Java</strong>. <a href="https://www.codewars.com/kata/reviews/553a8e47f3cc94c58c000123/groups/553adaa02d1cacbea9000048">source</a></p>

<div><div><pre><code><span>public</span> <span>class</span> <span>Solution</span> <span>{</span>

  <span>public</span> <span>int</span> <span>solution</span><span>(</span><span>int</span> <span>number</span><span>)</span> <span>{</span>
    <span>int</span> <span>sum</span><span>=</span><span>0</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span><span>=</span><span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>number</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>if</span> <span>(</span><span>i</span><span>%</span><span>3</span><span>==</span><span>0</span> <span>||</span> <span>i</span><span>%</span><span>5</span><span>==</span><span>0</span><span>)</span> <span>{</span>
        <span>sum</span><span>+=</span><span>i</span><span>;</span>
      <span>}</span>
    <span>}</span>
    <span>return</span> <span>sum</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p><strong>Solution in Python</strong>. <a href="https://www.codewars.com/kata/reviews/54a5ebd237f4350faf00006c/groups/54a7a58272ad2b8b9600055c">source</a></p>

<div><div><pre><code><span>def</span> <span>solution</span><span>(</span><span>number</span><span>):</span>
    <span>sum</span> <span>=</span> <span>0</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>number</span><span>):</span>
        <span>if</span> <span>(</span><span>i</span> <span>%</span> <span>3</span><span>)</span> <span>==</span> <span>0</span> <span>or</span> <span>(</span><span>i</span> <span>%</span> <span>5</span><span>)</span> <span>==</span> <span>0</span><span>:</span>
            <span>sum</span> <span>+=</span> <span>i</span>
    <span>return</span> <span>sum</span>
</code></pre></div></div>

<p><strong>Solution in C++</strong>. <a href="https://www.codewars.com/kata/reviews/578538457e3a78630c000166/groups/5799efd74be91294190003ac">source</a></p>

<div><div><pre><code><span>int</span> <span>solution</span><span>(</span><span>int</span> <span>number</span><span>)</span> 
<span>{</span>
  <span>int</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>int</span> <span>n</span> <span>=</span> <span>3</span><span>;</span> <span>n</span> <span>&lt;</span> <span>number</span><span>;</span> <span>n</span><span>++</span><span>)</span> <span>{</span>
    <span>if</span> <span>((</span><span>n</span><span>%</span><span>3</span> <span>==</span> <span>0</span><span>)</span> <span>||</span> <span>(</span><span>n</span><span>%</span><span>5</span> <span>==</span> <span>0</span><span>))</span>
      <span>sum</span> <span>+=</span> <span>n</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>sum</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><strong>Solution in C#</strong>. <a href="https://www.codewars.com/kata/reviews/550b09270681519ec1001768/groups/550b0c865951388d45000bd1">source</a></p>

<div><div><pre><code><span>public</span> <span>static</span> <span>class</span> <span>Kata</span>
<span>{</span>
  <span>public</span> <span>static</span> <span>int</span> <span>Solution</span><span>(</span><span>int</span> <span>value</span><span>)</span>
  <span>{</span>
    <span>var</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
    <span>for</span><span>(</span><span>int</span> <span>i</span> <span>=</span> <span>3</span><span>;</span> <span>i</span> <span>&lt;</span> <span>value</span><span>;</span> <span>i</span><span>++)</span>
    <span>{</span>
      <span>if</span><span>(</span><span>i</span> <span>%</span> <span>3</span> <span>==</span> <span>0</span> <span>||</span> <span>i</span> <span>%</span> <span>5</span> <span>==</span> <span>0</span><span>)</span> <span>sum</span> <span>+=</span> <span>i</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>sum</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>You see the pattern here? Even in Python, a language that uses whitespace instead of curly braces, the structure of the solutions are all similar. It is not then difficult to see how someone who is proficient in one of the languages can easily make sense of any of the other languages because the structure of their syntax are the same.</p>

<p>Note that some of these imperative languages above now have constructs that makes it possible to emulate functional syntax. For example iterations and operations usually performed via <code>for loops</code> can now be done using construncts like streams and lambdas. This only shows the influence of functional programming on mainstream imperative languages. Infact these functional style is often seen as unnatural to the original languages. The creator of Python, Guido van Rossum, shared a similar sentiment about functional programming style in Python:</p>

<blockquote>
  <p>Python probably has the reputation of supporting functional programming based on the inclusion of lambda, map, filter, and reduce in the language, but in my eyes these are just syntactic sugar, and not the fundamental building blocks that they are in functional languages.</p>
</blockquote>

<ul>
  <li><a href="https://books.google.nl/books?id=yB1WwURwBUQC&amp;pg=PA26&amp;lpg=PA26&amp;dq=Python+probably+has+the+reputation+of+supporting+functional+programming+based+on+the+inclusion+of+lambda,+map,+filter,+and+reduce+in+the+language,+but+in+my+eyes+these+are+just+syntactic+sugar,+and+not+the+fundamental+building+blocks+that+they+are+in+functional+languages&amp;source=bl&amp;ots=-FON4zmkcC&amp;sig=ACfU3U0t3fD8IgnwdRoOLWbMvdRsqmMMOg&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwizwPvo0O_tAhVH4aQKHWrJDuUQ6AEwAHoECAEQAg#v=onepage&amp;q=Python%20probably%20has%20the%20reputation%20of%20supporting%20functional%20programming%20based%20on%20the%20inclusion%20of%20lambda%2C%20map%2C%20filter%2C%20and%20reduce%20in%20the%20language%2C%20but%20in%20my%20eyes%20these%20are%20just%20syntactic%20sugar%2C%20and%20not%20the%20fundamental%20building%20blocks%20that%20they%20are%20in%20functional%20languages&amp;f=false">source</a></li>
</ul>

<p>Now let us see the solution in Haskell:</p>

<p><strong>Solution in Haskell</strong>. <a href="https://www.codewars.com/kata/reviews/5546614c0240a76900000188/groups/5a42ff9c2d59e1e85a0035e0">source</a></p>

<div><div><pre><code><span>module</span> <span>MultiplesOf3And5</span> <span>where</span>
<span>import</span> <span>Data.List</span>

<span>solution</span> <span>::</span> <span>Integer</span> <span>-&gt;</span> <span>Integer</span>
<span>solution</span> <span>n</span> <span>=</span> <span>sum</span> <span>$</span> <span>[</span><span>3</span><span>,</span><span>6</span><span>..</span><span>n</span><span>-</span><span>1</span><span>]</span> <span>`</span><span>union</span><span>`</span> <span>[</span><span>5</span><span>,</span><span>10</span><span>..</span><span>n</span><span>-</span><span>1</span><span>]</span>
</code></pre></div></div>

<p>This looks very different from the previous solutions. The syntax is different and that is because Haskell’s syntax is not inspired by C. <strong>More importantly, this syntax is native to Haskell, and not just a style</strong>. This highlights how Haskell is different when it comes to the axis of syntax.</p>

<blockquote>
  <div><p>An analogy:
Imagine you understand British English, and you want to learn how to write American English. Such a task would be pretty straight forward since you can more or less apply the bulk of the knowledge you already have. What you will then need to learn consists of knowing where to tweak things like the grammar and spelling and idioms that are peculiar to American English. Now contrast that to learning how to write Russian. To do that successfully you will need to be able to set aside what you already know in English and be ready to pick up new grammar rules, new alphabets, new spellings, new idioms, etc.</p><p>
Learning yet another of the mainstream C-family like languages once you know one, is like learning how to speak American English if you already know any variant of English Languages. Learning Haskell on the other hand is similar to already knowing English but wanting to learn Russian. You have to appreciate and understand the fact that the process cannot be approached with a strategy that involves applying what you already know and tweaking one or two things here and there, it has to be approached with the intention to pick up a totally different set of rules about computation and programming. If you are not aware of this fact, then it would become easy to get frustrated and make statements like: I am a senior programmer and in my 10 years of programming I have been able to pick up a new language in 2 weeks tops! I can’t do that with Haskell, hence Haskell is impenetrable. Nope Haskell is not impenetrable, you have just been applying the wrong learning technique. Being aware of this is part of the first steps in learning Haskell successfully.</p></div>
</blockquote>

<h2 id="computation-model-difference-haskell-is-not-an-imperative-language">Computation Model Difference: Haskell is not an imperative language</h2>

<p>The other axis where Haskell is different is its computation model it is based on. This difference is not as obvious as the syntax difference but is a more important difference to appreciate.</p>

<p>Programming languages are based on <a href="https://en.wikipedia.org/wiki/Model_of_computation">Models of computation</a>. This is not difficult to appreciate, as programming languages can be seen as a mechanism to express computations.</p>

<p>The theory of computation and the different possible models have a rich mathematical and academic background, with sequential models, functional models, and concurrent models being the three broad categories.</p>

<p>Most mainstream programming languages are imperative in nature. This means their semantic is derived from the sequential model of computation. To be specific, most imperative languages are implementations of <a href="https://en.wikipedia.org/wiki/Random-access_machine">Random access machines</a>/<a href="https://en.wikipedia.org/wiki/Turing_machine">Turing machines</a>, which are just two examples of the sequential model of computation.</p>

<p>The essence of this model involves expressing computation as a sequential step that involves data mutation together with control structures that control how data is accessed and updated as part of the computation.</p>

<p>This model is the basis of the imperative programming paradigm.</p>

<p>Haskell on the other hand is not based on a sequential model of computation hence it is not an imperative programming language. Haskell is based on the functional model of computation. To be specific, Haskell is an implementation of the <a href="https://en.wikipedia.org/wiki/Lambda_calculus">Lambda calculus</a>, which is one example of a functional model of computation.</p>

<p>The essence of Lambda Calculus involves expressing computation based on function abstraction and application using variable binding and substitution. Haskell, at its core is nothing but an implementation of Lambda Calculus.</p>

<p>These computation models then dictate the mental model that would be required when working with a programming language based on them. A sequential model that involves data mutation requires a different model than a functional model that is an implementation of lambda calculus which requires function abstraction and application.</p>

<p>Hence this is why it is beneficial, especially for seasoned developers picking up Haskell to understand a bit of Lambda Calculus, not to the level required of a mathematician or a computer scientist, but enough to understand why Haskell is the way it is. If not for any other reason but the fact that it will help to appreciate what we mean by function in a mathematical sense and how that is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html">https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html</a></em></p>]]>
            </description>
            <link>https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549742</guid>
            <pubDate>Sun, 27 Dec 2020 08:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust in a KDE Project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549727">thread link</a>) | @lukastyrychtr
<br/>
December 27, 2020 | https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html | <a href="https://web.archive.org/web/*/https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>While trying to implement a long planned feature, an ad block in Angelfish, the Plasma Mobile webbrowser,
I was looking for a mostly complete and performant library that provides this functionality.</p>

<p>First I found libadblockplus, which is a C++ library providing the AdblockPlus core functionality.
Sounds great, right? Well, not quite. It includes it’s own v8 java script engine,
and since we are talking about a webbrowser with a QML interface here,
including a third java script engine and a second copy of v8 was absolutely not an option.
Even if this wasn’t a webbrowser,
running a java script engine as implementation detail of a library is at least … problematic.</p>

<p>The other option I found is <a href="https://github.com/brave/adblock-rust">adblock-rust</a>,
which is the built-in ad block of the Brave browser. As the name tells, it is written in Rust,
and I was originally looking for a C++ library. But it turned out this was not much of a problem,
since Rust features excellent C interoperability, just like C++.
Based on this common ground, bindings can be created to use Rust code from C++ (and the other way around if needed).</p>

<h2 id="approach-1">Approach 1</h2>
<p>My first approach was to use raw ffi. That means essentially building a C API featuring the typical C primitive types in rust,
and telling the rust compiler to represent structs in memory the same way that C would do.
Thanks to cbindgen, which automatically generates a header file with the information for the C compiler to know which fields a struct has and were they are,
we directly get something we can include in our C++ project.</p>

<p>The rust build system cargo is capable of running custom code at build time, and we can use that to run cbindgen on our rust code, by adding a file named <code>build.rs</code>:</p>
<pre><code>extern crate cbindgen;

use std::env;

fn main() {
    let crate_dir = env::var("CARGO_MANIFEST_DIR").unwrap();

    cbindgen::generate(&amp;crate_dir)
        .unwrap()
        .write_to_file("bindings.h");
}
</code></pre>

<p>Our core data structure for the ad block looks like this:</p>
<pre><code>#[repr(C)]
pub struct Adblock {
    blocker: *mut Engine,
}
</code></pre>
<p>It stores a pointer to the rust Engine type in a C compatible struct.
The struct can not be created directly from C / C++, since we don’t know anything about the Engine type there.</p>

<p>So we need a function on the rust side that creates and initializes the Engine for us and packs it into an <code>Adblock</code> struct.
Since the code in angelfish is doing a bit more than only that, the function takes two C string arguments, and returns a pointer to a mutable (non-const) Adblock object.</p>
<pre><code>#[no_mangle]
pub extern "C" fn new_adblock(
    list_dir: *const c_char,
    public_domain_suffix_file: *const c_char,
) -&gt; *mut Adblock
</code></pre>
<p>A few more thigs in this function signature are unusual, but they are all related to the FFI / C compatibility we need here:</p>
<ul>
  <li><code>#[no_mangle]</code> tells the rust compiler not to apply its rust specific function name mangling</li>
  <li><code>extern "C"</code> tells that this function should use the C calling conventions.</li>
</ul>

<p>Every time we interact with data from C, the rust compiler is unable to run its usual safety checks.
For that reason we need unsafe blocks around those lines of code.
If anything unexpectedly segfaults, it’s likely to be in our unsafe blocks.
To get a string that we can feed into a usual rust API, we can use <code>unsafe { CStr::from_ptr(public_domain_suffix_file).to_str() }</code>.</p>

<p>For more examples of how to interact with the C / C++ side, feel free to have a look at <a href="https://invent.kde.org/plasma-mobile/plasma-angelfish/-/blob/20e166c0fe2e38be63824b957c02fa58865ac67c/src/rs/adblock/src/adblock.rs">some real code in Angelfish</a>.
I’m by no means an expert on this, but it should help you get started.</p>

<p>Using this approach, the ad block could successfully be implemented in about 140 lines of rust code, of which only half is FFI code, and the rest actual logic.</p>

<h2 id="approach-2">Approach 2</h2>
<p>The second approach is to use the cxx crate (library), which can generate most of the boilerplate FFI code automatically, and provides a modern API on the C++ side.
To do that, it implements its own wrapper types, each wrapping the functionality of one type of one of the languages. Those wrapper types are implemented in both languages, and allow easily passing more advanced types than pointers and number types through the FFI boundary.
On the rust side, the wrapper types are not really visible, because a macro generates everything for us.</p>

<p>The only unusual thing on the rust side will be a small ffi module, declaring which types and functions we want to expose to C++:</p>
<pre><code>#[cxx::bridge]
mod ffi {
    extern "Rust" {
        type Adblock;
        type AdblockResult;

        fn new_adblock(list_dir: &amp;str, suffix_file: &amp;str) -&gt; Box&lt;Adblock&gt;;
        fn should_block(
            self: &amp;Adblock,
            url: &amp;str,
            source_url: &amp;str,
            request_type: &amp;str,
        ) -&gt; Box&lt;AdblockResult&gt;;
    }
}
</code></pre>

<p>All objects are returned as smart pointers, like <code>Box</code>.
On the C++ side, this will result in a <code>rust::Box&lt;Adblock&gt;</code>, which is a type generated by the cxx_build crate, which is doing something slightly similar to cbindgen.</p>

<p>With the cxx crate, our build.rs will look like this:</p>
<pre><code>extern crate cxx_build;

fn main() {
    cxx_build::bridge("src/adblock.rs").compile("angelfish-adblock")
}
</code></pre>

<p>You may wonder, if the cxx crate makes everything so easy, why did I start with approach 1 at all?
I had had a look at the cxx crate a few month ago, when it was still too minimal to do what I needed. Luckily I had another look, since it has become really useful in the meantime.
However learning the raw ffi way was important to understand what actually happens in the background, and I’d almost recommend everyone to have a look at that first before using the cxx crate. Using <code>cargo expand</code> you can then understand what cxx generated for you.</p>

<p>Given the cxx crate makes this so much easier, I initially feared it might add tons of new dependencies and increase the build time, but to my surprise it actually has a lot less dependencies than cbindgen. Even though cbindgen only uses those at build time (they don’t end up in the binary), they take some time to build.</p>

<p>Angelfish has recently switched to using the cxx crate, so you find usage examples in the <a href="https://invent.kde.org/plasma-mobile/plasma-angelfish/-/blob/d92e48e392303deda6cf3c1552f9f7b5189e2953/src/rs/adblock/src/adblock.rs">current version of the ad block code</a>.</p>

<h2 id="build-system">Build system</h2>
<p>After we have written the FFI, we need to build the Rust code as part of our project, most likely using CMake. This could be very annoying and complicated, but luckily <a href="https://github.com/AndrewGaspar/corrosion">Corrosion</a> exists to make this very easy for us.
It can build our rust code using the cargo build system, and create CMake targets for the library we built, so its easy to link against it.</p>

<h2 id="usage-in-kde">Usage in KDE</h2>
<p>Now that the implementation part is explained,
it makes sense to look into where this can be useful and where not.
Unfortunately the truth is that some distros are still not fully happy with having to package rust code,
because the rust community has a different approach to sharing code than known from the C / C++ world.
While Qt re-implements some functionality also found in other C++ libraries, to only make it necessary to package Qt and not one library for json, one for xml, for http and so on, the rust community likes to split everything into small packages, so no unnecessary code is included.</p>

<p>In Angelfish, all the rust code is optional, and Angelfish can of course still be built without Rust.</p>

<p>Possible areas in KDE that could profit from using Rust are icon and SVG theme rendering code, which could profit from using rsvg or resvg.
I can imagine it could also be useful for document thumbnailers, when a rust implementation of the file type already exists. A similar case could be KIO workers, and pretty much any other project that can profit from optional plugins.</p>

<h2 id="conclusion">Conclusion</h2>
<p>This approach to using Rust in KDE allows to make use of the many libraries and language features the ecosystem provides, without running into the infamous “rewrite it in Rust” reflex. It avoids having to create rust bindings for all KDE Frameworks and Qt only to make use of Rust, and still produces readable code.</p>



	</div><p>The comment feature is still experimental! Comments may be deleted at any time.</p></div>]]>
            </description>
            <link>https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549727</guid>
            <pubDate>Sun, 27 Dec 2020 08:34:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Infinite Pizza]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549523">thread link</a>) | @colinprince
<br/>
December 26, 2020 | https://tocogames.itch.io/infinitepizza | <a href="https://web.archive.org/web/*/https://tocogames.itch.io/infinitepizza">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="community_topic_posts_widget_13011"><div><div data-post="{&quot;user_id&quot;:201665,&quot;id&quot;:2357351}" id="post-2357351"><div><a href="https://itch.io/profile/blancokix"></a><div><div><p>This game was amazing. I’m going to get my friend to play it as well. It’s been a while since I played a game that tested me visually in this way.&nbsp;<br></p></div></div></div></div><div data-post="{&quot;user_id&quot;:1656824,&quot;id&quot;:2355504}" id="post-2355504"><div><a href="https://itch.io/profile/bearson"></a><div><p>i really like this game. i have played it for quite a bit. this is my highest record so far and therefore i want to see if its the highest record ever. please anyone reply if they beat it.&nbsp;<img src="https://img.itch.zone/aW1nLzQ4ODIzMzUucG5n/original/T9ALdU.png"><span></span><span></span><br></p></div></div></div><div data-post="{&quot;user_id&quot;:1375852,&quot;id&quot;:2344699}" id="post-2344699"><div><a href="https://itch.io/profile/spaceadmirallaika"></a><div><div><p>I hate how this game makes my brain feel</p><p>plz add VR support</p></div></div></div></div><div data-post="{&quot;user_id&quot;:1891340,&quot;id&quot;:2344514}" id="post-2344514"><div><a href="https://itch.io/profile/poukitoe"></a><div><div><p>That was so much fun, awesome game!&nbsp;</p></div></div></div></div><div data-post="{&quot;user_id&quot;:1889759,&quot;id&quot;:2341541}" id="post-2341541"><div><a href="https://itch.io/profile/usedsoup"></a><div><p>Great game I love falling down this pizza hell but I wish there was a ost download so I can have this hellish feeling cutting a normal pizza.</p></div></div></div><div data-post="{&quot;user_id&quot;:1252386,&quot;id&quot;:2337156}" id="post-2337156"><div><a href="https://itch.io/profile/42ama"></a><div><p>Freaking loved it, even the tension and difficult. But can you introduce auto-play mode into game, I think it will benefit greatly from it.</p></div></div></div><div data-post="{&quot;user_id&quot;:3742989,&quot;id&quot;:2334729}" id="post-2334729"><div><a href="https://itch.io/profile/phonehome"></a><div><p>Small bug: This likes to launch as a VR game in oculus, totally black screen in the headset but still funny. Not sure why it does this. Would like a fix though as it is kind of annoying to have oculus software launch every time the game does.</p></div></div></div><div data-post="{&quot;user_id&quot;:42105,&quot;id&quot;:2331970}" id="post-2331970"><div><a href="https://itch.io/profile/saltire"></a><div><p>Most cyberpunk game of 2020.</p></div></div></div><div data-post="{&quot;user_id&quot;:155990,&quot;id&quot;:2330760}" id="post-2330760"><div><a href="https://itch.io/profile/mortalmercury"></a><div><div><p>I would change 3 things, the tomato splash causes severe lag (like half a second of lags), so an option to disable the splashes would be great, the second thing is a button to speed up the panning up after dying, the third is that sometimes in a circle with two openings, one of them leads to a wall only.</p><p>But apart from that, GREAT</p></div></div></div></div><div data-post="{&quot;user_id&quot;:172283,&quot;id&quot;:2330278}" id="post-2330278"><div><a href="https://itch.io/profile/bodro"></a><div><div><p>Where am I?</p><p><img src="https://img.itch.zone/aW1nLzQ4Mzg0MjQucG5n/original/JBYQHG.png"></p></div></div></div></div><div><div data-post="{&quot;user_id&quot;:155990,&quot;id&quot;:2330748}" id="post-2330748"><div><a href="https://itch.io/profile/mortalmercury"></a><div><div><p>Pizza Hell</p><p>Pineapple pizza</p></div></div></div></div></div><div data-post="{&quot;user_id&quot;:2212832,&quot;id&quot;:2329898}" id="post-2329898"><div><a href="https://itch.io/profile/relevant-tangent"></a><div><p>This was excellent, the slow pan (pizza) up after you die was a great idea.</p></div></div></div><div data-post="{&quot;user_id&quot;:1606160,&quot;id&quot;:2328689}" id="post-2328689"><div><a href="https://itch.io/profile/toasterstrooder"></a><div><div><p>A strange concept, realized very well!&nbsp;</p>
<p>I'm impressed with how well this is optimized. I&nbsp;expected this to make my little laptop explode but it ran totally fine! The only performance hitch I had was some dips when tomatoes and tomato cans would burst after being shot.&nbsp;</p></div></div></div></div><div data-post="{&quot;user_id&quot;:2057754,&quot;id&quot;:2328450}" id="post-2328450"><div><a href="https://itch.io/profile/fraktal0"></a><div><p>Incredible concept with a mouthwatering art style. I would love to traverse further into pizzaspace in an expanded release. Maybe let us order a pizza from a list of ingredients and it generates the level with those ingredients?</p></div></div></div><div data-post="{&quot;user_id&quot;:2227392,&quot;id&quot;:2327278}" id="post-2327278"><div><a href="https://itch.io/profile/sswaffen"></a><div><p>I loooovee non-euclidean geometrical games!!!</p></div></div></div><div data-post="{&quot;user_id&quot;:689115,&quot;id&quot;:2327237}" id="post-2327237"><div><a href="https://itch.io/profile/angelsolodev"></a><div><p>Dude, I want to live in the pizza</p></div></div></div><div data-post="{&quot;user_id&quot;:88329,&quot;id&quot;:2322768}" id="post-2322768"><div><a href="https://itch.io/profile/harderyoufools"></a><div><p>Very good pizza, would traverse again.&nbsp;👍</p></div></div></div><div data-post="{&quot;user_id&quot;:2782444,&quot;id&quot;:2317998}" id="post-2317998"><div><a href="https://itch.io/profile/seventhsentinel"></a><div><p>Trippy. My eyes feel funny. Cool idea.</p></div></div></div><div data-post="{&quot;user_id&quot;:129555,&quot;id&quot;:2314964}" id="post-2314964"><div><a href="https://itch.io/profile/novaprima"></a><div><p>Very Super Hexagon, which means I only played it a few times, haha. But I can still appreciate it.</p></div></div></div><div data-post="{&quot;user_id&quot;:3105432,&quot;id&quot;:2311195}" id="post-2311195"><div><a href="https://itch.io/profile/massive-monk"></a><div><p>This game is a one of a kind experience. I love it!</p></div></div></div><div data-post="{&quot;user_id&quot;:335606,&quot;id&quot;:2310228}" id="post-2310228"><div><a href="https://itch.io/profile/730"></a><div><p>would be nice to see a writeup about this, cool job<br></p></div></div></div><div data-post="{&quot;user_id&quot;:20387,&quot;id&quot;:2310045}" id="post-2310045"><div><a href="https://itch.io/profile/lauramichet"></a><div><p>This game is completely wild. Amazing job</p></div></div></div><div data-post="{&quot;user_id&quot;:102217,&quot;id&quot;:2308291}" id="post-2308291"><div><a href="https://itch.io/profile/secretstage"></a><div><div><p>Psychedelic &amp; delicious! Great visual style and fitting sound!</p>
<p>Can't wait to eat that pizza... as soon as I can get to the other end. :)</p></div></div></div></div><div data-post="{&quot;user_id&quot;:88490,&quot;id&quot;:2308008}" id="post-2308008"><div><a href="https://itch.io/profile/gsantos"></a><div><p>Amazing idea but the game is really too hard, I think colliders could be a little smaller to make it more forgiving.</p></div></div></div><div data-post="{&quot;user_id&quot;:509169,&quot;id&quot;:2306217}" id="post-2306217"><div><a href="https://itch.io/profile/terminusest13"></a><div><p>This was a lot of fun. The sound effects were wonderful, too. Sometimes there were walls that popped up too fast for me to react, but I think I need to acquire proficiency.</p></div></div></div><div data-post="{&quot;user_id&quot;:1961337,&quot;id&quot;:2305217}" id="post-2305217"><div><a href="https://itch.io/profile/fluxsauce"></a><div><p>That was SO WEIRD, love it!</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://tocogames.itch.io/infinitepizza</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549523</guid>
            <pubDate>Sun, 27 Dec 2020 07:36:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Google]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25549502">thread link</a>) | @p2pai
<br/>
December 26, 2020 | https://dcgross.com/a-new-google?src=t | <a href="https://web.archive.org/web/*/https://dcgross.com/a-new-google?src=t">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>[TL;DR: Google has gotten bad; we all know it; ideas for a startup making a better Google.]</p> <p>In 2000, Google got popular because hackers realized it was better than Lycos or Excite. This effect is happening again. Early adopters aren’t using Google anymore.</p> <p>They aren’t using DuckDuckGo either. They’re still using Google.com, but differently. To make Google usable, users are adding faux-query modifiers that to supress the “garbage Internet”.</p> <p>You see this in the typeahead logs.</p> <p><img src="https://dcgross.com/assets/new-google/image6.png" alt=""> <em></em></p><center><em>Products (Reddit)</em></center> <p><img src="https://dcgross.com/assets/new-google/image4.png" alt=""> <em></em></p><center><em>Services (Reddit, Yelp)</em></center> <p><img src="https://dcgross.com/assets/new-google/image1.png" alt=""> <em></em></p><center><em>Movies (Rotten Tomatoes)</em></center> <p><img src="https://dcgross.com/assets/new-google/image5.png" alt=""> <em></em></p><center><em>Even code (Github)</em></center> <p>Interestingly, this doesn’t work for all categories. <img src="https://dcgross.com/assets/new-google/image3.png" alt=""> <img src="https://dcgross.com/assets/new-google/image2.png" alt=""> <em></em></p><center><em>Recipes don’t have a “Reddit” equivalent</em></center> <h3 id="query-operators-mean-somethings-broken">Query Operators Mean Something’s Broken</h3> <p>More advanced users use modifiers like <code>site: filetype: intitle:</code> because adding “reddit” isn’t strict enough, as spammy websites often manipulate content to win SEO.</p> <p>How about those websites that stuff the year in the title? “Reviews UPDATED JANUARY 2020” are exploiting the fact that customers suffix queries with the year. What those people are trying to command is freshness, not a title match.</p> <p>Something’s broken, and a tiny share of Google is open for the taking. Obviously attacking incumbents head-on doesn’t work. Here are two alternative ideas for bootstrapping next-generation search:</p> <h3 id="1-boogle-a-query-reformulator">#1 Boogle, A Query Reformulator</h3> <p>Introducing Boogle, a proxy for Google that’s just Better Google Search. It’s a query expander. We predict the correct operators for your query, proxy Google’s results, and serve. For example:</p> <p><code>query("stripe.js example") -&gt; query("stripe.js example (site:github.com OR site:gitlab.com OR site:..."))</code></p> <p><code>query("is anker charger") -&gt; query("is anker charger (inurl:forum OR site:reddit.com OR ...))"</code></p> <p>Query topic modeling is a rich science with plenty of examples.</p> <p>You’d almost as fast as Google, never worse, and occasionally better. This will help build the reflex to use you instead. This approach isn’t that hard to get started with, and might work for the high-end users.</p>  <p>You could go after this vertical by vertical – build the <em>best</em> site for electric product search, for travel, for code, etc. A key question is how to build habitual recall to use your product over Google. Amazon and Airbnb both enjoy a huge amount of direct traffic. Some learnings from those:</p> <ul> <li><strong>Stellar mobile destination.</strong> Using Airbnb directly feels more fluid and fun than using Google for Airbnb.</li> <li><strong>The 90% Rule.</strong> To build reflex you need to give me what I want most of the time.** **With Prime, Amazon made it such that we stopped price comparing across other sites; Amazon would get it to us fastest, and that turns out to matter more than price. Most of the time you open Amazon.app, it satisfies.</li> <li><strong>Come for search, stay for something else.</strong> I don’t think of Airbnb or Amazon as search apps. They help me get things or book homes. You might want to your search app to be a destination for something else. This is where I think community comes in.</li> </ul> <p>Picking a vertical that <em>doesn’t</em> have strong typeahead completions[1] would help you build community around your search engine. Recipes, fitness, fashion, etc. don’t have decacorn conglomerates like Github or Reddit. That might mean it’s easier to build community around them, and put your flagship search engine on top.</p> <hr> <p>If you’re working on this kind of stuff, try out <a href="https://pioneer.app/">Pioneer</a> or just shoot me an email – daniel@pioneer.app.</p> <hr> <p>[1] In reality I’d pick the vertical _I _love most. If you’re a guitar player start with music; a movie buff should build better Rotten Tomatos. Etc.</p> </article></div>]]>
            </description>
            <link>https://dcgross.com/a-new-google?src=t</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549502</guid>
            <pubDate>Sun, 27 Dec 2020 07:30:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GNU Stow to manage your dotfiles (2012)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549462">thread link</a>) | @matthberg
<br/>
December 26, 2020 | http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html | <a href="https://web.archive.org/web/*/http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	   

<p>I accidentally stumbled upon something yesterday that I felt like
sharing, which fell squarely into the "why the hell didn’t I know about this
before?" category. In this post, I’ll describe how to manage
the various configuration files in your GNU/Linux home directory (aka
"dotfiles" like <code>.bashrc</code>) using GNU Stow.</p>

<p>The difficulty is that it would be helpful to manage one’s
configuration files with a version control system like Git, Mercurial
or Bazaar, but many/most dotfiles reside at the top-level of your home
directory, where it wouldn’t be a good idea to initialize a VCS
repository. Over time I’ve come across various programs which aim to
manage this for you by keeping all the files in a subdirectory and
then installing or linking them into their appropriate places. None of
those programs ever really appealed to me.  They would require a ton
of dependencies (like Ruby and a ton of libraries for it) or they
would require me to remember how to use them, which is difficult when
really for such a task you rarely use the program.</p>

<p>Lately I’ve been using <a href="http://www.gnu.org/software/stow">GNU Stow</a> to manage
programs I install from source to <code>/usr/local/</code>. Basically, in this typical
usage, you install locally built packages to
<code>/usr/local/stow/${PKGNAME}-{PKGVERSION}</code> and then from <code>/usr/local/stow/</code> you run
<code># stow ${PKGNAME}-${PKGVERSION}</code> and the program generates symbolic links to
all the programs' files into the appropriate places under <code>/usr/local/</code>. Then,
when you uninstall a program via Stow, you don’t have to worry about any stray
files that you or a provide Makefile may have missed. It also makes handling
alternate versions of a program quite easy (i.e. when I’m experimenting with
different configurations of <a href="http://dwm.suckless.org/">dwm</a> or
<a href="http://st.suckless.org/">st</a>).</p>

<p>Some time ago I happened across a mailing list posting where someone described
using Stow to manage the installation of their dotfiles. I didn’t pay much
attention to it but my brain must have filed it away for later. Yesterday I
decided to give it a try and I have to say that it is so much more convenient
than those other dedicated dotfile-management programs, even if it wasn’t an
immediately obvious option.</p>

<p>The procedure is simple. I created the <code>${HOME}/dotfiles</code> directory and then
inside it I made subdirectories for all the programs whose cofigurations I
wanted to manage. Inside each of those directories, I moved in all the
appropriate files, maintaining the directory structure of my home directory. So,
if a file normally resides at the top level of your home directory, it would go
into the top level of the program’s subdirectory. If a file normally goes in the
default <code>${XDG_CONFIG_HOME}/${PKGNAME}</code> location (<code>${HOME}/.config/${PKGNAME}</code>),
then it would instead go in <code>${HOME}/dotfiles/${PKGNAME}/.config/${PKGNAME}</code> and
so on. Finally, from the <code>dotfiles</code> directory, you just run <code>$ stow $PKGNAME</code>
and Stow will symlink all the package’s configuration files to the appropriate
locations. It’s then easy to make the <code>dotfiles</code> a VCS repository so you can
keep track of changes you make (plus it makes it so much easier to share
configurations between different computers, which was my main reason to do it).</p>

<p>For example, let’s say you want to manage the configuration for Bash, VIM and
Uzbl. Bash has a couple files in the top-level directory; VIM typically has your
.vimrc file on the top-level and a .vim directory; and Uzbl has files in
<code>${XDG_CONFIG_HOME}/uzbl</code> and <code>${XDG_DATA_HOME}/uzbl</code>. So, your home directory
looks like this:</p>

<pre><code>home/
    brandon/
        .config/
            uzbl/
                [...some files]
        .local/
            share/
                uzbl/
                    [...some files]
        .vim/
            [...some files]
        .bashrc
        .bash_profile
        .bash_logout
        .vimrc
</code></pre>

<p>You would then create a <code>dotfiles</code> subdirectory and move all the files there:</p>

<pre><code>home/
    /brandon/
        .config/
        .local/
            .share/
        dotfiles/
            bash/
                .bashrc
                .bash_profile
                .bash_logout
            uzbl/
                .config/
                    uzbl/
                        [...some files]
                .local/
                    share/
                        uzbl/
                            [...some files]
            vim/
                .vim/
                    [...some files]
                .vimrc
</code></pre>

<p>Then, perform the following commands:</p>

<pre><code>$ cd ~/dotfiles
$ stow bash
$ stow uzbl
$ stow vim
</code></pre>

<p>And, voila, all your config files (well, symbolic links to them) are
all in the correct place, however disorganized that might be, while
the actual files are all neatly organized in your <code>dotfiles</code>
directory, which is easily turned into a VCS repo. One handy thing is
that if you use multiple computers, which may not have the same
software installed on them, you can pick and choose which
configurations to install when you need them. All of your dotfiles are
always available in your <code>dotfiles</code> directory, but if you don’t need
the configuration for one program, you simply don’t Stow it and thus
it does not clutter your home directory.</p>

<p>Well, that’s all there is to it. Hopefully someone else out there
finds this useful! I know I’ve found it to be a huge help.</p>

<p><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png"></a><br><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Using GNU Stow to Manage Your Dotfiles</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://brandon.invergo.net/" property="cc:attributionName" rel="cc:attributionURL">Brandon Invergo</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>


             
	   </article></div>]]>
            </description>
            <link>http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549462</guid>
            <pubDate>Sun, 27 Dec 2020 07:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not Being Bullish Enough on Bitcoin Is a Mistake]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25549230">thread link</a>) | @alwillis
<br/>
December 26, 2020 | https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/ | <a href="https://web.archive.org/web/*/https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<figure><img loading="lazy" width="1024" height="731" src="https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1024x731.png" alt="" srcset="https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1024x731.png 1024w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-300x214.png 300w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-768x548.png 768w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1536x1097.png 1536w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1200x857.png 1200w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1980x1414.png 1980w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-600x428.png 600w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough.png 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Not Being Bullish Enough on Bitcoin is a big mistake. Why? You’ll sell too early, and not grasp Bitcoin well enough to get the big picture here. You might not secure the coins well enough, and you might not actually realise the societal implications of Bitcoin. </p>



<h2>Not Being Bullish Enough On Bitcoin Means Selling too early</h2>



<p>Fundamentally, a lot of people did not truly peer into <a href="http://stephanlivera.com/185">what Bitcoin is</a>, and this made them not bullish enough. This is a big error, as it pushes them to sell bitcoin too early. While they think they’re being clever timing a top, Bitcoin proceeds to humble them a few years later after another cycle. </p>



<p>Lopp has a great example here: </p>



<figure></figure>



<p>At time of writing in Dec 2020, Bitcoin is now around $23,000 USD. Selling early is penny wise, pound foolish. </p>



<p>Many people wish they had bought bitcoin earlier, but truth be told: that’s only half the challenge. The other half is actually HODLing it through the long term and not selling it out. </p>



<p>As bitcoin old-timers in the space will tell you, you could have bought early… but then you probably would have also sold early. It takes understanding and conviction.</p>



<h2>Not Being Bullish Enough On Bitcoin Means Not Securing it Correctly</h2>



<p>It’s a wild roller-coaster. Bitcoin can 10x in the space of a few months, and you can be left <em>very</em> exposed if you’re not careful. A $10k bitcoin stack can quickly become $100k, a $100k stack can quickly become $1M and so on. </p>



<p>Consider the worth of your stack currently, and think about if Bitcoin were to 10x or 20x over a few months or a year. Would you be comfortable with the level of security you have? </p>



<p>If you aren’t bullish enough, and you’re only looking for a 2x and then flip for fiat profits, you aren’t thinking big enough. You should be looking to learn about bitcoin security by listening to SLP such as <a href="http://stephanlivera.com/97">SLP97</a> and <a href="http://stephanlivera.com/215">SLP215</a> with Michael Flaxman. You should be looking at ways to: </p>



<ul><li>Ensure appropriate entropy in your bitcoin seed generation </li><li>Minimise single points of failure</li><li>Consider multi signature</li><li>In the ideal case, use open source hardware and software that has been vetted from a security perspective</li><li>Learn about how to verify signatures for software you use</li><li>Learn hardware wallet best practices</li></ul>



<h2>Not learning enough about how to use Bitcoin the right way</h2>



<p>When we talk about using Bitcoin, we mean using it in a self sovereign way. You shouldn’t be in a situation where you are exclusively trusting or relying on your service provider to give you your bitcoins. </p>



<p>This is not stocks or dollars in your bank account. This is Bitcoin. Use it the self sovereign way. </p>



<p>In practice this means: </p>



<ul><li>Don’t leave your coins in custodial accounts. Use sovereign bitcoin wallets where you hold the private keys. Or at least, a quorum of private keys (e.g. you hold 2 of 3 keys, or 4 of 5 keys). </li><li>Ideally, perform your own validation by running your own underlying bitcoin node. This is easy with <a href="https://www.ministryofnodes.com.au/2020/09/28/cost-effective-bitcoin-use-hardware-wallet-own-node/">Specter Desktop + Bitcoin Core</a>, or with <a href="https://www.ministryofnodes.com.au/2020/03/26/mynode-video-tutorials/">myNode</a>, or other projects e.g. Umbrel, <a href="http://raspiblitz.com/">RaspiBlitz</a>, <a href="http://ronindojo.io/">Ronin Dojo</a>, <a href="http://btcpayserver.org/">BTCPay Server</a>, <a href="http://nodl.it/">nodl</a> etc. </li></ul>



<h2>Not realising the societal implications of Bitcoin</h2>



<p>Fiat money has cultural consequences that many simply do not understand right now. It’s like we’re fish swimming in the water without realising what we’re swimming in. We’ve grown up in an environment of cheap debt, facing incentives to go into debt or lose. </p>



<p>This drives all kinds of changes in our society that weren’t so obvious pre-1971. Increased welfare statism, increased debt, higher time preference, increased centralisation into managerial superstates, to name a few. </p>



<p>As Bitcoin becomes more widely adopted, society’s return to hard money will drive significant cultural shifts that align with the return to hard money. Listen to <a href="http://stephanlivera.com/51">SLP51 with Guido Hulsmann</a> to know more.</p>



<h2>Conclusion</h2>



<p>Fundamentally, it takes knowledge, conviction, and dedication to do this. There are many pitfalls along the way, and it takes work from the HODLer to methodically and skilfully avoid these pitfalls. Of course, we can lament the difficulty and push it off til the future when it’ll be easier. But that is also giving up the huge return potential, and also the freedom and moral imperative of bringing about a Bitcoin Standard. </p>



<p>Do your research and learning, be methodical in your approach, and you’ll be in with a good shot. </p>



<h2>Help With Being Bullish Enough</h2>



<p>See our <a href="https://www.ministryofnodes.com.au/store/">web store</a> for guides and products. For many readers of this blog, you’d probably benefit from using Coldcard + Specter Desktop + Bitcoin Core, for which we offer an in depth video guide <a href="https://www.ministryofnodes.com.au/product/bitcoin-starter-guide-how-to-hold-intermediate/">here</a>. </p>



<p>Or otherwise, if you’re not sure where to start, or want other assistance, we offer zoom call consulting <a href="https://www.ministryofnodes.com.au/consulting/">here</a>. Zoom consults are offered on a ‘pay what you think it was worth’ basis. Book a call, then <a href="https://www.ministryofnodes.com.au/support/">pay us here afterwards</a>.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549230</guid>
            <pubDate>Sun, 27 Dec 2020 06:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DiamonDie's ASCII Art Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549054">thread link</a>) | @thedookmaster
<br/>
December 26, 2020 | https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art. | <a href="https://web.archive.org/web/*/https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><i>This tutorial is written by Maija Haavisto (<a href="http://www.angelfire.com/mn/Maija/asciiart.html">old homepage</a>, and <a href="http://diamondie.deviantart.com/">another homepage</a>)</i></p>
<hr>




<h2>Table of contents</h2>
<p>
1 Introduction<br>
2 Types of ASCII art<br>
&nbsp; 2.1 Lineart<br>

&nbsp; 2.2 Solid<br>
&nbsp; 2.3 Grayscale<br>
&nbsp; 2.4 Camelized<br>
&nbsp; 2.5 Others<br>
3 Drawing ASCII art<br>
&nbsp; 3.1 Starting out<br>

&nbsp; 3.2 Lineart<br>
&nbsp; 3.3 Solid art<br>
&nbsp; 3.4 Grayscale<br>
&nbsp; 3.5 Antialiasing<br>
&nbsp; 3.6 Tracing<br>
&nbsp; 3.7 Aspect ratio<br>

&nbsp; 3.8 Difficulties and limitations<br>
&nbsp; 3.9 Perspective, 3D and isometric ASCII<br>
&nbsp; 3.10 Textures and materials<br>
&nbsp; 3.11 Lighting and shadow<br>
&nbsp; 3.12 Uses for different characters<br>
4 Fixed-width fonts<br>

&nbsp;&nbsp;&nbsp; 4.1 Courier New<br>
&nbsp;&nbsp;&nbsp; 4.2 DOS font<br>
&nbsp;&nbsp;&nbsp; 4.3 Topaz New<br>
&nbsp;&nbsp;&nbsp; 4.4 Lucida Console<br>
&nbsp;&nbsp;&nbsp; 4.5 Fixedsys<br>
&nbsp;&nbsp;&nbsp; 4.6 Arial Alternative<br>

&nbsp;&nbsp;&nbsp; 4.7 MS Gothic<br>
&nbsp;&nbsp;&nbsp; 4.8 Andale Mono (aka Monotype.com)<br>
5 ASCII art software<br>
&nbsp;&nbsp; 5.1 JavE<br>
&nbsp;&nbsp; 5.2 FIGlet<br>
&nbsp;&nbsp; 5.3 TheDraw/Aciddraw<br>

&nbsp;&nbsp; 5.4 Acidview<br>
&nbsp;&nbsp; 5.5 PabloDraw<br>
6 Other stuff<br>
&nbsp; 6.1 ASCII map<br>
&nbsp; 6.2 Displaying ASCII art on web pages<br>
&nbsp; 6.3 Coloring ASCII art<br>

&nbsp; 6.4 Demoscene ASCII art<br>
&nbsp; 6.5 ASCII art culture and etiquette

</p><h2>1 Introduction</h2>

<p>ASCII is an acronym of "American Standard Code for Information
Interchange". ASCII art means art made out of different characters in
the ASCII map and can thus be represented in plain text format. It
cannot include extended characters or text formatting such as bold or
italics. ASCII art is always done on a fixed-width font like Courier
New or Fixedsys, never on a proportional font like Arial or Times New
Roman. It can be made in Notepad or MS-DOS Edit, but there are also
some specific programs for making ASCII art. And no, I'm not talking
about ASCII converters.</p><p>
People often comment on ASCII art by saying "Wow, that is so amazing,
I'd never have the patience to make something like that". I don't get
it. Why do they think ASCII art requires so much patience? I can make a
decent fullscreen ASCII in an hour (even if it sometimes takes ten
hours). It takes me at least fifteen hours to draw a decent fullscreen
CG picture.</p><p>
ASCII art isn't easy and it does require skill, but you don't have to
care about things like brush strokes or colors and usually not about
shading either. In a way it is a lot like pixel art. When I started
pixeling it felt very familiar due to my ASCII and ANSI experience.
Pixel artists will probably experience a similar reaction when they
start drawing ASCII. You don't have to have great drawing skills to be
a good ASCII artist. I, for instance, suck at drawing, I can paint but
I can't do the sketch like thing at all. ASCII sketching is practically
something non-existant, but if this interests you, nothing stops you
from trying this new style.</p><p>
Some people wonder what's the point. What's the point in making art in
general? I think limitations are what makes art interesting and feeds
the creative mind. ASCII art probably isn't something that you
encounter in an art museum (which is regrettable), it's more like
everyday art. I guess it has something in common with pop art. ASCII
art can be sent via email or to Usenet newsgroups, it can be
used on IRC and many chatrooms (do that with caution, though). You can
include ASCII art in your signature or login screen or print it out
with your old matrix printer. It can be used for representing game
situations, graphs or molecular models.</p><p>
I've heard opinions of ASCII art not being art but graphical design,
but I disagree with that. Design is usually considered to be something
functional, such as advertisements or interfaces, while visual art is
something you can hang on your walls. ASCII art usually isn't
functional but aesthetical. I know people who have ASCII pictures
hanging on their walls.</p><p>

There are other ASCII tutorials, but I decided there's still room
for another one. Many of the others are outdated, some are even more
than 10 years old. They also feature slightly different techniques and
lack some of the parts that my tutorial focuses on. This turned out
perhaps more like a ASCII drawing/culture FAQ than an actual tutorial,
but I hope it will still be useful.

</p><h2>2 Types of ASCII art</h2>

<h4>2.1 Lineart</h4>

<div><p>Lineart is just what its name implies, things are represented with
(usually thin) outlines, sometimes dotty, sometimes consisting mostly
of slashes, underscores and pipes. Lineart also includes most FIGlet
fonts and demoscene logos. Suitable for both huge images and tiny
pictures.</p></div><pre>            .-"""-.
           '       \
          |,.  ,-.  |
          |()L( ()| |
          |,'  `".| |
          |.___.',| `
         .j `--"' `  `.
        / '        '   \
       / /          `   `.
      / /            `    .
     / /              l   |
    . ,               |   |
    ,"`.             .|   |
 _.'   ``.          | `..-'l
|       `.`,        |      `.
|         `.    __.j         )
|__        |--""___|      ,-'
   `"--...,+""""   `._,.-' mh

Penguin by DiamonDie (2002?)</pre>

<h4>2.2 Solid</h4>

<div><p>Solid art is the "opposite" of lineart, it's not outlined but filled
and flat-shaded.
It's often best fit on mid-sized and large pictures, though it can also
work for small pieces, such as the heart here. Often it looks better
than lineart, simply for the fact that it's not as "thin". Solid art is
often used for logos, ornament designs and text, but it fits almost any
kind of subject. It's not very well suited for faces though.</p></div><pre>  ,o8o, ,o8o,
,888888,888888,
888888888888888
888888888888888
`8888888888888'
  `888888888'
    `88888'
      `8'

Heart by DiamonDie (1997)</pre>

<h4>2.3 Grayscale</h4>

<div><p>Grayscale is like solid art, but it consists of many different
characters that are used to portrays lighter and darker areas, making
it the most suitable kind of ASCII for picturing faces. It is usually
best viewed white on black, such as the example below (people using
most graphical browsers can select it with a mouse or press Ctrl-A to
see it in inverse color). Most converters create grayscale art, though
rather messy kind with often no antialiasing. Grayscale could be
considered the most difficult of all ASCII techniques.</p></div><pre>                           .,,,yyyy@@yyyyy,,,                                  
                      ,ytS$$CCCCCCCCCCCCCCC?III;,.                             
                   .yt$$$$$$$$CCCCCCCCCCCCCCCCIIIIII;.                         
                 ,4$$$$$$$$$$$$$$SCCCCCCCCCCCCCCC?IIIII;                       
               y$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCCCCIIII,                       
             ,$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCCCIIII:                      
            l$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCIIIIi                      
           t$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCIIII:                      
         .l$$$$$$$$$$$$$$$$$$$$$$$$$$$SCCCCCCCCCCCCCIIII,  i                   
         d$$$$$$$$$$$$$$$$$$$$$$$$$$$SCCCCCCCCCCCCCIIIII. ;I,                  
         $$$$$$$$$$$$$$$$$$$$$$$$$$SSCCCCCCCCCCCCCIIIIIII .III                 
        j$$$$$$$$$$$$$$$$$$$$$$$$$SSCCCCCCCCCCCCCCIIIIIIIi.II;                 
        ]$$$$$$$$$$$$$$$$$$$$P"'   `"^?CCCCCCCCCCIIIIIIIIIIIII                 
        l$$$$$$$$$$$$$$$$P"''    .,..   `;?CCCCCCC?IIIIIIIIII;     .y%*        
        l$$$$$$$$$$$$SP"     ,yS$$$$$$Shy..`"IICCCCCCII:  ::      4C7;  \      
        $$$$$$$$$$$SP.   .;;$$$SCCCCCSSCCCCSb: ICCCCCCCII; ''  liC$ClCC;;l     
        $$$$$$$$$$$$I::lIIIICCSSSSSSCCCCCCCCCCIICCCCCCCI       ICCC$lCC??;b    
        P"^^^48$$$$$$SSIII' `Ii :   y,"ICCCS$SCCCCCCCCCCI      ICl"l "7SSbl.   
       :        l$$8888II66 ,?$b,yySIIICC$$$$$$$$SCCCCCCCI     ?CCb l JCC$il   
       :  .    ,$$$$$$CCCC$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI     ICS$li$$SCC?l   
        `SS",+.$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI     !?S$ ;I$$SCCP   
         "' : S$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI      ICSCS$$$$$I    
          ;:6$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI        `?C$$$$P     
            `$$$$$$$$$$S$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI         `""""'      
            j$$$$$$$$$SCCS$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCI                      
            $$$$$$$$$$$$$CI$$$$$$$$$$$$$$$$$$$$$$$SCCCCCI;                     
           j$$$$$$$$$$SS$CI$$$$$$$$$$$$$$$$$$$$$$SSCCCCCIi                     
           7$$$$T7"`,yyiIIC$$$$$$$$$$$$$$$$$$$$$SSSSCCCC?i                     
            "4$SC**7"""-:47$$$$$$$$$$$$$$$$$$$$$SSSSCCCCCI                     
              7I       . ,';' ";7ICS$$$$$$$$$C$S$$$$$CCCCl                     
              : jy.,jyyjCCCCi ..i."7C$$$$$$C$CS$S$$$SCCC?'      ;              
             : d$$$$CCC7?"""""?7CiiCS$$$$SCCCC$S$$$$CCCC;       i,             
              .CC,]CCSSSCCSCCCIiIiICS$$$SSCCCCS$$$$SCC?        .|              
              :`j$$$$$$$$SCCCC$$$CICS$$SCCCCCCCC$CC?;          iI.             
               :l$$$$$$$CCCCCS$$$$C?iCCCCCCCCC7"'.,          .iII,             
                :C?"~~    ,CCC$$$IiIiCCCCCCC?   '           ,IIIII             
                 :$7  ,_,jS$$$$CIiIi?iCCC??                iI?CCCII            
                .;  :;i:;;?S???iiIiIi?i'                iII?CCCCCII.           
                ;  ';'    ?lCi??i;i;;                  iI?CCCCCCCCIIi          
               :            ;? ;I"                  iIIICCSCCCCCCCCIIl         
                ;                             .,iiI?CCCC$$$$$SSCCCCCCIi I, II; 
                 '.                 _,.   ,i,IIII?CCCCCS$$$$$$SSSCCCCIIIIIIIII'
                   ' ~  + =- - ' ~ ` SCCIIIIII???CCCCS$$$$$$$$$$$SCCCCCCC?I"   
                                     l$$CCCCCCCCCCCCS$$$$$$$$$$$$$$$$SCCC"`    

It Figures by `nemoorange</pre>

<h4>2.4 Camelized</h4>

<p>Camelized ASCII art isn't very popular, even though it already appeared
in
the book Alice in Wonderland. It is usually poetry (sometimes prose)
made into the shape of an object, often an animal. There are a couple
of different techniques for making the shapes. Some people use extra
spacing to achieve lines of required length, others wrap words from the
middle or use extra characters. JavE has a feature for camelized ASCII.

</p><h4>2.5 Others</h4>

<p>There are variations of the previously listed styles, such as</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.">https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.</a></em></p>]]>
            </description>
            <link>https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549054</guid>
            <pubDate>Sun, 27 Dec 2020 05:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Working Hours: Burnout, Pacing, and Hustle Culture]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25548423">thread link</a>) | @mooreds
<br/>
December 26, 2020 | https://www.karllhughes.com/posts/working-hours | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/working-hours">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/startup-working-hours.png" alt="Startup Working Hours: Burnout, Pacing, and Hustle Culture">
</p> 

<p>
2020, Dec 16&nbsp;&nbsp;&nbsp;—&nbsp;
8 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>When I joined my first startup almost ten years ago, most of the prevailing wisdom about startups said that you should be ready for an 80-hour per week grind. So, I made it my mission to work longer and harder than anyone else on the path to success.</p>
<p>At that time, I didn’t have a family, significant other, or many hobbies outside of work, plus I liked my job, so it was relatively easy to put in long hours and work weekends. While I did a lot of tasks in those early days, looking back, I realize that <em>I didn’t actually accomplish much.</em></p>
<p>After working for three early-stage startups and <a href="https://www.karllhughes.com/posts/cto-writer">founding my own in 2020</a>, I’ve talked to countless founders about startup hours, pacing, burnout, and hustling. I’ve since seen a lot of founders fall into the trap of working more hours instead of working smarter, so in this post, I’ll give you my perspective on why this happens. Finally, I’ll share a few things that I’ve learned about maintaining balance in a startup from both an employee’s and founder’s perspective.</p>
<h2 id="typical-startup-hours">“Typical” Startup Hours</h2>
<p>One of the challenging things about joining a startup is that there are rarely “typical” work hours. Some startups expect employees to be in the office from 8 am to 8 pm every day and answer emails on the weekend, while others might allow complete flexibility with very little concern over hours worked.</p>
<p><strong>While it’s <a href="https://www.karllhughes.com/posts/myths-working-engineer-startup">a myth that every startup requires you to work overtime every week</a>, most startup employees put in 50-60 hours per week, and many founders put in 60-100 per week.</strong></p>
<p>The problem with long hours is that they’re counterproductive:</p>
<blockquote>
<p>“John Pencavel found that productivity per hour declines sharply when a person works more than 50 hours a week. After 55 hours, productivity drops so much that putting in any more hours would be pointless. And, those who work up to 70 hours a week are only getting the same amount of work done as those who put in the 55 hours.” - <a href="https://www.cnbc.com/2019/03/20/stanford-study-longer-hours-doesnt-make-you-more-productive-heres-how-to-get-more-done-by-doing-less.html">CNBC Report on Standford Productivity Study</a></p>
</blockquote>
<p><a href="https://amzn.to/2WjbkL5"><img src="https://i.imgur.com/Vn2qohv.jpg" alt="Bored and Brilliant book cover"></a></p>
<p>Your body ultimately needs sleep, food, relaxation, and <a href="https://www.gq.com/story/how-and-why-you-should-be-bored"><em>even boredom</em></a> to function properly. This is especially true for those of us who do <a href="https://www.wired.com/story/eight-hour-workday-is-a-lie/">high-concentration, creative work</a> (like writing, programming, and strategic thinking).</p>
<p>One of my favorite reads in 2019 was <em><a href="https://amzn.to/2WjbkL5">Bored and Brilliant</a></em> because it reminded me of the need to put down my phone and just think every once in a while. Regular introspection leads to clarity, focus, and prioritization that is extremely valuable as a startup founder.</p>
<p><em>Looking for more good startup books? I’ve listed <a href="https://www.karllhughes.com/posts/startup-books">a few dozen of my favorites here</a>.</em></p>
<h2 id="why-are-startup-hours-so-long">Why Are Startup Hours so Long?</h2>
<p>So if the research is against long hours for most people, why do startup founders work so much? And, why do they, in turn, expect their employees to do the same?</p>
<p>There are four factors I see at play in defining startup working hours:</p>
<h3 id="1-hustle-culture">1. Hustle Culture</h3>
<blockquote>
<p>“I don’t think it’s fair for people to say that they work 100 hours. That’s just a PR move, like when Elon Musk sleeps on a hard couch in a meeting room. Why couldn’t he have a nice bed delivered to his office?” - <a href="https://www.quora.com/How-many-hours-per-day-do-startup-employees-work-compared-to-those-at-a-regular-company/answer/Nope-Nope-351">Anonymous opinion on Quora</a></p>
</blockquote>
<p>You might think of startup founders as original, free-thinking, creative people, but most of them are just as vulnerable to peer pressure and cultural norms as any of us. So, when high-profile startup founders report that they <a href="https://www.businessinsider.com/elon-musk-sleeps-under-desk-as-tesla-faces-model-3-production-goals-2018-6">slept at the office</a>, other founders see this as a template for success. Some even <a href="https://hbr.org/2015/04/why-some-men-pretend-to-work-80-hour-weeks">lie about the number of hours they work</a> because of the cultural pressure to put in more time.</p>
<h3 id="2-work-life-separation-is-dwindling">2. Work-Life Separation is Dwindling</h3>
<p>It’s even harder to “unplug” from work when your office is six feet away from your bedroom, and your phone goes to bed with you at night. Now that more companies are going remote, employees <a href="https://www.cbsnews.com/news/covid-19-lockdown-work-from-home-day-one-hour-longer/">are working longer hours</a> and having more meetings in what would be off-hours.</p>
<p>The problem is even more pronounced for startup founders. They are often betting their financial future on their new business or so wildly passionate about the problem they solve that it’s next to impossible to “turn it off.”</p>
<h3 id="3-external-pressure">3. External Pressure</h3>
<p>Building a business requires making promises to a lot of people. As a founder, you’re telling employees that they’ll have a job, you’re telling customers that you’ll deliver value, and you’re promising your family that all this sacrifice will be worth it someday. These pressures are amplified when startups raise money because venture-funded startups have a board who might watch the founders closely to make sure they’re working as hard as possible to get them the return they expect.</p>
<p>Once these external pressures are internalized, companies tend to build a culture that encourages long hours. Managers then reward employees who put in the most time, and employees come to expect these working conditions. You can see this vicious cycle most prominently in <a href="https://abovethelaw.com/2019/12/the-biglaw-firm-where-associates-are-putting-in-the-most-working-hours/">law and consulting</a> where billable hours are a badge of honor.</p>
<h3 id="4-gatekeeping">4. Gatekeeping</h3>
<p>This might be controversial, but I believe that part of the reason startups tout their commitments to long hours is as a form of gatekeeping.</p>
<p>When you require everyone in your company to work 60+ hour weeks, you exclude people who have a family at home, kids they need to pick up from school, or mental health issues. This disproportionately hurts minorities, single parents, older workers, and <a href="https://www.telegraph.co.uk/news/2016/06/16/working-long-hours-harms-women-but-protects-men-study-shows/">women</a>, and it’s part of the reason we see fewer underrepresented groups in startups.</p>
<p>This isn’t always the case though. I remember meeting a CTO at another startup early in my career who quit work at 3 pm every day to pick up his kids. This <a href="https://www.karllhughes.com/posts/startup-culture">set a culture at the company</a>, which was totally different from my experience.</p>
<p><img src="https://i.imgur.com/ApmhcQ1.png" alt="Long hours is a form of gatekeeping"></p>
<h2 id="you-need-appropriate-pacing">You Need Appropriate Pacing</h2>
<p>All this pressure will eventually lead to burnout somewhere within your startup. Whether the founder cracks under pressure or you can’t retain employees because of the rigorous pace, it often hurts the organization in the long run.</p>
<p>Short sprints of long hours are possible - and in my experience, often necessary in a startup - but growing a successful company takes years, not months. No number of hours worked can shortcut this fact.</p>
<blockquote>
<p>“If you really look closely, most overnight successes took a long time.” – Steve Jobs</p>
</blockquote>
<p>The problem is that many founders get pressured into thinking short-term. Whether it’s investors pushing them to show traction required for future funding rounds or unfulfilled promises to customers, founders often overcommit themselves to a point where a sustainable pace is impossible.</p>
<h2 id="tips-for-startup-founders">Tips for Startup Founders</h2>
<p>At different stages of a company’s life, different levels of commitment are required. But, no matter what you’re working on, it’s not productive to keep grinding away month after month without giving yourself a break.</p>
<p>Similarly, if you have employees, <strong>you can’t expect them to selflessly spend their lives working long hours and holidays just to help you fulfill your dream.</strong> You <em>can</em> push people to a certain point, but learning how to do so in a productive and worthwhile way is one of the best things you can learn if you want to retain your best employees.</p>
<p>Here are four things I’ve learned about startup work hours and pacing as a founder:</p>
<h3 id="1-dont-push-people-without-a-purpose">1. Don’t Push People Without a Purpose</h3>
<p>It’s tempting as an entrepreneur to always want more from your employees, but just because you feel a sense of urgency in managing your business doesn’t mean every one of your employees will feel the same. <strong>One of the most frustrating things for employees is being pushed to work harder, longer hours without a clear purpose that ties directly into their performance.</strong></p>
<p>Similarly, if you do expect employees to work 60+ hours per week, be upfront with them about this expectation. There are plenty of young go-getters (I was one of them) who don’t mind putting in long hours but be aware that you might be missing some highly-qualified, experienced candidates with this approach.</p>
<h3 id="2-more-work-is-not-a-solution-to-poor-planning">2. More Work is Not a Solution to Poor Planning</h3>
<p>If one department in your company is behind on a deadline, figure out how you can work with them to either adjust expectations, change their requirements, or estimate better next time. Just because you or someone in your organization planned poorly does not mean it’s a good idea to push everyone else to the breaking point.</p>
<h3 id="3-listen-to-your-employees">3. Listen to Your Employees</h3>
<p>Even more important than avoiding situations that stress your employees is listening to them when they are feeling the pressure. If you’re cultivating the right atmosphere at the office, don’t be surprised when someone shows up to tell you that they can’t keep up the pace for another 60 hour week.</p>
<h3 id="4-trust-your-people">4. Trust Your People</h3>
<p>Finally, as an entrepreneur, you have to be able to trust your employees. If you don’t, you need to ask yourself why you hired them or find a way to replace them. When you trust your employees, you’ll know that when they insist they’re working too much, they really are.</p>
<p><em>Note: I’ve added a few books on this topic in <a href="https://www.karllhughes.com/posts/startup-books">my list of the best startup books for founders here</a>.</em></p>
<h2 id="questions-for-potential-startup-employees">Questions for Potential Startup Employees</h2>
<p>While the bulk of an early-stage startup’s culture is defined by the founders, employees and managers have a lot of influence on working hours and pacing too. If you’re being hired by a startup and you’re not sure about what the culture is like, here are some questions you can ask to get a better sense:</p>
<h3 id="1-how-many-hours-per-week-is-typical">1. How Many Hours Per Week is Typical?</h3>
<p>You can ask this question without sounding lazy. I always tell employees this expectation, but if you’re in an interview with a startup and they don’t say it explicitly, it’s better to know what they expect than to be surprised on your first day.</p>
<h3 id="2-do-you-have-typical-working-hours">2. Do You Have Typical Working Hours?</h3>
<p>Again, with more companies going remote, many are also giving employees the option to work their own hours. I have customers in Europe, Australia, Asia, and the US, so even though I try not to work more than 40 hours per week, I don’t have a very “typical” schedule.</p>
<h3 id="3-do-people-hang-out-outside-of-work-much">3. Do People Hang Out Outside of Work Much?</h3>
<p>I asked this question in interviews with startups because I wanted to know the dynamic of …</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/working-hours">https://www.karllhughes.com/posts/working-hours</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/working-hours</link>
            <guid isPermaLink="false">hacker-news-small-sites-25548423</guid>
            <pubDate>Sun, 27 Dec 2020 02:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google’s API Design Standard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25548258">thread link</a>) | @dkharrat
<br/>
December 26, 2020 | https://google.aip.dev/general | <a href="https://web.archive.org/web/*/https://google.aip.dev/general">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="jump-content">
          


<section id="aip-main">
  
  <h3 id="meta">Meta</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>1</td>
        <td>
          <a href="https://google.aip.dev/1">AIP Purpose and Guidelines</a>
          </td>
      </tr>
      <tr>
        <td>2</td>
        <td>
          <a href="https://google.aip.dev/2">AIP Numbering</a>
          </td>
      </tr>
      <tr>
        <td>200</td>
        <td>
          <a href="https://google.aip.dev/200">Precedent</a>
          </td>
      </tr>
      <tr>
        <td>8</td>
        <td>
          <a href="https://google.aip.dev/8">AIP Style guide</a>
          </td>
      </tr>
      <tr>
        <td>9</td>
        <td>
          <a href="https://google.aip.dev/9">Glossary</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="process">Process</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>100</td>
        <td>
          <a href="https://google.aip.dev/100">API Design Review FAQ</a>
          </td>
      </tr>
      <tr>
        <td>205</td>
        <td>
          <a href="https://google.aip.dev/205">Beta-blocking changes</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="resource-design">Resource Design</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>121</td>
        <td>
          <a href="https://google.aip.dev/121">Resource-oriented design</a>
          </td>
      </tr>
      <tr>
        <td>122</td>
        <td>
          <a href="https://google.aip.dev/122">Resource names</a>
          </td>
      </tr>
      <tr>
        <td>123</td>
        <td>
          <a href="https://google.aip.dev/123">Resource types</a>
          </td>
      </tr>
      <tr>
        <td>124</td>
        <td>
          <a href="https://google.aip.dev/124">Resource association</a>
          </td>
      </tr>
      <tr>
        <td>126</td>
        <td>
          <a href="https://google.aip.dev/126">Enumerations</a>
          </td>
      </tr>
      <tr>
        <td>128</td>
        <td>
          <a href="https://google.aip.dev/128">Declarative-friendly interfaces</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>156</td>
        <td>
          <a href="https://google.aip.dev/156">Singleton resources</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="operations">Operations</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>131</td>
        <td>
          <a href="https://google.aip.dev/131">Standard methods: Get</a>
          </td>
      </tr>
      <tr>
        <td>132</td>
        <td>
          <a href="https://google.aip.dev/132">Standard methods: List</a>
          </td>
      </tr>
      <tr>
        <td>133</td>
        <td>
          <a href="https://google.aip.dev/133">Standard methods: Create</a>
          </td>
      </tr>
      <tr>
        <td>134</td>
        <td>
          <a href="https://google.aip.dev/134">Standard methods: Update</a>
          </td>
      </tr>
      <tr>
        <td>135</td>
        <td>
          <a href="https://google.aip.dev/135">Standard methods: Delete</a>
          </td>
      </tr>
      <tr>
        <td>136</td>
        <td>
          <a href="https://google.aip.dev/136">Custom methods</a>
          </td>
      </tr>
      <tr>
        <td>151</td>
        <td>
          <a href="https://google.aip.dev/151">Long-running operations</a>
          </td>
      </tr>
      <tr>
        <td>231</td>
        <td>
          <a href="https://google.aip.dev/231">Batch methods: Get</a>
          </td>
      </tr>
      <tr>
        <td>233</td>
        <td>
          <a href="https://google.aip.dev/233">Batch methods: Create</a>
          </td>
      </tr>
      <tr>
        <td>234</td>
        <td>
          <a href="https://google.aip.dev/234">Batch methods: Update</a>
          </td>
      </tr>
      <tr>
        <td>235</td>
        <td>
          <a href="https://google.aip.dev/235">Batch methods: Delete</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="fields">Fields</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>140</td>
        <td>
          <a href="https://google.aip.dev/140">Field names</a>
          </td>
      </tr>
      <tr>
        <td>203</td>
        <td>
          <a href="https://google.aip.dev/203">Field behavior documentation</a>
          </td>
      </tr>
      <tr>
        <td>141</td>
        <td>
          <a href="https://google.aip.dev/141">Quantities</a>
          </td>
      </tr>
      <tr>
        <td>142</td>
        <td>
          <a href="https://google.aip.dev/142">Time and duration</a>
          </td>
      </tr>
      <tr>
        <td>143</td>
        <td>
          <a href="https://google.aip.dev/143">Standardized codes</a>
          </td>
      </tr>
      <tr>
        <td>144</td>
        <td>
          <a href="https://google.aip.dev/144">Repeated fields</a>
          </td>
      </tr>
      <tr>
        <td>145</td>
        <td>
          <a href="https://google.aip.dev/145">Ranges</a>
          </td>
      </tr>
      <tr>
        <td>146</td>
        <td>
          <a href="https://google.aip.dev/146">Generic fields</a>
          </td>
      </tr>
      <tr>
        <td>147</td>
        <td>
          <a href="https://google.aip.dev/147">Sensitive fields</a>
          </td>
      </tr>
      <tr>
        <td>148</td>
        <td>
          <a href="https://google.aip.dev/148">Standard fields</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>216</td>
        <td>
          <a href="https://google.aip.dev/216">States</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="design-patterns">Design Patterns</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>152</td>
        <td>
          <a href="https://google.aip.dev/152">Jobs</a>
          </td>
      </tr>
      <tr>
        <td>153</td>
        <td>
          <a href="https://google.aip.dev/153">Import and export</a>
          </td>
      </tr>
      <tr>
        <td>154</td>
        <td>
          <a href="https://google.aip.dev/154">Resource freshness validation</a>
          </td>
      </tr>
      <tr>
        <td>155</td>
        <td>
          <a href="https://google.aip.dev/155">Request identification</a>
          </td>
      </tr>
      <tr>
        <td>157</td>
        <td>
          <a href="https://google.aip.dev/157">Partial responses</a>
          </td>
      </tr>
      <tr>
        <td>158</td>
        <td>
          <a href="https://google.aip.dev/158">Pagination</a>
          </td>
      </tr>
      <tr>
        <td>159</td>
        <td>
          <a href="https://google.aip.dev/159">Reading across collections</a>
          </td>
      </tr>
      <tr>
        <td>160</td>
        <td>
          <a href="https://google.aip.dev/160">Filtering</a>
          </td>
      </tr>
      <tr>
        <td>162</td>
        <td>
          <a href="https://google.aip.dev/162">Resource Revisions</a>
          </td>
      </tr>
      <tr>
        <td>163</td>
        <td>
          <a href="https://google.aip.dev/163">Change validation</a>
          </td>
      </tr>
      <tr>
        <td>164</td>
        <td>
          <a href="https://google.aip.dev/164">Soft delete</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>165</td>
        <td>
          <a href="https://google.aip.dev/165">Criteria-based delete</a>
          </td>
      </tr>
      <tr>
        <td>210</td>
        <td>
          <a href="https://google.aip.dev/210">Unicode</a>
          </td>
      </tr>
      <tr>
        <td>214</td>
        <td>
          <a href="https://google.aip.dev/214">Resource expiration</a>
          </td>
      </tr>
      <tr>
        <td>217</td>
        <td>
          <a href="https://google.aip.dev/217">Unreachable resources</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="compatibility">Compatibility</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>180</td>
        <td>
          <a href="https://google.aip.dev/180">Backwards compatibility</a>
          </td>
      </tr>
      <tr>
        <td>181</td>
        <td>
          <a href="https://google.aip.dev/181">Stability levels</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="polish">Polish</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>191</td>
        <td>
          <a href="https://google.aip.dev/191">File and directory structure</a>
          </td>
      </tr>
      <tr>
        <td>192</td>
        <td>
          <a href="https://google.aip.dev/192">Documentation</a>
          </td>
      </tr>
      <tr>
        <td>193</td>
        <td>
          <a href="https://google.aip.dev/193">Errors</a>
          </td>
      </tr>
      <tr>
        <td>194</td>
        <td>
          <a href="https://google.aip.dev/194">Automatic retry configuration</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="protobuf">Protocol buffers</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>127</td>
        <td>
          <a href="https://google.aip.dev/127">HTTP and gRPC Transcoding</a>
          </td>
      </tr>
      <tr>
        <td>213</td>
        <td>
          <a href="https://google.aip.dev/213">Common components</a>
          </td>
      </tr>
      <tr>
        <td>215</td>
        <td>
          <a href="https://google.aip.dev/215">Common component versions</a>
          </td>
      </tr>
      </tbody>
  </table>
  
</section>

        </section></div>]]>
            </description>
            <link>https://google.aip.dev/general</link>
            <guid isPermaLink="false">hacker-news-small-sites-25548258</guid>
            <pubDate>Sun, 27 Dec 2020 02:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflecting on London Underground's Overheating]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25548128">thread link</a>) | @CalvinBarrows
<br/>
December 26, 2020 | https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/ | <a href="https://web.archive.org/web/*/https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content" role="main">
	
<article id="post-32595">

<section>
	<img width="1000" height="580" src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/RB-Calvin-1000x580.jpg" alt="Calvin Barrows">	     
<section>
<span>3rd August 2020</span>
</section>   
	
            <!-- Share buttons by mashshare.net - Version: 3.7.2--><p>Calvin Barrows has written an article for railbusinessdaily.com about the root cause(s) of overheating in certain metro systems, using London Underground’s ‘Tube’ Network as an example.</p>
<p>Calvin is a Chartered Engineer, latterly retired. His work focused on forensic engineering, to establish the mechanisms of structural and mechanical failures; then continuing as an engineering manager, within the rail industry.</p>
<p>Sylvia Telatycka is co-author and linguist, who with Calvin runs a small but successful property development and rental business.</p>
<p>“This guest article aims to encourage a wider discussion around our hypothesis as to the root cause(s) of overheating in certain metro systems, using London Underground’s ‘Tube’ Network as an example.</p>
<p>Rather than go into complicated thermodynamic formulae to demonstrate the credible science upon which this theory is based, we have described in simple terms the comparable heat generation and heat exchange processes at work, to clarify how these affect this historic Tube network. This is important because, in the earliest days of the London Tube, overheating was simply not an issue…. but WHY….?</p>
<p>In the first instance, we need to understand clearly what the problem is. Paraphrasing Charles Kettering: a problem well defined is half solved and mindful of that, we took the basic premise of the Tube overheating and framed a series of questions to help identify the problem.</p>
<p>1. When does overheating happen?</p>
<p>2. Do ALL metros/subways overheat?</p>
<p>3. Why might some metros/subways overheat, and some might not?</p>
<p>4. And why are these questions relevant to London’s network?</p>
<p>5. How can this overheating be mitigated?</p>
<p>Few would disagree that the Tube overheats but understanding WHEN and WHERE it happens is most revealing. In winter passengers mainly travel bundled up in their winter coats and the saloons are heated. In summer, heavy clothing is shed – indeed some passengers have been known to travel in swimwear.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35.png" alt="" width="598" height="320" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35.png 598w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35-300x161.png 300w" sizes="(max-width: 598px) 100vw, 598px"></p>
<p>In the above graph i, London’s mean surface ambient air temperatures, averaged over a 30 year period, show a clear increase from approximately -5°C in the winter to around +30°C in the summer.</p>
<p>Interestingly, the following graph ii represents the results of TfL’s temperature monitoring within the underground network, for both the deep tube and sub-surface lines. The TfL temperature variations not only confirm passengers’ subjective perception, they also mimic the curve of temperature data above and demonstrate conclusively that underground network temperatures align with the external seasonal temperatures.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17.png" alt="" width="587" height="298" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17.png 587w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17-300x152.png 300w" sizes="(max-width: 587px) 100vw, 587px"></p>
<p>In the course of our research we looked at different types of rail networks, categorising them as follows because they all perform differently in relation to overheating:-</p>
<p>1. Metro train networks – which run ONLY underground.</p>
<p>2. Trains networks – which run predominately overground.</p>
<p>3. Metro train networks – which run both overground and underground.</p>
<p>Underground-only networks like Glasgow’s or Warsaw’s are not affected by the overground conditions, so there is little seasonal variation in train and network temperatures. Their ambient underground temperature remains about 16°C – unlike the wide temperature range the TfL data above show for London’s Tube network. Underground-only networks irrefutably demonstrate that operational heat such as braking, being generated year-round, is NOT a significant cause of metro networks overheating. Furthermore, since passengers are not being exposed to overheating they remain comfortable and safe.</p>
<p>Overground-only trains are cool in winter and therefore heated. However, in summer they will overheat, unless they are proactively cooled, usually by air-conditioning, though AC deals with the symptoms, not underlying causes, and it is environmentally unfriendly. Whilst AC is technically sound as long as it can discharge the exhaust heat to free air, if it does not work for some reason…. What then? There have been at least three incidents over the last 15 years where power failures compromised the AC, triggering saloon temperature rises to 46°C; with distressed passengers fainting from heat exhaustion, and others desperate enough to smash windows and even to try and break through emergency doors.</p>
<p>Which brings us neatly to MIXED metro networks like London’s Tube, which run both overground and underground, to see why this overheating is NOT restricted to the overground areas of these networks. The reason behind this apparent contradiction is that these mixed networks are, thermodynamically speaking, open systems – ones that freely exchange energy and matter with their surroundings – where:-</p>
<p>1. The free exchange of energy is a regular transfer of air in and out of the tunnels; and</p>
<p>2. The free exchange of mass is a regular travel of hot, loaded trains in and out of the tunnel.</p>
<p>TfL engineers continue to focus on ‘base load’, aka the operational heat, which by definition is year-round, so this can never explain the seasonal nature of the problem. Saloon AC is not a viable solution here, expelling more heat into an already overheated tunnel. We need to be thinking more holistically: rather than the ‘Cooling the Tube Project’ it should be the ‘Cooling the Whole Tube Network in the Summer Project’.</p>
<p>Clearly the root cause of this 100+ year old seasonal problem is the SUN. However, its sheer power to affect every aspect of a network like London’s Tube has been significantly underestimated. In a thermodynamic nutshell:-</p>
<p>1. Radiation from the sun is short wave energy in the form of light, which on striking the earth or a solid object increases their internal energy.</p>
<p>2. This internal energy is in the form of heat and is then re-radiated from the surface of the earth (and solid objects) as long wave heat energy, which in turn warms the ambient air.</p>
<p>The unintentional consequence of the above process in a thermodynamically open system is that hot ambient air plus heat from solar irradiated trains travelling on the surface is carried into the tunnels.</p>
<p>In the context of mixed metro networks, when overground, all external surfaces of the train exposed to the sun, including wheels and bogies, are being directly irradiated. Like any heat conductive surface, the irradiated train body get hot. The sun’s shortwave radiation readily shines through the window glass; then striking the internal surfaces is converted into heat within those materials. However, heat being longwave radiation and, struggling to pass back out through the window glass, is trapped – an unintended ‘greenhouse’ effect. Finally, the undercarriage components consist of massive chunks of metal – usually black – with the ability to absorb immense amounts of heat.</p>
<p>Furthermore, while rail buckling is a familiar problem, the knock-on effects of the sun on the track beds have never really figured in the context of the network overheating. The whole of the track bed including the rails is absorbing and reflecting heat. So, when trains pass over it, this heat is then reflected outwards and upwards into the wheels, bogies, underside of the carriages, the brakes and traction motors. These get super-heated, not so much through operation, but principally because they are in an overheated environment.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34.png" alt="" width="548" height="282" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34.png 548w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34-300x154.png 300w" sizes="(max-width: 548px) 100vw, 548px"></p>
<p>The above concept graph predicts the build-up of solar irradiation acting on a train, starting early in the day and repeatedly travelling (in this example) the length of the Central Line. The train is irradiated when overground and dissipates a large proportion of that heat load during the underground sections of the journey. However, each irradiated train movement passing throughout the entire network compounds the effect of previous trains, elevating tunnel temperatures even more as the day progresses – rudimentary monitoring has shown saloon temperatures overground typically increase by up to 6°C in 30 mins between Leyton and Epping around 4.30-5.00pm on a summer afternoon.</p>
<p>While the piston-drag effect as the train passes in and out of the tunnel portals will draw in hot ambient air, probably contributing a small amount of heat to the underground sections, compared to the storage-radiator capacity of the train itself, cumulatively dissipating within the tunnel, it is unlikely to be that significant.</p>
<p>Having identified the root causes of overheating and the contributing factors, the task of managing the overheating in the tunnels is actually quite simple – deal with the overheating of the trains on the surface BEFORE THEY ENTER THE TUNNELS.</p>
<p>There are four obvious radiant barrier measures. These are solar-reflective paints (typical surface temperature reductions of 20⁰C) and Low E glass (absorbing some 80% less solar radiation than standard glass), both of which could be easily retroactively applied to existing trains and become the standard for new rolling stock. Then there is green planting on tracks, with its low heat absorption properties compared to ballast and rails. Once in place maintenance costs should be minimal and the benefits considerable. Lastly effective stabling of off-peak trains, providing appropriate solar shade AND ventilation, is imperative.</p>
<p>In conclusion, and most importantly, it should not be forgotten that overheating saloons will adversely affect passenger health and safety. In London’s Tube, this problem would be exacerbated in a ‘stalled-train event’ underground. Passengers overheated in a carriage, within an overheated tunnel, is a potentially fatal matter, especially when temperatures rise, as they often do in summer, to 40°C or higher and where passengers can do nothing but wait until LU staff can direct their escape.”</p>
<p>i Meteoblue (2020) Climate London Basel Switzerland www.meteoblue.com https://www.meteoblue.com/en/weather/historyclimate/climatemodelled/london_united-kingdom_2643743</p>
<p>ii Transport for London (July 2018) Average monthly evening peak temperatures by line London: Transport for London …</p></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/">https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/</a></em></p>]]>
            </description>
            <link>https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25548128</guid>
            <pubDate>Sun, 27 Dec 2020 01:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start Contributing to Open Source Software]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25547724">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now | <a href="https://web.archive.org/web/*/https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure> <figcaption>I know you want to. - Photo by Author </figcaption></figure> <p>You might not be aware of it, but you use some form of open source software every single day.</p> <p>Every time you start an app on your phone or launch a program on your computer, you profit from the code that someone has written for free.</p> <p>WordPress, the largest and most well-known content management system, is used by <a href="https://w3techs.com/technologies/details/cm-wordpress" rel="nofollow">38% of all websites</a> worldwide. It is open source and free to use.</p> <p>Linux is powering <a href="https://w3techs.com/technologies/details/os-linux" rel="nofollow">30% of all websites</a> globally. It is open source and free to use.</p> <p>These are just two examples out of a myriad of projects which were created to solve a problem or serve a use case.</p> <p>These projects became highly popular as communities formed around them. They tried to deliver the best product possible in terms of user experience, stability, security, and more.</p> <p>But not only the usage of open source projects is rising. The participation in the open source movement as a whole is growing as well.</p> <p>According to the <a href="https://octoverse.github.com/" rel="nofollow">State of the Octoverse report</a> by GitHub, out of more than 40 million developers on GitHub, 10 million new&nbsp;users joined in 2019 alone!</p> <p>The open source movement is growing quickly and you should become a part of it too.</p> <p>Whenever I see a new update for my operating system or new software releases of tools that I actively use every day, it makes me smile. I enjoy the thought of products continuously getting better and more sophisticated.</p> <p>Do you feel the same way?</p> <p>Here is why I am convinced that you should start contributing to open source software right now.</p> <h2>You can learn a lot from the source code</h2> <p>Since the source code in open source projects is available for anyone to read, that means that a large number of developers can battle-test and improve a project.</p> <p>Developers point out privacy or security issues, update the documentation, and improve source code to the newest web development standards all the time.</p> <p>Especially when you go through the code of projects with hundreds or even thousands of contributors, you can gain immense knowledge about best practices and code quality.</p> <p>Not only is reviewing the code itself a learning experience, but also the structure and folder hierarchy in larger projects is well thought-out and works well in the long run.</p> <h2>You will work with the smartest people</h2> <p>Compared to a company that has a limited number of employees to work on feature requests and bug fixes, you have the brightest minds working in open source development.</p> <p>In my imagination, I see it as swarm intelligence, which can solve every problem that arises.</p> <p>The more people that join a community, the better a project can scale. It can be like a buzzing beehive, where you could have pull requests to a codebase from users all around the world 24/7, non-stop.</p> <p>A good example is the well-known code editor <a href="https://github.com/microsoft/vscode" rel="nofollow">Visual Studio Code</a> which got very popular with a total of 1,200+ contributors on GitHub.</p> <p>You won’t see a single day without any pull requests on GitHub and the monthly release cycles always bring out new amazing features.</p> <p>When you participate in a project and submit a pull request, you will receive extremely helpful feedback from highly experienced maintainers. You can then implement that feedback to grow as a developer.</p> <h2>Your own code could be used globally</h2> <p>Since some software development projects are used by millions of users daily, it can be very rewarding to see your own code helping so many people.</p> <p>I wrote lint rules for the JavaScript projects called <a href="https://github.com/sindresorhus/eslint-plugin-unicorn" rel="nofollow">eslint-plugin-unicorn</a> and <a href="https://github.com/sveltejs/svelte" rel="nofollow">svelte</a>. It’s a great feeling knowing that my pull request will improve the code quality of many developers all around the world.</p> <p>From my personal experience, it is also motivating to get positive feedback in the form of a thankful comment.</p> <h2>Open source projects are inclusive</h2> <p>A great advantage of free open source software is that no one is excluded from using the product because they can’t afford it.</p> <p>While some open source projects cost money to use, most do not.</p> <p>Also, when you’re contributing to a project on GitHub, many of the bigger repositories have a code of conduct. These make sure that every contributor feels welcome and accepted in a project.</p> <h2>Projects are starting to become sustainable</h2> <p>The main goal of a company is to become profitable - which often leads to questionable decisions. But open source software focuses on solving the needs of its users as the highest priority.</p> <p>Most projects are entirely volunteer-supported, and project maintainers will unfortunately never see any financial reward. But there are great ways nowadays that you can help make these projects sustainable.</p> <p>With websites like <a href="https://opencollective.com/" rel="nofollow">OpenCollective</a>&nbsp;or <a href="https://github.com/sponsors" rel="nofollow">GitHub Sponsors</a>, you can donate to speed up the development of projects that you like.</p> <p>Personally, I think that it would be great if every company donated at least a small sum to open source software projects because they profit from these tools daily. Such support would reduce the stress for a lot of maintainers and some could even take up the work full-time.</p> <h2>How to contribute to open source</h2> <p>Contributing to open source development sounds more scary than it really is. There are plenty of projects out there on GitHub which encourage first time contributors and newbies to take action by labeling issues as “Good first issue”, “Beginner friendly” or “Help wanted”.</p> <p>Don’t know where to start?</p> <p>Ask yourself: what is an application that you enjoy using every day and where you would want to give back?</p> <p>It can be as simple as searching for that application on GitHub and looking through the open issues.</p> <p>It doesn’t have to be a code contribution, either - you can also help out by creating a pull request to update the documentation, fix typos that you find, or by doing a thorough code review.</p> <p>The <code>README.md</code> file of a project usually includes a passage of how to contribute.</p> <p>If you decide to contribute to a project, I recommend reading my article about&nbsp;<a href="https://markushatvan.com/blog/contributing-to-open-source-projects-the-right-way">Contributing To Open Source Projects The Right Way</a>. It’s a detailed step-by-step guide about the contribution workflow.</p> <p>I wrote it to be very beginner friendly, so don’t worry about becoming overwhelmed. You will be able to find your first project and submit a contribution in no time!</p> <h2>Wrapping up</h2> <p>It always impressed me that everyone in the world can join an open source software project and work on it.</p> <p>And open source software only works as a collaborative effort. The goal is to produce the best product or service without compromising on important factors like stability, security, or user privacy.</p> <p>I hope you understand the importance of open source software and that you value its benefits. No matter what your reasons are for giving back to the open source community, just know that you are highly appreciated!</p> <p>Many projects can only thrive with support and contributions from developers like you.</p> <h2>Helpful resources</h2> <ul><li><a href="https://octoverse.github.com/" rel="nofollow">The State of the Octoverse</a></li> <li><a href="https://opensource.com/resources/what-open-source" rel="nofollow">What is open source?</a></li> <li><a href="https://clearcode.cc/blog/why-developers-contribute-open-source-software/" rel="nofollow">What Motivates a Developer to Contribute to Open-Source Software?</a></li></ul> <div><p><b>If you liked this post, share it:</b></p> <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Facebook"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z" key="path-0"></path> </svg></a> <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now&amp;title=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now&amp;summary=The%20open%20source%20movement%20is%20growing%20quickly%20and%20you%20should%20become%20a%20part%20of%20it%20too.&amp;source=LinkedIn" rel="noopener noreferrer" target="_blank" title="Share on LinkedIn"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 448 512" width="21"> <path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z" key="path-0"></path> </svg></a> <a href="https://twitter.com/intent/tweet?text=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now&amp;url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Twitter"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" key="path-0"></path> </svg></a> <a href="https://www.reddit.com/submit?url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now&amp;title=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now" rel="noopener noreferrer" target="_blank" title="Share on Reddit"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z" key="path-0"></path> </svg></a> <a href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Pinterest"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 496 512" width="23.25"> <path d="M496 256c0 137-111 248-248 248-25.6 0-50.2-3.9-73.4-11.1 10.1-16.5 25.2-43.5 30.8-65 3-11.6 15.4-59 15.4-59 8.1 15.4 31.7 28.5 56.8 28.5 74.8 0 128.7-68.8 128.7-154.3 0-81.9-66.9-143.2-152.9-143.2-107 0-163.9 71.8-163.9 150.1 0 36.4 19.4 81.7 50.3 96.1 4.7 2.2 7.2 1.2 8.3-3.3.8-3.4 5-20.3 6.9-28.1.6-2.5.3-4.7-1.7-7.1-10.1-12.5-18.3-35.3-18.3-56.6 0-54.7 41.4-107.6 112-107.6 60.9 0 103.6 41.5 103.6 100.9 0 67.1-33.9 113.6-78 113.6-24.3 0-42.6-20.1-36.7-44.8 7-29.5 20.5-61.3 20.5-82.6 0-19-10.2-34.9-31.4-34.9-24.9 0-44.9 25.7-44.9 60.2 0 22 7.4 36.8 7.4 36.8s-24.5 103.8-29 123.2c-5 21.4-3 51.6-.9 71.2C65.4 450.9 0 361.1 0 256 0 119 111 8 248 8s248 111 248 248z" key="path-0"></path> </svg></a></div>   </article></div>]]>
            </description>
            <link>https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547724</guid>
            <pubDate>Sun, 27 Dec 2020 00:40:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API pagination design]]>
            </title>
            <description>
<![CDATA[
Score 338 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25547716">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://solovyov.net/blog/2020/api-pagination-design/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/api-pagination-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>Returning all results for a given query could be a challenge for an API, especially if there are thousands of results. It puts a load on a server, on a client, on a network, and often is unnecessary. Thus people invented pagination.</p>
<p>The usual way to paginate is an offset or a page number. So you make a request like that:</p>
<pre><code>GET /api/products?page=10
{"items": [...100 products]}
</code></pre>
<p>and to continue you make a request like that:</p>
<pre><code>GET /api/products?page=11
{"items": [...another 100 products]}
</code></pre>
<p>In case of a simple offset it’ll look like <code>?offset=1000</code> and <code>?offset=1100</code> — it’s the same old soup, just reheated. It’ll either go straight into SQL query like <code>OFFSET 1000 LIMIT 100</code> or will be multiplied by page size (that <code>LIMIT</code> value). In any case, it’s a suboptimal solution, since every database has to skip that 1000 rows. And to skip them it needs to identify them. It does not matter if it’s PostgreSQL, or ElasticSearch, or MongoDB, it’ll have to order them, count them, and throw them away.</p>
<p>This is a kind of work which no one needs. But it repeats over and over again since it’s <em>easy</em> to implement — you directly map your API onto your query to a database.</p>
<p>What do you do then? We could look at what databases do! They have this concept, called <a href="https://en.wikipedia.org/wiki/Cursor_(databases)">cursor</a> — it’s a pointer to a row. So you can say to a database “return me 100 rows after <strong>that</strong> one”. And it’s much easier for a database to do since there is a good chance that you’ll identify the row by a field with an index. And suddenly you don’t need to fetch and skip those rows, you’ll go directly past them.</p>
<p>An example:</p>
<pre><code>GET /api/products
{"items": [...100 products],
 "cursor": "qWe"}
</code></pre>
<p>API returns an (opaque) string, which you can use then to retrieve the next page:</p>
<pre><code>GET /api/products?cursor=qWe
{"items": [...100 products],
 "cursor": "qWr"}
</code></pre>
<p>Implementation-wise there are many options. Generally, you have some ordering criteria, for example, product id. In this case, you’ll encode your product id with some reversible algorithm (let’s say <a href="https://hashids.org/">hashids</a>). And on receiving a request with the cursor you decode it and generate a query like <code>WHERE id &gt; :cursor LIMIT 100</code>.</p>
<p>Just a little performance comparison, look at how offsets work:</p>
<pre><code>=# explain analyze select id from product offset 10000 limit 100;
                                                           QUERY PLAN                                                            
---------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1114.26..1125.40 rows=100 width=4) (actual time=39.431..39.561 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1274406.22 rows=11437243 width=4) (actual time=0.015..39.123 rows=10100 loops=1)
 Planning Time: 0.117 ms
 Execution Time: 39.589 ms
</code></pre>
<p>And how where works:</p>
<pre><code>=# explain analyze select id from product where id &gt; 10000 limit 100;
                                                          QUERY PLAN                                                          
------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..11.40 rows=100 width=4) (actual time=0.016..0.067 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1302999.32 rows=11429082 width=4) (actual time=0.015..0.052 rows=100 loops=1)
         Filter: (id &gt; 10000)
 Planning Time: 0.164 ms
 Execution Time: 0.094 ms
</code></pre>
<p>That is a difference of several orders of magnitude! Of course, the actual numbers depend on a size of a table, on your filters and on a store implementation. There <a href="https://use-the-index-luke.com/no-offset">a great article</a> with more technical information - there are slides embedded, see slide 42 for performance comparison.</p>
<p>Of course, nobody orders products by an id — you usually order them by some relevancy (and then by id as a <a href="https://stackoverflow.com/a/17330992/46854">tie breaker</a>). In the real world, you’ll have to look at your data to determine what to do. Orders can be ordered by id (as it’s monotonically increasing). Wishlist items can be ordered like that as well — by wishlisting time. In our case products come from ElasticSearch, which naturally supports this cursor stuff.</p>
<p>One deficiency you can see is that it’s impossible to generate a “previous page” link with a stateless API. So in case of a user-facing pagination, if it’s important to have prev/next and “go directly to page 10” buttons there is no way around this offset/limit stuff. But in other cases using cursor-based pagination can greatly improve performance, especially on really big tables with really deep pagination.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/api-pagination-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547716</guid>
            <pubDate>Sun, 27 Dec 2020 00:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to backup and decrypt Signal for iPhone message history]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25547699">thread link</a>) | @jonnytran
<br/>
December 26, 2020 | https://cight.co/backup-signal-ios-jailbreak/ | <a href="https://web.archive.org/web/*/https://cight.co/backup-signal-ios-jailbreak/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>I started using Signal 5 years ago as I became increasingly conscious of my data footprint. Around the same time, I closed my Facebook and Instagram accounts, and later, my Google Account.</p><h2 id="the-problem-with-signal">The problem with Signal</h2><p>Signal makes it very difficult, and in most cases, impossible, for one to back up, export, or migrate message data. The Signal team insists these restrictions are meant to protect users’ privacy. However, backup and migration policies differ for each official Signal client and sometimes contradict each other.</p><p>For example, while iOS offers no official backups process, Android backups are built into the app. At the same time, iOS users can migrate their data to a new device (as long as their phone number hasn’t changed), but this is impossible on Android. Meanwhile, decrypting messages from the desktop client is trivial, but linking one’s phone and desktop client only syncs messages forward in time.</p><h2 id="why-export-signal-s-message-history">Why export Signal's message history</h2><p>Because it’s my fucking data.</p><p>The road to exporting my data was long, frustrating and filled with dead ends – it took over a year to get here. What's paradoxical is that someone else's phone turned out to be the key to my data. </p><p>In recent years, I moved most of my conversations to Signal, including those with family and close friends. Shortly after we started dating, I asked my partner to switch to Signal, and we’ve used it exclusively ever since. At some point, I thought it would be nice to export our conversation history – a sort of time capsule of our relationship. “Easy,” I thought. I was wrong.</p><p>Since we started dating, I had switched from a OnePlus 2 to an iPhone XS Max. And since migrating from Android to iOS isn’t possible, part of our conversation history was locked on my old phone. Jailbreaking the iPhone was out of the question since my version of iOS had not been jailbreaken. The Signal Desktop client could have offered an easy avenue to decrypt our chat history, but there was a period of several months during which I had not linked my iPhone to the Signal desktop client.</p><p>I opened a <a href="https://community.signalusers.org/t/ios-backups-through-the-desktop-client/8123">thread about this in the Signal Community Forum</a> in June of 2019. It quickly became apparent that backing up my Signal data would be an uphill battle. </p><p>Luckily, my partner had an iPhone 7, which she recently replaced with a company phone. Her old iPhone contained our entire message history in one place and was easy to jailbreak. Jackpot.</p><p>One important lesson I learned during this process:<strong> to ensure access to your conversation history, install the Desktop client and link it to your mobile device as soon as you start using Signal. </strong>The Signal database and encryption key are both accessible on your computer, allowing for easy decryption. Linking the desktop client later will only sync messages forward in time from the moment the devices are linked.</p><h2 id="tips-to-increase-your-chances-of-exporting-your-signal-database">Tips to increase your chances of exporting your Signal database</h2><p>If you haven’t linked the desktop client and extracting the iOS database is your only option, this guide is for you. If you've decided to embark upon this journey, here's some advice. </p><h3 id="stop-updating-ios">Stop updating iOS</h3><p>Your best chance of jailbreaking iOS is on older firmware versions. Turn off automatic updates and decline prompts to update iOS.</p><h3 id="backup-shsh-blobs-with-every-new-ios-update">Backup SHSH blobs with every new iOS update</h3><p><a href="https://en.wikipedia.org/wiki/SHSH_blob">SHSH blobs</a> are the digital signatures that Apple generates and uses to personalize iOS firmware files for each iOS device. Apple only signs firmware updates for a limited time after release. Having these signatures handy allows one to install versions of iOS after Apple stops signing them – like when a jailbreak becomes available for that version. In some cases, you may be able to downgrade iOS to a previous version.</p><p>Backup SHSH blobs every time Apple releases a new version of iOS (e.g., 14.0, 14.1, 14.1.1). I personally use the <a href="https://github.com/airsquared/blobsaver">blobsaver</a> app, but <a href="https://tsssaver.1conan.com/v2/">TSS Saver</a> is a popular alternative.</p><h3 id="learn-about-jailbreaking-and-stay-up-to-date-on-developments">Learn about jailbreaking and stay up to date on developments</h3><p>Developers and hackers are constantly working to break the security of iOS, and new methods to jailbreak iPhones are frequently made public. Stay informed on jailbreak releases by following the <a href="https://www.reddit.com/r/jailbreak/">/r/jailbreak subreddit</a>.</p><p>This <a href="https://docs.google.com/spreadsheets/d/11DABHIIqwYQKj1L83AK9ywk_hYMjEkcaxpIg6phbTf0/edit#gid=1014970938">exhaustive list of jailbreak compatibility</a> by device and iOS version is also a great resource.</p><p>It's also useful to understand the difference between <a href="https://www.theiphonewiki.com/wiki/Untethered_jailbreak">untethered</a>, <a href="https://www.theiphonewiki.com/wiki/Semi-untethered_jailbreak">semi-untethered</a>, <a href="https://www.theiphonewiki.com/wiki/Semi-tethered_jailbreak">semi-tethered</a>, and <a href="https://www.theiphonewiki.com/wiki/Tethered_jailbreak">tethered</a> jailbreaks.</p><h3 id="recognize-that-this-may-not-work">Recognize that this may not work</h3><p>Depending on your iPhone, you might never be able to jailbreak it or extract Signals decryption key from the iOS Keychain. Apple is making it increasingly difficult to jailbreak iOS devices – improvements to hardware and software are leaving fewer cracks for hackers to exploit.</p><p>Ok, let's get our hands dirty. </p><h2 id="how-to-maybe-backup-signal-for-iphone">How to (maybe) backup Signal for iPhone </h2><p>This guide explains how I was able to backup and extract data from Signal's encrypted SQLite database on an iPhone 7 with iOS 13.6.1. </p><h3 id="prerequisites">Prerequisites </h3><ul><li>Physical access to the iPhone with Signal still installed</li><li>An original iPhone cable</li><li>A Mac or Linux computer</li><li>Patience and a bit of luck</li></ul><p>Shell environments will be differentiated as such. </p><pre><code>// Host machine
$ &lt;command&gt;

// iPhone 
root# &lt;command&gt;</code></pre><h3 id="step-1-jailbreak-ios">Step 1: Jailbreak iOS</h3><p>For iOS 13.6.1 on an iPhone 7, I used <strong>checkra1n</strong> which offers a straight forward semi-tethered jailbreak. Depending on the iPhone device and version of iOS, a jailbreak may or may not be available. </p><p>See this <a href="https://docs.google.com/spreadsheets/d/11DABHIIqwYQKj1L83AK9ywk_hYMjEkcaxpIg6phbTf0/edit#gid=1014970938">updated list of iOS jailbreaks</a> for device compatibility and instructions. </p><h3 id="step-2-ssh-into-the-iphone">Step 2: SSH into the iPhone </h3><p>Cydia usually comes with OpenSSH installed and enabled, allowing shell access over IP or USB. If SSH access isn't activated, launch Cydia and install OpenSSH. </p><p><strong>As always, the root password on iOS is <code>alpine</code>.</strong></p><p>If the iPhone and the host machine are on the same network, SSH into the phone using its IP address. It may be found in the phone's WiFi settings. </p><pre><code>$ ssh root@[iphone ip] -p 22</code></pre><p>If SSH over the air isn't possible, USB may be an alternative. However, this involves enabling a proxy service on the host machine.</p><p>First, install <em><em>libimobiledevice</em></em> on the host machine. </p><pre><code>$ brew install libimobiledevice</code></pre><p>Then, edit <em><em>com.usbmux.iproxy.plist</em></em> and append the following XML to the file. </p><pre><code>$ nano ~/Library/LaunchAgents/com.usbmux.iproxy.plist</code></pre><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;
&lt;plist version="1.0"&gt;
&lt;dict&gt;
&lt;key&gt;Label&lt;/key&gt;
&lt;string&gt;com.usbmux.iproxy&lt;/string&gt;
&lt;key&gt;ProgramArguments&lt;/key&gt;
&lt;array&gt;
&lt;string&gt;/usr/local/bin/iproxy&lt;/string&gt;
&lt;string&gt;2222&lt;/string&gt;
&lt;string&gt;22&lt;/string&gt;
&lt;/array&gt;
&lt;key&gt;RunAtLoad&lt;/key&gt;
&lt;true/&gt;
&lt;key&gt;KeepAlive&lt;/key&gt;
&lt;true/&gt;
&lt;/dict&gt;</code></pre><p>And finally, launch the proxy on the host machine. </p><pre><code>$ launchctl load ~/Library/LaunchAgents/com.usbmux.iproxy.plist</code></pre><p>It should now be possible to SSH into the iPhone over USB on port <code>2222</code>.</p><pre><code>$ ssh root@localhost -p 2222</code></pre><h3 id="step-3-install-required-packages">Step 3: Install required packages </h3><p>Once logged into to the iPhone's shell, install the following packages as they will come in handy. </p><pre><code>root# apt install zip unzip nano wget</code></pre><h3 id="step-4-backup-the-signal-data-directory">Step 4: Backup the Signal data directory</h3><p><strong>Locate Signal's data directory</strong></p><p>Much like macOS, iOS stores application data in a <em>Library</em>-like directory. In iOS&nbsp;13, its located here <code>/private/var/mobile/Containers/Shared/AppGroup/</code>. </p><p>Signal's data directory contains the encrypted SQLite database file in <code>./grdb/signal.sqilte</code> and attachments, such as images and videos in <code>./Attachments</code>.</p><p>The data directory may be found by searching the filesystem for Signal's encrypted database file, <code>signal.sqlite</code>.</p><pre><code>root# find / -type f -iname "signal.sqlite"</code></pre><p>That should return something which looks like this:<br><code>/private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/grdb/signal.sqlite</code> </p><p>The Signal directory is: <code>/private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/</code></p><p><strong>Zip the Signal directory</strong></p><p>It is recommended to zip the entire directory, not only the database file, as it also contains images and other message attachments. This archive can reach several gigabytes.</p><pre><code>root# cd /private/var/mobile/Containers/Shared/AppGroup/
root# zip -r signal-backup.zip &lt;Signal directory&gt;

# ex: zip -r signal-backup.zip /private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/</code></pre><p><strong>Retrieve the backup on the host machine</strong></p><p>In a new terminal session on the host machine, use <code>scp</code> to copy the backup. </p><pre><code>$ scp -P 22 root@localhost:/private/var/mobile/Containers/Shared/AppGroup/signal-backup.zip ~/</code></pre><p>Once complete, verify that the backup has fully transferred by unpacking it.</p><p>This is the most complex part of this operation and it helps to have a basic understanding of core iOS development concepts.</p><p><strong>Understanding iOS Entitlements </strong></p><p>From the <a href="https://developer.apple.com/documentation/bundleresources/entitlements">Apple Developer Documentation</a>: </p><blockquote>An entitlement is a right or privilege that grants an executable particular capabilities. For example, an app needs the HomeKit Entitlement — along with explicit user consent — to access a user’s home automation network. An app stores its entitlements as key-value pairs embedded in the code signature of its binary executable.</blockquote><p><strong>Enter Keychain Dumper</strong></p><p>We will use <a href="https://github.com/ptoomey3/Keychain-Dumper"><strong>Keychain-Dumper</strong></a> to attempt extracting the Signal encryption key. It requires entitlements to access Keychain data for any particular app. </p><p>Reading through Keychain-Dumper's GitHub issues, I learned that entitlements changed in iOS 13.5 – prior to this version, an application <a href="https://github.com/ptoomey3/Keychain-Dumper/issues/52#issuecomment-638174691">could be given wildcard entitlements</a>. Changes in 13.5 made it such that apps need specific entitlements. Thankfully, it's possible to update an executable's entitlements, even as a binary.</p><p>The <code>keychain_dumper</code> binary included in its <a href="https://github.com/ptoomey3/Keychain-Dumper">GitHub repo</a> has wildcard entitlements. We'll need to update them in order to give it permission to decrypt the Signal key.</p><p><strong>Install Keychain Dumper on the iPhone</strong></p><p>Back on the iPhone, download and extract the <a href="https://github.com/ptoomey3/Keychain-Dumper/releases/tag/1.0.0">keychain_dumper binary</a>, and move it to <code>/usr/bin</code>.</p><pre><code>root# wget https://github.com/ptoomey3/Keychain-Dumper/releases/download/1.0.0/keychain_dumper-1.0.0.zip
root# unzip keychain_dumper-1.0.0.zip
root# mv keychain_dumper /usr/bin</code></pre><p><strong>Update <em>keychain_dumper</em>'s …</strong></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cight.co/backup-signal-ios-jailbreak/">https://cight.co/backup-signal-ios-jailbreak/</a></em></p>]]>
            </description>
            <link>https://cight.co/backup-signal-ios-jailbreak/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547699</guid>
            <pubDate>Sun, 27 Dec 2020 00:36:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Is Lying to You and You're Listening]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25547602">thread link</a>) | @haltingproblem
<br/>
December 26, 2020 | https://www.younglingfeynman.com/essays/misleadingdata | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/misleadingdata">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-d54917c3f4c66758a8bd"><div><p>I really believe you have to be careful with data.</p><p>There’s this assumption that if you split test, the data tells you what’s better.</p><p>But that’s clearly not always the case.</p><p>Why?</p><p>This is actually a bigger idea than it seems.</p><p>Many companies that have a data-first approach don’t realize they’re reasoning off of an assumption and treat it like an axiom. [1]</p><p>But optimize long enough and everything becomes the equivalent of BuzzFeed or porn.</p><p>Clickbait, sex, drama, and superficialness. Being everything to everyone and nothing to no one.</p><p>Groupon’s quality went down the drain because Mason’s employees told him sending more emails per day increased revenue.</p><p>The deals became ever lower in quality and users got annoyed.</p><p>There was a time where people<strong> could not wait</strong> to get an email from Groupon. They had killer deals. They had hilarious copywriters. Even if you didn’t buy, getting an email was a treat. But now that it has been properly sterilized to please spineless, risk-averse shareholders, and optimized for maximum quarterly revenue, can you think of a single person that feels that way anymore? Not one person? Groupon clearly has lost its soul, its essence. Mason said in an interview (can’t recall the source) that he wondered if Groupon was meant to be an extraordinary company, just for a smaller market. It certainly would have made it easier to build the company according to his vision rather than something that needed to please the shareholders that needed an IPO to get a return.</p><p>In the early days you had the GOATS like Reid Hoffman (founder LinkedIn), Max Levchin (Paypal and Affirm), and the likes answering questions. Now it’s some 14yr old telling you about the opportunity of a lifetime: screencasting stories from Reddit, having the speech to text tool read them, turn it into a video and put it on YouTube. And then…? Millions I guess?</p><p>It went from THE place to get high-quality courses from knowledgeable instructors to the flea-market of cheap knock-offs and fake guru business opportunity courses. While you can find quality courses there, the overall quality has badly degraded. The best instructors aren’t incentivized to create a course because your $1000 course containing 3 decades of experience will sell for $9.99 of which you’ll get $2.50. So if you actually have something to offer, you’ll go somewhere else, leaving mainly the type of people that game the system in order to make a quick buck.</p><p>People used to LOVE Facebook with a vengeance. Now I have 80 notifications, 40 of which are new friend suggestions of people I’ve never met, 20 are strangers that sent out a blast to get likes for their new page, 17 are events, and 3 are birthdays. [2]</p><p>Oh yeah… and not 1 is actually relevant to me.&nbsp;You can fool a user only so many times before you’ve essentially trained them to ignore you.</p><p><em>They started implementing the same dark patterns with their DM. You get notifications for being friends for a certain time and when you accept a new friend.</em></p><p>In its search for endless optimization, the platform has become bloated and just plain annoying. I can’t think of a single person in my cohort (and younger cohorts) that use FB as much or more as 10 years ago.&nbsp;</p><p>The current demographic appears to be the same type of people that use Bing over Google, or Explorer over Chrome. Late adopters that are sticky to defaults.</p><p>So be careful when optimizing. Remember the quantification bias! </p><p><em>Discussed in </em><a href="https://www.younglingfeynman.com/essays/paradigm"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a></p><p>Just because something is easy to measure doesn’t mean it’s insightful. Just because something can’t be measured easily doesn’t mean it isn’t.</p><p>Remember that business is part art part science: <a href="https://www.younglingfeynman.com/essays/artofbusiness" target="_blank">The Art Of Business, Where Science And Business Depart</a>.</p><p>[1]  I <a href="https://www.younglingfeynman.com/essays/comedy">made the point before</a> when it comes to certain areas that are sufficiently complex (e.g. statistics, data science, economics), you either want no one or a person with extraordinarily deep expertise. </p><p>Interesting piece on the fraud that’s going on in Data Science: <a href="https://logicmag.io/intelligence/interview-with-an-anonymous-data-scientist/"><em>The Smart, the Stupid, and the Catastrophically Scary: An Interview with an Anonymous Data Scientist</em></a></p><p>What you don’t want is someone that knows enough to bullshit you but not enough to get it right. An indicator that you might have the right person is the phrase: ‘‘I’m not sure’’ or ‘‘ it depends on…’’. In these fields, the vast majority of so-called experts add no value at best or negative value at worst.</p><p>[2] This is what I admired so much about Systrom’s and Krieger’s Instagram. Their almost zen-like essentialism. No bloating, no fluff, trying very hard to take away things as they did about adding things. How many new features did they launch in a month before their Facebook acquisition? How many new features does IG launch now per month? </p><p>I’m not saying adding new features is bad. I’m also not saying that a company shouldn’t scale. The point I’m making is that entropy is real. It’s much easier for your product to become worse, than it is to become better. So if that’s not a core focus, it probably won’t happen by accident.</p><p>But scale and improvements in user love (which follow from a better service/product) are not mutually exclusive. Apple provides a data point. Especially during the Jobs reign. </p><p><em>More on this in the essay series: </em><a href="https://www.younglingfeynman.com/essays/deeplove"><em>Do You Have Customers Who Deeply Love You?</em></a><em> </em></p></div></div></div>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/misleadingdata</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547602</guid>
            <pubDate>Sun, 27 Dec 2020 00:20:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The cost of a Ruby threads leakage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25547555">thread link</a>) | @mooreds
<br/>
December 26, 2020 | https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/ | <a href="https://web.archive.org/web/*/https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547555</guid>
            <pubDate>Sun, 27 Dec 2020 00:10:57 GMT</pubDate>
        </item>
    </channel>
</rss>
