<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 16 Jul 2020 08:17:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 16 Jul 2020 08:17:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Purism-Librem13v4]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830046">thread link</a>) | @luu
<br/>
July 14, 2020 | https://anarc.at/hardware/laptop/purism-librem13v4/ | <a href="https://web.archive.org/web/*/https://anarc.at/hardware/laptop/purism-librem13v4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>The <a href="https://puri.sm/products/librem-13/">Purism Librem 13</a> is a 13" laptop that's similar to the
Macbook Air but slightly heavier and thicker, from what I
understand. I have the <code>v4</code> means it's the fourth hardware version of
the device. This is the latest incarnation of the <a href="https://anarc.at/hardware/angela/">angela</a>
node.</p>

<p>TL;DR: I recommend people avoid the Purism brand and products. I find
they have questionable politics, operate in a "libre-washing" fashion,
and produce unreliable hardware. Will not buy again.</p>






<ul>
<li>Operating system: PureOS</li>
<li>TPM: Included</li>
<li>Battery life: Roughly 7 to 9 hours (actual: more like 6h)</li>
<li>Processor: Core i7 7500U (Kabylake)</li>
<li>Display: 13.3" 1920×1080</li>
<li>Graphics: Intel HD Graphics 620</li>
<li>Memory: Up to 32GB, DDR4 at 2133 MHz</li>
<li>Storage: 2.5" SATA + NVMe-capable M.2 slots</li>
<li>Chassis: Black anodized aluminium</li>
<li>Webcam: 720p 1.0 megapixel</li>
<li>Dimensions: 325×219×18mm</li>
<li>Weight: 1.4kg</li>
<li>Wireless: Atheros 802.11n w/ Two Antenna</li>
<li>Radio hardware killswitch: Yes</li>
<li>Mic and cam killswitches: Yes</li>
<li>Audio port: 1 headphone/line output jack</li>
<li>USB ports: 2 USB 3.0 Ports (1 type C, data transfer only)</li>
<li>External monitor output: 1 HDMI Port (4K capable @ 30Hz max)</li>
<li>Card reader: Yes, 2-in-1 SD/MMC</li>
<li>Backlit keyboard: Yes</li>
<li>Touch interface: Elantech Multitouch Trackpad</li>
<li>Thermal design: Low noise fan (actual: not really, quite noisy when
all CPUs are maxed)</li>
</ul>


<p>The machine came with a 250GB Crucial SSD drive with PureOS
pre-installed, even if I ordered it without storage.</p>

<h2 id="semi-standard-power-connector"><a name="index1h2"></a>Semi-standard power connector</h2>

<p>The power connector is <a href="https://learn.sparkfun.com/tutorials/connector-basics/power-connectors">somewhat standard</a>: 19V DC on a 5.5mm
sleeve with 2.5 positive pin, with a <a href="https://en.wikipedia.org/wiki/IEC_60320#C5/C6_coupler">C5/C6 cable</a> for the AC side
(as opposed to the more standard C13/C14 coupler, mind you). I was
able to find a "universal 19V adapter" for ~60$ at a local store that
also supported other barrel connectors.</p>

<p>It would be better if the laptop would charge through USB-C,
naturally, as <em>that</em> is slowly becoming the standard for charging
computing devices, but that will have to do for now.</p>

<h2 id="good-monitor"><a name="index2h2"></a>Good monitor</h2>

<p>The monitor shipped with the Librem is actually quite good by my
standards (1920x1080 / 1080p / FullHD). It does mean messing around
with <a href="https://wiki.debian.org/MonitorDPI">HiDPI</a> settings which I haven't quite figured out yet.</p>

<p><a href="https://vincent.bernat.ch/en/blog/2018-4k-hidpi-dual-screen-linux">This post</a> seems to have good resources. From what I understand,
the resolution of the screen is actually 166dpi, which takes some
configuring to display properly. This can be computed from the aspect
ratio (16:9), the resolution (1920x1080) and the diagonal of the
screen (13.3"). According to <a href="https://www.sven.de/dpi/">this calculator</a>, this is the
formula:</p>

<pre><code>Display size: 11.59" × 6.52" = 75.59in² (29.44cm × 16.56cm = 487.64cm²) at 165.63 PPI, 0.1534mm dot pitch, 27434 PPI² 
</code></pre>

<p>All this does make my old monitor (which I found in the basement) look
like crap. So I need to find a <a href="https://forums.puri.sm/t/suitable-external-monitor-for-librem-13/5627">new monitor</a>, arguably not a
problem with the Librem per se of course...</p>

<p>It seems the Librem can drive 1440p, so not "4K UHD" (3840x2160), but
"QHD" (2560x1440) which should be more than enough.</p>

<h2 id="liberated-boot"><a name="index3h2"></a>Liberated boot</h2>

<p>The Purism folks did a pretty awesome job at liberating their
BIOS. They run their own version of coreboot they call
<a href="https://docs.puri.sm/PureBoot.html">Pureboot</a>. In theory, it should be easier to setup a trusted,
<a href="http://wiki.debian.org/SecureBoot">SecureBoot</a> but in practice I have yet to set that up.</p>

<p>I did try to configure the laptop with an encrypted <code>/boot</code>, but that
didn't go so well. First, I get a double password prompt: once in
<code>grub</code> and once in the <code>initramfs</code>. But more annoying is the <code>grub</code>
prompt has no retry: if you fail, you drop in the rescue shell which
is really impractical.</p>

<p>(Update: that is, of course, not specific to Purism or PureOS, but a
limitation in grub itself.)</p>

<p>Finally, Pureboot doesn't support encrypted <code>/boot</code> so it actually
makes it <em>harder</em> to implement trusted boot.</p>

<p>The coreboot stuff needs to be updated, and instructions are available
<a href="https://puri.sm/coreboot/">on the Purism website</a>.</p>

<h2 id="excellent-linux-support"><a name="index4h2"></a>Excellent Linux support</h2>

<p>On top of the liberated BIOS, it must be said the device has
<em>excellent</em> support for free operating systems. <em>Every</em> device on the
machine has full support in the Linux kernel, even the "older" version
in Debian stretch (Linux 4.9). No binary blobs, no proprietary
drivers, even for wifi.</p>

<p>That is just awesome. It's the first device, in a long time, that
gives me this freedom, so it should be acknowledged and celebrated.</p>

<p>Update: I still have some <code>non-free</code> packages installed:</p>

<ul>
<li><p>the Intel CPU firmware package (<a href="http://packages.debian.org/intel%2Dmicrocode">intel-microcode</a>)</p></li>
<li><p>I also use some "non-free" documentation packages (<a href="http://packages.debian.org/doc%2Drfc">doc-rfc</a>, <a href="http://packages.debian.org/emacs%2Dcommon%2Dnon%2Ddfsg">emacs-common-non-dfsg</a>, <a href="http://packages.debian.org/make%2Ddoc">make-doc</a>)</p></li>
<li><p>Bluetooth requires <a href="http://packages.debian.org/firmware%2Datheros">firmware-atheros</a></p></li>
</ul>


<p>When building the <code>initramfs</code>, there are warnings about the <code>i915</code>
graphics controller, which is solved by installing the <a href="http://packages.debian.org/firmware%2Dmisc%2Dnonfree">firmware-misc-nonfree</a> package, but the graphics card works without
the firmware. Apparently, the warnings are harmless and indeed PureOS
fixed <a href="https://tracker.pureos.net/T362">the bug</a> by simply <a href="https://source.puri.sm/pureos/core/initramfs-tools/commit/005ca5b834fa7ee44bb913d74b4ff2aa542fc9d1">disabling all such warnings</a>.3</p>

<p>The Debian-specific stuff is also documented in <a href="https://wiki.debian.org/InstallingDebianOn/Purism/Librem%2013">the Debian wiki</a>.</p>

<h2 id="good-speakers"><a name="index5h2"></a>Good speakers</h2>

<p>The builtin speakers sound great.</p>



<p>I have a few issues with the device.</p>

<h2 id="weird-keyboard-layout"><a name="index6h2"></a>Weird keyboard layout</h2>

<p>The <a href="https://forums.puri.sm/t/keyboard-layout-unable-to-recognize-pipe/2022">keyboard layout is strange</a>: the key above <kbd>enter</kbd>,
instead of sending <kbd>\</kbd> or <kbd>|</kbd>, sends
"chevrons". This is due to the Purism folks expecting you to pick the
"US international" keyboard instead of the "US" keyboard, which is a
very strange pick, as the "US" keyboard seems pretty standard. The
workaround is to drop this in your <code>udev</code> configuration, say in
<code>/etc/udev/hwdb.d/90-purism-pipe-symbol-fix.hwdb</code>:</p>

<pre><code>evdev:atkbd:dmi:bvn*:bvr*:bd*:svnPurism:pnLibrem13v4*
 KEYBOARD_KEY_56=backslash
</code></pre>

<p>Then running:</p>

<pre><code>sudo systemd-hwdb update
sudo udevadm trigger
</code></pre>

<p>The keyboard layout, in general, is a little unique: the sound buttons
are split across the <kbd>F4</kbd> key (mute) and
<kbd>-</kbd>/<kbd>=</kbd> (volume up/down keys) for some reason.</p>

<p>The <kbd>PrtSc</kbd> key <a href="https://forums.puri.sm/t/does-alt-sysrq-work-on-librem-laptops/5290/9">can be as SysRq</a> but is <em>backwards</em>
(<kbd>ScrLk</kbd> <kbd>PrtSc</kbd>) to their usual order
(<kbd>PrtSc</kbd> <kbd>ScrLk</kbd>).</p>

<h2 id="limited-usb-c-port"><a name="index7h2"></a>Limited USB-C port</h2>

<p>The USB-C port <a href="https://forums.puri.sm/t/is-hdmi-over-usb-c-possible-on-13v2/2020">does not support video</a> which makes it limited to
charging and data transfer. It can also not charge the laptop itself,
as there's a separate power connector, losing many of the benefits
usually associated with USB-C.</p>

<p>Ideally, a USB-C port might be used as a universal docking port: one
wire to plug and you have power, video, audio, and USB for keyboard
and mouse. Unfortunately, I'm still stuck with about 4 wires to plugin
when I come into the office, something I was hoping to avoid. People
have <a href="https://forums.puri.sm/t/please-recommend-a-port-replicator-docking-station/1115">looked for a dock station</a> without success.</p>

<h2 id="shipping-delays-doa"><a name="index8h2"></a>Shipping delays, DOA</h2>

<p>I waited almost four weeks to have my laptop delivered. Presumably
this was due to a <a href="https://forums.puri.sm/t/where-was-purism-moving/5799/">warehouse move</a> but I found that communication
about the issue could have been better. Worse: the laptop was <a href="https://forums.puri.sm/t/librem-13v3-bricked/5714/19?u=anarcat">dead on
arrival</a> (DOA) so I had to return it, adding another week delay for
getting an actual working laptop. FedEx even charged me for the return
even though Purism actually issued a shipping label, something I still
haven't quite resolved.</p>

<p>Update: I ended up paying over 260$ in shipping fees to Fedex, in the
end. I first paid around 70$ for the first laptop sent, then Fedex
sent me <em>another</em> 200$ bill for the <em>second</em> laptop. Purism were
unable to help me with this issue and Fedex has been totally useless
as well. I've tried to reach to both organizations to get around those
fees but the time wasted waiting on hold and support has outgrown the
possible savings I could to by not paying the damn bill, so I just
paid it now.</p>

<h2 id="bright-leds-not-accessible-when-lid-closed"><a name="index9h2"></a>Bright LEDs, not accessible when lid closed</h2>

<p>There are three leds on the top right of the keyboard: one for wifi,
battery and power. They are very bright and even though they can
technically be dimmed, the firmware is not open so there's <a href="https://forums.puri.sm/t/is-there-a-way-to-dim-the-leds-on-the-13-v2/1172">no way to
dim the LEDs</a>.</p>

<h2 id="no-ethernet-port"><a name="index10h2"></a>No ethernet port</h2>

<p>That was a deal breaker for me originally, but I changed my
mind. First, I don't need gigabit transfer speeds that often. Then my
office doesn't have wired connectivity yet, so it is not that
useful. Plus, I can afford to have a USB dongle there with a gigabit
ethernet port, indeed, I already have one of those USB hubs. So not
that big of a deal.</p>

<h2 id="libre-washing"><a name="index11h2"></a>Libre-washing</h2>

<p>I have found Purism's commitment to free hardware and free software to
be questionable. While, yes, they try to provide a <a href="#liberated-boot">liberated boot</a>
and coreboot-based BIOS, that BIOS is not free software. At best they
"neuter" the Intel Management Engine, but you still require non-free
firmware to operate a Librem Computer, from the CPU down to the
Bluetooth and Wifi hardware. Even if that is a very common pattern on
laptops and phone, it is a huge disconnect with the "purity" and
"freedom" narrative on their website.</p>

<p>For example, the replacement for the Librem 13, called Librem 14,
claims to be:</p>

<blockquote><p><strong>The first 14″ laptop designed to protect your digital life</strong></p>

<p>Ultra-portable workstation laptop that was designed chip-by-chip,
line-by-line, to respect your rights to privacy, security, and
freedom.</p></blockquote>

<p>Yet it still ships with Intel processors, known for a large variety of
fundamental security issues that are part of the hardware design,
which Intel refuses to fix. That it ships <a href="https://puri.sm/coreboot/">coreboot</a> on top of that
is besides the point: coreboot, as shipped by Purism, is not open
source, or at least ships proprietary blobs.</p>

<p>Compare this with the work System76 has been doing in recent
times. While they brand themselves as just a company shipping Linux
laptops, they <a href="https://blog.system76.com/post/187072707563/the-new-firmware-manager-updating-firmware-across">work with the de-facto standard LVFS</a> (even though
that is a <a href="https://blog.system76.com/post/173801677358/system76-and-lvfs-what-really-happened">bumpy ride</a>), actually <a href="https://blog.system76.com/post/612315972866637824/a-look-back-at-manufacturing">design and prototype their own
hardware</a>, and <a href="https://opensource.com/article/20/1/system76-open-source-firmware">liberated their keyboard microcontroller</a>. They
have even started <a href="https://blog.system76.com/post/186655523269/open-firmware-and-more-news-from-july">working on an open Thunderbolt
microcontroller</a>. And while those might sound like small things
compared to liberating the CPU firmware, I will point out that they
actually <em>succeed</em> in completely liberating those components, while
Purism, in the <em>years</em> they have supposedly been working on those
projects, have only managed to reuse (and, to be fair, improve on) the
work <em>others</em> have done to neutralize the IME.</p>

<p>What has Purism done, in the meantime? Neutralized IME. That's
it. They have not published <em>anything</em> on LVFS. Even closed-source
companies like <a href="https://fwupd.org/lvfs/vendors/#logitech">Logitech</a>, <a href="https://fwupd.org/lvfs/vendors/#synaptics">Synaptics</a>, <a href="https://fwupd.org/lvfs/vendors/#hp-ws">HP</a> and <a href="https://fwupd.org/lvfs/vendors/#dell">Dell</a>
ship their updates on LVFS. Purism <a href="https://fwupd.org/lvfs/vendors/#purism">has a test account</a> and work
has been <a href="https://forums.puri.sm/t/submit-firmware-to-linux-vendor-firmware-service-lvfs-for-easy-updating/4731">stalled for years now</a>.</p>

<h2 id="bullshit-anti-interdiction"><a name="index12h2"></a>Bullshit anti-interdiction</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anarc.at/hardware/laptop/purism-librem13v4/">https://anarc.at/hardware/laptop/purism-librem13v4/</a></em></p>]]>
            </description>
            <link>https://anarc.at/hardware/laptop/purism-librem13v4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830046</guid>
            <pubDate>Tue, 14 Jul 2020 09:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Rust NIFs for Elixir with Rustler]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23829651">thread link</a>) | @marcoow
<br/>
July 14, 2020 | https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/ | <a href="https://web.archive.org/web/*/https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>Rustler is a fantastic project built to make writing Rust NIFs a simple process;
and the upcoming v0.22 release will provide a much cleaner syntax to do so. The
library handles encoding and decoding Rust values into Erlang terms, catches
Rust panics before they unwind to C and <em>should</em> make it impossible to crash the
BEAM from a Rust NIF.</p>
<h2 id="getting-started-with-rustler">Getting started with Rustler</h2>
<p>One of my first forays into Rust-implemented NIFs was while building a
micro-library providing Base64 encoding and decoding, creatively named
<a href="https://github.com/niklaslong/base64" target="_blank" rel="noopener">base64</a>. It's utterly pointless as that
functionality comes built-in to Elixir but I wanted to start with something
simple. On the plus side, this meant I could easily compare the performance of
the NIF version to the Elixir implementation which can be found in the
<a href="https://hexdocs.pm/elixir/Base.html" target="_blank" rel="noopener"><code>Base</code> module</a>.</p>
<p>The library consists of two functions: <code>encode/2</code> and <code>decode/2</code> and it's using
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64</a> to do the heavy
lifting in the NIFs. Let's walk through how this all works.</p>
<p>To get started, we need a new mix project with rustler installed as a
dependency.</p>
<pre><code>mix new base64

mix deps.get
mix rustler.new
</code></pre><p>Let's explore the project's resulting structure (I've left out the usual Elixir
files and directories and focused on <code>lib</code> and <code>native</code>):</p>
<pre><code>.
â”œâ”€â”€ lib
â”‚   â””â”€â”€ base64.ex
â””â”€â”€ native
    â””â”€â”€ base64_nif
        â”œâ”€â”€ Cargo.lock
        â”œâ”€â”€ Cargo.toml
        â”œâ”€â”€ README.md
        â””â”€â”€ src
            â””â”€â”€ lib.rs</code></pre><ul>
<li><code>lib</code> will contain Elixir code (like any standard mix project).</li>
<li><code>base64.ex</code> will contain the stubs to our NIFs. This is the Elixir module the
NIF module will be registered to.</li>
<li><code>native</code> will be home to the Rust code. In fact, a cargo package has been
created within this directory (in this case named <code>base64_nif</code>).</li>
<li><code>lib.rs</code> will contain the NIFs.</li>
</ul>
<p>The Rust NIFs are compiled and linked into a shared library loaded by Erlang
code at runtime. Elixir (or Erlang) implementations of the functions are also
necessary. These are usually minimal stubs defining the name and arity of the
NIFs and serve as fallback implementations if the NIFs aren't loaded. Let's
start with the Elixir stubs.</p>
<pre><code>

<span><span>defmodule</span> <span>Base64</span></span> <span>do</span>
  <span>use</span> Rustler, <span>otp_app:</span> <span>:base64</span>, <span>crate:</span> <span>"base64_nif"</span>

  <span>@spec</span> decode(binary, atom) :: binary
  <span><span>def</span> <span>decode</span></span>(_b64, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span>@spec</span> encode(binary, atom) :: binary
  <span><span>def</span> <span>encode</span></span>(_s, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span><span>defp</span> <span>error</span></span>(), <span>do:</span> <span>:erlang</span>.nif_error(<span>:nif_not_loaded</span>)
<span>end</span></code></pre><p>The first line is configuration and lets Rustler know what Rust crate to compile
for the Elixir module.</p>
<p>As mentioned above, <code>decode/2</code> and <code>encode/2</code> don't actually implement any
decoding or encoding; they simply call <code>error/0</code> if the NIFs can't be found.
However, the names and the arguments must match in both the Rust and Elixir
implementations. Both functions take in a <code>binary</code> to be encoded or decoded and
an <code>atom</code> for configuration as different character sets that can be used
(url-safe, without padding, etc...). The default is fittingly set to
<code>:standard</code>. The Rust NIFs are implemented as follows.</p>
<pre><code>

<span>use</span> base64;
<span>use</span> rustler::Atom;

<span>mod</span> atoms {
    rustler::atoms! {
      crypt,
      imap_map7,
      standard,
      standard_no_pad,
      url_safe,
      url_safe_no_pad,
    }
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>decode</span></span>(b64: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    <span>let</span> bytes = base64::decode_config(b64, config).expect(<span>"decode failed: invalid b64"</span>);

    <span>String</span>::from_utf8(bytes).unwrap()
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>encode</span></span>(s: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    base64::encode_config(s.as_bytes(), config)
}

<span><span>fn</span> <span>match_config</span></span>(option: Atom) -&gt; base64::Config {
    
}

rustler::init!(<span>"Elixir.Base64"</span>, [decode, encode]);</code></pre><p>The last line is interesting: <code>rustler::init</code> is a procedural macro that allows
the use of <code>#[rustler::nif]</code> to annotate functions to be wrapped as NIFs. It
takes in the name of the Elixir module in which the stubs are defined (in this
case <code>"Elixir.Base64"</code>) and an array containing the names of the functions
annotated as NIFs (in this case <code>[decode, encode]</code>). In short, this links
everything together.</p>
<p>The use statements at the top of the file are importing the
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64 crate</a> (<code>base64</code>)
mentioned earlier, which we'll use for encoding and decoding, and the
<code>rustler::Atom</code> type which allows us to represent an Elixir/Erlang <code>atom</code> in
Rust. Both the <code>rustler</code> and <code>base64</code> crates have been added to the <code>Cargo.toml</code>
dependencies.</p>
<p>The <code>rustler::atoms</code> macro defines Rust functions that return Erlang atoms; in
this case, the possible options for the <code>encode/2</code> and <code>decode/2</code> functions.</p>
<p>Finally, we come to the NIF definitions. The functions take in a <code>String</code> and a
<code>rustler::Atom</code>, and return a <code>String</code>. This is consistent with the Elixir
stubs, as are the names. In this case, the conversions between Rust values and
Elixir terms are conveniently handled by Rustler. However, for more complex
types, this may need to be implemented manually.</p>
<h2 id="how-does-it-compare-to-the-elixir-implementation">How does it compare to the Elixir implementation?</h2>
<p>Rust is fast. Really fast. This was my set-up (using
<a href="https://github.com/bencheeorg/benchee" target="_blank" rel="noopener">benchee</a>):</p>
<pre><code>Operating System: macOS
CPU Information: Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
Number of Available Cores: 4
Available memory: 16 GB
Elixir 1.10.2
Erlang 22.3.2</code></pre><p>I used <em>hello world</em> as the short string and Sarah Kayâ€™s poem
<em><a href="https://www.youtube.com/watch?v=0snNB1yS3IE" target="_blank" rel="noopener">B (If I Should Have a Daughter)</a></em>
as the longer string.</p>
<p>Decoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif decode           175.74 K
Elixir/Erlang decode        4.35 K - 40.37x slower +224.03 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif decode           953.17 K
Elixir/Erlang decode      555.63 K - 1.72x slower +0.75 Î¼s</code></pre><p>Encoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif encode           203.14 K
Elixir/Erlang encode        6.95 K - 29.23x slower +138.98 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif encode           941.14 K
Elixir/Erlang encode      615.62 K - 1.53x slower +0.56 Î¼s</code></pre><p>As the data to encode or decode becomes larger, the overhead of creating the
NIFs becomes smaller and the gains in speed are impressive. These results were
obtained with fairly small data and so the potential performance gains possible
by leveraging Rust NIFs when dealing with CPU-intensive tasks are exciting.</p>
<p>I left out the memory usage comparisons but the Elixir/Erlang implementations
used 3-5x more memory than the NIFs.</p>
<h2 id="tldr-rustler-makes-it-easy-to-implement-nifs">TL;DR: Rustler makes it easy to implement NIFs</h2>
<p>Other than the <code>#[rustler::nif]</code> function annotations and the <code>rustler::init</code>
call, nothing more is required to implement Rust NIFs with Rustler. The
boilerplate and the complexities of translating Rust values to Erlang terms
being handled by the library, there's little resistance to leveraging the power
of Rust in Elixir/Erlang.</p>

  </div></div>]]>
            </description>
            <link>https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829651</guid>
            <pubDate>Tue, 14 Jul 2020 08:16:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tufte CSS]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23828196">thread link</a>) | @mmastrac
<br/>
July 13, 2020 | https://edwardtufte.github.io/tufte-css/ | <a href="https://web.archive.org/web/*/https://edwardtufte.github.io/tufte-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>Dave Liepmann</p>
      <section>
        <p>Tufte CSS provides tools to style web articles using the ideas demonstrated by Edward Tufte’s books and handouts. Tufte’s style is known for its simplicity, extensive use of sidenotes, tight integration of graphics with text, and carefully chosen typography.</p>
        <p>Tufte CSS was created by <a href="http://www.daveliepmann.com/">Dave Liepmann</a> and is now an Edward Tufte project. The original idea was cribbed from <a href="https://tufte-latex.github.io/tufte-latex/">Tufte-<span>L<span>a</span>T<span>e</span>X</span></a> and <a href="http://rmarkdown.rstudio.com/tufte_handout_format.html">R Markdown’s Tufte Handout format</a>. We give hearty thanks to all the people who have contributed to those projects.</p>
        <p>If you see anything that Tufte CSS could improve, we welcome your contribution in the form of an issue or pull request on the GitHub project: <a href="https://github.com/edwardtufte/tufte-css">tufte-css</a>. Please note the <a href="https://github.com/edwardtufte/tufte-css#contributing">contribution guidelines</a>.</p>
        <p>Finally, a reminder about the goal of this project. The web is not print. Webpages are not books. Therefore, the goal of Tufte CSS is not to say “websites should look like this interpretation of Tufte’s books” but rather “here are some techniques Tufte developed that we’ve found useful in print; maybe you can find a way to make them useful on the web”. Tufte CSS is merely a sketch of one way to implement this particular set of ideas. It should be a starting point, not a design goal, because any project should present their information as best suits their particular circumstances.</p>
      </section>

      <section>
        <h2 id="getting-started">Getting Started</h2>
        <p>To use Tufte CSS, copy <code>tufte.css</code> and the <code>et-book</code> directory of font files to your project directory, then add the following to your HTML document’s <code>head</code> block:</p>

        <pre><code>&lt;link rel="stylesheet" href="tufte.css"/&gt;</code></pre>

        <p>Now you just have to use the provided CSS rules, and the Tufte CSS conventions described in this document. For best results, View Source and Inspect Element frequently.</p>
      </section>

      <section>
        <h2 id="fundamentals">Fundamentals</h2>
        <h3 id="fundamentals--sections-and-headers">Sections and Headings</h3>
        <p>Organize your document with an <code>article</code> element inside your <code>body</code> tag. Inside that, use <code>section</code> tags around each logical grouping of text and headings.</p>
        <p>Tufte CSS uses <code>h1</code> for the document title, <code>p</code> with class <code>subtitle</code> for the document subtitle, <code>h2</code> for section headings, and <code>h3</code> for low-level headings. More specific headings are not supported. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:</p>
        <blockquote cite="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB">
          <p>[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of <em>sentences</em> which then cumulate sequentially into <em>paragraphs</em>, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.</p>
          
        </blockquote>
        <p>As a bonus, this excerpt regarding the use of headings provides an example of block quotes. In Tufte CSS they are just lightly styled, semantically correct HTML using <code>blockquote</code> and <code>footer</code> elements. See page 20 of <a href="https://www.edwardtufte.com/tufte/books_vdqi">The Visual Display of Quantitative Information</a> for an example in print.</p>
        <p><span>In his later books<label for="sn-in-his-later-books"></label></span><span><a href="http://www.edwardtufte.com/tufte/books_be"><em>Beautiful Evidence</em></a></span>, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and the first few words of the sentence set in small caps. For this we use a span with the class <code>newthought</code>, as demonstrated at the beginning of this paragraph. Vertical spacing is accomplished separately through <code>&lt;section&gt;</code> tags. Be consistent: though we do so in this paragraph for the purpose of demonstration, do not alternate use of header elements and the <code>newthought</code> technique. Pick one approach and stick to it.</p>

        <h3 id="fundamentals--text">Text</h3>
        <p>Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. Tufte CSS uses <code>#fffff8</code> and <code>#111111</code> because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. We stick to the greyscale for text, reserving color for specific, careful use in figures and images.</p>
        <p>In print, Tufte has used the proprietary Monotype Bembo<label for="sn-proprietary-monotype-bembo"></label><span>See Tufte’s comment in the <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt">Tufte book fonts</a> thread.</span> font. A similar effect is achieved in digital formats with the now open-source <a href="https://github.com/edwardtufte/et-book">ETBook</a>, which Tufte CSS supplies with a <code>@font-face</code> reference to a .ttf file. In case ETBook somehow doesn’t work, Tufte CSS shifts gracefully to other serif fonts like Palatino and Georgia.</p>
        <p>Also notice how Tufte CSS includes separate font files for bold (strong) and italic (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice.</p>
        <p>If you prefer sans-serifs, use the <code>sans</code> class. It relies on Gill Sans, Tufte’s sans-serif font of choice.</p>
        <p>Links in Tufte CSS match the body text in color and do not change on mouseover or when clicked. Here is a <a href="#">dummy example</a> that goes nowhere. These links are underlined, since this is the most widely recognized indicator of clickable text. <label for="mn-blue-links">⊕</label><span>Blue text, while also a widely recognizable clickable-text indicator, is crass and distracting. Luckily, it is also rendered unnecessary by the use of underlining.</span> However, because most browsers’ default underlining does not clear descenders and is so thick and distracting, the underline effect is instead achieved using CSS trickery involving background gradients instead of standard <code>text-decoration</code>. Credit goes to Adam Schwartz for that technique.</p>
        <p>As always, these design choices are merely one approach that Tufte CSS provides by default. Other approaches can also be made to work. The goal is to make sentences readable without interference from links, as well as to make links immediately identifiable even by casual web users.</p>
      </section>

      <section>
        <h2 id="epigraphs">Epigraphs</h2>
        <div>
          <blockquote>
            <p>The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.</p>
            
          </blockquote>
          <blockquote>
            <p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p>
            
          </blockquote>
          <blockquote>I do not paint things, I paint only the differences between things.</blockquote>
        </div>
        <p>If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. Modeled after chapter epigraphs in Tufte’s books (particularly <em>Beautiful Evidence</em>), these are <code>blockquote</code> elements with a bit of specialized styling. Quoted text is italicized. The source goes in a <code>footer</code> element inside the <code>blockquote</code>. We have provided three examples in the epigraph of this section, demonstrating shorter and longer quotes, with and without a paragraph tag, and showing how multiple quotes within an epigraph fit together with the use of a wrapper class.</p>
      </section>

      <section>
        <h2 id="sidenotes">Sidenotes: Footnotes and Marginal Notes</h2>
        <p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<label for="sn-extensive-use-of-sidenotes"></label><span>This is a sidenote.</span> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p>
        <p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p>
        <p>Sidenotes consist of two elements: a superscript reference number that goes inline with the text, and a sidenote with content. To add the former, just put a label and dummy checkbox into the text where you want the reference to go, like so:</p>
        <pre><code>&lt;label for="sn-demo"
       class="margin-toggle sidenote-number"&gt;
&lt;/label&gt;
&lt;input type="checkbox"
       id="sn-demo"
       class="margin-toggle"/&gt;</code></pre>
        <p>You must manually assign a reference <code>id</code> to each side or margin note, replacing “sn-demo” in the <code>for</code> and the <code>id</code> attribute values with an appropriate descriptor. It is useful to use prefixes like <code>sn-</code> for sidenotes and <code>mn-</code> for margin notes.</p>
        <p>Immediately adjacent to that sidenote reference in the main text goes the sidenote content itself, in a <code>span</code> with class <code>sidenote</code>. This tag is also inserted directly in the middle of the body text, but is either pushed into the margin or hidden by default. Make sure to position your sidenotes correctly by keeping the sidenote-number label close to the sidenote itself.</p>
        <p>If you want a sidenote without footnote-style numberings, then you want a margin note.
          <label for="mn-demo">⊕</label>
          
          <span>
            This is a margin note. Notice there isn’t a number preceding the note.
          </span> On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text. However, on small screens, a margin note is like a sidenote except its viewability-toggle is a symbol rather than a reference number. This document currently uses the symbol ⊕ (<code>&amp;#8853;</code>), but it’s up to you.</p>
        <p>Margin notes are created just like sidenotes, but with the <code>marginnote</code> class for the content and the <code>margin-toggle</code> class for the label and dummy checkbox. For instance, here is the code for the margin note used in the previous paragraph:</p>
        <pre><code>&lt;label for="mn-demo" class="margin-toggle"&gt;&amp;#8853;&lt;/label&gt;
&lt;input type="checkbox" id="mn-demo" class="margin-toggle"/&gt;
&lt;span class="marginnote"&gt;
  This is a margin note. Notice there isn’t a number preceding the note.
&lt;/span&gt;</code></pre>
        </section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edwardtufte.github.io/tufte-css/">https://edwardtufte.github.io/tufte-css/</a></em></p>]]>
            </description>
            <link>https://edwardtufte.github.io/tufte-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828196</guid>
            <pubDate>Tue, 14 Jul 2020 03:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strange public IPv4 address assigned behind NAT (2019)]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23827521">thread link</a>) | @rohan1024
<br/>
July 13, 2020 | https://broadbandforum.co/t/190267/ | <a href="https://web.archive.org/web/*/https://broadbandforum.co/t/190267/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://broadbandforum.co/t/190267/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827521</guid>
            <pubDate>Tue, 14 Jul 2020 01:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking with environment variables]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23827486">thread link</a>) | @pentestercrab
<br/>
July 13, 2020 | https://www.elttam.com/blog/env/ | <a href="https://web.archive.org/web/*/https://www.elttam.com/blog/env/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

<p>On a recent project we gained the ability to specify environment variables but not the process that was executed.
We were also unable to control the contents of a file on disk, and bruteforcing process identifiers (PIDs) and file descriptors found no interesting results, eliminating <a href="https://www.elttam.com/blog/goahead/">remote LD_PRELOAD exploitation</a>.
Fortunately, a scripting language interpreter was executed which enabled us to execute arbitrary commands by specifying particular environment variables.
This blog post discusses how arbitrary commands can be executed by a range of scripting language interpreters when supplied with malicious environment variables.</p>



<p>A quick read of the <code>ENVIRONMENT</code> section of the <code>perlrun(1)</code> man page reveals plenty of environment variables worth investigating.
The <code>PERL5OPT</code> environment variable allows specifying command-line options, but is restricted to only accepting the options <code>CDIMTUWdmtw</code>.
This unfortunately means that <code>-e</code>, which allows supplying perl code to run, is out.</p>

<p>All is not lost though, as demonstrated in the <a href="https://github.com/HackerFantastic/exploits/blob/master/cve-2016-1531.sh">exploit</a> for CVE-2016-1531 by <a href="https://twitter.com/hackerfantastic">Hacker Fantastic</a>.
The exploit writes a malicious perl module to <code>/tmp/root.pm</code> and supplies the environment variables <code>PERL5OPT=-Mroot</code> and <code>PERL5LIB=/tmp</code> to achieve arbitrary code execution.
However this was an exploit for a local privilege escalation vulnerability and a generic technique should ideally not require access to the file system. Looking at <a href="https://twitter.com/bl4sty">blasty</a>’s <a href="https://haxx.in/blasty-vs-exim.sh">exploit</a> for the same CVE, the exploit did not require creating a file and used the environment variables <code>PERL5OPT=-d</code> and <code>PERL5DB=system("sh");exit;</code>.
The same environment variables were also used to <a href="https://old.reddit.com/r/netsec/comments/1dm8fv/hack_this_website_and_win_bitcoins_the_first/c9tm6j4/">solve a CTF challenge</a> in 2013.</p>

<p>One final nicety of a generic technique would be to use a single environment variable instead of two.
<a href="https://twitter.com/justinsteven">@justinsteven</a> found this was possible by leveraging <code>PERL5OPT=-M</code>.
While either <code>-m</code> or <code>-M</code> can be used to load a perl module, the <code>-M</code> option allows adding extra code after the module name.</p>

<h2 id="proof-of-concept">Proof of Concept</h2>

<figure>
  <figcaption>Figure-0: arbitrary code execution achieved using an environment variable against perl running an empty script (/dev/null)</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>--env</span> <span>'PERL5OPT=-Mbase;print(`id`)'</span> perl:5.30.2 perl /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>Reading the <code>ENVIRONMENT VARIABLES</code> section of the <code>python(1)</code> man page, <code>PYTHONSTARTUP</code> initially appears like it may be a piece of a straightforward solution.
It allows specifying a path to a Python script that will be executed prior to displaying the prompt in interactive mode.
The interactive mode requirement didn’t seem like it would be an issue as the <code>PYTHONINSPECT</code> environment variable can be used to enter interactive mode, the same as specifying <code>-i</code> on the command line.
However, the documentation for the <code>-i</code> option explains that <code>PYTHONSTARTUP</code> will not be used when python is started with a script to execute.
This means that <code>PYTHONSTARTUP</code> and <code>PYTHONINSPECT</code> cannot be combined and <code>PYTHONSTARTUP</code> only has an effect when the python REPL is immediately launched.
This ultimately means that <code>PYTHONSTARTUP</code> is not viable as it has no effect when executing a regular Python script.</p>

<p>Other environment variables which looked promising were <code>PYTHONHOME</code> and <code>PYTHONPATH</code>. Both of these will let you gain arbitrary code execution but require you to also be able to create directories and files on the filesystem. It may be possible to loosen those requirements through the use of the proc filesystem and/or ZIP files.</p>

<p>The majority of the remaining environment variables are simply checked if they contain a non-empty string, and if so, toggle a generally benign setting. One of the rare exceptions to this is <code>PYTHONWARNINGS</code>.</p>

<h2 id="making-progress-with-pythonwarnings">Making progress with PYTHONWARNINGS</h2>
<p>The documentation for <code>PYTHONWARNINGS</code> states <code>it is equivalent to specifying the -W option</code>. The <code>-W</code> option is used for warning control to specify which warnings and how often they are printed. The full form of argument is <code>action:message:category:module:line</code>. While warning control didn’t seem like a promising lead, that quickly changed after checking the implementation.</p>

<figure>
  <figcaption>Figure-1: Python-3.8.2/Lib/warnings.py</figcaption>

<figure><pre><code data-lang="python"><span>[...]</span>
<span>def</span> <span>_getcategory</span><span>(</span><span>category</span><span>):</span>
    <span>if</span> <span>not</span> <span>category</span><span>:</span>
        <span>return</span> <span>Warning</span>
    <span>if</span> <span>'.'</span> <span>not</span> <span>in</span> <span>category</span><span>:</span>
        <span>import</span> <span>builtins</span> <span>as</span> <span>m</span>
        <span>klass</span> <span>=</span> <span>category</span>
    <span>else</span><span>:</span>
        <span>module</span><span>,</span> <span>_</span><span>,</span> <span>klass</span> <span>=</span> <span>category</span><span>.</span><span>rpartition</span><span>(</span><span>'.'</span><span>)</span>
        <span>try</span><span>:</span>
            <span>m</span> <span>=</span> <span>__import__</span><span>(</span><span>module</span><span>,</span> <span>None</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>klass</span><span>])</span>
        <span>except</span> <span>ImportError</span><span>:</span>
            <span>raise</span> <span>_OptionError</span><span>(</span><span>"invalid module name: %r"</span> <span>%</span> <span>(</span><span>module</span><span>,))</span> <span>from</span> <span>None</span>
<span>[...]</span></code></pre></figure>

</figure>

<p>The above code shows that as long as our specified category contains a dot, we can trigger the import an arbitrary Python module.</p>

<p>The next problem is that the vast majority of modules from Python’s standard library run very little code when imported. They tend to just define classes to be used later, and even when they provide code to run, the code is typically <a href="https://docs.python.org/3/library/__main__.html">guarded with a check of the <code>__main__</code> variable</a> (to detect if the file has been imported or run directly).</p>

<p>An unexpected exception to this is the <a href="https://xkcd.com/353/">antigravity module</a>. The Python developers included an <a href="https://en.wikipedia.org/wiki/Easter_egg_(media)">easter egg</a> in <a href="https://github.com/python/cpython/commit/206e3074d34aeb5a4d0c1e24d970b6569f7ad702">2008</a> which can be triggered by running <code>import antigravity</code>. This import will immediately open your browser to the xkcd comic that joked that <code>import antigravity</code> in Python would grant you the ability to fly.</p>

<p>As for how the <code>antigravity</code> module opens your browser, it uses another module from the standard library called <code>webbrowser</code>. This module checks your PATH for a large variety of browsers, including mosaic, opera, skipstone, konqueror, chrome, chromium, firefox, links, elinks and lynx. It also accepts an environment variable <code>BROWSER</code> that lets you specify which process should be executed. It is not possible to supply arguments to the process in the environment variable and the xkcd comic URL is the one hard-coded argument for the command.</p>

<p>The ability to turn this into arbitrary code execution depends on what other executables are available on the system.</p>

<h2 id="leveraging-perl-for-arbitrary-code-execution">Leveraging Perl for Arbitrary Code Execution</h2>

<p>One approach is to leverage Perl which is commonly installed on systems and is even available in the standard Python docker image. However, the <code>perl</code> binary cannot itself be used. This is because the first and only argument is the xkcd comic URL. The comic URL argument will cause an error and the process to exit without the <code>PERL5OPT</code> environment variable being used.</p>

<figure>
  <figcaption>Figure-2: PERL5OPT having no effect when a URL is passed to perl</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perl https://xkcd.com/353/
<span>Can't open perl script "https://xkcd.com/353/": No such file or directory</span></code></pre></figure>

</figure>

<p>Fortunately, when Perl is available it also common to have the default Perl scripts available, such as perldoc and perlthanks. These scripts will also error and exit with an invalid argument, but the error in this case happens later than the processing of the <code>PERL5OPT</code> environment variable. This means you can leverage the Perl environment variable payload detailed earlier in this blog post.</p>

<figure>
  <figcaption>Figure-3: PERL5OPT working as intended with perldoc and perlthanks</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perldoc https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)
</span><span>$</span><span> </span>run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perlthanks https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>

<h2 id="proof-of-concept-1">Proof of Concept</h2>

<figure>
  <figcaption>Figure-4: arbitrary code execution achieved using multiple environment variables against Python 2 and Python 3</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:2.7.18 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'

</span><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:3.8.2 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'</span></code></pre></figure>

</figure>



<p>A <a href="https://research.securitum.com/prototype-pollution-rce-kibana-cve-2019-7609/">blog post</a> by <a href="https://twitter.com/securitymb">Michał Bentkowski</a> provided a payload for exploiting Kibana (CVE-2019-7609). A prototype pollution vulnerability was used to set arbitrary environment variables which resulted in arbitrary command execution. Michał’s payload used the <code>NODE_OPTIONS</code> environment variable and the <a href="https://en.wikipedia.org/wiki/Procfs">proc filesystem</a>, specifically <code>/proc/self/environ</code>.</p>

<p>Although Michał’s technique was creative and worked perfectly for their vulnerability, the technique is not always guaranteed to work and has some constraints that would be nice to remove.</p>

<p>The first constraint is that it using <code>/proc/self/environ</code> is only viable if the contents can be made to be syntactically valid JavaScript. This requires being able to create an environment variable and have it appear first in the contents of <code>/proc/self/environ</code>, or knowing/bruteforcing the environment variable’s name that will appear first and overwriting it’s value.</p>

<p>Another constraint, as the first environment variable’s value finishes with a single line comment (<code>//</code>). Therefore, any newline character in other environment variables will likely cause a syntax error and prevent the payload from executing. The use of multi-line comments (<code>/*</code>) will not fix this issue as they must be closed to be syntactically valid. Therefore, in the rare case that an environment variable contains a newline character, it is required to know/bruteforce the environment variable’s name and overwrite it’s value to a new value that does not contain a newline.</p>

<p>Removing these contraints is an exercise left for the reader.</p>

<h2 id="proof-of-concept-2">Proof of Concept</h2>

<figure>
  <figcaption>Figure-5: achieving arbitrary code execution with environment variables against NodeJS by Michał Bentkowski</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'NODE_VERSION=console.log(require("child_process").execSync("id").toString());//'</span> <span>-e</span> <span>'NODE_OPTIONS=--require /proc/self/environ'</span> node:14.2.0 node /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>If you run <code>ltrace -e getenv php /dev/null</code> you will find PHP uses the <code>PHPRC</code> environment variable.
The environment variable is used …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elttam.com/blog/env/">https://www.elttam.com/blog/env/</a></em></p>]]>
            </description>
            <link>https://www.elttam.com/blog/env/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827486</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is QuantGov?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827427">thread link</a>) | @hhs
<br/>
July 13, 2020 | https://www.quantgov.org/about | <a href="https://web.archive.org/web/*/https://www.quantgov.org/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.quantgov.org/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827427</guid>
            <pubDate>Tue, 14 Jul 2020 00:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alex: An Updatable Adaptive Learned Index [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827257">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf | <a href="https://web.archive.org/web/*/https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827257</guid>
            <pubDate>Tue, 14 Jul 2020 00:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond Analytics: The Evolution of Stream Processing Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827170">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://streaming-research.github.io/Tutorial-SIGMOD-2020/ | <a href="https://web.archive.org/web/*/https://streaming-research.github.io/Tutorial-SIGMOD-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <h2 id="tutorial-information">Tutorial Information</h2>
<h3 id="wednesday-june-17-2020">Wednesday, June 17 2020</h3>
<h4 id="join-us-on-zoom-and-slack">Join us on <a href="https://acm-org.zoom.us/j/93450885761?pwd=OGZmekwyRFR2Q3ZTd3VwL3hsc0JlUT09">Zoom</a> and <a href="https://join.slack.com/t/sigmodpods/shared_invite/zt-em1btw2v-tTI9OXRtzi4apsMaCoqjTA">Slack</a></h4>

<h4 id="session-1-1030-am---1200-pm-pdt">Session 1: 10:30 AM - 12:00 PM PDT</h4>
<ul>
  <li>Part I: Introduction &amp; Fundamentals</li>
  <li>Part II: Time, Order, &amp; Progress</li>
  <li>Part III: State Management</li>
</ul>

<h4 id="session-2-130-pm---300-pm-pdt">Session 2: 1:30 PM - 3:00 PM PDT</h4>
<ul>
  <li>Part IV: Fault Recovery &amp; High Availability</li>
  <li>Part V: Load Management &amp; Elasticity</li>
  <li>Part VI: Prospects</li>
</ul>

<h2 id="overview">Overview</h2>
<p>Stream processing has been an active research field for more than 20 years, but it is now witnessing its prime time due to recent successful efforts by the research community and numerous worldwide open-source communities. The goal of this tutorial is threefold. First, we aim to review and highlight noteworthy past research findings, which were largely ignored until very recently. Second, we intend to underline the differences between early (’00-’10) and modern (’11-’18) streaming systems, and how those systems have evolved through the years. Most importantly, we wish to turn the attention of the database community to recent trends: streaming systems are no longer used only for classic stream processing workloads, namely window aggregates and joins. Instead, modern streaming systems are being increasingly used to deploy general event-driven applications in a scalable fashion, challenging the design decisions, architecture and intended use of existing stream processing systems.</p>

<h2 id="presenters">Presenters</h2>

<ul>
  <li><a href="https://www.ri.se/en/paris-carbone">Paris Carbone</a> (RISE)</li>
  <li><a href="http://mariosfragkoulis.gr/">Marios Fragkoulis</a> (Delft University of Technology)</li>
  <li><a href="https://cs-people.bu.edu/vkalavri/">Vasiliki Kalavri</a> (Boston University)</li>
  <li><a href="http://asterios.katsifodimos.com/">Asterios Katsifodimos</a> (Delft University of Technology)</li>
</ul>

<h2 id="slides-and-videos">Slides and Videos</h2>

<ol>
  <li>Introduction and fundamentals <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part1-introduction.pdf">[Slides]</a> <a href="https://youtu.be/6qmwLKzXdgM">[Video]</a></li>
  <li>Time, order, and progress <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part2-time.pdf">[Slides]</a> <a href="https://youtu.be/sWcMx52eP58">[Video]</a></li>
  <li>State management and guarantees <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part3-state-management.pdf">[Slides]</a> <a href="https://youtu.be/Zgy5a5tBOco">[Video]</a></li>
  <li>Advanced fault recovery and high availability <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part4-Fault-HA.pdf">[Slides]</a> <a href="https://youtu.be/p3zXV2w_MgM">[Video - Part I]</a> <a href="https://youtu.be/28CRUcFAGPs">[Video - Part II]</a></li>
  <li>Load management and elasticity <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part5-load-management.pdf">[Slides]</a> <a href="https://youtu.be/Pxe0M-mprOM">[Video]</a></li>
  <li>Prospects and discussion <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part6-prospects.pdf">[Slides]</a> <a href="https://youtu.be/DW9kU7gCL8A">[Video]</a></li>
</ol>

<h2 id="cite-pdf">Cite (<a href="https://dl.acm.org/doi/abs/10.1145/3318464.3383131">PDF</a>)</h2>

<div><div><pre><code>@inproceedings{10.1145/3318464.3383131,
author = {Carbone, Paris and Fragkoulis, Marios and Kalavri, Vasiliki and Katsifodimos, Asterios},
title = {Beyond Analytics: The Evolution of Stream Processing Systems},
year = {2020},
isbn = {9781450367356},
doi = {10.1145/3318464.3383131},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {2651–2658}
}
</code></pre></div></div>



      </section>
    </div></div>]]>
            </description>
            <link>https://streaming-research.github.io/Tutorial-SIGMOD-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827170</guid>
            <pubDate>Tue, 14 Jul 2020 00:12:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826786">thread link</a>) | @elsewhen
<br/>
July 13, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826786</guid>
            <pubDate>Mon, 13 Jul 2020 23:20:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The AirPods Pro “Rattlegate”]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 314 (<a href="https://news.ycombinator.com/item?id=23826070">thread link</a>) | @dewey
<br/>
July 13, 2020 | https://annoying.technology/posts/abea6876cf4f2e13/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/abea6876cf4f2e13/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/a57da8f4dbb8954a0649e58235d5555af26d4c2f/d294d/media/rattlegate.jpg"></p><p>The AirPods Pro “Rattlegate”</p><p>The first generation of the AirPods was generally regarded as a perfect product. “Apple at its best!” was the universally accepted opinion.</p><p>I used them for a long time. No speaker issues, no battery issues.</p><p>Excited for the noise cancelling feature I ordered the AirPods Pro and for the first few months everything was fine. One day the left AirPod started buzzing every time I was moving my head. Slightly tilting my head would result in a buzzing noise with changing intensity depending on how my head moved.</p><p>Support agreed that this is a problem and sent a new AirPod.</p><p>A few weeks later the right AirPod started to produce weird rattling noises. It sounded like some tiny part fell off and was now bouncing around in the AirPod. It also started to behave weird as soon as there was a bit of wind.</p><p>Support agreed that this is a problem and sent a new AirPod.</p><p>Days later it was the left AirPod’s turn and it’s now rattling again.</p><p>There’s something very wrong with this product line and just getting a new one every few months is — financially and ecologically — not sustainable as they end up in a landfill. I’m also <a href="https://forums.macrumors.com/threads/airpods-pro-rattlegate.2233658/">far from being the only one</a> having this issue.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/abea6876cf4f2e13/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826070</guid>
            <pubDate>Mon, 13 Jul 2020 22:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23825606">thread link</a>) | @refrigerator
<br/>
July 13, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825606</guid>
            <pubDate>Mon, 13 Jul 2020 21:09:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Calculating Churn Rates Wrong]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23825420">thread link</a>) | @cmogni1
<br/>
July 13, 2020 | https://catchjs.com/Blog/Churn | <a href="https://web.archive.org/web/*/https://catchjs.com/Blog/Churn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
<ol>
    <li><a href="https://catchjs.com/Docs">Blog</a></li>
    <li>You're all calculating churn rates wrong</li>
</ol>

        

        
        <p>
            Many smart people will tell you to obsess over your churn rate.
        </p>
        <p>
            <img src="https://catchjs.com/Blog//images/blog/churn/churn_rate_formula2.png" alt="churn rate=(customers lost in month)/(customers at start of month)">
        </p>
        <p>
            According to Andreessen Horowitz, this number is <a href="https://a16z.com/2015/08/21/16-metrics/">one of the top 16 metrics</a>
            to measure a SaaS startup by. Well, sorry Andreessen, and sorry Horowitz, but this just isn't right.
        </p><p>
            It's counterintuitive, but it's a statistical fact: This number actually <b>tells you nothing useful about churn</b>,
            but really relates to the age of the subscriptions you have.
            It will in most cases go down on it's own, and, absurdly, the only way to keep it from going down is to have very
            high growth. So the number will literally <b>only look <i>bad</i> if your business is doing extremely <i>well</i></b>,
            and optimizing for it will be directly counter-productive.
            The error here is a simple statistical mistake that is easy to make, and luckily also easy to understand and avoid.
        </p><p>
            If you run a subscription based SaaS business, you're likely very concerned with how long you can keep your
            customers. We're a JavaScript exception tracking service, and the health of this business is fully determined by how many
            customers we bring in, and how long we can keep them. On the surface, <i>churn rate</i> may seem like a natural proxy for changes
            in <i>customer lifetimes</i>. Let's dig into why that is not true.
        </p>
        <h2>
            The false assumption
        </h2>
        <p>
            Computing a churn rate <b>assumes that a customer is equally likely to leave at any time</b>, no matter how long they've
            been subscribed to you. This is almost certainly not true. In fact, as we will see, having a constant churn probability over time
            essentially implies that you'll <i>never have long term customers</i>.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/expon.png" alt="Hazard function (churn) and the implied survival function (from an Exponential distribution)">
            <figcaption>If a user has a constant churn probability over time, this implies that customer lifetimes come from an Exponential distribution.</figcaption>
        </figure>
        <p>
            If you have a constant churn of <code>c</code> per month, the probability that a customer stays subscribed for <code>n</code> months is <code>(1-c)^n</code>. This implies that customer lifetimes come from the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a>. If customers can quit the subscription at any time, we have continuous time and should use the continuous time analogue, the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential distribution</a>.
        </p>
        <h2>
            What your churn is actually like, with help from K. S. Lomax
        </h2>
        <p>
            The problem is, your customer is not equally likely to cancel their subscription at any time. Most likely, you have a situation where the drop-off in customers is higher in the first few days than it is later. This is even more so if you have a free trial period for your product.
        </p><p>
            If the churn probability gets lower the longer the customer has been subscribed, you could model that as <code>c/(t+1)</code>, where
            <code>t</code> is the timestep (e.g. number of days the customer has been subscribed), and <code>c</code> is some constant.
            In this case, this implies that customer lifetimes comes from a <a href="https://en.wikipedia.org/wiki/Lomax_distribution">Lomax distribution</a>.
            This is equivalent to a Pareto distribution shifted to start at 0.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/lomax.png" alt="Hazard function (churn) and the implied survival function (from a Lomax distribution)">
            <figcaption>The Lomax distribution can express churn probabilities that get lower with time.</figcaption>
        </figure>
        <h2>
            What your churn is actually like, with help from Waloddi Weibull
        </h2>
        <p>
            If you suspect that churn probability per day may <i>increase</i> the longer a user has been subscribed, the Lomax distribution won't
            work for you. Instead you could enlist the help of Swedish statistician Waloddi Weibull.
            The <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull distribution</a> can express both decreasing,
            flat, and increasing probabilities of a customer quitting. This makes it a popular choice for modeling customer lifetimes.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/weibull.png" alt="Hazard function (churn) and the implied survival function (from two Weibull distributions)">
            <figcaption>The Weibull distribution can express both growing and shrinking churn probabilities.</figcaption>
        </figure>

        <h2>
            Optimizing for a falsehood will lead you astray
        </h2>
        <p>
            Now let's see why properly modeling this is important.
        </p><p>
            Let's measure churn the wrong way, and see where it takes us.
            Let's say customer lifetimes come from a Lomax distribution. Let's also say you have a business that is in terrible shape, where
            the number of new sign ups per day is falling by one per day. How will this look on the churn rate? We can simulate it and find out.
        </p>
        <p>
            Keep in mind, in each of the examples below we simulate lifetimes from the same customer lifetime distribution,
            and this distribution <b>does not change</b> over time.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/shrinking_business.png" alt="Shrinking business, churn appears to fall">
            <figcaption>With a shrinking business, churn appears to improve because subscriptions are getting fewer and older.</figcaption>
        </figure>
        <p>
            This is clearly a dying business, yet the churn rate graph is looking great! <b>
                The churn rate per day is falling steadily,
                even if we know that there is no change in customer lifetimes in our model.
            </b>
        </p><p>
            So what's going on? This sharp fall in churn rate is a consequence of the fact that we're not getting new customers.
            Because we're not growing, a bigger share of our customers have been around for a long time, which
            means they're less likely to churn, which means our daily churn graph goes down more than it would otherwise.
            This change on the population level happens despite there being no change in underlying individual customer lifetimes.
        </p><p>
            Let's change this into a scenario where your business is experiencing insane growth. We'll keep the customer lifetimes exactly the same,
            but change it so that the number of new sign ups per day is growing superlinearly.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/growing_business.png" alt="Growing business, churn appears to be flat">
            <figcaption>With a growing business, churn rate appears to not change, only because most subscriptions are new.</figcaption>
        </figure>
        <p>
            Even if the customer lifetimes are unchanged from before, the churn rate graph here is flat. An investor would frown and say
            we're doing nothing to improve how well we retain our customers. In reality, the only reason the graph looks "bad" has nothing to
            do with churn, it is because we're doing insanely well at getting new sign ups.
        </p><p>
            <b>
                If you are steering yourself and your team on the basis of this metric, you're rewarding yourself for stifling growth
                and punishing yourself for growing.
            </b> Obviously, this is 100% counterproductive.
        </p>
        <h2>
            How the h*** do we measure churn then?
        </h2>
        <p>
            As you might have guessed from the previous paragraphs, we should model the <i>distribution of customer lifetimes</i>,
            and we should do it in a <i>statistically sound way</i>. Lomax and Weibull distributions are good choices of model.
        </p><p>
            The part where this gets tricky is that we'll have two types of data: The customers that have quit, and the customers
            that are still subscribed. It's only our ex-customers that give us a total lifetime to work with. For our still-subscribed
            customers, we only know that their subscription has lasted up until now, and we don't know how much longer it will last
            into the future. In statistical lingo, we have what is called <i>right-censored data</i>.
        </p><p>
            Luckily there's a way to use all our data, even from our still-subscribed customers.
        </p>


        <h2>
            Weibull or Lomax?
        </h2>
        <p>
            Choosing between Weibull or Lomax (or any other distribution) has no simple answer. Weibull is more flexible
            in that it can express growing, shrinking and flat churn probabilities. However, this expressive power will
            not help you if your data is fundamentally Lomax-like. First and foremost, base your choice
            on your knowledge of the business that you're in. If you have any prior knowledge about how churn probabilities
            will develop, base your choice of distribution on that. There are also various
            <a href="https://www.weibull.com/hotwire/issue71/relbasics71.htm">goodness of fit</a> tests you could use to
            inform this decision. The truth is, any choice of distribution will be wrong to some degree, so you need to make
            a judgment call as to what fits your situation the best, based both on both your data and your prior knowledge.
            For the purposes of the rest of this post, we'll just fit both distributions and disregard the question of
            which suits us the best.
        </p>

        <h2>
            Let's do some proper statistics
        </h2>
        <p>
            The probability distributions we'll model are defined by their parameters.
            We want to find the parameters that fit the data best. To start, we want to make a guess at these parameters,
            and have a way to tell how good our guess was. Luckily, we have a statistically sound way of knowing how good a guess
            is given the data we have. Extra luckily, this is also true when we have censored data.
            This function that tells us how likely our parameters are given the data we have is called the Likelihood function.
            We get it by looking up the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a>
            value for the uncensored data points and the <a href="https://en.wikipedia.org/wiki/Survival_function">survival function</a> value
            for each of the censored data points, and multiplying all these values together.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/likelihood.png" alt="Likelihood formula with right-censored data">
            <figcaption>
                Likelihood function L for right-censored data. <code>f(.)</code> is the probability distribution function, <code>S(.)</code> is the survival function,
                <code>D</code> is the set of uncensored lifetimes and <code>R</code> …</figcaption></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://catchjs.com/Blog/Churn">https://catchjs.com/Blog/Churn</a></em></p>]]>
            </description>
            <link>https://catchjs.com/Blog/Churn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825420</guid>
            <pubDate>Mon, 13 Jul 2020 20:49:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python malware on the rise]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 58 (<a href="https://news.ycombinator.com/item?id=23824689">thread link</a>) | @vesche
<br/>
July 13, 2020 | https://www.cyborgsecurity.com/python-malware-on-the-rise/ | <a href="https://web.archive.org/web/*/https://www.cyborgsecurity.com/python-malware-on-the-rise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
                        <p>
                July 13, 2020            </p>
            
			
            <hr>
                        <p><img width="2560" height="1646" src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-scaled.jpg" alt="" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-scaled.jpg 2560w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-300x193.jpg 300w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-1024x658.jpg 1024w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-768x494.jpg 768w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-1536x988.jpg 1536w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-2048x1317.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">            </p>
                        <p>The vast majority of serious malware&nbsp;<a href="https://software.imdea.org/~juanca/papers/malsource_raid16.pdf">over the past 30 years</a>&nbsp;has been written in Assembly or compiled languages such as C, C++, and Delphi. However, ever-increasing over the past decade, a large amount of malware has been written in interpreted languages, such as Python. The low barrier to entry, ease of use, rapid development process, and massive library collection has made Python attractive for millions of developers- including malware authors. Python has quickly become a standard language in which threat actors create Remote Access Trojans (RATs), information stealers, and vulnerability exploit tools. As&nbsp;<a href="https://www.techrepublic.com/article/python-is-eating-the-world-how-one-developers-side-project-became-the-hottest-programming-language-on-the-planet/">Python continues to grow radically in popularity</a>&nbsp;and the&nbsp;<a href="https://research.checkpoint.com/2019/malware-against-the-c-monoculture/">C malware monoculture</a>&nbsp;continues to be challenged, it would seem only certain that Python will be increasingly utilized as malware in cyber attacks.</p>

<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth.jpg" alt="" width="770" height="660" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth.jpg 770w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth-300x257.jpg 300w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth-768x658.jpg 768w" sizes="(max-width: 770px) 100vw, 770px"></p>
<p><span>Image Source: Stack Overflow</span></p>

<p>In comparison to a standard compiled language like C, writing malware in Python comes with a whole host of difficulties. The first being that Python is required to be installed on the operating system in order to interpret and execute Python code. However, as we’ll see in the next section, a Python program can easily be converted into a native executable using a variety of different methods.</p>
<p>Malware written in Python will also have adverse effects on file size, memory footprint, and processing power. Serious malware is often designed to be small, stealthy, have low memory footprint, and use limited processing power. A compiled malware sample written in C might be 200 KB, while a comparable malware sample written in Python might be 20 MB after converted into an executable. Both the CPU &amp; RAM usage will also be significantly higher when using an interpreted language.</p>
<p>However, it’s 2020 and the digital landscape isn’t what it once was. The internet is faster than it’s ever been, our computers have more memory &amp; storage capacity than ever, and CPUs get faster every year. Python is also more ubiquitous than ever, coming pre-installed on macOS and most all Linux distributions by default.</p>

<p>Microsoft Windows is still the primary target for most malicious campaigns, and it does not come with Python installed by default. Therefore, for threat actors to distribute their malware effectively they must convert their Python code into an executable format. There are many methods to “compile Python” into a native executable. Let’s take a look at the few most popular methods…</p>
<h3>PyInstaller</h3>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller.png" alt="" width="500" height="100" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller.png 500w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller-300x60.png 300w" sizes="(max-width: 500px) 100vw, 500px"></p>

<p><a href="https://www.pyinstaller.org/">PyInstaller</a>&nbsp;is capable of building Python applications into stand-alone executables for Windows, Linux, macOS and more by “freezing” Python code. It is one of the most popular methods to convert Python code into executable format and has been used widely for both legitimate and malicious purposes.</p>
<p>Let’s create a simple “Hello, world!” program in Python and freeze it into a stand-alone executable using PyInstaller:</p>
<pre><code>$ cat hello.py
print('Hello, world!')

$ pyinstaller --onefile hello.py
...

$ ./dist/hello 
Hello, world!

$ file dist/hello 
dist/hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=294d1f19a085a730da19a6c55788ec08c2187039, stripped

$ du -sh dist/hello 
7.0M    dist/hello
</code></pre>
<p>This process created a portable, stand-alone Linux ELF (Executable and Linkable Format) which is the equivalent to an EXE on Windows. Now let’s create and compile a “Hello, world!” program in C on Linux for comparison:</p>
<pre><code>$ cat hello.c
#include &lt;stdio.h&gt;
int main() {
    printf("Hello, world!");
}

$ gcc hello.c -o hello

$ ./hello 
Hello, world!

$ file hello
hello: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=480c7c75e09c169ab25d1b81bd28f66fde08da7c, for GNU/Linux 3.2.0, not stripped

$ du -sh hello
20K hello
</code></pre>
<p>Notice how much larger the file size is: 7 MB (Python) vs 20 KB (C)! This demonstrates the major drawback we discussed previously about file size and memory usage. The Python executable is so much larger due to the fact it must bundle the Python interpreter (as a shared object file on Linux) inside the executable itself in order to run.</p>
<h3>py2exe</h3>
<p><a href="https://www.py2exe.org/">Py2exe</a>&nbsp;is another popular method to convert Python code into Windows EXE (executable) format that can be run natively. Similar to PyInstaller, it bundles the Python interpreter with your Python code to make a portable executable. Py2exe is likely to fall out of style with time as it has not been supported past Python 3.4, this is due to&nbsp;<a href="https://docs.python.org/3/whatsnew/3.6.html#cpython-bytecode-changes">the bytecode in CPython being heavily changed in Python 3.6 and beyond</a>.</p>
<p>Py2exe utilizes distutils and requires a small&nbsp;<code>setup.py</code>&nbsp;script to be created to produce an executable. Let’s create an example “Hello, world!” executable using py2exe:</p>
<pre><code>&gt; type hello.py
print('Hello, world!')

&gt; type setup.py
import py2exe
from distutils.core import setup
setup(
    console=['hello.py'],
    options={'py2exe': {'bundle_files': 1, 'compressed': True}},
    zipfile=None
)

&gt; python setup.py py2exe
...

&gt; dist\hello.exe
Hello, world!
</code></pre>
<p>The&nbsp;<code>hello.exe</code>&nbsp;created by py2exe is similar in size to PyInstaller coming in at 6.83 MB.</p>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe.png" alt="" width="369" height="508" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe.png 369w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe-218x300.png 218w" sizes="(max-width: 369px) 100vw, 369px"></p>
<h3>Nuitka</h3>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/nuitka.png" alt="" width="120" height="24"></p>
<p><a href="https://nuitka.net/">Nuitka</a>&nbsp;is perhaps the most underutilized, and yet more advanced method of compiling Python code to an executable. It translates Python code into a C program that then is linked against libpython to execute code the same as CPython. Nuitka can use a variety of C compilers including gcc, clang, MinGW64, Visual Studio 2019+, and clang-cl to convert your Python code to C.</p>
<p>Let’s create a “Hello, world!” Python program on Linux and compile it using Nuitka:</p>
<pre><code>$ cat hello.py
print('Hello, world!')

$ nuitka3 hello.py
...

$ ./hello.bin
Hello, world!

$ file hello.bin 
hello.bin: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=eb6a504e8922f8983b23ce6e82c45a907c6ebadf, for GNU/Linux 3.2.0, stripped

$ du -sh hello.bin
432K    hello.bin
</code></pre>
<p>Nuitka produced a portable binary very simply, and at 432 KB is a fraction of the size of what PyInstaller or py2exe can produce! How is Nuitka able to do this? Let’s take a look at the build folder:</p>
<pre><code>$ cloc hello.build/
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
C                               11           2263            709           8109
C/C++ Header                     1              1              0              7
-------------------------------------------------------------------------------
SUM:                            12           2264            709           8116
-------------------------------------------------------------------------------
</code></pre>
<p>Nuitka produced over 8,000 lines of C code from our 1 line Python program. The way Nuitka works is it actually translates the Python modules into C code and then uses libpython and static C files of its own to execute in the same way as CPython does.</p>
<p>This is very impressive, and it seems highly likely the Nuitka “Python compiler” will see further adoption as time goes on. As we’ll see later, Nuitka might have a further, built-in advantage in protection against Reverse Engineering (RE). There already exist several tools to easily analyze binaries produced by PyInstaller and py2exe to recover Python source code. However, by Nuitka translating the Python code to C it is much more difficult to reverse engineer.</p>

<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools.png" alt="" width="557" height="383" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools.png 557w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools-300x206.png 300w" sizes="(max-width: 557px) 100vw, 557px"></p>
<p>Python malware can take advantage of a massive ecosystem of open-source Python packages and repositories. Almost anything you could think of, someone has already built it using Python. This is a huge advantage to malware authors as simplistic capabilities can be cherry-picked from the open web and more complex capabilities likely don’t need to be written from scratch.</p>
<p>Let’s take a look at three simple, yet powerful tool examples:</p>
<ol>
<li>Code Obfuscation</li>
<li>Taking Screenshots</li>
<li>Performing Web Requests</li>
</ol>
<h3>Tool Example 1 – Obfuscation</h3>
<p>Malware authors using Python have many libraries they could use to obfuscate their Python code to make code readability much more difficult, such as:&nbsp;<a href="https://github.com/liftoff/pyminifier">pyminifier</a>&nbsp;and&nbsp;<a href="https://github.com/dashingsoft/pyarmor">pyarmor</a>.</p>
<p>Here’s a small example of how&nbsp;<code>pyarmor</code>&nbsp;can obfuscate Python code:</p>
<pre><code>$ cat hello.py 
print('Hello, world!')

$ pyarmor obfuscate hello.py
...

$ cat dist/hello.py
from pytransform import pyarmor_runtime
pyarmor_runtime()
__pyarmor__(__name__, __file__, b'\x50\x59\x41\x52\x4d\x4f\x52\x00\x00\x03\x08\x00\x55\x0d\x0d\x0a\x04\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x40\x00\x00\x00\xd5\x00\x00\x00\x00\x00\x00\x18\xf4\x63\x79\xf6\xaa\xd7\xbd\xc8\x85\x25\x4e\x4f\xa6\x80\x72\x9f\x00\x00\x00\x00\x00\x00\x00\x00\xec\x50\x8c\x64\x26\x42\xd6\x01\x10\x54\xca\x9c\xb6\x30\x82\x05\xb8\x63\x3f\xb0\x96\xb1\x97\x0b\xc1\x49\xc9\x47\x86\x55\x61\x93\x75\xa2\xc2\x8c\xb7\x13\x87\xff\x31\x46\xa5\x29\x41\x9d\xdf\x32\xed\x7a\xb9\xa0\xe1\x9a\x50\x4a\x65\x25\xdb\xbe\x1b\xb6\xcd\xd4\xe7\xc2\x97\x35\xd3\x3e\xd3\xd0\x74\xb8\xd5\xab\x48\xd3\x05\x29\x5e\x31\xcf\x3f\xd3\x51\x78\x13\xbc\xb3\x3e\x63\x62\xca\x05\xfb\xac\xed\xfa\xc1\xe3\xb8\xa2\xaa\xfb\xaa\xbb\xb5\x92\x19\x73\xf0\x78\xe4\x9f\xb0\x1c\x7a\x1c\x0c\x6a\xa7\x8b\x19\x38\x37\x7f\x16\xe8\x61\x41\x68\xef\x6a\x96\x3f\x68\x2b\xb7\xec\x60\x39\x51\xa3\xfc\xbd\x65\xdb\xb8\xff\x39\xfe\xc0\x3d\x16\x51\x7f\xc9\x7f\x8b\xbd\x88\x80\x92\xfe\xe1\x23\x61\xd0\xf1\xd3\xf8\xfa\xce\x86\x92\x6d\x4d\xd7\x69\x50\x8b\xf1\x09\x31\xcc\x19\x15\xef\x37\x12\xd4\xbd\x3d\x0d\x6e\xbb\x28\x3e\xac\xbb\xc4\xdb\x98\xb5\x85\xa6\x19\x11\x74\xe9\xab\xdf', 1)

$ python dist/hello.py
Hello, world!
</code></pre>

<h3>Tool Example 2 – Screenshots</h3>
<p>Information stealing malware will often come with the capability to take screenshots of the users desktop in order to steal sensitive …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cyborgsecurity.com/python-malware-on-the-rise/">https://www.cyborgsecurity.com/python-malware-on-the-rise/</a></em></p>]]>
            </description>
            <link>https://www.cyborgsecurity.com/python-malware-on-the-rise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824689</guid>
            <pubDate>Mon, 13 Jul 2020 19:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Igalia's open prioritization experiment for contributing to browsers]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23824505">thread link</a>) | @staktrace
<br/>
July 13, 2020 | http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html | <a href="https://web.archive.org/web/*/http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
  <article>
  
  <p>Jul 13, 2020</p>
  <p>As many web platform developer and Firefox users, I believe <a href="https://www.mozilla.org/en-US/mission/">Mozilla’s mission</a> is instrumental for a better Internet. In a recent <a href="https://www.igalia.com/chats/ecosystem-health">Igalia’s chat about the Web Ecosystem Health</a>, participants made the usual observation regarding this important role played by Mozilla on the one hand and the limited development resources and small Firefox’s usage share on the other hand. In this blog post, I’d like to explain an experimental idea we are launching at Igalia to try and make browser development better match the interest of the web developer and user community.</p>

<p><a href="https://www.igalia.com/open-prioritization/">
    <img src="http://frederic-wang.fr/images/open-prioritization.png" width="750" height="255" alt="Open Prioritization by Igalia. An experiment in crowd-funding prioritization.">
  </a>
</p>

<h2 id="igalias-contribution-to-browser-repositories">Igalia’s contribution to browser repositories</h2>

<p>As mentioned in the past in this blog, Igalia has contributed to different part of Firefox such as multimedia (e.g. &lt;video&gt; support), layout (e.g. Stylo, WebRender, CSS, MathML), scripts (e.g. BigInt, WebAssembly) or accessibility (e.g. ARIA). But is it enough?</p>

<p>Although commit count is an imperfect metric it is also one of the easiest to obtain. Let’s take a look at how Igalia’s commits repositories of the Chromium (chromium, v8), Mozilla (mozilla-central, servo, servo-web-render) and WebKit projects were distributed last year:</p>

<figure>
  <img width="374" height="305" src="http://frederic-wang.fr/images/distribution-of-igalia-commits-2019.png" alt="pie chart">
  <figcaption><small>Diagram showing, the distribution of Igalia's contributions to browser repositories in 2019 (~5200 commits). Chromium (~73%), Mozilla (~4%) and WebKit (~23%).</small>
  </figcaption>
</figure>

<p>As you can see, in absolute value Igalia contributed roughly 3/4 to Chromium, 1/4 to WebKit, with a small remaining amount to Mozilla. This is not surprising since Igalia is a consulting company and our work depends on the importance of browsers in the market where Chromium dominates and WebKit is also quite good for iOS devices and embedded systems.</p>

<p>This suggests a different way to measure our contribution by considering, for each project, the percentage relative to the total amount of commits:</p>

<figure>
  <img width="436" height="339" src="http://frederic-wang.fr/images/igalia-commit-percentage-per-project-2019.png" alt="Bar graph">
  <figcaption><small>Diagram showing, for each project, the percentage of Igalia's commits in 2019 relative to the total amount of the project. From left to right:
  Chromium (~3.96%), Mozilla (~0.43%) and WebKit (~10.92%).</small>
  </figcaption>
</figure>

<p>In the WebKit project, where ~80% of the contributions were made by Apple, Igalia was second with ~10% of the total. In the Chromium project, the huge Google team made more than 90% of the contributions and many more companies are involved, but Igalia was second with about 4% of the total. In the Mozilla project, Mozilla is also doing ~90% of the contributions but Igalia only had ~0.5% of the total. Interestingly, the second contributing organization was… the community of unindentified gmail.com addresses! Of course, this shows the importance of volunteers in the Mozilla project where a great effort is done to encourage participation.</p>

<h2 id="open-prioritization">Open Prioritization</h2>

<p>From the commit count, it’s clear Igalia is not contributing as much to the Mozilla project as to Chromium or WebKit projects. But this is expected and is just reflecting the priority set by large companies. The solid base of Firefox users as well as the large amount of volunteer contributors show that the Mozilla project is nevertheless still attractive for many people. Could we turn this into browser development that is not funded by advertising or selling devices?</p>

<p>Another related question is whether the internet can really be shaped by the global community as defended by the Mozilla’s mission? Is the web doomed to be controlled by big corporations doing technology’s “evangelism” or lobbying at standardization committees? Are there prioritization issues that can be addressed by moving to a more collective decision process?</p>

<p>At <a href="https://www.igalia.com/about/">Igalia</a>, we internally try and follow <a href="https://wingolog.org/tags/cooperatives">a more democratic organization</a> and, at our level, intend to make the world a better place. Today, we are launching a new <a href="https://www.igalia.com/open-prioritization/">Open Prioritization</a> experiment to verify whether crowdfunding could be a way to influence how browser development is prioritized. Below is a short (5 min) <a href="https://www.youtube.com/embed/xCRxNVbUqhk">introductory video</a>:</p>

<iframe width="850" height="508" src="https://www.youtube.com/embed/xCRxNVbUqhk" frameborder="0" allowfullscreen=""></iframe>

<p>I strongly recommend you to take a look at the proposed projects and <a href="https://www.igalia.com/open-prioritization/#faq">read the FAQ</a> to understand how this is going to work. But remember <em>this is an experiment</em> so we are starting with a few ideas that we selected and tasks that are relatively small. We know there are tons of user reports in bug trackers and suggestions of standards, but we are not going to solve everything in one day !</p>

<p>If the process is successful, we can consider generalizing this approach, but we need to test it first, check what works and what doesn’t, consider whether it is worth pursuing, analyze how it can be improved, etc</p>

<h2 id="two-crowdfunding-tasks-for-firefox">Two Crowdfunding Tasks for Firefox</h2>

<figure>
  <img src="https://upload.wikimedia.org/wikipedia/commons/0/06/CIELAB_color_space_top_view.png" alt="CIELAB color space*">
  <figcaption><small>Representation of the CIELAB color space (top view)
  <a href="https://commons.wikimedia.org/wiki/File:CIELAB_color_space_top_view.png">by Holger Everding, under CC-SA 4.0</a>.</small>
  </figcaption>
</figure>

<p>As explained in the previous paragraph, we are starting with small tasks. For Firefox, we selected the following ones:</p>

<ul>
  <li>
    <p>CSS <code>lab()</code> colors. This is about giving web developers a way to express colors using the <a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB color space</a> which approximates better the human perception. My colleague Brian Kardell wrote a <a href="https://bkardell.com/blog/Unlocking-Colors.html">blog with more details</a>. Some investigations have been made by <a href="https://bugs.webkit.org/show_bug.cgi?id=205675">Apple</a> and <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1026287">Google</a>. Let’s see what we can do for Firefox !</p>
  </li>
  <li>
    <p>SVG path <code>d</code> attribute. This is about expressing <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1571119">SVG path using the corresponding CSS syntax</a> for example <code>&lt;path style="d: path('M0,0 L10,10,...')"&gt;</code>. This will likely involve a refactoring to use the same parser for both SVG and CSS paths. It’s a small feature but part of a more general <a href="https://www.youtube.com/watch?v=1d--S_wgAJA">convergence effort between SVG and CSS</a> that Igalia has been involved in.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Is this crowd-funded experiment going to work? Can this approach solve the prioritization problems or at least help a bit? How can we improve that idea in the future?…</p>

<p>There are many open questions but we will only be able to answer them if we have enough people participating. I’ll personally pledge for the two Firefox projects and I invite you to at least take a look and decide whether there is something there that is interesting for you. Let’s try and see!</p>

</article>


</div></div>]]>
            </description>
            <link>http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824505</guid>
            <pubDate>Mon, 13 Jul 2020 19:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vessel Finder]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23823963">thread link</a>) | @Mosiout1936
<br/>
July 13, 2020 | https://marinetraffic24.com/pt/vesselfinder/ | <a href="https://web.archive.org/web/*/https://marinetraffic24.com/pt/vesselfinder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://marinetraffic24.com/pt/vesselfinder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823963</guid>
            <pubDate>Mon, 13 Jul 2020 18:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to learn to code 10x faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823899">thread link</a>) | @sameerkapur
<br/>
July 13, 2020 | https://blog.thecodex.me/how-to-code-10x-faster/ | <a href="https://web.archive.org/web/*/https://blog.thecodex.me/how-to-code-10x-faster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            



            <section>
                <div>
                    <h3 id="what-i-ve-learned-from-teaching-500-000-students-to-code-and-building-dozens-of-projects-">What I've learned from teaching 500,000 students to code and building dozens of projects.</h3><p>Avi here. Since I started programming, a question that I've been asked again and again from my students is, "How do I learn faster?" Here's the answer: <strong>Build projects.</strong></p><p>Let me explain with a story of my own. I started programming when I was 10-years-old after a friend showed me that she had built a Python weather dashboard that told her exactly when it would rain. I was astounded. I spent the next day figuring out how I could write my own Python Script to crawl Yahoo's Weather API and 24 hours later I had built my first program. If you had told me I had to take an 8-week long bootcamp to learn how to code or watch monotonous YouTube videos until it clicked, I might have never started in the first place. No one forced me to get into programming - I discovered my passion because I wanted to build this cool idea. StackOverflow became my best friend as I achieved my goal. Along the way, I learned about a variety of concepts from calling APIs in Python to parsing JSON and had plenty of practice applying them in my project. The lesson here: <strong>use projects as motivators to learn. </strong></p><p>Okay so we got that out of the way. Building projects are the key to learning things faster. Now what? How do I pick the right projects? Where do I even start?</p><p>The next big takeaway:<strong> Work on projects that matter to you. </strong>My first project was a simple weather script because my ten-year-old brain thought that was wicked cool, but you probably have other passions and interests. Don't compromise. Build projects around your interests and hobbies. If you are starting a project, make sure that it is something that you deeply resonate with. If you are into cars, build a car speed comparison tool. If you are into productivity, build a time tracker to help you be more productive. Even better, build things you want. When those ideas for a cool app or website pop up in your head, START BUILDING IT because motivation is perishable. As the saying goes, the best time to start was yesterday, the next best time to start is now.</p><p>Good things happen to those who are patient. Here are three magic words: <strong>Repetition, Compounding, and Consistency.</strong> These three words are the key to solidifying programming fundamentals and truly understanding new concepts and ideas as you apply them in projects. You've heard how important spaced repetition is for learning - the same thing applies when learning how to code. Try coding for an hour a day. Don't have an hour a day? Code for 30 minutes. Can't do 30 minutes consistently? Try for 15 minutes. Break tasks down into smaller tasks and knock them out.</p><p>Last but not the least, the tip that changed my life: Teach what you learn. Yes, it sounds simple - teach what you learn - but I can't repeat it enough. Explaining concepts allow you to improve your understanding and solidify your learning. Teaching has positive externalities as well. After I started teaching others how to code and began posting videos on <a href="https://www.youtube.com/c/TheCodex">Youtube</a>, I not only understood each and every concept better, but thousands of others used my videos to learn how to code. My AP Stats teacher had a philosophy that to truly understand any concept you must "learn one, do one, and teach one." Teaching others has helped me hold myself accountable to truly understanding concepts until I feel ready to share my knowledge and it's paved my path in becoming a professional Python Developer and Data Scientist.</p><p>For those of you interested in project walkthroughs: Every Tuesday, I'm releasing a new Python/Data Science Project tutorial. I was honestly just tired of watching webcasted lectures and YouTube videos of instructors droning on with robotic voices teaching pure theory, so I started recording my own fun and practical projects. I posted the first project walkthrough on building a Weather API Dashboard with Flask and you can build the whole project for free <strong><a href="https://thecodex.me/projects/weather-api-dashboard-with-python-and-flask">here</a>.</strong></p><p>Want to get notified every time a new project launches? Click <strong><a href="https://cdn.forms-content.sg-form.com/a9d3bb34-c4a3-11ea-a1ea-52b70f2fc72a">here</a></strong>.</p><hr><p>Hey! I'm Avi - your new Python and data science teacher. I've taught over 500,000 students around the world not just how to code, but how to build real projects. I'm on a mission to help you jumpstart your career by helping you master python and data science. Start your journey on TheCodex here: <a href="https://thecodex.me/">https://thecodex.me/</a></p><figure><img src="https://blog.thecodex.me/content/images/2020/07/avi-emailtxt-min-2.jpg" alt="" srcset="https://blog.thecodex.me/content/images/size/w600/2020/07/avi-emailtxt-min-2.jpg 600w, https://blog.thecodex.me/content/images/size/w1000/2020/07/avi-emailtxt-min-2.jpg 1000w, https://blog.thecodex.me/content/images/size/w1600/2020/07/avi-emailtxt-min-2.jpg 1600w, https://blog.thecodex.me/content/images/2020/07/avi-emailtxt-min-2.jpg 1616w" sizes="(min-width: 720px) 720px"><figcaption>new projects and courses coming soon :)</figcaption></figure>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.thecodex.me/how-to-code-10x-faster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823899</guid>
            <pubDate>Mon, 13 Jul 2020 18:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ETL: Navigating the Cloud Transition (Architectures & Factors to consider)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823680">thread link</a>) | @ibains
<br/>
July 13, 2020 | https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition | <a href="https://web.archive.org/web/*/https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823680</guid>
            <pubDate>Mon, 13 Jul 2020 18:06:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Harold Lloyd Filmed "Safety Last!"]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823505">thread link</a>) | @gus_massa
<br/>
July 13, 2020 | https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/ | <a href="https://web.archive.org/web/*/https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg"><img data-attachment-id="2371" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg" data-orig-size="1853,2365" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="108 – T Lloyd Safety Last Tally’s Broadway Theatre below 2 crp" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=235" data-large-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=640" src="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=118&amp;h=150" alt="108 - T Lloyd Safety Last Tally's Broadway Theatre below 2 crp" width="118" height="150" srcset="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=118&amp;h=150 118w, https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=236&amp;h=300 236w" sizes="(max-width: 118px) 100vw, 118px"></a>The image of Harold Lloyd hanging desperately from the hands of a skyscraper clock during <em>Safety Last! </em>(1923) is one of the great icons of film history.&nbsp; Using maps, aerial views, and vintage photographs, my book <a href="http://www.amazon.com/Silent-Visions-Discovering-Hollywood-Through/dp/1595800573/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1330485203&amp;sr=1-1"><em>Silent Visions</em></a> shows how Harold filmed each of his five stunt-climbing comedies within the downtown Los Angeles Historic Core, while documenting the burgeoning urban skyline as it appears in the background of his films. [Note: <span>I will be introducing <em>Safety Last!</em> on June 25, 2016</span> at the Orpheum Theater as part of the Los Angeles Conservancy’s <a href="https://www.laconservancy.org/events/safety-last-orpheum-theatre">Last Remaining Seats</a>.]</p>
<div data-shortcode="caption" id="attachment_6143"><p><a href="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg"><img aria-describedby="caption-attachment-6143" data-attachment-id="6143" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/pan-04-9/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg" data-orig-size="1800,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="pan 04" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640" src="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640&amp;h=223" alt="On the roof of 908 S. Broadway from Safety Last! and the YouTube video clip" width="640" height="223" srcset="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640&amp;h=223 640w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=1278&amp;h=446 1278w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=150&amp;h=52 150w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=300&amp;h=105 300w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=768&amp;h=268 768w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=1024&amp;h=357 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-6143">The closing scene from <em>Safety Last!</em> (left) was filmed on the roof of 908 S. Broadway, the same building where the clock stunt climbing set was built. The same roof (right), now supporting the steel girder foundation for a large antennae, appears during the Criterion Collection <a href="http://youtu.be/tnrjyjKH5OU"><em>Locations and Effects</em> mini clip</a>.</p></div>
<p>The slides below show how the many <em>Safety Last!</em> stunts were created, and may be downloaded further below as a 14 MB PowerPoint presentation.&nbsp; You can also access a <a href="https://silentlocations.files.wordpress.com/2016/06/los-angeles-conservancy-harold-lloyd-safety-last-tour-bengtson-2016.pdf">self-guided walking tour</a> of the downtown locations appearing in <em>Safety Last!</em>, <em>Never Weaken, </em>and <em>Feet First. </em><a href="https://silentlocations.files.wordpress.com/2019/10/complete-list-of-all-harold-lloyd-stunt-climbing-buildings-updated-2019.pdf">(In all Lloyd employed 17 downtown buildings during his “thrill” comedies – see a PDF list of descriptions here</a><em><a href="https://silentlocations.files.wordpress.com/2019/10/complete-list-of-all-harold-lloyd-stunt-climbing-buildings-updated-2019.pdf">)</a>.<br>
</em></p>
<p>[Note: on the ground, Charlie Chaplin, Buster Keaton and Harold Lloyd <a href="https://silentlocations.com/chaplin-keaton-lloyd-alley/">filmed scenes from their masterpieces <em>The Kid</em> (1921), <em>Cops</em> (1922) and <em>Safety Last!</em> at the same Hollywood alley you can still visit today</a>.]</p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg"><img data-attachment-id="7315" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_01/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_01" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640&amp;h=480" alt="SL short blog_Page_01" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg"><img data-attachment-id="7316" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_02/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_02" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640&amp;h=480" alt="SL short blog_Page_02" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg"><img data-attachment-id="7317" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_03/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_03" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640&amp;h=480" alt="SL short blog_Page_03" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg"><img data-attachment-id="7318" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_04/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_04" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640&amp;h=480" alt="SL short blog_Page_04" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg"><img data-attachment-id="7319" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_05/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_05" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640&amp;h=480" alt="SL short blog_Page_05" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg"><img data-attachment-id="7320" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_06/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_06" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640&amp;h=480" alt="SL short blog_Page_06" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg"><img data-attachment-id="7321" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_07/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_07" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640&amp;h=480" alt="SL short blog_Page_07" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg"><img data-attachment-id="7322" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_08/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_08" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640&amp;h=480" alt="SL short blog_Page_08" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg"><img data-attachment-id="7323" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_09/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_09" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640&amp;h=480" alt="SL short blog_Page_09" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg"><img data-attachment-id="7324" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_10/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_10" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640&amp;h=480" alt="SL short blog_Page_10" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg"><img data-attachment-id="7325" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_11/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_11" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640&amp;h=480" alt="SL short blog_Page_11" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg"><img data-attachment-id="7326" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_12/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_12" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640&amp;h=480" alt="SL short blog_Page_12" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg"><img data-attachment-id="7327" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_13/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_13" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640&amp;h=480" alt="SL short blog_Page_13" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p>Here is the link to download the PowerPoint.&nbsp; Most of the slides are animated, so wait a moment each time before clicking the “next” button.</p>
<div data-shortcode="caption" id="attachment_2367"><p><a href="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg"><img aria-describedby="caption-attachment-2367" data-attachment-id="2367" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/untitled/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg" data-orig-size="609,644" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Untitled" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=284" data-large-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=609" title="Untitled" src="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=283&amp;h=300" alt="" width="283" height="300" srcset="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=283&amp;h=300 283w, https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=566&amp;h=600 566w, https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=142&amp;h=150 142w" sizes="(max-width: 283px) 100vw, 283px"></a></p><p id="caption-attachment-2367">The recent multiple Oscar-winning movie <em>Hugo</em> pays tribute to <em>Safety Last!</em>; first by including a clip of the Lloyd movie within the film, and also when the young hero Hugo Cabret finds himself hanging from a train station clock. <em>Hugo</em> (C) 2011 Paramount Pictures</p></div>
<p><a href="https://silentlocations.files.wordpress.com/2012/02/how-harold-lloyd-filmed-safety-last-by-john-bengtson.ppt">How Harold Lloyd Filmed Safety Last by John Bengtson</a></p>
<p>You will need a PowerPoint viewer to watch the show, and can download a PowerPoint viewer at this <a href="http://www.microsoft.com/downloads/en/details.aspx?displaylang=en&amp;FamilyID=cb9bf144-1076-4615-9951-294eeb832823">site</a>.</p>
<p>You can also check out <a href="https://silentlocations.wordpress.com/category/safety-last/">my other posts about <em>Safety Last! </em>here</a>.</p>
<p>A short segment from the <em>Locations and Effects</em> 2013 documentary with Academy-Award winning effects supervisor Craig Barron and the author filmed for the <a href="http://www.criterion.com/films/28446-safety-last">Criterion Collection release of the <em>Safety Last!</em> Blu-ray </a>appears below.</p>
<p><span><iframe width="560" height="315" src="https://www.youtube.com/embed/tnrjyjKH5OU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p><p><span>To see where Harold filmed his amazing comedies, be sure to check out my book <a href="https://www.amazon.com/Silent-Visions-Discovering-Hollywood-Through/dp/1595800573/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1533680311&amp;sr=1-1&amp;keywords=john+bengtson+silent"><em>Silent Visions</em></a>.&nbsp; </span></p>
<p><span>If you need a good laugh, or want to raise your spirits, just listen to Michael Mortilla’s audio-only recording of the audience laughing and squealing with delight while watching <em>Safety Last!</em>&nbsp; It’s great to play as background music <span>– the swells and squeals of laughter just grow and grow.</span></span></p>
<p><a href="http://www.midilifecrisis.com/Music_and_Sound/SafetyLast_Audience_Michael_Mortilla_Piano.mp3">Michael Mortilla accompanying Safety Last!</a></p>
<p>HAROLD LLOYD images and the names of Mr. Lloyd’s films are all trademarks and/or service marks of Harold Lloyd Entertainment Inc. Images and movie frame images reproduced courtesy of The Harold Lloyd Trust and Harold Lloyd Entertainment Inc.</p>
<p><img data-attachment-id="15216" data-permalink="https://silentlocations.com/chaplin-keaton-lloyd-alley/chaplin-keaton-lloyd-sign/" data-orig-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg" data-orig-size="1570,211" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Chaplin-Keaton-Lloyd-sign" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640" src="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640" alt="Chaplin-Keaton-Lloyd-sign" srcset="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640 640w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=1280 1280w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=150 150w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=300 300w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=768 768w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>Please help support naming the <a href="https://silentlocations.com/chaplin-keaton-lloyd-alley/">Chaplin Keaton Lloyd alley</a> in Hollywood by posting a review on <a href="https://goo.gl/maps/NGK6JpvncU3ejLDX7">Google Maps</a>. Prototype alley sign design by noted Dutch graphic artist – <a href="http://pietschreuders.com/">Piet Schreuders</a>. Download a 4-page brochure <a href="https://silentlocations.files.wordpress.com/2020/02/honor-the-chaplin-keaton-lloyd-alley.pdf">HERE</a>.</p>
<p>The site of the clock set, built on the roof of 908 S. Broadway on Google Maps.</p>

											</div></div>]]>
            </description>
            <link>https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823505</guid>
            <pubDate>Mon, 13 Jul 2020 17:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I started working in the cloud in a matter of days]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823272">thread link</a>) | @markothedev
<br/>
July 13, 2020 | https://microtica.com/an-outstanding-cloud-automation-experience/ | <a href="https://web.archive.org/web/*/https://microtica.com/an-outstanding-cloud-automation-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p><a href="https://microtica.com/" target="_blank" rel="noreferrer noopener">Microtica</a> has the goal to provide the best cloud automation experience for developers from its very beginnings. We are so happy when we hear a success story, especially from developers who weren’t familiar with cloud automation previously.&nbsp;</p>



<p>This is why we decided to bring to you a series of interviews with our customers that experience the benefits of our solution. They jumped into a whole new world in a matter of days instead of months. </p>



<p>We are calling it: <strong>Developers Say.&nbsp;</strong></p>



<p>The first developer we talked to is Marko, a full-stack developer from <a href="https://vertt.ch/">Vertt</a>.&nbsp;</p>



<p><em>You can read more about how Vertt accelerated its DevOps processes with Microtica <a href="https://microtica.com/case-studies/accelerating-devops-processes/" target="_blank" rel="noreferrer noopener">here</a>.</em></p>



<h2><strong>What’s the product you’re developing?</strong></h2>



<p><a href="https://vertt.ch/">Vertt</a> is a Swiss ride-hailing startup that provides a reliable, responsible and secure transportation experience. As a service, Vertt wants to fill in the voids that exist in the Swiss transportation system. We innovate all the time, in order to provide society with a one-stop mobility solution.&nbsp;</p>



<h2><strong>Which technologies did you use when developing the solution?&nbsp;</strong></h2>



<p>You could say we actually have <strong>five applications</strong>. Four are mobile-native iOS and Android applications, two for the passenger experience, and two are for the drivers. We also have <strong>one web application </strong>which is the admin panel for our business team, developed in Angular.</p>



<p>As for the backend and infrastructure part, the solution is built on the latest <strong>microservice technology with AWS as a cloud provider</strong>. The backend is developed in Node.js.&nbsp;</p>



<div><figure><img src="https://media-exp1.licdn.com/dms/image/C5603AQFmUaDjB8TNSg/profile-displayphoto-shrink_800_800/0?e=1599696000&amp;v=beta&amp;t=5D8Bl17XcfwZ91kQIRTsD-_mg_ag4O9jwwGWIAs4Nuc" alt=""><figcaption>Marko from Vertt</figcaption></figure></div>



<h2><strong>Can you tell us about your background as a developer?&nbsp;</strong></h2>



<p>I am a full-stack developer with two years of experience. Vertt is my first major project and my first time working on a project of this magnitude. This project is where <strong>I gained most of my knowledge and learned about the big picture.</strong> I’m developing <strong>the backend logic in NodeJS</strong> for the entire system. I’m also working on the dashboard for our business team in Angular. I’ve worked on just a few projects prior to this. They were mostly small websites that didn’t require a backend component or scalability features.</p>



<h2><strong>Why did you choose a microservice infrastructure for this particular project?</strong></h2>



<p>We often see startups <a href="https://microtica.com/why-transition-from-monolith-to-microservices/" target="_blank" rel="noreferrer noopener">kicking off with a monolithic application</a> just to get something out there. However, when they expand, they face <strong>various problems related to scalability and continuous integration</strong>.&nbsp;</p>



<p><em>We wanted to do it the right way. </em>The <a href="https://microtica.com/everything-about-microservices/" target="_blank" rel="noreferrer noopener">benefits of the microservice architecture</a> are well-known. <strong>Different codebases, separate deployable units performing separate functionalities</strong>, and the most important for us—<strong>scaling individually</strong>.&nbsp;</p>



<h2><strong>How did you deliver software before discovering Microtica?</strong></h2>



<p>We started using <strong>Jenkins </strong>as part of our DevOps process. As our team consists of full-stack and mobile developers, we were really <strong>struggling with all the setup and integration of numerous plug-ins.</strong> We were using Jenkins as a build orchestration tool. We soon became very <strong>limited by the release management</strong> that Jenkins has to offer. Issues like access control management, configuration usability, and scaling began to overwhelm us and defocus us from our daily tasks.</p>



<p>As the team began to grow, tracking and accountability of various team members became a great issue. As we did most deployments and builds via a single user,<strong> tracking was only at the code level </strong>through our source control tool Git.&nbsp;</p>



<h2><strong>What was the biggest challenge you had as a developer working with cloud automation?</strong></h2>



<p>The main challenge for any beginner or intermediate developer is <strong>connecting all pieces together </strong>and making them work as one. Understanding how the entire system is designed and managed behind the curtain in the cloud is a continuous process that consists of <strong>constant learning and hands-on effort.</strong> Coming across stuff like cloud automation, scaling, and continuous delivery is always challenging, especially if you don’t have much experience to get started.&nbsp;</p>



<h2><strong>How did Microtica help you overcome these challenges?</strong></h2>



<p>Microtica made deploying our entire system extremely<strong> easy and effortless.</strong> With just a few clicks and a few extra files, we set up and deployed our entire system consisting of 13 microservices.&nbsp;</p>



<p>After <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">setting up our initial development environment</a> <strong>it only took us one hour to get the test and production environments up and running.</strong> For this, we used the Clone Environment feature. This was really important to us because we wanted to fully migrate to Microtica before going to production.</p>



<p>The integration went <strong>smoothly and pretty fast</strong>. We only needed to create a couple of files in each microservice to create and guide the deployment pipeline. Now we can change parameters and redeploy our services within minutes and with almost no downtime.</p>



<p>It was extremely helpful that we could use their ready-to-use components. This eliminated the need to write complex CloudFormation templates for simple AWS resources. It allowed us to reuse the components by using just the UI.</p>



<h2><strong>How did Microtica help you grow as a developer?</strong></h2>



<p>Before working with Microtica, I didn’t have much experience and knowledge in the cloud automation space. Microtica gave me <strong>an initial push</strong>.  It made me confident enough to <strong>set up and maintain a fully functional system with three environments.</strong> I could create custom infrastructure and deploy microservices in the cloud <strong>in a matter of days.</strong> It allowed me to focus more on the actual development and less on infrastructure maintenance.</p>



<h2><strong>What kind of challenges are ahead of you and your team?</strong></h2>



<p>Our system is expanding on a daily basis along with its complexity. With a new feature every month, it’s crucial for us to have a firm grasp of<strong> the entire system at any time</strong>. Since we made a production release, <strong>stability has become our number one priority.</strong> It’s also probably the biggest challenge that we will face in the future.</p>



<figure><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101"><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg" alt="Start with cloud automation" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-300x180.jpg 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-768x461.jpg 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1536x922.jpg 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-667x400.jpg 667w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01.jpg 2000w" sizes="100vw"></a></figure>



<h2><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101" target="_blank" rel="noreferrer noopener">Sign up for Microtica</a> and start with cloud automation today.</h2>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:identifier="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:title="Developers Say: An Outstanding Cloud Automation Experience"
    trackback:ping="https://microtica.com/an-outstanding-cloud-automation-experience/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/an-outstanding-cloud-automation-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823272</guid>
            <pubDate>Mon, 13 Jul 2020 17:31:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Econometrics with R]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823031">thread link</a>) | @ethanwillis
<br/>
July 13, 2020 | https://www.econometrics-with-r.org/index.html | <a href="https://web.archive.org/web/*/https://www.econometrics-with-r.org/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">
<p>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span>selecting it with the cursor</span> and then click the <i></i> on the pop-up menu. You can also see the annotations of others: click the <i></i> in the upper right hand corner of the page 
</p>

<div id="preface">

<hr>
<center>
<img src="https://www.econometrics-with-r.org/images/cover.png">
</center>
<div><p> Chair of Econometrics <img src="https://www.econometrics-with-r.org/images/logo_claim_en_rgb.png"> <br> Department of Business Administration and Economics <br> University of Duisburg-Essen <br> Essen, Germany <br> <a href="https://www.econometrics-with-r.org//%22mailto:info@econometrics-with-r.org?subject=Econometrics%20with%20R\%22">info@econometrics-with-r.org</a></p><p> Last updated on Friday, August 30, 2019
</p>
</div>
<hr>
<p>Over the recent years, the statistical programming language R has become an integral part of the curricula of econometrics classes we teach at the University of Duisburg-Essen. We regularly found that a large share of the students, especially in our introductory undergraduate econometrics courses, have not been exposed to any programming language before and thus have difficulties to engage with learning R on their own. With little background in statistics and econometrics, it is natural for beginners to have a hard time understanding the benefits of having R skills for learning and applying econometrics. These particularly include the ability to conduct, document and communicate empirical studies and having the facilities to program simulation studies which is helpful for, e.g., comprehending and validating theorems which usually are not easily grasped by mere brooding over formulas. Being applied economists and econometricians, all of the latter are capabilities we value and wish to share with our students.</p>
<p>Instead of confronting students with pure coding exercises and complementary classic literature like the book by <span>Venables &amp; Smith (<a href="#ref-venables2010" role="doc-biblioref">2010</a>)</span>, we figured it would be better to provide interactive learning material that blends R code with the contents of the well-received textbook <em>Introduction to Econometrics</em> by <span>Stock &amp; Watson (<a href="#ref-stock2015" role="doc-biblioref">2015</a>)</span> which serves as a basis for the lecture. This material is gathered in the present book <em>Introduction to Econometrics with R</em>, an empirical companion to <span>Stock &amp; Watson (<a href="#ref-stock2015" role="doc-biblioref">2015</a>)</span>. It is an interactive script in the style of a reproducible research report and enables students not only to learn how results of case studies can be replicated with R but also strengthens their ability in using the newly acquired skills in other empirical applications.</p>
<div id="conventions-used-in-this-book">
<h4>Conventions Used in this Book</h4>
<ul>
<li><p><em>Italic</em> text indicates new terms, names, buttons and alike.</p></li>
<li><p><tt>Constant width text</tt> is generally used in paragraphs to refer to <tt>R</tt> code. This includes commands, variables, functions, data types, databases and file names.</p></li>
<li><p><code>Constant width text on gray background</code> indicates <tt>R</tt> code that can be typed literally by you. It may appear in paragraphs for better distinguishability among executable and non-executable code statements but it will mostly be encountered in shape of large blocks of <tt>R</tt> code. These blocks are referred to as code chunks.</p></li>
</ul>
</div>
<div id="acknowledgement">
<h4>Acknowledgement</h4>
<p>We thank the <em>Stifterverband für die Deutsche Wissenschaft e.V.</em> and the <em>Ministry of Science and Research North Rhine-Westphalia</em> for their financial support. Also, we are grateful to Alexander Blasberg for proofreading and his effort in helping with programming the exercises.
A special thanks goes to Achim Zeileis (University of Innsbruck) and Christian Kleiber (University of Basel) for their advice and constructive criticism. Another thanks goes to Rebecca Arnold from the Münster University of Applied Sciences for several suggestions regarding the website design and for providing us with her nice designs for the book cover, logos and icons. We are also indebted to all past students of our introductory econometrics courses at the University of Duisburg-Essen for their feedback.</p>
<p><br>
<img src="https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc-sa.eu.svg" alt="Creative Commons License"></p>
<p>This book is licensed under the <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
</div>
</div>
<h3>References</h3>
<div id="refs">
<p>Stock, J. H., &amp; Watson, M. W. (2015). <em>Introduction to Econometrics, Third Update, Global Edition</em>. Pearson Education Limited.</p>

</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://www.econometrics-with-r.org/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823031</guid>
            <pubDate>Mon, 13 Jul 2020 17:09:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula Webinar: Infrastructure as Code in OpenNebula using Terraform]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822942">thread link</a>) | @amarti
<br/>
July 13, 2020 | https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw | <a href="https://web.archive.org/web/*/https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Terraform, the open source Infrastructure as Code software tool created by HashiCorp, is a solution for building, changing, and versioning infrastructure safely and efficiently. It allows infrastructure to be expressed as code in a simple, human readable language called HCL. Terraform reads configuration files and provides an execution plan of changes, which can be reviewed for safety and then applied and provisioned automatically.</p><p>What to expect from this webinar?</p><p>- Learn about Terraform’s Infrastructure as Code approach and about its basic uses and capabilities, including the value it provides for managing the full lifecycle of your infrastructure, plan and predict changes, and create reproducible environments.</p><p>- Discover the new version and future roadmap of the OpenNebula Provider, through which cloud admins can use Terraform to interact with OpenNebula cluster resources.</p><p>- Watch a live demo on how this amazing integration is being used in an actual cloud, and how to simplify a real infrastructure workflow by using the OpenNebula Provider for Terraform.</p><p>This webinar will be presented by Michael Abdou (Customer Success Manager at OpenNebula). Our guest speakers for this event will be Taylor Dolezal (Senior Developer Advocate at HashiCorp) and Jean-Philippe Fourès (Cloud Product Manager at Iguane Solutions).</p><p>Press and media, please contact: events@opennebula.io
</p></div></div>]]>
            </description>
            <link>https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822942</guid>
            <pubDate>Mon, 13 Jul 2020 17:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effecftive Poster Design for Science Communication [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23822939">thread link</a>) | @pabloem
<br/>
July 13, 2020 | http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf | <a href="https://web.archive.org/web/*/http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822939</guid>
            <pubDate>Mon, 13 Jul 2020 17:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Open Source, licenses and changes]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 26 (<a href="https://news.ycombinator.com/item?id=23822732">thread link</a>) | @nfrankel
<br/>
July 13, 2020 | https://blog.frankel.ch/on-opensource-licenses-changes/ | <a href="https://web.archive.org/web/*/https://blog.frankel.ch/on-opensource-licenses-changes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting"> <meta itemprop="mainEntityOfPage" content="//on-opensource-licenses-changes/"> <meta itemprop="description" content="">  <figure itemscope="" itemprop="image" itemtype="http://schema.org/ImageObject"> <meta itemprop="url" content="https://blog.frankel.ch/assets/resources/open-source-licenses-changing/OSI_Standard_Logo_0.svg"> </figure> <section> <div itemprop="articleBody"> <p>The subject of Open Source and OS licenses has been waxing and waning over time. Recently, it became hot again. In this post, I’d like to do a quick recap to set the stage. Then, I’ll analyze reasons for license changes.</p> <div> <h2 id="the-rise-of-open-source">The rise of Open Source</h2> <div> <p>Before I actually started my career - even I was before even born - software was provided with its source code. The value was in the hardware. Most customers - if not every one of them - modified and adapted the source code to their hardware. Then, in 1969, the United States' government ruled (against IBM) that the bundling of software and hardware together was <em>anticompetitive</em>. The value moved from hardware to software because of an unexpected side-effect of the previous ruling. Thus began the rise of Microsoft Windows. Interestingly enough, that also changed the way software was delivered. Customers only got the binaries, not the source code. Of course, this is mostly the case today.</p> <p>Around ten years later, a new trend started in reaction to that: some with Richard Stallman decided that releasing the source code was the only <em>right</em> way to deliver software. Furthermore, their position was that software should be free. Because that tiny initiative became a respectable model, this view on things is more than relevant today. Today, Open Source means different things in the mind of different people.</p> </div> </div> <div> <h2 id="open-source-is-a-loaded-term">Open Source is a loaded term</h2> <div> <p>Literally, Open Source is only the delivery of the source code along the binary. No more, no less. For commercial software, if carefully worded in the purchasing contract, that means that the customer should be able to maintain the software if the vendor doesn’t anymore (<em>e.g.</em> goes bankrupt). Yet, according to Stallman’s definition, software needs to be free:</p> <div> <blockquote> <ul><li><span>Free as a bird</span></li><li><span>Free as a beer</span></li></ul> </blockquote> </div> <p>To avoid any confusion, I’d rather use the expression Free Open-Source Software <em>a.k.a.</em> FOSS.</p> </div> </div> <div> <h2 id="what-qualifies-as-open-source">What qualifies as Open Source</h2> <div> <p>This gap in the terms were deeply materialized in tensions in the community between tenants of the business-compatible Open Source and FOSS as defined above. From the former group was born the <a href="https://en.wikipedia.org/wiki/Open_Source_Initiative" target="_blank" rel="noopener">Open Source Initiative</a>. The importance of this organization cannot be understated: it decides what licenses are considered Open Source, based on the <a href="https://en.wikipedia.org/wiki/The_Open_Source_Definition">Open Source definition</a>. Criteria are:</p> <ol><li><span>Free Redistribution</span></li><li><span>Source Code</span></li><li><span>Derived Works</span></li><li><span>Integrity of The Author’s Source Code</span></li><li><span>No Discrimination Against Persons or Groups</span></li><li><span>No Discrimination Against Fields of Endeavor</span></li><li><span>Distribution of License</span></li><li><span>License Must Not Be Specific to a Product</span></li><li><span>License Must Not Restrict Other Software</span></li><li><span>License Must Be Technology-Neutral</span></li></ol> <p>As of the time of writing of this post, licenses that are allowed to be qualified as Open Source are <a href="https://opensource.org/licenses/alphabetical" target="_blank" rel="noopener">limited in number</a>. Here’s a couple of them:</p> <ul><li><span><a href="https://opensource.org/licenses/Apache-2.0">Apache License 2.0</a></span></li><li><span><a href="https://opensource.org/licenses/gpl-license">GNU General Public License (GPL)</a></span></li><li><span><a href="https://opensource.org/licenses/lgpl-license" target="_blank" rel="noopener">GNU Library or "Lesser" General Public License (LGPL)</a></span></li><li><span><a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener">MIT license</a></span></li></ul> <p>Here are two counter-examples:</p> <ul><li><span>The <a href="https://github.com/climate-strike/license" target="_blank" rel="noopener">Climate Strike License</a> is not Open Source, as it’s not in the list above</span></li><li><span><a href="https://creativecommons.org/licenses/">Creative Commons licenses</a> are not Open Source, as they don’t apply to software only</span></li></ul> </div> </div> <div> <h2 id="monetizing-open-source">Monetizing Open Source</h2> <div> <p>Open Source began as a community of like-minded people who wanted to create something together, and were willing to put on the extra effort, after office hours. However, today, the main contributors on the main projects are paid by private companies: they code during office hours. The reason for that is that Open Source - not FOSS - is compatible with business.</p> <p>There are a couple of ways to monetize Open Source software:</p> <div> <dl> <dt>Training and consulting</dt> <dd> <p>If you provide a great software, companies will start using it. At some point, there are chances they will need consulting, for advanced usage. After that, they will also need training to level up their workforce. It has been the traditional way to make money with Open Source. Unfortunately, this doesn’t scale.</p> </dd> <dt>Support</dt> <dd> <p>While consulting is planned, support comes in handy when the sh…​ has already hit the fan. Picture this: it’s 10PM, the monitoring Open Source stack your company uses has crashed, and refuse to start again. One definitely needs support in this case. <em>In general</em>, managers don’t like to use any kind of software - whether FOSS, Open Source or something else - if they don’t have an associated support contract.</p> </dd> <dt>Open Source core</dt> <dd> <p>The software offers features that are Open Source. A set of features available via extensions/plugins operate under a commercial (<em>i.e.</em> paying) license. The respective size of each depends on one’s strategy. The more features in the Open Source part, the more people will use it, but the less money one will get. This is a fine balance to find.</p> </dd> <dt>Dual license</dt> <dd> <p>The software is available under two different licenses, one Open Source, the other commercial. When one uses the software, one needs to choose which license should apply. For this model to work, and companies to decide to pay a license fee, the Open Source license should be a deterrent. The <a href="https://opensource.org/licenses/gpl-license" target="_blank" rel="noopener">GNU General Public License</a> is a solid choice: it mandates that software that embeds the GPL software should be released under the GPL license itself <em>i.e.</em> for free.</p> </dd> </dl> </div> </div> </div> <div> <h2 id="service-wrapping">Service-wrapping</h2> <div> <p>It’s no mystery that "the Cloud" has become ubiquitous since a couple of years, whether you like it or not. As more companies moved their IT-systems to the Cloud, the Cloud service providers became a force to be reckoned with. With that power, they bargained with software vendors on ways to provide the latter’s software on their infrastructure. In general, the deal was pretty much one-sided: Cloud providers got a larger portfolio of services, while software vendors got "free advertisement" for their software, and in the best of case, crumbs of the revenue.</p> <p>But even that was not enough. Some cloud providers became so bold as to stop pretending it was even a deal. They just got they greedy hands on the Open Source software, and service-wrapped it. It was completely legal, as none of the licenses prevents that. However, it raises the question of revenue sharing: one company is paying to develop the software, while another company is getting the biggest share of the revenues, because it controls the marketplace.</p> <p>Because of that, some software vendors decided to change their license to prevent service wrapping. The issue is that no Open Source license is able to achieve that. Hence, those new licenses are not considered Open Source, as per the Open Source Initiative definition.</p> </div> </div> <div> <h2 id="other-license-changes">Other license changes</h2> <div> <p>Changing one’s license is in general not a great idea. When somebody uses your software, they need to be able to trust they can use it in the future under the same terms. The anti-service wrapping changes made sure that was the case.</p> <p>Interestingly enough, I saw recently a license change unrelated to service wrapping. In the light of the CoVid-19 pandemics, somebody thought it would be a good idea to change the license to a new one:</p> <div> <blockquote> <p>CoronaVirus License :</p> <p>The coronavirus is coming to you. It’s coming at an exponential speed: gradually, and then suddenly. It’s a matter of days. Maybe a week or two. When it does, your healthcare system will be overwhelmed. Your fellow citizens will be treated in the hallways. Exhausted healthcare workers will break down. Some will die. They will have to decide which patient gets the oxygen and which one dies. The only way to prevent this is social distancing today. Not tomorrow. Today. That means keeping as many people home as possible, starting now.</p> <p>To use this program, you must</p>  <p>2) Apply social distancing</p> <p>If you live in UK, Europe, North &amp; South America, Iran, Japan, Korea…​ and if you refuse to do so, please uninstall Dummy from your system and do not use this service anymore.</p> </blockquote> </div> <p>While the intention behind this change was commendable, the change was not. This is a sure sign the license cannot be trusted. If it changes today, why cannot it change tomorrow, for other reasons? I’d advise everybody in this situation not to do that.</p> <div> <table> <tbody><tr> <td> <i title="Important"></i> </td> <td> The license change was rollbacked as it was considered at least partially unlawful. </td> </tr> </tbody></table> </div> </div> </div> <div> <h2 id="conclusion">Conclusion</h2> <div> <p>In this post, we described the origin of Open Source Software. We looked at the semantics of the expression "Open Source", and described the difference with <abbr title="Free Open Source Software">FOSS</abbr>. Then, we wrote about the Open Source Initiative, the characteristics it applies to define Open Source, and some licenses that fit this definition. We proceeded to list some ways on how to monetize FOSS. Finally, we described the problematic behavior of some Cloud providers, and how changing the license is a way to avoid it. Other reasons for license changes might break the contrast of trust between a software vendor and its users.</p> </div> </div>    </div> </section>   </article> </div> </div></div>]]>
            </description>
            <link>https://blog.frankel.ch/on-opensource-licenses-changes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822732</guid>
            <pubDate>Mon, 13 Jul 2020 16:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PiHole As-a-Service (On Steroids)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821863">thread link</a>) | @microkernel
<br/>
July 13, 2020 | https://www.gardion.de/english-intro | <a href="https://web.archive.org/web/*/https://www.gardion.de/english-intro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><img src="https://www.gardion.de/assets/svg/devices-37.svg" height="48" alt="Icon"></p><h3>My internet!</h3>
        <p>Facebook is breathing down your neck? Your Xiaomi mobile is spying
          on you? Your app is reporting where you go and which flight you take? Not anymore. Gardion is a filtering VPN
          with the sole purpose to keep you safe and your data private.<mark>Gardion is your internet „invisibility
            cloak“.</mark></p>
      </div><div>
        <p><img src="https://www.gardion.de/assets/svg/science-15.svg" height="48" alt="Icon"></p><h3>Anytime, anywhere</h3>
        <p>Gardion works on all devices, anywhere; be it your smartphone (iOS, Android),
          your tablet or your laptop. Being geeks we made sure that BSD, Linux and other open systems can interface as
          well. <mark>The only requirement: Support for IPSEC or Wireguard</mark>. It works at home, while travelling,
          via WIFI and mobile network.
        </p>
      </div><div>
        <p><img src="https://www.gardion.de/assets/svg/communications-16.svg" height="48" alt="Icon"></p><h3>Trust, instead of Panama</h3>
        <p>The other VPN providers reside in Panama, Romania or the Netherlands Antilles.
          With Gardion you are on the safe side: When you want to work in a strong and trustworthy jurisdiction Germany
          is your choice. <mark>Our headquarter is in Freiburg/Germany and our servers are in Germany as well. No AWS,
            no Google cloud</mark>.
        </p>
      </div></div>]]>
            </description>
            <link>https://www.gardion.de/english-intro</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821863</guid>
            <pubDate>Mon, 13 Jul 2020 15:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deschooling Society (1970)]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 179 (<a href="https://news.ycombinator.com/item?id=23821855">thread link</a>) | @minerjoe
<br/>
July 13, 2020 | https://davidtinapple.com/illich/1970_deschooling.html | <a href="https://web.archive.org/web/*/https://davidtinapple.com/illich/1970_deschooling.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="700">
				<tbody><tr>
					<td><span size="+2">DESCHOOLING SOCIETY</span><p>
						
						&nbsp;
						IVAN ILLICH</p><p>
						
						&nbsp;
						
						&nbsp;
						Contents</p><p>
						
						&nbsp;
						
						Introduction xix </p><p>
						
						<a href="#1">1. Why We Must Disestablish School</a></p><p>
						
						<a href="#2">2. Phenomenology of School<br>
						</a><br>
						<a href="#3">3. Ritualization of Progress<br>
						</a><br>
						<a href="#4">4. Institutional Spectrum</a></p><p>
						
						<a href="#5">5. Irrational Consistencies</a></p><p>
						
						<a href="#6">6. Learning Webs</a></p><p>
						
						<a href="#7">7. Rebirth of Epimethean Man</a></p><p>
						
						&nbsp;
						
						
						
						
						&nbsp;
						
						Introduction</p><p>
						
						
						&nbsp;
						
						I owe my interest in public education to Everett Reimer. Until we first met in Puerto Rico in 1958, I had never questioned the value of extending obligatory schooling to all people. Together we have come to realize that for most men the right to learn is curtailed by the obligation to attend school. The essays given at CIDOC and gathered in this book grew out of memoranda which I submitted to him, and which we discussed during 1970, the thirteenth year of our dialogue. The last chapter contains my afterthoughts on a conversation with Erich Fromm on Bachofen's Mutterrecht.</p><p>
						
						
						Since 1967 Reimer and I have met regularly at the Center for Intercultural Documentation (CIDOC) in Cuernavaca, Mexico. Valentine Borremans, the director of the Center, also joined our dialogue, and constantly urged me to test our thinking against the realities of Latin America and Africa. This book reflects her conviction that the ethos, not just the institutions, of society ought to be "deschooled."</p><p>
						
						
						Universal education through schooling is not feasible. It would be no more feasible if it were attempted by means of alternative institutions built on the style of present schools. Neither new attitudes of teachers toward their pupils nor the proliferation of educational hardware or software (in classroom or bedroom), nor finally the attempt to expand the pedagogue's responsibility until it engulfs his pupils' lifetimes will deliver universal education. The current search for new educational funnels must be reversed into the search for their institutional inverse: educational webs which heighten the opportunity for each one to transform each moment of his living into one of learning, sharing, and caring. We hope to contribute concepts needed by those who conduct such counterfoil research on education--and also to those who seek alternatives to other established service industries.</p><p>
						
						
						On Wednesday mornings, during the spring and summer of 1970, I submitted the various parts of this book to the participants in our CIDOC programs in Cuernavaca. Dozens of them made suggestions or provided criticisms. Many will recognize their ideas in these pages, especially Paulo Freire, Peter Berger, and Jos? Maria Bulnes, as well as Joseph Fitzpatrick, John Holt, Angel Quintero, Layman Allen, Fred Goodman, Gerhard Ladner, Didier Piveteau, Joel Spring, Augusto Salazar Bondy, and Dennis Sullivan. Among my critics, Paul Goodman most radically obliged me to revise my thinking. Robert Silvers provided me with brilliant editorial assistance on Chapters 1, 3, and 6, which have appeared in The New York Review of Books.</p><p>
						
						
						Reimer and I have decided to publish separate views of our joint research. He is working on a comprehensive and documented exposition, which will be subjected to several months of further critical appraisal and be published late in 1971 by Doubleday &amp; Company. Dennis Sullivan, who acted as secretary at the meetings between Reimer and myself, is preparing a book for publication in the spring of 1972 which will place my argument in the context of current debate about public schooling in the United States. I offer this volume of essays now in the hope that it will provoke additional critical contributions to the sessions of a seminar on "Alternatives in Education" planned at CIDOC in Cuernavaca for 1972 and 1973.</p><p>
						
						
						I intend to discuss some perplexing issues which are raised once we embrace the hypothesis that society can be deschooled; to search for criteria which may help us distinguish institutions which merit development because they support learning in a deschooled milieu; and to clarify those personal goals which would foster the advent of an Age of Leisure (schole) as opposed to an economy dominated by service industries. </p><p>
						
						
						IVAN ILLICH</p><p>
						
						
						&nbsp;
						
						
						CIDOC</p><p>
						
						
						Cuernavaca, Mexico</p><p>
						
						
						November, 1970<br>
						<a name="1"></a>.</p><a href="#top"><span size="-1">index&nbsp;</span></a><span size="+1">1.  Why We Must Disestablish School</span><p>
						
						
						&nbsp;
						
						
						Many students, especially those who are poor, intuitively know what the schools do for them. They school them to confuse process and substance. Once these become blurred, a new logic is assumed: the more treatment there is, the better are the results; or, escalation leads to success. The pupil is thereby "schooled" to confuse teaching with learning, grade advancement with education, a diploma with competence, and fluency with the ability to say something new. His imagination is "schooled" to accept service in place of value. Medical treatment is mistaken for health care, social work for the improvement of community life, police protection for safety, military poise for national security, the rat race for productive work. Health, learning, dignity, independence, and creative endeavor are defined as little more than the performance of the institutions which claim to serve these ends, and their improvement is made to depend on allocating more resources to the management of hospitals, schools, and other agencies in question.</p><p>
						
						
						In these essays, I will show that the institutionalization of values leads inevitably to physical pollution, social polarization, and psychological impotence: three dimensions in a process of global degradation and modernized misery. I will explain how this process of degradation is accelerated when nonmaterial needs are transformed into demands for commodities; when health, education, personal mobility, welfare, or psychological healing are defined as the result of services or "treatments." I do this because I believe that most of the research now going on about the future tends to advocate further increases in the institutionalization of values and that we must define conditions which would permit precisely the contrary to happen. We need research on the possible use of technology to create institutions which serve personal, creative, and autonomous interaction and the emergence of values which cannot be substantially controlled by technocrats. We need counterfoil research to current futurology.</p><p>
						
						
						I want to raise the general question of the mutual definition of man's nature and the nature of modern institutions which characterizes our world view and language. To do so, I have chosen the school as my paradigm, and I therefore deal only indirectly with other bureaucratic agencies of the corporate state: the consumer-family, the party, the army, the church, the media. My analysis of the hidden curriculum of school should make it evident that public education would profit from the deschooling of society, just as family life, politics, security, faith, and communication would profit from an analogous process.</p><p>
						
						
						I begin my analysis, in this first essay, by trying to convey what the deschooling of a schooled society might mean. In this context, it should be easier to understand my choice of the five specific aspects relevant to this process with which I deal in the subsequent chapters.</p><p>
						
						
						Not only education but social reality itself has become schooled. It costs roughly the same to school both rich and poor in the same dependency. The yearly expenditure per pupil in the slums and in the rich suburbs of any one of twenty U.S. cities lies in the same range-and sometimes is favorable to the poor. Rich and poor alike depend on schools and hospitals which guide their lives, form their world view, and define for them what is legitimate and what is not. Both view doctoring oneself as irresponsible, learning on one's own as unreliable, and community organization, when not paid for by those in authority, as a form of aggression or subversion. For both groups the reliance on institutional treatment renders independent accomplishment suspect. The progressive underdevelopment of self- and community-reliance is even more typical in Westchester than it is in the northeast of Brazil. Everywhere not only education but society as a whole needs "deschooling."</p><p>
						
						
						Welfare bureaucracies claim a professional, political, and financial monopoly over the social imagination, setting standards of what is valuable and what is feasible. This monopoly is at the root of the modernization of poverty. Every simple need to which an institutional answer is found permits the invention of a new class of poor and a new definition of poverty. Ten years ago in Mexico it was the normal thing to be born and to die in one's own home and to be buried by one's friends. Only the soul's needs were taken care of by the institutional church. Now to begin andend life at home become signs either of poverty or of special privilege. Dying and death have come under the institutional management of doctors and undertakers.</p><p>
						
						
						Once basic needs have been translated by a society into demands for scientifically produced commodities, poverty is defined by standards which the technocrats can change at will. Poverty then refers to those who have fallen behind an advertised ideal of consumption in some important respect. In Mexico the poor are those who lack three years of schooling, and in New York they are those who lack twelve.</p><p>
						
						
						The poor have always been socially powerless. The increasing reliance on institutional care adds a new dimension to their helplessness: psychological …</p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidtinapple.com/illich/1970_deschooling.html">https://davidtinapple.com/illich/1970_deschooling.html</a></em></p>]]>
            </description>
            <link>https://davidtinapple.com/illich/1970_deschooling.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821855</guid>
            <pubDate>Mon, 13 Jul 2020 15:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Virgin YouTube vs. the Chad PeerTube]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23821616">thread link</a>) | @antepodius
<br/>
July 13, 2020 | https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3 | <a href="https://web.archive.org/web/*/https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821616</guid>
            <pubDate>Mon, 13 Jul 2020 15:15:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 rituals I followed to be a better programmer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821485">thread link</a>) | @arpitbbhayani
<br/>
July 13, 2020 | https://arpitbhayani.me/blogs/better-programmer | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/better-programmer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>"How to get better at programming?" is the question I had been asked quite a few times, and today I lay down the 8 rituals I have been following, and action items for each, to be good and get better at programming.</p>

<p>Doing something repeatedly always helps and writing a lot of code will develop our ability to</p>
<ul>
<li>write code while we think</li>
<li>think faster, think better</li>
<li>foresee requirement changes and possible logic extensions</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>One significant contribution to a project every two weeks</li>
<li>Solve at least two programming questions (from <a href="https://www.codechef.com/">Codechef</a>, <a href="https://www.spoj.com/">Spoj</a> or <a href="https://www.hackerrank.com/">HackerRank</a>) every week, till we solve at least 300 questions</li>
</ul>

<p>If we don't do something repeatedly, it becomes extremely hard to get good at it. Writing code consistently helps us</p>
<ul>
<li>define the programmatic and algorithmic flow quickly</li>
<li>build a habit of programming and thinking analytically</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>make one small contribution to anyone project every three days</li>
</ul>

<p>Solving programming questions is about developing logic but things become a little trickier when we build a complex system, as it requires us to take our programming skills to go up a notch. Some examples of complex systems are - a Library management system, a <a href="https://twitter.com/">Twitter</a> clone, an <a href="https://www.instagram.com/">Instagram</a> clone, etc. Building a complex system</p>
<ul>
<li>widens our tech stack</li>
<li>makes us keep our code flexible, extensible and reusable</li>
<li>helps us understand how to split our code into independent segments that work in harmony</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>build one complex system every 4 months</li>
</ul>

<p>After we spend some time writing programs and solving problems, things become monotonous and do not seem to challenge us anymore, so to spice things up a bit we should model something from the real world, like</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Projectile_motion">projectile motion</a></li>
<li><a href="https://en.wikipedia.org/wiki/Double_pendulum">double pendulum</a></li>
<li><a href="https://en.wikipedia.org/wiki/Numerical_model_of_the_Solar_System">solar system simulation</a></li>
</ul>
<p>There are lots of libraries and framework like <a href="https://p5js.org/">p5.js</a> that makes visual programming simple.</p>
<h3>Action Items</h3>
<ul>
<li>once every 6 months model a physical phenomenon</li>
</ul>

<p>It is not only writing code that improves our programming skills but it is reading some quality code written by expert programmers that make the difference. Reading code written by experts improve our programming vocabulary and by doing this we</p>
<ul>
<li>learn the best programming practices</li>
<li>discover the new programming paradigms</li>
<li>find ways to properly structure our code for extensibility</li>
</ul>
<p>The best way to start doing it is by picking up an open-source project and start skimming the code. It is okay to not understand it in the first go but it is important to skim it a few times and get acquainted. After a few skim, everything will fall in place, the code becomes familiar and we start to understand the flow and business logic.</p>
<h3>Action Items</h3>
<ul>
<li>pick an open-source project every 6 months and skim its code once every two months</li>
<li>pick a tiny open-source utility, from an experienced developer, every month and skim it</li>
</ul>

<p>There is always someone sitting on the other side of the globe, who knows a thing or two more than us. Look for them and collaborate on a project. The developer community is filled with super smart and super enthusiastic developers who love to share and collaborate. Use websites like <a href="https://dev.to/">Dev.to</a>, <a href="https://hashnode.com/">Hashnode</a> and <a href="https://twitter.com/">Twitter</a> to find and interact with like-minded people.</p>
<h3>Action Items</h3>
<ul>
<li>collaborate on a project once a year</li>
<li>be active on platforms like <a href="https://dev.to/">Dev.to</a>, <a href="https://hashnode.com/">Hashnode</a> and <a href="https://twitter.com/">Twitter</a></li>
</ul>

<p>A programming language is just a tool to express business logic. While learning a programming language we should try to understand the constructs and paradigms used - for example: <a href="https://en.wikipedia.org/wiki/Functional_programming">Functional programming</a>, <a href="https://en.wikipedia.org/wiki/Polymorphism_(computer_science)">Polymorphism</a>, <a href="https://en.wikipedia.org/wiki/Event-driven_programming">Event driven programming</a>, <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a>, etc. It is important to do so because we could pick constructs from one language and use it in another to solve our problem. For example: picking Functional programming (Callbacks) from Javascript and using it in Python to create generic action functions.</p>
<h3>Action Items</h3>
<ul>
<li>learn one design pattern every month and build a simulation around it</li>
<li>pick a language construct and implement it in some other language</li>
</ul>

<p>Writing code before putting in some thought is degraded the code more often than not. The code written like this lacks simplicity, reusability, and extensibility. Spending some time thinking about problem statement or task at hand and having a rough execution plan always helps.</p>
<h3>Action Items</h3>
<ul>
<li>always define the scope of implementation, create an execution plan and then code</li>
</ul>

<p>These rituals have helped me get better at programming with time and in parallel, I pick at max 3 and act on the action items. Programming is simple but being better than most is difficult. Doing it consistently makes one get better by the day.</p>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/better-programmer</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821485</guid>
            <pubDate>Mon, 13 Jul 2020 15:03:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Income/savings calculator for moving to Canada]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23821323">thread link</a>) | @senecaso
<br/>
July 13, 2020 | https://boomstick.games/northward/index.html | <a href="https://web.archive.org/web/*/https://boomstick.games/northward/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://boomstick.games/northward/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821323</guid>
            <pubDate>Mon, 13 Jul 2020 14:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling to Assembly from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23821305">thread link</a>) | @halst
<br/>
July 13, 2020 | https://keleshev.com/compiling-to-assembly-from-scratch | <a href="https://web.archive.org/web/*/https://keleshev.com/compiling-to-assembly-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        

<p><span id="home"><a title="Home" href="https://keleshev.com/">☰</a></span></p>



<!--



md5-79bfa919c595b8f7aa78f6d429bc2a15


-->

<center><img id="cover" src="https://keleshev.com/compiling-to-assembly-from-scratch.jpg" width="200" height="300"></center>

<center><p> <a href="https://transactions.sendowl.com/products/78310234/604B9EF1/purchase" rel="nofollow"> Pre-order •  <b>$27</b> </a></p></center>

<center><em>TypeScript — ARM  — August 2020</em></center>

<p><big><em>So, you’ve been trying to learn how compilers and programming languages work?</em> </big></p>

<p>Perhaps, you’ve learned about compiling to JavaScript,
or about building an interpreter? Or, maybe, about
compiling to bytecode? All good steps.</p>

<p><em>But there’s a tension building up.</em></p>

<p>Because it feels a bit like cheating.
Because you know that somewhere, somehow, the code you write
is translated to assembly instructions. To the machine language.
That’s where the rubber hits the road. That’s where it gets hot.
And, oh-so-many resources are hesitant to cover this part.
But not this book.</p>

<p>This ebook will show you in detail
how you can build a compiler from scratch
that goes all the way from <em>source</em> to <em>assembly</em>.</p>

<p>The example code is written in <strong>TypeScript</strong>, a dialect of <strong>JavaScript</strong>.
The book describes the design and implementation of a compiler that emits
32-bit <strong>ARM</strong> assembly instructions.</p>



<blockquote>
  <h2>Pre-order and get a draft!</h2>
  
  
  
  <p><strong><em>You get now:</em></strong></p>
  
  <ul>
  <li>Draft <em>(contains full Part I of the book)</em></li>
  <li>PDF-only</li>
  <li>DRM-free</li>
  <li>Source code <em>(link in the book)</em></li>
  <li>Discourse forum: book’s private community <em>(invite in the book)</em></li>
  </ul>
  
  <p><strong><em>You get later</em></strong> <em>(ETA–August 2020)<strong></strong></em><strong><em>:</em></strong></p>
  
  <ul>
  <li>Complete book</li>
  <li>All future revisions</li>
  <li>PDF, EPUB <em>(other formats on request)</em></li>
  <li>DRM-free</li>
  </ul>
  
  <p><em>Note, $27 is pre-order–only price with 40% discount. When the book is out it will be $45.</em>
  <br></p>
</blockquote>



<h2>Why ARM?</h2>

<p>In many ways, the ARM instruction set is what makes this book possible.</p>

<p>Compared to Intel x86-64, the ARM instruction set is a work of art.</p>

<p>Intel x86-64 is the result of evolution from an 8-bit processor,
to a 16-bit one, then to a 32-bit one, and finally to a 64-bit one.
At each step of the evolution, it accumulated complexity and cruft.
At each step, it tried to satisfy conflicting requirements.</p>

<ul>
<li>Intel x86-64 is based on <em>Complex Instruction Set Architecture</em> (CISC),
which was initially optimized for writing assembly by hand.</li>
<li>ARM, on the other hand, is based on <em>Reduced Instruction Set Architecture</em> (RISC),
which is optimized for writing compilers.</li>
</ul>

<p><em>Guess which one is an easier target for a compiler?</em></p>

<p>If this book targeted Intel x86-64 instead of ARM, it would have been two times as long
and — more likely — never written.
Also, with 160 <em>billion</em> devices shipped, we better get used to the fact
that ARM is the dominant instruction set architecture today.</p>

<p>In other words… ARM is a good start.
After learning it, you will be better equipped
for moving to x86-64 or the new ARM64.</p>

<p><em>Will you be able to run the code your compiler produces?</em></p>

<p>I bet you will! The Appendix will contain a bazillion ways
to execute ARM code, starting from Raspberry Pi,
cloud VM, to various ways to emulate ARM on Linux, Windows, and macOS.</p>

<h2>Why TypeScript?</h2>

<p>First of all, you will be able to follow this book in any reasonable programming language.
For me, it was tough to pick one for this job, and I’m pleased I’ve chosen TypeScript.</p>

<p>TypeScript is probably nobody’s favorite, but it’s a good compromise:</p>

<ul>
<li>Are you coming from a dynamic language like JavaScript, Python, or Ruby?
Then if you close your eyes at the
type annotations, TypeScript is just modern-day JavaScript.</li>
<li>If you’re coming from Java or C#, then you will feel right at home,
since TypeScript
is brought to you by the same people who brought you C# <em>(and Turbo Pascal!)</em>.</li>
</ul>

<p>Don’t worry if you’ve never seen TypeScript code before.
If you can read the following, you will most likely be able to pick it up,
as the book goes <em>(real code from the book here!)</em>:</p>

<pre><b>class </b>Label {
  <b>static </b>counter = 0;
  value: number; <em>// Type annotation
</em>
  <b>constructor</b>() {
    <b>this</b>.value = Label.counter++;
  }

  toString() {
    <b>return </b>'.L' + <b>this</b>.value;
  }
}
</pre>

<p>I avoided using any TypeScript- or JavaScript-specific
language features in the code.</p>

<p>If you’re into statically-typed functional programming
languages (Haskell, OCaml, or Reason ML),
you will find that the class structure I used
has a nice translation to an algebraic data type.
It is, in fact, how I wrote it first.</p>



<h2>Book Contents</h2>

<p>The book consists of two parts. Part I
presents a <em>detailed</em>, <em>step-by-step</em> guide on how
to develop a small “baseline” compiler that can compile simple
programs to ARM assembly.</p>

<p>By the end of Part I, you will have a working compiler that can
compile simple functions like this one:</p>

<!--table>
<tr>
<td>


md5-73395652867122248e3299aa94c98c61


</td>
<td>
</td>
</tr>
</table-->

<pre><b>function </b>factorial(n) {
  <b>if </b>(n == 0) {
    <b>return </b>1;
  } <b>else </b>{
    <b>return </b>n * factorial(n - 1);
  }
}
</pre>

<p>Into ARM assembly code like this:</p>

<pre>.global factorial
factorial:
  <b>push </b>{fp, lr}
  <b>mov </b>fp, sp
  <b>push </b>{r0, r1}
  <b>ldr </b>r0, =0
  <b>push </b>{r0, ip}
  <b>ldr </b>r0, [fp, #-8]
  <b>pop </b>{r1, ip}
  <b>cmp </b>r0, r1
  <b>moveq </b>r0, #1
  <b>movne </b>r0, #0
  <b>cmp </b>r0, #0
  <b>beq </b>.L1
  <b>ldr </b>r0, =1
  <b>b </b>.L2
.L1:
  <b>ldr </b>r0, =1
  <b>mov </b>r1, r0
  <b>ldr </b>r0, [fp, #-8]
  <b>sub </b>r0, r0, r1
  <b>bl </b>factorial
  <b>mov </b>r1, r0
  <b>ldr </b>r0, [fp, #-8]
  <b>mul </b>r0, r0, r1
.L2:
  <b>mov </b>sp, fp
  <b>pop </b>{fp, pc}
</pre>

<p>This code won’t win any awards, and an optimizing compiler
could do much better, but it’s a start!</p>

<p>Part II talks about <em>more advanced</em> topics in <em>less details</em>.
It explores several different (often mutually exclusive)
directions in which you can take your compiler.</p>

<center>⁂</center>

<center><a id="excerpt" href="https://keleshev.com/excerpt-compiling-to-assembly-from-scratch.pdf"><img id="excerpt" src="https://keleshev.com/book-preview.png" width="400" height="300"></a></center>

<center><a href="https://keleshev.com/excerpt-compiling-to-assembly-from-scratch.pdf"> Read Excerpt </a></center>

<center><img src="https://keleshev.com/keleshev.jpg" width="200" height="200"></center>

<h2>About me</h2>

<p>My name is Vladimir Keleshev,
I have worked with compilers both commercially
and in open-source.
My fondness of ARM assembly stems from
my previous work in embedded systems.
Currently, I work in finance
with domain-specific languages.
I’m <a href="https://twitter.com/keleshev">@keleshev</a> on Twitter.</p>



<blockquote>
  <h2>Be the first to know when the book is finalized!</h2>
  
  <center>Reading a draft is not your style? I get it. Subscribe to be notified when the book is finalized (and related news about the book and compilers).</center>
  
  <center><a href="https://sellfy.com/p/bkz0pv/" id="bkz0pv" data-text="Pre-order"></a></center>
  
  
  
  <center><small>You can unsubscribe at any time</small></center>
</blockquote>

<!--


md5-7ee03ea5643bff2df00890120280d45e



When I write blog posts I usually spent the first half
of the time writing the code and develoing the idea, and
the second half on the prose.
This book will be no exception.

At the moment I have finished writing
the code, and I am very happy with the results.
I expect the book to be ready early summer 2020, and a draft to
be available even sooner.

-->



<center><img src="https://keleshev.com/dragon.png" width="256" height="260"></center>

<center><em>Illustrations by <a href="https://twitter.com/PbKatiuska">@PbKatiuska</a></em></center>

    

</div>]]>
            </description>
            <link>https://keleshev.com/compiling-to-assembly-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821305</guid>
            <pubDate>Mon, 13 Jul 2020 14:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I made $11,673 in 5 days with an open-source project]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23821220">thread link</a>) | @samuelstancl
<br/>
July 13, 2020 | https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/ | <a href="https://web.archive.org/web/*/https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div v-pre="">
            <p>At the end of June, I launched a business-focused extension to my open-source project. <a href="https://tenancyforlaravel.com/saas-boilerplate/">The multi-tenant SaaS boilerplate for Laravel</a>.</p>

<p>The sales completely exceeded my expectations.</p>

<p>$4,980 within the first 24 hours and $11,673 within the first 5 days.</p>

<p>🤯</p>

<p>Here’s the story leading to this.</p>

<h2>Story of the project</h2>

<p>Exactly 2 years ago (June 2018), I was 16 and I decided to start building my first SaaS application. It was meant to be an e-commerce platform focused on B2B sales.</p>

<p>After working on the project for 9 months, I needed to implement <a href="https://www.indiehackers.com/post/what-is-multi-tenancy-why-you-might-need-it-8a0d64f161">multi-tenancy</a>. I looked at the existing solutions (Laravel packages) and they all felt extremely confusing and complex.</p>

<p>I decided to do the naive thing and write my own package. See, I wasn’t very experienced with Laravel at this point. I’ve only been using it since around July 2018. And this was at the beginning of 2019.</p>

<p>The main thing that I disliked about the existing solutions was that they pretty much required that you rebuild your entire application around their package.</p>

<p>That felt horrifying to me — again, I wasn’t a very experienced developer.</p>

<p>I felt like there should be a solution that just works with an existing application. The basic idea of multi-tenancy is letting customers have separate databases. Why would I have to rewrite my entire application for this? Why can’t I just tell the app to use database X after identifying the customer?</p>

<h3>Version 1</h3>

<p>I released v1 of the package in February. It was limited in features, but it fulfilled my needs. I didn’t have to rewrite my app anymore.</p>

<p>The package didn’t get much traction at this point.</p>

<p><img src="https://samuelstancl.me/assets/img/tenancy-stars-v1.png" alt="The star count for version 1"></p>

<p>On February 17, it got the first star on GitHub. 3 months later, it only had 60 stars.</p>

<p>And my SaaS wasn’t succeeding either. I decided to abandon the project basically immediately after I wrote the multi-tenancy package. I realized how bad the code was. The product market fit was there, but I didn’t want to work on this codebase anymore.</p>

<p>I started some other projects instead. They of course got abandoned too, after a few months. Such is the life of SaaS.</p>

<h3>Version 2</h3>

<p>In July, I decided to double down on the package. I started working on version 2. It added a lot more features and made it less proof-of-concept-y and more production ready. Fulfilled more business needs.</p>

<p>In August, I created a landing page for the project. I started <strong>treating it more as a product</strong>.</p>

<p><img src="https://i0.wp.com/wp.laravel-news.com/wp-content/uploads/2019/10/stancl-tenancy.jpg?fit=2220%2C1125&amp;ssl=1?resize=2200%2C1125" alt="The first landing page">
<small>The first landing page.</small></p>

<p>By the end of August, the project had some 216 stars.</p>

<p>I doubled down on the marketing side of things, got some articles written and by the end of October, the project was at 476 stars.</p>

<h3>Burnout</h3>

<p>At this point, I took a hiatus from the project. I was juggling multiple projects at once and was starting to get severely burnt out.</p>

<p>For the following two months, I got basically zero work done. On any projects. This was the darkest time for me, work and focus-wise.</p>

<p>There’s a positive side to it, though. Experiencing a strong burnout for a manageable period of time is good — if you analyze it well. Teaches you what <strong>not</strong> to do and how much it sucks to be burnt out. After an experience like that, you’ll focus very hard on not getting burnt out.</p>

<p><img src="https://builtwithtailwind.s3.amazonaws.com/237/conversions/tenancy.samuelstancl.me_-featured.jpg" alt="The second landing page">
<small>I finished this period of focusing on the package with a second, better-designed landing page.</small></p>

<h3>The lockdown</h3>

<p>The coronavirus pandemic was a blessing in disguise when it comes to side projects.</p>

<p>Instead of school, I got to stay at home.</p>

<p>In the past few months I didn’t do much work. So working now was actually refreshing!</p>

<p>The timing really couldn’t have been any better. School got closed first week of March. About 2 weeks after I could (and did) legally get my sole proprietor license.</p>

<p>I took on a bit of client work, started making a bit of $ from that, but mostly <strong>I again focused on the package</strong>.</p>

<p>There were some quirks I didn’t like about the architecture of the code. I also didn’t like that the package was making an impression of being too opinionated and not enterprise™ enough.</p>

<p>So I focused on fixing exactly that.</p>

<p>I contacted a person who was interested in me adding some more enterprise-y features back in October. I explained that I’m focusing on the package again and that I’d like to add a lot of things to it.</p>

<p>He was very glad to hear this. We talked for a while and he offered <strong>sponsoring me to add specific features to the open-source package</strong>:</p>

<blockquote>
  <p>Let me know if €5,000 is a good price for you.</p>
</blockquote>

<p>This was huge.</p>

<p>See, the project was released in February 2019. And there were <strong>no donations whatsoever</strong> until October.</p>

<p><img src="https://docs.google.com/spreadsheets/d/e/2PACX-1vSJCo55YgQmuVaJCuyfsKmSs23UIemGD3g198A5fvYhSQeMdzBI7NA7z9NEx0VwbNSEYdj_N4uZEsBx/pubchart?oid=1707722928&amp;format=image" alt="Donations between launch (February 2019 and March 2020)"></p>

<p>And even until March, the donations totaled $111.</p>

<p>5,000 EUR felt massive.</p>

<p>This was at the end of April.</p>

<p>I accepted the offer, expressed great gratitude and got to work.</p>

<p>I decided to focus <strong>FULLY</strong> on the package.</p>

<p>I was writing code and documentation all <strike>days</strike> nights long. Quarantine did its thing on my sleep schedule, but I was happy. Got a ton of work done.</p>

<p>Woke up at 16:00, went to bed at 8:00. Every day.</p>

<p>On May 13th (about 2-3 weeks after the donation) I announced a closed beta.</p>

<p>Why closed? Continue reading.</p>

<h3>Competition</h3>

<p>Like I said, there were other packages.</p>

<p>The project that made me create my own package also had a sister package. It was in development for seemingly forever.</p>

<p>However, in May, Spatie — a web development agency that’s very famous in the Laravel world for their open-source work — started writing their own multi-tenancy package.</p>

<p>This made the other project hurry development too. So in May, these packages were being released:</p>

<ul>
<li>My package’s version 3</li>
<li>Spatie’s new package</li>
<li>tenancy.dev’s new package</li>
</ul>

<p>This got stressful fast.</p>

<p>The Spatie package was built on the same principles as my package. Automatic, no changes needed. Except it was a lot simpler version.</p>

<p>That was no good!</p>

<p>Also remember when I said that I was trying to focus my package more on the enterprise-y needs, like flexibility? That’s what the tenancy.dev package is about, to a large degree.</p>

<p>Hence the closed beta. I ain’t showing no code to competition!</p>

<p><img src="https://samuelstancl.me/assets/img/tenancy-stars-comparison.svg" alt="Comparison of GitHub stars between the packages">
<small>The evolution of GitHub stars — <span>blue</span> is my package, <span>green</span> is the older competing package, <span>yellow</span> is Spatie's new package.</small></p>

<h3>The boilerplate</h3>

<p>With the beta done, it was time to focus on the commercial product.</p>

<p>The idea was this: Even though the package does all the heavy lifting for you, you still need to implement it. And many apps will implement it in the same way.</p>

<p>So there was a place for another project. A boilerplate with all the stuff you’d be writing anyway. This means customer (tenant) onboarding flow, billing logic, an admin panel, domain management, customer HTTPS certificate management etc.</p>

<p>And it also fit perfectly into my beta. I had a beta that I wanted users to test. I also wanted to build an app that would use the package. This would make me see all the missing parts, from the perspective of a <strong>user</strong> of the package.</p>

<p>This took about a month of half-work to build.</p>

<p>Why half-work? Motivation was slowly disappearing, the beta &amp; new marketing website was out, so competition was sort of taken care of. Also a bunch of personal stuff happening.</p>

<h2>The launch</h2>

<p>I was on a family vacation in Southern Europe. I originally wanted to finish all my work before going there, but you know how IT projects are.</p>

<p>I spent the first week doing fun stuff — working out, walking, reading, listening to audiobooks and podcasts.</p>

<p>But after a week of spending my time completely differently than I normally do, I decided to finish the work. So, I spent 3 days inside the apartment. There was no time to go outside, I <strong>had</strong> to finish this.</p>

<p>I was finishing the package’s features alongside the boilerplate.</p>

<p>The package was ready for release. And so was the boilerplate.</p>

<p>This was at <strong>3 AM in the morning</strong>. I was severely overworked and it was time to write an announcement.</p>

<p>I didn’t have enough energy to send an email, do a Twitter thread, make a launch discount or any of the other stuff. Nor did I have the confidence in my abilities to do it well at 3 AM.</p>

<p>But I was glad I managed to get the marketing site done! In some form anyway.</p>

<p>So I went with a <strong>safer approach</strong>. I announced the release on my Discord server. This way only a small portion of my users saw it and if anything was wrong, I’d manage to extinguish the fire before it got too big.</p>

<p>So I made an announcement and went to bed. I didn’t expect much. I actually <strong>don’t know</strong> what I expected.</p>

<p>But I can say that <strong>waking up to $600 in sales surprised me</strong>.</p>

<p>I woke up, went to the bathroom, and went straight to the computer. Inviting people who bought the project to the private community (no automated process — gotta do that MVP!). Improving the marketing page.</p>

<p>Then I got to scheduling a <a href="https://twitter.com/samuelstancl/status/1277920614670577672">Twitter thread</a> on Hypefury and writing a marketing email on Mailchimp.</p>

<p>Then both went out.</p>

<p>And the sales started coming in.</p>

<p>A lot of them.</p>

<p>A <strong>LOT</strong> of them.</p>

<p>My inbox quickly got filled with tens of emails with the subject line of:</p>

<blockquote>
  <p>New sale of Multi-tenant SaaS boilerplate for Laravel - Standard version</p>
</blockquote>

<p><img src="https://i.imgur.com/SaBSah1.png" alt="https://i.imgur.com/SaBSah1.png"></p>

<p>I was incredibly happy.</p>

<p>The first day concluded with a bit over $5000 in sales.</p>

<h2>The selling process</h2>

<p>The product was sold in two tiers. Standard and Enterprise.</p>

<p>The difference between the two versions was that the Enterprise version got priority support and could be used by companies with an annual revenue of $60k and higher. This is the same model <a href="http://nova.laravel.com/">Laravel Nova</a> uses.</p>

<p>I launched the product with <strong>two launch discounts</strong>.</p>

<p>A “generic” one, that I haven’t yet decided when it will end.</p>

<p>And a better one, that <strong>only lasted the first 48 hours</strong>.</p>

<p>The prices were:</p>

<ul>
<li>Standard: $299 -&gt; $199 (generic) -&gt; <strong>$149 (48 hour)</strong></li>
<li>Enterprise: $499 -&gt; $379 (generic) -&gt; <strong>$349 (48 hour)</strong></li>
</ul>

<p>I think given the sales, I hit the nail on the head with the pricing.</p>

<p>It was pretty affordable for solo projects, while also being high enough for the enterprise version.</p>

<p>My project is in this strange space where there are one-man indie hacker projects on one side of the income spectrum, and huge enterprises on the other side of the spectrum. Very little in between.</p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/">https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/</a></em></p>]]>
            </description>
            <link>https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821220</guid>
            <pubDate>Mon, 13 Jul 2020 14:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are not prisoners of groupthink]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23821180">thread link</a>) | @henriquez
<br/>
July 13, 2020 | https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html | <a href="https://web.archive.org/web/*/https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <h2>
            <a href="https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">
                We are not prisoners of groupthink.
            </a>
        </h2>
        <h3>How I stopped worrying about "cancel culture" with this one weird tip.</h3>
        
        <p><em>This is a response to the Gareth Roberts essay titled
<a href="https://unherd.com/2020/07/why-the-prisoner-is-more-accurate-than-orwell/">"We are all prisoners of groupthink".</a></em></p>
<p>A common theme on the Internet is selection bias. We seek out content and
interactions that fit our sensibilities, beliefs and emotional disposition.
Social networks have exploited this tendency, drawing us into
<a href="https://en.wikipedia.org/wiki/Filter_bubble">filter bubbles</a> where we are
algorithmically bombarded with content designed to maximize our "engagement"
with no regard to damage done in terms of our psychological well-being or
intellectual isolation. This makes us better consumers, but reinforces
divisions between individuals and poisons any possibility of meaningful
discourse, instead favoring shit-flinging competitions between so-called
<a href="https://twitter.com/realdonaldtrump/status/1261126114799468549?lang=en">"keyboard warriors."</a>
This is well-documented, the social media companies are aware of it,
and they don't care because <a href="https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499">division makes money.</a></p>
<p>Our filter bubbles are designed to comfort and placate us while we're force-fed
promoted content and offers and idealized imagery. Our collective ability
to think critically has been siphoned away; anything that remotely challenges
our beliefs is seen as a threat or an attack. Over time this has lead to the
ridiculous notion that "words are violence," and from this, the rise of
<a href="https://en.wikipedia.org/wiki/Online_shaming#Call-outs_and_cancellation">cancel culture</a>,
the First World pastime of mobbing, doxing, and socially destroying
anyone who dares to voice an unpopular opinion or do something stupid. This cancel
culture was born of social media. Sure, some might blame other factors like liberal
arts education but really they're nothing new to society. But I'll tell you what changed.</p>

        
            
<p>Back in the good old days (when you didn't need 32gb of
memory to browse the web), Twitter and Facebook used to display a chronological
feed of your friends' posts. This was very functional, but ended up creating a problem
for the social media companies: in order to maximize the amount of time you spend on
their sites they needed you to friend/follow tons of people (even people you aren't really
friends with). But if you did that, your feed would turn into a shitshow, with too
much content for any person keep up with. So Facebook and Twitter went back to the
drawing board and came up with a fantastic innovation: the algorithmic content feed
(aka. the death of society and end of the Internet). The feed algorithm could "get
into your head" with <a href="https://en.wikipedia.org/wiki/Psychographics">psychographic microtargeting</a>,
allowing the machine to recommend content and advertisements that <em>you</em> are likely to
"engage" with—click, like, share,
anything to keep you on the site and viewing more ads a little longer.</p>
<p>The deprecation of the chronological timeline in favor of the
machine-curated content feed had major psychological side effects for everyone involved.
When the machine decided what content to recommend it would favor content that is most
likely to create engagement; this trends toward content that creates an emotional
response, which on the Internet is most often outrageous content that evokes fear or
anger. By bombarding people with upsetting shit and exposing them to "communities" of other
people <a href="https://knowyourmeme.com/memes/circle-jerk">circlejerking</a> about how upsetting
everything is, the machine dialed the filter
bubble effect up to 11, essentially dividing people into groups and then radicalizing
them with increasingly extremist content. And in the process,
<strong>Facebook and Twitter radicalized the actual publishers of content.</strong></p>
<p>Remember when you could pick up a newspaper or turn on
your television and get news coverage that seemed at least superficially factual
and unbiased? Obviously those days are gone. Newspapers are mostly out of business,
TV viewership is down, and the dying husk of our mainstream media is increasingly
obsessed with a contrived "culture war." Traditional media has been superceded by
the Internet, and with social media dominating peoples' time spent on
the Internet, Facebook and Twitter have become gatekeepers between the
publishers and their viewers. Factual and unbiased reporting is simply not engaging
enough and will not appear on peoples' feeds. Only breathless hyperbolic
fear-mongering and rage porn will break through the algorithm and get clicks.
Mainstream publishers have been forced to shift their entire media strategies
around <em>online engagement</em> as they desperately attempt to stay relevant on the Internet.
And what's more engaging than a controversy? Thus,
mainstream publishers have "picked sides" that resonate with their
audiences'
filter bubbles in the artifical culture war, promoting non-newsworthy events
into manufactured controversies, and sparking mob action with headlines like
<a href="https://www.cnn.com/2020/07/11/us/goya-foods-unanue-trump-hispanic-market/index.html">"Here's why [food CEO's] meeting with [world leader] is prObLeMaTiC."</a></p>
<p>And that brings us to recent months, where
after locking every person of fighting age in closet-sized apartments, where peoples' only
access to the outside world was filtered through the toxic lens of social media, and
where the only information available was underpinned by fear and outrage, people
lost their shit. And now we're collectively hand-wringing about cancel culture (but
being real careful not to upset the mob.)</p>
<p>But here's the thing: cancel culture is irrelevant if you don't give a fuck.
You are not a prisoner of groupthink. You might be a prisoner of your belief
that you should give a fuck. But that is under your control. We are not living
a George Orwell hellscape, memes like
<em>"<a href="https://en.wikipedia.org/wiki/Nineteen_Eighty-Four">1984</a> was a warning, not
an instruction manual"</em> fall flat. The premise that we should care what a bunch
of larpy wannabe do-gooders think on Twitter and Facebook is false.
It doesn't matter—you can't lose a game you don't play. Cancel culture was born
of social media. <strong>If we cancel Facebook and Twitter</strong>, we can break the cycle of
extreme division and hyperbolic microtargeting, shatter the filter bubbles,
and reclaim our access to information from monopolistic ad targeting algorithms.
By divorcing our attention from these toxic echo chambers, manufactured controversies
will become less profitable,
people will be able to think more critically and talk to each other more sincerely,
and cancel culture will end organically. There are really no major drawbacks.</p>
<p>So much of our time online is <em>wasted</em> creating, curating, and "defending"
these perfectly plastic personas, avatars, idealized identities that represent
some vague notion of a persistent sense of self on the Internet. And for what?
Do you really talk to your 600 Facebook friends? Do you even give a shit about
who your 10,000 Instagram followers are? Do they give a shit about you? No.
People waste so much of their lives trying to stake out an online identity that
they start to believe it actually matters, <em>but it doesn't.</em>
<strong>A persistent online identity is a liability, not an asset.</strong></p>
<p>We are all tempted by the lie that social networks base their existence on:
that we need to put our "selves" online for all to see. This lie is a mental hack,
exploiting our human need for meaningful interactions with other people,
as well as the dark aspects of human nature: ego, anger and trauma. As society
increasingly isolates and divides humans from one another physically and
socially, we are tempted by the lie that our online personas form a meaningful
extension of our real-world selves.</p>
<p>Sadly, the vast majority of our interactions on social media are hollow, and the
few glimmers of meaningful connections with others that <em>do</em> occur
instill a Pavlovian-style hope, an addictive draw to keep us infinitely scrolling
through our algorithmically-curated content feeds in the vain hope that the
machine will bring meaning to the emptiness of our lives. But social media is little more
than mental masturbation. The service is free but the price we pay is dear.</p>
<p>When you put your real self online, you open yourself up to attack.
Like a federal indictment, the mob can come for anyone at any time. Whether or
not you are a good person is irrelevant, and trying to craft your online persona
to appease the mob is a loser's game. As the filter bubbles increasingly divide-and-circlejerk
people into more extreme viewpoints, what passes for acceptable
behavior today could be heresy tomorrow. And when your name, your employer, and
your family are all connected to your social media presence, you put yourself in
real world danger for very little real world benefit.</p>
<p>So what can you do? <strong>Cancel yourself.</strong> Delete your social media presence.
Sever the link between your online self and your real-world self. Seriously.
<em>You can't lose a game you don't play.</em></p>
<p>But wait, <em>isn't this extreme?</em> Maybe it is, or maybe you're just addicted to
social media. I've talked to a lot of people about this and heard some common
excuses people use to rationalize addictive behavior to themselves.</p>
<ul>
<li><strong>"But social media is an important part of my professional network."</strong></li>
</ul>
<p>I can only speak anecdotally. I've built a successful career without using LinkedIn
or other social networks to promote myself. My work ethic, skill and reputation have
carried me
as far as I care to go in my field. Also anecdotally, when I hired a contractor
to remodel my basement, I didn't check her Facebook page; I saw her work at a
neighbor's house and asked them to put me in touch. She did a great job on
my basement (and later posted photos of it to her Instagram). Good work
promotes itself.</p>
<p>But what doesn't work is when the line between personal and professional gets
blurred, which is almost inevitable on a medium designed around social
interaction. The tension between <em>being a professional</em> and <em>having an opinion</em> is
overwhelming for some people. The person who lists in their Twitter bio that
they "work for Google" and "bash the fash" isn't doing themself or their employer
any favors. Such tact only works for those who stay in the good graces of the mob,
which is, again, a loser's game.</p>
<ul>
<li><strong>"But I use social media to keep in touch with my school friends."</strong></li>
</ul>
<p>No you …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html</a></em></p>]]>
            </description>
            <link>https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821180</guid>
            <pubDate>Mon, 13 Jul 2020 14:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Be More Unlikeable]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 70 (<a href="https://news.ycombinator.com/item?id=23821121">thread link</a>) | @elijahmurray
<br/>
July 13, 2020 | https://www.gritlist.co/be-unlikeable/ | <a href="https://web.archive.org/web/*/https://www.gritlist.co/be-unlikeable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            


                <section>
                    <div>
                        <blockquote>"The reasonable man adapts himself to the world; the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man." - George Bernard Shaw</blockquote><p>I grew up in a family where I was taught to be likable. To please, to impress, and to make others happy. Seems like a pretty good idea, right?</p><p>While likeability is a good trait if you want to be popular it isn't ideal if you want to achieve. Let me explain.</p><p>Popularity feels good. Being liked feels good. Humans evolved as social creatures and we crave attention from each other. This pattern plays out over and over in schoolyards, bars, and workplaces, or anywhere humans meet. And the cooperation needed for our survival can only happen if you're accepted by your tribe.</p><p>However, praise by the masses won't make you successful, let alone fulfilled. Actually it's more likely that <em>popularity will prevent you from being successful.</em></p><p>Movie stars, professional athletes, and a business visionaries–we all want to be them. We grow up trying to be them. Personally, I've long idolized Steve Jobs and Elon Musk. But most of our heroes got to where they are by being unlikeable, not likable.</p><p>We love these men and women for being unique yet we internally berate ourselves for being different. These heroes have been described as annoying, difficult, stubborn, and unreasonable. Not exactly what we strive to read about ourselves in peer reviews. Sure, they have some popularity, but it's not all rainbows. Was Gandhi liked? Yes, but he also had millions of people who were against him, and ultimately murdered him. So if it's the oddballs that we look up to, why do we try to be so likable?</p><p>This aversion to difference starts early. Bullies throughout life pick on the kid who is different, on the easy target. Additionally modern culture has decided that the best path in life is to do as you're told; follow the rules, stay in line, and smile. Follow the leader and be a good girl/boy. The scripture of conformity is pervasive.</p><p>And there is true merit to fitting in. Society can't exist without collectively agreed upon rules. Early on we learn that being a three year old hellion is unacceptable has consequences. If I spit out my Cheerios one more time mom will be angry mom, so I'm going to be nice.</p><p>So we're taught to fit in. Be likable and hide your "flaws". Like the only white fish in a school of black fish you don't want to be the different one when a shark is on the prowl. Blend in and don't stand out. Seek group acceptance.</p><p>While conformity has its place in keeping society running, too much conformity stunts progress.</p><p>Differences are what make you, you and me, me. They're what make change possible. Change comes from differences, not from more of the same. After all, a species evolves based on small aberrations, on "flaws", that turn into strengths and a better way of being.</p><p>All progress comes from those who see the world differently. First they act differently and then they convince others to see differently as well. They don't accept the status quo and they don't assimilate.</p><p>Generally speaking this results in being unpopular. Many of the people who helped change the world aren't liked even in the height of their success. But they kept pushing their indomitable will against the world, and eventually, the world shifted ever so slightly.</p><p>Practice being unreasonable this week. Don't "yes" your way through life, following someone else's path for you. Be a bit more of a jerk. Be more demanding. Piss a few people off.</p><p>And be okay with it. Be okay with people being angry or mad or annoyed with you. Cultivate your ability to keep pushing towards your goals despite what others say.</p><p>And who knows, maybe you'll see the world shift ever so slightly.</p>
                    </div>
                </section>



        </article></div>]]>
            </description>
            <link>https://www.gritlist.co/be-unlikeable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821121</guid>
            <pubDate>Mon, 13 Jul 2020 14:28:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A/B capital for cloud infrastructure and enterprise software]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821049">thread link</a>) | @ekhornung
<br/>
July 13, 2020 | https://upside.fm/saurabh-sharma-jump-capital/ | <a href="https://web.archive.org/web/*/https://upside.fm/saurabh-sharma-jump-capital/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="target-id5f0fc631733a6"><p>Saurabh Sharma 0:00<br> All of us come from all varying backgrounds. And I would say that DNA kind of flows in somewhat automatically. You want to roll up your sleeves even to help the companies to the extent they need, right. We’re not enforcing this. And I would say that combined with I would say, yeah, to some extent, and midwest primarily them in building these businesses. I do think that differentiates.</p><p>Jay Clouse 0:20<br> The startup investment landscape is changing. and world class companies are being built outside of Silicon Valley. We find them, talk with them and discuss the upside of investing in them. Welcome to Upside.</p><p>Hello, hello. Hello, and welcome back to the upside podcast, the first podcast finding upside outside of Silicon Valley. I’m Jay Clouse, and I’m accompanied by my co host, mister money mustache himself Eric Hornung.</p><p>Eric Hornung 1:00<br> Unfortunately, Jay, maybe you can’t see it through this pop filter, but the mustache is no longer.</p><p>Jay Clouse 1:06<br> It’s a little stubbly.</p><p>Eric Hornung 1:08<br> Yeah, it’s a little stubbly it’s, it’s my, it’ll be my first full shave. Since I got rid of the mustache. I did the first two months of quarantine with the beard and the mustache. I was doing my best Jay Clouse. And then I said, You know what, I’m just not a beard guy. It’s not. It’s itchy. It’s, um, I think I’ve described it previously on the podcast as pube.</p><p>Jay Clouse 1:32<br> And I cringe every time you say the word pube on the podcast.</p><p>Eric Hornung 1:34<br> Yeah, it’s I’ve probably said it too many times on the podcast, I would say, yeah, once you get rid of once you get rid of the beard, and you’re looking yourself in the mirror and you say, Can I pull this off? If I walk out of this bathroom? Will my fiance kill me? And you just go for it. It’s a magical moment. Jay. When there’s a there’s a shriek and then an acceptance of this is who I am now. I’m a moustache guy.</p><p>Jay Clouse 1:59<br> You sent me the photo and I was like, Oh, I’m so glad that you shaved it in this order and took the time to get a photo of this before it’s gone. And then it stuck around six weeks.</p><p>Eric Hornung 2:09<br> Yeah.</p><p>Jay Clouse 2:10<br> Was it really there for six weeks?</p><p>Eric Hornung 2:11<br> It might have been five weeks but yeah, something like that.</p><p>Jay Clouse 2:13<br> Wow. And and Colleen was okay with it.</p><p>Eric Hornung 2:17<br> I think she liked it better than the beard.</p><p>Jay Clouse 2:20<br> Wow.</p><p>Eric Hornung 2:21<br> Yeah. So it was a nice mustache. I won’t lie we got trimmed it up. I gave it a little bit of love. It’s just you know it the mustache life is tough, Jay because you drink a little bit of milk. Yeah, mustache in your milk, milk in your mustache. Whatever is it.</p><p>Jay Clouse 2:34<br> I actually don’t experience many of the mustache pains myself because my mustache is the weakest part of my beard.</p><p>Eric Hornung 2:39<br> Hmm.</p><p>Jay Clouse 2:40<br> So yeah, I go on enumerate on the number of moose mustache problems.</p><p>Eric Hornung 2:45<br> Yeah, yeah, very eating a hot wing with a mustache. You got hot wing for the next four hours because it’s not leaving your mustache. Anyway, yeah. So the mustache the whole That whole that whole phases is behind me, Jay, but it lives on in memoriam.</p><p>Jay Clouse 3:05<br> Well, I’m glad that you made the jump into not only trying the beard but trying a mustache. And speaking of jump, today we are talking with Saurabh Sharma. He is a partner at Jump Capital, a thesis led sector focused and operating centric venture capital firm specializing in series A and B in growth stage investments, Jump Capital invest in data driven technology companies within the FinTech, B2B SaaS, IT data infrastructure and media sectors. They’re based in both Chicago and New York. Eric, how do we find them capital,</p><p>Eric Hornung 3:43<br> I got connected with Jump Capital, indirectly, I think two years ago, maybe it was via Twitter or via an email or something. And so I don’t exactly remember how it happened. But I’ve been in contact via email with a few of the partners there just because I really like the way that they are structured and set up and what they focus on. And they’re very explicit about what they do, which I find to be refreshing in the venture capital space. And we wanted to have a conversation with them. And you know, we got to have one today.</p><p>Jay Clouse 4:13<br> Jump Capital has invested in a previous Pod Co Balto, they’ve invested in Personal Capital, just to name a couple of companies that you’ve heard of also Lisnr in Cincinnati. He talked about them being explicit and what they actually invest in. They also say on their website that they invest $1 to $10 million in their first investment, when companies have a $1 to $5 million revenue run rate. And typically, less than $10 million of investment so far today, so yeah, very explicit on their website in terms of industry, what types of companies are looking for, even at what stage? You know, the investment, the investment terms are?</p><p>Eric Hornung 4:51<br> Yeah, they have a operating partner model which is much more like private equity than it is a lot of the venture capital firms. We talked to the platform model almost. So when you’re very specific about the types of companies that you’re going to invest in, I think that operating model becomes stronger because you can get the best people to do the specific thing that needs to be done in these four focus areas in that very specific space where its product market fit has been met and it is growth time.</p><p>Jay Clouse 5:21<br> All right. Well, we’d love to hear your thoughts on this episode with Saurabh as we go through, you can tweet at us @UpsideFM or email us Hello@upside.FM. And we’ll get into that interview right after this. This episode of upside is sponsored by Tresta. Tresta is an app for iPhone and Android that lets you do business calling and texting from anywhere with no hardware. Just a smartphone you’re already using. Tresta is the best business phone app on the market. Whether you’re a founder or freelancer, just starting your business or you’re already established. Growing your network and your business is all about communication. You’ve got to be available no matter where you are. Tresta offers the call management features that empower you to communicate smarter and more efficiently, like auto attendance, call recording, user groups and more. And you don’t need any special equipment, just the smartphone you’re already using. Tresta is easy to configure. So you can set everything up yourself all online. Tresta’s virtual phone system makes it easier and more affordable than ever to set up a fully functioning mobile office. It’s just $15 per user per month with no contract. So start your free 30 day trial today at www.tresta.com/upside. That’s www.tresta.com/upside. Saurabh welcome to the show.</p><p>Saurabh Sharma 6:08<br> Thank you folks. Great to be here.</p><p>Eric Hornung 6:47<br> Let’s take it on a rocket ship. How did you get to Jump Capital.</p><p>Saurabh Sharma 6:51<br> Yeah, I mean it’s a kind of an unconventional path. I don’t think I was looking misery your venture capitalist. From a career perspective. I think it’s a three organic way down. Journey has been a little bit all over the place, which I think bodes well to venture frankly, just kind of amalgamation of a bunch of things. But you know, I’m fundamentally I’m an engineer by training and science, grew up in India in engineering there, got a scholarship to Apollo undergrad in France. Finish that became a computer science researcher in France, in the National Research Labs, got an opportunity to come to my masters and possibly a PhD at Cornell, where they’re in just kind of got brainwashed of Academia, by Wall Street, being brothers and all the banks that just go to campus and hire quantum computer science guys, so I just finished my Master’s in Cornell, join Lehman Quanta Algo trading desk was there, you know, the hay days and just perfect time as they’re even open to await the peak of Lehman. And so you know, phenomenal times, obviously, ranging from fairly very large scale architectures for competition trading in New York, London, and some phenomenal desks in the Ritz trading. Bring meeting go face. Solid tobacco was there almost to the end not exactly to the end I had an opportunity to apply for business schools which I had been pushing off and I thought really good time. After 07, there are some signs they might be weaker and then I got my admit I got took some time off and moved to India back to this small snippet of equity for business school, but I didn’t know it was gonna go up. It kind of blew up premier the first week I started my business school in Chicago booths. So the next year was kind of experimenting, starting my own company a bunch of my friends. And then you know, I’m preparing to started doing them for them and post that went back to Wall Street a little bit works on capitals with Bob Lehman at the time realized probably wasn’t for me back Michael was the chief quite a bit to join early stage uncle life Bank of Chicago Southern by April kowski Radke local mountain nurse in the region funded that a startup that I was involved in earlier. And then it allowed us to spend some time with light bank, Eric ended up being the Groupon CEO asked me to come along during some times to kind of turn around the story. And so another kind of run at pretty phenomenal setup of interesting projects of turning around the business. I was involved in an internal data science team run mobile relevant strategy, and then Mary Barra fashion conference in New York. So running operations and marketing for that, for that business in an intersection folks a jump and it was kind of good amalgamation a jump, as we will talk about more it has some relevance to so creating groups, very computational focus. So that can all put it together. You know, I’m actually in background I’ve been venture, I’ve been in tech and to join the joint jump for about four and a half years ago. So again, somewhat unconventional but but took me multiple paths. But I think all that is super …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://upside.fm/saurabh-sharma-jump-capital/">https://upside.fm/saurabh-sharma-jump-capital/</a></em></p>]]>
            </description>
            <link>https://upside.fm/saurabh-sharma-jump-capital/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821049</guid>
            <pubDate>Mon, 13 Jul 2020 14:21:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking the Myth of 10% Brain Usage]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23821046">thread link</a>) | @iuliangulea
<br/>
July 13, 2020 | https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>The human brain is a marvel of biological engineering. It allowed us to accumulate and pass on the knowledge of many prior generations throughout millennia, resulting in a civilization that went into space, taught computers to see and speak, and that continually discovers and investigates the laws of the Universe.</p>
<p>Its complexity is astounding, and we do not fully understand it yet. And because of that, occasionally, myths about the functioning of the brain pop out. Among the most prominent such legends is the one that claims we are dormant geniuses. But before analyzing and debunking that, let’s discuss some brain facts.</p>
<h2 id="size-does-not-matter">Size Does Not Matter</h2>
<p>For instance, did you know that the brain weighs around 1300-1400 grams? It represents only 2% of the total body weight of a 150 pound or 70kg human. However, it requires:</p>
<ul>
<li>15% of total cardiac output (the blood that flows in our body);</li>
<li>20% of total body oxygen;</li>
<li>25% of total body glucose utilization</li>
</ul>
<p><img src="https://iuliangulea.com/images/brain-energy-consumption.png" alt="Human brain weight vs. energy consumption"></p>
<p>That is quite an energy-hungry organ inside our skull! But even that fades away when comparing to children: at around five years old, the human brain takes up as much as 50% of oxygen consumption<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>Surprisingly, the brain’s level of oxygen consumption does not significantly vary when you are resting vs. when you do some cognitively intense work. Overall, measures of the whole brain changes in blood flow during intense mental activity have failed to demonstrate any change. Even <em>local changes</em> in blood flow of the regions involved most in a cognitive task are often 5% or less.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>Conversely, it is well known and demonstrated that glucose is the brain’s “fuel,” therefore increases in blood glucose levels can positively impact cognitive performance in some tasks.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<h2 id="the-mystical-brain-myth">The Mystical Brain Myth</h2>
<p>There is a popular myth that we use our brains at only 10% of its capacity, thus boldly affirming that we have a whopping 90% of dormant potential that we can awaken and become geniuses.</p>
<p>Unlike other widespread myths that started from a single event, or unscientific claims from poorly designed research studies (e.g., <a href="https://en.wikipedia.org/wiki/Andrew_Wakefield">Andrew Wakefield</a> and his fraudulent study than falsely claimed a link between vaccines and autism), the myth that humans use only 10% of their brains started at the end of the nineteenth century and was gradually strengthened by many people since then. The <a href="https://en.wikipedia.org/wiki/Ten_percent_of_the_brain_myth#Origin">Wikipedia</a> article on the subject has a lengthy explanation of the potential origin and evolution of the myth throughout the years.</p>
<h3 id="a-small-confession">A Small Confession</h3>
<p>Before moving on, I have a revelation to make. Occasionally, I might buy a cloth item and wear it once or twice. If I recall correctly, there might have been one or two items in my experience that I have not worn at all. Do you know anyone with similar oddities?</p>
<p>This makes my wardrobe much like the brain described in the myth: I am using around 10% of it, and I can “tap into” the rest of my wardrobe should such need arise.</p>
<h3 id="your-brain-is-not-a-wardrobe">Your Brain Is Not A Wardrobe</h3>
<p>But our brain is not a collection of cloth items. Though there are still unanswered questions regarding some brain functions, brain mapping physiology demonstrates that all its areas have a purpose. And you do not have to be a neuroscientist to prove that, simply recall from your anatomy classes that the brain has different regions, such as the frontal lobe, occipital lobe, cerebellum, and the fact that each of those lobes has its role.</p>
<h2 id="debunking-the-myth">Debunking The Myth</h2>
<p>Let’s address that myth in a more scientific manner.</p>
<p>If we are using only 10% of our brains, that means a person would be fine if the other 90% of the brain got removed. 10% of the 1400g average brain is 140g—that’s the size of a sheep’s brain.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Since I doubt sheep have their own 90% hidden potential myth, it makes no sense that humans have advanced so far as a civilization by using only part of their brains equivalent in size to a sheep’s brain.</p>
<p>There are instances in history when people were injured and got parts of their brain removed (although not as close as even 10%), the most prominent (and among the first recorded ones) being the case of <a href="https://en.wikipedia.org/wiki/Phineas_Gage">Phineas Gage</a>, who survived an accident where a large iron rod was driven through his left part of the head, from the bottom of the cheek, through his left eye and frontal lobe all the way to the top of his head. He lived 12 years more after that accident. There are varying opinions on his recovery, but it took him ~10 years to recover from the unfortunate event.</p>
<p>Another example is the case of <a href="https://en.wikipedia.org/wiki/Lev_Zasetsky">Lev Zasetsky</a>. A bullet entered his left parieto-occipital area and resulted in a long coma. Following this, he became unable to perceive the right side of things. Objects he did see often appeared as fragmented pieces rather than whole objects. He did not recover in the 50 years he lived after the injury.</p>
<p>As mentioned in <a href="https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">How People Learn—The Brain Basics</a>, our brains can rewire through a process called <em>neuroplasticity,</em> which can help regain some of the lost functions as a result of an accident. Unfortunately, that is not always the case. Researchers have found that only 27% of people recover from a <em><strong>concussion.</strong></em><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> That means almost 3 out of 4 people do not fully recover! And this is “just” a concussion—your brain does not lose any of its parts.</p>
<p>If 90% of the brain were unnecessary, it is highly unlikely that we would not have evolved such big brains with irrelevant matter in the first place. There are several factors for that:</p>
<ul>
<li>Historical risk of childbirth deaths due to the big skull size would stress out the selection of offspring with smaller brain sizes.</li>
<li>Natural selection favors characteristics that offer an advantage of some sort over the other. There is no way such a big brain would have formed in the first place if it wouldn’t be necessary for survival.</li>
<li>As already mentioned, the brain requires an enormous amount of energy. Even if we had 90% of the brain unused and suddenly were to “wake” it, we couldn’t provide our brains with enough power, as it already consumes 20%-25% of the entire body resources.</li>
</ul>
<p>All this scientific evidence works against this myth. We indeed use only some areas of the brain at any given time, but throughout the day, we use all of it, not just 10%. And next time you hear about this myth, recall the sheep brain weight.</p>
<hr>
<p>If you liked this article, feel free to subscribe below to be among the first to receive future updates and follow me on twitter (<a href="https://twitter.com/iuliangulea">@iuliangulea</a>) as well.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Kennedy C, Sokoloff L. <a href="https://pubmed.ncbi.nlm.nih.gov/13449166/">An adaptation of the nitrous oxide method to the study of the cerebral circulation in children; normal values for cerebral blood flow and cerebral metabolic rate in childhood.</a> J. Clin. Invest. 1957;36:1130–1137. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>The Effect Of Mental Arithmetic On Cerebral Circulation And Metabolism by Sokoloff L., Mangold, R., Wechsler, R., Kennedy, C. &amp; Kety, S. S. (1955) <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Rachael T. Donohoe, David Benton—<a href="https://www.researchgate.net/profile/David_Benton/publication/12840251_Cognitive_functioning_is_susceptible_to_the_level_of_blood_glucose/links/5489df990cf225bf669c75e5.pdf">Cognitive functioning is susceptible to the level of blood glucose</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Differences Between Human And Sheep Brains—<a href="https://animals.mom.com/differences-between-human-and-sheep-brains-3500869.html">animals.mom.com</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://www.braininjuryaustralia.org.au/research-recovery-concussion/">How Many Make A Full Recovery From A Concussion?</a>—BrainInjuryAustralia.org.au <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    
    
        
    

</div></div>]]>
            </description>
            <link>https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821046</guid>
            <pubDate>Mon, 13 Jul 2020 14:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a DIY Pen Plotter: MidTbot]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820926">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Earlier this year, I built a DIY pen plotter (mostly) from scratch. I'd been
meaning to post a build log, because this was one of the more enjoyable hardware
projects I've worked on recently. However, it's taken a while to write-up this
project because, well,
<a href="https://benjamincongdon.me/blog/2020/03/24/March-Updates/">there was a lot of stuff going on</a>.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter_hu26049e58bcb0e8f71afc8b124b2c5223_266932_0x400_resize_q75_box.jpg" alt="Completed Plotter with Ruler for Scale"> </a><figcaption>
        <p>Completed Plotter with Ruler for Scale</p>
    </figcaption>
    </figure>

<h2 id="why-build-a-plotter">Why Build a Plotter?</h2>
<p>So, why is it worth building a pen plotter? The short answer is, “they're cool”.
The longer answer is that, despite commercial printers (ink jet, laser, etc.)
working better for general purpose printing, the quality of a pen-plotted image
is noticeably different than something that's been traditionally printed.
Plotted images can have a more natural, organic feeling to them, because they're
produced by raising and lowering a pen manually, like a human does.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>I've also had a persistent curiosity with
<a href="https://benjamincongdon.me/blog/2019/03/07/Generative-Doodling/">generative art</a>. Much of the community
built around generative art (colloquially,
<a href="https://twitter.com/hashtag/plottertwitter">#plottertwitter</a>) uses pen plotters
to turn “bits into atoms”. While most folks opt to buy a commercial plotter like
the <a href="https://axidraw.com/">Axidraw</a> or restore vintage plotters from the 1980's,
there's a growing community of people building their own plotters.</p>
<h2 id="assembling-the-components">Assembling the Components</h2>
<p>The first step in the project was collecting the bill of materials (BOM).
There's a well-researched BOM on the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/Docs/mechanical_BOM.md">project Github</a>.
Other than the midTbot PCB, which is for sale
<a href="https://www.tindie.com/products/33366583/midtbot-esp32-v2-controller-kit/">on Tindie</a>,
I had to order:</p>
<ul>
<li>Linear shafts and Linear Bearings (Amazon)</li>
<li>Pulleys and Idler Pulleys (Amazon)</li>
<li>Rubber Timing Belt (Amazon)</li>
<li>2 Stepper Motors (Amazon)</li>
<li>Stepper Motor Controllers (Amazon)</li>
<li>12V 3A Power Supply (Already had one)</li>
<li>Basic Hobby Servo Motor (Already had one from previous Arduino projects)</li>
<li>Assorted M3/M5 Head Screws (Home Depot, Ali Express)</li>
</ul>
<p>I was pleasantly surprised how available most of the parts were online –
everything except for the screws/nuts were available on Amazon.</p>
<p>Once I received my midTbot PCB, there was some soldering and assembly to do. I
followed
<a href="https://github.com/bdring/midTbot_esp32/wiki/Controller-Kit-Assembly-Instructions">these instructions</a>
to attach the homing switches, power supply, and header pins to the board.</p>
<h3 id="printing-the-chassis">Printing the Chassis</h3>
<p>The chassis of the midTbot is entirely 3D printed. There are ~7 things that you
need to print
(<a href="https://github.com/bdring/midTbot_esp32/tree/master/STL">source files</a> on
Github), and they're all fairly simple shapes, so the prints were easy to do.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print_hu632932bafc371cef54c7ef30f19a742b_135778_0x400_resize_q75_box.jpg" alt="Completed prints of the &amp;lsquo;feet&amp;rsquo; and tailblock pieces"> </a><figcaption>
        <p>Completed prints of the ‘feet’ and tailblock pieces</p>
    </figcaption>
    </figure>

<p>The hardest thing to print (and the most finicky part of the project in general)
was the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/STL/midt_esp32_pen_mnt.stl">pen mount</a>.
This piece has some overhangs on it, so it was important to configure the
printer to add support material.</p>
<h2 id="assembly">Assembly</h2>
<p>With the PCB assembled, mechanical parts purchased, and chassis pieces printed,
it was time to do the final assembly. Again, I followed the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Assembly-Instructions">assembly instructions</a>
on the project Github.</p>
<p>The assembly process was straightforward: the PCB gets screwed into one of the
printed pieces, the pulleys and linear rods get screwed in to the “feet” and
carriage block pieces, and the stepper motors are secured to the chassis with
the PCB “sandwiched” in between the chassis and the motors.</p>
<p>One difficult step was attaching the stepper motors to the PCB. Per the project
instructions, you're supposed to solder the stepper motor wires into plastic
<a href="https://en.wikipedia.org/wiki/Pin_header">pin sockets</a>, so you can easily
detach the motors from the PCB. But, after I tried and failed several times to
solder the stepper motors into the female socket block, I simply soldered the
female sockets to the board directly and soldered the stepper motor wires onto
solid-core jumper wires. The end result wasn't as clean as what's shown in the
project instructions, but still allowed me to hot-swap the motors if needed.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics_hu69d27adac9c276a7c142cb42ce695fc5_460646_0x400_resize_q75_box.jpg" alt="Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)"> </a><figcaption>
        <p>Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)</p>
    </figcaption>
    </figure>

<p>Once the main “chunk” of the plotter was assembled (pictured above), the only
things left to do were to thread the timing belt around the pulleys, and attach
both ends of the belt to the pen head with a small amount of tension.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2_hubcee09c1499dfeaed0cdedbd52521e35_510199_0x400_resize_q75_box.jpg" alt="Belt Attach Points (circled)"> </a><figcaption>
        <p>Belt Attach Points (circled)</p>
    </figcaption>
    </figure>

<p>The last step in assembly (and, unfortunately the most fiddly part of the whole
process) was attaching the pen holder to the “head” block. The long screw that
makes the joint between the pen holder and “head” block needs to be tuned
meticulously: If the screw is too tight, then the pen can get stuck in the “up”
position – not returning to the “down” position when the servo retracts. On the
other hand, if the screw is too loose, then this translates to “slop” in the
pen's position, which results in wiggly drawings that are unusable.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo_hu041824ca24038cc947b7d5fa7334f321_403811_0x400_resize_q75_box.jpg" alt="Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)"> </a><figcaption>
        <p>Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)</p>
    </figcaption>
    </figure>

<p>At this point, the bot was assembled! I powered it on and installed a specific
version of the <a href="https://github.com/bdring/Grbl_Esp32">Grbl_Esp32</a> firmware
designed for the midTbot per the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Compiling-Firmware-for-the-MidTBot">project instructions</a>.
Grbl_Esp32 is a really nifty piece of software: it allows you to upload an run
Gcode (basically, machine readable instructions for how to move the pen) on the
plotter's Esp32 controller. Since the Esp32 has built-in wifi (and bluetooth),
its able to serve a basic web UI:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui.png">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui_hu659f08144d7f460a1e53d6a3f50b9a17_60893_0x400_resize_box_2.png" alt="Grbl_Esp32 Web UI"> </a><figcaption>
        <p>Grbl_Esp32 Web UI
            <a href="https://github.com/luc-github/ESP3D-WEBUI">Source: Github</a></p>
    </figcaption>
    </figure>

<p>The Web UI is sufficient for most tasks: homing, minor positioning adjustments,
starting/pausing/resuming prints. There are only a few tasks – like calibration
– that require you to drop down to the Grbl “command line”.</p>
<p>It took me a while to get my midTbot calibrated. The project documentation was a
bit light on the specifics, so there was a lot of trial-and-error and
troubleshooting.</p>
<h2 id="plotting-software">Plotting, Software</h2>
<p>Now that I had a functioning plotter bot, the next thing to do was try it out.
Of course, to do so you need to actually produce Gcode that the bot can use.
There are tons of tools to do this – and a full discussion of Gcode/plotter
software is worth a whole other post. Suffice it to say, there are a variety of
resources on the <a href="https://drawingbots.net/knowledge/tools">Drawing Bots</a>
community page that serve as a good starting point.</p>
<p>I spent most of my time working with <a href="https://inkscape.org/">Inkscape</a>‘s
Gcodetools plugin. Axidraw (which makes a commercial pen plotter) also has some
useful
<a href="https://wiki.evilmadscientist.com/Axidraw_Software_Installation">Inkscape plugins</a>,
although some of the functionality won't work with the midTbot. Gcodetools
nominally allows you to translate SVGs to Gcode, however this is a tedious
process. <em>Not just any</em> SVG will work well with it; the SVG basically already
needs to be a line drawing for Gcodetools to have any hope of working correctly.
It has basic support for infilled regions too, but again you have to be careful
with it – any slight hiccup, and it produces unusable Gcode.</p>
<p>To be honest, the software aspect of pen plotting is the most frustrating part
of the workflow. I haven't yet found a great toolchain for the “art” -&gt; Gcode
pipeline, so there's a lot of finicky steps. (It doesn't help that Inkscape is a
second-class X11 app on macOS…)</p>
<h2 id="additional-hardware-modifications">Additional Hardware Modifications</h2>
<p>After I ordered a midTbot PCB, the creator added me to a Slack group. Some of
the other folks who'd built midTbots contributed back modifications they'd made
to their builds. I took a couple of these and added them to my bot too:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount_hu1f2dbe1c25aab483c480e60644105b8f_437548_0x400_resize_q75_box.jpg" alt="Magnetic Pen Mount with Thumb Screw"> </a><figcaption>
        <p>Magnetic Pen Mount with Thumb Screw</p>
    </figcaption>
    </figure>

<p>First, I ordered heftier thumb screws for the pen attachment (as pictured); the
screws in the original BOM are tricky to manipulate by hand. Second, I printed a
magnetic detachable pen holder (as pictured) which makes it easier to add/remove
pens without disturbing the rest of the setup. If you want to do multicolor
prints, this modification is a must. Finally, I printed wider supports for the
bots frame. Supposedly, this allows you to increase the available print size of
the bot (if you also order longer linear rods). I didn't get around to actually
increasing my bot's print size, but the wider supports made the bot more stable,
and easier to attach to a work table.</p>
<h2 id="results">Results</h2>
<p>After an afternoon of calibrating the bot and installing the mods I discussed
above, I got some prints that I'm pretty happy with.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle_hu7abfc5bba89b65ef467a92e89d404d38_647220_0x400_resize_q75_box.jpg" alt="SierpiÅ„ski triangle"> </a><figcaption>
        <p><a href="https://en.wikipedia.org/wiki/Sierpi%C5%84ski_triangle">SierpiÅ„ski triangle</a></p>
    </figcaption>
    </figure>

<p>Sierpinski's triangle (above) is a single line, but has a lot of intricate
detail. This is a good exercise of the precision of the stepper motors, which as
you can see is quite good. The precision also requires the pen mount to be
calibrated correctly, so that there isn't any “slop” between the pen and the
body of the plotter.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube_hu4580d2579ea2776d604d9e44b4623042_575462_0x400_resize_q75_box.jpg" alt="Isometric Cube"> </a><figcaption>
        <p>Isometric Cube
            <a href="https://github.com/wblut/isogrid">Source: Github</a></p>
    </figcaption>
    </figure>

<p>This was a slightly harder pattern for the bot to draw. The lines are all
straight, but there are a fair number of pen raises. Generally, the more pen
up/down cycles a print has, the greater the likelihood of failure.</p>
<p>I've also noticed that <em>where</em> the pattern is in the print area of the bot makes
a difference. The closer the pen head is to the main bot chassis, the more the
pen is pulled away from the paper due to the counterweight of the “tail”
section. As such, I tried to position the prints as close to the middle of the
print area as possible. Below is what happens when the pen holder misbehaves:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader_hu1a98c8f9a4b8a7a0c3eafda2f5f8180d_194935_0x400_resize_q75_box.jpg" alt="Somewhat failed &amp;lsquo;Space Invaders&amp;rsquo; Print (Note the discontinous/missing lines)"> </a><figcaption>
        <p>Somewhat failed ‘Space Invaders’ Print (Note the discontinous/missing lines)
            <a href="https://github.com/abey79/vpype">Source: vpype Example Code</a></p>
    </figcaption>
    </figure>

<p>The plot isn't a complete failure, but many of the lines don't get drawn or only
get partially drawn. This is often caused by the pen mount screw being too
tight, causing the pen …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</a></em></p>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820926</guid>
            <pubDate>Mon, 13 Jul 2020 14:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Grok with Elasticsearch to add structure to your data]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820793">thread link</a>) | @alexmarquardt
<br/>
July 13, 2020 | https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/ | <a href="https://web.archive.org/web/*/https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div id="primary">
	<main id="main" role="main">
		
<article id="post-1351" class="page">
	<!-- .entry-header -->

	
	<div>
		<p>July 13, 2020</p><p>As well as being a search engine, Elasticsearch is also a <a href="https://www.elastic.co/blog/intro-to-aggregations">powerful analytics engine</a>. However in order to take full advantage of the near-real-time analytics capabilities of Elasticsearch, it is often useful to add structure to your data <em>as it is ingested</em> into Elasticsearch. The reasons for this are explained very well in the <a href="https://www.elastic.co/blog/schema-on-write-vs-schema-on-read">schema on write vs. schema on read</a> article, and for the remainder of this blog, when I talk about structuring data, I am referring to <em>schema on write</em>.</p>

<p>Because of the importance of structuring your data, in this blog I will show you how to add structure to unstructured documents by using an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/ingest.html">ingest node</a> with the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok Processor</a>. Then, I will describe a simple method to construct new Grok patterns, and a method that can be used to debug errors in existing Grok patterns. Finally I will provide links to some publicly available Grok patterns and then briefly mention the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/dissect-processor.html">Dissect Processor</a> as a possible alternative to Grok.</p>

<p>As a side note, if you are going to put in the effort to structure your data, you should consider structuring your data so that it conforms to the <a href="https://www.elastic.co/blog/introducing-the-elastic-common-schema">Elastic Common Schema</a>, which will facilitate the analysis of data from diverse sources.</p>



<p>It is not uncommon to see documents sent to Elasticsearch that are similar to the following.:</p>

<pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre>

<p>The message field in the above document contains unstructured data. It is a series of words and numbers that are not suitable for near-real-time analytics. In order to take full advantage of the powerful analytics capabilities of Elasticsearch, we should parse the message field to extract relevant data. For example, we could extract the following fields from the above message:</p>

<pre>"host.ip": "55.3.244.1"&nbsp;<br>"http.request.method": "GET"<br>"url.original": "/index.html"<br>"http.request.bytes": 15824<br>"event.duration": 0.043</pre>

<p>Adding such a structure will allow you to unleash the full power of Elasticsearch on your data.</p>



<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok</a> is a tool that can be used to extract structured data out of a given text field within a document. You define a field to extract data from, as well as the Grok pattern for the match. Grok sits on top of <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a>. However, unlike regular expressions, Grok patterns are made up of <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">reusable patterns</a>, which can themselves be composed of other Grok patterns.&nbsp;</p>

<p>Before going into details of how to build and debug your own Grok patterns, we first give a quick overview of what a Grok pattern looks like, how it can be used in an ingest pipeline, and how it can be simulated. Don’t worry if you don’t fully understand the details of the Grok expression yet, as these details will be discussed in-depth in the following sections of this blog.</p>

<p>In the previous section we presented an example document that looks as follows:</p><pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p><br>The desired structure can extracted from this example message field by using the following Grok expression:</p>

<pre>%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}</pre>

<p>And we define a pipeline which contains this Grok pattern inside a Grok processor.</p>

<pre>PUT _ingest/pipeline/example_grok_pipeline<br>{<br>  "description": "A simple example of using Grok",<br>  "processors": [<br>    {<br>      "grok": {<br>        "field": "message",<br>        "patterns": [<br>          "%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}"<br>        ]<br>      }<br>    }<br>  ]<br>}</pre>

<p>We can then <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/simulate-pipeline-api.html">simulate the above pipeline</a> with the following command.</p>

<pre>POST _ingest/pipeline/example_grok_pipeline/_simulate<br>{<br>  "docs": [<br>    {<br>      "_source": {<br>        "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>      }<br>    }<br>  ]<br>}</pre>

<p>Which responds with a structured document that looks as follows:&nbsp;</p>

<pre>{<br>  "docs" : [<br>    {<br>      "doc" : {<br>        "_index" : "_index",<br>        "_type" : "_doc",<br>        "_id" : "_id",<br>        "_source" : {<br>          "host" : {<br>            "ip" : "55.3.244.1"<br>          },<br>          "http" : {<br>            "request" : {<br>              "method" : "GET",<br>              "bytes" : 15824<br>            }<br>          },<br>          "message" : "55.3.244.1 GET /index.html 15824 0.043 other stuff",<br>          "event" : {<br>            "duration" : 0.043<br>          },<br>          "url" : {<br>            "original" : "/index.html"<br>          }<br>        },<br>        "_ingest" : {<br>          "timestamp" : "2020-06-24T22:41:47.153985Z"<br>        }<br>      }<br>    }<br>  ]<br>}</pre><p><br>This document contains the original unstructured&nbsp; message field, and it also contains all of the additional fields which have been extracted from the message. We now have a document that contains structured data!</p>



<p>In the above example we <em>simulated</em> execution of an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/pipeline.html">ingest pipeline</a> that contains our Grok pattern, but didn’t actually run it on any real documents. An ingest pipeline is designed to process documents at ingest time, as described in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/ingest.html">ingest node documentation</a>. One way to execute an ingest pipeline is by adding the pipeline name to the <em>PUT</em> command as follows:&nbsp;</p>

<pre>PUT example_index/_doc/1?pipeline=example_grok_pipeline<br>{<br>&nbsp;&nbsp;"message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p>And the document that has been written can be seen by executing:</p><pre>GET example_index/_doc/1</pre><p>Which will respond with the following:</p><pre>{<br>  "_index" : "example_index",<br>  "_type" : "_doc",<br>  "_id" : "1",<br>  "_version" : 2,<br>  "_seq_no" : 2,<br>  "_primary_term" : 1,<br>  "found" : true,<br>  "_source" : {<br>    "host" : {<br>      "ip" : "55.3.244.1"<br>    },<br>    "http" : {<br>      "request" : {<br>        "method" : "GET",<br>        "bytes" : 15824<br>      }<br>    },<br>    "message" : "55.3.244.1 GET /index.html 15824 0.043 other stuff",<br>    "event" : {<br>      "duration" : 0.043<br>    },<br>    "url" : {<br>      "original" : "/index.html"<br>    }<br>  }<br>}</pre><p>Alternatively (and likely preferably), the ingest pipeline can be applied by default to all documents that are written to a given index by adding it to the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/index-modules.html#dynamic-index-settings">index settings</a>:</p>

<pre>PUT example_index/_settings<br>{<br>&nbsp;&nbsp;"index.default_pipeline": "example_grok_pipeline"<br>}</pre>



<p>After adding the pipeline to the settings, any documents that are written to <em>example_index</em> will automatically have the <em>example_grok_pipeline</em> applied to them.&nbsp;</p>

<p>This can be verified by writing a new document to <em>example_index</em> as follows:</p>

<pre>PUT example_index/_doc/2<br>{<br>&nbsp;&nbsp;"message": "66.3.244.1 GET /index.html 500 0.120 new other stuff"<br>} </pre>

<p>And the document that has been written can be seen by executing:</p>

<pre>GET example_index/_doc/2</pre>

<p>Which, as expected will return the document that we just wrote. This document has the new fields that were extracted from the message field:</p>

<pre>{<br>  "_index" : "example_index",<br>  "_type" : "_doc",<br>  "_id" : "2",<br>  "_version" : 3,<br>  "_seq_no" : 2,<br>  "_primary_term" : 1,<br>  "found" : true,<br>  "_source" : {<br>    "host" : {<br>      "ip" : "66.3.244.1"<br>    },<br>    "http" : {<br>      "request" : {<br>        "method" : "GET",<br>        "bytes" : 500<br>      }<br>    },<br>    "message" : "66.3.244.1 GET /index.html 500 0.120 new other stuff",<br>    "event" : {<br>      "duration" : 0.12<br>    },<br>    "url" : {<br>      "original" : "/index.html"<br>    }<br>  }<br>}</pre>



<p>In the previous section, we presented an example document with the following structure:</p><pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p>And we then used the following Grok pattern to extract structured data from the message field:</p>

<pre>"%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}"</pre>

<p>As described in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok Processor documentation</a>, the syntax for Grok patterns comes in three forms: <em>%{SYNTAX:SEMANTIC}, %{SYNTAX}, %{SYNTAX:SEMANTIC:TYPE}</em>, all of which we can see in the above Grok pattern.&nbsp;</p><ul><li>The <em>SYNTAX</em> is the name of the pattern that will match your text. Built-in <em>SYNTAX</em> patterns <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">can be seen on github</a>.</li><li>The <em>SEMANTIC</em> is the name of the field that will store the data that matches the <em>SYNTAX</em> pattern.</li><li>The <em>TYPE</em> is the data type you wish to cast your named field.</li></ul>

<p>The first part of the Grok pattern is the following:</p>

<pre>%{IP:host.ip}</pre>

<p>This declaration matches an IP address (corresponding to the <em>IP</em> Grok pattern) and stores it in a field called <em>host.ip</em>. Four our example data, this will extract a value of <em>55.3.244.1</em> and store it in the <em>host.ip</em> field.</p>

<p>If we want more details on the <em>IP</em> Grok pattern, we can look into the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a>, and we will see the following definition:&nbsp;</p>

<pre>IP (?:%{IPV6}|%{IPV4})</pre>

<p>This means that the <em>IP</em> pattern will match one of the <em>IPV6</em> or <em>IPV4</em> Grok patterns. To understand what the <em>IPV6</em> and <em>IPV4</em> patterns are, once again we can look into the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a> to see their definitions, and so on.&nbsp;</p>

<p>The next part of the Grok pattern is a single whitespace character followed by the following expression:</p>

<pre>%{WORD:http.request.method}</pre>

<p>This portion of the Grok expression extracts the word <em>GET</em> from the <em>message</em>&nbsp;and stores it into the <em>http.request.method</em> field. If we want to understand the definition of the <em>WORD</em> pattern, we can look at the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a>.&nbsp;</p>

<p>One can do the same kind of analysis to understand the patterns that match the <em>url.original</em>, <em>request.bytes</em> and <em>event.duration</em> fields, which we leave as an exercise for the reader</p>

<p>Finally, the last statement in the Grok pattern is the following:</p>

<pre>%{GREEDYDATA}</pre>

<p>This expression does not have a <em>SEMANTIC</em> part, which means that the matching data is not stored into any field.&nbsp; Additionally, the <em>GREEDYDATA</em> Grok pattern will consume as much text as it can, which means that in our example it will match everything after the <em>event.duration</em> field. The <em>GREEDYDATA</em> expression will come in handy when debugging complex Grok patterns, as discussed in the following sections of this blog.&nbsp;&nbsp;</p>



<p>When constructing a new Grok pattern, it is often easiest to construct the Grok pattern incrementally starting from the left and working towards the right side of the unstructured text that we are trying to match.&nbsp;</p>

<p>Two tools that can be helpful for building and …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/">https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/</a></em></p>]]>
            </description>
            <link>https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820793</guid>
            <pubDate>Mon, 13 Jul 2020 13:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple devices are leaking sensitive data over BLE]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23820589">thread link</a>) | @dchest
<br/>
July 13, 2020 | https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/ | <a href="https://web.archive.org/web/*/https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
										
						<p>By <a href="http://perso.citi-lab.fr/gcelosia/">Guillaume Celosia</a> and <a href="https://perso.citi-lab.fr/mcunche/index.html">Mathieu Cunche</a></p>
<h4><a href="https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf"><strong>Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols</strong></a></h4>

<p>We found that Apple devices are leaking sensitive information in the BLE wireless signals they emit. Those issues are associated with the Apple Continuity services and are affecting all Apple devices as well as devices compatible with the Continuity framework. Based on a reverse engineering of Continuity, we identified that the Bluetooth Low Energy (BLE) messages emitted by Apple devices include unencrypted data that can expose sensitive information. We discovered that those data can be easily collected by an eavesdropper and processed in order to: track users, monitor activities in a smarthome, obtain phone number, email addresses and Apple Voice Assistant, Siri, commands, and more.</p>
<p><img src="https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy.png" alt="" width="822" height="385" srcset="https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy.png 822w, https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy-300x141.png 300w, https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy-768x360.png 768w" sizes="(max-width: 822px) 100vw, 822px"></p>

<h2>BLE advertising</h2>
<p>In BLE, devices broadcast short messages, called Advertising Packets, to announce their presence and feature to nearby devices (those messages can be observed from an Android device using an application like <a href="https://play.google.com/store/apps/details?id=com.contextis.android.BLEScanner&amp;hl=en">Ramble</a>). Advertising Packets can include the name of the device, its type, but can also include custom data in a field called Manufacturer specific. This field is typically used by vendors to transmit data for application. Apple make use of this field to include data for its Continuity Protocols.</p>
<h2>Apple Continuity Protocols</h2>
<p>Apple has developed a number of features, called <a href="https://support.apple.com/en-us/HT204681"><i>Continuity</i></a>, that are designed to increase the usability of its products. Those features include: activity transfert, file transfert (airDrop), Wi-Fi password sharing, etc. The communication between nearby devices, required by Continuity services, is done by using BLE. Continuity data are embedded in BLE advertising packets and are broadcast to be picked up by nearby devices.</p>

<h2>Data exposed in cleartext</h2>
<p>We found that, even though some elements are encrypted, most of the data included in Continuity messages is sent in plain text. The exposed data can thus be passively collected by an eavesdropper and exploited to mount one of the attack presented below.</p>
<h2>Tracking users (iPhones, iPad, airpods …)</h2>
<p>We found that the content of <i>Apple Continuity </i>BLE messages can be used to track the device despite the use address randomization. We have identified several elements that remain constant over time or that can undermine the anti-tracking feature mechanism (i.e. address randomization). For instance, we found that messages emitted by earpods include information (battery levels and lid open counter) that can be exploited to track the earpod set. We also discovered a novel attack that would allow tracking by actively replaying BLE messages. An passive attacker could exploit this information to track the the location of individuals in spite of address randomization, the anti-tracking feature of BLE.</p>
<h2>Linking device belonging to the same iCloud account</h2>
<p>We discovered that it is possible to link together devices associated to the same iCloud account. This attack relies on the replay of messages that will trigger a response only from devices associated to the same <i>iCloud</i> account. An attacker could exploit this to identify all the device belonging to a person, and could narrow down its home if some device are left there.</p>
<h2>Monitoring activities in a smart home (Homekit)</h2>
<p>We found that messages emitted by <i>Homekit</i>-compatible devices can betray the activity in a smart-home. <a href="https://developer.apple.com/homekit/"><i>Homekit</i></a> is a smart-home framework developed by <i>Apple</i> and found in <a href="https://www.apple.com/fr/shop/accessories/all-accessories/homekit">devices</a> of <i>Apple</i> and other vendors (…). <i>Homekit</i> devices using BLE continuously emit messages that include an indicator reflecting the device state. For instance, in the case of a lightbulb, this indicator changes only when it is either turned on or turned off. Similarly, in an infrared movement detector, the indicator changes only when a person crosses the detection field. In-lab experiments showed that a passive attacker can leverage Homekit BLE messages to track the evolution of devices in a household and thus monitor the activities of the occupants.</p>
<h2>Device model, software version and more</h2>
<p>We found that a number of messages expose a wide variety of information on the emitting device characteristics and state: device model, OS version, device color, cellular connectivity, battery level, current activity etc.</p>
<h2>E-mail address and Phone numbers (Airdrop &amp; Nearby)</h2>
<p>We found that when using features such as Airdop and Nearby, devices emit messages from which email addresses and phone numbers can be extracted. Continuity services allow to seamlessly share resources with nearby devices: Airdrop to share files, Nearby to share Wi-Fi network credential. Prior exchange of information, the devices establish their identity by exchange identifiers over BLE: email addresses and/or phone numbers. Those identifiers are not sent in clear but are rather hashed using a cryptographic hash-function. This obfuscation can be bypassed in most cases and the identifiers recovered.</p>
<h2>Voice assistant commands (Siri)</h2>
<p>We found that when activated via voice, the Siri voice assistant will generate a message including a digital fingerprint of the command. Although the raw audio signal cannot be reconstructed from it, the fingerprint could be leveraged to infer the command.</p>

<p>The vulnerabilities identified were reported to Apple, Osram and Eve on May 29 th , 2019.</p>

<p>This work was supported by the <a href="http://www.citi-lab.fr/chairs/iot-chair/">INSA Lyon – SPIE ICS IoT chair</a> and the H2020 <a href="https://www.sparta.eu/">SPARTA</a> Cybersecurity Competence Network project.</p>
<p><img src="https://team.inria.fr/privatics/files/2019/10/logo-chaire-e1570022002577.jpg" alt="" width="200" height="66"><img src="https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-150x150.jpg" alt="" width="150" height="150" srcset="https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-150x150.jpg 150w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-300x300.jpg 300w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-144x144.jpg 144w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg.jpg 400w" sizes="(max-width: 150px) 100vw, 150px"></p>

<p>The corresponding research paper, <a href="https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf"><u>Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols</u></a>, will be presented at the <a href="https://petsymposium.org/2020/index.php">20th Privacy Enhancing Technologies Symposium (PETS 2020)</a> on 14-18 July 2020 in Montreal, Canada.</p>
<h3><a name="citeme"></a>APA style citation and bibtex entry</h3>
<p>You can use the following APA style citation or bibtex entry to reference our paper:</p>
<pre>Celosia, G., &amp; Cunche, M. (2020).Discontinued Privacy: Personal Data Leaks
in Apple Bluetooth-Low-Energy Continuity Protocols. <i>Proceedings on Privacy
Enhancing Technologies, 2020</i>(1), 26-46. De Gruyter Open.
@article{celosia2020close,
    title={Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols},
    author={Celosia, Guillaume and Cunche, Mathieu},
    journal={Proceedings on Privacy Enhancing Technologies},
    volume={2020},
    number={1},
    pages={26--46},
    year={2020},
    publisher={De Gruyter Open}
}</pre>
<p><a href="http://creativecommons.org/licenses/by/4.0/">Creative Com</a></p>
								</div></div>]]>
            </description>
            <link>https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820589</guid>
            <pubDate>Mon, 13 Jul 2020 13:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad Habits]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820496">thread link</a>) | @fizentech
<br/>
July 13, 2020 | https://fizentech.com/bad-habits/ | <a href="https://web.archive.org/web/*/https://fizentech.com/bad-habits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Does your organization have habits that are detrimental to their success?&nbsp; The answer of course, is yes - all organizations and their people, have embedded routines and habits that are limiting their success.&nbsp; Changing a habit is challenging and often we don't even realize we have a habit that is limiting our ability to improve.</p>
<p>In the groundbreaking book, The Power of Habit, Charles Duhigg points out that in a paper published by a Duke University researcher, it was <em>found that more than 40 percent of the actions people performed each day weren't due to decision making, but were habits. In a sense, that's alarming because when we're in the middle of a habit, we're thinking less.</em></p>
<p>Well ... hold on, we do NOT want our IT professionals thinking less, we want them actively thinking through problems and critically finding ways to improve the experience of end users.&nbsp; That can become a challenge when working on an IT Help Desk becomes routine, or a strong willed Project Manager is not listening to the input of the team; and resources disengage and come to expect to be led rather than to lead.</p>
<p>As an technology provider, we provide IT Services to a broad range of industries.&nbsp; The variation in organizations we serve has helped us work with many different people, in a variety of geographical areas and countries.&nbsp; We have found that leaders with good habits naturally attract and retain employees with good habits.&nbsp; The culture of the organizations we serve and the attitudes and routines of its employees, often reflect the attitudes, routines and habits of their executive teams and owners.&nbsp; It can be hard medicine to accept, but it is true - you lead from the top (but that doesn't mean you can't be a positive agent for change, whatever your position is within a group).</p>
<p>Starbucks has often been cited for the system they developed for exceptional customer service, now referred to as the LATTE System.&nbsp; They encourage their employees to,</p>
<ul>
<li>Listen to the Customer</li>
<li>Acknowledge their complaint</li>
<li>Take action by solving the problem</li>
<li>Thank them</li>
</ul>
<p>Customers can be a wonderful and often <a href="https://fizentech.com/help-wanted/">free source of advice</a> on what your organization is or is not doing well.&nbsp; We have added an additional ingredient to this wonderful formula, and that is returning back to our customer to make sure systems are still operating as discussed.&nbsp; We want to be sure they are still happy with the outcome; perhaps easier for us as our clients are typically part of ongoing managed service agreements.</p>
<p>A few years ago we were required to roll out endpoint management to a very large customer base.&nbsp; Our product offering includes endpoint monitoring and protection for mobile devices and workstations, and when you're working with large user groups; coordinating the installations can be a real challenge.&nbsp; Nobody wants to be inconvenienced or disrupted by a software installation.</p>
<p>Our client had previous experiences with MDM and RMM roll outs that did not go very well, and we found ourselves listening to their experiences and brainstorming how we could avoid the common approaches used by other IT vendors; forcing installation and maintenance windows on end users.</p>
<p>We found if we put the power of scheduling the installations for end users into their own hands, rather than falling back on the common habit in IT organizations to force installation and maintenance windows; the installation process not only went smoother but completed faster.&nbsp; By providing end users scheduling options they were empowered with autonomy and enjoyed controlling their own downtime.</p>
<p>Willpower is the biggest and most important element of developing good habits for an organization.&nbsp; An essential element of willpower, is autonomy.&nbsp; &nbsp;Everyone wants to believe and feel that they are in control of their lives, schedule and organization.&nbsp; When we take away someone's choices, they become frustrated - but when we provide choices, we find that our ability to coordinate and deliver for a client grows tenfold.</p>
<p>We need to reflect on the processes, systems and rule-sets that are governing how our organizations operate; and by listening to our stakeholders, find new ways to innovate and empower them to be apart of our mission; to keep their IT systems running smoothly.&nbsp; Find ways to engage with your user base, and use their feedback to drive innovative IT Services within their organization; they will thank you.</p>

</div></div>]]>
            </description>
            <link>https://fizentech.com/bad-habits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820496</guid>
            <pubDate>Mon, 13 Jul 2020 13:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How reframing discounts led to a 4x increase in yearly plans]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820462">thread link</a>) | @Mnlfrgr
<br/>
July 13, 2020 | https://manuel.friger.io/blog/reframing | <a href="https://web.archive.org/web/*/https://manuel.friger.io/blog/reframing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <div>
            <p><!--block-->Back in May my wife and I decided to move out of our flat in Bristol.</p>

<p>By then we had already been living for a couple of months with my in-laws and it didn't make sense to keep paying £1k+/month in rent.</p>

<p>After some discussion, we decided to throw some money at the problem and put all our stuff in a storing facility.</p>

<p>I started googling storage companies in Bristol and I was quickly overwhelmed by the number of options (pro tip: don't start a storage business, it's ridicolously competitive).</p>

<p>Every company allowed me you to get an online quote by entering the size of the storing unit and how long I wanted to rent it for.</p>

<p>But one company did things differently.</p>

<p>On top of asking me the same two questions, UK Storage Company also <strong>asked me to choose a discount</strong>.</p>

<div>
<p><span data-trix-cursor-target="left" data-trix-serialize="false">ï»¿</span><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/205/content_Screenshot_2020-07-10_Your_storage_quote_is_below%281%29.png"></p></div>

<p>At first, I was confused.</p>

<p>I wondered why they would allow me to choose my own discount. Then I realised it was the good ol' "the longer you commit, the less you pay" gimmick.</p>

<p><strong>Same technique, different framing.</strong><br>
UK Storage Company put me in the driver's seat and empowered me to make my decision.</p>

<p>That's when my brain started whirring and buzzing, and one question began to form in my head: what if I used the same framing <a href="https://referralhero.com/">for my SaaS product</a>?</p>

<p>After all, cash-flow is king for (bootstrapped) startups and having people commit to yearly plans helps to lower churn.</p>

<p>Would that have any effect on how many people choose the longer plans (biannual or annual) over the monthly one?</p>

<p>That same day I <a href="https://twitter.com/manuel_frigerio/status/1264609587413553155">tweeted about it</a> and updated the checkout page of my app as shown below.</p>

<p><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/206/content_Screenshot_2020-07-10_ReferralHero_-_Advanced_Referral_Marketing_Software_.png"></p>



<h2><!--block-->The results</h2>

<p><!--block-->After 7 weeks the experiment has been a great success.<br>
With the new framing, the percentage of people who chose the biannual or annual plan <strong>has gone from 4.8% to 19%</strong>, a rather nice <strong>395% increase</strong>.<br>
<span data-trix-cursor-target="right" data-trix-serialize="false"><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/207/content_chart.png"></span><br>
I've done several pricing experiments over the years but none of them has been as successful and in such short space of time.</p>

<p>Perhaps even more interesting is that <strong>more than twice as many people chose the annual plan over the biannual plan</strong>.</p>

<p>My hunch is that this is due to the higher discount rate of the annual plan (35% for 12 months vs 15% for 6 months means an extra 5% discount when you choose the annual plan), which increases the perceived value.</p>

<h2><!--block-->Never stop experimenting</h2>

<p><!--block-->There's a small handful of levers you can pull to grow a business and <a href="https://manuel.friger.io/blog/charge-more">pricing is probably the most underutilised one</a>. Most SaaS businesses choose a pricing model and rarely, if ever, review it.</p>

<p>A better (and more profitable) approach is to run small experiments. If they work, incorporate them. If they don't, try something else.</p>

<p>Some people are scared that changing things will upset their customers but the truth is:</p>

<ol>
	<li>
	<p><!--block-->you are allowed to change whatever you want about your business.</p>
	</li>
	<li>
	<p><!--block-->you can always revert back. Nothing is fixed.</p>
	</li>
	<li>
	<p><!--block-->in reality, nobody cares.</p>
	</li>
</ol>

<h2><!--block-->Do it yourself</h2>

<p><!--block-->If you want to try this experiment in your business, here are a couple of suggestions:</p>

<ul>
	<li>
	<p><!--block-->don't <a href="https://medium.com/@FlorentGeerts/the-jam-experiment-how-choice-overloads-makes-consumers-buy-less-d610f8c37b9b">overload people</a> with options; have maximum 3.</p>
	</li>
	<li>
	<p>to nudge people towards one option, offer a substantially higher discount (like I did with the yearly plan)</p>
	</li>
	<li>
	<p>Don't try to be sneaky and word the options properly. As you can see in my example, people know exactly what they get and how much they pay.</p>
	</li>
	<li>
	<p>ask people immediately after sign-up when they are in the right frame of mind. In my experience, asking people to switch to yearly plans a couple of months after they have used your product triggers many more questions in their mind, whereas by asking them before they try your product you're putting them in front of a simple decision: do I want to save money?</p>
	</li>
</ul>

<p><!--block-->As people who work in the tech industry, we are all exposed to the same ideas, patterns and filters. This is why there's so little innovation and everyone just copies what everyone else is doing.</p>

<p>Sometimes all you need to do is to look at what companies in completely different industries operate. You might be suprised what a storage company can teach you.</p>

<p><strong>PS:</strong> If you do try this experiment, <a href="https://manuel.friger.io/cdn-cgi/l/email-protection#4e232f203b2b220e283c27292b3c602721">let me know how it goes</a>.</p>

<p><strong>PPS:</strong> You probably want to know if we did hire that storing company in the end. The answer is NO. Eventually, we decided to hire a removal company and have all our stuff with us.</p>

          </div>
        </div>
        
      </div><div>
        <h3>Did you enjoy this?</h3>
        <p>Then you will like <a target="_blank" href="https://manuel.friger.io/join">ðŸ”¥The Fireside</a>, a monthly-ish newsletter about psychology, business, technology and the intersection of those plus any new articles I publish on this blog.</p>
      </div></div>]]>
            </description>
            <link>https://manuel.friger.io/blog/reframing</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820462</guid>
            <pubDate>Mon, 13 Jul 2020 13:24:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russ v7.0 – Services framework/library for Unix sockets]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23820398">thread link</a>) | @johnmdev
<br/>
July 13, 2020 | https://expl.info/display/RUSS/Home | <a href="https://web.archive.org/web/*/https://expl.info/display/RUSS/Home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-type="normal">
<div>
<p>RUSS is a protocol and framework for building service-oriented servers using UNIX/Domain sockets.</p><p>RUSS is an alternative to HTTP/web technologies for services running on UNIX/Linux.</p><p>RUSS is built on some familiar ideas:</p><ul><li>orthogonal operations: execute, help, list</li><li>service path: /-separated list of strings identifying a service and how to get there</li><li>ordered list of string arguments (aka positional arguments)</li><li>unordered collection of string attritubes as key=value pairs (like environment variables)</li><li>exit/return value</li><li>stream I/O over file descriptors (stdin, stdout, stderr)</li></ul><p>The benefits of using UNIX/Domain sockets are:</p><ul><li>performance</li><li>standard part of UNIX/Linux (no kernel modules needed)</li><li>credentials are mediated by the OS</li><li>connection between independent processes (even between different users)</li><li>passing of descriptors between independent processes (even between different users)</li></ul><p>Get started with&nbsp;<a href="https://expl.info/display/RUSS/RUSS+v7+-+Quickstart+Setup">RUSS v7 - Quickstart Setup</a>.</p><p>Further information for users and developers is available in the&nbsp;<a href="https://expl.info/display/RUSS/Documentation">Documentation</a>&nbsp;section:</p><ul><li><a href="https://expl.info/display/RUSS/RUSS+Specification">RUSS Specification</a></li><li><a href="https://expl.info/display/RUSS/RUSS+v7+-+Tools">RUSS v7 - Tools</a></li><li><a href="https://expl.info/display/RUSS/RUSS+v7+-+Core+Servers">RUSS v7 - Core Servers</a></li><li><a href="https://expl.info/pages/viewpage.action?pageId=40501388">pyruss - RUSS for the Python Programming Language</a></li><li><a href="https://expl.info/display/RUSS/goruss+-+RUSS+for+the+Go+Programming+Language">goruss - RUSS for the Go Programming Language</a></li></ul><h2 id="Home-Firstthings">First things</h2><ul><li><code>+</code>&nbsp;-&nbsp;the area that system servers register at; usually under&nbsp;<code>/var/run/russ/services</code><span><code><br></code></span></li><li><span><code>ruls</code>&nbsp;- command line tool to list servers/services (think&nbsp;<code>ls</code>)<br></span></li><li><span><code>ruhelp</code>&nbsp;- command line tool to get help information (think&nbsp;<code>man</code>)</span></li><li><span><code>ruexec</code>&nbsp;- command line tool to execute a service</span></li><li><span><code>pyruss</code>&nbsp;- Python bindings for the C API</span></li><li><span><code>rubb</code>&nbsp;- manage servers/services</span></li></ul><h2 id="Home-ListingServers/Services">Listing Servers/Services</h2><p>What's available?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruls +
debug
exec
plus
proc
set
ssh
tee</pre>
</div></div><p>What services does the&nbsp;<code>debug</code>&nbsp;server provide?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruls +/debug
chargen
conn
daytime
discard
echo
env
exit
request
session
spath</pre>
</div></div><h2 id="Home-GettingHelp-BuiltinManPage">Getting Help - Built in Man Page</h2><p>How do I use the&nbsp;<code>debug</code>&nbsp;services?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruhelp +/debug
Provides services useful for debugging.

/chargen[/...]
    Generate and send characters following the RFC 864 character
    generator protocol sequence.

/conn[/...]
    Report connection information.

/daytime
    Report the date and time.

/discard[/...] [--perf]
    Discard all data received from stdin. If --perf is specified,
    performance feedback is reported to stderr.

/echo[/...]
    Simple echo service: read from stdin and write back to stdout.

/env
    Report server side environ entries.

/exit &lt;value&gt;
    Return with given exit value (between 0 and 255).

/request[/...]
    Report request information.

/session[/...]
    Report session information.

/spath[/...]
    Report service path information.</pre>
</div></div><h2 id="Home-RunningaService">Running a Service</h2><p>Try the character generator:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/debug/chargen
!"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefgh
"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghi
#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghij
^C</pre>
</div></div><p>Show "request" information (as received and sent back by the server):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec -a X=123 -a Y=abc +/debug/request hello there world
protocol string (0010)
spath (/request)
op (execute)
opnum (2)
attrv[0] (X=123)
attrv[1] (Y=abc)
argv[0] (hello)
argv[1] (there)
argv[2] (world)</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/debug/daytime
Friday, February 16, 2018 11:45:50-GMT</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service on another machine "buddy" (<code>ssh</code>&nbsp;must work without user interaction):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/ssh/buddy/+/debug/daytime
Friday, February 16, 2018 11:46:55-GMT</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service from Python:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ PYTHONPATH=/usr/lib/russng python2
&gt;&gt;&gt; import pyruss
&gt;&gt;&gt; rv, ev, out, err = pyruss.execv_wait_inouterr_timeout(1000, "+/ssh/buddy/+/debug/daytime")
&gt;&gt;&gt; print out
Friday, February 16, 2018 11:48:23-GMT</pre>
</div></div><p>Echo a message, hopping through three machines "buddy", "bobby", and "bibby" (as before,&nbsp;<code>ssh</code>&nbsp;must work without user interaction):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ echo "hop hop hop" | ruexec +/ssh/buddy/+/ssh/bobby/+/ssh/bibby/+/debug/echo
hop hop hop</pre>
</div></div></div>
</div></div>]]>
            </description>
            <link>https://expl.info/display/RUSS/Home</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820398</guid>
            <pubDate>Mon, 13 Jul 2020 13:16:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Project over Money, Team over Project]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23820390">thread link</a>) | @strdr4605
<br/>
July 13, 2020 | https://strdr4605.github.io/project-over-money-team-over-project | <a href="https://web.archive.org/web/*/https://strdr4605.github.io/project-over-money-team-over-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><h2>Project over money, team over project</h2><p><time>11.07.2020</time> — <a href="https://strdr4605.github.io/tags/motivation">motivation</a> — <span>2<!-- --> min read</span></p><section><p>Behind any work stands a motivation. Sometimes work is a pleasure, other times you do things that are unpleasant just because you have to.
But in the end motivations like money, common goal, future achievements drive us to work.
When choosing a job as a software engineer, things that motivate me and probable you are the <strong>project</strong> what I will work on,
<strong>team</strong> what I will work with and <strong>money</strong> for my personal need.
When making the final decision I usually value <strong>project over money, team over project</strong>.</p><h2>Team</h2><p>For me, the team that I will work with is the most important aspect when searching for a new job.</p><blockquote><p>“If you are the smartest person in the room, then you are in the wrong room.” ― Confucius</p></blockquote><p>Being in a team with people that are more experienced than you is the key to fast-growing.
But don't just stay and wait when their knowledge will be transferred to you.</p><ul><li>Observe their behaviors</li><li>Make proposals and wait for feedback</li><li>Ask for advice</li><li>Ask "Why?" when they make a decision. "Why this database?" "Why this service?" ...</li></ul><p>Make sure to not push too hard on them. As this can defocus and irritate some people.</p><p>Even if your teammates aren't more experienced than you they may share interesting articles, tips, thoughts.</p><p>In the end, if you have a hard situation, maybe the project is not that interesting (at the moment) or you have problems with finishing a task,
with a great team, you can carry on and pass any issues.</p><h2>Project</h2><p>At this moment in my career, I am really focused on the technical part of a project.
I enjoy learning new tools, libraries that will increase productivity, and when coding I am trying to create a piece of art.</p><p>But also the idea and the product may still be a good motivation and even if the tech stack is not that good,
with a great team, you will refactor everything as long as you believe in the product idea.</p><p>Even if the team is not that good or you don't have a team at all, enjoying the tech stack or believing in the product
will make you continue working and loving your job.</p><p>While at the interview, I try to discover as much as possible about the project stack and idea to understand if
I am willing to accept an offer bellow my initial expectations.</p><h2>Money + benefits</h2><p>Money is important as everyone has their needs and money represent your value as a software engineer.
Employee benefits like included food, gym, short commute time may be also added to the total compensation pack.</p><p>If you have a family and bills to pay money may be a decisive factor.
But still, put everything on the table and before making the final decision ask yourself a question.</p><blockquote><p>What will be your next job after this one?</p></blockquote><p>In other words: Where will this job lead you? How much will your professional skills increase?
Will this job have temporary benefits you will bust your entire career?</p><p>Does it worth an additional 100% salary increase to work with a 5+ year old legacy codebase, old tech stack, and maybe a bad team?</p><h2>Conclusion</h2><p>As everyone has a price I will try to conclude with some compensation examples.</p><p>If I am enjoying the project and/or the team at my current job, I would not accept a 5-15% salary increase offer,
as after 3-6 months I may get even more increase at my current job.
If I don't like the project or the team is toxic, I may accept a lower job offer just because
I will gain more from the new team or new tech stack.</p><p>Focus on your professional skills, gain maximum value from your team (don't forget to also give back and share your knowledge with teammates),
learn your tech stack, enjoy your software engineering career and the money will eventually come to you.</p></section></div></div>]]>
            </description>
            <link>https://strdr4605.github.io/project-over-money-team-over-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820390</guid>
            <pubDate>Mon, 13 Jul 2020 13:15:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Querying 40k Datasets with SQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820382">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/40k-sql-datasets | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/40k-sql-datasets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#introduction" as="#introduction">Introduction</a></li><li><a href="#data-should-be-discoverable-and-composable" as="#data-should-be-discoverable-and-composable">Data should be discoverable and composable</a></li><li><a href="#mounting-vs-cloning-data" as="#mounting-vs-cloning-data">Mounting vs. Cloning Data</a></li><li><a href="#mounting-data-in-splitgraph-cloud" as="#mounting-data-in-splitgraph-cloud">Mounting data in Splitgraph Cloud</a></li><li><a href="#avoiding-the-pull-of-data-gravity" as="#avoiding-the-pull-of-data-gravity">Avoiding the pull of Data Gravity</a></li><li><a href="#looking-to-the-future" as="#looking-to-the-future">Looking to the future</a></li></ol></nav><section><h2 id="introduction">Introduction</h2><p><a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">Splitgraph</a> is a tool and platform for building, versioning, querying and sharing datasets. Inspired by Docker and Git, it works on top of PostgreSQL and integrates seamlessly with anything that uses PostgreSQL. Our <a href="https://www.splitgraph.com/explore" as="https://www.splitgraph.com/explore">data catalog</a> already includes over 40,000 datasets from government open data portals, all queryable via SQL.</p><p>The Splitgraph catalog classifies these datasets as <a href="https://www.splitgraph.com/docs/splitgraph-cloud/external-repositories">external repositories</a>. These are different from the default <a href="https://www.splitgraph.com/docs/concepts/repositories">Splitgraph repositories</a>, which are collections of <a href="https://www.splitgraph.com/docs/concepts/images">Splitgraph images</a>. Yet Splitgraph allows you to query them in the same way as you do Splitgraph images. For example, you can use SQL to query any repository or <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals" as="/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals"><code>JOIN</code> between multiple of them</a>. Or you can use Splitfiles to <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#splitfile" as="/docs/ingesting-data/socrata#splitfile">build reproducible datasets</a> from them. And every external repository includes an <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">auto-generated PostgREST API</a>.</p><p>External repositories allow Splitgraph Cloud to index live data without actually ingesting it. This way, you can use the catalog to discover live data. But you only need to ingest it when you're ready to query it, or snapshot it as part of a Splitgraph image.</p></section><section><h2 id="data-should-be-discoverable-and-composable">Data should be discoverable and composable</h2><p>Many services exist for cataloging data and making it discoverable. For example, <a href="https://datasetsearch.research.google.com/" as="https://datasetsearch.research.google.com/">Google Dataset Search</a> provides a nice interface for searching and discovering datasets (in fact, <a href="https://datasetsearch.research.google.com/search?query=opd%20crimes&amp;docid=jrM9a8yTUXMZaY1QAAAAAA%3D%3D" as="https://datasetsearch.research.google.com/search?query=opd%20crimes&amp;docid=jrM9a8yTUXMZaY1QAAAAAA%3D%3D">it even includes Splitgraph repositories</a>). The problem is, the data is fragmented and siloed across different data portals. It's nice to be able to search for data and download a CSV file. But most datasets are uninteresting in isolation. The real power comes from the ability to combine datasets and query them together.</p><p>Splitgraph does not only provide an index for discovering open data. It also provides the tools for composing open datasets together. For example, mounting the data from the <a href="https://data.cambridgema.gov/" as="https://data.cambridgema.gov">Cambridge</a> and <a href="https://data.cityofchicago.org/" as="https://data.cityofchicago.org">Chicago</a> data portals is as simple as running two commands:</p><pre><code metastring=""><span><span>$</span> <span>sgr <span>mount</span> socrata chicago -o <span>'{"domain": "data.cityofchicago.org"}'</span></span></span>
<span>Connecting to remote server...
Mounting Socrata domain...
Getting Socrata metadata
warning: Requests made without an app_token will be subject to strict throttling limits.
Loaded metadata for 504 Socrata tables

</span><span><span>$</span> <span>sgr <span>mount</span> socrata cambridge -o <span>'{"domain": "data.cambridgema.gov"}'</span></span></span>
<span>Connecting to remote server...
Mounting Socrata domain...
Getting Socrata metadata
warning: Requests made without an app_token will be subject to strict throttling limits.
Loaded metadata for 137 Socrata tables
</span></code></pre><p>At this point, all the datasets in these two data portals are available for querying. You can query them in isolation, or you can query them together. You can use a Splitfile, <code>sgr sql</code>, or any standard SQL client:</p><p><a href="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png" as="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png"><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png" alt="DBeaver overview"></a></p><p>Here's how you can compare daily COVID cases in Chicago and Cambridge (from two separate data portals) with a standard <code>JOIN</code> query:</p><pre><code metastring=""><span>SELECT</span>
    cambridge_cases<span>.</span><span>date</span> <span>AS</span> <span>date</span><span>,</span>
    chicago_cases<span>.</span>cases_total <span>AS</span> chicago_daily_cases<span>,</span>
    cambridge_cases<span>.</span>new_positive_cases <span>AS</span> cambridge_daily_cases
<span>FROM</span>
    chicago<span>.</span>covid19_daily_cases_and_deaths_naz8_j4nc chicago_cases
<span>FULL</span> <span>OUTER</span> <span>JOIN</span>
    cambridge<span>.</span>covid19_cumulative_cases_by_date_tdt9_vq5y cambridge_cases
<span>ON</span>
    date_trunc<span>(</span><span>'day'</span><span>,</span> chicago_cases<span>.</span>lab_report_date<span>)</span> <span>=</span> cambridge_cases<span>.</span><span>date</span>
<span>ORDER</span> <span>BY</span> <span>date</span> <span>ASC</span><span>;</span>
</code></pre><p>(For more details and in-depth instructions, see the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW documentation</a>.)</p><p>Note that this is not limited to combining multiple public datasets. Often, the work of a data analyst includes combining internal data with public or licensed datasets from external vendors. The same semantics of "mounting" data in Splitgraph apply.</p></section><section><h2 id="mounting-vs-cloning-data">Mounting vs. Cloning Data</h2><p>With Splitgraph, there are two primary ways to ingest data: cloning it or mounting it.</p><p><a href="https://www.splitgraph.com/docs/working-with-data/clone-vs-checkout">"Cloning" (and checking-out)</a> an image means downloading a versioned data image, which is a snapshot of a database comprised of delta-compressed diffs. For example, the result of running a Splitfile is an image.</p><p>"Mounting" means establishing a connection to a live data source. The term comes from the idea of "mounting" a filesystem. A mounted table uses a <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction">foreign data wrapper</a> (FDW), and you don't ingest data from it until you query it. For example, the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW</a> translates SQL queries to <a href="https://dev.socrata.com/docs/queries/" as="https://dev.socrata.com/docs/queries/">SoQL queries</a> and forwards them to the Socrata server.</p><p>(For more details on mounting data, FDWs and custom mount handlers, read our recent <a href="https://www.splitgraph.com/blog/foreign-data-wrappers">"foreign data wrappers" blog post</a>.)</p></section><section><h2 id="mounting-data-in-splitgraph-cloud">Mounting data in Splitgraph Cloud</h2><p>Mounting is the key abstraction that allows Splitgraph Cloud to index external repositories with features like an auto-generated REST API. On the backend, the "query API" (a subject for a later post) uses the Splitgraph library and Socrata mount handler to mount repositories on demand. Then it exposes the mounted schemata to a customized version of <a href="http://postgrest.org/" as="http://postgrest.org/">PostgREST</a> which creates the API.</p><p>Separately, a periodic Airflow task queries the Socrata metadata API to discover and index over 40,000 repositories. Conveniently, the same Socrata software powers over 200 government open-data portals, so one mount handler provides a large catalog of useful live data.</p></section><section><h2 id="avoiding-the-pull-of-data-gravity">Avoiding the pull of Data Gravity</h2><p>Mounting is a powerful abstraction because it allows you to interact directly with upstream data sources, avoiding the need for ETL. In 2010, GE Engineer Dave McCrory coined the term "<a href="https://datagravitas.com/2010/12/07/data-gravity-in-the-clouds/" as="https://datagravitas.com/2010/12/07/data-gravity-in-the-clouds/">data gravity</a>." In his blog post, he observed that "data if large enough can be virtually impossible to move."</p><p>Splitgraph, as a data versioning solution, should work with all your data, not just the subsets of it that you can move. Traditional ETL tools force you to ingest or duplicate your data before you can interact with it. With Splitgraph, you only need to pull upstream data into your images at query time. This allows incremental adoption and quick experimentation; there is no need to move your data warehouse to start using Splitgraph. Instead, you only need to setup an FDW.</p><p>Note that the idea of data gravity applies to versioned data images (which you clone) as much as it does to upstream, live data (which you mount). What if you want to import only a subset of data from a large image? This is the use case for <a href="https://www.splitgraph.com/docs/large-datasets/layered-querying">layered querying</a>, which allows you to "check out" an image without downloading it. Instead, Splitgraph creates an FDW that queries only the "layers" of the image necessary to satisfy the query. You can think of layered querying like a mount handler for Splitgraph images.</p></section><section><h2 id="looking-to-the-future">Looking to the future</h2><p>At the moment, Splitgraph Cloud only uses the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW</a> as a mount handler for external repositories, since the <a href="https://www.tylertech.com/products/socrata" as="https://www.tylertech.com/products/socrata">Socrata data platform</a> powers most government open-data portals.  In the future, it could use additional mount handlers to provide access to a wider array of upstream sources. To create an external repository, Splitgraph just needs a suitable FDW and a way to index the upstream data. For example, it's easy to imagine indexing Google BigQuery datasets. More interestingly, an on-premise version of Splitgraph could index private databases or data warehouses behind a firewall.</p><p>Our goal for Splitgraph is to make tools for data science as easy and pleasurable to use as tools for coding. That's why our main philosophy is to "stay out of the way." Mounting data is a great example of this philosophy in action. Why force your data warehouse to talk to Splitgraph, when Splitgraph can talk to your data warehouse?</p><p>In the meantime, make sure to <a href="https://www.splitgraph.com/explore">explore data</a> on Splitgraph. If you know SQL, you can <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">get started</a> in less than 10 minutes.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/40k-sql-datasets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820382</guid>
            <pubDate>Mon, 13 Jul 2020 13:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wallet fingerprinting nearly a third of all Bitcoin transactions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820109">thread link</a>) | @b10c
<br/>
July 13, 2020 | https://b10c.me/mempool-observations/3-blockchaincom-recommendations/ | <a href="https://web.archive.org/web/*/https://b10c.me/mempool-observations/3-blockchaincom-recommendations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p>Transactions sent with Blockchain.com wallets make up for about a third of all
Bitcoin transactions. A methodology to identify these transactions is described
and used. Insights about the wallet-usage are derived from the resulting
dataset. The privacy implications and possible improvements are discussed.</p>
<hr>
<p>One of the first observations made when building the <a href="https://mempool.observer/monitor">Bitcoin Transaction
Monitor</a> was that many transactions precisely follow the recommendations of
a feerate estimator. These transactions appear as horizontal bands, which rise
and sink as the feerate recommendations change.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/bands.png" alt="Transactions following the Blockchain.com feerate recommendations">
    <figcaption><center></center></figcaption>
</figure>
    
<p>Most of these transactions share the same fingerprint. Only P2PKH outputs are
spent. No SegWit and neither multisig are spent. With every transaction, either
one or two outputs are created. When two outputs are created, then at least one
of them is a P2PKH output. The transactions are not time-locked, have a version
of one, and do not signal <a href="https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki">BIP-125 replaceability</a>. However, all are
<a href="https://github.com/bitcoin/bips/blob/master/bip-0069.mediawiki">BIP-69</a> compliant.</p>
<p>This matches the fingerprint of the Blockchain.com wallets: namely a Web, an
iOS, and an Android wallet. The wallets can only receive and spend P2PKH
outputs. While users can pay to all address formats<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the change-output, if
created, is a P2PKH output. The wallets construct the transactions with a
locktime of zero and a transaction version of one. The inputs and outputs are
all lexicographically sorted as specified by BIP-69.</p>
<p>The wallets use the Blockchain.com feerate estimator, which is publicly
accessible via <a href="https://b10c.me/blog/003-a-list-of-public-bitcoin-feerate-estimation-apis/#blockchaininfo-api">an API</a>. The API returns two feerate estimates: <em>priority</em>
and <em>regular</em>. The <em>priority</em> feerate aims for confirmation in the next hour
and the <em>regular</em> feerate for confirmation in an hour or more. By default,
the wallets follow the recommendations closely. Users can set a custom feerate,
but a warning is displayed.</p>
<h3 id="methodology">Methodology</h3>
<p>Combining the feerate estimates and the transaction fingerprints makes it
possible to identify transactions sent with one of the Blockchain.com wallets.
While the majority of the Blockchain.com transactions pay exactly the
recommended feerate, some under- or overpay by a fixed percentage. This is
caused by incorrect assumptions about the transaction size during the
calculation of the transaction fee. The transaction fee is the product of the
targeted feerate and the assumed transaction size. The final and actual
transaction size is only known after adding the signature to the transaction.</p>
<pre>fee  =  target feerate  ×  assumed transaction size
</pre>
<p>All underpaying transactions have two outputs. However, during the fee
calculation, the size of a one-output transaction is assumed. For example, for a
P2PKH <em>1in ⇒ 2out</em> transaction (226 bytes), the size of a <em>1in ⇒ 1out</em>
transaction (192 bytes) is used. This incorrect assumption results in the
transaction only paying around 85% (192 byte / 226 byte) of the recommended
feerate. As the transaction inputs make up for a large part of the transaction
size, the effect is smaller for transactions with more inputs. This behavior was
only present in the Blockchain.com Web wallet. A fix was <a href="https://github.com/blockchain/blockchain-wallet-v4-frontend/releases/tag/v4.32.6">released</a> on
April 21st, 2020.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/over-underpaying.png" alt="Transactions over- and underpaying by a fixed percentage">
    <figcaption><center></center></figcaption>
</figure>
    
<p>The overpaying transactions all have a single output. For these, a second output
is assumed during the fee calculation. To calculate the fee of a P2PKH
<em>1in ⇒ 1out</em> transaction (192 bytes), the size of a <em>1in ⇒ 2out</em> transaction
(226 bytes) is used. This results in the transaction paying about 118% (226 byte
/ 192 byte) of the recommended feerate. Similar to the underpaying transactions,
the effect is smaller for transactions with more inputs. These transactions are
assumed to originate from the Blockchain.com iOS wallet. This has not yet been
confirmed.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/methodology.png" alt="Visual explainer for methodology used to identify Blockchain.com transactions">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    Out of the set of transactions with the Blockchain.com wallet fingerprint, the
transactions paying the feerate recommended by the Blockchain.com feerate
estimator are selected. Transactions broadcast on April 19th, 2020, are shown.
The y-axis is centered around the <em>regular</em> recommendation, which was 3
sat/vbyte for most of the day. Between 12:00 UTC and 17:00 UTC, the <em>regular</em>
recommendation briefly jumped to 4 sat/vbyte for a few minutes each. On other
days the feerate recommendations are usually  more volatile. April 19th is a
Sunday. Sundays are known for less network activity compared to weekdays. This
day has been specifically chosen to showcase the methodology.
</p>
<p>Identifying Blockchain.com wallet transactions with this methodology is not
assumed to be perfectly accurate or reliable. For example, transactions send
with a custom feerate can not be identified and are false negatives.
Transactions constructed by different wallets that pay a similar feerate and
share the fingerprint could be identified as false positives. When the
recommended feerate is volatile, which is often the case for the <em>priority</em>
recommendation (for example, shortly after <a href="https://b10c.me/mempool-observations/2-bitmex-broadcast-13-utc/">the daily BitMEX broadcast</a>),
then some transactions might pay a feerate not recoded by the Bitcoin
Transaction Monitor. Additionally, the wallets could construct a transaction
using an older recommendation, which is different from the recommendation at the
time the transaction is broadcast. These transactions are false negatives as
well.</p>
<h3 id="observations">Observations</h3>
<p>The described methodology is used to identify the transactions send with
Blockchain.com wallets between April 1st and May 20th, 2020. The resulting
dataset spans over 50 days and contains about 4 million transactions. These pay
a total fee of 445.73 BTC and account for about 1.34 GB of block space. Roughly
two-thirds of the Blockchain.com wallet transactions target the <em>regular</em> feerate
while the remaining third targets the <em>priority</em> feerate.</p>
<p>Roughly the same number of outputs are created as are spend. Blockchain.com
wallet transactions have either a single payment-output or a payment-output and
a change-output. As the change-outputs are always P2PKH outputs, it is possible
to determine the payment-output type. Out of all outputs created about 31.7% are
P2PKH, 23.3% are P2SH, 0.34% are P2WPKH, and less than 0.01% are P2WSH
payment-outputs. The remaining 45.5% are P2PKH change-outputs. The most commonly
used input-output combinations are <em>P2PKH ⇒ P2PKH + P2PKH</em> with 33%,
<em>P2PKH ⇒ P2SH + P2PKH</em> with 26%, and <em>P2PKH ⇒ P2PKH</em> with around 7%.</p>
<br>
<!-- raw HTML omitted -->
<p>Users of the Blockchain.com wallet are most active between 15:00 UTC and 18:00
UTC and least active between 4:00 UTC and 5:00 UTC. At around 5:00 UTC, the
number of transactions per minute starts to rise. At this time it is 8am in
Moscow, and 7am in central Europe. Between 5:00 UTC and 10:00 UTC, the number
of transactions per minute rises from about 30 to just above 60. The
transactions per minute remain constant until rising again at noon UTC, which is
8am on the US east coast. The daily maximum is reached at around 16:00 UTC with
just above 75 transactions per minute. From there on, the activity declines
until reaching the minimum number of transactions per minute at around 4:00 UTC
again.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/time-of-day.png" alt="Activity hours of Blockchain.com wallet users.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    The transactions broadcast per minute with Blockchain.com wallets are shown. The
error bands show the standard deviation. The time between 8am and 8pm is
marked for central Asia, Europe, and eastern US timezones.
</p>
<br>
<!-- raw HTML omitted -->
<p><a href="https://thecryptofeed.net/articles/blockchain-com-says-they-account-for-a-third-of-all-bitcoin-transactions/">Reportedly</a>, Blockchain.com claims that their wallets are responsible for
one-third of all Bitcoin transactions. They <a href="https://www.blockchain.com/charts/my-wallet-n-tx">publish</a> the daily number of
transactions sent by their wallets. This lead to a discussion on the accuracy
and correctness of these numbers. The described dataset can be used to verify
this claim. The number of daily transactions in the dataset and the published
numbers can be compared. The total number of transactions sharing the
fingerprint with the Blockchain.com wallet transactions acts as an upper-bound.
The total transactions per day are retrieved from <a href="https://transactionfee.info/charts/transactions-per-day/">transactionfee.info</a> to
calculate Blockchain.com’s share of the network.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/one-third.png" alt="Showing that the Blockchain.com published numbers could be reasonably accurate.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>The daily transaction count published by Blockchain.com translates into a
network share of 30% to 35%. The share of the transactions with the same
fingerprint, the upper-bound, is on average about three absolute percent higher.
The share of the identified transactions in the dataset is about four to five
absolute percent lower than the Blockchain.com reported numbers at around 27% on
average. The transactions account for about 13% of the daily fees paid, and 20%
of the daily block space used.</p>
<p>However, the numbers reported by Blockchain.com still lie in a reasonable range.
There are multiple reasons why the described dataset could contain fewer
transactions than are reported by Blockchain.com. Some users might send
transactions with a custom feerate. These are not picked up by the described
methodology. Furthermore, it’s not clear if the reported numbers include
transactions send with the <a href="https://www.blockchain.com/de/api/blockchain_wallet_api">Blockchain.com Wallet API</a>. The API allows
users to construct transactions sending to multiple recipients which are not
accounted for in the described dataset.</p>
<br>
<!-- raw HTML omitted -->
<p>With the knowledge that the Blockchain.com Web wallet underpaid the recommended
feerate for transactions with two outputs, and the iOS wallet
overpays on transactions with one output, the wallet’s shares can be estimated.
For this, the assumption that the ratio of two-output to one-output transactions
is similar in all wallets must hold. The Web wallet accounts for one-third and
the iOS wallet for half of the Blockchain.com wallet transactions. The Android
wallet probably accounts for a majority of the remaining 17%. However, this can
not be verified as no data is indicating the share of the Android wallet.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/web-wallet-share.png" alt="Share of Web wallet transactions with two outputs.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    Between April 1st and April 22nd, the two-output transactions send with the Web
wallet made up for about a third of all two-output transactions send with
Blockchain.com wallets. The shown mean is weighted with the transaction counts.
A fix <a href="https://github.com/blockchain/blockchain-wallet-v4-frontend/releases/tag/v4.32.6">released</a> on April 21st resolved the underpaying behavior for
two-output transactions in the Web wallet. It took a few days until the release
got deployed.
</p>
<figure></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://b10c.me/mempool-observations/3-blockchaincom-recommendations/">https://b10c.me/mempool-observations/3-blockchaincom-recommendations/</a></em></p>]]>
            </description>
            <link>https://b10c.me/mempool-observations/3-blockchaincom-recommendations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820109</guid>
            <pubDate>Mon, 13 Jul 2020 12:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU: A Heuristic for Bad Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23819964">thread link</a>) | @some_furry
<br/>
July 13, 2020 | https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>If you see the letters GNU in a systems design, and that system intersects with cryptography, I can almost guarantee that it will be badly designed to an alarming degree.</p>



<p>This is as <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">true of GnuPG (and PGP in general)</a> as it is of designs like the proposed <a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html">GNU Name System</a> (IETF draft) and cryptographic libraries like GnuTLS and libgcrypt. In fact, I cannot recall single GNU-branded cryptography project that isn’t a roaring dumpster fire.</p>



<p>I will elaborate.</p>



<h2>Problems with the GNU Name System’s Cryptography</h2>



<h3>Asymmetric Cryptography</h3>



<p>The GNS (GNU Name System) uses an unconventional construction for zones:</p>



<blockquote><p>A zone in GNS is defined by a public/private ECDSA key pair (d,zk), where d is the private key and zk the corresponding public key. GNS employs the curve parameters of the twisted edwards representation of Curve25519 [<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC7748">RFC7748</a>] (a.k.a. edwards25519) with the ECDSA scheme ([<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC6979">RFC6979</a>]).</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-zones">GNU Name System IETF Draft, section 2</a></cite></blockquote>



<p>This is beyond weird: Going out of your way to use the edwards25519 curve from RFC 7748, but not use the Ed25519 signature algorithm, but still choosing to use deterministic ECDSA (RFC 6979).</p>



<p>(If you’re lost, I wrote about digital signature algorithms in <a href="https://soatok.blog/2020/04/26/a-furrys-guide-to-digital-signature-algorithms/">a previous blog post</a>.)</p>



<p>The authors acknowledge the unconventional nature of their design choice in section 9.1 of the RFC draft:</p>



<blockquote><p>GNS uses ECDSA over Curve25519. This is an unconventional choice, as ECDSA is usually used with other curves. However, traditional ECDSA curves are problematic for a range of reasons described in the Curve25519 and EdDSA papers. <strong>Using EdDSA directly is also not possible, as a hash function is used on the private key which destroys the linearity that the GNU Name System depends upon.</strong> We are not aware of anyone suggesting that using Curve25519 instead of another common curve of similar size would lower the security of ECDSA. GNS uses 256-bit curves because that way the encoded (public) keys fit into a single DNS label, which is good for usability.</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-cryptography">GNU Name System IETF Draft, section 9.1</a></cite></blockquote>



<p><s>The bold statement (my emphasis) is nonsense: In any design that uses digital signature algorithms, your system should map a private key (some opaque byte string) to a public key (some other opaque byte string) and signatures should also be opaque byte strings. The inclusion of a hash function under the hood of the signature algorithm is a moot point, especially since RFC 6979 also uses HMAC-SHA2 to generate deterministic nonces, thereby rendering their choice of RFC 6979 a contradiction of their stated goal.</s> Edit: <a href="#update-2020-07-09">see below</a>.</p>



<p>Using Ed25519 with a 32-byte private key (instead of a 64-byte private key) is also trivial. To wit: Libsodium offers <a href="https://libsodium.gitbook.io/doc/public-key_cryptography/public-key_signatures#key-pair-generation">crypto_sign_seed_keypair()</a> for this purpose.</p>



<p>But even worse: ECDSA is less secure and slower than EdDSA, even when you use the same curves, due to how the algorithms are implemented. The authors of the RFC do not defend this design choice beyond this hash function non sequitur.</p>



<div><figure><img data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I can’t be the only one feeling this way right now. Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.</figcaption></figure></div>



<h4 id="update-2020-07-09">(Update) “But They Need Hierarchical Keys”</h4>



<p>After I initially posted this, Redditor Steve132 informed me that <a href="https://www.reddit.com/r/crypto/comments/hnlyp1/gnu_a_heuristic_for_bad_cryptography/fxdbez4/">I overlooked the reason they made this design decision</a>.</p>



<blockquote><p>Take a look at Section 6.1&nbsp;<a rel="noreferrer noopener" href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion" target="_blank">https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion</a></p><blockquote><p>From here, the following steps are recursively executed, in order: Extract the right-most label from the name to look up. Calculate q using the label and zk as defined in Section 4.1.</p></blockquote><p>So then if you go to section 4.1, they do h=H(&lt;address string&gt;), (r,R) is some root keypair, then they do C (a child public key), C=hR, then q=H(C).</p><p>the idea behind the calculation of q is to use the root public key to derive a child public key from ONLY the root public key, exploiting the linearity property that in elliptic curves, if bG=B, then (b+s)G=(sG+B)</p><p>This allows a third party to derive child public keys without any knowledge of the private keys for the root. This technique is also used in bitcoin’s bip32 (<a rel="noreferrer noopener" href="https://en.bitcoin.it/wiki/BIP_0032" target="_blank">https://en.bitcoin.it/wiki/BIP_0032</a>) for ‘unhardened’ derivation scheme.</p><cite>Part of Steve132’s correction</cite></blockquote>



<p>I fully admit, I didn’t absorb this detail in my first pass of the RFC draft. It wasn’t clearly spelled out in Section 9 (which aims to justify their cryptography decisions), and I didn’t read the other sections as carefully. This was my mistake.</p>



<p>However, even with this explanation in mind, my original point that this design choice is both unconventional and unnecessary still stands, because <a href="https://ieeexplore.ieee.org/abstract/document/7966967?section=abstract">BIP32-Ed25519</a> already exists (albeit, it still needs <a href="https://forum.web3.foundation/t/key-recovery-attack-on-bip32-ed25519/44">a carefully designed implementation</a> to be secure against active attackers). </p>



<p>Therefore, the GNU Name System developers didn’t need to roll their own design, they could have used one that’s already seen real-world deployment instead. Why take on unnecessary risk?</p>



<p>Furthermore, trying to push through an implementation of ECDSA over edwards25519 isn’t just unnecessary and weird, it’s also probably dangerous, as Thai Duong noted:</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">While I don't agree that ECDSA is worse than Ed25519 – both have pros and cons — it takes courage to implement ECDSA over Edward25519. Do you know if they published any code?  This unfortunate marriage may introduce fun and unique bugs</p>— thaidn (@XorNinja) <a href="https://twitter.com/XorNinja/status/1281041946538938368?ref_src=twsrc%5Etfw">July 9, 2020</a></blockquote></div>
</div><figcaption>Thai Duong–author of the BEAST attack against SSL/TLS, among <a href="https://github.com/google/tink">other</a> <a href="https://github.com/google/wycheproof">things</a></figcaption></figure>



<p>Of course, all cryptography development can be said to be dangerous, but there are other problems fundamental to the GNU Name System design that makes any departure from a well-tread path very suspect.</p>



<h3>Symmetric Cryptography</h3>



<p>The GNU Name System project doesn’t stop there. It further throws <a href="https://tonyarcieri.com/all-the-crypto-code-youve-ever-written-is-probably-broken">IND-CCA2 security</a> out the window and specifies encrypting with AES and TwoFish in a cipher cascade, using Cipher Feedback (CFB) mode.</p>



<p>The authors do not even attempt to defend this decision. Typically this happens when the authors do not understand the risks involved. I sincerely doubt they’ve heard the words “adaptive chosen-ciphertext attack” in the course of their self-study.</p>



<p>(Because, y’know, attackers will surely never be able to replay UDP traffic if a runtime exception occurs because of corrupted data.)</p>



<h4>“Why Is This Bad?”</h4>



<p>Cipher cascades are usually the result of “we want to defend against a backdoored or broken cipher”. Bear in mind, the cipher itself is rarely the first part of a cryptosystem to be broken.</p>



<p>On that note, TwoFish isn’t <a href="https://blog.cryptographyengineering.com/2012/10/09/so-you-want-to-use-alternative-cipher/">the worst choice</a> of a cascade partner for AES, but I’d prefer a design that employed a different paradigm (since AES is a SPN permutation block cipher, an ARX-based stream cipher like Salsa20 or ChaCha seems reasonable).</p>



<p>AES is a boring choice, because it’s the industry standard. I’m not <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">particularly fond of AES</a> (due to it not being fast and constant-time in pure software implementations), but if you use it in an authenticated mode (AES-GCM, AES-CCM, AES-EAX, AES-OCB3, … I dunno, Poly1305-AES? Just use an AEAD mode!), it’s fine.</p>



<p><strong>Cipher Feedback (CFB) mode is not an authenticated mode.</strong></p>



<p>If you’re publishing a cryptography design in 2020 that fails the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>, you need to go back to the drawing board.</p>



<h4>“But They Use Digital Signatures”</h4>



<p><a href="https://blog.cryptographyengineering.com/2016/03/21/attack-of-week-apple-imessage/">Cough.</a></p>







<h2>Other GNU Projects</h2>



<p>If you want to learn about why GnuPG (and the PGP ecosystem in general) is terrible, I recommend <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">Latacora’s takedown</a>.</p>



<p>GnuTLS is an SSL/TLS library created by the same people who created (and then abandoned) libmcrypt, which was the scourge of <a href="https://meta.stackoverflow.com/questions/293930/problematic-php-cryptography-advice-in-popular-questions">bad cryptography in the PHP ecosystem</a> for many years (until it was <a href="https://wiki.php.net/rfc/mcrypt-viking-funeral">finally excised in PHP 7.2</a>). Consequently, the project’s <a href="https://www.gnutls.org/security-new.html">CVE history</a> should be no surprise.</p>



<p><strong>Quick story:</strong> Many years ago, a few timing attacks were discovered in libgcrypt by regular chatters in Freenode’s ##crypto channel. This led a lot of us <a href="https://lists.gnupg.org/pipermail/gcrypt-devel/2015-November/003618.html">to look at libgcrypt for more bugs</a>.</p>



<p>The general consensus of the ensuing IRC discussion was, roughly, “We probably shouldn’t try to fix them all, because a) that’s way too much effort because there’s too much badness and b) this library will be a ripe target for upcoming cryptanalysis researchers to get their first papers published for many years”. And, indeed, the attack papers that have come out over the years that affect libgcrypt <a href="https://eprint.iacr.org/2020/432">haven’t disappointed</a>.</p>



<p>To be clear, at the time this happened, I was garbage at writing C (and somehow even less confident than capable) and barely making ends meet, so “drop everything and volunteer to fix all the libgcrypt badness” wasn’t a tenable option for me. And since the world is largely moving away from GnuPG and libgcrypt, it honestly isn’t worth the effort trying to fix all the bad when an easier fix is “use something good instead”.</p>



<h2>Takeaway</h2>



<p>If you see the letters GNU anywhere in a project that intersects with cryptography–except for its public license–it’s almost certainly an error-prone cryptographic design.</p>



<p>Or, as my friend Kye calls it:</p>



<figure><div>

</div><figcaption>The Dunning-GNUger Effect.</figcaption></figure>



<h2>What To Use Instead?</h2>



<p>To replace GPG, you want <a href="https://age-encryption.org/">age</a> and <a href="https://jedisct1.github.io/minisign/">minisign</a>.</p>



<p>To replace GnuTLS or libgcrypt, depending on what you’re using it for, you want one of the following: s2n, OpenSSL/LibreSSL, or Libsodium.</p>



<p>For embedded systems, BearSSL is a good options today and <a href="https://www.reddit.com/r/crypto/comments/hdc4o6/new_results_on_gimli_fullpermutation/fvmpnym/">libhydrogen v2</a> will be an attractive choice when it’s released.</p>



<hr>



<p>Header image, like the GnuNet logo <a href="https://commons.wikimedia.org/wiki/File:Official_logo_of_the_GNUnet_project.svg">found here</a>, is available under the&nbsp;<a href="https://en.wikipedia.org/wiki/en:Creative_Commons">Creative Commons</a>&nbsp;<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">Attribution-Share Alike 4.0 International</a>&nbsp;license.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819964</guid>
            <pubDate>Mon, 13 Jul 2020 12:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Douglas Mason: How to Build ML Solutions for Twitter, Pinterest and Amazon Music]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819921">thread link</a>) | @FHMS
<br/>
July 13, 2020 | https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We caught up with <a href="https://www.linkedin.com/in/douglas-mason-9a500713/"><strong>Douglas Mason</strong></a>, data scientist and CEO of <a href="https://www.koyotescience.com/">Koyote Science</a>, where he is building machine learning models to predict COVID-19 outbreaks. He freely shared his wisdom and lessons he has learned from over a decade of data science work, ranging from his PhD at Harvard to his time at large companies such as Pinterest, Twitter, and AWS (Amazon).</p><h2><strong>Douglas’s background</strong></h2><p>Douglas took a unique path to becoming a data scientist. Although computers were always part of his household growing up, he thought they were boring, and he told his family he would “never study computer science.”</p><p>Instead, Douglas went to USC to study filmmaking, thinking he’d follow his dream of becoming a film director. Soon, he realized that filmmaking school wasn’t all he’d imagined it would be, and he took up classical guitar instead. From there, he accidentally discovered a passion for theoretical physics, which he found fascinating (and which paid more than guitar playing).</p><p>Not long after, Douglas discovered his interest in data science and climbed the ranks until he was heading engineering and data science teams at Twitter, Pinterest, and AWS. He describes working in the field as feeling like he’s living in a science fiction film.</p><blockquote>“When I work on that kind of stuff, I feel like Doctor Strange — as if I’m in the Multiverse. You actually get to live this Rick and Morty parallel-universe life.”</blockquote><p>But Douglas wasn’t content with using his expertise to improve revenue at large corporations, so he went on to found his own business, Koyote Science. He’s currently focused on building COVID-19 models to predict outbreaks.</p><h2><strong>Lessons learned from shipping machine learning projects</strong></h2><p>Douglas’s success hasn’t come without some hard-earned lessons. He told us about some of the challenges he’s seen across many of the teams and projects he’s worked on.</p><h3><strong>Lesson 1: Use machine learning to work with users instead of taking over&nbsp;</strong></h3><p>At Twitter, Douglas worked on a feature called “who to follow.” This gives Twitter users personalized recommendations about which accounts might be interesting for them. As a data scientist, Douglas discovered that people used this feature a lot. At first, it seemed great — people were following nearly everyone it recommended. But in the longer term, people who used this feature <strong>visited Twitter less</strong>.&nbsp;</p><p>Their feeds were filled with tweets chosen <strong>by an algorithm</strong>, rather than tweets from people they chose<strong> </strong>themselves — and there were just too many of them.</p><p>By reducing<strong> </strong>the number of “who to follow” recommendations, Douglas improved <strong>long-term</strong> engagement.</p><p>It’s common knowledge that long-term and short-term goals often conflict, but Douglas discovered a deeper lesson here. As machine learning solutions become more capable, it’s often tempting to use them to do too much. This is almost always a mistake. Douglas says:</p><blockquote>“I aim to build products that work with the user rather than trying to take over from the user.”</blockquote><p>AI as depicted in science fiction — with human-level intelligence — is probably to blame for the fact that many people try to <strong>do too much </strong>with machine learning. In many cases, it’s best used to <strong>augment </strong>human actions rather than replace them.</p><h3><strong>Lesson 2: Data pipelines and good engineering are more important than math and algorithms</strong></h3><p>People get very excited about <strong>new machine learning algorithms</strong>. First we had neural networks (NNs), then convolutional neural networks (CNNs), then generative adversarial networks (GANs), transformers, and more. Algorithms are fun and exciting to talk about and explore.</p><p>But Douglas, a self-confessed math nerd, has learned that the math and algorithms tend to get far too much attention, while real success comes from <strong>good data, good engineering, focusing on the customer’s problem, </strong>and <strong>not getting trapped in the math.</strong> He says:</p><blockquote>“It's very, very rare for the algorithm to make the difference. It's almost always the data pipeline. In my work, I have been able to reduce errors by 90% with a data pipeline, compared to 75% with a better algorithm. And yet everyone wants to talk to me about the algorithm, but no one wants to talk about the data pipeline.”</blockquote><p>We use metaphors that associate machine learning algorithms with neuroscientists and data pipelines with plumbing, so it’s not surprising which one grabs popular attention. Douglas found success by focusing on the less glamorous aspects of machine learning. In most cases, deciding <strong>what data to use </strong>and <strong>how to present it to the algorithm</strong> is more important than the algorithm itself.</p><h4>Focus on the customer’s goals</h4><p>Many “AI startups” today talk far more about <strong>the solutions they provide</strong> than the <strong>problems they solve</strong>, and Douglas has learned to maintain a laser focus on customer goals. Sometimes this means pulling himself away from the more enticing theoretical aspects of machine learning. He says:&nbsp;</p><blockquote>“As a mathematician, I love all the nuances of the math, and easily get lost in it. But the reality is that there's an infinite amount of math out there to learn. It's not feasible to lock myself in my room and learn all the math before I focus on customer goals.”</blockquote><p>The truth that many data scientists don’t want to hear is that successful machine learning solutions are not usually about creating something new, powerful, and exciting. More often, seeing problems from the correct angle and using tried and tested approaches is what you need.</p><h4>Work with and learn from experienced engineers</h4><p>Douglas has personally engineered many successful machine learning solutions and led teams of software engineers, but he remains modest about his engineering ability and emphasizes the <a href="https://datarevenue.com/en-blog/hiring-machine-learning-engineers-instead-of-data-scientists">importance of <strong>solid engineering</strong></a>.</p><blockquote>“At Amazon, I let the engineers do as much as possible, because they're better than me at engineering. I would love to give you another answer, but they're efficient, they're thoughtful, they've seen these structures before, so they know about implementation details.”</blockquote><p>It’s not all smooth sailing though. Douglas acknowledges the difficulties of getting different experts to work with each other, especially when highly technical people tend to have very strong opinions about tiny decisions.</p><p>The best way he’s found to get everyone on the same page is by constantly releasing Minimal Viable Products (MVPs), which takes us to our next lesson.</p><h3><strong>Lesson 3: Always build Minimum Viable Products (MVPs)</strong></h3><p>Douglas swears by MVPs, which demonstrate core pieces of a solution, even if many of the features are missing. When developing a machine learning solution, he’ll aim to deliver a new MVP <strong>every week.</strong></p><p>He uses these to:&nbsp;</p><ul role="list"><li><strong>Avoid traps: </strong>If a project is taking too long, the difficulty of building even an MVP can be used to argue that the project should be cut early, before years of effort are wasted. Douglas says:</li></ul><p>“If something ends up being way harder and I keep doing MVPs and never reach the goals, then that gives us information about the difficulty of what we're attempting to do.”</p><ul role="list"><li><strong>Communicate</strong>: Both technical and non-technical people tend to better understand things they can see and use, rather than abstract ideas.</li></ul><p>“People's response to an abstract concept of something is often completely different to their response when they see something real. That's why I'm always putting out MVPs. People who are looking from a higher-level perspective can gain the required intuition to give me feedback.”</p><p>It’s better to have to trash two weeks of work than two months, and MVPs can help with this.</p><p>MVPs have other benefits too. By releasing stripped-down versions of a solution, Douglas often discovers that less is more.</p><blockquote>“What you end up delivering is often much simpler than the thing you originally intended to do, but it's refined.”</blockquote><p>Of course, customers are sometimes unhappy when it turns out that the best solution was the simplest one. Douglas compares building machine learning solutions to creating art: it’s about the time that went into development, not the effort required for the final product.</p><blockquote>“There’s a classic Zen story about a king who hires an artist. The artist works for a year, but then paints the final painting in only three seconds. When the king complains, the artist says, ‘Oh, I spent a year trying to paint much harder things.’”</blockquote><p>MVPs keep you open to finding a <strong>better, simpler </strong>solution, even late in the development process, and it’s important to stay agile so you can pivot to these better solutions if necessary.</p><p>People often think something has to be <strong>complicated </strong>in order to be <strong>powerful</strong>,<strong> </strong>but in fact the opposite is often true.</p><h3><strong>Lesson 4: Control and precision are more important than size and power</strong></h3><p>Large machine learning models, such as GPT-3, are exciting and often make their way into headline news. But Douglas compares large models to early (failed) attempts to build planes. These planes competed against the famous, successful plane built by the Wright Brothers. What made them different? The Wright Brothers focused on <strong>control</strong>,<strong> </strong>while their competitors were going for <strong>size and power.</strong></p><blockquote>“What the Wright brothers did that was so ingenious was that they didn’t go for bigger engines. They were bicycle mechanics. They didn't even use powerful engines. And instead, what they focused on was control.”</blockquote><p>This is similar to machine learning models. As Douglas says:&nbsp;</p><blockquote>“We made the biggest model that does all this stuff. But then people ask, ‘How do I interpret this stuff?’ ‘How do I control it?’ ‘How do I make sure that my models don't go off the rails?’”</blockquote><p>Large machine learning models might often be more powerful, but unless they solve real problems, they’re not useful. If a model produces amazing results <strong>unpredictably</strong> and only <strong>some of the time</strong>, that’s not useful. If a model produces accurate results but we don’t <strong>understand why</strong> and can’t be sure the results will <strong>always be accurate</strong>, then that’s also not useful.</p><p>Instead, smaller, simpler, and arguably less powerful models that offer more <strong>interpretability</strong> and <strong>consistency</strong> are more valuable in nearly every case. Just like with flying, we need to be able to steer and to land, not just to go fast.</p><h2><strong>Shipping machine learning projects …</strong></h2></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819921</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a Data Delivery Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819918">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/data-delivery-network | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/data-delivery-network">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#how-content-delivery-networks-work" as="#how-content-delivery-networks-work">How content delivery networks work</a></li><li><a href="#why-do-you-need-a-backend-anyway" as="#why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</a><ol><li><a href="#alternatives-to-crud-services" as="#alternatives-to-crud-services">Alternatives to CRUD services</a></li><li><a href="#splitgraphs-architecture" as="#splitgraphs-architecture">Splitgraph's architecture</a></li></ol></li><li><a href="#data-delivery-network" as="#data-delivery-network">Data delivery network</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p>Serverless and edge computing have allowed application developers to bring their applications closer to the end user.</p><p>Instead of maintaining a group of servers in a single location, developers can let companies like Cloudflare, Fastly or Akamai handle their content delivery.</p><p>With <a href="https://en.wikipedia.org/wiki/Function_as_a_service" as="https://en.wikipedia.org/wiki/Function_as_a_service">Function as a service</a>, companies pay for what they use. They can avoid having to provision a server that stays idle most of the time.</p><p>In this article, we want to talk about these trends and how we can apply them to databases. We'll also talk about our decision to make the API for our Splitgraph registry work over a public SQL connection. We'll use this experience to propose the idea of a <strong>data delivery network</strong>.</p><section><h2 id="how-content-delivery-networks-work">How content delivery networks work</h2><p>Content delivery networks provide a straightforward way to scale a read-only HTTP layer. They use existing HTTP cache semantics like the Cache-Control header. The developer only needs to point their DNS records to use the CDN's nameservers. The CDN handles everything else for them. It has points of presence around the world and peering agreements with other ISPs. It can selectively cache data, handle DDoS protection and offer extra services on top.</p><p>The value proposition behind edge computing is simple. For a lot of companies, scaling compute is not their core competency. They can spend time and money provisioning servers and configuring something like Varnish. Or, they can use services that will handle scaling and caching for them.</p><p>However, applications still need to run SQL queries. A CDN doesn't completely help an application that performs client-side rendering. The database becomes the next performance bottleneck in scaling a service.</p><p>There are many ways to scale a database, for example, replication or sharding. But again, this requires specialist knowledge about a database that is easy to get wrong.</p></section><section><h2 id="why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</h2><p>Let's change gears and consider a classic Web application. It consists of the frontend, the backend and the database.</p><p>There are several purposes that a backend serves:</p><ul><li><p><strong>Business logic</strong>. The backend converts higher level API calls into low-level SQL queries. It prepares data for presentation and writes it back when needed.</p></li><li><p><strong>Authorization</strong>. The backend acts as a security barrier, validating API calls. This is necessary because the frontend is running on the user's machine: the client is not trusted.</p></li><li><p><strong>Multiplexing</strong>. A database connection has a larger overhead than an HTTP connection. A backend can shunt hundreds of simultaneous clients over to a few database connections.</p></li></ul><section><h3 id="alternatives-to-crud-services">Alternatives to CRUD services</h3><p>One big issue with writing RESTful backends is that there's a lot of boilerplate. The programmer has to write very similar code to handle every action. They have to care of validation, typechecking and handling edge cases.</p><p>Libraries like <a href="https://postgrest.org/en/latest/" as="https://postgrest.org/en/latest/">PostgREST</a> and <a href="https://www.graphile.org/postgraphile/" as="https://www.graphile.org/postgraphile/">Postgraphile</a> have helped developers decrease iteration times. They introspect database schemas and generate REST and GraphQL APIs for them.</p><p>PostgREST and Postgraphile perform their authorization using database methods like <a href="https://postgrest.org/en/v7.0.0/auth.html" as="https://postgrest.org/en/v7.0.0/auth.html">row level security</a>. In essence, they decrease the size of the <a href="https://en.wikipedia.org/wiki/Trusted_computing_base" as="https://en.wikipedia.org/wiki/Trusted_computing_base">"trusted computing base"</a>.</p><p>Often, services that use these kinds of tools don't even have a separate backend. Client side code can call the automatically generated GraphQL/REST API directly.</p></section><section><h3 id="splitgraphs-architecture">Splitgraph's architecture</h3><p>The database can perform a lot of work that the backend does more quickly and more efficiently.</p><p>We use this idea in the API for the Splitgraph registry that allows you to push and pull <a href="https://www.splitgraph.com/docs/concepts/images">data images</a>. A <a href="https://www.splitgraph.com/docs/architecture/sgr-client">Splitgraph client</a> can access it over a normal PostgreSQL connection to <code>postgresql://data.splitgraph.com:5432/sgregistry</code>.</p><p>Our API implements all <strong>business logic</strong> as PostgreSQL functions. This has a few immediate advantages:</p><ul><li>Lets PostgreSQL precompile them</li><li>Avoids an extra hop from the backend, decreasing latency</li><li>Makes basic validation and type checking trivial. It's not possible to call a function with a wrong number of arguments or different types.</li></ul><p>For more complex logic, we wrote it in higher-level languages like <a href="https://www.postgresql.org/docs/current/plpython.html" as="https://www.postgresql.org/docs/current/plpython.html">PL/Python</a> or PL/Lua. PostgreSQL even supports languages like C or JavaScript.</p><p>We solved the problem of <strong>multiplexing and authorization</strong> by adding <a href="https://www.pgbouncer.org/" as="https://www.pgbouncer.org/">PgBouncer</a>, a connection pooler, in front of our database. Our fork of PgBouncer injects a signed cookie into every transaction as a local variable. Downstream procedures validate this cookie for authentication and authorization. This lets us decouple PostgreSQL users from application users. Multiple inbound sessions can use the same connection.</p><p>Our fork of PgBouncer even inspects queries on the fly and filters them. This makes sure that the client can only call Splitgraph SQL API functions.</p><p>For the web frontend at <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com/">www.splitgraph.com</a>, we use Postgraphile. Besides not having to write an extra API server, it lets us generate TypeScript client code.</p></section></section><section><h2 id="data-delivery-network">Data delivery network</h2><p>We can apply these ideas and concepts to the problem of building a <strong>"data delivery network"</strong>. Such a network would completely abstract away all the issues around making sure that data is available at the edge. It can also provide plenty of other useful services.</p><p>Here's a quick sketch of what a DDN's administration interface would look like:</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200713-data-delivery-network/admin-panel.png"></p><p>To use a DDN, a developer would create a read-only account on their database and give the DDN the credentials. It will then make a few services available:</p><p>The DDN will create an <strong>SQL endpoint</strong>. Any existing SQL client or application will be able to connect to it and run queries.</p><p>Besides SQL, the DDN will also be able to introspect the origin database and provide <strong>REST and GraphQL API endpoints</strong>. A client, running in the user's web browser, can use these endpoints instead of a backend server.</p><p>The DDN will be able to <strong>cache</strong> read-only SQL transactions with configurable policies. It will only forward the query to the origin database if there's a cache miss or expiry.</p><p>The client code doesn't need to be trusted. The DDN can intercept and <strong>firewall</strong> queries or <strong>rate limit</strong> them. To simplify migrations, the DDN can <strong>rewrite</strong> queries on the fly before forwarding them.</p><p>The DDN's work doesn't need to stop at handling queries. It can also manage <strong>data imports and exports</strong>. For example, it can make data from other services available to clients. Or, it can export data to Google Sheets or a data warehouse.</p><p>In the case of Splitgraph, we envision you being able to even run a <code>JOIN</code> across a public Splitgraph image and your private data.</p></section><section><h2 id="conclusion">Conclusion</h2><p>The database is the next frontier of serverless and edge computing. One of Splitgraph's goals is building a data delivery network to handle these problems.</p><p>If you're interested in learning more about Splitgraph, you can check our <a href="https://www.splitgraph.com/docs/getting-started/frequently-asked-questions">frequently asked questions</a> section, follow our <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">quick start guide</a> or visit our <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">website</a>.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/data-delivery-network</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819918</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp GUI Toolkits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819896">thread link</a>) | @ogogmad
<br/>
July 13, 2020 | https://lispcookbook.github.io/cl-cookbook/gui.html | <a href="https://web.archive.org/web/*/https://lispcookbook.github.io/cl-cookbook/gui.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" <p=""><p>Lisp has a long and rich history and so does the development of
Graphical User Interfaces in Lisp. In fact, the first GUI builder was
written in Lisp (and sold to Apple. It is now Interface Builder).</p>

<p>Lisp is also famous and unrivalled for its interactive development
capabilities, a feature even more worth having to develop GUI
applications. Can you imagine compiling one function and seeing your
GUI update instantly? We can do this with many GUI frameworks today,
even though the details differ from one to another.</p>

<p>Finally, a key part in building software is how to build it and ship
it to users. Here also, we can build self-contained binaries, for
the three main operating systems, that users can run with a double
click.</p>

<p>We aim here to give you the relevant information to help you choose
the right GUI framework and to put you on tracks. Don’t hesitate to
<a href="https://github.com/LispCookbook/cl-cookbook/issues/">contribute</a>, to
send more examples and to furnish the upstream documentations.</p>



<p>In this recipe, we’ll present the following GUI toolkits:</p>

<ul>
  <li><a href="https://www.tcl.tk/">Tk</a> with <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a></li>
  <li><a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a> with <a href="https://github.com/Shinmera/qtools">Qtools</a></li>
  <li><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> with <a href="https://github.com/lispnik/iup/">lispnik/iup</a></li>
  <li><a href="https://www.gtk.org/">Gtk3</a> with <a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a></li>
  <li><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> with <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a></li>
</ul>

<p>In addition, you might want to have a look to:</p>

<ul>
  <li>the <a href="http://www.lispworks.com/products/capi.html">CAPI</a> toolkit (Common Application Programming Interface),
which is proprietary and made by LispWorks. It is a complete and cross-platform
toolkit (Windows, Gtk+, Cocoa), very praised by its users. LispWorks
also has <a href="http://www.lispworks.com/products/lw4mr.html">iOS and Android
runtimes</a>. Example
software built with CAPI include <a href="https://scorecloud.com/">ScoreCloud</a>. It is possible to
try it with the LispWorks free demo.</li>
  <li><a href="https://franz.com/products/allegro-common-lisp/acl_ide.lhtml">Allegro CL’s IDE and Common Graphics windowing system</a> (proprietary): Allegro’s IDE is a general environment for developing applications. It works in concert with a windowing system called Common Graphics. The IDE is available for Allegro CL’s Microsoft Windows, on x86 Linux platforms, and on the Mac.</li>
  <li><a href="https://ccl.clozure.com/docs/ccl.html#the-objective-c-bridge">CCL’s built-in Cocoa
interface</a>,
used to build applications such as <a href="https://opusmodus.com/">Opusmodus</a>.</li>
  <li><a href="https://github.com/plkrueger/CocoaInterface/">CocoaInterface</a>, a
Cocoa interface for Clozure Common Lisp. Build Cocoa user interface
windows dynamically using Lisp code and bypass the typical Xcode
processes.</li>
  <li><a href="https://common-lisp.net/project/mcclim/">McCLIM</a> and <a href="https://github.com/earl-ducaine/cl-garnet">Garnet</a> are toolkit in 100% Common Lisp. McClim even has <a href="https://techfak.de/~jmoringe/mcclim-broadway-7.ogv">a prototype</a> running in the browser with the Broadway protocol and Garnet has an ongoing interface to Gtk.</li>
  <li><a href="https://github.com/Shirakumo/alloy">Alloy</a>, another very new toolkit in 100% Common Lisp, used for example in the <a href="https://github.com/shinmera/kandria">Kandria</a> game.</li>
  <li><a href="https://notabug.org/cage/nodgui">nodgui</a>, a fork of Ltk, with syntax sugar and additional widgets.</li>
  <li><a href="https://gitlab.com/eql">eql, eql5, eql5-android</a>, embedded Qt4 and Qt5 Lisp, embedded in ECL, embeddable in Qt. Port of EQL5 to the Android platform.</li>
  <li>this <a href="https://github.com/defunkydrummer/abcl-jazz">demo using Java Swing from ABCL</a></li>
  <li><a href="https://github.com/mifpasoti/Gtk-Demos">examples of using Gtk without C files with SBCL</a>, as well as GTK-server.</li>
  <li>and, last but not least, <a href="http://ceramic.github.io/">Ceramic</a>, to ship a cross-platform web app with Electron.</li>
</ul>

<p>as well as the other ones listed on <a href="https://github.com/CodyReichert/awesome-cl#Gui">awesome-cl#gui</a> and <a href="https://www.cliki.net/GUI">Cliki</a>.</p>

<h2 id="tk-ltk">Tk (Ltk)</h2>

<p><a href="https://www.tcl.tk/">Tk</a> (or Tcl/Tk, where Tcl is the programming language) has the
infamous reputation of having an outdated look. This is not (so) true
anymore since its version 8 of 1997 (!). It is probably better than
you think:</p>

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/gui/ltk-on-macos.png" alt=""></p>

<p>Tk doesn’t have a great choice of widgets, but it has a useful canvas,
and it has a couple of unique features: we can develop a graphical
interface <strong>fully interactively</strong> and we can run the GUI <strong>remotely</strong>
from the core app.</p>

<p>So, Tk isn’t fancy, but it is an used and proven GUI toolkit (and
programming language) still used in the industry. It can be a great
choice to quickly create simple GUIs, to leverage its ease of deployment, or
when stability is required.</p>

<p>The Lisp binding is <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a>.</p>

<ul>
  <li><strong>Written in</strong>: Tcl</li>
  <li>
    <p><strong>Portability</strong>: cross-platform (Windows, macOS, Linux).</p>
  </li>
  <li>
    <p><strong>Widgets</strong>: this is not the fort of Tk. It has a <strong>small set</strong> of
default widgets, and misses important ones, for example a calendar. We
can find some in extensions (such as in <strong>Nodgui</strong>), but they don’t
feel native, at all.</p>
  </li>
  <li>
    <p><strong>Interactive development</strong>: very much.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no</p>
  </li>
  <li><strong>Other features</strong>:
    <ul>
      <li><strong>remote execution</strong>: the connection between Lisp and Tcl/Tk is
done via a stream. It is thus possible to run the Lisp program on
one computer, and to display the GUI on another one. The only
thing required on the client computer is tcl/tk installed and the
remote.tcl script. See <a href="http://www.peter-herth.de/ltk/ltkdoc/node46.html">Ltk-remote</a>.</li>
    </ul>
  </li>
  <li><strong>Bindings documentation</strong>: short but complete. Nodgui too.</li>
  <li><strong>Bindings stability</strong>: very stable</li>
  <li><strong>Bindings activity</strong>: low to non-existent.</li>
  <li><strong>Licence</strong>: Tcl/Tk is BSD-style, Ltk is LGPL.</li>
  <li>Example applications:
    <ul>
      <li><a href="https://notabug.org/cage/fulci/">Fulci</a> - a program to organise your movie collections.</li>
      <li><a href="https://github.com/mijohnson99/ltk-small-games">Ltk small games</a> - snake and tic-tac-toe.</li>
      <li><a href="https://github.com/vindarel/cl-torrents">cl-torrents</a> - searching torrents on popular trackers. CLI, readline and a simple Tk GUI.</li>
    </ul>
  </li>
</ul>

<p><strong>List of widgets</strong></p>

<p>(please don’t suppose the list is exhaustive)</p>

<pre><code>Button Canvas Check-button Entry Frame Label Labelframe Listbox
Menu Menubutton Message
Paned-window
Radio-button Scale
Scrollbar Spinbox Text
Toplevel Widget Canvas

Ltk-megawidgets:
    progress
    history-entry
    menu-entry
</code></pre>

<p>Nodgui adds:</p>

<pre><code>treelist tooltip searchable-listbox date-picker calendar autocomplete-listbox
password-entry progress-bar-star notify-window
dot-plot bar-chart equalizer-bar
swap-list
</code></pre>



<p>Do we need to present Qt and <a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a>? Qt is huge and contains
everything and the kitchen sink. Qt not only provides UI widgets, but
numerous other layers (networking, D-BUS…).</p>

<p>Qt is free for open-source software, however you’ll want to check the
conditions to ship proprietary ones.</p>

<p>The <a href="https://github.com/Shinmera/qtools">Qtools</a> bindings target Qt4. The Qt5 Lisp bindings are
yet to be created.</p>

<p>A companion library for Qtools, that you’ll want to check out once you
made your first Qtool application, is
<a href="https://github.com/Shinmera/qtools-ui">Qtools-ui</a>, a collection of
useful widgets and pre-made components. It comes with short
<a href="https://www.youtube.com/playlist?list=PLkDl6Irujx9Mh3BWdBmt4JtIrwYgihTWp">demonstrations
videos</a>.</p>

<!-- possible future: gobject-introspection -->

<ul>
  <li><strong>Framework written in</strong>: C++</li>
  <li><strong>Framework Portability</strong>: multi-platform, Android, embedded systems, WASM.</li>
  <li>
    <p><strong>Bindings Portability</strong>: Qtools runs on x86 desktop platforms on Windows, macOS and GNU/Linux.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: Web browser, a lot more.</p>
  </li>
  <li><strong>Bindings documentation</strong>: lengthy explanations, a few examples. Prior Qt knowledge is required.</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: active</li>
  <li><strong>Qt Licence</strong>: both commercial and open source licences.</li>
  <li>Example applications:
    <ul>
      <li>https://github.com/Shinmera/qtools/tree/master/examples</li>
      <li>https://github.com/Shirakumo/lionchat</li>
      <li>https://github.com/shinmera/halftone - a simple image viewer</li>
    </ul>
  </li>
</ul>

<h2 id="gtk3-cl-cffi-gtk">Gtk+3 (cl-cffi-gtk)</h2>

<p><a href="https://www.gtk.org/">Gtk+3</a> is the primary library used to build <a href="https://www.gnome.org/">GNOME</a>
applications. Its (currently most advanced) lisp bindings is
<a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a>. While primarily created for GNU/Linux, Gtk
works fine under macOS and can now also be used on Windows.</p>

<ul>
  <li><strong>Framework written in</strong>: C</li>
  <li>
    <p><strong>Portability</strong>: GNU/Linux and macOS, also Windows.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li><strong>Graphical builder</strong>: yes: Glade.</li>
  <li>
    <p><strong>Other features</strong>: web browser (WebKitGTK)</p>
  </li>
  <li><strong>Bindings documentation</strong>: very good: http://www.crategus.com/books/cl-gtk/gtk-tutorial.html</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: low activity, active development.</li>
  <li><strong>Licence</strong>: LGPL</li>
  <li>Example applications:
    <ul>
      <li>an <a href="https://github.com/ralph-schleicher/atmosphere-calculator">Atmosphere Calculator</a>, built with Glade.</li>
    </ul>
  </li>
</ul>

<h2 id="iup-lispnikiup">IUP (lispnik/IUP)</h2>

<p><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> is a cross-platform GUI toolkit actively developed
at the PUC university of Rio de Janeiro, Brazil. It uses <strong>native
controls</strong>: the Windows API for Windows, Gtk3 for GNU/Linux. At the
time of writing, it has a Cocoa port in the works (as well as iOS,
Android and WASM ones). A particularity of IUP is its <strong>small API</strong>.</p>

<p>The Lisp bindings are <a href="https://github.com/lispnik/iup/">lispnik/iup</a>. They are nicely
done in that they are automatically generated from the C sources. They
can follow new IUP versions with a minimal work and the required steps
are documented. All this gives us good guarantee over the bus
factor.</p>

<p>IUP stands as a great solution in between Tk and Gtk or Qt.</p>

<ul>
  <li><strong>Framework written in</strong>: C (official API also in Lua and LED)</li>
  <li>
    <p><strong>Portability</strong>: Windows and Linux, work started for
Cocoa, iOS, Android, WASM.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: medium.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes: <a href="http://webserver2.tecgraf.puc-rio.br/iup/en/iupvisualled.html">IupVisualLED</a></p>
  </li>
  <li>
    <p><strong>Other features</strong>: OpenGL, Web browser (WebKitGTK on GNU/Linux), plotting, Scintilla text editor</p>
  </li>
  <li><strong>Bindings documentation</strong>: good examples and good readme, otherwise low.</li>
  <li><strong>Bindings stability</strong>: alpha (but fully generated and working nicely).</li>
  <li><strong>Bindings activity</strong>: low but steady, and reactive to new IUP versions.</li>
  <li><strong>Licence</strong>: IUP and the bindings are MIT licenced.</li>
</ul>

<p><strong>List of widgets</strong></p>

<pre><code>Radio, Tabs, FlatTabs, ScrollBox, DetachBox,
Button, FlatButton, DropButton, Calendar, Canvas, Colorbar, ColorBrowser, DatePick, Dial, Gauge, Label, FlatLabel,
FlatSeparator, Link, List, FlatList, ProgressBar, Spin, Text, Toggle, Tree, Val,
listDialog, Alarm, Color, Message, Font, Scintilla, file-dialog…
Cells, Matrix, MatrixEx, MatrixList,
GLCanvas, Plot, MglPlot, OleControl, WebBrowser (WebKit/Gtk+)…
drag-and-drop
</code></pre>

<!-- editor's note: found missing a list view with columns. -->

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/iup-demo.png" alt=""></p>

<h2 id="nuklear-bodge-nuklear">Nuklear (Bodge-Nuklear)</h2>

<p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a small <a href="https://en.wikipedia.org/wiki/Immediate_mode_GUI">immediate-mode</a> GUI toolkit:</p>

<blockquote>
  <p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a minimal-state, immediate-mode graphical user interface toolkit written in ANSI C and licensed under public domain. It was designed as a simple embeddable user interface for application and does not have any dependencies, a default render backend or OS window/input handling but instead provides a highly modular, library-based approach, with simple input state for input and draw commands describing primitive shapes as output. So instead of providing a layered library that tries to abstract over a number of platform and render backends, it focuses only on the actual UI.</p>
</blockquote>

<p>its Lisp binding is <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a>, and its higher level companions <a href="https://github.com/borodust/bodge-ui">bodge-ui</a> and <a href="https://github.com/borodust/bodge-ui-window">bodge-ui-window</a>.</p>

<p>Unlike traditional UI frameworks, Nuklear allows the developer to take
over the rendering loop or the input management. This might require
more setup, but it makes Nuklear particularly well suited for games,
or for applications where you want to create new controls.</p>

<ul>
  <li><strong>Framework written in</strong>: ANSI C, single-header library.</li>
  <li>
    <p><strong>Portability</strong>: where C runs. Nuklear doesn’t contain
platform-specific code. No direct OS or window handling is done in
Nuklear. Instead <em>all input state has to be provided by platform
specific code</em>.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: small.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lispcookbook.github.io/cl-cookbook/gui.html">https://lispcookbook.github.io/cl-cookbook/gui.html</a></em></p>]]>
            </description>
            <link>https://lispcookbook.github.io/cl-cookbook/gui.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819896</guid>
            <pubDate>Mon, 13 Jul 2020 12:13:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“johnyj12345” exposing self-hosted Gitlab's secrets to the public]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819885">thread link</a>) | @ferruck
<br/>
July 13, 2020 | https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/ | <a href="https://web.archive.org/web/*/https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <h2><a href="https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" rel="bookmark">Possible Gitlab Hack</a></h2>
                <p>Today I noticed a new and unknown user on our company's Gitlab
instance: "johnyj12345". We immediatly took down our instance as it
seems as if that Johny was able to extract our secrets. You should
probably do so, too.</p>
                <p><i>Published <time datetime="2020-07-13T12:05:42+02:00">Monday, 13 July 2020</time> by <a href="https://blog.philipp-trommler.me/author/philipp-trommler.html">Philipp Trommler</a>. This article has also been translated to: <a href="https://blog.philipp-trommler.me/de/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" hreflang="de">de</a>.</i></p>
                <p>Searching the web <a href="https://www.google.com/search?q=johnyj12345">for the
username</a> (attention: Google link!)
reveals that many self-hosted Gitlab instances are affected. The publicly
visible procedure is always the same: Johny creates one or more issues that are
linked with each other and at the end of the link cascade there's either an
attached file or a link to a file which holds Gitlab's <code>secrets.yml</code>.</p>
<p>From the web search it seems like the hack started on Saturday, though that may
be a false conclusion. In any case, you should probably take down your Gitlab
instance if you're affected since the <code>secrets.yaml</code> contains Gitlab's base key
and the database encryption key which should better be private AFAIK. This may
or may not be an immediate attack surface, but better safe than sorry,
especially since the files can be easily found via Google.</p>
<p>We're currently looking for a sane and safe way of rotating the keys within that
file. Any help would be appreciated.</p>
                <p><i>Filed under <a href="https://blog.philipp-trommler.me/category/security.html">Security</a>. Tags: <a href="https://blog.philipp-trommler.me/tag/git.html">git</a>, <a href="https://blog.philipp-trommler.me/tag/gitlab.html">gitlab</a>, <a href="https://blog.philipp-trommler.me/tag/hacking.html">hacking</a>, <a href="https://blog.philipp-trommler.me/tag/web.html">web</a>.</i></p>
                <p><i>Want to comment on this article? Write me at blog [at] philipp-trommler [dot] me!</i></p>
            </article></div>]]>
            </description>
            <link>https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819885</guid>
            <pubDate>Mon, 13 Jul 2020 12:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Mock Interviews – learn about data and SQL by solving interview tasks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819221">thread link</a>) | @makaronich
<br/>
July 13, 2020 | https://www.sqlhabit.com/about-mock-interviews | <a href="https://web.archive.org/web/*/https://www.sqlhabit.com/about-mock-interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<div>
  <div>
    <section>
      
<div>
  

  <div><p>
    Mock Interviews will help you to get ready for an upcoming SQL interview. It's also a great way to learn and practice Data Analytics with SQL. The format is simple:
    </p>
  </div>

  <p><a href="https://www.sqlhabit.com/signup">
    Try Mock Interviews <br>for free
</a></p></div>

    </section>

    <section>
      <div>
        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews@2x-7a6e7ee7be9670546e04b57481518131981519804003b13c30b96beb72b70db9.jpg 2x">
    <img alt="Prepare for an interview" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg">
  </picture>

  <div>
    <h2>
      Prepare for an interview
</h2>
    <p>
      Mock Interviews are based on SQL challenges from Data Analysis, Product Management and Marketing interviews. Youâ€™ll have 45 minutes to solve 2 challenges varying in difficutly: easy, medium, hard and hardcore. <img title=":rocket:" alt="ðŸš€" src="https://twemoji.maxcdn.com/2/svg/1f680.svg">

    </p>
  </div>
</div>

        </div>

        

        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents@2x-b68c6ed4cd81b4a5d61ed804f4a8960e4ad180d40ff917f40e5e5deba66ba0fa.jpg 2x">
    <img alt="Master Data Analysis with SQL Habit course" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg">
  </picture>

  <div>
    <h2>
      Master Data Analysis with SQL Habit course
</h2>
    <p>
      Go beyond Mock Interviews and learn specifics of Data Analysis with SQL Habit course. Youâ€™ll not only master SQL, but learn how to apply it in different scenarios from Product Management and Marketing. All based on a story of a startup. <img title=":books:" alt="ðŸ“š" src="https://twemoji.maxcdn.com/2/svg/1f4da.svg">

    </p>
  </div>
</div>

        </div>
      </div>
    </section>

    <section>
      
<div id="pricing">
  <h2>
    Buy unlimited access to SQL Habit
  </h2>

  <div>
    <div>
      
<div>
  <p>
    FUNDAMENTALS
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>25 free</strong> lessons and exercises
          </p>
        </div>
        
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://www.sqlhabit.com/signup">Sign up</a></p><p>
        *no credit card required
      </p>

  </div>
</div>

    </div>
    <div>
      
<div>
  <p>
    COMPLETE PACKAGE
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>200+</strong> lessons and exercises
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to SQL Habit, forever
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to Mock Interviews
          </p>
        </div>
        <div>
          


          <p>
            Verified <strong>LinkedIn certificate</strong>
          </p>
        </div>
        <div>
          


          <p>
            A <strong>private Telegram group</strong> with the author and your fellow course participants
          </p>
        </div>
        <div>
          


          <div>
            <p><strong>Monthly live Q&amp;A sessions</strong>, next one is scheduled for August, 1 </p>

          </div>
        </div>
        <div>
          


          <p><strong>1 year of Datagrip</strong> for free
          </p>
        </div>
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://gum.co/kwYeT">Buy now</a></p>

  </div>
</div>

    </div>
  </div>
</div>

    </section>

    <section>
        <section>
          <div>
  <h2>
    Reviews
  </h2>

  

  <div>
      <div>
        <p><span>SQL habit is the best online course I have done! It is my number one recommendation when it comes to learn SQL, for a beginner or even an advanced user.</span>

Anatoli has a gift to teach through examples in a very fun and playful way. The course covers real life example of the data analysis function of a company, starting with accessible SQL (read no prior experience needed), to very advanced SQL (yes, I mean...
        </p>

          
      </div>
      <div>
        <p><span>I am so excited that I have finally learnt SQL and realised how much I can gain from it in my daily work! The course gave me a better understanding of Marketing and Product Analytics</span> â€” how data is tracked, stored and interpreted â€” on web and for mobile apps. I can't wait to put my new skills into practice! I have tested few SQL courses and I would highly recommend SQL Habit without a doubt! Thank you very...
        </p>

          <p>
            Artur, Marketing Analyst @ Babbel
          </p>
      </div>
      <div>
        <p>
          SQL was something I never touched before starting this course. But being a Product Designer, I often asked my colleagues about how many users saw a specific landing page, where did they come from, how many people signed up, etc. It made me want to learn more about the data behind those magic numbers I got from them all the time. <span>This course was an incredible help to understand exactly that and it made me way more...
        </span></p>

          <p>
            Franziska, Product Designer
          </p>
      </div>
  </div>
</div>

        </section>
    </section>

    <section>
      
<div>
  <h2>
    Frequently Asked Questions
  </h2>

  <div>

      <div>
    <p>Can I try the course for free?</p>

    <p>Absolutely. The first 33 lessons and exercises are free. Just <a href="https://www.sqlhabit.com/users/new">signup</a> with your email, no credit card info required.</p>
  </div>
  <div>
    <p>Do you accept PayPal purchases?</p>

    <p>SQL Habit uses Gumroad to accept payment and Gumroad supports PayPal.</p>
  </div>
  <div>
    <p>Can I get an invoice?</p>

    <p>Absolutely! Right after purchasing youâ€™ll get a receipt which includes a link to generate an invoice with any extra information you need to add for your own accounting purposes.</p>
  </div>
  <div>
    <p>Do you have monthly subscription?</p>

    <p>Nope, one time purchase allows you to access it <strong>forever</strong>. Honestly, I believe itâ€™ll take you 1-2 months to really develop this strong SQL Habit. <img draggable="false" title=":muscle:" alt="ðŸ’ª" src="https://twemoji.maxcdn.com/2/svg/1f4aa.svg"></p>
  </div>
  <div>
    <p>Can I purchase SQL Habit for my team/company?</p>

    
  </div>
  <div>
    <p>What if I realize itâ€™s not for me?</p>

    <p>No problem! Ping me at <a href="mailto:support@sqlhabit.com">support@sqlhabit.com</a> and youâ€™ll be refunded in full, no questions asked (except feedback).</p>
  </div>

  </div>
</div>

    </section>
  </div>
</div>

    </div></div>]]>
            </description>
            <link>https://www.sqlhabit.com/about-mock-interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819221</guid>
            <pubDate>Mon, 13 Jul 2020 10:32:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A $50.000/year streaming service]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819201">thread link</a>) | @gianlucahmd
<br/>
July 13, 2020 | https://blog.gianlucamauro.com/post/harvard-online-learning/ | <a href="https://web.archive.org/web/*/https://blog.gianlucamauro.com/post/harvard-online-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <section>
  
</section>










        

<section>

    <section id="articleHero">
    <div>
        <header>
            
            <div>
                <div>
                    


    
            
    



<p>
                    July 10, 2020
                     • 3 min read
                </p></div>
            </div>
        </header>
        
        
        
    </div>
</section>

    

    <article id="articleContent">
        <p>Harvard University announced that next academic year will be 100% online.</p>
<p>And the tuition won’t be a dime cheaper.</p>
<p><img src="https://blog.gianlucamauro.com/images/harvard.png" alt=""></p>
<p>Why does it matter?</p>
<p>I don’t want to question the worthiness of such an investment. Yet, I can’t help but wonder if you’ll loose some of your returns by switching from the Harvard University halls to your web browser.</p>
<p>When you give $50.000 to a University like Harvard, you’re paying for a bunch of stuff. Mainly:</p>
<ul>
<li>Prestige</li>
<li>The network (your network is your net worth, right?)</li>
<li>Learning, obviously</li>
</ul>
<p>How will the new experience impact these aspects?</p>
<p>The prestige will stay intact. You can show off your Harvard badge on LinkedIn without having to specify where you studied.</p>
<p>I don’t think that you’ll get exposure to the same network as with physical classes. Human connection is paramount to build strong social ties. Yes, you can talk to people trough Zoom and stuff. But let’s stop hiding: Zoom is a poor quality proxy for face to face interaction. Hopefully when Covid will be over students will catch up with the social interactions they missed.</p>
<p>Let’s talk about learning now.</p>
<p>For years, online learning has been seen as a “second choice” learning format. Yes, it’s more comfortable and democratic than “real” university learning, but at the cost of some quality. I have to admit, I was guilty myself of this bias a few years ago.</p>
<p><strong>By changing medium without touching its price tag, Harvard changed the game. Harvard stated loud and clear that online learning is still learning. And it’s worth as much.</strong></p>
<p>This is a huge win for people like me that work hard to create the best online educational content possible.</p>
<p>This legitimates online learning. It acknowledges that the medium does not devaluate the knowledge, passion and teaching skills of the teacher.</p>
<p>Among all the change that Covid has brought to our lives, some will stick forever. Once the stigma around online learning will be gone, we’ll be left with a more democratic way of learning.</p>
<p>Who has something to teach will be free of sharing his experience without fear. Who wants to improve herself will be free to do so without the entry barriers of the Harvard halls.</p>
<p>And my biggest wish of all: <strong>companies will treat people that built their education online with the same respect of who spent $200.000 to sit in Harvard’s classrooms.</strong></p>
<blockquote>
<p>Let the future tell the truth, and evaluate each one according to his work and accomplishments - Nikola Tesla</p>
</blockquote>

    </article>
    
    

<section id="subscriptionSection">
    <div>
        <div>
            <h3>
                Get my thoughts in your inbox
            </h3>
            <p>
                Join my subscribers to get curated emails with my posts. 
                No spam, no marketing bullshit. Opt-out at anytime. You have my word I won't not spam your inbox or share your email with any third parties.
            </p>


            

        </div>
    </div>
</section>











    
    
    
        
    




<section id="articleNext">
    
    
    
</section>


</section>







 

        
        
    

    </div></div>]]>
            </description>
            <link>https://blog.gianlucamauro.com/post/harvard-online-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819201</guid>
            <pubDate>Mon, 13 Jul 2020 10:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meddling Middlemen of Academia]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23819130">thread link</a>) | @Topolomancer
<br/>
July 13, 2020 | https://bastian.rieck.me/blog/posts/2020/middlemen/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/middlemen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>One of the strangest phenomena in academia is the reliance on publishing
companies. In this article, I want to outline some of the issues that
arise when working with publishers. I shall also endeavour to provide
some solutions to improve this collaboration.</p>
<p>Before we start, a brief <strong>disclaimer</strong>: this article will use an
amalgamation of different incidents that involved either myself, my
colleagues, or my friends.  Names&nbsp;(of the publishing companies)
have been withheld because I do not think it fair to use my ‘soapbox’
without giving the <em>other</em> side a chance to respond. Moreover,
everything I write here pertains to publishing your research in
a journal. Conference publishing—at least in machine learning—is
a joy<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. Plus, there <em>are</em> good examples of journals for machine
learning papers, foremost of them the <a href="http://www.jmlr.org/">Journal of Machine Learning
Research</a>. The ‘adversaries’ in this article are
rather the ‘big’ publishing companies and their practices. With that out
of the way, let us take a look at the state of the art!</p>

<p>If you are new to science, at some point, you will probably have to deal
with an established publishing company to get your article published.
The deal usually works like this:</p>
<ol>
<li>
<p>You look for a journal you want to publish in and submit your article
to the journal. This already often involves jumping through some
hoops. Without knowing the eventual fate of your article, you often
already have to abide by certain arbitrary formatting guidelines or
completely ‘butcher’ your article for the submission<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> by shifting
content around. However, this can be all accepted and endured because
of course, you want something from <em>them</em>, i.e. a published,
citable publication!</p>
</li>
<li>
<p>The journal then receives your submission—often through a web
interface that was developed with all the UX/UI knowledge of the
1980s<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> and has <em>never</em> been updated since—and this is where it gets
slightly <em>murky</em>. Another person—typically the editor of the
journal—now decides whether to accept the paper for reviewing, or
whether to provide you with a desk reject. A desk reject usually cannot
be appealed. It just shows you the door and leaves you to try again
with another journal&nbsp;(more murkiness here). For early-career
researchers like Ph.D. students submitting their first paper,
this can be highly discouraging. I see the reason for reducing the
workload on reviewers, of course, but I also heard of academic feuds
that were carried out on the backs of Ph.D. students and their
publications.</p>
</li>
<li>
<p>Assuming your paper ‘survived’ the desk reject, it will now be sent
to reviewers or referees. Their job is to review your paper
thoroughly, provide feedback, and in general give this whole business
a formal veneer. Setting aside problems in the reviewing
process—which I discussed <a href="http://bastian.rieck.me/blog/posts/2019/reviewing/">in another blog post</a>—this again opens up a portal into
a strange dimension: working as a reviewer for a journal is usually
a job that is provided for free&nbsp;(same goes for editorial
duties). Notice that this is <em>despite</em> the fact that those journals
are charging money to readers and universities. ETH Zurich, my
current employer, describes their experiences of the <a href="https://www.library.ethz.ch/en/Services/Using-ordering-resources/National-negotiations-with-publishers-Read-publish-reorganised">negotiations
with
publishers</a>
and mentions an expenditure of 6.4 million EUR&nbsp;(roughly 7.25
million USD) per year for being allowed to access journal articles.
That is a lot of money.</p>
<p>Setting aside the actual numbers here, let me just point out how
strange it is that companies are relying on <em>unpaid labour</em>, and this
reliance is <em>crucial</em> to their business model. They often do not
employ people that are qualified to judge the content that they want
to publish! But of course, reviewers and editors get the benefit of
<em>exposure</em>—that wonderful currency that is supposed to help your
career along! Even stranger: journals often charge hefty sums for
accessing your own research articles. To me, it is super weird that
research that is often <em>funded</em> by the taxpayer cannot be <em>accessed</em>
by the taxpayer.</p>
</li>
<li>
<p>Supposing your article got sufficiently good reviews to be published,
the next stage of the process starts. This is where the <em>meddling</em>
begins in earnest. After a little back and forth, you article will be
changed according to some arbitrary rules: the last period of every
sentence in an image caption will be removed, footnotes will be put
into the text—because for some reason, footnotes are permitted in
virtually every template and publishing medium, but deemed somewhat
uncouth by certain publishers—and you might have to redo certain
parts of your paper because of subtle font changes or what have you.</p>
<p>Again, lest you think of me as a particularly cranky person prone to
grumbling and finding faults, you are getting the wrong idea here.
I do not object to these changes, but I <em>do</em> object to the fact that
these meddlesome changes often decrease the quality of your paper.
Here are some irksome changes:</p>
<ul>
<li>
<p>Footnotes will be inserted willy-nilly into the text, regardless of
whether they make sense or not. That might break the flow of your
paper, but that is <em>your</em> problem.</p>
</li>
<li>
<p>Some ‘publisher house rules’ conflict with proper nomenclature in
a field. For example, the journal might have the ‘rule’ that all
fields in a table have to be capitalised. If this clashes with
nomenclature in your field, it is—you guessed it—<em>your</em> problem.</p>
</li>
<li>
<p>Your equations will typically be typeset yet
another time for you<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, which might introduce subtle changes: symbols
will change and you have to be go through your own paper once again
line-by-line to see whether anything untoward happened. Again, I am
primarily objecting to the substandard quality of this meddling:
the work that you put into writing your equations is completely
ignored, and now you have to chase—often very subtle—changes in
your own text. For mathematical typesetting, precision is crucial,
and it is unbecoming when people who do not <em>care</em> about this
precision create more work for you.</p>
</li>
<li>
<p>As a last example, your figures might be meddled with: you might be
forced to convert them into obsolete file formats&nbsp;(because
apparently, EPS is still the best format available), or, more
appallingly, vector graphics might be converted to raster
images&nbsp;(judging from the experiences of my friends and myself,
this is unfortunately relatively common!). This might sound like a tiny
problem again, but it decreases readability and accessibility for
some readers, and, more to the point of this post, it is somewhat
unnecessary meddling.</p>
</li>
</ul>
<p>Let me re-iterate my main point: I do not object to changing my
paper, I merely object to meddlesome changes that are just generating
useless work. For example, there is no need whatsoever to typeset
your equations again—this is quite literally the definition of
negative work.</p>
</li>
<li>
<p>If you survived this ordeal intact, you now must <em>pay</em>. To be fair,
not all journals charge you for normal articles, but <em>most</em> of them
charge you for open access publishing. In other words: if I want my
research, which is generously funded<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> by the Swiss taxpayers, to
be available to those selfsame taxpayers, I have to pay. The amounts
vary a little bit, of course, but we are talking upwards of a few
hundred USD at least. Luckily, this is <em>not</em> a problem for my
research group; my postdoctoral adviser, <a href="https://bsse.ethz.ch/mlcb/karsten.html">Prof. Karsten
Borgwardt</a> ensures that
sufficient funds for open access publications are available.</p>
<p>Interestingly, sometimes the cost is fielded by a conference; this
happens when the conference has a contract that ensures that its
publications will be available as special issue of some journal.
This might seem nice because it <em>shifts</em> the costs away from authors,
but it is also somewhat non-transparent; conference costs being high
already, I find it strange that some of the money goes into the
pockets of another party.</p>
<p>After all this negativity, it is time for a <em>positive example</em>:
NeurIPS, one of the flagship machine learning conferences, is
partnered with a publisher and makes <em>all</em> papers available for free
online. I <em>gladly</em> pay the conference fee for this!</p>
</li>
</ol>

<p>How can this process be improved? I have a few suggestions:</p>
<ol>
<li>
<p><strong>Transparency</strong>: publishers should make it clear <em>where</em> the funds are
going. Are we increasing shareholder value by working for free? How
are profits split and used?</p>
</li>
<li>
<p><strong>Giving back</strong>: it is generally understood that everyone needs to eat
and no one should have to work for free. Why is then that this
completely different in publishing? Almost all the profits are
essentially generated because editors and reviewers work for free.
I know that being remunerated for your reviewing work might raise
some questions about impartiality etc., so I think <em>paying</em> people to
write reviews might be somewhat problematic.</p>
<p>However, closely related to my point about transparency, publishers
could be more upfront about how they user their funds and <em>give back</em>
to the community. For example, publishers could sponsor students so
that they can visit a conference for free, or publishers could
sponsor the conferences themselves.</p>
<p>If you, as a publisher, engage the community and give back a little,
the community will be all the more happy to work with you. We need
you, but you also need us. Without the scientists, you cannot be
a scientific publisher.</p>
</li>
<li>
<p><strong>Commitment to excellence</strong>: publishers should commit to the highest
quality and the highest standards. Employ people that are capable of
working <em>with</em> the scientists, not <em>for</em> the scientists. Train your
employees to be experts in typography, typesetting, and pair them
with domain experts so that they do not create more work for the
authors by inadvertently destroying equations, figures, and so on.</p>
<p>This goal is not necessarily orthogonal to maximising your profits,
by the way: if you lower your standards, your reputation as
a publisher will suffer, meaning that scientists in the long
run&nbsp;(!) might not be willing to publish with you any more. If
you commit to excellence, by contrast, we will flock to you.</p>
<p>I know that working with a publisher that <em>cares</em> about the end
product as much as I do is a heavenly match! So we should endeavour
to make such …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bastian.rieck.me/blog/posts/2020/middlemen/">https://bastian.rieck.me/blog/posts/2020/middlemen/</a></em></p>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/middlemen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819130</guid>
            <pubDate>Mon, 13 Jul 2020 10:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real World Programming in SWI-Prolog]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23818901">thread link</a>) | @luu
<br/>
July 13, 2020 | http://www.pathwayslms.com/swipltuts/ | <a href="https://web.archive.org/web/*/http://www.pathwayslms.com/swipltuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>This is a hopefully ever expanding collection of tutorials on aspects of the SWI-Prolog environment.
Our emphasis is on learning to write <b>real world</b> applications in SWI-Prolog.</p>

<ol>
<li><a href="http://www.pathwayslms.com/swipltuts/dcg/index.html">Definite Clause Grammars</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/html/index.html">Web Applications</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/clpfd/clpfd.html">Constraint Logic Programming over Finite Domains</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/message/index.html">Printing Messages in SWI-Prolog</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/chr/index.html">Constraint Handling Rules</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
</ol>

<h2>Stuff that's in the general vein of the <i>Real World</i> tutorials, but are by others</h2>
<ul>
<li>There is a <a href="http://swish.swi-prolog.org/example/dict.swinb">SWISH tutorial on the dict structure</a> that was introduced with revision 7.0</li>
<li>There is a <a href="http://swish.swi-prolog.org/example/tabling.swinb">SWISH tutorial on tabling</a> that was introduced with 7.2.3</li>
<li>Michael Richter maintains a tutorial on using modules with SWI-Prolog <a href="http://chiselapp.com/user/ttmrichter/repository/gng/doc/trunk/output/tutorials/swiplmodtut.html">Using Modules with SWI-Prolog</a></li>
<li>Michael Hendricks has a tutorial for his vastly nifty pack "Julian" for reasoning about dates and times <a href="http://mndrix.github.io/julian/index.html">Julian tutorial</a></li>
<li>The Amzi Corporation maintains a useful introduction to expert systems <a href="http://www.amzi.com/ExpertSystemsInProlog/">Expert Systems in Prolog</a></li>
</ul>

<h2>Other stuff by me (Anne Ogborn) about Prolog</h2>
<li><a href="http://www.pathwayslms.com/swipltuts/student/index.html">FAQ For The ##Prolog Channel</a> by Anne Ogborn and Michael Richter</li>
<li>A little story about <a href="http://www.pathwayslms.com/swipltuts/teacher/index.html">teaching Programming Languages courses that include Prolog</a></li>
<li><a href="https://www.youtube.com/watch?v=JmOHV5IlPyU">Youtube video (35 mins) of my tutorial on Pengines at Strange Loop 2014</a></li>
<li><a href="https://www.youtube.com/watch?v=G_eYTctGZw8">Youtube video (40 mins)</a> of Michael Hendricks' talk on Production Prolog, with great hints on practical Prolog</li>
<li>I gave a workshop on SWI-Prolog web development at <a href="https://thestrangeloop.com/">Strangeloop 2013</a> The workshop materials were basically the set of html tutorials collected into a single program. <a href="https://github.com/Anniepoo/strangeloop">You can get them here</a>.</li>

<h2>Selected other folks' tutorials and info about prolog</h2>
<ul>
<li>Roman Bartok maintains a great <a href="http://kti.ms.mff.cuni.cz/~bartak/prolog/index.html">tutorial introduction to Prolog</a></li>
<li>The introductory book <a href="http://lpn.swi-prolog.org/lpnpage.php?pageid=online">Learn Prolog Now</a> is online, and has embedded SWISH so you can run the examples right in the text</li>
<li>Help, my brain is melting <a href="http://www.pathwayslms.com/swipltuts/())).pl">())).pl</a></li>
</ul>

<h2>Contribute!</h2>
<p>We'd love to have more contributors of tutorials. Areas we'd love to see covered: Pldoc, The IDE, CLP, Expert Systems, aggregator library, and whatever else excites you.</p>



</div>]]>
            </description>
            <link>http://www.pathwayslms.com/swipltuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818901</guid>
            <pubDate>Mon, 13 Jul 2020 09:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark Web Price Index 2020]]>
            </title>
            <description>
<![CDATA[
Score 282 | Comments 197 (<a href="https://news.ycombinator.com/item?id=23818727">thread link</a>) | @known
<br/>
July 13, 2020 | https://www.privacyaffairs.com/dark-web-price-index-2020/ | <a href="https://web.archive.org/web/*/https://www.privacyaffairs.com/dark-web-price-index-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><b>The dark web has a longstanding reputation as a haven for the worst kinds of criminal activity. This reputation is not wholly unjustified, as there are indeed terrible things happening around the world that can be bought and sold on the dark web. </b></p><p><span>The privacy offered by software such as TOR creates an environment where criminals can sell their wares on the dark web without the worry of law enforcement.</span></p><p><span>What’s more, many will have heard the horror stories of people’s bank accounts being cleaned out, or their identity stolen and turning up in custody in Mexico. Again, not unjustified horror.</span></p><p><span>You might be asking yourself, just how easy is it to obtain someone else’s personal information, documents, account details?&nbsp;</span></p><p><span>We certainly were.</span></p><p><span>To see just how prevalent such items of personal data are being listed, and at what price, we sent our researchers on a data-gathering mission into the dark web.</span></p><table><tbody><tr><td>Category</td><td>Product</td><td>Avg. dark web Price (USD)</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#2">Credit Card Data</a></td><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td></td><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td></td><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td></td><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td></td><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td></td><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td></td><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td></td><td>Walmart account with credit card attached</td><td>$10</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#3">Payment processing services</a></td><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td></td><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td></td><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td></td><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#4">Forged documents</a></td><td>US driving license, average quality</td><td>$70</td></tr><tr><td></td><td>US driving license, high quality</td><td>$550</td></tr><tr><td></td><td>Auto insurance card</td><td>$70</td></tr><tr><td></td><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td></td><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td></td><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td></td><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td></td><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td></td><td>Europe national ID card</td><td>$550</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#5">Social Media</a></td><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td></td><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td></td><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td></td><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td></td><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td></td><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td></td><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td></td><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td></td><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td></td><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td></td><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td></td><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td></td><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td></td><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td></td><td>Instagram likes x 1000</td><td>$6</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#6">Malware</a></td><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td></td><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td></td><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td></td><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td></td><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td></td><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td></td><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td></td><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td></td><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td></td><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td></td><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td></td><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td></td><td>Android x 1000</td><td>$600</td></tr><tr><td></td><td>Premium x 1000</td><td>$6000</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#7">DDoS Attack</a></td><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td></td><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table></section><div><section id="1"><h2>What We Found</h2><p>Whilst there are many marketplaces on the dark web, there are even more forum posts warning of scammers. This makes verified prices difficult to obtain without ordering the items to find out, which of course we didn’t.</p><p>Our methodology was to scan dark web marketplaces, forums, and websites, to create an index of the average prices for a range of specific products.</p><p>We were only interested in products and services relating to personal data, counterfeit documents, and social media.</p><p>This is what we found.</p></section><section id="2"><h2>Cloned credit cards and associated data</h2><table><tbody><tr><td>Product</td><td>Average dark web Price (USD)</td></tr><tr><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td>Walmart account with credit card attached</td><td>$10</td></tr></tbody></table><p>Credit card details usually come in the format CC|MM|YY|CVV|HOLDER_NAME|ZIP|CITY|ADDRESS|EMAIL|PHONE with the first 4 sections being the details on the card and the rest the details of the account holder. This will definitely cause a major inconvenience, but the prospect of someone using your online banking logins to gain full access to your account is far more daunting.</p><p><a href="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png"><img src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" data-src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" alt="Dark web credit card price" width="840" height="447"></a></p><p>Vendors tend to offer a guarantee of 80%. Meaning that two of every ten cards either won’t work or will have less than the advertised balance. We didn’t order any so can’t verify whether this is true, but the prevalence of these claims alongside the well documented increase in identity fraud cases suggests that there is a high turnover of such data.</p></section><section id="3"><h2>Payment processing services</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr></tbody></table><p>PayPal account details were easily the most common items listed, and extremely cheap. More expensive was actual transfers from a hacked account.</p><p>Another very common item for sale was guides on how to “cash out” – actually get the money in a way that doesn’t alert the authorities. These guides go for a few cents, but whether or not they actually work is not what we were looking for.</p></section><section id="4"><h2>Forged documents</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>US driving license, average quality</td><td>$70</td></tr><tr><td>US driving license, high quality</td><td>$550</td></tr><tr><td>Auto insurance card</td><td>$70</td></tr><tr><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td>Europe national ID card</td><td>$550</td></tr></tbody></table><p>These documents came with a range of guarantees and are available with any details the buyer chooses. With just a few pieces of real information about someone, a criminal could create a whole file of official documents to be used for all sorts of fraudulent activities. This one way in which an identity is stolen.</p><h3>Counterfeit money</h3><p>Counterfeit banknotes are extremely common, mainly in 20 or 50 denominations.</p><p>We came across USD, EUR, GBP, CAD, AUD most often. Some come with a UV pen test guarantee. The “quality” ones tend to cost around 30% of the banknote value.</p></section><section id="5"><h2>Social media</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td>Instagram likes x 1000</td><td>$6</td></tr></tbody></table><p>Offers to hack accounts or sell them were relatively scarce, but not non-existent. Perhaps due to a lack of demand for the product coupled with increased security practices. Hackers trying to get the social media credentials from their victims mostly have to resort to using <a href="https://www.getsafeonline.org/blog/what-is-pii-and-how-do-you-keep-it-private/">social engineering techniques</a>, which have a very high effort input for relatively low success ratio.</p><p>The extremely low cost for social engagement should seriously make you question an account’s validity before blindly trusting their wealth of social currency.</p></section><section id="6"><h2>Malware</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td>Android x 1000</td><td>$600</td></tr><tr><td>Premium x 1000</td><td>$6000</td></tr></tbody></table><p>Malicious tools are installed on comprised systems (Windows, Android and others) which gives attackers access to the system. Initial installation is via fake online casino, FB/social networks, warez websites etc.</p><p>Some forms of malware may simply use your computer’s resources for activities such as cryptocurrency mining. Others may be used to steal credentials as you enter them on a website. For each 1000 installs, hackers can often steal tens of thousands of dollars.</p></section><section id="7"><h2>DDoS attack</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table><p>A distributed denial of service (DDoS) attack aims to take a website offline by sending thousands of requests per second in order to overload the website’s server, causing it to crash.</p></section><section id="8"><h2>Why This Data Is Important</h2><p>For the average person, underground market data isn’t necessarily going to provide much use as they most likely aren’t shopping around for stolen card data or PayPal accounts. Though this is true, the prices at which these items sell provide a powerful perspective.</p><p>If someone gets their hands on your financial details or social media credentials, the prices mentioned above is basically what it’s worth to them. There’s a good chance that you value these things much more than they do, as to them you’re just another mark for a quick buck.</p><p>For far less than the amount your data would sell for on the black market, you can protect it from ever having to reach their hands with a couple of simple rules and habits. With this knowledge, there’s no excuse not to do what you can to protect your data.</p><p>Nothing is foolproof however, and …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.privacyaffairs.com/dark-web-price-index-2020/">https://www.privacyaffairs.com/dark-web-price-index-2020/</a></em></p>]]>
            </description>
            <link>https://www.privacyaffairs.com/dark-web-price-index-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818727</guid>
            <pubDate>Mon, 13 Jul 2020 09:08:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial sites treating FreeBSD like a Linux distro]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 77 (<a href="https://news.ycombinator.com/item?id=23818702">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>On the Gold Coast in January, Deb Goodkin from the FreeBSD Foundation began her Linux.conf.au talk with an intentionally-provocative slide: <em>FreeBSD, that’s just another Linux distro, right?</em> It was said in jest to highlight what a common misconception it is.</p>
<p>One way this manifests is through introductory FreeBSD guides online, usually on blogs with the words sysadmin, cookbook, or tutorial in their names; you know the ones I’m talking about. Invariably they advise updating the base system and pkgng, then immediately installing bash, nano, htop, lsof, coreutils, proc, and more. Some go as far as aliasing these over the built-in tools, and even setting bash as the root shell. From then on, you barely have to touch the FreeBSD userland.</p>
<p>Like a poorly-maintained cheese utensil, this used to grate. If you’re installing an entire GNU toolchain, why not use a Linux distribution, or Debian/kFreeBSD, or a Nexenta-like OS that’s built specifically for those tools? You’re not learning about FreeBSD’s features, nor are you taking advantage of any of its benefits beyond the kernel and base. It’s wasted opportunity, and could render future project contributions more difficult because of misunderstood assumptions about how the system works.</p>
<p><img src="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg" srcset="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg 1x, https://rubenerd.com/files/2020/usebsd-pillow@2x.jpg 2x" alt="A photo of a pillow saying: Use BSD"></p>
<p>I’ve since changed my tune somewhat, with a caveat. I also want to take this opportunity— not a sponsor—to spruik Jay Patel’s <a href="https://www.redbubble.com/people/jaypatelani/shop">RedBubble store</a> for your BSD laptop and loungeroom. I’ve already added some to next sticker batch.</p>
<p>What was I talking about?</p>
<p>We should be encouraging Linux people to try FreeBSD, and if giving them their familiar tooling gets their foot in the door, it’s worth it. I personally learn things the quickest by jumping in the deep end, but I know others want to take things a step at a time.</p>
<p>What also gets lost in the fray is FreeBSD, even with all those Linux-focused tools, is still a compelling and useful operating system. It’s a feature not a bug to be able to have all these tools available, and at times run them faster than Linux could on the same hardware. It may even integrate better into shops that otherwise entirely run Linux, given the motivation to write portable, POSIX-compliant code and applications is no longer a priority for most people (sadface).</p>
<p>So rather than saying those guides aren’t useful or even misrepresent FreeBSD, we need to reframe them. Instead of <em>introductions to FreeBSD</em>, say they’re <em>FreeBSD for Linux people</em>. This shouldn’t be constued as criticism; the latter kinds of post would be <em>hugely</em> useful. It’s also then easier to introduce BSD-specific tools and ideas, either inline after each Linuxism you introduce, or in a follow-up post where you compare and contrast.</p>
<p>We need more bridge-building and outreach between the two communities, and anything to make FreeBSD relatable to people coming from Linux, or any other operating system, is useful.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818702</guid>
            <pubDate>Mon, 13 Jul 2020 09:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Erasmus University Rotterdam builds first virtual campus in the Netherlands]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23818681">thread link</a>) | @vinrob92
<br/>
July 13, 2020 | https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands | <a href="https://web.archive.org/web/*/https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-history-node-id="61036"><p><span><p><time datetime="2020-07-09T12:13:58Z">Thursday, 9 Jul 2020</time></p> </span><span><p>Press release</p> </span></p> <figure> </figure><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Erasmus University Rotterdam (EUR) has re-created their Woudestein campus in the Minecraft platform to provide students and staff a sense of purpose and community during the Covid-19 crisis, a first for the Netherlands. The first blocks of the campus were laid by a small team of enthusiastic students and the project has since then mushroomed to include all buildings on campus, a secret underground labyrinth which players need to find, a treasure hunt for the 17 SDGs (de UN Sustainable Development Goals) and much more. </span></span></span></span></span></span></span></p><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Expansion plans are in the works for the Erasmus Medical Centre and the Erasmus University College. Through this project, EUR aims to fight the Covid-19 setback to the start of the academic year 2020-2021, by giving a platform to the Erasmus community to engage with each other.</span></span></span></span></span></span></span></p><div> <article data-video-provider="YouTube" data-video-id="cQ_Ke1z_Cjo"><div> <picture> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=7Ncx-0nR 1x" media="(min-width: 992px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_desktop/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=pjuiFzAV 1x" media="(min-width: 768px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_tablet/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=SqdQGgEy 1x" media="(min-width: 480px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ 1x" type="image/png"> <img src="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ" alt="Introducing The Virtual Campus - Erasmus University Rotterdam"> </picture></div><div> <h2>Introducing The Virtual Campus - Erasmus University Rotterdam</h2></div></article></div><div><h2>Campus recreated brick by brick</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>It started off as a project to provide students an opportunity for social engagement outside of the Zoom-filled lectures after the Covid-19 pandemic brought universities to a physical shutdown. After a research the Erasmus University Rotterdam (EUR) conducted into the effects of the Corona Crisis on the well-being of its students and staff members, the results strongly pointed towards the need for something to keep the Erasmus community together. People started to feel lonely and missed the ability to socially interact with each other, exactly that what a physical campus is able to provide a podium for. In an attempt to tackle this issue, ErasmusX – a disruptive innovative unit of the university – launched a creative project whereby students and staff could recreate their beloved Woudestein campus in the virtual gaming platform Minecraft. The very first building blocks were laid by members of the student-led Erasmus E-sports Community, and thereafter a professional Minecraft building team helped polish up the final product.</span></span></span></span></span></span></span></p></div><div><h2>"What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale"</h2></div><div><div><h2>Woudestein: a place to meet friends</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>To the EUR community, the campus is not just a place you go to in order to study and work. It is a place where you meet your friends (that perhaps have become like family), where you develop yourself as a human being, where you hang out and where you dream about the opportunities life has in store for you. It almost feels like a small village. “This feeling was so apparent when we saw the many emotional reactions from students and colleagues when they first see the virtual campus – they tell us that navigating the campus makes them feel like they are there again”, states Alexander Whitcomb, a project team member. “What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale. So walking from one end of the campus to the other with your avatar in Minecraft takes exactly the same amount of time as it would do in real life.“</span></span></span></span></span></span></span></p></div></div><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>The Minecraft campus has two main purposes. First it will be used for various planned activities such as onboarding all new incoming students during the famous EurekaWeek 2020, virtual tours for prospective students and the ErasmusX team is also exploring the game platform for educational and research purposes. Secondly, the campus is designed as a creative space, a way for students and staff to design their own interactions and discover new, innovative ways of engaging with one another through the virtual campus. The platform will be moderated by the Erasmus E-sports Community and all ideas are welcomed.</span></span></span></span></span></span></span></p><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Ultimately, the campus in Minecraft is there to strengthen the community of Erasmians, in an academic year where physical interactions are limited by Covid-19, and a ‘normal’ university experience remains unavailable until further notice.</span></span></span></span></span></span></span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818681</guid>
            <pubDate>Mon, 13 Jul 2020 08:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM64 Popcount in Golang and Assembler]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818574">thread link</a>) | @fanf2
<br/>
July 13, 2020 | https://barakmich.dev/posts/popcnt-arm64-go-asm/ | <a href="https://web.archive.org/web/*/https://barakmich.dev/posts/popcnt-arm64-go-asm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Apropos of Apple’s ARM announcment, I thought I might write up a post on a recent bit of code I wrote that specifically looks at ARM64, and its benchmarks on various hardware.</p><p>I’ve been implementing some compact data structures for a project. One of the CPU hotspots for the implementation is the need to run a quick population count across a potentially large bit of memory.</p><p>If you’ve never seen population count before, it’s the count of the number of set 1 bits in a byte (or list of bytes) – for example:</p><div><pre><code data-lang="text">0xF3 == 0b11110011
popCount(0xF3) == 6
</code></pre></div><p>Now, every reasonable x86_64/amd64<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> CPU in the past decade or so has a built-in instruction for this: <a href="https://en.wikipedia.org/wiki/SSE4#POPCNT_and_LZCNT"><code>POPCNT</code></a>. It works like this (in Go Assembler):</p><div><pre><code data-lang="text">MOV    $0xF3, R10  // Store a constant
POPCNT   R10, AX   // AX now equals 6
</code></pre></div><p>Go uses the built-in instruction for this in the <code>math/bits</code> via SSA compiler rewrites (which it added in 1.9), but only up to a uint64 at a time; using assembly to loop over a <code>[]byte</code> is considerably more efficient</p><p><a href="https://github.com/tmthrgd"><code>@tmthrgd</code></a> created a really nice little x86_64-assembly-optimized package at <a href="https://github.com/tmthrgd/go-popcount">github.com/tmthrgd/go-popcount</a>. It works great, works around a weird little Intel bug (see the helpful comments) and is still faster than looping and using the Go standard library, which it helpfully benchmarks as well.</p><p>Recently, I picked up one of the new 8GB Raspberry Pi 4s. Loaded it up with the nice new <a href="https://manjaro.org/">Manjaro 20.06</a> and set up my usual environment. As a test, I wanted to try my latest WIP data structure code.
Of course, the bottleneck was right where I expected it to be: in the population count.</p><h3 id="implementing-it">Implementing it</h3><p>I discovered that ARM64 has a <code>POPCNT</code>-like instruction, logically enough called <code>CNT</code>. I thought, since I’ve been playing with Go assembly for memmove, why not try my hand at the new architecture?</p><p>Go already has the SSA-rewrite for OnesCount on ARM (added in 1.11), but again, only a uint64 at a time. There might be some performance on the table.</p><p><a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">Official architecture guide</a> at the ready, I got to work. And there was a lot to learn. Some notes:</p><h4 id="1-its-part-of-the-vector-suite-neon">1. It’s part of the vector suite, NEON</h4><p>NEON is the name for the addition of vector instructions to the ARM architecture, so I’d be working with both an unfamiliar architecture <em>and</em> its vector instructions.</p><p>In x86-land, <code>POPCNT</code> and vectorization are two separate concepts. <code>POPCNT</code>, as an instruction, deals with everyday, 64-bit integer registers, and not the vector registers (even though it appeared approximately the same time as the addition to vector instructions, SSE4)<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p><p>ARM/NEON did <code>CNT</code> differently. Since you can load an array of items (say, 16 bytes, in the ARM64 vector registers), <code>CNT</code> will count them individually. In fact, you can <em>only</em> do it in vectors of single bytes.</p><p>So this means that the following signatures are approximately the way to think about it:</p><div><pre><code data-lang="go"><span>func</span> <span>popCountx86</span><span>(</span><span>in</span> <span>uint64</span><span>)</span> <span>uint64</span> <span>// register-at-a-time, 64-bit (8 bytes)
</span><span></span>
<span>func</span> <span>popCountNeon</span><span>(</span><span>in</span> <span>[</span><span>16</span><span>]</span><span>byte</span><span>)</span> <span>[</span><span>16</span><span>]</span><span>uint8</span> <span>// 16 bytes all counted in parallel.
</span></code></pre></div><p>This ends up being really effective, as it turns out (below).</p><h4 id="2-gos-assembler-documentation-is-barebones">2. Go’s assembler documentation is barebones</h4><p>Writing instructions so that Go’s assembler is happy with the instructions you’re giving it is a bit frustrating.</p><p>There’s a good gloss at <a href="https://golang.org/pkg/cmd/internal/obj/arm64/">golang.org/pkg/cmd/internal/obj/arm64</a> which gives an overview of many of the differences.
For example, all vector instructions start with <code>V</code>, different than what ARM64 switched to (they used to commonly start with V on 32-bit ARM) – so while I understand the desire for continuity (and even subtly like it, knowing it’s a vector op) it’s just makes another little difference to remember vs. the original documentation.</p><p>But more frustrating is, even if your instruction is supported (and most of them are) knowing how to <em>use</em> the instruction in Go assembler boils down to “assume data goes left-to-right and hope there’s an example <a href="https://github.com/golang/go/blob/master/src/cmd/asm/internal/asm/testdata/arm64enc.s">in the test suite</a>”</p><p>I’m a big Go fan, yet Go’s history into Plan 9 and accompanying assembler (and, relatedly, odd calling conventions) is one of my gripes about Go, even more than lack of generics (which is a topic for another day).
Sure, there were some good ideas in Plan 9 that influenced the design of Go – from a design level, it’s great! – but on the implementation level, this is one place where I kinda wish it had followed precident.
Take whichever side you want in the Intel vs GNU syntax debate, <a href="https://xkcd.com/927/">creating a third option</a> means relearning all the quirks from scratch, and ignoring any documentation that already exists.</p><h3 id="putting-it-all-together">Putting it all together</h3><p>The end result is my friendly fork of <code>go-popcount</code>: <a href="https://github.com/barakmich/go-popcount">github.com/barakmich/go-popcount</a></p><p>Really, it’s more of an extension than a fork – it provides the same API, just with handwritten assembly for ARM64 chips.</p><h4 id="how-it-works">How it works</h4><p>The vectorization works really well. The process is:</p><ul><li>Load a set of vector registers, 16 bytes each</li><li>popCount them</li><li>Vector sum their partial results (up to 32 individual vectors, to fit the 8-bit counts), trying to avoid a data dependency</li><li>Finally, sum (“widening”, in vector terms) the final vector</li><li>Add it to the final output</li></ul><p>The other thing to balance was how much to load from memory vs. how much work to do to optimize throughput. That ended up being about 8 vectors (128 bytes) at a time.
That may vary as a function of CPU, but it’s a good place to start.</p><h4 id="arm64-feels-nice">ARM64 feels nice</h4><p>This is purely subjective, but there were a number of moments where I felt “hey, that’s handy” in writing ARM64 assembly.
Of course modern x86_64 chips account for all of these differences and makes them performant – through deeper instruction pipelines or having <a href="http://sunnyeves.blogspot.com/2009/07/intel-x86-processors-cisc-or-risc-or.html">micro-op instruction queues</a> that ultimately pull the same tricks.
But at the same time, when you’re dropping down to work at the instruction level, it’s kind of a breath of fresh air.</p><h5 id="pre-and-post-increment">Pre-and-post increment</h5><p>A lot of the time when you’re working with an array of whatever you’re pulling a chunk of memory into registers, doing some transform, and putting it back.</p><div><pre><code data-lang="asm"><span>VLD1.P</span> <span>64</span><span>(</span><span>R1</span><span>),</span> <span>[</span><span>V16.B16</span><span>,</span> <span>V17.B16</span><span>,</span> <span>V18.B16</span><span>,</span> <span>V19.B16</span><span>]</span>
</code></pre></div><p>Reads as load 1-byte*size structures into the following vector registers – so far so good, this is similar to the <a href="https://www.felixcloutier.com/x86/movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64"><code>VMOVDQU</code></a> instruction family (though the size-structure variants on that instruction are a recent addition) on x86. It has a similar ability to load many registers in multiple back-to-back instructions through address/offset/size calculation, but ARM has a nice one-liner that way.</p><p>But I really like the auto-increment of <code>R1</code> by the read size (64) after loading – hence post-increment. Many loads from memory have a similar flag. It’s very descriptive and means things like “increment the offset register and decrement the size register and test” things live with their appropriate parts of the code, instead of having to increment later (and finding the optimal time)</p><h5 id="consistency-of-style">Consistency of style</h5><p>This is a holdover from history, but the consistency of having fixed-size instructions is a nice thing when trying to hand-assemble an instruction. I had to do some hand-assembly when <a href="https://github.com/golang/go/issues/39445">I discovered and reported a bug in Go</a>. It was silently writing the wrong version of the instruction while accepting the correct one as input. Kudos to the Go community – it was fixed by an expert within a day or two, so I’m looking forward to the next version that contains the fix!</p><p>Still, this meant with a <a href="https://xkcd.com/378/">steady hand</a> and a copy of <a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">the architecture guide</a> I could feasibly implement any instructions that were missing.</p><p>Also in consistency-land, most binary operations take <code>input1_reg, input2_reg, output_reg</code> with few exceptions. Omitting the output_reg is Go’s assembler syntactic sugar to set output to input2. x86, again for historical reasons (trying to keep instructions small), often has the store-to-the-second-register as the primary or only version of an operation, which can lead to more operations overall (and cognitive overhead IMO).</p><h3 id="benchmarking-on-arm">Benchmarking on ARM</h3><p>So let’s take a look at some benchmarks.
The most interesting thing about looking at population count is that this little routine does something useful and shows tradeoffs between CPU bounds and memory bandwith between the CPU, the on-chip caches, and main memory.
At array sizes small enough to fit into CPU cache (but big enough to run the compute loop a few times), the CPU is the limiting factor – how many bits it can count.
For larger data sizes, the memory bandwidth becomes the bound; the CPU is waiting on getting enough data to crunch through.</p><p>To this end, the benchmark curves in the repository max out in throughput at about 16K (most work possible, while still being in cache) and then trail down into a steady state as memory becomes the bound. So I’ll truncate the full benchmarks to compare peak throughput and long tail.</p><p>Some findings and commentary:</p><h4 id="raspberry-pi-4">Raspberry Pi 4</h4><div><pre><code data-lang="text">Unoptimized (Go implementation):
BenchmarkCountBytesGo/16K              297778          8056 ns/op     2033.78 MB/s
BenchmarkCountBytesGo/512M                  8     279380432 ns/op     1921.65 MB/s

Optimized (My hand-rolled assember):
BenchmarkCountBytes/16K                520807          2303 ns/op     7113.24 MB/s
BenchmarkCountBytes/512M                    8     131214574 ns/op     4091.55 MB/s
</code></pre></div><p>This was my finished product on my local Pi. I may be able to do better, but varying the block sizes between grabbing from memory and doing the vector addition for popcount topped out about here, so I’m fairly satisfied.</p><p>Interestingly, the ~4.1GB/s memory bandwidth follows exactly with <a href="https://hackaday.com/2019/07/10/raspberry-pi-4-benchmarks-processor-and-network-performance-makes-it-a-real-desktop-contender/">initial read benchmarks of the Pi 4</a> suggesting it’s close to saturation, which is good news.</p><h4 id="ampere-emag">Ampere eMag</h4><p>So my next thought was to spin up an ARM64 server with my old friends at <a href="https://packet.net/">Packet</a>. They have a <a href="https://www.packet.com/cloud/servers/c2-large-arm/">c2.large.arm</a> and it’s gonna be great!</p><div><pre><code data-lang="text">Unoptimized:
BenchmarkCountBytesGo/16K      	   69939	     17208 ns/op	 952.09 MB/s
BenchmarkCountBytesGo/512M     	       2	 582293709 ns/op	 921.99 MB/s

Optimized:
BenchmarkCountBytes/16K        	  458394	      2614 ns/op	6267.80 MB/s
BenchmarkCountBytes/512M       	      12	  93371433 ns/op	5749.84 MB/s
</code></pre></div><p>…but I was rather underwhelmed.</p><p>This isn’t necessarily Packet’s fault – they were early onto having ARM hardware available and it’s …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://barakmich.dev/posts/popcnt-arm64-go-asm/">https://barakmich.dev/posts/popcnt-arm64-go-asm/</a></em></p>]]>
            </description>
            <link>https://barakmich.dev/posts/popcnt-arm64-go-asm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818574</guid>
            <pubDate>Mon, 13 Jul 2020 08:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Consolidation of the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817946">thread link</a>) | @Fizzadar
<br/>
July 13, 2020 | https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/ | <a href="https://web.archive.org/web/*/https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
 
<div>

        <h2>
            On the Consolidation of the Web
            <span>Wed 29 July 2020</span>
        </h2>

        <p>In recent years, the web has been consolidating. From the servers to the apps, a growing majority of the web is controlled by a small pool of companies. When AWS was founded in 2006 I was just starting out with my first VPS, running this blog on WordPress (the good ol' days!). For the last 10 years I have part-run a small VPS (“cloud server”) host called <a href="https://afterburst.com/">Afterburst</a>. Throughout these years I have watched this consolidation, and these are my observations.</p>

<h3>The Pre-Cloud Days</h3>

<p>Way back in 2009 blogs were booming. The market for personal servers was growing rapidly. People often used forums (remember those?) to find providers. Providers would compete to attract the most eyeballs to their sale posts.</p>

<p>The quality and cost of hosting varied wildly. During summer there would be a huge influx of budget “summer hosts” during school holidays. The majority of these would then fold only two months later. Thinking back, it was The While West. Of course there were big players; but the smaller hosts had the cheapest offers and captured the market for personal servers.</p>

<p>I believe that this was a great market for all. Buyers had a wealth of choice of companies tiny to massive. Providers were kept in check by thriving forum communities, leading to better services. The smaller providers would offer a personal touch, often partaking in forums alongside their customers. To me, this was an amazing environment in which I learnt a huge amount about servers but also customer service.</p>

<h3>The Clouds Ascend</h3>

<p>The VPS market was exploding when we started Afterburst in 2010. Shared hosting/PHP was stagnating and the prices had bottomed out. Shared hosting was consolidating fast, hosts were folding daily. Dedicated server and VPS markets remained strong and WebHostingTalk (our “home” forum) was buzzing with activity. The competition for the best VPS was in full swing.</p>

<p>And then came DigitalOcean.</p>

<p>When DO arrived in 2011 everything changed. They managed to make the much hyped “cloud” accessible to everyone where AWS had so far struggled. You could click a button and have a cloud server available within minutes. The all-SSD package, “cloud” marketing and a wave of free launch coupons caused them to explode onto the scene.</p>

<p>It was fascinating to watch the “cloud” hype train. “Cloud servers” were, almost overnight, seen as superior to “VPS”. This is despite most “cloud server” providers offering nothing different to VPS. Now I totally get that The Cloud goes way beyond servers. The offerings today include a staggering number of services. But an individual looking for a server to host their blog? They don’t need any of that, just the server space.</p>

<p>In the years since DO arrived they, AWS and later Azure/GCloud boomed. Cloud was/is the future - we must move everything “to the cloud” many a huge tech company would say. As much as it was marketing hype, the individual started to follow. The cloud was only a little more expensive and came with fancy UI and excellent developer tooling. It was cool to be using the cloud. The small/traditional VPS provider market began to slow, and later reduce. The golden days were over.</p>

<p>Whilst this was very frustrating at the time it also forced us to review and improve our marketing and customer experience. We started marketing cloud servers and optimised the checkout and customer sign-up flow. The competition led to an improved service for existing and new customers.</p>

<h3>So - where are we now?</h3>

<p>10 years later, we’re still here! The consolidation of providers has slowed and many continue to survive. Forums like WHT struggle on but are shadows of their former selves. There’s still a market for individual servers - people have a natural desire to tinker in ways that specific services cannot provide.</p>

<p>I think there will remain a cohort of individual bloggers and websites. But I also believe the web is dividing. On one side a small number of platforms the vast majority of “normal” people consume from and share to. And elsewhere a separate “old style” web of fragmented loosely connected websites/forums/blogs formed by those who tinker. Perhaps something will merge the two together in the future.</p>

<p>It’s like supermarkets consuming ‘Mom and Pop shops’, a trend that goes back decades now. Yet small greengrocers and butchers still live on. There are signs of people returning to these shops in growing numbers. Perhaps this is the start of a reverse trend, could the web follow suit? I’d like to think so.</p>
</div>
    
    </section></div>]]>
            </description>
            <link>https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817946</guid>
            <pubDate>Mon, 13 Jul 2020 07:18:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Sourcing Company Culture]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817799">thread link</a>) | @soorajchandran
<br/>
July 12, 2020 | https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/ | <a href="https://web.archive.org/web/*/https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-318">

	

	
	<div>
		
<figure><img data-attachment-id="353" data-permalink="https://blog.oysterhr.com/adobestock_32068789/" data-orig-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png" data-orig-size="1491,1008" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="adobestock_32068789" data-image-description="" data-medium-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300" data-large-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=750" src="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024" alt="" srcset="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024 1024w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=150 150w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300 300w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=768 768w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png 1491w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>TL;DR: <em>Companies that have recently gone fully-remote can draw inspiration from open source. Doing so provides helpful ways to think about attracting talent and building culture.&nbsp;</em></p>



<p><strong>Fully-Distributed is Taking Off</strong></p>



<p>Though the headlines have focused on the <a rel="noreferrer noopener" href="https://www.cnn.com/2020/05/22/tech/work-from-home-companies/index.html" target="_blank">big name companies</a> and their announcements about going remote, events of the last four months have undoubtedly created a lot of new fully-distributed companies you’ve <a rel="noreferrer noopener" href="https://www3.nhk.or.jp/nhkworld/en/news/videos/20200622091038913/" target="_blank">never heard of</a>. This includes organizations that may have been partially or even fully-colocated (office-based) before Coronavirus. And this is happening in part because remote working has worked out so well for so many of them, and in part because it has proven difficult for many companies to scale down to a “reduced” real estate footprint — to serve a subset of their employees. Hybrid is <a rel="noreferrer noopener" href="https://www.linkedin.com/pulse/remote-work-having-moment-future-isnt-hybrid-sid-sijbrandij/" target="_blank">harder</a> than fully-distributed, we keep hearing. And the truth is that returning to the office is still an open discussion (fraught with overwhelming <a rel="noreferrer noopener" href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank">emergent</a><a href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank" rel="noreferrer noopener"> logistical considerations</a>) even for companies that really want to.</p>



<p>We have also no doubt seen in the last four months an acceleration in the rate of creation of new fully-distributed startups that reject offices altogether, and that do not expect their people to meet physically to get work done. This was already a trend, and any founders who may have been hesitant before Coronavirus because they were worried about investor bias or their own inexperience with remote leadership, now have <a href="https://techcrunch.com/sponsor/oyster/the-dawn-of-the-distributed-age/" target="_blank" rel="noreferrer noopener">enormous encouragement</a> to kick the office to the curb.</p>



<p>This means, however, that now many, many more companies, not just the ones that were already on the fully-distributed bandwagon before COVID-19, are going to face the challenges unique to fully-distributed organizations.</p>



<p><strong>Next-Level Guidance is Needed</strong></p>



<p>There’s been a great outpouring of new content from the community on the basic how-to’s of remote working. We have also seen that the “bibles of remote working” (that have been around for years from the pioneering remote working companies like <a rel="noreferrer noopener" href="https://distributed.blog/" target="_blank">Automattic</a>, <a href="https://about.gitlab.com/company/culture/all-remote/guide/">Gitlab</a>, and <a href="https://basecamp.com/remote-resources">Basecamp</a>, etc) are getting the reference attention they deserve. These basics (like asynchronous communication) are of course essential principles that have to be properly installed for a fully-distributed team to walk and run. But there are other challenges that come with being a fully-remote organization for which there’s less explicit guidance.</p>



<p>Two such challenges we keep hearing about are:</p>



<ul><li>How do you attract and recruit great talent from around the world (<em>whom you may never meet in person</em>)?, and</li><li>How do you create and sustain great culture (<em>when everything is virtual</em>)?</li></ul>



<p><strong>Open Source, a Model of Distributed Success</strong></p>



<p>To these important challenges of fully-distributed organizations, the <a href="https://www.redhat.com/en/topics/open-source/what-is-open-source" target="_blank" rel="noreferrer noopener">principles and history of Open Source</a> would seem to offer a lot.&nbsp;</p>



<p>We often hear that software “eats” things. An aspect of that is that the ways of software development continue to penetrate into the ways other types of work are done. That open source should provide ways of thinking and working that are helpful to fully-distributed organizations may be yet another example of something that started in software development spreading more generally into business. Like <a rel="noreferrer noopener" href="https://agilemanifesto.org/principles.html" target="_blank">Agile</a> and <a rel="noreferrer noopener" href="https://www.agilealliance.org/glossary/kanban/" target="_blank">Kanban</a> have. This keeps happening because these “frameworks from another domain” offer avenues to better ways of working, even when what you’re doing is some other type of knowledge work.&nbsp;</p>



<blockquote><p>Whether or not they are a software company, fully-distributed organizations are going to have to become more like software companies in their ways of working.</p><a href="http://twitter.com/share?&amp;text=Whether%20or%20not%20they%20are%20a%20software%20company%2C%20fully-distributed%20organizations%20are%20going%20to%20have%20to%20become%20more%20like%20software%20companies%20in%20their%20ways%20of%20working.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=HeyOyster" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>This shift will be necessary for non-software development knowledge work to be done well in a fully-distributed organization. Naturally, that has deep implications for how technology will support knowledge work in the future. For that reason, we’re also going to see a pattern where new tools are going to be created that allow non-software developer knowledge workers to work more like developers do. This was also probably a trend well in evidence before Coronavirus, now greatly accelerated.</p>



<p>Once your organization is thinking and working a bit more like a fully-distributed software company (especially if you ARE a software company), it shouldn’t be too difficult to aspire to some of the attributes of an open source project.&nbsp;&nbsp;</p>



<p>Open source is worthy to provide guidance and inspiration to any fully-distributed company because it demonstrates a model through which great talent is not only attracted but also uniquely enabled and remotely synchronized to produce semi-miraculous results.&nbsp;</p>



<p>There is no better example of this than Linux.</p>



<blockquote><p>“Linux was the first project for which a conscious and successful effort to use the entire world as its talent pool was made.”</p><cite><em>Eric Steven Raymond, <a rel="noreferrer noopener" href="http://www.catb.org/~esr/writings/cathedral-bazaar/cathedral-bazaar/ar01s11.html" target="_blank">The Social Context of Open-Source Software</a></em></cite></blockquote>



<p>Successful open source projects like Linux should inspire fully-distributed companies because they demonstrate the extraordinary productivity potential of organized knowledge work performed by a team of people who didn’t ever have to meet in person to accomplish it.</p>



<p><strong>Becoming a Beacon for Global Talent</strong></p>



<p>Organizations who’ve let go of their offices and have recently made the transition to fully-distributed are probably still focused on getting things back on track, and on fostering the healthy continuity of the pre-existing team. Though hiring may not be the present priority, they must surely be thinking about how recruitment will work as a fully-remote company. Whether they are fully-distributed or just have newly-created remote roles, as organizations shift their recruiting perspective from thinking locally to thinking globally, this is going to radically transform the recruiting process as we have known it.&nbsp;</p>



<p>Even for companies that decide they will only hire in a subset of timezones (to facilitate synchronous work, like <a href="https://www.quora.com/q/quora/Remote-First-at-Quora" target="_blank" rel="noreferrer noopener">Quora</a>), the size of the available talent pool would still overwhelm the traditional recruitment approaches of “publishing” their open roles and waiting for “applicants” to express an interest in them. The new pervasiveness of remote working and highly-distributed companies is going to create unprecedented liquidity in the global talent marketplace. This is great for all parties, but it also means that everyone’s game has to change.&nbsp;</p>



<p>Thinking and acting like an open source project may be a good way for fully-distributed companies to evolve their talent acquisition game. Reflect on the Linux example in a post-Coronavirus talent market. When the most talented individuals can work for any company in the world, how will your company compete? How can your company distinguish itself amongst a much larger number of prospective employers?</p>



<blockquote><p>The downside for employers gaining access to the global talent pool is that they are also suddenly competing with every company in the world for talent.</p><a href="http://twitter.com/share?&amp;text=The%20downside%20for%20employers%20gaining%20access%20to%20the%20global%20talent%20pool%20is%20that%20they%20are%20also%20suddenly%20competing%20with%20every%20company%20in%20the%20world%20for%20talent.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=2hp" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>One approach is to become like an open source project, whose first organizing principle is attracting people who care deeply about the same thing. This of course requires knowing what that special thing (of singular and obsessive focus) is for your organization. I think most companies can find their unique <a href="https://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action" target="_blank" rel="noreferrer noopener">Why</a>, if they try. And I think it’s a good thing that prospective global employers should feel they have to produce a thoughtful and compelling expression of their purpose to compete for global talent.</p>



<p><strong>Creating Culture on Purpose</strong></p>



<p>Perhaps your company is bootstrapping its culture for the first time as a brand new fully-distributed startup. Or perhaps you’re an established organization now transitioning from an office-based culture. Either way, you may as a leader be wondering how to develop and nurture culture when everything is virtual and everyone’s remote.</p>



<p>Attracting people who share a common passion is potentially more than just a way to acquire talent. It can also be a terrific way to instantiate culture. But attracting talent like an open source project, however, is not just about having a clear and compelling purpose. It’s also about calling those talented people to come work on that purpose together in a <strong>particular</strong> way.</p>



<blockquote><p>“Culture is a pattern of basic assumptions — invented, discovered, or developed by a given group as it learns to cope with its problems of external adaptation and internal integration — that has worked well enough to be considered valid and, therefore, to be taught to new members as the correct way to perceive, think, and feel in relation to those problems.”</p><cite><em>Edgar Schein, <a rel="noreferrer noopener" href="https://agustinazubair.files.wordpress.com/2013/04/13-organizational_culture_and_leadership_3rd_edition-p-4581.pdf" target="_blank">Organizational Culture and Leadership</a></em></cite></blockquote>



<p>In other words, culture is inherently linked to a particular problem space, and isn’t directly about people or their attributes. Organizational culture is about how people decide to work together on a specific set of problems.</p>



<p>For many office-based companies, the “Our values” plaque that hangs on the wall is just a list of nice ideas. And though that list of values is intended to be the codification of their culture, those values may not relate in any useful way to the work to be done, and therefore probably don’t drive much useful behavior. The experience and the effects of culture, therefore, are organic, accidental, and overly-dependent on physical proximity.</p>



<blockquote><p>“Running a remote work environment effectively, requires amongst other things a deliberate approach to culture development. </p><p>Transitioning from an office to remote is not going to be easy for a lot of companies. The reason for this is leaders took the human proximity, camaraderie, informal comms &amp; ‘water cooler moments’ for granted. </p><p>The majority of CEOs who ran office-based businesses before the pandemic and didn’t invest in their culture unknowingly relied on their office space environment to hold their unwritten culture together.”</p><cite><em>Bretton Putter (via <a rel="noreferrer noopener" href="https://twitter.com/BrettonPutter/status/1263829426258817025" target="_blank">Twitter</a>)</em></cite></blockquote>



<p>As human beings we abhor vacuums, particularly social ones. This is the reason why, in the face of non-deliberate culture, we are able to “fill in” …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</a></em></p>]]>
            </description>
            <link>https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817799</guid>
            <pubDate>Mon, 13 Jul 2020 06:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817638">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817638</guid>
            <pubDate>Mon, 13 Jul 2020 06:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Evolutionary Psychology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817470">thread link</a>) | @ghosthamlet
<br/>
July 12, 2020 | https://www.deepideas.net/introduction-to-evolutionary-psychology/ | <a href="https://web.archive.org/web/*/https://www.deepideas.net/introduction-to-evolutionary-psychology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				<div>
					


<div> <!-- start fusion sticky header wrapper -->
	<div>
		<div>
							<div data-margin-top="31px" data-margin-bottom="0px" data-margin-left="0px" data-margin-right="0px">
			<a href="https://www.deepideas.net/">

						<!-- standard logo -->
			<img src="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png" srcset="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png 1x" width="332" height="102" alt="deepideas.net Logo" data-retina_logo_url="">

			
					</a>
		
<div>
			<h3>
			a blog on cognitive science and artificial intelligence, dedicated to the deep thinkers of this world		</h3>
	</div>
</div>
								
			
					</div>
	</div>
	
</div> <!-- end fusion sticky header wrapper -->
				</div>
				
			</header>
						
			
		
				
			
			

						<main id="main">
				<div>

<section id="content">
			
	
					<article id="post-648">
						
														
						
																									<div>
				<p>Evolutionary psychology is an approach to understand human behavior that combines insights gained from evolutionary biology, the computational sciences and the study of ancestral living conditions. It has been put forward as an opposing view to what Tooby and Cosmides (1992) call the <em>Standard Social Science Model</em> (SSSM), which has dominated the social and behavioral sciences throughout most of the 20th century. According to the SSSM, the mental organization of adult human beings is not caused by human nature. Rather, humans acquire their mental organization almost entirely from their sociocultural and physical environment. Human beings, on this view, only have a minimal amount of innate impoverished drives (like hunger, thirst, sexual motivation, etc.) and, independently of these, a capacity to be socialized through learning.</p>
<p>A prominent argument given in favor of the SSSM is the fact that genetically determined behavior might be maladaptive due to changing environmental conditions, and therefore the mind evolved towards general-purpose and domain-general learning systems. On this view, the phenotype’s behavior is plastic and tailored toward maximizing individual fitness under changing environmental circumstances. The selective pressures of ancestral environments gave rise to this plasticity, but the concrete adaptive problems that have been faced in these environments play only a minor role in explaining the behavior of modern humans. This is the reason why many social scientists study human behavior in modern conditions more or less independently from their evolutionary history.</p>
<p>Evolutionary psychology, in contrast, holds that psychological mechanisms are evolved adaptations to ancestral adaptive problems. An analogy is drawn here between organs in the body and “cognitive programs” or “mental organs”: Analogous to how organs in the body evolved to solve a particular adaptive problem, e.g. digesting food, cognitive programs evolved to solve a particular adaptive information processing problem, e.g. predator/prey distinction, kin detection, language, etc.</p>
<p>In the following, we will break down the individual tenets of evolutionary psychology and review the arguments that are given in support of these tenets. Since not all tenets are shared by all evolutionary psychologists, we will focus here on the formulation given by Cosmides and Tooby (1987) and Tooby and Cosmides (2005). The tenets are not listed explicitly, but can be reconstructed implicitly from these texts. I will go through each tenet in turn and present a reconstruction of the arguments that motivate these tenets.</p>
<h3>Tenet 1: The brain evolved to be a computer that solves information processing problems.</h3>
<p>This tenet is motivated as follows: Environments pose adaptive information processing problems to organisms. Hence, the genes of organisms that successfully solve these information processing problems spread in the gene pool and such organisms are, by definition, computers.</p>
<p>This tenet, Tooby and Cosmides (2005, p. 31) argue, is shared by proponents of the SSSM. Even a domain-general learning mechanism would be an innate information processing mechanism that evolved at some point to solve adaptive problems. For example, operant conditioning presupposes an innate mechanism to alter the probability of behaviors based on their intrinsically reinforcing consequences (like food or pain). Similarly, classical conditioning presupposes innate unconditioned stimuli and a method to calculate contingencies. Consequently, Tooby and Cosmides (2005, p. 32) conclude that “learning is not an alternative explanation to the claim that natural selection shaped the behavior” and that “a behavior can be, at one and the same time, cultural, learned, and evolved”. This means that the commonly perceived controversy between innateness/evolvedness on the one hand and learnedness on the other is based on a false dichotomy. Rather, it is proposed, evolution created programs as learning mechanisms, and these mechanisms are a prerequisite for learning to be able to occur. The disagreement between the SSSM and evolutionary psychology, therefore, only regards the structure of the evolved learning mechanisms, not the question whether such learning mechanisms evolved at all.</p>
<p>When we accept the theory of evolution through natural selection, it arguably becomes theoretically impossible to deny that the brain evolved to be a computer that solves adaptive information processing problems – unless we claim that (A) evolution hasn’t found this path yet, (B) evolution cannot find this path in principle since it would lead through a fitness valley or (C) adaptive problems aren’t information processing problems and therefore a computer would not be the ideal solution. Discussing these possibilities would be beyond the scope of this introduction, so I am going to suppose (A), (B) and (C) to be false for the rest of this discussion. This leads us to accept this tenet.</p>
<h3>Tenet 2: The brain is not a “blank slate” domain-general fitness-maximizing machine.</h3>
<p>Cosmides and Tooby (1987, p. 47) and Tooby and Cosmides (2005, pp. 294- 299) argue that there is no domain-general success criterion that is correlated with fitness and, therefore, a domain-general mechanism would not be successful at actually maximizing fitness and could therefore not have evolved. This argument can be summarized as follows: If no domain-specific innate knowledge is present in the organism, then it can only acquire knowledge that can be inferred from perceptual inputs, without relying on innate perceptual heuristics. Similarly, it can learn behaviors only through trial and error learning, which would amount to generating random sequences of actions, observing the fitness outcome (e.g. the number of produced offspring) and then reinforcing or mitigating behaviors based on this outcome. Proposing instead that the mechanism could rely on perceptual cues like smell or taste as a proxy for expected fitness, they argue, amounts to “admitting domain-specific innate knowledge”.</p>
<p>However, when observing a certain positive or negative fitness outcome (like an increase or decrease in the produced offspring), it is virtually impossible to trace it back to the precise actions or sequences of actions that caused it, since virtually any action taken before in the organism’s life could have caused it. Furthermore, whether a sequence of action promotes fitness is highly context-sensitive. Thus, due to the resulting combinatorial explosion, behaviors cannot reliably be reinforced or mitigated and behavior stays more or less random. Therefore, an organism with adequate innate domain-specific knowledge, perceptual heuristics and perception-action patterns would have a fitness advantage over an organism that only has a domain-general fitness-maximizing mechanism, consequently triggering selection for organisms with these traits.</p>
<h3>Tenet 3:&nbsp;The brain executes innate, domain-specific, functionally isolable cognitive programs that generate particular behaviors in response to particular external or internal informational inputs. Most or even all of these programs evolved as a response to a particular adaptive information processing problem.</h3>
<p>It should be noted that it is not claimed that all cognitive programs generate behavior deterministically based on the current perceptual input. Rather, some of these programs exhibit what is commonly called <em>experience-dependent plasticity</em>: They are able to learn based on the input they receive throughout the organism’s development (Cosmides and Tooby, 1987, p. 284). For example, the language program learns to acquire the language of a person’s surrounding community. The programs, therefore, did not evolve to produce a certain kind of behavior, but they evolved to produce a mapping from current inputs and the sequence of inputs they received throughout development to behaviors. Different programs have different degrees of experience-dependent plasticity, depending on the fitness advantage that plasticity would provide over genetic determinism in the program’s adaptive domain.</p>
<p>In a similar fashion, programs are <em>experience-expectant</em>: They evolved to be able to develop only if they receive certain informational inputs at critical periods throughout development (Tooby and Cosmides, 2005, p. 34-35). This entails that a program’s innateness does not mean that it is present at birth – much like teeth are innate but not present at birth. Rather, a cognitive program can develop at any point in an organism’s life, depending on whether it is relevant at that point in life and whether the developmentally relevant informational inputs have been received. Tooby and Cosmides (2005, p. 35) stress that this developmentally relevant information consists not only of contingencies in physical laws and the behavior of other organisms, but also of the physical and cultural environment. The latter comprise a second inheritance system that co-evolves with the genes, and changes in these environments can lead to significant alterations in the operation of the cognitive programs, or even a failure of certain cognitive programs to develop.</p>
<p>It should also be noted that it is not claimed that the cognitive programs can&nbsp;only generate behavior according to their original adaptive function. For example, the language program, which arose as an adaptation for spoken language, can learn to acquire reading and writing (Tooby and Cosmides, 2005, p. 26). The ability to learn reading and writing is not an adaptation but a by-product of the adaptation for spoken language.</p>
<p>However, it is claimed that the …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepideas.net/introduction-to-evolutionary-psychology/">https://www.deepideas.net/introduction-to-evolutionary-psychology/</a></em></p>]]>
            </description>
            <link>https://www.deepideas.net/introduction-to-evolutionary-psychology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817470</guid>
            <pubDate>Mon, 13 Jul 2020 05:32:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Is Surprisingly Good as a Server Language]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 326 (<a href="https://news.ycombinator.com/item?id=23817464">thread link</a>) | @signa11
<br/>
July 12, 2020 | https://stu2b50.dev/posts/rust-is-surpris76171 | <a href="https://web.archive.org/web/*/https://stu2b50.dev/posts/rust-is-surpris76171">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
      <div id="main">
        

    

    <div>
        
<p>At some point, I got tired of my old static site generator setup for my blogs and other pages. It was annoying to ssh every time I wanted to make a modification, it was annoying to sftp or sshfs all my images, and so forth. And god forbid, if you ever wanted someone else to write something or make an edit, let me tell you, most people are not particularly happy when you tell him "hey, I'll make you a user on my server, give me your public key so you can ssh in".</p>
<p>I wanted something with a <em>little</em> more dynamism. </p>
<p>So that was the project: a small scope blog, where a few, already <em>trusted</em> users can make, edit, and post new pages in markdown (with a nice markdown editor courtesy of <a href="https://simplemde.com/">SimpleMDE</a>). Additionally, I want a built in jank verison of imgur so I can satisfy my need to be self sufficient without going crazy.</p>
<p>So while I could whip something up in an afternoon with Django, I could also experiment with other languages. The project is simple enough that I can't imagine being too limited by any language's ecosystem. And I've been itching to write something substansive in Rust...</p>
<h3>Which framework?</h3>
<p>The biggest framework is probably <code>actix-web</code>. But</p>
<ol>
<li>When I was scoping out my options months ago, actix-web's maintainer quit with a bunch of drama</li>
<li>At least from what I could tell reading the docs, it seems more suited to APIs rather than servers serving templated HTML</li>
<li>With the above, I wanted this to be a weekend project, not a weekly project, so the more batteries included the better</li>
<li>I really don't want to figure out which async library is considered better. And note that with each async library, comes its own ecosystem of libraries, which only work with that async library, so it's a pretty hard decision to reverse after you made it.</li>
</ol>
<p>So Rocket it is. </p>

<p>Something I didn't realize until I started scoping out this project is that on servers... the memory model is actually pretty simple! </p>
<p>Much of your state is just handled by your database. I <em>never</em> actually fought with the borrow checker. I never had to. For the most part, everything had exactly one owner, and exactly one lifetime: the function that's handling the request. </p>
<p>Rocket, too, has a surprising amount of "magic":</p>
<pre><code>#[get("/posts/&lt;slug&gt;/"]
pub fn post_view(slug: String) -&gt; Option&lt;Template&gt; {
    ...
		
    Some(Template::render("/posts/post", hashmap! { "post" =&gt; post}))
}
</code></pre>
<p>As opposed to Flask's</p>
<pre><code>@app.route("/posts/&lt;string:slug&gt;")
def post_view(slug):
    ...
		
    return render_template("posts/post.html", post=post)
</code></pre>
<p>Rust's macro system has really impressed me so far. Not only is there a shocking amount of "just works", but it's all statically typed and compiled.</p>
<p>The closest analogue to Rocket is flask + all the flask adjacent libraries (SQLAlchemy-flask, etc). Rocket, through the power of 3rd party integrations, comes with two template engines (handlebars, and Tera, which is basically Jinja2), database pooling support for quite a few ORMs/DB drivers, and more.</p>
<p>It's still at the point where you have to roll your own auth, though.</p>
<p>While I've heard comparisons to Django/Rails, it doesn't really seem like they're going that direction. Django/Rails purposefully put you, the developer, on the metaphorical rails, dictating best practices from everything from where the files go, to how you update your models and views. Rocket doesn't do that, and I'm not sure it should ever.</p>
<p>I also had, for the most part, the experience that "if it compiles, it works". Most of my runtime errors were in the templates, which incidentally is the only thing that's not statically typed. </p>
<p>I guess that's really what surprised me. For a lot of it, "it just works"! There's not a lot of boilerplate syntax, type inference keeps your functions clean, and I didn't write a <em>single</em> lifetime annotation at any point. My rust server really didn't look that different from my flask server, or my Django server, and honestly it looks cleaner than my Java server. All with no garbage collector or runtime.</p>

<p>Next, I'll talk about Diesel, which as far as I can see, is the most mature ORM available. While I do have my gripes, it's not really anything "objectively" bad. I suppose it's more on tradeoffs, and Diesel chooses to go light on the magic. </p>
<p>For one, it's annoying to make two structs for each table. You need one to represent the table, and one to insert with (with any autogenerated columns like the primary key removed). For instance, I have</p>
<pre><code>#[derive(Identifiable, Queryable, Associations, PartialEq, Debug, Serialize)]
#[belongs_to(BlogPosts, foreign_key="post_id")]
#[table_name = "tags"]
pub struct Tag {
    id: i32,
    tag_name: String,
    post_id: i32,
}

#[derive(Insertable)]
#[table_name = "tags"]
pub struct InsertTag {
    tag_name: String,
    post_id: i32
}
</code></pre>
<p>Additionally, while in some ORMs you write your table models, and the ORM generates your SQL migrations, in Diesel, you write your SQL migrations by hand, and the ORM generates a <code>schema.rs</code> file that contains the mappings. I actually don't mind that one too much.</p>
<p>Diesel also only supports parent-child relationships, and you have to be quite explicit. There's no magic field on your parent, that magically gives you a list of its children. No, you just have to write the query and call it. In some sense it's more like using a slightly fancier query builder.</p>
<p>Dipping down from that level of magic, it's not really a <em>bad</em> thing per se. By being explicit, you prevent users from believing too much in that magic, and shooting themselves in the foot, like N+1 selects. </p>
<p>But I'm not going to say it didn't slow me down quite a bit, either. And to be honest, writing joins was a humongous pain in the ass. Maybe that's how it should be, but maybe that also caused a generation of NoSQL databases. 🤷</p>

<p>Here's how you upload an image in flask</p>
<pre><code>@app.route('/images/upload')
def upload_file():
	files = request.files['file']
	if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
</code></pre>
<p>Here's the "simpler" example, while using a <em>third party library in addition</em> from abonader</p>
<p><a href="https://github.com/abonander/multipart/blob/master/examples/rocket.rs"><strong>See the whole thing here</strong></a></p>
<pre><code>#[post("/upload", data = "&lt;data&gt;")]
// signature requires the request to have a `Content-Type`
fn multipart_upload(cont_type: &amp;ContentType, data: Data) -&gt; Result&lt;Stream&lt;Cursor&lt;Vec&lt;u8&gt;&gt;&gt;, Custom&lt;String&gt;&gt; {
    // this and the next check can be implemented as a request guard but it seems like just
    // more boilerplate than necessary
    if !cont_type.is_form_data() {
        return Err(Custom(
            Status::BadRequest,
            "Content-Type not multipart/form-data".into()
        ));
    }

    let (_, boundary) = cont_type.params().find(|&amp;(k, _)| k == "boundary").ok_or_else(
            || Custom(
                Status::BadRequest,
                "`Content-Type: multipart/form-data` boundary param not provided".into()
            )
        )?;

    match process_upload(boundary, data) {
        Ok(resp) =&gt; Ok(Stream::from(Cursor::new(resp))),
        Err(err) =&gt; Err(Custom(Status::InternalServerError, err.to_string()))
    }
}

fn process_upload(boundary: &amp;str, data: Data) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {
    let mut out = Vec::new();

    // saves all fields, any field longer than 10kB goes to a temporary directory
    // Entries could implement FromData though that would give zero control over
    // how the files are saved; Multipart would be a good impl candidate though
    match Multipart::with_body(data.open(), boundary).save().temp() {
        Full(entries) =&gt; process_entries(entries, &amp;mut out)?,
        Partial(partial, reason) =&gt; {
            writeln!(out, "Request partially processed: {:?}", reason)?;
            if let Some(field) = partial.partial {
                writeln!(out, "Stopped on field: {:?}", field.source.headers)?;
            }

            process_entries(partial.entries, &amp;mut out)?
        },
        Error(e) =&gt; return Err(e),
    }

    Ok(out)
}
</code></pre>
<p>Now, to be fair, Rocket is in version 0.4.5. From <a href="https://github.com/SergioBenitez/Rocket/issues/106"><strong>this github issue</strong></a>, multipart form support is coming in 0.5.0. But it doesn't change the fact that right now, the current libraries are somewhat immature still. They lack some of the edge features, especially for more traditional web servers that serve templated HTML, as opposed to pure API servers, or an SPA. </p>
<hr>
<p>Rust's errors are quite good, usually. But that's before you get into, well, libraries that try to do a bit more. I ran into some... interesting error messages, mostly from macros in Rocket and Diesel. Take a look at this one, for instance.</p>
<pre><code>the trait bound `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32): diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not satisfied

the trait `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not implemented for `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32)`

help: the following implementations were found:
        &lt;(A, B, C, D, E, F, G, H, I) as diesel::Queryable&lt;(SA, SB, SC, SD, SE, SF, SG, SH, SI), __DB&gt;&gt;
note: required because of the requirements on the impl of `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stu2b50.dev/posts/rust-is-surpris76171">https://stu2b50.dev/posts/rust-is-surpris76171</a></em></p>]]>
            </description>
            <link>https://stu2b50.dev/posts/rust-is-surpris76171</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817464</guid>
            <pubDate>Mon, 13 Jul 2020 05:31:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The three levels of Hindu philosophy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817439">thread link</a>) | @paraschopra
<br/>
July 12, 2020 | https://invertedpassion.com/three-levels-of-hindu-philosophy/ | <a href="https://web.archive.org/web/*/https://invertedpassion.com/three-levels-of-hindu-philosophy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-511">
		<!-- .entry-header -->
	<div>
		
		
<p><strong>1/</strong> The first level related to the metaphysical and spiritual domain.</p>



<p>It says that Brahman is all that exists and our material world (Maya) comes from ignorance.</p>



<p>The Brahman is not a God. It is beyond any quality – it isn’t intelligent, good or bad. It just is.</p>



<p><strong>2/</strong> It also suggests that if we strip away all ignorance, we will discover that the self – the atman – is one and the same thing as the Brahman.</p>



<p>At its core, this level denies the duality of subject and object and says they both are the same.</p>



<p><strong>3/</strong> The second level has more religious connotations because, like all religions, its purpose is the stabilization of society.</p>



<p>The concept of Karma and Dharma ensures that society has net positive interactions. And the rituals and idol worship ensures everyone knows who is in the camp.</p>



<p><strong>4/</strong> This level ensures an ethical code exists and that it’s clear who all share that same ethical code.</p>



<p>The symbols – the idols, the chants, the rituals – take a spiritual dimension on their own, but these are subservient to the belief in one Brahman – the essence of the world.</p>



<p><strong>5/</strong> The third level is psychological – to give guidance to an individual on how to live his/her life.</p>



<p>The suggestion in <a href="https://invertedpassion.com/what-gita-teaches-us-and-what-it-doesnt/">Gita</a> that one must do work without an expectation of reward is towards minimizing psychological anguish.</p>



<p><strong>6/</strong> To reiterate, the three levels of Hindu philosophy are:</p>



<ul><li>METAPHYSICAL: <a href="https://en.wikipedia.org/wiki/Mah%C4%81v%C4%81kyas">Tat tvam asi.</a> You’re it [it = Brahman]</li><li>SOCIETAL: Rebirth, Karma, Dharma, and Rituals</li><li>PSYCHOLOGICAL: Expect no reward</li></ul>



<p><strong>7/</strong> Of course, everyone has their interpretation. Unlike Judeo-Christian religions, there are no definitive books on Hindusim.</p>



<p>Rather than a bug, I think it’s a feature.</p>



<p>It ceases to be a philosophy if you can’t interpret it on your own.</p>



<p><strong>8/</strong> There are some beautiful ideas in Hinduism, though I’m not sure I agree with all of them.</p>



<p>If you have your favorite ideas, let me know. I love diving deep into Indian philosophy.</p>



<p><em>This essay is a lightly-edited version of a <a href="https://twitter.com/paraschopra/status/1104658952061681665">Twitter thread I posted</a>.</em></p>



<p>Someone made an image out of the three levels:</p>



<figure><img src="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg" alt="" srcset="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg 756w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-221x300.jpg 221w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-768x1041.jpg 768w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-1134x1536.jpg 1134w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq.jpg 1338w" sizes="(max-width: 756px) 100vw, 756px"><figcaption>Made by <a href="https://twitter.com/nisacharan">@nishacharan</a></figcaption></figure>



<p><span><strong>Have an opinion on this essay?</strong></span> You can send your feedback on <a href="https://invertedpassion.com/cdn-cgi/l/email-protection#deaebfacbfadefe7e6e9f5b7aeb8bbbbbabcbfbdb59eb9b3bfb7b2f0bdb1b3">email</a> to me.


</p>



			</div><!-- .entry-content -->
						<!-- .entry-footer -->
		</article></div>]]>
            </description>
            <link>https://invertedpassion.com/three-levels-of-hindu-philosophy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817439</guid>
            <pubDate>Mon, 13 Jul 2020 05:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Butt Pomodoro – A butt triggered pomodoro timer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817401">thread link</a>) | @Abishek_Muthian
<br/>
July 12, 2020 | https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A need gap of <a href="https://needgap.com/problems/130-remind-me-to-take-break-when-working-from-home-wfh-activity" target="_blank">Remind me to take break when working from home</a> was recently posted. Forgetting to take regular breaks when immersed with work in front of a computer is a common problem, especially when working from home.</p><p>On the flip side, <a href="https://needgap.com/problems/30-getting-things-done-at-individual-level-productivity-taskmanagement" target="_blank">getting distracted from completing a task</a> is also a common problem.</p><h3 id="why-pomodoro">Why pomodoro?</h3><p><a href="https://en.wikipedia.org/wiki/Pomodoro_Technique" target="_blank">Pomodoro technique</a> is to work in 25 minutes intervals called pomodoro, taking 5 minutes break every pomodoro and taking a 30 minutes break after 4 pomodoros.</p><p>This helps in mitigating <a href="https://needgap.com/problems/93-focus-drift-cognitivescience-neuroscience" target="_blank">focus drift</a>, burn outs and enables us to complete our tasks.</p><h3 id="why-butt-triggered">Why butt triggered?</h3><p>There are no dearth of pomodoro timer based apps in the market, but they require manual trigger of the timer each time we are about to start a task, this is a huge overhead as stated by in the first problem statement.</p><p>I personally feel that the activity of constantly interacting with the pomodoro timer is counter-intuitive for productivity and so to address that it needs to be triggered seamlessly without any user action.</p><p>Most of us work with the computer while seated on a chair, I figured that triggering the pomodoro timer with a sensor under the seat would fulfil my goals.</p><h3 id="design-goals">Design goals</h3><h4 id="simple">Simple</h4><p>The solution should be simple enough to be easily reproducible by many, even by those without the technical know-how of the solution.</p><h4 id="portable">Portable</h4><p>Setup should be easily transportable to any chair, be it at home or office. Hence, facial recognition with machine learning based solution is not being considered.</p><h4 id="inexpensive">Inexpensive</h4><p>Components should be easily available and inexpensive.</p><h3 id="design-choices">Design choices</h3><h4 id="sensor">Sensor</h4><p>Sensor is needed to trigger the timer when I sit on the chair, basically to serve as a switch.</p><p>I started with a pressure sensor made with Velostat fabric, since its light weight and could seamlessly fit between the seat cushion and the chair. But the resistance varied too much in my test to serve as a reliable switch and I didn’t like the possibility conductive threads setting my ass on fire if they get shorted.</p><p><amp-accordion id="velostat-accordian" disable-session-states=""><section><h5>Click to see Velostat with Conductive Threads</h5><amp-img alt="Velostat with conductive thread" src="/images/Velostat_Conductive_Thread.jpg" width="3915" height="3813" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="trigger">Trigger</h4><p>Then I experimented with a standard 12mm momentary button switch on a 170 holes mini breadboard and it served the purpose well. Depending upon your chair, seat cushion and your weight; you might have to choose a button which works well for you.</p><p><amp-accordion id="button-accordian" disable-session-states=""><section><h5>Click to see Momentary Button</h5><amp-img alt="Button" src="/images/Momentary_Button.jpg" width="2863" height="3451" layout="responsive"></amp-img></section><section><h5>Click to see Mini Breadboard</h5><amp-img alt="Button" src="/images/Mini_Breadboard.jpg" width="1670" height="1365" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="microcontroller">Microcontroller</h4><p>Microcontroller is needed process the input signal from the button, compute the timers and send message to the notifications.</p><p>ESP8266 based NodeMCU is being used the microcontroller for this as it has WiFi for communication.</p><p><amp-accordion id="nodemcu-accordian" disable-session-states=""><section><h5>Click to see NodeMCU</h5><amp-img alt="NodeMCU" src="/images/ESP8266_NodeMCU.jpg" width="962" height="1451" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="power">Power</h4><p>I’m supplying 5V power over microUSB with 18650 power-bank to the NodeMCU.</p><p><amp-accordion id="powerbank-accordian" disable-session-states=""><section><h5>Click to see 18650 Power-Bank</h5><amp-img alt="18650 Power-Bank" src="/images/18650_Power-Bank.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><p><em>Note: The reliability of this power-bank is questionable as I’ve had failures, so I would suggest using a simple battery holder instead.</em></p><p><amp-accordion id="battery_holder-accordian" disable-session-states=""><section><h5>Click to see the setup with battery holder, terminals secured with solder, hot glue and tape</h5><amp-img alt="Butt Pomodoro with Battery Holder" src="/images/Butt_Pomodoro_Battery_Holder.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="computation">Computation</h4><p>My initial plan was to use the NodeMCU itself for computation as that’s what microcontrollers are used for, but stopping the timers at will was bit of a hassle with Arduino code on NodeMCU and decided to leverage the comfort of Go with <a href="https://gobot.io/documentation/platforms/esp8266/" target="_blank">Gobot</a> using Firmata firmware.</p><p>Gobot allows client-server architecture on IoT devices, so NodeMCU can be controlled remotely from a client. The main advantage of using Gobot is that it allows me to modify the code and test it without having to flash it on the NodeMCU each time. I’m running Gobot client on a Raspberry Pi 2 after flashing firmata server on NodeMCU.</p><p><em>Update: Starting and stopping timers with Gobot on NodeMCU within different Goroutines resulted in unnecessary race conditions, deadlocks hence I resorted to calculating elapsed time manually and simple flags to start the timers. I guess, this method could have been easily implemented directly on the NodeMCU with Arduino code, but due to other advantages of using Gobot I’m continuing with it.</em></p><h4 id="communication">Communication</h4><p>I’m using <a href="http://mqtt.org/" target="_blank">MQTT protocol</a> for communication between the devices. <a href="https://appcodelabs.com/introduction-to-iot-build-an-mqtt-server-using-raspberry-pi" target="_blank">A MQTT broker(server) runs on the Raspberry Pi</a> along with the Gobot client which acts as the MQTT publisher.</p><p><a href="https://play.google.com/store/apps/details?id=in.dc297.mqttclpro" target="_blank">MQTT Client android app</a> is the MQTT subscriber. <a href="https://play.google.com/store/apps/details?id=net.dinglisch.android.taskerm" target="_blank">Tasker android app</a> creates a notification when MQTT client receives the message, displays the notification via <a href="https://play.google.com/store/apps/details?id=com.joaomgcd.autonotification" target="_blank">Auto Notification Tasker plugin</a>(paid) and <a href="https://play.google.com/store/apps/details?id=com.rageconsulting.android.lightflow" target="_blank">Light Flow android app</a>(paid) reads out the notification message and creates custom LED light.</p><p>The notification is further received at my desktop smart clock, which is an old android wear smartwatch modified to receive latest Google Play services updates.</p><p><amp-accordion id="communication-accordian" disable-session-states=""><section><h5>Click to see MQTT Client</h5><amp-img alt="MQTT Client" src="/images/MQTT_Client.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Tasker profile</h5><amp-img alt="Tasker Profile" src="/images/Tasker-profile.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Notification Configuration</h5><amp-img alt="Auto Notification Configuration" src="/images/AutoNotification.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Light Flow Configuration</h5><amp-img alt="Light Flow Configuration" src="/images/LightFlow_configuration.jpg" width="1080" height="1920" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="circuit">Circuit</h4><p><amp-accordion id="circuit-accordian" disable-session-states=""><section><h5>Click to see the circuit diagram</h5><amp-img alt="Butt pomodoro circuit diagram" src="/images/Circuit.png" width="614" height="587" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="setup">Setup</h4><p>Here is the overview of the complete architecture and the setup.</p><p><amp-accordion id="architecture-accordian" disable-session-states=""><section><h5>Click to see the architecture diagram</h5><amp-img alt="Butt pomodoro architecture" src="/images/Butt_pomodoro_architecture.png" width="686" height="660" layout="responsive"></amp-img></section><section><h5>Click to see the Butt pomodoro setup</h5><amp-img alt="Butt pomodoro setup" src="/images/Butt_pomodoro_setup.jpg" width="6000" height="4000" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="code">Code</h4><p>Source code for the Gobot client is available over the <a href="https://github.com/heavyinfo/buttpomodoro" target="_blank">GitHub</a>.</p><h4 id="demo">Demo</h4><h5 id="demo-video-enable-audio">Demo Video (enable audio)</h5><p><amp-accordion id="demo_video-accordian" disable-session-states=""><section><h5>Click to see video from Twitter (Fast loading, requires loading of twitter script)</h5><amp-twitter width="375" height="472" layout="responsive" data-tweetid="1281998220118249472"></amp-twitter></section></amp-accordion></p><p><a href="https://abishekmuthian.com/videos/Butt-Pomodoro-Demo.mp4" target="_blank">Click to see video from local .mp4 source, Slow loading, Requires HTML5 video support</a></p><p><a href="https://abishekmuthian.com/videos/Butt_Pomodoro.webm" target="_blank">Click to see video from local .webm source, Slow loading, Requires HTML5 video support</a></p><h3 id="enhancements">Enhancements</h3><p>Further enhancements which could improve the usability of the Butt Pomodoro -</p><pre><code>* Using a PIR (Passive Infrared) sensor as a trigger for contact less butt detection.

* Using a Bluetooth LE based microcontoller to communicate directly with the smartphone for cutting down the separate compute module.

* Custom app record the data on completed pomodoros, incomplete pomodoros, breaks and displaying it with cool visualisations. Of course, for notifications as well.
</code></pre><p>Tweet to me <a href="https://twitter.com/heavyinfo" target="_blank">@heavyinfo</a>.</p><h3 id="business-plan">Business Plan</h3><p>Do you think Butt Pomodoro is something people want?</p><p>Would you like to build Butt Pomodoro as a commercial product? I have <a href="https://hitstartup.com/business-plans/" target="_blank">business plan at hitstartup</a> to help you get started.</p></div></div>]]>
            </description>
            <link>https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817401</guid>
            <pubDate>Mon, 13 Jul 2020 05:17:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting audio code from C to rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817392">thread link</a>) | @est31
<br/>
July 12, 2020 | https://jneem.github.io/nnnoiseless/ | <a href="https://web.archive.org/web/*/https://jneem.github.io/nnnoiseless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    <time datetime="2020-07-12T00:00:00+00:00">July 12, 2020</time>
  </header>
<p>I ported a C library to rust last week, and it went pretty smoothly. This is
the story, and <a href="https://github.com/jneem/nnnoiseless">here</a> is the repo.</p>

<p>The library in question is <a href="https://github.com/xiph/rnnoise">RNNoise</a>, a
library for removing noise from audio. It works well, it runs fast, and best of
all it has no knobs that you need to tune. There’s even a <a href="https://github.com/RustAudio/rnnoise-c">rust
binding</a>.</p>

<p>So why bother porting it?
Well, I need to patch it so that it would compile with MSVC, but my PR went
unnoticed for a month. I thought about maintaining my own fork, but it’s been
more than 10 years since I last wrote anything in C or C++.
And that’s how I ended up porting RNNoise to rust. It probably wasn’t the most
efficient use of my time, but I had fun and learned something.</p>

<p>There’s a lot of information out there about porting C to rust, but the most
useful resource for me was the fantastic
<a href="https://github.com/carols10cents/rust-out-your-c-talk">talk</a> by Carol (Nichols
|| Goulding). It lays out a simple process for porting one function
at a time: first, you set up the cargo to compile as a static library and you
set up the C build system to link that static library into the C library
(see the slides for the relevant Makefile and Cargo.toml snippets).
Then you can port one function at time: the C code goes like this:</p>

<div><div><pre><code><span>+</span><span>extern</span> <span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>);</span>
<span>+</span><span>void</span> <span>__celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>-</span><span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>{</span>
    <span>/* C body of _celt_lpc */</span>
<span>}</span>
</code></pre></div></div>

<p>and the rust code goes like this:</p>

<div><div><pre><code><span>+</span><span>#[no_mangle]</span>
<span>+</span><span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>_</span><span>celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span> <span>ac</span><span>:</span> <span>*</span><span>const</span> <span>f32</span><span>,</span> <span>p</span><span>:</span> <span>c_int</span><span>)</span> <span>{</span>
<span>+</span>    <span>unsafe</span> <span>{</span>
<span>+</span>        <span>let</span> <span>lpc_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts_mut</span><span>(</span><span>lpc</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span><span>);</span>
<span>+</span>        <span>let</span> <span>ac_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>ac</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span> <span>+</span> <span>1</span><span>);</span>
<span>+</span>        <span>rs_celt_lpc</span><span>(</span><span>lpc_slice</span><span>,</span> <span>ac_slice</span><span>);</span>
<span>+</span>    <span>}</span>
<span>+</span><span>}</span>
<span>+</span>
<span>+</span><span>fn</span> <span>rs_celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>],</span> <span>ac</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>])</span> <span>{</span>
<span>+</span><span>// rust body of celt_lpc</span>
<span>+</span><span>}</span>
</code></pre></div></div>

<p>If you’ve watched the talk (which you should), you might notice that this is a
tiny bit different from what they recommend: I’ve renamed the original C
function instead of deleting it. I found that this helped me narrow down porting
mistakes, because it made it easy to switch back and forth between the C and
rust implementations.</p>



<p>Most of the porting process was mechanical and easy. One of the less fun parts was
porting code involving C structs. RNNoise has structs that (when ported to
rust) look like this:</p>

<div><div><pre><code><span>#[repr(C)]</span>
<span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>*</span><span>const</span> <span>RnnModel</span><span>,</span>
    <span>// Various buffers, whose sizes are determined by some subfields of `model`.</span>
    <span>vad_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>An idomatic rust version might look something like</p>
<div><div><pre><code><span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>&amp;</span><span>'static</span> <span>RnnModel</span><span>,</span>
    <span>vad_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>
<p>but this isn’t layout-compatible with the original C version, and so I need to
stick with the original struct for as long as <code>RnnState</code> is being accessed by
both C and rust code. This increases the amount of <code>unsafe</code> sprinkled around
the rust code, and it was also the source of an annoying bug of the sort that I
thought I had left behind by moving to rust.</p>



<p>At some point during the porting process, my tests started failing in release mode,
but not in debug mode. Most likely some undefined behavior triggered by my amateurish
attempts at unsafe code, but I couldn’t quickly spot the problem and the prospect of
a more careful round of debugging didn’t spark a whole lot of joy. So I did something
that I never would have dared to do in my C/C++ days: I ignored the problem and kept
porting; after all, the tests were still working in debug mode. And sure enough,
a few more ported functions later and <code>rustc</code> found the problem for me: in a function
taking a <code>&amp;RnnState</code> parameter, I was modifying data in the <code>vad_gru_state</code> buffer.
Since I was using unsafe code, <code>rustc</code> didn’t complain at first. But once I ported
the <code>RnnState</code> struct to safe and idiomatic rust, the compiler flagged the problem
immediately.</p>



<p>After getting everything to 100% safe (if not particulary idiomatic) rust, it was time
to check whether performance had suffered.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark.svg" alt="initial benchmark"></p>

<p>Yes, apparently, by about 50%. The most obvious culprit was bounds checking: there was
a lot of indexing in the C code, and some of it wasn’t trivial to convert to a more
rust-friendly, iterator-based version. First priority was the neural network evaluation:</p>

<div><div><pre><code><span>let</span> <span>m</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 114.</span>
<span>let</span> <span>n</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 96.</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span><span>;</span>
    <span>for</span> <span>j</span> <span>in</span> <span>0</span><span>..</span><span>m</span> <span>{</span>
        <span>output</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>layer</span><span>.input_weights</span><span>[</span><span>j</span> <span>*</span> <span>n</span> <span>+</span> <span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>*</span> <span>input</span><span>[</span><span>j</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>I can already see you shaking your head. I’m doing naive matrix-vector multiplication
with a 100x100ish matrix in
<a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">column-major format</a>?
Not only is this costing me bounds checks, it’s terrible for memory locality.
Swapping the weights storage from column- to row-major order only made things
about 1.5% faster, but more importantly it made the whole thing iterator-friendly.
Converting to zips and sums bought another 15%, leaving me only about 25-30% slower
than the C code.</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span>
        <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>+</span> 
        <span>layer</span><span>.input_weights</span><span>[(</span><span>i</span> <span>*</span> <span>m</span><span>)</span><span>..</span><span>((</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>*</span> <span>m</span><span>)]</span>
            <span>.iter</span><span>()</span>
            <span>.zip</span><span>(</span><span>input</span><span>)</span>
            <span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span>
            <span>.sum</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>For my next optimization opportunity, I moved on to the function
that
computes <a href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlations</a>.
The un-optimized version of this function looks like</p>

<div><div><pre><code><span>fn</span> <span>pitch_xcorr</span><span>(</span><span>xs</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>ys</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>xcorr</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>])</span> <span>{</span>
    <span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>()</span> <span>{</span>
        <span>xcorr</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>&amp;</span><span>ys</span><span>[</span><span>i</span><span>..</span><span>])</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>();</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>but the C code contained a massive, manually-unrolled version. I’d skipped
it while porting, but maybe I’d gain something from porting it over. Here’s
an abbreviated version of the optimized function, assuming that all
lengths are a multiple of 4 (the real code also handles the case that they aren’t).</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>(</span><span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>())</span><span>.step_by</span><span>(</span><span>4</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>c0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>let</span> <span>mut</span> <span>y0</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>0</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y1</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y2</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>2</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y3</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>3</span><span>];</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>[(</span><span>i</span> <span>+</span> <span>4</span><span>)</span><span>..</span><span>]</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>

        <span>y0</span> <span>=</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>

        <span>y1</span> <span>=</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>

        <span>y2</span> <span>=</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>

        <span>y3</span> <span>=</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Basically, both inner and outer loops have been unrolled four times, and I’ve
exploited the inner loop’s unrolling to optimize the memory access pattern.
Thanks to the amazing <a href="https://github.com/gnzlbg/cargo-asm"><code>cargo asm</code></a>, I
can happily report that there’s no bounds-checking in the inner loop and that
all the arithmetic has been <a href="https://en.wikipedia.org/wiki/Automatic_vectorization">auto-vectorized</a>
to work four <code>f32</code>s at a time. (Maybe it would get even faster if I unrolled 8 times and
compiled with AVX enabled; I haven’t tried that yet.)</p>

<p>This change more than doubled the speed of <code>pitch_xcorr</code>, and gained me about 10% overall.
More importantly, it showed me how to coerce the compiler into auto-vectorizing something
that it hadn’t auto-vectorized before. I went back to the neural network code and
replaced things like</p>

<div><div><pre><code><span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>ys</span><span>)</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>()</span>
</code></pre></div></div>

<p>with things like</p>

<div><div><pre><code><span>{</span>
    <span>let</span> <span>mut</span> <span>sum0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>sum0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>sum1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>sum2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>sum3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
    <span>sum0</span> <span>+</span> <span>sum1</span> <span>+</span> <span>sum2</span> <span>+</span> <span>sum3</span>
<span>}</span>
</code></pre></div></div>

<p>for another 20% improvement.</p>

<p>Current score: the rust version (still 100% safe) is about 15% faster, and there’s probably plenty more
still on the table.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark_after.svg" alt="final benchmark"></p>

<p>The performance lesson I learned from this is that bounds checking can be expensive in numerical code
and iterator-style code can help a bit, but if you really want faster numerical code then you need
to write in a style that the auto-vectorizer likes. (Or you could use the <a href="https://doc.rust-lang.org/core/arch/index.html">SIMD intrinsics</a>
directly, but that’s another story.)</p>



<p>Like I wrote above, it’s been a while since I did any C/C++, and because of that I’ve started to take tools
like cargo for granted. This little porting project brought back some memories, mostly because about half of the
code in RNNoise was actually “vendored” from <a href="https://gitlab.xiph.org/xiph/opus">opus</a>. I put “vendored”
in quotes because I usually think of vendoring as involving a subdirectory (maybe even a git submodule if
I’m lucky) with its own build artifacts. That’s not what’s going on here, though; I’m just talking about files
that were copied from the source directory of one project to the source directory of another, complete with
never-used functions and never-def’ed ifdefs. The thing is, though, that I understand exactly why they did it:
it’s by far the easiest way to share code between C projects. So I just want to finish by saying a big “thank you”
to <code>cargo</code> and <code>crates.io</code> for making me not have to deal with C dependency management any more.</p>


  
  
</article></div>]]>
            </description>
            <link>https://jneem.github.io/nnnoiseless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817392</guid>
            <pubDate>Mon, 13 Jul 2020 05:14:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Artificial Neural Networks Closer to Animal Brains]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23817347">thread link</a>) | @hardmaru
<br/>
July 12, 2020 | https://maraoz.com/2020/07/12/brains-vs-anns/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/12/brains-vs-anns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p><img src="https://maraoz.com/img/brains-vs-anns/cover.jpg"></p>

<p>Lately, I’ve been thinking and reading a lot about consciousness and how the human mind works. A question that emerges all the time is whether machines can <a href="https://en.wikipedia.org/wiki/Turing_test">emulate human thought</a>. An even more interesting one is whether consciousness (a subjective experience) can arise from a machine, but I’ll leave that discussion for a future post (I’ll need ~20 more years to think about that before I can write about it).</p>

<p>So, how far are we from _behaviorally _imitating a human? Truth is, we achieved a lot in the past 5 years (see <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a>, <a href="https://openai.com/blog/better-language-models/">OpenGPT-2</a>, <a href="https://openai.com/blog/jukebox/">OpenAI Jukebox</a>, <a href="https://en.wikipedia.org/wiki/Tesla_Autopilot">Tesla Autopilot</a>, <a href="https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning">Alphastar</a>, <a href="https://openai.com/blog/openai-five-defeats-dota-2-world-champions/">OpenAI Dota2 Team</a>, <a href="https://openai.com/blog/openai-api/">OpenAI API</a>), but we’re still quite not there. My hunch is that we still can learn a lot from biology’s state of the art. I’ve done some research on differences in how human brains work and how we emulate them using deep neural networks, and what follows is a summary of what I’ve found (and some new ideas).</p>

<figure>
  <img src="https://maraoz.com/img/brains-vs-anns/image1.png">
  <figcaption>
    I find it encouraging that John Carmack is studying human brains for his AI research. <a href="https://twitter.com/ID_AA_Carmack/status/1280693213549002752">Source</a>.
  </figcaption>
</figure>

<h2 id="morphology">Morphology</h2>

<p>The most surprising difference between artificial and human brains is how <em>sequential</em> our artificial neural networks (ANN) are, compared to the richly interconnected biological counterparts.</p>

<p>I’m always amazed by the sheer amount of layers that are stacked on top of each other <a href="https://jalammar.github.io/illustrated-gpt2/">in the latest deep learning models</a>. The largest GPT-3 model (with 175B parameters) uses 96 attention layers, each with 96x 128-dimension heads. <a href="https://arxiv.org/pdf/2005.14165.pdf">Their paper</a> shows that language model performance scales as a power-law with model size.</p>

<p>However, this assumes the size of the network can only increase by adding more layers, making it “deeper”. Using layers enables for great performance in training via <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">backpropagation/ADAM</a>, but I think the current mostly-sequential approach to scaling ANNs is limiting. Some ideas:</p>

<h3 id="wide-vs-deep-neural-networks">Wide (vs. Deep) Neural Networks</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image8.png">
<img src="https://maraoz.com/img/brains-vs-anns/image3.png"></p>

<p>A promising approach is exploring other kinds of architectures, where the concept of “layer” is forgotten, and networks are built more freely (with connections being modelled at the neuron level, and allowing for loops and more complex topologies). This <a href="https://en.wikipedia.org/wiki/Boltzmann_machine">has been somewhat explored in the past</a>, but I haven’t seen recent studies where today’s computing power is thrown at such architectures. Additionally, <a href="https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies">Ken Stanley’s NEAT (2002)</a> and derivatives are a very promising way of finding new topologies via evolution.</p>

<h3 id="neural-grids">Neural Grids</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image6.png"></p>

<p>Another idea worth exploring: grid-like structures where each cell communicates only with its neighbors. In this neural net model, potential is not only passed forward, but also “upward” and “downward”, or even diagonally. This would emulate more closely, I think, a real brain’s connectivity. A related approach is <a href="https://www.mitpressjournals.org/doi/abs/10.1162/artl.2009.15.2.15202">Hypercube-based NEAT (2009)</a>, which allows exploiting the task’s geometry by mapping its regularities onto the topology of the network.</p>

<h3 id="artificial-cortical-columns">Artificial Cortical Columns</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image9.png">
<img src="https://maraoz.com/img/brains-vs-anns/image5.png"></p>

<p>Human’s brain neocortex seems to have a surprisingly self-repeating pattern, called <a href="https://youtu.be/x2mYTaJPVnc?t=98">cortical columns</a>. Each column can be thought of as a reusable ~110 neuron module that appears (with variations) across neocortex areas associated with such different functions as vision, motor control, auditory perception, decision-making, planning, etc. <a href="https://numenta.com/neuroscience-research/cortical-columns/">Studying these structures</a> and applying similar concepts/topologies to ANNs seems like a promising approach. Cortical columns provide amazingly generic hierarchical information processing capabilities, feedback mechanisms, and layered communication with other parts of the brain.</p>

<h3 id="generative-architectures-arising-from-growth">Generative architectures arising from growth</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image10.png"></p>

<p>What if neural net architecture is determined by a generative / procedural algorithm on runtime, instead of being defined by researchers? The seed could be random or evolved through genetic algorithms too. I think that somehow mimicking <a href="https://www.youtube.com/watch?v=BtLyik7oAxc&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=4">neurulation of human embryos</a> via simple models could lead to finding better-performing architectures. Human brains grow into existence, and maybe that matters for high-level intelligence.</p>

<h2 id="function">Function</h2>

<h3 id="evolve-first-learn-later">Evolve first, Learn later.</h3>

<p>Some techniques use <a href="https://www.nature.com/articles/s42256-018-0006-z">neuroevolution used to automate network design</a> or <a href="https://blog.otoro.net/2017/11/12/evolving-stable-strategies/">evolutionary strategies finding network weights instead of gradient descent</a>. It’d be interesting to see hybrid approaches where network structure is evolved and <em>later</em> allowed to learn in an environment (like humans!). Additionally, as I learnt from <a href="https://www.nature.com/articles/s41467-019-11786-6">this fascinating paper by Tony Zador</a> (2019), “A large component of an animal’s behavioral repertoire is not the result of supervised or unsupervised learning, but rather of behavior programs already present at birth”. Learning is actually one of such behaviors, so… shouldn’t researchers be focusing more on optimizing the lower-level mechanism of evolution instead of polishing our “hand-crafted” learning algorithms and architectures?</p>

<p>On a similar ‘meta-learning’ vein, the comically named <a href="http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf">Learning to learn by gradient descent by gradient descent</a> (2016) paper shows that you can train a network to optimize other networks, and they perform better than hand-crafted learning algorithms like <a href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c">ADAM</a> and <a href="https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a">RMSProp</a>.</p>

<h3 id="continuous-vs-discrete-neuron-firing">Continuous (vs. discrete) neuron firing</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image4.png"></p>

<p>Instead of processing inputs in discrete events, our networks could ‘stare’ at inputs for a couple iterations, and neurons can ‘store-up’ potential until they fire. This aims to mimic how we humans can look at something we don’t understand, but after a couple of seconds we “get it”. This could also enable the emergence of “memories” in the form of stored potential, too, analogous to the hidden state vector of LSTMs. Check out <a href="https://www.youtube.com/watch?v=lddzHEtu934">Gabriel Kreiman’s related work (2018)</a> on improving object detection in occluded or distorted conditions. Regardless of the specific implementations mentioned above, biological brains clearly have a temporal dimension (for example, <a href="https://www.youtube.com/watch?v=aFrG7KdjUOs&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=32">neurons in the visual motion MT area respond to direction of motion</a>), which we need to understand better to inform construction of artificial ones. Another interesting time-related property of biological brains is <a href="https://youtu.be/fki7AmLma_I?t=450">the difference between tonic vs bursting modes of neuron firing</a>.</p>

<h3 id="connecting-functional-building-blocks">Connecting functional building blocks</h3>

<p>Animal brains are surprisingly pre-wired and connected since birth, and it’s still not clear in general which behaviors are learned through experience and which are innate. Moreover, a big field of study in neuroscience is understanding how the human brain is wired, mostly via <a href="https://en.wikipedia.org/wiki/Tractography">diffusion tractography</a>, and in some cases <a href="https://youtu.be/KFfaBoDANNI?t=134">it’s been shown that connectivity can predict function</a>. However, the fascinating <a href="https://www.youtube.com/watch?v=8Bvblav-BQk&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=65">‘rewired ferrets’ experiments</a> showed that training input also conditions function strongly (newborn ferrets with auditory cortex rewired to receive visual input still learn to see). This implies that animal brains have a very optimized initial configuration, but also the flexibility to adapt to structural damages or drastical environmental condition changes.</p>

<p>Many well-performing techniques simply stack two architectures that work for two separate domains (eg: CNN visual embedder and LSTM language model) and re-train them for a new combined task (eg: image captioning).</p>

<p><img src="https://maraoz.com/img/brains-vs-anns/image7.png">
<img src="https://maraoz.com/img/brains-vs-anns/image2.png"></p>

<p>I suggest trying to mimic what we know today of how the human brain is wired (from <a href="http://www.humanconnectomeproject.org/">the Human Connectome Project</a>, for example), and plugging in some state-of-the-art modules for vision, language, and audio-processing.</p>

<h3 id="slow-and-data-light-learning">Slow and Data-Light Learning</h3>

<p>Humans seem to learn slowly (in real time, it takes a human ~2 years to learn a language at a basic level, and ~18 years to learn advanced level language usage or complex language tasks like translation) but with few examples. Machines, on the other hand, learn very fast (in the order of weeks to achieve state of the art in some tasks) but are very data-hungry. Some techniques require less training data but might take longer to train, like <a href="https://medium.com/@SmartLabAI/a-brief-overview-of-imitation-learning-8a8a75c44a9c">Imitation Learning</a>, <a href="https://openai.com/blog/competitive-self-play/">Competitive Self-Play</a>, and <a href="https://arxiv.org/abs/2005.11212">Symbolic Pregressions (2020)</a> and could be key to getting closer to human intelligence.</p>

<h3 id="intermixing-learning-techniques">Intermixing Learning Techniques</h3>

<p>A combination of learning strategies could be necessary for human-level intelligence, as Yann LeCun suggests with his cake analogy: “If intelligence is a cake, the bulk of the cake is <a href="https://ai.stackexchange.com/a/10624">self-supervised learning</a>, the icing on the cake is <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, and the cherry on the cake is <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>.”</p>

<p>Humans train by learning from others (supervised learning) <em>and</em> experimenting on our own (unsupervised/self-supervised learning). For example, a chess student first talks to a teacher, then plays some games. They wouldn’t go to a chess tournament after just talking to a teacher or playing games alone. Can we combine/emulate these kinds of training efficiently in ML too?</p>

<h2 id="final-words--further-studying">Final words &amp; further studying</h2>

<p>What do you think of these approaches? Have you actually seen any of these used in the wild (with success or otherwise)? Which do you think may have merits? Let me know if you do some experiments to try them out.</p>

<p>If you’ve been intrigued by the potential of imitating biological brains, here are some up-to-date resources to dig deeper, in order of relevance:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=i1pdQjdAndc&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0">Nancy Kanwisher’s The Human Brain course on YouTube</a> (2018)</li>
  <li><a href="https://www.youtube.com/watch?v=8-KF0rnhKTU&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=2">Ninja Nerd Lectures on Embryology</a> (2019)</li>
  <li><a href="https://www.nature.com/articles/s41467-019-11786-6">A critique of pure learning and what artificial neural networks can learn from animal brains by Anthony M. Zador</a> (2019)</li>
  <li><a href="https://www.youtube.com/watch?v=pkJkHB_c3nA">AI for physics &amp; physics for AI by Max Tegmark</a> (2020)</li>
  <li><a href="https://www.youtube.com/watch?v=x2mYTaJPVnc">Brains Explained video on cortical columns</a> (2017)</li>
  <li><a href="https://www.youtube.com/watch?v=h0InlY2WKc0">Deciphering Brain Codes to Build Smarter AI by Gabriel Kreiman</a> (2020)</li>
</ul>

<p><em>Thanks to Javi Silveira, <a href="https://twitter.com/hardmaru">David Ha (@hardmaru)</a>, <a href="https://twitter.com/alcuadrado">Pato Palladino (@alcuadrado)</a> and <a href="https://twitter.com/itsladywhite">Lady White (@itsladywhite)</a> for providing feedback and pointers.</em></p>

<p><em>Image by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">David Clode on Unsplash</a>.</em></p>


  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/12/brains-vs-anns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817347</guid>
            <pubDate>Mon, 13 Jul 2020 05:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$15 HDMI Capture Card Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817119">thread link</a>) | @rubatuga
<br/>
July 12, 2020 | https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><br>
<video src="https://www.naut.ca/videos/smash60fps.mp4" poster="https://www.naut.ca/videos/smash60fps.jpg" preload="none" controls="" playsinline=""></video>

<p>Above is a sample of 60fps Super Smash Bros Ultimate gameplay (I'm a Jigglypuff main) recorded with the $15 HDMI Capture Card and OBS. This card has been making the rounds last month on <a href="https://twitter.com/Ascii211/status/1268631069051453448">Twitter</a>, as well as on <a href="https://www.youtube.com/watch?v=daS5RHVAl2U">YouTube</a>, mainly due to its low, low price of $15 USD. I've decided to get one myself and take a look. The chipset contained in the card is the MacroSilicon MS2109. Here is the review, as well as a discussion of the potential use-cases.</p>
<h3 id="operatingsystem">Operating System</h3>
<p>This card, surprisingly enough, works on Windows, macOS and Linux! This is because it implements the UVC standard, a USB device that is OS agnostic. Getting it working on Linux is a bit of a hassle, but you can find out how <a href="https://bigl.es/friday-fun-10-hdmi-to-usb-capture/">here</a>.</p>
<p>I noticed that using the capture card on Linux or macOS resulted in significantly more framedrops and synchronization issues, when compared to Windows (although the macOS issues might be due to weak CPU). If you are okay with slightly choppy or stuttery recordings, then feel free to use the card on macOS or Linux. The Windows UVC driver captures more frames, and has the most options of the three. Most of the guide will be focusing on the Windows driver. The controls that are listed in OBS for each operating system are shown below.<br>
<img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-7.13.22-PM.jpg" alt="Screen-Shot-2020-07-09-at-7.13.22-PM"></p>
<h3 id="yuy2vsmjpeg">YUY2 vs MJPEG</h3>
<p>Windows and Linux both support the YUY2 and MJPEG video format, while macOS only supports MJPEG. YUY2 in this context refers to an almost uncompressed form of data (except for colour information), while MJPEG uses lossy JPEG compression on every frame. This means that YUY2 provides a cleaner image with no compression artifacts, while MJPEG has a noisier and blockier image. Compare the two capture formats below:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.33.23-AM.png" alt="Screen-Shot-2020-07-09-at-12.33.23-AM"></p>
<p>As you can see MJPEG has degraded the image data, which is necessary to compress each frame to a small size. Only MJPEG can achieve high framerates with this card because the interface it uses, USB 2.0, caps out around 50 MB/s. For reference, a YUY2 1280x720 60fps signal would exceed 100 MB/s. If you want a card that supports a 60fps YUY2 signal, you can expect to pay in the range of hundreds of dollars.</p>
<p>Both the YUY2 and MJPEG video formats from this card use something called <a href="https://en.wikipedia.org/wiki/Chroma_subsampling">chroma subsampling</a>, a data saving trick that takes advantage of the human eye's decreased colour resolution. It essentially deletes colour data, while keeping brightness data intact. I tested both formats, and they are outputting a 4:2:2 signal (50% of the colour data is deleted). You can see that the horizontal axis changes colour at 2 pixel boundaries, while the vertical axis changes at 1 pixel boundaries.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.32.56-AM.png" alt="Screen-Shot-2020-07-09-at-12.32.56-AM"></p>
<h3 id="resolutionandframerate">Resolution and Framerate</h3>
<p>A wide variety of resolutions and framerates are supported on the input side of the device. It even supports input at 4K 60fps! From the NVIDIA Control Panel, here is an abridged list of the resolutions and framerates supported on the <strong>input side</strong>:</p>
<pre><code>4K    60,59,50,30,29,25,24,23Hz
1080p 60,59,50Hz
720p  60,59,50Hz
576p  50Hz
480p  60,59Hz
PC    60Hz
</code></pre>
<p>To clarify, just because this card can accept or capture a 4K signal, does not mean that it can send the full signal to your computer. This card contains a scaler, which scales the image down (or up, depending on the input) in resolution before it is sent. With reference to the OBS properties window, here is an abridged list of the resolutions and max framerates as seen by my Windows PC:</p>
<pre><code>1920x1080 MJPEG:30fps, YUY2:5fps
1600x1200 MJPEG:30fps, YUY2:5fps
1360x768  MJPEG:30fps, YUY2:?
1280x960  MJPEG:50fps, YUY2:?
1280x720  MJPEG:60fps, YUY2:10fps
1024x768  MJPEG:60fps, YUY2:10fps
800x600   MJPEG:60fps, YUY2:20fps
720x480   MJPEG:60fps, YUY2:30fps
</code></pre>
<p>Each resolution dictates a maximum framerate for the device, limited by the bandwidth of the USB interface. To summarize, this card supports an output of 1920x1080 30fps and 1280x720 60fps with the MJPEG format.</p>
<h3 id="resolutionandframeratecaveats">Resolution and Framerate Caveats</h3>
<p>First I'll talk about framerate. I noticed that recording or streaming from the card at 60fps tends to repeat or skip a frame every few seconds, even with buffering on. Make sure to keep buffering on, otherwise you will lose frames at 30fps as well. I have confirmed this by recording videos in OBS and analyzing them frame by frame.</p>
<p>If you want virtually perfect frame capture at both 720p and 1080p, you should use 30fps with buffering!</p>
<p>Also, you may notice that there are 29.97fps and 59.94fps options in OBS. Only use these if you are absolutely sure that your device needs these values. You will likely run into desynchronization issues if you accidentally use these framerates.</p>
<p>Next, when I tested the 1920x1080 capture, I was shocked by how blurry it was. It turns out that this card doesn't actually do true 1080p! Here's a screenshot of Wikipedia, compared to what was captured at 1920x1080.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-2.48.49-AM.png" alt="Screen-Shot-2020-07-09-at-2.48.49-AM"></p>
<p>It looks like the card is capturing the vertical resolution fine, but the horizontal resolution is a soft mess. I tried out 1280x720, and everything looked crisp and fine, leading me to suspect that the card was capturing internally at a resolution of 1280 columns. I ended up using display calibration images from <a href="http://www.lagom.nl/lcd-test/sharpness.php">Lagom LCD</a> to see how the pixels in the capture were behaving. Right click the following image and choose Open/View Image for a better view.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-3.05.56-AM.png" alt="Screen-Shot-2020-07-09-at-3.05.56-AM"></p>
<p>Using the reference on the left, we can see that 1280x720 has correct vertical and horizontal resolution. 1360x768 and 1920x1080 also have correct vertical resolution, but the columns are turning grey. This is because adjacent white and black pixels from the high input resolution are merged into a lower resolution, i.e. from 1920 columns into 1280 columns. If you also noticed that pixel columns are brighter than the rows, I will be talking about that in the next section.</p>
<p>As a quick aside, everything above was for progressive video input. Interestingly, this card also supports an input of 1080i/interlaced video, which I tested with macOS and my Canon 600D camera. Using 1080i was absolutely horrible for desktop recording, since the card uses a brainless deinterlacing algorithm that halves the vertical resolution to 540. Yes, it actually looks that bad. As for my camera, it was decent, but the edges were kind of funny.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.01.51-AM.png" alt="Screen-Shot-2020-07-09-at-5.01.51-AM"></p>
<h3 id="imageaccuracycaveats">Image Accuracy Caveats</h3>
<p>This card needs "Color Range" set to "Full" in the OBS Capture Card Properties. Any devices that are connected to the card input need to have their HDMI "Range" set to "Limited". This is the only correct combination, otherwise highlights and shadows in the video are clipped. The following shows the effects of the device range options.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.53.19-PM.png" alt="Screen-Shot-2020-07-09-at-5.53.19-PM"></p>
<p>As you might have noticed from the previous section, the 1280x720 capture is brightening the columns. This indicates that the card is performing image sharpening only in the horizontal direction. You can find evidence of this type of sharpening wherever there are sharp edges:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.21.58-AM.png" alt="Screen-Shot-2020-07-09-at-5.21.58-AM"></p>
<p>This is a bad feature, as all image sharpening should be done after the capture. Fortunately, there is a way to get around this for 1280x720 content. Simply set your device to 1280x720, and then capture at 1920x1080. The image loses some clarity in brightness changes, due to the unnecessary resize, but all the sharpening has disappeared! Furthermore, since we are receiving 1920x1080 data, we now have better colour resolution as well, close to 4:3:3 chroma subsampling.</p>
<p>The 1920x1080 MJPEG capture also has significantly less compression artifacts than the 1280x720 MJPEG capture, which is probably due to different framerate support. From the image below, you can see that the 1080p capture is the winner all around (sharpening was applied post-capture for comparison with 720p).</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.25.44-PM.png" alt="Screen-Shot-2020-07-09-at-5.25.44-PM"></p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>
<p>If you are capturing slower gameplay, i.e. only 30fps, set your device to 1920x1080 and then capture at 1920x1080. This provides the most brightness and colour resolution at 30fps.</p>
</li>
<li>
<p>If you have 1280x720 content, capture at 1920x1080. This will result in the least amount of sharpening and MJPEG artifacts.</p>
</li>
<li>
<p>If you are capturing a desktop screen or anything with thin lines and pixels, then set your device to 1280x720 and then capture at 1280x720.</p>
</li>
<li>
<p>If you need 60fps content, i.e. for gaming, then set your device to 1920x1080 and then capture at 1280x720. This disables sharpening. The sample at the beginning of the article was encoded with "x264" at the "veryfast" setting.</p>
</li>
</ul>
<p>Warning: if you see a listing for a $20 USD capture card that claims to support USB 3.0 and 1080p 60fps, it's a scam. I've already bought two of them from Amazon and eBay, and had to return both because they turned out to be a repackaging of the product I just reviewed!</p>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817119</guid>
            <pubDate>Mon, 13 Jul 2020 04:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 in schoolchildren – A comparison between Finland and Sweden [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 93 (<a href="https://news.ycombinator.com/item?id=23816709">thread link</a>) | @mrfusion
<br/>
July 12, 2020 | https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf | <a href="https://web.archive.org/web/*/https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816709</guid>
            <pubDate>Mon, 13 Jul 2020 02:50:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Features are a better abstraction than issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816682">thread link</a>) | @gauthamshankar
<br/>
July 12, 2020 | https://zepel.io/blog/how-issue-tracking-hurts-development/ | <a href="https://web.archive.org/web/*/https://zepel.io/blog/how-issue-tracking-hurts-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>The short answer is yes. Let me explain.</p><p>I’ve been working with developers and designers my entire life. </p><p>I’ve built a couple of products, worked at a young startup, and I’m now at Zepel helping development teams build better software.</p><p>I’ve spoken to 1000+ development teams while at Zepel alone. <strong>And it's evident that the way we build products is broken.</strong></p><p>There’s so much disconnect between how you and I talk about building products and how our teams actually build them.</p><p>For all the talk of scrum and agile and getting feedback quickly, there’s so much that’s broken in how we act on the feedback and build the feature.</p><p>Teams spend so much time and effort getting a deeper understanding of customers’ needs. And yet distil everything down to a simple two-line ticket and a couple of lines of markdown description.</p><p>This is hurting your developers. And it’s hurting your business.</p><blockquote>Nothing is more frustrating than having to understand what an entire feature should or shouldn’t do from a two-line ticket filled with ten bullet points of acceptance criteria.</blockquote><p><em>*Here are five prioritized tickets for the upcoming sprint. We have to ship them on time!*</em></p><p>On the other hand, you have teams who are able to build top quality software. They’re the ones who can concentrate on the fine implementation details without losing focus on the broader purpose of the feature as a whole.</p><p>Everyone wants to get to that level. But instead, teams do the exact opposite.</p><p><strong>Teams think in issues and tickets, instead of the feature as a system.</strong></p><hr><h2 id="development-teams-are-not-ticket-movers-">Development teams are not ticket movers!</h2><p>Today, everything is about moving a ticket from “Todo” to “Done” as quick as possible. And watching <a href="https://zepel.io/agile/reports/burndown/">burndown charts</a>. And customizing the tool to the extent that the developer only views a single ticket.</p><p><em>*“What’s the velocity of our team?” is simply another way of asking how quickly can my team move an issue from “Todo” to “Done”.*</em></p><p>Pieces of that stuff are important for productivity and shipping on time.</p><p>But seriously, how is your team supposed to ship anything of value if you narrow their focus down to the smallest unit of work without any context of why it’s needed or how it connects to the whole feature?!</p><p>Overall, we’ve lost our way. Product development today has become more about checking items off a list as quickly as possible. </p><p><strong>It isn’t enough to write multiple user stories and share a Figma link if you want to ship quality software.</strong></p><hr><h2 id="how-software-product-teams-really-build-software-together">How software product teams really build software together</h2><p>Development teams build better software together when they have the complete context of what and why something is being built.</p><p>To achieve this, the foundational elements need to change.</p><p>And it starts with getting the right abstractions and naming conventions.</p><p><strong>The names you choose determine the perception and the quality of conversations you have. </strong>It’s why top developers spend time obsessing over names for classes, functions, and variables.</p><p>When you open up a VS Code and see a function called <code>send_signup_email</code>, you have a certain sense of what’s going to be inside and why that’s there.</p><p>The right abstractions can drive the team towards asking the right questions. And this is critical.</p><p><strong>Because when you’re tracking issues and tickets in isolation you have no choice but to measure only outputs.</strong></p><p>And teams today don’t want to measure only the outputs. They want to measure <em>outcomes</em>.</p><hr><h2 id="what-s-the-right-abstraction">What’s the right abstraction?</h2><p>The right abstraction is the one that prioritizes people over processes and tools. It's the one you and I use every day — it's Features.</p><p>When a squad creates a Feature and opens it, they’ll get to look at the entire feature as a unit. A <a href="https://zepel.io/agile/user-stories/">user story</a> inside it might describe a specific functionality. But the difference is, now each developer and designer know how it connects to the larger scheme of things for the entire feature.</p><blockquote>A feature forces inept managers to stop focussing on output-oriented questions like “how can we work faster”. <p>And shifts the focus on outcome-oriented questions like “why should we prioritize this feature” and “how does this feature tie to the OKR”.</p></blockquote><p>Miscellaneous tasks and incoming bugs can be tracked on a separate “List”, so high-priority bugs don't get missed out. And of course, when it comes to tracking them, they can all be tracked on a Sprint or on a Kanban Board.</p><p><strong>Feature as an abstraction is the right middle ground that lets you focus on the output as well as the outcome.</strong> It lets you zoom in and track what's happening today. It also allows you to zoom out and track a feature's progress across multiple disciplines. And it enables you to see how a feature moves from a feature request all the way to prioritization and development.</p><p>Simple issue trackers and project management tools have shoehorned teams into ticket-movers and have made them think in outputs. Metrics get feigned to show productivity. Thinking in outcomes has become ridiculously hard. And it's hurting businesses.</p><p>It's time for tools to reflect the reality of product development. It's time to remove the disconnect between development teams and what your customers really want. </p><p>It's time to stop thinking in isolated tickets and start thinking in features as a system!</p><hr><p>If you liked what you read, I think you’ll love what we have in store for you. Go ahead and <a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=product-development-is-broken">try Zepel for free</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://zepel.io/blog/how-issue-tracking-hurts-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816682</guid>
            <pubDate>Mon, 13 Jul 2020 02:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Website allows you to experience what it is like to live with dyslexia]]>
            </title>
            <description>
<![CDATA[
Score 420 | Comments 175 (<a href="https://news.ycombinator.com/item?id=23816678">thread link</a>) | @colinprince
<br/>
July 12, 2020 | http://geon.github.io/programming/2016/03/03/dsxyliea | <a href="https://web.archive.org/web/*/http://geon.github.io/programming/2016/03/03/dsxyliea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        


<div>
  <div>
    
<p>A friend who has dyslexia described to me how she experiences reading. She <em>can</em> read, but it takes a lot of concentration, and the letters seems to “jump around”.</p>

<p>I remembered reading about <a href="https://en.wikipedia.org/wiki/Typoglycemia">typoglycemia</a>. Wouldn’t it be possible to do it interactively on a website with Javascript? Sure it would.</p>

<p>Feel like making a bookmarklet of this or something? <a href="https://github.com/geon/geon.github.com/blob/master/_posts/2016-03-03-dsxyliea.md">Fork it</a> on github.</p>

<blockquote>
  <p>Dyslexia is characterized by difficulty with learning to read fluently and with accurate comprehension despite normal intelligence. This includes difficulty with phonological awareness, phonological decoding, processing speed, orthographic coding, auditory short-term memory, language skills/verbal comprehension, and/or rapid naming.</p>
</blockquote>

<blockquote>
  <p>Developmental reading disorder (DRD) is the most common learning disability. Dyslexia is the most recognized of reading disorders, however not all reading disorders are linked to dyslexia.</p>
</blockquote>

<blockquote>
  <p>Some see dyslexia as distinct from reading difficulties resulting from other causes, such as a non-neurological deficiency with vision or hearing, or poor or inadequate reading instruction. There are three proposed cognitive subtypes of dyslexia (auditory, visual and attentional), although individual cases of dyslexia are better explained by specific underlying neuropsychological deficits and co-occurring learning disabilities (e.g. attention-deficit/hyperactivity disorder, math disability, etc.). Although it is considered to be a receptive language-based learning disability in the research literature, dyslexia also affects one’s expressive language skills. Researchers at MIT found that people with dyslexia exhibited impaired voice-recognition abilities.</p>
</blockquote>

<p><em>Source: <a href="http://en.wikipedia.org/wiki/Dyslexia">Wikipedia</a></em></p>






    <hr>
    
    <hr>
    


  


<p><a href="http://disqus.com/">blog comments powered by </a>




  </p></div>
  
  
</div>


      </div></div>]]>
            </description>
            <link>http://geon.github.io/programming/2016/03/03/dsxyliea</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816678</guid>
            <pubDate>Mon, 13 Jul 2020 02:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Host a Wiki or Knowledge Base for Your Team]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23816462">thread link</a>) | @chsasank
<br/>
July 12, 2020 | http://chsasank.github.io/outline-self-hosted-wiki.html | <a href="https://web.archive.org/web/*/http://chsasank.github.io/outline-self-hosted-wiki.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>How is your startup sharing knowledge with the rest of your team?
We’ve been using slack’s <code>#general</code> or <code>#random</code> channels to make announcements.
We regularly post documents and PPTs slack channels so that they can be used by other people. We have a channel called <code>#setup</code> to post all IT related information like how to login to VPN etc.</p>

<p>But after a few weeks, these docs/notes become super hard to find. As good slack’s search is, you have to precisely know what you’re looking for. What we needed was a centralized knowledge base website - something like <a href="https://www.atlassian.com/software/confluence">Confluence</a></p>

<p>But Confluence is clunky and slow, and not cheap ($5/user). We experimented with <a href="https://tiddlywiki.com/">TiddlyWiki</a>. It calls itself ‘a non-linear personal web notebook’. It’s an opensource software which you can host on your servers or AWS. But its non linear organization makes it super unintuitive and confusing.</p>

<h2 id="why-outline">Why Outline?</h2>

<p>Then, I found <a href="https://www.getoutline.com/">outline</a>! Outline is similar to TiddlyWiki in that it’s opensource and free to self-host. Its UI is a great balance between simplicity of plain text notes and feature creep of Confluence. Login to outline is through your slack - so one less password to remember (or save). You can create private notebooks for a team or just for yourself. You can create a public link of a note so that you can share it with people outside your team - say via email.</p>

<p><span>
    Outline has great UI
</span>
<img src="https://www.getoutline.com/images/screenshot.png"></p>

<p>Best part of all of this is that <em>data doesn’t leave your servers</em> if you self-host it!
We already have a server lying around on AWS to host our own <a href="https://en.wikipedia.org/wiki/Python_Package_Index">python package server, pypi</a>. Since neither hosting pypi nor hosting outline are particularly intensive, we’ve hosted outline on this machine as <code>wiki.qure.ai</code>.</p>

<h2 id="install-outline">Install Outline</h2>

<p>Unfortunately, documentation for self-hosting outline is limited. There’s no robust docker-compose avaialable that you can use to directly create your server. In the rest of this post, I’ll show you how to host in your laptop or server. Before starting, make sure to install <a href="https://docs.docker.com/get-docker/">docker</a> and <a href="https://docs.docker.com/compose/install/">docker-compose</a>.</p>

<div><div><pre><code>git clone https://github.com/chsasank/outline-wiki-docker-compose.git
cd outline-wiki-docker-compose
make install
</code></pre></div></div>
<p><span>
    make install
</span>
<img src="http://chsasank.github.io/assets/images/outline/make_install.png"></p>

<p>Follow the instructions. You’ll have to create a slack app.
<span>
   Slack app
</span>
<img src="http://chsasank.github.io/assets/images/outline/slack_app.png"></p>

<p>If you want to install HTTPS:</p>



<p>Run the server:</p>



  </section></div>]]>
            </description>
            <link>http://chsasank.github.io/outline-self-hosted-wiki.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816462</guid>
            <pubDate>Mon, 13 Jul 2020 02:00:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Biotech]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23816390">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/how-to-build-a-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/how-to-build-a-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

      

        

        <div data-content-field="main-content">
          <div data-type="page" data-updated-on="1594684464227" id="page-5e0541ebe2b52a3155df2dcb"><div><div><div data-block-type="2" id="block-3ee5a93fdab84f05b621"><p><h3>The Summer of 2019, I gave a series of lectures to Longevity Fund’s Venture Fellows on the basics of building a biotechnology company. This is the write up of those lectures, with some additions by Laura Deming &amp; myself. </h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1577404962916_9483"><div><h2>First Steps</h2><p>You’re intrigued by biotech and want to explore ideas in the area. Where do you start? </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1577402821118_87823"><div><h2>Raising Money</h2><p>Science is expensive! One way to fund your work is to get venture capital (VC) investment. It’s a very different process from applying for an academic research grant. </p><p>There are a lot of excellent resources out there on raising capital.* Because of this I’ve focused here on “SF style” biotech investing, and the areas where the advice for a bio company differs from that of a tech company. </p><h3><a href="https://www.celinehh.com/vc101">VC for Bio 101</a> </h3><h3><a href="https://www.celinehh.com/investment-memo">Biotech investment memos</a></h3><p><a href="https://pmarchive.com/guide_to_startups_part1.html">*Marc Andreessen’s guide to startups</a>, the <a href="http://paulgraham.com/articles.html">PG essays</a>, and <a href="https://www.amazon.com/Venture-Deals-Smarter-Lawyer-Capitalist/dp/1118443616">Venture Deals</a> are three classics</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1577402821118_96448"><div><h2>Building in Bio</h2><p>A bit of a deeper dive into the predominant types of drugs and the considerations around each of them. The type of drug you select impacts the safety, dosing strategy, potential efficacy, downstream price &amp; profit margin, and competitiveness of your drug. </p></div></div></div></div></div>
        </div>
      
    </div></div>]]>
            </description>
            <link>https://www.celinehh.com/how-to-build-a-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816390</guid>
            <pubDate>Mon, 13 Jul 2020 01:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bringing GPU Acceleration to Inkscape, Week 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816235">thread link</a>) | @shahreel
<br/>
July 12, 2020 | https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/ | <a href="https://web.archive.org/web/*/https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
      
<h2>
  Bringing GPU Acceleration to Inkscape, Week 2
</h2>
<p>Published the <time datetime="2020-06-12T20:02:31+02:00">2020-06-12</time></p>
<p>Hello everyone!</p>
<p>For the past two weeks since the beginning of this <a href="https://summerofcode.withgoogle.com/organizations/6070010742571008/#5859756641615872">GSoC
2020</a>
I have attempted to integrate <a href="https://github.com/servo/pathfinder">Pathfinder</a>
into Inkscape, in order to draw (and refresh!) the canvas much faster by using
your GPU.</p>
<p>After some early attempts, where I created a C++ Inkscape extension opening
Pathfinder’s demo on the current SVG, and another extension which was basically
a copy of <a href="https://github.com/servo/pathfinder/blob/master/examples/c_canvas_glfw_minimal/c_canvas_glfw_minimal.c">Pathfinder’s C canvas
example</a>,
I’ve started to properly integrate it into Inkscape’s widgets.</p>
<p>That’s where the fun began, here is a small tour of the fun bugs I encountered:</p>
<h3 id="using-apitrace-on-wayland-can-be-interesting">Using <code>apitrace</code> On Wayland Can Be Interesting</h3>
<p><a href="https://apitrace.github.io/"><code>apitrace</code></a> is a very handy tool for debugging
OpenGL applications, it avoids having to understand the code’s structure, and
allows me to focus on the actual behaviour from the driver’s point of view.</p>
<pre><code><span>glXGetCurrentContext() not found: /usr/bin/../lib/apitrace/wrappers/egltrace.so: undefined symbol: glXGetCurrentContext
apitrace: warning: caught signal 6
</span></code></pre>
<p>I was a bit sad to see that a bug I found at the intersection of
<a href="https://github.com/apitrace/apitrace/issues/380">apitrace</a> and
<a href="https://github.com/anholt/libepoxy/issues/68">libepoxy</a> back in 2015
reappeared now, this time caused by GDK doing the same.  In the end I rebuilt
both libepoxy and GTK+ with only their Wayland backend so they wouldn’t be
tempted to call GLX symbols.  This breaks Firefox and probably some other
software which link against their X11 symbols, but on my build/testing machine
it’s fine.</p>
<p>Speaking of running a (soon-to-be) OpenGL program on a remote machine,
<a href="https://gitlab.freedesktop.org/mstoeckl/waypipe">waypipe</a> from last year’s
GSoC is extremely useful, it feels almost instantaneous on my 900&nbsp;KiB/s down
80&nbsp;KiB/s up ADSL connection.  For comparison, I also tried X11 forwarding over
ssh which only shows Inkscape’s window after 1:05, and also mounting the build
directory over sshfs where it takes 1:20 to do the same, and 6:40 (!) to
generate a stack trace in case of a panic.  I probably should have figured that
out during the community bonding period, but I didn’t think of it.</p>
<h3 id="pathfinder-doesn-t-like-to-draw-into-gtk-glarea-very-much">Pathfinder Doesn’t Like To Draw Into <code>Gtk::GLArea</code> Very Much</h3>
<p>I spent quite a few days trying to get Pathfinder to draw into a GTK+ widget,
first inside of Inkscape, then in a <a href="https://linkmauve.fr/files/pathfinder-glarea.tar.xz">testcase
application</a>.  The
<code>Gtk::GLArea</code> widget lets an application draw using OpenGL.  I want it to
eventually replace Inkscape’s <code>SPCanvas</code>, once I’m done and <a href="https://wiki.inkscape.org/wiki/index.php?title=Inkscape_Canvas">Tavmjong as
well</a>, but in
the meantime I’ll keep them both side-by-side in order to compare their
rendering more easily.</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/empty-glarea.png" alt=""></p>
<p>Despite the rendering being done, according to <code>apitrace</code>’s step-by-step
debugging, the <code>Gtk::GLArea</code> stayed hopelessly black.  Even though I could
render a simple solid colour using <code>glClearColor()</code> and
<code>glClear(GL_COLOR_BUFFER_BIT)</code>, as soon as I tried to render using Pathfinder
it went back to a solid black.</p>
<p>Experimenting with the OpenGL contexts, I could make Pathfinder render its
iconic tiny house everywhere but where I wanted it:</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/almost-but-not-quite.png" alt=""></p>
<p>Here is a particularly trippy rendering I got, when <code>Gtk::GLArea</code> is reading
from a framebuffer Pathfinder hasn’t written into:</p>

<p>It was only with the help of <a href="https://github.com/s3bk">sebk</a> that I finally
figured out that I wasn’t passing the correct
<a href="https://www.khronos.org/opengl/wiki/Framebuffer_Object">fbo</a> to Pathfinder.  I
was passing <code>0</code> which means the default (display’s) framebuffer instead of the
one created for me by GTK+.  With this fixed, everything rendered fine, even on
resize:</p>

<p>After that it was a simple matter of <a href="https://github.com/servo/pathfinder/pull/357">adding some API to Pathfinder’s C
bindings</a> and I can render the
same SVG as Inkscape!</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/same-svg.png" alt="">
On the left hand side we can see <a href="https://poez.io/">poezio</a>’s logo rendered by
Inkscape with cairo; on the right hand side the same logo being serialised and
passed to Pathfinder to be rendered on the GPU.</p>
<p>And this concludes my first progress report of this GSoC, a big thanks to
ebassi, halfline and Neville[m] from
<a href="xmpp:%23gtk%irc.freenode.net@irc.jabberfr.org?join">#gtk</a>, and especially sebk
from <a href="xmpp:%23pathfinder%23mozilla.org@matrix.org?join">#pathfinder</a>, who
helped me a lot in that process!</p>


    </div>
  </section></div>]]>
            </description>
            <link>https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816235</guid>
            <pubDate>Mon, 13 Jul 2020 01:23:13 GMT</pubDate>
        </item>
    </channel>
</rss>
