<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 16 Sep 2020 04:24:10 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 16 Sep 2020 04:24:10 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Deep Diamond – Deep Learning in Clojure Is Fast, Simpler Than Keras]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24468679">thread link</a>) | @dragandj
<br/>
September 14, 2020 | https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
You can <a href="https://www.patreon.com/posts/22476035">adopt a pet function!</a>
Support my work <a href="https://patreon.com/draganrocks">on my Patreon page</a>, and access my <a href="https://www.patreon.com/posts/im-ditching-and-22476348">dedicated discussion server</a>. Can't afford to <a href="https://patreon.com/draganrocks">donate</a>? Ask for a free invite.
<p>September 5, 2020</p>
<p>
    Please share: .
</p>

<p>
    <a href="https://aiprobook.com/">New books are available for subscription.</a>
    </p><p><a href="https://aiprobook.com/deep-learning-for-programmers">
            <img src="http://aiprobook.com/img/dlfp-cover.png">
        </a>
        <a href="https://aiprobook.com/numerical-linear-algebra-for-programmers">
            <img src="http://aiprobook.com/img/lafp-cover.png">
        </a>
    </p>


<p>
through the direct equivalent of a fine Convolutional network example in Keras.
</p>

<p>
Good News: <a href="https://github.com/uncomplicate/deep-diamond">Deep Diamond</a>() preview release is in Clojars, and is already quite useful! And fast!
It is yet to be fully polished, but you can try it now and, I hope, you'll like it.
</p>

<p>
It now covers the functionality that is being explained from scratch in the <a href="http://aiprobook.com/">books that I'm writing</a>.
Convolutions work, too; at the speed of Road Runner!
</p>

<p>
In accordance with my philosophy, "less talk, more walk", I introduce Deep Diamond
through the direct equivalent of this fine <a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">MNIST CNN example in Keras</a>.
</p>

<div id="outline-container-org54ea652">
<h2 id="org54ea652">Specify the network blueprint</h2>
<div id="text-org54ea652">
<p>
We specify the network by plain Clojure vectors and functions, and create the blueprint.
No need for special compilers and whatnot. The structure of internal parts would be
picked up automatically, or we can specify these explicitly.
</p>

<div>
<pre><span>(</span><span>def</span> <span>net-spec</span> <span>[</span><span>(</span>convo <span>[</span>32<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>convo <span>[</span>64<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>pooling <span>[</span>2 2<span>]</span> <span>:max</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>128<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>10<span>]</span> <span>:softmax</span><span>)</span><span>]</span><span>)</span>

<span>(</span><span>defonce</span> <span>net-bp</span>
  <span>(</span>network <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
           net-spec<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb8d8bce">
<h2 id="orgb8d8bce">Create the network</h2>
<div id="text-orgb8d8bce">
<p>
The blueprint is a Clojure function that can instantiate the network
object that holds the parameter tensors that the network should learn by using
one of the built-in optimization algorithms. In this case, I'll use adaptive moments,
<code>:adam</code>. Xavier initialization is, again, a plain function that initializes
the network with appropriate weights.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>net</span> <span>(</span>init! <span>(</span>net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>
</pre>
</div>

<p>
That's it! The network is ready to learn.
</p>
</div>
</div>

<div id="outline-container-orgae4dec0">
<h2 id="orgae4dec0">Train the network on MNIST data (CPU)</h2>
<div id="text-orgae4dec0">
<p>
The original MNIST data is distributed through four binary files that
you can download <a href="http://yann.lecun.com/exdb/mnist/">here</a>. To demonstrate how nice Clojure is, I'm not
using any special MNIST-specific code that is magically imported
from the framework's model Zoo. The complete code, from scratch, is at the
end of the article (I'm just pushing it there so it doesn't steal the spotlight :).
</p>

<div>
<pre><span>(</span>time <span>(</span>train net train-images y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
The network learns in mini-batches of 128 images of the total of 60000,
with adaptive moments, through 12 full epochs. That makes 5625 forward/backward
update cycles.
</p>

<p>
The total time for that on my old 2013. i7-4790k CPU is: <b>368</b> seconds.
<b>6 minutes for 6000 cycles. A thousand cycles per minute.</b>
</p>

<p>
Isn't that a lot? You should try and run this in Keras with TensorFlow, and
see that we got a pretty nice performance! (I'll publish some comparisons soon,
and in the meantime you can try for yourself!).
</p>
</div>
</div>

<div id="outline-container-org7c0813e">
<h2 id="org7c0813e">Has it learned anything?</h2>
<div id="text-org7c0813e">
<p>
See the metrics:
</p>

<div>
<pre><span>(</span><span>-&gt;&gt;</span> <span>(</span>infer net test-images<span>)</span>
     <span>(</span>dec-categories<span>)</span>
     <span>(</span>classification-metrics test-labels-float<span>)</span>
     <span>:metrics</span><span>)</span>
</pre>
</div>

<pre>{:accuracy 0.9919,
 :f1 0.9918743606319073,
 :ba 0.9954941141884774,
 :sensitivity 0.9918944358825683,
 :specificity 0.9990937924943865,
 :precision 0.9918542861938476,
 :fall-out 9.062075056135655E-4}
</pre>

<p>
Accuracy is 99.2% which is in the ballpark of what the Keras example gives.
</p>
</div>
</div>


<div id="outline-container-org78cec4a">
<h2 id="org78cec4a">GPU</h2>
<div id="text-org78cec4a">
<p>
Want to go faster? No problem, Deep Diamond supports GPU, in the same process,
at the same time, with the same code!
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>gpu</span> <span>(</span>cudnn-factory<span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-net-bp</span> <span>(</span>network gpu
                         <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
                         net-spec<span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>gpu-net</span> <span>(</span>init! <span>(</span>gpu-net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-x-train</span>
  <span>(</span>transfer! train-images <span>(</span>tensor gpu <span>[</span>60000 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-y-train</span>
 <span>(</span>transfer! y-train <span>(</span>tensor gpu <span>[</span>60000 10<span>]</span> <span>:float</span> <span>:nc</span><span>)</span><span>)</span><span>)</span>

<span>(</span>time <span>(</span>train gpu-net gpu-x-train gpu-y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
Elapsed time? <b>20 seconds</b> on my Nvidia GTX 1080Ti (which is a few generations old)!
</p>
</div>
</div>

<div id="outline-container-org2c2d651">
<h2 id="org2c2d651">The books</h2>
<div id="text-org2c2d651">
<p>
Should I mention that the book <a href="https://aiprobook.com/deep-learning-for-programmers/">Deep Learning for Programmers: An Interactive Tutorial with
CUDA, OpenCL, DNNL, Java, and Clojure</a> teaches the nuts and bolts of neural networks and deep learning
by showing you how Deep Diamond is built, <b>from scratch</b>? In interactive sessions. Each line of code
can be executed and the results inspected in the plain Clojure REPL. The best way to master something is to build
it yourself!
</p>

<p>
It' simple. But fast and powerful!
</p>

<p>
Please subscribe, read the drafts, get the full book soon, and support my work on this free open source library.
</p>
</div>
</div>

<div id="outline-container-orga8b021d">
<h2 id="orga8b021d">Appendix: Reading, encoding, and decoding data</h2>
<div id="text-orga8b021d">
<p>
The code that reads the raw image data and converts it to proper tensors
should go up in the sequence of execution, but is not that interesting.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>train-images-file</span> <span>(</span>random-access <span>"data/mnist/train-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels-file</span> <span>(</span>random-access <span>"data/mnist/train-labels.idx1-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images-file</span> <span>(</span>random-access <span>"data/mnist/t10k-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-file</span> <span>(</span>random-access <span>"data/mnist/t10k-labels.idx1-ubyte"</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-images</span>
  <span>(</span>map-tensor train-images-file <span>[</span>60000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels</span>
  <span>(</span>map-tensor train-labels-file <span>[</span>60000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images</span>
  <span>(</span>map-tensor test-images-file <span>[</span>10000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels</span>
 <span>(</span>map-tensor test-labels-file <span>[</span>10000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>enc-categories</span> <span>[</span>val-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>cat-tz <span>(</span>tensor val-tz <span>[</span><span>(</span>first <span>(</span>shape val-tz<span>)</span><span>)</span> <span>(</span>inc <span>(</span>long <span>(</span>amax val-vector<span>)</span><span>)</span><span>)</span><span>]</span> <span>:flo</span><span>at</span><span> </span><span>:nc</span><span> </span><span>)</span>
                  cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-t<span>z</span><span>)</span><span>)</span><span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! cat-matrix <span>(</span>entry val-vector j<span>)</span> j 1.0<span>)</span><span>)</span>
      cat-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>dec-categories</span> <span>[</span>cat-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>val-tz <span>(</span>tensor cat-tz <span>[</span><span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>]</span> <span>:float</span> <span>:x</span><span>)</span>
                  val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! val-vector j <span>(</span>imax <span>(</span>col cat-matrix j<span>)</span><span>)</span><span>)</span><span>)</span>
      val-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-labels-float</span> <span>(</span>transfer! train-labels <span>(</span>tensor <span>[</span>60000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-train</span> <span>(</span>enc-categories train-labels-float<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-float</span> <span>(</span>transfer! test-labels <span>(</span>tensor <span>[</span>10000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-test</span> <span>(</span>enc-categories test-labels-float<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>


    </article></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24468679</guid>
            <pubDate>Mon, 14 Sep 2020 10:45:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Did You Know Fonts Could Do All This?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24468213">thread link</a>) | @Moist-Toes
<br/>
September 14, 2020 | https://venam.nixers.net/blog/unix/2020/09/14/playing_with_fonts.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/unix/2020/09/14/playing_with_fonts.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/mexican_calendar_systems.jpg" alt="Confusing Mexican Calendar, at least for those not in the know" loading="lazy"></p>

<p>Freetype, included in the <a href="https://venam.nixers.net/blog/unix/2017/06/04/fonts-on-unix.html">font stack on
Unix</a>, is quite
complex. There are so many layers to get it to do what it does that
it’s easy to get lost. From finding the font, to actually rendering it,
and everything in between.<br>
Like most of the world, I use a rather low screens definition
(1366x768 with 96 dpi) and rather old-ish laptop, unlike some <a href="https://tonsky.me/blog/monitors/">font
designers that live in a filter bubble where everyone has the latest
macbook</a>. Thus, good and legible font
rendering is important.<br>
Let’s play with lesser known toggles available to us when it comes to font
rendering and see what they do, let’s have fun and explore possibilities.</p>

<h2 id="a-general-picture">A General Picture</h2>

<p>Generally, to make a font look better on screens, which are arrays of
pixels, we use a combination of these three:</p>

<ul>
  <li><strong>Antialiasing</strong>: Applying a light shade around the glyph. It is useful
at small scale, when you don’t have enough pixels, but it makes most
glyphs look bolder.</li>
</ul>

<p><img src="https://venam.nixers.net/blog/assets/font_antialias.jpg" alt="Font anti-alias example" loading="lazy"></p>

<ul>
  <li><strong>Subpixel rendering</strong>: A technique similar to antialias but using
subpixels, the color components inside the pixels. By applying a
small amount of colors on the sides you can reach more granular
precision. However, if applied clumsily, or if you simply move the
window containing the text, these colored subpixels will become
apparent, what we call fringe.</li>
</ul>

<p><img src="https://venam.nixers.net/blog/assets/font_subpixel_rendering.jpg" alt="Font sub-pixel rendering example" loading="lazy"></p>

<ul>
  <li><strong>Hinting</strong>: Pixels are blocks but text is made of curves, that means
these curves will never match exactly with screen pixels. Hinting
is about repositioning or selecting the closest pixels while trying
as much as possible to keep the shape of the glyph intact. There are
multiple levels of hinting, hinting information provided by the font
itself (bytecode interpreter hinting), and hinting provided by the
rendering library (auto-hinting).</li>
</ul>

<p><img src="https://venam.nixers.net/blog/assets/font_hinting.jpg" alt="Font hinting example" loading="lazy"></p>

<p><em>NB</em>: “It’s just text”… This article is yet another that
shows how fonts aren’t as easy as they look.  For more info
about the font stack, please visit <a href="https://venam.nixers.net/blog/unix/2017/06/04/fonts-on-unix.html">my previous article on the
topic</a>, and if you
want an idea of what it means to draw them on the screen take a look a
<a href="https://venam.nixers.net/blog/unix/2018/09/02/fonts-xcb.html">this article</a>.</p>

<p>What is applied, when, how to control all of this, can we see what they
do, and should we even care?</p>

<p>Freetype and fontconfig default rendering these days is pretty good,
so there shouldn’t be anything to worry about; Until there’s something
to worry about, like a font not looking the way you want.<br>
Our first stop will be something that intrigued me because I haven’t
heard many talk about it: the Freetype driver’s properties.<br>
The Freetype driver is used whenever hinting is needed, so this is the
part it actually changes — how hinting is applied.</p>



<p>Let’s start with arming ourselves with ways to easily test all this.<br>
Freetype2 demos utilities are a must, you can clone them
<a href="https://venam.nixers.net/blog/unix/2020/09/14/git.sv.nongnu.org/freetype/freetype2-demos.git">here</a>
or fetch them from your package repositiory, for example
<a href="https://packages.debian.org/jessie/freetype2-demos">Debian</a> and <a href="https://www.archlinux.org/packages/extra/x86_64/freetype2-demos/">Arch
Linux</a>.<br>
These will give you a bunch of useful tools such as <code>ftdiff</code>, <code>ftview</code>,
<code>ftstring</code> <code>ftgrid</code>, <code>fttimer</code>, <code>ftbench</code>, and others. The most important
ones for us are <code>ftdiff</code> and <code>ftgrid</code>.</p>

<p>Example usage:</p>

<figure><pre><code data-lang="shell">ftdiff <span>-r</span> 96 <span>-s</span> 10 ~/.local/share/fonts/times.ttf
ftgrid <span>-r</span> 96 <span>-f</span> 20 10 ~/.local/share/fonts/times.ttf
ftstring <span>-r</span> 96 <span>-m</span> <span>'Hello World!'</span> 10 ~/.local/share/fonts/times.ttf</code></pre></figure>

<p>Additionally, you can install <code>pango-view</code> from <code>pango-tools</code>
to later test if fontconfig applies your configurations
properly. It can be used by preparing a file written in <a href="https://developer.gnome.org/pygtk/stable/pango-markup-language.html">pango
markup</a>
and displaying it using <code>pango-view --markup file.pangpang</code>.<br>
You can set the fontconfig debug level higher to see which font is
actually loaded by setting the <code>FC_DEBUG</code> to something like 4096,
<code>FC_DEBUG=4096</code>.</p>

<p>More values can be found here, we’ll use them later to see if our
fontconfig settings are applied properly:</p>

<figure><pre><code data-lang="man">Name         Value    Meaning
---------------------------------------------------------
MATCH            1    Brief information about font matching
MATCHV           2    Extensive font matching information
EDIT             4    Monitor match/test/edit execution
FONTSET          8    Track loading of font information at startup
CACHE           16    Watch cache files being written
CACHEV          32    Extensive cache file writing information
PARSE           64    (no longer in use)
SCAN           128    Watch font files being scanned to build caches
SCANV          256    Verbose font file scanning information
MEMORY         512    Monitor fontconfig memory usage
CONFIG        1024    Monitor which config files are loaded
LANGSET       2048    Dump char sets used to construct lang values
MATCH2        4096    Display font-matching transformation in patterns</code></pre></figure>

<p>Yet another way is to test directly in your browser URL bar:</p>

<figure><pre><code data-lang="xml">data:text/html,<span>&lt;meta</span> <span>charset=</span><span>"utf8"</span><span>&gt;&lt;p</span> <span>style=</span><span>"font-family: Times New Roman;"</span><span>&gt;</span>Hello World<span>&lt;/p&gt;</span></code></pre></figure>

<h2 id="the-freetype2-drivers-properties">The Freetype2 Drivers Properties</h2>

<p>So let’s get back to our testing of Freetype2 drivers.<br>
On <a href="https://www.freetype.org/freetype2/docs/reference/ft2-properties.html">this documentation
page</a>,
ft (freetype) properties are listed and are said to affect the behavior
of the drivers, each touching a different one. They are set by modifying
the <code>FREETYPE_PROPERTIES</code> environment variable, normally loaded from
<code>/etc/profile.d/freetype2.sh</code>.<br>
However, most of the ones listed are targeted at the CFF, Type 1,
and CID fonts driver and not at TrueType fonts, so they do nothing
if you don’t have these font types. The only toggle <a href="https://www.freetype.org/freetype2/docs/reference/ft2-tt_driver.html">available for
TrueType</a>
is the <code>interpreter-version</code> which controls the bytecode interpreter,
the rasterizer, and thus how the outline gets hinted.</p>

<p>The options available to us are the following:</p>

<ul>
  <li>35 — For classic mode GDI (Win 98/2000)</li>
  <li>38 — GDI+ old (Vista, Win 7), Infinality, considered slow</li>
  <li>40 — For minimal mode (stripped down Infinality, this is the default)
(After Win 7)</li>
</ul>

<p>Kind of weird that we jump from 35 to 38, where did 36 and the rest go? The
answer is that it’s a choice from the Freetype devs to only include those
and not the ones in between.</p>

<p>And the differences look as follows, notice the native hinter in the
left column:</p>

<ul>
  <li>v35</li>
</ul>

<figure><pre><code data-lang="shell"><span>FREETYPE_PROPERTIES</span><span>=</span><span>"truetype:interpreter-version=35"</span> ftdiff <span>-r</span> 96 <span>-s</span> 10 ~/.local/share/fonts/times.ttf</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/ftdiff_v35.png" alt="ftdiff interpreter v35" loading="lazy"></p>

<figure><pre><code data-lang="shell"><span>FREETYPE_PROPERTIES</span><span>=</span><span>"truetype:interpreter-version=35"</span> ftgrid <span>-r</span> 96 <span>-f</span> 36 10 ~/.local/share/fonts/times.ttf</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/ftgrid_v35.png" alt="ftgrid interpreter v35" loading="lazy"></p>

<ul>
  <li>v38</li>
</ul>

<figure><pre><code data-lang="shell"><span>FREETYPE_PROPERTIES</span><span>=</span><span>"truetype:interpreter-version=38"</span> ftdiff <span>-r</span> 96 <span>-s</span> 10 ~/.local/share/fonts/times.ttf</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/ftdiff_v38.png" alt="ftdiff interpreter v38" loading="lazy"></p>

<figure><pre><code data-lang="shell"><span>FREETYPE_PROPERTIES</span><span>=</span><span>"truetype:interpreter-version=38"</span> ftgrid <span>-r</span> 96 <span>-f</span> 36 10 ~/.local/share/fonts/times.ttf</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/ftgrid_v38.png" alt="ftgrid interpreter v38" loading="lazy"></p>

<ul>
  <li>v40</li>
</ul>

<figure><pre><code data-lang="shell"><span>FREETYPE_PROPERTIES</span><span>=</span><span>"truetype:interpreter-version=40"</span> ftdiff <span>-r</span> 96 <span>-s</span> 10 ~/.local/share/fonts/times.ttf</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/ftdiff_v40.png" alt="ftdiff interpreter v40" loading="lazy"></p>

<figure><pre><code data-lang="shell"><span>FREETYPE_PROPERTIES</span><span>=</span><span>"truetype:interpreter-version=40"</span> ftgrid <span>-r</span> 96 <span>-f</span> 36 10 ~/.local/share/fonts/times.ttf</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/ftgrid_v40.png" alt="ftgrid interpreter v40" loading="lazy"></p>

<p>We can also test using <code>pango-view</code> (remember again that this should be a font
that has native hinting enabled but not the auto-hinter):</p>

<figure><pre><code data-lang="xml"><span>&lt;span</span> <span>font_family=</span><span>"Times New Roman"</span> <span>font=</span><span>"10"</span> <span>foreground=</span><span>"black"</span> <span>alpha=</span><span>"83%"</span><span>&gt;</span>
Lorem ipsum dolor sit amet, c
onsectetur adipiscing elit, s
ed do eiusmod tempor incididu
nt ut labore et dolore magna 
aliqua. Ut enim ad minim venia
m, quis nostrud exercitation u
llamco laboris nisi ut aliquip
ex ea commodo consequat. Duis 
aute irure dolor in reprehende
rit in voluptate velit esse ci
llum dolore eu fugiat nulla pa
riatur. Excepteur sint occaeca
t cupidatat non proident, sunt
in culpa qui officia deserunt 
mollit anim id est laborum.
<span>&lt;/span&gt;</span></code></pre></figure>

<p>You can also change the font via the <code>--font=</code> argument of <code>pango-view</code>.</p>

<figure><pre><code data-lang="shell"><span>FREETYPE_PROPERTIES</span><span>=</span><span>"truetype:interpreter-version=35"</span> pango-view <span>--markup</span> text.bangarang</code></pre></figure>

<ul>
  <li>v35</li>
</ul>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/pango-view_v35.png" alt="pango interpreter v35" loading="lazy"></p>

<ul>
  <li>v38</li>
</ul>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/pango-view_v38.png" alt="pango interpreter v38" loading="lazy"></p>

<ul>
  <li>v40</li>
</ul>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/pango-view_v40.png" alt="pango interpreter v40" loading="lazy"></p>

<p>So definitely, older interpreter versions were rougher with hinting, much
bolder, and could deform the glyphs. The newer ones are more minimal with
it. We also notice that the auto-hinter isn’t that bad and that avoiding
hinting can help. I took the specific case of the Windows font ‘Times New
Roman’ because it has the reputation of rendering badly with Freetype,
mostly because of the job the interpreter does. Applying very light or no
hinting at all helps tremendously, even at very small point size as you
can see in the next comparison. The hinting does indeed help legibility
at this scale but the font shape and personality is completely destroyed.</p>

<p>From left to right: v35, v38, v40.</p>

<p><img src="https://venam.nixers.net/blog/assets/fun_with_fonts/pango-view_small_point.png" alt="pang interpreter small point comparison" loading="lazy"></p>

<h2 id="how-fontconfig-works">How Fontconfig Works</h2>

<p>We’re not done with hinting yet, there can be many levels of hinting
that can be applied, but let’s first take a detour and learn a bit about
fontconfig and how to use it.</p>

<p>Fontconfig is the layer in the font stack responsible for loading the
font along with the configurations that tell the next layer how to find
the font file and what changes to apply when rendering it. It is usually
composed of a library, a preset of configuration files, and a bunch
of helpful tools all starting with the prefix <code>fc-</code> such as: <code>fc-cache</code>,
<code>fc-query</code>, <code>fc-match</code>, and <code>fc-conflist</code>, to name a few.</p>

<p>The configuration files are usually found in <code>/etc/fonts/</code> and split into
the presets available <code>/etc/fonts/conf.avail</code>, and the chosen presets in
<code>/etc/fonts/conf.d</code>, which are symbolic links to the former.<br>
The precedence of the rules is alphanumerical, a first-come
first-served principle, thus <code>01-custom-rule.conf</code> will be loaded
before <code>99-not-important-rule.conf</code>. Local user configurations, in
the user’s <code>$XDG_CONFIG_HOME/fontconfig</code> directory, are loaded from
one of these configurations that contains an include statement. On
my machine it is the <code>50-user.conf</code>, so it’s precedence is lower
than anything loaded before it. This isn’t practical when testing
rules so rename this file to something like <code>01-user.conf</code>. Now
anything you put in <code>$XDG_CONFIG_HOME/fontconfig/conf.d</code> or
<code>$XDG_CONFIG_HOME/fontconfig/fonts.conf</code> should have priority.<br>
You can make sure the order and configurations are loaded properly by
using the <code>fc-conflist</code> command. It lists in order of precedence the
configurations found, the ones starting with a <code>+</code> are loaded, the ones
with <code>-</code> are not.</p>

<p>These files are composed of mainly 4 components:</p>

<ul>
  <li>Match rules: If something matches, then edit the properties
mentioned. There are ton of matching and editing rules, even including
stuff like the program name that is currently trying to load …</li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/unix/2020/09/14/playing_with_fonts.html">https://venam.nixers.net/blog/unix/2020/09/14/playing_with_fonts.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/unix/2020/09/14/playing_with_fonts.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24468213</guid>
            <pubDate>Mon, 14 Sep 2020 09:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of the Tiny and Obfuscated Image Decoder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24468039">thread link</a>) | @a_e_k
<br/>
September 14, 2020 | http://eastfarthing.com/blog/2020-09-14-decoder/ | <a href="https://web.archive.org/web/*/http://eastfarthing.com/blog/2020-09-14-decoder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<header>

</header><p>
I was mystified when I first came across the <a href="http://www.ioccc.org/2018/bellard/hint.html">“Most Inflationary”</a> winning
<a href="http://www.ioccc.org/2018/bellard/">entry</a> in the 2018 <a href="https://www.ioccc.org/">IOCCC</a>.  Written by the <a href="https://bellard.org/">incredibly prolific</a> Fabrice
Bellard, this tiny program with just 4KB of source code emitted a
128×128 resolution version of the <a href="https://en.wikipedia.org/wiki/Lenna#Criticism">(in)famous</a> Lena test image.  Voodoo!
The IOCCC judges wrote “We could understand some of the arithmetic but none
of the magic.”  I was determined to figure out the magic and inspired by
<a href="https://fabiensanglard.net/">Fabien Sanglard</a> to try to write up how it works.
</p>

<p>
Using the program is straightforward enough, and both the source and the
details of running it can be found on its IOCCC page.  I used GCC to
compile it and piped the output directly to ImageMagick to view it:
</p>

<div>
<pre>gcc -O3 -o prog prog.c
./prog | display -                        # Show embedded image
./prog d &lt; vintage_cars.bin | display -   # Show an external image
</pre>
</div>

<p>
Running it with no arguments like the first case will decompress the
embedded data and produce the following image (zoomed for detail):
</p>


<figure>
<img src="http://eastfarthing.com/blog/2020-09-14-decoder/image.png" alt="image.png">

</figure>

<p>
Admittedly, this has a fair number of compression artifacts, but it’s still
pretty darned impressive for 2439 bytes of image data and 1544 bytes of
source code for the decompressor.
</p>

<p>
So let’s see how it works.  This will be a deep dive and by far my longest
post yet (I’ve erred on the side of too much detail), so make
yourself comfortable!  From here on in, I’m going to show the pieces of the
original program juxtaposed with the corresponding pieces from my
deobfuscated version.  When I mention line numbers, I’ll be referring to
the later unless noted otherwise.  I’ll typically use italicized numbers in
parenthesis to denote these.
</p>

<p>
For my version I have expanded the lone macro (used to compact <code>for</code>
loops), reformated the source, and renamed the variables.  The only
structural changes that I have made are from updating to modern style
function headers and pushing declarations down to be as local in scope as
possible (C99 style).  In one case, I gave a variable different names when
pushing it down into two blocks where it had been reused in different ways.
</p>


<div id="outline-container-org65f3743">
<h2 id="org65f3743">Input Header</h2>
<div id="text-org65f3743">
<p>
We’ll start at the end of the program with the <code>main()</code> function and then
work our way backwards to the beginning; we’ll essentially go from top to
bottom in terms of control flow.  Here’s the <code>main()</code> function:
</p>

<div>
<pre><span>112: </span><span>main</span>(D){
<span>113: </span><span>int</span> <span>a</span>,<span>l</span>,<span>L</span>,<span>M</span>,<span>g</span>,<span>N</span>;
<span>114: </span>s=D&gt;1?256:1968;
<span>115: </span>Q();
<span>116: </span>g=n(5);
<span>117: </span>f=1&lt;&lt;g;
<span>118: </span>N=f-n(5);
<span>119: </span>O=n(5);
<span>120: </span>P=n(5);
<span>121: </span>W(0,0,g);
<span>122: </span>printf(<span>"P6 %d %d 255 "</span>,f,N);
<span>123: </span>e(a,N*f){
<span>124: </span>l=y[0][a];
<span>125: </span>L=y[1][a];
<span>126: </span>M=y[2][a];
<span>127: </span>D=l-L;
<span>128: </span>K(D+M);
<span>129: </span>K(l+L);
<span>130: </span>K(D-M);
<span>131: </span>}
<span>132: </span><span>return</span> 0;
<span>133: </span>}
</pre>
</div>
<div>
<pre><span>228: </span><span>int</span> <span>main</span>( <span>int</span> <span>argc</span> )
<span>229: </span>{
<span>230: </span>    radix = argc &gt; 1 ? 256 : 1968;
<span>231: </span>    renormalize_and_read();
<span>232: </span>    <span>int</span> <span>level</span> = decode_unsigned( 5 );
<span>233: </span>    width = 1 &lt;&lt; level;
<span>234: </span>    <span>int</span> <span>height</span> = width - decode_unsigned( 5 );
<span>235: </span>    luma = decode_unsigned( 5 );
<span>236: </span>    chroma = decode_unsigned( 5 );
<span>237: </span>    extract_block( 0, 0, level );
<span>238: </span>    printf( <span>"P6 %d %d 255 "</span>, width, height );
<span>239: </span>    <span>for</span> ( <span>int</span> <span>pixel</span> = 0; pixel &lt; height * width; pixel++ )
<span>240: </span>    {
<span>241: </span>        <span>int</span> <span>Y</span>  = image[ 0 ][ pixel ];
<span>242: </span>        <span>int</span> <span>Cg</span> = image[ 1 ][ pixel ];
<span>243: </span>        <span>int</span> <span>Co</span> = image[ 2 ][ pixel ];
<span>244: </span>        <span>int</span> <span>temporary</span> = Y - Cg;
<span>245: </span>        write_byte_clamped( temporary + Co );
<span>246: </span>        write_byte_clamped( Y         + Cg );
<span>247: </span>        write_byte_clamped( temporary - Co );
<span>248: </span>    }
<span>249: </span>    <span>return</span> 0;
<span>250: </span>}
</pre>
</div>

<p>
The image is basically encoded in two distinct layers.  The lower level
uses a lossless <a href="https://en.wikipedia.org/wiki/Entropy_encoding">entropy encoding</a> scheme that stores only single bits and
unsigned integers.  We’ll see this in detail later.  For now, it’s enough
to know that the first line (<i>230</i>) checks for an argument to determine
whether to expect the image on standard input or to decompress the image
from an internal string.  The data is stored slightly differently in the
two modes and the related value here doubles as a flag.  The second line
(<i>231</i>) then primes the pump for the decoding this bitstream.  (However,
this turns out to be superfluous as it would have been called later
anyway.)
</p>

<p>
At the higher level, the first thing to be decoded (<i>232–236</i>) is a small
header comprised of four integers.  The first of these stores the image
width as a power of two.  Due to a fixed-size array used to store the
decompressed image, the width is limited to 1024.  The second integer
stores how many lines shorter the image height is compared to the width.
This will be zero for square images but means that only square or landscape
oriented images are possible.  The next two lines decode a pair of
parameters related to the image quality.  Higher numbers here give greater
compression at the expense of image quality.  The lowest legal values for
each are 1 and should produce near lossless results.  For the built-in Lena
image, the four values in this header are 7, 0, 41, and 82, respectively.
</p>
</div>
</div>


<div id="outline-container-org4f12528">
<h2 id="org4f12528">PPM Output</h2>
<div id="text-org4f12528">
<p>
The decoded image is written to standard output in the form of a PPM file.
This is a <a href="http://netpbm.sourceforge.net/doc/ppm.html">wonderfully simple format</a> for writing that consist of a small
header indicating the image type, resolution, and maximum color value.  A
single <code>printf()</code> suffices for this (<i>238</i>).  Following this, the image
data itself is simply a series of unsigned bytes in interleaved RGB order
for each pixel and the pixels in left-to-right, top-to-bottom order
(<i>245–247</i>).  Because of the lossy format, the decompressed RGB values may
fall outside the 0 to 255 range, so a small helper function is used to
clamp and then write them:
</p>

<div>
<pre><span>109: </span><span>K</span>(b){
<span>110: </span>putchar(b&lt;0?0:b&gt;255?255:b);
<span>111: </span>}
</pre>
</div>
<div>
<pre><span>223: </span><span>int</span> <span>write_byte_clamped</span>( <span>int</span> <span>byte</span> )
<span>224: </span>{
<span>225: </span>    putchar( byte &lt; 0 ? 0 : byte &gt; 255 ? 255 : byte );
<span>226: </span>}
</pre>
</div>
</div>
</div>


<div id="outline-container-orgf3b7761">
<h2 id="orgf3b7761">YCgCo Color Space</h2>
<div id="text-orgf3b7761">
<p>
The compressed image data is not actually encoded using the usual RGB color
space, though of course it outputs this at the end.  Instead, it uses the
<a href="https://en.wikipedia.org/wiki/YCgCo">YCgCo</a> color space.  This is easily transformed back to RGB (<i>244–247</i>) but
has some nice properties where image compression is concerned.  Notably,
it decorrelates the <a href="https://en.wikipedia.org/wiki/Luma_(video)">luma</a> from the <a href="https://en.wikipedia.org/wiki/Chrominance">chroma</a> data.
</p>

<p>
To see this, lets look at the just the Y (luma) color channel of the
built-in image.  We can do this by zeroing out the Cg (green–magenta) and
Co (orange–blue) chroma channels before transforming back to RGB:
</p>


<figure>
<img src="http://eastfarthing.com/blog/2020-09-14-decoder/y.png" alt="y.png">

</figure>

<p>
Note how the result is simply the image in greyscale.
</p>

<p>
We can also look at the Cg channel in isolation by setting the Y values in
all pixels to 128 and the Co values in all pixels to zero.  This will show
us how the Cg data looks added to a neutral grey image:
</p>


<figure>
<img src="http://eastfarthing.com/blog/2020-09-14-decoder/cg.png" alt="cg.png">

</figure>

<p>
And we can do likewise to view the Co channel in isolation by setting the Y
values to 128 and the Cg values to zero:
</p>


<figure>
<img src="http://eastfarthing.com/blog/2020-09-14-decoder/co.png" alt="co.png">

</figure>

<p>
Hopefully it is clear now why this transform is useful: the majority of the
actual image detail is contained in the Y channel with only a little bit in
the Cg and Co channels.  Moreover, the human eye is more sensitive to
luminance than chrominance so by separating these out the encoder can
compress them with different degrees of lossiness.  This is why there are
not one but two image quality factors (<i>235–236</i>).
</p>

<p>
Many lossy image and video codecs, such as <a href="https://en.wikipedia.org/wiki/JPEG#Downsampling">JPEG</a>, offer an option called
<a href="https://en.wikipedia.org/wiki/Chroma_subsampling">chroma subsampling</a>.  When used, the luminance channel is typically stored
at full resolution while the chrominance channels are downscaled and stored
as a lower resolution image by the encoder, then upscaled by the decoder.
The tiny image decoder doesn’t bother with this.  Instead, the encoded
images just crank up the lossiness factor for the chrominance channels
(which JPEG images usually do too).
</p>

<p>
It’s also worth noting (<i>241–243</i>) that the decoder decompresses
the Y, Cg, and Co channels to a <a href="https://en.wikipedia.org/wiki/Planar_(computer_graphics)">planar format</a> in memory before writing the
transformed RGB values in the PPM-required <a href="https://en.wikipedia.org/wiki/Packed_pixel">interleaved</a> form.
</p>
</div>
</div>


<div id="outline-container-orgdf2665b">
<h2 id="orgdf2665b">Quadtree Traversal</h2>
<div id="text-orgdf2665b">
<p>
The actual extraction of the image to these planes in memory occurs
completely within the function called at line 237.  This is the main
routine for the higher level decoding of the image and is by far the
largest function in the program:
</p>

<div>
<pre><span> 61: </span><span>W</span>(z,l,g){
<span> 62: </span><span>int</span> <span>v</span>,<span>a</span>,<span>j</span>,<span>I</span>,<span>d</span>,<span>k</span>,<span>A</span>,*<span>o</span>,<span>c</span>,<span>B</span>,<span>q</span>,<span>C</span>,<span>h</span>,<span>w</span>,<span>J</span>;
<span> 63: </span><span>if</span>(g&gt;5||g&gt;2&amp;&amp;t(g-3)){
<span> 64: </span>c=1&lt;&lt;--g;
<span> 65: </span>e(a,4)W(z+a%2*c,l+a/2*c,g);
<span> 66: </span>}
<span> 67: </span><span>else</span>{
<span> 68: </span>c=1&lt;&lt;g;
<span> 69: </span>d=c*c;
<span> 70: </span>q=n(73);
<span> 71: </span>e(A,3){
<span> 72: </span>o=y[A]+l*f+z;
<span> 73: </span>B=A&gt;0;
<span> 74: </span>e(a,d)i[a]=0;
<span> 75: </span>e(a,d){
<span> 76: </span><span>if</span>(t(61+g*2+B))<span>break</span>;
<span> 77: </span>a+=n(5+B*10);
<span> 78: </span>k=1-2*t(3);
<span> 79: </span>i[a]=k*(n(25+(B+(a&lt;d/8)*2)*10)+1)*(A?P:O);
<span> 80: </span>}
<span> 81: </span><span>if</span>(<span>!</span>q){
<span> 82: </span>v=0;
<span> 83: </span>e(a,c){
<span> 84: </span>v+=l?o[-f+a]:0;
<span> 85: </span>v+=z?o[a*f-1]:0;
<span> 86: </span>}
<span> 87: </span>*i+=z&amp;&amp;l?v/2:v;
<span> 88: </span>}
<span> 89: </span>R(i+d,1,i,1,c,c,10);
<span> 90: </span>R(o,f,i+d,c,1,c,10+g);
<span> 91: </span><span>if</span>(q){
<span> 92: </span>C=q&lt;17;
<span> 93: </span>w=C?9-q:q-25;
<span> 94: </span>e(a,c)e(j,c){
<span> 95: </span>e(I,2){
<span> 96: </span>h=a*w+w;
<span> 97: </span>J=h&amp;7;
<span> 98: </span>h=(h&gt;&gt;3)+j+I;
<span> 99: </span><span>if</span>(k=h&lt;0)h=(h*8+w/2)/w-2;
<span>100: </span>h=h&lt;c?h:c-1;
<span>101: </span>i[I]=k^C?o[h*f-1]:o[-f+h];
<span>102: </span>}
<span>103: </span>o[C?j*f+a:a*f+j]+=*i*(8-J)+i[1]*J+4&gt;&gt;3;
<span>104: </span>}
<span>105: </span>}
<span>106: </span>}
<span>107: </span>}
<span>108: </span>}
</pre>
</div>
<div>
<pre><span>143: </span><span>void</span> <span>extract_block</span>( <span>int</span> <span>left</span>, <span>int</span> <span>top</span>, <span>int</span> <span>level</span> )
<span>144: </span>{
<span>145: </span>    <span>if</span> ( level &gt; 5 || level &gt; 2 &amp;&amp; decode_bit( level - 3 ) )
<span>146: </span>    {
<span>147: </span>        <span>int</span> <span>size</span> = 1 &lt;&lt; --level;
<span>148: </span>        <span>for</span> ( <span>int</span> <span>corner</span> = 0; corner &lt; 4; corner++ )
<span>149: </span>            extract_block( left + corner % 2 * size,
<span>150: </span>                           top  + corner / 2 * size,
<span>151: </span>                           level );
<span>152: </span>    }
<span>153: </span>    <span>else</span>
<span>154: </span>    {
<span>155: </span>        <span>int</span> <span>size</span> = 1 &lt;&lt; level;
<span>156: </span>        <span>int</span> <span>area</span> = size * size;
<span>157: </span>        <span>int</span> <span>predictor</span> = decode_unsigned( 73 );
<span>158: </span>        <span>for</span> ( <span>int</span> <span>channel</span> = 0; channel &lt; 3; channel++ )
<span>159: </span>        {
<span>160: </span>            <span>int</span> *<span>output</span> = image[ channel ] + top * width + left;
<span>161: </span>            <span>int</span> <span>is_chroma</span> = channel &gt; 0;
<span>162: </span>            <span>for</span> ( <span>int</span> <span>coefficient</span> = 0; coefficient &lt; area; coefficient++ )
<span>163: </span>                buffer[ coefficient ] = 0;
<span>164: </span>            <span>for</span> ( <span>int</span> <span>coefficient</span> = 0; coefficient &lt; area; coefficient++ )
<span>165: </span>            {
<span>166: </span>                <span>if</span> ( decode_bit( 61 + level * 2 + is_chroma ) )
<span>167: </span>                    <span>break</span>;
<span>168: </span> …</pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://eastfarthing.com/blog/2020-09-14-decoder/">http://eastfarthing.com/blog/2020-09-14-decoder/</a></em></p>]]>
            </description>
            <link>http://eastfarthing.com/blog/2020-09-14-decoder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24468039</guid>
            <pubDate>Mon, 14 Sep 2020 08:32:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm now a user of Vim, not classical Vi (partly because of windows)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24467213">thread link</a>) | @pcr910303
<br/>
September 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/VimNowAUser | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/VimNowAUser">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>I'm now a user of Vim, not classical Vi (partly because of windows)</h2>

	<p><small>September 13, 2020</small></p>
</div><div><p>In the past I've written entries (such as <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/ViAndVimAndMe">this one</a>)
where I said that I was pretty much a Vi user, not really a Vim user,
because I almost entirely stuck to Vi features. In a comment on <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/VimNotUsingFeatures">my
entry on not using and exploring Vim features</a>,
rjc reinforced this, saying that I seemed to be using vi instead of
vim (and that there was nothing wrong with this). For a long time I
thought this way myself, but these days this is not true any more.
These days I really want Vim, not classical Vi.</p>

<p>The clear break point where I became a Vim user instead of a Vi
user was when I started internalizing and heavily using Vim's
<a href="https://vimhelp.org/quickref.txt.html#Q_wi">(multi-)window commands</a>
(<a href="https://vimhelp.org/usr_08.txt.html#usr_08.txt">also</a>). I started
this as far back as 2016 (as signalled by <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/VimMotionCmdsToRemember">this entry</a>), but it took a while before I really had
the window commands sink in and habits regarding them become routine
(like using '<code>vi -o</code>' on most occasions when I'm editing multiple
files). I'm not completely fluid with Vim windows and I certainly
haven't mastered all the commands, but at this point I definitely
don't want to go back to not having them available.</p>

<p>(In my old vi days, editing multiple files was always a pain point
where I would start reaching for another editor. I just really want
to see more than one file on a screen at once in my usual editing
style. Sometimes I want to see more than one spot in a file at the
same time, too, especially when coding.)</p>

<p>I also very much want Vim's unlimited undo and redo, instead of a
limited size undo. There are a bunch of reasons for this, but one
of them is certainly that the Vi command set makes it rather easy
to accidentally do a second edit operation as you're twitching
around before you realize that you actually want to undo the first
one. This is especially the case if your edit operation was an
accident (where you hit the wrong keys by mistake or didn't realize
that you weren't in insert mode), or if you've developed the habit
of reflexively reflowing your current paragraph any time you pause
in writing.</p>

<p>(There are probably other vim features I've become accustomed to
without realizing it or without realizing that they're Vim features,
not basic Vi features. Everywhere I use 'vi', it's really Vim.)</p>

<p>Although I'm now unapologetically using vim, my vimrc continues to
be pretty minimal and is mostly dedicated to turning things off and
setting sensible (ie modern) defaults, instead of old vi defaults.
I'm unlikely to ever try to turn my vim into a superintelligent
editor for reasons beyond the scope of this entry.</p>

<p>(I do use one Vim plugin in some of my vim setups, Aristotle
Pagaltzis' <a href="https://github.com/ap/vim-buftabline/">vim-buftabline</a>.
I would probably be more enthused about it if I edited lots of files
at once in my vim sessions, but usually I don't edit more than a
couple at once.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/VimNowAUser</link>
            <guid isPermaLink="false">hacker-news-small-sites-24467213</guid>
            <pubDate>Mon, 14 Sep 2020 05:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[California’s Apocalyptic ‘Second Nature’]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24467050">thread link</a>) | @oldertimer
<br/>
September 13, 2020 | https://rosaluxnycblog.org/california-fires/ | <a href="https://web.archive.org/web/*/https://rosaluxnycblog.org/california-fires/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-592">

	<!-- .entry-header -->

	
	<div>
		
<figure><img data-attachment-id="594" data-permalink="https://rosaluxnycblog.org/california-fires/joshua-tree/" data-orig-file="https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?fit=1200%2C699&amp;ssl=1" data-orig-size="1200,699" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="joshua-tree" data-image-description="" data-medium-file="https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?fit=300%2C175&amp;ssl=1" data-large-file="https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?fit=1024%2C596&amp;ssl=1" loading="lazy" width="1024" height="596" src="https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=1024%2C596&amp;ssl=1" alt="" srcset="https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=1024%2C596&amp;ssl=1 1024w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=300%2C175&amp;ssl=1 300w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=768%2C447&amp;ssl=1 768w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=720%2C419&amp;ssl=1 720w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=560%2C326&amp;ssl=1 560w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=1024%2C596&amp;ssl=1 1024w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=300%2C175&amp;ssl=1 300w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=768%2C447&amp;ssl=1 768w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=720%2C419&amp;ssl=1 720w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=560%2C326&amp;ssl=1 560w, https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?w=1200&amp;ssl=1 1200w" data-lazy-src="https://i1.wp.com/rosaluxnycblog.org/wp-content/uploads/2020/09/joshua-tree.jpg?resize=1024%2C596&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Wildfire in Joshua Tree National Park in 2014 (National Park Service photo).</figcaption></figure>



<p>By Mike Davis</p>



<p>En route to Vegas and 20 minutes away from the state line, there is an exit from I-15 to a two-lane blacktop called Cima Road. It’s the unassuming portal to one of North America’s most magical forests: countless miles of old-growth Joshua trees mantling a field of small Pleistocene volcanoes known as Cima Dome. The monarchs of the forest are 45 feet high and 1,000 years old. In mid-August an estimated 1.3 million of these astonishing giant yuccas perished in the lightning-ignited Dome Fire. &nbsp;</p>



<p>This is not the first time that the Eastern Mojave Desert has burned, a megafire in 2005 scorched 1 million acres of desert, but it spared the Dome, the heart of the forest. Desert plants, unlike California oaks and chaparral, are not fire-adapted, so their recovery is an open question. The invasion of an alien bunch grass, known as Red Brome, has created a flammable understory to the Joshuas and transformed the Mojave into a fire ecology. (Invasive cheatgrass has played this role in the Great Basin for decades.) More frequent fires will accelerate vegetation change and ultimately threaten the existence of the trees.</p>



<p>Our burning deserts are regional expressions of a global trend. A world set on fire by climate change has unleashed a dangerous transformation of plant ecology, and thus faunal populations, from the Arctic to Patagonia, Montana to Mongolia. &nbsp;California is a paradigmatic example of such a vicious circle, where extreme heat leads to extreme fires that prevent natural rejuvenation and accelerate the conversion of iconic landscapes into depauperate grasslands and treeless mountain slopes.</p>



<p>At the beginning of this century, water planners and fire authorities were primarily focused on the threat of multi-year droughts caused by intensified La Niña episodes and stubbornly persistent high pressure domes—both of which could be attributed to anthropogenic warming.</p>



<p>Their worst fears were realized in the great drought of the last decade, the biggest in perhaps 500 years, which led to the death of millions of oaks and pines, which then provided fuel for the fire-storms in 2018 and 2019.</p>



<p>These recent catastrophes, however, have forced scientists to recognize a new phenomenon, the &nbsp;“hot drought.” Even in years with average 20th-century rainfall, extreme summer heat—our new normal—is producing massive water loss through evaporation in reservoirs and plant communities. A wet winter and early spring may mesmerize us with extravagant displays of flowering plants, but they also produce bumper crops of grasses and weeds that are then baked in our furnace summers to become fire starter when the devil winds return.</p>



<p>Residential development in high and extreme fire-danger areas, where a majority of new housing in the state has been constructed over the past twenty years, has also promoted the botanical counter-revolution as the thinning of forests and the clearing of chapparal opens new pathways for pyromaniacal black mustards and bromes. Weeds plus dead or drought-stressed trees is the shorthand formula for megafire.</p>



<p>Mediterranean vegetation (California west of the Sierras and south of Klamaths) has co-evolved with fire, and indeed oaks and most chaparral plants require episodic fire to reproduce. But routine extreme fire in Greece, Spain, Australia and California is now over-riding Holocene adaptations and producing irreversible changes in the biota. The only real constraint on future wildfire is available fuel mass. More areas will become like the Malibu Coast where fire burns in the same sector every decade or two as dictated by the 8-12 years required for coastal sage scrub to mature.</p>



<p>In the late 1940s the ruins of Berlin became a laboratory where natural scientists studied plant succession in the wake of three years of incessant fire bombing. The expectation was that the original vegetation of the region—oak woodlands and their shrubs—would soon reestablish itself. To their horror this was not the case. Instead escaped exotics, most of them alien to Germany, established themselves as the new dominants.</p>



<p>The botanists continued their studies until the last bomb sites were cleared in the 1980s. The persistence of this dead-zone vegetation and the failure of the plants of the Pomeranian woodlands to reestablish themselves prompted a debate about “Nature II.” The contention was that the extreme heat of incendiaries and the pulverization of brick structures had created a new soil type that invited colonization by plants such as the “tree of heaven” (<em>Ailanthus</em>) that had evolved on the moraines of Pleistocene ice sheets. An all-out nuclear war, they warned, might reproduce these conditions on a vast scale.</p>



<p>Fire in the Anthropocene has become the physical equivalent of endless nuclear war. In the aftermath of Victoria’s Black Saturday fires in early 2009, Australian scientists calculated that their released energy equaled the explosion of 1,500 Hiroshima-sized bombs. The current firestorms in the Pacific states are many times larger, and we should compare their destructive power to the mega-tonnage of hundreds of hydrogen bombs.</p>



<p>A new, profoundly sinister nature is rapidly emerging from our fire rubble at the expense of landscapes we once considered sacred. Our imaginations can barely encompass the speed or scale of the catastrophe. Gone California, gone.</p>



<p><em>Mike Davis is the author of “</em>City of Quartz<em>” and “</em>Ecology of Fear.<em>”&nbsp;</em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://rosaluxnycblog.org/california-fires/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24467050</guid>
            <pubDate>Mon, 14 Sep 2020 05:23:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buggy technology is indistinguishable from malware]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24466997">thread link</a>) | @frisco
<br/>
September 13, 2020 | https://maxhodak.com/nonfiction/2020/09/13/buggy-technology-malware.html | <a href="https://web.archive.org/web/*/https://maxhodak.com/nonfiction/2020/09/13/buggy-technology-malware.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  <p>A while ago, the camera on my phone started acting up: opening it would show an image for a couple seconds but then go black. Simultaneously, when I turned my wireless headphones on there would be a couple seconds of sidetone (hearing through your own microphone) before it cut to the expected silence.</p>

<p>I promptly got a new phone and the old one was sent to forensics.</p>

<p>A little while after that, my stereo receiver started randomly losing its internet connection, causing streaming from Spotify to break. If I reset it to factory settings – and retrained the room calibration, speaker configuration, etc – it would come back, but within a week it would decide to give up on internet connectivity once again.</p>

<p>All of this was both frustrating and unnerving. We’ve become inured to the poor reliability and security of modern electronics – they are simply too complicated – and one thing I’ve had a hard time reconciling is my feeling that we <em>have</em> to do better with the reality that most things do not experience a strong economic pressure to do so. It is extraordinarily expensive to develop avionics software and other similar safety-critical things, and this is a sign to me both that the fundamental toolchain is broken and that most consumers simply don’t care. Even after the <a href="https://en.wikipedia.org/wiki/Office_of_Personnel_Management_data_breach">OPM hack</a>, the <a href="https://en.wikipedia.org/wiki/Democratic_National_Committee_cyber_attacks">DNC cyberattacks</a>, the <a href="https://en.wikipedia.org/wiki/2017_Equifax_data_breach">Equifax breach</a>, and the <a href="https://en.wikipedia.org/wiki/Sony_Pictures_hack">Sony Pictures hack</a> still no one has developed any good firewalls I would actually trust with my life. They are all too complex, composed of millions of lines of unproven code written by humans.</p>

<p>Fundamentally, I see the problem as being the fact that the space of things a system <em>can</em> do being a tiny subset of things the systems is <em>physically capable</em> of doing.</p>

<p>
  <img src="https://maxhodak.com/images/system-function-bubble.png">
</p>

<p>There is no meaningful difference between buggy software and insecure software – security vulnerabilities are just bugs used for a malicious intent. In order to build truly secure systems, we must shrink the space of things the machine is capable of doing to things we want it to do and formally prove this.</p>

<p>It is enormously difficult to formally verify a program of any meaningful size. One common approach – used by some autopilots, among other things – is to write a model DSL and a small code generator that is feasible to formally verify, and then use that to generate the much larger source code of the actual program, which by extension is verified. This is a good idea and I’d love to see things like this used more widely.</p>

<p>Another approach is to use a language with lots of safety features like strong algebraic typing, immutable memory and no dynamic allocation. These are often functional languages and can go a long way towards making it so that if it compiles, it’s probably correct.</p>

<p>Ultimately you also need awareness of the hardware you are running on: no one was talking about speculative execution attacks five years ago, but now they’re just one example of practical attacks stemming from complex hardware performance optimizations.</p>

<p>I’m a big fan of <a href="https://sel4.systems/">SeL4</a> and especially its verified <a href="https://riscv.org/2020/06/sel4-is-verified-on-risc-v/">RISCV implementation</a>. Yes, RISCV made some microarchitecture trade-offs that are somewhat academically pure at a cost to practicality, but for something like a brain implant you definitely want to prioritize making the intended-behavior and possible-behavior bubbles as close to equal as possible.</p>

<p>The cryptocurrency world also feels these issues acutely: bugs in smart contracts quickly become large financial losses. Long term, I think the investments they are making into formal verification could be one of their largest contributions back to the broader ecosystem.</p>

<p>These problems are all things Neuralink is going to have to invest in over time in order to ensure that the implants are reliable and secure. We will probably need to go way beyond traditional guidelines like MISRA and develop more powerful formal verification tools and code generation for verified hardware, but I think that’s only the tip of the iceberg towards systems that I’d really trust to put in my brain and connect to an increasingly hostile internet. There definitely needs to be much greater investment in these kinds of things, and hopefully an ecosystem develops that explores many possible approaches in parallel.</p>

</div></div>]]>
            </description>
            <link>https://maxhodak.com/nonfiction/2020/09/13/buggy-technology-malware.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24466997</guid>
            <pubDate>Mon, 14 Sep 2020 05:15:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The compositor is evil]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24466929">thread link</a>) | @raphlinus
<br/>
September 13, 2020 | https://raphlinus.github.io/ui/graphics/2020/09/13/compositor-is-evil.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/ui/graphics/2020/09/13/compositor-is-evil.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>First, I want to make it clear that I’m not accusing the compositor of true evil, which I define roughly as deliberately causing suffering. There’s unfortunately too much of that in the world. I mean it in the more metaphorical sense that it causes serious problems and forces other parts of the system to be more complex to work around its limitations.</p>

<p>I will also outline a better design that might be implemented in the future, as well as some possibilities for how applications can deal with the current situation. But first, to understand better how we got into this mess, we’ll look a bit into the past.</p>

<h2 id="8-bit-systems-video-processing-engines">8-bit systems: video processing engines</h2>

<p>Early home computers and video games had 8-bit CPUs and only a few kilobytes of RAM. Some computers, like the Apple II, allocated some of the RAM as a frame buffer and used the CPU to fill it, but this approach is quite limiting. So designers of most other systems of the time got creative - in particular, they augmented the CPU with a graphics processing engine. This engine did a fair amount of processing during <em>scanout,</em> in other words on the fly as the system generated a video signal.</p>

<p>The details of these early graphics processors varied, but most were a combination of four basic operations:</p>

<ul>
  <li>Indirect lookup of tile images (also useful for text).</li>
  <li>Expansion of low bit depth pixels into more colors through a palette.</li>
  <li>Control over the offset in video memory to read (for scrolling effects).</li>
  <li>Overlay of small graphic elements (sprites).</li>
</ul>

<p>The combination of even a modest CPU and one of these video processing engines led to a creative explosion of games, with a unique aesthetic formed from the primitives provided by the video chip: colorful scrolling backgrounds formed from tiles, with the player avatar and other characters overlaid, also moving dynamically. One of the most popular (and best documented) such chips is the <a href="https://en.wikipedia.org/wiki/MOS_Technology_VIC-II">C64 VIC-II</a>, and of course the <a href="https://en.wikipedia.org/wiki/Picture_Processing_Unit">NES PPU</a> is another classic example. People still create software for these beloved systems, learning from tutorials such as <a href="https://dustlayer.com/vic-ii/2013/4/22/when-visibility-matters">VIC-II for beginners</a>.</p>

<p>While the constraints of the hardware served as artistic inspiration for a diverse and impressive corpus of games, they also limited the kind of visual expression that was possible. For example, any attempt at 3D was primitive at best (though there were driving games that did impressive attempts, using the scrolling and color palette mechanisms to simulate a moving roadway).</p>

<p>The most ambitious games and demos agressively poked at the hardware, “racing the beam” to dynamically manipulate the registers in the video chip, unlocking more colors and other graphical effects that no doubt were not even anticipated by the original designers of the hardware.</p>

<p>Also worth mentioning as an extreme example is the Atari 2600, which had all of 20 bits (that’s right, two and a half bytes) devoted to what might be considered a frame buffer. Basically all graphical effects needed to be implemented by racing the beam. Fortunately, the programmer could make use of the deterministic cycle counts for instructions on the 6502 microprocessor, so that writes to the video registers would happen with timing considerably finer than one scan line. Even so, it requires some <a href="https://gist.github.com/anonymous/67b32347d5ca97d21a4c9e69a3b1a1a3">fairly tricky code</a> to even display the <a href="https://8bitworkshop.com/v3.6.0/embed.html?p=vcs&amp;r=TFpHAAAQAAAAAR1Ufls8AQMFDBJ42KIAiqjKmkjQ%2B6kOhQKFAErQ%2Ba2EAgyGCanGhQaFB6kAhQipGIUKDI%2BiJYUCytD7hgGgB4YNhg6GD4UCBADqEg%2BFEIURhQKI0PugEKIMeQ2FDrki8YUPuVXxhRu5ZfGFBLkz8YUNuUTxhQ4MFww%2BytDYuQAMSxEMCwyk6uoFDhyI0LKgOAUERgzH%2B6kChQGpIYUCjZYCBQOXTAvwABIeEgb8rFz4wPwE9BIDBPwAAPCgUPAw8ADwEgMA8AAAwMDAgADAQBIFwAUJNGwAqAULRDcSIRIR%2FxIfEh8SHxIfEh8SHxIfEh8SHxIfEh8SHxIfEh8SHxIfEh8SHxIfEh8SHxIfEh8SHxIfEh8SHxIfEh4SHBIIAPAA8A%3D%3D">Recurse Center logo</a> in all three colors.</p>

<p>An important aspect of all these systems, even those as underpowered as the Atari 2600, is that latency was <em>very</em> low. A well coded game might process the inputs during the vertical blanking interval, updating scroll and sprite coordinates (just a few register pokes), so they apply to the next frame being scanned out - latency under 16ms. Similar math applies to the latency of typing, which is why the Apple IIe <a href="https://danluu.com/input-lag/">scores so well</a> on latency tests compared to modern computers.</p>

<h2 id="16-and-32-bit-home-computers-cpu--framebuffer">16 and 32 bit home computers: CPU + framebuffer</h2>

<p>Through the late 80s, while arcade games continued to evolve their graphics hardware, the IBM PC became ascendant as a home computer. From its roots as a “business” computer, its CPU performance and RAM grew dramatically, but video output was generally a framebuffer with almost none of the capabilities listed above. Even so, display resolutions and bit depths improved (VGA was 640x480 with 16 colors per pixel). A reasonably powerful CPU, especially in the hands of an expert coder, can produce rather impressive graphics. An example is Microsoft Flight Simulator, which had 3D graphics, fully drawn in software.</p>

<p>Another landmark release was the original Doom, released in 1993, which also was entirely software-rendered graphics, complete with lighting and textures.</p>

<p>The rendering of UI and 2D graphics continued to evolve during this time as well, with proportional spaced fonts becoming the standard, and <a href="http://www.truetype-typography.com/ttalias.htm">antialiased font rendering</a> slowly becoming standard as well during the 90s. (Likely the <a href="https://telcontar.net/Misc/GUI/RISCOS/#text">Acorn Archimedes</a> was the first to ship with antialiased text rendering, around 1992)</p>

<h2 id="multiple-windows-and-process-separation">Multiple windows and process separation</h2>

<p>A trend at the same time was the ability to run multiple applications, each with their own window. While the idea had been around for a while, it burst on to the scene with the Macintosh, and the rest of the world caught up shortly after.</p>

<p>Early implementations did <em>not</em> have “preemptive multitasking,” or what we would call process separation. Applications, even when running in windowed mode, wrote directly into the framebuffer. The platform basically provided a library for applications to keep track of visible regions, so they wouldn’t paint in regions where the window was occluded. Related, when an occluding window went away, the system would notify the application it needed to repaint (WM_PAINT on Windows), and, because computers were slow and this took a while, the “damage region” was visible for a bit (this is explained and animated in Jasper St. Pierre’s <a href="https://magcius.github.io/xplain/article/x-basics.html">X Window System Basics</a> article).</p>

<p>In this early version of windowing GUI, latency wasn’t seriously affected. Some things were slower because resolution and bit depth was going up, and of course text needed to be rendered into bitmaps (more computationally expensive with antialiasing), but a well-written application could still be quite responsive.</p>

<p>However, running without process separation was a serious problem, if for no other reason than the fact that a misbehaving application could corrupt the entire system; consumer desktop systems were seriously behind the Unix/X11 ecosystem in this regard. System crashes were extremely common in the days of pre-X Mac OS, and pre-NT Windows (though Windows 95 had a limited form of process separation in that the display server bounded the window’s drawing area). Certainly in the Unix tradition, applications would run in their own process, with some kind of client-server protocol to combine the presentation of the multiple applications together. The X System (aka X11) came to dominate in Unix, but before that there were many other proposals, notably <a href="https://en.wikipedia.org/wiki/Blit_(computer_terminal)">Blit</a> and <a href="https://en.wikipedia.org/wiki/Blit_(computer_terminal)">NeWS</a>. Also common to the Unix tradition, these would commonly run across a network.</p>

<h2 id="apples-aqua-compositor">Apple’s Aqua compositor</h2>

<p>When <a href="https://en.wikipedia.org/wiki/Mac_OS_X_10.0">OS X</a> (now macOS) first shipped in 2001, it was visually striking in a number of ways. Notably for this discussion, the contents of windows were blended with full alpha transparency and soft shadows. At the heart of this was a <em>compositor.</em> Applications did not draw directly to the screen, but to off-screen buffers which were then composited using a special process, <a href="https://en.wikipedia.org/wiki/Quartz_Compositor">Quartz Compositor</a>.</p>

<p>In the first version, all the drawing and compositing was done in software. Since machines at the time weren’t particularly powerful, performance was bad. According to a <a href="https://arstechnica.com/gadgets/2011/05/mac-os-x-revisited/2/">retrospective review</a>, “in its initial incarnation, Aqua was unbearably slow and a huge resource hog.”</p>

<p>Even so, things improved. By 10.2 (Jaguar) in August 2002, Quartz Extreme did the compositing in the GPU, finally making performance comparable to pre-compositor designs.</p>

<p>While there have been changes (discussed in some detail below), Quartz Compositor is fundamentally the modern compositor design used today. Microsoft Vista adopted a similar design with <a href="https://docs.microsoft.com/en-us/windows/win32/dwm/dwm-overview">DWM</a>, first in Vista, and made non-optional by Windows 8. Also, while I consider Aqua the first real <a href="https://en.wikipedia.org/wiki/Compositing_window_manager">compositor</a> in the modern sense, there were important predecessors, notably the Amiga. Jasper St. Pierre points out that Windows 2000 had a limited compositor, known as <a href="https://docs.microsoft.com/en-us/windows/win32/winmsg/window-features#layered-windows">“layered windows”</a>, where certain windows could be redirected offscreen.</p>

<h2 id="doing-more-in-the-compositor">Doing more in the compositor</h2>

<p>Using the GPU to just bitblt window contents is using a tiny fraction of its capabilities. In the compositing process, it could be fading in and out alpha transparency, sliding subwindows around, and applying other effects without costing much at all in performance (the GPU is already reading all the pixels from the offscreen buffers and writing to the display surface). The only trick is exposing these capabilities to the application.</p>

<p>On the Apple side, this was driven by iOS and its heavy reliance on <a href="https://developer.apple.com/documentation/quartzcore">Core Animation</a>. The idea is that “layers” can be drawn using relatively slow software rendering, then scrolling and many other effects can be done smoothly at 60fps by compositing these layers in the GPU.</p>

<p>Core Animation was also made available in Mac OS 10.5 (Leopard). The corresponding Windows version was <a href="https://docs.microsoft.com/en-us/windows/win32/directcomp/directcomposition-portal">DirectComposition</a>, introduced in Windows 8 and a core feature of the <a href="https://en.wikipedia.org/wiki/Metro_(design_language)">Metro</a> design language (which was not very popular at the time).</p>

<p>These features have made the compositor more integral to modern GUI software, though there is a range of how aggressively applications make use of compositor feature.</p>

<h2 id="where-does-the-latency-come-from">Where does the latency come from?</h2>

<p>I talk a lot about latency, but let’s understand why introducing the compositor fundamentally adds so much of it. Some of this is also discussed in the blog post <a href="http://www.lofibucket.com/articles/dwm_latency.html">Desktop compositing latency is real and it annoys me</a> (also see <a href="https://news.ycombinator.com/item?id=15747650">HN discussion</a>).</p>

<p>The amount of time needed to render a frame of content varies. If the goal is smooth 60fps (as I think it should be!) then …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/ui/graphics/2020/09/13/compositor-is-evil.html">https://raphlinus.github.io/ui/graphics/2020/09/13/compositor-is-evil.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/ui/graphics/2020/09/13/compositor-is-evil.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24466929</guid>
            <pubDate>Mon, 14 Sep 2020 05:03:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The C++ Bestiary]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24466778">thread link</a>) | @signa11
<br/>
September 13, 2020 | http://videocortex.io/2017/Bestiary/ | <a href="https://web.archive.org/web/*/http://videocortex.io/2017/Bestiary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  

  <section>
    <p>Spooky Halloween C++ Special!</p>

<p><img src="http://videocortex.io/assets/Halloween/pumpkin.jpg" alt="pumpkins"></p>





<h2 id="a-compendium-of-cryptic-characters">A Compendium of Cryptic Characters</h2>

<p>C++ is blessed with a plethora of gotchas, traps, caveats, pitfalls and footguns. Within the C++ dungeons lurk many shady characters. ‘Tis the time of year to meet some of these bountifully spawned beasts.</p>

<ul id="markdown-toc">
  <li><a href="#a-compendium-of-cryptic-characters" id="markdown-toc-a-compendium-of-cryptic-characters">A Compendium of Cryptic Characters</a>    <ul>
      <li><a href="#-abominable-types" id="markdown-toc--abominable-types">⛄ Abominable Types</a></li>
      <li><a href="#-aliens" id="markdown-toc--aliens">👽 Aliens</a></li>
      <li><a href="#-demons" id="markdown-toc--demons">👹 Demons</a></li>
      <li><a href="#-dll-hell" id="markdown-toc--dll-hell">👿 DLL Hell</a></li>
      <li><a href="#-duck-typing" id="markdown-toc--duck-typing">🦆 Duck Typing</a></li>
      <li><a href="#-flying-saucers" id="markdown-toc--flying-saucers">🛸 Flying Saucers</a></li>
      <li><a href="#-imps" id="markdown-toc--imps">😈 Imps</a></li>
      <li><a href="#️-shadow-variables" id="markdown-toc-️-shadow-variables">🕴️ Shadow Variables</a></li>
      <li><a href="#-terminators" id="markdown-toc--terminators"><img src="http://videocortex.io/assets/terminator_robot_head.gif" alt="terminator"> Terminators</a></li>
      <li><a href="#-transparent-objects" id="markdown-toc--transparent-objects">👻 Transparent Objects</a></li>
      <li><a href="#-unicorns" id="markdown-toc--unicorns">🦄 Unicorns</a></li>
      <li><a href="#-voldemort-types" id="markdown-toc--voldemort-types">💀 Voldemort Types</a></li>
      <li><a href="#-zombies" id="markdown-toc--zombies">🧟 Zombies</a></li>
      <li><a href="#️-zombies--brains-" id="markdown-toc-️-zombies--brains-">🧟‍♀️ Zombies &amp; Brains 🧠</a></li>
    </ul>
  </li>
  <li><a href="#terminus" id="markdown-toc-terminus">Terminus</a></li>
</ul>

<p>🎃</p>

<h3 id="-abominable-types">⛄ Abominable Types</h3>
<p><em>“There is a dark corner of the type system that is little known other than to compier writers…”  <br>
– <a href="https://twitter.com/alisdairmered">Alisdair Meredith</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0172r0.html">Abominable Function Types</a></em></p>

<p><img src="http://videocortex.io/assets/Halloween/abominable.jpg" width="200px">An <em>abominable</em> function type is the type produced by writing a function type followed by a <em>cv-ref</em> qualifier.</p>

<div><div><pre><code><span>using</span> <span>abominable</span> <span>=</span> <span>void</span><span>()</span> <span>const</span> <span>volatile</span> <span>&amp;&amp;</span><span>;</span>
</code></pre></div></div>

<p><code>abominable</code> names a <em>function type</em>, <em>not</em> a reference type, and despite appearances, is neither a <code>const</code> nor a <code>volatile</code> qualified type. There is no such thing as a <em>cv-qualified function type</em> in the type system, and the abominable function type is something else entirely.<br>
Note that it is <strong>impossible</strong> to create a function that has an abominable type!
<br clear="left"></p>

<p><em>“The only examples I have of explicitly writing these types fall into the category of showing off knowledge of the corners of compilers, and winning obfuscated coding contests.<br>
I have not yet encountered the following idiom in real-world usage outside of such scenarios.”  – ibid</em></p>

<div><div><pre><code><span>struct</span> <span>rectangle</span> 
<span>{</span>
    <span>using</span> <span>int_property</span> <span>=</span> <span>int</span><span>()</span> <span>const</span><span>;</span>                     <span>// common signature for several methods</span>
    <span>int_property</span> <span>top</span><span>,</span> <span>left</span><span>,</span> <span>bottom</span><span>,</span> <span>right</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>;</span> <span>// declare property methods! </span>
    <span>// ...                                                                    ^^^^^^^</span>
<span>};</span>
</code></pre></div></div>

<p>Spooked? Curious? Read more in <em><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0172r0.html">Tales of the Abominable Function Types!</a></em><br>
<em>Mwahahahah…</em></p>
<p>🎃</p>

<h3 id="-aliens">👽 Aliens</h3>
<p><em><strong>Bishop</strong>: No, the hard-wiring between here and there was damaged. We can’t <strong>align</strong> the dish.<br>
<strong>Ripley</strong>: Well, then somebody has got to go out there, take a portable terminal, and patch in manually.<br>
– Aliens 1986</em></p>

<p><img src="http://videocortex.io/assets/Halloween/aliens.jpg" width="200px">Stretching it a bit thin so forgive my “silly” typo, and let’s mention <code>alignas</code> (which when squinting hard enough you might just read as <code>aliens</code>) and its kin. The <a href="http://en.cppreference.com/w/cpp/language/alignas"><code>alignas</code> keyword specifier</a> was introduced in C++11. It specifies the <a href="http://en.cppreference.com/w/cpp/language/object#Alignment">alignment requirement</a> of a type or an object.</p>

<p><em>Every object type has the property called alignment requirement, which is an integer value (of type <code>std::size_t</code> and always a power of 2) representing the number of bytes between successive addresses at which objects of this type can be allocated. The alignment requirement of a type can be queried with <code>alignof</code> or <code>std::alignment_of</code>. The pointer alignment function <code>std::align</code> can be used to obtain a suitably-aligned pointer within some buffer, and <code>std::aligned_storage</code> can be used to obtain suitably-aligned storage. Each object type imposes its alignment requirement on every object of that type; stricter alignment (with larger alignment requirement) can be requested using <code>alignas</code>. In order to satisfy alignment requirements of all non-static members of a class, padding may be inserted after some of its members.</em></p>

<p>🎃</p>

<h3 id="-demons">👹 Demons</h3>
<p><em>“Permissible undefined behavior ranges from ignoring the situation completely with unpredictable results, to having <strong>demons</strong> fly out of your nose.”<br>
– John F. Woods, <a href="https://groups.google.com/forum/?hl=en#!msg/comp.std.c/ycpVKxTZkgw/S2hHdTbv4d8J">comp.std.c 1992</a></em></p>

<p><img src="http://videocortex.io/assets/Halloween/demon.jpg" width="200px"> The most notorious and infamous of all is probably the Nasal Demon of <strong>Undefined Behavior</strong>.<br>
With its ancient origins in the C language, it predates many of the other members of this list. Nevertheless, it is still an ever present threat and terror to the unsuspecting journeyman.</p>

<p>In <a href="http://en.cppreference.com/w/cpp/language/ub">short</a>, <em>Undefined Behavior (UB)</em> renders the <em>entire</em> program meaningless if certain rules of the language are violated.</p>

<p>A lot has been written about UB. <a href="https://twitter.com/johnregehr">John Regehr</a> has a facinating <a href="https://blog.regehr.org/archives/213">series on UB</a> and an <a href="https://blog.regehr.org/archives/1520">update on Undefined Behavior in 2017</a> too. His <a href="https://youtu.be/v1COuU2vU_w">two</a> <a href="https://youtu.be/TPyLrJED0zQ">part</a> CppCon 2017 <a href="https://youtu.be/v1COuU2vU_w">“Undefined Behavior in 2017”</a> videos are online too.</p>

<p><strong>STARTLING NEW EPIC:</strong> In Sept. 2017, the Demon showed it still has what it takes when a short UB snippet went <a href="https://www.reddit.com/r/cpp/comments/6xeqr3/compiler_undefined_behavior_calls_nevercalled/">viral</a>:</p>

<div><div><pre><code><span>#include &lt;cstdlib&gt;                                    // for system()
</span><span>typedef</span> <span>int</span> <span>(</span><span>*</span><span>Function</span><span>)();</span>                            <span>// typedef function pointer type  </span>
<span>static</span> <span>Function</span> <span>Do</span><span>;</span>                                   <span>// define function pointer, default initialized to 0 </span>
<span>static</span> <span>int</span> <span>EraseAll</span><span>()</span> <span>{</span> <span>return</span> <span>system</span><span>(</span><span>"rm -rf /"</span><span>);</span>  <span>}</span> <span>// naughty function</span>
<span>void</span> <span>NeverCalled</span><span>()</span>    <span>{</span> <span>Do</span> <span>=</span> <span>EraseAll</span><span>;</span>              <span>}</span> <span>// this function is never called!</span>
<span>int</span> <span>main</span><span>()</span>            <span>{</span> <span>return</span> <span>Do</span><span>();</span>                <span>}</span> <span>// call default-initialized function=UB: chaos ensues.</span>
</code></pre></div></div>
<p>which Clang  compiles to</p>

<pre><code>main:
        movl    $.L.str, %edi
        jmp     system

.L.str:
        .asciz  "rm -rf /"
</code></pre>
<p>That is, the compiled program executes <code>rm -rf /</code> even though the original program never calls <code>EraseAll()</code>! However, Clang is allowed to do this since the function pointer <code>Do</code> is initialized to <code>0</code> as it is a static variable, and calling <code>0</code> invokes undefined behavior – but it may seem strange that the compiler chooses to generate this code. It does, however, follow naturally from how compilers analyze programs…</p>

<p>Read more about this cryptic tale <a href="https://kristerw.blogspot.co.il/2017/09/why-undefined-behavior-may-call-never.html">here</a>.</p>

<p>🎃</p>

<h3 id="-dll-hell">👿 DLL Hell</h3>
<p><em>“There is no greater sorrow then to recall our times of joy in wretchedness.”<br>
― Dante Alighieri, Inferno</em></p>

<div><p><img src="http://videocortex.io/assets/Halloween/hell.jpg" width="200px"> <a href="https://en.wikipedia.org/wiki/DLL_Hell">DLL Hell</a> is a term for the complications that arise when working with dynamic link libraries (DLLs) used with Microsoft Windows operating systems.<br>
DLL Hell can manifest itself in many different ways in which applications do not launch or work correctly. Like Dante’s Inferno <a href="http://historylists.org/art/9-circles-of-hell-dantes-inferno.html">Circles of Hell</a>, DLL Hell is the Windows ecosystem-specific form of the general concept <a href="https://en.wikipedia.org/wiki/Dependency_hell">Dependency Hell</a>.</p></div>
<p>🎃</p>

<h3 id="-duck-typing">🦆 Duck Typing</h3>
<p><em>“If it looks like a duck and quacks like a duck but it needs batteries, you probably have the wrong abstraction.”<br>
– <a href="https://lostechies.com/derickbailey/2009/02/11/solid-development-principles-in-motivational-pictures/">The Internets on the Liskov Substitution Principle</a></em></p>

<p><img src="http://videocortex.io/assets/Halloween/duckula.jpg" width="200px"><a href="https://en.wikipedia.org/wiki/Duck_typing"><em>Duck typing</em></a> is an application of <em>The Duck Test</em> in type safety.<br>
<a href="https://en.wikipedia.org/wiki/Duck_test"><em>The Duck Test</em></a> is a form of <a href="https://en.wikipedia.org/wiki/Abductive_reasoning"><em>abductive reasoning</em></a>.<br>
This is its usual expression:</p>

<p><em>If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.</em></p>

<div><p>“Classic” Duck Typing requires that type checking be deferred to runtime and is mostly relevant to dynamically typed languages (unlike C++). However, templates or generic functions or methods apply the duck test in a <em>static</em> typing context.  </p><p>

In fact, one of the main reasons for C++ Concepts (if/when) they finally land, is to bring a more disciplined approach to template type specification and … well..</p></div>

<p><strong><em>Be vewy vewy quiet… it’s Duck Typing Season</em></strong>.</p>
<p><img src="http://videocortex.io/assets/Halloween/duck_season.gif" width="400px"><br>Concepts vs. Duck Typing</p>

<p><strong><em>Wead mowe <a href="http://www.drdobbs.com/templates-and-duck-typing/184401971">hewe.</a></em></strong></p>

<p>🎃</p>

<h3 id="-flying-saucers">🛸 Flying Saucers</h3>
<p><em>“Unknown objects are <strong>operating</strong> under intelligent control…<br>
It is imperative that we learn where UFOs come from and what their purpose is…” <br>
– Admiral Hillenkoetter, First CIA Director 1960</em></p>

<p><img src="http://videocortex.io/assets/Halloween/ufo.jpg" width="200px">C++20 may see the invasion of a new operator into the language:<br>
<strong>The &lt;=&gt; Spaceship Operator!</strong><br>
This is a single, 3-way comparison, <code>&lt;=&gt;</code> operator, that once defined allows the compiler to automatically generate all other comparison operators: <code>&lt;</code>, <code>&lt;=</code>, <code>==</code>, <code>!=</code>, <code>&gt;=</code>, <code>&gt;</code>. It provides a consistent interface and support for partial ordering and other goodies.</p>

<p>Walter E. Brown gave a <a href="https://youtu.be/_PKpyD6Ba1s">lightning talk</a> about it at CppCon 2017 and the latest proposal is <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0515r2.pdf">P0515R2</a>.</p>


<p>🎃</p>

<h3 id="-imps">😈 Imps</h3>
<p><em>“It’s easy to confuse ‘what is’ with ‘what ought to be,’ especially when ‘what is’ has worked out in your favor.”<br>
– Tyrion Lannister, A.K.A. <strong>“The Imp”</strong></em></p>

<p><img src="http://videocortex.io/assets/Halloween/TheBottleImp.jpg" width="200px">The C++ standard mentions <a href="http://eel.is/c++draft/intro.defs#defns.undefined">undefined behavior</a> Demon’s two less dangerous brothers, <a href="http://eel.is/c++draft/intro.defs#defns.unspecified"><em>unspecified behavior</em></a> and the <a href="http://eel.is/c++draft/intro.defs#defns.impl.defined"><em>implementation-defined behavior Imp</em></a>.</p>

<p><strong>Implementation-defined behavior</strong>: unspecified behavior where each implementation documents how the choice is made.<br>
In <em>implementation-defined behavior</em> the implementation is <em>required</em> to document/guarantee what exactly is going to happen, while in case of <em>unspecified behavior</em> the implementation is <em>not</em> required to document or guarantee anything.
<br clear="left">
Imps come in many form - <a href="http://eel.is/c++draft/impldefindex">here’s an impressive (if disheartening) list of known Imps</a>.<br>
<a href="https://stackoverflow.com/q/2397984/135862">Read more</a> if you dare!</p>
<p>🎃</p>

<h3 id="️-shadow-variables">🕴️ Shadow Variables</h3>
<p><em>“Only a lone foe could pierce that cordon; once inside, he would have to move by stealth, and strike with power and suddenness. I chose that mission.”<br>
-– The Shadow, <a href="http://thelivingshadow.wikia.com/wiki/Shadow_Magazine_Vol_1_131">Shadow Magazine #131 1937</a></em></p>

<p><img src="http://videocortex.io/assets/Halloween/shadow.jpg" width="200px"><a href="https://en.wikipedia.org/wiki/Variable_shadowing">Variable shadowing</a> occurs when a variable declared within a certain scope (e.g a block, a function) has the same name as a variable declared in an outer scope. The outer variable is said to be shadowed by the inner variable, while the inner identifier is said to mask the outer identifier. This can lead to confusion, as it may be unclear which variable subsequent uses of the shadowed variable name refer to, which depends on the name resolution rules of the language. In each scope, the same name or identifier may refer to a different variable with a completely different type.<br>
Variable shadowing is by no means limited to C++.</p>

<p>See an extreme example <a href="https://godbolt.org/g/WV7DMC">here</a>.</p>

<div><div><pre><code><span>bool</span> <span>x</span> <span>=</span> <span>true</span><span>;</span>                                              <span>// x is a bool</span>
<span>auto</span> <span>f</span><span>(</span><span>float</span> <span>x</span> <span>=</span> <span>5.</span><span>f</span><span>)</span> <span>{</span>                                     <span>// x is a float</span>
    <span>for</span> <span>(</span><span>int</span> <span>x</span> <span>=</span> <span>0</span><span>;</span> <span>x</span> <span>&lt;</span> <span>1</span><span>;</span> <span>++</span><span>x</span><span>)</span> <span>{</span>                           <span>// x is an int</span>
        <span>[</span><span>x</span> <span>=</span> <span>std</span><span>::</span><span>string</span><span>{</span><span>"Boo!"</span><span>}](){</span>                        <span>// x is a std::string</span>
            <span>{</span> <span>auto</span> <span>[</span><span>x</span><span>,</span><span>_</span><span>]</span> <span>=</span> <span>std</span><span>::</span><span>make_pair</span><span>(</span><span>42ul</span><span>,</span> <span>nullptr</span><span>);}</span>  <span>// x is now unsigned long</span>
        <span>}();</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>
<p clear="left">🎃</p>

<h3 id="-terminators"><img src="http://videocortex.io/assets/terminator_robot_head.gif" alt="terminator"> Terminators</h3>
<p><em>“Hasta la vista, baby!” <br>
– Terminator</em></p>

<p><img src="http://videocortex.io/assets/Halloween/terminator.jpg" width="200px">C++ provides surprisingly numerous ways for a program to terminate. These include both normal and unexpected termination.<br>
When writing robust software and libraries, it is important to be be aware of the various ways your code might abruptly end. Similarly, many of these conditions might occur at module-boundaries such as DLLs.<br>
Amongst the standard C++ program terminators we find: multiple flavors of <code>std::exit()</code>, <code>std::abort()</code>, <code>std::terminate()</code>, <code>std::signal()</code> and <code>std::raise()</code>.</p>


<p>🎃</p>

<h3 id="-transparent-objects">👻 Transparent Objects</h3>
<p><em>“a thing and not a man; a child, or even <code>std::less&lt;&gt;</code> – a black amorphous …</em></p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://videocortex.io/2017/Bestiary/">http://videocortex.io/2017/Bestiary/</a></em></p>]]>
            </description>
            <link>http://videocortex.io/2017/Bestiary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24466778</guid>
            <pubDate>Mon, 14 Sep 2020 04:34:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding How Gaussian Blur Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24465615">thread link</a>) | @aryamansharda
<br/>
September 13, 2020 | https://digitalbunker.dev/2020/09/13/understanding-gaussian-blurs/ | <a href="https://web.archive.org/web/*/https://digitalbunker.dev/2020/09/13/understanding-gaussian-blurs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
<p>Let’s take a detailed look at the implementation behind Gaussian blurs. It’s the image processing algorithm that enables image manipulations like this:</p>
<div><figure><img src="https://i1.wp.com/www.researchgate.net/publication/337080453/figure/fig5/AS:822588544647171@1573131800889/different-levels-of-Gaussian-Blur.jpg?w=1200&amp;ssl=1" alt="different levels of Gaussian Blur | Download Scientific Diagram" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/www.researchgate.net/publication/337080453/figure/fig5/AS:822588544647171@1573131800889/different-levels-of-Gaussian-Blur.jpg?w=1200&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>We’ll start by reviewing Gaussian distributions and image convolution – the driving forces behind Gaussian blurs. Then, we’ll implement our own Gaussian blur algorithm from scratch with Swift.&nbsp;</p>
<blockquote><p>If you haven’t already read my article about <a href="https://digitalbunker.dev/2020/08/28/how-does-edge-detection-work/" target="_blank" rel="noreferrer noopener">edge detection in images</a>, I’d recommend you read that first. It’ll help establish a foundation around convolution and the fundamentals of image processing.&nbsp;</p></blockquote>
<h2>Convolution</h2>
<p>In simple terms, convolution is simply the process of taking a small matrix called the kernel and running it over all the pixels in an image. At every pixel, we’ll perform some math operation involving the values in the convolution matrix and the values of a pixel and its surroundings to determine the value for a pixel in the output image. </p>
<div><figure><img src="https://i1.wp.com/docs-assets.developer.apple.com/published/09348c5368/a55b1477-4f79-4221-8aa1-ab3ae9f01f89.png?w=1200&amp;ssl=1" alt="Blurring an Image | Apple Developer Documentation" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/docs-assets.developer.apple.com/published/09348c5368/a55b1477-4f79-4221-8aa1-ab3ae9f01f89.png?w=1200&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Image Convolution</figcaption></figure></div>
<p>By changing the values in the kernel, we can change the effect on the image – blurring, sharpening, edge detection, noise reduction, etc. </p>
<blockquote><p>Convolution will be clearer once we see an example.</p></blockquote>
<h2>Gaussian Distributions</h2>
<p>Next, let’s turn to the Gaussian part of the Gaussian blur. Gaussian blur is simply a method of blurring an image through the use of a Gaussian function. </p>
<blockquote><p>You may have heard the term Gaussian before in reference to a <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank" rel="noreferrer noopener">Gaussian distribution (a.k.a. normal distribution)</a>.</p></blockquote>
<p>Below, you’ll see a 2D Gaussian distribution. Notice that there is a peak in the center and the curve flattens out as you move towards the edges.&nbsp;</p>
<div><figure><img src="https://lh5.googleusercontent.com/Q73cvNltSuV3L-IDuHO5FsvGLk75aMiO7r0XQq0eQlEdIybmgzxkafvlIUs8kjVzgga2O1kGjKINOOfVAwyJp5xWL_Dns0QKBp2jNVdrCVfiuGOztLyROPG1qOgjApO4U5l-8q8b" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>Imagine that this distribution is superimposed over a group of pixels in an image. It should be apparent looking at this graph, that if we took a weighted average of the pixel’s values and the height of the curve at that point, the pixels in the center of the group would contribute most significantly to the resulting value. This is, in essence, how Gaussian blur works.</p>
<blockquote><p>TLDR: A Gaussian blur is applied by convolving the image with a Gaussian function. </p></blockquote>
<p>In English, this means that we’ll take the Gaussian function and we’ll generate an <code>n x m</code> matrix. Using this matrix and the height of the Gaussian distribution at that pixel location, we’ll compute new RGB values for the blurred image.</p>
<h2>Overview</h2>
<p>To start off, we’ll need the Gaussian function in two dimensions:&nbsp;</p>
<div><figure><img loading="lazy" src="https://lh4.googleusercontent.com/k3HBCpKjbajv6jtn47G4AiRSe7EaFJkdAE2tzyhk7Ka8a05Bn0ZUHROsvOQC9iY8GPu8nCit45OOE0bybFW1kzaJp23TDxoKZHnVTinkMs3jkslLIXC1vmk4UalsnoMRnItqQl0v" alt="" width="284" height="78" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>The values from this function will create the convolution matrix / kernel that we’ll apply to every pixel in the original image. The kernel is typically quite small – the larger it is the more computation we have to do at every pixel.&nbsp;</p>
<p><code>x</code> and <code>y</code> specify the delta from the center pixel (0, 0). For example, if the selected radius for the kernel was 3, <code>x</code> and <code>y</code> would range from -3 to 3 (inclusive).&nbsp;</p>
<p><em><code>σ</code></em> – the standard deviation – influences how significantly the center pixel’s neighboring pixels affect the computations result.&nbsp;</p>
<blockquote><p>Technically, in a Gaussian function, because it extends infinitely, you could argue that you’d need to consider every pixel in the image to get the “correct” blur effect, but in practice pixels beyond 3<em>σ</em> have very little impact on the resulting values.</p></blockquote>
<h2>Implementation</h2>
<p>We’re almost ready to start the implementation. </p>
<p>We’ll need to create a separate output image. We can’t modify the source image directly because changing the pixel values will mess up the math for the adjacent pixel’s computation in the next iteration. </p>
<p>Finally, we need to consider how we’ll handle the edges. If we were looking at the very first pixel in an image, the kernel would extend beyond the bounds of the image. As a result, implementations will commonly ignore the outer most set of pixels, duplicate the edge, or wrap the image around. </p>
<p>In our case, for ease of implementation, we’ll ignore it pixels on the edges.&nbsp;&nbsp;</p>
<p>Let’s start with implementing the Gaussian function.&nbsp;The first task is to identify reasonable values for <code>x</code>, <code>y</code>, and <em><code>σ</code>. </em></p>
<p>While the kernel can technically be an arbitrary size, we should scale <em><code>σ</code> </em>in proportion to the kernel size. If we have a large kernel radius, but a small sigma, then all of the new pixels we’re introducing with our larger radius aren’t really affecting the computation.&nbsp;</p>
<p>Here’s an example of a large kernel radius, but a small sigma:&nbsp;</p>
<div><figure><img src="https://lh5.googleusercontent.com/ic0vafHD4byCwnuAvU2ZMUCuxPt9-Q8cey6aAcKw5uIcn7fnUjOktEL5aUSohATCmFDiYA2p6zgtBelUjGY3c2yDpwXuG7T2Z8GurFeyddedPaH7vyvQpDyhPmGVpwd224N1ojcm" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Sigma 1, Kernel 111</figcaption></figure></div>
<p>As opposed to Sigma 5, Kernel 111:</p>
<div><figure><img src="https://lh3.googleusercontent.com/Awid63HhzetqQMJiYjho3d7BPKEGM_ERn62V-UenNx54YBw7hj4DspY64C97ofY5KS3Vfd3e8tlY0esedLNfS_Bf984CVrRfFrp_LQANChO0fsJhm8pMR253SPkjAc6BOU5AznU2" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Sigma 5, Kernel 111</figcaption></figure></div>
<h2><strong>Code</strong></h2>
<p>To finish our implementation, we’ll also need to normalize the values in our kernel. Otherwise the image will become darker as the values will sum to slightly less than 1. Finally, we’ll need to make sure that the size of the kernel is odd to ensure that there is an actual center pixel.&nbsp;</p>
<p>The code below is by no means the fastest and favors clarity over brevity: </p>
<p>Here’s the full implementation in Swift:</p>

<p>Here are some of the results on a photo I captured amidst Yosemite’s fires last weekend: </p>
<p>Original: </p>
<figure><img loading="lazy" width="650" height="488" src="https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/YosemiteOriginal.jpg?resize=650%2C488&amp;ssl=1" alt="" srcset="https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/YosemiteOriginal.jpg?w=650&amp;ssl=1 650w, https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/YosemiteOriginal.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/YosemiteOriginal.jpg?resize=370%2C278&amp;ssl=1 370w" sizes="(max-width: 650px) 100vw, 650px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/YosemiteOriginal.jpg?w=650&amp;ssl=1 650w, https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/YosemiteOriginal.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/YosemiteOriginal.jpg?resize=370%2C278&amp;ssl=1 370w" data-lazy-src="https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/YosemiteOriginal.jpg?resize=650%2C488&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Radius: 3</p>
<figure><img loading="lazy" width="650" height="488" src="https://i0.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite3.png?resize=650%2C488&amp;ssl=1" alt="" srcset="https://i0.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite3.png?w=650&amp;ssl=1 650w, https://i0.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite3.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite3.png?resize=370%2C278&amp;ssl=1 370w" sizes="(max-width: 650px) 100vw, 650px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite3.png?w=650&amp;ssl=1 650w, https://i0.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite3.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite3.png?resize=370%2C278&amp;ssl=1 370w" data-lazy-src="https://i0.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite3.png?resize=650%2C488&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>

<p>Radius: 5</p>
<figure><img loading="lazy" width="650" height="488" src="https://i1.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite5.png?resize=650%2C488&amp;ssl=1" alt="" srcset="https://i1.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite5.png?w=650&amp;ssl=1 650w, https://i1.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite5.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite5.png?resize=370%2C278&amp;ssl=1 370w" sizes="(max-width: 650px) 100vw, 650px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite5.png?w=650&amp;ssl=1 650w, https://i1.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite5.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite5.png?resize=370%2C278&amp;ssl=1 370w" data-lazy-src="https://i1.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite5.png?resize=650%2C488&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>

<p>Radius: 11</p>
<figure><img loading="lazy" width="650" height="488" src="https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite11.png?resize=650%2C488&amp;ssl=1" alt="" srcset="https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite11.png?w=650&amp;ssl=1 650w, https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite11.png?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite11.png?resize=370%2C278&amp;ssl=1 370w" sizes="(max-width: 650px) 100vw, 650px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite11.png?w=650&amp;ssl=1 650w, https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite11.png?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite11.png?resize=370%2C278&amp;ssl=1 370w" data-lazy-src="https://i2.wp.com/digitalbunker.dev/wp-content/uploads/2020/09/Yosemite11.png?resize=650%2C488&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>

 
</div></div>]]>
            </description>
            <link>https://digitalbunker.dev/2020/09/13/understanding-gaussian-blurs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24465615</guid>
            <pubDate>Mon, 14 Sep 2020 01:14:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Computers Generate Random Numbers?]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24465225">thread link</a>) | @aryamansharda
<br/>
September 13, 2020 | https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/ | <a href="https://web.archive.org/web/*/https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
<p>Anyone with any programming experience understands that computers are deterministic machines. If you provide the same input, you’ll always get the same output. That’s why having computers generate something by chance is trickier than it may seem.</p>
<p>Computers use random numbers for everything from cryptography to gambling, generative algorithms, video games, and more. However, computers are inherently incapable of being random. Instead, programmers rely on pseudorandom number generators (PRNGs). These are simply a category of algorithms that programmatically generate new random numbers from a given starting value called the seed.&nbsp;</p>
<p>These algorithms are not without their own limitations. Since the random numbers are programmatically generated, if someone were able to identify the seed value and the PRNG algorithm you were using, they’d be able to predict the next random number in the sequence. This would allow an attacker to break encryption, predict the next playing card in a sequence, cheat in a video game, etc. </p>
<p>Despite this concern, PRNGs are extremely useful in situations involving modeling and simulations as it allows you to “replay” a series of random events by initializing your random number generator with the same seed.&nbsp;</p>
<p>In situations where the randomness of the random numbers is critical, we use a “true” random number generator (TRNGs). Unlike PRNGs that have an arbitrary seed value, TRNGs pick a seed value from their environment / external data. </p>
<p>Here are a few potential options:</p>
<ul><li>Mouse movements</li><li>Fan noise</li><li>Atmospheric pressure</li><li>Number of microseconds since the last whole second</li></ul>
<p>We just need to pick a seed that an attacker wouldn’t be able to predict. This seed value will then be passed into an algorithm, similar to PRNGs, that will generate a random number to use.&nbsp;</p>
<p>The use case will generally dictate whether a PRNG will suffice or if a “true” RNG is needed. Regardless, it’s important to understand the practical differences between both approaches. </p>
<p>PRNGs are faster than TRNGs and their determinism is extremely useful in cases where you want to replay a series of “random” events. Additionally, some PRNGs are periodic in nature, but modern PRNGs with the right initialization parameters have a period long enough that it’s not a major concern. Conversely, TRNGs are slower than PRNGs, are non-deterministic, and are not periodic.</p>
<h2>Linear Congruential Generator</h2>
<p>Let’s take a look at implementing a simple PRNG. We’ll implement a variant called the <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">linear congruential generator</a> (LCG) algorithm. LCG was previously one of the most commonly used and studied PRNGs (<a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">more info</a>).&nbsp;</p>
<p>Here’s the recurrence relation for LCG:</p>
<div><figure><img src="https://lh3.googleusercontent.com/iNcDHvHA6BvD1fpYntUkZ-11dzW6EYoW5dHv7mMhPZhDNo5fJaIMZXUh7SmZq0AoobvHxg7K5MMvqoWav7ee0xHase0fhAjWmNWoW7RcT5GzAao1jVwtGY11q2yL6iuvWiYFgyHS" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>The <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">Wikipedia page on LCG</a> documents a few commonly used values for modulus, multiplier, and increment. There’s no consensus on the best values to use hence the differing values across implementations.&nbsp;</p>
<p>We have to be mindful of what values we use for these parameters. Choosing the wrong values can create a period that is too short which would render our random number generator useless. </p>
<p>In the image below, you can see that small changes to our parameters can greatly impact the period length.</p>
<div><figure><img src="https://lh4.googleusercontent.com/FVum2kuYt4oMYjOdzHx2txpQH0NgheDDSUSxyQJamzGbZgPcUALt3Mmv4H-BElodwXwTzcLaqicG8IdsPFAgolV4DK8NkZXtghDQ_hX6MyMsxU_irWeOxR1ijaoYgecOU3fbuPbQ" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<h2>Implementation</h2>
<p>For our implementation, we’ll use the values documented in previous standards of the C languages (C90/C99/ANSI C,&nbsp; and C11).&nbsp;</p>
<p><code>a = 1103515245</code></p>
<p><code>m = 2³¹</code></p>
<p><code>c = 12345</code></p>
<blockquote><p>Whatever PRNG algorithm you choose should result in a uniform distribution of random numbers and a sufficiently long period.&nbsp;&nbsp;</p></blockquote>
<p>Here’s a simple implementation in Swift:</p>

<h2>Simulating Dice Rolls</h2>
<p>Let’s say you wanted to simulate a dice roll. </p>
<p>It might seem reasonable to change the modulus to 6, but this would create a period far too short to be usable. We need to stick with well-chosen and tested values for our parameters. </p>

<p>Instead, using the approach in the code above, we can simulate 40,000 dice rolls:</p>
<div><figure><img src="https://lh6.googleusercontent.com/uVT2lMlmWHcYIio5WmgkMMXz9nkkA_P4lzIVWeyVETxasCDn5s_5qQWgBh5FAvfPDwHipyMaqHWmb_lOp_J7oOXiRdxo_3lywqvrIo4Ky40QoDUYIrJ15w5mC6B9XWVLWvyySRWr" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>Dice Value: 40,000 Roll Simulations</p>
<blockquote><p>Looking at the results, we can see that it is indeed a uniform distribution of values.</p></blockquote>
<h2>Generating Random Numbers In A Range</h2>
<p>Next, let’s consider generating random numbers that fall in a range. Again, we shouldn’t change our parameters without fully understanding how it affects the period. </p>
<p>Instead, we should map our PRNG’s results to values in our desired range.&nbsp;</p>

<div><figure><img src="https://lh4.googleusercontent.com/A2h_s4Z_eN-qGkjEZabgPwWpOjMmIDdD9fQlYcdM344voNTlxPIvammtm6RRXJ6aDgG83h67zZYf4E4olN7jz5VRiIK10D_XeRTf0whcfHLZhn8Q9142vJBZU9Ma40DIvFVw7FdU" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>After a million simulations across the specified range [30, 80)</p>
<h2>Further Reading</h2>
<p>If you’re interested in a <a href="https://en.wikipedia.org/wiki/List_of_random_number_generators">more modern PRNG</a>, I’d recommend exploring the <a href="https://en.wikipedia.org/wiki/Mersenne_Twister">Mersenne-Twister</a> approach. It’s currently the most popular PRNG algorithm and currently used in Python (numpy), Ruby, PHP, R, and C++.&nbsp;This was meant to be a high-level introduction into this topic. If you’re interested in learning more about this topic, <a href="https://en.wikipedia.org/wiki/List_of_random_number_generators#Pseudorandom_number_generators_(PRNGs)">here a few other PRNGs to consider. </a> </p>
<p>Hope you enjoyed this article! Feel free to check out my other articles below!</p>
 
</div></div>]]>
            </description>
            <link>https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24465225</guid>
            <pubDate>Mon, 14 Sep 2020 00:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Learnt from Benchmarking Http4k, Ktor (Kotlin) and Actix (Rust) μservices]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24465124">thread link</a>) | @strohel
<br/>
September 13, 2020 | https://matej.laitl.cz/bench-rust-kotlin-microservices/ | <a href="https://web.archive.org/web/*/https://matej.laitl.cz/bench-rust-kotlin-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://matej.laitl.cz/images/2020-09-13-bench-rust-kotlin-microservices/cover.png" alt="illustration">
Back in spring 2020 at <a href="https://goout.net/">GoOut</a>,
we were looking to replace our <a href="https://spring.io/projects/spring-framework">Spring</a>-<a href="https://tomcat.apache.org/">Tomcat</a>
duo by a more lightweight framework to power our future Kotlin microservices.
We did some detailed (at times philosophical) theoretical comparisons that I much enjoyed,
but these cannot substitute a hands-on experience.
We decided to implement proof-of-concept microservices using the most viable frameworks,
stressing them in a benchmark along the way.
While <strong>Kotlin</strong> was the main language,
I saw this as an opportunity to have some fun at home and test (my proficiency with) <strong>Rust</strong>,
which is touted for being fast.
I ended up stress-testing Kotlinâ€™s <a href="https://www.http4k.org/"><strong>Http4k</strong></a>, <a href="https://ktor.io/"><strong>Ktor</strong></a>,
and Rustâ€™s <a href="https://actix.rs/"><strong>Actix</strong> Web</a>, read on to see how they fared.</p>

<p><em>Feel free to <a href="#the-results">jump to the results</a> and read the background later, if youâ€™re impatient.</em></p>

<h2 id="on-techempower-framework-benchmarks">On TechEmpower Framework Benchmarks</h2>

<p>Why not just refer to excellent <a href="https://www.techempower.com/benchmarks/">TechEmpower Benchmarks (TEB)</a>?</p>

<p>A very valid question to ask. A couple of reasons:</p>

<ul>
  <li>Submitted TEB implementations tend to be rather optimised.
We wanted to measure such a code style that we would normally write:
one striving to be simple/idiomatic/readable,
but finished promptly and not extensively profiled.
On the other hand, we wanted to include production-grade API error handling
(correct HTTP codes and JSON error messages listing problems of individual parameters etc.).</li>
  <li>Besides high-water req/s performance and associated latencies,
we wanted to capture more operational characteristics like memory usage, CPU usage and efficiency,
along the lifetime of a microservice instance.</li>
  <li>In production, we run our microservices in a rather high-density Kubernetes cluster,
where every instance has to be CPU- and memory-constrained.
We wanted to simulate this environment
and check whether we can use trending â€œserverlessâ€� offerings for new services.</li>
  <li>Our data store, Elasticsearch, differs from ones included in TEB,
and we were curious how synchronous vs. asynchronous flavours of the Elasticsearch client compare.</li>
</ul>

<h2 id="the-service">The Service</h2>

<p>For a description of the service to implement &amp; benchmark,
<a href="https://github.com/strohel/locations-rs/blob/master/api-spec.md">see its API Spec document available in the locations-rs repository</a>.</p>

<p>We benchmark its simplest <code>/city/v1/get</code> endpoint,
whose work is to look up a <code>city</code> document by id in Elasticsearch,
look up associated <code>region</code> document,
and render response JSON.
It uses internal in-memory cache for regions (there is just tens of them),
but no cache for much more numerous cities.</p>

<p>To reduce bandwidth when fetching documents from Elasticsearch,
all implementations instruct it to strip (at least) the largest property <code>geometry</code>.
This property is only used in Elasticsearch-side filtering, not by the microservice.
I believe the stripping significantly strains Elasticsearch
(or rather transfers the strain from the microservice to it).</p>

<h2 id="the-benchmark">The Benchmark</h2>

<h3 id="recipe">Recipe</h3>

<p>The benchmark consists of multiple identical â€œrunsâ€� for each Dockerised implementation spawned
by <a href="https://github.com/strohel/locations-rs/blob/master/bench-3-impls.py">bench-3-impls.py</a>.
The runs are named after the implementation and their ordinal number,
thus <code>rs-actix-1</code> is the first run of the Rust (Actix) implementation,
and <code>kt-ktor-3</code> is the third run of Kotlin (Ktor) implementation.</p>

<p>Each run simulates the first couple of minutes of the microservice instance using <a href="https://github.com/strohel/locations-rs/blob/master/test-image.py">test-image.py</a>.
Steps of one run:</p>
<ol>
  <li>Docker container is started, measuring the time until the service starts responding,</li>
  <li>a suite of HTTP checks is made ensuring correct responses and error handling behaviour,</li>
  <li>HTTP load is generated using <a href="https://github.com/wg/wrk">wrk</a>
in a series of 10-second long steps with increasing concurrent connection count;
the metrics are collected from <code>wrk</code> and Docker API after each step:
    <ul>
      <li>first 5 steps use just one concurrent connection, acting as a warm-up,</li>
      <li>each of the next 11 steps doubles concurrent connection count, i.e. continuing with 2, 4,
8, â€¦, 1024, 2048.<sup id="fnref:conn-count" role="doc-noteref"><a href="#fn:conn-count">1</a></sup></li>
    </ul>
  </li>
</ol>

<p>Finally, all runs are plotted using the awesome <a href="http://www.pygal.org/">Pygal</a> library
in <a href="https://github.com/strohel/locations-rs/blob/master/render-tests.py">render-tests.py</a>.
Different runs of a single implementation use the same colour,
allowing for visual inspection of the variance between them.</p>

<h3 id="runtime-environment">Runtime Environment</h3>

<p>Docker is told to constrain resources available to the microservice containers,
a practice usual in typical Kubernetes clusters.</p>

<p>The CPU is limited to 1.5 CPU-units using an equivalent of the <code>--cpus=1.5</code> Docker option.
This means that even though the instance has access to all 4 CPU cores of the machine,
it can use only 15 CPU-seconds (out of theoretical 40 CPU-seconds) in each 10-wall-clock-second step.
The value of 1.5 was chosen small enough to ensure the tested microservice is the actual bottle-neck during the benchmark,
and large enough to assert frameworks make proper use of multiple CPU cores.</p>

<p>Memory is limited to 512 MiB. I argue that anything beyond 512 MiB should not be called a <em>micro</em>service.</p>

<p>The two JVM-hosted Kotlin implementations run in OpenJDK 11,
with <code>-XX:MaxRAMPercentage=75</code> as the sole option.
It should allow JVM to allocate up to 75% of available 512 MiB memory to Java heap.</p>

<h3 id="hardware">Hardware</h3>

<p>The benchmarks run on 2 Virtual Machines in Google Cloud Platform (GCP) Compute Engine
located in the same zone.</p>

<ul>
  <li>1st VM, <code>n2d-highcpu-4</code> machine type (4 AMD Epyc <em>Rome</em> vCPUs, 4 GB memory):
    <ul>
      <li>Runs the benchmarked microservice in a Docker container <em>and</em> the <code>wrk</code> load generator.</li>
      <li>As the container is limited to 1.5 CPU and <code>wrk</code> takes less than leftover 2.5 CPUs,
they should not affect each other.</li>
      <li>Indeed, the maximum CPU utilisation during short peaks never exceeded 70%.</li>
      <li>The N2D <a href="https://www.quortex.io/post/an-open-source-framework-to-benchmark-cloud-providers-performances-for-live-streaming">machine type is said to have the best performance/cost ratio on GCP and even across cloud providers</a>.</li>
    </ul>
  </li>
  <li>2nd VM, <code>e2-custom</code> machine type
(12 <a href="https://cloud.google.com/blog/products/compute/understanding-dynamic-resource-management-in-e2-vms">high-density vCPUs</a>, 6 GB memory):
    <ul>
      <li>Runs a stock Dockerised Elasticsearch 7.8.0 instance, storage backend for the microservices.</li>
      <li>Maximum CPU utilisation during short peaks never exceeded 80% â€”
I have scaled the number of Elasticsearch CPU cores up until it ceased to be a bottleneck, arriving at 12.</li>
    </ul>
  </li>
</ul>

<h2 id="the-contenders">The Contenders</h2>

<ol>
  <li><code>locations-kt-http4k</code>: <a href="https://gitlab.com/gooutopensource/locations-kt-http4k/-/tree/kt-http4k">code on GitLab</a>
    <ul>
      <li>lang: <strong>Kotlin</strong> v1.3.72</li>
      <li>framework: <a href="https://www.http4k.org/"><strong>Http4k</strong></a> v3.163.0 with <em>Undertow</em> server engine v2.0.22<sup id="fnref:http4k-perf" role="doc-noteref"><a href="#fn:http4k-perf">2</a></sup></li>
      <li>programming model: classic <strong>synchronous</strong> (threads &amp; blocking I/O calls)</li>
    </ul>
  </li>
  <li><code>locations-kt-ktor</code>: <a href="https://gitlab.com/gooutopensource/locations-kt-ktor/-/tree/kt-ktor">code on GitLab</a>.
    <ul>
      <li>lang: <strong>Kotlin</strong> v1.3.70</li>
      <li>framework: <a href="https://ktor.io/"><strong>Ktor</strong></a> v3.163.0 with <em>Netty</em> server engine v4.1.44</li>
      <li>programming model: <strong>async</strong> (Kotlin coroutines)</li>
    </ul>
  </li>
  <li><code>locations-rs</code>: <a href="https://github.com/strohel/locations-rs/tree/rs-actix">code on GitHub</a>.
    <ul>
      <li>lang: <strong>Rust</strong> v1.45.2</li>
      <li>framework: <a href="https://actix.rs/"><strong>Actix</strong> Web</a> v2.0 (later we find v3.0 performs equally)</li>
      <li>programming model: <strong>async</strong> (Rust <em>async/await</em> with <a href="https://tokio.rs/">Tokio</a> runtime v0.2.22 through <code>actix-rt</code>)</li>
    </ul>
  </li>
</ol>

<p>We also initially implemented a Kotlin proof-of-concept in <a href="https://vertx.io/">Vert.x</a>,
but it turned out none of the team members was keen on the programming paradigm this framework suggested
(which may be a subjective matter), so we hadnâ€™t proceeded further with it.</p>

<h3 id="the-story-of-locations-kt-http4k">The Story of <code>locations-kt-http4k</code></h3>

<p>Http4k Locations service was written by <a href="https://buhvi.co/">@<strong>goodhoko</strong></a> at <a href="https://goout.net/">GoOut</a>.
It became the production implementation at GoOut
and is thus most complete along with extras like Swagger serving.</p>

<p>Http4k <a href="https://www.http4k.org/guide/modules/servers/">allows one to select from several server backends</a>,
so we first need to do a qualification benchmark and select the best performing engine to be fair.</p>

<p>See <a href="https://storage.googleapis.com/strohel-pub/bench-http4k-server-engines-pub/bench-results.html"><strong>Kttp4k server engine results on a dedicated page</strong></a>.
Line labels on the graph correspond to <a href="https://gitlab.com/gooutopensource/locations-kt-http4k/-/tags">tags in the locations-kt-http4k repository</a>.</p>

<p>One nice side-effect of this benchmarking was that
I have <a href="https://github.com/http4k/http4k/issues/141#issuecomment-679330954">discovered a cause</a>
of the <a href="https://github.com/http4k/http4k/issues/141"><strong>Netty</strong> backend performance issue</a>,
and <a href="https://github.com/http4k/http4k/pull/480">@<strong>daviddenton</strong> was quick to fix it</a>.
The <code>netty-updfix-*</code> graphs, which exhibit some nice latency characteristics, already contain the fix.
It was later released in http4k v3.259.0 (be sure to upgrade if you use this backend).</p>

<p><strong>Apache HttpCore</strong> version 4.4, labelled as <code>apache4-*</code>, was most CPU-efficient backend
and achieved shared first place in peak req/s performance.
However, it tends to draw too much memory as the number of concurrent connections grows,
and is out-of-memory-killed once their number reaches (extreme) 1024.
Apache HttpCore version 5.0 (<code>apache-*</code>) and a variant with lowered socket backlog (<code>apache-q100-*</code>)
suffer from the same problem.
I have <a href="https://github.com/http4k/http4k/issues/481">opened an issue</a> to see if thatâ€™s a bug or not,
insights welcome.
Meanwhile, I would recommend different http4k backends for services not shielded by load balancers.</p>

<p>The winner of this qualification round is the <strong>Undertow</strong> backend
(<code>undertow-*</code> for v3.163.0 and <code>undertow-upd-*</code> for v3.258.0),
which shares the first place in high-water req/s performance,
but also brings good all-round results in the rest of the metrics,
especially memory consumption under load.</p>

<p>The <strong>Jetty</strong> backend (<code>jetty-*</code>) slightly but consistently lags behind other production engines
in most metrics.
For completeness, I have also included the <strong>SunHttp</strong> backend that is intended for development only,
which the benchmarks confirm.</p>

<p><em>Update: this implementation uses a higher-level contracts API for generating OpenAPI specs, which <a href="https://gitlab.com/gooutopensource/locations-kt-http4k/-/issues/1">may have some performance impact</a>. I will remeasure to find out.</em></p>

<h3 id="the-story-of-locations-kt-ktor">The Story of <code>locations-kt-ktor</code></h3>

<p>Ktor variant was also written by <a href="https://buhvi.co/">@<strong>goodhoko</strong></a> at <a href="https://goout.net/">GoOut</a>,
I later tweaked the <code>/city/v1/get</code> endpoint for functional parity with other implementations.
It remains the least complete implementation with just this single endpoint.</p>

<p>It uses <a href="https://github.com/jillesvangurp/es-kotlin-wrapper-client">es-kotlin-wrapper-client</a> to wrap
<a href="https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high-getting-started-asynchronous-usage.html">intrinsic async API of the Elasticsearch client</a>
into Kotlin coroutines.</p>

<p>Ktor also allows for pluggable HTTP server engines which I benchmarked.
See <a href="https://storage.googleapis.com/strohel-pub/bench-ktor-server-engines/bench-results.html"><strong>Ktor server engine benchmarks page</strong></a>.</p>

<p>The pattern is similar here with <strong>Netty</strong> being more efficient and performant than <strong>Jetty</strong>,
thus qualified as Ktorâ€™s engine of choice for the main benchmark.</p>

<h3 id="the-story-of-locations-rs">The story of <code>locations-rs</code></h3>

<p>I wrote the Rust clone in my free time, closely following the development of <code>locations-kt-http4k</code>.</p>

<p>As <a href="https://www.reddit.com/r/rust/comments/iqq8k9/announcing_actixweb_v30/">Actix Web 3.0 was <em>just</em> released</a>
and I was eager to compare how it fares against v2.0 performance-wise.
<a href="https://storage.googleapis.com/strohel-pub/bench-actix-versions/bench-results.html"><strong>The one-to-one benchmark shows v3.0 is at least on par with v2.0</strong></a>.
I think thatâ€™s good news given that v3.0 has advanced on the safety front.
Note that I had to <a href="https://github.com/strohel/locations-rs/commits/rs-actix3-skylake">remove Swagger support</a>
as <a href="https://github.com/wafflespeanut/paperclip">paperclip</a> is not yet ported to Actix 3.0,
but that should have no runtime effect.
The rest of this article uses the original …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/">https://matej.laitl.cz/bench-rust-kotlin-microservices/</a></em></p>]]>
            </description>
            <link>https://matej.laitl.cz/bench-rust-kotlin-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24465124</guid>
            <pubDate>Mon, 14 Sep 2020 00:10:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's Build a C Compiler (Part 0)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24464797">thread link</a>) | @backslash_16
<br/>
September 13, 2020 | https://lotabout.me/2016/Let-s-Build-a-C-Interpreter-0/ | <a href="https://web.archive.org/web/*/https://lotabout.me/2016/Let-s-Build-a-C-Interpreter-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>EDIT</em>: Note that I’ve include the full tutorial in the project <a href="https://github.com/lotabout/write-a-C-interpreter/tree/master/tutorial/en" target="_blank" rel="noopener">write-a-C-interpreter</a>. Please check that instead.</p>
<p>In “Let’s Build a C Compiler” series, we will build a compiler from scratch
for C programming language. I hope you will get some understanding of compiler
construction by the end of this tutorial. At the same time we will build a
usable compiler of C though some syntaxes are not supported.</p>
<p>Note that it is actually an Interpreter and can interpret itself. I use the
word “compiler” because it is more attractive, but we did more than that. Also
this series is actually written in Chinese in the first place, If you are
confused by my English, please leave some comments.</p>
<p>In this very first chapter there will not be any code. If you are those that
likes code instead of texts, please skip. I’ll talk about the intention of
this series.</p>
<h2 id="why-compiler-theory"><a href="#why-compiler-theory"></a>Why Compiler Theory</h2>
<p>What is the most important courses in computer science? I would give “Data
Structure”, “Algorithm” and “Compiler Theory”. In my point of view,
understanding <strong>recursion</strong> is the first level for programmers, and <strong>writing
a compiler</strong> is the next one.</p>
<p>(Of course, there exists a lot of excellent programmers that don’t write a
compiler, but at least writing one is a big challenge)</p>
<p>People used to say that you can write more efficient code if you know how the
compiler works. But who cares when the modern computers have performance so
high that we can hardly imagine before? Then why bother with compiler theory?</p>
<p>Because it is cool!</p>
<p>OK, admit it, you are still reading mainly because you are curious how far
would I go with this tutorial. But be careful, it will go quite far.</p>
<p>No? You just want to know how to build a compiler? OK then… my mistake.</p>
<h2 id="hard-to-understand-hard-to-implement"><a href="#hard-to-understand-hard-to-implement"></a>Hard to understand, hard to implement?</h2>
<p>I have always been in awe of compiler. So when I went to college and they taught
compiler theory, I was so enthusiastic! And then… then I quit, because I
could not understand a single part.</p>
<p>Normally a course about compiler will cover:</p>
<ol>
<li>How to represent syntax (such as BNF, etc.)</li>
<li>Lexer, with somewhat NFA(nondeterministic finite automata),
DFA(deterministic finite automata).</li>
<li>Parser, such as recursive descent, LL(k), LALR, etc.</li>
<li>Intermediate Languages.</li>
<li>Code generation.</li>
<li>Code optimization.</li>
</ol>
<p>I believe that most(98%) students will not care anything beyond parser(at
least in my school). And the most important thing is: we still don’t know how
to build a compiler! Even after all these theories. The main reason is that
what “Compiler Theory” try to teach is actually “how to build a parser
generator”, namely a tool that consumes syntax grammar and generates compiler
(such as lex/yacc).</p>
<p>These theories try to taught us how to solve problems in a common way
automatically. That means once you master them, you are able to deal with all
kinds of grammars. They are indeed useful in industry. Nevertheless they are
too powerful and too complicate for students and most programmers. You will be
convinced if you read the source code of lex/yacc (or flex/bison).</p>
<p>The good news is, building a compiler is far simpler than you’d ever imagined.
I won’t lie, it is not easy, but not that hard.</p>
<h2 id="original-intention-is-for-self-practicing"><a href="#original-intention-is-for-self-practicing"></a>Original intention is for self-practicing</h2>
<p>I saw <a href="https://github.com/rswier/c4" target="_blank" rel="noopener">c4</a> on Github. It is a small C
interpreter which is claimed to be implemented by only 4 functions. The most
amazing part is that it is bootstrapping (that interpret itself). Also it is
done with about 500 lines!</p>
<p>Existing tutorials is either very simple(such as implementing a simple
calculator) or using automation tools(such as flex/bison). c4 is implemented
all on its own. The bad thing is that it try to be minimal, so the code is
quite a mess, hard to understand. So I started a new project that:</p>
<ol>
<li>implement a working C compiler(interpreter actually)</li>
<li>Writing this tutorial to show how to do it.</li>
</ol>
<p>c4 is about 500 Lines, it took 1 week for me to re-write it, resulting 1400
lines including comments. The project is hosted on Github: <a href="https://github.com/lotabout/write-a-C-interpreter" target="_blank" rel="noopener">Write a C Interpreter</a></p>
<p>Note: Almost all logic of this project is taken from c4. So the original
author(rswier) takes credit.</p>
<h2 id="caution"><a href="#caution"></a>Caution</h2>
<p>Two major problem I met when I working with this project are:</p>
<ol>
<li>boring, there will be codes that are almost identical.</li>
<li>hard to debug. We don’t have good test cases. On the other hand if the
output is wrong, I could only follow the generated code all by myself to
debug.</li>
</ol>
<p>So I hope you’ll take out enough time and patience for studying, cause I am
sure that you will feel a great sense of accomplishment just like I do.</p>
<h2 id="references"><a href="#references"></a>References</h2>
<ol>
<li><a href="http://compilers.iecc.com/crenshaw/" target="_blank" rel="noopener">Let’s Build a Compiler</a>: a very good
tutorial of building a compiler for fresh starters.</li>
<li><a href="http://www.hwaci.com/sw/lemon/" target="_blank" rel="noopener">Lemon Parser Generator</a>: the parser
generator that is used in SQLite. Good to read if you won’t to understand
compiler theory in code.</li>
</ol>
<p>In the end, I am human with a general level, there will be inevitably wrong
with the articles and codes(also my English). Feel free to correct me!</p>
<p>Hope you enjoy it.</p></div></div>]]>
            </description>
            <link>https://lotabout.me/2016/Let-s-Build-a-C-Interpreter-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24464797</guid>
            <pubDate>Sun, 13 Sep 2020 23:24:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Substring Removal Game with Python and JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24464608">thread link</a>) | @ethink
<br/>
September 13, 2020 | https://www.ezzeddinabdullah.com/posts/substring-removal-game-with-python-and-javascript | <a href="https://web.archive.org/web/*/https://www.ezzeddinabdullah.com/posts/substring-removal-game-with-python-and-javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h2>Understanding the Problem</h2><p><a href="https://codeforces.com/contest/1398/problem/B">Substring Removal Game</a> is an 800-point problem at codeforces, I&nbsp;hope you have read the problem carefully and have tried thinking about solving it. This problem basically states as its name sounds to say, to remove a substring.</p><p>Per each test, you're given a string of binary characters (0's and 1's)&nbsp;and you're required to remove each consecutive 1's to make Alice win. Who is Alice? Alice and Bob are players in the game, and the winner is the one who removes the highest numbers of 1's. Your duty is to make Alice win given that Alice is the first to move.</p><h2>How to Think for a Solution</h2><p>This problem has two inputs:</p><ul role="list"><li>input for test cases</li><li>input for each string of binary characters per each test case</li></ul><p>You can think of this problem as capturing all consecutive ones in the string first and then we can make a decision on which 1's we should focus on to make Alice win. For example, if the input is 01111001 this means that we have 4 consecutive 1's and then just 1; to make Alice win in this case, we should make her take that move which is obviously her first move already and then Bob can take the second move which is the last 1 in the string.</p><p>Let's have another example, 111111 these are 6 ones which can be the first move for Alice so 6 moves will be her win.</p><p>How about this tricky one:&nbsp;101010101?</p><p>So there are 5 ones .. which of them should be Alice's moves? That would be the first and the third and the fifth .. so here 3 moves for Alice.</p><p>What for this one:&nbsp;011011110111?</p><p>Here, we have 2 consecutive ones, 4 consecutive ones, and 3 consecutive ones. Which moves can make Alice win? so we need then to think how we can make number of moves the highest possible so if we sort numbers of consecutive ones in descending order and then start on the highest number that would give us the first move for Alice, and the second move should be a step two from that one. So in this case:&nbsp;[4 3 2] Alice will take moves 4 and 2 which sum up to 6.</p><p>‍</p><p>That's how I&nbsp;thought about this problem and below is my implementations in Python and Javascript:</p><h2>Python</h2><p>‍</p><h2>Javascript</h2><p>‍</p><h2>Shoutout</h2><p>I'd like to share <a href="https://www.youtube.com/watch?v=xE8qf5sfn4Y&amp;ab_channel=codeExplainer">this video</a> because the idea of solving this solution is from this guy. Check out his solution in C++&nbsp;if you're interested.</p></div></div></div></div>]]>
            </description>
            <link>https://www.ezzeddinabdullah.com/posts/substring-removal-game-with-python-and-javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24464608</guid>
            <pubDate>Sun, 13 Sep 2020 22:53:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Habits of Successful Language Learners]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24464565">thread link</a>) | @sova
<br/>
September 13, 2020 | https://learn-japanese.org/2019/10/10/habits-of-successful-language-learners/ | <a href="https://web.archive.org/web/*/https://learn-japanese.org/2019/10/10/habits-of-successful-language-learners/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-166">

	

	
			<figure>
				<img width="1568" height="675" src="https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=1568" alt="" loading="lazy" srcset="https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=1568 1568w, https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=3136 3136w, https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=150 150w, https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=300 300w, https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=768 768w, https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=1024 1024w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="169" data-permalink="https://learn-japanese.org/2019/10/10/habits-of-successful-language-learners/sun-eclipse-pole/" data-orig-file="https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg" data-orig-size="4096,1762" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sun eclipse pole" data-image-description="" data-medium-file="https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=300" data-large-file="https://learnjapanesebest.files.wordpress.com/2019/10/sun-eclipse-pole-e1570735921920.jpeg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<h3>Habit and Patterns versus Discipline.</h3>



<h4>Stoics Had An Idea: Discipline</h4>



<p>Marcus Aurelius and the movement of Stoicism emphasized Discipline.  However, discipline is like stamina.  It runs out when applied constantly.  </p>



<h4>Patterns live longer than Forces</h4>



<p>The solution is Habit. </p>



<p>Patterns Live Longer than Forces.  </p>



<p>A man who had gone through the front windshield of a car and cracked his skull on the open pavement once told me, years after the fact, “Nothing by force.”</p>



<h4>Nothing By Force</h4>



<p>Typically, people try to learn by doing something all at once for many hours and hoping they made a deep enough imprint for it to last a lifetime.</p>



<h4>The Analogy of the Stone and Drops of Water</h4>



<p>The Analogy of the Stone and Drops of Water were conveyed by a Tibetan Lama: </p>



<blockquote><p>Consider you have a large rock where you want to bore a hole through to the other side.  </p><p>If water were to drip one drop at a time onto this stone, after a long and determined while the hole would be bored through the rock.</p><p>If, on the other hand, we decide to become clever, and calculate exactly how many drops it takes to bore a hole, we can fill a gigantic vessel with the right amount of water and pour it all on the rock at once.</p><p>The effect is what ?  The rock is shiny, it looks resplendent in the sun, there’s a cool sensation for a little while, but the glimmery rock dries off and there’s no hole bored through.</p><p>Only with the determination of a chain of droplets does a hole get bored through the rock.</p><cite>The analogy of the rock, as conveyed by a Tibetan Lama</cite></blockquote>



<p>Discipline, though limited, can help establish habits.</p>



<h4>Establishment of Proper Habits must be Paramount</h4>



<p>Habit will push through even when discipline is lacking.  Habit is nurtured gradually and with a positive mindset it’s powerful when even small successes are rejoiced in.  Making any open-minded habit stick effectively takes a positive attitude, which helps in the creation of a positive association for the process and the goal.</p>



<p>Now that we can see that habits are far more essential to our long-term success than any one-off action, let’s look at the important major habits of successful language learners.</p>



<h3>Habits Specific to Successful Language Learners</h3>



<p><strong>Voracious Appetite for Knowledge.</strong>  “I’m hungry for knowledge” Roger said with a broad smile on his face.   He was a neighbor, with a house on the lot just behind ours.  A stray chicken came in one afternoon to our backyard.  In this city you could raise your own chickens, and sometimes they’d get out.  We wondered if it was from the house behind ours.  I went for a walk and made friends with the neighbors.  Roger was a high school student in the inner city, he wanted to take the GRE so he could continue his life in all the right ways.  I offered to help him prepare for the exam.  We spent a whole Saturday, four hours nonstop, going over a practice exam.  We only went over 3 or 4 long-style questions that had many subquestions.  Overall, we spent about 4 hours on 16 questions and I could see the exhaustion and fatigue in his body, but his mind was relentless.  He really wanted to pass this exam, and meetings with a tutor were rare, so we made the most of it.  I remember discussing what we were most hungry for in life, and Roger’s answer with a huge smile was, “I’m hungry for knowledge.”</p>



<p><strong>Not easily discouraged, Happy to make progress however small</strong>. One part of conditioning yourself to succeed is paying more attention to your successes than your failures, in an emotional perspective.  Your successes should help you thrive and your mistakes should become more manure for the next harvest.  If you couldn’t grow wheat, you need more fertilizer.  It’s that simple.  Don’t flounder.  The rich person’s mindset simply comes with more choices and less beat-yourself-up-in-times-of-failure.  It’s not that wealthy people are necessarily smarter or cooler, they simply don’t fear losing one chip when they have a thousand.  If you feel like you always have one chip and you just lost it, you’ll keep your spirit low and your absorption low.  If you can rejoice in a success, however small, you will raise your spirit and raise your absorption.</p>



<p><strong>Strong willingness to reach out and help new learners.</strong> The most successful people in any domain are often the ones helping others succeed.  Just look at any entrepreneur who is successful and count how many people around them are also successful.  It’s no coincidence, a successful leader, explorer, teacher, and learner reaches out to help those around him or her succeed.</p>



<p><strong>Strong willingness to try and reduce complex concepts to simple information for new learners.</strong> Feynman said try and teach what you just figured out to a child, and that’s a great way to try and learn something well and intuitively.  Crafting and creating language around a subtle concept is a challenge in itself, and those who are relentless find great treasure and wealth in forming the perfect words for the thought at hand.  Break it down so a new learner can understand, and you are probably doing pretty well when it comes to understanding the topic.</p>



<p><strong>Great at establishing small personal rewards for success in process and flow.</strong> I’ve heard of people putting gummy bears after each paragraph in a textbook to reward themselves for reading and reaching a new point.  It’s a genius little reward system.  Take a normal thing that you would normally just devour, like a pack of gummy bears, and turn it into a reward process for reading the textbook.  Got another creative idea?  Leave it in the comments please!</p>



<p><strong>Able to identify positive flow loops and able to reinforce them.</strong> When you find a technique that works, even if it feels boring, stick with it.  If you’re making gains in muscle with a boring routine, stick with it.  It might feel boring, but if your measured progress is increasing, stick with it.  Try to figure out what’s working, and even if you cannot pin it down, stick with it.  One working technique is worth more than an infinitely tall pile of techniques that don’t work.</p>



<p><strong>Creatively tailors approaches based on highest priority items.</strong> For example, you may notice your pronunciation is not connecting even though you know all the words.  You reschedule your lessons around videos and audio that you repeat and sing to yourself to get the pitch down perfectly.</p>



<p><strong>Whiff of the Goal and the Right Attitude</strong></p>



<p>Having a taste or even a whiff of what the goal smells like is nice and can keep you going.  Remember how great things will be when you’re fluent, when you have a great understanding, when you can incorporate yourself into the flux and flow of a whole new culture.  “How good it would be to benefit others, how good it would be to master communication”  these are thoughts that can help align our values with our goals, and help align our actions with our values.  Even thinking a thought like one of these for thirty seconds with a smile has immense benefit, because we’re crafting the right attitude to get the job done.</p>



<h3>Research Findings</h3>



<p>Although the amount of research on successful language learning habits is rare, study habits research has some great info.</p>



<figure><img data-attachment-id="181" data-permalink="https://learn-japanese.org/screen-shot-2019-10-10-at-16-14-22/" data-orig-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.14.22.png" data-orig-size="863,332" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2019-10-10-at-16.14.22" data-image-description="" data-medium-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.14.22.png?w=300" data-large-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.14.22.png?w=750" src="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.14.22.png?w=863" alt="" srcset="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.14.22.png 863w, https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.14.22.png?w=150 150w, https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.14.22.png?w=300 300w, https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.14.22.png?w=768 768w" sizes="(max-width: 863px) 100vw, 863px"><figcaption><a href="https://eric.ed.gov/?id=ED437506">https://eric.ed.gov/?id=ED437506</a><br>A book on Lifelong Learning.<br>“Resilience, Resourcefulness, Reflectiveness”<br>“Learning Power,” we hypothesize, can be increased by Improving Habits.</figcaption></figure>



<figure><img data-attachment-id="179" data-permalink="https://learn-japanese.org/screen-shot-2019-10-10-at-16-10-05-1/" data-orig-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.10.05-1.png" data-orig-size="816,252" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2019-10-10-at-16.10.05-1" data-image-description="" data-medium-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.10.05-1.png?w=300" data-large-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.10.05-1.png?w=750" src="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.10.05-1.png?w=816" alt="" srcset="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.10.05-1.png 816w, https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.10.05-1.png?w=150 150w, https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.10.05-1.png?w=300 300w, https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-16.10.05-1.png?w=768 768w" sizes="(max-width: 816px) 100vw, 816px"><figcaption><a href="https://journals.sagepub.com/doi/abs/10.2466/pms.2000.90.3c.1151">https://journals.sagepub.com/doi/abs/10.2466/pms.2000.90.3c.1151</a><br>Conclusions: Space your study periods; <br>Have good diet, exercise, and therefore Rest;<br>Be Amped to Study.  You can Shine Up your Attitude!</figcaption></figure>



<figure><img data-attachment-id="175" data-permalink="https://learn-japanese.org/screen-shot-2019-10-10-at-15-53-17/" data-orig-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-15.53.17.png" data-orig-size="672,521" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2019-10-10-at-15.53.17" data-image-description="" data-medium-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-15.53.17.png?w=300" data-large-file="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-15.53.17.png?w=672" src="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-15.53.17.png?w=672" alt="" srcset="https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-15.53.17.png 672w, https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-15.53.17.png?w=150 150w, https://learnjapanesebest.files.wordpress.com/2019/10/screen-shot-2019-10-10-at-15.53.17.png?w=300 300w" sizes="(max-width: 672px) 100vw, 672px"><figcaption><a href="https://srhe.tandfonline.com/doi/abs/10.1080/0260293022000009339">https://srhe.tandfonline.com/doi/abs/10.1080/0260293022000009339</a></figcaption></figure>



<p>Clearly, <strong>asking for guidance when you don’t know things</strong>,</p>



<p><strong>Looking over things you’ve missed or gotten wrong</strong> (doing review),</p>



<p><strong>Making a habit of looking back at your notes in the down-time and off-time</strong>,</p>



<p>And <strong>psyching yourself up</strong> to study every day a little bit,</p>



<p><strong>All of these lead to success.</strong>  Not doing them leads to the opposite.</p>



<figure><img data-attachment-id="173" data-permalink="https://learn-japanese.org/roo-happy/" data-orig-file="https://learnjapanesebest.files.wordpress.com/2019/10/roo-happy.png" data-orig-size="112,112" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="roo-happy" data-image-description="" data-medium-file="https://learnjapanesebest.files.wordpress.com/2019/10/roo-happy.png?w=112" data-large-file="https://learnjapanesebest.files.wordpress.com/2019/10/roo-happy.png?w=112" src="https://learnjapanesebest.files.wordpress.com/2019/10/roo-happy.png?w=112" alt=""></figure>



<p>Next: <a href="https://learnjapanese.best/2019/10/07/to-learn-japanese-you-need-a-rocket-ship/">Read “To Learn Japanese, You Need a Rocketship”</a></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://learn-japanese.org/2019/10/10/habits-of-successful-language-learners/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24464565</guid>
            <pubDate>Sun, 13 Sep 2020 22:45:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Negative externalities: What's the true price of beef and cheese?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24464025">thread link</a>) | @shafyy
<br/>
September 13, 2020 | https://blog.yeticheese.com/negative-externalities-whats-the-true-price-of-beef-and-cheese/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/negative-externalities-whats-the-true-price-of-beef-and-cheese/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Meat and dairy production have negative effects on the environment, on our health and on animal welfare. One way to economically quantify these negative effects is with the concept of negative externality. A negative externality is a cost that affects a third party who did not choose to incur the cost. This usually happens when the market price of a good does not reflect the true cost.</p><p>Animal-based food production has an array of negative externalities. Therefore, the true price of buying cheese or beef should be significantly higher. Otherwise, our society incurs those costs in form of environmental damage, health issues and animal welfare problems.</p><p>While it's pretty clear what the negative externalities are, it's very hard to quantify them. Let's see what they are and why they are hard to quantify.</p><h2 id="negative-externalities-from-meat-and-dairy">Negative externalities from meat and dairy</h2><h3 id="environment">Environment</h3><p>Producing meat and dairy has a lot of different negative effects on our environment. Livestock such as cows emit greenhouse gases while they process the food they eat. This is mostly in the form of methane. We use half of the habitable land that's available for agriculture, and 77% of that is either used by livestock directly or to grow crops for them. Agriculture also uses a lot of water, as 70% of the global water is used for it. Furthemore, livestock produce a lot of feces, and that, together with the use of fertilizers, pollute our waters (called eutrophication). Finally livestock agriculture is the leading cause of biodiversity loss and the number one reason for endangering wildlife [1].</p><figure><img src="https://blog.yeticheese.com/content/images/2020/09/What-are-the-environmental-impacts-of-agriculture-1.png" alt="What are the environmental impcats of food and agriculture?" width="1600" height="1035" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/09/What-are-the-environmental-impacts-of-agriculture-1.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/09/What-are-the-environmental-impacts-of-agriculture-1.png 1000w, https://blog.yeticheese.com/content/images/2020/09/What-are-the-environmental-impacts-of-agriculture-1.png 1600w" sizes="(min-width: 720px) 720px"></figure><h3 id="health">Health</h3><p>There is an increasing amount of research showing that proteins from plants are healthier than proteins from animals. For example, eating more plant proteins and less animal proteins leads to better cardiovascular health [2].</p><p>The use of antibiotics for animals is the leading cause for resistance to antibiotics in humans. This means that we need to find new medicine or ways to treat diseases that we successfully treat today [3]. In the US, 80% of all antibiotics are used for livestock [4].</p><p>A current example of negative health externality from eating animal-based foods is COVID-19. It's most likely that the virus spread to humans from bats [5]. Obviosuly, bats are not the main driver of livestock agriculture across the world. However, there are enough other examples that might hit closer to home. For example, you might have heard of the mad cow disease or the swine flu [6][7]. Or what about getting salmonellosis from eating pouletry, from which around 280,000 people died worldwide in 2015 [8]?</p><h3 id="animal-welfare">Animal welfare</h3><p>In the US, every year 9.8 billion animals are raised and killed for meat and dairy production [9]. While there exist some farms where animals are treated well, the reality is that most of the dairy and meat is produced in highly industrialized animal factories. Animals are mostly kept indoors, don't have enough space and are not treated well. Even in the case of "good" farms, animals are in the end killed and babies are separated from their mothers. This can't be right.</p><p>One might argue that bad animal welfare doesn't have a negative impact on us as a society, and therefore no negative externality. One would be wrong, though. The market and studies have shown that people are willing to pay more for meat and dairy that comes from animals that had better living conditions. This suggests that bad animal welfare takes some kind of toll on people and they are ready to pay more to make it go away.</p><h2 id="quantifying-the-negative-externalities">Quantifying the negative externalities</h2><p>In theory, this sounds easy. Just add up the costs from the list above. In reality, all we can do is take an educated guess. Let's look at some of the research that has been done in this area.</p><p>One study that looked at pork in The Netherlands estimated that the price of pork needs to be 31% higher to reflect its true price. The authors found that pork needs to be € 2.06 more expensive per kilogramm, and break it down as follows:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/09/Screenshot-2020-09-09-at-12.46.46-PM.png" alt="" width="1452" height="384" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/09/Screenshot-2020-09-09-at-12.46.46-PM.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/09/Screenshot-2020-09-09-at-12.46.46-PM.png 1000w, https://blog.yeticheese.com/content/images/2020/09/Screenshot-2020-09-09-at-12.46.46-PM.png 1452w" sizes="(min-width: 720px) 720px"></figure><p>I think the overall cost is in the ballpark, but they underestimate the costs of climate change and overestimate the cost of animal welfare (especially at the upper bound there) [10].</p><p>Another study looked at the negative externalities in New Zealand's dairy industry and found that the incurred costs are higher than the revenues generated from the export of it [11].</p><p>One study that looked only at the global environmental and health costs incurred by eating meat and dairy, estimating them between $ 1 to 31 trillion per year. This is a wide range, and is the result of different methods and scenarios they used to calculate the costs [12].</p><p>While it's hard to predict the exact costs, it's clear that the negative externalities of meat and dairy are not included in their price.</p><h2 id="solutions-to-correct-the-negative-externalities">Solutions to correct the negative externalities</h2><p>A common way of addressing negative externalities is by levying a tax on the product or service. For example, taxes make up 42.5% of the price of a pack of cigarettes in the US [13]. Therefore, less people are willing to buy cigarettes and this is overall better for society because there are less public health costs.</p><p>A tax on meat and dairy would increase its price and most likely lead to less consumption and production. In fact, many countries already have a carbon tax on fossil fuels, but not on animal-based foods [14]. Unlike a pure carbon tax, a tax on meat and dairy would not only include GHG emissions, but also incorporate the other negative externalities discussed earlier.</p><p>Such a tax has been proposed by some researchers. As mentioned above, one study found that the tax would need to increase the price of pork in The Netherlands by 31% to account for all the costs [10].</p><p>In reality, government are doing the opposite. They are subsidizing livestock farmers. The European Union pays around $ 30 billion dollars in direct subsidies to farmers, that's nearly 20% of their whole budget [15].</p><p>Negative externalities can also be corrected by shifting demand. We need more excellent plant-based alternatives to meat, milk and cheese. It's great to see that companies like Impossible Foods and Beyond Meat are successful and available at an increasing number of stores and restaurants. But we need more. We need thousands of food companies that are committed to shifting our population to a plant-based diet.</p><p>So, what can you do? Vote for politicians who understand these issues and are committed to solving them. Eat less meat and dairy, instead eat meat and cheese made directly from plants. And, tell your friends and family about the this. Most people don't realize how their diet relates to climate change.</p><h3 id="references">References</h3><p>1: <a href="https://ourworldindata.org/environmental-impacts-of-food">Environmental impacts of food production (Our World in Data)</a><br>2: <a href="https://pubmed.ncbi.nlm.nih.gov/27479196/">Association of Animal and Plant Protein Intake With All-Cause and Cause-Specific Mortality (JAMA Internal Medicine)</a><br>3: <a href="https://science.sciencemag.org/content/357/6358/1350">Reducing antimicrobial use in food animals (Science)</a><br>4: <a href="https://www.sciencemag.org/news/2017/09/are-antibiotics-turning-livestock-superbug-factories">Are antibiotics turning livestock into superbug factories? (ScienceMag)</a><br>5: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7095063/">The proximal origin of SARS-CoV-2 (Nat Med)</a><br>6: <a href="https://en.wikipedia.org/wiki/Bovine_spongiform_encephalopathy">https://en.wikipedia.org/wiki/Bovine_spongiform_encephalopathy</a><br>7: <a href="https://en.wikipedia.org/wiki/Swine_influenza">https://en.wikipedia.org/wiki/Swine_influenza</a><br>8: <a href="https://en.wikipedia.org/wiki/Salmonellosis">https://en.wikipedia.org/wiki/Salmonellosis</a><br>9: <a href="https://www.humanesociety.org/all-our-fights/protect-farm-animals">Improving the Lives of Farm Animals (The Humane Society)</a><br>10: <a href="https://www.researchgate.net/publication/242724630_The_true_price_of_meat">The true price of meat (Institute for Environmental Studies,VU University)</a><br>11: <a href="https://mro.massey.ac.nz/handle/10179/11158">The true cost of milk: Environmental deterioration vs. profit in the New Zealand dairy industry</a><br>12: <a href="https://researcharchive.lincoln.ac.nz/bitstream/handle/10182/4766/Dairy_farming_in_Canterbury.pdf;jsessionid=955EFA723B491D99CD46BB13106D0302?sequence=1">Some External Costs of Dairy Farming in Canterbury</a><br>13: <a href="https://en.wikipedia.org/wiki/Cigarette_taxes_in_the_United_States">https://en.wikipedia.org/wiki/Cigarette_taxes_in_the_United_States</a><br>14: <a href="https://en.wikipedia.org/wiki/Carbon_tax">https://en.wikipedia.org/wiki/Carbon_tax</a><br>15: <a href="https://www.theguardian.com/environment/2019/may/22/eu-ignoring-climate-crisis-with-livestock-farm-subsidies-campaigners-warn">EU ignoring climate crisis with livestock farm subsidies, campaigners warn (The Guardian)</a></p>
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/negative-externalities-whats-the-true-price-of-beef-and-cheese/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24464025</guid>
            <pubDate>Sun, 13 Sep 2020 21:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running OpenWrt with SELinux]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24463763">thread link</a>) | @tapper
<br/>
September 13, 2020 | https://aparcar.org/running-openwrt-with-selinux/ | <a href="https://web.archive.org/web/*/https://aparcar.org/running-openwrt-with-selinux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>This blog post describes the creation and testing of OpenWrt images running
SELinux to improve security. The support is still limited and not ready for any
productive usage, however this post should give a basic idea of its current
state.</p>
<h2 id="history">History</h2>
<p>Back in November 2019 Thomas Petazzoni sent a <a href="https://lists.infradead.org/pipermail/openwrt-devel/2019-November/025973.html">first patchset</a> adding optional
SELinux support to OpenWrt. Due to the complexity of integrating SELinux into
the OpenWrt build system and missing bits in the patchset, the patches never
made it into the main branch.</p>
<p>In July 2020 W. Michael Petullo gave the patchset a <a href="https://github.com/openwrt/openwrt/pull/3207">second spin</a>, updated
legacy Python2 to Python3, rebased everything and reworked all change requests
from the reviewers. Special thanks to Daniel Golle. Due to the deep integration
of SELinux inside the operating system special versions of <code>busybox</code>, <code>procd</code>
and <code>f2fs-tools</code> <a href="https://github.com/openwrt/openwrt/pull/3303">were created</a>, keeping the regular (non SELinux)
images small while allowing to integrate the additional SELinux feature via
package installations.</p>
<h2 id="creating-images">Creating images</h2>
<p>To try SELinux on OpenWrt it is currently required to compile the Kernel with
additional options. There are ideas to provide dual Kernel ImageBuilders with a
regular and a SELinux ready version, however this isn’t ready just yet.</p>
<p>You’ll need a OpenWrt <a href="https://openwrt.org/docs/guide-developer/quickstart-build-images">build system</a> and a bit of time!</p>
<p>As of 2020/09 only <code>x86/64</code>, <code>armvirt/64</code> and <code>ath79/generc</code> using a <em>squashfs</em>
filesystem where tested with SELinux, if you use a different target, please
share your results.</p>
<p>The following build options are required:</p>
<div><pre><code data-lang="shell">Global build settings -&gt;
	<span># CONFIG_TARGET_ROOTFS_SECURITY_LABELS=y</span>
	<span>[</span>*<span>]</span> Enable rootfs security labels

	Kernel build options -&gt;
		<span># CONFIG_KERNEL_SECURITY_SELINUX=y</span>
		<span>[</span>*<span>]</span> NSA SELinux Support
</code></pre></div><p>These options will automatically select the package <code>refpolicy</code> to set labels
inside the created <code>squashfs</code> filesystem.</p>
<p>Select the SELinux variants of <code>procd</code>, <code>busybox</code> and (optionally)
<code>mkf2fs</code>. Be sure to deselect the <em>regular</em> versions as there is currently
a dependency error if both variants are selected.</p>
<div><pre><code data-lang="shell">Base system -&gt;
	&lt;*&gt; busybox-selinux
	&lt;*&gt; procd-selinux

Utilities -&gt;
	Filesystem -&gt;
		<span># optional: only if target uses f2fs</span>
		&lt;*&gt; mkf2fs-selinux			
</code></pre></div><h2 id="running">Running</h2>
<p>The following will run an <code>armvirt/64</code> image:</p>
<div><pre><code data-lang="shell">BIN_DIR<span>=</span>./bin/targets/armvirt/64

qemu-system-aarch64 <span>\ </span>
        -M virt <span>\
</span><span></span>        -append <span>"console=ttyAMA0,115200 root=/dev/vda"</span> <span>\
</span><span></span>        -cpu cortex-a57 <span>\
</span><span></span>        -device virtio-blk-device,drive<span>=</span>hd <span>\
</span><span></span>        -drive file<span>=</span><span>"</span>$BIN_DIR<span>/openwrt-armvirt-64-rootfs-squashfs.img"</span>,if<span>=</span>none,format<span>=</span>raw,id<span>=</span>hd <span>\
</span><span></span>        -kernel <span>"</span>$BIN_DIR<span>/openwrt-armvirt-64-Image"</span> <span>\
</span><span></span>        -nographic 
</code></pre></div><p>A boot log is written directly to the used terminal and should show lines like the following:</p>
<div><pre><code data-lang="shell"><span>[</span>    0.002483<span>]</span> LSM: Security Framework initializing
<span>[</span>    0.005608<span>]</span> SELinux:  Initializing.
...
<span>[</span>    2.732347<span>]</span> SELinux:  policy capability network_peer_controls<span>=</span><span>1</span>
<span>[</span>    2.732662<span>]</span> SELinux:  policy capability open_perms<span>=</span><span>1</span>
<span>[</span>    2.732773<span>]</span> SELinux:  policy capability extended_socket_class<span>=</span><span>1</span>
<span>[</span>    2.732899<span>]</span> SELinux:  policy capability always_check_network<span>=</span><span>0</span>
<span>[</span>    2.733022<span>]</span> SELinux:  policy capability cgroup_seclabel<span>=</span><span>1</span>
<span>[</span>    2.733132<span>]</span> SELinux:  policy capability nnp_nosuid_transition<span>=</span><span>1</span>
<span>[</span>    2.753174<span>]</span> audit: type<span>=</span><span>1403</span> audit<span>(</span>1599863280.884:2<span>)</span>: auid<span>=</span><span>4294967295</span> ses<span>=</span><span>4294967295</span> lsm<span>=</span>selinux res<span>=</span><span>1</span>
</code></pre></div><p>If <code>refpolicy</code> worked all files should received an initial label:</p>
<div><pre><code data-lang="shell">root@OpenWrt:/# ls -Z
system_u:object_r:bin_t          bin
system_u:object_r:tmpfs_t        dev
system_u:object_r:etc_t          etc
system_u:object_r:default_t      init
system_u:object_r:lib_t          lib
system_u:object_r:lib_t          lib64
system_u:object_r:mnt_t          mnt
system_u:object_r:unlabeled_t    overlay
system_u:object_r:proc_t         proc
system_u:object_r:root_t         rom
root:object_r:user_home_dir_t    root
system_u:object_r:bin_t          sbin
system_u:object_r:sysfs_t        sys
system_u:object_r:tmpfs_t        tmp
system_u:object_r:usr_t          usr
system_u:object_r:default_t      var
system_u:object_r:default_t      www
</code></pre></div><p>Also processes will receive a label, however <code>procd</code> does not yet set contexts.
This involves some C programming and should be tackled in the near future. The
list below show that <code>dropbear</code>, <code>netifd</code> and <code>odhcpd</code> all share the same
context labels.</p>
<div><pre><code data-lang="shell">root@OpenWrt:/# ps -Z
  PID CONTEXT                          STAT COMMAND
    <span>1</span> system_u:system_r:init_t         S    /sbin/procd
    <span>2</span> system_u:system_r:kernel_t       SW   <span>[</span>kthreadd<span>]</span>
    <span>3</span> system_u:system_r:kernel_t       IW&lt;  <span>[</span>rcu_gp<span>]</span>
    <span>4</span> system_u:system_r:kernel_t       IW&lt;  <span>[</span>rcu_par_gp<span>]</span>
    <span>5</span> system_u:system_r:kernel_t       IW   <span>[</span>kworker/0:0-eve<span>]</span>
    <span>6</span> system_u:system_r:kernel_t       IW&lt;  <span>[</span>kworker/0:0H-kb<span>]</span>
    <span>7</span> system_u:system_r:kernel_t       IW   <span>[</span>kworker/u2:0-ev<span>]</span>
...
  <span>985</span> system_u:system_r:init_t         S    /usr/sbin/dropbear -F -P /var/run/
 <span>1060</span> system_u:system_r:init_t         S    /sbin/netifd
 <span>1100</span> system_u:system_r:init_t         S    /usr/sbin/odhcpd
 <span>1327</span> system_u:system_r:init_t         S&lt;   /usr/sbin/ntpd -n -N -S /usr/sbin/
 <span>1712</span> system_u:system_r:init_t         R    ps -Z
</code></pre></div><p>This wraps up the current state. There is still more to do, a few points in the
next section.</p>
<h2 id="todo">ToDo</h2>
<p>The fun didn’t quite come to an end yet:</p>
<ul>
<li><del>A <a href="https://github.com/openwrt/packages/pull/10664">pending Pull Request</a> over at <code>openwrt/packages.git</code> will add additional
tools like <code>audit2allow</code>.</del> Merged</li>
<li>Extending  <a href="https://git.openwrt.org/?p=project/procd.git"><code>procd</code></a> to set correct contexts</li>
<li>Use <code>refpolicy</code> labels in <a href="https://github.com/openwrt/openwrt/blob/master/scripts/ipkg-build"><code>ipkg-build</code></a>.</li>
<li>Offer ImageBuilders with a second Kernel supporting SELinux features.</li>
</ul>

</div></div>]]>
            </description>
            <link>https://aparcar.org/running-openwrt-with-selinux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24463763</guid>
            <pubDate>Sun, 13 Sep 2020 20:34:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using WordPress as a headless CMS with Next.js – part 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24463132">thread link</a>) | @kendalmintcode
<br/>
September 13, 2020 | https://robkendal.co.uk/blog/using-wordpress-as-a-headless-cms-with-next.js | <a href="https://web.archive.org/web/*/https://robkendal.co.uk/blog/using-wordpress-as-a-headless-cms-with-next.js">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/788dc194cc59b1493e2352e986e456a771d17e5d/0bc81/img/next-js-with-wordpress-part-2-blog-post.png" alt="Blog article on connecting WordPress as a headless CMS to Next.js"></p>
<p>In <a href="https://robkendal.co.uk/blog/configuring-wordpress-as-a-headless-cms-with-next.js" title="Setting up WordPress as a headless CMS with GraphQL support">part one of using WordPress as a headless CMS with Next.js</a>, we looked at the basics of setting up a WordPress instance so that we can access Posts and Pages and custom content via GraphQL using the Next.js framework. We also created a new Next.js app using the <code>create-next-app</code> tool.</p>
<p>For part two in the series, we're going to take those starting bases and connect the dots to supply content data from WordPress via the WPGraphQL plugin and access it in our Next.js project.</p>
<p><em>If you like this article, you'll love the other helpful content I post on Twitter.</em> <a href="https://twitter.com/kendalmintcode" title="Find me on Twitter @kendalmintcode"><em>Find me on Twitter @kendalmintcode</em></a> <em>and say hi.</em></p>
<h2>Cleaning up the new Next.js project</h2>
<blockquote>
<p><strong>Note:</strong> <a href="https://robkendal.co.uk/blog/configuring-wordpress-as-a-headless-cms-with-next.js" title="Part one of setting up WordPress as a headless CMS with GraphQL">in part one, we created a new Next.js application</a> using the <code>create-next-app</code> tool. I'd recommend going through the steps in part one first, to get that set up before continuing along here.</p>
</blockquote>
<p>Out of the box, the <code>create-next-app</code> provided by Next.js adds in a lot of helpful stuff as a starter for ten. However, we can remove some of the cruft to get us down to a basic build and limit any possible confusion.</p>
<h3>Files to delete</h3>
<p>Open up the project from part one in VS Code (or your favourite IDE) and delete the following files and folders:</p>
<ul>
<li>/pages/api</li>
<li>/pages/api/hello.js</li>
</ul>
<h3>Files to edit</h3>
<p>Next, we need to amend the <code>/pages/index.js</code> file. This is the main entry point, our home page, for our app. At the moment, it's crammed full of Next.js guides and links and other helpful, but unwanted markup, so let's clear it out.</p>
<p>Open up <code>/pages/index.js</code> and locate the <code>&lt;main&gt;</code> element in the component. Replace everything between the open <code>&lt;main&gt;</code> and closing <code>&lt;/main&gt;</code> with the following:</p>
<pre><code>&lt;h1 className={styles.title}&gt;Welcome to our demo blog!&lt;/h1&gt;

&lt;p&gt;
  You can find more articles on the{' '}
  &lt;Link href='/blog'&gt;
  &lt;a&gt;blog articles page&lt;/a&gt;
  &lt;/Link&gt;
&lt;/p&gt;
</code></pre>
<p>If you've used React Router, you might be familiar with the rather unique-looking way that we're linking to the <code>/blog</code> page. Next.js uses a similar internal routing component as React Router to link to internal pages, it looks like this:</p>
<pre><code>&lt;Link href='/blog'&gt;
  &lt;a&gt;blog articles page&lt;/a&gt;
&lt;/Link&gt;
</code></pre>
<p>You can <a href="https://nextjs.org/docs/api-reference/next/link" title="Next.js Link element">read more about the Next.js Link element</a> here, but the essence is that you need to declare the <code>&lt;Link&gt;</code> component and add a <code>href="/link-to-your-page"</code> attribute with the path to where you want to link to. Finally, you need to add a single <code>&lt;a&gt;</code> anchor element with whatever name you want to use for the link.</p>
<p><strong>Note:</strong> you should add any class names or other typical anchor attributes you wish to the <code>&lt;a&gt;</code> tag <em>not</em> the <code>&lt;Link&gt;</code> component.</p>
<p>One last thing to do here and that's <strong>import the <code>Link</code> component</strong>. Add the following to the top of the <code>/pages/index.js</code> file:</p>
<pre><code>import Link from 'next/link';
</code></pre>
<p>With that done, the entire <code>/pages/index.js</code> file should look like this:</p>
<pre><code>import Head from 'next/head';
import Link from 'next/link';
import styles from '../styles/Home.module.css';

export default function Home() {
  return (
    &lt;div className={styles.container}&gt;
      &lt;Head&gt;
        &lt;title&gt;Create Next App&lt;/title&gt;
        &lt;link rel='icon' href='/favicon.ico' /&gt;
      &lt;/Head&gt;

      &lt;main className={styles.main}&gt;
        &lt;h1 className={styles.title}&gt;Welcome to our demo blog!&lt;/h1&gt;

        &lt;p&gt;
          You can find more articles on the{' '}
          &lt;Link href='/blog'&gt;
            &lt;a&gt;blog articles page&lt;/a&gt;
          &lt;/Link&gt;
        &lt;/p&gt;
      &lt;/main&gt;

      &lt;footer className={styles.footer}&gt;
        &lt;a
          href='https://vercel.com?utm_source=create-next-app&amp;utm_medium=default-template&amp;utm_campaign=create-next-app'
          target='_blank'
          rel='noopener noreferrer'
        &gt;
          Powered by{' '}
          &lt;img src='/vercel.svg' alt='Vercel Logo' className={styles.logo} /&gt;
        &lt;/a&gt;
      &lt;/footer&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<h3>Files to add</h3>
<p>Of course, we need a couple more files that we'll build out over the course of the article. These will handle our blog post routing and data handling, interacting with our WordPress backend.</p>
<p>Add the following folders and files within them:</p>
<ul>
<li>Folder <code>/lib</code> - put this in the root of the project. This will hold any utility files and specifically our API file that will talk to WordPress.</li>
<li>File <code>/lib/api.js</code> - this will handle our GraphQL queries and data fetching.</li>
<li>Folder <code>/pages/blog</code> - nothing fancy here, just a folder to hold our blog pages.</li>
<li>File <code>/pages/blog/index.js</code> - when people visit a route like <code>https://somedomain.co.uk/blog/</code> this is the page that will serve that request.</li>
<li>File <code>/pages/blog/[slug].js</code> - similar to the above, this rather weird looking page will handle individual blog pages, e.g. a domain like <code>https://yourdomain.com/blog/an-interesting-article/.</code></li>
<li>File <code>/styles/Blog.module.css</code> - this is a standard CSS file that will hold styles for our blog list items.</li>
<li>File <code>/.env.local</code> - an environment variable file to hold</li>
<li>File <code>/styles/Blog.module.css</code> - a modular</li>
</ul>
<p>That odd looking file name, <code>[slug].js</code> looks really unfamiliar, but it's how Next.js determines dynamic routes within a folder.</p>
<p>We'll cover that next.</p>
<h2>Dynamic routing in Next.js</h2>
<p>Before we start building out our new pages, it'll be helpful to quickly highlight how dynamic routing in Next.js works.</p>
<p>Out of the box, without doing anything fancy, Next.js will try to match any route you throw at it to a <code>.js</code> file that it finds under the <code>/pages</code> folder in your project.</p>
<p>For example:</p>
<ul>
<li><code>/</code> will match <code>/pages/index.js</code></li>
<li><code>/blog/</code> will match <code>/pages/blog.js</code> or <code>/pages/blog/index.js</code></li>
<li><code>/contact/thanks</code> will match <code>/pages/contact/thanks.js</code></li>
</ul>
<p>However, when it comes to dynamic routes, such as a blog post or product page, we might have one physical page file that acts as a template of sorts, handling an unknown amount of routes.</p>
<p>For this, Next.js will match a filename in the format <code>[param]</code>. So, in our case above where we have the file path <code>/pages/blog/[slug].js</code>, Next.js will call the <code>[slug].js</code> page for the following routes:</p>
<ul>
<li><code>/blog/my-awesome-blog-post</code></li>
<li><code>/blog/another-great-post-title</code></li>
<li><code>/blog/some-final-title-here</code></li>
<li>...and so on.</li>
</ul>
<p>You can call this dynamically routed file whatever you like between the <code>[</code> and <code>]</code> characters, but you'll be referencing this name inside the file (as you'll soon see), so it makes sense to call it something meaningful. In our case 'slug' is the terms that WordPress uses, so we'll leave it as that.</p>
<p>It's worth looking at the <a href="https://nextjs.org/docs/routing/dynamic-routes" title="Official documentation on Next.js dynamic routing">official Next.js documentation on dynamic routing</a> to familiarise yourself with the syntax and conventions to apply them to your app/site.</p>
<h2>Fetching data with the api.js file</h2>
<p>Now for the real meat and potatoes of the article: fetching data!</p>
<p>There's no right way to build out your files in a project like this, but I tend to prefer building things in a least-dependent to most-dependent order. In our case, the data-fetching isn't dependent on anything else, but the UI-layer depends on this, so it makes sense to start here.</p>
<h3>Dealing with environment variables</h3>
<p>Some things, like global variables that might change between environments are best stored in (funnily enough) environment variable files, usually created as <code>.env</code> files in the root of your project.</p>
<p>Since we've already created one such file, let's populate it with our WordPress GraphQL URL. Open up the file <code>/.env.local</code> and add the following line:</p>
<pre><code>    WP_API_URL=http://demo.robkendal.co.uk/graphql/
</code></pre>
<blockquote>
<p><strong>Note:</strong> you can use my URL as above, but note that a) it might be taken down without notice, and b) you may not get the results you want. It's always best to get your own WordPress instance. Either way, you'll want to add in the url in the format <code>http://your-domain-here.com/graphql/</code></p>
</blockquote>
<p>Next.js comes with built in support for environment variable files. You just have to add a <code>.env.local</code> file in the root of your file and add in what you need. As always, the Next team have <a href="">great docs on environment variables</a> for you to peruse.</p>
<h3>Adding the general fetching function</h3>
<p>Open up the <code>/lib/api.js</code> file and let's start adding in our data-fetching magic. The first thing is to add the general fetch function that will handle the talking to our WordPress GraphQL endpoint.</p>
<p>At the top of the file, we'll reference our API URL we just added into the <code>.env</code> file, followed by the <code>fetchAPI</code> function.</p>
<pre><code>const API_URL = process.env.WP_API_URL;

async function fetchAPI(query, { variables } = {}) {
  // Set up some headers to tell the fetch call
  // that this is an application/json type
  const headers = { 'Content-Type': 'application/json' };

  // build out the fetch() call using the API_URL
  // environment variable pulled in at the start
  // Note the merging of the query and variables
  const res = await fetch(API_URL, {
    method: 'POST',
    headers,
    body: JSON.stringify({ query, variables })
  });

  // error handling work
  const json = await res.json();
  if (json.errors) {
    console.log(json.errors);
    console.log('error details', query, variables);
    throw new Error('Failed to fetch API');
  }
  return json.data;
}
</code></pre>
<p>This is an asynchronous function as we need to wait for the <code>fetch()</code> call to complete. The rest of the comments should be enough to walk you through the file.</p>
<p>Believe it or not, this is the most complex function in our API file. Whilst not the longest, it does have more moving parts. The upcoming functions we'll be defining next largely outline GraphQL queries that the <code>fetchAPI()</code> function here will handle.</p>
<h3>Add function to get blog post listings</h3>
<p>From here on out, we'll define our GraphQL queries that will shape the data we want back from WordPress.</p>
<blockquote>
<p><strong>Quick tip:</strong> the best approach to defining GraphQL queries is to fire up the GraphiQL plugin on the WordPress instance, write your query, test the results and then copy it into your API file. That way, you know it works and hopefully eliminate errors along the way.</p>
</blockquote>
<p>As far as queries go, this is quite straightforward. We're looking at all posts, grabbing the first 20 results (for brevity), and ordering them by descending date order.</p>
<p>With these exception of the <code>extraPostInfo</code> ACF custom fields <a href="https://robkendal.co.uk/blog/configuring-wordpress-as-a-headless-cms-with-next.js" title="Part one of configuring WordPress as a headless CMS with Next.js">we defined in part one of this series</a>, the rest of the data is standard WordPress data, such as title, id and the slug of the post.</p>
<pre><code>// Notice …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://robkendal.co.uk/blog/using-wordpress-as-a-headless-cms-with-next.js">https://robkendal.co.uk/blog/using-wordpress-as-a-headless-cms-with-next.js</a></em></p>]]>
            </description>
            <link>https://robkendal.co.uk/blog/using-wordpress-as-a-headless-cms-with-next.js</link>
            <guid isPermaLink="false">hacker-news-small-sites-24463132</guid>
            <pubDate>Sun, 13 Sep 2020 19:08:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Normalizing or Standardizing Distribution in Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24463067">thread link</a>) | @rangerranvir
<br/>
September 13, 2020 | https://ranvir.xyz/blog/normalize-standardize-distribution-in-machine-learning/ | <a href="https://web.archive.org/web/*/https://ranvir.xyz/blog/normalize-standardize-distribution-in-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
Normalizing and standardizing are the common concepts in statistics which help the data to bring under a common shelter without changing the relative difference between the different values present in data.</p><p>
Does that sound odd? Donâ€™t worry keep going and you will know what I am talking about.</p>
<p><img data-src="https://i.ibb.co/0KKGBsN/Main-Images-1.png" alt="Normalizing or Standardizing distribution " title="Normalizing or Standardizing distribution " src="https://i.ibb.co/0KKGBsN/Main-Images-1.png">
</p>
<h2 id="why-do-we-want-to-normalize-the-distribution">Why do we want to Normalize the distribution</h2>

<p>
Letâ€™s first start with the <code>why</code> and then move to the further questions.</p><p>
The values present with different features can vary a lot. For example, a <code>is_old</code> can have binary values(0 and 1) on the other hand a feature like <code>cost</code> can have values ranging from <code>$100</code> to <code>$10000</code> depending upon the item under consideration.</p><p>

If we donâ€™t normalize/ Standardize your dataset feature having more range will contribute more toward the learning leading to bias in the model. In the above example, the <code>cost</code> value will contribute more toward the trained dataset.</p><p>
We generally normalize values when feature are present in the dataset having different range.</p>
<p><em>Normalization</em> doesnâ€™t lead to change in the real range of the dataset.</p>
<p><em>Standardization</em> leads to reduction of dataset between values in such a way that mean of the distribution is set to 0 and standard deviation is set to 1.</p>
<h2 id="how-to-normalize-standardize-distribution">How to normalize/ standardize distribution</h2><p>
A standard way to normalize a distribution is to apply this formula on each and every column.</p>
<p>
$\frac{x - x_{min}}{x_{max} - x_{min}}$
</p>
<p>
This will distribute the values normally and reduce all the values between 0 and 1.</p><p>
For standardization, we use the following formula,</p>
<p>
$\frac{x - x_{mean}}{x_{standard_deviation}}$
</p>

<h2 id="apply-standardization-on-a-dataset">Apply Standardization on a dataset</h2><p>
Data source used: <a href="https://github.com/singh1114/ml/blob/master/datascience/Machine%20learning/knn/KNN_Project_Data">GitHub of Data Source</a></p>
<div><div><pre><code>
<span># Import everything
</span><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>seaborn</span> <span>as</span> <span>sns</span>
<span>%</span><span>matplotlib</span> <span>inline</span>

<span># Create a DataFrame
</span><span>df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'KNN_Project_Data'</span><span>)</span>

<span># Print the head of the data.
</span><span>df</span><span>.</span><span>head</span><span>()</span>
</code></pre></div></div>
<p><img data-src="https://i.imgur.com/2bDtkX4.png" alt="KNN algorithm Head of dataframe" title="KNN algorithm Head of dataframe" src="https://i.imgur.com/2bDtkX4.png">
</p><p>
As we can already see that the data in the data frame is not standardized, if we donâ€™t normalize the data the outcome will be fairly different and we wonâ€™t be able to get the correct results.</p><p>
We can understand this concept in more detail if we think in terms of neural networks. Letâ€™s say we have a dataset and we are trying to find the salary of the employees given some features like, years of experience, grades in high school, university and salary in last organization different other factors.</p><p>
Now if we keep the data as it is, some features having higher values will get higher importance. So, to give a fair chance to every feature to contribute equally toward the model initially( with fixed weights), we normalize the distribution.</p><p>
Sklearn provides a very simple way to standardize your data.</p>
<div><div><pre><code><span>from</span> <span>sklearn.preprocessing</span> <span>import</span> <span>StandardScaler</span>

<span>scaler</span> <span>=</span> <span>StandardScaler</span><span>()</span>
<span>scaler</span><span>.</span><span>fit</span><span>(</span><span>df</span><span>.</span><span>drop</span><span>(</span><span>'TARGET CLASS'</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>))</span>
<span>sc_transform</span> <span>=</span> <span>scaler</span><span>.</span><span>transform</span><span>(</span><span>df</span><span>.</span><span>drop</span><span>(</span><span>'TARGET CLASS'</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>))</span>
<span>sc_df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>sc_transform</span><span>)</span>

<span># Now you can safely use sc_df as your input features.
</span><span>sc_df</span><span>.</span><span>head</span><span>()</span>
</code></pre></div></div>
<p><img data-src="https://i.imgur.com/6ADY6NW.png" alt="KNN algorithm normalized data frame" title="KNN algorithm normalized data frame" src="https://i.imgur.com/6ADY6NW.png">
</p><p>
This standardization uses the values of mean and standard deviation to calculate the new as opposed to the one of the basic <code>min-max</code> approach we discussed earlier.</p>
<p><img data-src="https://i.ibb.co/8Ms1K4Y/Screenshot-2020-05-12-at-12-42-38-AM.png" alt="KNN algorithm StandardScaler normalization" title="KNN algorithm StandardScaler normalization" src="https://i.ibb.co/8Ms1K4Y/Screenshot-2020-05-12-at-12-42-38-AM.png">
</p>
<h2 id="apply-normalization-on-a-dataset">Apply Normalization on a dataset</h2>
<div><div><pre><code><span>from</span> <span>sklearn.preprocessing</span> <span>import</span> <span>MinMaxScaler</span>

<span>minmaxscaler</span> <span>=</span> <span>MinMaxScaler</span><span>()</span>
<span>minmaxscaler</span><span>.</span><span>fit</span><span>(</span><span>df</span><span>.</span><span>drop</span><span>(</span><span>'TARGET CLASS'</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>))</span>
<span>sc_transform</span> <span>=</span> <span>minmaxscaler</span><span>.</span><span>transform</span><span>(</span><span>df</span><span>.</span><span>drop</span><span>(</span><span>'TARGET CLASS'</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>))</span>
<span>sc_df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>sc_transform</span><span>)</span>
<span>sc_df</span><span>.</span><span>head</span><span>()</span>
</code></pre></div></div>
<p><img data-src="https://i.ibb.co/WcL0TJC/Screenshot-2020-05-31-at-2-22-38-AM.png" alt="MinMaxScaler" title="MinMaxScaler" src="https://i.ibb.co/WcL0TJC/Screenshot-2020-05-31-at-2-22-38-AM.png">
</p><p>
This is how <code>MinMaxScaler</code> works in sklearn.</p>
<p><img data-src="https://i.ibb.co/D96pZQZ/Screenshot-2020-05-31-at-2-24-41-AM.png" alt="MinMaxScaler Sklearn" title="MinMaxScaler Sklearn" src="https://i.ibb.co/D96pZQZ/Screenshot-2020-05-31-at-2-24-41-AM.png">
</p><p>
The idea behind preprocessing modules in Sklearn is that, you can fit with any given data and then transform some different data to change the data according to one on which you fit it.</p><p>
So, it is a general practice to fit the <code>StandardScaler</code> on the train data and transform on both train and test data.</p><p>
Hope you liked the post. Leave a comment if you have any question. Also, do subscribe to the newsletter if you want to read more such posts.</p>
</div></div>]]>
            </description>
            <link>https://ranvir.xyz/blog/normalize-standardize-distribution-in-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24463067</guid>
            <pubDate>Sun, 13 Sep 2020 18:59:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Geometry/trigonometry in 10 figures and 100 symbols]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24462919">thread link</a>) | @R3G1R
<br/>
September 13, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p><strong><span>G</span>eometry</strong> and <strong>trigonometry</strong> are branches of mathematics concerned with geometrical figures and angles of triangles. The following list documents some of the most notable symbols in these topics, along with each symbol’s usage and meaning.</p><p>For readability purpose, these symbols are categorized by their <strong>function</strong> into tables. Other comprehensive lists of <a href="https://mathvault.ca/hub/higher-math/math-symbols/" target="_blank" aria-label="math symbols (opens in a new tab)" rel="noreferrer noopener">math symbols</a> — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img loading="lazy" width="400" height="518" src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p></div></div></div></div><h2>Point/Line-related Symbols<span></span></h2><p>In geometry, <strong>points</strong> and <strong>lines</strong> form the foundation of more complex geometrical figures such as triangles, circles, quadrilaterals and polygons. The following table documents some of the most notable symbols related to these — along with each symbol’s meaning and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$A$, $B$, $C$, $D$,<br>$P$, $Q$, $R$, $S$</td><td>Variables for <strong>points</strong></td><td>If $P_1 =P_2$, then $\overline{P_1 Q} = \overline{P_2 Q}$.</td></tr><tr><td>$\ell$</td><td>Variable for <strong><a href="https://en.wikipedia.org/wiki/Line_(geometry)" target="_blank" aria-label="lines (opens in a new tab)" rel="noreferrer noopener">lines</a></strong></td><td>$\ell_1 \parallel \ell_2$</td></tr><tr><td>$\overleftrightarrow{AB}$</td><td><strong>(Infinite) line</strong> formed by points $A$ and $B$</td><td>$\overleftrightarrow{AB}=\overleftrightarrow{BA}$</td></tr><tr><td>$\overline{AB}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Line_segment" target="_blank" aria-label="Line segment (opens in a new tab)" rel="noreferrer noopener">Line segment</a></strong> between points $A$ and $B$</td><td>$\overline{AB} \cong \overline{PQ}$</td></tr><tr><td>$\overrightarrow{AB}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Line_(geometry)#Ray" target="_blank" aria-label="Ray (opens in a new tab)" rel="noreferrer noopener">Ray</a></strong> from point $A$ to point $B$</td><td>$\overrightarrow{AB} \ne \overrightarrow{BA}$</td></tr><tr><td>$|AB|$</td><td><strong><a href="https://en.wikipedia.org/wiki/Distance#Geometry" target="_blank" aria-label="Distance (opens in a new tab)" rel="noreferrer noopener">Distance</a></strong> from point $A$ to point $B$</td><td>$|BC| \le \\ |AB| + |AC|$</td></tr><tr><td>$\ell_1 \parallel \ell_2$</td><td>Lines $\ell_1$ and $\ell_2$ are <strong><a href="https://en.wikipedia.org/wiki/Parallel_(geometry)" target="_blank" aria-label="parallel (opens in a new tab)" rel="noreferrer noopener">parallel</a></strong></td><td>If $\square ABCD$ is a parallelogram, then $\overline{AB} \parallel \overline{CD}$.</td></tr><tr><td>$\ell_1 \nparallel \ell_2$</td><td>Lines $\ell_1$ and $\ell_2$ are <strong>non-parallel</strong></td><td>If $\overleftrightarrow{PQ} \nparallel \overleftrightarrow{RS}$, then they must intersect at a point $A$.</td></tr><tr><td>$\ell_1 \perp \ell_2$</td><td>Lines $\ell_1$ and $\ell_2$ are <strong><a href="https://en.wikipedia.org/wiki/Perpendicular" target="_blank" aria-label="perpendicular (opens in a new tab)" rel="noreferrer noopener">perpendicular</a></strong></td><td>If $\overline{AB} \perp \overline{BC}$, then $|AC|^2 = |AB|^2 + \\ |BC|^2.$</td></tr><tr><td>$\ell_1 \not\perp \ell_2$</td><td>Lines $\ell_1$ and $\ell_2$ are <strong>non-perpendicular</strong></td><td>If $\overline{AB} \not\perp \overline{BC}$, then $\square ABCD$ is not a <a aria-label="rectangle (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Rectangle" target="_blank">rectangle</a>.</td></tr></tbody></table></figure><h2>Angle-related Symbols<span></span></h2><p>An <strong>angle</strong> essentially corresponds to an “opening” of a geometrical figure, whose quantification leads to much development in geometry and trigonometry. The following table documents some of the most notable symbols related to angles — along with each symbol’s meaning and example.</p><figure><table><thead><tr><th>hSymbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$a, b, c$, $\alpha$ (<a aria-label="alpha (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">alpha</a>),<br>$\beta$ (<a aria-label="beta (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">beta</a>), $\gamma$ (<a aria-label="gamma (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">gamma</a>),<br>$\theta$ (<a aria-label="theta (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">theta</a>), $\phi$ (<a aria-label="phi (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">phi</a>)</td><td>Variables for <strong><a href="https://en.wikipedia.org/wiki/Angle" target="_blank" aria-label="angles (opens in a new tab)" rel="noreferrer noopener">angles</a></strong></td><td>$\alpha + \beta &lt; \gamma$</td></tr><tr><td>$^{\circ}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Degree_(angle)" target="_blank" aria-label="Degree (opens in a new tab)" rel="noreferrer noopener">Degree</a></strong> symbol</td><td>$\alpha = 180^{\circ} – \beta$</td></tr><tr><td>$\mathrm{rad}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Radian" target="_blank" aria-label="Radian (opens in a new tab)" rel="noreferrer noopener">Radian</a></strong> symbol</td><td>$\pi \, \mathrm{rad} = 180^{\circ}$</td></tr><tr><td>$\mathrm{grad}$, $^{\mathrm{g}}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Gradian" target="_blank" aria-label="Gradian (opens in a new tab)" rel="noreferrer noopener">Gradian</a></strong> symbol</td><td>$100 \, \mathrm{grad} = 90^{\circ}$</td></tr><tr><td>$\angle ABC$</td><td><strong>Angle</strong> formed by points $A$, $B$ and $C$</td><td>$\angle ABC = \angle CBA$</td></tr><tr><td>$\angle P$</td><td><strong><a href="https://en.wikipedia.org/wiki/Internal_and_external_angles" target="_blank" aria-label="Interior angle (opens in a new tab)" rel="noreferrer noopener">Interior angle</a></strong> at point $P$</td><td>$m \angle P + m \angle Q = 90^{\circ}$</td></tr><tr><td>$\measuredangle ABC$, $m\angle ABC$</td><td><strong>Measure</strong> of angle formed by points $A$, $B$ and $C$</td><td>$\measuredangle PQR \approx 54^{\circ}$</td></tr><tr><td>$\sphericalangle ABC$</td><td><strong><a aria-label="Spherical angle  (opens in a new tab)" href="https://en.wikipedia.org/wiki/Spherical_angle" target="_blank" rel="noreferrer noopener">Spherical angle</a></strong> formed by points $A$, $B$ and $C$</td><td>If $P$, $Q$, $R$ lie on a sphere, then $\sphericalangle PQR$ is the spherical angle between $\overparen{PQ}$ and $\overparen{QR}$.</td></tr><tr><td>$’$</td><td><strong><a href="https://en.wikipedia.org/wiki/Minute_and_second_of_arc" target="_blank" aria-label="Arcminute (opens in a new tab)" rel="noreferrer noopener">Arcminute</a></strong> symbol</td><td>$x’ = \left( \dfrac{x}{60}\right)^{\circ}$</td></tr><tr><td>$^{\prime\prime}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Minute_and_second_of_arc" target="_blank" aria-label="Arcsecond (opens in a new tab)" rel="noreferrer noopener">Arcsecond</a></strong> symbol</td><td>$38^{\prime\prime} = \left(\dfrac{38}{60}\right)’$</td></tr><tr><td>∟</td><td><strong><a aria-label="Right angle (opens in a new tab)" href="https://en.wikipedia.org/wiki/Right_angle" target="_blank" rel="noreferrer noopener">Right angle</a></strong> symbol</td><td><img loading="lazy" width="300" height="190" src="https://mathvault.ca/wp-content/uploads/3-4-5-Right-Triangle.png" alt="A pink right triangle with length 3, 4 and 5" title="3 4 5 Right Triangle"></td></tr><tr><td>$-, =, \equiv$ (<a href="https://en.wikipedia.org/wiki/Hatch_mark#Congruency_notation" target="_blank" aria-label="hatch marks (opens in a new tab)" rel="noreferrer noopener">hatch marks</a>)</td><td><strong>Equal angle/length</strong></td><td><img loading="lazy" width="300" height="150" src="https://mathvault.ca/wp-content/uploads/45-45-90-Right-Triangle.png" alt="45-45-90-degree Right Triangle" title="45 45 90 Right Triangle"></td></tr></tbody></table></figure><div><figure><img src="https://mathvault.ca/wp-content/uploads/Key-Angles-in-Unit-Circle.png" alt="Key angles in unit circle in degree and radian" width="450" title="Key Angles in Unit Circle"><figcaption><strong>Key angles in degree and radian</strong></figcaption></figure></div><h2>Circle-related Symbols<span></span></h2><p>A <strong>circle</strong> can be thought of as a set of all points equidistant to a given point, and often plays a crucial role in the development of <a href="https://en.wikipedia.org/wiki/Euclidean_geometry" target="_blank" rel="noopener noreferrer">Euclidean geometry</a> and trigonometry. The following table documents some of the most notable symbols related to circle — along their respective meaning and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$O$</td><td>Variable for <strong><a aria-label="circles (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Circle" target="_blank">circle</a></strong><br>(or <strong><a href="https://en.wikipedia.org/wiki/Centre_(geometry)#Circles,_spheres,_and_segments" target="_blank" aria-label="center of circle (opens in a new tab)" rel="noreferrer noopener">center of circle</a></strong>)</td><td>If circles $O_1$ and $O_2$ share the same radius, then they are congruent.</td></tr><tr><td>$\odot P$</td><td><strong>Circle</strong> centered around point $P$</td><td>If $P \ne Q$, then $\odot P \ne \odot Q$.</td></tr><tr><td>$r$</td><td><strong><a aria-label="radius (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Radius" target="_blank">Radius</a></strong> of circle</td><td>$r = \sqrt{\dfrac{A}{\pi}}$</td></tr><tr><td>$d$</td><td><strong><a aria-label="diameter (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Diameter" target="_blank">Diameter</a></strong> of circle</td><td>$d =2r$</td></tr><tr><td>$C$</td><td><strong><a aria-label="circumference (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Circumference" target="_blank">Circumference</a></strong> of circle</td><td>$C=2\pi r$</td></tr><tr><td>$\overparen{AB}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Arc_(geometry)" target="_blank" aria-label="Arc segment (opens in a new tab)" rel="noreferrer noopener">Arc segment</a></strong> between points $A$ and $B$</td><td>If $\overline{AB}$ is a diameter, then $\overparen{AB}$ would correspond to the half-circumference.</td></tr><tr><td>$\pi$</td><td><strong><a aria-label="Archimedes' constant (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Pi" target="_blank">Pi</a></strong><br>(Archimedes’ constant)</td><td>$\pi = \dfrac{C}{d} \approx 3.1416$</td></tr><tr><td>$\tau$</td><td><strong><a aria-label="Tau constant (opens in a new tab)" rel="noreferrer noopener" href="https://math.wikia.org/wiki/Tau_(constant)" target="_blank">Tau</a></strong><br>(constant representing the ratio between circumference and radius)</td><td>$\tau = 2 \pi \approx 6.2832$</td></tr><tr><td>$A$</td><td><strong><a href="https://en.wikipedia.org/wiki/Area_of_a_circle" target="_blank" aria-label="Area of circle (opens in a new tab)" rel="noreferrer noopener">Area of circle</a></strong></td><td>$A \propto r^2$</td></tr></tbody></table></figure><h2><span id="Trigonometric_Functions"></span>Trigonometric Functions<span></span></h2><p>In trigonometry, many functions are used to relate angles within a right triangle to its various <strong>lengths</strong> or <strong>ratios</strong>. The following table documents some of the most common functions in this category — along with their respective usage and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\sin \theta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Sine" target="_blank" aria-label="Sine function (opens in a new tab)" rel="noreferrer noopener">Sine function</a></strong></td><td>$\sin\left(\dfrac{\pi}{2}\right) = 1$</td></tr><tr><td>$\mathrm{crd}\, \theta$</td><td><strong><a aria-label="Chord function (opens in a new tab)" href="https://en.wikipedia.org/wiki/Chord_(geometry)#In_trigonometry" target="_blank" rel="noreferrer noopener">Chord function</a></strong><br>(Length of chord subtended by angle $\theta$ in unit circle)</td><td>$\mathrm{crd}\, \theta \ge \sin \theta$</td></tr><tr><td>$\cos \theta$</td><td><strong><a href="https://mathworld.wolfram.com/Cosine.html" target="_blank" aria-label="Cosine function (opens in a new tab)" rel="noreferrer noopener">Cosine function</a></strong></td><td>$\sin^2 \theta + \cos^2 \theta =1$</td></tr><tr><td>$\tan \theta$</td><td><strong><a href="https://mathworld.wolfram.com/Tangent.html" target="_blank" aria-label="Tangent function (opens in a new tab)" rel="noreferrer noopener">Tangent function</a></strong></td><td>$\tan \theta = \dfrac{\sin \theta}{\cos \theta}$</td></tr><tr><td>$\csc \theta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Trigonometric_functions#Right-angled_triangle_definitions" target="_blank" aria-label="Cosecant function (opens in a new tab)" rel="noreferrer noopener">Cosecant function</a></strong></td><td>$\csc \theta = \dfrac{1}{\sin \theta}$</td></tr><tr><td>$\sec \theta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Trigonometric_functions#Right-angled_triangle_definitions" target="_blank" aria-label="Secant function (opens in a new tab)" rel="noreferrer noopener">Secant function</a></strong></td><td>$\sec^2 \theta = \tan^2 \theta + 1$</td></tr><tr><td>$\cot \theta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Trigonometric_functions#Right-angled_triangle_definitions" target="_blank" aria-label="Cotangent function (opens in a new tab)" rel="noreferrer noopener">Cotangent function</a></strong></td><td>$\cot \theta = \dfrac{\cos \theta}{\sin \theta}$</td></tr><tr><td>$\arcsin x$, $\sin^{-1}x$</td><td><strong><a aria-label="Arcsine function (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Notation" target="_blank">Arcsine function</a></strong><br>(Inverse sine)</td><td>$-\dfrac{\pi}{2} \le \arcsin x \le \dfrac{\pi}{2}$</td></tr><tr><td>$\arccos x$, $\cos^{-1}x$</td><td><strong><a aria-label="Arccosine function (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Notation" target="_blank">Arccosine function</a></strong><br>(Inverse cosine)</td><td>$\arccos \left( \dfrac{\sqrt{2}}{2} \right) = \dfrac{\pi}{4}$</td></tr><tr><td>$\arctan x$, $\tan^{-1}x$</td><td><strong><a aria-label="Arctangent function (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Notation" target="_blank">Arctangent function</a></strong><br>(Inverse tangent)</td><td>$\displaystyle \lim_{x \to \infty} \arctan x = \dfrac{\pi}{2}$</td></tr></tbody></table></figure><figure><ul><li><figure><img loading="lazy" width="600" height="240" src="https://mathvault.ca/wp-content/uploads/Sine-Graph.png" alt="Graph of sine function" data-id="27584" data-full-url="https://mathvault.ca/wp-content/uploads/Sine-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/sine-graph/" title="Sine Graph"><figcaption><strong>Sine function</strong></figcaption></figure></li><li><figure><img loading="lazy" width="600" height="240" src="https://mathvault.ca/wp-content/uploads/Cosine-Graph.png" alt="Graph of cosine function" data-id="27581" data-full-url="https://mathvault.ca/wp-content/uploads/Cosine-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/cosine-graph/" title="Cosine Graph"><figcaption><strong>Cosine function</strong></figcaption></figure></li><li><figure><img loading="lazy" width="590" height="276" src="https://mathvault.ca/wp-content/uploads/Tangent-Graph.png" alt="Graph of tangent function" data-id="27585" data-full-url="https://mathvault.ca/wp-content/uploads/Tangent-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/tangent-graph/" title="Tangent Graph"><figcaption><strong>Tangent function</strong></figcaption></figure></li><li><figure><img loading="lazy" width="590" height="346" src="https://mathvault.ca/wp-content/uploads/Cosecant-Graph.png" alt="Graph of cosecant function" data-id="27580" data-full-url="https://mathvault.ca/wp-content/uploads/Cosecant-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/cosecant-graph/" title="Cosecant Graph"><figcaption><strong>Cosecant function</strong></figcaption></figure></li><li><figure><img loading="lazy" width="590" height="346" src="https://mathvault.ca/wp-content/uploads/Secant-Graph.png" alt="Graph of secant function" data-id="27583" data-full-url="https://mathvault.ca/wp-content/uploads/Secant-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/secant-graph/" title="Secant Graph"><figcaption><strong>Secant function</strong></figcaption></figure></li><li><figure><img loading="lazy" width="590" height="276" src="https://mathvault.ca/wp-content/uploads/Cotangent-Graph.png" alt="Graph of cotangent function" data-id="27582" data-full-url="https://mathvault.ca/wp-content/uploads/Cotangent-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/cotangent-graph/" title="Cotangent Graph"><figcaption><strong>Cotangent function</strong></figcaption></figure></li></ul></figure><h2>Other 2D/3D-figure-related Symbols<span></span></h2><p>In elementary geometry, much of the study revolves around the analysis of <a href="https://en.wikipedia.org/wiki/Polygon" target="_blank" rel="noopener noreferrer"><strong>polygons</strong></a>, <a href="https://en.wikipedia.org/wiki/Polyhedron" target="_blank" rel="noopener noreferrer"><strong>polyhedra</strong></a> and other <strong>3-dimensional figures</strong>. The following table documents some of the most notable symbols in these categories — along with each symbol’s respective meaning and usage.&nbsp;</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\triangle ABC$</td><td><strong><a href="https://en.wikipedia.org/wiki/Triangle" target="_blank" aria-label="Triangle (opens in a new tab)" rel="noreferrer noopener">Triangle</a></strong> with vertices $A$, $B$ and $C$</td><td>$\triangle ABC \sim \triangle A’B’C’$</td></tr><tr><td>$\square ABCD$</td><td><strong><a href="https://en.wikipedia.org/wiki/Square" target="_blank" aria-label="Square (opens in a new tab)" rel="noreferrer noopener">Square</a></strong>/<strong><a aria-label="Quadrilaterals (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Quadrilateral" target="_blank">Quadrilaterals</a></strong> with vertices $A$, $B$, $C$ and $D$</td><td>If $\overline{AB} \parallel \overline{CD}$, then $\square ABCD$ is a <a href="https://en.wikipedia.org/wiki/Trapezoid" target="_blank" aria-label="trapezoid (opens in a new tab)" rel="noreferrer noopener">trapezoid</a>.</td></tr><tr><td>$\Pi$ (<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Capital pi (opens in a new tab)" rel="noreferrer noopener">Capital pi</a>)</td><td>Variable for <strong><a href="https://en.wikipedia.org/wiki/Plane_(geometry)" target="_blank" aria-label="planes (opens in a new tab)" rel="noreferrer noopener">planes</a></strong></td><td>$\Pi_1 \parallel \Pi_2$</td></tr><tr><td>$F \sim F’$</td><td>Figure $F$ is <strong><a href="https://en.wikipedia.org/wiki/Similarity_(geometry)" target="_blank" aria-label="similar (opens in a new tab)" rel="noreferrer noopener">similar</a></strong> to figure $F’$</td><td>$\triangle ABC \sim \triangle PQR$</td></tr><tr><td>$F \nsim F’$</td><td>Figure $F$ is <strong>not similar</strong> to figure $F’$</td><td>Since $F$ is a <a href="https://en.wikipedia.org/wiki/Regular_polygon" target="_blank" aria-label="regular pentagon (opens in a new tab)" rel="noreferrer noopener">regular pentagon</a> and $F’$ is not, $F \nsim F’$.</td></tr><tr><td>$F \cong F’$</td><td>Figure $F$ is <strong><a href="https://en.wikipedia.org/wiki/Congruence_(geometry)" target="_blank" aria-label="congruent (opens in a new tab)" rel="noreferrer noopener">congruent</a></strong> to figure $F’$</td><td>$\triangle ABC \cong \triangle A’B’C’$<br>$\implies \overline{AB} \cong \overline{A’B’}$</td></tr><tr><td>$F \ncong F’$</td><td>Figure $F$ is <strong>not congruent</strong> to figure $F’$</td><td>$\square ABCD \nsim \\ \square A’B’C’D’ \implies \\ \square ABCD \ncong \\ \square A’B’C’D’ $</td></tr><tr><td>$\varphi$ (<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="phi (opens in a new tab)" rel="noreferrer noopener">phi</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Golden_ratio" target="_blank" aria-label="Golden ratio (opens in a new tab)" rel="noreferrer noopener">Golden ratio</a></strong></td><td>$\varphi = \dfrac{1 + \sqrt{5}}{2} \approx 1.618$</td></tr><tr><td>$h$</td><td><strong><a aria-label="Height (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Height" target="_blank">Height</a></strong> of triangle/quadrilateral/<br>3D figures</td><td>Since $h = 5$, $A=\dfrac{5 \cdot 3}{2}$.</td></tr><tr><td>$b$</td><td><strong><a href="https://en.wikipedia.org/wiki/Base_(geometry)" target="_blank" aria-label="Base (opens in a new tab)" rel="noreferrer noopener">Base</a></strong> of triangle/quadrilateral</td><td>For an obtuse triangle, $b$ corresponds to the <em>extended base</em> of the triangle.</td></tr><tr><td>$l$</td><td><strong><a href="https://en.wikipedia.org/wiki/Length#Use_in_mathematics" target="_blank" aria-label="Length (opens in a new tab)" rel="noreferrer noopener">Length</a></strong> of rectangle/rectangular solid</td><td>When $l=10$, $A= 10 \cdot 20$.</td></tr><tr><td>$w$</td><td><strong><a href="https://en.wikipedia.org/wiki/Width_(disambiguation)" target="_blank" aria-label="Width (opens in a new tab)" rel="noreferrer noopener">Width</a></strong> of rectangle/rectangular solid</td><td>$A = lw$</td></tr><tr><td>$P$</td><td><strong><a href="https://en.wikipedia.org/wiki/Perimeter" target="_blank" aria-label="Perimeter (opens in a new tab)" rel="noreferrer noopener">Perimeter</a></strong> of planar figure</td><td>For a rectangle, $P = 2l + 2w$.</td></tr><tr><td>$A$</td><td><strong><a aria-label="Area (opens in a new tab)" href="https://en.wikipedia.org/wiki/Area" target="_blank" rel="noreferrer noopener">Area</a></strong> of planar figure<br>(or <a href="https://en.wikipedia.org/wiki/Surface_area" target="_blank" aria-label="surface area (opens in a new tab)" rel="noreferrer noopener">surface area</a> of 3D figure)</td><td>For a triangle, $A = \dfrac{bh}{2}$.</td></tr><tr><td>$V$</td><td><strong><a href="https://en.wikipedia.org/wiki/Volume" target="_blank" aria-label="Volume (opens in a new tab)" rel="noreferrer noopener">Volume</a></strong> of 3D figure</td><td>For a sphere, $V \propto r^3$.</td></tr><tr><td>$n$</td><td>Number of <strong><a href="https://en.wikipedia.org/wiki/Polygon" target="_blank" aria-label="sides (opens in a new tab)" rel="noreferrer noopener">sides</a></strong> in polygon</td><td>For an $n$-gon, the sum of interior angles equals $(n – 2) \cdot 180^{\circ}$.</td></tr><tr><td>$V$</td><td>Number of <strong><a href="https://en.wikipedia.org/wiki/Vertex_(geometry)#Of_a_polytope" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">vertices</a></strong> in polyhedron</td><td>For a cube, $V = 8$.</td></tr><tr><td>$E$</td><td>Number of <strong><a href="https://en.wikipedia.org/wiki/Edge_(geometry)" target="_blank" aria-label="edges (opens in a new tab)" rel="noreferrer noopener">edges</a></strong> in polyhedron</td><td>In general, $E \ge V$ for polyhedra.</td></tr><tr><td>$F$</td><td>Number of <strong><a href="https://en.wikipedia.org/wiki/Face_(geometry)" target="_blank" aria-label="faces (opens in a new tab)" rel="noreferrer noopener">faces</a></strong> in polyhedron</td><td>For a <a href="https://en.wikipedia.org/wiki/Tetrahedron" target="_blank" aria-label="tetrahedron (opens in a new tab)" rel="noreferrer noopener">tetrahedron</a>, $F=4$.</td></tr><tr><td>$\chi$ (<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="chi (opens in a new tab)" rel="noreferrer noopener">chi</a>)</td><td><strong><a aria-label="Euler characteristic (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Euler_characteristic" target="_blank">Euler characteristic</a></strong></td><td>For <a href="https://en.wikipedia.org/wiki/Convex_polytope" target="_blank" aria-label="convex polyhedra (opens in a new tab)" rel="noreferrer noopener">convex polyhedra</a>, $\chi = V-E + F = \\ 2.$</td></tr></tbody></table></figure><p id="ps">The following figures illustrate the 5 <a href="https://en.wikipedia.org/wiki/Platonic_solid" target="_blank" rel="noopener noreferrer"><strong>platonic solids</strong></a> (regular, convex polyhedra), along with their respective number of vertices, edges and faces.</p><figure><ul><li><figure><img loading="lazy" width="500" height="474" src="https://mathvault.ca/wp-content/uploads/Tetrahedron.png" alt="Colored tetrahedron" data-id="27666" data-full-url="https://mathvault.ca/wp-content/uploads/Tetrahedron.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/tetrahedron/" title="Tetrahedron"><figcaption><strong>Tetrahedron</strong> $(V= 4, E= 6, \\ F=4, \chi=2)$</figcaption></figure></li><li><figure><img loading="lazy" width="500" height="556" src="https://mathvault.ca/wp-content/uploads/Cube.png" alt="Colored cube" data-id="27662" data-full-url="https://mathvault.ca/wp-content/uploads/Cube.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/cube/" title="Cube"><figcaption><strong>Cube</strong> $(V=8, E=12, \\ F=6, \chi=2)$</figcaption></figure></li><li><figure><img loading="lazy" width="500" height="495" src="https://mathvault.ca/wp-content/uploads/Octahedron.png" alt="Colored octahedron" data-id="27665" data-full-url="https://mathvault.ca/wp-content/uploads/Octahedron.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/octahedron/" title="Octahedron"><figcaption><strong>Octahedron</strong> $(V=6, E=12, \\ F=8, \chi=2)$</figcaption></figure></li><li><figure><img loading="lazy" width="500" height="500" src="https://mathvault.ca/wp-content/uploads/Dodecahedron.png" alt="Colored dodecahedron" data-id="27663" data-full-url="https://mathvault.ca/wp-content/uploads/Dodecahedron.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/dodecahedron/" title="Dodecahedron"><figcaption><strong>Dodecahedron</strong> $(V=20, E=30, F=12, \chi= 2)$</figcaption></figure></li><li><figure><img loading="lazy" width="500" height="481" src="https://mathvault.ca/wp-content/uploads/Icosahedron.png" alt="Colored icosahedron" data-id="27664" data-full-url="https://mathvault.ca/wp-content/uploads/Icosahedron.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/icosahedron/" title="Icosahedron"><figcaption><strong>Icosahedron</strong> $(V=12, E=30, F=20, \chi=2)$</figcaption></figure></li></ul></figure><p>For the master list of symbols, see <a href="https://mathvault.ca/hub/higher-math/math-symbols">mathematical symbols</a>. For lists of symbols categorized by <strong>type</strong> and <strong>subject</strong>, refer to the relevant pages below for more.</p><div><div><div><figure><img loading="lazy" width="400" height="518" src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p></div></div></div></div><h2><span id="Additional_Resources"></span>Additional Resources<span></span></h2><ul><li><a href="https://mathvault.ca/higher-math-learning-guide"><strong>Definitive Guide to Learning Higher Mathematics</strong></a>: A standalone, 10-principle framework for tackling higher mathematical learning, thinking and problem solving efficiently</li><li><a href="https://mathvault.ca/latex"><strong>Ultimate LaTeX Reference Guide</strong></a>: Definitive reference guide to make the LaTeXing process more efficient and less painful</li><li><a href="https://mathvault.ca/10-commandments/"><strong>10 Commandments of Higher Mathematical Learning</strong></a>: An illustrated web guide on 10 scalable rules for learning higher mathematics</li><li><a href="https://mathvault.ca/math-glossary/"><strong>Definitive Glossary of Higher Math Jargon</strong></a>: A tour around higher mathematics in 106 terms</li></ul></section></div></div></div></div></div>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24462919</guid>
            <pubDate>Sun, 13 Sep 2020 18:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Attack Surface audiobook can reform Audible]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24462880">thread link</a>) | @samizdis
<br/>
September 13, 2020 | https://pluralistic.net/2020/09/13/theory-of-change/#avalanche | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/09/13/theory-of-change/#avalanche">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1373">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
mr gotcha, the nib, comics, matt bors, amazon, chickenization, audible, audiobooks, publishing, attack surface, little brother, crowdfunding, epistemological chaos, scholarship, koch brothers, koch industry, corruption, surkov

Summary:
How the Attack Surface audiobook can reform Audible; How to buy doubt; Mr Gotcha v covid

URL:
https://pluralistic.net/2020/09/13/theory-of-change/

Title:
Pluralistic: 13 Sep 2020 theory-of-change

Bullet:
🔥

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://www.nakedcapitalism.com/), Seanan McGuire (https://seananmcguire.tumblr.com).

--><br>
<a href="https://pluralistic.net/2020/09/13/theory-of-change/"><img src="https://i2.wp.com/craphound.com/images/13Sep2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/13Sep2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/09/13/theory-of-change/#avalanche">How the Attack Surface audiobook can reform Audible</a>: Pebbles R Us.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/09/13/theory-of-change/#surkov-koch">How to buy doubt</a>: The Koch brothers vs reality's left-wing bias.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/09/13/theory-of-change/#mr-gotcha">Mr Gotcha v covid</a>: We should improve public health somewhat.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/09/13/theory-of-change/#retro">This day in history</a>: 2005, 2010, 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/09/13/theory-of-change/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="avalanche"></a><br>
<img src="https://i1.wp.com/craphound.com/images/Ehpcl2DU4AAN0vy.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/Ehpcl2DU4AAN0vy.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>There's an <em>excellent</em> piece up on Fast Company by Steven Melendez about my Kickstarter campaign to pre-sell audibooks of my next novel, as a way to demonstrate the viability of publishing audio without caving to Audible/Amazon's mandatory DRM policy.</p>
<p><a href="https://www.fastcompany.com/90549199/why-this-author-is-taking-a-stand-against-amazons-audiobook-monopoly">https://www.fastcompany.com/90549199/why-this-author-is-taking-a-stand-against-amazons-audiobook-monopoly</a></p>
<p>Melendez does great work laying out the case for refusing DRM, and the risks to publishers and writers in allowing Amazon to lock their works to its platform (it's a felony to remove DRM or provide the tools to do so, even if you own the copyright to the DRM-locked work!).</p>
<p>Reading his piece, it strikes me that I could do a better job for laying out my theory of change here – how preordering the audiobook could actually lead to a fairer world where power shifts away from Amazon (owners of Audible) to the creators of audiobooks.</p>
<p>Obviously most authors couldn't do what I'm doing. I've been publishing books since 2000, more than 20 of 'em, with several NYT bestsellers. This particular book is the sequel to two <em>massive</em> bestsellers with huge, dedicated followings.</p>
<p>Publishing lives and dies on this kind of book. One of the major reason that publishers publish "midlist" books and first novels is in the hopes that they'll "break out" and become perennial bestsellers that subsidize the next round of risky bets on midlist and first books.</p>
<p>So while this isn't a typical kind of book, it's an important one.</p>
<p>So let's say this does really well in audio, selling, say, 10,000 copies. That works out really well for me, as I'm the publisher for this one, because I keep 95% of that (Kickstarter gets 5%).</p>
<p><a href="https://www.kickstarter.com/projects/doctorow/attack-surface-audiobook-for-the-third-little-brother-book">https://www.kickstarter.com/projects/doctorow/attack-surface-audiobook-for-the-third-little-brother-book</a></p>
<p>By contrast, if my publisher sold this with Audible, they'd get 70% (Amazon takes 30%), and then I'd get 25% of that (17.5% of the gross). That means I earn 542% of what my take would be with a publisher/Audible on these sales.</p>
<p>So my profit on 10,000 self-published, Kickstarted audiobooks is roughly equivalent to 54,200 commercial books sold through Audible. I had to pay to produce the audiobook and put in a hard month's work on promoting the KS, but that still a great upside.</p>
<p>So that's one way things could change. Frontlist writers could demand to retain their audio rights in publisher negotiations and do what I did. It's hard work, and only a minority of writers are situated to do it, but it would make sense for some of 'em.</p>
<p>And that would definitely make a dent in Amazon's business: they're a hit-driven biz, too. If a big chunk of major books were "Audible exclusive" (that is, sold everywhere EXCEPT Audible), they'd feel the pinch, first in lost revenues and then in lost subscribers.</p>
<p>After all, once the presale campaign is over, this book will be for sale everywhere EXCEPT Audible: libro.fm, downpour.com, even Google Play. All of those stores have stock and plans that are basically identical to Audible.</p>
<p>And if they amass sizeable collections of exclusive-of-Audible bestsellers, there will be good reasons for customers to defect to them from Audible.</p>
<p>But what about the publishers? Well, maybe they won't release their frontlist authors' audiobook rights – but if they can make <em>much</em> more money by working <em>with</em> authors to presell their audiobooks, <em>and</em> weaken Amazon's stranglehold over their business…why wouldn't they?</p>
<p>In this scenario, authors and publishers do (better-than-retail) revenue shares for a crowdfunded, DRM-free presale campaign, again diverting the bestselling titles from Amazon/Audible, once again driving support for retail alternatives to Amazon.</p>
<p>One advantage I haven't mentioned yet: shifting away from Audible is <em>great</em> news for libraries, since neither Audible originals, nor Kindle originals, are available <em>at all</em> for library purchase. Imagine a publisher <em>boycotting libraries</em>!</p>
<p>And here's the theory-of-change part: realistically, not selling through Amazon means that a lot of readers and listeners won't encounter your work – even if you make more money overall, this is not ideal.</p>
<p>My end-game is for Amazon to make good on the promise it made in 2008 when it bought Audible: to drop its DRM (or at least make it optional!). That way, readers who buy their audiobooks from Amazon can change retailers without abandoning their expensive audiobooks.</p>
<p>That alone won't end Amazon's dominance (we'll need meaningful antitrust enforcement for that), but without that step, competition doesn't have a hope in hell.</p>
<p>We MUST end the situation where every dollar spent on our books at Audible is a dollar our readers will have to throw away to switch to a rival.</p>
<p>We can do that, and we don't need every writer to be in a position to refuse Audible to make it happen.</p>
<p>We just need to starve them of the books from their most popular authors – and happily, those authors stand the best chance of making <em>more</em> money by doing crowdfunders for pre-sales.</p>
<p>If bestsellers like me do this, we'll make more money <em>and</em> we'll make the world better for <em>all</em> authors.</p>
<p>And one more bonus: I'm using the crowdfunder to presell ebooks (and sell ebooks for the previous two volumes – 4,000 ebooks in five days (and counting).</p>
<p>I'm the retailer for these ebooks, so I get 30% off the top, send the remaining 70% to my publisher, and they send me 25% of that back as a royalty: that means I get 47.5% of the gross on these.</p>
<p>And they're ebooks that are sold without enriching Amazon.</p>
<p>That's my fiendish plan – my plan to be the pebble that starts the avalanche that moves the mountain.</p>
<p>You can help! A $15 pre-order for the audiobook (list price $25!) will help to change the world:</p>
<p><a href="https://www.kickstarter.com/projects/doctorow/attack-surface-audiobook-for-the-third-little-brother-book">https://www.kickstarter.com/projects/doctorow/attack-surface-audiobook-for-the-third-little-brother-book</a></p>
<p>I look forward to selling the first-ever DRM-free Audible book.</p>
<p>(thank you for attending my TED Talk!)</p>
<hr>
<p><a name="surkov-koch"></a><br>
<img src="https://i1.wp.com/craphound.com/images/461px-Flat_Earth_Society_Logo.png.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/461px-Flat_Earth_Society_Logo.png.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Reality has a well-known leftist bias. If you want to convince people that inequality, high carbon emissions and austerity are good for them, you need to get them to abandon reality.</p>
<p>That's actually easier than you'd think.</p>
<p>Reality is hard to know. Are 737 Maxes safe? Should you wear a mask? Are vaccines safe? Is your kid's distance ed any good?</p>
<p>These are all questions that can only be answered by mastering multiple disciplines, reviewing the literature, checking the math in the papers, etc.</p>
<p>To know reality, we rely not on experts, but on expert <em>processes</em>: the regulatory truth-seeking exercises in which neutral experts hear competing claims from other experts and adjudicate them, showing their work and disqualifying themselves if they have conflicts.</p>
<p>Maybe you can't evaluate microbiology claims, but you should be able to figure out whether the process they used to arrive at those claims was fair, neutral, transparent, and subject to review when new evidence emerges.</p>
<p>If you want to make the truth unknowable, you don't start by convincing people of wrong things, you start by making it hard to know whether <em>anything</em> is true.</p>
<p>Look at Vladislav Surkov, who was Putin's long-serving disinformation guy.</p>
<p>Surkov's signature move was boasting that he secretly funded <em>some</em> opposition groups, but never saying which ones were inauthentic and which ones were the true opposition.</p>
<p>Whenever a opposition group came out with a claim about Putin, instead of arguing about the claim, people would argue about the group's authenticity. They didn't just disagree on what was true: they disagreed on how anyone could know if something WAS true.</p>
<p>Writing in the Desmog Blog, Tom Perrett runs down the history of the Koch brothers' "academic philanthropy," showing it to be a series of shrewd investments in in Surkov-style disinformation.</p>
<p><a href="https://www.desmogblog.com/2020/09/12/charles-koch-academic-george-mason-utah-state-university">https://www.desmogblog.com/2020/09/12/charles-koch-academic-george-mason-utah-state-university</a></p>
<p>Koch executives call this "investment in intellectual raw materials" that support its corporate goals.  Koch investments in the Mercatus Center at GMU and the Center for Growth and Opportunity at Utah State and elsewhere have paid off handsomely.</p>
<p>A quarter-century of expensively purchased scholarship has created an epistemological chaos that support denial about economic fairness, the climate emergency, a public sphere, and other obvious facts that are now, incredibly, in doubt.</p>
<p>Perrett: "Koch funding in academia and think tanks has broader implications for policy implementation, as state governments routinely rely on the state university systems to provide independent analyses of issues before the legislature and agencies, and advocacy groups use academic findings to bolster lobbying and public campaigns."</p>
<hr>
<p><a name="mr-gotcha"></a><br>
<img src="https://i1.wp.com/craphound.com/images/EhpiFvzUMAET470.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/EhpiFvzUMAET470.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Even if you don't know his name, chances are you've seen Matt Bors's incredible cartoons for The Nib, especially this classic panel from his enduring 2016 "Mr Gotcha" strip:</p>
<p><img src="https://i1.wp.com/craphound.com/images/mister-gotcha-4-9faefa-1.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/mister-gotcha-4-9faefa-1.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p><a href="https://thenib.com/mister-gotcha/">https://thenib.com/mister-gotcha/</a></p>
<p>Its currency and fame are easy to explain: Mr Gotcha is a superb example of the odious neoliberal idea that there are no systemic problems (or, importantly, solutions), only individual choices.</p>
<p>Don't like climate change? Recycle.</p>
<p>Don't like monopolies? Shop indie.</p>
<p>Don't like inequality? Donate to charity.</p>
<p>Don't like racism? Don't be racist.</p>
<p>Don't like sexual assault? Don't rape anyone.</p>
<p>This framework is a recipe for despair, self-loathing and inaction, and Bors's Mr Gotcha is the perfect avatar for it.</p>
<p>Four years later, Bors has brought back Mr Gotcha for a very special covid edition:</p>
<p><a href="https://thenib.com/mr-gotcha-covid/">https://thenib.com/mr-gotcha-covid/</a></p>
<p>Mr Gotcha starts off by with a reiteration  of the current right-wing disinformation meme.</p>
<p>Before Bors widens the frame to include apologism for police murder.</p>
<p><img src="https://i2.wp.com/craphound.com/images/MB2.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/MB2.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>In …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/09/13/theory-of-change/#avalanche">https://pluralistic.net/2020/09/13/theory-of-change/#avalanche</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/09/13/theory-of-change/#avalanche</link>
            <guid isPermaLink="false">hacker-news-small-sites-24462880</guid>
            <pubDate>Sun, 13 Sep 2020 18:29:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting the Most Out of Anki]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24462874">thread link</a>) | @bytedude
<br/>
September 13, 2020 | https://www.bytedude.com/getting-the-most-out-of-anki/ | <a href="https://web.archive.org/web/*/https://www.bytedude.com/getting-the-most-out-of-anki/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
     <div>
       <article itemscope="" itemtype="http://schema.org/BlogPosting">

 <div itemprop="articleBody">
    <p>
<label for="spoiler-check">Table of Contents</label></p><ul id="markdown-toc">
 <li><a href="#keep-it-simple" id="markdown-toc-keep-it-simple">Keep It Simple,</a></li>
 <li><a href="#avoid-shared-decks" id="markdown-toc-avoid-shared-decks">Avoid Shared Decks</a></li>
 <li><a href="#be-frugal-with-cards" id="markdown-toc-be-frugal-with-cards">Be Frugal With Cards</a></li>
 <li><a href="#take-care-when-reversing-cards" id="markdown-toc-take-care-when-reversing-cards">Take Care When Reversing Cards</a></li>
 <li><a href="#uze-clozes-liberally" id="markdown-toc-uze-clozes-liberally">Uze Clozes Liberally</a></li>
 <li><a href="#use-the-speed-focus-mode-add-on" id="markdown-toc-use-the-speed-focus-mode-add-on">Use The Speed Focus Mode Add-On</a></li>
 <li><a href="#get-comfortable-with-the-hotkeys" id="markdown-toc-get-comfortable-with-the-hotkeys">Get Comfortable With The Hotkeys</a></li>
 <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
 <li><a href="#footnotes" id="markdown-toc-footnotes">Footnotes</a></li>
</ul>
<p>Spaced repetition (or SR) is a highly effective method of remembering information. The <a href="https://apps.ankiweb.net/docs/manual.html#spaced-repetition">Anki Manual</a> says this about the discovery of spaced repetition:<sup id="fnref:manual"><a href="#fn:manual">1</a></sup></p>
<blockquote>
 <p>This was a revolution in learning, as it meant material could be learnt and retained with the absolute minimum amount of effort necessary.</p>
</blockquote>
<p><a href="https://apps.ankiweb.net/">Anki</a> is the most popular spaced repetition software (or SRS). At its heart, Anki is just a program for making and displaying flashcards, but the flashcards are shown to you on a schedule – ideally, close to the same day as you would have forgotten the card, and no sooner. This means you can remember more information in less time than with traditional study methods.</p>
<p>There are many SRS programs but I use and recommend Anki because it’s simple, available for all platforms, syncs easily, and has a lot of additional functionality available through <a href="https://ankiweb.net/shared/addons/">plug-ins</a>. It also has many shared decks (pre-made sets of flashcards) available<sup id="fnref:shared"><a href="#fn:shared">2</a></sup>.</p>
<p>Although this post is Anki-specific, a lot of the information will surely apply to other SRS programs as well. And while I’m primarily using Anki for language-learning, the basic principles that I’ll talk about are fairly universal.</p>
<p>Can we start the post or what?</p>
<h2 id="keep-it-simple">Keep It Simple,</h2>
<p>Stupid! Cards should be as simple as you can make them, containing only some core, atomic bit of information.</p>
<p>There are two main reasons you don’t want to complicate your cards:</p>
<ol>
 <li>Anki is meant to be efficient. That is the entire reason to use an SRS system as opposed to traditional study methods. If your studying isn’t efficient, you are wasting your time and missing the point. You should only spend a few seconds per card before moving on to the next card.</li>
 <li>Getting one small part of a complicated note wrong means you have to mark the whole thing wrong. The way I see it, there’s no alternative. When you get the card wrong, however slightly, you can’t just mark it “Okay” – you will be learning and reinforcing wrong information. To avoid this situation entirely, simply avoid cards with a lot of information. Short phrases and idioms are okay.</li>
</ol>
<p>Have a <strong>sentence you’d like to learn</strong>? Break it up into <a href="https://apps.ankiweb.net/docs/manual.html#cloze-deletion">clozes</a>. Again, the problem with things like full sentences is the risk of getting a single word out of the whole thing wrong. Clozes work by <em>occluding</em>, or hiding, only the parts of a sentence that you want to learn – and each occlusion will have its own separate card. Now you have an atomic bit of information to answer each time! You also get to see the information in its proper context as you study. It’s simple and it’s effective.</p>
<p>Have a <strong>list of things</strong> (all US states in alphabetical order)? Stop. Anki isn’t meant for that – really! I see people trying to shoehorn SRS systems for all kinds of purposes, thinking that since it’s efficient, it can be used for everything, and in the process actually making their studying wildly inefficient and wasteful. I think Anki is simply the wrong tool for lists most of the time. Methods such as the <a href="https://en.wikipedia.org/wiki/Method_of_loci">memory palace</a> seem more appropriate here.</p>
<p>A lot of shared decks in particular get this simplicity thing wrong, which is part of the reason you should…</p>

<p>Shared decks are pre-made sets of cards that are available to download on <a href="https://ankiweb.net/shared/decks/">Anki’s website</a>. I suggest you avoid using them as much as possible.</p>
<ol>
 <li>You will be learning things out of context. It is crucial to study information only after encountering it out in the wild. For example, I tried learning that the Polish word for <em>magpie</em> is <em>sroka</em>. Trouble is, I had no idea what a magpie looked like, and could never memorize the word <em>sroka</em>. After seeing one in the wild, I was able to memorize the word instantly.<sup id="fnref:course"><a href="#fn:course">3</a></sup></li>
 <li>The card quality is generally quite low. A lot of shared decks I’ve seen pack a lot of information into each card, in the mistaken notion that this <em>improves</em> the quality of the cards – it does not. These are <em>low-quality cards</em>. Cards should be simple, so you do <em>not</em> want this extraneous information when studying.</li>
 <li>Another way in which shared decks tend to be low quality is that their cards are sometimes, well, wrong. I’ve noticed this in a lot of separate shared decks. Now, if you make your own cards you’re also liable to end up with bad information, which is dangerous because you will very efficiently learn… the wrong thing. Still, if you make your own cards based on something you’ve already learned (i.e. with the proper context), you’ll be easier able to spot if what you’re learning isn’t right. If you learn from a shared deck without this context, you’d have no idea. As a result of blindly learning from shared decks I still have some wrong bits of information stuck in my brain, like candy wrappers under the sofa.</li>
</ol>
<p>That’s what’s bad about shared decks – so what’s good about making your <em>own</em> decks? Well, making your own cards will help you remember them. I can’t prove that, but it’s pretty common sense. It’s a lot like note-taking – in addition to preserving knowledge for later, the act of writing itself helps you learn.</p>
<p>Apart from that, designing your own notes will force you to <strong>be selective in what information you choose to learn</strong>. Adding cards takes time, and that’s a <em>good</em> thing. It’s way too easy to download a deck and start learning thousands of notes, but it’s a big mistake, because you should…</p>
<h2 id="be-frugal-with-cards">Be Frugal With Cards</h2>
<p>It’s tempting to get overexcited when starting out with Anki and add hundreds of cards about every little thing. But remember, each card that you add costs you time, time which adds up over the long term across many reviews. It’s easy to add a lot of cards when you are new to Anki and have a blank slate, but when you wind up with hundreds of cards scheduled each day, you get a lot more picky about what info you want to learn. I made this mistake early on and I delete cards more often than I add them now. Choose your cards carefully.</p>
<h2 id="take-care-when-reversing-cards">Take Care When Reversing Cards</h2>
<p>Most of you already know the importance of studying cards both ways. If you want to learn the Italian word <em>mela</em>, for example, it’s not enough to have a card <code>la mela -&gt; the apple</code>; you need to be able to produce the Italian word given the English word, as well. Most language learners have realized this, especially those that only learned one way and found that they could understand a language, but not speak it themselves.</p>
<p>The temptation is to automate the process of creating reversed cards and Anki makes it easy for you: you just have to select the “Basic (and reversed card)” note type when adding a new note. However, I’ve run into a lot of problems with this in the past. The word <em>whip</em>, for example, can translate into two different words in Polish: <em>bicz</em> or <em>bat</em>. Either answer is correct, so going from English to Polish I can have a card <code>whip -&gt; bicz, bat</code>. However, I don’t want to reverse that and have <code>bicz, bat -&gt; whip</code>, because here I’m only required to remember one of the words and not both. I can guess what <code>bicz</code> means if I know <code>bat</code>. So it’s better to have two cards here: <code>bicz -&gt; whip</code>, and <code>bat -&gt; whip</code>.</p>
<p>Of course, it takes more work to do things this way, but that’s fine. Making cards shouldn’t be seen as a waste of time as it helps you to learn. By deciding that a piece of information is important it primes your brain to learn it, and then your brain has to work to formulate a structure for this bit of knowledge, in the form of a note.</p>
<p>One thing you <em>do</em> miss, though, is that making cards separately results in them not being <em>related</em>, as they would be if they were generated from the same note (i.e. a “Basic (and reversed card)” note). Related cards are not shown on the same day, as you’d presumably still have the answer from the first related card fresh in your head when seeing subsequent ones. I don’t know of a good solution to this other than manually burying subsequent cards that display the same information – burying reschedules a card for the next day. A handy shortcut for this is the <code>-</code> key.</p>
<h2 id="uze-clozes-liberally">Uze Clozes Liberally</h2>
<p>I already mentioned <a href="https://www.bytedude.com/getting-the-most-out-of-anki/#keep-it-simple">clozes</a> in the context of minimizing the amount of information per note. Here are a few more reasons you should use them:</p>
<ol>
 <li>Clozes give context. It’s more effective to learn a word in the context of how it’d be used in real life. <code>Pasame [...](the apple)</code> is a better way of learning <em>la manzana</em> than <code>the apple -&gt; la manzana</code>.</li>
 <li>Clozes can help distinguish between subtle differences, e.g. for learning when to use different synonyms.</li>
 <li>Clozes are also great for learning words that don’t make sense on their own, such as prepositions. These pretty much require a context to learn them in.</li>
</ol>
<h2 id="use-the-speed-focus-mode-add-on">Use The Speed Focus Mode Add-On</h2>
<p>As mentioned above, you should be going through cards <em>quick</em>. That’s the point of an efficient study system. To ensure you don’t spend too much time on a single card, use the <a href="https://ankiweb.net/shared/info/1046608507">Speed Focus Mode</a> add-on. I set it up so that I get an alert after five seconds on one card, and it auto-reveals the answer after eight seconds. If I couldn’t get the answer by the time it’s revealed, then I simply didn’t know it well enough and I mark it Wrong. The reason I set such high times is that many of my cards are, unfortunately, not very optimized for simplicity (see above). I’m slowly simplifying my cards, but I have thousands of them. Ideally I wouldn’t ever spend more than three or four seconds on one card.</p>
<h2 id="get-comfortable-with-the-hotkeys">Get Comfortable With The Hotkeys</h2>
<p>Anki has hotkeys to make your studying faster, so make good use of them! You can read about them in the <a href="https://apps.ankiweb.net/docs/manual.html#keyboard-shortcuts">Anki manual</a>. My favorites are hitting <code>B</code> to bring up the browser and <code>A</code> to add a card. I also use the <a href="https://ankiweb.net/shared/info/1310550323">Right-Hand Reviews</a> add-on which adds a few more hotkeys for studying with the right-hand, as well as the <a href="https://ankiweb.net/shared/info/992946134">Answer Key Cascade</a> add-on which makes the answer keys more ergonomic to use (and is compatible with Right-Hand Reviews).</p>
<p>It’s always great when a program is super-user friendly (and Anki is worth being a super-user of).</p>
<h2 id="conclusion">Conclusion</h2>
<p>I …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bytedude.com/getting-the-most-out-of-anki/">https://www.bytedude.com/getting-the-most-out-of-anki/</a></em></p>]]>
            </description>
            <link>https://www.bytedude.com/getting-the-most-out-of-anki/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24462874</guid>
            <pubDate>Sun, 13 Sep 2020 18:28:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[School, Nietzsche, and Comfort for High School Kids]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24462858">thread link</a>) | @stopachka
<br/>
September 13, 2020 | https://stopa.io/post/235 | <a href="https://web.archive.org/web/*/https://stopa.io/post/235">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>I have four fierce and independent nephews. Three of them are over 13, which means theyâ€™re now â€œseriousâ€� about academics. They also have equally fierce moms with high expectations, and that means report card season can get tough. </p><p>To help them get through the ordeal, I repeat a few ideas over and over. I realized these ideas apply to all ages, so I thought I'd share them with you.</p><p>Hereâ€™s what I tell them: </p><p><strong>Your goal is curiosity</strong></p><p>I donâ€™t think grades are important.</p><p><em>(This gives them a bit of a shock, and their mom raises an eyebrow, but I forge on)</em></p><p>You can do so much more than whatâ€™s expected of you. <em>Just</em> getting good grades wonâ€™t have you feeling like youâ€™re becoming the person you want to be.</p><p>I want you to make great friends and explore. Create games, music, launch businesses, play, investigate, talk to that girl, do whatever drives you. Those experiences forge your character and teach you in uncountable ways</p><p><em>Adult Aside â€”</em> 
<em>Think about how much of your time is spent on status games. The most leveraged, creative work comes when youâ€™re</em> <a href="https://www.stopa.io/post/230" target="_blank"><em>following your taste</em></a><em>. Are your goals just about the status game, or something bigger?</em></p><p><strong>But grades are your day job</strong></p><p>You still want to get good grades though. This keeps your options open, gives you chances to learn new things, and keeps people from asking too many questions.</p><p>At this point, they invariably say: <em>Butâ€¦some courses Iâ€™m just not interested in â€” when will X be useful, etc</em> </p><p>Treat this as your day job and a challenge. Whatâ€™s the minimum time you need to spend to get the grade you want on those courses? </p><p>If you focus on the challenge, a lot of your time will be spent figuring out creative solutions and productivity hacks. This itself will be more fun than the course, help you build discipline, and learn techniques that will be useful to you throughout life.  Remember, you just want to do a good job so you can be that inventor, renaissance explorer, hacker, or artist that you want to be. </p><p><em>Adult Aside â€”</em> 
<em>Before google came around, search was boring: a â€œsimpleâ€� technical problem that no one wanted to solve anymore. Google turned it into a very interesting problem. Think about how you could do that to some of your grudging must-do tasks. At the very least it will strengthen your discipline</em></p><p><strong>Be wary of slave morality</strong></p><p>They may interject with a platitude: W<em>hatâ€™s important is to be a good person, I donâ€™t kiss up to the teacher, who cares about grades.</em> </p><p>Have you heard of Nietzcheâ€™s slave morality? Be wary of combining bad characteristics with good ones. You can get good grades <em>and</em> be a good person. </p><p>Learn to catch yourself doing this, because it will happen all the time in your life. Now itâ€™s grades, but tomorrow it may be â€œRich people are evil, Iâ€™m not evilâ€�. </p><p>You may feel good about yourself, but if you follow this idea, you wonâ€™t get what you want. Instead, ask the question: â€œHow can I get good grades and *not kiss up?â€� Find people like that and learn from them.</p><p><em>Adult Aside â€”</em> 
<em>Anytime you want something that you donâ€™t have, this thinking will materialize. â€œOh people who are fit spend so much time in the gym, Iâ€™m not that kind of personâ€�, etc etc. Be careful about the constraints you set with your ideas.</em></p><p><strong>Be wary of all or nothing thinking</strong></p><p>Slave morality can get hard to swallow, so they may say â€” <em>but grades are unfair. Even if I do well the teacher can knock me for â€œparticipationâ€�, thatâ€™s why the kiss-up people get good grades.</em></p><p>Youâ€™re right. This is frustrating and unfair. And thereâ€™s a reason some people kiss up: itâ€™s easier to do that. But, just because some parts are unfair and some people cheat, doesnâ€™t mean you should give up on what you want. The world isnâ€™t so black and white.</p><p><em>Tell yourself: you will do whatâ€™s under your control.</em> Learn from the people you admire who behave the way you think is right. Yes some people have an advantage, yes some things are plain unfair, but you can still get what you want. If you do all of that and it doesn't work, you'll know you tried your best, and something better will certainly happen regardless. </p><p><em>Adult Aside â€”</em> 
<em>I remember Ramit Sethi telling the story of someone who wanted to start working out, but only had one day free a week. Instead of working out once a week, they didnâ€™t work out at all. They thought it had to be 5 times a week. The more you can let go of the black and white nature of childhood, the more youâ€™ll flourish</em></p><p><strong>Be wary of comfort</strong></p><p>A final interjection may come from comfort â€” <em>I want to learn this thing, but I donâ€™t want to look dumb, etc.</em>  </p><p>If you lived in our village, youâ€™d be <em>prettyy cool.</em> Wow you study in the big city, wow, you know so much math, wow you are good at fighting.</p><p>But imagine if you met a navy seal from Afghanistan. How do you think your fighting skill would stack up?</p><p>If you <em>actually</em> want to become great, you have to get outside of your comfort zone<em>.</em> Actively look for those opportunities. Youâ€™ll have an urge to drop them because you want to feel coolâ€¦but hey itâ€™s better to <em>be</em> cool then to <em>feel</em> cool</p><p><em>Adult Aside â€”</em> 
<em>Ask yourself constantly, where are the people I can learn from? It can be uncomfortable to go from the best person in the room to a <a href="http://paulgraham.com/noob.html" target="_blank">noob</a>, but this is the path forward</em> </p><p><strong>Appreciations</strong> </p><p>Many of these ideas crystallized by reading two people have inspired me: Nassim Taleb and Paul Graham. Nassim for elucidating the life of the flaneur, and Paul for his essay <a href="http://www.paulgraham.com/hs.html" target="_blank">â€œWhat youâ€™d wish youâ€™d knownâ€�</a></p><p><em>Thanks to Nino Parunashvili, Elene Asanidze, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/235</link>
            <guid isPermaLink="false">hacker-news-small-sites-24462858</guid>
            <pubDate>Sun, 13 Sep 2020 18:26:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wikipedia Matters (2019) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24462593">thread link</a>) | @walterbell
<br/>
September 13, 2020 | http://marit.hinnosaar.net/wikipediamatters.pdf | <a href="https://web.archive.org/web/*/http://marit.hinnosaar.net/wikipediamatters.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://marit.hinnosaar.net/wikipediamatters.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24462593</guid>
            <pubDate>Sun, 13 Sep 2020 17:49:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The sweet and the bitter of cloud computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24462569">thread link</a>) | @nyongrevoir
<br/>
September 13, 2020 | https://ssteo.github.io/2019-cybercentral/ | <a href="https://web.archive.org/web/*/https://ssteo.github.io/2019-cybercentral/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				<section data-id="ce91735b152043e229dac5e6f1eb128a"><section data-id="bbc556b8f3236941e8a766fb297bc2b3">
<div data-block-type="text" data-block-id="01a50226a856d8ae58c5d062c15fef76"><div><p><strong>Sze Siong Teo | CyberCentral Summit 2019</strong></p></div></div>
<div data-block-type="image" data-block-id="3d020d0902432192f427f3908b2f29f6"><p><img data-natural-width="137" data-natural-height="66" data-lazy-loaded="" data-src="cloudsec/8e070d1d6bddb4be82eae0b2189d04a5.svg"></p></div>
</section><section data-id="cbc3c181cd7c7451f67429dee6146b14"><div data-block-type="text" data-block-id="1670387dc1f73f0df94d929864073a8b"><div data-placeholder-tag="h2" data-placeholder-text="Subtitle">
<h2>about me</h2>

<p>programming - 22 years</p>

<p>devops - 5 years</p>

<p>security - 8 years</p>



<p>industry exp. - 14 years</p>
</div></div>
<div data-block-type="image" data-block-id="e40a3a22e6a1d682c525cb985b10c074"><p><img data-natural-width="300" data-natural-height="300" data-lazy-loaded="" data-src="cloudsec/af70adef7634a3ae3877840aa9441570.jpg" src="https://ssteo.github.io/2019-cybercentral/cloudsec/af70adef7634a3ae3877840aa9441570.jpg"></p></div>
</section><section data-id="975b96a7e90971f8e80331a54e2dad71">
<div data-block-type="text" data-block-id="3878bd3bb1cda9e2adca28e9dc9ca940"><div data-placeholder-tag="h2" data-placeholder-text="Subtitle" dir="ui">
<ul>
	<li><span>On-premise vs public cloud</span></li>
	<li><span>Real world cloud security issues</span></li>
	<li><span>Mitigation techniques</span></li>
</ul>
</div></div></section><section data-id="f27c22c9a737867f3170d48d0d46637a"><div data-block-type="text" data-block-id="d55eefd0103155f84a7b84214ca5419f"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>on-premise vs public cloud</h2>
</p></div>
<div data-block-type="text" data-block-id="e24c66d0e68a40342ee1bbc05d818b78"><div data-placeholder-tag="p" data-placeholder-text="Text">
<ul>
	<li><span>Compute - whose app. runs there?</span></li>
	<li><span>Network - who uses the same ASN?</span></li>
	<li><span>Storage - where is your data?</span></li>
	<li><span>How wide is the system trust chain?</span></li>
</ul>
</div></div></section><section data-id="e7e29c673f1737819427423710c88852"><div data-block-type="text" data-block-id="9e21b8a68fb504be88a24cd6a6332b8b"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>REAL WORLD cloud security issues</h2>
</p></div>

<div data-block-type="image" data-block-id="20edcfaf03af3f0fa203f2a8a720cc7a"><p><img data-natural-width="1538" data-natural-height="670" data-lazy-loaded="" data-src="cloudsec/ecc1dd5ecf50f2eafe49a3c73aeebe49.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/ecc1dd5ecf50f2eafe49a3c73aeebe49.png"></p></div>
</section><section data-id="09404ebc54630e82c6cb3b5b76546b49"><div data-block-type="text" data-block-id="7e2b17e0eaaf2044bb1b423d2c9d75e3"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>Credential leak: Example #1</h2>
</p></div>
<div data-block-type="image" data-block-id="db0ddb0285ac84e1ab555e73a2b39a39"><p><img data-natural-width="1975" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/752e8dda7e34fd54baac5f08e0f880bf.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/752e8dda7e34fd54baac5f08e0f880bf.png"></p></div></section><section data-id="b72435ded6eadd4f02495fdf06b45054"><div data-block-type="text" data-block-id="84b4b80345329c8a8bd992b8988b3e48"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>Credential leak: Example #2</h2>
</p></div>
<div data-block-type="image" data-block-id="74dad1a9f4995eec747698d7226c4d4e"><p><img data-natural-width="1739" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/fc2220474d3782636c19db56982f3814.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/fc2220474d3782636c19db56982f3814.png"></p></div></section><section data-id="2959a715702dd64fb0290bf813211978"><div data-block-type="text" data-block-id="a881f502505e7330816e3673a0949309"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>Credential leak: Example #3</h2>
</p></div>
<div data-block-type="image" data-block-id="97e3b85b6007fd9d19b30285576a3e2d"><p><img data-natural-width="1913" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/655a60930460e8d6780d009b6a3c3ee5.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/655a60930460e8d6780d009b6a3c3ee5.png"></p></div></section><section data-id="118b688ee27e58955b11eacfdb2c377a"><div data-block-type="text" data-block-id="30c574bfc93eaf66851e22ef906744ea"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>Credential leak: Example #4</h2>
</p></div>
<div data-block-type="image" data-block-id="15b27b3472fa4a1334d00d1d40a2a77e"><p><img data-natural-width="1906" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/5610796dfeab9fa6d22145334541612d.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/5610796dfeab9fa6d22145334541612d.png"></p></div></section><section data-id="dcaab272d842ee78f3b3adf21232dbf1"><div data-block-type="text" data-block-id="311d7b025d02e61c9e9a9c07a16722e5"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>Credential leak: Example #5</h2>
</p></div>
<div data-block-type="image" data-block-id="e74c96909b97ccc5c31e258a0551b684"><p><img data-natural-width="1313" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/24072cb92fcdfec039bbad8b2731ee8c.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/24072cb92fcdfec039bbad8b2731ee8c.png"></p></div></section><section data-id="732403469f7a12b822bef1eb14e9f7d0"><div data-block-type="text" data-block-id="df0de0bc7b75a6159ff0d175ccb39c8f"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>github hackerone program's hacktivity</h2>
</p></div>
<div data-block-type="image" data-block-id="a0dea3fb42fdfb023cc2d63aada0ccb8"><p><img data-natural-width="1499" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/56759aa66540e2b405c9ac20f6beb83f.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/56759aa66540e2b405c9ac20f6beb83f.png"></p></div>
</section><section data-id="370120c5ca2c0e6eb06026dbcb3fb38b"><div data-block-type="text" data-block-id="c5e003bcc3e7703b724cc1a85941c00c"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>gitlab hackerone program's hacktivity</h2>
</p></div>
<div data-block-type="image" data-block-id="42714c2f8388f8ae230df1089d328014"><p><img data-natural-width="1514" data-natural-height="1160" data-lazy-loaded="" data-src="cloudsec/ae8f771177b430ad7dce77fd24e271fd.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/ae8f771177b430ad7dce77fd24e271fd.png"></p></div>
</section><section data-id="9e378a736523e35ab188db9067e54ad4"><div data-block-type="text" data-block-id="d68c3c69bb2abcc962627ebe14dfe489"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>Common saas CI/CD config filenames</h2>
</p></div>
<div data-block-type="text" data-block-id="dd22ed5785277c5f70ef637608ccade6"><div data-placeholder-tag="p" data-placeholder-text="Text">
<ul>
	<li><span>.travis.yml</span></li>
	<li><span>.circleci/config.yml</span></li>
	<li><span>.gitlab-ci.yml</span></li>
	<li><span>shippable.yml</span></li>
	<li><span>fastlane/Fastfile (iOS/Android)</span></li>
</ul>
</div></div></section><section data-id="30ca1d12341120b4b61507d88b24a43d"><div data-block-type="text" data-block-id="3915209aa7cc7fc433ab7ccbe5dc7871"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>REAL WORLD cloud security issues</h2>
</p></div>

<div data-block-type="image" data-block-id="6512f3a228ecf91deb2286071f85b7cf"><p><img data-natural-width="1748" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/30511c5d27773db2b759545ebff114de.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/30511c5d27773db2b759545ebff114de.png"></p></div>
</section><section data-id="2752166959ade2a04fdfea31a2823f26"><div data-block-type="image" data-block-id="a7af1d319836f9cc7c299866a276ec33"><p><img data-natural-width="1104" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/baec77592762027094b9c5d8ed9a27b7.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/baec77592762027094b9c5d8ed9a27b7.png"></p></div>
</section><section data-id="1b540cd2bde5c2797c022d7f190f388b">
<div data-block-type="image" data-block-id="dbfadbc3140ffe8b788a2285a298bff5"><p><img data-natural-width="1865" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/2c220abb2b33d065b6440de269cfeb9e.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/2c220abb2b33d065b6440de269cfeb9e.png"></p></div>
</section><section data-id="45c770ae8362b8ba43b887edf6ab9b4a"><div data-block-type="image" data-block-id="4411c9c6ae1fcc5f84165d587a319da4"><p><img data-natural-width="1367" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/c2b4b3314204fdd167a895ec4ee5cbb9.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/c2b4b3314204fdd167a895ec4ee5cbb9.png"></p></div>
<div data-block-type="text" data-block-id="3256f1c3a7dccb4191e7c01cc5fd4a29"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>typosquatting: sneak attack on supply chain</h2>
</p></div>
</section><section data-id="ce3ae32640f96baef4b6c73b12fb181a"><div data-block-type="text" data-block-id="677672d548ea0cfeeff2663ce8779d31"><div data-placeholder-tag="p" data-placeholder-text="Text">
<ol>
	<li><span>npm, PyPI, CPAN, Rubygems, maven, Packagist, etc..</span></li>
	<li><span>ISO files, VMDK, VDI, Docker Hub, AMI marketplace</span></li>
	<li><span>Lambda layers - <a href="https://github.com/mthenw/awesome-layers" target="_blank">https://github.com/mthenw/awesome-layers</a></span></li>
	<li><span>AWS Serverless Application Repository</span></li>
	<li><span>Application download website / software update repository</span></li>
</ol>
</div></div>
<div data-block-type="text" data-block-id="85a289dbb927856ecc24e979ae2e20f2"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>different types of software supply chain</h2>
</p></div></section><section data-id="71f48d62382d13a688c57a0e1b254bae"><div data-block-type="text" data-block-id="5401f12dcbaec062f2cbe80be0e6f53f"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>REAL WORLD cloud security issues</h2>
</p></div>
<div data-block-type="text" data-block-id="ae625d1a64f919c93771847c36081433"><p><span>#3 Misconfigured cloud resources</span></p></div>
<div data-block-type="image" data-block-id="39da4e50597d6b098c046f6ce3647339"><p><img data-natural-width="1676" data-natural-height="830" data-lazy-loaded="" data-src="cloudsec/564f6da1cfd9e3ff0f58aa36740a3a54.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/564f6da1cfd9e3ff0f58aa36740a3a54.png"></p></div>
</section><section data-id="fb875d5f55c2e92c34ab2a4a746f03d5"><div data-block-type="text" data-block-id="e9282c07a777641981f258ac31369010"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>most common s3 bucket acl confusion</h2>
</p></div>
<div data-block-type="image" data-block-id="74a90d58f242def9f2a6dbce8d3409e3"><p><img data-natural-width="1652" data-natural-height="1126" data-lazy-loaded="" data-src="cloudsec/b4fe7e605017b37ba7819fc9e0b1a0f1.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/b4fe7e605017b37ba7819fc9e0b1a0f1.png"></p></div>
</section><section data-id="a7b5e434c85f210c026211fa0b47fd89"><div data-block-type="text" data-block-id="5972e2770dbd933b58796cec2783cbb3"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>how attackers get your bucket name?</h2>
</p></div>



<div data-block-type="text" data-block-id="b3c87592fe9534489dde0a1a8980ab74"><div data-placeholder-tag="p" data-placeholder-text="Text">
<ul>
	<li><span>customer-transaction-backup</span></li>
	<li>customer-profile-backup</li>
	<li>cybercentral-wordpress-backup</li>
	<li>cybercentral-wordpress-snapshot</li>
	<li>cybercentral-backup-20190405 (date, etc.)</li>
	<li>banking-transaction-kafka-backup</li>
	<li>user-transaction-kafka-logs</li>
</ul>
</div></div></section><section data-id="0359666520866d4f451e3fc17e492436"><div data-block-type="text" data-block-id="f17faee29959ae98ec4576ae0a8ab9d7"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>how attackers get your bucket name?</h2>
</p></div>

<div data-block-type="text" data-block-id="7803fd22d2f3832e10117782d899f532"><p><span>http://<span><em><strong>bucket_name</strong></em></span>.s3-<span><em><strong>aws_region</strong></em></span>.amazonaws.com</span></p></div>
<div data-block-type="text" data-block-id="a78cf34ff79291ed335b0077da147a86"><p><strong>Brute force with SecLists on below URL format:</strong></p></div>
<div data-block-type="text" data-block-id="ecc2eee1a7fdc075088c2a72f860e61a"><div data-placeholder-tag="p" data-placeholder-text="Text">
<ul>
	<li>
<span>mysql-dump.tar.gz, </span><span>mysql-dump.bz2</span>
</li>
	<li><span>users.sql.zip, users.tar.gz</span></li>
	<li>consumer-service-spring-config.xml</li>
	<li>test.tar.gz</li>
	<li>all.tar.gz, all.zip, all.bz2</li>
	<li>db-backup.tar.gz, db_backup.bz2, etc.</li>
</ul>
</div></div>
<div data-block-type="text" data-block-id="482d020bb4712fad0ef8a0084444d243"><p><strong>Same approach for filenames when directory listing not available:</strong></p></div>
<div data-block-type="text" data-block-id="7ef40425fd129873bb8660533f1121d2"><p><span><em><strong>(Under the hood: aws s3 ls [target_bucket_name])</strong></em></span></p></div>
</section><section data-id="b2db2d1ab8bc357460c6737829977ffb">

<div data-block-type="text" data-block-id="49490ae59033df6cbb39d534e6fe86f5"><div><div data-placeholder-tag="p" data-placeholder-text="Text">
<ol>
	<li>
<span>IAM policy read+write common fallacy</span>
	<ul>
		<li><span>If you have write permission, then you should be able to read from it too</span></li>
	</ul>
	</li>
	<li>
<span>IAM principal with:</span>
	<ul>
		<li><span>Wildcard on S3, SQS policy, etc.</span></li>
		<li><span>Trust to the root of other account</span></li>
	</ul>
	</li>
	<li>
<span>IAM policy with wildcard in:</span>
	<ul>
		<li><span>IAM actions</span></li>
		<li><span>AWS resources</span></li>
	</ul>
	</li>
</ol>
</div></div></div>
<div data-block-type="image" data-block-id="c0639ba2956e2718d84807cc27c8ebb5"><p><img data-natural-width="744" data-natural-height="974" data-lazy-loaded="" data-src="cloudsec/9bd2dc0ce697085e3378a6257e94c7b1.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/9bd2dc0ce697085e3378a6257e94c7b1.png"></p></div></section><section data-id="d1c36a8e86ddda4bc9f28aa57fcec70e">
<div data-block-type="image" data-block-id="2573977f0e9947616dd8cb48a22bc7fc"><p><img data-natural-width="1425" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/f9788e0d3c07c25a134b7529317e1c03.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/f9788e0d3c07c25a134b7529317e1c03.png"></p></div>
<div data-block-type="text" data-block-id="afcfce15a95bbc1c54cfd6012ec2f042"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>Ssrf exploit in Google cloud that leads to rce</h2>
</p></div></section><section data-id="af90d974dbc8ddee6386f0abe929dd67"><div data-block-type="text" data-block-id="d18ed1c152dd7ad705a1c6f0ff24957c"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>Ssrf exploit in AWS that leads to rce</h2>
</p></div>

<div data-block-type="image" data-block-id="71a5b55bfbf3800a75f1c8706adf5809"><p><img data-natural-width="1806" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/d0048e039f4419465997d5e88c74f043.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/d0048e039f4419465997d5e88c74f043.png"></p></div></section><section data-id="f1f891d922e22689dd8f68d880922d50"><div data-block-type="text" data-block-id="5d55918243d2aea5965d510063be12b0"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>misunderstood zero trust model</h2>
</p></div>


<div data-block-type="text" data-block-id="66eafa09e38d09e9e2d0dedb28b0781c"><div><p><em>“The strategy around Zero Trust boils down to don’t trust anyone. We’re talking about, ‘Let’s cut off all access until the network knows who you are. Don’t allow access to IP addresses, machines, etc. until you know who that user is and whether they’re authorized.’”</em></p></div></div>
<div data-block-type="text" data-block-id="dbe47b73540bc7ffb8e953245d305b51"><div><div data-placeholder-tag="p" data-placeholder-text="Text">
<ol>
	<li><span>Usage of default VPC &amp; default security group</span></li>
	<li><span>EC2/RDS with public IP and open security group</span></li>
</ol>
</div></div></div>
<div data-block-type="text" data-block-id="3e1433d1f525b59776b821f51a952666"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2><span>unnecessary exposure to public network</span></h2>
</p></div></section><section data-id="6edcb1dd4631ee945fe363f352edcf1c"><div data-block-type="text" data-block-id="ef4a116dc015faebede6229f85161933"><p data-placeholder-tag="h2" data-placeholder-text="Title Text">
<h2>misconfigured mongodb server in public</h2>
</p></div>
<div data-block-type="image" data-block-id="8967164b25b0500be1a14463ccf435b4"><p><img data-natural-width="1401" data-natural-height="1350" data-lazy-loaded="" data-src="cloudsec/8da0c06bd8519e0e5efe84945849d275.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/8da0c06bd8519e0e5efe84945849d275.png"></p></div>
</section><section data-id="15dc7e003a9f05d58b1d86acbd81ffa8">
<div data-block-type="text" data-block-id="eb9928b7152008075a879c6f7eced168"><div data-placeholder-tag="p" data-placeholder-text="Text">
<ol>
	<li><span>Never store any plaintext credential in source control</span></li>
	<li><span>Always keep the servers fully patched</span></li>
	<li><span>Use only libraries from official&nbsp; sources and pin the package version</span></li>
	<li><span>Don't use S3 bucket ACL, use S3 bucket policy instead</span></li>
	<li><span>Don’t use access keys that ties to IAM user, always use IAM role</span></li>
	<li><span>Always provide "just sufficient" IAM permission for all service</span></li>
	<li><span>Never use AWS root user, go for split account model if multiple teams</span></li>
	<li><span>Limit egress traffic to known host only if possible</span></li>
	<li><span>Use private DNS zone for internal systems whenever possible</span></li>
	<li><span>Strong password policy and make MFA mandatory</span></li>
	<li><span>CloudTrail must be enabled and app. level logging is essential for SIEM</span></li>
	<li><span>SSO for all system is mandatory in large organization</span></li>
	<li><span>Rate limit request by cookie and by IP or trigger reCaptcha</span></li>
	<li><span>Never perform any HTTP request based on unsanitized input</span></li>
</ol>
</div></div></section><section data-id="08c07ba2db649d7eb60313afb079e051">

<div data-block-type="image" data-block-id="1091cfb2d38d804b9c8a63b624e06945"><p><img data-natural-width="225" data-natural-height="225" data-lazy-loaded="" data-src="cloudsec/7c803910276483d88a00aee82dd52ddb.png" src="https://ssteo.github.io/2019-cybercentral/cloudsec/7c803910276483d88a00aee82dd52ddb.png"></p></div></section></section>
			</div>
		</div></div>]]>
            </description>
            <link>https://ssteo.github.io/2019-cybercentral/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24462569</guid>
            <pubDate>Sun, 13 Sep 2020 17:45:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dialects in Code: Part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24462488">thread link</a>) | @raicem
<br/>
September 13, 2020 | https://www.rosstuck.com/dialects-in-code-part-1 | <a href="https://web.archive.org/web/*/https://www.rosstuck.com/dialects-in-code-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>For a long time, I’ve been interested in how different folks can use the same programming language in radically different ways. I’ve privately used the term “dialects” to describe these different approaches. In this series, I want to talk about recognizing dialects in code and how we can make them work for us.</p>

<p>Before we get into concrete benefits though, let’s focus on dialects, where they come from and how they find their way into our code.</p>

<h2 id="the-big-bad-theory">The Big Bad Theory</h2>
<p>Telepathy doesn’t exist.</p>

<p>To communicate our thoughts, we need to encode them into language. The process of encoding thoughts into a language produces an artifact, like written text, spoken words, sign language, subtle facial expressions or even a combination of these.</p>

<p>This artifact is always an imperfect copy of the author’s original thoughts. You can say “X is like Y” or “I am sad today” but this is always a simplification that doesn’t have the exact connotations, knowledge or context that remain in your brain.  Those thoughts remain hidden to us. Sharing the full state of your brain would take too long, be too complex and might not be possible since the other person still has their own thoughts.  Like saving a JPEG, encoding a thought into a language is always a lossy process. The artifact that comes out of the encoding process is different than the thought that went into it.</p>

<p>The advantage of artifacts is they <em>can</em> be shared. By simplifying our thoughts, we reduce the information we’re transmitting to a managable amount. Sometimes the thought even becomes clearer because we’ve simplified it. Artifacts can also be communicated or stored for further use. That’s a huge advantage.</p>

<p>On the other side, the person consuming the artifact will understand it differently depending on their own thoughts, experiences and knowledge. I could say something like “Monads are monoids in the category of endofunctors.” This might be a concise, correct statement but how you perceive it depends on your knowledge of functional programming knowledge, or recognizing it as a meme/joke, or just how you feel about me in general.</p>

<p>Language has rules but they’re very fuzzy rules on both the creating and receiving side.</p>

<h2 id="now-in-code">Now in Code</h2>
<p>The same is true for programming. When we begin writing code, we have an idea we want to express, like a rough sketch of an API, or a fix for a bug, or a full fledged model. If we want to automate the execution of that idea, we need to express it in a programming language.</p>

<p>Programming languages tend to offer less expressiveness than natural languages. That means it takes extra effort to encode information in them and it takes a lot of contextual knowledge to understand the authorial intent. On the flip side, programming languages are significantly less ambiguous than natural languages. If expressing an idea in English is like saving a photo as a JPEG, expressing an idea in code is like saving a photo as a GIF with max 256 colors: you lose detail but gain conciseness.</p>

<p>That tradeoff allows a computer to execute our idea with incredible speed and accuracy, which is a heck of a thing.</p>

<h2 id="information-through-convention">Information Through Convention</h2>
<p>The loss of information about business requirements or programmer intent still presents a major challenge for maintenance and future development. We can work around this by supplementing the code with discussion and documentation, and teams frequently do. However, the code itself remains one of our most vital and useful artifacts. Even very human centric methodologies like Domain-Driven Design acknowledge code as the primary artifact your team uses.</p>

<p>So to help preserve our mental well-being, programmers created practices, tricks, and conventions to help impart more meaning into code.</p>

<p>For example, long-term PHP’ers may remember that classes didn’t always have visibility modifiers for properties or methods. This was frustrating when writing a class because things could change or be called in unexpected ways and it was frustrating when using a class because it wasn’t always clear which things you should or shouldn’t touch.</p>

<div><div><pre><code><span>// If a user changes the name property directly here, the changed name may get saved</span>
<span>// in the database but it will fail to change the lastUpdated time. Oops!</span>
<span>class</span> <span>User</span>
<span>{</span>
    <span>var</span> <span>$name</span><span>;</span>

    <span>function</span> <span>name</span><span>(</span><span>$name</span><span>)</span>
    <span>{</span>
        <span>$this</span><span>-&gt;</span><span>name</span> <span>=</span> <span>$name</span><span>;</span>
        <span>$this</span><span>-&gt;</span><span>lastUpdated</span> <span>=</span> <span>time</span><span>();</span>
    <span>}</span>
</code></pre></div></div>

<p>To work around this, PHP borrowed an existing convention that private or protected class features should be prefixed with an underscore. By adding and understanding this convention, we can convey extra information that prevents bugs:</p>

<div><div><pre><code><span>// Here the _ tells the user “don’t change this property directly” so </span>
<span>// hopefully they’ll scroll farther down and find the name() method</span>
<span>class</span> <span>User</span>
<span>{</span>
    <span>var</span> <span>$_name</span><span>;</span>

    <span>function</span> <span>name</span><span>(</span><span>$name</span><span>)</span>
    <span>{</span>
        <span>$this</span><span>-&gt;</span><span>_name</span> <span>=</span> <span>$name</span><span>;</span>
        <span>$this</span><span>-&gt;</span><span>lastUpdated</span> <span>=</span> <span>time</span><span>();</span>
    <span>}</span>
</code></pre></div></div>

<p>It may seem crude today but for developers at the time, this convention added a lot of safety and intent to the code. You could rely more readily on autocomplete without having to read the entire class and that was a big productivity gain.</p>

<p>Still, it wasn’t perfect: you couldn’t differentiate between protected and private. Some folks tried a double underscore, others did it the other way around and most didn’t differentiate between the two at all. Eventually, this was formalized into the PHP language itself as public/protected/private visibility modifiers which is now the most widely used way of expressing this.</p>

<p>Most practices will never end up as part of the core language itself. They’ll remain userland conventions like a variable naming scheme, a specific directory structure, a preference for one design pattern over another, etc. And that’s good, userland conventions are typically cheaper to produce and iterate on. Even features that make their way into the language itself (our visibility modifiers) may change or even be removed. Languages are always in motion, evolving towards the future.</p>

<h2 id="enter-the-dialect">Enter the Dialect</h2>
<p>Over time, these practices group, combine, split and merge into semi-stable clusters which are used and recognized by a group of people. Keeping with our “Programming languages as a language” metaphor, I refer to these groups as “dialects” of the programming language.</p>

<p>In human language, a dialect is a version of a language (say, English) with its own grammar, vocabulary, idioms and other other features. For example, I’m originally from the Southern part of the US where we say “y’all” and “over yonder”, which is unique to our region.</p>

<p>Dialects within the same base language are usually still intelligible to each other. I can communicate with folks from the US Midwest who have their own dialect. I may have more trouble with someone from the UK who speaks Cockney but given time, we can probably work it out.</p>

<p>All of this is true for programming communities as well. Different communities will have unique practices, unique ways of combining them and occasionally different difficulty levels in understanding each other, even if they’re using the same programming language.</p>

<p>Because of its wide variety of uses, PHP has a host of dialects and like human languages, most are associated with and propagated by a community of some kind. The boundaries between dialects can be blurry, as they’re essentially artificial, but it can be useful to talk about. We can identify them by a particular framework (Laravel vs Symfony dialects), a product (Drupal vs Wordpress dialects). It can be generational (PHP devs from before 2010), geographic (PHP’ers from The London School of TDD), or even comparative (“Java-style” PHP). A dialect can be as small as one person (a personal style) or as large as several million.</p>

<p>It’s important to realize that just as with natural languages, there is no “true” dialect of a programming language. Even a standardized dialect is still just a dialect. Therefore, when we talk about encoding our thoughts into an artifact, we’re doing this by applying not just a language but a specific dialect of that language and that will impact the resulting artifact, i.e. code.</p>

<h2 id="how-do-dialects-impact-my-code">How do dialects impact my code?</h2>
<p>Even something as simple as naming a class is impacted by our choice of dialect. Let’s say you had a class that receives an event and dispatches it to 0 or more listeners. Would you go with:</p>

<div><div><pre><code><span>class</span> <span>EventDispatcher</span>
<span>class</span> <span>DispatchesEvents</span>
</code></pre></div></div>

<p><code>EventDispatcher</code> is probably the most common choice, as the bulk of dialects I’ve seen name classes after nouns. That said, there are communities in PHP that prefer to name classes after the responsibilities that class has, using a form that focuses on verbs. It’s a very distinctive choice and like my use of “y’all”, it’s often a good clue as to the origin of the code I’m looking at.</p>

<p>As we said before, both dialects are equally valid, there is no right or wrong choice here! However, confusion arises when consumers of the artifact are unaware of the implicit rules of the dialect used or, worse, apply conventions from the wrong dialect.</p>

<p>For example, in some communities, the verb-first form is never used for classes but is used for traits. If I’m looking at a file tree of a library and assume that <code>DispatchesEvents.php</code> is a trait, that can confuse my understanding of the overall library.</p>

<p>So, should we value mutual intelligibility of dialects above all else and always use the most common convention? There’s certainly value in that but allowing changes like this is a key element in innovation. It’s a balancing act and heavily dependent on the intended audience for our code. Is this only used in a specific team? Will it be a widely consumed library? Is it mainly consumed as a binary without ever looking at the code?</p>

<p>Let’s look at another example. You need to iterate over a list of numbers and perform some operation to each of them. How do you prefer to iterate over them?</p>

<div><div><pre><code><span>for</span> <span>(</span><span>$i</span> <span>=</span> <span>0</span><span>;</span> <span>$i</span> <span>&lt;</span> <span>count</span><span>(</span><span>$list</span><span>);</span> <span>$i</span><span>++</span><span>)</span>
<span>foreach</span> <span>(</span><span>$numbers</span> <span>as</span> <span>$list</span><span>)</span>
<span>map</span><span>(</span><span>$list</span><span>,</span> <span>/*...*/</span><span>)</span>
</code></pre></div></div>

<p>While we may each have a …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rosstuck.com/dialects-in-code-part-1">https://www.rosstuck.com/dialects-in-code-part-1</a></em></p>]]>
            </description>
            <link>https://www.rosstuck.com/dialects-in-code-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24462488</guid>
            <pubDate>Sun, 13 Sep 2020 17:33:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AresDB: Uber's GPU-Powered Open Source, Real-Time Analytics Engine]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 75 (<a href="https://news.ycombinator.com/item?id=24461844">thread link</a>) | @Recovery2020
<br/>
September 13, 2020 | https://ubere.ng/2HzMPVK | <a href="https://web.archive.org/web/*/https://ubere.ng/2HzMPVK">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p><a href="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1.png" data-caption=""><img width="696" height="298" src="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-696x298.png" srcset="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-696x298.png 696w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-300x128.png 300w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-768x329.png 768w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-1024x438.png 1024w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-1068x457.png 1068w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-981x420.png 981w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1.png 1500w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="Featured"></a></p>
        <p><span>At Uber, real-time analytics allow us to attain business insights and operational efficiency, enabling us to make data-driven decisions to improve experiences on the Uber platform. For example, our operations team relies on data to monitor the market health and spot potential issues on our platform; software powered by machine learning models leverages data to predict rider supply and driver demand; and data scientists use data to improve machine learning models for better forecasting. </span></p>
<p><span>In the past, we have utilized many third-party database solutions for real-time analytics, but none were able to simultaneously address all of our functional, scalability, performance, cost, and operational requirements. </span></p>
<p><span>Released in November 2018, AresDB is an open source, real-time analytics engine that leverages an unconventional power source, graphics processing units (GPUs), to enable our analytics to grow at scale. An emerging tool for real-time analytics, GPU technology has advanced significantly over the years, making it a perfect fit for real-time computation and data processing in parallel. </span></p>
<p><span>In the following sections, we describe the design of AresDB and how this powerful solution for real-time analytics has allowed us to more performatively and efficiently unify, simplify, and improve Uber’s real-time analytics database solutions. After reading this article, we hope you try out AresDB for your own projects and find the tool useful your own analytics needs, too! </span></p>
<h3>Real-time analytics applications at Uber</h3>
<p><span>Data analytics are crucial to the success of Uber’s business. Among other functions, these analytics are used to: </span></p>
<ul>
<li><span>Build </span><b>dashboards</b><span> to monitor our business metrics</span></li>
<li><span>Make </span><b>automated decisions</b><span> (such as </span><a href="https://www.uber.com/drive/partner-app/how-surge-works/" target="_blank" rel="noopener noreferrer"><span>trip pricing</span></a><span> and </span><a href="https://eng.uber.com/advanced-technologies-detecting-preventing-fraud-uber/" target="_blank" rel="noopener noreferrer"><span>fraud detection</span></a><span>) based on aggregated metrics that we collect</span></li>
<li><span>Make </span><b>ad hoc queries</b><span> to diagnose and troubleshoot business operations issues</span></li>
</ul>
<p><span>We can summarize these functions into categories with different requirements as follows:</span></p>
<table>
<tbody>
<tr>
<td></td>
<td><b>Dashboards</b></td>
<td><b>Decision Systems</b></td>
<td><b>Ad hoc Queries</b></td>
</tr>
<tr>
<td><span>Query Pattern</span></td>
<td><span>Well known</span></td>
<td><span>Well known</span></td>
<td><span>Arbitrary </span></td>
</tr>
<tr>
<td><span>Query QPS</span></td>
<td><span>High</span></td>
<td><span>High</span></td>
<td><span>Low</span></td>
</tr>
<tr>
<td><span>Query Latency</span></td>
<td><span>Low</span></td>
<td><span>Low</span></td>
<td><span>High</span></td>
</tr>
<tr>
<td><span>Dataset</span></td>
<td><span>Subset</span></td>
<td><span>Subset</span></td>
<td><span>All data</span></td>
</tr>
</tbody>
</table>

<p><span>Dashboards and decision systems leverage real-time analytical systems to make similar queries over relatively small, yet highly valuable, subsets of data (with maximum data freshness) at high QPS and low latency.</span></p>
<h4>The need for another analytical engine</h4>
<p><span>The most common problem that real-time analytics solves at Uber is how to compute time series aggregates, calculations that give us insight into the user experience so we can improve our services accordingly. With these computations, we can request metrics by specific dimensions (such as day, hour, city ID, and trip status) over a time range on arbitrarily filtered (or sometimes joined) data. Over the years, Uber has deployed multiple solutions to solve this problem in different ways.</span></p>
<p><span>Some of the third-party solutions we’ve used for solving this type of problem include:</span></p>
<ul>
<li><a href="https://github.com/apache/incubator-pinot" target="_blank" rel="noopener noreferrer"><b>Apache Pinot</b></a><span>, an open source distributed analytical database written in Java, can be leveraged for large-scale data analytics. Pinot employs a lambda architecture internally to query batch and real-time data in columnar storage, uses inverted bitmap index for filtering, and relies on star-tree for aggregate result caching. However, it does not support key-based deduplication, upsert, joins, and advanced query features such as geo-spatial-filtering. In addition, being a JVM-based database, query execution on Pinot runs at a higher cost in terms of memory usage.</span></li>
<li><a href="https://www.elastic.co/" target="_blank" rel="noopener noreferrer"><b>Elasticsearch</b></a><span> is used at Uber for a variety of streaming analytics needs. It was built on Apache </span><a href="http://lucene.apache.org/" target="_blank" rel="noopener noreferrer"><span>Lucene</span></a><span> for full-text keyword search that stores documents and inverted index. It has been widely adopted and extended to also support aggregates. The inverted index enables filtering, yet it is not optimized for time range-based storage and filtering. It stores records as JSON documents, imposing additional storage and query access overhead. Like Pinot, Elasticsearch is a JVM-based database, and as such, does not support joins and its query execution runs at a higher memory cost. </span></li>
</ul>
<p><span>While these technologies have strengths of their own, they lacked crucial functionalities for our use case. We needed a unified, simplified, and optimized solution, and thought outside-of-the-box (or rather, inside the GPU) to reach a solution.</span></p>
<h3>Leveraging GPUs for real-time analytics</h3>
<p><span>To render realistic views of images at a high frame rate, GPUs process a massive amount of geometries and pixels in parallel at high speed. While the clock-rate increase for processing units has plateaued over the past few years, the number of transistors on a chip has only increased per </span><a href="https://en.wikipedia.org/wiki/Moore%27s_law" target="_blank" rel="noopener noreferrer"><span>Moore’s law</span></a><span>. As a result, GPU computation speeds, measured in Gigaflops per second (GFLOP/s), are rapidly increasing. Figure 1, below, depicts the theoretical GFLOP/s trend comparing NVIDIA GPUs and Intel CPUs over the years:</span></p>
<figure id="attachment_5345" aria-describedby="caption-attachment-5345"><a href="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2.png" alt="" width="600" height="314" srcset="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2.png 1999w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-300x157.png 300w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-768x402.png 768w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-1024x536.png 1024w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-696x365.png 696w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-1068x559.png 1068w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-802x420.png 802w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-1920x1006.png 1920w" sizes="(max-width: 600px) 100vw, 600px"></a><figcaption id="caption-attachment-5345">Figure 1: Comparison of CPU and GPU single precision floating point performance through the years. Image taken from Nvidia’s CUDA C programming guide.</figcaption></figure>
<p><span>When designing our real-time analytics querying engine, integrating GPU processing was a natural fit. At Uber, the typical real-time analytical query processes a few days of data with millions to billions of records and then filters and aggregates them in a short amount of time. This computation task fits perfectly into the parallel processing model of general purpose GPUs because they:</span></p>
<ul>
<li><span>Process data in parallel very quickly. </span></li>
<li><span>Deliver greater computation throughput (GFLOPS/s), making them a good fit for heavy computation tasks (per unit data) that can be parallelized. </span></li>
<li><span>Offer greater compute-to-storage (ALU to GPU global memory) data access throughput (not latency) compared to central processing units (CPUs), making them ideal for processing I/O (memory)-bound parallel tasks that require a massive amount of data.</span></li>
</ul>
<p><span>Once we settled on using a GPU-based analytical database, we assessed a few existing analytics solutions that leveraged GPUs for our needs:</span></p>
<ul>
<li><a href="https://www.kinetica.com/" target="_blank" rel="noopener noreferrer"><b>Kinetica</b></a><span>, a GPU-based analytics engine, was initially marketed towards U.S. military and intelligence applications in 2009. While it demonstrates the great potential of GPU technology in analytics, we found many key features missing</span> <span>for our use case, including </span><span>schema alteration, partial insertion or updates, data compression, column-level memory/disk retention configuration, and join by geospatial relationships.</span></li>
<li><a href="https://www.omnisci.com/" target="_blank" rel="noopener noreferrer"><b>OmniSci</b></a><span>, an open source, SQL-based query engine, seemed like a promising option, but as we evaluated the product, we realized that it did not have critical</span><span> features for Uber’s use case, such as deduplication. While </span><span>OminiSci</span> <span>open sourced their project in 2017, after some analysis of their C++-based solution, we concluded that neither contributing back nor forking their codebase was viable.</span></li>
<li><span>GPU-based real-time analytics engines, including </span><a href="https://www.cse.ust.hk/gpuqp/" target="_blank" rel="noopener noreferrer"><span>GPUQP</span></a><span>, </span><a href="http://cogadb.dfki.de/" target="_blank" rel="noopener noreferrer"><span>CoGaDB</span></a><span>, </span><a href="http://www.vldb.org/pvldb/vol6/p817-yuan.pdf" target="_blank" rel="noopener noreferrer"><span>GPUDB</span></a><span>, </span><a href="http://www.vldb.org/pvldb/vol6/p709-heimel.pdf" target="_blank" rel="noopener noreferrer"><span>Ocelot</span></a><span>, </span><a href="http://www.vldb.org/pvldb/vol6/p1374-he.pdf" target="_blank" rel="noopener noreferrer"><span>OmniDB</span></a><span>, and </span><a href="https://github.com/bakks/virginian" target="_blank" rel="noopener noreferrer"><span>Virginian</span></a><span>, are frequently used by academic institutions. However, given their academic purpose, these solutions focus on developing algorithms and designing proof of concepts as opposed to handling real-world production scenarios. For this reason, we discounted them for our scope and scale.</span></li>
</ul>
<p><span>Overall, </span><span>these engines</span><span> demonstrate the great advantage and potential of data processing using GPU technology, and they inspired us to build our own GPU-based, real-time analytics solution tailored to Uber’s needs. With these concepts in mind, we built and open sourced AresDB.</span></p>
<h3>AresDB architecture overview</h3>
<p><span>At a high level, AresDB stores most of its data in host memory (RAM that is connected to CPUs), handling data ingestion using CPUs and data recovery via disks. At query time, AresDB transfers data from host memory to GPU memory for parallel processing on GPU. As shown in Figure 2, below, AresDB consists of a memory store, a meta datastore, and a disk store:</span></p>
<figure id="attachment_5346" aria-describedby="caption-attachment-5346"><a href="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20.png" alt="" width="600" height="340" srcset="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20.png 1999w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-300x170.png 300w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-768x435.png 768w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-1024x580.png 1024w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-696x394.png 696w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-1068x605.png 1068w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-741x420.png 741w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-1920x1088.png 1920w" sizes="(max-width: 600px) 100vw, 600px"></a><figcaption id="caption-attachment-5346">Figure 2: The AresDB single instance architecture features memory and disk stores, and meta stores.</figcaption></figure>
<h4>Tables</h4>
<p><span>Unlike most </span><span>relational database management systems (</span><span>RDBMSs), there is no database or schema scope in AresDB. All tables belong to the same scope in the same AresDB cluster/instance, enabling users to refer to them directly. Users store their data as fact tables and dimension tables.</span></p>
<h5>Fact table</h5>
<p><span>A fact table stores an infinite stream of time series events. Users use a fact table to store events/facts that are happening in real time, and each event is associated with an event time, with the table often queried by the event time. An example of the type of information stored by fact tables are trips, where each trip is an event and the trip request time is often designated as the event time. In case an event has multiple timestamps associated with it, only one timestamp is designated as the time of the event displayed in the fact table.</span></p>
<h5>Dimension table</h5>
<p><span>A dimension table stores current properties for entities (including cities, clients, and drivers). For example, users can store city information, such as city name, time zone, and country, in a dimension table. Compared to fact tables, which grow infinitely over time, dimension tables are always bounded by size (e.g., for Uber, the cities table is bounded by the actual number of cities in the world). Dimension tables do not need a special time column.</span></p>
<h4>Data types</h4>
<p><span>Table below details the current data types supported in AresDB:</span></p>
<table>
<tbody>
<tr>
<td><a href="https://github.com/uber/aresdb/wiki/Data-Types" target="_blank" rel="noopener noreferrer"><b>Data Types</b></a></td>
<td><b>Storage (in Bytes)</b></td>
<td><b>Details</b></td>
</tr>
<tr>
<td><span>Bool</span></td>
<td><span>1/8</span></td>
<td><span>Boolean type data, stored as single bit</span></td>
</tr>
<tr>
<td><span>Int8, Uint8</span></td>
<td><span>1</span></td>
<td rowspan="3"><span>Integer number types. User can choose based on cardinality of field and memory cost.</span></td>
</tr>
<tr>
<td><span>Int16, Uint16</span></td>
<td><span>2</span></td>
</tr>
<tr>
<td><span>Int32, Uint32</span></td>
<td><span>4</span></td>
</tr>
<tr>
<td><span>SmallEnum</span></td>
<td><span>1</span></td>
<td><span>Strings are auto translated into enums. SmallEnum can holds string type with cardinality up to 256</span></td>
</tr>
<tr>
<td><span>BigEnum</span></td>
<td><span>2</span></td>
<td><span>Similar to SmallEnum, but holds higher cardinality up to 65535</span></td>
</tr>
<tr>
<td><span>Float32</span></td>
<td><span>4</span></td>
<td><span>Floating point number. We support Float32 and intend to add Float64 support as needed</span></td>
</tr>
<tr>
<td><span>UUID</span></td>
<td><span>16</span></td>
<td><a href="https://en.wikipedia.org/wiki/Universally_unique_identifier" target="_blank" rel="noopener noreferrer"><span>Universally unique identifier</span></a></td>
</tr>
<tr>
<td><span>GeoPoint</span></td>
<td><span>4</span></td>
<td><span>Geographic points</span></td>
</tr>
<tr>
<td><span>GeoShape</span></td>
<td><span>Variable Length</span></td>
<td><span>Polygon or multi-polygons</span></td>
</tr>
</tbody>
</table>
<p><span>With AresDB, strings are …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ubere.ng/2HzMPVK">https://ubere.ng/2HzMPVK</a></em></p>]]>
            </description>
            <link>https://ubere.ng/2HzMPVK</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461844</guid>
            <pubDate>Sun, 13 Sep 2020 16:19:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uxcel: UX/UI for Developers and Designers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24461671">thread link</a>) | @lazar_nikolov
<br/>
September 13, 2020 | https://nikolovlazar.com/uxcel-ux-ui-for-developers-and-designers | <a href="https://web.archive.org/web/*/https://nikolovlazar.com/uxcel-ux-ui-for-developers-and-designers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1600010628912/wTYNJ5bF3.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><h2 id="meet-uxcel">Meet Uxcel</h2>
<p>A few weeks ago I stumbled upon <a target="_blank" href="https://uxcel.com/?ref=nikolovlazar.com">Uxcel</a>, an app that teaches you UX/UI. It looked really clean, so I decided to give it a go. The app has a <strong>Course</strong>, <strong>Lesson of the Week</strong>, and a <strong>UEye Training</strong> sections.</p>
<p>First I finished the UX/UI Design Foundation course. It has 6 levels which covers pretty much everything, like Color Theory, UI Design Principles, Typography, Iconography, Terminologies, Animations etc... The app's teaching method is fun. It shows you either 2 different images and you need to select the correct one, or 1 image with multiple answers. After you pick/answer it shows you the correct answer and a brief explanation.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1600011317011/sbjpDJUin.png?auto=format&amp;q=60" alt="Screenshots of the app"></p>
<p>When I finished all 6 levels it generated a nice <a target="_blank" href="https://certificates.uxcel.com/DP1AFJPVJJHL">certificate</a> for me, which felt good and I shared it on LinkedIn.</p>
<p>After finishing the course, I started playing around with the UEye Training. I can't tell you how <strong>addicting</strong> and fun this is! It works similarly to the course, you're presented with 2 pictures, one of them has a UI mistake, the other one is correct. You have 20 seconds to identify the correct one. When you pick the correct one it gives you points. You can <strong>really</strong> benefit from this if you regularly do the UEye Training. They also have a configurable Reminder, which is a cool feature.</p>
<p>Since finding out about it, I've never missed a day without doing some UEye Training. They've recently added some new designs and it was so fun noticing the little mistakes. The points system and leaderboard brings more motivation to keep practicing.</p>
<h2 id="pro-tip">Pro tip:</h2>
<p>Uxcel is a PWA, a Progressive Web App. This means that you can install it on your Home screen on your smartphone. Here's how to do that:</p>
<ul>
<li>On iOS: Open <a target="_blank" href="https://app.uxcel.com/learn?ref=nikolovlazar.com">app.uxcel.com/learn</a> in Safari, click on the Share button (the one in the middle), and scroll down. You should see a "Add to Home Screen" option.</li>
<li>On Android: Open <a target="_blank" href="https://app.uxcel.com/learn?ref=nikolovlazar.com">app.uxcel.com/learn</a> in Chrome and you should see a banner on the bottom saying "Add to home screen".</li>
</ul>
<p>Make sure to install it on your smartphone, so you can practice anytime and anywhere.</p>
<p>Also, They regularly update their UX/UI Design Foundations course, so even if you complete it, click on the "Review Course" to see if they've added something new.</p>
<h2 id="lets-practice-together">Let's practice together</h2>
<p>Whether you're a developer or designer, Uxcel is one of the tools that can help you become good at UX/UI Designing. Keep practicing and you'll start to see progress. So, <a target="_blank" href="https://uxcel.com/?invite=9DUE0MRLSJTU">join me</a> and let's practice together.</p>
<hr>
<p>&gt;
Show some love:</p>
</div></div></section></div>]]>
            </description>
            <link>https://nikolovlazar.com/uxcel-ux-ui-for-developers-and-designers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461671</guid>
            <pubDate>Sun, 13 Sep 2020 16:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What If ‘Capitalism’ Isn't the Problem? [audio]]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24461604">thread link</a>) | @ojarow
<br/>
September 13, 2020 | https://musingmind.org/podcasts/julie-nelson | <a href="https://web.archive.org/web/*/https://musingmind.org/podcasts/julie-nelson">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-052ee15c0c629a5866d7"><div><p>My guest today is Julie Nelson: economist, and zen teacher. She co-edited a book in 1993 that became known to many as an early manifesto for feminist economics, and has spent her career questioning assumptions - of both the human mind and the discipline of economics.</p><p>She is an economics professor (emeritus) at the University of Massachusetts, Boston, a senior research fellow at the Global Development and Environment Institute at Tufts, and a senior assistant teacher at the Greater Boston Zen Center. She is author of the book <em>Economics for Humans, </em>co-editor of <em>Beyond Economic Man: Feminist Theory and Economics</em>, and a number of others.</p><p>A polarizing question lingers as the theme for our conversation: <em>what if capitalism isn’t the problem? </em>Julie suggests that many of the ills - greed, environmental degradation, extreme inequality - so many on the left are quick to blame capitalism for have little to do with capitalism. Rather, she targets ‘economism’ - a particular set of economic theories and assumptions, plus a layer of incentives we’ve built atop them. Neither updating our theories to better match reality, nor redesigning the incentive structures that underlie economic outcomes require an exit from capitalism.</p><p>Viewing capitalism as a rigid and dogmatic system that inherently produces certain outcomes, Julie suggests, are “short-cuts to thinking” that keep us from seeing the agency we already have to change the system.</p><p>A few other topics we explore:</p><ul data-rte-list="default"><li><p>Imaginative rationality.</p></li><li><p>The ‘emptiness’, or ‘no-nature’ of markets.</p></li><li><p>Are consciousness and materialism compatible?</p></li><li><p>Can waged work be intrinsically motivated?</p></li><li><p>How can we change our capitalist system from with?</p></li></ul><p>Enjoy!</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599754497552_93915"><div><h3>Time Map</h3><p>0:40 ~ How do Julie’s zen practice and economics research relate to one another?</p><p>8:30 ~ What is “imaginative rationality”, and what role can it play in economic thought?</p><p>13:20 ~ The mistake that is made by both free-market fundamentalists and eco-socialists: markets do not have fixed, inherent outcomes. They are responsive and adaptive to their social, political, and legal contexts.</p><p>21 ~ Example of “profit maximizing firms”. Corporate greed is not necessarily capitalism’s fault, but a particular system of incentives and corporate governance laws that we’re created <em>within</em> our form of capitalism.</p><p>26 ~ Does consciousness lack any ‘inherent nature’ in the same way that markets do? Is consciousness ‘unconditional’, or is it fundamentally expressed and shaped through and by the conditions of our lives?</p><blockquote><p><em>28:50 ~ “Our brains did not develop to help us think logically about things, our brains developed to help us survive.” </em></p></blockquote><p>36:30 ~ Does it make sense to think of progress as a gradual decreasing of the amount of time citizens are impelled by necessity to sell and exchange on labor markets in order to access the resources they need to survive? Should we return to the forgotten American dream of the late 19th century, where economic progress would deliver more leisure time for all?</p><p>39:20- ~ Julie makes a case <em>for</em> waged work. She wisely rejects my binary that if we work for wages, we’re extrinsically motivated, and only if we are free from wages can we tap into intrinsic motivation.</p><p>43:10 ~ How do we raise wages for socially valuable work, where we want high quality care, that is drastically underpaid, like early childhood education? </p><p>49:30 ~ Adapting Erik Olin Wright’s theory of change - “taming and eroding” capitalism - what are the leverage points inside our current capitalist system that we can focus on to drive change from within?</p><p>57:30 ~ The ‘mushroom man’ theory of human nature at the heart of outdated economic models.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599754497552_28871"><div><p>You can support the podcast by sharing on social media, with a friend, or leaving a rating &amp; <a href="https://podcasts.apple.com/us/podcast/musing-mind-podcast/id1480082389" target="_blank">review on Apple Podcasts</a>!</p><p>Receive new episodes &amp; related musings by <a href="https://musingmind.substack.com/" target="_blank">joining the newsletter community</a>. If you’d like to get in touch with me, you can reach me <a href="https://twitter.com/OshanJarow" target="_blank">on Twitter</a>, or <a href="https://musingmind.org/contact" target="_blank">directly</a>. </p><p>If you’re <em>really</em> interested in helping the podcast exist, consider <a href="https://www.patreon.com/OshanJarow" target="_blank">becoming a Patron</a> with a small monthly donation of even $1! Your support means the world, and goes directly towards improving the podcast’s audio quality, equipment, research, and overall experience.</p><p>Thank you!</p></div></div></div>]]>
            </description>
            <link>https://musingmind.org/podcasts/julie-nelson</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461604</guid>
            <pubDate>Sun, 13 Sep 2020 15:52:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disrespectful Design – Users aren’t stupid or lazy]]>
            </title>
            <description>
<![CDATA[
Score 382 | Comments 213 (<a href="https://news.ycombinator.com/item?id=24461365">thread link</a>) | @Ozzie_osman
<br/>
September 13, 2020 | https://somehowmanage.com/2020/09/13/disrespectful-design-users-arent-stupid-or-lazy/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/09/13/disrespectful-design-users-arent-stupid-or-lazy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-68">

	

	
	<div>
		
<p>It’s a common narrative in tech to design products with the assumption that users are stupid and lazy. I think that is both disrespectful and wrong.</p>



<p>The idea is rooted in a lot of research around product usability, but it has been bastardized. Thing of it as a perversion of the <a href="https://en.wikipedia.org/wiki/Don%27t_Make_Me_Think">Don’t Make Me Think</a> thesis.</p>



<p><em>Don’t Make Me Think</em>, the seminal web usability book by Steve Krug, tells us that products should be as simple as possible for users to use. Products shouldn’t be self-explanatory (ie understandable given a set of instructions), they should be self-evident (ie so obvious that they can be used <em>without</em> having to read instructions). A good door has a push/pull sign to make it self-explanatory, but it still requires you to read and think. An even better door wouldn’t even need that label at all—you know what to do instinctively.</p>



<p>But somehow, we’ve perverted that idea. Users are lazy, even stupid, we say. They just want to flick their fingers down an infinite feed, letting their eyes wander from item to item.</p>



<p>But in <em>Don’t Make Me Think</em>, Krug never refers to users in a derogatory way. He tells us how good products should work, and why basic psychology supports that. People want to reduce cognitive friction as much as possible. People don’t like unneeded cognitive friction. People skim quickly and “muddle through” products. And, most of all, people won’t undertake effort unless they believe it’s worth the cost. These are all facts backed by usability research and psychology.</p>



<p>In other words, he tells us <em>what</em> good products should look like, and <em>how</em> people use them. But he doesn’t pass judgment on users. That’s up to us.</p>



<p>And so naturally, we apply our view of the world, our values. If you view your users with contempt, then the reason behind why people don’t like complicated products is because they are stupid and lazy. If, on the other hand, you <em>respect</em> your users, you might view things differently.</p>



<p>Firstly, our brains have been wired, through millions of years of evolution, to conserve effort and time. That’s actually not being lazy, it’s being smart and protective of one of our most valuable assets. Naturally, we don’t undertake an activity unless we believe it’s worth the cost (though there are ways to trick us, more on that later). And if it takes effort to even figure out how much effort an activity will require, we’ll avoid that activity altogether. That’s the functional, practical piece of our brain at work.</p>



<p>Secondly, we are a complex bundle of emotions. Even if we’re smart, we don’t like <em>feeling</em> stupid. And complex, difficult things makes us feel stupid. They strike at our very identity and self-worth. So we try to avoid them like we avoid that hard topic we were never good at in school. <em>That</em> part is the emotional piece of our brain at work.</p>



<p>So what explains the rise of products like Facebook, which have gotten a large part of humanity mindlessly scrolling through feeds of what can most easily be described as garbage content? Well, we humans aren’t perfect. If you’ve got billions of dollars, some of the brightest minds, and a lot of data at your disposal, you can get a lot of people to do what you want. If you treat users as stupid and lazy, you can turn them into stupid and lazy people in the context of your product… but that’s a subject for another post.</p>



<p>So here’s how I think about people and product design.</p>



<p>Firstly, products should definitely be as simple as possible. Because I <em>respect </em>users’ time, not because I look down on their intelligence.</p>



<p>Second, have a theory of how people behave. I’m a big fan of <a href="https://en.wikipedia.org/wiki/Self-determination_theory">Self-determination Theory</a>, which states that people value autonomy, relatedness, and competence. And I love building product that help people improve all those three dimensions.</p>



<p>Three, have a set of principles for your product. For instance, of the three axes of self-determination, I particularly care about autonomy (control). And I’ve found that good products, ones that respect their users, <em>give them more control</em>. Bad products <em>take away control</em>. Simplicity can fulfill both of those purposes. It can give people control by abstracting away things they don’t care about and helping them focus. Or it can take away control by only letting users do things the product’s designers want them to do. So that’s one of my principles: give people control. Help them do things <em>they </em>want to do, not things <em>you</em> want them to do.</p>



<p>Let’s respect our users. Technology can bring out the best or worst in us, both individually and collectively. Let’s focus on the best.</p>



<hr>



<p><strong>EDIT:</strong> The above article is what I wrote, in its half-formed state on a Sunday morning. It looks like it’s blowing up on HackerNews, so I wanted to just add a few points.</p>



<ul><li>I know I can come across as idealistic. I’ve even gotten that as feedback on a formal performance review (but also, I’ve gotten that I’m cynical, so *shrug*). I’m not saying people can’t be lazy, entitled, or stupid. We can. We have that <em>capacity</em>. But we have the <em>capacity</em> for so much more than that. And we should focus our tools, our technology, on our best capacities.</li><li>If Self-determination Theory resonates with you, I’d urge you to think about how it applies to building teams or even parenting. Your employees and colleagues, or your children and family members, have all the human capacities as well (though obviously, for children, they are still under development). Since I’m much more experienced at managing teams (dozen years) than being a parent (two years), I’ll just say that companies that view employees as lazy and incompetent are a scourge. If you can afford to avoid working at companies like that, try your best. And if you’re tasked with building companies or teams, you get to choose. You still need rules, hierarchies, and processes, but if you give people autonomy and relatedness/purpose, and trust their competence, I hope you’ll be pleasantly surprised. If you treat employees as stupid and lazy, they will be.</li><li>On simplicity vs. control/flexibility: I’m a big fan of the Alan Kay quote that “<a href="https://en.wikiquote.org/wiki/Alan_Kay">simple things should be simple, complex things should be possible</a>.” I think great products find a way of achieving both those objectives. You keep things simple, but don’t throw out the baby with the bath-water. Like the word processor. 99% of the time, you just want to type some text, so you get a cursor and WYSIWIG typing. But sometimes, you want to style, you want to indent, you want to program macros. We apply this principle often at <a href="https://www.monarchmoney.com/">Monarch Money</a> (personal finance platform that I’m working on) and so far have found it to be quite successful.</li></ul>



<hr>



<p><em>About me:</em> <em>I’m a <a href="https://www.linkedin.com/in/oaosman/">software builder / entrepreneur</a>. I write about software, software engineering management, and product-building</em>. <em>I currently manage the engineering team at <a href="https://www.monarchmoney.com/">Monarch Money</a>, a personal finance platform. You can follow me here</em> <em>on this blog</em>, <a href="https://medium.com/@Oao84"><em>or on Medium</em></a>. <em>I also helped write a <a href="https://www.amazon.com/Holloway-Guide-Technical-Recruiting-Hiring/dp/195212008X">book on hiring/recruiting in the software world</a> with a group of really awesome people.</em></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://somehowmanage.com/2020/09/13/disrespectful-design-users-arent-stupid-or-lazy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461365</guid>
            <pubDate>Sun, 13 Sep 2020 15:15:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Governments should adopt and invest in FOSS]]>
            </title>
            <description>
<![CDATA[
Score 328 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24461364">thread link</a>) | @nivenkos
<br/>
September 13, 2020 | http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en | <a href="https://web.archive.org/web/*/http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post covers why I believe local and national governments should
adopt and invest in <a href="https://www.gnu.org/philosophy/free-sw.en.html">Free and Open Source Software</a> (FOSS).</p>

<p>This has been in the news recently due to the city of Munich renewing 
it’s <a href="https://www.zdnet.com/article/linux-not-windows-why-munich-is-shifting-back-from-microsoft-to-open-source-again/">LiMux Linux distribution</a>
thanks to an agreement between the local SDP and Green politicians, and
the efforts of the <a href="https://publiccode.eu/">Public Money, Public Code</a> campaign.</p>

<!--more-->

<p>Opinions expressed are solely my own and do not express the views or opinions of my employer.</p>

<h2 id="limux">LiMux</h2>

<p><a href="https://en.wikipedia.org/wiki/LiMux">LiMux</a> is a project by the German city of Munich to migrate its desktop
infrastructure to FOSS solutions, specifically to the LiMux Linux
distribution (based on Ubuntu) and LibreOffice (initially to OpenOffice). The project was started in 2004, and
migration began in 2006.</p>

<p>By the end of 2013, 15,000 desktops had been migrated successfully.
However, in September 2016 <a href="https://mspoweruser.com/microsoft-germany-moves-into-a-new-headquarters/">Microsoft announced the opening of a new headquarters in Munich</a>, and then
in 2017 the <a href="https://www.techrepublic.com/article/end-of-an-open-source-era-linux-pioneer-munich-confirms-switch-to-windows-10/">city council decided to switch back to Microsoft Windows and Office</a>.
The timing of this decision led to many accusations of effective
bribery, using the potential office opening to pressure the council in to using
Microsoft products (note that there is no evidence of a kick-back scheme
<a href="https://www.zdnet.com/article/microsoft-to-pay-25m-to-doj-and-sec-in-hungary-bribery-case/">like practiced by Microsoft Hungary</a>).</p>

<p>Fortunately <a href="https://fsfe.org/news/2020/news-20200506-01.en.html">this decision has now been reversed</a>, and LiMux 
development and roll-out will continue.</p>

<h2 id="other-cities">Other cities</h2>

<p>Munich is not the only city choosing Free Software solutions, many
others are beginning to see the potential benefits too. In Catalonia,
Barcelona’s <a href="https://ajuntament.barcelona.cat/digital/es/transformacion-digital/tecnologia-para-un-gobierno-mejor/software-libre">Digital Transformation programme supports Free Software</a>.
From first-hand experience this means that the government transport /
road organisation use LibreOffice for all documents - so local driving
schools, etc. do not need a copy of Microsoft Office to handle the
necessary digital paperwork.</p>

<p>In Valencia, <a href="https://www.muylinux.com/2013/08/22/generalitat-valenciana-libreoffice/">the local government migrated its administration and
schools to LibreOffice</a>
saving 1.5 million euros per year, and saving students and other
end-users from having to purchase their own copies of Microsoft Office.</p>

<p>However, it is not always straightforward. <a href="https://lwn.net/Articles/737818/">Munich faced a lot of push-back in some areas</a>, and the <a href="https://cronicaglobal.elespanol.com/politica/colau-gasta-4-5-millones-en-microsoft-mientras-promete-software-libre_32165_102.html">city of Barcelona still pays almost 5 million
euros</a>
in license costs to Microsoft.</p>

<p>The main issue here is not so much the direct cost to the city itself
(which is substantial, but not critical compared to other costs -
especially since any migration will incur a significant short-term
cost), but more that the cost must be paid over and over again by all
users separately. Barcelona continues to pay millions to Microsoft every
year, but so will other cities in Spain and across Europe, and then so will all
users of those services that may have to use a copy of Microsoft Office for
compatibility reasons (i.e. students and small businesses).</p>

<p>The same cost is paid over and over again to a foreign company that will
not hire local developers or invest in the local economy, and <a href="https://en.wikipedia.org/wiki/Criticism_of_Microsoft#Vendor_lock-in">uses vendor lock-in</a>
to eventually control all of the critical infrastructure.</p>

<h2 id="benefits-of-foss">Benefits of FOSS</h2>

<p>The most commonly cited benefit of Free Software is certainly the cost
savings vs. proprietary licensing. Whilst this can be a benefit
in some circumstances, I think it overlooks many greater far-reaching
benefits, and may not actually manifest itself in the short-term due to
the additional costs of the actual migration (i.e. costs of deployment
and training).</p>

<h3 id="shared-investment">Shared investment</h3>

<p>The main benefit of using FOSS solutions is that any investment in the
development and improvement of the software also benefits all other
users of the software.</p>

<p>That is, whilst the city of Munich might need <a href="https://github.com/WollMux/WollMux">some improvements in
handling templates</a>, other cities
might need other improvements - however they can all benefit from
each others’ investment, with no need to pay again just to keep a license.</p>

<p>This helps to build up a commonwealth of high-quality, well-maintained
software which anyone can use. There is no central, unique
owner of the projects (any project could be forked if necessary), so
there is no company that can demand payments just to allow you to keep using the
existing software.</p>

<p>Any investment in development made is truly an investment, leading directly
to project improvements, rather than just money sent to a foreign
company whilst the customers have no ownership of the actual product,
allowing the company to charge even more in the future just for the
right to keep using it (usually this is done by giving discounts for the
early migration which then result in higher prices later once the
customer is locked in).</p>

<p>Note that this initial investment might be higher than the current costs
of existing proprietary software licensing, when considering the
migration and training costs and possible development costs. However,
unlike those licensing costs it is a one-time cost, and the customer
retains some ownership over the resulting product (i.e. there is not a
license that can be revoked).</p>

<h3 id="freedom-for-development">Freedom for development</h3>

<p>There is also more freedom in the development process. The fact that the
products aren’t owned by a company means that contributions can be made
by anyone, anywhere.</p>

<p>Users of the software (such as the cities mentioned above) could fund
<a href="https://github.com/hng/tech-coops">local co-operatives of developers</a> to add desired features and maintain
the projects, instead of being forced to fund a foreign corporation with
no local investment.</p>

<p>In the long-term this might also help to break up some of the monopolistic
Big Tech companies, and result in a freer society and business
environment for everyone.</p>

<h3 id="national-security">National security</h3>

<p>In Europe especially, the current dependence on proprietary software
often means a dependence on foreign corporations which operate in
co-operation with their country’s intelligence service. As revealed by
Edward Snowden, <a href="https://www.theguardian.com/world/2013/jul/11/microsoft-nsa-collaboration-user-data">Microsoft provided backdoor access to encrypted messages</a> to
the NSA, CIA and FBI as part of the <a href="https://en.wikipedia.org/wiki/PRISM_(surveillance_program)">PRISM programme</a>.</p>

<p>It is indefensible that such a company can run the critical infrastructure
of the vast majority of local and central government administrations, as
well as personal computers. Especially when the <a href="https://www.theguardian.com/us-news/2015/jul/08/nsa-tapped-german-chancellery-decades-wikileaks-claims-merkel">NSA has been proven to
intercept communications of supposedly allied nations</a>.</p>

<p>With FOSS software there is no central company to be pressured by
intelligence services or build in backdoors. All of the code can be
scrutinised by developers and users. <a href="https://en.wikipedia.org/wiki/Linus%27s_law">Linus’s Law</a> states:</p>

<blockquote>
  <p>Given enough eyeballs, all bugs are shallow.</p>
</blockquote>

<p>The same concept applies to introducing backdoors to access private data. It
might be possible to pressure or bribe one company to do so, but it
isn’t possible to do the same to tens of thousands of independent users and
developers.</p>

<h2 id="bigger-picture">Bigger picture</h2>

<p>The effects of co-ordinated FOSS adoption are much more far-reaching and
positive than solely saving the costs of current software licenses.</p>

<p>The adoption of FOSS and investment by many governments (at all levels)
would help to create a commonwealth of quality Free Software for all
citizens and government bodies to benefit from.</p>

<p>It would also allow development of these projects to be done from
anywhere, allowing users to fund local developers or co-operatives. This
would help to break up the massive, monopolistic Big Tech companies, and
could also be used as a way of bringing investment and jobs to parts of
the country/region that require it.</p>

<p>This would also be highly beneficial to developers, as they would have
more control over their own work (as they are not tied to the few
employers that own these popular products), and would also likely be
able to negotiate a larger portion of the compensation directly since
there would not be the overhead of salespeople and lawyers, etc. present in
current large software companies.</p>

<p>All Free Software users would benefit from the greater usage and
investment - GNU/Linux users could expect better hardware support for
example, as it becomes more commonplace.</p>

<h2 id="how-to-get-there">How to get there</h2>

<p>Whilst the benefits of adopting FOSS are clear, the cases in Munich and
Hungary show that it will not be an easy path to greater adoption. We
cannot just rely on central government eventually carry out the adoption
as the few representatives are easily pressured by the beneficiaries of
the status quo, and are serving a much larger political platform.</p>

<p>Ultimately, I think the solution lies in applying “Linus’s Law” to
politics itself. It is no coincidence that the successes in FOSS
adoption so far have been concentrated in local government - in specific
city councils and regional administrations, because it is easier for
engaged groups of citizens to have a direct effect in local government.</p>

<p>At a national level, it might be possible for a large software company
to pressure a few political leaders and policy makers, however, it is
much harder to do the same to a whole board of a dozen or more local
councillors (especially across the multitude of different counties and
regional administrations). There is “safety in numbers” as it becomes
unfeasible to pressure and manipulate large groups of
politically-engaged citizens.</p>

<p>It it is the responsibility of every citizen in a democratic society not
only to inform themselves and vote in national elections, but also to really partake in the
political system: by joining a political party, taking part in local and
regional elections, and ensuring that the democratic standards are
upheld both inside the party and in political institutions.</p>

<p>This should have support from across the political spectrum, as
guaranteeing the security and privacy of citizens’ data whilst also
cutting out the middlemen of massive foreign corporations, shouldn’t be
a controversial policy.</p>

<p>Efforts in local politics have already proven successful, such as the
LiMux project and others mentioned previously. So if you agree with the
points raised here I hope you will join whichever local political party
you agree most with, and help to bring about FOSS adoption by your
government.</p>

<h2 id="summary">Summary</h2>

<p>Greater FOSS adoption by our governments benefits the administrations
themselves by being free …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en">http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en</a></em></p>]]>
            </description>
            <link>http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461364</guid>
            <pubDate>Sun, 13 Sep 2020 15:15:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Babel AST Explorer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24461176">thread link</a>) | @primroot
<br/>
September 13, 2020 | https://lihautan.com/babel-ast-explorer/ | <a href="https://web.archive.org/web/*/https://lihautan.com/babel-ast-explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lihautan.com/babel-ast-explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461176</guid>
            <pubDate>Sun, 13 Sep 2020 14:44:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to tell browsers that your site supports color-schemes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24461084">thread link</a>) | @stefanjudis
<br/>
September 13, 2020 | https://www.stefanjudis.com/today-i-learned/how-to-tell-browsers-that-your-site-supports-color-schemes/ | <a href="https://web.archive.org/web/*/https://www.stefanjudis.com/today-i-learned/how-to-tell-browsers-that-your-site-supports-color-schemes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p> <span>This post is part of my <a href="https://www.stefanjudis.com/today-i-learned/">Today I learned</a> series in which I share all my learnings regarding web development.</span></p><div><p>User preferences and settings play an essential role in how websites look in 2020. To name two examples: well-made websites look great on different devices and handle various font-size settings with ease.</p><p>Over the past few years, a new user preference made it into the group of things "that change how a website looks" – yes, I'm talking about color themes. "How to implement dark mode on a website?" was one of the most important topics in 2019.</p><p><em>(yes... this site will have a dark mode eventually, too)</em></p><p>But how can you enable dark mode then? With today's web technology, your site can react to your visitors' color preferences (coming from the operating system) using <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">the <code>prefers-color-scheme</code> media query</a>. This media query allows you to write CSS depending on the preferred color scheme.</p><pre><code><span>--color-one</span><span>:</span> #ff0000<span>;</span>
<span>--color-two</span><span>:</span> #00ff00<span>;</span>

<span><span>@media</span> <span>(</span><span>prefers-color-scheme</span><span>:</span> dark<span>)</span></span> <span>{</span>
  
  <span>--color-one</span><span>:</span> #00ffff<span>;</span>
  <span>--color-two</span><span>:</span> #ff00ff<span>;</span>
<span>}</span>
</code></pre><p>Technically, this approach is straight forward, but implementing a high-quality theme handling is not trivial. It includes way more than just switching some colors. To learn more, I recommend reading <a href="https://twitter.com/tomayac">Thomas Steiner's</a> excellent guide on this topic: <a href="https://web.dev/prefers-color-scheme/">"prefers-color-scheme: Hello darkness, my old friend"</a>.</p><h2 id="dont-forget-to-indicate-your-sites-supported-color-schemes"><a href="#dont-forget-to-indicate-your-sites-supported-color-schemes">#</a> Don't forget to indicate your site's supported color schemes</h2><p>Having the ability to style websites depending on user color settings is excellent, but unfortunately, it's not covering the whole picture. So what's missing?</p><p>Even after writing hundreds of custom CSS lines, there are usually elements still relying on browser default styling. It could be a text input field, a checkbox, a radio button, or even the good old scroll bar using the CSS rules in the browser's user agent stylesheet. <strong>The browser doesn't know about your color scheme and comes with default styles based on a light mode.</strong> These styles define dark text and highlights on a bright background.</p><p>To complete your color scheme and make all your elements dark mode compatible, you have to define and overwrite all these CSS rules from the user agent stylesheet. This process is not ideal!</p><p>The <a href="https://drafts.csswg.org/css-color-adjust/#propdef-color-scheme"><code>color-scheme</code> property</a> helps here. It allows you to give browsers the information on your website's supported color schemes.</p><p><code>color-scheme</code> accepts two values:</p><ul><li><code>normal</code> – your site/an element does not support color schemes</li><li><code>[ light | dark | &lt;custom-ident&gt; ]+</code> – your site or a specific element can be rendered with the defined color schemes (<code>custom-ident</code> is currently unsupported and is only defined for possible future use cases)</li></ul><p>You can set these values as an HTML meta element or as a CSS declaration.</p><pre><code>
<span><span><span>&lt;</span>meta</span> <span>name</span><span><span>=</span><span>"</span>color-scheme<span>"</span></span> <span>content</span><span><span>=</span><span>"</span>dark light<span>"</span></span><span>&gt;</span></span>
</code></pre><pre><code><span>:root</span> <span>{</span>
  
  <span>color-scheme</span><span>:</span> dark light<span>;</span>
<span>}</span>
</code></pre><p>With this information, browsers can improve their default styling to match defined color schemes. With adjusted user agent styles, you don't have to overwrite every color to make an element dark mode compatible because the browser took care of it already.</p><p><a href="https://drafts.csswg.org/css-color-adjust/#preferred">The spec defines the following behavior</a> when a <code>color-scheme</code> property is defined:</p><blockquote><p>If the author has indicated that the page can support this color scheme, the user agent must match the following to the user’s preferred color scheme:</p><ul><li>the color of the canvas surface</li><li>the default colors of scrollbars and other interaction UI</li><li>the default colors of form controls and other "specially-rendered" elements</li><li>the default colors of other browser-provided UI, such as "spellcheck" underlines</li></ul></blockquote><p>For the example of dark mode, this paragraph means: <strong>if a site claims to support a dark color scheme, the browser must provide dark mode compatible colors, form controls, scroll bars and other UI elements.</strong></p><p>This browser behavior makes it easier to build color-schemed UIs because default UI elements adjust their color automatically. You can avoid overwriting every color! 🎉</p><h2 id="browser-support-of-color-scheme"><a href="#browser-support-of-color-scheme">#</a> Browser support of <code>color-scheme</code></h2><p>If you <a href="https://caniuse.com/mdn-html_elements_meta_name_color-scheme">go to caniuse.com to check the browser support of <code>color-scheme</code></a>, you'll be surprised. It looks reasonably good and it seems that only Firefox is missing to support <code>color-scheme</code>.</p><div><figure><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 2636 926"><path fill="#dfd8c1" d="M0 0h2636v916H0z"></path><g transform="translate(5.1 5.1) scale(10.29688)" fill-opacity=".5"><ellipse fill="#28570c" cx="109" cy="66" rx="35" ry="17"></ellipse><path fill="#1c5f12" d="M145.5 72.6l-15 .8-2-38 15-.8z"></path><path fill="#2a1e06" d="M144 63h62v5h-62z"></path><ellipse fill="#fff4e6" rx="1" ry="1" transform="matrix(-33.1947 22.54252 -57.06763 -84.03422 244.1 55.8)"></ellipse><path fill="#47470a" d="M51 63h84v5H51z"></path><ellipse fill="#fff8e8" rx="1" ry="1" transform="matrix(28.7783 11.16237 -14.04152 36.2012 23.4 56.5)"></ellipse><path fill="#fff9ee" d="M113 0h15v62h-15z"></path><path fill="#932000" d="M2 13h21v6H2z"></path></g></svg> <a href="https://images.ctfassets.net/f20lfrunubsq/6d0UJcg8d5ONEZMmJgfL31/9730c548d76ab7c11a75470b1d36ad16/Screenshot_2020-09-13_at_13.05.36.png"><img width="1000" height="351" srcset="https://images.ctfassets.net/f20lfrunubsq/6d0UJcg8d5ONEZMmJgfL31/9730c548d76ab7c11a75470b1d36ad16/Screenshot_2020-09-13_at_13.05.36.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=300&amp;h=105 300w, https://images.ctfassets.net/f20lfrunubsq/6d0UJcg8d5ONEZMmJgfL31/9730c548d76ab7c11a75470b1d36ad16/Screenshot_2020-09-13_at_13.05.36.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=500&amp;h=175 500w, https://images.ctfassets.net/f20lfrunubsq/6d0UJcg8d5ONEZMmJgfL31/9730c548d76ab7c11a75470b1d36ad16/Screenshot_2020-09-13_at_13.05.36.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=700&amp;h=245 700w, https://images.ctfassets.net/f20lfrunubsq/6d0UJcg8d5ONEZMmJgfL31/9730c548d76ab7c11a75470b1d36ad16/Screenshot_2020-09-13_at_13.05.36.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=900&amp;h=316 900w, https://images.ctfassets.net/f20lfrunubsq/6d0UJcg8d5ONEZMmJgfL31/9730c548d76ab7c11a75470b1d36ad16/Screenshot_2020-09-13_at_13.05.36.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=1100&amp;h=386 1100w" sizes="(max-width: 50em) 98vw, 700px" src="https://images.ctfassets.net/f20lfrunubsq/6d0UJcg8d5ONEZMmJgfL31/9730c548d76ab7c11a75470b1d36ad16/Screenshot_2020-09-13_at_13.05.36.png" alt="caniuse.com support table showing that color-scheme is mainly supported only with Firefox missing" loading="lazy" onload="this.classList.add('kf-fade-in')"></a></figure></div><p>Unfortunately, this support table is not telling the whole truth. According to the specification "real support" for <code>color-scheme</code> consists of two things:</p><ol><li>the browser must technically support the <code>color-scheme</code> property</li><li>the browser must adjust colors and provide UI elements taking <code>color-scheme</code> into consideration</li></ol><p>While Chromium browsers technically support <code>color-scheme</code>, they fail on delivering UI elements that are <code>color-scheme: dark</code>-compatible.</p><p>Thomas Steiner put together <a href="https://color-scheme-demo.glitch.me/">a useful page</a> if you want to have a look. The page toggles the <code>color-scheme</code> property every few seconds going from <code>light</code> to <code>dark</code> and back. This approach allows us to have a look at which elements react to different color schemes.</p><div><figure><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1796 1409"><path fill="#858585" d="M0 0h1796v1403H0z"></path><g transform="translate(3.5 3.5) scale(7.01563)" fill-opacity=".5"><ellipse cx="130" cy="160" rx="255" ry="62"></ellipse><ellipse fill="#fff" cx="111" cy="48" rx="255" ry="52"></ellipse><ellipse fill="#fff" rx="1" ry="1" transform="matrix(-197.82802 -11.0603 2.81686 -50.3833 128 48.8)"></ellipse><ellipse rx="1" ry="1" transform="rotate(-164.9 94.8 71) scale(128.65061 57.80774)"></ellipse><path fill="#fff" d="M223 108h31v21h-31z"></path><ellipse rx="1" ry="1" transform="matrix(-13.04437 45.49111 -124.52932 -35.7082 168.8 157.6)"></ellipse><ellipse fill="#fff" cx="204" cy="27" rx="255" ry="73"></ellipse><path d="M0 100h216v29H0z"></path></g></svg> <a href="https://images.ctfassets.net/f20lfrunubsq/5k4hoL8mr6IhqvHppox7xh/e1f0421a910f195bff1e742571eb65ab/Screenshot_2020-09-13_at_13.25.33.png"><img width="1000" height="784" srcset="https://images.ctfassets.net/f20lfrunubsq/5k4hoL8mr6IhqvHppox7xh/e1f0421a910f195bff1e742571eb65ab/Screenshot_2020-09-13_at_13.25.33.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=300&amp;h=235 300w, https://images.ctfassets.net/f20lfrunubsq/5k4hoL8mr6IhqvHppox7xh/e1f0421a910f195bff1e742571eb65ab/Screenshot_2020-09-13_at_13.25.33.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=500&amp;h=392 500w, https://images.ctfassets.net/f20lfrunubsq/5k4hoL8mr6IhqvHppox7xh/e1f0421a910f195bff1e742571eb65ab/Screenshot_2020-09-13_at_13.25.33.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=700&amp;h=549 700w, https://images.ctfassets.net/f20lfrunubsq/5k4hoL8mr6IhqvHppox7xh/e1f0421a910f195bff1e742571eb65ab/Screenshot_2020-09-13_at_13.25.33.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=900&amp;h=706 900w, https://images.ctfassets.net/f20lfrunubsq/5k4hoL8mr6IhqvHppox7xh/e1f0421a910f195bff1e742571eb65ab/Screenshot_2020-09-13_at_13.25.33.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=1100&amp;h=862 1100w" sizes="(max-width: 50em) 98vw, 700px" src="https://images.ctfassets.net/f20lfrunubsq/5k4hoL8mr6IhqvHppox7xh/e1f0421a910f195bff1e742571eb65ab/Screenshot_2020-09-13_at_13.25.33.png" alt="Chrome UI elements not responding to color-scheme: dark" loading="lazy" onload="this.classList.add('kf-fade-in')"></a></figure></div><p>As you see above, Chrome and Edge 85 are changing the background and text color, but UI elements like inputs and buttons stay the same.</p><div><figure><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1803 1396"><path fill="#919191" d="M0 0h1803v1394H0z"></path><g transform="translate(3.5 3.5) scale(7.04297)" fill-opacity=".5"><ellipse cx="102" cy="154" rx="255" ry="55"></ellipse><ellipse fill="#fff" cx="127" cy="38" rx="255" ry="62"></ellipse><ellipse fill="#fff" cx="91" cy="41" rx="255" ry="59"></ellipse><ellipse rx="1" ry="1" transform="matrix(-173.1075 -21.25493 5.78204 -47.09095 133.8 151.2)"></ellipse><path fill="#fff" d="M227 29h25v97h-25z"></path><ellipse fill="#fff" rx="1" ry="1" transform="matrix(-4.20117 46.16306 -224.3933 -20.42139 134.8 49)"></ellipse><path d="M165 100h91v6h-91z"></path><ellipse fill="#fff" cx="65" cy="42" rx="255" ry="58"></ellipse></g></svg> <a href="https://images.ctfassets.net/f20lfrunubsq/4Iouaxc8SBottKsSKvoXsQ/2455d2dfbc99247c83e6597a017c6331/Screenshot_2020-09-13_at_14.09.58.png"><img width="1000" height="774" srcset="https://images.ctfassets.net/f20lfrunubsq/4Iouaxc8SBottKsSKvoXsQ/2455d2dfbc99247c83e6597a017c6331/Screenshot_2020-09-13_at_14.09.58.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=300&amp;h=232 300w, https://images.ctfassets.net/f20lfrunubsq/4Iouaxc8SBottKsSKvoXsQ/2455d2dfbc99247c83e6597a017c6331/Screenshot_2020-09-13_at_14.09.58.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=500&amp;h=387 500w, https://images.ctfassets.net/f20lfrunubsq/4Iouaxc8SBottKsSKvoXsQ/2455d2dfbc99247c83e6597a017c6331/Screenshot_2020-09-13_at_14.09.58.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=700&amp;h=541 700w, https://images.ctfassets.net/f20lfrunubsq/4Iouaxc8SBottKsSKvoXsQ/2455d2dfbc99247c83e6597a017c6331/Screenshot_2020-09-13_at_14.09.58.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=900&amp;h=696 900w, https://images.ctfassets.net/f20lfrunubsq/4Iouaxc8SBottKsSKvoXsQ/2455d2dfbc99247c83e6597a017c6331/Screenshot_2020-09-13_at_14.09.58.png?fm=jpg&amp;fit=scale&amp;q=75&amp;w=1100&amp;h=851 1100w" sizes="(max-width: 50em) 98vw, 700px" src="https://images.ctfassets.net/f20lfrunubsq/4Iouaxc8SBottKsSKvoXsQ/2455d2dfbc99247c83e6597a017c6331/Screenshot_2020-09-13_at_14.09.58.png" alt="UI elements in Safari that are adjusting to color-scheme: dark" loading="lazy" onload="this.classList.add('kf-fade-in')"></a></figure></div><p>On the other hand, if you look at Safari, you'll see that inputs and buttons change their appearance and seamlessly integrate into a dark color scheme. That's pretty nice!</p><h2 id="should-you-use-the-color-scheme-property-today"><a href="#should-you-use-the-color-scheme-property-today">#</a> Should you use the <code>color-scheme</code> property today?</h2><p>With Chromium browsers not adjusting their UI elements to a defined color scheme, I don't think that it's prime time for the <code>color-scheme</code> property yet. If you can't rely on elements to "just fit into your dark mode theme" you still have to write all this additional CSS to make UI elements fit in.</p><p>Nevertheless, I think that this web platform addition is precious, and maybe we reach complete cross-browser support quickly. 🤞 For my site, I'll add <code>&lt;meta name="color-scheme" content="normal"&gt;</code> to this site until I finally support dark mode. 🙈</p><h3 id="additional-resources"><a href="#additional-resources">#</a> Additional resources</h3><ul><li><a href="https://drafts.csswg.org/css-color-adjust/#propdef-color-scheme">Spec for the <code>color-scheme</code> property</a></li><li><a href="https://web.dev/color-scheme/">"Improved dark mode default styling with the color-scheme CSS property and the corresponding meta tag"</a></li><li><a href="https://blog.jim-nielsen.com/2020/color-scheme-property/">"Don’t Forget the color-scheme Property"</a></li></ul></div></div>]]>
            </description>
            <link>https://www.stefanjudis.com/today-i-learned/how-to-tell-browsers-that-your-site-supports-color-schemes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461084</guid>
            <pubDate>Sun, 13 Sep 2020 14:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: We made finding a REMOTE developer job easy]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24460965">thread link</a>) | @BorisBorisov91
<br/>
September 13, 2020 | https://join.remotemore.com/hackernews | <a href="https://web.archive.org/web/*/https://join.remotemore.com/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://join.remotemore.com/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460965</guid>
            <pubDate>Sun, 13 Sep 2020 14:11:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of SwiftUI]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24460658">thread link</a>) | @mpweiher
<br/>
September 13, 2020 | https://steipete.com/posts/state-of-swiftui/ | <a href="https://web.archive.org/web/*/https://steipete.com/posts/state-of-swiftui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="https://d33wubrfki0l68.cloudfront.net/2cc5b5dcbba58e6a8ab6be0fc5ba3f4135fc9844/bc970/assets/img/2020/fruta-swiftui/fruta-crash.png"></p><p>Apple released SwiftUI last year, and it’s been an exciting and wild ride. With iOS 14, a lot of the rough edges have been smoothed out — is SwiftUI finally ready for production?</p><h2 id="fruta-sample-app">Fruta Sample App</h2><p>Let’s look at <a href="https://developer.apple.com/documentation/app_clips/fruta_building_a_feature-rich_app_with_swiftui">Apple’s Fruta example</a>, a cross-platform feature-rich app that’s built completely in SwiftUI. It’s great that Apple is finally releasing a more complex application for this year’s cycle.</p><p>I took a look when Big Sur beta 1 came out, and it was pretty unpolished:</p><div><blockquote><div lang="en" dir="ltr"><p>Been clicking around for a minute with Apple's new Fruta SwiftUI sample. </p><p>Things jump around wildly, fav' doesn't work, and it crashes once you open a second window. I understand it's b1, but looking at how SwiftUI went last year I doubt this will all be fixed. <a href="https://t.co/zGRRYswRde">pic.twitter.com/zGRRYswRde</a></p></div>— Peter Steinberger (@steipete) <a href="https://twitter.com/steipete/status/1277623561604214784?ref_src=twsrc%5Etfw">June 29, 2020</a></blockquote></div><p>Since then, there have been many betas, and we’re nearing the end of the cycle, with the GM expected in October. So it’s time to look at Fruta again. And indeed, the SwiftUI team did a great job fixing the various issues: The toolbar is pretty reliable, the sidebar no longer jumps out, multiple windows works… however, <a href="https://twitter.com/steipete/status/1305054121523916806?s=21">views are still sometimes misaligned</a>, and it’s still fairly easy to make it crash on both <a href="https://twitter.com/steipete/status/1305051342596177921?s=21">macOS (FB8682269)</a> and <a href="https://twitter.com/steipete/status/1305052083989684224?s=21">iOS 14b8 (FB8682290)</a>.</p><h2 id="swiftui-attributegraph-crashes">SwiftUI AttributeGraph Crashes</h2><p>Most SwiftUI crashes are a result of either a diffing issue in AttributeGraph, or a bug with one of the bindings to the platform controls (AppKit or UIKit). Whenever you see <code>AG::Graph</code> in the stack trace, that’s SwiftUI’s AttributeGraph (written in C++), which takes over representing the view hierarchy and diffing. Crashes there are usually in this form:</p><div><p><code><table><tbody><tr><td><pre>1
</pre></td><td><pre> Fruta[3607:1466511] [error] precondition failure: invalid size for indirect attribute: 25 vs 24
</pre></td></tr></tbody></table></code></p></div><p>Googling for this error reveals that there are <a href="https://github.com/fermoya/SwiftUIPager/issues/60">a</a> <a href="https://developer.apple.com/forums/thread/129171">lot</a> <a href="https://stackoverflow.com/questions/58304009/how-to-debug-precondition-failure-in-xcode">of</a> <a href="https://www.reddit.com/r/SwiftUI/comments/fosrbf/precondition_failure_invalid_input_index/">similar</a> <a href="https://twitter.com/steipete/status/1258762457805455361">problems</a>. People sometimes do find workarounds via wrapping views into other views or changing the hierarchy. But mostly, we’re powerless, and this is something Apple needs to fix in its framework. Since SwiftUI ships as part of the OS, end users need to update their devices to get these fixes.</p><h2 id="platform-binding-crashes">Platform-Binding Crashes</h2><p>SwiftUI uses many components from AppKit and UIKit, which is a much better strategy than reinventing the wheel. These components are stateful and are synced with custom manager classes that perform the state diffing. These wrappers can cause issues, and as they’re written in Swift, there aren’t many possibilities to fix issues from the outside (unlike with swizzling in the earlier days).</p><p>Example: Removing a favorited item while it’s selected crashes in the AppKit binding that syncs the SwiftUI state with <code>NSTableView</code> (FB8684522).</p><blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">Removing a favorite crashes the app immediately. <a href="https://t.co/i5wiMJr4XX">pic.twitter.com/i5wiMJr4XX</a></p>— Peter Steinberger (@steipete) <a href="https://twitter.com/steipete/status/1305075451711369216?ref_src=twsrc%5Etfw">September 13, 2020</a></blockquote><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td><pre>2020-09-13 10:31:25.483965+0200 Fruta[79371:2051792] [General] Row 0 out of row range [0--1] for rowViewAtRow:createIfNeeded:
2020-09-13 10:31:25.498144+0200 Fruta[79371:2051792] [General] (
	0   CoreFoundation                      0x00007fff20cdb0df __exceptionPreprocess + 242
	1   libobjc.A.dylib                     0x00007fff20b3d469 objc_exception_throw + 48
	2   AppKit                              0x00007fff237a7905 -[NSTableRowData rowViewAtRow:createIfNeeded:] + 675
	3   AppKit                              0x00007fff23813008 -[NSTableView viewAtColumn:row:makeIfNecessary:] + 29
	4   SwiftUI                             0x00007fff49565fc7 $s7SwiftUI19ListCoreCoordinatorC17selectionBehavior5atRow2inAA012PlatformItemC0V0L0V09SelectionG0VSgSi_So11NSTableViewCtF + 39
	5   SwiftUI                             0x00007fff49566b36 $s7SwiftUI19ListCoreCoordinatorC18selectionDidChange2inySo11NSTableViewC_tF + 2662
	6   SwiftUI                             0x00007fff49187850 $s7SwiftUI26NSTableViewListCoordinatorC05tableD19SelectionIsChangingyy10Foundation12NotificationVFTm + 112
	7   SwiftUI                             0x00007fff49187912 $s7SwiftUI26NSTableViewListCoordinatorC05tableD19SelectionIsChangingyy10Foundation12NotificationVFToTm + 114
	8   CoreFoundation                      0x00007fff20c56a6c __CFNOTIFICATIONCENTER_IS_CALLING_OUT_TO_AN_OBSERVER__ + 12
	9   CoreFoundation                      0x00007fff20cf23bb ___CFXRegistrationPost_block_invoke + 49
	10  CoreFoundation                      0x00007fff20cf232f _CFXRegistrationPost + 454
	11  CoreFoundation                      0x00007fff20c275ce _CFXNotificationPost + 723
	12  Foundation                          0x00007fff218ba5e2 -[NSNotificationCenter postNotificationName:object:userInfo:] + 59
	13  AppKit                              0x00007fff237ae588 -[NSTableView _sendSelectionChangedNotificationForRows:columns:] + 219
	14  AppKit                              0x00007fff2373b739 -[NSTableRowData _updateVisibleViewsBasedOnUpdateItems] + 4503
	15  AppKit                              0x00007fff2373a453 -[NSTableRowData _updateVisibleViewsBasedOnUpdateItemsAnimated] + 224
	16  AppKit                              0x00007fff2371a2dc -[NSTableRowData _doWorkAfterEndUpdates] + 95
	17  AppKit                              0x00007fff2371a19d -[NSTableView _endUpdateWithTile:] + 119
	18  SwiftUI                             0x00007fff49186759 $s7SwiftUI26NSTableViewListCoordinatorC011updateTableD0_4from2toySo0cD0C_xxtF + 1145
	19  SwiftUI                             0x00007fff4956c010 $s7SwiftUI19ListCoreCoordinatorC29updateTableViewAndVisibleRows_4from2toySo07NSTableH0C_xxtFyyXEfU_ + 304
	20  SwiftUI                             0x00007fff4956ccf5 $s7SwiftUI19ListCoreCoordinatorC24withSelectionUpdateGuardyyyyXEF + 53
	21  SwiftUI                             0x00007fff4956b2ff $s7SwiftUI19ListCoreCoordinatorC29updateTableViewAndVisibleRows_4from2toySo07NSTableH0C_xxtF + 79
</pre></td></tr></tbody></table></code></p></div><p>It’s likely there more bugs waiting to be discovered, but I only spent a few hours with Fruta and on writing up this article.</p><h2 id="performance">Performance</h2><p>On my 2,4 GHz 8-Core Intel Core i9 MacBook Pro, it takes longer than a second to update the main view when changing the selection. This feels sluggish, not to mention it’s significantly longer than even most websites — that load data via the network — need. Fruta has everything local. What’s so slow here? Let’s look at Instruments!</p><p><img src="https://d33wubrfki0l68.cloudfront.net/46551951d369616ff89d71678a98813dfcd2d94b/97d03/assets/img/2020/fruta-swiftui/instruments.png" alt=""></p><ul><li>Of the 10 seconds captured, 30 percent of them are used for the various retain/release and malloc calls in Swift and Objective-C.</li><li><code>NSAttributedString</code> shows up often in stack traces, which hints that text layout seems especially expensive.</li><li>The AttributeGraph SwiftUI layout engine seems to create a lot of throwaway objects. These might mostly be Swift structs, but they’re still expensive.</li><li>JPG decoding happens on the main thread, but it’s only responsible for less than 1 percent of the time spent here.</li><li>When checking Hide System Libraries, there’s basically no work done in Fruta’s business logic.</li><li>Sorting for Top Functions, we see that AppKit’s auto layout logic, combined with SwiftUI’s graph, is taking up a lot of time.</li><li>There seems to be a lot of unnecessary invalidation. For example, <code>AppKitToolbarCoordinator</code> adds a toolbar item, which triggers <code>NSHostingView.preferencesDidChange()</code>, causing everything to lay itself out once again, even though the toolbar size doesn’t change.</li></ul><p>The good news is there seem to be a lot of potential future optimizations possible to make this fast. Alternatively, there’s always the possibility of <a href="https://twitter.com/noahsark769/status/1304938866999046144?s=21">dropping out of SwiftUI for performance critical parts</a>.</p><p>This isn’t unique to Fruta. I’ve been taking a look at <a href="https://twitter.com/Dimillian">@Dimillian’s</a> RedditOS app, which is built with SwiftUI on macOS. He <a href="https://twitter.com/Dimillian/status/1301802048824979456">stopped development</a> because it’s so slow that it’s not shippable. I did some debugging with an earlier version of Big Sur where the app still somewhat worked:</p><div><blockquote><p lang="en" dir="ltr">The AppKit port of SwiftUI is... not very efficient. Been testing <a href="https://t.co/67UCuKmPts">https://t.co/67UCuKmPts</a> for a minute, 10% of the time it freezes on the main thread are just spent to... update toolbar buttons? It's a bit hard to measure because it crashes so quickly. <a href="https://t.co/hW4nNe0ydV">pic.twitter.com/hW4nNe0ydV</a></p>— Peter Steinberger (@steipete) <a href="https://twitter.com/steipete/status/1282655123244752897?ref_src=twsrc%5Etfw">July 13, 2020</a></blockquote></div><p>The general pattern here points to AppKit: The interaction between SwiftUI views and AppKit views <a href="https://twitter.com/fcbunn/status/1259078251340800000">seems to</a> be <a href="https://twitter.com/stuartcarnie/status/1301895206875181056">poor</a>. It’s important to understand that SwiftUI itself is fast — for many use cases it’s even faster than using <code>CALayer</code>, <a href="https://twitter.com/cocoawithlove/status/1143859576661393408">as @cocoawithlove proved</a> — and the UIKit port is by far faster and better than the AppKit port.</p><h2 id="conclusion">Conclusion</h2><p>If your target platform is iOS 14, you’re now good to go with hobby projects or individual screens in SwiftUI. I’m currently working on making our <a href="http://pspdfkit.com/">PDF SDK for iOS</a> easier to use with SwiftUI, and we’ll replace the settings/about screen of <a href="https://pdfviewer.io/">PDF Viewer</a> with a SwiftUI version.</p><p>I personally wouldn’t yet go all-in on SwiftUI for production apps, although the crash rate is likely manageable and Apple is actively improving things with every release. Remember that SwiftUI ships with the OS, not with your app, so any bug fixes will only help if your users update the OS.</p><p>Other ports are not so great. AppKit seems particularly troublesome, but I’ve also heard of big issues with tvOS. If you need to deploy your app to the Mac, use Catalyst, which is a much more stable binding and feels really good with Big Sur’s native mode, where content is no longer scaled.</p><p>If you’re curious about SwiftUI, <strong>please don’t let this dampen your enthusiasm</strong>. It’s extremely fun to write, it’s clearly the future at Apple, and all these issues will surely be resolved within a few years.</p></div></div>]]>
            </description>
            <link>https://steipete.com/posts/state-of-swiftui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460658</guid>
            <pubDate>Sun, 13 Sep 2020 13:19:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[List of Data Science Podcasts (and the code to find them)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24460568">thread link</a>) | @gms64
<br/>
September 13, 2020 | https://gregondata.com/blog/best-data-science-podcasts/ | <a href="https://web.archive.org/web/*/https://gregondata.com/blog/best-data-science-podcasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="the-most-popular-data-science-podcasts">the most popular data science podcasts</h2>
<p><em>For the people who read the TL;DR first. You people disgust me, you savages.</em></p>










































































































































































































































































































































































<table><thead><tr><th>title</th><th>author</th><th>avg_rtg</th><th>rtg_ct</th><th>episodes</th></tr></thead><tbody><tr><td><a href="https://podcasts.apple.com/us/podcast/lex-fridman-podcast/id1434243584" rel="nofollow noopener noreferrer" target="_blank">Lex Fridman Podcast</a></td><td>Lex Fridman</td><td>4.9</td><td>2400</td><td>126</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/machine-learning-guide/id1204521130" rel="nofollow noopener noreferrer" target="_blank">Machine Learning Guide</a></td><td>OCDevel</td><td>4.9</td><td>626</td><td>30</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-skeptic/id890348705" rel="nofollow noopener noreferrer" target="_blank">Data Skeptic</a></td><td>Kyle Polich</td><td>4.4</td><td>431</td><td>300</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-stories/id502854960" rel="nofollow noopener noreferrer" target="_blank">Data Stories</a></td><td>Enrico Bertini and Moritz Stefaner</td><td>4.5</td><td>405</td><td>162</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/twiml-ai-podcast-formerly-this-week-in-machine-learning/id1116303051" rel="nofollow noopener noreferrer" target="_blank">The TWIML AI Podcast (formerly This Week in Machine Learning &amp; Artificial Intelligence)</a></td><td>Sam Charrington</td><td>4.7</td><td>300</td><td>300</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/dataframed/id1336150688" rel="nofollow noopener noreferrer" target="_blank">DataFramed</a></td><td>DataCamp</td><td>4.9</td><td>188</td><td>59</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/the-ai-podcast/id1186480811" rel="nofollow noopener noreferrer" target="_blank">The AI Podcast</a></td><td>NVIDIA</td><td>4.5</td><td>162</td><td>125</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/superdatascience/id1163599059" rel="nofollow noopener noreferrer" target="_blank">SuperDataScience</a></td><td>Kirill Eremenko</td><td>4.6</td><td>161</td><td>300</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/partially-derivative/id942048597" rel="nofollow noopener noreferrer" target="_blank">Partially Derivative</a></td><td>Partially Derivative</td><td>4.8</td><td>141</td><td>101</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/machine-learning/id384233048" rel="nofollow noopener noreferrer" target="_blank">Machine Learning</a></td><td>Stanford</td><td>3.9</td><td>138</td><td>20</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/talking-machines/id955198749" rel="nofollow noopener noreferrer" target="_blank">Talking Machines</a></td><td>Tote Bag Productions</td><td>4.6</td><td>133</td><td>106</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/ai-in-business/id670771965" rel="nofollow noopener noreferrer" target="_blank">AI in Business</a></td><td>Daniel Faggella</td><td>4.4</td><td>102</td><td>100</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/learning-machines-101/id892779679" rel="nofollow noopener noreferrer" target="_blank">Learning Machines 101</a></td><td>Richard M. Golden</td><td>4.4</td><td>87</td><td>82</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/storytelling-with-data-podcast/id1318029970" rel="nofollow noopener noreferrer" target="_blank">storytelling with data podcast</a></td><td>Cole Nussbaumer Kna</td><td>4.9</td><td>80</td><td>33</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-crunch/id1165189603" rel="nofollow noopener noreferrer" target="_blank">Data Crunch</a></td><td>Data Crunch Corporation</td><td>4.9</td><td>70</td><td>64</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-viz-today/id1352837603" rel="nofollow noopener noreferrer" target="_blank">Data Viz Today</a></td><td>Alli Torban</td><td>5</td><td>64</td><td>62</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/artificial-intelligence/id765641080" rel="nofollow noopener noreferrer" target="_blank">Artificial Intelligence</a></td><td>MIT</td><td>4.1</td><td>61</td><td>31</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/oreilly-data-show-podcast/id944929220" rel="nofollow noopener noreferrer" target="_blank">O'Reilly Data Show Podcast</a></td><td>O'Reilly Media</td><td>4.2</td><td>59</td><td>60</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/machine-learning-software-engineering-daily/id1230807136" rel="nofollow noopener noreferrer" target="_blank">Machine Learning – Software Engineering Daily</a></td><td>Machine Learning – Software Engineering Daily</td><td>4.5</td><td>59</td><td>115</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-science-at-home/id1069871378" rel="nofollow noopener noreferrer" target="_blank">Data Science at Home</a></td><td>Francesco Gadaleta</td><td>4.2</td><td>58</td><td>100</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-engineering-podcast/id1193040557" rel="nofollow noopener noreferrer" target="_blank">Data Engineering Podcast</a></td><td>Tobias Macey</td><td>4.7</td><td>58</td><td>150</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/big-data/id1148791298" rel="nofollow noopener noreferrer" target="_blank">Big Data</a></td><td>Ryan Estrada</td><td>4.6</td><td>58</td><td>13</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/follow-the-data-podcast/id1104371750" rel="nofollow noopener noreferrer" target="_blank">Follow the Data Podcast</a></td><td>Bloomberg Philanthropies</td><td>4.3</td><td>57</td><td>82</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/making-data-simple/id605818735" rel="nofollow noopener noreferrer" target="_blank">Making Data Simple</a></td><td>IBM</td><td>4.3</td><td>56</td><td>104</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/analytics-on-fire/id1088683533" rel="nofollow noopener noreferrer" target="_blank">Analytics on Fire</a></td><td>Mico Yuk</td><td>4.4</td><td>51</td><td>48</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/learn-to-code-in-one-month/id1460397186" rel="nofollow noopener noreferrer" target="_blank">Learn to Code in One Month</a></td><td>Learn to Code</td><td>4.9</td><td>50</td><td>26</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/becoming-a-data-scientist-podcast/id1076448558" rel="nofollow noopener noreferrer" target="_blank">Becoming A Data Scientist Podcast</a></td><td>Renee Teate</td><td>4.5</td><td>49</td><td>21</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/practical-ai-machine-learning-data-science/id1406537385" rel="nofollow noopener noreferrer" target="_blank">Practical AI: Machine Learning &amp; Data Science</a></td><td>Changelog Media</td><td>4.5</td><td>48</td><td>105</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/present-beyond-measure-show-data-visualization-storytelling/id1029765276" rel="nofollow noopener noreferrer" target="_blank">The Present Beyond Measure Show: Data Visualization, Storytelling &amp; Presentation for Digital Marketers</a></td><td>Lea Pica</td><td>4.9</td><td>44</td><td>58</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/the-data-chief/id1509495585" rel="nofollow noopener noreferrer" target="_blank">The Data Chief</a></td><td>Mission</td><td>4.9</td><td>43</td><td>16</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/ai-today-podcast-artificial-intelligence-insights-experts/id1279927057" rel="nofollow noopener noreferrer" target="_blank">AI Today Podcast: Artificial Intelligence Insights, Experts, and Opinion</a></td><td>Cognilytica</td><td>4.2</td><td>42</td><td>161</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-driven/id1241441038" rel="nofollow noopener noreferrer" target="_blank">Data Driven</a></td><td>Data Driven</td><td>4.9</td><td>41</td><td>257</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/humain-podcast-artificial-intelligence-data-science/id1452117009" rel="nofollow noopener noreferrer" target="_blank">HumAIn Podcast - Artificial Intelligence, Data Science, and Developer Education</a></td><td>David Yakobovitch</td><td>4.8</td><td>39</td><td>78</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-gurus/id1351574994" rel="nofollow noopener noreferrer" target="_blank">Data Gurus</a></td><td>Sima Vasa</td><td>5</td><td>39</td><td>106</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/masters-of-data-podcast/id1363415303" rel="nofollow noopener noreferrer" target="_blank">Masters of Data Podcast</a></td><td>Sumo Logic hosted by Ben Newton</td><td>5</td><td>38</td><td>74</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/the-policyviz-podcast/id982966091" rel="nofollow noopener noreferrer" target="_blank">The PolicyViz Podcast</a></td><td>The PolicyViz Podcast</td><td>4.7</td><td>36</td><td>180</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/the-radical-ai-podcast/id1505229145" rel="nofollow noopener noreferrer" target="_blank">The Radical AI Podcast</a></td><td>Radical AI</td><td>4.9</td><td>34</td><td>35</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/women-in-data-science/id1440076586" rel="nofollow noopener noreferrer" target="_blank">Women in Data Science</a></td><td>Professor Margot Gerritsen</td><td>4.9</td><td>28</td><td>24</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/towards-data-science/id1470952338" rel="nofollow noopener noreferrer" target="_blank">Towards Data Science</a></td><td>The TDS team</td><td>4.6</td><td>26</td><td>50</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-in-depth/id1468304417" rel="nofollow noopener noreferrer" target="_blank">Data in Depth</a></td><td>Mountain Point</td><td>5</td><td>22</td><td>24</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-science-imposters-podcast/id1249728040" rel="nofollow noopener noreferrer" target="_blank">Data Science Imposters Podcast</a></td><td>Antonio Borges and Jordy Estevez</td><td>4.4</td><td>22</td><td>88</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/the-artists-of-data-science/id1506968775" rel="nofollow noopener noreferrer" target="_blank">The Artists of Data Science</a></td><td>Harpreet Sahota</td><td>4.9</td><td>19</td><td>41</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/datafemme/id1484529990" rel="nofollow noopener noreferrer" target="_blank">#DataFemme</a></td><td>Dikayo Data</td><td>5</td><td>17</td><td>30</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/the-banana-data-podcast/id1463103655" rel="nofollow noopener noreferrer" target="_blank">The Banana Data Podcast</a></td><td>Dataiku</td><td>4.9</td><td>15</td><td>33</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/experiencing-data-with-brian-t-oneill/id1444887095" rel="nofollow noopener noreferrer" target="_blank">Experiencing Data with Brian T. O'Neill</a></td><td>Brian T. O'Neill</td><td>4.9</td><td>14</td><td>13</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/secrets-of-data-analytics-leaders/id1334792097" rel="nofollow noopener noreferrer" target="_blank">Secrets of Data Analytics Leaders</a></td><td>Eckerson Group</td><td>4.8</td><td>13</td><td>82</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-journeys/id1358963399" rel="nofollow noopener noreferrer" target="_blank">Data Journeys</a></td><td>AJ Goldstein</td><td>5</td><td>13</td><td>26</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-driven-discussions/id1258339160" rel="nofollow noopener noreferrer" target="_blank">Data Driven Discussions</a></td><td>Outlier.ai</td><td>5</td><td>12</td><td>8</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/data-futurology-leadership-strategy-in-artificial-intelligence/id1385051346" rel="nofollow noopener noreferrer" target="_blank">Data Futurology - Leadership And Strategy in Artificial Intelligence, Machine Learning, Data Science</a></td><td>Felipe Flores</td><td>4.4</td><td>11</td><td>135</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/artificially-intelligent/id1223852506" rel="nofollow noopener noreferrer" target="_blank">Artificially Intelligent</a></td><td>Christian Hubbs and Stephen Donnelly</td><td>4.9</td><td>11</td><td>100</td></tr></tbody></table>
<p><em>A few additional podcasts were recommended by the community at reddit - those are listed below</em></p>








































<table><thead><tr><th>title</th><th>author</th><th>avg_rtg</th><th>rtg_ct</th><th>episodes</th></tr></thead><tbody><tr><td><a href="https://podcasts.apple.com/us/podcast/linear-digressions/id941219323" rel="nofollow noopener noreferrer" target="_blank">Linear Digressions</a></td><td>Udacity</td><td>4.8</td><td>325</td><td>291</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/not-so-standard-deviations/id1040614570" rel="nofollow noopener noreferrer" target="_blank">Not So Standard Deviations</a></td><td>Roger Peng and Hilary Parker</td><td>4.2</td><td>164</td><td>100</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/the-local-maximum/id1344107244" rel="nofollow noopener noreferrer" target="_blank">The Local Maximum</a></td><td>Max Sklar</td><td>4.9</td><td>42</td><td>136</td></tr><tr><td><a href="https://podcasts.apple.com/us/podcast/chai-time-data-science/id1473685440" rel="nofollow noopener noreferrer" target="_blank">Chai Time Data Science</a></td><td>Sanyam Bhutani</td><td>4.8</td><td>9</td><td>109</td></tr></tbody></table>
<h2 id="why-i-want-to-find-data-science-podcasts">why i want to find data science podcasts</h2>
<p>This would normally be at the top of an article on finding data science podcasts. Well it would be at the top of any article. But realistically, most people are finding this from google, and they're just looking for the answer that's at the top of the page. If you type in 'the most popular data science podcasts', you really don't want to have to scroll down endlessly to find the answer you're looking for. So to make <em>their</em> experience better, we're just leaving the answer up there. And giving them sass. Lots of sass.</p>
<p>Anyways, I really like listening to things. While newsletters are great for keeping up with current events and blogs are great for learning specific things, podcasts have a special place in my heart for allowing me to aimlessly learn something new every day. The format really lends itself to delivering information efficiently, but in a way where you can multitask.  Pre-COVID, my morning commute was typically full of podcasts. While COVID has rendered my commute a nonexistent affair, I still try to listen to at least a podcast a day if I can manage it.  My view is that 30 minutes of learning a day will really add up in the long run, and I feel that podcasts are a great way to get there.</p>
<p>Now that we've been through my love affair with podcasts, you can imagine my surprise when I started looking for a few data science ones to subscribe to and I <em>didn't</em> find a tutorial on how to use web scraping to find the most popular data science podcasts to listen to.  I know, crazy.  There's a web scraping tutorial on everything under the sun except for - seemingly - podcasts.  I mean there's probably not one on newsletters either, but we'll leave that alone for now... </p>
<p>So if no one else is crazy enough to write about finding data science podcasts with web scraping, then...</p>
<h2 id="gameplanning-the-process">gameplanning the process</h2>
<p>By now we're almost certainly rid of those savages who are only here for the <strong>answer</strong> (<em>gasp, how could they</em>), so we'll go into the little process I went through to gather the data.  It's not particularly long, and took me probably an hour to put it together, so it should be a good length for an article.</p>
<p>I'm using python here with an installation of Anaconda (which is a common package management / deployment system for python).  I'll be running this in a Jupyter notebook, since its a one-off task that I don't need to use ever again... hopefully.</p>
<p>In terms of what I'm going to do, I'll run a few google keyword searches which are limited to the '<a href="https://podcasts.apple.com/us/podcast/'" rel="nofollow noopener noreferrer" target="_blank">https://podcasts.apple.com/us/podcast/'</a> domain and scrape the results for the first few pages.  From there I'll just be scraping the apple podcast page to get the total number of ratings and the average rating. Yea, the data will be biased, but its a quick and dirty way to get the answer I'm looking for.</p>
<h2 id="code-to-find-top-data-science-podcasts---version-1">code to find top data science podcasts - version 1</h2>
<div><pre><code># import default python packages
import urllib
import requests
import time
</code></pre></div>
<p>The above packages are included in python, the below ones aren't always included. If you don't have them installed, you'll have to download them. You can find out how to use <a href="https://packaging.python.org/tutorials/installing-packages/#use-pip-for-installing" rel="nofollow noopener noreferrer" target="_blank">pip</a> to do it or <a href="https://docs.anaconda.com/anaconda/user-guide/tasks/install-packages/" rel="nofollow noopener noreferrer" target="_blank">conda</a>. </p>
<div><pre><code># import non-standard python packages
# if you dont have these installed, install them with pip or conda
from bs4 import BeautifulSoup
import pandas as pd
</code></pre></div>
<p>Now that the packages have been imported, you should define your user agent. First off, because its polite if you're scraping anything. Secondly, google gives different results for mobile and desktop searches.  This isn't actually my user-agent, I took it from another tutorial since I'm a bit lazy.  I actually use linux...</p>
<div><pre><code># define your desktop user-agent
USER_AGENT = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0"
</code></pre></div>
<p>Alright now we're going to define the queries we want to run. And then create a function that spits out the URL we want to scrape on google.  I'm putting the queries in a kwargs format, since I want to put them through a function.  That means I can just loop through the list of kwargs and get the results that the function returns.</p>
<div><pre><code># Queries
list_kwargs = [
    {"string": 'data podcast'},
    {"string": 'data podcast', "pg": 2},
    {"string": 'data podcast', "pg": 3},
    {"string": 'data science podcast'},
    {"string": 'data engineering podcast'},
    {"string": 'data visualization podcast'},
]

def string_to_podcast_query(string, pg=None):
    query = urllib.parse.quote_plus(f'site:https://podcasts.apple.com/us/podcast/ {string}')
    if pg != None:
        query = query + "&amp;start=" + str(10*(pg-1))
    return f"https://google.com/search?hl=en&amp;lr=en&amp;q={query}", string

# define the headers we will add to all of our requests
headers = {"user-agent" : USER_AGENT}

# set up an empty list to push results to
results = []

# cycle through the list of queries 
for x in list_kwargs:
    # return the query url and the search term that was used to create it (for classification later)
    url, search_term = string_to_podcast_query(**x)

    # make a get request to the url, include the headers with our user-agent
    resp = requests.get(url, headers=headers)

    # only proceed if you get a 200 code that the request was processed correctly
    if resp.status_code == 200:
        # feed the request into beautiful soup
        soup = BeautifulSoup(resp.content, "html.parser")
    
    # find all divs (a css element that wraps page areas) within google results
    for g in soup.find_all('div', class_='r'):
        # within the results, find all the links 
        anchors = g.find_all('a')
        if anchors:
            # get the link and title, add them to an object, and append that to the results array
            link = anchors[0]['href']
            title = g.find('h3').text
            item = {
                "title": title,
                "link": link,
                "search_term": search_term
            }
            results.append(item)

    # sleep for 2.5s between requests.  we don't want to annoy google and deal with recaptchas
    time.sleep(2.5)
</code></pre></div>
<p>Alright, now we have the google results back - nice.  From here, lets put that in a pandas dataframe and filter it a bit.</p>
<div><pre><code>google_results_df = pd.DataFrame(results)

# create a filter for anything that is an episode.  They should contain a ' | '.
# drop any duplicate results as well.
google_results_df['is_episode'] = google_results_df['title'].str.contains(' | ',regex=False)
google_results_df = google_results_df.drop_duplicates(subset='title')

google_results_podasts = google_results_df.copy().loc[google_results_df['is_episode']==False]
</code></pre></div>
<p>Ok cool, we have a list of podcasts. Lets define …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gregondata.com/blog/best-data-science-podcasts/">https://gregondata.com/blog/best-data-science-podcasts/</a></em></p>]]>
            </description>
            <link>https://gregondata.com/blog/best-data-science-podcasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460568</guid>
            <pubDate>Sun, 13 Sep 2020 13:00:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Explore breathtaking places from home with 360° Audio Tours]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24460331">thread link</a>) | @Kiryous
<br/>
September 13, 2020 | https://online.srprsm.com/audio | <a href="https://web.archive.org/web/*/https://online.srprsm.com/audio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="allrecords" data-hook="blocks-collection-content-node" data-tilda-project-id="279" data-tilda-page-id="13541354" data-tilda-page-alias="audio" data-tilda-formskey="0c52d6b535f84cee5d19f5f15dea746e"><div id="rec225818586" data-animationappear="off" data-record-type="204"><!-- cover --><div id="recorddiv225818586" bgimgfield="img"> <div> <div><div> <div> <div data-hook-content="covercontent"> <div> <p><span>Explore breathtaking places from home with 360° Audio Tours</span></p> <p>Visit places you couldn't even dream of seeing. Go on amazing Google StreetView's walkthroughs accompanied by an expert audio guide right. Join right from your phone, tablet or laptop</p>  </div> </div> </div> </div> </div> </div> </div> </div><div id="rec228422151" data-animationappear="off" data-record-type="396"><!-- T396 --> <div><div data-artboard-recid="228422151" data-artboard-height="325" data-artboard-height-res-960="315" data-artboard-height-res-640="505" data-artboard-height-res-480="490" data-artboard-height-res-320="540" data-artboard-height_vh="" data-artboard-valign="center" data-artboard-ovrflw="">     <div data-elem-id="1474900324080" data-elem-type="text" data-field-top-value="102" data-field-top-res-960-value="98" data-field-top-res-640-value="287" data-field-top-res-480-value="274" data-field-top-res-320-value="309" data-field-left-value="450" data-field-left-res-960-value="377" data-field-left-res-640-value="90" data-field-left-res-480-value="90" data-field-left-res-320-value="30" data-field-width-value="580" data-field-width-res-960-value="450" data-field-width-res-640-value="460" data-field-width-res-480-value="300" data-field-width-res-320-value="260" data-field-axisy-value="top" data-field-axisx-value="left" data-field-container-value="grid" data-field-topunits-value="" data-field-leftunits-value="" data-field-heightunits-value="" data-field-widthunits-value=""> <p>Tour shows you the Old Town and the city's underground vaults. Audio will reveal the dark side of Edinburgh's history with passion, humor, and flair. Be ready for the unusual on this 2-hour adventure!<br></p> </div>   <div data-elem-id="1599064813365" data-elem-type="text" data-field-top-value="20" data-field-top-res-960-value="20" data-field-top-res-640-value="214" data-field-top-res-480-value="217" data-field-top-res-320-value="211" data-field-left-value="450" data-field-left-res-960-value="378" data-field-left-res-640-value="90" data-field-left-res-480-value="90" data-field-left-res-320-value="30" data-field-width-value="560" data-field-axisy-value="top" data-field-axisx-value="left" data-field-container-value="grid" data-field-topunits-value="" data-field-leftunits-value="" data-field-heightunits-value="" data-field-widthunits-value=""> <div field="tn_text_1599064813365"><p>Fragment from </p><u>(coming next week!)</u></div> </div> </div> </div> <!-- /T396 --></div><div id="rec226754861" data-record-type="795"><!-- T795 --><div> <div> <div> <p>This week's audio tours</p> <p>Become the most interesting person in the room: Learn 10 secrets about Italian masterpieces with art historians or go to the tallest rooftop</p> </div> </div></div></div><div id="rec227122990" data-record-type="37"><!-- T022 --><div><div><div><div><p>Hurry up! This set will expire in</p></div></div></div></div></div><div id="rec226778583" data-animationappear="off" data-record-type="131"><!-- T123 --><div><div><div>

<div>
   <p><span>02</span> days <span>15</span> hours <span>32</span> minutes <span>00</span> seconds
    </p>
</div>


 
</div> </div></div></div><div id="rec226675593" data-record-type="493"><!-- t493 --><div><div><div><div><p>How <strong>360 ° Audio Tours</strong> works</p></div></div></div> <div><div> <div> <div> <p><img src="https://static.tildacdn.com/tild3937-6231-4535-b162-643164363639/-/empty/Screenshot_2020-09-0.png" data-original="https://static.tildacdn.com/tild3937-6231-4535-b162-643164363639/Screenshot_2020-09-0.png" imgfiled="img5"> </p> </div> </div> <div> <div> <div> <div>  <div> <p> 10 new tours every week</p> <p> Every Wednesday we publish new set of online experiences Narrated by native English-speakers. It's available only for a week.</p> </div> </div> <div>  <div> <p> Local heroes committed to quality<br></p> <p> We select authors, only 3 out of 10 applications get approved. Tours crafted by local experts with 5+ years of experience in their field.</p> </div> </div> <div>  <div> <p> You don't need to download anything</p> <p> No zoom, no skype. Just launch and explore. Works in browser on your phone, tablet or desktop computer</p> </div> </div> </div> </div> </div> <div> <div> <p><img src="https://static.tildacdn.com/tild3937-6231-4535-b162-643164363639/-/empty/Screenshot_2020-09-0.png" data-original="https://static.tildacdn.com/tild3937-6231-4535-b162-643164363639/Screenshot_2020-09-0.png" imgfield="img5"> </p> </div> </div> </div> </div> </div></div><div id="rec227123780" data-animationappear="off" data-record-type="807"><!-- t807 --><div> <div> <div> <div> <div data-vote-id="227123780" data-hook-content="" data-vote-type="multi" data-vote-visibility="onclick"> <p>Vote for the next week tours</p> <p>Help us make next week even more awesome</p> <div data-question-id="1516285049769" data-question-num="1"> <div> <p>Pick destination you want to go virtually</p> </div> <div>         <div data-answer-id="9"> <p><label>  <span>Black Rock City (if you know what I mean)</span> </label> </p>   </div> </div> </div>  <div> <p>You are great! Your vote has been counted. Thank you for participating!</p> </div> </div> </div> </div> </div></div></div><div id="rec226421357" data-record-type="529" data-bg-color="#eeeeee"><!-- t529 --><div><div><div><div><p>Why people love online experiences with Surprise Me</p><p>More than 700 people tried online tours since beta launch in July</p></div></div></div> <div> <div> <div> <p>Thank you very much! It's like I really fulfilled my dream to went there</p> </div>  <div>  <div> <p>Lily Richards</p> <p>Always dreamed to visit Chernobyl</p> </div> </div> </div> <div> <div> <p>The tour is great! Nothing unnecessary, a lot of video.<br>I felt immersed even there was no host or guide. Waiting for more new experiences!</p> </div>  <div>  <div> <p>James Martin</p> <p>Missed the canals of Venice very much</p> </div> </div> </div>  <div> <div> <p>Awesome tour, a lot of unique stories and tips for wine tasting and museum for my future trip. We "walked" almost an hour in Florence. Loved it! I decided to book a flight to Florence for 2021. Thanks to the author :-)</p> </div>  <div>  <div> <p>Christian Jarvis</p> <p>Absolutely in love with Italian wine and art</p> </div> </div> </div> <div> <div> <p>I'm thrilled, I didn't even know that there are people living in the exclusion zone right now!</p> </div>  <div>  <div> <p>April Larkins</p> <p>Creative director and thrill-seeker</p> </div> </div> </div> </div></div></div><div id="rec224592069" data-record-type="524"><!-- t524 --><div><div><div><div><p>Meet this week creators</p><p>These locals from 6 countries crafted online tours for you with all their soul</p></div></div></div><div> <div><div> <div> <p>Margi</p> <p>I'll show you Rome empire could be interesting as Game of Thrones</p> </div></div> </div> <div><div> <div> <p>Alexandre</p> <p>Knows everything about Black Death in Prague, Catacombs in Rome and Paris and other creepy things</p> </div></div> </div> <div><div> <div> <p>Hugo</p> <p>Climbed on 100+ roofs, include the world's tallest building — the Burj Halifa </p> </div></div> </div></div></div></div><div id="rec226144434" data-animationappear="off" data-record-type="704" data-bg-color="#1f5bff"><!-- T704 --><div> <div> <div> <div> <p>25% off for new subscribers</p> <p>Once a week you will learn about our latest tours and hottest deals. No spam<br></p> </div>  </div> </div></div><!--[if IE 8 ]><style> .t-input-block .t-input:focus ~ .t-input__vis-ph, .t-input_has-content + .t-input__vis-ph { top: 10px; font-size: 12px; }</style><![endif]--></div></div></div>]]>
            </description>
            <link>https://online.srprsm.com/audio</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460331</guid>
            <pubDate>Sun, 13 Sep 2020 12:17:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smaller Internet Providers in Canada Just Got a Big Win in Court]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24460328">thread link</a>) | @cmrdporcupine
<br/>
September 13, 2020 | https://www.huffingtonpost.ca/entry/internet-providers-ruling_ca_5f5b7f81c5b6b48507ff83e4?ncid=fcbklnkcahpmg00000001 | <a href="https://web.archive.org/web/*/https://www.huffingtonpost.ca/entry/internet-providers-ruling_ca_5f5b7f81c5b6b48507ff83e4?ncid=fcbklnkcahpmg00000001">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure>
        </figure><div><p><span>TORONTO — The Federal Court of Appeal dismissed appeals by some of Canada’s largest telephone and cable companies Thursday, handing an interim victory to the country’s independent internet providers.</span></p>        <!-- entry_paragraph_1_ad -->
    
<p><span>The court also ordered the network owners including Bell, Rogers and others to pay costs of the appeal to TekSavvy Solutions Inc., which is the largest of Canada’s independent ISPs, and an industry association.</span></p><p><span>“This is a massive win for Canadians,” said Matt Stein, chair of the Canadian Network Operators Consortium (CNOC) and CEO of Distributel, one of about 30 CNOC members.</span></p><p><span>He said that the court’s decision ends a “pivotal chapter” in a fight that challenged “Canada’s longstanding practice of appropriate oversight to ensure fair pricing and competition.”</span></p><h3>TekSavvy refuses to pay more</h3><p><span>The court’s 3-0 ruling concluded by saying the award of costs to TekSavvy and CNOC reflects the fact that the appellants were not successful in convincing the three judges on any of the issues they raised.</span></p><p><span>There were several appeals before the court, including one filed by Bell Canada on behalf of BCE, and another for most of Canada’s largest cable operators, including Rogers, Shaw, Quebecor’s Videotron and Cogeco.</span></p><p><span>But the Federal Court of Appeal is only one way in which the big network owners have been fighting to prevent the CRTC from reducing the wholesale rates they charge to independent internet providers, which compete for some of the same customers.</span>&nbsp;</p><p>On Friday,&nbsp;TekSavvy Solutions Inc. said it’s owed tens of millions of dollars in rebates from excessive wholesale internet fees and won’t pay more to Bell or Rogers until the balance is settled.</p></div>                
                                
                <!-- start relEntries --><!-- end relEntries --><div><p><span>The CRTC is also reviewing its own decision, as part of the regulatory process, and the federal government has indicated it could step in at some point if it thinks the arms-length regulator doesn’t strike the right balance.</span></p><p><span>Coincidentally, BCE’s chief financial officer told an industry conference Thursday that sentiment seems to have shifted in favour of telecommunications network builders since the pandemic.</span></p><p><span>In response to questions in an interview-style session with a Bank of America analyst, BCE chief financial officer Glen LeBlanc said benefit of having strong, reliable wireless and internet networks was recognized during the COVID-19 pandemic.</span></p><p><span>He pointed to a federal government statement on Aug. 15, issued on the one-year anniversary of the CRTC’s wholesale prices decision, that suggested some errors in its process could undermine investments in Canada’s communications networks, particularly in rural and remote areas.</span></p><p><span>“On the basis of its review, the (cabinet) considers that the (August 2019) rates do not, in all instances, appropriately balance the policy objectives of the wholesale services framework and is concerned that these rates may undermine investment in high-quality networks, particularly in rural and remote areas,” Industry Minister Navdeep Bains said.</span></p><p><span>Bains said it was unnecessary to refer the decision back to the CRTC for reconsideration “at this time,” but said that the government will continue to monitor the CRTC proceedings to ensure it establishes the “right incentives” for both investment and competitive choice.</span></p><p><em><strong>Watch: Canadians are getting shafted on mobile data plans. Story continues below.</strong></em></p></div><div><p><span>Canada’s small and mid-sized ISPs collectively serve about one million households using infrastructure they either own or rent. Although they have only about one-tenth of the market share, they argue that they provide an important alternative to the bigger carriers.</span></p><p><span>However, the independent ISPs depend on connecting their equipment to networks built and owned by the “facilities based” carriers.</span></p><p><span>The main message of the facilities-based carriers is that the CRTC’s proposed wholesale rates, which haven’t been put into effect because of the court appeal, were so low they didn’t cover the cost of providing the services purchased by their wholesale customers.</span></p><p><span>The independent ISPs argued the interim wholesale prices they’ve been paying since 2016 have always been excessively high and they’ll be able to lower retail rates if the CRTC’s decision is put in place.</span></p><p><span>The CRTC ordered the facilities-based carriers to cut their wholesale capacity rates by up to 43 per cent and chop their access rates up to 77 per cent.</span></p><p><span>A statement by VMedia Inc., a Toronto-based CNOC member, says that the appeal court’s decision appears to show the cabinet’s statement last month was “without foundation.”</span></p><p><span>It also said the threat of reduced investments in network infrastructure is a “staple in all rate-setting hearings” but they’ve not been borne out in previous decisions that went against the network owners-operators.</span></p></div><section></section></div></div>]]>
            </description>
            <link>https://www.huffingtonpost.ca/entry/internet-providers-ruling_ca_5f5b7f81c5b6b48507ff83e4?ncid=fcbklnkcahpmg00000001</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460328</guid>
            <pubDate>Sun, 13 Sep 2020 12:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's so hard about PDF text extraction?]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 157 (<a href="https://news.ycombinator.com/item?id=24460142">thread link</a>) | @fagnerbrack
<br/>
September 13, 2020 | https://filingdb.com/b/pdf-text-extraction | <a href="https://web.archive.org/web/*/https://filingdb.com/b/pdf-text-extraction">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>There is a common view that extracting text from a PDF document should not be too difficult. After all, the text is right there in front of our eyes and humans consume PDF content all the time with great success. Why would it be difficult to automatically extract the text data? </p><p>Turns out, much how <a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/">working with human names is difficult</a> due to numerous edge cases and incorrect assumptions, working with PDFs is difficult due to the extreme flexibility given by the PDF format.</p><p>The main problem is that PDF was never really designed as a data input format, but rather, it was designed as an output format giving fine grained control over the resulting document.</p><p>At its core, the PDF format consists of a stream of instructions describing how to draw on a page. In particular, text data isn’t stored as paragraphs - or even words - but as characters which are painted at certain locations on the page. As a result, most of the content semantics are lost when a text or word document is converted to PDF - all the implied text structure is converted into an almost amorphous soup of characters floating on pages.</p><p>As part of building <a href="https://www.filingdb.com/">FilingDB</a>, we’ve extracted text data from tens of thousands of PDF documents. In the process, we have seen how every single assumption we had about how PDF files are structured was proven incorrect. Our mission was particularly difficult as we had to process PDF documents coming from a variety of sources, with wildly different styling, typesetting and presentation choices.</p><p>The list below documents some of the ways PDF files have made it difficult (or even impossible) to extract text contents.</p><h2>PDF read protection</h2><p>You may have come across PDF files which refuse to let you copy their text content. For example, here is what SumatraPDF shows when attempting to copy text from a copy-protected document.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/tCFgGsFAVfhZQqJx.png" alt="copy denied.png"></p><p>Interestingly, the text is already visible, yet the PDF viewer is refusing to populate the clipboard with the highlighted text.</p><p>The way this is implemented is by having several “access permissions” flags, one of which controls whether copying content is allowed. It’s important to keep in mind that this restriction is not enforced by the PDF file - the actual PDF contents are unaffected and it is up to the pdf renderer to honour this flag.</p><p>Needless to say, this offers no real protection against extracting the text out of the PDF, as any reasonably sophisticated PDF handling library will allow the user to either toggle the flags or ignore them.</p><h2>Off-page characters</h2><p>It is not uncommon for PDF files to contain more textual data than is actually displayed on the page. Take this page from the 2010 Nestle annual report.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/rWwxfWHHBcjvZQul.png" alt="Nestle hidden text.png"></p><p>There is more text associated with this page than meets the eye. In particular, the following can be found in the content data associated with this page:</p><blockquote>“KitKat celebrated its 75th anniversary in 2010 but remains young and in touch with trends, having over 2.5 million Facebook fans. It is sold in over 70 countries and enjoys good growth in the developed world and emerging markets, such as the Middle East, India and Russia. Japan is its second biggest market.”</blockquote><p>This text is actually positioned outside the page’s bounding box, so it is not displayed by most PDF viewers, but the data is there and will appear when programmatically extracting the text.</p><p>This occasionally happens due to last minute decisions to remove or replace text during the type setting process.</p><h2>Small / invisible characters on page</h2><p>PDFs occasionally introduce very small or hidden text on the page. For example, here is a page from the Nestle 2012 annual report.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/kqduhxcugDRKTbDC.png" alt="hidden characters.png"></p><p>The page contains small white text on white background with the following contents:</p><blockquote>​“Wyeth Nutrition logo Identity Guidance to markets</blockquote><blockquote>Vevey Octobre 2012 RCC/CI&amp;D”</blockquote><p>This is sometimes done for the benefit of accessibility, similar to how the alt attribute is used in HTML.</p><h2>​Too many spaces</h2><p>Sometimes PDFs include extra spaces between letters in a word. This is most likely done for kerning purposes. (“Kerning” is the process of adjusting distances between characters during the type setting process)</p><p><strong>Example</strong>: the 2013 Hikma Pharma annual report contains the following text:</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/LNAUhbShXUkPbOhc.png" alt="an_excellent.PNG"></p><p>Copying the text gives:</p><blockquote>“ch a i r m a n ' s s tat em en t”</blockquote><p>Reconstructing the original text is a difficult problem to solve generally. Our most successful approach has been applying OCR techniques.</p><h2>Not enough spaces</h2><p>Sometimes PDFs do not contain spaces or replace them with a different character.</p><p><strong>Example 1</strong>: The following extract from the 2017 SEB annual report.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/byRVQrWFscgwqUbM.png" alt="global trends.PNG"></p><p>The extracted text shows:</p><blockquote>“Tenyearsafterthefinancialcrisisstarted”</blockquote><p><strong>Example 2</strong>: The 2013 Eurobank annual report shows the following</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/cNjRRWVALUGfSnRl.png" alt="eurobank.PNG"></p><p>Extracting the text gives:</p><blockquote>“On_April_7,_2013,_the_competent_authorities”</blockquote><p>Again, our most successful solution was to run OCR on these pages.</p><h2>Embedded fonts</h2><p>PDF font handling is complex to say the least. To understand how PDF files store text data we must first know about glyphs, glyph names, fonts.</p><ul><li>A glyph is a set of instructions describing how to draw a symbol or character.</li><li>A glyph name is the name associated with that glyph. For example “trademark” for the “™” glyph and “a” for the “a” glyph.</li><li>Fonts are lists of glyphs with associated glyph names. For example, most fonts have a glyph that most humans would recognize as the letter “a”, with different fonts showing various ways of drawing that letter.</li></ul><p>In a PDF, the characters are stored as numbers, called “codepoints”. To decide what to draw on the screen, a renderer has to go:</p><p><code>codepoint -&gt; glyph name -&gt; glyph</code></p><p>For example, a PDF document can contain codepoint 116, which it maps into the glyph name “<code>t</code>” which, in turn, maps into the glyph describing how to draw “<code>t</code>” on the screen.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/boPNiRoKrNIlOHHD.png" alt="unicode glyphs.png"></p><p>Now, most PDF files use a standard codepoint encoding. A codepoint encoding is a set of rules that assign meaning to the codepoints themselves. For example:</p><ul><li>ASCII and Unicode both use codepoint 116 to represent the letter “<code>t</code>”.</li><li>Unicode maps codepoint 9786 to “<code>white smiley face</code>”, rendered as ☺, whereas ASCII is not defined at that codepoint. </li></ul><p>However, PDF documents occasionally use their own custom encoding together with custom fonts. It might seem strange, but a document can use codepoint 1 to represent the letter “<code>t</code>”. It will map codepoint 1 into the glyph name “<code>c1</code>”, which will map into a glyph describing how to draw the letter “<code>t</code>”.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/oLGIEmjOegjUtsiQ.png" alt="custom glyphs.png"></p><p>While for a human the end result looks the same, a machine will get confused by the codepoints it is seeing. If the codepoints do not follow a standard encoding, then it is virtually impossible to programmatically know what codepoints 1, 2 and 3 represent.</p><p>Why would a PDF document contain nonstandard fonts and encodings?</p><ul><li>One reason is to make text extraction more difficult.</li><li>Another is the use of subfonts. Most fonts contain glyphs for a very large number of codepoints and a pdf might only use a subset of these. To save space, a PDF creator can strip away all unneeded glyphs and create a compact subfont which will most likely use a non-standard encoding.</li></ul><p>One workaround is to extract the font glyphs from the document, run them through OCR software and build the map from font glyph to unicode. This then lets you translate from the font-specific encoding to the unicode encoding e.g: codepoint 1 is mapped to name “<code>c1</code>” which, based on looking at the glyph, should be a “<code>t</code>”, which is unicode codepoint 116.</p><p>The encoding map that you’ve just generated, the one going from 1 to 116, is called a ToUnicode map in the PDF standard. PDF documents can provide their own ToUnicode map, but it’s optional and many do not.</p><h2>Word and paragraph detection</h2><p>Reconstructing paragraphs and even words from the amorphous character soup of PDF files is a difficult task.</p><p>The PDF document provides a list of characters on a page and it is up to the consumer to identify words and paragraphs. Humans are naturally effective at doing this as reading is a widespread skill.</p><p>The common approach is to have a grouping or clustering algorithm which compares letter sizes, positions and alignments in order to determine what is a word/paragraph.</p><p>Naive implementations can easily have complexity larger than O(n²), resulting in long processing times on busy pages.</p><h2>Text and paragraph order</h2><p>Deciding on text and paragraph order is difficult on two levels.</p><p>First, sometimes there is no correct answer. While documents with conventional, single column typesetting have a natural order of reading, documents with more adventurous layouts are challenging. As an example, it is not clear if the following inset should appear before, after, or during the article it is placed next to:</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/tdNisrVDTpYeRiVU.png" alt="paragraph order.PNG"></p><p>Second, even when the answer is clear to a human, determining robust paragraph order is a very difficult problem to solve, perhaps even AI-hard. This might sound like an extreme statement, however there are cases where the correct paragraph order can only be decided by understanding the text content.</p><p>Consider the following two-columns layout, describing how to prepare a vegetable salad:</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/LVpxBZtdQdXIYMfv.png" alt="recipe.png"></p><p>In the western world, a reasonable assumption is that reading is done left to right and top to bottom. So the best we can do without looking at the contents is to reduce the answer to 2 options: A B C D and A C B D.</p><p>By looking at the content, understanding what it is talking about and knowing that vegetables are washed before chopping, we can determine that A C B D is the correct order. Determining this algorithmically is a difficult problem.</p><p>That being said, a “works most times” approach is to rely on the order in which the text is stored inside the PDF document. This usually corresponds to the order the text was inserted at creation time and, for large bodies of text containing multiple paragraphs, they tend to reflect the writer-intended order.</p><h2>Embedded images</h2><p>It is not uncommon for some (or all) of the PDF content to actually be a scan. In these cases, there is no text data to extract directly, so we have to resort to OCR techniques.</p><p>As an example, the Yell 2011 annual report is only available as a document scan:</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/kMKEqcgsWNHNhiXI.png" alt="scan.PNG"></p><h2>Why not OCR all …</h2></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://filingdb.com/b/pdf-text-extraction">https://filingdb.com/b/pdf-text-extraction</a></em></p>]]>
            </description>
            <link>https://filingdb.com/b/pdf-text-extraction</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460142</guid>
            <pubDate>Sun, 13 Sep 2020 11:33:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nokia 3310 3G as a podcast player]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24460136">thread link</a>) | @progre
<br/>
September 13, 2020 | http://prog.re/blog/2020-09-13.html | <a href="https://web.archive.org/web/*/http://prog.re/blog/2020-09-13.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
<h2>TLDR</h2>
<p><del>The Nokia 3310 3G is a</del> <em>Some versions</em> of the Nokia 3310 3G works as a descent podcast player, but you have to manage
your podcasts on a real computer.</p>
<h2>The story about why I bought candy bar feature phone in 2020</h2>
<p>Nokia 3310 3G is a feature phone with at least a design
heritage from the much loved Nokia 3310 of the late nineties.
A feature phone in 2020 is maybe not as strange as it might seem.
While the smart-phones are getting ever more advanced, there is also
a counter trend of digital decluttering.</p>
<p>I used to love my smartphone. I was on reddit (back when the mobile website worked)
and youtube all the time on my phone. I use it as a music player while I'm doing kitchen stuff.</p>
<p>But the main use was as a podcast player. Pre-corona I had a commute of
about an hour in each direction (bike + bus). I spent most of the bike time
with podcasts in my ear (the bus time was spent on hobby programming projects).</p>
<p>In January of 2020 I went on paternal leave and the podcast time picked up
significantly as I spent the days lugging around my sleeping then 7 months old boy
while walking the 8 months old lab. I would get about 10 hours of battery time out of
my phone, a 2016 model of Samsung A3. Now, clearly the battery had seen better
days. And it was never a high end phone to begin with. But 10 hours battery time
was getting to be a stress factor.</p>
<p>The thing is I sort of have to have a smartphone. Swish payments is one factor.
Most things that used to be actual currency transactions is Swish payments now.
Buy meat from the cattle farmer? Swish. Buy honey from the beekeeper? Swish. Buy socks
to support your coworkers kids soccer team? Swish. And Swish is available on phones only.
The chromebook that I use for mostly everything can run Android apps but the Swish app
refuses to install on a non phone device.</p>
<p>Another factor is BankID. BankID used to be only a bank issued smart card and a special
little card reader. You would stick the card into a slot in the reader and enter your pin
on the readers keypad. To log into you bank or to a government service you would get a 9 digit
code from the website that you would enter into the reader. The BankID reader would then display
a 6 digit answer code that you would enter into the website and the BankID system would then
guarantee your identity to the bank or government service. But then Mobile Bank Id showed up.
It's a smartphone app that does the same thing except the code-answer code exchange is done
automatically without user interaction now. And lots of websites are starting to retire
the old reader way identifying yourself, leaving Mobile BankID with the only option.</p>
<p>Being on paternal leave I did not have the money for a brand new smartphone, other than one
really low end one. It was also clear to me that it was the podcast consumption that was eating
up my battery. The days that I didn't listen to podcast I would get 24 hour of battery or more.
I'm not sure why podcasts in particular are so hard on the battery, it seemed that about equal
time on Spotify would not drain it nearly as much. I suspect that the fact that the podcast files
are stored on a external SD card has something to do with it.</p>
<p>I started looking at buying dedicated MP3 player. I know from buying an mp3 player for my oldest
daughter that the cheap ones are shit for podcasts and audio books. They reset the play list when
you turn them off and there is no way to have them turned on all the time. They power down when
taking a charge. San-disk still makes an mp3 player that are good for podcast and audio books.
"Resume function" is the keyword to look for. Roxcore also has one (I got one for my daughter when
the <em>really</em> cheap one turned our to be shit).</p>
<p>But then I saw the Nokia 3310 phones. At 600 SEK it's about the same price as a Roxcore mp3 player.
So I started to think I would get one and use it as an mp3 player <em>and</em> have it double as a backup
phone in case my smartphone had drained it's battery. But I was a bit hesitant, because I couldn't get
good information on weather the 3310 did the resume thing or not.</p>
<p>Eventually I bought one anyway. And I bought a 32 GB micro SD for it to store podcasts.
The 3310 has apps but no app store. You supposedly <em>can</em> download java apps for the Java Micro
framework or whatever its called and run them on the phone. But I haven't bothered. The phone has a
music player that picks up any mp3 file stored in the "Music" folder on the SD card, or the phone itself.
The music player really likes those mp3 tags for sorting the music by artist and albums, so it's not ideal
for podcasts. As a last ditch it sorts the files by name, so it kind of works out anyway. And yes, it does
"resume". Even if you exit the music player app it resumes where you stopped. And I get 4 to 5 days of battery
time even with rather heavy use. My old Samsung spends most of it's time in my bag now, and when not used, that
thing has pretty fantastic battery time too.</p>
<p>I use GPodder on windows to manage podcast downloads as the phone cant handle downloads.
It's pretty OK. I don't use the sync feature though, I just let it download everything,
and then I pick and choose what to transfer to the phone.</p>
<h2>Addendum</h2>
<p>I got a mail from <a href="http://ibawizard.net/">Jakub</a> where he wondered how I got the "resume" function
to work. He also has a 3310 (model of 2018), and apparently <em>his</em> phone does not resume anything,
but instead resets the player even on "stop". My phone has software version 30.0.0.17.03 (no build date), his phone
has software version V11.02.11, build date 2017-04-26. You can get the software version by dialing *#0000#
Since the version is completely differently formatted, I suspect that it's a different OS altogether.</p>
<p>So be careful I guess, some phones with earlier software may not work as a podcast player. My advice is do buy
from a bricks-and-mortar store and check the software version before you give them your money.</p>
    </article></div>]]>
            </description>
            <link>http://prog.re/blog/2020-09-13.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460136</guid>
            <pubDate>Sun, 13 Sep 2020 11:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS is required to develop – no questions asked]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24460121">thread link</a>) | @metaralf
<br/>
September 13, 2020 | https://www.fanfario.com/post/1110-macos-is-required-to | <a href="https://web.archive.org/web/*/https://www.fanfario.com/post/1110-macos-is-required-to">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>My home setup consists of many operating systems. We are working in various fields, mainly creating business apps.</p><p>So, the technological landscape is pretty clear for me: I need</p><ol><li>Windows - because my clients have that most of the time</li><li>Linux - because the servers all run with it, especially the cloud ones</li><li>MacOS - because building iPhone apps needs it and the OS has significant market share (especially among those, who are willing to spend money on purchases)</li></ol><p>I was never fond of statements like "Mac is better than Windows", for me it is a different system with different things to know. It has a completely different architecture than Windows and that might makes it better for developers. But for the user, who is used to Windows stuff, it is just a hurdle to migrate.</p><p>As nerds we must embrace the diversity - in life and in technology.</p><p>I always hoped (after our early Atari/AMIGA feuds), that developers and sysadmins will overcome that "my system is better than yours" nonsense between systems.&nbsp;</p><p>In my opinion it is our task to make that stuff run as good as it can. I also think, if you promote only one system, you might just not know enough about the other.</p>        </div></div>]]>
            </description>
            <link>https://www.fanfario.com/post/1110-macos-is-required-to</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460121</guid>
            <pubDate>Sun, 13 Sep 2020 11:28:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a website to check performance of top websites in the world]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24459974">thread link</a>) | @1hakr
<br/>
September 13, 2020 | https://simpleops.io/websites | <a href="https://web.archive.org/web/*/https://simpleops.io/websites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://simpleops.io/websites</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459974</guid>
            <pubDate>Sun, 13 Sep 2020 10:50:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jugaad, an Indian Delivery Methodology]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24459888">thread link</a>) | @ggeorgovassilis
<br/>
September 13, 2020 | https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/ | <a href="https://web.archive.org/web/*/https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h2>Introduction</h2>



<p>Jugaad is an attitude towards delivery which originated in India and consists of three simple tenets:</p>



<ul><li>Humility: use whatever works without prejudice</li><li>Openness: keep your options open</li><li>Frugality: small expenses keep regrets small</li></ul>



<p>Jugaad is agility taken to the extreme and most suitable for projects with a high degree of change, risk and uncertainty. Nothing demonstrates the essence of jugaad better than the homonymous improvised vehicles built in India. All essential mechanical parts lay open and are easily accessible instead of being enclosed in casings. The vehicle can be assembled from commonly available, repurposed parts. It can be customised and extended to fit a variety of personal and professional needs, workloads and environments. The choice of parts can adapt the jugaad vehicle to different types of terrain, usage, fuel and availability of parts.</p>



<figure><img data-attachment-id="1737" data-permalink="https://blog.georgovassilis.com/olympus-digital-camera/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg" data-orig-size="1024,768" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.9&quot;,&quot;credit&quot;:&quot;Picasa 2.0&quot;,&quot;camera&quot;:&quot;X100,D540Z,C310Z&quot;,&quot;caption&quot;:&quot;OLYMPUS DIGITAL CAMERA&quot;,&quot;created_timestamp&quot;:&quot;-62169984000&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.8&quot;,&quot;iso&quot;:&quot;70&quot;,&quot;shutter_speed&quot;:&quot;0.003125&quot;,&quot;title&quot;:&quot;OLYMPUS DIGITAL CAMERA&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="OLYMPUS DIGITAL CAMERA" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=300" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=1024" src="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=1024" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg 1024w, https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=150 150w, https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=300 300w, https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>By Sanjaykattimani at English Wikipedia – Transferred from en.wikipedia to Commons by Liftarn using CommonsHelper., Public Domain, <a href="https://commons.wikimedia.org/w/index.php?curid=11937421" rel="nofollow">https://commons.wikimedia.org/w/index.php?curid=11937421</a></figcaption></figure>



<h2>Disclaimer</h2>



<p>This post is not the result of studying literature, most of which seems to have been written around the peek of the jugaad hype in 2010. It rather distils the experience of a decade working with delivery teams in India, what I learned from their approach to delivery and from being immersed in Indian corporate culture. Through large parts of this post it may seem that I advocate the adoption of jugaad and the abolition of other agile methods; the opposite is true – I will try to make the point that the wholistic approach of jugaad to solution design should be paired with the tactical discipline of a framework like agile or XP.</p>



<h2>The tenets work together</h2>



<p>The three tenets (Humility, Openness, Frugality) complement and contradict each other in a beautiful way: Humility <em>generates</em> options for a solution, openness <em>guides</em> and <em>combines</em> them and frugality <em>eliminates</em> them. Only solutions adhering to all three tenets are built in the jugaad spirit.</p>



<figure><img data-attachment-id="1741" data-permalink="https://blog.georgovassilis.com/options/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/options.png" data-orig-size="607,165" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="options" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/options.png?w=300" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/options.png?w=607" src="https://georgovassilis.files.wordpress.com/2020/09/options.png?w=607" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/options.png 607w, https://georgovassilis.files.wordpress.com/2020/09/options.png?w=150 150w, https://georgovassilis.files.wordpress.com/2020/09/options.png?w=300 300w" sizes="(max-width: 607px) 100vw, 607px"><figcaption>Tenets refine options</figcaption></figure>



<h2>Humility: use whatever works without prejudice</h2>



<p>Delivery methods like Waterfall, Scrum and XP wage religious wars over definitions (eg. what is the right sprint length?), processes (eg. degree of upfront planning), skills (eg. which framework should we use) and tools (eg. Maven or Gradle) all of which are more or less derivatives of adherence to a method. Jugaad replaces those definitions, processes, skills and tools with a central guidance: <em>be conscious about the shortcuts taken</em> with respect to the two other tenets. Jugaad frequently comes with a high degree of “out of the box” thinking and requires, for it to work, the humility to let go of technical and methodological preconceptions about what is the “appropriate” way and focus solely on the result.</p>



<p>Humility is the starting point in jugaad in that using “whatever works” generates a plethora of options. So how do we choose amongst these options? That is where Openness takes over.</p>



<h2>Openness: keep your options open</h2>



<p>The ostensible carelessness with which jugaad approaches delivery is built on the solid foundation of Openness. Whatever we build should be easy to extend, change or reverse. Openness often lacks elegance and conciseness, the inner workings of things are exposed, there is not much polish and one can see the parts a solution is made of – not to mention the security concerns arising from such solution. Just think of the jugaad vehicle we talked about earlier if you need a mental picture. But those trade-offs enable easily modifiable solutions and are exactly that: conscious trade-offs, not shortcomings. A solution which is open to change is a solid project or product foundation as it can adapt to unforeseen changes and doesn’t require much up-front design. Openness takes Humility’s options and guides them into coherent patterns. Not all options will form a good solution and not all combinations of options will work; Openness tells us which of them <em>might</em> work without losing an arm and a leg in the process of finding out.</p>



<h2>Frugality: small expenses keep regrets small</h2>



<p>Frugality is about risk management: reducing upfront costs <em>now </em>allows exploring more value propositions and solution approaches <em>now</em> while spending resources <em>later</em> on improving the solution. A low cost incurred early jeopardises a project less than a large cost incurred at the same time, especially if whatever that cost bought us turned out to be the wrong thing. Frugality is a holistic view on the patterns guided by Openness – it takes into consideration synergies between options and maximises value, both in terms of business value created for the solution (how many of the requirements were implemented at what effort) as well as value added to the project delivery (how much delivery and quality was improved, what was learned etc).</p>



<h2>Comparison by example</h2>



<p>Jugaad is illustrated best with a couple of examples which contrast traditional, “proper” design with improvised jugaad design.</p>



<h3>Example: receipt system</h3>



<p>Design a system that generates, stores and sends receipts via email to customers. Customer support should be able to retrieve receipts.</p>



<p>The traditional, “proper” solution:  we program a system that stores receipts in a relational database, generates receipt PDFs, stores those PDFs in the database, sends the PDFs to customers. We program a web interface for use by customer service which can query the database for receipts.</p>



<figure><img data-attachment-id="1742" data-permalink="https://blog.georgovassilis.com/traditional-solution/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png" data-orig-size="538,243" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="traditional-solution" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=300" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=538" src="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=538" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png 538w, https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=150 150w, https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=300 300w" sizes="(max-width: 538px) 100vw, 538px"><figcaption>The traditional solution has many custom built components</figcaption></figure>



<p>The jugaad-engineered solution: we program a system that generates HTML receipts, emails them to customers and BCCs a customer support email account with the same receipt. Customer support can use their email client to retrieve receipts. These components are either packaged and require no development effort (Customer support E-Mail client, E-Mail server), there a only few components and they are easy to implement.</p>



<figure><img data-attachment-id="1744" data-permalink="https://blog.georgovassilis.com/jugaad-solution/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png" data-orig-size="538,243" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="jugaad-solution" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=300" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=538" src="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=538" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png 538w, https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=150 150w, https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=300 300w" sizes="(max-width: 538px) 100vw, 538px"><figcaption>The jugaad solution has few, mostly packaged components</figcaption></figure>



<p>Let’s evaluate the jugaad-engineered solution against jugaad’s tenets and compare it with the “traditional” solution.</p>



<p>Humility: the design relies on packaged components which probably already exist and it only minimally invades the existing IT landscape. It reuses high quality packaged solutions (e-mail server, e-mail client) which may already exist in the organisation and reduces implementation tasks to e-mail server and e-mail client configurations. The traditional delivery method places several requirements on how the solution is built: it mandates formal APIs, probably a particular technology platform, a pre-defined method according to which components are structured (eg. SOLID), technical documentation and thorough test automation long before it is clear that the project will make it into production, but nevertheless increasing conceptional and real complexity of the solution and the delivery process and requiring an increased skill set for project participants. </p>



<p>Openness: the e-mail protocols between the application, e-mail servers and e-mail clients are well understood and extensible. Using E-Mail clients requires low to no training and the IT department probably maintains them already. The components themselves can be substituted without affecting much the rest of the solution; eg. a new field can be added to future receipts without modifying already issued receipts. Because many components can be operated by human agents (the e-mail server and e-mail clients), many new features and workarounds can be implemented as manual processes before coding and automating them into software. Since not much effort has been put at the initial stage into upfront design there isn’t much effort wasted when requirements change and implementations follow.</p>



<p>Frugality: the use of packaged components, especially when they are already familiar, reduces implementation effort and speeds up delivery at the cost of the finished product showing incongruities where different components interface.  New requirements needing larger changes can be implemented by exchanging existing components for components better fitting the requirements or even rewriting them from scratch, if needed. In many cases the early progress made thanks to the low initial effort should more than make up for the higher, later cost. The traditional solution contrasts badly with jugaad in terms of effort. For example, it will mandate a particular API design such as a REST API for the receipt generator and receipt retrieval or even a REST API between the receipt generator and the email server, because… principles. Technical documentation will be written for the components long before it is clear that the project will ever go live, not considering that any effort spent on non-value adding features jeopardises a go-live. And last not least unit tests will be written to achieve an arbitrarily agreed upon test coverage before it is clear that they generate business value eg. by catching regressions. The jugaad-engineered solution will produce formal APIs, documentation and test automation when their added value outweighs the implementation effort.</p>



<h2>Contrast with agile</h2>



<p>Jugaad has no processes like Scrum or XP. It talks about the values worth striving for. It doesn’t talk about velocity or quality; even the focus on low cost introduces the discipline to achieving openness, thus being able to revisit a previously built solution. Agile highlights <em>reactiveness</em>, it’s main point being the ability to react to unforeseen changes, but it uses a predefined process such as Scrum or Kanban. The process must adapt to organisational changes or changing skill sets. Jugaad does not dictate any delivery process, so in a way it is orthogonal to existing agile practices. By adding formalised steps to it, a mature jugaad practice may evolve into Scrum or Kanban if that seems useful.</p>



<p>But jugaad is not about agile without …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/">https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/</a></em></p>]]>
            </description>
            <link>https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459888</guid>
            <pubDate>Sun, 13 Sep 2020 10:31:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paddle of the Century]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24459886">thread link</a>) | @goodcanadian
<br/>
September 13, 2020 | https://www.cbc.ca/radiointeractives/paddle | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radiointeractives/paddle">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<!--
==		SECTION 1
==		START OF TRIP "Setting Off"
==		Winnipeg
==
==
-->
<section id="journey-start">


				<p>Don Starkell wasn't the kind of guy to shy away from improbable odds. So when people told him his dream of paddling a canoe from Winnipeg to the Amazon was impossible, it fuelled his determination to do it.
				</p>
				<p>The epic trip would stretch nearly 20,000 kilometres, through 13 countries, and would include life-threatening tropical storms, fierce waves and a near-execution in Honduras.</p>
				
					<figure id="figure1">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/14-1984-Don-Bike-to-Coast-1.jpg" alt="" id="image1">
					<figcaption> Don on a bike trip from Winnipeg to Nova Scotia in 1984. (Rhonda Rich/Submitted by Dana Starkell)
					</figcaption>
				</figure> 
				<p>“If we’d known what lay ahead,” Don wrote years later, “we certainly would not have gone.”</p>
				<p>Against all odds, Don and his son Dana would complete the trip in just under two years, setting a Guinness World Record for the longest canoe trip ever taken.</p>
				


</section>
<!--
==		SECTION 2
==		Setting Off "Paddling Down the Mississippi River"
==		Mississippi River
==
==
-->

			<section id="setting-off">
<h2><span>Setting off</span></h2>
			<p>Don started talking about the canoe trip 10 years before it actually began.</p>
<p>During visits to a local library, Dana remembers him poring over the histories of people who had travelled portions of the proposed trek.</p>

<p><a href="https://www.cbc.ca/archives/entry/the-longest-canoe-trip-ever">CBC Archives: The Longest Canoe Trip Ever</a></p>

<p>“It's just a matter of putting it together,” he remembered his father saying.</p>
<p>Don was already a seasoned — and decorated — canoeist. He'd been paddling since he was in his teens and was a member of the winning team in the 1967 Centennial Voyageur Canoe Pageant — a 104-day race that stretched from Rocky Mountain House, Alta., to Montreal.</p>
				<figure id="figure2">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/don-dana-jeff-1.jpg" alt="" id="image2">
					<figcaption>Don with his young sons Dana, left, and Jeff, right, around the time he first began talking to them about paddling to the Amazon. (Submitted by Dana Starkell)
					</figcaption>
				</figure>

<p>The long trip was the perfect opportunity for Dana to hone his musical skills. He brought his guitar along to play when he wasn't paddling.</p>
<p>His younger brother, Jeff, wasn't so lucky; his passions — electronics and engineering — were less beach-friendly. He’d have to put his studies on hold.</p>
<p>Nevertheless, the Starkell family pushed off from the beach on Winnipeg's Red River with Dana, 19, and Jeff, 18, in the <em>Orellana</em>, their custom-built fibreglass canoe, on June 1, 1980 — a Canadian flag proudly declaring their origins.</p>

				<figure id="figure3">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/2-011-06.01.jpg" alt="" id="image3">
					<figcaption>Departure day. From left, Don, Dana and Jeff prepare for takeoff from the banks of the Red River in Winnipeg. (Submitted by Dana Starkell)
					</figcaption>
				</figure>
<p>Most days, it went about like any other camping trip. Dana, being larger than Jeff, would sit at the front of the boat, with Jeff behind him and their father at the rear.</p>
<p>Don kept a journal throughout the trip. It would form the basis of his 1987 memoir, <em>Paddle to the Amazon.</em></p>
<p>“The Mississippi has been good to us, and we feel none of the resentment toward it that we felt toward the Red,” he wrote on July 31. “We do have our little hardships: warm drinking water, Mississippi sand in everything, and of course the heat.”</p>
			</section>
			
<!--
==		SECTION 3
==		The Pancake Incident 
==		NEW ORLEANS
==
==
-->	
			<section>
			<div id="the-pancake-incident">
				<h2><span>The pancake incident</span></h2>
				<p>Their travels through the U.S. waterways were mostly peaceful. But even though everything generally went well, after months on the water, tensions began developing among the trio.</p>
<p>Jeff recalled Dana and his dad scrapping over a single pancake that wasn’t split into perfectly even thirds.</p>

				<figure id="figure4">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/ND-us.jpg" alt="" id="image4">
					<figcaption>Don, Jeff and Dana on the Red River in North Dakota. (Submitted by Jeff Starkell)
					</figcaption>
				</figure>

<p>“Dana grabbed the pancake, and then my dad kinda grabbed him in a big bear hug and smothered him down to the ground to kind of settle them down.”</p>				
<p>Don recorded other tense moments in his journal.</p>
<p>“I’ve been trying so hard not to be bossy that we’ve now got three captains in the boat, each with a mind of his own. It’s a problem, and I’m going to have to be a little less democratic,” he wrote on Aug. 18.</p>
<p>“If I go too far, however, I’ll have a mutiny on my hands. I need my crew — need everything they can give me.”</p>
</div>
			</section>
			
			<!--
==		SECTION 4
==		Leaving the Intracoastal Waterway "D-DAY"
==		PORT ISABEL
==
==
-->
		
			<section id="d-day">
				<h2><span>‘D-Day’</span></h2>
				<p>In his journal, Don called Sept. 20, 1980 “D-Day,” when they planned to leave the protection of the Intracoastal Waterway near Port Isabel, Texas, and head out into the open sea, eventually crossing into Mexican waters.</p>
<p>Don assured his sons that as long as they followed his instructions, everything would be fine. The harsh currents resulting from the Waterway meeting the Gulf of Mexico had other ideas.</p>
<p>“Our first attempts to launch? I mean, it was a total disaster. We had no idea what we were doing,” Dana said.</p>


				<figure id="figure5">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/3-Leaving-Wpg.jpg" alt="" id="image5">
					<figcaption>Don, Dana and Jeff on Day 1, on the Red River Floodway. (Submitted by Dana Starkell)
					</figcaption>
				</figure>
	<p>It took multiple attempts to make even minor headway without their canoe getting filled with water. Eventually, they realized they just had to paddle forward and that getting semi-swamped was just part of the process.</p>
			</section>

<!--
==		SECTION 5
==		Rough Waters ???
==		Playa Washington
==		(Deleted)
==
-->

<!--
==		SECTION 6
==		Stuck in Muddy Lagoon "Jeff Leaves"
==		Laguna Madre 
==
==
-->

			<section>
			<div id="jeff-leaves">
				<h2><span>Jeff leaves</span></h2>
<p>Rough waters made the next steps even more difficult. On Sept. 30, Don wrote in his journal that after 10 days of fighting the relentless currents, they managed to progress little more than three kilometres.</p>
<p>Things got worse when they hit the Laguna Madre, a long stretch of water that runs inland along Mexico’s coast. Jeff recalls they entered it at a double — both daily and monthly — high tide. They thought it was enough to take them down the coast, but it soon dried up.</p>
<p>“The next thing you know, we’re in the middle of this lagoon, a mile on either side of us mud,” Dana recalled.</p>

</div>

<!--
==		SECTION 7
==		Settling in for a while
==		Veracruz, Mexico
==
==
--> 
<div id="settling-veracruz">
<p>The three decided they would settle in the Mexican port city of Veracruz for the winter to re-evaluate if and when they could continue.</p>
<p>Dana still had his guitar to pass the time. But Jeff saw little reason to put his career aspirations on indefinite hold. So he decided to return home and enrol in engineering school.</p>
				<figure id="figure6">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/6-02.27.jpg" alt="" id="image6">
					<figcaption>Dana practises guitar on a beach in Tampico, Mexico. (Submitted by Dana Starkell)
					</figcaption>
				</figure>
				
<p>“It wasn’t an easy decision for me. I felt like I was letting them down to some extent,” Jeff said.</p>
<p>“But on the other hand, you only have one life, and you sort of have to live it the way you want to live it.”</p>
</div>
</section>



<!--
==		SECTION 8
==		Tropical Storm Arlene
==		Colson Cays (Belize)
==
==
-->

			<section id="arlene">
			<h2><span>Tropical storm Arlene</span></h2>
<p>By February 1981, the Gulf had calmed enough for Don and Dana set off again — with nearly 14,000 kilometres left to go.</p>
<p>After crossing from Mexico into Belize, they enjoyed a peaceful stretch along the Colson Cays in Belize. But that calmness was violently shattered by tropical storm Arlene, which barrelled down on them just as they took shelter in a fishing shack.</p>
				<figure id="figure7">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/7-S125-Venuzuela-Coast.jpg" alt="" id="image7">
					<figcaption>Dana and Don off the coast of Venezuela. (Submitted by Dana Starkell)
					</figcaption>
				</figure>
				
<p>All night, the wind and waves tore at the flimsy plywood walls of the shack. Don and Dana were certain it would be ripped from its moorings and they would be flung out to sea.</p>
<p>But somehow they survived the night. Even more surprising, so did their canoe. Don had tied it to posts driven into the sharp coral bank the night before. Incredibly, it suffered no damage.</p>
<p>“As we packed and retarped,” Don wrote in his journal, “we kept saying to one another, 'It’s a miracle.'”</p>
			</section>

<!--
==		SECTION 9
==		Held at Gunpoint 
==		Laguna De Caratasca (Honduras)
==
==
-->	
			<section id="held-at-gunpoint">
				<h2><span>Gunpoint in Honduras</span></h2>
			<p>On May 24, with their water supplies dwindling, Don and Dana stumbled on a small coconut plantation on the Laguna de Caratasca, which runs just inside the Honduran coastline.</p>
<p>Upon pulling into shore, they struck up a conversation with two women who agreed to cook them some food.</p>
<p>Don was filling their canteens with fresh coconut water when two men approached them — one of them brandishing a shotgun.</p>
<p>"They walk right up to us and the guy levels this shotgun at us, raises it slightly overhead, blows it off just to show us they weren't fooling around and then ordered us down to our canoe," Dana said.</p>

				<figure id="figure8">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/12-S225-Rio-Negro.jpg" alt="" id="image8">
					<figcaption>Dana on the Rio Negro, in Venezuela. (Submitted by Dana Starkell)
					</figcaption>
				</figure>
<p>The rogue soldiers ransacked the canoe, then ordered Don and Dana to start marching.</p>
<p>“They stopped a few times to shoot us, but every time … some people would come along down this road,” Dana said.</p>
<p>“At that stage of the trip, my dad is thinking like, you know, we're not getting out of this. These guys are going to kill us.”</p>
<p>Eventually, the men dropped Don and Dana off at a military base, leaving the duo puzzled over why their lives were spared.</p>
<p>The next morning, just before they were released and returned to their canoe, the women they had met earlier showed up in tears at the military base.</p>
<p>“It was those two ladies that we met that saved us. They told [one of the soldiers] that if they killed us, they were going to report him. And those guys could have turned around and put bullets through their heads,” Dana explained. “Just as easy.”</p>

			</section>

<!--
==		SECTION 10
==		Montage
==		Nicaragua, CR,Pan,Col,Ven.Trinidad
==
==
-->			
			<section>
			<h2><span>Long stretch</span></h2>
<div id="long-stretch">			
			<p>Nearly a year after leaving Winnipeg, Don and Dana had paddled through six countries — Canada, the U.S., Mexico, Belize, Guatemala and Honduras — with seven still to go: Nicaragua, Costa Rica, Panama, Colombia, Venezuela, Trinidad and Tobago and finally Brazil.</p>




<p>Sometimes, Dana was able to break the ice with strangers in towns along the way by playing his guitar.</p>
<p>But other times, Dana and his father adopted a “survival mode,” growing into their now-haggard appearances to scare off would-be aggressors.</p>

				<figure id="figure9">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/10-Puerto-Ayacucho.jpg" alt="" id="image9">
					<figcaption>Dana making friends in Puerto Ayacucho, Venezuela, on the Orinoco River. (Submitted by Dana Starkell)
					</figcaption>
				</figure>

<p>“The way we thought at the time was just to kind of look at somebody in such a way to say to them: If they bothered us, we would kill 'em,” Dana said.</p>
<p>By Dana’s recollection, they had at least 13 encounters with people who threatened them at gunpoint. But nothing came as close to disaster as the Honduras incident.</p>
</div>

<!--
==		SECTION 11
==		Final Destination
==		Belem Brazil
==
==
-->	

<div id="final-destination">
<p>Finally, on May 1, 1982, the father-son duo paddled into the port of Bélem, Brazil — where the Amazon meets the Atlantic. It marked the end of a 23-month journey covering nearly 20,000 kilometres from Winnipeg's Red River.</p>
				<figure id="figure10">
					<img src="https://www.cbc.ca/radiointeractives/content/paddle/images/8-portofspain-trinidad-01.jpg" alt="" id="image10">
					<figcaption>Don and Dana arrive in Port of Spain, Trinidad and Tobago. (Submitted by Dana Starkell)
					</figcaption>
				</figure>

<p>Dana remembers his father talking about going even further down the Rio de la Plata to Argentina, despite everything they had …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/radiointeractives/paddle">https://www.cbc.ca/radiointeractives/paddle</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/radiointeractives/paddle</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459886</guid>
            <pubDate>Sun, 13 Sep 2020 10:31:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cel7 – a 60kb framework for making grid-based ASCII games]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24459860">thread link</a>) | @rxi
<br/>
September 13, 2020 | https://rxi.itch.io/cel7 | <a href="https://web.archive.org/web/*/https://rxi.itch.io/cel7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>cel7</strong> is a 60kb framework for making grid-based games limited to 4-bit color ASCII output. The framework is based around the <a href="https://github.com/rxi/fe" target="_blank" rel="nofollow noopener">fe</a> programming language.<br></p>
<p><img src="https://img.itch.zone/aW1nLzM4NDE0MTEuZ2lm/original/f8AnhL.gif"><br></p>
<p>To run a game simply pass the game's code file(s) as a command-line argument or drag a game file onto the executable. Your game file(s) can be appended to the end of the executable to create a self-contained single-file game.</p>
<hr>
<pre>config
------------------------------------------------------------------------
(= title "Game Title")   : window title
(= width 16)             : width in characters
(= height 16)            : height in characters
(= debug nil)            : set if `-debug` was passed to executable
 
 
callbacks
------------------------------------------------------------------------
(= init (fn () ...))     : called after graphics have been initialized
(= step (fn () ...))     : called every frame
(= keydown (fn (k) ...)) : called when a key is pressed
(= keyup (fn (k) ...))   : called when a key is released
 
 
functions
------------------------------------------------------------------------
(// a b)                 : integer divide
(% a b)                  : modulus
(quit)                   : exits the application
(rand n)                 : returns a random number between 0 and n
(poke addr byte)         : sets byte in memory
(peek addr)              : gets byte from memory
(poke addr string)       : sets string in memory
(peek addr n)            : gets n bytes from memory as a string
(color clr)              : sets color for subsequent draw operations
(put x y ...)            : places text at [x, y]
(get x y)                : returns the character at [x, y]
(fill x y w h chr)       : sets the characters in the rectangle to chr
 
fe language reference:
https://github.com/rxi/fe/blob/master/doc/lang.md
 
 
memory addresses
------------------------------------------------------------------------
0x0000                   : unused
0x4000                   : color palette
0x4040                   : font atlas (96x7x7 bytes)
0x52a0                   : screen buffer
</pre>
</div></div>]]>
            </description>
            <link>https://rxi.itch.io/cel7</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459860</guid>
            <pubDate>Sun, 13 Sep 2020 10:27:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use AWS Developer Tools with AWS SSO?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24459837">thread link</a>) | @nikovirtala
<br/>
September 13, 2020 | https://www.cloudgardener.dev/how-to-use-aws-developer-tools-with-aws-sso/ | <a href="https://web.archive.org/web/*/https://www.cloudgardener.dev/how-to-use-aws-developer-tools-with-aws-sso/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>September 12, 2020</p></header><section><p><span>
      <a href="https://www.cloudgardener.dev/static/18a176e4256024dec93f1d59fafc3aa7/0f98f/key.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="the key" title="the key" src="https://www.cloudgardener.dev/static/18a176e4256024dec93f1d59fafc3aa7/1c72d/key.jpg" srcset="https://www.cloudgardener.dev/static/18a176e4256024dec93f1d59fafc3aa7/a80bd/key.jpg 148w,
https://www.cloudgardener.dev/static/18a176e4256024dec93f1d59fafc3aa7/1c91a/key.jpg 295w,
https://www.cloudgardener.dev/static/18a176e4256024dec93f1d59fafc3aa7/1c72d/key.jpg 590w,
https://www.cloudgardener.dev/static/18a176e4256024dec93f1d59fafc3aa7/a8a14/key.jpg 885w,
https://www.cloudgardener.dev/static/18a176e4256024dec93f1d59fafc3aa7/fbd2c/key.jpg 1180w,
https://www.cloudgardener.dev/static/18a176e4256024dec93f1d59fafc3aa7/0f98f/key.jpg 1920w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>What I cannot create, I do not understand. ― Richard P. Feynman</p>
</blockquote>
<p>As multi-account AWS architectures have become more common, there has also been a need to implement centralized user and access management. The AWS solution to this problem is AWS SSO, which is indeed a neat solution, but …</p>
<p>Many popular developer tools, including AWS’ own CDK (Cloud Development Kit) and Amplify, do not support it yet, as we can find from the GitHub issues:</p>
<ul>
<li><a href="https://github.com/aws/aws-cdk/issues/5455">AWS SSO Named Profiles Support</a></li>
<li><a href="https://github.com/aws-amplify/amplify-cli/issues/4488">Problem using CLI via AWS SSO</a></li>
</ul>
<p>As usual, the best answer to these problems can be found on Twitter, so also this time. <a href="https://twitter.com/nikovirtala/status/1304308556083200006">I complained about the issue</a>, and very soon, I had the best solution so far in my hands!</p>
<p><a href="https://twitter.com/ben11kehoe">Ben Kehoe</a> has written two nice helper tools to go around the problem:</p>
<ul>
<li><a href="https://github.com/benkehoe/aws-sso-credential-process">benkehoe/aws-sso-credential-process</a></li>
<li><a href="https://github.com/benkehoe/aws-export-credentials">benkehoe/aws-export-credentials</a></li>
</ul>
<p>And <a href="https://twitter.com/ShortJared">Jared Short</a> came up with a little helper function, which will nicely tie the whole process together.</p>
<p>So, what do I need to do?</p>
<ol>
<li>Install the two tools; <a href="https://github.com/benkehoe/aws-sso-credential-process">aws-sso-credential-process</a> and <a href="https://github.com/benkehoe/aws-export-credentials">aws-export-credentials</a></li>
<li>Place following to your <code>.bashrc</code>, <code>.zshrc</code> or similar: <em>– Don’t forget to replace the start URL and region values.</em></li>
</ol>
<div data-language="bash"><pre><code><span>export</span> <span>AWS_CONFIGURE_SSO_DEFAULT_SSO_START_URL</span><span>=</span>https://<span>&lt;</span>your-sso<span>&gt;</span>.awsapps.com/start
<span>export</span> <span>AWS_CONFIGURE_SSO_DEFAULT_SSO_REGION</span><span>=</span><span>&lt;</span>your-default-region<span>&gt;</span>

<span>sso</span><span>(</span><span>)</span><span>{</span>
  <span>unset</span> AWS_PROFILE
  <span>export</span> <span>AWS_PROFILE</span><span>=</span><span>$1</span>
  aws sts get-caller-identity <span>&amp;&gt;</span> /dev/null <span>\</span>
  <span>||</span> aws sso login <span>\</span>
  <span>||</span> <span>(</span>unset AWS_PROFILE <span>&amp;&amp;</span> aws-configure-sso-profile --profile<span>)</span>
  <span>eval</span> <span><span>$(</span>aws-export-credentials --env-export<span>)</span></span>
<span>}</span></code></pre></div>
<ol start="3">
<li>Source your profile, run <code>sso</code>, and off you go! – The helper tools will configure your shell with credentials that most of the tools can understand, even they wouldn’t support AWS SSO yet.</li>
</ol></section><hr></article></div>]]>
            </description>
            <link>https://www.cloudgardener.dev/how-to-use-aws-developer-tools-with-aws-sso/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459837</guid>
            <pubDate>Sun, 13 Sep 2020 10:22:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fasciculations in Amyotrophic Lateral Sclerosis]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24459762">thread link</a>) | @JPLeRouzic
<br/>
September 13, 2020 | https://padiracinnovation.org/News/2020/09/fasciculations-in-amyotrophic-lateral-sclerosis | <a href="https://web.archive.org/web/*/https://padiracinnovation.org/News/2020/09/fasciculations-in-amyotrophic-lateral-sclerosis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">                                   
                    <p>James A. Bashford and colleagues <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7425399/"><strong>aimed to identify a novel quantitative biomarker related to fasciculations</strong></a> that could monitor patients with amyotrophic lateral sclerosis over time.</p>

<p>Fasciculations are a hallmark of amyotrophic lateral sclerosis. Their presence precedes the onset of muscle weakness. However benign fasciculation syndrome is not considered a prodrome of amyotrophic lateral sclerosis.</p>

<p>The authors have recently developed Surface Potential Quantification Engine (SPiQE), which is an automated analytical tool designed to detect and characterize fasciculation potentials from resting high-density surface electromyography. SPiQE is capable of analysing 30-min recordings, producing simple outputs related to fasciculation frequency, amplitude, inter-fasciculation intervals and data quality. SPiQE’s analytical pipeline achieved a classification accuracy of 88% when applied to 5318 fasciculation potentials that had been identified manually.</p>

<p><img src="https://backyardbrains.com/experiments/img/Hand_Motor_Units_web.jpg" width="400">
<em>Source: <a href="https://backyardbrains.com/">https://backyardbrains.com/</a></em></p>

<p>A motor unit comprises the motor neuron cell body, axon, terminal branches and connecting muscle fibres. Amyotrophic lateral sclerosis leads to a process called chronic partial denervation. This means that as motor units succumb to the disease and die, surviving motor units are instructed to sprout and branch to reinnervate orphaned muscles fibres.</p>

<p>This is an evolutionary, compensatory mechanism designed to maintain muscle power in the face of a reduced motor unit pool. In amyotrophic lateral sclerosis, a reinnervating motor unit steadily acquires new muscle fibres and consequently produces motor unit action potentials of larger amplitude, longer duration and greater complexity.</p>

<p>However, due to the relentless loss of motor units in amyotrophic lateral sclerosis, this process of reinnervation cannot maintain muscle strength indefinitely. A saturation point is reached and muscle fibres consequently atrophy, leading swiftly to clinical weakness. By assessing fasciculation amplitude serially as a surrogate of this reinnervation process, the scientists hoped to gain insight into this process.</p>

<p>It had been suggested that motor unit firing pattern is evidence for motoneuronal or axonal fasciculations; namely interspike intervals of approximately 5&nbsp;ms (doublet intervals) provide evidence for the axonal firing. Fasciculation doublets have been shown to occur in biceps brachii, vastus lateralis and tibialis anterior from patients with amyotrophic lateral sclerosis, as well as the gastrocnemius (along with the soleus muscle, the gastrocnemius forms half of the calf muscle) from both patients with amyotrophic lateral sclerosis and benign fasciculation syndrome.</p>

<p>Fasciculation doublets are defined as the occurrence of two almost identical motor unit potentials, presumed to both arise from the same motor unit, with a very short IFI of &lt;100 ms. Shorter inter-fasciculation intervals (5–10 ms) are likely to arise distally in the terminal branches, whereas longer inter-fasciculation intervals (40–80 ms) are thought to originate proximally at the soma.</p>

<p>Faced with the low occurrence rate of doublets during electrical stimulation, the scientists hypothesized that collection of vast numbers of fasciculations would be required to observe IFI peaks in these ranges. In turn, this might help to elucidate the origin of fasciculations in amyotrophic lateral sclerosis.</p>

<p>So in this study, Bashford and colleagues compared amyotrophic lateral sclerosis patients with control subjects who have benign fasciculation syndrome, a condition that is defined by the isolated presence of fasciculations, particularly in muscles of the lower limbs, without evidence of underlying motor neuron degeneration</p>

<p>Twenty patients with amyotrophic lateral sclerosis and five patients with benign fasciculation syndrome each underwent up to seven assessments at intervals of 2 months 
A total of 420 (210 biceps, 210 gastrocnemius) amyotrophic lateral sclerosis and 116 (58 biceps, 58 gastrocnemius) benign fasciculation syndrome recordings were analyzed. Ten biceps recordings from two patients with amyotrophic lateral sclerosis were excluded due to contamination from a Parkinsonian resting tremor</p>

<p>The scientists tested whether the presence of muscle weakness in patients with amyotrophic lateral sclerosis influenced the change in fasciculation frequency over time. The scientists divided the data into strong and weak muscles. The scientists divided each muscle into pre-weakness, peri-weakness and post-weakness groups. This allowed them to assess the chronology of disease by equating these groups to early, middle and late stages of disease, respectively. This was only possible due to the anatomical specificity of the high-density surface electromyography technique, which is a major strength in this setting.</p>

<p>For biceps, fasciculation frequency in strong amyotrophic lateral sclerosis muscles was 10× greater than the benign fasciculation syndrome baseline, while fasciculation frequency in weak muscles started at levels 40× greater than the benign fasciculation syndrome baseline. Over the 14 months of the study, fasciculation frequency decreased in weak muscles at a rate three times faster than average. This supported the suspicion of the authors that biceps fasciculation frequency was non-linear, first rising steadily from a pre-morbid baseline in strong muscles and subsequently falling as weakness ensued.</p>

<p>Given that there was no significant change in biceps fasciculation frequency over the 14 months of the study in strong amyotrophic lateral sclerosis muscles, Bashford and colleagues hypothesize that the rising phase is slow, perhaps starting many years before clinical weakness. In contrast to biceps, gastrocnemius demonstrated a significant decline in fasciculation frequency in strong muscles, but plateaued in weak muscles.</p>

<p>The most striking implication from these results was the rise and subsequent fall of fasciculation frequency in amyotrophic lateral sclerosis biceps muscles. This non-linear pattern had been previously suggested after statistically modelling fasciculation counts using muscle ultrasound and might explain why a previous surface EMG study of fasciculation frequency did not show a significant linear change over time.</p>

<p>The scientists hypothesize that the two main contributing factors to fasciculation frequency are the size of the affected motor unit pool and the relative degree of hyperexcitability. The size of the viable motor unit pool declines over time in biceps muscles, even while muscles remained strong (albeit at a slower rate than weak muscles). 
However, it remains unknown what proportion of motor units are affected (and therefore hyperexcitable) at a given stage of the disease.</p>

<p>The decline in fasciculation frequency can be attributed to the relentlessly shrinking motor unit pool. The picture above highlight the proposed model of the interactions between muscle power, size of viable motor unit pool (as assessed by MUNIX) and fasciculation frequency in benign fasciculation syndrome and three stages of disease in amyotrophic lateral sclerosis.</p>

<p><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7425399/bin/EMS94304-f006.jpg" width="600"></p>

<p>The diagrams depict the dynamic changes in motor unit architecture and relative hyperexcitability (depicted by electric bolts) as a consequence of motor neuron degeneration and motor unit loss.</p>

<p>In benign fasciculation syndrome, there is global hyperexcitability affecting all motor units to a similar degree in the absence of motor neuron degeneration.</p>

<p>In early amyotrophic lateral sclerosis, a subset of motor units are hyperexcitable, motor unit loss has begun and mild–moderate compensatory reinnervation has occurred. Due to the stability of biceps fasciculation frequency in strong muscles over 14 months (at a firing rate ~10 greater than the benign fasciculation syndrome baseline), the rising phase is hypothesized to begin many years before muscle weakness first appears.</p>

<p>It is postulated that towards the latter end of the rising phase, the rate of increase in fasciculation frequency speeds up, so that by the onset of weakness, fasciculation frequency is ~40 the benign fasciculation syndrome baseline.</p>

<p>In the middle stage, the ongoing loss of motor units has promoted extensive re-innervation of surviving motor units, which then become hyperexcitable themselves. This compensatory mechanism leads to fasciculations of greater amplitude and allows muscles to remain strong by staving off muscular atrophy.</p>

<p>However, as a tipping point is reached, these compensatory mechanisms saturate, leading to the onset of muscle atrophy and weakness.</p>

<p>In late amyotrophic lateral sclerosis, the death of the most re-innervated motor units leads to worsening muscle atrophy and weakness. The relentless loss of motor units drives the falling fasciculation frequency. Evidence of doublets with inter-fasciculation intervals in the 20–80 ms range is consistent with the period of motor unit subtypes (fast-slow), supporting a proximal origin of fasciculations at the soma. Throughout all stages of amyotrophic lateral sclerosis and in benign fasciculation syndrome, the degree of hyperexcitability of the lower motor neuron is likely to be driven and/or influenced by descending corticospinal inputs.</p>

<h3><u>Advertisement</u></h3>
<p><a href="https://www.amazon.com/dp/1698147899">
<img src="https://images-na.ssl-images-amazon.com/images/I/51pNZDKvmIL._SX331_BO1,204,203,200_.jpg" width="200">
<br>
This book retraces the main achievements of ALS research over the last 30 years, presents the drugs under clinical trial, as well as ongoing research on future treatments likely to be able stop the disease in a few years and to provide a complete cure in a decade or two.<br>
</a></p>
                </div></div>]]>
            </description>
            <link>https://padiracinnovation.org/News/2020/09/fasciculations-in-amyotrophic-lateral-sclerosis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459762</guid>
            <pubDate>Sun, 13 Sep 2020 10:05:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not all engineering leaders are engineering managers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24459636">thread link</a>) | @adrianhoward
<br/>
September 13, 2020 | https://leaddev.com/not-all-engineering-leaders-are-engineering-managers | <a href="https://web.archive.org/web/*/https://leaddev.com/not-all-engineering-leaders-are-engineering-managers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Management should not be the only option for engineering advancement, or even the default one. So how can we support our leading engineers to follow the career path that they truly want?</p><div>
<div>
<div> <p>Great managers make great teams, and organisations are rightfully eager to find engineers with manager potential. But management should not be the default career path for engineers. Many of the "leadership" skills that make for good managers (e.g. setting a clear direction, caring about other humans, understanding the business, building consensus, communicating ideas) are also the ones that make&nbsp;<em>stellar</em>&nbsp;senior, staff, and principal engineers. If we require these skills at senior engineering levels, we'll boost our ability to complete difficult projects, make better technical decisions, and bring up the skill level of our whole engineering organisation.&nbsp;</p>

<p>While career progression for a software engineer often involves management, many companies provide a parallel 'technical track': a job ladder for engineers who want to continue to focus on their technical skills.&nbsp;</p>
<p>There are many variants of this career path, but a common one is a&nbsp;<em>senior engineer</em>&nbsp;getting promoted to&nbsp;<em>staff engineer,&nbsp;</em>and then to&nbsp;<em>principal engineer</em>.&nbsp;</p>
<p>Just as on the management track, seniority on the technical track reflects the&nbsp;<em>impact&nbsp;</em>of the role i.e. how much more successful they made the engineering team or the business as a whole. However unlike the management track, this impact is usually achieved without direct authority. While some folks do straddle the line between engineer and manager, staff and principal engineers typically don't have a team of reports who can be deployed to solve problems. This doesn't mean that they work alone though.&nbsp;</p>

<p>The technical track is often called the 'individual contributor' track, but few senior engineers should be true individual contributors. Most should be responsible for clear improvement across their team or organisation.&nbsp;</p>
<p>This improvement comes from creating compelling&nbsp;<strong>technical strategy</strong>,&nbsp;<strong>executing on projects</strong>&nbsp;that wouldn't have succeeded otherwise, and&nbsp;<strong>influencing other engineers</strong>&nbsp;to do their best work. I believe that these three axes are how we can describe success for senior roles on the technical track.</p>
<h2>Strategy</h2>
<p>It's easy for software engineers to focus on immediate problems. Our most senior engineers should be able to see beyond those immediate needs and prepare for future needs too. By staff level, an engineer should be planning at least a year ahead: understanding how technical changes now (or staying with the status quo) will affect the team then. This means always having a ton of technical, business and industry context, and using that knowledge to predict risks, opportunities, scaling cliffs, and so on. When the way forward is too ambiguous, they should notice which decisions are being avoided and either chase down consensus or make a compelling case for a particular technical direction.</p>
<h2>Execution</h2>
<p>Our senior engineers most likely got to their role because they're skilled at executing and completing projects. By staff level, they should be able to lead projects that are too broad, ambiguous or contentious for most engineers to tackle. Engineers leading these projects will use a mix of technical and organisational skills. They need to have enough time and mental bandwidth to dig into the details and make big decisions, enough self-confidence to ask the 'obvious' questions that will shake out misunderstandings, and enough organisational clout to influence the technical direction of multiple teams without stomping on their autonomy.&nbsp;</p>
<h2>Good influence</h2>
<p>We learn from our own mistakes and successes, but each of us only has a finite number of our own projects to reflect on. We need to learn from each other's mistakes and successes too. Our most senior engineers have&nbsp;<em>seen some things&nbsp;</em>and likely broken some things too, and those experiences shouldn't go to waste. Staff engineers can set explicit standards for their organisations, for example by creating guidelines and best practices, by leaving thoughtful comments on code and documents, and by having a high bar for what gets deployed. But they also set implicit cultural norms through their own output. Managers can bang the drum for quality, but if the most senior engineers don't write tests then you'll never convince the juniors to do it.&nbsp;</p>
<p>These three aspects of a stellar senior engineer (strategy, execution and good influence) all need skills that we often recognise as "management" material. The good strategic ideas, the project solutions and the thorough reviews will carry little weight if they're not communicated clearly or if nobody is convinced to follow them. Without the ability to build consensus across teams, we'll choose solutions that may be optimal inside a single team but don't interoperate well, or that duplicate effort. Without business context, engineers will make flawed technical decisions or will waste their time working on something with little value. Without empathy for other humans, review comments may reduce the confidence of junior engineers instead of boosting their skills.&nbsp;</p>
<p>Of course all this work needs technical depth and technical judgement too. We want our strategies to be sound, our project solutions to actually solve the problems, and our review comments to make code and designs better. But technical knowledge is not enough on its own. Impact at this level means being a force multiplier.&nbsp;</p>
<h2>Not just for extroverts</h2>
<p>I want to be clear that I'm not saying all staff and principal engineers need to be "people people". Influence doesn't have to be loud or extroverted. Leadership can come from designing "happy path" solutions that protect other engineers from common mistakes. It can come from reviewing other engineers' code and designs in a way that improves their confidence and skills, or highlighting design proposals that don't have a genuine business need. I've seen excellent staff engineers who would never describe themselves as leaders but who raise everyone's game as they quietly set the direction for their technical area.&nbsp;</p>
<p>It's possible for engineers who prefer to work alone to still make the organisation better through their judgement and good influence. There are a lot of ways to have impact. But contrast those folks with senior engineers who make the people around them&nbsp;<em>worse</em>. No matter what their output is, it's hard to imagine how they can have enough impact to compensate for the reduced output and growth of other engineers, the effects on employee retention, and the projects that will fail as a result of their unwillingness to collaborate across teams.&nbsp; We set ourselves up to fail if we promote this kind of engineer to a level where they'll be seen as an exemplar.</p>

<p>If we recognise the need for leadership attributes in our most senior engineers, we should cultivate those skills. That means hiring and promoting for the skills we want, finding engineers opportunities where they can lead, and reducing the emphasis on management as the only career path.</p>
<h2>Don't promote for code output</h2>
<p>No matter what leaders describe as the company culture, the skills that are shown to be valued are the ones that are getting people hired and promoted. We need to require strategy, execution and good influence from our senior engineers. If we promote a staff engineer who churns out code but can't work with other people, that becomes the implicit definition of a staff engineer. On the other hand, if our most senior engineers are modelling leadership skills and making everyone better, we're setting up a virtuous cycle. Mid-level engineers will strive to emulate the same behaviour, and leadership skills will grow throughout the org.</p>
<h2>Every project, every initiative and every crisis is an opportunity</h2>
<p>Every cross-team project or messy ambiguous problem is a training opportunity to bring an engineer up a level. While we will sometimes want to deploy our reliable heavy hitters on a project that can’t afford to fail, we should take every opportunity to invite another engineer to try leading a project that's slightly too big for them.&nbsp;</p>
<p>If they're set up for success through mentoring, coaching and lots of support, we'll build the next generation of heavy hitters. The vast majority of our learning happens on the job, so long as we make sure the learning opportunities are available.</p>
<h2>Management is a lateral move</h2>
<p>Management is a&nbsp;<em>different job</em>&nbsp;from engineering. Though on my earlier diagram of an engineering job ladder it is a clear step up, we shouldn't be treating it as a promotion. It should be considered a lateral move to another role. Thinking of management as the obvious "next step up" treats it as a prize to be won, rather than a skill to be honed. The best managers I know are the ones who want to be great managers, not the ones who merely want to climb a rung on their career ladder.&nbsp;</p>
<p>Our technical track ladder should be a genuine parallel path to our management ladder, with the same status and recognition, and it should be explicit about the leadership skills and business context needed at each level.&nbsp; Moving back and forth between tracks should be normal and encouraged. Skills built on either side will be valuable on the other.</p>
<h2>In conclusion</h2>
<p>We'll always need excellent managers and it's great to encourage engineers to manage if that's what they're drawn to. However, it shouldn't be the default career path.</p>
<p>When we push our engineers with leadership skills into management, we're sifting those abilities out of our engineering pool. We can end up without the skills that we need to make our projects successful.&nbsp;</p>
<p>Experienced engineers on the 'technical track' raise everyone's game by modeling what good engineering looks like. They have the mix of engineering and organisational context that's needed to drive projects that most engineers wouldn't be able to tackle. And they talk to each other, ensuring that our technical decisions make sense even when looked at through a global …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leaddev.com/not-all-engineering-leaders-are-engineering-managers">https://leaddev.com/not-all-engineering-leaders-are-engineering-managers</a></em></p>]]>
            </description>
            <link>https://leaddev.com/not-all-engineering-leaders-are-engineering-managers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459636</guid>
            <pubDate>Sun, 13 Sep 2020 09:40:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Utrecht removes road to be ringed by water once more]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24459567">thread link</a>) | @vasco
<br/>
September 13, 2020 | https://www.dutchnews.nl/news/2020/09/joining-the-circle-utrecht-removes-road-to-be-ringed-by-water-once-more/ | <a href="https://web.archive.org/web/*/https://www.dutchnews.nl/news/2020/09/joining-the-circle-utrecht-removes-road-to-be-ringed-by-water-once-more/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="attachment_163597"><p><img aria-describedby="caption-attachment-163597" src="https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-560x373.jpg" data-src="https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-560x373.jpg" alt="" width="560" height="373" data-srcset="https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-560x373.jpg 560w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-360x240.jpg 360w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-768x512.jpg 768w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-640x427.jpg 640w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-92x62.jpg 92w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-130x87.jpg 130w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht.jpg 840w" data-sizes="(max-width: 560px) 100vw, 560px" srcset="https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-560x373.jpg 560w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-360x240.jpg 360w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-768x512.jpg 768w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-640x427.jpg 640w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-92x62.jpg 92w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht-130x87.jpg 130w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Singel-Utrecht-PHoto-Utrecht.jpg 840w"></p><p id="caption-attachment-163597">The new Singel Photo: CU2030, Gemeente Utrecht</p></div><p>After decades of argument, Utrecht has restored the ‘singel’ canal that surrounds the city in an effort to promote greener living.</p><p>In a ceremony on Saturday, the city will officially open the Catarijnesingel, which was once part of a multi-lane highway. Boats will be able to sail around the city centre again for the first time in years from 2pm.</p><p>‘This is a historic moment for Utrecht,’ said Eelco Eerenberg, head of the station area for the municipality. ‘A lot of people from Utrecht and from outside Utrecht have always said it was a huge mistake to fill the Utrecht Singel and now after years of building work, this fault will be made good. The inner city will once again be surrounded by water and greenery.’</p><p>The city had originally intended to have a larger ceremony but due to coronavirus restrictions, DutchNews.nl understands, is celebrating the moment in a smaller way. The new stretch of canal is part of a series of measures – such as building the world’s largest <a href="https://www.dutchnews.nl/news/2019/08/utrecht-stations-bike-park-is-now-the-biggest-in-the-world/">bike</a> park – to redevelop the area around the train station while promoting more eco-friendly living.</p><div id="attachment_163598"><p><img aria-describedby="caption-attachment-163598" src="https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-560x372.jpg" data-src="https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-560x372.jpg" alt="" width="560" height="372" data-srcset="https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-560x372.jpg 560w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-360x240.jpg 360w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-768x511.jpg 768w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-640x426.jpg 640w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-92x62.jpg 92w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-130x86.jpg 130w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht.jpg 842w" data-sizes="(max-width: 560px) 100vw, 560px" srcset="https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-560x372.jpg 560w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-360x240.jpg 360w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-768x511.jpg 768w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-640x426.jpg 640w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-92x62.jpg 92w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht-130x86.jpg 130w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2020/09/Highway-utrecht.jpg 842w"></p><p id="caption-attachment-163598">The old highway Photo: CU2030, Gemeente Utrecht</p></div><p>Utrecht became a city in 1122, and as part of this had the right to build a wall and a protective canal around its walls. However, from the 1950s, a series of traffic management plans have replaced much of the water with roads (although one segment was listed and preserved by the Dutch government).</p><p>Following increasing pressure to reopen the Singel canal, residents voted in a 2002 referendum for a ‘master plan’ for the centre involving digging up the roads on the Weerdsingel and Catharijnesingel and replacing them with water again. Utrecht is also building a covered shopping centre, which boats will be able to sail underneath.</p><p>‘You can see the Singel as part of the kaleidoscope of modern city development,’ added Eerenberg. ‘An old military hospital is now a hotel, a monastery become a teaching hospital and then homes and offices…They all had important functions for the city in their time and their place on the Singel.’</p><p>He said that now the city is developing ‘green’ and ‘blue’ corridors for people and nature to develop, with the aim of increasing wellbeing. The Singel will also be joined to the Leiden Rijn and is expected to improve migration routes for thousands of fish.</p><p>‘There’s not much space in the city, and cars take up a lot of room relative to pedestrians, cyclists and public transport,’ said Eerenberg. ‘But these also contribute to cleaner air for residents and liveability. In Utrecht, we choose water and greenery over a highway for cars.’</p><div onclick="window.location.href='https://www.dutchnews.nl/donate-to-dutchnews-nl/'"><div><h4>Thank you for donating to DutchNews.nl</h4><p>The DutchNews.nl team would like to thank all the generous readers who have made a donation in recent weeks. Your financial support has helped us to expand our coverage of the coronavirus crisis into the evenings and weekends and make sure you are kept up to date with the latest developments.</p><p> <strong>DutchNews.nl</strong> has been free for 14 years, but without the financial backing of our readers, we would not be able to provide you with fair and accurate news and features about all things Dutch. Your contributions make this possible.</p><p> <strong> <a href="https://www.dutchnews.nl/donate-to-dutchnews-nl/"> If you have not yet made a donation, but would like to, <br>you can do so via Ideal, credit card or Paypal. </a> </strong></p></div></div></div></div>]]>
            </description>
            <link>https://www.dutchnews.nl/news/2020/09/joining-the-circle-utrecht-removes-road-to-be-ringed-by-water-once-more/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459567</guid>
            <pubDate>Sun, 13 Sep 2020 09:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Bloom's two sigma problem: A systematic review]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24458662">thread link</a>) | @bschne
<br/>
September 12, 2020 | https://nintil.com/bloom-sigma/ | <a href="https://web.archive.org/web/*/https://nintil.com/bloom-sigma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>One of the <a href="https://patrickcollison.com/questions">Collison questions</a> is</p>
<blockquote>
<p><strong>Is Bloom's "Two Sigma" phenomenon real? If so, what do we do about it?</strong></p>
<p>Educational psychologist <a href="https://en.wikipedia.org/wiki/Benjamin_Bloom">Benjamin Bloom</a> <a href="http://web.mit.edu/5.95/readings/bloom-two-sigma.pdf">found</a> that one-on-one tutoring using <a href="https://en.wikipedia.org/wiki/Mastery_learning">mastery learning</a> led to a <em>two sigma</em>(!) improvement in student performance. The results were replicated. He asks in his paper that identified the "2 Sigma Problem": how do we achieve these results in conditions more practical (i.e., more scalable) than one-to-one tutoring?</p>
<p>In a related vein, <a href="https://journals.sagepub.com/doi/abs/10.3102/0034654317751919">this large-scale meta-analysis</a> shows large (&gt;0.5 <a href="https://en.wikiversity.org/wiki/Cohen%27s_d">Cohen's d</a>) effects from direct instruction using mastery learning. "Yet, despite the very large body of research supporting its effectiveness, DI has not been widely embraced or implemented."</p>
</blockquote>
<hr>
<p>Answering the question requires first to explain what <em>Direct Instruction</em> and <em>Mastery Learning</em> mean.</p>
<h3 id="scope-of-the-present-article">Scope of the present article</h3>
<p>This article is concerned with a general study of Bloom's two sigma problem, which in turn involves an examination of an educational method, mastery learning, and tutoring. I have also included a review of software-based tutoring. Later on I look at educational research in general, spaced repetition, and deliberate practice, as these seem closely related to the core topics of this review for reasons that will be obvious after reading through it.</p>
<p>I am only concerned here with student performance in tests, not with other putative benefits from education; I don't look in detail at what keeps students motivated, what makes them feel well, what makes them more creative, or better citizens.. I could have looked at longer term measures of success (e.g. income later on in life) but I couldn't find such studies.</p>
<p>As a general note, when discussing effect sizes here,  unless otherwise noted, the effect sizes are of the intervention being discussed vs business as usual, using whatever educational method the school was using.</p>
<h3 id="definitions">Definitions</h3>
<h4 id="the-two-sigma-problem">The Two Sigma problem</h4>
<p>Benjamin Bloom, decades ago, <a href="http://web.mit.edu/5.95/www/readings/bloom-two-sigma.pdf">found</a> that individual tutoring raised student's performance relative to a baseline class by two standard deviations, which is a MASSIVE<sup><a href="#massive">1</a></sup> effect. As 1:1 tutoring is very expensive, he wondered if there are approaches that approximate such an effect that were applicable for larger classrooms. Finding such a method was the "two sigma problem". And Mastery Learning seemed to be the promising way to solve it.</p>
<p><img src="https://nintil.com/images/2019-07-03-bloom-sigma/bloom.png" alt="Image result for bloom two sigma"></p>
<h4 id="direct-instruction">Direct Instruction</h4>
<p>From the meta-analysis cited above, Direct Instruction is a teaching program originally developed by Siegfried Engelmann in the 60s that assumes that any student can learn any given piece of material, and this will happen when </p>
<blockquote>
<p>(a) they have mastered prerequisite knowledge and skills and (b) the instruction is unambiguous. </p>
</blockquote>
<p>This doesn't sound that helpful; fortunately the <a href="https://www.nifdi.org/what-is-di/basic-philosophy.html">National Institute for Direct Instruction</a> has a bit more information. </p>
<blockquote>
<p>There are four main features of DI that ensure students learn faster and more efficiently than any other program or technique available:</p>
<p><strong>Students are placed in instruction at their skill level.</strong> 
When students begin the program, each student is tested to find out which skills they have already mastered and which ones they need to work on. From this, students are grouped together with other students needing to work on the same skills. These groups are organized by the level of the program that is appropriate for students, rather than the grade level the students are in.</p>
<p><strong>The program’s structure is designed to ensure mastery of the content.</strong> 
The program is organized so that skills are introduced gradually, giving children a chance to learn those skills and apply them before being required to learn another new set of skills. Only 10% of each lesson is new material. The remaining 90% of each lesson’s content is review and application of skills students have already learned but need practice with in order to master. Skills and concepts are taught in isolation and then integrated with other skills into more sophisticated, higher-level applications. All details of instruction are controlled to minimize the chance of students' misinterpreting the information being taught and to maximize the reinforcing effect of instruction.</p>
<p><strong>Instruction is modified to accommodate each student’s rate of learning.</strong> 
A particularly wonderful part about DI is that students are retaught or accelerated at the rate at which they learn. If they need more practice with a specific skill, teachers can provide the additional instruction within the program to ensure students master the skill. Conversely, if a student is easily acquiring the new skills and needs to advance to the next level, students can be moved to a new placement so that they may continue adding to the skills they already possess.</p>
<p><strong>Programs are field tested and revised before publication.</strong> 
DI programs are very unique in the way they are written and revised before publication. All DI programs are field tested with real students and revised based on those tests before they are ever published. This means that the program your student is receiving has already been proven to work.</p>
</blockquote>
<p>Direct Instruction is  <a href="https://en.wikipedia.org/wiki/Scripted_teaching">highly scripted</a>, <a href="https://en.wikibooks.org/wiki/Contemporary_Educational_Psychology/Chapter_8:_Instructional_Strategies/Mastery_Learning"><em>including even the words they should speak while teaching</em></a>.</p>
<p>Note that Direct Instruction (titlecase) is not the same as <a href="https://www.nifdi.org/what-is-di/di-vs-di">direct instruction</a> (lowercase), there are various programmes around that have "direct instruction" in the name, like <a href="https://dataworks-ed.com/blog/2014/07/direct-instruction-di-vs-explicit-direct-instruction-edi/">Explicit Direct Instruction</a> . Unless otherwise noted, we'll be talking about Direct Instruction in this review. Both are teacher-centered methods in that the teacher is seen as the one who is transmitting knowledge to the student rather than, say, the student being aided by the teacher in a quest to discover knowledge. Direct Instruction is regulated by the National Institute for Direct Instruction, as mentioned above, while direct instruction is not.</p>
<h4 id="mastery-learning">Mastery learning</h4>
<p>Mastery learning (ML) is not the same as Direct Instruction, but ML <em>is a component of Direct Instruction</em>. It is also one of the methods Bloom originally looked at, so we also examine ML in this review. One key difference is that ML does not called for scripted lessons, while DI requires them.</p>
<p>The key principle of ML is simply to force students to master a lesson before moving on to the next one. At the end of each lesson, on a monthly or weekly basis, students' knowledge is tested. Those students that do not pass are given remediation classes, and they have to re-sit the test until they master it. This can be done in a group setting, as with Bloom's original Learning for Mastery (LFM) programme, or individually, as in Keller's Personalized System of Instruction (PSI), where each student advances as their own pace.</p>
<h3 id="summary">Summary</h3>
<ul>
<li>The literatures examined here are full of small sample, non-randomized trials, and highly heterogeneous results.</li>
<li>Tutoring in general, most likely, does not reach the 2-sigma level that Bloom suggested. Likewise, it's unlikely that mastery learning provides a 1-sigma improvement.
<ul>
<li>But high quality tutors, and high quality software are likely able to reach a 2-sigma improvement and beyond. </li>
</ul>
</li>
<li>All the methods (mastery learning, direct instruction, tutoring, software tutoring, deliberate practice, and spaced repetition) studied in this essay are found to work to various degrees, outlined below.</li>
<li>This essay covers many kinds of subjects being taught, and likewise many groups (special education vs regular schools, college vs K-12). The effect sizes reported here are averages that serve as general guidance.</li>
<li>The methods studied tend to be more effective for lower skilled students relative to the rest.</li>
<li>The methods studied work at all levels of education, with the exception of direct instruction: There is no evidence to judge its effectiveness at the college level.</li>
<li>The methods work substantially better when clear objectives and facts to be learned are set. There is little evidence of <a href="https://www.econlib.org/archives/2012/08/low_transfer_of.html">learning transfer</a>: Practicing or studying X subject does not improve much performance outside of X.</li>
<li>There is some suggestive evidence that the underlying reasons these methods work are increased and repeated exposure to the material, the <a href="https://en.wikipedia.org/wiki/Testing_effect">testing effect</a>, and fine-grained feedback on performance in the case of tutoring.</li>
<li>Long term studies tend to find evidence of a fade-out effect, effect sizes decrease over time. This is likely due to the skills being learned not being practiced.</li>
</ul>
<h4 id="effect-sizes">Effect sizes</h4>
<p>Assessing if an effect size is meaningful may be hard. A common way of doing so is as <a href="https://en.wikipedia.org/wiki/Effect_size">follows</a>:</p>
<table><thead><tr><th><em>Effect size</em></th><th><em>d</em></th></tr></thead><tbody>
<tr><td>Very small</td><td>0.01</td></tr>
<tr><td>Small</td><td>0.20</td></tr>
<tr><td>Medium</td><td>0.50</td></tr>
<tr><td>Large</td><td>0.80</td></tr>
<tr><td>Very large</td><td>1.20</td></tr>
<tr><td>Huge</td><td>2.0</td></tr>
</tbody></table>
<p>However, one should be able to finetune the descriptive language used, by using a domain-specific reference. In this case, the average effect on performance from one year of schooling  (going from 5th to 6th grade) is d=0.26 for reading performance, and the average effect from 141 large scale RCTs of educational interventions is 0.06, from  Hugues &amp; Matthew (<a href="http://eprints.whiterose.ac.uk/141754/">2019</a>). Because of this, I will be using a scale adapted from Kraft (<a href="https://scholar.harvard.edu/files/mkraft/files/kraft_2018_interpreting_effect_sizes.pdf">2018</a>):</p>
<table><thead><tr><th><em>Effect size</em> (E.S.)</th><th><em>d</em></th></tr></thead><tbody>
<tr><td>Small</td><td>&lt;0.05</td></tr>
<tr><td>Medium</td><td>0.05-0.2</td></tr>
<tr><td>Large</td><td>0.2-0.5</td></tr>
<tr><td>Very large</td><td>0.5-1</td></tr>
<tr><td>Extremely large</td><td>1-1.5</td></tr>
<tr><td>Huge</td><td>&gt;1.5</td></tr>
</tbody></table>
<p>With that in mind, here is the summary of the main results, along with the best studies I could find to back up the claims. For comparison, I include Bloom's findings:</p>
<table><thead><tr><th><em>Method</em></th><th>E.S. (general)</th><th>E.S. (disadvantaged)</th><th>E.S. (Bloom)</th><th>Key references</th></tr></thead><tbody>
<tr><td>Tutoring*</td><td>Very large</td><td>-</td><td>Huge</td><td>VanLehn (<a href="http://www.public.asu.edu/%7Ekvanlehn/Stringent/PDF/EffectivenessOfTutoring_Vanlehn.pdf">2011</a>)</td></tr>
<tr><td>Software-based tutoring (High quality)*</td><td>Very large</td><td>-</td><td>-</td><td>VanLehn (<a href="http://www.public.asu.edu/%7Ekvanlehn/Stringent/PDF/EffectivenessOfTutoring_Vanlehn.pdf">2011</a>), Kulik &amp; <a href="https://journals.sagepub.com/doi/abs/10.3102/0034654315581420">Fletcher (2016)</a></td></tr>
<tr><td>Mastery learning**</td><td>Medium</td><td>Large</td><td>Extremely large</td><td>Kulik et al. (<a href="http://www.uky.edu/%7Egmswan3/575/kulik_kulik_Bangert-Drowns_1990.pdf">1990</a>), Slavin (<a href="https://journals.sagepub.com/doi/10.3102/00346543057002175">1987</a>)</td></tr>
<tr><td>Direct Instruction**</td><td>Medium</td><td>Large</td><td>-</td><td>Borman et al. (<a href="https://journals.sagepub.com/doi/10.3102/00346543073002125">2003</a>), Stockard et al. (<a href="https://journals.sagepub.com/doi/abs/10.3102/0034654317751919">2018</a>)</td></tr>
</tbody></table>
<p>* With really good tutors and really good software, the effect size can indeed be Huge.</p>
<p>** When considering narrow knowledge of a series of facts, or basic skills taught at the elementary level, the effects of ML and DI can be Large for the general population and Extremely Large for disadvantaged students. </p>
<h3 id="the-evidence-behind-direct-instruction">The evidence behind direct instruction</h3>
<p>The meta-analysis I start the article with has a literature review, noting that all the previous …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nintil.com/bloom-sigma/">https://nintil.com/bloom-sigma/</a></em></p>]]>
            </description>
            <link>https://nintil.com/bloom-sigma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458662</guid>
            <pubDate>Sun, 13 Sep 2020 05:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which API Gateway to Choose from AWS: HTTP vs. REST]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24458568">thread link</a>) | @aray07
<br/>
September 12, 2020 | https://www.learnaws.org/2020/09/12/rest-api-vs-http-api/ | <a href="https://web.archive.org/web/*/https://www.learnaws.org/2020/09/12/rest-api-vs-http-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<hr>
<p>I was recently looking into API Gateways for a project. As I was reading up on AWS’ API Gateway, I realized that there were two options that I could potentially choose: <em>REST APIs</em> or <em>HTTP APIs</em>. The two services had similar names and provided similar features and left me feeling pretty confused about which option was more suitable for my use-case.</p>
<p>One can always count on AWS to create new products that end up confusing people even more. As I started digging deeper to understand the differences, I wondered why Amazon created an entirely new HTTP API service instead of improving the existing REST API service. This way the customers get all the benefits and don’t have to spend time trying to understand the differences and choosing the right service for themselves.</p>
<p>In this article, I’ll try and do a comparison between the two services, and hopefully, that will be useful for folks who are trying to decide between the two services.</p>

<h2 id="api-gateway">API Gateway</h2>
<p><strong>API Gateway</strong> is a managed service that makes it easier to manage the APIs (creating, publishing, and maintaining secure APIs). API gateway has become one of the pillars of the microservices and serverless architectures.</p>
<p><a href="https://www.alexdebrie.com/posts/api-gateway-elements/">This article</a> is a great resource for learning more about API Gateway.</p>
<h2 id="http--rest-apis">HTTP &amp; REST APIs</h2>
<p>The first version of API Gateway was introduced in 2015. The first version of the API Gateway is referred to as REST APIs which is probably the most common usage of the API Gateway.</p>
<p>During re:invent in 2019, Amazon introduced a new flavor of the API Gateway, called HTTP APIs. HTTP APIs were designed from the ground up and thus, are supposed to be faster and cheaper than REST APIs.</p>
<h3 id="pricing">Pricing</h3>
<p>The tables below show the pricing for both HTTP &amp; REST APIs for the us-east-1 region. As shown below, HTTP APIs are significantly cheaper than REST APIs.</p>
<p><strong>REST</strong></p>
<table>
<thead>
<tr>
<th>Number of requests(per month)</th>
<th>Price(per million)</th>
</tr>
</thead>
<tbody>
<tr>
<td>First 333 million</td>
<td>$3.50</td>
</tr>
<tr>
<td>Next 667 million</td>
<td>$2.80</td>
</tr>
</tbody>
</table>
<p><strong>HTTP</strong></p>
<table>
<thead>
<tr>
<th>Number of requests(per month)</th>
<th>Price(per million)</th>
</tr>
</thead>
<tbody>
<tr>
<td>First 300 million</td>
<td>$1.00</td>
</tr>
<tr>
<td>300+ million</td>
<td>$0.90</td>
</tr>
</tbody>
</table>
<h3 id="performance">Performance</h3>
<p><a href="https://aws.amazon.com/blogs/compute/building-better-apis-http-apis-now-generally-available/">In their announcement</a>, AWS claimed that HTTP APIs are up to 60% faster than REST APIs. I spun up a simple service to compare the performance for myself. To mimic a somewhat realistic scenario, my service makes a call to DynamoDB and an external third party API. From my tests, it seems like AWS’ claims about HTTP APIs being faster does hold up.</p>
<p><strong>REST</strong></p>
<p><img src="https://www.learnaws.org/assets/img/http-vs-rest/rest-api-perf.png" alt="rest-perf" title="Rest API Performance"></p>
<p><strong>HTTP</strong>
<img src="https://www.learnaws.org/assets/img/http-vs-rest/http-api-perf.png" alt="http-perf" title="HTTP API Performance"></p>
<h3 id="features">Features</h3>
<p>There is a lot of feature disparity between the two offerings and its helpful to look at these differences to understand which service is more suitable for one’s requirements.</p>
<p>I have tried to summarize some of the critical differences between the two services below (as of Sep 2020). AWS is actively working on getting HTTP APIs to feature parity with REST APIs, so the list below might change in the future.</p>
<h4 id="throttling">Throttling</h4>
<p>Both HTTP and REST APIs support Account-level throttling. By default, API Gateway limits the steady-state request rate to 10,000 requests per second (rps).
REST APIs also support <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html">usage plans</a> with API keys which can be helpful if you need to throttle at an individual API key level.</p>
<p>AWS Web Application Firewall (WAF) can also be integrated with the REST APIs to provide additional protection from attacks.</p>
<h4 id="caching">Caching</h4>
<p>HTTP APIs don’t support the ability to cache endpoint responses whereas REST APIs provide this functionality.</p>
<h4 id="tracing">Tracing</h4>
<p>AWS X-Ray can be used to trace requests made via REST APIs whereas this functionality isn’t supported for HTTP APIs.</p>
<h4 id="endpoint-type">Endpoint type</h4>
<p>API Gateway supports three different endpoints types:</p>
<ul>
<li><strong>Edge-optimized</strong>: Ideal for geographically distributed clients</li>
<li><strong>Regional</strong>: Intended for clients in the same AWS region</li>
<li><strong>Private</strong>: can only be accessed from your AWS VPC</li>
</ul>
<p>Currently, HTTP APIs only support the Regional endpoint type.</p>
<h4 id="request-validation">Request validation</h4>
<p>REST APIs currently support <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-method-request-validation.html">request validation</a> whereas HTTP APIs don’t.</p>
<p><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-vs-rest.html">This page</a> from AWS lists all of the differences between the two services.</p>
<h2 id="conclusion">Conclusion</h2>
<p>As of Sep 2020, the main reason to use HTTP APIs seems to be the cost. However, if your APIs need any of the features not yet supported by the HTTP APIs, using the REST APIs will be your best bet. AWS has already built tools that make migrating APIs from REST to HTTP easy, so it will hopefully be straightforward to migrate your APIs in the future.</p>

</div></div>]]>
            </description>
            <link>https://www.learnaws.org/2020/09/12/rest-api-vs-http-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458568</guid>
            <pubDate>Sun, 13 Sep 2020 05:17:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brutality of Life Reading List]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24458522">thread link</a>) | @exolymph
<br/>
September 12, 2020 | https://www.sonyasupposedly.com/brutality-books/ | <a href="https://web.archive.org/web/*/https://www.sonyasupposedly.com/brutality-books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://www.sonyasupposedly.com/content/images/size/w300/2020/09/DP823443.jpg 300w,
                                https://www.sonyasupposedly.com/content/images/size/w600/2020/09/DP823443.jpg 600w,
                                https://www.sonyasupposedly.com/content/images/size/w1200/2020/09/DP823443.jpg 1000w,
                                https://www.sonyasupposedly.com/content/images/size/w2000/2020/09/DP823443.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://www.sonyasupposedly.com/content/images/size/w2000/2020/09/DP823443.jpg" alt="Brutality of Life Reading List (12 Books)">
                </figure>
                <section>
                    <div>
                        <p>Earlier this year I summed up the perpetual utilitarian lament:</p><!--kg-card-begin: html--><blockquote darkmode="" data-title="All%20you%20can%20do%20is%20as%20much%20as%20you%20can." data-author="@sonyasupposedly" cite="https://www.sonyasupposedly.com/against-fatalism/">
                      <p>Despite <a href="https://rootsofprogress.org/smart-rich-and-free" target="_blank" rel="noopener">nigh-inestimable progress</a>, the world is pervaded by suffering. An unimaginable amount of suffering. Trying to comprehend it specifically and thoroughly makes me feel sick. It is staggering, the magnitude of pain.</p><p>At times the futility of <em>ever fixing this</em> breaks me. How Sisyphean it is, the prospect of searching interminably for new solutions to <a href="http://web.archive.org/web/20140801022058/http://slatestarcodex.com/2014/07/30/meditations-on-moloch/" target="_blank" rel="noopener">coordination problems</a>! I lament that positive-sum possibilities can barely be glimpsed through a tangle of innumerable constraints.</p><p>The fact is... it's true. There is tremendous suffering, beyond my ability to convey and beyond the auspices of the word "fix." Nothing can be said, no conclusion can be reached, that will negate that. It is what it is.</p><p>Reality does not have a human value system. The most you can say about the association between the two is that human value systems are figments within reality, gesturing at its structure. Sometimes the gesture is 🙏, sometimes it's 🖕, and everything in between.</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>I'm not over it, and probably never will be. It's not that I'm inordinately empathetic or anything, but I share the typical concern for people's wellbeing. In particular, watching someone close to me Go Through Some Shit is gut-wrenching (again, as it is for most of us). And I know that it won't stop! "Life is pain, Highness. Anyone who says differently is selling something." Life is other things too, but it's definitely pain.</p><p>The Problem of Suffering seems like a category error, to borrow / repurpose a framing <a href="https://twitter.com/thesravaka/status/1292953978062475272">from @thesravaka</a>. Suffering <em>is</em>. The Problem of Suffering supposes a fantasy in which it is not, but no clever philosophizing can instantiate that fantasy. We live in the existent world, for which suffering poses no grand problems —&nbsp;that fate belongs to its inhabitants. But whaddaya know, <a href="https://www.gwern.net/Backstop#pain-is-the-only-school-teacher">pain is indispensable to survival</a>.</p><p>It's okay to grieve, I think — perhaps even unavoidable, or inadvisable to avoid. I don't know how I'd get through this <em>year</em> without befriending grief, let alone my whole life, and my experiences of both have been pretty good compared to what others have endured.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">one of the hardest parts of growing up has been letting myself feel the pain</p>— 🎀 sonyasupposedly.com 🤖 (@sonyasupposedly) <a href="https://twitter.com/sonyasupposedly/status/1302469281372749825?ref_src=twsrc%5Etfw">September 6, 2020</a></blockquote>

</figure><figure><blockquote data-width="550"><p lang="en" dir="ltr">I don't wanna feel the pain. it hurts. but that's the thing, it's gonna hurt one way or the other</p>— 🎀 sonyasupposedly.com 🤖 (@sonyasupposedly) <a href="https://twitter.com/sonyasupposedly/status/1302469601519783938?ref_src=twsrc%5Etfw">September 6, 2020</a></blockquote>

</figure><p>I mourn for my illusions —&nbsp;of control, of perfect knowledge... the latter in itself an illusion of control. The most cherished mirages I cry for repeatedly, since they sneak back into my mind to break my heart again. And again.</p><p>I mourn for my fears, for the awful possibility of dreaded outcomes. I mourn for the people I know who are dying, which is all of them, but some much quicker than others.</p><p>There's a lot to let go of, you know? A lot that I can't keep within my grasp. Nor can I pretend to be okay with this state of affairs. Sure, it's okay to <em>not feel okay</em>, but even if it weren't, would that change anything? I would still be appalled by the cruelty of life. I would still struggle with acceptance, despite the relative and objective ease of my circumstances. Likewise, I would still grieve.</p><p>For unnameable reasons I find it therapeutic to examine the facets of pain closely, specifically, and in depth. I want to know how bad it can be. Not firsthand, of course, and thus not with the visceral punch of having learned from experience. Regardless there is understanding to be gained from others' accounts. Would Elie Wiesel have written <em><a href="https://en.wikipedia.org/wiki/Night_(book)">Night</a></em> otherwise? (Look, I'm not above an occasional argument from authority.)</p><p>Sordid agony has always intrigued me — I was that kid reading about serial killers on Wikipedia in the library during high school. (<a href="https://en.wikipedia.org/wiki/Albert_Fish">Albert Fish</a> and the <a href="https://en.wikipedia.org/wiki/Murder_of_Junko_Furuta">torment of poor Junko Furuta</a> are my picks for most awful. We're talking very seriously awful, so click with caution.) These days I scarcely have the stomach for extended revelry in prurient gore, a la <a href="https://en.wikipedia.org/wiki/The_120_Days_of_Sodom">de Sade's work</a> or <a href="https://en.wikipedia.org/wiki/Hogg_(novel)">Samuel Delany's <em>Hogg</em></a>. But witness to profound hardship is available in other forms.</p><p>Lacking a deft resolution to this preamble, I'll just segue to the books that have helped me process [some of] my rage and frustration with, well... the Problem of Suffering. It may not be a problem for the universe, but it sure is a problem for me.</p><p>A few obvious titles were omitted, since flogging a <em>dead</em> horse doesn't comport with the spirit of the list — corpses can't feel any blows! Har har. Fine, I'll be straight with you, what I mean is that I considered recommending more Cormac McCarthy. <em>The Color Purple</em> would be a worthy inclusion. Etc. But I erred on the side of idiosyncrasy.</p><p>All of the following books are harrowing reads (in my opinion) and unlikely to cheer the soul. Steer clear if wallowing would be bad for you!</p><h2 id="fiction">Fiction</h2><p>In order of how strongly I feel about the book being crucial documentation of life's brutality:</p><p><strong><em>Johnny Got His Gun</em> by Dalton Trumbo</strong></p><ul><li><a href="https://amzn.to/3hpl5Q4">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780553274325">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/Johnny_Got_His_Gun">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Johnny Got His Gun by Dalton Trumbo" data-author="Phil Mongredien" cite="https://www.theguardian.com/books/2009/aug/16/johnny-got-his-gun-trumbo">
                      <p>After his dugout suffers a direct hit from a German shell in the last days of the Great War, 20-year-old American infantryman Joe Bonham gradually comes to in a French hospital. As his thoughts become more lucid, he realises he has been left deaf, dumb and blind and that all four of his limbs have subsequently been amputated. His face, meanwhile, has been obliterated by the shell and what is left — "a red gash ... with mucus hanging from it" — is now covered by a mask to avoid distressing the nurses.</p>
<p>Despite his injuries, his mind still functions as well as ever, letting him think back to his childhood in small-town Colorado and allowing him to contemplate the full horror of his situation. Joe soon realises he is "the nearest thing to a dead man on Earth ... a dead man with a mind that could think".</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>A quote from the book: "Maybe nothing was real not even himself oh god and wouldn't that be wonderful." Imagine if <em>Slaughterhouse-Five</em> were markedly more grueling.</p><p><strong><em>A Canticle for Leibowitz</em> by Walter M. Miller</strong></p><ul><li><a href="https://amzn.to/2ZAwvKW">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780553273816">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/A_Canticle_for_Leibowitz">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Every%20Book%20I%20Read%20in%202017" data-author="Sonya Mann" cite="https://www.sonyaellenmann.com/2018/01/every-book-i-read-2017.html">
                      A very strong contender for Best Book I Read in 2017. After the nuclear apocalypse, history devours itself like an ouroboros. Science becomes religion becomes science becomes religion. Human nature doesn't improve, but it still has its moments of transcendent goodness.
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>With a little more time and distance, one of the best books that I've read <em>ever</em>.</p><p><strong><em>Bastard Out of Carolina</em> by Dorothy Allison</strong></p><ul><li><a href="https://amzn.to/3ir7xVx">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780452297753">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/Bastard_Out_of_Carolina">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Just%20the%20way%20men%20are%3A%20Bastard%20out%20of%20Carolina" data-author="Maureen Freely" cite="https://www.independent.co.uk/arts-entertainment/book-review-just-the-way-men-are-bastard-out-of-carolina-dorothy-allison-flamingo-pounds-599-1481952.html">
                      Although her story has all the components of formulaic dirty realism, there is never any redneck posturing, no luxuriating in colourful bad language or behaviour. When she has a man cause a family crisis by telling his wife 'I wouldn't touch you even if you took a bath in whiskey tonic and put a bag over your head', it's not to glorify or denigrate a 'good ol' boy' but simply to report what he said.
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>A quote from the book: "Family is family, but even love can't keep people from eating at each other." Ain't that the truth.</p><p><strong><em>The Good Earth</em> by Pearl S. Buck</strong></p><ul><li><a href="https://amzn.to/35v8N6p">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780743272933">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/The_Good_Earth">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="The%20Good%20Earth%20by%20Pearl%20S%20Buck%20%5BA%20Review%5D" data-author="@talkabout_books" cite="https://weneedtotalkaboutbooks.com/2018/06/19/the-good-earth-by-pearl-s-buck-a-review/">
<p>I am not one to cry from reading, but I imagine many a reader would when reading of the despair of life with a young family during a famine and of what they witness. There is much more emotional engagement elsewhere in the story, whether it is the despair of poverty; the frustration of the inequities between rich and poor, men and women, workers and freeloaders; the fear of violence and disappointment in the character's choices. [...]</p>
<p>Wang has known nothing other than the hardworking, precarious, life of a peasant. The life within the House of Hwang is as alien to him as the life of a Westerner. He does not consider how different his life might have been if he had been born into privilege. Nor does he realise, since upward financial and social mobility is his dream, how, if he were to succeed, it would change the way he feels about his wife, the way he would raise his sons or the life he would choose to lead. The thought that his sons might grow up in a completely different environment to himself, with personalities, opportunities, ambitions and wants completely foreign to his own would baffle him.</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p><strong><em>Outer Dark</em> by Cormac McCarthy</strong></p><ul><li><a href="https://amzn.to/2FB1lvx">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780679728733">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/Outer_Dark">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Outer Dark by Cormac McCarthy" data-author="Kirkus Reviews" cite="https://www.kirkusreviews.com/book-reviews/cormac-mccarthy/outer-dark/">
                      Against a landscape as sparse as the trees on the ridge just yonder, anonymous characters, the ferryman, the snake hunter, the beekeeper, the preacher, pursue an unyielding existence. Only a little more identified here are Culla Holme and Rinthy, his nineteen-year-old sister who has just had (his?) child in a cabin. A day or two later he tells her it has died, while going off with the tinker to leave the child elsewhere (where?). Rinthy as soon as she is strong enough goes on her long search to find the tinker and her child[.]
                      
                      </blockquote>
                      <!--kg-card-end: html--><p><a href="https://www.thesatirist.com/books/outerdark.html">Here's a better review</a> that unfortunately divulges nearly all of the plot details.</p><p><strong><em>The House of God</em> by Samuel Shem</strong> (because of the <a href="http://slatestarcodex.com/2016/11/10/book-review-house-of-god/">Slate Star Codex review</a>)</p><ul><li><a href="https://amzn.to/32rjK7k">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780425238097">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/The_House_of_God">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Book%20Review%3A%20House%20of%20God" data-author="Scott Alexander" cite="https://slatestarcodex.com/2016/11/10/book-review-house-of-god/">
                      The whole thing had a touch of magical realism, which turns out to be exactly the right genre for a story about medicine. Real medicine is absolutely magical realist. It's a series of bizarre occurrences just …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sonyasupposedly.com/brutality-books/">https://www.sonyasupposedly.com/brutality-books/</a></em></p>]]>
            </description>
            <link>https://www.sonyasupposedly.com/brutality-books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458522</guid>
            <pubDate>Sun, 13 Sep 2020 05:05:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Feedback Loop of Productivity]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24458482">thread link</a>) | @root993
<br/>
September 12, 2020 | https://www.sankalpjonna.com/posts/the-feedback-loop-of-productivity | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/the-feedback-loop-of-productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Being productive all the time is not just difficult, it might actually burn you out, but that being said lack of productivity for an extended period of time is dangerous too because it gives the mind an excuse to start looking at all the negative things happening in the world, especially with the global pandemic going on. </p><p>So how does one stay productive consistently? I find that the only way to be productive is through feedback. To be productive you need to receive a small but noticeable reward for attempting to be productive. If that did not make any sense, let me try and explain it with an example.</p><p><strong>Kickstarting the loop</strong></p><p><strong>‍</strong><br></p><p>I wanted to write a piece of content today because I have not written anything in a long period of time. Once this piece is out there on a few social media platforms, I might see a small but noticeable spike in the traffic to my blog which I can confirm from my good friend google analytics. This little spike in traffic is my tiny reward which will kick start a feedback loop.</p><p>Now there is higher likelihood that I will try and write some more content next week because I still remember the feeling of that reward and I want to feel it again, but the difference now is that I have built a tolerance for this reward and the only way I would feel satisfied is if I receive a higher reward which in this case might translate to a higher spike in google analytics.</p><p><strong>Add incremental steps to the loop</strong></p><p><strong>‍</strong><br></p><p>To receive a higher reward I am now motivated to write better quality content which reaches a wider group of audience and what gets even better is if people start engaging with me after reading my post and wish to dwell further into the subject. </p><p>If I can keep this up every week while slightly increasing the quantum of work but also the quantum of reward, eventually it becomes a habit that I can no longer ignore.</p><p><strong>Use the feedback loop for everything</strong></p><p><strong>‍</strong><br></p><p>I build software, so for me the feedback loop translates to building a small software module that does one particular task, run a few tests on it to see if it functions like it should and this will kick start the feedback loop. I feel rewarded that I built one tiny part of a large project which works perfectly and is ready to be integrated with the rest of the project.</p><p>Incremental steps can then be added by combining different modules with each other and making them work together. The loop becomes much stronger once there is an actual visual component to look at and interact with because at this point you have basically created something tangible and the reward you get from that lasts much longer than the smaller rewards.</p><p><strong>Conclusion</strong></p><p><strong>‍</strong><br></p><p>It is entirely possible that I put out this piece of content today and nobody cares. Maybe I do not see any spike in google analytics at all. But the very fact that I managed to write something today and share it a few people who are at the very least likely to give it a read creates a feeling of accomplishment which serves as a small reward to kick start the feedback loop. </p><p>Sometimes the reward is not as great as expected but as long as it is not zero, the loop is strong enough to get you going.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/the-feedback-loop-of-productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458482</guid>
            <pubDate>Sun, 13 Sep 2020 04:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting PineTime Watch Face from C to Rust on Riot with LVGL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24458275">thread link</a>) | @lupyuen
<br/>
September 12, 2020 | https://lupyuen.github.io/pinetime-rust-riot/articles/watch_face | <a href="https://web.archive.org/web/*/https://lupyuen.github.io/pinetime-rust-riot/articles/watch_face">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <!--[if lte IE 8]>
    <div class="warning">
        This old browser is unsupported and will most likely display funky
        things.
    </div>
    <![endif]-->

        <!-- Begin scripts/rustdoc-before.html: Pre-HTML for Custom Markdown files processed by rustdoc, like chip8.md -->

    <!-- Begin Theme Picker -->
    
    
    <!-- Theme Picker -->

    <!-- End scripts/rustdoc-before.html -->
    

    
    <nav id="TOC"><ul>
<li><a href="#function-declaration">1 Function Declaration</a><ul></ul></li>
<li><a href="#variable-declaration">2 Variable Declaration</a><ul></ul></li>
<li><a href="#null-pointers">3 Null Pointers</a><ul></ul></li>
<li><a href="#import-c-functions-into-rust">4 Import C Functions into Rust</a><ul></ul></li>
<li><a href="#numeric-types">5 Numeric Types</a><ul></ul></li>
<li><a href="#pass-strings-from-rust-to-c">6 Pass Strings from Rust to C</a><ul></ul></li>
<li><a href="#pointer-dereferencing">7 Pointer Dereferencing</a><ul></ul></li>
<li><a href="#return-value">8 Return Value</a><ul></ul></li>
<li><a href="#c-to-rust-conversion-first-version">9 C to Rust Conversion: First Version</a><ul></ul></li>
<li><a href="#import-c-structs-into-rust">10 Import C Structs into Rust</a><ul></ul></li>
<li><a href="#import-c-enums-into-rust">11 Import C Enums into Rust</a><ul></ul></li>
<li><a href="#unsafe-code-in-embedded-rust">12 Unsafe Code in Embedded Rust</a><ul></ul></li>
<li><a href="#import-c-types-and-functions-into-rust-with-bindgen">13 Import C Types and Functions into Rust with <code>bindgen</code></a><ul></ul></li>
<li><a href="#whitelist-and-blacklist-c-types-and-functions-in-bindgen">14 Whitelist and Blacklist C Types and Functions in <code>bindgen</code></a><ul></ul></li>
<li><a href="#safe-wrappers-for-imported-c-functions">15 Safe Wrappers for Imported C Functions</a><ul></ul></li>
<li><a href="#generate-safe-wrappers-with-rust-procedural-macro">16 Generate Safe Wrappers with Rust Procedural Macro</a><ul></ul></li>
<li><a href="#return-errors-with-the-rust-result-enum">17 Return Errors with the Rust Result Enum</a><ul></ul></li>
<li><a href="#check-errors-with-the-rust-result-enum">18 Check Errors with the Rust Result Enum</a><ul></ul></li>
<li><a href="#c-to-rust-conversion-final-version">19 C to Rust Conversion: Final Version</a><ul></ul></li>
<li><a href="#heapless-strings-in-rust">20 Heapless Strings in Rust</a><ul></ul></li>
<li><a href="#lifetime-of-rust-variables">21 Lifetime of Rust Variables</a><ul></ul></li>
<li><a href="#static-variables-in-rust">22 Static Variables in Rust</a><ul></ul></li>
<li><a href="#simplify-strings">23 Simplify Strings</a><ul></ul></li>
<li><a href="#vscode-development-and-debugging">24 VSCode Development and Debugging</a><ul></ul></li>
<li><a href="#riot-development-on-windows">25 RIOT Development on Windows</a><ul></ul></li>
<li><a href="#webassembly-simulator">26 WebAssembly Simulator</a><ul></ul></li>
<li><a href="#lvgl-and-riot-bindings-for-rust">27 LVGL and RIOT Bindings for Rust</a><ul></ul></li>
<li><a href="#whats-next">28 What's Next</a><ul></ul></li>
<li><a href="#references">29 References</a><ul></ul></li></ul></nav><p><img src="https://lupyuen.github.io/images/rust-on-riot-small.jpg" alt="Rust on RIOT on PineTime Smart Watch"></p>
<p><em>This article is presented in CINEMASCOPE... Rotate your phone to view the C and Rust source code side by side... Or better yet, read this article on a desktop computer</em></p>
<p>We'll learn step by step to convert this <a href="https://github.com/bosmoment/PineTime-apps/blob/master/widgets/home_time/screen_time.c">Embedded C code</a> (based on LVGL) to <a href="https://github.com/lupyuen/pinetime-rust-riot/blob/master/rust/app/src/watch_face.rs">Embedded Rust</a> on RIOT...</p>
<table><thead><tr><th><strong>Original C Code</strong></th><th><strong>Converted Rust Code</strong></th></tr></thead><tbody>
<tr><td><code>lv_obj_t *screen_time_create(home_time_widget_t *ht) {</code> <p>&nbsp;&nbsp;<code>    //  Create a label for time (00:00)</code> <br>&nbsp;&nbsp;<code>    lv_obj_t *scr = lv_obj_create(NULL, NULL);</code> <br>&nbsp;&nbsp;<code>    lv_obj_t *label1 = lv_label_create(scr, NULL);</code></p><p>&nbsp;&nbsp;<code>    lv_label_set_text(label1, "00:00");</code> <br>&nbsp;&nbsp;<code>    lv_obj_set_width(label1, 240);</code> <br>&nbsp;&nbsp;<code>    lv_obj_set_height(label1, 200);</code> <br>&nbsp;&nbsp;<code>    ht-&gt;lv_time = label1;</code> <br>&nbsp;&nbsp;<code>    ...</code> <br>&nbsp;&nbsp;<code>    return scr;</code> <br><code>}</code></p></td><td><code>fn create_widgets(widgets: &amp;mut WatchFaceWidgets) -&gt; </code> <br>&nbsp;&nbsp;<code>    LvglResult&lt;()&gt; {</code> <p>&nbsp;&nbsp;<code>    //  Create a label for time (00:00)</code> <br>&nbsp;&nbsp;<code>    let scr = widgets.screen;</code> <br>&nbsp;&nbsp;<code>    let label1 = label::create(scr, ptr::null()) ? ;</code></p><p>&nbsp;&nbsp;<code>    label::set_text(label1, strn!("00:00")) ? ;</code> <br>&nbsp;&nbsp;<code>    obj::set_width(label1, 240) ? ;</code> <br>&nbsp;&nbsp;<code>    obj::set_height(label1, 200) ? ;</code> <br>&nbsp;&nbsp;<code>    widgets.time_label = label1;</code> <br>&nbsp;&nbsp;<code>    ...</code> <br>&nbsp;&nbsp;<code>    Ok(())</code> <br><code>}</code></p></td></tr>
<tr><td><em>From <a href="https://github.com/bosmoment/PineTime-apps/blob/master/widgets/home_time/screen_time.c">widgets/home_time/screen_time.c</a></em></td><td><em>From <a href="https://github.com/lupyuen/pinetime-rust-riot/blob/master/rust/app/src/watch_face.rs">rust/app/src/watch_face.rs</a></em></td></tr>
</tbody></table>
<p>We'll also learn how Rust handles memory safety when calling C functions...</p>
<table><thead><tr><th><strong>Original C Code</strong></th><th><strong>Converted Rust Code</strong></th></tr></thead><tbody>
<tr><td></td><td></td></tr>
<tr><td><code>int set_time_label(home_time_widget_t *ht) {</code> <p>&nbsp;&nbsp;<code>    //  Create a string buffer on stack</code> <br>&nbsp;&nbsp;<code>    char time[6];</code></p><p>&nbsp;&nbsp;<code>    //  Format the time</code> <br>&nbsp;&nbsp;<code>   int res = snprintf(time,</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>       sizeof(time),</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>       "%02u:%02u",</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>        ht-&gt;time.hour,</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>        ht-&gt;time.minute);</code></p><p>&nbsp;&nbsp;<code>if (res != sizeof(time) - 1) {</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>LOG_ERROR("overflow");</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>return -1;</code> <br>&nbsp;&nbsp;<code>}</code></p><p>&nbsp;&nbsp;<code>//  Set the label</code> <br>&nbsp;&nbsp;<code>lv_label_set_text(ht-&gt;lv_time, time);</code></p><p>&nbsp;&nbsp;<code>//  Return OK</code> <br>&nbsp;&nbsp;<code>return 0;</code> <br><code>}</code></p></td><td><code>fn set_time_label(</code> <br>&nbsp;&nbsp;<code>   widgets: &amp;WatchFaceWidgets,</code> <br>&nbsp;&nbsp;<code>   state: &amp;WatchFaceState) -&gt;</code> <br>&nbsp;&nbsp;<code>    LvglResult&lt;()&gt; {</code> <p>&nbsp;&nbsp;<code>    //  Create a static string buffer</code> <br>&nbsp;&nbsp;<code>    static mut TIME_BUF: String =</code><br>&nbsp;&nbsp;&nbsp;&nbsp;<code> new_string();</code></p><p>&nbsp;&nbsp;<code>    unsafe {</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>        //  Format the time</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>        TIME_BUF.clear();</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>       write!(&amp;mut TIME_BUF,</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>            "{:02}:{:02}\0",</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>            state.time.hour,</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>            state.time.minute)</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>            .expect("overflow");</code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;<code>        //  Set the label</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;<code>       label::set_text(widgets.time_label,</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>            &amp;to_strn(&amp;TIME_BUF) ? ;</code> <br>&nbsp;&nbsp;<code>    }</code></p><p>&nbsp;&nbsp;<code>    //  Return OK</code> <br>&nbsp;&nbsp;<code>    Ok(())</code> <br><code>}</code></p></td></tr>
<tr><td></td><td></td></tr>
<tr><td><em>From <a href="https://github.com/bosmoment/PineTime-apps/blob/master/widgets/home_time/screen_time.c">widgets/home_time/screen_time.c</a></em></td><td><em>From <a href="https://github.com/lupyuen/pinetime-rust-riot/blob/master/rust/app/src/watch_face.rs">rust/app/src/watch_face.rs</a></em></td></tr>
</tbody></table>

<p>Here's a C function that calls the <a href="https://lvgl.io/">LVGL</a> library to create a Label Widget.  The Label Widget displays the time of the day (like <code>23:59</code>).  This code was taken from the <a href="https://github.com/bosmoment/PineTime-apps/blob/master/widgets/home_time/screen_time.c">bosmoment /
PineTime-apps</a> port of <a href="https://www.riot-os.org/">RIOT</a> to the <a href="https://wiki.pine64.org/index.php/PineTime">PineTime Smart Watch</a>.</p>
<pre><code>lv_obj_t *screen_time_create(home_time_widget_t *ht) {
    //  Create a label for time (00:00)
    lv_obj_t *scr = lv_obj_create(NULL, NULL);
    lv_obj_t *label1 = lv_label_create(scr, NULL);

    lv_label_set_text(label1, "00:00");
    lv_obj_set_width(label1, 240);
    lv_obj_set_height(label1, 200);
    ht-&gt;lv_time = label1;
    return scr;
}
</code></pre>
<p><em>From <a href="https://github.com/bosmoment/PineTime-apps/blob/master/widgets/home_time/screen_time.c">widgets/home_time/screen_time.c</a></em></p>
<p>Functions whose names start with <code>lv_</code> (like <code>lv_obj_create</code>) are defined in the LVGL library. <code>lv_obj_t</code> is a C Struct exposed by the LVGL library. <code>home_time_widget_t</code> is a custom C Struct defined by the RIOT application.</p>
<p>Let's start by converting this function declaration from C to Rust...</p>
<pre><code>lv_obj_t *screen_time_create(home_time_widget_t *ht) { ...
</code></pre>
<p>This function accepts a pointer and returns another pointer. In Rust, functions are defined with the <code>fn</code> keyword...</p>

<div><pre><span>fn</span> <span>screen_time_create</span>( ...</pre></div>
<p>The return type <code>lv_obj_t</code> goes to the end of the function declaration, marked by <code>-&gt;</code>...</p>

<div><pre><span>fn</span> <span>screen_time_create</span>(<span>ht</span>: <span>*</span><span>mut</span> <span>home_time_widget_t</span>) 
    <span>-&gt;</span> <span>*</span><span>mut</span> <span>lv_obj_t</span> { ...</pre></div>
<p>Note that the names and types have been flipped, also for pointers...</p>
<table><thead><tr><th><strong>Original C Code</strong></th><th><strong>Converted Rust Code</strong></th></tr></thead><tbody>
<tr><td><code>lv_obj_t *</code></td><td><code>*mut lv_obj_t</code></td></tr>
<tr><td><code>home_time_widget_t *ht</code></td><td><code>ht: *mut home_time_widget_t</code></td></tr>
<tr><td><code>lv_obj_t *screen_time_create(...)</code></td><td><code>fn screen_time_create(...)</code> <br> &nbsp;&nbsp;<code>-&gt; *mut lv_obj_t</code></td></tr>
</tbody></table>
<p>As we convert code from C to Rust, we'll find ourselves doing a lot of this Name/Type Flipping.</p>
<p>Rust is strict about Mutability of variables (whether a variable's value may be modified). <code>*mut</code> declares that the pointer refers to an object that is Mutable (i.e. may be modified). For objects that may not be modified, we write <code>*const</code> (similar to C).</p>
<p>Here's the C function declaration converted to Rust...</p>
<table><thead><tr><th><strong>Original C Code</strong></th><th><strong>Converted Rust Code</strong></th></tr></thead><tbody>
<tr><td><code>lv_obj_t *screen_time_create(</code> <br> &nbsp;&nbsp;<code>home_time_widget_t *ht)</code></td><td><code>fn screen_time_create(</code> <br> &nbsp;&nbsp;<code>ht: *mut home_time_widget_t)</code> <br> &nbsp;&nbsp;<code>-&gt; *mut lv_obj_t</code></td></tr>
<tr><td><em>From <a href="https://github.com/bosmoment/PineTime-apps/blob/master/widgets/home_time/screen_time.c">widgets/home_time/screen_time.c</a></em></td><td><em>From <a href="https://github.com/lupyuen/pinetime-rust-riot/blob/master/rust/app/src/watch_face.rs">rust/app/src/watch_face.rs</a></em></td></tr>
</tbody></table>

<p>Now let's convert this variable declaration from C to Rust...</p>
<pre><code>lv_obj_t *scr = lv_obj_create( ... ); 
</code></pre>
<p><code>scr</code> is a pointer to a C Struct <code>lv_obj_t</code>. <code>scr</code> is set to the value returned by the C function LVGL <code>lv_obj_create</code> (which creates a LVGL Screen).</p>
<p>In Rust, variables are declared with the <code>let</code> keyword, followed by the variable name and type...</p>

<div><pre><span>let</span> <span>scr</span>: <span>*</span><span>mut</span> <span>lv_obj_t</span> <span>=</span> <span>lv_obj_create</span>( ... );</pre></div>
<p><em>(Yep we did the Name/Type Flipping again)</em></p>
<p>Here's a really cool thing about Rust... Types are optional in variable declarations!</p>
<p>We may drop the type <code>*mut lv_obj_t</code>, resulting in this perfectly valid Rust declaration...</p>
<pre><code>let scr = lv_obj_create( ... );
</code></pre>
<p><em>What is this type dropping magic? Won't Rust complain about the missing type?</em></p>
<p>If we think about it... <code>lv_obj_create</code> is a C function already declared somewhere. The Rust Compiler already knows that <code>lv_obj_create</code> returns a value of type <code>*mut lv_obj_t</code>.</p>
<p>Thus the Rust Compiler uses <strong>Type Inference</strong> to deduce that <code>scr</code> must have type <code>*mut lv_obj_t</code>!</p>
<p>This saves us a lot of rewriting when we convert C code to Rust.</p>
<p>Here's how it looks when we convert to Rust the two variable declarations from our C function...</p>
<table><thead><tr><th><strong>Original C Code</strong></th><th><strong>Converted Rust Code</strong></th></tr></thead><tbody>
<tr><td><code>lv_obj_t *screen_time_create(</code> <br> &nbsp;&nbsp;<code>home_time_widget_t *ht) {</code></td><td><code>fn screen_time_create(</code> <br> &nbsp;&nbsp;<code>ht: *mut home_time_widget_t)</code> <br> &nbsp;&nbsp;<code>-&gt; *mut lv_obj_t {</code> <br></td></tr>
<tr><td>&nbsp;&nbsp;<code>//  Create a label for time (00:00)</code></td><td>&nbsp;&nbsp;<code>//  Create a label for time (00:00)</code></td></tr>
<tr><td>&nbsp;&nbsp;<code>lv_obj_t *scr = lv_obj_create( ... );</code></td><td>&nbsp;&nbsp;<code>let scr = lv_obj_create( ... );</code></td></tr>
<tr><td>&nbsp;&nbsp;<code>lv_obj_t *label1 = lv_label_create(scr, ... );</code></td><td>&nbsp;&nbsp;<code>let label1 = lv_label_create(scr, ... );</code></td></tr>
<tr><td><em>From <a href="https://github.com/bosmoment/PineTime-apps/blob/master/widgets/home_time/screen_time.c">widgets/home_time/screen_time.c</a></em></td><td><em>From <a href="https://github.com/lupyuen/pinetime-rust-riot/blob/master/rust/app/src/watch_face.rs">rust/app/src/watch_face.rs</a></em></td></tr>
<tr><td><br></td><td></td></tr>
</tbody></table>
<p>The parameters are missing from the above code... Let's learn to convert <code>NULL</code> to Rust.</p>

<p><code>NULL</code> is an unfortunate fact of life for C coders. In our C code we pass two <code>NULL</code> pointers to <code>lv_obj_create</code>...</p>
<pre><code>//  In C: Call lv_obj_create passing 2 NULL pointers
lv_obj_t *scr = lv_obj_create(NULL, NULL); 
</code></pre>
<p>Both <code>NULL</code>s look the same to C... But not to Rust! Let's look at the function declaration in C...</p>
<pre><code>//  In C: Function declaration for lv_obj_create
lv_obj_t * lv_obj_create(lv_obj_t *parent, const lv_obj_t *copy);
</code></pre>
<p><em>From https://github.com/littlevgl/lvgl/blob/master/src/lv_core/lv_obj.h</em></p>
<p>See the difference? The first parameter is a non-<code>const</code> pointer (i.e. it's Mutable), whereas the second parameter is a <code>const</code> pointer.</p>
<p>Here's how we pass the two <code>NULL</code> pointers in Rust...</p>

<div><pre>
<span>let</span> <span>scr</span> <span>=</span> <span>lv_obj_create</span>(<span>ptr</span>::<span>null_mut</span>(), <span>ptr</span>::<span>null</span>());</pre></div>
<p><code>null_mut</code> creates a <code>NULL</code> Mutable pointer, <code>null</code> creates a Non-Mutable <code>const NULL</code> pointer.</p>
<p><code>ptr</code> references the Rust Core Library, which we import like this...</p>


<p>When we insert the <code>NULL</code> parameters into the converted Rust code, we get this...</p>
<table><thead><tr><th><strong>Original C Code</strong></th><th><strong>Converted Rust Code</strong></th></tr></thead><tbody>
<tr><td><code>lv_obj_t *screen_time_create(</code> <br> &nbsp;&nbsp;<code>home_time_widget_t *ht) {</code></td><td><code>fn screen_time_create(</code> <br> &nbsp;&nbsp;<code>ht: *mut home_time_widget_t)</code> <br> &nbsp;&nbsp;<code>-&gt; *mut lv_obj_t {</code> <br></td></tr>
<tr><td>&nbsp;&nbsp;<code>//  Create a label for time (00:00)</code></td><td>&nbsp;&nbsp;<code>//  Create a label for time (00:00)</code></td></tr>
<tr><td>&nbsp;&nbsp;<code>lv_obj_t *scr = lv_obj_create(</code></td><td>&nbsp;&nbsp;<code>let scr = lv_obj_create(</code></td></tr>
<tr><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>NULL,</code></strong></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>ptr::null_mut(),</code></strong></td></tr>
<tr><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>NULL</code></strong></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>ptr::null()</code></strong></td></tr>
<tr><td>&nbsp;&nbsp;<code>);</code></td><td>&nbsp;&nbsp;<code>);</code></td></tr>
<tr><td>&nbsp;&nbsp;<code>lv_obj_t *label1 = lv_label_create(</code>&nbsp;&nbsp;&nbsp;&nbsp;</td><td>&nbsp;&nbsp;<code>let label1 = lv_label_create(</code></td></tr>
<tr><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>scr,</code></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>scr,</code></td></tr>
<tr><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>NULL</code></strong></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>ptr::null()</code></strong></td></tr>
<tr><td>&nbsp;&nbsp;<code>);</code></td><td>&nbsp;&nbsp;<code>);</code></td></tr>
<tr><td><em>From <a href="https://github.com/bosmoment/PineTime-apps/blob/master/widgets/home_time/screen_time.c">widgets/home_time/screen_time.c</a></em></td><td><em>From <a href="https://github.com/lupyuen/pinetime-rust-riot/blob/master/rust/app/src/watch_face.rs">rust/app/src/watch_face.rs</a></em></td></tr>
<tr><td><br></td><td></td></tr>
</tbody></table>

<p>Let's look back at the C code that we're convering to Rust...</p>
<pre><code>//  In C: Create a label for time (00:00)
lv_obj_t *scr = lv_obj_create(NULL, NULL);
lv_obj_t *label1 = lv_label_create(scr, NULL);

//  Set the text, width and height of the label
lv_label_set_text(label1, "00:00");
lv_obj_set_width(label1, 240);
lv_obj_set_height(label1, 200);
</code></pre>
<p>The <code>lv_...</code> functions called above come from the LVGL library. Here are the function declarations in C...</p>
<pre><code>//  In C: LVGL Function Declarations
lv_obj_t * lv_obj_create(lv_obj_t *parent, const lv_obj_t *copy);
lv_obj_t * lv_label_create(lv_obj_t *par, const lv_obj_t *copy);
void lv_label_set_text(lv_obj_t *label, const char *text);
void lv_obj_set_width(lv_obj_t *obj, int16_t w);
void lv_obj_set_height(lv_obj_t *obj, int16_t h);
</code></pre>
<p><em>From https://github.com/littlevgl/lvgl/blob/master/src/lv_core/lv_obj.h, https://github.com/littlevgl/lvgl/blob/master/src/lv_objx/lv_label.h</em></p>
<p>To call these C functions from Rust, we need to import them with <code>extern "C"</code> like this...</p>

<div><pre>
<span>extern</span> <span>"C"</span> {
    <span>fn</span> <span>lv_obj_create</span>(<span>parent</span>: <span>*</span><span>mut</span> <span>lv_obj_t</span>, <span>copy</span>: <span>*</span><span>const</span> <span>lv_obj_t</span>) <span>-&gt;</span> <span>*</span><span>mut</span> <span>lv_obj_t</span>;
    <span>fn</span> <span>lv_label_create</span>(<span>par</span>: <span>*</span><span>mut</span> <span>lv_obj_t</span>, <span>copy</span>: <span>*</span><span>const</span> <span>lv_obj_t</span>) <span>-&gt;</span> <span>*</span><span>mut</span> <span>lv_obj_t</span>;
    <span>fn</span> <span>lv_label_set_text</span>(<span>label</span>: <span>*</span><span>mut</span> <span>lv_obj_t</span>, <span>text</span>: <span>*</span><span>const</span> <span>u8</span>);
    <span>fn</span> <span>lv_obj_set_width</span>(<span>obj</span>: <span>*</span><span>mut</span> <span>lv_obj_…</span></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lupyuen.github.io/pinetime-rust-riot/articles/watch_face">https://lupyuen.github.io/pinetime-rust-riot/articles/watch_face</a></em></p>]]>
            </description>
            <link>https://lupyuen.github.io/pinetime-rust-riot/articles/watch_face</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458275</guid>
            <pubDate>Sun, 13 Sep 2020 04:14:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Together vs. Alone: Thoughts on building a team]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24458258">thread link</a>) | @grwthckrmstr
<br/>
September 12, 2020 | https://www.preetamnath.com/blog/building-a-team | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/building-a-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We live in an incredible time in human history where the basic infrastructure for many of us is so good.</p><p>In today’s world it is possible to get ahead and achieve a lot all by yourself. You can be a writer with 1mn readers, a social media star with 1mn followers, or a SaaS business with $1mn in ARR.&nbsp;</p><p>That’s the mindset Sankalp and I both embodied when we first started on our journey. We had faith that just the 2 of us working together towards our shared goal is enough to get us really far.</p><p>Thankfully that faith turned into reality and lead to the success of SuperLemon.</p><h3>Challenging our beliefs</h3><p>But any great mindset or philosophy is only as great as the people who practice it, and people are always evolving and getting better. Mindset and philosophy evolves too.</p><p>The people in our lives who believed in us and wanted us to do even better challenged us on our beliefs of doing things amongst just the 2 of us.</p><p>One of them said - we are setting small goals, because we are afraid of hiring. If we had the confidence that we can put together a great team, we would think bigger and set higher goals.</p><p>We knew in our hearts that the challenge was genuine. Due to our poor experiences with hiring in the past, we started favouring the path of least resistance, which is to not try to hire anyone. Automatically our goals would only be as lofty as how much the two of us can achieve together. </p><p>We had to change this about ourselves. And so we immediately set out to <a href="https://twitter.com/hipreetam93/status/1296089975818055680" target="_blank">hire someone amazing</a> into our team. It was an exercise to prove to ourselves that we have what it takes to do this.</p><h3>An updated mindset</h3><p>Less than a month later, we hired an amazing <a href="https://twitter.com/akashjdotcom" target="_blank">first engineer</a> and have made an offer to another. This exercise has turned out way better than we anticipated, and it did exactly what it was supposed to do. It allowed us to dream bigger.</p><p>Our mindset and philosophy has thus been updated - We can get far in today’s world just by ourselves, but if we want to get really really far with our next venture <a href="https://delight.chat/" target="_blank">Delight.chat</a>, we need more than just the two of us.&nbsp;</p><p>While we suddenly haven't started wanting to build a 400 person company, our mindset has evolved enough to accept and understand how building a team of 5-15 people could produce a 100x result of what we had previously set out to achieve.</p><h3>People on the inside</h3><p>We need people on the inside (a team) who are aligned with our shared vision, and working together using their mind and abilities towards achieving that goal. </p><p>It's not just having more hands in the engineering team in building the product, or marketing team in creating content or distribution channels.</p><p>Their consciousness, ideas, problem solving abilities, attitude and values get added into a collective pool with our own. The sum is greater than the parts.</p><p>The people joining our team are entrepreneurial minds whose values align with ours, who want to build and grow something new and challenging from the ground up, learn from the experience, and eventually start their own companies. We will be their first supporters when they do. Psst, <a href="https://www.notion.so/Join-our-tribe-at-Delight-chat-dfb896c946a843ebb58bbb1cc161fe33#dfa80f89af17410e9076d1d4fbfcff35" target="_blank">we are hiring</a>.</p><h3>People on the outside</h3><p>We need people on the outside (advisors, investors) who are aligned with our end goal of building a great company, and are going out of their way in helping us get there. </p><p>They align with our mindset of building a real business that thrives without burning $1 for 70 cents,&nbsp;delivers real value to end users, and grows to a reasonably large size while being profitable.</p><p>Their experience observing other entrepreneurs and companies will help us avoid common pitfalls, make better connections like key hires, and open up doors that we can't even imagine today, because we don't know those doors exist. Serendipity.</p><h3>Onwards</h3><p>I feel incredibly lucky and grateful that we have a handful of such people who believe in us, and who are now working with us towards achieving our shared goal.</p><p>Together, we will reach farther than we previously dared to imagine.</p><p>Off we go towards the next milestone in this great adventure.</p></div></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/building-a-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458258</guid>
            <pubDate>Sun, 13 Sep 2020 04:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Data Courses, Hadoop, Kafka and Spark]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24458019">thread link</a>) | @dataguy12
<br/>
September 12, 2020 | https://www.coriers.com/the-top-10-big-data-courses-hadoop-kafka-and-spark/ | <a href="https://web.archive.org/web/*/https://www.coriers.com/the-top-10-big-data-courses-hadoop-kafka-and-spark/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.coriers.com/the-top-10-big-data-courses-hadoop-kafka-and-spark/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458019</guid>
            <pubDate>Sun, 13 Sep 2020 03:23:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Solution of the n-body Problem [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24457977">thread link</a>) | @AceyMan
<br/>
September 12, 2020 | https://www.math.uvic.ca/faculty/diacu/diacuNbody.pdf | <a href="https://web.archive.org/web/*/https://www.math.uvic.ca/faculty/diacu/diacuNbody.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div Ìqqì="">„ÕKtógE=	æ¶À`
¡¥Î%L{Š½¬ˆA¬ÝN0’«��ÃŸ­l¥fòÏGþt~iã€0‘ž˜Yõ%q	úÕÆEo¼&nbsp;ýEaÎÎàp(UnÔ[,²`žUmJLð‹�z}•¢<bi>lô…-õ¤k	’5ÚW¨è[kÅœí#kÿ:µXP1Y��ï
Ý&nbsp;Š(&nbsp;™$‹s€)õ‘9’r¹ùS€=èÃê$¶"�?ZC2¾3ìE;LŒŒ˜ù‰ÀúU©£ÆÈÝÅEoyÄ/ÝoCVkŸå[ÐŠÛ¶—Í�õï@_È«nÊXn=eÆÁeV=´®íbI&amp;ìg9¬ÈÆé„â€5¾ß÷�åVƒ(aÐŒÕ°[ÿtþu`&nbsp;&nbsp;¢Š(	
	'w¬ ¹=³[SÛ¬à,ì
bÉ«ouA™!FF*Ò°eAäU(l!xQ›vH­]U
¡G@0(ïþ&gt;dÿxÕûIR+g8ÿ:¡wÿ2¼jÕ•ªËyrÃ¢®x&nbsp;µ6ÝòÆ1îjÅµâNv‘µý=jË8Ö$ci^¢¨ÄÅ$VA½EGQ��Ðà·'é@Ï{Gjüíè*¹Ô]OÍi‘-#�p*ÕÜk%»ärA&nbsp;Þê9ø7¡©ë
'1ººõ5¸@&gt;´´QE÷qÁÁù›ÐS¦2�Éäú
Ì¼„C(PÄäd“@6·hV;vàÓå™!\¹Ç·­Sµ�AjžFùWÖ‹›b!i¦rdôµ=5óB“Œæ®Ö5’oºAès[�Í-ß1?¾¿�b}:ueêñð¿îÿSZ`‚2Efjñð¿îÿS@iŒ%,p:þ4é5%„�SÅW²·3îˆAŒ�Þ­¶�	\
Àúæ€¢Œq"í÷ê*à Œƒ�khÚ
7QÞ¯é’–FŒœíäPê¯5äP’3¹‡aEìÆ~S†nf[Gç\*“�O4sûDõqõ§Ç¨FÇ¥}úŠ¶ÀJÉ¿ˆE?ËÂ°ÍkƒÞ–³´ÙŽLDñŒŠ¿#ˆãgn€f€`ŠKîjœšŠ„BÃÔœUY&amp;’êURx'v§F¡BÄP)ïRkvM¥Xâ«ZÿÇÌï
·}j‹•Ò:ŽÆªZÿÇÌï
ÙvØ…°Nxª¿Ú1�àj¹T5A*ŽAÁ&nbsp;�F?î=YŠA$aÀ Æ²-\Gr…ºg5µ@Î¡8(õ$i;íUaÆyªÚ�ó'H”d�ëWb‰bŒ"ŽŸ­IEPP^ÿÇ¬ŸOëSÔ¿ñë'ÓúÐ5o'Ü_¥`Ö´²Í_.-êTs@	©-±Ü°¬ët2LˆSV$ŠêéÁdÀíž«–¶«n3ÕÏz•äHÆ]‚�z�ïà^„±ö&lt;‘$&nbsp;\�X×#�ÕzÅj¥Ê4s|«éQÃ|²Ê!èsU-íd¸Œeö¢ž*xlž¤l†Ažh÷J­-ü1œ¹ö¨µ)Êâ%=yj‹O…d�³…íï@iñ}jho"˜í«z•ãI«("±eC¬¹û§&nbsp;
Ú¯}ÿ’~Î‹)ŒÐeŽYx4_Ç¤Ÿ‡ó&nbsp;Ëoøù�ýáüëR{¸ààä·&nbsp;¬ˆ·!ù³Åi.ž„fGfcÔÐF¤™æ2Ö­Å*L»‘²+.îÐÛá�ÊÒ›g)Šuç†àŠÙ¬íSïGô5£YÚ§Þ�èhÒþüŸAZ5�¥ýù&gt;‚´h	ÀÉâªÉ(/ôéUonZIÂ)ÇÖ®Z[¤p©*0É&amp;€šŒlpÊËïÖ­+PÊrzÎÔaXÙ]º�K¦JD†#Ðò&gt;´}åHþû…úš�ïá^„·ÐT³[Ç1Ë®N1œÖ)àÐÓN‰
ÈçŒâ«ÿi&amp;Õ¶=sI
Ÿ›¼ÎOØU{ÛQ	*xçµiC2L»�ç×Ú¢žò8[o,{ãµgZ‰]‘¶ÒÃûUã§E³›w­,wñ1Ã¾ç¥Z¬'S²ªqZÖ,ZÕ3ÛŠ|òù1ïÚ[éTÃÍ|v,c­_u…XpF
$Q¬H&nbsp;ÛX#˜²9!ÇLU¨,Ì‡WÊã#š‰,æÃ²ZÐ&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;Š(&nbsp;›ëN¦úÐÑE”RÑ@	A¢ƒ@�M&gt;š½M:€
(¢€
(¢€
(¢€
(¢€
(¢€#ŸýDŸîŸåXU»qÿòº•aÐÕ§üzÇô©ªOøõ�ýÚš€
ÍÕ~üCZU›ªýøþ†€Jÿ['Ò´ë3JÿZÿJÓ&nbsp;;±‹©?Þ5§§Ç¢ýOó¬Ë¡þ•'ûÆ´ôÿøô_©þt©ÿëþ÷ô5Ÿ&amp;TVÚOzÕ¾ˆËlÀ•äVB±G:ƒ‘@"Æn÷
úÒfäå¦'ð«0\$è
‘žã¸©Y‚Œ±{Ðvð-ºRNNrjZj:ºîS�{Ó¨¢Š(†Tˆ³ó‘œSë&gt;iV=H3tò«êÁ€*A¸&nbsp;dVeê+/P¶XY]»zÖ¬ÍNefXÔço&amp;€"Ósö¡Žàæ®jñì?ÞÖ£Ó!#2°ÆF¬ÞFe¶eG"€2-ø¹�ýáüëz¹õ;7ps[ÈÁÐ2œ‚3@µ1›_£
Ì„~ý1ýáZ:£�®y-U4ø¼Ë…8ùS“@‘©ÇÑú
×¬�Gþ&gt;ÏÐP�+ýKÿ½WªŽ—þ¥ÿÞþ•z€25øú?AVt¯õ/þõVÔ�Dú�Ré“"F`¹9&nbsp;
û§é\ýlÜÜÇgˆÀšÆ&nbsp;
è¿Õ'û¢¢¾ÿ�I&gt;ŸÖ¥‹ýRº*+ïøô“è?�eAþ¾?÷‡ó­ÚÁ„…™žkszàÃÞ€X7ññ'ûÇùÖõ`Ïþ¾O÷�ó&nbsp;
køô�ü÷ªú·Ü�êjÅ�üzGôþ´ÍF2öÙ”9ü(…‡ü~Gøÿ*Ú¬+wòçF=­Àr2(Žª”‡Þ©ÙÇÔxõ«z«F�úÔZdE¦óE­jÖÏü|Éþñþu»Xw?ñó'ûÇùÐ¥‡üz'ãüé×ñë'û´ÛøôOÇùÓî¿ãÚO÷h/õ‰õ½X1­_÷…oPEPXŸÞ¶}MoÖ-äF;‡‰È&nbsp;

;þ=êjÕQÓ™;ƒšºNOJÃœbyþñþu¥¦ÿÇ¯üÖd‡|ŒÃ»+bÖ3º)ëÔÐwÿ²}+õÉÇñ
Ø»ÿ�Y&gt;•�úäÿxPõQ@Q@sçïè+Ÿn¦€7-ÿãÞ?÷Gò©*+VÚ2E¤&nbsp;[¿øù“ýãZZüy§ãüë6ëþ&gt;dÿxÖ–Ÿÿ‰øÿ:’çþ=¥ÿtÖ"ýáõ­»Ÿøö“ýÓXª&gt;aõ&nbsp;
úÉÔ¹º&gt;ÀVµfj‘‘*ÉØŒPvi;†òdÚ^jÉ·»aƒ8ÁªÖ3ˆ%;¸VàûV° Œƒ‘@ÃLlüÒÀV‚®Õè1JX/RÖ–€
(¢€
Ç¾m×OíÅk³RÇ&nbsp;¬0ÓÝÚ€4l"Ê	Ÿ®0£ÐSu7Ähž§5uT*…À¬­E÷\•ì£.–™gNY½fÌ[Ž)–Ea³äI5h@#¡&nbsp;?-Çð7åG–ÿÜoÊ·h&nbsp;­ãò&nbsp;Dî?Z¡ªÇÂÿ»ýMjV^§ÿþèþf€%Ò¾ìŸ‡õ«õ�¥&lt;ÅÏ'£@š&nbsp;rU§iCæ‘»Ezþ}ÖæÇÊ1Þ¯ÚCäBýãÉ&nbsp;
Ú¯XÇÖ¡Ó¿ãè}
YÔã-¸þÍS´qÒÓ8&nbsp;
šÏÕG¯ô­
ÎÕf5úš‚Ãþ?ñþU{Q8µÇ©«i±–˜ÉŽcñ«wÈ^Õ±Ôs@–˜QçÖ¶ëIG:ƒ‘[PÌ“ e#ÜzPz‡üz?áüë6Óþ&gt;£ÿz¯j§’c'·j£iÿ1ÿ¼(n›"	#d=Å:ŠÀ`UŠž&nbsp;âµí§j$c÷GÍøU-F-“ï‡þu
LËÄ:&gt;(ÝŠ™®vZÐ¨mbò`UïÔýjj(¢Š*ßøô“éýjz‚÷þ=$úZÆ­äû‹ô¬,s[©÷é@¢Š(¬[Ïøú“ë[U�yÿR}hCOÿ�Eúš³U´ÿøõ_©«4�ÍÛþÊ­ixÙ&amp;=EA¨ÆVãwf§énºz€hJ±ïÇú[þÊ¶+ø†º|vâ€,i]%J±}ÿ’~Î£Óc)b9cúT—ßñèÿ‡ó&nbsp;»oøù‹ýá[•‡n@¸ŒžaÏã[”èÖLúf²a¦EØVž¡ Kr½ÛŠ­§@ZO4�•z{šÓ¬íWïGô5£YÚ§Þ�èhÒþüŸAZp¤Ö~—÷äú
Ñ&nbsp;|žkB&amp;¾1®Ð6ãŽ�*”¨c‘”õ´´ùƒÂŸ™xÇµC4“€n=iÖ–rE0‘ÊŒg�Wè&nbsp;°äÖý`7Þ4·oÿñÿº?•WÔÿÔ/ûÕbßþ=ãÿt*¯©ÿ¨_÷¨®�ÿcèkZ²tÿøú_¡­jÅ¼ÇÚ¤úÖŽŸÿ‹õ?Î³ï?ãêO­hiÿñè¿S@h¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š)¾´êo­-Q@	E-”(&nbsp;{Ó©«ÔÓ¨¢Š(¢Š(¢Š(¢Š(¢Š(œÖ÷2–pOÚ¡þÌùè¿•iQ@¢µ¸‹fAéWh¢€ b„!Ãv&amp;¨Éc&lt;­ºITšÐ¢€3ã°š&amp;Ýª
]ˆ:ÆŒ»‘O¢€3åÓä’g}êÓàµ¸€€³
™É«´PT®4ñ#ˆ…'±éWh&nbsp;Ÿ°\À\Ô©§ÈÇ÷¯�ìrkFŠlh±&nbsp;E)ÔQ@Q@.lDÎ\1zç¥W[K¨�îØ~
ZtPq†ùÆð&gt;´øtåRVÝì:Uê(`KEJçO1xÈRzƒÒ£ŠØØñ·Ó#£Eg)ç“tîÒ®Ã
B›P`:’ŠŽa!LDÁ[=MR{	äbï"–5£EgÅis|¹Pg­^\í¾ö9úÓ¨&nbsp;
×v¢àt5GìÆÑõÍkÑ@ílDCsà¿oAUÿ³eþúÎµ(&nbsp;
ÖñÜFBÉ"²Œµ;&nbsp;‘¡§Q@2iÓ+˜aõÅOidÈûæ:.jý
À�±ä²¯®j‰Óe'%Ó'ëZ”P( º‡j‡B€ô«„dsKEgÏ§e‹B@Ý4D·Ñ.À¦H5¡Eg¦“|ïŒþ&amp;¯GÄ�`
}
ÀœíòG®j‘Ó¦bIuÉç©­:(”0]B«¡Lô«3¡’EêF*J(/û:n»’¯@'‰™HíŠšŠ(¢Š*‹t¸L7t55–-.`}ÑòGpjG³!FP&nbsp;õíZP;k‰ƒ¹ÜÃ§&nbsp;«”Q@¦Šî`ÈYP�:QÎäýkNŠ­º¢FB�ñÖ¬ÑEQE™q`ûËD2§·¥iÑ@PÙLÎ‚‰ßš½0™UVÜ(Žjz(-¬'f,ÅrNzÔÐÅw
í]…sW¨&nbsp;L¥áuJ�+7û&gt;öGãZ´Pÿh‰¶‘Ž©%�eBŽ2
&gt;ŠÊ—O•IÙ†­"Cvœ uükZŠ£
œ†Eyß89ÆsW¨¢€
(¢€!ºG’Hñ“Ç5^ÚÅâ•dvSŽÂ¯Q@eÏi3Ü¹�Ç ö­J(¥µ’Ç†�ïaÐvnŠ(¢Š(ª7V’Os‘€¸êjõ�Öw6UIÇBµ2Ç{(ÚÌÊ½É­({d€|£-Ý�MEŒ¡”«ƒÖ³f°u$Åó/§zÓ¢€(G5Ú.Ó	lw"˜-'¸“|ÇnkJŠdQ¬H§RÑ@·6´C ÿ¥@–“³mØÃÜñ[4P'²	jÊƒt‡Õt²¸FVU#šÕ¢€#„ÈS÷ª³Ú¤¢Š¯}›nØê¼Š¡e™p¹û«É­É|¨ûÍÀ¦ØÅåÁ’&gt;gæ€,ÑEQEU…ÜÈSËO^jõ“ö�îÌU¸èI#GªÝQEÍ2�"Œ6zäÕ³¸‘Ë²Œ““ÍjQ@`[¨h�Xg=jâP$r)ÔPW,ñíncéYæÚâ	"’GB¼Ö­Gí7,¸Xo\ŽgÝ7®;šÒ¢€`•
ê3Û²&nbsp;$’8©è&nbsp;—±™¡½@íKÞ Øªø÷«ERŠÑ�¼Ë–Ü»W`
Z(®YP•`8ŸqÕÃÑ�Ž´¨&nbsp;Ûx®mÜ²ÅœŒš¿3F®Öî)ôPK»O?çC‡þuDÛÏgc;ŠÙ¢€2Ñï[�¿êE[µ�ã,ò¶çn:ô«4PL§G»#¯¥gýŠùçúŠ×¢€*Û4ê9"Â��Ù¨.ÍÀÃ´žµ£EeEÌ2‡XòG½hÀò:"l9éRQ@w³I;²¡ ž
MköˆUc1es×=*õQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQESGzu4w&nbsp;¢Š(¤¢ŠZJZJ©§SW½:€
(¢€
(¢€
(¢€
(¢€
)�"G�ì=3MûL?óÕ:–Š‹íÿÏUüèûD?óÑ:–Š‹í0ÿÏUüèûD?óÑ:–Š‹íÿÏUüèûD?óÕ:–Š‹íÿÏUüèûD?óÕ:–Š‹íÿÏUüèûD?óÕ?:–Š‹íÿÏTüèûD?óÕ:–Š‹íÿÏTüèûD?óÕ?:–Š‹íÿÏTüèûD?óÑ:–Š�íÿÏTüé&gt;ÑüõOÎ€%¢£óáÿž‰ùÑçÃÿ=Só&nbsp;	(¨üøçª~tyðÿÏDüèJ*?&gt;ùêŸ�|_óÑ?:’Š�Ï‹þz'çGŸüôOÎ€$¢£óâÿž‰ùŠ&lt;ø¿çª~b€$¢£ó¢ÿž‰ÿ}
&lt;ø¿ç¢~b€$¢£ó¢ÿž‰ùŠ&lt;è¿ç¢þt%�üôOÌQçEÿ=ó&nbsp;	(¨üè¿ç¢~b�:/ùèŸ÷Ð&nbsp;	(¨üè¿ç¢~b�:/ùèŸ˜&nbsp;	(¨üè¿ç¢ßB—Î‹þz/ç@¢™çGÿ=ó£Î�þz'æ(ôS&lt;è¿ç¢ßB�:?ùèŸ˜&nbsp;ÑLó£ÿž‰ùŠ&lt;Øÿç¢~b€E3Í�þz'ýô(ócÿž‹ùŠ}Ï6?ùè¿˜£Í�þz/æ(ôS&lt;Øÿ¾¿�lóÑ:}Ï6?ï¯çG›÷×ó&nbsp;ÑLócþúþty±ÿ}:}Ï6?ï¯çG›÷×ó&nbsp;ÑLó#þúþty‘ÿ}:}Ï1?¾¿�b}:}ß1?¾¿�b}:uß1?¾¿�b}:uß1?¾¿�b}:uß1?¾¿�b}:uÝéýåüèÞŸÞ_Î€E7zy:7§÷—ó&nbsp;QMÞŸÞ_Î�éýáùÐ¨¦ï_ïÎ�ëýáùÐ¨¦ï_ïÎ�ëýáùÐ¨¦ï_ïÎ�ëýáùÐ¨¦î_ïÎ�ËýáùÐ¨¦î_ïÎ�ËýáùÐ¨¤Ü¿Þ�—ûÃó&nbsp;¢“rÿx~tn_ïÎ€ŠMËýáùÑ¹}Gç@E&amp;áê(Ü=E-›‡¨£#ÔPÑI‘ê(Èõ´RdzŠ2=hh¤Èõ£#Ö€ŠL�Z2=hh¤È£"€ŠLŠ3@YMu,sÈTð[¡­LÒRr@?Q@ðÇ-ä¡åû‚´zQÅ´RRÐEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPEPMéÔßZZ(¤&nbsp;ŠZ(¤¥¤&nbsp;zšu5zšuQEQEQEQE2H’\oPØéLû$óÌTÔPdƒþyŠ&gt;Éüó=Ù ÿžcó4}’ùæ?ZžŠƒì�Ï1úÑö;ùæ?3SÑ@}Žùæ?3GØíÿç˜üÍOEAö;ùæ?3GØíÿç˜üÍOEAö;ùæ?3GØíÿç˜üÍOEAö8?ç˜üÍc·ÿžcó5=Øíÿç˜üÍcƒþy�ÌÔôPc·ÿžcó4}Žßþy�ÌÔôPcƒþy�ÌÑö;ùæ?3SÑ@}Žßþy�ÌÑö;ùæ?3SÑ@}Žßþy�ÌÑö;ùæ?3SÑ@}Žßþyþ¦�±ÛÿÏ?ÔÔôP±ÛÿÏ?ÔÑö+ùçúš±EWû¿üóýM/ØíÿçŸêjz(¿Ø­ÿçŸêhû¿üóýMX¢€+ýŠßþyþ¦—ìvÿóÏõ5=ØíÿçŸêi&gt;ÇüóýMX¢€+ýŽùçúš&gt;Å÷?SV(&nbsp;
ÿb·þçêhûÜýMX¢€+ýŠî~¦�±AýÏÔÕŠ(¿Ø­ÿ¹úš&gt;Å÷?SV(&nbsp;
ÿbƒûŸ©£ìVÿÜýMX¢€+ý†ßûŸ©£ìPsõ5bŠ¯ö(?¹úš&gt;Å÷?SV(&nbsp;
ÿbƒû‡ó4}ŠîÌÕŠ(¿Ømÿ¸3Iö?º:³EWûÝ?�aƒû‡ó5bŠ­ö?º:&gt;Ã÷OçVh&nbsp;
ßaƒû§ó£ì0tþufŠ­ö?º:&gt;Ã÷OçVh&nbsp;
ßaƒû§ó£ì0tþufŠ­ö?º:&gt;Ã÷OçVh&nbsp;
ßaƒû§ó£ì0tþufŠ­ö?º:&gt;Ã¡üêÍ[ì0zÎ�°Áè:³EVû�ùÑö=çVh&nbsp;
ß`ƒÐþt}†FüêÍ[ìz7çGØ`ôoÎ¬Ñ@¾Ã£~t}†FüêÍ[ì0z7çGØ`ôoÎ¬Ñ@¾Ã£~t}†FüêÍ[ì0ú7çGØaÿkó«4Po°Ãþ×çGØ!ÿkó«4Po°Ãþ×çIöÚüêÕWìÿµùÑöÚüêÕWìÿµùÑöÚüêÕWìú¿çGØ!õÎ­Q@~Ã«þt}‚WüêÕWìz¿çGØbõÎ­Q@~Á«þt}†/WüêÕWìyÿ:&gt;Á«þujŠ«ö¿¼ÿ�`‹ûÏùÕª(¯Ø"þóþt}‚/ï?çV¨&nbsp;
¿`‹ûÏùÑö¿¼ÿ�Z¢€*ý‚/ï?çGØ#þóþujŠ«öÿ¼ÿ�a�ûÏùÕª(¯Øcþóþt}†?ï¿çV¨&nbsp;
¿a�ûïùÑöÿ¾ÿ�Z¢€*ý†?ï¿çGØ#þûþujŠ«öÿ¾ÿ�`�ûïùÕª(¯Øcþûþt}†?ï¿çV¨&nbsp;
¿`Oï¿çGØSûïùÕª(¯ØSûïùÑöÿž�ùÕª(¯ØSþz?çGØSûïùÕª(¯ØSûïùÑöþûþujŠ«öÿž�ùÑöÿž�ùÕª(§ØSþz?çKöÿž�ùÕª(§ØSþz?çGØWþz?çVè&nbsp;
Ÿa_ùèÿ�/ØWþz?çV¨&nbsp;
¿a_ùèÿ�a_ùèÿ�Z¢€*}…ç«þt¿aóÕÿ:µEUûÿÏY?:&gt;Â¿óÕÿ:µEUûÿž¯GØGüõÎ­Q@~Ä?ç«þtŸa_ùêÿ�[¢€*}„ÏWüé~Â?ç«þujŠ©öÿ=_ó£ì#þz¿çVè&nbsp;
ŸaóÖOÎ�°�ùêÿ�[¢€*}„ÏWüèûÿž¯ùÕº(§Ø‡üõ“ó£ì#þ{IùÕº(§Ø‡üõ“ó£ìCþz¿çVè&nbsp;
ŸbóÙÿ:&gt;Ä?ç«þunŠ©ö!ÿ=Ÿó£ìCþ{IùÕº(§Ø‡üöÎ—ìCþ{?çV¨&nbsp;
ŸbóÕÿ:_±ÓW«TPO±Óg¥ûÿž²~ujŠ«ö!ÿ=_ó«».IÀÆM:Š(¢Š(¢Š(¢Š(¢Š(¢Š)½Í:›@EPRÑE†–’€êiÔÕêiÔQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQHHHZMëýáùÐ¨¦ï_ïÎ€ÊNýhÔSXÓï:�©¢9RPJ€q@¢Š(¢Š(¢Š(¢‘˜(%ŽîiD�e0ö&nbsp;QEQEQEQI¹sŒŒýhÜ=E-ÝëýáùÒ‚C@E”´SXÜ�Ž	”ú(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š(¢Š)¾´êhêhh¢Š(¢Š))h&nbsp;^¦�M^¦�@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@’4�a×"±åee"¶ëøø“ýãüèHYAýÓùÓØEz…Û´šŸíãýjþt[Íç+7@Ç¥UÔbEŒ:®·'ÖŸ¦Ç»½þj_ñî¿ïCF™ÿíþ÷ôrŠ†âu·MÇ’z
¯—W½
"öã­^¢³Åì°Ë²uqWY�—¹ãŒ�ž´ú+6KùC•Úžô³_H_÷\/¸ë@®âi¡Ú�sŸ­Gcnðî/Æ{S®ndƒ$E•þöi,®à¹l1€(Õ^êy!X÷/vÍW†ùØ¶åÜ…TP…™%åÌoó.ßb*õ´Âxƒã¡-Q@¯àO-¥
ž}êµœ+4¬¯œž*íÿüz·Ô:«¦¯o÷­Y6ãpüj¬öòZ�èço¨ã©QÜ(kyþé&nbsp;,®Ìß#ýñßÖ¬J¥âeŒVE©+sÞÅj\Jñ.R2ãœô&nbsp;
Ö–’Ç8wÀß­_ª6÷’Op€«Ï®³RÇ&nbsp;&nbsp;¢©=ÅÄƒtž§©¦A~þ`Y@Á8Î1ŠÐ¢Š­-ØWòâ_2OAÐPš+&gt;K‹¸¾gPéÅZ’gH•¼²Ù8=(j*”�5Â¦©ÍMqpÐ‚|¢Ê?‹<pôukk—¸‘·�‚­ÐepepepepepméÔßz�z(¢€Š( ¤¥¢€{Ó©«ÔÓ¨�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¢Š(�¬[�þ‘'ûÇùÖÉ uâ±g!§r��jý–="" ªzkxŒ(êfògÒ¥vvi�@õ?ø÷_÷¨Ó?ãÝ¿Þþ‚�i‡’£#;©4Â<†çu�a©17�v¯z="" zÇ�j©©Æw, qŒžÂpöásó="" pmlbe#ºÕ»mªg¶gëu5ón’8õ«Öñù0* s@—cý1Ç½kr»jŒØ¬›¢="" Û‘Ó5®="hïøôÃùÕ}/þZþÖ¬_öW¸þu_K" }?­�y½ÿ��i="">ŸÖªi`osß­Þ�-_éU4ÂŽ	ç€&amp;Ô‡î÷
I¦©o÷©Ú—ü{÷…7L#Ëqžs@h¢Š­ÿ­õ[Lÿ\ßîÿZ³~Ñ[ÜŠ©§2¤ÌY€{šÔ¨îlýÓAž%È¿�R¹¸k’"„;ûÐH^é=&amp;µ¤ÿVßCPÚ[ç—nµ4„Ø“Ž
eéÿñô&gt;†µ[NìmïšÊ° ].}
\ÔIÜwaš&gt;×ù"V|t
+&gt;àŸ´1+°ç8«Å
8s†'9ÇQUîŸÌ¸fÁõ&nbsp;
[‡)°êGLÁ�‰ë¶¯Êžl,&nbsp;ýáÅe@æÚã,0&nbsp;
i£ÆQŽô¥aòíL•Ýæ.&gt;´ÿ¼™â€2ì?ãí~†¯ÞÇ¬ŸJÍ·�Cp®Ã�Á«wWI$‘å‰œtÍ3ýcý+F³tÂ&lt;×ñZTQEQEQEQEQESiÔßZZ(¤&nbsp;Š(&nbsp;¤¥¢€zšu5zšuQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQE2HÒPŒ�Qý’ùæ?3SÑ@Gq6ä\c­KE[BìY�}è[XUƒ*`ƒ‘É©¨&nbsp;`À{®l`Î@#èjÍVñDr‰Ï¯z|‘¬‹µÆE:Šƒì�Ï1OŽâ$Æ¸Ï½IEE%¼R6ç\Ÿ­7ìp‘þ¦§¢€"’åmÎ¹=:Ó~ÇüóýMOE2HÒEÚã"˜¶°«TÁMMEQEG$1ÊFõÎ=éŸc·ÿžcó5=´€Ë1Rª**�ôê(¨ä…%ÆõÎ:sRQ@}Žùçúš“ËO/ËÆWÁ§Ñ@ÒÎ}ÁrGLœÓžÚ³&amp;I÷©¨&nbsp;GÄ»P`g4Ùmâ˜å×ŸQRÑ@–Æ9Á?SV´PZC#*A=piËoÆcòž¾õ-Øàÿž©©è¢€
(¢€
(¢€
(¢€
(¢€
(¢€
m:š(i)h&nbsp;¢Š(h¢ŠEêiÔÕêiÔQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQEQESGzu4w&nbsp;¢Š…</pôukk—¸‘·�‚­ðepepepepepméôßz�z(¢€š( ¤¥¢€{ó©«ôó¨�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¢š(�¬[�þ‘'ûçùöé></bi></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.math.uvic.ca/faculty/diacu/diacuNbody.pdf">https://www.math.uvic.ca/faculty/diacu/diacuNbody.pdf</a></em></p>]]>
            </description>
            <link>https://www.math.uvic.ca/faculty/diacu/diacuNbody.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24457977</guid>
            <pubDate>Sun, 13 Sep 2020 03:13:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fullscreen web apps on iPad Safari]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24457639">thread link</a>) | @marvindanig
<br/>
September 12, 2020 | https://bubblin.io/blog/fullscreen-api-ipad | <a href="https://web.archive.org/web/*/https://bubblin.io/blog/fullscreen-api-ipad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>Did you know that Apple rolled out support for the <a rel="nofollow" href="https://www.w3.org/TR/fullscreen/">Fullscreen API</a>
on iPad Safari last fall? Well, if you didn’t you do so now. 🙂</p>
<p>What this means is that developers can now create fully immersive web applications for the users on the iPad. It removes every distraction on the screen reliably to help the user focus on the task/content at hand—just like a native app would—and yet it allows them to get away if they wanted to by escaping fullscreen mode.</p>
<p>Meaning, more freedom and better accessibility features of the web! Personally, I think that this is a huge win for the web. <em>It is particularly useful for those of us who use an iPad as their “go to” device for surfing at night</em>. 🤘</p>
<p>While there are some issues in the current implementation of the fullscreen api on iPad Safari, that we will get into shortly, this update from Apple has been nothing short of a bonus for our startup. We built fullscreen capability right into Bubblin’s <a href="https://bubblin.io/">Superbooks</a> for the book-lovers on our site.</p>
<p>The following blogpost explains how we implemented it.</p>
<p>Before we start let’s take a look at the current level of <a rel="nofollow" href="https://caniuse.com/#feat=fullscreen" target="_blank">vendor support</a> for the fullscreen api:</p>
<p><img src="https://raw.githubusercontent.com/marvindanig/assets/master/fullscreen.jpg" width="100%" alt="fullscreen-api-ipad" title="support fullscreen api ipad safari"></p>
<blockquote>
<p><strong>Update:</strong> As of 1<sup>st</sup> March, 2019 most bugs around escaping fullscreen mode have been resolved by Apple.</p>
</blockquote>
<p>As you can see from Caniuse nearly all major browsers on the desktop and Android devices have had some level of support for the fullscreen API, and now the iOS Safari <del>doesn’t show the latest information</del> too has a decent level of support. <del>This feature was released on iOS 12.0 Safari (Now iPadOS Safari) barely a few days ago and as of November 4th, 2018 March 1st, 2019 Caniuse still doesn’t reflect the changes yet. Hopefully, it will be updated soon!</del> Updated.</p>
<p>Aside from familiar vendor prefixes, and varying method names and a few other minor inconsistencies across implementations, it doesn’t take much to be able to start using the fullscreen api on the iPadOS Safari.</p>
<p>❦</p>
<p>Here’s how I implemented using vanilla javascript:</p>
<p>First, define a named function <code>_toggleFullScreen</code> that lets you <em>toggle</em> between fullscreen and <code>url</code> mode:</p>
<div><div><pre><code>
<span>const</span> <span>_toggleFullScreen</span> <span>=</span> <span>function</span> <span>_toggleFullScreen</span><span>()</span> <span>{</span>
	<span>if</span> <span>(</span><span>document</span><span>.</span><span>fullscreenElement</span> <span>||</span> <span>document</span><span>.</span><span>mozFullScreenElement</span> <span>||</span> <span>document</span><span>.</span><span>webkitFullscreenElement</span><span>)</span> <span>{</span>
		<span>if</span> <span>(</span><span>document</span><span>.</span><span>cancelFullScreen</span><span>)</span> <span>{</span>
			<span>document</span><span>.</span><span>cancelFullScreen</span><span>();</span>
		<span>}</span> <span>else</span> <span>{</span>
			<span>if</span> <span>(</span><span>document</span><span>.</span><span>mozCancelFullScreen</span><span>)</span> <span>{</span>
				<span>document</span><span>.</span><span>mozCancelFullScreen</span><span>();</span>
			<span>}</span> <span>else</span> <span>{</span>
				<span>if</span> <span>(</span><span>document</span><span>.</span><span>webkitCancelFullScreen</span><span>)</span> <span>{</span>
					<span>document</span><span>.</span><span>webkitCancelFullScreen</span><span>();</span>
				<span>}</span>
			<span>}</span>
		<span>}</span>
	<span>}</span> <span>else</span> <span>{</span>
		<span>const</span> <span>_element</span> <span>=</span> <span>document</span><span>.</span><span>documentElement</span><span>;</span>
		<span>if</span> <span>(</span><span>_element</span><span>.</span><span>requestFullscreen</span><span>)</span> <span>{</span>
			<span>_element</span><span>.</span><span>requestFullscreen</span><span>();</span>
		<span>}</span> <span>else</span> <span>{</span>
			<span>if</span> <span>(</span><span>_element</span><span>.</span><span>mozRequestFullScreen</span><span>)</span> <span>{</span>
				<span>_element</span><span>.</span><span>mozRequestFullScreen</span><span>();</span>
			<span>}</span> <span>else</span> <span>{</span>
				<span>if</span> <span>(</span><span>_element</span><span>.</span><span>webkitRequestFullscreen</span><span>)</span> <span>{</span>
					<span>_element</span><span>.</span><span>webkitRequestFullscreen</span><span>(</span><span>Element</span><span>.</span><span>ALLOW_KEYBOARD_INPUT</span><span>);</span>
				<span>}</span>
			<span>}</span>
		<span>}</span>
	<span>}</span>
<span>};</span>
</code></pre></div></div>
<p>This <code>_toggleFullScreen</code> function takes care of all the vendor prefixes and browser quirks across the spectrum. Now we just have to find out which device, browser, and iOS version the user is on to enable the fullscreen functionality for them. We have to determine if the user is (1) <strong>on the iPad</strong> and (2) using the <strong>Safari browser</strong>, and (3) if the browser they are on is <strong>iOS 12 or higher</strong> already. All of that.</p>
<p>Fortunately (or unfortunately) the vendor sniffing technique comes to the rescue:</p>
<div><div><pre><code><span>const</span> <span>userAgent</span> <span>=</span> <span>window</span><span>.</span><span>navigator</span><span>.</span><span>userAgent</span><span>;</span>

<span>const</span> <span>iPadSafari</span> <span>=</span>
	<span>!!</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/iPad/i</span><span>)</span> <span>&amp;&amp;</span>  		<span>// Detect iPad first.</span>
	<span>!!</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/WebKit/i</span><span>)</span> <span>&amp;&amp;</span> 	<span>// Filter browsers with webkit engine only</span>
	<span>!</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/CriOS/i</span><span>)</span> <span>&amp;&amp;</span>		<span>// Eliminate Chrome &amp; Brave</span>
	<span>!</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/OPiOS/i</span><span>)</span> <span>&amp;&amp;</span>		<span>// Rule out Opera</span>
	<span>!</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/FxiOS/i</span><span>)</span> <span>&amp;&amp;</span>		<span>// Rule out Firefox</span>
	<span>!</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/FocusiOS/i</span><span>);</span>		<span>// Eliminate Firefox Focus as well!</span>

<span>const</span> <span>element</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'fullScreenButton'</span><span>);</span>

<span>function</span> <span>iOS</span><span>()</span> <span>{</span>
	<span>if</span> <span>(</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/ipad|iphone|ipod/i</span><span>))</span> <span>{</span>
		<span>const</span> <span>iOS</span> <span>=</span> <span>{};</span>
		<span>iOS</span><span>.</span><span>majorReleaseNumber</span> <span>=</span> <span>+</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/OS </span><span>(\d)?\d</span><span>_</span><span>\d(</span><span>_</span><span>\d)?</span><span>/i</span><span>)[</span><span>0</span><span>].</span><span>split</span><span>(</span><span>'_'</span><span>)[</span><span>0</span><span>].</span><span>replace</span><span>(</span><span>'OS '</span><span>,</span> <span>''</span><span>);</span>
		<span>return</span> <span>iOS</span><span>;</span>
	<span>}</span>
<span>}</span>

<span>if</span> <span>(</span><span>element</span> <span>!==</span> <span>null</span><span>)</span> <span>{</span>
	<span>if</span> <span>(</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/iPhone/i</span><span>)</span> <span>||</span> <span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/iPod/i</span><span>))</span> <span>{</span>
		<span>element</span><span>.</span><span>className</span> <span>+=</span> <span>' hidden'</span><span>;</span>
	<span>}</span> <span>else</span> <span>if</span> <span>(</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/iPad/i</span><span>)</span> <span>&amp;&amp;</span> <span>iOS</span><span>().</span><span>majorReleaseNumber</span> <span>&lt;</span> <span>12</span><span>)</span> <span>{</span>
		<span>element</span><span>.</span><span>className</span> <span>+=</span> <span>' hidden'</span><span>;</span>
	<span>}</span> <span>else</span> <span>if</span> <span>(</span><span>userAgent</span><span>.</span><span>match</span><span>(</span><span>/iPad/i</span><span>)</span> <span>&amp;&amp;</span> <span>!</span><span>iPadSafari</span><span>)</span> <span>{</span>
		<span>element</span><span>.</span><span>className</span> <span>+=</span> <span>' hidden'</span><span>;</span>
	<span>}</span> <span>else</span> <span>{</span>
		<span>element</span><span>.</span><span>addEventListener</span><span>(</span><span>'click'</span><span>,</span> <span>_toggleFullScreen</span><span>,</span> <span>false</span><span>);</span>
	<span>}</span>
<span>}</span>


</code></pre></div></div>
<p>We tested the code above on quite a few browsers on the iPad, but vendor sniffing, as you might already know, is an inefficient-cumbersome-avoid-as-much-as-you-can solution.</p>
<p>Going forward I expect more browsers on the iPad to support fullscreen api (maybe iPadOS Google Chrome will be next?) or that they will be ruled out using vendor sniffing. Given that support for fullscreen api on tablets will only improve over time, we can easily revisit the sniffer code above until this progressive enhancement melts into broader support.</p>
<blockquote>
<p>To see the above code working open a <a href="https://bubblin.io/book/bookiza-documentation-by-marvin-danig/1">Superbook on your iPad</a>, turn a few pages and go fullscreen (menu on bottom right under three dots).</p>
</blockquote>

<p>Here are a few sample <code>userAgent</code> strings that I used to identify browsers on the iPad:</p>
<h4 id="ipad-safari">iPad Safari:</h4>
<div><div><pre><code><span>Mozilla</span><span>/</span><span>5.0</span> <span>(</span><span>iPad</span><span>;</span> <span>CPU</span> <span>OS</span> <span>12</span><span>_1</span> <span>like</span> <span>Mac</span> <span>OS</span> <span>X</span><span>)</span> <span>AppleWebKit</span><span>/</span><span>605.1</span><span>.</span><span>15</span> <span>(</span><span>KHTML</span><span>,</span> <span>like</span> <span>Gecko</span><span>)</span> <span>Version</span><span>/</span><span>12.0</span> <span>Mobile</span><span>/</span><span>15</span><span>E148</span> <span>Safari</span><span>/</span><span>604.1</span>
</code></pre></div></div>
<h4 id="firefox-original">Firefox Original:</h4>
<div><div><pre><code><span>Mozilla</span><span>/</span><span>5.0</span> <span>(</span><span>iPad</span><span>;</span> <span>CPU</span> <span>OS</span> <span>12</span><span>_1</span> <span>like</span> <span>Mac</span> <span>OS</span> <span>X</span><span>)</span> <span>AppleWebKit</span><span>/</span><span>605.1</span><span>.</span><span>15</span> <span>(</span><span>KHTML</span><span>,</span> <span>like</span> <span>Gecko</span><span>)</span> <span>FxiOS</span><span>/</span><span>14.0</span><span>b12646</span> <span>Mobile</span><span>/</span><span>16</span><span>B92</span> <span>Safari</span><span>/</span><span>605.1</span><span>.</span><span>15</span>
</code></pre></div></div>
<h4 id="firefox-focus">Firefox Focus:</h4>
<div><div><pre><code><span>Mozilla</span><span>/</span><span>5.0</span> <span>(</span><span>iPad</span><span>;</span> <span>CPU</span> <span>OS</span> <span>12</span><span>_1</span> <span>like</span> <span>Mac</span> <span>OS</span> <span>X</span><span>)</span> <span>AppleWebKit</span><span>/</span><span>605.1</span><span>.</span><span>15</span> <span>(</span><span>KHTML</span><span>,</span> <span>like</span> <span>Gecko</span><span>)</span> <span>FocusiOS</span><span>/</span><span>7.0</span><span>.</span><span>3</span> <span>Mobile</span><span>/</span><span>16</span><span>B92</span> <span>Safari</span><span>/</span><span>605.1</span><span>.</span><span>15</span>
</code></pre></div></div>
<p>…and so on.</p>
<p>On the CSS side you may not have to make any changes, but there are few options to consider depending on your situation:</p>
<div><div><pre><code>
<span>:-webkit-full-screen</span> <span>body</span><span>,</span>
<span>:-moz-full-screen</span> <span>body</span><span>,</span>
<span>:-ms-fullscreen</span> <span>body</span> <span>{</span>
	<span>/* properties */</span>
	<span>width</span><span>:</span> <span>100vw</span><span>;</span>
	<span>height</span><span>:</span> <span>100vh</span><span>;</span>
<span>}</span>

<span>:full-screen</span> <span>body</span> <span>{</span>
	<span>/*pre-spec */</span>
	<span>/* properties */</span>
	<span>width</span><span>:</span> <span>100vw</span><span>;</span>
	<span>height</span><span>:</span> <span>100vh</span><span>;</span>
<span>}</span>

<span>:fullscreen</span> <span>body</span> <span>{</span>
	<span>/* spec */</span>
	<span>/* properties */</span>
	<span>width</span><span>:</span> <span>100vw</span><span>;</span>
	<span>height</span><span>:</span> <span>100vh</span><span>;</span>
<span>}</span>

<span>/* deeper elements */</span>

<span>:-webkit-full-screen</span> <span>body</span> <span>{</span>
	<span>width</span><span>:</span> <span>100vw</span><span>;</span>
	<span>height</span><span>:</span> <span>100vh</span><span>;</span>
<span>}</span>

<span>/* styling the backdrop*/</span>

<span>::backdrop</span><span>,</span>
<span>::-ms-backdrop</span> <span>{</span>
	<span>/* Custom styles */</span>
<span>}</span>


</code></pre></div></div>
<p>That’s it.</p>
<p>You now have a web-app that can easily go fullscreen on the iPad Safari and people can enjoy it like a standalone/native app without needing to add to the homescreen. Again, I think this is a huge win for the web and you might want to take advantage of it for your app.</p>
<hr>
<p><strong>Written by</strong>: Marvin Danig, I’m the CEO of Bubblin Superbooks but I also love to code. Follow me on <a href="https://twitter.com/marvindanig">Twitter</a> for more!</p>
<p><strong>Credits</strong>: Special thanks to Sonica Arora (<a href="https://twitter.com/sonicaaaaaa">@sonicaaaaaa</a>) and Abbey Rennemeyer (<a href="https://twitter.com/abbeyrenn">@abbeyrenn</a>), Editor of freeCodeCamp for all the editing help on this article.</p>
<p><strong>P.S.:</strong> It’s likely that some of you read this article on your desktop. I recommend revisiting on your iPad. It’s about post-PC era you know. 🙈</p>
</div></div>]]>
            </description>
            <link>https://bubblin.io/blog/fullscreen-api-ipad</link>
            <guid isPermaLink="false">hacker-news-small-sites-24457639</guid>
            <pubDate>Sun, 13 Sep 2020 02:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the Monte Carlo Tree Search Algorithm in an AI to Beat 2048]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24457625">thread link</a>) | @xtrp
<br/>
September 12, 2020 | https://xtrp.io/blog/2020/09/12/using-the-monte-carlo-tree-search-algorithm-in-an-ai-to-beat-2048-and-other-games/ | <a href="https://web.archive.org/web/*/https://xtrp.io/blog/2020/09/12/using-the-monte-carlo-tree-search-algorithm-in-an-ai-to-beat-2048-and-other-games/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I recently worked on an open source <a href="https://jupiter.xtrp.io/">project called Jupiter</a>, an online AI to beat the popular online game <a href="http://play2048.co/">2048</a>.</p>
<p>Go try out the AI:</p>
<p><a href="https://jupiter.xtrp.io/"><img src="https://raw.githubusercontent.com/xtrp/jupiter/master/demo-image.png" alt="Jupiter Screenshot"></a></p>
<p>In writing this AI, I decided to use a machine learning method called the Monte Carlo Tree Search (MCTS) algorithm. Monte Carlo algorithms like the one used in Jupiter have been used in several notable AIs, including DeepMind's <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a>, which famously beat the Go world champion in May 2017.</p>
<p>In this article, I'll explain:</p>
<ul>
<li>How and why the Monte Carlo method works</li>
<li>When and where Monte Carlo algorithms can be useful </li>
<li>How I used the Monte Carlo method in an AI to beat 2048</li>
<li>How to implement Monte Carlo algorithms in JavaScript and other languages</li>
</ul>
<p>Note: I got the idea of using a Monte Carlo method to beat 2048 from <a href="https://stackoverflow.com/a/23853848/10007107">this StackOverflow answer</a>.</p>
<h2>What is the Monte Carlo Method?</h2>
<p>The Monte Carlo method is the idea of using a large number of random simulations of an experiment to gain insights into the experiment's end results. Random simulations of an experiment are frequently referred to as <em>Monte Carlo simulations</em>.</p>
<p>For example, let's say that you were flipping a coin, and trying to figure out the probability of the coin landing heads. With the Monte Carlo method, we could simulate 10,000 coin tosses, and calculate the percentage of coins that landed heads.</p>
<p>Here's what that would look like.</p>
<p><img src="https://xtrp.io/api/content/static_files/using-the-monte-carlo-tree-search-algorithm-in-an-ai-to-beat-2048-and-other-games/coinflip.png" alt="Flip Coin Example Graph"></p>
<p>As can be seen, the result converges to the expected value, 50%. A notable feature of Monte Carlo simulations is that a higher number of simulations is correlated with higher accuracy. For example, if we only performed two simulations, there is a high (25%) probability of heads landing in both simulations, giving a result of 100%. This is very inaccurate in comparison to the expected result of 50%.</p>
<p>Monte Carlo simulations <strong>work because of the Law of Large Numbers</strong>, which says:</p>
<blockquote>
<p>If you simulate the same experiment many times, the average of the results should converge to the expected value of the simulation.</p>
</blockquote>
<p>In other words, Monte Carlo simulations are a way to estimate what will happen in a given experiment <strong>without having to implement any specific algorithms or heuristics</strong>.</p>
<h2>When and Where the Monte Carlo Method Can Be Useful</h2>
<p>The Monte Carlo method is used in a variety of fields, including game AI development, finance and economics, and evolutionary biology to name a few.</p>
<p>The Monte Carlo method can be useful in any experiment with a random factor, where end results cannot be predicted algorithmically. For example, in 2048, a new tile at a random location is added after every move, making it impossible to calculate the exact location of upcoming tiles and subsequently the end result of the game as well.</p>
<p>In these types of experiments, running a large number of Monte Carlo simulations can help get a sense of the average end results, the probability of various events occurring, and the relationship between the variables in the experiment.</p>
<p>For example, using the Monte Carlo method to in Jupiter allowed me to better understand how variables like starting move, number of moves in a game, and best tile in the board affected the end results of the game.</p>
<h2>How I Used the Monte Carlo Method in Jupiter, an AI to Beat 2048</h2>
<p>Let's start with a few definitions:</p>
<ul>
<li><strong>Board and Tiles</strong>: a 4x4 grid with tiles optionally placed on each grid spot</li>
<li><strong>Game State</strong>: a set of tiles on the board which represents the board at a specific time</li>
<li><strong>Game Score</strong>: the sum of all the tiles on the board</li>
<li><strong>Real Game</strong>: the game that is being played and shown on the browser, not a simulation</li>
</ul>
<p>At any given game state, let's assume that four possible moves can be made: left, right, up, or down.</p>
<blockquote>
<p>There are indeed cases where a certain move is not possible in a given game state. Removing impossible moves can be easily added to the algorithm later.</p>
</blockquote>
<p>With the Monte Carlo method, we can run a set of game simulations for every move.</p>
<p>For each possible move, the program simulates a set of simulations which <strong>start by playing the move for that set first</strong>. After that, the rest of the game can be played completely randomly until it is over.</p>
<p>In JavaScript, this algorithm looks something like:</p>
<pre><code>// assume Game object exists
// assume currentGame variable exists as the real game

const totalSimulations = 200; // 50 simulations are played for each move 

const possibleMoves = ["left", "right", "down", "up"];
possibleMoves.forEach((move) =&gt; { // simulations for all four possible starting moves
  for(let i = 0; i &lt; totalSimulations / 4; i++) {
    const simulation = new Game(); // create simulation
    simulation.board = currentGame.board; // copy current game state to simulation
    simulation.makeMove(move); // make initial move
    while(!simulation.gameover()) {
      simulation.makeMove(possibleMoves[Math.floor(Math.random() * 4)]);
    } // make random moves until simulation game is over
  }
});</code></pre>
<p>After all the simulations are completed, the program can gather the total final game scores of all the simulations, and average them for each move. We can then find the optimal move by optimizing for the highest final game score.</p>
<p>For example, if the simulations which started by playing left had an average final score of 250, whereas the ones which started by playing the other moves had an average final game score of 225, then left is the optimal move.</p>
<p>In this program, <strong>the optimal move is the one with simulations with the highest average final game score</strong>.</p>
<blockquote>
<p><strong>Note: I could have chosen to optimize for a different value such as the number of moves in the game.</strong></p>
<p>However, this would actually make no difference in how the algorithm functions, because the number of moves in the game almost exactly predicts the game score. In 2048, the new tile added after each game move is normally a 2 tile, but has a 10% chance of being a 4 tile instead. This means the expected value of the new tile is 2.2 (<code>2 × 90% + 4 × 10%</code>). The total value of tiles is also preserved after every tile combination (ex: 2 tile combined with another 2 tile gives a 4 tile). As a result, game score can be calculated by multiplying the expected value of the new tile by the number of moves in the game, or with this formula: <code>2.2 × (real game move count + average move count)</code>.</p>
</blockquote>
<p>To add this functionality of optimizing for highest score to our current code: add an array of total final scores for the simulations for each possible move, and choose the move with the highest value in that array to play like so:</p>
<pre><code>const possibleMoves = ["left", "right", "down", "up"];
const totalSimulations = 200;

let moveSimulationTotalScores = [0, 0, 0, 0];

possibleMoves.forEach((move, moveIndex) =&gt; { // simulations for all four possible starting moves
  for(let i = 0; i &lt; totalSimulations / 4; i++) {
    const simulation = new Game(); // create simulation
    simulation.board = currentGame.board; // copy current game state to simulation
    simulation.makeMove(move); // make initial move
    while(!simulation.gameover()) {
      simulation.makeMove(possibleMoves[Math.floor(Math.random() * 4)]);
    } // make random moves until simulation game is over
    moveSimulationTotalScores[moveIndex] += simulation.getScore();
  }
});

// make best move with highest total simulation scores
let topScore = Math.max(...moveSimulationTotalScores);
let topScoreIndex = moveSimulationTotalScores.indexOf(topScore);
let bestMove = possibleMoves[topScoreIndex];

currentGame.makeMove(bestMove);</code></pre>
<p>In the end, this algorithm is simple to implement given a well-written 2048 game class. In JavaScript, there are a number of performance upgrades that can be made, starting by adding concurrency with <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API">Web Workers</a> and pruning moves with very low final game scores.</p>
<h2>Conclusion</h2>
<p>I hope you enjoyed this post, and found it useful in helping you understand and implement the Monte Carlo method in your own projects.</p>
<p>Go check out <a href="https://jupiter.xtrp.io/">Jupiter</a> and <a href="https://github.com/xtrp/jupiter">its source code</a>.</p>
<p>Thanks for scrolling.</p>
<p><em>— Gabriel Romualdo, September 12, 2020</em></p></div></div>]]>
            </description>
            <link>https://xtrp.io/blog/2020/09/12/using-the-monte-carlo-tree-search-algorithm-in-an-ai-to-beat-2048-and-other-games/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24457625</guid>
            <pubDate>Sun, 13 Sep 2020 02:14:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bayesian Data Analysis Course]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24456382">thread link</a>) | @noch
<br/>
September 12, 2020 | https://avehtari.github.io/BDA_course_Aalto/ | <a href="https://web.archive.org/web/*/https://avehtari.github.io/BDA_course_Aalto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<!--/.navbar -->




<p>This is the web page for the Bayesian Data Analysis course at Aalto (CS-E5710) by <a href="https://users.aalto.fi/~ave/">Aki Vehtari</a>.</p>
<p>Aalto students should check also <a href="https://mycourses.aalto.fi/user/index.php?id=28239">MyCourses announcements</a>. In Autumn 2020 the course will be arranged completely online. This web page will be much updated during the August.</p>
<p>All the course material is available in a <a href="https://github.com/avehtari/BDA_course_Aalto">git repo</a> (and these pages are for easier navigation). All the material can be used in other courses. Text (except the BDA3 book) and videos licensed under CC-BY-NC 4.0. Code licensed under BSD-3.</p>
<div>
<p><img src="https://avehtari.github.io/BDA_course_Aalto/bda_cover.png">

</p>
</div>
<p><a href="https://users.aalto.fi/~ave/BDA3.pdf">The electronic version of the course book Bayesian Data Analysis, 3rd ed, by by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin</a> is available for non-commercial purposes. Hard copies are available from <a href="https://www.crcpress.com/Bayesian-Data-Analysis/Gelman-Carlin-Stern-Dunson-Vehtari-Rubin/p/book/9781439840955">the publisher</a> and many book stores. See also <a href="http://www.stat.columbia.edu/~gelman/book/">home page for the book</a>, <a href="http://www.stat.columbia.edu/~gelman/book/errata_bda3.txt">errata for the book</a>, and <a href="https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes.pdf">chapter notes</a>.</p>
<div id="prerequisites">
<h2>Prerequisites</h2>
<ul>
<li>Basic terms of probability theory
<ul>
<li>probability, probability density, distribution</li>
<li>sum, product rule, and Bayes' rule</li>
<li>expectation, mean, variance, median</li>
<li>in Finnish, see e.g. <a href="http://math.aalto.fi/~lleskela/LectureNotes003.html">Stokastiikka ja tilastollinen ajattelu</a></li>
<li>in English, see e.g. Wikipedia and <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/">Introduction to probability and statistics</a></li>
</ul></li>
<li>Some algebra and calculus</li>
<li>Basic visualisation techniques (R or Python)
<ul>
<li>histogram, density plot, scatter plot</li>
<li>see e.g. <a href="https://avehtari.github.io/BDA_course_Aalto/demos.html#BDA_R_demos">BDA R demos</a></li>
<li>see e.g. <a href="https://avehtari.github.io/BDA_course_Aalto/demos.html#BDA_Python_demos">BDA Python demos</a></li>
</ul></li>
</ul>
<p>This course has been designed so that there is strong emphasis in computational aspects of Bayesian data analysis and using the latest computational tools.</p>
<p>If you find BDA3 too difficult to start with, I recommend</p>
<ul>
<li>For regression models, their connection to statistical testing and causal analysis see <a href="https://avehtari.github.io/ROS-Examples/">Gelman, Hill and Vehtari, "Regression and Other Stories"</a>.</li>
<li>Richard McElreath's <a href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking, 2nd ed</a> book is easier than BDA3 and the 2nd ed is excellent. Statistical Rethinking doesn't go as deep in some details, math, algorithms and programming as BDA course. Richard's lecture videos of <a href="https://github.com/rmcelreath/statrethinking_winter2019">Statistical Rethinking: A Bayesian Course Using R and Stan</a> are highly recommended even if you are following BDA3.</li>
<li>For background prerequisites some students have found chapters 2, 4 and 5 in <a href="https://sites.google.com/site/doingbayesiandataanalysis/">Kruschke, "Doing Bayesian Data Analysis"</a> useful.</li>
</ul>
</div>
<div id="course-contents-following-bda3">
<h2>Course contents following BDA3</h2>
<p>Bayesian Data Analysis, 3rd ed, by by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin. <a href="http://www.stat.columbia.edu/~gelman/book/">Home page for the book</a>. <a href="http://www.stat.columbia.edu/~gelman/book/errata_bda3.txt">Errata for the book</a>. <a href="https://users.aalto.fi/~ave/BDA3.pdf">Electronic edition for non-commercial purposes only</a>.</p>
<ul>
<li>Background (Ch 1, Lecture 1)</li>
<li>Single-parameter models (Ch 2, Lecture 2)</li>
<li>Multiparameter models (Ch 3, Lecture 3)</li>
<li>Computational methods (Ch 10 , Lecture 4)</li>
<li>Markov chain Monte Carlo (Chs 11-12, Lectures 5-6)</li>
<li>Extra material for Stan and probabilistic programming (see below, Lecture 6)</li>
<li>Hierarchical models (Ch 5, Lecture 7)</li>
<li>Model checking (Ch 6, Lectures 8-9)
<ul>
<li>+ <a href="https://doi.org/10.1111/rssa.12378">Visualization in Bayesian workflow</a></li>
</ul></li>
<li>Evaluating and comparing models (Ch 7)
<ul>
<li>+ <a href="https://arxiv.org/abs/1507.04544">Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC</a> (<a href="https://doi.org/10.1007/s11222-016-9696-4">Journal link</a>)</li>
<li>+ <a href="https://avehtari.github.io/modelselection/">Videos and case studies</a></li>
<li>+ <a href="https://avehtari.github.io/modelselection/CV-FAQ.html">Cross-validation FAQ</a></li>
</ul></li>
<li>Decision analysis (Ch 9, Lecture 10)</li>
<li>Large sample properties and Laplace approximation (Ch 4, Lecture 11-12)</li>
<li>In addition you learn workflow for Bayesian data analysis</li>
</ul>
</div>
<div id="how-to-study">
<h2>How to study</h2>
<p>Recommended way to go through the material is</p>
<ul>
<li>Read the reading instructions for a chapter in <a href="https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes.pdf">chapter notes</a>.</li>
<li>Read the chapter in BDA3 and check that you find the terms listed in the reading instructions.</li>
<li>Watch the corresponding <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Sessions/List.aspx#folderID=%22f0ec3a25-9e23-4935-873b-a9f401646812%22">lecture video</a> to get explanations for most important parts.</li>
<li>Read corresponding additional information in the <a href="https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes.pdf">chapter notes</a>.</li>
<li>Run the corresponding demos in <a href="https://github.com/avehtari/BDA_R_demos">R demos</a> or <a href="https://github.com/avehtari/BDA_py_demos">Python demos</a>.</li>
<li>Read the exercise instructions and make the corresponding <a href="https://github.com/avehtari/BDA_course_Aalto/tree/master/assignments">assignments</a>. Demo codes in <a href="https://github.com/avehtari/BDA_R_demos">R demos</a> and <a href="https://github.com/avehtari/BDA_py_demos">Python demos</a> have a lot of useful examples for handling data and plotting figures. If you have problems, visit TA sessions or ask in course slack channel.</li>
<li>If you want to learn more, make also self study exercises listed below</li>
</ul>
</div>
<div id="slides-and-chapter-notes">
<h2>Slides and chapter notes</h2>
<ul>
<li><a href="https://github.com/avehtari/BDA_course_Aalto/tree/master/slides">Slides</a>
<ul>
<li>including code for reproducing some of the figures</li>
</ul></li>
<li><a href="https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes.pdf">Chapter notes</a>
<ul>
<li>including reading instructions highlighting most important parts and terms</li>
</ul></li>
</ul>
</div>
<div id="videos">
<h2>Videos</h2>
<p>The following video motivates why computational probabilistic methods and probabilistic programming are important part of modern Bayesian data analysis.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=ukE5aqdoLZI">Computational probabilistic modeling in 15mins</a></li>
</ul>
<p>Short video clips on selected introductory topics are available in <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Sessions/List.aspx#folderID=%22f0ec3a25-9e23-4935-873b-a9f401646812%22">a Panopto folder</a> and listed below.</p>
<ul>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=d841f429-9c3d-4d24-8228-a9f400efda7b">1.1 Introduction to uncertainty and modelling</a></li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=13fc7889-cfd1-4d99-996c-a9f400f6e5a2">1.2 Introduction to the course contents</a></li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7a297f7d-bb7b-4dd0-9913-a9f500ec822d">2.1 Observation model, likelihood, posterior and binomial model</a></li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=75b9f18f-e379-4557-a5fa-a9f500f11b40">2.2 Predictive distribution and benefit of integration</a></li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=099659a5-f707-473d-8b03-a9f500f39eb5">2.3 Priors and prior information</a></li>
</ul>
<p>2019 fall lecture videos are in <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Sessions/List.aspx#folderID=%22f0ec3a25-9e23-4935-873b-a9f401646812%22">a Panopto folder</a> and listed below.</p>
<ul>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=9c271082-5a8c-4b66-b6c2-aacc00fc683f">Lecture 2.1</a> and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=70655a8a-0eb4-4ddd-9f52-aacc00fc67a2">Lecture 2.2</a> on basics of Bayesian inference, observation model, likelihood, posterior and binomial model, predictive distribution and benefit of integration, priors and prior information, and one parameter normal model. BDA3 Ch 1+2.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=ab958b4b-e2c4-4534-8305-aad100ba191f">Lecture 3</a> on multiparameter models, joint, marginal and conditional distribution, normal model, bioassay example, grid sampling and grid evaluation. BDA3 Ch 3.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=8a3c7bbc-e2b8-4c16-97b2-aad800ba7927">Lecture 4.1</a> on numerical issues, Monte Carlo, how many simulation draws are needed, how many digits to report, and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=44446861-eaa2-41b5-bf33-aad800caf18a">Lecture 4.2</a> on direct simulation, curse of dimensionality, rejection sampling, and importance sampling. BDA3 Ch 10.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=098dfdb4-f3b8-46aa-b988-aadf00bd3177">Lecture 5.1</a> on Markov chain Monte Carlo, Gibbs sampling, Metropolis algorithm, and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=9f657178-d8cf-4cb8-af62-aadf00cd9423">Lecture 5.2</a> on warm-up, convergence diagnostics, R-hat, and effective sample size. BDA3 Ch 11.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=1744f6a0-84d3-4218-8a86-aae600ba7e84">Lecture 6.1</a> on HMC, NUTS, dynamic HMC and HMC specific convergence diagnostics, and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=e60ba1a9-f752-4b0a-88c6-aae600caa61a">Lecture 6.2</a> on probabilistic programming and Stan. BDA3 Ch 12 + <a href="#stan">extra material</a>.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=79dee6de-afa9-446f-b533-aaf400cabf2b">Lecture 7.1</a> on hierarchical models, and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=c822561c-f95d-44fc-a1d0-aaf400d9fae3">Lecture 7.2</a> on exchangeability. BDA3 Ch 5.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=2820df34-d958-4c6c-93f3-aaf400dece37">Project work info</a></li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7047e366-0df6-453c-867f-aafb00ca2d78">Lecture 8.1</a> on model checking, and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=d7849131-0afd-4ae6-ad64-aafb00da36f4">Lecture 8.2</a> on cross-validation part 1. BDA3 Ch 6-7 + extra material.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=50b2e73f-af0a-4715-b627-ab0200ca7bbd">Lecture 9.1</a> PSIS-LOO and K-fold-CV, <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=b0299d53-9454-4e33-9086-ab0200db14eeb">Lecture 9.2</a> model comparison and selection, and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=4b6eeb48-ae64-4860-a8c3-ab0200e40ad8">Lecture 9.3</a> extra lecture on variable selection with projection predictive variable selection. Extra material.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=82943720-de0f-4195-8639-ab0900ca2085">Lecture 10.1</a> on decision analysis. BDA3 Ch 9.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=cad1e8f8-e1f0-408a-ad9d-ab0900db3977">Project presentation info</a></li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=e22fedc7-9fd3-4d1e-8318-ab1000ca45a4">Lecture 11.1</a> on normal approximation (Laplace approximation) and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=a8e38a95-a944-4f3d-bf95-ab1000dbdf73">Lecture 11.2</a> on large sample theory and counter examples. BDA3 Ch 4.</li>
<li><a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=e998b5dd-bf8e-42da-9f7c-ab1700ca2702">Lecture 12.1</a> on frequency evaluation, hypothesis testing and variable selection and <a href="https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=c43c862a-a5a4-45da-9b27-ab1700e12012">Lecture 12.2</a> overview of modeling data collection, BDA3 Ch 8, linear models, BDA Ch 14-18, lasso, horseshoe and Gaussian processes, BDA3 Ch 21.</li>
</ul>
</div>


<div id="self-study-exercises">
<h2>Self study exercises</h2>
<p>Great self study BDA3 exercises for this course are listed below. Most of these have also <a href="http://www.stat.columbia.edu/~gelman/book/solutions3.pdf">model solutions available</a>.</p>
<ul>
<li>1.1-1.4, 1.6-1.8 (model solutions for 1.1-1.6)</li>
<li>2.1-2.5, 2.8, 2.9, 2.14, 2.17, 2.22 (model solutions for 2.1-2.5, 2.7-2.13, 2.16, 2.17, 2.20, and 2.14 is in slides)</li>
<li>3.2, 3.3, 3.9 (model solutions for 3.1-3.3, 3.5, 3.9, 3.10)</li>
<li>4.2, 4.4, 4.6 (model solutions for 3.2-3.4, 3.6, 3.7, 3.9, 3.10)</li>
<li>5.1, 5.2 (model solutions for 5.3-5.5, 5.7-5.12)</li>
<li>6.1 (model solutions for 6.1, 6.5-6.7)</li>
<li>9.1</li>
<li>10.1, 10.2 (model solution for 10.4)</li>
<li>11.1 (model solution for 11.1)</li>
</ul>
</div>


<div id="acknowledgements">
<h2>Acknowledgements</h2>
<p>The course material has been greatly improved by the previous and current course assistants (in alphabetical order): Michael Riis Andersen, Paul Bürkner, Akash Dakar, Alejandro Catalina, Kunal Ghosh, Joona Karjalainen, Juho Kokkala, Måns Magnusson, Janne Ojanen, Topi Paananen, Markus Paasiniemi, Juho Piironen, Jaakko Riihimäki, Eero Siivola, Tuomas Sivula, Teemu Säilynoja, Jarno Vanhatalo.</p>
<p>The web page has been made with rmarkdown’s site generator.</p>
</div>



</div></div>]]>
            </description>
            <link>https://avehtari.github.io/BDA_course_Aalto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24456382</guid>
            <pubDate>Sat, 12 Sep 2020 22:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you find giving feedback hard, read this for advice]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24456112">thread link</a>) | @ochronus
<br/>
September 12, 2020 | https://ochronus.online/thoughts-on-feedback/ | <a href="https://web.archive.org/web/*/https://ochronus.online/thoughts-on-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <figure>
    <picture>
        <source type="image/webp" media="(max-width: 400px)" srcset="https://ochronus.online/post-images/responsive/300/thoughts-on-feedback.webp" alt="Thoughts on feedback">
        <source type="image/webp" media="(max-width: 800px)" srcset="https://ochronus.online/post-images/responsive/600/thoughts-on-feedback.webp" alt="Thoughts on feedback">
        <source type="image/webp" media="(max-width: 1400px)" srcset="https://ochronus.online/post-images/responsive/1000/thoughts-on-feedback.webp" alt="Thoughts on feedback">
        <source type="image/webp" media="(max-width: 1900px)" srcset="https://ochronus.online/post-images/responsive/1600/thoughts-on-feedback.webp" alt="Thoughts on feedback">
        <source type="image/webp" media="(min-width: 2000px)" srcset="https://ochronus.online/post-images/responsive/2000/thoughts-on-feedback.webp" alt="Thoughts on feedback">

        <source type="image/jpeg" media="(max-width: 400px)" srcset="https://ochronus.online/post-images/responsive/300/thoughts-on-feedback.jpeg" alt="Thoughts on feedback">
        <source type="image/jpeg" media="(max-width: 800px)" srcset="https://ochronus.online/post-images/responsive/600/thoughts-on-feedback.jpeg" alt="Thoughts on feedback">
        <source type="image/jpeg" media="(max-width: 1400px)" srcset="https://ochronus.online/post-images/responsive/1000/thoughts-on-feedback.jpeg" alt="Thoughts on feedback">
        <source type="image/jpeg" media="(max-width: 1900px)" srcset="https://ochronus.online/post-images/responsive/1600/thoughts-on-feedback.jpeg" alt="Thoughts on feedback">
        <source type="image/jpeg" media="(min-width: 2000px)" srcset="https://ochronus.online/post-images/responsive/2000/thoughts-on-feedback.jpeg" alt="Thoughts on feedback">


        <img src="https://ochronus.online/post-images/responsive/2000/thoughts-on-feedback.webp" alt="Thoughts on feedback">
    </picture>
</figure><p>

A good, blameless feedback culture is essential for working together efficiently as it forms healthy relationships, fuels personal and professional growth and aligns us with common norms. Feedback is one of the cornerstones of company culture.</p>
<p>All that said I’ve found that giving good feedback is quite problematic for most of the people (me included!). There’s a social stigma to giving so-called constructive feedback (see, even the name is somewhat of a euphemism), we feel we’re expected to be nice to each other and surely telling someone they were wrong is not nice. We also tend to be way too simple and not specific when giving praise - no, a simple ‘well done’ is usually not considered as useful feedback.</p>
<p>Let me share with you a few key points about giving useful feedback. I promise it’s all easy and trivial, you just need to consciously practice it.</p>
<h2 id="the-how">The how</h2>
<p>One of the most important things is getting buy-in for providing feedback. That gives back some of the control to the recipient and helps in having a more open mindset compared to unsolicited feedback. Simply ask if the other party is open to talk about the certain topics. Give some context so they can decide. E.g. “May I share some thoughts about the daily standup we had today?”
Be objective and be specific. These support each other, generalization tends to lead to giving feedback on perceived character traits which is a huge anti-pattern (“You always commit bad code.").
There are a few feedback models out there, what worked the best for me is the SBI (Situation - Behavior - Impact) model. This helps in giving enough context and specificity and being objective. An example: “During the standup today you didn’t mention you were blocked in your work and by this we missed our chance to deploy today, resulting in a delay in delivery.”</p>
<ul>
<li>Don’t use the feedback sandwich technique (starting with a compliment, then negative feedback, then an optional compliment again). Unfortunately it’s still something certain coaches suggest - my advice is that it’s not OK. There’s a reason some call it sh*t sandwich. It shows that you’re not confident in your communication and gives mixed signals, practically killing the actionability of your feedback.</li>
<li>Don’t include suggestions in your feedback! That’s the next step, but it’s not part of the feedback. It’s very easy to slip into this anti-pattern: “Why didn’t you just use library X? That would make so much sense”. First, this is not feedback, this is question, second it’s not objective but you’re talking about your opinion, not the other person’s behavior and its effect.</li>
<li>Follow the SBI model even for praises! We tend to oversimplify positive feedback. A pat on the shoulder, a thumbs-up or a ‘nice job!’ has its place and value but the point of positive feedback is more than just recognition: it’s also to make the other person understand what exactly went well in what context and how to repeat that in the future. It’s much nicer to hear “By helping me out with data about the costs during my presentation yesterday we successfully convinced the board to fund our roadmap, thank you for that!” vs. “Thx for the help!”</li>
<li>It’s even better to focus on data than behavior (if you can).</li>
<li>Always leave room for the other party to express their thoughts on the matter and even disagree. You can facilitate this by asking how they feel about the issue.</li>
<li>Make sure to agree on a course of actions together. It’s not enough to drop your feedback and leave. You can help guide this process but the ownership lies with the recipient of the feedback (and yes, they can choose not to take action but they should be clear about that and their reasons). Ask guiding questions like “What are our action items here?” or “How can we make sure next time you feel safe to talk about your blockers during standup?”.</li>
<li>Remember I said don’t generalize? Well if it’s a positive feedback it can actually help and encourage if you talk about patterns in the recipient’s behavior. “I’ve noticed that you give awesome presentations lately, for example this last time about Kubernetes….”</li>
<li>It’s completely OK to talk about your feelings in the situation you’re describing, just make sure you’re explicit about them being feelings and not facts. “When you interrupted me during my presentation last Tuesday I felt really disrespected and undervalued” (v.s. “You don’t respect me”).</li>
</ul>
<h2 id="the-when">The when</h2>
<ul>
<li>Timely feedback is key. Give feedback as soon as you can - hopefully the same day the event that you’re giving feedback about happened. Why? First, both of you still have the context fresh in your minds, second, this way a mental connection is formed between action and reaction.</li>
<li>Unless you have good experience in it don’t give instant feedback. Make sure you give yourself some breathing space and time to consider how you want to deliver your message. This is especially true for emotionally loaded situations.</li>
<li>As a rule of thumb praise publicly and criticize privately. Of course it’s completely OK to repeat praise in a private setting and rephrase/clarify it.</li>
</ul>
<p>Finally, giving good feedback is as much about forming the habit as skills. Make sure you practice it, I guarantee you can find good occasions almost each day if you look closely.</p>

      </div></div>]]>
            </description>
            <link>https://ochronus.online/thoughts-on-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24456112</guid>
            <pubDate>Sat, 12 Sep 2020 21:46:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust in 2021]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24455827">thread link</a>) | @bpierre
<br/>
September 12, 2020 | https://matklad.github.io/2020/09/12/rust-in-2021.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/09/12/rust-in-2021.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>And now to something completely different!
I want this:</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td><pre>$ git clone git@github.com:rust-lang/rust.git &amp;&amp; cd rust
$ cargo t
info: syncing channel updates for 'beta-x86_64-unknown-linux-gnu'
info: latest update on 2020-09-10, rust version 1.47.0-beta
info: downloading component 'cargo'
info: downloading component 'rustc'
info: installing component 'cargo'
info: installing component 'rustc'
Compiling unicode-xid v0.2.1
Compiling proc-macro2 v1.0.20

...

Finished test [unoptimized] target(s) in 5m 45s
  Running target/debug/deps/rustc-bf0145d0690d0fbc

running 9001 tests

...

test result: ok. 9001 passed;  in 1m 3s
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>That is, I want to simplify working on the compiler itself to it being just a crate.
This section of the article expands on the comment I’ve made on the
<a href="https://internals.rust-lang.org/t/experience-report-contributing-to-rust-lang-rust/12012/17?u=matklad">irlo</a>
a while ago.</p>
<p>Since a couple of months ago, I am slowly pivoting from doing mostly green field dev in the rust-analyzer’s code base to refactoring <code>rustc</code> internals towards merging the two.
The process has been underwhelming, and slow and complicated build process plays a significant part in this: I feel like my own productivity is at least five times greater when I work on <code>rust-analyzer</code> in comparison to <code>rustc</code>.</p>
<p>Before I go into details about my vision here, I want to give shout-outs to
<a href="https://github.com/Mark-Simulacrum/">@Mark-Simulacrum</a>, <a href="https://github.com/mark-i-m">@mark-i-m</a>, and <a href="https://github.com/jyn514">@jyn514</a>
who already did a lot of work on simplifying the build process in the recent several months.</p>
<p>Note that I am going to make a slightly deeper than “Rust in 20XX” dive into the topic, feel free to skip the rest of the post if technical details about bootstrapping process are not your cup of tea.</p>
<p>Finally, I also should warn that I have an intern advantage here — I have absolutely no idea about how Rust’s current build process works, so I tell how it should work from the position of ignorance. Without further ado,</p>
<div>
<h3 id="how-simple-could-the-build-process-be"><a href="#how-simple-could-the-build-process-be"></a>How Simple Could the Build Process Be?</h3>
<p><code>rustc</code> is a bootstrapping compiler.
This means that, to compile <code>rustc</code> itself, one needs to have a previous version of <code>rustc</code> available.
This <em>could</em> make compiler’s build process peculiar.
My thesis is that this doesn’t need to be the case, and that the compiler could be just a crate.</p>
<p>Bootstrapping does make this harder to see though, so, as a thought experiment, let’s imagine what would <code>rustc</code>'s build process look like were it not written in Rust.
Let’s imagine the world where <code>rustc</code> is implemented in Go.
How would one build and test this rust compiler?</p>
<p>First, we clone the <code>rust-lang/rust</code> repository.
Then we download the latest version of the Go compiler — as we are shipping <code>rustc</code> binaries to the end user, it’s OK to require a cutting-edge compiler.
But there’s probably some script or gvm config file to make getting the latest Go compiler easier.
After that, <code>go test</code> builds the compiler and runs the unit tests.
Unit tests take a snippet of Rust code as an input and check that the compiler correctly analyses the snippet: that the parse tree is correct, that diagnostics are emitted, that borrow checker correctly accepts or rejects certain problems.</p>
<p>What we can not check in this way is that the compiler is capable of producing a real binary which we can run (that is, <code>run-pass</code> tests).
The reason for that is slightly subtle — to produce a binary, compiler needs to link the tested code with the standard library.
But we’ve only compiled the compiler, we don’t have a standard library yet!</p>
<p>So, in addition to unit-tests, we also need somewhat ad-hoc integration tests, which assume that the compiler has been build already, use it to compile the standard library, and then compile, link, and run the corpus of the test programs.
Running std’s own <code>#[test]</code> tests is also a part of this integration testing.</p>
<p>Now, let’s see if the above setup has any bottlenecks:</p>
<div>
<ol>
<li>
<p>Getting the Go compiler is fast and straightforward.
In fact, it’s reasonable to assume that the user already have a recent Go compiler installed, and that they are familiar with standard Go workflows.</p>
</li>
<li>
<p>Compiling <code>rustc</code> would take a little while.
On the one hand, Rust is a big language, and you need to spend quite a few lines of code to implement it.
On the other hand, compilers are very straightforward programs, which don’t do a lot of IO, don’t have to deal with changing business requirements and don’t have a lot of dependencies.
Besides, Go is a language known for fast compile times.
So, spending something like five minutes on a quad-core machine for compiling the compiler seems reasonable.</p>
</li>
<li>
<p>After that, running unit-tests is a breeze: unit-tests do not depend on any state external to the test itself; we are testing pure functions.</p>
</li>
<li>
<p>The first integration tests is compiling and <code>#[test]</code>ing <code>std</code>.
As <code>std</code> is relatively small, compiling it with our compiler should be relatively fast.</p>
</li>
<li>
<p>Running tens of thousands of full integration tests will be slow.
Each such test would need to do IO to read the source code, write the executable, and run the process.
It is reasonable to assume that <em>most</em> of potential failures are covered with compiler’s and <code>std</code>'s unit tests.
But it would be foolish to rely solely on those tests — fully integrated test suite is important to make sure that compiler indeed does what it is supposed to, and it is vital to compare several independent implementations — who knows, maybe one day we’ll rewrite <code>rustc</code> from Go to Rust, and re-using compiler’s unit-tests would be much harder in that context.</p>
</li>
</ol>
</div>
<p>So, it seems like except for the final integration test suite, there’s no complexity/performance bottlenecks in our setup for a from-scratch build.
The problem with integrated suite can be handled by running a subset of smoke tests by default, and only running the full set of integrated tests on CI.
Testing is embarrassingly parallel, so a beefy CI fleet should handle that just fine.</p>
<p>What about incremental builds?
Let’s say we want to contribute a change to <code>std</code>.
First time around, this requires building the compiler, which is unfortunate.
This is a one-time cost though, and it shouldn’t be prohibitive (or we will have troubles with changes to the compiler itself anyway).
We can also cheat here, and just download some version of <code>rustc</code> from the internet to check <code>std</code>.
This will mostly work, except for the bits where <code>std</code> and rustc need to know about each other (lang items and intrinsics).
For those, we can use <code>#[cfg(not(bootstrap))]</code> in the <code>std</code> to compile different code for older versions of the compiler.
This makes <code>std</code> implementation mind-bending though, so a better alternative might be to just make CI publish the artifacts for the compiler built off the master branch.
That is, if you only contribute to <code>std</code>, you download the latest compiler instead of building it yourself.
We have a trade off between implementation complexity and compile times.</p>
<p>If we want to contribute a change to the compiler, then we are golden as long as it can be checked by the unit-tests (which, again, in theory is everything except for <code>run-pass</code> tests).
If we need to run integrated tests with <code>std</code>, then we need to recompile <code>std</code> with the new compiler, after every change to the compiler.
This is pretty unfortunate, but:</p>
<div>
<ul>
<li>
<p>if you fundamentally need to recompile <code>std</code> (for example, you change lang-items), there’s no way around this,</p>
</li>
<li>
<p>if you don’t need to recompile <code>std</code>, than you probably can write an <code>std</code>-less unit-test,</p>
</li>
<li>
<p>as an escape hatch, there might be some kind of <code>KEEP_STDLIB</code> env var, which causes integrated tests to re-use existing <code>std</code>, even if the compiler is newer.</p>
</li>
</ul>
</div>
<p>To sum up, compiler is just a program which does some text processing.
In the modern world full of distributed highly-available long-running systems, compiler is actually a pretty simple program.
It also is fairly easy to test.
The hard bit is not the compiler itself, but the standard library: to even start building the standard library, we need to compile the compiler.
However, most of the compiler can be tested without <code>std</code>, and <code>std</code> itself can be tested using compiler binary built from the master branch by CI.</p>
</div>
<div>
<h3 id="why-todays-build-process-is-not-simple"><a href="#why-todays-build-process-is-not-simple"></a>Why Today’s Build Process is not Simple?</h3>
<p>In theory, it should be possible to replace Go from the last section with Rust, and get a similarly simple bootstrapping compiler.
That is, we would use latest stable/beta Rust to compile <code>rustc</code>, then we’ll use this <code>rustc</code> to compile <code><code>std</code></code>, and we are done.
We might add a sanity check — using the freshly built compiler &amp; <code>std</code>, recompile the compiler again and check that everything works.
This is optional, and in a sense just a subset of a crater run, where we check one specific crate — compiler itself.</p>
<p>However, today’s build is <em>more</em> complicated than that.</p>
<p><em>First</em>, instead of using a "standard distribution" of the compiler for bootstrapping, <code>x.py</code> downloads custom beta toolchain.
This could and should be replaced with using <code>rustup</code> by default.</p>
<p><em>Second</em>, master <code>rustc</code> requires master <code>std</code> to build.
This is the bit which makes <code>rustc</code> not a simple crate.
Remember how before the build started with just compiling the compiler as a usual program?
Today, <code>rustc</code> build starts with compiling master <code>std</code> using the beta compiler, than with compiling master <code>rustc</code> using master <code>std</code> and beta compiler.
So, there’s a requirement that <code>std</code> builds with both master and beta compilers, and we also has this weird state where versions of compiler and <code>std</code> we are using to compile the code do not match. In other words, while <code>#[cfg(not(bootstrap))]</code> was an optimization in the previous section (which could be replaced with downloading binary <code>rustc</code> from CI), today it is required.</p>
<p><em>Third</em>, there’s not much in a way of the unit tests in the compiler.
Almost all tests require <code>std</code>, which means that, to test anything, one needs to rebuild everything.</p>
<p><em>Fourth</em>, LLVM &amp; linkers.
A big part of "compilers are easy to test" is the fact that they are, in theory, closed systems interacting with the outside world in a limited well-defined way.
In the real world, however, rustc relies on a bunch of external components to work, the biggest one of which is LLVM.</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matklad.github.io/2020/09/12/rust-in-2021.html">https://matklad.github.io/2020/09/12/rust-in-2021.html</a></em></p>]]>
            </description>
            <link>https://matklad.github.io/2020/09/12/rust-in-2021.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24455827</guid>
            <pubDate>Sat, 12 Sep 2020 21:20:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QAnon Key Figure Revealed as Financial InfoSec Analyst from New Jersey]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24455697">thread link</a>) | @nickfromseattle
<br/>
September 12, 2020 | https://www.logically.ai/articles/qanon-key-figure-man-from-new-jersey | <a href="https://web.archive.org/web/*/https://www.logically.ai/articles/qanon-key-figure-man-from-new-jersey">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
							<p><img src="https://www.logically.ai/hubfs/Qmap.jpg" alt="">
								<span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>A Logically investigation identifies a key QAnon figure as New Jersey resident Jason Gelinas. The investigation ties QAnon properties to a company owned by Gelinas, an information technology specialist who has held prominent positions at both Credit Suisse and Citigroup.</em></p>

<p><span>Ever since the shadowy figure known as Q made his first appearance on the 4chan imageboard in October of 2017, the author’s identity has remained a mystery. Since then, Q has posted thousands of ‘drops,’ converting legions of followers to the belief that Donald Trump is leading a global fight against a satanic cabal of child trafficking elites, commonly referred to in the QAnon world as the ‘Deep State’.</span></p>
<p>Over the years, Q’s posts would move from the 4chan forum to 8chan, and finally to its later iteration, 8kun. But these forums weren’t where most of Q’s followers would go to access the drops: most would find them neatly compiled on a site called QMap, now the main platform on which Q’s drops are published. For years it was believed that QMap was an endeavour that was independent of both the chan forums and the person or people posting Q’s drops, but recent discoveries concerning an IP address behind QMap raised questions as to whether Jim Watkins, the owner of 8chan and 8kun, an elusive figure in his own right, could also be Q. <a href="https://www.dailydot.com/debug/who-is-qanon-jim-watkins-rumors/"><span>As some QAnon researchers have pointed out</span></a>, however, the story of Q’s operations does not end with Jim Watkins.</p>

<p>In the world of QAnon, the site qmap.pub is something of a sacred text. It’s a site designed to collect Q’s posts on other message boards and collate them in a searchable database; over the years, it has grown to include glossaries on themes, profiles on people named across the drops (handily sorted into ‘Evil’, ‘Traitor/Pawn’, and ‘Patriot’), and even a prayer wall.</p>
<p>Most followers of QAnon tend not to visit Q’s posts on 8kun and the ‘chan’ boards where they are initially posted (the vernacular used on those sites is deliberately exclusionary and newcomers are often put off). This makes qmap.pub a crucial port of call for all QAnon information and a major node in how the movement disseminates its lore. The site&nbsp;has been hitting over 10 million monthly users since April of this year.</p>
<p>The developer of QMap has been known only as ‘QAPPANON’ since the launch of the site in May of 2018. They have a successful Patreon where they regularly post and update their following on the running of the website. They pull in over 600 patrons and a $3,320 a month income - although there is a $4,000 a month target for ‘running costs’ of the website. In addition to the website, QMap also had an accompanying app on the Google Play Store (for $2.99) until <a href="https://www.cnet.com/news/google-removes-qanon-apps-from-play-store-for-violating-terms/"><span>it was removed in May</span></a> this year as “harmful content”. The user QAPPANON is synonymous with qmap.pub, acting as its sole developer and mouthpiece.&nbsp;</p>
<p>The QAnon community recognizes the importance of QAPPANON and how central QMap is to how the movement functions. In a recent campaign to deplatform QAPPANON from Patreon, QAnon power-influencer Praying Medic leapt to their defence, calling on his nearly 400,000 Twitter followers to help (and funnelling them towards QAPPANON’s Patreon). In addition, Praying Medic linked to the Patreon on his podcast, describing it as the “Qmap Patreon”.</p>

<p><span><img src="https://www.logically.ai/hs-fs/hubfs/PrayMed.png?width=600&amp;name=PrayMed.png" alt="PrayMed" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/PrayMed.png?width=300&amp;name=PrayMed.png 300w, https://www.logically.ai/hs-fs/hubfs/PrayMed.png?width=600&amp;name=PrayMed.png 600w, https://www.logically.ai/hs-fs/hubfs/PrayMed.png?width=900&amp;name=PrayMed.png 900w, https://www.logically.ai/hs-fs/hubfs/PrayMed.png?width=1200&amp;name=PrayMed.png 1200w, https://www.logically.ai/hs-fs/hubfs/PrayMed.png?width=1500&amp;name=PrayMed.png 1500w, https://www.logically.ai/hs-fs/hubfs/PrayMed.png?width=1800&amp;name=PrayMed.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>

<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png?width=535&amp;name=Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png" alt="Screenshot_2020-09-10 Praying Medic on Twitter" width="535" srcset="https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png?width=268&amp;name=Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png 268w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png?width=535&amp;name=Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png 535w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png?width=803&amp;name=Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png 803w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png?width=1070&amp;name=Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png 1070w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png?width=1338&amp;name=Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png 1338w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png?width=1605&amp;name=Screenshot_2020-09-10%20Praying%20Medic%20on%20Twitter.png 1605w" sizes="(max-width: 535px) 100vw, 535px"></span></p>

<h4><strong><span>Who is behind QAPPANON?</span></strong></h4>
<p><a href="https://www.dailydot.com/debug/who-is-qanon-jim-watkins-rumors/"><span>It has been suspected that the owner of 8kun, Jim Watkins, is Q</span></a> and perhaps QAPPANON. A shared IP address for 8kun and qmap.pub was viewed as a significant link between Watkins and Q, placing him as a figure doing more than just hosting Q’s preferred method of communication. If Watkins was not in fact Q, his hosting of QMap suggested that at the very least, he could “become Q whenever he wanted”. When approached by Daily Dot, however, QAPPANON stated “they are ‘not associated with Watkins’ and that they moved to VanwaTech because “QMap suffers denial of service attacks regularly, hence the need for a content delivery network that could stop it.”</p>

<h4><strong><span>Logically Investigation into QAPPANON’s identity</span></strong></h4>
<p>Our investigation can reveal that QAPPANON is not Watkins, but instead a New Jersey man in his forties with prominent roles in technical analysis and IT security for the banking sector.&nbsp;</p>
<p>QAPPANON’s email address was initially discovered during our investigation into QMap’s translation efforts and international reach. A now-deleted Facebook post allowed us to trace the email to a CNET&nbsp;download cache for the QMap app as well as a new app in development called Armor of God.</p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Shirl1.png?width=600&amp;name=Shirl1.png" alt="Shirl1" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/Shirl1.png?width=300&amp;name=Shirl1.png 300w, https://www.logically.ai/hs-fs/hubfs/Shirl1.png?width=600&amp;name=Shirl1.png 600w, https://www.logically.ai/hs-fs/hubfs/Shirl1.png?width=900&amp;name=Shirl1.png 900w, https://www.logically.ai/hs-fs/hubfs/Shirl1.png?width=1200&amp;name=Shirl1.png 1200w, https://www.logically.ai/hs-fs/hubfs/Shirl1.png?width=1500&amp;name=Shirl1.png 1500w, https://www.logically.ai/hs-fs/hubfs/Shirl1.png?width=1800&amp;name=Shirl1.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Shirl2.png?width=600&amp;name=Shirl2.png" alt="Shirl2" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/Shirl2.png?width=300&amp;name=Shirl2.png 300w, https://www.logically.ai/hs-fs/hubfs/Shirl2.png?width=600&amp;name=Shirl2.png 600w, https://www.logically.ai/hs-fs/hubfs/Shirl2.png?width=900&amp;name=Shirl2.png 900w, https://www.logically.ai/hs-fs/hubfs/Shirl2.png?width=1200&amp;name=Shirl2.png 1200w, https://www.logically.ai/hs-fs/hubfs/Shirl2.png?width=1500&amp;name=Shirl2.png 1500w, https://www.logically.ai/hs-fs/hubfs/Shirl2.png?width=1800&amp;name=Shirl2.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<p>The email found here in the URL serves as a point of contact in a call for translators for qmap.pub. Importantly, the post here states that “<strong><em>Q</em></strong> is looking for someone” rather than “QMap is looking for someone.” As Watkins’s connection to QMap has resulted in speculation that he could be Q, the connection here should not be ignored. However, this may be the result of Shirley_is believing that Q speaks through qmap.pub. What this post <em>does </em>indicate is that QAPPANON is directly responsible for hiring translators for QMap, and therefore has employees.</p>
<p>An extraction of QAPPANON’s email address from the URL led to their developer profile and list of created apps on CNET. While the qmap app is well known at this point, Armor of God is relatively new, having been uploaded on the 18th June 2020.</p>
<p><br><span><img src="https://www.logically.ai/hs-fs/hubfs/QAPPANONCnet.png?width=600&amp;name=QAPPANONCnet.png" alt="QAPPANONCnet" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/QAPPANONCnet.png?width=300&amp;name=QAPPANONCnet.png 300w, https://www.logically.ai/hs-fs/hubfs/QAPPANONCnet.png?width=600&amp;name=QAPPANONCnet.png 600w, https://www.logically.ai/hs-fs/hubfs/QAPPANONCnet.png?width=900&amp;name=QAPPANONCnet.png 900w, https://www.logically.ai/hs-fs/hubfs/QAPPANONCnet.png?width=1200&amp;name=QAPPANONCnet.png 1200w, https://www.logically.ai/hs-fs/hubfs/QAPPANONCnet.png?width=1500&amp;name=QAPPANONCnet.png 1500w, https://www.logically.ai/hs-fs/hubfs/QAPPANONCnet.png?width=1800&amp;name=QAPPANONCnet.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<h5><span><strong>Armor of God:</strong></span></h5>
<p>When investigating Armor of God, we were met with a bare sign-up screen. Attempts to register and investigate the platform both on desktop and mobile versions were met with login errors and no email to confirm registration or change passwords. This led us to believe that, while downloadable on app stores, the platform is not yet up and running.&nbsp;</p>
<p><img src="https://www.logically.ai/hs-fs/hubfs/AOG%20SPlash.png?width=600&amp;name=AOG%20SPlash.png" alt="AOG SPlash" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/AOG%20SPlash.png?width=300&amp;name=AOG%20SPlash.png 300w, https://www.logically.ai/hs-fs/hubfs/AOG%20SPlash.png?width=600&amp;name=AOG%20SPlash.png 600w, https://www.logically.ai/hs-fs/hubfs/AOG%20SPlash.png?width=900&amp;name=AOG%20SPlash.png 900w, https://www.logically.ai/hs-fs/hubfs/AOG%20SPlash.png?width=1200&amp;name=AOG%20SPlash.png 1200w, https://www.logically.ai/hs-fs/hubfs/AOG%20SPlash.png?width=1500&amp;name=AOG%20SPlash.png 1500w, https://www.logically.ai/hs-fs/hubfs/AOG%20SPlash.png?width=1800&amp;name=AOG%20SPlash.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></p>
<div><p><a href="https://youtu.be/xhVPxPiQQB4"><span>Proof-of-concept</span></a> <a href="https://youtu.be/xEZjHWxklTM"><span>videos</span></a> on QAPPANON’s Youtube channel reveal what appears to be a hybrid platform functioning as a QAnon research hub, Facebook-like, and Twitter-like. Archived versions of the Armor of God <a href="https://web.archive.org/web/20200425181515/https://server.aog.pub/site/about"><span>about page</span></a>, <a href="https://web.archive.org/web/20200425181518/https://server.aog.pub/site/privacy"><span>privacy policy</span></a> and <a href="https://web.archive.org/web/20200425183516/https://server.aog.pub/site/terms"><span>T&amp;Cs</span></a> from the Wayback Machine revealed more information.</p><p><span><img src="https://www.logically.ai/hs-fs/hubfs/AoGAbout.png?width=600&amp;name=AoGAbout.png" alt="AoGAbout" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/AoGAbout.png?width=300&amp;name=AoGAbout.png 300w, https://www.logically.ai/hs-fs/hubfs/AoGAbout.png?width=600&amp;name=AoGAbout.png 600w, https://www.logically.ai/hs-fs/hubfs/AoGAbout.png?width=900&amp;name=AoGAbout.png 900w, https://www.logically.ai/hs-fs/hubfs/AoGAbout.png?width=1200&amp;name=AoGAbout.png 1200w, https://www.logically.ai/hs-fs/hubfs/AoGAbout.png?width=1500&amp;name=AoGAbout.png 1500w, https://www.logically.ai/hs-fs/hubfs/AoGAbout.png?width=1800&amp;name=AoGAbout.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p></div>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=600&amp;name=AoGAPP.png" alt="AoGAPP" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=300&amp;name=AoGAPP.png 300w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=600&amp;name=AoGAPP.png 600w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=900&amp;name=AoGAPP.png 900w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=1200&amp;name=AoGAPP.png 1200w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=1500&amp;name=AoGAPP.png 1500w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=1800&amp;name=AoGAPP.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>

<p>Following the “get the Android app” link led to the Google Play store. Here, we can see that QAPPANON is listed as the profile responsible for uploading the app.</p>
<p><br><span><img src="https://www.logically.ai/hs-fs/hubfs/AoGPlay.png?width=600&amp;name=AoGPlay.png" alt="AoGPlay" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/AoGPlay.png?width=300&amp;name=AoGPlay.png 300w, https://www.logically.ai/hs-fs/hubfs/AoGPlay.png?width=600&amp;name=AoGPlay.png 600w, https://www.logically.ai/hs-fs/hubfs/AoGPlay.png?width=900&amp;name=AoGPlay.png 900w, https://www.logically.ai/hs-fs/hubfs/AoGPlay.png?width=1200&amp;name=AoGPlay.png 1200w, https://www.logically.ai/hs-fs/hubfs/AoGPlay.png?width=1500&amp;name=AoGPlay.png 1500w, https://www.logically.ai/hs-fs/hubfs/AoGPlay.png?width=1800&amp;name=AoGPlay.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>

<p>However, further down, we can see a different entity listed as the developer of Armor of God: Patriot Platforms.</p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/AoGDev.png?width=226&amp;name=AoGDev.png" alt="AoGDev" width="226" srcset="https://www.logically.ai/hs-fs/hubfs/AoGDev.png?width=113&amp;name=AoGDev.png 113w, https://www.logically.ai/hs-fs/hubfs/AoGDev.png?width=226&amp;name=AoGDev.png 226w, https://www.logically.ai/hs-fs/hubfs/AoGDev.png?width=339&amp;name=AoGDev.png 339w, https://www.logically.ai/hs-fs/hubfs/AoGDev.png?width=452&amp;name=AoGDev.png 452w, https://www.logically.ai/hs-fs/hubfs/AoGDev.png?width=565&amp;name=AoGDev.png 565w, https://www.logically.ai/hs-fs/hubfs/AoGDev.png?width=678&amp;name=AoGDev.png 678w" sizes="(max-width: 226px) 100vw, 226px"></span></p>
<p>Therefore, far from being a rogue developer creating QMap, QAPPANON has a company—and a company must be filed for.</p>

<h5><span><strong>Patriot Platforms LLC</strong></span></h5>
<p>Visiting Patriot Platforms’ <a href="http://patriotplatforms.com/"><span>website</span></a> reveals a plain splash page with a link to their support email.</p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/PPSplash.png?width=600&amp;name=PPSplash.png" alt="PPSplash" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/PPSplash.png?width=300&amp;name=PPSplash.png 300w, https://www.logically.ai/hs-fs/hubfs/PPSplash.png?width=600&amp;name=PPSplash.png 600w, https://www.logically.ai/hs-fs/hubfs/PPSplash.png?width=900&amp;name=PPSplash.png 900w, https://www.logically.ai/hs-fs/hubfs/PPSplash.png?width=1200&amp;name=PPSplash.png 1200w, https://www.logically.ai/hs-fs/hubfs/PPSplash.png?width=1500&amp;name=PPSplash.png 1500w, https://www.logically.ai/hs-fs/hubfs/PPSplash.png?width=1800&amp;name=PPSplash.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<p>We cross-referenced the listed premises of Patriot Platforms to<a href="https://www.google.com/maps/@40.6867177,-74.437065,3a,75y,149.28h,81.03t/data=!3m7!1e1!3m5!1shgM1E9AZLH-OI0Yg9uF08w!2e0!6s%2F%2Fgeo0.ggpht.com%2Fcbk%3Fpanoid%3DhgM1E9AZLH-OI0Yg9uF08w%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D148.3542%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656"><span> a PO box at a New Jersey Post Office</span></a>.</p>
<p><br><span><img src="https://www.logically.ai/hs-fs/hubfs/PPoffice.png?width=600&amp;name=PPoffice.png" alt="PPoffice" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/PPoffice.png?width=300&amp;name=PPoffice.png 300w, https://www.logically.ai/hs-fs/hubfs/PPoffice.png?width=600&amp;name=PPoffice.png 600w, https://www.logically.ai/hs-fs/hubfs/PPoffice.png?width=900&amp;name=PPoffice.png 900w, https://www.logically.ai/hs-fs/hubfs/PPoffice.png?width=1200&amp;name=PPoffice.png 1200w, https://www.logically.ai/hs-fs/hubfs/PPoffice.png?width=1500&amp;name=PPoffice.png 1500w, https://www.logically.ai/hs-fs/hubfs/PPoffice.png?width=1800&amp;name=PPoffice.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<p>This was corroborated with a search for business details.&nbsp;</p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/PP%20Edit.png?width=600&amp;name=PP%20Edit.png" alt="PP Edit" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/PP%20Edit.png?width=300&amp;name=PP%20Edit.png 300w, https://www.logically.ai/hs-fs/hubfs/PP%20Edit.png?width=600&amp;name=PP%20Edit.png 600w, https://www.logically.ai/hs-fs/hubfs/PP%20Edit.png?width=900&amp;name=PP%20Edit.png 900w, https://www.logically.ai/hs-fs/hubfs/PP%20Edit.png?width=1200&amp;name=PP%20Edit.png 1200w, https://www.logically.ai/hs-fs/hubfs/PP%20Edit.png?width=1500&amp;name=PP%20Edit.png 1500w, https://www.logically.ai/hs-fs/hubfs/PP%20Edit.png?width=1800&amp;name=PP%20Edit.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<p>From here, we also found a name, Jason Gelinas, after which we were able to narrow this down to Jason J. Gelinas in New Jersey, whose listed phone number correlates with the one belonging to Patriot Platforms LLC.</p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Gelinas1.png?width=600&amp;name=Gelinas1.png" alt="Gelinas1" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/Gelinas1.png?width=300&amp;name=Gelinas1.png 300w, https://www.logically.ai/hs-fs/hubfs/Gelinas1.png?width=600&amp;name=Gelinas1.png 600w, https://www.logically.ai/hs-fs/hubfs/Gelinas1.png?width=900&amp;name=Gelinas1.png 900w, https://www.logically.ai/hs-fs/hubfs/Gelinas1.png?width=1200&amp;name=Gelinas1.png 1200w, https://www.logically.ai/hs-fs/hubfs/Gelinas1.png?width=1500&amp;name=Gelinas1.png 1500w, https://www.logically.ai/hs-fs/hubfs/Gelinas1.png?width=1800&amp;name=Gelinas1.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span><span></span></p>

<h5><span><strong>Jason J. Gelinas</strong></span></h5>
<p>Jason J. Gelinas, an information technology specialist from Berkeley Heights, New Jersey, whose CV lists prominent positions with both Credit Suisse and Citigroup, is the founder and sole employee of Patriot Platforms LLC, which is credited as the developer behind the QMap and Armor of God platforms. Gelinas’s home address is, in fact, a mere seven-minute drive from Patriot Platforms LLC’s listed P.O. box, also in Berkeley Heights; further investigation shows the connection between Gelinas’s personal WhatsApp and Patriot Platforms’ listed phone number.</p>

<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Gelinas2.png?width=600&amp;name=Gelinas2.png" alt="Gelinas2" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/Gelinas2.png?width=300&amp;name=Gelinas2.png 300w, https://www.logically.ai/hs-fs/hubfs/Gelinas2.png?width=600&amp;name=Gelinas2.png 600w, https://www.logically.ai/hs-fs/hubfs/Gelinas2.png?width=900&amp;name=Gelinas2.png 900w, https://www.logically.ai/hs-fs/hubfs/Gelinas2.png?width=1200&amp;name=Gelinas2.png 1200w, https://www.logically.ai/hs-fs/hubfs/Gelinas2.png?width=1500&amp;name=Gelinas2.png 1500w, https://www.logically.ai/hs-fs/hubfs/Gelinas2.png?width=1800&amp;name=Gelinas2.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>

<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Gelinas3.png?width=600&amp;name=Gelinas3.png" alt="Gelinas3" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/Gelinas3.png?width=300&amp;name=Gelinas3.png 300w, https://www.logically.ai/hs-fs/hubfs/Gelinas3.png?width=600&amp;name=Gelinas3.png 600w, https://www.logically.ai/hs-fs/hubfs/Gelinas3.png?width=900&amp;name=Gelinas3.png 900w, https://www.logically.ai/hs-fs/hubfs/Gelinas3.png?width=1200&amp;name=Gelinas3.png 1200w, https://www.logically.ai/hs-fs/hubfs/Gelinas3.png?width=1500&amp;name=Gelinas3.png 1500w, https://www.logically.ai/hs-fs/hubfs/Gelinas3.png?width=1800&amp;name=Gelinas3.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>

<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Gelinas4.png?width=600&amp;name=Gelinas4.png" alt="Gelinas4" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/Gelinas4.png?width=300&amp;name=Gelinas4.png 300w, https://www.logically.ai/hs-fs/hubfs/Gelinas4.png?width=600&amp;name=Gelinas4.png 600w, https://www.logically.ai/hs-fs/hubfs/Gelinas4.png?width=900&amp;name=Gelinas4.png 900w, https://www.logically.ai/hs-fs/hubfs/Gelinas4.png?width=1200&amp;name=Gelinas4.png 1200w, https://www.logically.ai/hs-fs/hubfs/Gelinas4.png?width=1500&amp;name=Gelinas4.png 1500w, https://www.logically.ai/hs-fs/hubfs/Gelinas4.png?width=1800&amp;name=Gelinas4.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<p>The distance between property owned by Jason J. Gelinas and Patriots Platforms’ postal address (P.O.Box) is only a 7 minute drive.</p>
<p>Jason appears to be scrubbed from social media, with only a Flickr account left. The account name is jjgelinas77.</p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20jjgelinas77.png?width=505&amp;name=Screenshot_2020-09-10%20jjgelinas77.png" alt="Screenshot_2020-09-10 jjgelinas77" width="505" srcset="https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20jjgelinas77.png?width=253&amp;name=Screenshot_2020-09-10%20jjgelinas77.png 253w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20jjgelinas77.png?width=505&amp;name=Screenshot_2020-09-10%20jjgelinas77.png 505w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20jjgelinas77.png?width=758&amp;name=Screenshot_2020-09-10%20jjgelinas77.png 758w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20jjgelinas77.png?width=1010&amp;name=Screenshot_2020-09-10%20jjgelinas77.png 1010w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20jjgelinas77.png?width=1263&amp;name=Screenshot_2020-09-10%20jjgelinas77.png 1263w, https://www.logically.ai/hs-fs/hubfs/Screenshot_2020-09-10%20jjgelinas77.png?width=1515&amp;name=Screenshot_2020-09-10%20jjgelinas77.png 1515w" sizes="(max-width: 505px) 100vw, 505px"></span></p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/FlickrEddit.png?width=600&amp;name=FlickrEddit.png" alt="FlickrEddit" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/FlickrEddit.png?width=300&amp;name=FlickrEddit.png 300w, https://www.logically.ai/hs-fs/hubfs/FlickrEddit.png?width=600&amp;name=FlickrEddit.png 600w, https://www.logically.ai/hs-fs/hubfs/FlickrEddit.png?width=900&amp;name=FlickrEddit.png 900w, https://www.logically.ai/hs-fs/hubfs/FlickrEddit.png?width=1200&amp;name=FlickrEddit.png 1200w, https://www.logically.ai/hs-fs/hubfs/FlickrEddit.png?width=1500&amp;name=FlickrEddit.png 1500w, https://www.logically.ai/hs-fs/hubfs/FlickrEddit.png?width=1800&amp;name=FlickrEddit.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<p>Crucially, echoes of Gelinas’ username “jjgelinas77” can be seen in the screenshots for Armor of God - “Board Owner <strong>@anon77</strong>” works as an app developer.&nbsp;</p>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=600&amp;name=AoGAPP.png" alt="AoGAPP" width="600" srcset="https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=300&amp;name=AoGAPP.png 300w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=600&amp;name=AoGAPP.png 600w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=900&amp;name=AoGAPP.png 900w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=1200&amp;name=AoGAPP.png 1200w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=1500&amp;name=AoGAPP.png 1500w, https://www.logically.ai/hs-fs/hubfs/AoGAPP.png?width=1800&amp;name=AoGAPP.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></span></p>
<h5><span><strong>Relationship between Jason, Armor of God, QAPPANON</strong></span></h5>
<p><span><img src="https://www.logically.ai/hs-fs/hubfs/Qmap%20next%20edit-1.jpg?width=546&amp;name=Qmap%20next%20edit-1.jpg" alt="Qmap next edit-1" width="546" srcset="https://www.logically.ai/hs-fs/hubfs/Qmap%20next%20edit-1.jpg?width=273&amp;name=Qmap%20next%20edit-1.jpg 273w, https://www.logically.ai/hs-fs/hubfs/Qmap%20next%20edit-1.jpg?width=546&amp;name=Qmap%20next%20edit-1.jpg 546w, https://www.logically.ai/hs-fs/hubfs/Qmap%20next%20edit-1.jpg?width=819&amp;name=Qmap%20next%20edit-1.jpg 819w, https://www.logically.ai/hs-fs/hubfs/Qmap%20next%20edit-1.jpg?width=1092&amp;name=Qmap%20next%20edit-1.jpg 1092w, https://www.logically.ai/hs-fs/hubfs/Qmap%20next%20edit-1.jpg?width=1365&amp;name=Qmap%20next%20edit-1.jpg 1365w, https://www.logically.ai/hs-fs/hubfs/Qmap%20next%20edit-1.jpg?width=1638&amp;name=Qmap%20next%20edit-1.jpg 1638w" sizes="(max-width: 546px) 100vw, 546px"></span></p>
<p>So does that mean Gelinas <em>is </em>Q? No. In fact, it’s quite unlikely that someone such as Gelinas would have been involved in the very early (i.e. 4chan) days of Q. It does suggest, however, that after the success of the QMap platform since it was launched in 2018, a direct line was opened between Watkins and Gelinas, as well as Q (if we are to believe that Q is actually an independent third party and whether the Q from the early days is the Q of today). Indeed, as <span>creator and former owner of 8chan </span>Fred Brennan told Logically, Watkins essentially operates Vanwatech, the company hosting both 8kun and QMap, meaning that he can offer Gelinas free or negligible running costs for QMap, which then reframes the monthly income from Patreon.</p>
<p>So how close is all this to Q? In a nutshell, it’s closer than we’ve ever been. In fact, recent Q drops discussing the ‘Armor of God’ prayer more and more frequently coincide almost perfectly with attempts to launch the ‘Armor of God’ platform, giving this the feel of a coordinated PR campaign. Of course, that could be down to the tendency among Q’s followers to use and re-use the same language, but given the established connection between Gelinas and Watkins, the fact that this timing suggests a level of coordination should not be dismissed.&nbsp;</p></span>
							</p>
						</article></div>]]>
            </description>
            <link>https://www.logically.ai/articles/qanon-key-figure-man-from-new-jersey</link>
            <guid isPermaLink="false">hacker-news-small-sites-24455697</guid>
            <pubDate>Sat, 12 Sep 2020 21:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Restoring a 1984 “Space Shuttle” pinball machine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24455634">thread link</a>) | @hellepardo
<br/>
September 12, 2020 | http://ratml.org/space_shuttle/ | <a href="https://web.archive.org/web/*/http://ratml.org/space_shuttle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <!-- individual page content starts here -->
    <center>
    <span>space shuttle</span><br>
    </center>
    <p>
    <b>I. Introduction</b></p><p>
    Cultural influences <a href="https://en.wikipedia.org/wiki/Pinball_Wizard">[1]</a> suggest that expertise at pinball could be a useful
social goal.  Developing this expertise is likely best accomplished via
ownership of a pinball machine, and thus it was decided that it was a worthy
goal to obtain a pinball machine.  This page details the process of developing
this expertise.  Unfortunately, no social payoffs have yet been found, and thus
it must be considered that the original premise was incorrect.
    </p>
    
    <p><b>II. Acquisition</b></p><p>
    Unfortunately, time constraints meant that once this decision was made, a
pinball machine needed to be purchased within hours.  After spending a small
amount of time searching for a machine <a href="https://pinside.com/pinball/market">[2]</a>, a Space
Shuttle <a href="https://www.ipdb.org/machine.cgi?id=2260">[3]</a> was located and purchased.  In retrospect, a good
knowledge of pinball machines is even required to buy a good pinball machine.
Nonetheless, the electronic expertise of those involved meant that something of
a challenge for restoration was desired.
    </p>
    <p>
    At first inspection, the Space Shuttle was in poor condition.  See Figures 1
through 3.  The machine also did not work, and at the time of purchase its only
apparent utility was discovered by feline residents (see Figure 4.)  Many of the
lights in the machine were inoperable and the MPU board was clearly not booting
up to start a game.  In fact, once the MPU board was removed, a large burn mark
was evident.  The situation causing the burn was not reported by the previous
owner, but it seems likely that open flame was involved.
    </p>
    <table>
      <tbody><tr>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/first_look.jpg"><img src="http://ratml.org/space_shuttle/img/first_look.thumb.jpg"></a>
          <span><b>Figure 1.</b> With the MPU board
removed, a burn mark exists on the backing plate.</span>
          </center>
        </td>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/playfield.jpg"><img src="http://ratml.org/space_shuttle/img/playfield.thumb.jpg"></a>
          <span><b>Figure 2.</b> The playfield condition
was very poor.</span>
          </center>
        </td>
      </tr>
      
      <tr>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/lights.jpg"><img src="http://ratml.org/space_shuttle/img/lights.thumb.jpg"></a>
          <span><b>Figure 3.</b> Most lights were
inoperable.</span>
          </center>
        </td>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/drusilla.jpg"><img src="http://ratml.org/space_shuttle/img/drusilla.thumb.jpg"></a>
          <span><b>Figure 4.</b> The purchase can be
justified via this usage.</span>
          </center>
        </td>
      </tr>
    </tbody></table>
    <p>
    Inspection revealed that the burn mark was right behind where the power
supply connected to the MPU board (see Figure 5).  Given that the +12V and -12V pins are right
next to each other <a href="https://www.ipdb.org/files/2260/Williams_1984_Space_Shuttle_Instruction_Manual_dated_Nov_3_1984_with_schematics.pdf">[4] (pdf)</a>, the cause of the fire was most likely that
someone incorrectly plugged in the power supply, and nearly immediately lit the
machine on fire.  Figure 6 shows that many solder joints on the board were also
in very poor condition or broken completely.  This type of phenomenon was
typically found near the transistors that power the various solenoids on the
playfield.  Further, the battery on the MPU board had leaked and caused
corrosion everywhere, complicating the task of restoration.
    </p>
    <table>
      <tbody><tr>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/burn.jpg"><img src="http://ratml.org/space_shuttle/img/burn.thumb.jpg"></a>
          <span><b>Figure 5.</b> A closer look at the
burn mark.</span>
          </center>
        </td>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/typical_board.jpg"><img src="http://ratml.org/space_shuttle/img/typical_board.thumb.jpg"></a>
          <span><b>Figure 6.</b> Many solder joints on
the board were in very poor condition.</span>
          </center>
        </td>
      </tr>
    </tbody></table>
    
    <p><b>III.  MPU board restoration</b></p><p>
    At this point it became clear that the route to social acceptance via
expertise at playing pinball was not going to be a quick option.  This was
further compounded by the fact that the engineers involved in the operation also
decided that purchasing a perfectly good new MPU board <a href="https://www.bigdaddy-enterprises.com/ProductPages/RotDogBoards.html">[5]</a>
was not the desired option, and instead a period-appropriate logic analyzer that
was obtained from a junkyard <a href="http://www.astrotoo.com/">[6]</a> would be used to debug all issues with the MPU board
and restore it to working order.  Figure 7 shows a typical setup.
    </p>
    <center>
    <a href="http://ratml.org/space_shuttle/img/logic_analyzer.jpg"><img src="http://ratml.org/space_shuttle/img/logic_analyzer.thumb.jpg"></a>
    <span><b>Figure 7.</b> At least eight weekends were
spent in roughly this configuration.</span>
    </center>
    <p>
    The Space Shuttle is a Williams System 9 pinball machine <a href="https://pinwiki.com/wiki/index.php?title=Williams_System_9_-_11">[7]</a>.  The System 9 board was used for a handful of
different games in roughly the mid-1980s.  The system actually contains two
MPUs, both containing Motorola 6800-series processors <a href="https://en.wikipedia.org/wiki/Motorola_6800">[8]</a>.
One of these MPUs controls the game state, and another is used for sound.  See
Figure 8 for a general schematic of the main game control MPU.
    </p>
    <center>
    <a href="http://ratml.org/space_shuttle/img/ss_schematic.png"><img src="http://ratml.org/space_shuttle/img/ss_schematic.thumb.png"></a>
    <span><b>Figure 8.</b> The MC6808 controlling the
game state is pictured on the left side of the schematic.  Of the connections
on this schematic, probably 15-20% had been corroded or otherwise
disconnected.</span>
    </center>
    <p>
    The general setup of the machine is that the processor interacts with the
physical machine via the use of MC6821 PIOs <a href="https://resi.store/datasheets/mc6821.pdf">[9] (pdf)</a>.  These
PIOs are used for input, collecting the state of each of the switches on the
playfield, and also for output, setting whether solenoids or lights are enabled
or disabled.  The main processor interacts with the sound processor also via a
PIO, which will set an interrupt for the sound processor that causes it to play
sound.
    </p>
    <p>
    Needless to say, for this setup to work, all of the wires must be connected.
It was observed during the restoration process---which took many weekends---that
the address bus was no longer connected (due to corrosion) to the main
processor, and some bits on the data bus were also disconnected from many PIOs.
In addition, the clock signal was not connected to many devices on the board,
and the reset circuit (pictured in the top left of Figure 8 and used to
initialize the machine correctly on power-on) had numerous disconnections.  In
fact, during the restoration process it was decided that the original design was
lacking, and it was modified.  After this modification, the reset signal was no
longer an issue that was encountered during the restoration process.
    </p>
    <center>
    <a href="http://ratml.org/space_shuttle/img/strange_clicking.mp4"><img src="http://ratml.org/space_shuttle/img/strange_clicking.thumb.jpg"></a>
    <span><b>Video 1.</b> <i>(click to watch)</i> After
many hours of debugging, the processor began interacting with the playfield,
albeit somewhat incorrectly.</span>
    </center>
    <p>
    Overall, during the debugging process, several main sources of problems were
identified:
    </p>
    <ol>
    <li>Traces destroyed by corrosion.</li>
    <li>Components destroyed by fire.</li>
    <li>Traces rendered unconnected via unexplained means.</li>
    <li>Failed logic chips.</li>
    <li>Transistors disconnected via overheating and melting their soldered
connections.</li>
    </ol>
    <p>
    Every destroyed trace was simply replaced with a bodge wire.  A random
number generator was used to decide whether to place the bodge wire on the front
or the back of the board, and sometimes bodge wires were connected directly to
chip leads, obviating the sockets that were used in the original construction to
allow fast replacement of chips.  The most impressive bodge wire architecture is
shown in Figure 9.
    </p>
    <center>
    <a href="http://ratml.org/space_shuttle/img/impressive_bodges.jpg"><img src="http://ratml.org/space_shuttle/img/impressive_bodges.thumb.jpg"></a>
    <span><b>Figure 9.</b> The extra height allows
additional airflow to cool the chip.</span>
    </center>
    <p>
    Eventually, after many hours of surely pointless labor and bodging, the
board entered a state where it could start and play a game.  Video 2 documents
this thrilling development.
    </p>
    <center>
    <a href="http://ratml.org/space_shuttle/img/first_game.mp4"><img src="http://ratml.org/space_shuttle/img/first_game.thumb.jpg"></a>
    <span><b>Video 2.</b> <i>(click to watch)</i>  After
many hours of debugging, the Space Shuttle was convinced to play a game of
pinball.  No immediate social group rewards were discerned as a result of this
development, and the question was raised of whether the Space Shuttle had the
potential to be a fun game.</span>
    </center>
    <p>
    The other part of the MPU board was the sound and speech processor.  In
fact, the Space Shuttle uses an off-board speech processor, with the same TI
chip used in the Speak &amp; Spell toy <a href="https://en.wikipedia.org/wiki/Speak_%26_Spell_(toy)">[10]</a>.  Video 3 shows the out-of-the-box functionality of the
speech board.  The only debugging necessary was the connection from the main
processor board to the speech board.  It is currently believed that the speech
board immediately worked as a result of its not having ever been on fire.
    </p>
    <center>
    <a href="http://ratml.org/space_shuttle/img/sound_test.mp4"><img src="http://ratml.org/space_shuttle/img/sound_test.thumb.jpg"></a>
    <span><b>Video 3.</b> <i>(click to watch)</i>  The
speech chip worked almost immediately.  To this day, if you say ``airlock open
close'' to the engineers involved on the project, they will instinctively and
immediately scream.</span>
    </center>
    <p>
    In the end, the MPU board was restored to a precarious but working state.
Final images of the restored board can be seen in Figures 10 and 11.
    </p>
    <table>
      <tbody><tr>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/finished_board_1.jpg"><img src="http://ratml.org/space_shuttle/img/finished_board_1.thumb.jpg"></a>
          <span><b>Figure 10.</b> Top of fully restored
board.  Roughly 10 chips had to be replaced and numerous bodge wires were
necessary.</span>
          </center>
        </td>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/finished_board_2.jpg"><img src="http://ratml.org/space_shuttle/img/finished_board_2.thumb.jpg"></a>
          <span><b>Figure 11.</b> Bottom of fully
restored board.  The area near the original burn is covered in electrical tape
to prevent exposed circuit traces from shorting to each other or to the
backplane.</span>
          </center>
        </td>
      </tr>
    </tbody></table>
    <p>
    <b>IV. Light and playfield restoration</b></p><p>
    The original condition of the playfield lights in Figure 3 was clearly
unacceptable, if the Space Shuttle was intended to be used for social gain.
Therefore, an LED light kit <a href="https://cointaker.com/products/space-shuttle-super-led-kit">[11]</a> was purchased and installed.  In addition, a PinScore
unit <a href="https://www.pinballlife.com/pinscore-display-system-for-williams-systems-6a-7-9.html">[12]</a> was obtained to replace the failing numeric displays
on the backbox.  The superior results can
be seen in Figure 12, as well as in other videos and figures throughout.
    </p>
    <center>
    <a href="http://ratml.org/space_shuttle/img/pinscore.jpg"><img src="http://ratml.org/space_shuttle/img/pinscore.thumb.jpg"></a>
    <span><b>Figure 12.</b> The PinScore unit and LEDs
provided far superior lighting to the broken and inoperable lamps that were
installed when the machine was obtained.</span>
    </center>
    <p>
    Once the MPU restoration was complete (see Section III), it was immediately
decided (contrary to the original project goals) that the purpose of the pinball
machine was not to have fun playing it, and thus disassembly of the playfield
for complete restoration began.  Removing the playfield had an unexpected impact
on the feline residents of the house in which the Space Shuttle was stored; see
Figure 13.
    </p>
    <center>
    <a href="http://ratml.org/space_shuttle/img/disassembly_1.jpg"><img src="http://ratml.org/space_shuttle/img/disassembly_1.thumb.jpg"></a>
    <span><b>Figure 13.</b> Once the playfield was
removed, it immediately became a place of habitation.  However, the pictured
orange cat did not follow in the footsteps of the desiccated 1980s lizard that
had also taken up residence in the machine, and at the time of this writing
remains orange.</span>
    </center>
    <p>
    Disassembly of the machine revealed further the awful condition in which the
playfield was; see Figure 14 and 15.  During disassembly, an unusual moment of
forward thinking resulted in collecting pictures of the entire bottom side of
the playfield <a href="http://ratml.org/space_shuttle/img/playfield/">[13]</a>, shown in
Figure 16.
    </p>
    <table>
      <tbody><tr>
        <td>
          <center>
          <a href="http://ratml.org/space_shuttle/img/disassembly_2.jpg"><img src="http://ratml.org/space_shuttle/img/disassembly_2.thumb.jpg"></a>
          <span><b>Figure 14.</b> Note the damaged
playfield surface …</span></center></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://ratml.org/space_shuttle/">http://ratml.org/space_shuttle/</a></em></p>]]>
            </description>
            <link>http://ratml.org/space_shuttle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24455634</guid>
            <pubDate>Sat, 12 Sep 2020 21:01:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I got my first GitHub sponsor]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24455622">thread link</a>) | @leoloso
<br/>
September 12, 2020 | https://leoloso.com/posts/milestone-first-github-sponsor/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/milestone-first-github-sponsor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>2 days ago I subscribed to GitHub sponsors to fund my work on the <a href="https://github.com/GraphQLAPI/graphql-api-for-wp">GraphQL API for WordPress</a>, and I already got <a href="https://github.com/sponsors/leoloso/">my first sponsor</a>!</p><figure><img src="https://leoloso.com/images/leoloso-github-sponsors.png" alt="GitHub sponsors" loading="lazy" width="2048" height="1510"><figcaption>GitHub sponsors</figcaption></figure><p>Following the example set by Caleb Porzio (who's making <a href="https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">more than u$d 100k/y doing open source</a>), I have decided to use the <a href="https://calebporzio.com/sponsorware">sponsorware model</a> to fund my project. It works like this:</p><ul><li>Whenever I get 10 new sponsors (at u$d 14/m), I start developing the most up-voted feature from a special <a href="https://github.com/GraphQLAPI/graphql-api-for-wp/projects/2">"Sponsorware" list</a> (which I'm completing as I'm writing this milestone)</li><li>Once implemented, the new feature becomes available to all the sponsors, via a private GitHub repo</li><li>As soon as I get 50 new sponsors, the new feature becomes open source, accessible to everyone via the public GitHub repo, and is integrated into the plugin</li></ul><figure><img src="https://leoloso.com/images/sponsorware-features.png" alt="Sponsorware features" loading="lazy" width="2048" height="1120"><figcaption>Sponsorware features</figcaption></figure><p>In a few months, I will also start creating instructional videos, explaining how to make the most out of the plugin. According to Caleb, this is the biggest money-making strategy.</p><p>I have also decided to add a middle tier (at u$d 70/m), where I provide Slack-based personal support, to help users of my plugin set-up GraphQL with WordPress, troubleshooting, and answering their questions. A user needed help to develop a functionality, so he decided to sponsor me &lt;= my first sponsor ❤️</p><p>Finally, I added a higher tier (at u$d 700) for corporate sponsors. I plan to ask around in the WordPress community if their companies may be interested in participating. That would be a win-win: They get plenty of face from contributing to open source, and I get the certainty that I can make a living wage from my work and can focus on the development of the plugin (and not on marketing, which is not my forte).</p><figure><img src="https://leoloso.com/images/leoloso-github-sponsor-projects.png" alt="My sponsors and sponsored projects" loading="lazy" width="2048" height="1210"><figcaption>My sponsors and sponsored projects</figcaption></figure><p>I hope the sponsorware model works, and I can make a living while working on open source. I'll keep writing updates on how it goes, here on my blog, and <a href="https://www.indiehackers.com/leoloso">on IndieHackers</a>.</p><p>I have now <a href="https://github.com/GraphQLAPI/graphql-api-for-wp/projects/2">listed down all the features</a> I plan to implement if I can get the funding. Right now, there are 23 of them (some of them are low-effort, so they can be bundled together):</p><figure><a href="https://leoloso.com/images/sponsorable-features.png" target="_blank"><img src="https://leoloso.com/images/sponsorable-features.png" alt="Features looking for sponsors" loading="lazy" width="3200" height="1806"></a><figcaption>Features looking for sponsors</figcaption></figure></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/milestone-first-github-sponsor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24455622</guid>
            <pubDate>Sat, 12 Sep 2020 21:00:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Symbolics Genera – The Best Software Environment Available (1985)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24455366">thread link</a>) | @mitchbob
<br/>
September 12, 2020 | http://lispm.de/genera-concepts | <a href="https://web.archive.org/web/*/http://lispm.de/genera-concepts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>An excerpt from the Symbolics Genera Manual.</p>
<div>
<p><a name="t2"></a>Genera - The Best Software Environment Available</p>

</div>
<div>
<p>To all our new users: Welcome.</p>

</div>
<p>This conceptual introduction explains what your Symbolics computer is all about. We urge you to at least skim it before you start daily work with the system. We try here to summarize some of the "big picture" concepts in your new software environment; knowing about this framework will help you in learning its details more efficiently.</p>
<p>Most new users of Symbolics machines have worked on traditional time-sharing systems, such as VAX/VMS, or on microcomputers or conventional UNIX workstations. ("Genera Comparison Charts" shows some equivalents between these systems and Genera.) If you feel somewhat uneasy about learning how to use the most advanced software environment around, relax!</p>
<p>You don't have to learn everything at once in order to do anything - look at this as a long-term, incremental learning project. You don't have to learn everything by yourself. Our documentation and Genera itself are here to help you.</p>
<p>Genera and Symbolics Common Lisp dramatically increase your productivity and efficiency by providing many built-in software facilities (similar to library routines) that you would otherwise have to write yourself. Our edit-compile-debug cycle happens so fast that you are virtually editing, compiling, and debugging simultaneously. The editor, compiler and debugger are all resident utilities, available anytime, anywhere.</p>
<div><p><img src="http://lispm.de/images/figure1.gif" alt="Figure 1"><br></p></div>
<p>Figure 1. Your view of Genera's command level.</p>
<p>Genera has no "command levels" or separate "command environments" - you can get there from here. You can move directly from any application to any other application, usually with just two keystrokes. You do not have to close one application to enter another. (See Figure 1.)</p>
<p>Many different activities, such as the editor and electronic mail, run at the same time in separate processes. That means you can move around the system from one application to another without affecting the state of other applications. For example, you can move directly from editing a file to reading online documentation to sending mail and back to editing the file.</p>
<p>To illustrate the basic environmental concept, suppose for a moment the house you live in were like a conventional software environment. The electricity would be in one room, the telephone in another, the heat in another, and the tap water in another. To access one facility, you would have to leave the other behind, moving back to a central access hallway that opened onto all the other rooms.</p>
<p>Suppose you were talking on the telephone in the telephone room. If you wanted to turn on the light in order to write something down, you would have to leave the telephone room, and go to the electricity room. If you then wanted to wash your hands, you would have to leave the electricity room and go to the water room. It would be unthinkable to use the heat, light, or telephone in the water room.</p>
<div><p><img src="http://lispm.de/images/figure2.gif" alt="Figure 2"><br></p></div>
<p>Figure 2. House as Operating System. This house design has central heating, electricity in every room, and so on. That is, basic services are available or accessible in every context.</p>
<p>Continuing this analogy, with a house designed like Genera, you could access electricity, heat, water, telephone, vacuuming, and so forth, from every room (Figure 2)! As you will see when you learn more about Genera, you can access a Genera activity in many different ways as well.</p>
<p>In a conventional computer system, the operating system is the foundation and other separate software application programs are layered on top of the operating system. The command level (exec, monitor, or shell) controls access to the operating system's facilities as well as access to (invoking and terminating) the application programs (Figure 3).</p>
<div><p><img src="http://lispm.de/images/figure3.gif" alt="Figure 3"><br></p></div>
<p>Figure 3. Traditional operating systems require the user to interact with a command monitor in order to access applications and the facilities of the operating system.</p>
<p>Genera is your whole environment; it encompasses what you normally think of as an operating system as well as everything else - system commands and all other activities. From where you look at it, there is no "top-level" controller or exec.</p>
<p>All Genera activities are themselves Lisp functions, based on a pool of thousands of Lisp functions, all implemented in Lisp. Below those, it's just the hardware - you never need to deal with a lower-level internal implementation language.</p>
<div><p><img src="http://lispm.de/images/figure4.gif" alt="Figure 4"><br></p></div>
<p>Figure 4. The Lisp Environment, consisting of all the function and data objects in virtual memory. Activities are just collections of functions and data.</p>
<p>Genera is intelligent. Its many processes can communicate with each other, and they all automatically share data. Genera keeps an internal record of the history of almost everything that happens in the system - command history, output history, process history, window history, and so on.</p>
<p>Histories make it possible to use previous output on a window as input to a command. The mouse can select a relevant piece of output anywhere on the screen because the history mechanism keeps track of the data object types of all the output. As a result, the reusable output is completely context-sensitive.</p>
<p>For example, clicking on a filename in a directory listing displays the contents of the file. When a command needs a filename argument, clicking on that same filename gives the file to the command as an argument. The meaning of the clicks is both context-sensitive and intuitive. You can scoop up a piece of output in one activity and enter it as input to another activity in a matter of seconds. With just a few keystrokes, you can find, modify, and reuse a command that you entered earlier in the day.</p>
<p>The key to Genera's intelligence is the sharing of knowledge and information among all activities. At any time, the collection of all the state of all the processes is called the environment (Figure 4). Any function running in any process can use any piece of data in the environment directly. You do not need laborious special-purpose protocols or intermediate files.</p>
<p>The entire software environment, in its pristine unused state, ready for booting, is saved on disk as a world. A world consists of all the Lisp objects (functions, variables, windows, processes, and so on) that make up the software environment. The world contains the fully initialized environment, ready to boot and use.</p>
<p>Genera doesn't draw any boundaries around itself. It is customizable and extensible by design. Unlike most software, it has an open architecture; you can change anything that is part of Genera. In fact, we encourage you to take advantage of this and to build your applications as extensions of Genera.</p>
<p>The extensibility of the system is possible thanks to both its modular design and its implementation, using highly flexible, object-oriented data structures called flavors. Any data object defined by a flavor or class can be customized or extended cleanly.</p>
<p>Object-oriented data structures are at the heart of symbolic processing because they allow abstract descriptions of data and operations in terms that fit well with the application. The data objects are essentially models of the real-world objects they are implementing. Thus programming uses a problem-solving vocabulary that matches the terminology of the problem domain.</p>
<p>Genera itself was designed to be extended in a number of different ways. You can set customizing variables and create simple files of personal initializations (called init files), or you can extend or replace parts of Genera itself in order to create your own special application.</p>
<p>When you write a program, it becomes an extension of Genera itself (Figure 5). What you do becomes part of the world and enriches the software environment. Because you have loaded a world into your own standalone machine, you can customize and extend the system without affecting the work of others. To get a fresh world, simply boot your machine again.</p>
<div><p><img src="http://lispm.de/images/figure5.gif" alt="Figure 5"><br></p></div>
<p>Figure 5. Your Programs Become an Extension of Genera.</p>
<p>To sum things up, its built-in features, open architecture, intelligence, and extensibility make Genera a new breed of software environment. Genera can help you perform tough software development tasks more quickly than you ever imagined possible.</p>
<p>As you delve deeper into the conceptual material in the next chapters, and then begin to get hands-on practice with Genera in the workbook, do not feel overwhelmed. You shouldn't put pressure on yourself to learn all about a revolutionary new software environment in a day or two. Take it easy. Try things out. Master a little at a time. Genera fosters an incremental approach in all things, including its own mastery.</p>
<p>Genera has amazing functionality and flexibility - often you can perform any task in any application in several different ways. But do not equate high flexibility and functionality with low usability! Genera is also ultimately the most usable software environment available. We want you to explore our functionality at your own pace. There is virtually no limit to the capabilities you will discover in Genera. And Genera will not place artificial upper limits on your creativity.</p>
<div>
<p><a name="t39"></a>Genera - A Short Conceptual Tour</p>

</div>
<div>
<p>The Road to Symbolic Computing</p>

</div>
<p>What's the central philosophy behind the evolution of computing in general and Genera in particular?
Free programmers from thinking about unnecessary details and they can accomplish more. The more abstractly they are allowed to think, the bigger and harder the problems they can solve.</p>
<p>Some major advances in the history of conventional computing were motivated by this philosophy:</p>
<div>
<ul>
<li>
<p>Assembly language. To avoid having to program in ones and zeros, assemblers were invented and programmers were able to express instructions to the computer mnemonically.</p>
</li>
<li>
<p>High-level languages. To avoid having to think about the computer hardware and instructions when solving a problem, high-level programming languages such as FORTRAN were invented. These allowed programmers to …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lispm.de/genera-concepts">http://lispm.de/genera-concepts</a></em></p>]]>
            </description>
            <link>http://lispm.de/genera-concepts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24455366</guid>
            <pubDate>Sat, 12 Sep 2020 20:31:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RC3 – Remote Chaos Experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24455042">thread link</a>) | @heinrich5991
<br/>
September 12, 2020 | https://events.ccc.de/2020/09/04/rc3-remote-chaos-experience/ | <a href="https://web.archive.org/web/*/https://events.ccc.de/2020/09/04/rc3-remote-chaos-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
						<p><em>Der CCC richtet in diesem Jahr erstmalig die Remote Chaos Experience (rC3) statt einer Veranstaltung vor Ort in Leipzig aus.<br>
</em><em>Dafür braucht es Kreativität, Experimentierfreude und tatkräftige Unterstützung.</em></p>
<p>[<a href="https://events.ccc.de/2020/09/04/rc3-remote-chaos-experience/#english">English Version below</a>]</p>
<p>Eine Präsenzveranstaltung mit 17.000 Menschen wird in diesem Jahr weder verantwortungsvoll noch legal durchführbar sein.<br>
Aber nach der Durststrecke 2020 haben wir uns ein schönes Jahresende redlich verdient! Deshalb wird es die rC3 – Remote Chaos Experience geben.<br>
Wir wollen so viel wie möglich von Freude, Inhalten, Zusammensein und wunderbarem Wahnsinn transportieren, die einen Chaos Communication Congress ausmachen.</p>
<p>Hackerinnen sind remote-Arbeit und -Zusammenkünfte gewohnt. Umso wichtiger ist das jährliche persönliche Treffen.<br>
Natürlich wird es schwierig, all den Wahnsinn online abzubilden, der den Congress für uns ausmacht.<br>
Doch dann sagte jemand, es wäre unmöglich. Unser Ehrgeiz war geweckt.<br>
Wir wollen sehen, wie sich die geballte Energie und Kreativität der Hackerinnen dieser Herausforderung widmet.</p>
<h2>Was erwartet mich?</h2>
<p>Die rC3 wird eine Vielzahl von <strong>kleinen lokalen Events</strong> in den örtlichen Hackspaces <strong>mit einem gemeinsamen Programm</strong> von gestreamten Talks, Online-Workshops, Kunst, Kultur und verschiedensten Formen des vernetzten Zusammenseins.</p>
<p>In den vergangenen Monaten konnte der Club mit dem <a href="https://events.ccc.de/?s=divoc">digital verteilten Online-Chaos</a> wichtige Erfahrungen sammeln. Für die rC3 gilt es, noch darüber hinauswachsen. Dafür werden alle gebraucht, die mitmachen und mitgestalten wollen.</p>
<h2>Wie kann ich mich einbringen?</h2>
<p>Du hattest schon immer großartige Ideen für den Congress – aber dir hat der Platz dafür gefehlt?<br>
Physische Limitierungen schränken dich ohnehin nur unnötig ein?</p>
<p>Willkommen im Internet! Hier können wir bisher für unmöglich gehaltene Dinge entwickeln!<br>
Endlich kann auch dein Wohnzimmer oder euer Hackspace zur Bühne, zum weltweiten Workshop-Space, zur Kunst-Installation werden!</p>
<p>Unser aller Kreativität ist es, die den Congress für alle zum Wunderland macht.<br>
Die vielen Workshops sind es, die jedes Jahr jung und alt für Neues begeistern.<br>
Großartige Vorträge vermitteln jedes Jahr neues Wissen aus Wissenschaft, Technik und Gesellschaft.</p>
<p>Was sind Deine Ideen für eine Online-Welt?</p>
<h2>Wie kann ich mitgestalten? Have your say!</h2>
<p>In den nächsten Wochen wird es <a href="https://events.ccc.de/">an dieser Stelle</a> einen Call for Participation geben. Die Content-Track-Teams freuen sich schon auf eure kreativen Einreichungen und Format-Ideen!</p>
<p>Bis dahin wollen wir Ideen sammeln, wie wir zusammen die rC3 gestalten wollen.<br>
Was erwarten wir von einer Remote-Veranstaltung?<br>
Welche neuen Formate, Spiele und Easter-Eggs sind möglich?<br>
Was können wir beitragen?<br>
Und welche Fehler sollten die C3-Teams beim Planen vermeiden?</p>
<p>Wir freuen uns über jedes Input unter<br>
<strong><a href="https://content.events.ccc.de/haveyoursay/">content.events.ccc.de/haveyoursay</a></strong></p>
<h2>Wann ist das nochmal?</h2>
<p>Save the date:<br>
27. – 30. Dezember 2020<br>
Online und im lokalen Hackspace mit deiner bevorzugten Infektionsgemeinschaft</p>
<hr>
<p>[English Version]<a name="english"></a></p>

<p><em>This year, CCC hosts the Remote Chaos Experience (rC3) instead of an on-site event in Leipzig.<br>
This endeavor requires creativity, joy of experimentation and active support.</em></p>
<p>A face-to-face event with 17,000 people will be neither responsible nor legally feasible this year. But after this tedious and painful 2020, we really deserve a nice finale!<br>
This is why the rC3 – Remote Chaos Experience will be held.<br>
As much as virtually possible, we want to convey the joy, content, togetherness and wonderful madness that make up a Chaos Communication Congress.</p>
<p>Hackers are used to remote work and online meetings. This makes our annual face-to-face meetings all the more important. Of course, it will be difficult to re-enact online all the things that make Congress what it is for us.<br>
But then someone said it would be impossible. Our ambition was aroused.<br>
Just like every year, we want to see the concentrated energy and creativity of hackers with dedication.</p>
<h2>What can I expect?</h2>
<p>rC3 will be a variety of <strong>distributed small local events</strong> in hackspaces <strong>with a joint program </strong>of streamed talks, online workshops, art, culture and various forms of networked togetherness.</p>
<p>In recent months, CCC has gained quite some experience with <a href="https://events.ccc.de/?s=divoc">digitally distributed online chaos</a> events.<br>
With rC3, we want to grow even beyond that. For this, we need everyone who wants to participate and help shape rC3.</p>
<h2>How can I get involved?</h2>
<p>You always had great ideas for Congress – but you lacked the space for it?<br>
Common restrictions of the physical world are annoying limitations to your creativity anyway?</p>
<p>Welcome to the Internet! Here, we can develop things that have been impossible so far!<br>
Finally, your living room or hackspace can become a stage, a worldwide workshop space, an art installation!</p>
<p>It’s all our creativity that makes the Congress a wonderland for everyone.<br>
It is the many workshops that inspire young and old for new things every year.<br>
Great lectures convey new knowledge from science, technology and society every year.</p>
<p>What are your ideas for an online gathering?</p>
<h2>How can I bring in my ideas? Have your say!</h2>
<p>In the next weeks, there will be a Call for Participation <a href="https://events.ccc.de/">at this site</a>. The content track teams are already looking forward to your creative submissions and format ideas!</p>
<p>Until then, we want to collect ideas on how we want to unfold rC3 together.<br>
What do we expect from a remote event?<br>
What new formats, games and easter-eggs are possible?<br>
What can we contribute?<br>
And what mistakes should the C3 teams avoid while planning?</p>
<p>We are looking forward to any input under<br>
<strong><a href="https://content.events.ccc.de/haveyoursay/">content.events.ccc.de/haveyoursay</a></strong></p>
<h2>When is it again?</h2>
<p>Save the date:<br>
December 27-30, 2020<br>
Online and in your local hackspace with your preferred infection community</p>
																	
					</div></div>]]>
            </description>
            <link>https://events.ccc.de/2020/09/04/rc3-remote-chaos-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24455042</guid>
            <pubDate>Sat, 12 Sep 2020 19:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bazel, Haskell, and Build-System Joy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24454957">thread link</a>) | @q3k
<br/>
September 12, 2020 | https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html | <a href="https://web.archive.org/web/*/https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <article>
                
                
                  <h2>2020-09-10</h2>
                
                <section>
                    <p>As part of my day job at GitHub, I work on the <a href="https://github.com/github/semantic"><code>semantic</code></a> program analysis toolkit. It’s a lot of fun and a lot of Haskell: we clock around <span>17,000</span> lines of Haskell source, though at times it’s been as high as <span>29,000</span>. The project in total has around a hundred direct dependencies, and several hundred resulting indirect ones. Though initially we used <a href="https://docs.haskellstack.org/en/stable/README/">Stack</a> to build <code>semantic</code>, we switched to <a href="https://cabal.readthedocs.io/en/3.4/">Cabal</a> when it gained the ability to build within a sandbox.</p>
<p>With <code>cabal</code> and a clean build environment, <code>semantic</code> takes between twenty and forty-five minutes to complete. When optimizations are enabled, it can take on the order of hours, especially when rebuilding dependencies with optimizations. And this is fair! Haskell is a complicated language that takes serious computational power to compile. And though Cabal is a versatile and fast-improving tool, it isn’t perfect, especially when applied to large monorepos containing many subprojects. Issues we ran into include:</p>
<ul>
<li>Little compositionality: though <code>common</code> stanzas in <code>.cabal</code> files cut down on repetition within a single file, it’s not possible to share settings or configurations across multiple files.</li>
<li>Suboptimal caching: due to the vagaries of Template Haskell, <code>cabal</code> is very conservative about caching files containing TH splices. This is correct behavior on <code>cabal</code>’s part, but grows tedious when innocuous changes cause rebuilds that we know are unnecessary. The third-party <a href="https://github.com/haskell-works/cabal-cache"><code>cabal-cache</code></a> ameliorated some of this on our CI boxes, but did not address the problem fully. Additionally, any modification to a <code>.cabal</code> file throws out its associated caches, even when doing something that shouldn’t invalidate existing caches, such as adding a new module.</li>
<li>Phasing restrictions: our build process involved generating Haskell data types from text files containing grammar descriptions, and it’s not generally possible to access project-local files during Template Haskell splices.</li>
<li>Scriptability: when dealing with large projects, it’s often very convenient to do some limited forms of iteration when specifying build configurations, and the pure-text format of <code>.cabal</code> files precludes this.</li>
<li>Reliable REPLs: in order to yield a REPL capable of loading files without first compiling the entire project, we required a complicated and brittle <a href="https://github.com/github/semantic/blob/master/script/ghci-flags">bash script</a>.</li>
<li>Convenience: compared to other languages in which you can just drop new source files and have them picked up by the compiler, <code>cabal</code> requires you to list them explicitly. While explicit is very often better than implicit, the case of adding a new module to a project is so common that editing <code>.cabal</code> files every time becomes tedious.</li>
</ul>
<p>As you can imagine, living with hour-long CI cycles was not an indefinitely tenable situation. But I think the issue of long CI cycles goes deeper than mere inconvenience: I believe that we as software developers have an ethical duty to keep build times and CI times down. We live in a world where carbon emissions have created, at least in part, a climate so troubled that the west coast of the United States is <a href="https://www.nytimes.com/2020/09/09/us/fires-oregon-california-live-updates.html">a literal hellscape</a>, where island populations are being displaced due to <a href="https://www.theguardian.com/environment/georgemonbiot/2009/may/07/monbiot-climate-change-evacuation">rising sea levels</a>, and where <a href="https://ourworld.unu.edu/en/a-growing-digital-waste-cloud">cloud computing consumes more energy</a> than some entire nations; I’ve grown to find the thought of letting corporations’ Travis or CircleCI instances recompute thousands of pointless builds upsetting, upsetting in a way similar to the thought of said companies contaminating groundwater with industrial byproducts. To meaningfully change the way companies consume resources requires broad labor action; however, irrespective of when this action is taken, we as engineers have an opportunity and responsibility to be the agents of change.</p>
<p>I also believe that very few people<span><label for="sn-0"></label><span>Excluding Rust programmers, who get to use the truly excellent <code>cargo</code>, and who seem to be very happy with it.</span></span> are truly happy with their build tool. I certainly haven’t been, anyway. To name but a few: the shortcomings of <code>make</code> have been documented for longer than I’ve been alive; <code>xcodebuild</code> only works on macOS/iOS targets; <a href="https://cmake.org/">CMake</a> is powerful but has no interoperability with <code>cabal</code>. It’s hardly controversial to suggest that, given a large project, no build system will be perfect for all people. This faact doesn’t make the quest for a better build system useless, but should also inform the engineer-voice that demands perfection.</p>
<p>Wearied by hour-long builds, both on CI and locally, I looked around for alternative build solutions that might ease that weariness. I settled on <a href="https://bazel.build/">Bazel</a>, with the <a href="https://haskell.build/"><code>rules_haskell</code></a> toolkit designed by the fine folks at <a href="https://www.tweag.io/">Tweag</a>. I’m happy to report that the experience was brilliant: if it’s possible for a build system to produce joy, Bazel and <code>rules_haskell</code> do. What follows is a brief overview of the Bazel experience, and the process of porting a large, multi-project repository to support either <code>cabal build</code> or <code>bazel build</code>.</p>

<p>The biggest thing to wrap your head around when coming to Bazel from other build systems is that <em>everything</em> on which your build depends—source files, data files, package dependencies, vendored git repositories−must be specified explicitly in Bazel. It does not suffice for your build process to just look at a given file I know is present in the repository; if the target that I’m specifying depends on that file, it must be listed explicitly as a dependency. Dependencies, in Bazel parlance, are more than libraries or repositories: the set of dependencies, and the hashed contents of all these dependencies, are what tells Bazel when builds can be cached and when they can’t. This also goes for test targets: if your tests need to read from some corpus of fixtures, you’ll have to specify those fixtures as an explicit dependency so that they’re available at runtime. This can be an involved process, as sometimes you just want to access a file (come on, it’s <em>right there</em>, I found myself whispering), but the benefits also show up in testing: if your tests are deterministic (as they should be), Bazel is capable of caching your test results, and only rerunning them when the source <em>or the fixtures</em> change. Given that the full tests for <code>semantic</code> parsing take several minutes to run, this is a profound improvement, especially on CI.</p>
<p>Beginning a new Bazel project, or converting from Cabal, requires starting with the <code>WORKSPACE</code> file. The <code>WORKSPACE</code> specifies the root of the current project, downloads and sets up GHC, and is the only place where external dependencies—such as those downloaded from Hackage—are specified. Targets are specified per-project in <code>BUILD.bazel</code> files, each of which refers as needed to external dependencies defined in the <code>WORKSPACE</code>. The language used to specify these <code>.bzl</code> files is known as <a href="https://docs.bazel.build/versions/master/skylark/language.html">Starlark</a>, and is a subset of Python that discourages mutability and iteration—though I’m hardly the world’s biggest fan of Python, I found Starlark very pleasant to use, as its chosen subset of Python is strict enough to disallow most of the things I find egregious. Once the <code>WORKSPACE</code> file is set up, the process of conversion becomes specifying per-project library and executable targets in the <code>BUILD.bazel</code> file present in each project within the monorepo.</p>
<h2 id="whence-cabal-dependencies">Whence Cabal Dependencies?</h2>
<p>As I mentioned earlier, there are several hundred direct and indirect dependencies across all subprojects in the <code>semantic</code> monorepo. Each of these dependencies has to be declared and made available as a build target, specified in the <code>WORKSPACE</code>. There are three options for specifying dependencies on Hackage projects:</p>
<ul>
<li>Specify them all manually by downloading them with <a href="https://docs.bazel.build/versions/master/repo/http.html"><code>http_archive</code></a> and <a href="https://api.haskell.build/haskell/cabal.html#haskell_cabal_library"><code>haskell_cabal_library</code></a>, doing so would be tedious beyond words, especially given that we’d have to declare dependencies for each package.</li>
<li>Use the <a href="https://nixos.org/">Nix</a> expression language, in combination with the <a href="https://github.com/tweag/rules_nixpkgs"><code>rules_nixpkgs</code></a> ruleset, and transform Nix derivations into Bazel targets.</li>
<li>Pin to a particular <a href="https://www.stackage.org/">Stackage</a> release, specifying non-Stackage dependencies with a YAML file in the project root.</li>
</ul>
<p>Though Nix has considerable merit, especially when corralling system dependencies, it’s still an unconventional choice in industry, and I deemed it politically unattainable to introduce not just one but two new frameworks for builds. As such, I chose to build against a Stackage release, especially given that we have no real system-level dependencies and that ninety percent of our dependencies are already present in Stackage snapshots.</p>
<h2 id="code-generation-it-matters">Code Generation: It Matters</h2>
<p>Because maintaining syntax trees by hand was much too onerous, my coworker <a href="https://twitter.com/aymannadeem">Ayman</a> swooped in and wrote Template Haskell splices that <a href="https://github.blog/2020-08-04-codegen-semantics-improved-language-support-system/">generate syntax types</a> from a <a href="https://tree-sitter.github.io/tree-sitter/">tree-sitter</a> JSON description of the grammar. This works well, but hinges on the ability to read said grammar descriptions from the filesystem. This was a fraught process in Cabal, relying on autogenerated <code>Paths_</code> modules providing access to files specified in the <code>data-files</code> setting in each project’s <code>.cabal</code> file, and only happened to work by accident: were <code>semantic</code> uploaded to Hackage, no one would be able to use it as a dependency, as <code>cabal</code> would be unable to find the required file. As it is, this happened to work because our downstream clients use a pinned Git hash in their <code>cabal.project</code> to pull in <code>semantic</code> as a dependency; because <code>cabal</code> checks out the whole repository in this case, the tree-sitter files happen to be in the correct place.</p>
<p>Bazel and <code>rules_haskell</code> take a more principled approach to this. Rather than calling pre-provided functions to determine the locations of these JSON files, we make the build system take care of finding them, by declaring that each language package has an explicit dependency on said file. We can pass in the location of this file as a preprocessor flag to the build process, which is then substituted using the <code>CPP</code> extension to Haskell. This doesn’t work perfectly—there’s an <a href="https://github.com/tweag/rules_haskell/issues/1337">incorrect interaction</a> when invoking a REPL on a language package in question—but suffices in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html">https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html</a></em></p>]]>
            </description>
            <link>https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24454957</guid>
            <pubDate>Sat, 12 Sep 2020 19:41:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Drywall Job Material Calculator]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24454774">thread link</a>) | @realbuildpro
<br/>
September 12, 2020 | https://realbuildpro.com/tools | <a href="https://web.archive.org/web/*/https://realbuildpro.com/tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <p>
        
        <h3>
          CONTRACTORS IN THE CONSTRUCTION INDUSTRY DESERVE FREE AND EASY TOOLS
          AT THEIR FINGER TIPS.
        </h3>
      </p>
    </div>
  </div><div>
    <h3>
      Providing value to the construction industry with innovative software.
    </h3>
    <p>
      Real Build Pro is built from the necesity to harness modern technology in
      the fast paced and complex construction business. We pride ourselves on
      our top of the line construction software that helps you wrangle your next
      job site.
    </p>
    <h6>Follow us at  <a href="https://github.com/RealBuildPro/ConstructionCalculator">
        <img height="24px" src="https://image.flaticon.com/icons/png/512/3291/3291695.png" alt="Github">
        </a></h6>
  </div></div>]]>
            </description>
            <link>https://realbuildpro.com/tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-24454774</guid>
            <pubDate>Sat, 12 Sep 2020 19:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Digital Gift for Programmers Day]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24454727">thread link</a>) | @w1nter
<br/>
September 12, 2020 | https://hacker.gifts/products/space-invaders | <a href="https://web.archive.org/web/*/https://hacker.gifts/products/space-invaders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
          <p><span>Instant Delivery • Digital Gift</span></p>
<p>Space Invaders is a&nbsp;digital gift for hackers: programmers, sysadmins and computer enthusiasts.</p>
<p>It's like a quest. It starts with a picture that contains&nbsp;a clue,&nbsp;which leads to another one, and another one... In the end a secret greetings message is revealed.</p>
<p>Each quest is unique. We will generate a personalized card based on the data you enter here.</p>
<p>Check out <strong><a href="https://hacker.gifts/pages/how-it-works" target="_blank" rel="noopener noreferrer">How It Works</a></strong>&nbsp;and <strong><a href="https://hacker.gifts/pages/faq">FAQ</a></strong> for more information.</p>
        </div></div>]]>
            </description>
            <link>https://hacker.gifts/products/space-invaders</link>
            <guid isPermaLink="false">hacker-news-small-sites-24454727</guid>
            <pubDate>Sat, 12 Sep 2020 19:13:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Want to Fix Goodreads]]>
            </title>
            <description>
<![CDATA[
Score 370 | Comments 189 (<a href="https://news.ycombinator.com/item?id=24454221">thread link</a>) | @prepend
<br/>
September 12, 2020 | http://prepend.com/culture/2020/09/fixing_goodreads.html | <a href="https://web.archive.org/web/*/http://prepend.com/culture/2020/09/fixing_goodreads.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  

  <article>
    <p>I use <a href="https://goodreads.com/">goodreads</a> a lot because I like to read books and want to find more books to read. This morning I was reading a <a href="https://news.ycombinator.com/item?id=24451428">thread on hackernews</a> on <a href="https://www.newstatesman.com/science-tech/social-media/2020/08/better-goodreads-possible-bad-for-books-storygraph-amazon">Sarah Manavis’s NewStatesman article</a> and it reminds me of how much I want, I yearn, for useful book recommendations. I think about this pretty much every time I open the goodreads page or app and hope that maybe this is the day they finally fix recommendations, so I figure I would capture some ideas I have for fixing their recommendations.</p>

<h2 id="i-love-goodreads">I Love Goodreads</h2>

<p>First, I love Goodreads. My <a href="https://www.goodreads.com/user/show/9499790-brian">profile</a> says I joined May 2012. But I think that’s just whenever I started this profile and I have multiple, old profiles that I can’t find. My memory says I started using them soon after launch, but maybe I’m misremembering. But I’ve used them for a long time because I like to read books. I love browsing bookstores and libraries looking for new books. I experience joy finding a 50 or 100 year old book that I didn’t know about. One of my favorite things is reading a book so good that I can’t go to bed, or want to walk an extra mile. But that’s pretty rare for me, I’m lucky if I get one of those a year.</p>

<p>I have goodreads on my <a href="http://prepend.com/stack.xml">link stack</a> with the tag <a href="https://www.prepend.com/future/technology/2020/01/purdah.html">“purdah”</a> that I think means it is part of the stuff I do that uniquely identifies me.</p>

<p>Any time I get a recommendation from a friend or article or wherever, I add it to my “to read” shelf on goodreads. That helps me when I’m trying to buy a new book. So at least I can read through the 245 books that at least a past me wanted to read. This works well and is better than a vanilla list.</p>

<p>I also like seeing what my friends read and especially what they like or dislike. My friends have different tastes so it’s not as simple as just reading everything they read, but it helps a little. It’s one of the few places that I think facebook helps because at least I get to find out facebook friends who also are on goodreads. Every once in a while I find a new book through this feed, maybe once every 2 years. This might be because I don’t have many friends on goodreads (only 42), but I think it’s also because different people have different tastes in books.</p>

<p>I also like that goodreads will tell me when an author I’ve read releases a new book, or is having a book chat or something. Although I wish they would tell me when they come to a local book signing.</p>

<h2 id="the-problem-as-i-see-it">The Problem As I See It</h2>

<p>This gets me to what I think is wrong and want to fix. I have read and rated 802 books with my average rating of 3.97. This makes sense as I’m probably only going to read books I think I’ll like, but I think this is the average goodreads rating, not the average of my ratings. Looking at what I rated, I’ve only given out 3 one stars, 42 two stars and tons of five stars. I keep scrolling on and on.</p>

<p>The user interface for goodreads is pretty bad- information is hard to find, layout is wasted, search doesn’t work well, hard to tell ads from user content- but that’s not what I’m talking about here. The main problem is in finding books that I will like. Maybe a UX overhaul from a great designer would help, but not that much. A craigslist interface would be great if they could just solve this one problem…</p>

<blockquote>
  <p><strong>What is the single book that I will love most in all the world?</strong></p>
</blockquote>

<p>I want to find the next amazing experience. Books are great because they are cheap and portable. It’s not like wine where the best is more than I’ll ever pay. Or travel where a first class flight can cost $20k. If I can find a book, I can read it. And maybe someone I know can read it too.</p>

<p>If I can mix in more wonderful books, my life will be better. My family’s life will be better. Etc etc. Maybe this is the answer to world enlightenment. Probably not, but it will be great, I think.</p>

<p>When I click on <a href="https://www.goodreads.com/recommendations">recommendations</a>, goodreads shows me five books that I don’t want to read. And it’s weirdly bad. Some of it makes since why it’s bad. They recommend different versions of books I’ve read. They recommend two different versions of <em>Lord of the Rings</em> (one of my favorite books), but I guess they don’t know these are the same book. That’s just a waste of time and it’s weird that amazon isn’t smart enough to avoid duplicative books.</p>

<p><img src="http://prepend.com/assets/images/goodreads_recommendations.png" alt="Screenshot of goodreads recommendations page"></p>

<p>But then they recommend stuff like Stephen King’s <em>The Long Walk</em>. This is perplexing because I only have one book that goodreads knows I’ve read from King and I rated it two stars. I don’t have any of his books in my “to read” list. Why would they recommend this book? Two of my friends rated it four stars and one even wrote a recommendation. So maybe that’s why. I’m aware of this book and don’t want to read it. But other books like <em>Shoe Dog</em> by Phil Knight has no relationship to me. Why would they recommend this? I also know about this book and don’t want to read it. I wish there was some way to note books that I don’t want to read. Then at least they would stop showing me the same book over and over.</p>

<p>So it seems like goodreads is making pretty basic, rules-based recommendations. And they don’t help me pick new books.</p>

<h2 id="my-perfect-wish">My Perfect Wish</h2>

<p>My idea for an 11-star experience <sup id="fnref:brian_chesky" role="doc-noteref"><a href="#fn:brian_chesky">1</a></sup> in finding new books is that Goodreads knows me even better than I know myself and constantly recommends the perfect book. They recommend books that teach me, that spark enlightenment, that I hate but teach me to appreciate other books, books for when I want to be happy, and books for when I need to be sad. I want something like Jane from Ender’s Game who experiences everything I know but is fixated on finding me a good book. So the output of a book sommelier whose passion is seeing me sit there and love a book.</p>

<p>That’s what I would like.</p>

<h2 id="a-little-story-about-jeff-bezos">A Little Story About Jeff Bezos</h2>

<p>Once I was lucky enough to go to TED. It was great on so many levels, I highly recommend it and 2/3 of the cost was tax deductible. It was full of great stuff. I got to wait in the registration line in front of Neil Gaiman and Amanda Palmer, that was neat.</p>

<p>Anyway, one night Neil Gaiman was doing in a midnight ghost story reading in some neat four story townhouse type building <sup id="fnref:vancouver_club" role="doc-noteref"><a href="#fn:vancouver_club">2</a></sup> that was totally empty and spooky and a great place for the event. The reading was on the top floor and there was a huge crowd waiting for the single elevator in this place. The lights were off and there weren’t any staff around so it was maybe 100 people waiting to go up three at a time. So I looked around the corner and took the stairs. About 2 or 3 other people had the same idea so we started racing up the stairs to get to the top and avoid the crowds.</p>

<p><img src="http://prepend.com/assets/images/vancouver_club.jpg" alt="Vancouver Club street view">
<em>photo by <a href="https://fineartamerica.com/profiles/2-joe-fox">Joe Fox</a></em></p>

<p>This building was awesome. It seemed 100 years old, rare in Vancouver, and as we went up the stairs we saw each floor. The stairwell opened up to a big room that could probably seat a 50 person wedding dinner. The lights were off, and someone had opened a few windows and the white, wispy curtains were blowing with a little breeze. Even though it didn’t feel like a breeze. I said “cool, haunted house” and stopped climbing the stairs to look around. The person next to me said “yeah, cool” and we started quickly running around checking out the empty room. We did this on the third floor too and me and this random person did quick 60 second explorations of this spooky house.</p>

<p>It all happened quickly. Maybe 3 minutes to go up the stairs, run around each floor, and get to the top. About halfway through I realized this random dude was Jeff Bezos. I thought that was neat. I’ve bought books from Amazon since 1995 and I’m pretty sure I telnetted into it to order some books (although maybe that was cdnow before they bought them), so it was cool to think that Jeff Bezos likes haunted houses and still likes exploring empty buildings.</p>

<p>We got to the top and went into the venue and were maybe the first 10 people. Comically got there maybe after two or three elevators full of people. We went to the front where Gaiman was setting up at the podium. I got a comfy chair right in the front about five feet in front of Gaiman. Jeff Bezos sat in the chair to my left. The chair on my right had Neil’s wife, Amanda Palmer, who was carrying a ukelele case. I didn’t know it was a ukulele case until she told me. She also said she might play, but she didn’t.</p>

<p>Gaiman finished setting up and came up to talk to Bezos. Bezos asked if Gaiman got the books he sent. Gaiman said he did and they were really great and he enjoyed reading them. It seemed like this was the most recent in a series of book shipments.</p>

<p>Aside from nerd joy from getting to witness this small talk of people who interest me, I thought, at the time and many times since,</p>

<blockquote>
  <p>How cool is it that Neil-freaking Gaiman is still finding new books that are great, and how cool would it be to get book recommendations from Jeff Bezos. I bet he has access to the best book recommendations in the world.</p>
</blockquote>

<p>Also, TED has something called the “TED book club” where they mail you this box of books a month before the conference. This was the closest I’ve come to my dream. They maybe sent 10 and 5 are still on my bookshelf. But not the shelf behind me, so I don’t remember them specifically. I’ll look them up one day.</p>

<p>That’s probably better than Jane making recommendations. Amazon had just bought goodreads a year earlier and I was hopeful that any day, goodreads would roll out a wonderful recommendation engine any day now.</p>

<h2 id="what-i-want-to-do-to-fix">What I Want to Do to Fix</h2>

<p>What I would like to do is to just get a data dump of mine and everyone on goodreads recommendations. I don’t need to know the identities, just to know what recommendations go with what individual. It would be neat to protect privacy and find individuals to potentially follow them on goodreads, but I think for the analysis I want to do, I don’t need to know the actual identities.</p>

<p>I think if I have this data, I could try to find people who rate a few hundred books like I have, then look at what books they’ve read the most, or books that they’ve rated highest. I think that would be a good signal that I might like it.</p>

<p>It would also be cool to see …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://prepend.com/culture/2020/09/fixing_goodreads.html">http://prepend.com/culture/2020/09/fixing_goodreads.html</a></em></p>]]>
            </description>
            <link>http://prepend.com/culture/2020/09/fixing_goodreads.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24454221</guid>
            <pubDate>Sat, 12 Sep 2020 18:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mowing the Lawn in Spirals]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24453865">thread link</a>) | @jelliclesfarm
<br/>
September 12, 2020 | https://thatsmaths.com/2015/10/29/mowing-the-lawn-in-spirals/ | <a href="https://web.archive.org/web/*/https://thatsmaths.com/2015/10/29/mowing-the-lawn-in-spirals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<h3>
									Mowing the Lawn in&nbsp;Spirals								</h3>

				<p><small>
					<span>
						Published <abbr title="2015-10-29T10:28:26+0000">October 29, 2015</abbr>					</span>

					<span> <a href="https://thatsmaths.com/category/occasional/" rel="category tag">Occasional</a></span>

					<a href="https://thatsmaths.com/2015/10/29/mowing-the-lawn-in-spirals/#respond">Leave a&nbsp;<span>Comment</span></a>
					
					<br>Tags: <a href="https://thatsmaths.com/tag/archimedes/" rel="tag">Archimedes</a>, <a href="https://thatsmaths.com/tag/geometry/" rel="tag">Geometry</a><br>
				</small></p><!-- .entry-meta -->
			</div><div>
				<p><span><span><i><span>Like a circle in a spiral / Like a wheel within a wheel / </span></i><span><i>Never ending or beginning / On an ever-spinning reel.&nbsp;&nbsp;&nbsp; </i>The Windmills Of Your Mind </span></span></span></p>
<p><span><span>Broadly speaking, a spiral curve originates at a central point and gets further away (or closer) as it revolves around the point. Spirals abound in nature, being found at all scales from the whorls at our finger-tips to vast rotating spiral galaxies. The seeds in a sunflower are arranged in spiral segments. In the technical world, the grooves of a gramophone record and the coils of a watch balance-spring are spiral in form.</span></span></p>
<div data-shortcode="caption" id="attachment_3728"><p><a href="https://thatsmaths.files.wordpress.com/2015/10/spirals-three.jpg"><img loading="lazy" aria-describedby="caption-attachment-3728" data-attachment-id="3728" data-permalink="https://thatsmaths.com/2015/10/29/mowing-the-lawn-in-spirals/spirals-three/" data-orig-file="https://thatsmaths.files.wordpress.com/2015/10/spirals-three.jpg" data-orig-size="980,327" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Spirals-Three" data-image-description="" data-medium-file="https://thatsmaths.files.wordpress.com/2015/10/spirals-three.jpg?w=300" data-large-file="https://thatsmaths.files.wordpress.com/2015/10/spirals-three.jpg?w=500" src="https://thatsmaths.files.wordpress.com/2015/10/spirals-three.jpg?w=660&amp;h=237" alt="Left: Archimedean spiral. Centre: Fermat spiral. Right: Hyperbolic spiral." width="660" height="237"></a></p><p id="caption-attachment-3728">Left: Archimedean spiral. Centre: Fermat spiral. Right: Hyperbolic spiral.</p></div>

<p><span><span><span><b>Spiral Equations</b></span></span></span></p>
<p><span><span>In polar coordinates, the radial distance <i>r</i> ( <i>θ</i> ) from the central point is a monotonic function of the azimuthal angle <i>θ.</i> There are several canonical spiral forms. The simplest is the Archimedean spiral, <i>r = a θ</i>. This is generated by a point moving with uniform speed along a ray that is rotating with constant angular speed. Since the points of intersection with a fixed ray from the origin are evenly spaced with separation 2 <i>π a</i>, it is also called an arithmetic spiral (left panel of figure above). It was described by Archimedes in his work <i>On Spirlas</i>. </span></span></p>
<p><span><span>More generally, we consider <i>r</i><sup><i>k</i></sup><i> = a</i><sup><i>k</i></sup><i> θ</i>. For <i>k</i> = 2 we get Fermat’s spiral <i>r = a </i><i>√</i><i> θ</i> (centre panel of Fig). For <i>k</i> = –1 we have <i>r = a </i><i>/</i><i> θ</i>, which is a hyperbolic spiral (right panel of Fig).</span></span></p>
<p><span><span>An equiangular spiral is such that every ray from the origin cuts it at the same angle. Its equation is <i>r = a</i> exp (<i> b</i> <i>θ</i> ). Since <i>b</i> <i>θ</i> = log (<i>r / a</i> ), it is also called a logarithmic spiral and, since the intersection points with a fixed ray form a geometric sequence, the name geometric spiral is also used. Christopher Wren observed that many sea-shells, such at the <em>Nautilus</em>, have logarithmic spiral cross-sections.</span></span></p>
<div data-shortcode="caption" id="attachment_3729"><p><a href="https://thatsmaths.files.wordpress.com/2015/10/nautiluscutawaylogarithmicspiral.jpg"><img loading="lazy" aria-describedby="caption-attachment-3729" data-attachment-id="3729" data-permalink="https://thatsmaths.com/2015/10/29/mowing-the-lawn-in-spirals/nautiluscutawaylogarithmicspiral/" data-orig-file="https://thatsmaths.files.wordpress.com/2015/10/nautiluscutawaylogarithmicspiral.jpg" data-orig-size="635,480" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="NautilusCutawayLogarithmicSpiral" data-image-description="" data-medium-file="https://thatsmaths.files.wordpress.com/2015/10/nautiluscutawaylogarithmicspiral.jpg?w=300" data-large-file="https://thatsmaths.files.wordpress.com/2015/10/nautiluscutawaylogarithmicspiral.jpg?w=500" src="https://thatsmaths.files.wordpress.com/2015/10/nautiluscutawaylogarithmicspiral.jpg?w=573&amp;h=439" alt="Nautilus shell with the form of a logarithmic spiral [image from the user Chris 73, freely available from Wikimedia Commons]." width="573" height="439"></a></p><p id="caption-attachment-3729">Nautilus shell with the form of a logarithmic spiral<br>[image from the user Chris 73, freely available from Wikimedia Commons].</p></div>
<p><span><span><span><b>Involutes</b></span></span></span></p>
<p><span><span>Suppose you wish to cut the grass. Here is an easy way:</span></span></p>
<ul>
<li>
<p><span><span>Erect a stout column in the centre of the lawn;</span></span></p>
</li>
<li>
<p><span><span>Tie the mower to the column with a long rope;</span></span></p>
</li>
<li>
<p><span><span>Start it so that it winds inward in a spiral arc;</span></span></p>
</li>
<li>
<p><span><span>Relax and enjoy the magic of the <i>automower</i>.</span></span></p>
</li>
</ul>
<p><span><span>The curve traced by the mower looks like an Archimedean spiral. It is actually slightly different: it is the involute of a circle (namely, the circular cross-section of the central column). The column should be chosen to have circumference 2 <i>π a </i><i>= D </i>where<i> D </i>is the blade diameter of the mower.</span></span></p>
<p><span><span>If the column is described by the equations</span></span></p>
<p><span><span><i>x = a </i>cos <i>θ</i> ,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <i>y = a</i> sin <i>θ</i> </span></span></p>
<p><span><span>where <i>a</i> is the radius of the circle, then the curve traced out by the mower is</span></span></p>
<p><span><span><i>x = a </i>( cos <i>θ</i> + <i>θ</i> sin <i>θ</i> ) , &nbsp; &nbsp; &nbsp; &nbsp; <i>y = a </i>( sin <i>θ</i> – <i>θ </i>cos<i> θ </i>)</span></span></p>
<p><span><span>The radius vector is <i>r</i><sup>2</sup> = <i>a</i><sup>2</sup> ( 1 + <i>θ </i><sup>2</sup> ) . For <i>θ</i> = 0 we have <i>r = a</i>, whereas, for the Archimedean spiral ( <i>r</i><sup>2</sup> = a<sup>2</sup> <i>θ </i><sup>2</sup> ) we have <i>r</i> = 0 when <i>θ</i> = 0. The two curves are close, but not identical:<br>
</span></span></p>
<div data-shortcode="caption" id="attachment_3732"><p><a href="https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg"><img aria-describedby="caption-attachment-3732" data-attachment-id="3732" data-permalink="https://thatsmaths.com/2015/10/29/mowing-the-lawn-in-spirals/spirals-two/" data-orig-file="https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg" data-orig-size="865,432" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Spirals-Two" data-image-description="" data-medium-file="https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg?w=300" data-large-file="https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg?w=500" src="https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg?w=500&amp;h=250" alt="Left: Archimedean spiral. Right: Involute of a circle." srcset="https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg?w=500&amp;h=250 500w, https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg?w=150&amp;h=75 150w, https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg?w=300&amp;h=150 300w, https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg?w=768&amp;h=384 768w, https://thatsmaths.files.wordpress.com/2015/10/spirals-two.jpg 865w" sizes="(max-width: 500px) 100vw, 500px"></a></p><p id="caption-attachment-3732">Left: Archimedean spiral. Right: Involute of a circle.</p></div>
<p><span><span><b>Acknowledgement: </b></span></span></p>
<p><span><span>This article was inspired by correspondence with Stephen Richardson of Exeter NH. </span></span></p>
<p><span><span><span><b>Sources:</b></span></span></span></p>
<p><span><span>Wells, David, 1991: <i>The Penguin Dictionary of Curious and Interesting Geometry</i>. Penguin Books, ISBN: 9-780-140-11813-1.</span></span></p>

							</div></div>]]>
            </description>
            <link>https://thatsmaths.com/2015/10/29/mowing-the-lawn-in-spirals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24453865</guid>
            <pubDate>Sat, 12 Sep 2020 17:13:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gesture Recognition with Line Integrals]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24453825">thread link</a>) | @justinmeiners
<br/>
September 12, 2020 | https://justinmeiners.github.io/gesture-recognition | <a href="https://web.archive.org/web/*/https://justinmeiners.github.io/gesture-recognition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <p>
            By: Justin Meiners (2020)

            </p><p>
            <a target="_blank" href="https://en.wikipedia.org/wiki/Line_integral">
                Line integrals</a> measure the extent to which a path agrees with a vector (directional) field.
                This provides an easy way to implement handwriting/tracing/gesture recognition.
                Although not as accurate as fancy ML methods, it still can recognize a wide
                varation in drawings with good accuracy and is versatile in application.
                However, this would not work for OCR applications as the direction of the strokes is an essential component of recognition.
           </p>

            <p>
                The line integral and total length of the path both contribute
                to the scoring. This allows "5" and "8" to be distinguished.
                The centroid of the path is used for adjusting position.
            </p>


            <p>
                Try drawing a number (1-9) in the box to see if it detects it.
            </p>

            
            <canvas id="main-canvas" width="220" height="220"></canvas>

            

            <p>
                To make a new glyph:
                </p><ul>
                    <li> Clear the Canvas </li>
                    <li> Hold <b>SHIFT</b> and draw the character 5-8 times.
Try to keep the position the same as before. Naturally you will add a little variation.

                    </li><li> Optional: Press smooth a few times, then redraw a few more times. </li>
                    <li> Type in the string your glyph represents and <b>Save</b>.</li>
                </ul>
            

            

            <p><label>String
            
            </label>
            </p><h4>Saved Glyphs</h4>
            
            <ul id="glyphs">
            </ul>
        </div></div>]]>
            </description>
            <link>https://justinmeiners.github.io/gesture-recognition</link>
            <guid isPermaLink="false">hacker-news-small-sites-24453825</guid>
            <pubDate>Sat, 12 Sep 2020 17:07:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Quality DOSBox Video Capture]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24453737">thread link</a>) | @zdw
<br/>
September 12, 2020 | https://susam.in/blog/good-quality-dosbox-video-capture/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/good-quality-dosbox-video-capture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 01 Sep 2020</p>
<h2 id="vintage-dos-programs"><a href="#vintage-dos-programs">Vintage DOS Programs</a></h2>

<p>
Once in a while, I fire up one of the vintage DOS games or language
interpreters in DOSBox for nostalgia's sake. I have archived these
vintage programs at <a href="https://github.com/susam/dosage">github.com/susam/dosage</a>.
DOSBox is an emulator program that emulates IBM PC compatible computers
running DOS. Trying my hands on these antiquated DOS programs now evokes
old memories from my childhood days days when I first came across
computers as part of our primary school curriculum.
</p>

<p>
Computers were much simpler in those days. The ones in our school were
IBM PC compatible computers with mostly monochrome displays. A couple of
them had support for a very limited number of colours provided by CGA or
EGA graphics cards. The ability to boot a computer using a
5¼-inch floppy disk containing MS-DOS, load a Logo or BASIC
interpreter, or a computer game from another floppy disk, and then write
some programs or play a few games without any distraction had its own
charm that I find missing from modern day computing.
</p>

<p>
Often while using old DOS programs with DOSBox in this day and age, I
want to take screenshot captures or video captures of the DOSBox
sessions and share them with my friends. In this article, I will explain
how I create good quality screenshot captures and video captures of
DOSBox sessions in formats that I can share with others.
</p>


<h2 id="contents"><a href="#contents">Contents</a></h2>
<ul>
  <li><a href="#vintage-dos-programs">Vintage DOS Programs</a></li>
  <li><a href="#software-versions">Software Versions</a></li>
  <li><a href="#ibm-pc-logo-in-dosbox">IBM PC Logo in DOSBox</a></li>
  <li><a href="#digger-in-dosbox">Digger in DOSBox</a></li>
  <li><a href="#dosbox-screenshot-capture">DOSBox Screenshot Capture</a></li>
  <li><a href="#dosbox-video-capture">DOSBox Video Capture</a></li>
  <li><a href="#dosbox-audio-video-capture">DOSBox Audio/Video Capture</a></li>
  <li><a href="#dosbox-gif-animation">DOSBox GIF Animation</a></li>
  <li><a href="#references">References</a></li>
</ul>


<h2 id="software-versions"><a href="#software-versions">Software Versions</a></h2>

<p>
Since this article involves several pieces of software, some of what is
written here may not hold good in future if the behaviour of any of
these software tools change in future. The list below contains the
versions of all software tools that were used to test the commands
provided in this article:
</p>

<ol>
  <li>macOS High Sierra 10.13.6</li>
  <li>DOSBox 0.74-3</li>
  <li>FFmpeg 4.3.1</li>
  <li>ImageMagick 7.0.10-28
  </li><li>IBM Personal Computer Logo Version 1.00</li>
  <li>Digger (Original PC booter version by Windmill Software)</li>
</ol>

<p>
Note that both Logo and Digger programs in the list above are DOS
programs that were released in 1983. They cannot be run directly on
modern computers but they can be run with DOSBox since it emulates old
IBM PC compatible computers.
</p>


<h2 id="ibm-pc-logo-in-dosbox"><a href="#ibm-pc-logo-in-dosbox">IBM PC Logo in DOSBox</a></h2>

<p>
IBM Personal Computer Logo developed by Logo Computer Systems Inc.
(LCSI) in 1983 was the first piece of software I got introduced to while
learning computers as a kid. I came across it at the age of 8 when I was
in Class 4 and our school had a 5¼-inch floppy disk with IBM PC
Logo on it. As a result, Logo was the first programming language I
learnt in my life. About 20 years later, I would realize that the first
programming language I learnt is a dialect of Lisp. How wonderful!
</p>

<figure id="logo-welcome-screenshot">
  <a href="https://susam.in/files/blog/dosbox-logo-0.png"><img src="https://susam.in/files/blog/dosbox-logo-0.png" alt="A screenshot of IBM Personal Computer Logo with copyright notices of IBM and LCSI, welcome message, and question mark prompt"></a>
  <figcaption>
    Welcome screen of IBM Personal Computer Logo
  </figcaption>
</figure>

<!--
Class Age Year
   KG   4   88
    1   5   89
    2   6   90
    3   7   91
    4   8   92
    5   9   93
    6  10   94
    7  11   95
    8  12   96
    9  13   97
   10  14   98
-->

<p>
If the Logo interpreter program <code>LOGO.COM</code> exists in the
current directory, it can be run with DOSBox using the following
command:
</p>

<pre><code>dosbox LOGO.COM</code></pre>

<p>
One of the things I enjoyed drawing with Logo was a grid of overlapping
circles like this:
</p>

<figure id="logo-program-screenshot">
  <a href="https://susam.in/files/blog/dosbox-logo-1.png"><img src="https://susam.in/files/blog/dosbox-logo-1.png" alt="A grid made with 20 circles along with Logo source code for it"></a>
  <figcaption>
    Grid of circles drawn with IBM Personal Computer Logo
  </figcaption>
</figure>

<p>
Here is the Logo source code for the above output:
</p>

<pre><code>REPEAT 20 [REPEAT 180 [FD 1 RT 2] RT 18]</code>
</pre>


<h2 id="digger-in-dosbox"><a href="#digger-in-dosbox">Digger in DOSBox</a></h2>

<p>
At around the same time I learnt Logo, I also came across Digger, a
computer game for IBM PC developed by Windmill Software in 1983.
</p>

<figure id="digger-welcome-screenshot">
  <a href="https://susam.in/files/blog/dosbox-digger-0.png"><img src="https://susam.in/files/blog/dosbox-digger-0.png" alt="A screenshot of Digger welcome screen with the names and pictures of various game characters with a copyright notice of Windmill Software"></a>
  <figcaption>
    Welcome screen of Digger
  </figcaption>
</figure>

<p>
If the Digger program <code>DIGGER.COM</code> exists in the directory,
it can be run using DOSBox with the following command:
</p>

<pre><code>dosbox DIGGER.COM -c "config -set cpu cycles=500" -machine cga</code>
</pre>

<p>
The <code>-machine cga</code> option emulates a machine with Color
Graphics Adapter (CGA) because Digger requires a machine of this type to
run correctly. The <code>cycles=500</code> configuration option slows
down the speed at which DOSBox emulates instructions in order to emulate
the slow machines of olden days. Without this option, Digger runs too
fast to be able to be conveniently playable.
</p>

<figure id="digger-game-screenshot">
  <a href="https://susam.in/files/blog/dosbox-digger-1.png"><img src="https://susam.in/files/blog/dosbox-digger-1.png" alt="A screenshot of underground maze in the game of Digger"></a>
  <figcaption>
    A game of Digger that has just begun
  </figcaption>
</figure>

<p>
Digger has an excellent gameplay where the player digs through
underground tunnels to pick up emeralds, drop gold bags to release the
gold or squash nobbins and hobbins, collect the released gold to earn
more points, and so on. It uses bright and attractive colours. The music
is great. When Digger was released in 1983, it was quite advanced for
its time.
</p>



<h2 id="dosbox-screenshot-capture"><a href="#dosbox-screenshot-capture">DOSBox Screenshot Capture</a></h2>

<p>
The screenshots above were obtained by running IBM PC Logo and the
original 1983 PC booter version of Digger on DOSBox and then resizing
the screenshots such that their aspect ratio matches the aspect ratio of
old CRT computer monitors.
</p>

<p>
To obtain the screenshots, we first press <kbd>Ctrl</kbd> +
<kbd>F5</kbd> while DOSBox is running. The paths of the screenshots
appear in the console output at the terminal where DOSBox was launched.
For example:
</p>

<pre><samp>Capturing Screenshot to /Users/susam/Library/Preferences/capture/logo_000.png
Capturing Screenshot to /Users/susam/Library/Preferences/capture/logo_001.png</samp>
</pre>

<pre><samp>Capturing Screenshot to /Users/susam/Library/Preferences/capture/digger_000.png
Capturing Screenshot to /Users/susam/Library/Preferences/capture/digger_001.png</samp>
</pre>

<p>
The screenshots obtained in this manner have an aspect ratio of 8:5
which makes the output look stretched horizontally. The old CRT computer
monitors for which these old DOS programs were written had an aspect
ratio of 4:3 instead. This stretched look can be fixed by resizing the
images to an aspect ratio of 4:3. Here are the commands used to fix the
aspect ratio and produce the images:
</p>

<pre><code>convert logo_000.png -sample '1920x1440!' dosbox-logo-0.png
convert logo_001.png -sample '1920x1440!' dosbox-logo-1.png</code>
</pre>
<pre><code>convert digger_000.png -sample '1920x1440!' dosbox-digger-0.png
convert digger_001.png -sample '1920x1440!' dosbox-digger-1.png</code>
</pre>

<!--
According to Screen Resolution Statistics for January 2020 by
w3schools.com, here are the statistics of browser resolutions:

Resolution   %age  Cumulative

Lower         9.0    9.0
1280 x  720   3.9   12.9
1024 x  768   1.4   14.3
1360 x  768   1.0   15.3
1366 x  768  27.6   42.9
1280 x  800   1.8   44.7
1536 x  864   9.8   54.5
1440 x  900   5.6   60.1
1600 x  900   4.1   64.2
1280 x 1024   2.4   66.6
1680 x 1050   2.6   69.2
1920 x 1080  20.3   89.5
1920 x 1200   1.5   91.0
2560 x 1440   1.7   92.7
Other High    7.3  100.0

1440 x 1080 is strictly larger than 55.3% displays.
1600 x 1200 is strictly larger than 66.6% displays.
1920 x 1440 is strictly larger than 91.0% displays.
x 1080 >= 89.5% displays
x 1200 >= 91.0% displays.
x 1440 >= 92.7% displays
-->

<p>
The <code>convert</code> program comes with ImageMagick. There are a few
things worth noting here:
</p>

<ul>
  <li>
    We use the <code>-sample</code> option here to resize the image as
    opposed to using <code>-resize</code> or <code>-scale</code>. The
    <code>-resize</code> or <code>-scale</code> option would smooth the
    jagged edges in the text and graphics by introducing additional
    colours. The <code>-resize</code> option is great for real world
    images where we do want the edges to be smooth while scaling up or
    down but in these screenshots we want to retain the crisp and jagged
    edges that is typical of DOSBox and the old CRT monitors. Therefore
    we use the <code>-sample</code> option that does not introduce any
    new colours. Instead it uses nearest-neighbour interpolation (point
    sampling) to decide the colours of the scaled image.
  </li>
  <li>
    The <code>!</code> flag is used to ignore the aspect ratio of the
    original image. Without this flag, the output files would be
    1920x1200 in size, that is, the largest size with an aspect ratio of
    8:5 that fits in a 1920x1440 box. With this flag, the original
    aspect ratio of 8:5 is ignored and the output is exactly 1920x1440
    in size.
  </li>
</ul>

<p>
By the way, I have donated these images above to Wikimedia Commons under
the Creative Commons Attribution 4.0 International (CC BY 4.0) license:
</p>

<ul>
  <li><a href="https://commons.wikimedia.org/wiki/File:IBM_LCSI_Logo_Welcome_Screen.png">File:IBM_LCSI_Logo_Welcome_Screen.png</a></li>
  <li><a href="https://commons.wikimedia.org/wiki/File:IBM_LCSI_Logo_Circles.png">File:IBM_LCSI_Logo_Circles.png</a></li>
  <li><a href="https://commons.wikimedia.org/wiki/File:Digger_Original_PC_Booter_Version_Welcome_Screen.png">File:Digger_Original_PC_Booter_Version_Welcome_Screen.png</a>
  </li><li><a href="https://commons.wikimedia.org/wiki/File:Digger_Original_PC_Booter_Version_Game.png">File:Digger_Original_PC_Booter_Version_Game.png</a></li>
</ul>

<p>
Having the images on Wikimedia Commons helps to include these
screenshots in the Wikipedia articles on <a href="https://en.wikipedia.org/wiki/Logo_(programming_language)#Implementations">Logo</a>
and <a href="https://en.wikipedia.org/wiki/Digger_(video_game)">Digger</a>.
</p>


<h2 id="dosbox-video-capture"><a href="#dosbox-video-capture">DOSBox Video Capture</a></h2>

<p>
To start capturing video of DOSBox, we press <kbd>Ctrl</kbd> +
<kbd>Alt</kbd> + <kbd>F5</kbd>. The same key combination stops capturing
video. The following output appears in the console output to show where
the video file is saved:
</p>

<pre><samp>Capturing Video to /Users/susam/Library/Preferences/capture/logo_000.avi
Stopped capturing video.</samp>
</pre>

<p>
Say, I want to share a video capture of DOSBox with Logo running on it
with my friends who might be on devices that do not support playing AVI
files. The following FFmpeg command converts the video to a format that
can be distributed widely and played on a wide range of devices and
players:
</p>

<pre><code>ffmpeg -i logo_000.avi -an -c:v libx264 -preset veryslow \
       -crf 17 -vf format=yuv420p,scale=1920:1440:flags=neighbor,fps=30 \
       dosbox-logo.mp4</code>
</pre>

<p>
Here is what the output looks like:
</p>

<figure id="logo-video">
  <video controls="">
    <source src="https://susam.in/files/blog/dosbox-logo.mp4" type="video/mp4">
  </video>
  <figcaption>
    Video capture of IBM Personal Computer Logo
    [<a href="https://susam.in/files/blog/dosbox-logo.mp4">MP4</a>]
  </figcaption>
</figure>

<p>
Let us briefly discuss the various FFmpeg options used here:
</p>

<ul>
  <li>
    <p>
      <code>-i logo_000.avi</code>
    </p>
    <p>
      This, of course, specifies the input file.
    </p>
  </li>
  <li>
    <p>
      <code>-an</code>
    </p>
    <p>
      The audio is silent in this video, so we reduce the file size a
      little by disabling the audio stream with this option. For
      example, without this option the output file size was 317 KB but
      with this option it turned out to be 282 KB.
    </p>
    <p>
      This option should not be specified if the audio stream needs to
      preserved, for example, with DOS games that have audio. We will
      see an example of this in the next section.
    </p>
  </li>
  <li>
    <p>
      <code>-c:v libx264</code>
    </p>
    <p>
      This option selects the x264 encoder to encode the video stream
      into H.264 format. H.264 is also known as MPEG-4 Part 10, Advanced
      Video Coding (MPEG-4 AVC). Currently, it is the most popular
      format for recording, compression, and distribution of video
      content.
    </p>
  </li>
  <li>
    <p>
      <code>-crf 17</code>
    </p>
    <p>
      This option provides visually lossless output, that is, high
      quality output without any loss in quality that can be perceived
      by human eyes. For completely lossless output, we need to use the
      <code>-crf 0</code> option. However, this option sets the video
      profile to <code>High 4:4:4 Predictive</code> which prevents the
      video from playing in some video players. This issue is discussed
      in more detail in the point about <code>yuv420p</code> pixel
      format that comes later in this list. Since <code>-crf 0</code>
      cannot be used due to this issue, the next best option is
      <code>-crf 1</code> which while not completely lossless is much
      better than …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://susam.in/blog/good-quality-dosbox-video-capture/">https://susam.in/blog/good-quality-dosbox-video-capture/</a></em></p>]]>
            </description>
            <link>https://susam.in/blog/good-quality-dosbox-video-capture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24453737</guid>
            <pubDate>Sat, 12 Sep 2020 16:53:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Development as a Core Competency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24453272">thread link</a>) | @neinasaservice
<br/>
September 12, 2020 | https://21-lessons.com/2020/09/09/software-development-as-core-competency | <a href="https://web.archive.org/web/*/https://21-lessons.com/2020/09/09/software-development-as-core-competency">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1119">

    

	<div>

		
<p>2020 is a lot. For over six months now, we’ve been changing and adapting to get through this pandemic. We’re wearing masks, keep distance to other people, and figure out the new normal as we go.<br>It’s not just our personal lives where we need to adapt, but also our business world. Suddenly, we can’t go to stores anymore, and in-person services become challenging or impossible. This situation forces many businesses to overthink their strategy.</p>



<p>Basically, from today on, they need to solicit or conduct business online and even reinvent themselves to stay relevant. We’re in the middle of Digital Transformation, and it just became non-optional. Either you accept and go with it or staying in the game will become more challenging than ever.</p>



<p>Because we can’t meet in person as we used to, much interaction happens online via websites, text, and video chat.<br>For companies, this means to step up their game in software development. There’s a lot of new tools and best practices to work through. How do you write clean code, integrate Code Reviews, Continuous Integration, and Continuous Delivery into your workflows?<br>But most importantly, do the internal processes support software development?</p>



<p>Let’s say a company’s strategy was to sell cars in their dealerships before and now wants to move the business online.<br>Building the software development competency in-house is one thing and a high priority. More importantly, however, it is to ensure that internal processes are set up to support a digital-first business model.<br>The process of how they sell a car now is changing completely. Before, there was a Salesperson that helped and walked you through everything. Now, there needs to be a configurator. You also need to keep track of how many cars you have in the lot and possibly deliver them to the customer’s home after the purchase.<br>How do you manage payments and signing paperwork? All of that needs to happen online and quickly.</p>



<p>To meet all these requirements, the software development team needs to focus on delivering software quickly and in high quality.<br>That includes Continuous Integration and Delivery, automated Testing, a well-defined deployment process, and short development cycles.</p>



<p>Since this will be a new system, not just from a technical standpoint but also from customer demand, it might not be easy to predict demand upfront.<br>This circumstance requires a dynamic hosting environment where you can quickly scale up and down as needed.</p>



<p>How quickly can you react to changing market conditions? How does your internal change process look?<br>If a customer requests a new feature or reports a bug, how long does it take you to react to it? Now, a bug fix is a different process than a feature request. Yet, both undergo some decision process beforehand before they get into software development.</p>



<p>If you look at your organization from a bird’s eye view, do you notice any bottlenecks? Ask yourself this: Where would your workflow break if you released unlimited work into the organization? Where’s the bottleneck? Is it software development? Is it QA? Ops? Product? This bottleneck will determine how much work you can get done in a unit of time.</p>



<p>So, it’s not just starting to hire software developers but also remodeling your entire organization to become digital.</p>



<p>What do you think? What are your experiences? Please share them with me in the comments section and follow me on <a href="https://linkedin.com/in/schulte-jan" data-type="URL" data-id="https://linkedin.com/in/schulte-jan">LinkedIn</a>.</p>


	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://21-lessons.com/2020/09/09/software-development-as-core-competency</link>
            <guid isPermaLink="false">hacker-news-small-sites-24453272</guid>
            <pubDate>Sat, 12 Sep 2020 15:41:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Rust to TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 149 (<a href="https://news.ycombinator.com/item?id=24453007">thread link</a>) | @valand
<br/>
September 12, 2020 | https://valand.dev/blog/post/from-rust-to-typescript | <a href="https://web.archive.org/web/*/https://valand.dev/blog/post/from-rust-to-typescript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Edits:</em></p>
<ul>
<li><em>HN discussion here: <a href="https://news.ycombinator.com/item?id=24453007#24454277">https://news.ycombinator.com/item?id=24453007#24454277</a>. Thank you HN folks for the corrections, kind responses, and insightful discussion.</em></li>
<li>*fixes in Getting Rid of Exceptions snippet 1.</li>
</ul>
<p>I was introduced to Rust in 2018 and has been enamored since. Rust is a system programming language, much like C++. Unlike C++ though, being relatively new, its language design is more modern and sophisticated. Writing with can feel more like writing TypeScript or Haskell. Not surprising since, despite being a language with a very minimum runtime and no GC, it derives many principles of functional programming such as immutability, type inference, higher-order functions, pattern-matching, etc. Over the course of tinkering things with Rust, I realized that writing Rust code makes me a better coder in other languages. This article will describe how my attempt to push the best in Rust's language design into TypeScript, my main language, without altering the language itself.</p>
<h2>Getting Rid of Exceptions</h2>
<p>The first thing that strikes me the first time I learnt Rust is that there are no straightforward to write exception-like code in Rust. For someone used to exceptions after using many languages like C++, Java, JavaScript and TypeScript, this seems like an incomplete language. But Rust's lack of straightforward exception-like is actually thought out in advance.</p>
<p>Exceptions feel neat the first time you understand it. A thrown exception skips code execution into the <code>catch</code> block. By doing that you can ignore the rest of code in the function. The rest of the code in the function represents positive case, which may seem irrelevant when an error happens. Here's a piece of code:</p>

    <div data-language="text/typescript">
      <pre><code><span>function</span><span> </span><span>foo</span><span>(</span><span>someNumber</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{
</span><span>  </span><span>if</span><span> </span><span>(</span><span>someNumber</span><span> </span><span>===</span><span> </span><span>0</span><span>)</span><span> </span><span>{
</span><span>    </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>"Error: foo"</span><span>);
</span><span>  </span><span>}
</span><span>  </span><span>return</span><span> </span><span>someNumber</span><span> </span><span>+</span><span> </span><span>1</span><span>;
}
</span><span>function</span><span> </span><span>bar</span><span>(</span><span>someNumber</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{
</span><span>  </span><span>return</span><span> </span><span>foo</span><span>(</span><span>someNumber</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>;
}
</span><span>function</span><span> </span><span>baz</span><span>(</span><span>someNumber</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{
</span><span>  </span><span>return</span><span> </span><span>bar</span><span>(</span><span>someNumber</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>;
}
</span><span>baz</span><span>(</span><span>0</span><span>);</span></code></pre>
    </div>
<p>When <code>baz</code> is called it will throw an uncaught exception. By reading the code you know that <code>foo</code> throws an Error. Debugging this snippet is a piece of cake, right?</p>
<p>Now let's see another snippet. In the snippet below you are importing a function that can throw exception.</p>

    <div data-language="text/typescript">
      <pre><code><span>import</span><span> </span><span>{</span><span> </span><span>callMe</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>"somePackage"</span><span>;

</span><span>try</span><span> </span><span>{
</span><span>  </span><span>
</span><span>  </span><span>callMe</span><span>();
}</span><span> </span><span>catch</span><span> </span><span>(</span><span>exception</span><span>)</span><span> </span><span>{
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>console</span><span>.</span><span>error</span><span>(</span><span>exception</span><span>.</span><span>message</span><span>);
}</span></code></pre>
    </div>
<p>Compared to the first snippet, this one is harder to debug. It seems so because 1.) You don't know that <code>callMe</code> will throw an error or not. 2.) If it throws an exception you will not know what is the type of the exception. The more modular your code is, the harder it is to debug exceptions.</p>
<p>Why is that? If you noticed, in the first snippet, you know which function is throwing what because the <code>throw</code> and the caller are in one file. You don't need to switch files or even scroll that far to see what's wrong. Furthermore, unlike in other language like java, TypeScript exceptions are not typed. Because of that, unlike return values, the compiler could not deduce if a function will throw an exception or not, and that's bad. Combined with the fact that an exception propagates up until they are caught. That means exception can be n-level deep. The deeper it is from, the harder it is to debug it.</p>
<p>If you're familiar with statically-typed language, deferring what's supposed to be done in compile-time to run-time is bad. It hands over problems from the compiler to the user.</p>
<p>There are best practices for writing <code>try/throw/catch</code>, such as developers should throw <code>Error</code> objects instead of nullish values. But pushing everyone to apply best practice is not enough. You cannot assert control toward what is being written in external dependencies. There are not many points introducing law when enforcers are nowhere to be found.</p>
<p>Only when you have dealt with complex codebase you will understand why <a href="https://wiki.c2.com/?DontUseExceptionsForFlowControl">we should not use exception for flow control</a>.</p>
<p>So how Rust does this? Rust encourages us to return errors instead of throwing it by providing a data type called <code>Result</code>. It is a tagged union which can either be <code>Ok(IdealData)</code> or <code>Err(NonIdealData)</code>. With this, a function can communicate the situation of a a call to its caller. For example:</p>

    <div data-language="rust">
      <pre><code><span>fn</span><span> </span><span>main</span><span> () {</span><span>
</span><span>    </span><span>let</span><span> </span><span>number</span><span>: </span><span>Result</span><span>&lt;</span><span>u8</span><span>, </span><span>_</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>"1"</span><span>.</span><span>parse</span><span>();</span><span>
</span><span>    </span><span>let</span><span> </span><span>non_number</span><span>: </span><span>Result</span><span>&lt;</span><span>u8</span><span>, </span><span>_</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>"a"</span><span>.</span><span>parse</span><span>();</span><span>
</span><span>    </span><span>println!</span><span>(</span><span>"{:?}"</span><span>, &amp;</span><span>number</span><span>);      </span><span>
</span><span>    </span><span>println!</span><span>(</span><span>"{:?}"</span><span>, &amp;</span><span>non_number</span><span>);  </span><span>
</span><span>}</span></code></pre>
    </div>
<p>The function <code>.parse()</code> converts a <code>string</code> into <code>u8</code>. There are scenarios where parsing a <code>string</code> into a <code>u8</code> can result in failure, one is if the parsed string is not a numeric string. Because <code>.parse()</code> has a negative case, it returns <code>Result&lt;u8, _&gt;</code>.</p>
<p>In Rust, <code>Err</code> does not jump like exceptions. Regardless the result is <code>Ok</code> or <code>Err</code>, the program will simply execute the next line. To handle the error the programmer has to check the return value is <code>Ok</code> or <code>Err</code>. Early return is encouraged instead of throw. Rust has the <code>?</code> syntax which help making early returns more concise to write and read.</p>
<p>To adopt this feature to TypeScript, these are the important things:</p>
<ol>
<li>Errors are returned instead of thrown</li>
<li>Errors types are known</li>
</ol>
<p>To simulate this behavior I am going to use tagged union too. I found this helpful library, <a href="https://github.com/gcanti/io-ts">fp-ts</a>. It covers a great deal of functional programming experience by leveraging TypeScript's type system, but I will only use a small portion of it.</p>
<p><code>fp-ts</code> has <code>Either&lt;Left, Right&gt;</code> data type. It is like Rust's <code>Result</code> but more flexible. <code>Either</code> is a tagged union value container. <code>Either</code> is <code>Left</code> or <code>Right</code>, usually <code>Right</code> represents the ideal case and <code>Left</code> represents the non-ideal case but both can be used with any types. Below is the type definition of <code>Either</code>.</p>

    <div data-language="text/typescript">
      <pre><code><span>type</span><span> </span><span>Either</span><span>&lt;</span><span>L</span><span>,</span><span> </span><span>R</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>Left</span><span>&lt;</span><span>L</span><span>&gt;</span><span> </span><span>|</span><span> </span><span>Right</span><span>&lt;</span><span>R</span><span>&gt;</span><span>;
</span><span>type</span><span> </span><span>Left</span><span>&lt;</span><span>L</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span> </span><span>_tag</span><span>:</span><span> </span><span>"left"</span><span>;</span><span> </span><span>left</span><span>:</span><span> </span><span>L</span><span> </span><span>};
</span><span>type</span><span> </span><span>Right</span><span>&lt;</span><span>R</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span> </span><span>_tag</span><span>:</span><span> </span><span>"right"</span><span>;</span><span> </span><span>right</span><span>:</span><span> </span><span>R</span><span> </span><span>};</span></code></pre>
    </div>
<p>What's cool about <code>Either</code> is that TypeScript actually supports deducing tagged union from its tag. For example inside this block <code>if (someEither._tag === "left") { }</code> TypeScript knows that <code>someEither</code> is a <code>Left</code>. If there's a <code>return</code> in that block, TypeScript will deduce that for the rest of the function block, <code>someEither</code> data type is <code>Right</code> and not <code>Either</code> anymore.</p>
<p>Let's make a called <code>tryCatch</code>. It is used to wrap a function into Either. <code>fp-ts</code> actually provides this function, but let's write it so that we know what's under the hood.</p>

    <div data-language="text/typescript">
      <pre><code><span>const</span><span> </span><span>tryCatch</span><span> </span><span>=</span><span> </span><span>&lt;</span><span>T</span><span>,</span><span> </span><span>E</span><span>&gt;</span><span>(</span><span>fn</span><span>:</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>T</span><span>,</span><span> </span><span>onError</span><span>:</span><span> </span><span>(</span><span>error</span><span>:</span><span> </span><span>unknown</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>E</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>try</span><span> </span><span>{
</span><span>    </span><span>
</span><span>    </span><span>return</span><span> </span><span>right</span><span>(</span><span>fn</span><span>());
</span><span>  </span><span>}</span><span> </span><span>catch</span><span> </span><span>(</span><span>error</span><span>)</span><span> </span><span>{
</span><span>    </span><span>
</span><span>    </span><span>return</span><span> </span><span>left</span><span>(</span><span>onError</span><span>(</span><span>error</span><span>));
</span><span>  </span><span>}
};</span></code></pre>
    </div>
<p>With our newly created <code>tryCatch</code>, creating a URL from string for example can be done like this.</p>

    <div data-language="text/typescript">
      <pre><code><span>export</span><span> </span><span>class</span><span> </span><span>InvalidURLError</span><span> </span><span>extends</span><span> </span><span>Error</span><span> </span><span>{}
</span><span>const</span><span> </span><span>makeURLFromString</span><span> </span><span>=</span><span> </span><span>(</span><span>str</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>=&gt;</span><span>
</span><span>  </span><span>tryCatch</span><span>(
</span><span>    </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>new</span><span> </span><span>URL</span><span>(</span><span>str</span><span>),
</span><span>    </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>new</span><span> </span><span>InvalidURLError</span><span>()
</span><span>  </span><span>);</span></code></pre>
    </div>
<p>Calling the function will look like this. The following snippet receives a string called <code>maybeUrl</code>. If <code>maybeUrl</code> is not a valid URL it returns an error. If the URL is not calling "example.com" it returns an error. Otherwise, it returns a promise from the <code>fetch</code> call.</p>

    <div data-language="text/typescript">
      <pre><code><span>export</span><span> </span><span>class</span><span> </span><span>NotExampleDotComError</span><span> </span><span>extends</span><span> </span><span>Error</span><span> </span><span>{}
</span><span>const</span><span> </span><span>callThisMaybeUrlIfItIncludesExampleDotCom</span><span> </span><span>=</span><span> </span><span>(
</span><span>  </span><span>maybeUrl</span><span>:</span><span> </span><span>string</span><span>
):</span><span> </span><span>Either</span><span>&lt;</span><span>InvalidURLError</span><span> </span><span>|</span><span> </span><span>NotExampleDotComError</span><span>,</span><span> </span><span>Promise</span><span>&lt;</span><span>any</span><span>&gt;&gt;</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>const</span><span> </span><span>urlResult</span><span> </span><span>=</span><span> </span><span>makeURLFromString</span><span>(</span><span>maybeUrl</span><span>);
</span><span>  </span><span>
</span><span>  </span><span>if</span><span> </span><span>(</span><span>isLeft</span><span>(</span><span>urlResult</span><span>))</span><span> </span><span>return</span><span> </span><span>urlResult</span><span>.</span><span>left</span><span>;

</span><span>  </span><span>const</span><span> </span><span>url</span><span> </span><span>=</span><span> </span><span>urlResult</span><span>.</span><span>right</span><span>;
</span><span>  </span><span>if</span><span> </span><span>(</span><span>url</span><span>.</span><span>origin</span><span> </span><span>!==</span><span> </span><span>"example.com"</span><span>)</span><span> </span><span>return</span><span> </span><span>left</span><span>(</span><span>new</span><span> </span><span>NotExampleDotComError</span><span>());

</span><span>  </span><span>return</span><span> </span><span>right</span><span>(</span><span>fetch</span><span>(</span><span>urlResult</span><span>));
};</span></code></pre>
    </div>
<p>There's a bit more line of codes here, but it is great that the TypeScript compiler now can deduce the error type and you have more control over the flow. You can even deduce if the variable <code>error</code> is <code>instanceof</code> <code>NotExampleDotComError</code> or <code>InvalidURLError</code> for cases like printing different errors.</p>
<h2>Safe TypeScript</h2>
<p>If you have played an early 2000s FPS games and tried to cheat, usually you will find the <code>noclip</code> command. It makes your avatar fly through walls and grounds. Sometimes, though, you take a shortcut and triggers the wrong script. When that happens, you can't finish your level and must restart to make it work again.</p>
<p>That's how I see Rust's <code>unsafe</code> and TypeScript's <code>any</code>.</p>
<p>These two features solve a similar problem. In Rust's case, it enables developers to temporarily unlock the power of handling raw pointer in case someone needs it. In TypeScript's case, someone might need to escape into the free-typed JavaScript world. And in both, it is the programmer's responsibility to make sure everything is fine before the program goes back to the safe system.</p>
<p>Unsafe to safe Rust is like <code>any</code> type to typed TypeScript. Unlike Rust, TypeScript's type only works until you compile it to JavaScript code. Rust has <a href="https://doc.rust-lang.org/beta/rust-by-example/conversion/try_from_try_into.html">TryInto/TryFrom</a> trait to convert raw data into a data type. But in TypeScript's case, if you inject a value that does not match TypeScript's type annotation, TypeScript can't do anything. This comes from TypeScript team's decision to make it only a thin layer on top of JavaScript. They thought it is best if for people to write TypeScript like JavaScript and the compilation result to look almost the same as the source code.</p>
<p>My approach for this would be securing all external hole of my application, which are:</p>
<ul>
<li>WebAPIs, which consist of DOM, deserializable user inputs, fetch API, etc.</li>
<li>External Dependencies which returns <code>any</code></li>
</ul>
<p>When I was trying this approach, I was lucky to find <a href="https://github.com/gcanti/io-ts">io-ts</a>, created by the same author as <code>fp-ts</code>. This library helps me create a runtime type checker, or "codec" as the library's author calls it. Instead of writing:</p>

    <div data-language="text/typescript">
      <pre><code><span>type</span><span> </span><span>User</span><span> </span><span>=</span><span> </span><span>{</span><span> </span><span>username</span><span>:</span><span> </span><span>string</span><span>;</span><span> </span><span>userId</span><span>:</span><span> </span><span>string</span><span> </span><span>};</span></code></pre>
    </div>
<p>I wrote the codec for User:</p>

    <div data-language="text/typescript">
      <pre><code><span>const</span><span> </span><span>UserCodec</span><span> </span><span>=</span><span> </span><span>ioTs</span><span>.</span><span>type</span><span>({</span><span> </span><span>username</span><span>:</span><span> </span><span>ioTs</span><span>.</span><span>string</span><span>,</span><span> </span><span>userId</span><span>:</span><span> </span><span>ioTs</span><span>.</span><span>string</span><span> </span><span>});
</span><span>type</span><span> </span><span>User</span><span> </span><span>=</span><span> </span><span>ioTs</span><span>.</span><span>TypeOf</span><span>&lt;</span><span>typeof</span><span> </span><span>UserCodec</span><span>&gt;</span><span>;</span></code></pre>
    </div>
<p>Again, this is longer, but this is very useful if we want to secure those holes.</p>

    <div data-language="text/typescript">
      <pre><code><span>export</span><span> </span><span>class</span><span> </span><span>InvalidTypeError</span><span> </span><span>extends</span><span> </span><span>Error</span><span> </span><span>{}
</span><span>export</span><span> </span><span>class</span><span> </span><span>Fet…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://valand.dev/blog/post/from-rust-to-typescript">https://valand.dev/blog/post/from-rust-to-typescript</a></em></p>]]>
            </description>
            <link>https://valand.dev/blog/post/from-rust-to-typescript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24453007</guid>
            <pubDate>Sat, 12 Sep 2020 15:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vim to Ed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24452916">thread link</a>) | @susam
<br/>
September 12, 2020 | http://blog.cretaria.com/posts/from-vim-to-ed.html | <a href="https://web.archive.org/web/*/http://blog.cretaria.com/posts/from-vim-to-ed.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                
                <p>Sync’ up! … without getting drained</p>
            </header>
	    <section>
<article>
<p><abbr>sep 11</abbr></p>
<h2>From Vim to Ed</h2>
<p>I switched from Vim to Ed twelve months ago,
and I wanted to report my findings on this
strange downstream adventure I took.</p>

<p>I’d been using Vim since about 1998, and I
hardly got close to mastering it after all those
years. In fact, that was one of the reasons I
thought of trying something like Ed: I was tired
of turning a corner only to find a zillion other
great features Vim offers.</p>

<p>I wanted to use an editor that didn’t have
features that were constantly distracting me
from what’s important: writing code.</p>

<h3>The goods</h3>


<p>Ed had one of the most fantastically steep learning
curves in all my many years of nerding. This ol’
editor was so weird in so many ways, I almost
lost heart right off the bat.</p>

<p>A good deal of the Ed ideas are forgotten
in time.  Nobody uses a line-based editor,
so this was one strange playing field to get
accustomed to.</p>

<p>However, once the learning curve was overcome,
the terseness of what I could do became an asset.</p>

<p>In Vim, there’s a million different ways to
get your cursor to zip all around. One of my
favorites was <code>w</code> where on the line in question,
all in normal mode, I could dart over to my
change in word-step motion.</p>

<p>In Ed, the line in question is right there in
front of you, and all you have is ‘regex’ as
your weapon to swap one thing for another.</p>

<p>You’d be surprised how good one can get via
this sole usage pattern. It’s not all that bad,
and thankfully, some distributions of Ed have
nice little shortcuts to make this all the
less pedantic.</p>

<p>With only a few agilities, Ed limits your usage
to x, y, or z. The result?  You get so darn good
at those.</p>

<p>Another powerful plus for Ed, is its undo/redo
limitation.</p>

<p>Usually, one would think, that after some
hacking, one would want to undo changes that
happened twenty edits ago. In Vim, you’d just
hold down <code>u</code> until it gets to that state. In Ed,
the buffer is limited to one undo. Incredibly,
this limitation has never ruined my day. Because
of my for-knowledge that Ed can’t undo twenty
edits ago, my approach on edits has been
‘Edified,’ and my behavior is in sync with this
one undo world.</p>

<p>I don’t pop open Vim ever, except to run a spell
check on something that isn’t code (like this
blog post, for example). Fascinating to me:
one of the side effects of Ed is my spelling
got a lot better. I’m more careful about what
I type, as the pain to undo or edit things is
quite real. Go figure!</p>

<h3>The bads</h3>


<p>Vim offers so much, it’s hard to
compare Ed to something this feature-rich. So,
I won’t.</p>

<p>Rather, I’ll just jot down some of my Ed-related
gripes.</p>

<p>First, one can scroll forward a page via <code>z</code>
in Ed, but one cannot do the reciprocal. I
was so bummed out on day one regarding this,
and I’m still bummed out 365 days later. What I
find shocking, is that <abbr>UNIX</abbr> <code>mail</code> has <code>z</code> to go
forward a page in header listings, and also <code>-z</code>
to go back a page. If only this was baked into
Ed from the start. My workaround is terrible,
and funny as it may sound, when I’m fatigued,
I sometimes try <code>-z</code> to see if it magically
started working.</p>

<p>Perhaps more of a gripe to the authors of <code>sed</code>
rather than Ed, but I wish there was a 100%
compatibility with ‘regex’ substitution patterns
that are valid in Ed, but in <code>sed</code>. This is
not the case, and it’s a shame. In general,
one has to forget about Ed’s awesome shorthand
tricks to get <code>sed</code> to work. It would be great
if the bounty of Ed vocabulary I’ve built up
just simply worked one-for-one in <code>sed</code>.</p>

<h3>More Ed for me</h3>


<p>One year dedicated to Ed is probably enough time
to arrive at a plateau of know-how where the
limitations will remain as such, and the pains
can’t be overcome with any more learning. That
said, I think I’ve arrived at a comfortable spot
with Ed, and I’m going to stick it out with it!</p><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" viewBox="200 0 400 800" width="400" height="800"><rect width="400" height="800" fill="#b33a3a"></rect><polygon points="299.5 150 254.5 247 351.5 247 "></polygon><path d="m321.9 548.9l-243.8 0"></path><path d="m303 247.1l0 243.8"></path><polygon points="94.5 150 49.5 247 146.5 247 "></polygon><path d="m98 247.1l0 243.8"></path><text font-family="Helvetica, Arial, sans-serif" font-size="60" y="112" x="10" style="fill-opacity:null">THIS END UP</text><a xlink:href="//cretaria.com"><text id="link-cretaria" font-family="Helvetica, Arial, sans-serif" font-size="50" y="680" x="10" fill-opacity="null">What’s Cretaria?</text></a><path d="m175 700l200 0" style="fill-opacity:null;fill:none;stroke-linejoin:null;stroke-opacity:null;stroke-width:4;stroke:#000"></path></svg></p></article>
            </section>
            
        </div></div>]]>
            </description>
            <link>http://blog.cretaria.com/posts/from-vim-to-ed.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24452916</guid>
            <pubDate>Sat, 12 Sep 2020 14:53:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GAlculator – Geometric Algebra Pocket Calculator]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24452509">thread link</a>) | @alex_hirner
<br/>
September 12, 2020 | https://enkimute.github.io/ganja.js/examples/galculator.html | <a href="https://web.archive.org/web/*/https://enkimute.github.io/ganja.js/examples/galculator.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h4>The Galculator - powered by Ganja.js</h4><p>
    The Galculator can be forked on <a href="https://github.com/enkimute/ganja.js">github</a></p><p>
    It works great on your phone - full screen if you add it to your homescreen.</p><h4>Example in <span>C</span> :</h4>
    <p>Calculate (3+2i)*(1+4i)</p>
    

    <h4>Example in <span>D</span></h4><p>
    Calculate the value of the function and first derivative at x=3</p><p>
    
    f(x)=x<sup>3</sup>-2x<sup>2</sup>+3
    </p>

    <h4>Example in spacetime <span>M</span></h4><p>
    You see two simultaneous lightning strikes in 10 microseconds, one where you are, one 20 km in the x-direction.<br>
    Are these events simultaneous for a spaceship flying at 0.5c in the x-direction? (given : atanh(0.5)=0.5493)
    </p>
    
    <h4>Example in PGA 2D (2,0,1)</h4>
    <p>Solve the system of equations :
       </p><li>x+y-0.5=0
       </li><li>2x-1y=0
    
    
    
  </li></div></div>]]>
            </description>
            <link>https://enkimute.github.io/ganja.js/examples/galculator.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24452509</guid>
            <pubDate>Sat, 12 Sep 2020 14:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Benchmark Analysis of Egress Filtering on Linux]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24452458">thread link</a>) | @simonpure
<br/>
September 12, 2020 | https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/ | <a href="https://web.archive.org/web/*/https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Traffic filtering is a common technique used to protect networks and hosts from malicious activity. The filtering can be done in the incoming and outgoing flows, better known as ingress and egress filtering. There are many examples of use cases for ingress filtering: mitigating DDoS attacks, avoiding SPAM, blocking access to services for specific geographic regions and so on.</p>
<p>One common application of egress filtering is to prevent applications and users from reaching remote hosts.
These kinds of filters are usually based on a large deny-list of IP address ranges, like <a href="https://www.icann.org/news/blog/reputation-block-lists-protecting-users-everywhere">Reputation Block Lists</a>. The technology used to perform this task has to be able to handle a high number of restricted hosts, up to millions in some cases.</p>
<p>Our friends at SAP asked us to perform a benchmark of the common Linux technologies available for this task. This blog post presents the methodology and results from benchmarking some of the Linux filtering technologies: eBPF, IP sets and iptables.</p>
<p><em>Update 2020-09-14:</em> we have received some great feedback and suggestions about other options to try, including BPF JIT optimization (that we left inadvertently disabled) and inline BPF map lookup. We will take a look at this and update this post as soon as possible - expected at the end of the month.</p>
<h2 id="goals">Goals</h2>
<p>We had the following goals going into this study:</p>
<ul>
<li>Provide a reproducible benchmark framework that anyone else can download and use.</li>
<li>Evaluate the different mechanisms in the Linux networking stack to filter out a large amount of IP addresses and assess their scalability when the amount of IP ranges to block reaches 1 million.</li>
</ul>
<h2 id="scenario">Scenario</h2>
<p>We aim to understand the cost of performing egress filtering based on the destination IP in a large set of IP ranges.</p>
<p>The scenario we consider is composed of a client and a server computer that communicate through an IP network. The egress filtering is performed on the client machine and there is no filtering performed on the server side.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/scenario.svg">
</figure>
<h2 id="metrics">Metrics</h2>
<p>An egress filter has to perform a matching operation to understand if a packet can continue its way or has to be dropped. This operation could be costly if the number of blocked IPs is high. This kind of filter impacts the throughput of IP connections, it consumes extra CPU and increases the latency. We decided to take into consideration these metrics under the following conditions.</p>
<ul>
<li>Throughput</li>
<li>CPU usage</li>
<li>Latency</li>
</ul>
<h2 id="linux-filtering-mechanisms">Linux Filtering Mechanisms</h2>
<p>The Linux kernel provides different mechanisms to filter network packets. In this benchmark we considered the most known ones. iptables is the historical and probably more known filtering utility in Linux. IP sets support high speed matching for sets of specific types, like IP ranges for instance. eBPF is very flexible and customizable. The following section provides more details of how we used those mechanisms in our benchmark.</p>
<h3 id="ebpf">eBPF</h3>
<p>eBPF is a virtual machine built in the Linux kernel. In the networking scope, it allows the user to load programs that are executed each time a packet arrives or is sent out of a networking interface. Those eBPF programs can modify, redirect or drop the packets.</p>
<p>There are different types of networking eBPF programs, CGROUP_SKB for per-cgroup filtering, SCHED_CLS and SCHED_ACT for filtering at the traffic control level, and XDP for filtering at the network interface level.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/ebpf.svg">
</figure>
<p>In our scenario, we want to apply the same filtering regardless of the cgroup of the application generating the traffic. The traffic coming from non-local applications or forwarded traffic should be filtered as well. This makes filtering at the socket level unfit for our scenario. XDP programs can only be attached to the ingress<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> path, removing it from consideration in our tests also. By process of elimination, we only consider eBPF programs attached to the traffic control layer.</p>
<p>Given that we want to keep the tests as simple as possible we decided to implement <a href="https://github.com/kinvolk/egress-filtering-benchmark/blob/master/pkg/filters/bpf/datapath/bpf.c">our own</a>filtering program in eBPF that will be attached to the traffic control layer with a clsact qdisc. The clsact qdisc was introduced in Linux 4.5, it’s a pseudo qdisc that allows to attach eBPF programs in ingress and egress using the <a href="https://qmonnet.github.io/whirl-offload/2020/04/11/tc-bpf-direct-action/">direct-action</a> mode.</p>
<p>Our filter implementation uses an <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=b95a5c4db09bc7c253636cb84dc9b12c577fd5a0">LPM map</a> to save the list of IP addresses to block. eBPF implements the <a href="https://en.wikipedia.org/wiki/Longest_prefix_match">LPM</a> algorithm with a <a href="https://en.wikipedia.org/wiki/Trie">digital tree</a>.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/ebpflookup.svg">
</figure>
<h3 id="iptables">iptables</h3>
<p>We tested the standard iptables implementation by adding DROP rules to the OUTPUT chain in the filter table. The rules we used have the following format</p>
<p><code>-A OUTPUT -d 192.168.0.0/16 -o eth0 -m comment --comment "benchmark" -j DROP</code></p>
<p>While implementing this filter we found that appending each rule independently was too slow and we had to use the <code>iptables-restore</code> utility to do it.</p>
<p>iptables uses a linear search algorithm for rule matching.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/iptableslookup.svg">
</figure>
<h3 id="ip-sets">IP Sets</h3>
<p>We performed the testing also with the <a href="https://ipset.netfilter.org/">IP sets</a> framework. We used an IP set of type <a href="https://ipset.netfilter.org/ipset.man.html#lbAZ"><code>hash:net</code></a> and linked it to iptables by using the following rule:</p>
<p><code>-A OUTPUT -o eth0 -m set --match-set myset dst -m comment --comment benchmark -j DROP</code>.</p>
<p>The IP address to check is hashed and the result of the hash is used as the index in a hash table. Each bucket of the hash table contains an array of networks for that hash. When an IP address is checked against an IP set of type “hash:net”, it is not known what network size will match. The IP set implementation hashes the IP address for all possible network sizes. For instance, if the IP to match is 1.2.3.4, it looks for 1.2.3.4/32, for 1.2.3.4/31 and so on until all the 32 possible network sizes have been tested.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/ipsetslookup.svg">
</figure>
<h2 id="benchmark-set-up">Benchmark Set-up</h2>
<p>We used <code>iperf3</code> to measure the performance of TCP, UDP and the CPU usage. The standard <code>ping</code> utility was used to measure the latency. We tested with 10, 100, 1k, 10k, 100k and 1M rules and each test was run 5 times to get statistical robustness.</p>
<p>We used two bare metal servers - running on <a href="https://www.packet.com/">Packet</a> - as client and server machines. The specifications of such servers are:</p>
<div><pre><code data-lang="fallback">c2.medium.x86
1x AMD EPYC 7401P 24-Core Processor @ 2.0GHz
2x 120GB SSD
2x 480GB SSD
64GB RAM
2x 10Gbps
</code></pre></div><p>The exact versions of the tools we used are:</p>
<ul>
<li><a href="https://www.flatcar-linux.org/">Flatcar Container Linux</a> by Kinvolk alpha (<a href="https://www.flatcar-linux.org/releases/#release-2605.0.0">2605.0.0</a>)</li>
<li>Linux kernel 5.4.59</li>
<li>iperf 3.0.7 (in a Docker container with the host network)</li>
<li>iptables v1.6.2</li>
<li>ipset v6.20.1, protocol version: 6</li>
</ul>
<h2 id="reproducibility">Reproducibility</h2>
<p><a href="https://github.com/kinvolk/k8s-egress-filtering-benchmark">https://github.com/kinvolk/egress-filtering-benchmark</a> has all the tools and instructions to reproduce these tests.</p>
<h2 id="results">Results</h2>
<h3 id="test-1---tcp-throughput">Test #1 - TCP Throughput</h3>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/throughput-tcp-linerate.svg">
</figure>
<p>The throughput graph shows that the test is reaching line rate, 10Gbps because we are using a single connection hence only one of the interfaces on the bonding is used in most of the cases. Only iptables with more than 10k rules is not able to handle that performance. From this test we can conclude that iptables doesn’t scale well after 100k, but unfortunately we cannot conclude anything from other tests as network performance is the bottleneck.</p>
<p>In order to stress the CPU more, we performed another test using UDP.</p>
<h3 id="test-2---udp-throughput">Test #2 - UDP Throughput</h3>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/throughput-udp.svg">
</figure>
<p>The goal of this test is to saturate the CPU. We used UDP packets and the <code> -b 10G</code> parameter to try to reach line rate. The graph shows that none of the cases reaches the 10Gbps line rate, it’s good for this test because it means the network is not the bottleneck anymore.</p>
<p>We can see that iptables does not scale well beyond 1k rules and that IP sets are a bit faster than eBPF on the clsact qdisc with a high number of rules.</p>
<h3 id="test-3---cpu-usage">Test #3 - CPU usage</h3>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/cpu.svg">
</figure>
<p>We used <code>iperf</code> with a target bandwidth of 1Gbps (<code>-b 1G</code>) to avoid saturating the CPU and be able to compare the CPU usage with the different filters. We take the CPU usage reported by <code>iperf</code> that includes all the applications running on the host. From the above graph we can see that the CPU usage with iptables increases when using more than 1k rules. The CPU usage with eBPF and IP sets filters stays almost constant showing a bit higher usage in the eBPF case.</p>
<h3 id="test-4---latency">Test #4 - Latency</h3>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/latency.svg">
</figure>
<p>We used the standard Linux ping utility to measure the latency with the <code>-i 0.001</code> and <code>-c 1000</code> parameters, sending 1000 pings at a 1 millisecond interval. The above graph shows that the latency is not affected by the number of rules in the eBPF and IP sets filters, it’s ~27µs in those cases. On the other hand, it increases linearly with the number of rules for the iptables case.</p>
<h3 id="test-5---setup-time">Test #5 - Setup Time</h3>
<p>This test aims to measure the time it takes to install the filtering rules on the system. It doesn’t take into consideration fixed times like loading the eBPF program, creating the IP sets but instead focuses on measuring the time it takes to update the rules themselves and how it changes with the number of rules.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/setup.svg">
</figure>
<p>The above graph shows that the time required to set up the rules in all the filters increases linearly with the number of rules.</p>
<p>With 100.000 IPs, the setup time is still less than one second. For 1 million IPs, the setup time is less than 10 seconds. This shows that in practice, all 3 methods have an acceptable setup time.</p>
<p>The setup time is very dependent on the benchmark implementation rather than being inherent to the filtering method. Each filtering method could be optimised in the benchmark code if it were deemed necessary.</p>
<ul>
<li>For the bpf filter: the benchmark performs one bpf() system call for every IP. From Linux 5.6, it is possible to <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=aa2e93b8e58e18442edfb2427446732415bc215e">perform several updates in a eBPF map with a single bpf() call</a>.</li>
<li>For the iptables and IP sets filters, the benchmark executes external commands and feeds each IP range individually over a pipe. We could avoid that by communicating the list to the kernel using the Netlink protocol directly. There are <a href="https://github.com/vishvananda/netlink/search?q=ipset&amp;type=Issues">some attempts</a> to implement IP Sets support in Golang with the vishvananda/netlink library.</li>
</ul>
<p>For this reason, the reader should be cautious before comparing the setup time of one filter to another. This should not be interpreted as one method being better than another but rather to show expected setup performance and that setup time is unlikely to be a problem for any filtering method.</p>
<h3 id="test-6---throughput-with-too-many-rules">Test #6 - Throughput with …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/">https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/</a></em></p>]]>
            </description>
            <link>https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24452458</guid>
            <pubDate>Sat, 12 Sep 2020 14:00:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Review of Language Learning Tactics]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24452418">thread link</a>) | @laybak
<br/>
September 12, 2020 | https://knowledgeartist.org/article/language-learning-tips | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/article/language-learning-tips">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>In my journey learning 9 languages over the years, I tried all sorts of different methods to make my learning more effective. Here are some of the notable approaches, along with why they work (or don't work). It </span> <a href="https://knowledgeartist.org/article/how-long-does-it-take-to-learn-a-language" target="_blank"><span>will be a long learning journey</span></a> <span>, I hope this article will make yours more fun and effective. </span></p> <p><span>Let's jump right in.</span></p>  <p><h3><span>Moving to the Target Country</span></h3></p> <p><span>In my experience learning a language, immersion is powerful. Being in a country where your target language is spoken is ideal. Your learning becomes always on, even if you don't realize it. </span></p> <p><span>I moved to Tokyo and worked at an all-Japanese company a few years ago. At the beginning I knew very little Japanese. But with this sink-or-swim approach and the daily immersion, I became comfortable with basic conversations within three months.</span></p> <p><span>Now, it is not always possible to just pack up and move to a different place. Read on for other tips I tested from my own experience. </span></p>  <p><h3><span>Language Exchange Meetups</span></h3></p> <p><span>You can only get so good at speaking a language without talking to native speakers. Language exchange groups are a great way to get that conversational practice. In a typical event, you would get paired up/grouped with native speakers of your target language, who are themselves looking to level up on your native tongue. </span></p> <p><span>For half of the time, the group would converse in one language, and then switch to the other language half-way. If you live in a major city, there are usually quite a few of these groups for the common languages. </span> <a href="https://www.meetup.com/" target="_blank"><span>Meetup</span></a> <span> is a great place to look for these events. This is an effective way to practice in your home city, or when you are already in your target country. </span></p>  <p><h3><span>Online Language Exchange</span></h3></p> <p><span>If you are unable to attend in-person meetups, online language exchange can be effective as well. Though in-person conversations would always feel more organic, you still get the instant feedback and practice with online language exchange calls. </span></p> <p><span>I have made a few friends along the way, while practicing my German, French, and Japanese. I previously had a pleasant experience using </span> <a href="https://www.italki.com/" target="_blank"><span>iTalki</span></a> <span>, where I could easily find language partners and schedule 1-1 Skype calls with them. It was entirely free. But at the time of writing, it appears they may have removed the free partner option.</span></p>  <p><h3><span>Learning Entire Phrases</span></h3></p> <p><span>I found it effective to memorize entire sentences, and pull them out when I need to. There are several benefits to this. When you are communicating in realtime, having phrases already memorized can reduce your stumbling. It can make you appear fluent and keep the conversation flowing. This also makes you feel more comfortable, knowing what to say or how to respond in a given situation.</span></p> <p><span>These familiar phrases serve as important anchors as well, for learning about the structure of the language, and for easily swapping out components to adapt to new situations. For example, after memorizing the phrase "After a few months of travelling, I am happy to finally be able to work with everyone", you can substitute some of the words and use it in a new scenario.</span></p> <p><span>Phrase books can be somewhat useful for this purpose, though it can sound scripted and unnatural. What feels more natural is writing down and remembering the response of native speaker in a real-life situation or in a movie.</span></p>  <p><h3><span>Movies/Shows in Your Target Language</span></h3></p> <p><span>Movies and TV shows are a great source of natural-sounding phrases (though overly dramatic sometimes) to add to your knowledge bank. This is great for a number of reasons: </span></p> <p><li><span>You can usually figure out what the movie is about (especially if you first watch it in your native language).</span></li></p> <p><li><span>It is enjoyable, which means you will stick with it</span></li></p> <p><li><span>You get to learn about the culture behind your target language</span> <strong> </strong> <span>as well.</span></li></p> <p><span>And if you are watching it on TV, I find that even the commercials in your target language are interesting. Not only is it good practice, you get a better sense of what kinds of products local people buy and the messaging that appeals to them. With the growing selection of international shows/movies on Netflix, along with audio and/or subtitles, this is a fun and easy way to make progress.</span></p>  <p><h3><span>Interviews with Subtitles and Translations</span></h3></p> <p><span>In addition to movies/shows, interviews are the perfect content for getting exposure to natural conversations, where people use casual everyday language. </span> <a href="https://www.youtube.com/user/magauchsein" target="_blank"><span>Easy Languages</span></a> <span> on YouTube is hands down one of my favourite language resources. They interview people on the streets on a different topic each episode, and provide subtitles in the original language + English. Over the years, they have built up an amazing collection of content in many (!) languages.</span></p> <p><span>Here's a taste of their content for German learners: </span></p> <div><p><iframe src="https://www.youtube.com/embed/hLoatpfE7VM?title=0&amp;byline=0&amp;portrait=0" frameborder="0"></iframe></p></div>  <p><h3><span>Passive Background Looping</span></h3></p> <p><span>This is one of the most effective hacks I developed to maximize my time spent learning a language. As I work, I would put on a familiar track of native speakers talking (much of the time it would be Easy Languages) in the ground. This way, I can get a lot of listening practice without spending much time. By picking content that you are already familiar with, you already know what is being talked about. And the looping gets you more "reps" for each phrase. It also helps you memorize entire phrases that you can use with ease later.</span></p>  <p><h3><span>Podcasts </span></h3></p> <p><span>This one can be tricky. I have tried quite a few podcasts and many podcast formats aren't that conducive to learning a foreign language. Either I don't understand what's going on, or there is too much repeating over the often dry content. But for Japanese learners, I highly recommend </span> <a href="https://bilingualnews.libsyn.com/" target="_blank"><span>Bilingual News</span></a> <span> hosted by Michael and Mami. It features the hosts talking about interesting topics in the news, with Michael speaking only English and Mami speaking only Japanese. The conversation always moves forward and remains engaging, and you can usually easily fill in the words you missed from the context. </span></p>  <p><h3><span>Ask a Native Speaker "How do I say X?" Wherever Possible</span></h3></p> <p><span>If you have friends (or better yet, roommates) from other countries, you can definitely get some practice in as you hang out. When you are trying to say something, why not learn to say it in your target language too? Anytime is learning time! You'll remember it much better than other methods because the learning takes place in real-life expeirences. I used to worry this may come off as annoying, but in my experience most people are happy to help, and appreciate the ernest effort you make to understand their language/culture. </span></p>  <p><h3><span>Changing Your Phone's Language</span></h3></p> <p><span>One easy way to squeeze out an extra bit of language immersion is to simply change your mobile phone to your target language. Doing so should automatically update the language in all your apps as well. Since you likely already know how to navigate through most apps anyway, in most cases you can guess the meaning of new words that you don't yet know. With this, even Facebook notifications become good practice. </span></p>  <p><h3><span>Taking classes</span></h3></p> <p><span>I have never been a fan of learning a language in a classroom, having taken Russian, French and Mandarin classs. This one is a bit of a hit or miss. The classroom environment has always felt a bit too artificial for this purpose. Typically, there is also limited practice, limited individual attention (and hence </span> <em>feedback</em> <span>). And the separation between the classroom learning context and the real-life situations makes it hard to apply the knowledge.</span></p> <p><span>That said, there are some amazing teachers out there who excel at teaching and building curriculum. And for some people, the structure of learning in a group guided by a competent instructor is just what they need. For Chinese learners, </span> <a href="https://www.excelmandarin.com/" target="_blank"><span>Excel Mandarin</span></a> <span> is an example of educators who have created an effective learning system for their students. Though not from my personal experience, I have heard nothing but positive reviews about these folks. </span></p>  <p><h3><span>Duolingo</span></h3></p> <p><span>There was a time when I would have a long-running practice streak on the popular free app </span> <a href="https://www.duolingo.com/" target="_blank"><span>Duolingo</span></a> <span>. I would use the app daily, and almost completed the curriculum for Brazilian Portuguese, Spanish, and German. I felt great. I felt engaged. I felt like I was making progress. But that's the dangerous part about apps like these that try to "gamify" the language learning process. it makes you feel productive, even if it may not reflect reality. </span></p> <p><span>It is all too easy to slip into auto-pilot mode, where you just rush to the finish line of each exercise. This is similar to how one would "speed read" a book in an hour and retain nothing from it. The app also trains you to get used to the machine-generated bad pronunciation, which is counter-productive for your listening skills. On the bright side, Duolingo can be helpful for exposure to new words, and adding some structure to your learning, especially if you are not following a curriculum or textbook.</span></p>  <p><h3><span>Reading Textbooks</span></h3></p> <p><span>Reading a textbook for the purpose of language learning is perhaps the best way to learn the formal structure of a language. But it is not effective for conversational purposes. Grammar rules are clean, but conversational languages are messy. Similar to the discussion above about taking classes, textbooks tend to give a similar passive understanding of rules, as opposed to the ability to apply that knowledge in real-time. </span></p>  <p><span>The best approach is the one you actually take and follow through with. One that fits your learning objectives and learning style. The more you can align your learning with your intrinsic motivation, the more likely it is that it will stick. </span></p>         


          
            
            <p><em>Each week, I send out a newsletter where I share my learnings, new ways to see things, and new ways to feel.</em></p>
            <p><em>Enter your email below to subscribe.</em></p>

            
          
        </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/article/language-learning-tips</link>
            <guid isPermaLink="false">hacker-news-small-sites-24452418</guid>
            <pubDate>Sat, 12 Sep 2020 13:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why do so many people want us back in the office?]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 584 (<a href="https://news.ycombinator.com/item?id=24452280">thread link</a>) | @ingve
<br/>
September 12, 2020 | https://paulitaylor.com/2020/09/12/why-do-so-many-people-want-us-back-in-the-office/ | <a href="https://web.archive.org/web/*/https://paulitaylor.com/2020/09/12/why-do-so-many-people-want-us-back-in-the-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>After the sudden and miraculous shift to remote work in March – the office fightback has well and truly begun.</p>



<p>Four months ago I wrote that – surprisingly- there was no fightback from technophobe hold-outs barricading themselves into their offices. They simply packed up their laptop and went home with the rest of us. <a rel="noreferrer noopener" href="https://paulitaylor.com/2020/04/06/did-a-virus-just-bring-about-the-end-of-the-office/" target="_blank">How </a><a href="https://paulitaylor.com/2020/04/06/did-a-virus-just-bring-about-the-end-of-the-office/">premature</a><a rel="noreferrer noopener" href="https://paulitaylor.com/2020/04/06/did-a-virus-just-bring-about-the-end-of-the-office/" target="_blank"> I was</a>. </p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>2019: millenials are wasting all their money on buying sandwiches </p><p>2020: THE ECONOMY WILL COLLAPSE IF YOU DON'T BUY MORE SANDWICHES</p></div>— Sam Grinsell (@samgrinsell) <a href="https://twitter.com/samgrinsell/status/1299288101743886336?ref_src=twsrc%5Etfw">August 28, 2020</a></blockquote></div>
</div></figure>



<p>If you thought that 2020 couldn’t get any crazier – it seems some people really are suggesting that businesses should alter their workplace strategies in order to save…sandwich shops.</p>



<p>OK, I’m exaggerating for effect. But there really has been a hand brake applied to the move to remote/hybrid working , or my favoured term,<em><a rel="noreferrer noopener" href="https://medium.com/work-futures/the-future-is-minimum-office-not-zero-office-821928abdba2" target="_blank"> minimum office</a></em> in recent weeks. </p>



<p>An <a rel="noreferrer noopener" href="https://www.telegraph.co.uk/news/2020/08/27/go-back-work-risk-losing-job-major-drive-launched-get-people/" target="_blank">article in the Daily Telegraph</a>&nbsp;suggested&nbsp;that employees who continue to work at home will be more vulnerable to redundancy, with bosses finding it far easier get rid of people they don’t physically see.</p>



<p><a rel="noreferrer noopener" href="https://twitter.com/KirstieMAllsopp/status/1290987043829489666?s=20" target="_blank">Kirstie Allsopp</a> led the anti-remote work charge on Twitter, suggesting that if your job can be done from home, it can be done from anywhere in the world. Who would have thought that a couple of months of working in shorts and a T-Shirt has made us more susceptible to being replaced by less expensive folk in India, Myanmar and China? </p>



<p>A debate that is framed around saving sandwich shops and an already dying high street isn’t helpful or progressive. Cynically I might suggest the real subtext here is about propping up commercial property investment portfolios. Realistically though, we won’t see anything like a return to the same number of offices, and although few will shed tears for commercial real estate investors many small businesses will suffer a big hit and go out of business unless they can pivot very rapidly.</p>



<p>Clearly there are two groups emerging, those who are desperate for the pandemic to be viewed as a temporary event before everything returns to ‘normal’ and those embracing the true long term disruption that is occurring.</p>



<p>Thank heavens then for more balanced thinkers like Tom Cheesewright who has an uncanny ability to pan back and take the long view. <a rel="noreferrer noopener" href="https://tomcheesewright.com/were-still-human/" target="_blank">Writing on his website</a> about the current over-confidence in the possibilities for remote working he says:</p>



<p><em>“There is something different about being there, in person, with all of your senses engaged. It’s what I called a few years ago, ‘<a href="https://tomcheesewright.com/the-unbeatable-bandwidth-of-being-there/">the unbeatable bandwidth of being there</a>‘. What gets transmitted and received through the screen and headset, mediated by a million miles of fibre optic cable, is not the full experience of meeting. Nor does it allow for all the things that happen around those meetings. <a href="https://tomcheesewright.com/aftershocks-and-opportunities/">I’ve talked at length about the need for peer support, the subtler parts of staff training, and the mutual inspiration that happens when you’re sharing a physical space</a>.”</em></p>



<p>I’m a remote working, or at least a minimum office, enthusiast. I’ve written on this site for years about the worst aspects of office life and <a rel="noreferrer noopener" href="https://paulitaylor.com/2014/07/31/why-the-death-of-the-office-cant-come-too-soon/" target="_blank">the most popular post on here applauds its impending doom</a>.  Six years on though I’d admit it’s a deeply flawed argument. The idea that constant interruptions and back to back meetings were a symptom of being in a corporate building has been well and truly busted by…Microsoft Teams. </p>



<p>In truth the problem with work is not the tools or the physical location, but <a href="https://paulitaylor.com/2020/01/03/ending-our-obsession-with-leadership/">the obsession with leadership</a> , an undue focus on work about work, an overbearing hierarchy and the lack of true digitisation of the enterprise. Deeper, more complex problems.  </p>



<p>It’s ironic that it has taken a pandemic to reveal what was good about the office. “The things that happen between meetings” that Tom writes about reveal our innate desire for human contact – the need to get <em>our senses fully engaged</em>. Wasteful? Quite often. But we dismiss this at our peril. It may seem logical that workplace chatter stifles productivity, but studies show the opposite to be true. </p>



<p>A narrow focus on efficiency in the workplace and a flawed view of what makes people productive is similarly regressive and likely to drag people back to the old normal. As Stowe Boyd writes the backlash against minimum office is in full flow , as detailed in <a href="https://www.wsj.com/articles/companies-start-to-think-remote-work-isnt-so-great-after-all-11595603397?mod=trending_now_pos1">Companies Start to Think Remote Work Isn’t So Great After All</a>, as executives want to get people back in the office:</p>



<p>“<em>An increasing number of executives now say that remote work, while necessary for safety much of this year, is not their preferred long-term solution once the coronavirus crisis passes.</em></p>



<p><em>“There’s sort of an emerging sense behind the scenes of executives saying, ‘This is not going to be sustainable,’” said Laszlo Bock, chief executive of human-resources startup Humu and the former HR chief at Google. No CEO should be surprised that the early productivity gains companies witnessed as remote work took hold have peaked and leveled off, he adds, because workers left offices in March armed with laptops and a sense of doom</em>.”</p>



<p>Perhaps it’s simply we haven’t yet matched our colleagues roles, and their specific work preferences, within our existing organisational design never mind considered a future state. Working from home (managed and supported appropriately) <strong>can</strong> be more productive than going into the office.</p>



<p><a rel="noreferrer noopener" href="https://email.mg2.substack.com/c/eJwlUMuOwyAM_JpySwQkNHDgsJf9jYiA27BNIDKmVf5-aStZHsv2-DHeEdwznvbIhVgtgHMMdtRSX1nDILTSLJb5hgC7i5slrMCOumzRO4o5vdu1Mdqw1YZJTmJYQC9SaR8kv3IlBmcmM_qgRsXeS2ZXQ4TkwcIT8MwJ2GZXoqNchp-L_G22LthnvLdIcskbcN0cQgGHfu0eKb82CHfoXhkfgKVzCN2emzswh-opPqG7Yd67Ne_Aon2P4YYPQiiteC_6M_0JzqezJnMZ-X6XfalLIecfvc87Q3u4up0kWnGhmAgwAX1K7fW54V5TpHOG5JZ2ylcV-or4eZLOA2yCV9mAGvubbFIZOWmuWNsWctMzfShljTf6B3tch00" target="_blank">A HBR study published in August</a>&nbsp;contrasted surveys of knowledge workers from 2013 and 2020, found that remote working was in fact helping address long-held frustrations about the rhythm of office work. </p>



<ol><li>Lockdown helps us focus on the work that really matters. We are spending 12% less time drawn into large meetings and 9% more time interacting with customers and external partners.</li><li>Lockdown helps us take responsibility for our own schedules. We do 50% more activities through personal choice — because we see them as important — and half as many because someone else asked us to.</li><li>During lockdown, we view our work as more worthwhile.&nbsp; We rate the things we do as valuable to our employer&nbsp;<em>and</em>&nbsp;to ourselves. The number of tasks rated as tiresome drops from 27% to 12%, and the number we could readily offload to others drops from 41% to 27%.</li></ol>



<p>The key phrase here is: <em>managed and supported appropriately</em>. Certainly managers need to reinvent themselves as mentors to this style of working and then – forgive me – get the hell out of the way. </p>



<p>The office as the default way of working is dead. But the office itself isn’t dead. With working from home, what we gain in work-life balance we might lose in innovation and creativity. There are people who could directly challenge that sentence but I suspect they will come from highly mature companies who have fully mastered the remote working learning curve. Many of us are still at the stage of doing what we did in the office , just remotely. The timorous amongst us may use the lack of productivity net gains as a reason to regress rather than push through the ‘pain barrier’ <a rel="noreferrer noopener" href="https://paulitaylor.com/2020/07/11/nirvana-or-business-as-usual-navigating-the-new-future-of-work/" target="_blank">as Matt Mullenweg describes it.</a> </p>



<p>We can do so much better, for ourselves, our customers and society if we stop being so frightened or so certain of the future. </p>



<p>We are going to have fewer offices and spend more time at home. </p>



<p>Our efforts would be a lot better spent improving the experience and outcomes of both rather than arguing about preserving a status quo whose time has truly run out. </p>



<p><em>The office versus remote work?</em> It’s not a binary choice we need to make. </p>



<p>The best thing you can do in any period of change is to bet on neither black or white. The future will be made up instead of shades of grey where few things are certain and <em>the best you can do to prepare is to be endlessly adaptable</em>. </p>



<hr>



<p><em>Photo by <a href="https://unsplash.com/@bchild311?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Benjamin Child</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>
			
			
				</div></div>]]>
            </description>
            <link>https://paulitaylor.com/2020/09/12/why-do-so-many-people-want-us-back-in-the-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24452280</guid>
            <pubDate>Sat, 12 Sep 2020 13:32:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Social Dilemma]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24451749">thread link</a>) | @imafish
<br/>
September 12, 2020 | https://www.thesocialdilemma.com/the-dilemma/ | <a href="https://web.archive.org/web/*/https://www.thesocialdilemma.com/the-dilemma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-wrapper">

	<div id="content" tabindex="-1">

		<div>

			<!-- Do the left sidebar check -->
			

<div id="primary">

			<main id="main">

				
					<article class="page" id="post-12">

						<div>

							








<p><strong>The problem beneath all other problems</strong></p>



<p>Technology’s promise to keep us connected has given rise to a host of unintended consequences that are catching up with us. If we can’t address our broken information ecosystem, we’ll never be able to address the challenges that plague humanity.</p>







<div id="mental-health"><div>
<div>




<div>
<div><figure><img loading="lazy" src="https://www.thesocialdilemma.com/wp-content/uploads/2020/08/Mental-Health.png" alt="" width="67" height="87"></figure></div>



<figure><img loading="lazy" src="https://www.thesocialdilemma.com/wp-content/uploads/2020/08/mental-health-dilemma-1.png" alt="" width="135" height="109"></figure>







<blockquote><p><strong>A 5,000 person study found that higher social media use correlated with self-reported declines in mental and physical health and life satisfaction</strong>.</p><cite><span>American Journal of Epidemiology, 2017</span></cite></blockquote>



<p>Persuasive design techniques like push notifications and the endless scroll of your newsfeed have created a feedback loop that keeps us glued to our devices.</p>
</div>




</div>
</div></div>







<div id="democracy"><div>
<div>




<div>
<div><figure><img loading="lazy" src="https://www.thesocialdilemma.com/wp-content/uploads/2020/09/democracy-dilemma.png" alt="" width="97" height="85"></figure></div>



<figure><img loading="lazy" src="https://www.thesocialdilemma.com/wp-content/uploads/2020/08/democracy-dilemma.png" alt="" width="176" height="82" srcset="https://www.thesocialdilemma.com/wp-content/uploads/2020/08/democracy-dilemma.png 351w, https://www.thesocialdilemma.com/wp-content/uploads/2020/08/democracy-dilemma-300x139.png 300w" sizes="(max-width: 176px) 100vw, 176px"></figure>







<blockquote><p><strong>The # of countries with political disinformation campaigns on social media doubled in the past 2 years.</strong></p><cite><span>New York Times</span></cite></blockquote>



<p>The ability for advertisers to apply social media microtargeting to nefarious purposes gives bad actors the tools to interfere with elections and fuel political divisions with phenomenal ease.</p>
</div>




</div>
</div></div>







<div id="discrimination"><div>
<div>




<div>
<div><figure><img loading="lazy" src="https://www.thesocialdilemma.com/wp-content/uploads/2020/09/Discriminsation-dilemma-1.png" alt="" width="97" height="65"></figure></div>



<figure><img loading="lazy" src="https://www.thesocialdilemma.com/wp-content/uploads/2020/08/discrimination-dilemma.png" alt="" width="213" height="82" srcset="https://www.thesocialdilemma.com/wp-content/uploads/2020/08/discrimination-dilemma.png 426w, https://www.thesocialdilemma.com/wp-content/uploads/2020/08/discrimination-dilemma-300x115.png 300w" sizes="(max-width: 213px) 100vw, 213px"></figure>







<blockquote><p><strong>64% of the people who joined extremist groups on Facebook did so because the algorithms steered them there.</strong></p><cite><span>Internal Facebook report, 2018</span></cite></blockquote>



<p>Algorithms promote content that sparks outrage, hate, and amplifies biases living within the data that we feed it.</p>
</div>




</div>
</div></div>







<p><strong>Looking for more?</strong></p>















<div id="resources"><div>
<h2>Resources</h2>



<p>Further reading from <em>The Social Dilemma</em> subjects:</p>
















</div></div>







<div><div>




<h3>Help change how technology is designed, regulated, and used.</h3>












</div></div>

							
						</div><!-- .entry-content -->

					</article><!-- #post-## -->


				
			</main><!-- #main -->

			<!-- Do the right sidebar check -->
			
</div><!-- #closing the primary container from /global-templates/left-sidebar-check.php -->



		</div><!-- .row -->

	</div><!-- #content -->

</div></div>]]>
            </description>
            <link>https://www.thesocialdilemma.com/the-dilemma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24451749</guid>
            <pubDate>Sat, 12 Sep 2020 11:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jellyfish: Toxic but fascinating]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24451504">thread link</a>) | @dnetesn
<br/>
September 12, 2020 | http://oceans.nautil.us/feature/615/toxic-but-fascinating | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/615/toxic-but-fascinating">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>I</span>t was in 1752 that Linnaeus gave jellyfish the alternative name â€˜medusaâ€™ from the Greek myth of the same name. The term was well chosen. The bell of a jellyfish is a reminder of the head of the Gorgon sister, with its tentacles, like snakes, substituting for hair. Both the mythical Medusa and her animal counterpart were capable of causing paralysis and even death.&nbsp;</p>

<p>In the version of the Medusa myth found in Ovidâ€™s <em>Metamorphoses</em>, Medusa, one of three Gorgon sisters, was originally depicted as a great beauty whose attractive powers did not go unnoticed. Her hair was only transformed into serpents by the goddess Athena as a punishment. Medusa had been ravished by the sea god Poseidon in Athenaâ€™s own temple and because the temple had been defiled, Athena gave Medusa the power to change any human who looked upon her into stone. Perseus, the son of Zeus and half-brother of Athena, was asked by Polydectes to secure the head of Medusa. Instead of gazing on the Gorgon sister and risking being petrified, Perseus used the reflection on his shield to guide him while removing Medusaâ€™s head with his sword. From her decapitated torso sprang two children, Pegasus, a flying horse, and Chrysaor, a warrior with a golden sword. The transformative powers of Medusaâ€™s head were retained following its separation from the body and when Perseus laid down the head on the seashore, the escaping blood was said to be the origin of red coral (intriguing, knowing the close relationship that exists between jellyfish and coral).&nbsp;<br></p>
<p>Caravaggioâ€™s depiction of Medusa, painted towards the end of the sixteenth century, echoes her destructive yet beautiful power while another painting, initially thought to be by Leonardo da Vinci, was to inspire a famous poem by Shelley:&nbsp;</p>
<p><span>â€™Tis the tempestuous loveliness of terror; <br>For from the serpents gleams a brazen glare <br>Kindled by that inextricable error,<br>Which makes a thrilling vapour of the air <br>Become a [ ] and ever-shifting mirror.<br>Of all the beauty and the terror there-
A womanâ€™s countenance, with serpent locks, <br>Gazing in death on heaven from those wet rocks.&nbsp;</span></p>
<p>A more up-to-date version of Medusa is seen in Frank Mooreâ€™s painting <em>To Die For</em>. It features the model Kate Moss, her severed head alive with serpents. It was a painting commissioned by Gianni Versace, who never saw it since he was killed before Moore had completed the work. Moore himself died prematurely of AIDS in 2002, aged 48. The picture featured in an exhibition in New York called <em>Toxic Beauty: The Art of Frank Moor</em>e.<br></p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_805b7becd4587e52023de0fe709ad787.jpg" alt="Medusa_by_Carvaggio"><figcaption><span>A ceremonial shield depicting the severed head of Medusa, painted in the late 16th century by Caravaggio. </span><br><span>Wikimedia Commons</span></figcaption></figure>
<p>In her poem â€˜Medusa,â€™ Sylvia Plath successfully combines the mythical creature and the sea animal. Written shortly before her own death, it portrays her mother, with whom she had a difficult relationship, as a destructive monster clinging to her by a â€˜cableâ€™, akin to a jellyfish tentacle, and intent on controlling, indeed paralysing, her. It is as though Plath felt the need to exorcize her mother from her life in order to achieve some emotional distance, as well as to afford her greater freedom to write and compose. Plath could be said to have used the device of the snake-haired Gorgon to describe her own internal image of a monstrous mother. Ironically, her mother shared her first name with that of a common genus of jellyfish, <em>Aurelia</em>.&nbsp;<br></p>
<p>Freud came to regard Medusaâ€™s head as a symbol of castration. In a short, posthumously published essay, â€˜Das Medusenhauptâ€™, he equates decapitation with being castrated, arguing that when a boy views female genitalia for the first time he suddenly realizes the possession of a penis cannot be taken for granted, leading to a specific anxiety about castration. In the same way, glimpsing the Medusaâ€™s head causes a male observer to be struck dumb, on the one hand fascinated by what he sees and, on the other, paralysed with fear.&nbsp;</p>
<p>The Medusa myth, with its built-in ambiguity (deadly but fascinating), has served to reinforce our own ambivalence towards this sea creature. It may also have created a reluctance on the part of scientists to work with these animals. There is however no doubting that, when seen in its natural environment, the jellyfish displays that other, more positive quality, an ability to hold our attention, indeed to fascinate. This is explored in Marianne Mooreâ€™s poem â€˜A Jelly-fishâ€™, where the creature exerts â€˜a fluctuating charmâ€™.</p>
<center>
<iframe src="https://player.vimeo.com/video/456062181?color=ffcd05&amp;title=0&amp;byline=0&amp;portrait=0" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
<p>A <em>Crossota</em> jellyfish filmed at the Enigma Seamount in the Marianas Trench, more than two miles beneath the ocean surface. CREDIT: Courtesy of the NOAA Office of Ocean Exploration and Research.</p>
</center>
<p>&nbsp;Jellyfish escape as quickly as they appear and while they may be allowed to touch us, they themselves often resist capture. They appear both alluring and elusive. The very nature of their movement contributes to their ethereal beauty, and where better to observe this than in a tropical lagoon? The Raja Ampat islands off West Papua boast several. Others can be found on the Kakaban islands off Borneo. In both places the jellyfish have lost their ability to sting humans, making it possible to appreciate their delicacy and movement in safety. In the Ampat islands, the lagoons are connected to the ocean through underwater channels that limit the entry and exit of seawater. In addition, the water there is stratified into an oxygen-rich surface layer where the jellyfish live and a deeper layer, devoid of oxygen, where they are absent. Two genera of jellyfish, the so-called golden jellyfish, <em>Mastigias</em>, and the moon jellyfish, <em>Aurelia</em>, coexist there. The species of <em>Mastigias</em> found in Ampat has lost the spots on its bell and oral arms and the marine biologist Michael Dawson believes this indicates a new subspecies has evolved there with no appreciable sting, presumably as the result of geographical isolation.</p>
<p>The slow, seemingly directionless pulsation of jellyfish can have a calming effect and lends itself to hospital and general practice waiting rooms, a feature as yet unexploited. Its languid movement calls into question how efficient this is as a means of locomotion. Work done at Woods Hole Marine Biological Laboratory in Massachusetts is providing the answer. It seems that jellyfish have a special way of recapturing some of the energy expended on each swimming stroke. When a medusa contracts its bell, it creates two vortex rings. The first is shed in its wake, propelling the animal forwards. The second, during the relaxa- tion phase, rolls under the bell. This second vortex ring spins faster than the first and, as it does so, sucks in water which pushes up against the underside of the bell, giving the jellyfish a second- ary boost. It is a technique that works only at slow speeds and when the body size is small. The conclusion reached by Brad Gemmell and his team at Woods Hole is that a jellyfish expends less energy in travelling a given distance than any other marine animal so far studied. Its efficiency, however, comes at a price, namely low speed and virtually no maneuverability.&nbsp;</p>
<p>It would be wrong, however, to dismiss the humble jellyfish as a primitive automaton, unable to modify its movement and behaviour. By attaching accelerometers to the barrel jellyfish, <em>Rhizostoma pulmo</em>, it has been shown that it is able to orientate its swimming in relation to the direction of the tides. When the tide withdraws from the shore, this particular jellyfish orientates itself so as to swim against the current. When the tide flows towards the shore, it also swims in a consistent direction, either with or against the current, depending on the depth of the water. This appears to be a mechanism for keeping jellyfish together as a swarm and avoiding their becoming stranded on the shore.</p>
<center>
<iframe src="https://player.vimeo.com/video/456062042?color=ffcd05&amp;title=0&amp;byline=0&amp;portrait=0" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""><span id="selection-marker-1" class="redactor-selection-marker"></span></iframe>
<p><em>Cassiopea</em>, the upside-down jellyfish, are the most evolutionarily ancient creature known to sleep. CREDIT: Caltech</p>
</center>
<p>The fascination that jellyfish engender in us deepens when we consider recent discoveries about another aspect of their behaviour, one which mirrors our own. In the so-called upside- down jellyfish, <em>Cassiopea</em>, it is possible to witness periods of diminished activity resembling sleep from which the creature is only slowly aroused (reminiscent of our own behaviour when sleep deprived). Like us, this jellyfish becomes â€˜sleepyâ€™ when exposed to the naturally occurring chemical melatonin. Sleep, or at least periods of cyclical inactivity, would appear to have arisen early on in evolution, well in advance of the possession of advanced nervous systems.&nbsp;<br></p>
<p>Earlier in the book, I stressed how the anatomy and the life cycle of jellyfish proved to be more complex than previously imagined. The behaviour of jellyfish in their natural habitat is proving equally complicated. We know that migrations of jellyfish in a horizontal direction are guided by the position of the sun. The golden jellyfish in Palau, for example, follow the sunâ€™s arc across the sky. Before sunrise, they cluster at the western end of Jellyfish Lake. With the dawn, they swim in an easterly direction towards the light, following the sun until they reach the eastern shore. As the sun continues towards the western horizon, the jellyfish reverse their course and return to the western shore to await the new day.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_4fb5ec979b6ccebb925978ba8c39ebd6.jpg" alt="Palau Jellies"><figcaption><span>Golden jellyfish following the sun in Jellyfish Lake, Palau. </span><br><span>Richard Schneider</span></figcaption></figure>
<p>Vertical migration also occurs. Using echo sounders in a deep Norwegian fjord, the movements of individual helmet jellyfish,&nbsp; <em>Periphylla</em> <em>periphylla</em>, were monitored. This species of jellyfish segregates itself into assemblages. Each assemblage shows a different preference as far as vertical positioning in the water is concerned. Night-time groups congregate for the purpose of feeding and reproduction while other groups form for brief periods in other situations, only to disperse and then re-group. It has been suggested that this represents a type of social behaviour and …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/615/toxic-but-fascinating">http://oceans.nautil.us/feature/615/toxic-but-fascinating</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/615/toxic-but-fascinating</link>
            <guid isPermaLink="false">hacker-news-small-sites-24451504</guid>
            <pubDate>Sat, 12 Sep 2020 10:51:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bug Larping for Fun and Profit]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24451367">thread link</a>) | @ingve
<br/>
September 12, 2020 | https://anti.computer/rants/2020-09-12-bug-larping-for-fun-and-profit.html | <a href="https://web.archive.org/web/*/https://anti.computer/rants/2020-09-12-bug-larping-for-fun-and-profit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>12 Sep 2020</p>
<p>
So it's been almost a year since I made the jump from team offense to team
defense.
</p>

<p>
I spent so long in a pure offense focused org that the pivot into thinking
about defensive problems was a bit jarring at first.
</p>

<p>
Not in the least because the economics of bug hunting in offense vs bug
hunting in defense are completely upside down.
</p>

<p>
Offense is goal oriented. You establish what you want to achieve, and audit
accordingly. Tending to your attack surface garden until you've grown all the
ingredients you need to complete your soup of the 0day.
</p>

<p>
On the defense side you're stuck trying to extrapolate from the ghosts of
haxmas past. And while there's certainly heaps of known and novel attack
research out there these days … at the end of the day you are going up
against an attacker who's goals, timelines, and resources are essentially
unknown.
</p>

<p>
And that blind spot still makes all the difference.
</p>

<p>
So we play the mitigation game.
</p>

<p>
Assume the code is borky and plop it in a sandbox, a hypervisor, a chromebook
wrapped in tinfoil running on the neighbors wifi …
</p>

<p>
Shuffle the memory. Make it non-executable. Hell, make it non-readable! Sign
the pointers. Validate the control flows. Cookie all the things. Heap
integrity checks. SMEP/SMAP/SMOP/SMUP …
</p>

<p>
Oh right, the hardware. Assume the hardware is broken. De-optimize. Slow
things down. Duplicate all the things at every privilege level.
</p>

<p>
Prevent the side-effect.
</p>

<p>
Stop the unknown.
</p>

<p>
PULL THE PLUG!
</p>

<p>
Phew.
</p>

<p>
Quite a bit of advanced exploit development happens out in the open now, and
Arxiv is, apparently, the new Phrack.
</p>

<p>
Who woulda thunk it?
</p>

<p>
You can even get a PhD based on offense research these days. And not some
handwavy diatribe that yammers on about polymorphic shellcode detection
either, no, the real thing.
</p>

<p>
Systems engineering teams try to distill the lessons on display into ever
advancing mitigations.
</p>

<p>
Exploit teams accept the challenge.
</p>

<p>
Round and round it goes, and the complexity bar keeps getting raised.
</p>

<p>
If you missed the era where most of this stuff happened out of sheer rage or
curiosity in the dark corners of IRC channels … that sound you hear in the
background is the slightly nervous chuckle of 40-something hackers world wide
as they start to worry about aging out of the game.
</p>

<p>
It's easy to confuse complexity for efficacy, especially when they're equally
headache inducing.
</p>

<p>
There's a lot of talk about the importance of establishing exploitability in
some sort of automated way. The idea being that you can only properly
prioritize which bugs to fix through proven exploitability.
</p>

<p>
I go back and forth on this myself.
</p>

<p>
The obvious argument is that yes, if a bug has provable security impact, then
it deserves to be prioritized.
</p>

<p>
I think where it gets tricky is with the idea of exploitability. Exploitability
is a weird term. It sounds like an objective valuation.
</p>

<p>
A true/false.
</p>

<p>
But exploitability is really a function of subjective attacker motivation,
experience, resources, and skill.
</p>

<p>
So, for all intents and purposes, the best you can do is establish
exploitability based on what you, the defender, know about exploitation in
relation to how and where your assets are deployed and under which threat
models you practically operate.
</p>

<p>
Ben Hawkes has some solid thoughts[1] on the subject in terms of "equivalence
classes". Match the conditions in which bug A manifests itself to the known
exploitable conditions of bug B and if there's sufficient overlap then you can
make a reasonable assumption of exploitability.
</p>

<p>
If not, then go pay someone to try and write the exploit and stack the result
of that effort into your hackonomicon.
</p>

<p>
Many moons ago I wrote a whitepaper[2] for Microsoft on the subject when they
first came out with the "exploitability index". I tried to argue along similar
lines then, but I think the main difference anno 2020 is that the quality of
the public body of exploitation knowledge is much higher.
</p>

<p>
Julien Vanegue recently also made some interesting arguments[3] in favor of
exploitability-based triage prioritization and where the state of the
art is currently lacking.
</p>

<p>
All debate aside, his exploitability Venn diagram is much prettier than mine.
</p>

<p>
One of the harder practical problems to tackle in the exploitability realm is
that the problem space starts to explode when you combine platform
configurations with software ecosystems.
</p>

<p>
Every layer of the attack surface vertical introduces a massive growth of
potential exploitability that you now have to reason about.
</p>

<p>
VuSec's recent work[4], which combines their speculative execution
vulnerability research with a more traditional software vulnerability, is a
great example of what happens when someone goes "now kiss!" to security
assumptions based on disjointed threat models.
</p>

<p>
So probably the best you can hope for is some limited interpretation of Ben
and Julien's ideas, and apply it to some specific subset of your code, in some
known and static platform configuration. The more you can limit the threat
model exponents, the more practical automated decision making regarding
exploitability becomes.
</p>

<p>
But, that does not factor in the transubstantiative nature of bugs in terms of
exploit development. Many successful exploits are in fact a combination of
bugs. Independently those bugs might not represent an exploitable
vulnerability, but in concert, they do.
</p>

<p>
Or, even more fun, one bug becomes multiple exploit primitives. Julien touches
on this a bit in his section on the flawed thinking around "Approximate
Exploitability". To truly make informed decisions about exploitability, you
have to enumerate all side-effects, of every bug, in every combination.
</p>

<p>
This makes an exploitability focused triage process much trickier, because now
you need combined bug awareness. The kind of awareness that requires focused
audits to try and find the various pieces to complete the attack puzzle.
</p>

<p>
A more practical approach is probably to evaluate bugs for their viability as
an exploit primitive. Sean Heelan's research[5] in the AEG realm comes to
mind.
</p>

<p>
But even then, it's hard to generalize the problem away from very specific
platform and configuration constraints. You would have to reinvent the same
wheel for almost every platform and software stack out there, each with its
own corpus of exploitability knowledge.
</p>

<p>
Which brings us back to the bugonomics of defense vs offense. If I'm an
attacker, I obviously care about exploitability. That's how I get things done.
</p>

<p>
But if I'm a defender, in the developer sense of the word, then I probably
care about general code quality more.
</p>

<p>
Bugs, and bug density, are symptomatic of code quality. The less bugs, the
less potential exploitation primitives … the less potential exploitation
primitives, the less chances of successful exploit chains.
</p>

<p>
Vulnerabilities are just rebranded bugs, after all. Nu pun intended.
</p>

<p>
So, the things we need to do to improve code quality are, by definition, the
same things we need to do reduce vulnerabilities. If that relation holds in
both directions, then perhaps there is more bang for buck in pipeline
strategies that focus on code quality and triage speed as a whole?
</p>

<p>
I do think it's important for developers to understand the ideas behind
exploitation. To have a firm understanding of how input has influence on your
code, and how sometimes that influence can pivot into behavior that benefits
an attacker.
</p>

<p>
But we turned the side-effect into its own thing. Glorified it. Built careers
out of it.
</p>

<p>
So here we are.
</p>

<p>
Knee deep in bugs, trying to convince the world that the ones we understand
the best are the most important ones. Chipping away at them one email
notification at a time … hoping that whoever receives them … agrees.
</p>

<p>
<b>waves hands furiously</b>
</p>

<p>
Love,
</p>

<p>
Bas
</p>

<ul>
<li>[1] <a href="https://twitter.com/benhawkes/status/1298000068436324352">https://twitter.com/benhawkes/status/1298000068436324352</a></li>
<li>[2] <a href="https://anti.computer/random/microsoft-exploitability-index-whitepaper-2009.pdf">https://anti.computer/random/microsoft-exploitability-index-whitepaper-2009.pdf</a></li>
<li>[3] <a href="https://openwall.info/wiki/_media/people/jvanegue/files/soundness_of_attacks.pdf">https://openwall.info/wiki/_media/people/jvanegue/files/soundness_of_attacks.pdf</a></li>
<li>[4] <a href="https://download.vusec.net/papers/blindside_ccs20.pdf">https://download.vusec.net/papers/blindside_ccs20.pdf</a></li>
<li>[5] <a href="https://seanhn.files.wordpress.com/2019/11/heelan_ccs_2019.pdf">https://seanhn.files.wordpress.com/2019/11/heelan_ccs_2019.pdf</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://anti.computer/rants/2020-09-12-bug-larping-for-fun-and-profit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24451367</guid>
            <pubDate>Sat, 12 Sep 2020 10:17:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Win32 apps like it's 2020: Helpers for a modern C++ world]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24451177">thread link</a>) | @crecker
<br/>
September 12, 2020 | https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/ | <a href="https://web.archive.org/web/*/https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        Colin Finck
        <br>
        <span>on&nbsp;</span><time datetime="2020-07-30 00:00:00 +0000 UTC">July 30, 2020</time>
</p>
		


		

		

<p>This is the second part of a three-part series on Win32 development:</p>

<ul>
<li><a href="https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-1/">Introduction</a></li>
<li><em>Helpers for a modern C++ world</em></li>
<li><a href="https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-3/">A DPI-aware resizable wizard</a></li>
</ul>

<p><a href="https://github.com/enlyze/Wizard-2020">Example Project on GitHub</a></p>

<hr>

<p><span>W</span>e are now going to get into the nitty-gritty details of Win32 and how modern C++ can help us here.</p>

<nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#pointers-that-free-themselves">Pointers that free themselves</a></li>
<li><a href="#universal-c-containers">Universal C++ containers</a></li>
<li><a href="#string-resources-without-regrets">String resources without regrets</a></li>
<li><a href="#mastering-the-handle-mess">Mastering the handle mess</a></li>
<li><a href="#gracefully-failing-constructors">Gracefully failing constructors</a></li>
<li><a href="#the-only-wndproc-you-ll-ever-need">The only <code>WndProc</code> you’ll ever need</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul></li>
</ul>
</nav>


<h2 id="pointers-that-free-themselves">Pointers that free themselves</h2>

<p>If you are coming from the C world, you have been managing all your resources manually so far.
You allocate each heap memory block using <code>malloc</code> and need to take care of a call to <code>free</code> in every exit path of the function.
As you have probably observed already, this easily leads to human mistakes:
A forgotten <code>free</code> in just one exit path is enough to cause a severe memory leak.
Freeing a pointer twice or using it after a <code>free</code> happens just as easy and can be the source of very painful bugs.</p>

<p>Being a C API, Win32 is no different in this regard.
It offers you <code>HeapAlloc</code> and <code>HeapFree</code>, which are a bit closer to the operating system than their C library counterparts, but otherwise suffer from the same issues.</p>

<p>Now you may argue that YOU obviously never make such mistakes.
So let’s just talk about the code you import from someone else.
If you see a manual memory allocation there, how can you be sure that the programmer correctly handled all exit paths?
There is no way to ensure that unless you check the entire code yourself.</p>

<p>C++ has been trying to be better at memory management since its infancy.
But it has taken until 2011 for C++ to finally come up with a reliable solution that is also going to work tomorrow: <code>std::unique_ptr</code><br>
This template class is a wrapper around any object that you want to put on the heap.
It allocates memory for the wrapped object in its constructor and frees it in its destructor.
As C++ automatically calls the destructor whenever the <code>std::unique_ptr</code> goes out of scope, you can no longer forget that and the human is taken out of the equation.
This makes <code>std::unique_ptr</code> a so-called <em>smart pointer</em>.</p>

<p>If you have been into C++ for quite a while, you may know <code>std::unique_ptr</code>’s predecessor <code>std::auto_ptr</code>.
This one has been deprecated for good (and entirely removed in newer C++ standards) due to its unclear ownership semantics.
The details don’t matter here, just keep in mind that <code>std::unique_ptr</code> fully owns an object and can’t accidentally lose it.
Unlike <code>std::auto_ptr</code>, you can only transfer ownership of that object by using an explicit <code>std::move</code>.</p>

<p>Note that <code>std::unique_ptr</code> is only an option for allocating a single object.
It does not work for arrays, because those need to be freed differently (<code>delete[]</code> vs. <code>delete</code>).
While people have often asked for an “auto_array_ptr”, modern C++ offers something even better, which we will dive into in the next section.</p>

<h2 id="universal-c-containers">Universal C++ containers</h2>

<p>For a long time, C <code>char</code> arrays and C++ <code>std::string</code> have been two different worlds.
You could get a constant representation of a <code>char</code> array from an <code>std::string</code> using the <code>c_str</code> method, but a true two-way interaction between both types wasn’t possible.
As a result, legacy C interfaces like the Win32 API often limited you to using traditional C-style arrays without the benefits of modern C++ containers.
You had fun managing all the memory allocations yourself, making sure that nothing leaks, and doing <code>strlen</code> over and over again because a <code>char</code> array doesn’t know its size.</p>

<p>This has changed for good starting with C++11, which guarantees that an <code>std::string</code> is internally stored as a <code>char</code> array.
C++17 adds a <code>data</code> method returning a writable pointer to that <code>char</code> array, finally making <code>std::string</code>s universally usable in all places that use <code>char</code> arrays.</p>

<p>Extensive and error-prone code like</p>
<div><pre><code data-lang="C"><span>const</span> <span>char</span><span>*</span> szTest <span>=</span> <span>"Hello"</span>;
<span>int</span> cch <span>=</span> MultiByteToWideChar(CP_ACP, szTest, <span>-</span><span>1</span>, NULL, <span>0</span>);

<span>const</span> WCHAR<span>*</span> wszTest <span>=</span> HeapAlloc(GetProcessHeap(), <span>0</span>, cch <span>*</span> <span>sizeof</span>(WCHAR));
<span>if</span> (<span>!</span>wszTest)
{
    printf(<span>"Out of memory!</span><span>\n</span><span>"</span>);
    <span>return</span> <span>1</span>;
}

MultiByteToWideChar(CP_ACP, szTest, <span>-</span><span>1</span>, wszTest, cch);

<span>// Do something with wszTest
</span><span>// Take care to clean it up in all exit paths using:
</span><span></span>
HeapFree(GetProcessHeap(), <span>0</span>, wszTest);</code></pre></div>
<p>can finally become as simple as</p>
<div><pre><code data-lang="C++">std<span>::</span>string strTest <span>=</span> <span>"Hello"</span>;
<span>int</span> cch <span>=</span> MultiByteToWideChar(CP_ACP, strTest, strTest.size(), <span>nullptr</span>, <span>0</span>);

std<span>::</span>wstring wstrTest;
wstrTest.resize(cch);
MultiByteToWideChar(CP_ACP, strTest, strTest.size(), wstrTest.data(), cch);

<span>// Do something with wstrTest, cleanup happens automatically
</span></code></pre></div>
<p>By the way, the same is also true for <code>std::vector</code>.
All your manual allocations of arrays, prone to buffer overflows and memory leaks, can finally be replaced by automatically managed <code>std::vector</code>s and still interact with APIs written in C.</p>

<h2 id="string-resources-without-regrets">String resources without regrets</h2>

<p>Let’s get deeper into Win32 specifics and use what we just learned.<br>
If you are writing applications for Windows, you have probably made good use of <em>resources</em> already.
Resources allow you to organize strings and graphics at a central location separated from your code.
Each resource is associated with a language code.
When running your application, Windows will pick the resource that best matches your operating system language setting.</p>

<p>For loading a Unicode string resource, the Win32 API of choice is the <code>LoadStringW</code> function.
Even if Microsoft sample code still does, you don’t want to use the ANSI counterpart <code>LoadStringA</code> and neither the <code>LoadString</code> macro that forwards to one of both.
Both were last needed in the era of Windows 95/98/Me, which didn’t come with native Unicode support.
The NT line of Windows has always supported Unicode from the kernel up to the applications.
All <code>A</code> functions there are implemented to convert the string to Unicode and then call the corresponding <code>W</code> function.
As we’re not targeting anything older than Windows XP here, we can (and should!) safely forget about <code>A</code> functions.
Some newer Windows APIs don’t even provide them anymore.</p>

<p>I have seen most people using <code>LoadStringW</code> by declaring a buffer that is “hopefully large enough” and letting the function copy the string into that buffer.
Even Microsoft sample code usually looks like this:</p>
<div><pre><code data-lang="C++">WCHAR wszString[<span>100</span>];
LoadStringW(hInstance, IDS_STRING_ID, wszString, <span>sizeof</span>(wszString) <span>/</span> <span>sizeof</span>(WCHAR));
</code></pre></div>
<p>This code is potentially dangerous in multiple dimensions:<br>
1. If the string for a language later turns out to be longer than 99 characters (consider the terminating NUL), it is silently truncated.
In the best case, this only impacts your user experience badly.
In the worst case, the user loses critical information because the string is later fed to a formatting function like <code>printf</code> and now misses a format character.
2. The developer may forget to divide by the size of a <code>WCHAR</code> in the last parameter, thereby creating the illusion of a larger buffer and laying the foundation for a typical buffer overflow.
3. The return value of <code>LoadStringW</code> isn’t checked at all, hence <code>wszString</code> may be uninitialized.
If you later work with that buffer, expect things to go tremendously wrong.</p>

<p>Only few people know about the other (scarcely documented) way of using <code>LoadStringW</code>:</p>
<div><pre><code data-lang="C++"><span>const</span> WCHAR<span>*</span> pString;
<span>int</span> CharacterCount <span>=</span> LoadStringW(hInstance, IDS_STRING_ID, <span>reinterpret_cast</span><span>&lt;</span>LPWSTR<span>&gt;</span>(<span>&amp;</span>pString), <span>0</span>);
</code></pre></div>
<p>Instead of copying the resource string into a buffer, this call provides you with a read-only pointer to it.
All resources are already loaded into memory when starting your application, so retrieving the string this way performs no additional copying.
However, there is a caveat here:
The string is not necessarily NUL-terminated when being loaded this way.
This makes it hard to use the string directly in a pure C world where NUL-terminated strings are expected everywhere.
While we also get the character count from this <code>LoadStringW</code> call, we cannot just insert the missing NUL terminator ourselves due to the read-only nature of the string pointer.</p>

<p>Fortunately, C++ comes to the rescue here.
As we have learned that its <code>std::</code> classes are full-fledged alternatives to C-style character arrays these days, we can use them to fix our trouble with <code>LoadStringW</code>.
Enough said, the final function looks like this:</p>
<div><pre><code data-lang="C++">std<span>::</span>wstring LoadStringAsWstr(HINSTANCE hInstance, UINT uID)
{
    PCWSTR pws;
    <span>int</span> cch <span>=</span> LoadStringW(hInstance, uID, <span>reinterpret_cast</span><span>&lt;</span>LPWSTR<span>&gt;</span>(<span>&amp;</span>pws), <span>0</span>);
    <span>return</span> std<span>::</span>wstring(pws, cch);
}
</code></pre></div>
<p>These 3 lines are sufficient to solve all of our problems above.
It doesn’t matter if the string is 10 or 1000 characters long, the function will transparently handle this.
It also doesn’t care about any terminating NUL character, because it just initializes a new <code>std::wstring</code> and copies the retrieved number of characters from the read-only resource pointer.
The returned <code>std::wstring</code> is guaranteed to be initialized and a comfortable and safe way to work with the loaded string.</p>

<p>I’m also using Hungarian notation in my final function to emphasize a few things.
The <code>pws</code> abbreviation refers to a <em>pointer to a wide-string</em>.
You may have more commonly seen <code>pwsz</code>, which would translate to a <em>pointer to a wide-string terminated by zero</em>.
As we just discussed, the latter part does not apply here, and this is underlined by the subtle difference in naming.
Similarly, <code>cch</code> stands for <em>count of characters</em> and distinguishes the integer variable from a count of bytes (<code>cb</code>).
You will deal with both when using Win32 API, and proper naming helps to not mess things up.</p>

<h2 id="mastering-the-handle-mess">Mastering the handle mess</h2>

<p>If you write your Win32 application in C, you soon have handles all over the place.
Every I/O operation, network connection or registry key, just to name a few, is identified by a handle variable that you must take care of.
When a resource is no longer needed, you need to close the handle manually - and again you must do so for all exit paths of your function.
This technique is susceptible to the same human mistakes that we …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/">https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/</a></em></p>]]>
            </description>
            <link>https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24451177</guid>
            <pubDate>Sat, 12 Sep 2020 09:40:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Social Dilemma by Tristan Harris – Review, Summary and Infographic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450987">thread link</a>) | @Lima_Writes
<br/>
September 12, 2020 | https://lifebeyond.one/blogs/tech-impact/why-you-should-watch-the-social-dilemma-on-netflix-today | <a href="https://web.archive.org/web/*/https://lifebeyond.one/blogs/tech-impact/why-you-should-watch-the-social-dilemma-on-netflix-today">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  <h2 name="0a5e">
<span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle">Get a wake-up call on<span>&nbsp;</span></span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle">the</span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle"><span>&nbsp;</span>impact of Big Tech<span>&nbsp;</span></span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle">and</span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle"><span>&nbsp;</span>take action,<span>&nbsp;</span></span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle">now</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span>
</h2>
<figure name="aad1"><img data-image-id="1*toFS4aaDipX_CuNrRhBtCQ.png" data-width="3505" data-height="2673" src="https://cdn-images-1.medium.com/max/1800/1*toFS4aaDipX_CuNrRhBtCQ.png"></figure>

<section name="1442">

<div>
<div>
<p name="db86">I watched “<a href="https://www.netflix.com/title/81254224" data-href="https://www.netflix.com/title/81254224" rel="noopener noreferrer" target="_blank">The Social Dilemma</a>”, the documentary by the Center for Humane Technology and featuring Tristan Harris, yesterday. It taught me zero new things. I learned nothing that I had not already come across during my research for my latest book <a href="https://lifebeyond.one/products/life-beyond-the-touch-screen-smartphone-addiction?ref=hackernoon.com" data-href="https://lifebeyond.one/products/life-beyond-the-touch-screen-smartphone-addiction?ref=hackernoon.com" rel="noopener noreferrer" target="_blank">Life Beyond the Touch Screen</a>. Or that I had not even incorporated in the book.</p>
<p name="b017">I was, however, very much inspired by the documentary.</p>
<p name="b017"><em><iframe width="560" height="315" src="https://www.youtube.com/embed/uaaC57tcci0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></em></p>
<p name="b017"><em>[Oh wait, I did learn two new things. I learned about </em><a href="https://www.nytimes.com/2018/11/06/technology/myanmar-facebook.html" data-href="https://www.nytimes.com/2018/11/06/technology/myanmar-facebook.html" rel="noopener noreferrer" target="_blank"><em>the role Facebook played</em></a><em> and admitted it played in the Myanmar Rohingya Muslim violence. And that there is such a thing as </em><a href="https://www.theguardian.com/lifeandstyle/2019/jan/23/faking-it-how-selfie-dysmorphia-is-driving-people-to-seek-surgery" data-href="https://www.theguardian.com/lifeandstyle/2019/jan/23/faking-it-how-selfie-dysmorphia-is-driving-people-to-seek-surgery" rel="noopener noreferrer" target="_blank"><em>Snapchat Dismorphia</em></a><em> — a.k.a. kids seeking surgery to look more like their filtered selfies in real life. ‘Da hell.]</em></p>
<p name="b017"><em>[Note: Tristan Harris, together with Nir Eyal and Yuval Noah Harari, has been one of my greatest inspirations for creating "Life Beyond the Touch Screen". Nothing but respect. Read on to understand more.]</em></p>
<p name="a2d9">I was inspired because I recognized two things. One being the difficulty Tristan Harris — legendary former design ethicist at Google — and other former and current high-ranking executives from silicon valley, venture capitalists and academics were having;</p>
<blockquote name="fe84"><em>In trying to explain what was so wrong and so dangerous about the role digital technology is taking in our lives today.</em></blockquote>
<p name="b0e2">What is that problem?</p>
<p name="13db">This was the second thing I recognized. The problem is that next to and simultaneous to adding so much ease and benefit to our lives, digital technology and mainly social media, are impacting our individual mental health, the mental health of our children, and the fabric of society and democracy in very, very dark ways as well.</p>
<p name="b43a">We are getting burn-out by the masses, staggeringly high rates of depression, anxiety and suicide in teens (mostly girls), and unprecedented levels of political polarization and tampering of election results with the help of an explosion of fake news. Propaganda, and real-life, deadly violence.</p>
<p name="5883">Why? Because armies of already genius experts in the psychology of persuasion and addiction, armed with the most powerful technology mankind has ever seen, are becoming more and more proficient at altering our behavior in minuscule but very, very real ways.</p>
<blockquote name="42dd">I am seriously afraid for our mental health, for that of our children, and for the world they will inherit.</blockquote>
<p name="d360">The problem underneath that being that the supercomputers and algorithms working to do that, are programmed from a capitalist and commercial perspective — so their highest goal is not humanity’s greater good: instead it is the highest possible profit.</p>
<p name="81e5">Our attention, time, and energy are being sold to the highest bidder. And as I have written before; maybe it’s <a href="https://medium.com/hackernoon/the-state-of-ai-in-the-world-56be75b51887" data-href="https://medium.com/hackernoon/the-state-of-ai-in-the-world-56be75b51887" rel="noopener noreferrer" target="_blank">not a question of when A.I. starts taking over from us humans</a> — but rather a question of when we will wake up to the fact that it already has.</p>
<h3 name="f1ee">“The Social Dilemma”- Review, Summary, ArtfulGraphic</h3>
</div>
<div>
<figure name="13ff"><img data-image-id="1*Zhq2MjvT7v_k5hT3TTDkeA.jpeg" data-width="1280" data-height="720" src="https://cdn-images-1.medium.com/max/1800/1*Zhq2MjvT7v_k5hT3TTDkeA.jpeg"></figure>
</div>
<div>
<p name="e837">I was so inspired by “The Social Dilemma” that I created the above ArtfulGraphic, to try and help create momentum — in all honesty, also to possibly ride the hype I’m hopefully helping to create, and promote <a href="https://lifebeyond.one/products/life-beyond-the-touch-screen-smartphone-addiction?ref=hackernoon.com" data-href="https://lifebeyond.one/products/life-beyond-the-touch-screen-smartphone-addiction?ref=hackernoon.com" rel="noopener noreferrer" target="_blank">my book</a>.&nbsp;</p>
<p name="1241">I drew a lady with a <em>black mirror</em> face, edited the picture in a wonderful app called Photofox, and then created the Graphic in PowerPoint — I’m no pro designer, sorry, not sorry.</p>
<p name="e1a1">Mainly, though, I created the above ArtfulGraphic to try to explain as simply as possible what’s going on.&nbsp;</p>
<p name="0971">Why this stuff matters and why you want to get inspired and take action now. And why you should watch “<a href="https://www.netflix.com/title/81254224" data-href="https://www.netflix.com/title/81254224" rel="noopener noreferrer" target="_blank">The Social Dilemma</a>” on Netflix today, preferably together with your spouse and your kids, if you have them.</p>
</div>
</div>
</section>
<section name="d9d2">


</section>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://lifebeyond.one/blogs/tech-impact/why-you-should-watch-the-social-dilemma-on-netflix-today</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450987</guid>
            <pubDate>Sat, 12 Sep 2020 08:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cybersecurity and AI in Health Applications]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450431">thread link</a>) | @xxlcloudinc
<br/>
September 11, 2020 | https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Cyber-crimes affect companies from all industries like IT, Legal, Education, Manufacturing, Finance. Healthcare is one of the most targeted since this sector relies on the perpetual exchange of big volumes of valuable data.</p>
<div><p>Amid a health crisis, a cyberattack targeting healthcare IT systems around the world takes place every three days <a href="#ref1"><sup>[1]</sup></a>.</p><p>Since the beginning of the second decade of this millennium, cyber threats and data breaches increase rate has <a href="https://www.industryweek.com/technology-and-iiot/article/22026828/cyberattacks-skyrocketed-in-2018-are-you-ready-for-2019" target="_blank" rel="nofollow">spiked disturbingly</a>. Cyber regulations are evolving and requiring healthcare facilities to address more than just the patient’s illnesses. Also responsible for the security of their data, they make health care information security a priority. And they are pushed to do it. Any intrusion on the integrity of internal data can have catastrophic consequences for patients and healthcare facilities.</p></div>
<figure><img src="https://cdn.codecoda.com/img/pixel.gif" data-plugin-lazyload="" data-plugin-options="{'effect' : 'fadeIn', 'speed' : 'fast'}" data-original="https://cdn.codecoda.com/themes/user/site/default/asset/img/blog/healthcare-breach-barometer-2016-2019.jpg" alt="Healthcare Data Breaches 2016-2019">
<figcaption><small>Healthcare Data Breaches 2016-2019</small></figcaption>
</figure>
<div><p>For healthcare companies, a breach of security is very costly. In this critical context, the health sector must be aware and ready to do everything possible to secure their health applications and data banks, by channeling enough technological and financial resources to them. The data collected in the health sector is particularly sensitive because most records become a significant liability when compromised. Healthcare organizations are prime targets for cybercriminals seeking to gain valuable information by exploiting vulnerable security systems. The risk of a breach is reduced by adopting security measures with mighty authentication methods, paired with employee training – <a href="https://www.forbes.com/sites/insights-fortinet/2019/08/27/the-importance-of-training-cybersecurity-awareness-as-a-firewall/#2693a2cd8b4b%20target=" _blank"="" rel="nofollow">a necessary follow-up action</a> that some companies tend to undermine, and, therefore, risk turning into a headline in cybersecurity news sites.</p><p>One specific area of healthcare is particularly susceptible to cyberattacks, and criminals often use it to create a breakpoint - the company’s supply chain. Because health organizations rely on multiple suppliers and external services, they support a vast network where massive data is on a constant exchange. Securing such an intense pipeline of information flow is exceptionally difficult, and hackers won’t hesitate to abuse this unfortunate fact.</p><p>In the Healthcare sector, computer systems contain sensitive data and support organizations in the delivery of quality patient services, making them a prime target for extortion attempts. Phishing, in which a cybercriminal poses as a legitimate organization or individual to entice trust, is a common form of attack. Emails have always been a possible point of entry, filled with bogus attachments and links to fake websites. Email breach is of particular concern in healthcare, as staff consistently uses emails to exchange highly valuable data. If an employee’s email login information is stolen or disclosed - including their username and password - they can be used by criminals to gain access to patient records, and based on this employee level of access, possibly leverage even further damage.</p></div>
<h2>Applications at the service of health: pay attention to the data!</h2>
<div><p>The concept of e-health is not technologically innovative. The service itself is not advanced by any means; what is innovative is the main piece of technology it uses. This tech choice consists of the provision of communicating applications allowing, here, to perform specific measures via the combined effort of a peripheral, a service platform (mainly based on cloud technologies) and a communication network <a href="#ref2"><sup>[2]</sup></a>.</p><p>The security principles and techniques applicable to e-health are, therefore, very similar to those considered by suppliers of critical connected systems. The main difference is that medical devices process health data, which is among the most lucrative for cybercriminals. Personal medical records reside under the aegis of restrictive regulations. Such regulations impose special protection to guarantee the integrity of the patient’s privacy.</p><p>New black gold, all the corporate data collected and processed, defines the level of risk for the services that use this information. In the case of e-health, all present vulnerabilities and medical data leak possibilities must be eradicated. Data protection can break the integrity of private data. For example, sensitive information can circulate multiple communication channels and get exposed to a breach. Not even the doctor-patient is entirely bulletproof.</p><p>A data communication channel may temporarily break data integrity. For example, doctor-patient communication is vulnerable to data leaks, despite the security-laden non-disclosure agreement they both approve.</p><p>Of course, sensitive data can be partially <b><a href="https://codecoda.com/en/blog/entry/benefits-of-encryption-technology-for-data-protection">encrypted</a></b> or partially exposed. For example, to explain conditions or medical treatment procedures, doctors use <i>pseudonymization</i>, when communication with their patients. Doctors also use <i>anonymization</i>, when it comes to data as part of statistics or a plan to improve a specific service.</p></div>
<h2>Cybersecurity in the Healthcare sector:</h2>
<p>Healthcare organizations should ensure that they have robust security measures in place to limit the risks of email account compromise <a href="#ref3"><sup>[3]</sup></a>, cyber security threat breaches, and other cyber security threat related incidents. These measures must cover all parameters inherent to <i>people, processes, and technologies</i>:
</p><ul><li><b>Practices and procedures</b> – Strong authentication methods, secure access to applications, systems, and data; Communication with staff and other key stakeholders’ regular updates, as well as reminders of safety behaviors and mandatory actions during safety failure;</li>
<li><b>Supplier Relationships</b> – Cybercriminals can exploit any weak link in a supply chain to gain access to a target. “The existence of strong links between companies within a healthcare ecosystem can compromise an entire ecosystem.” This is why, our latest Healthcare app project, MeTime, features a ‘close-quarters’ environment where vendors, clients and suppliers can safely exchange data while preserving privacy integrity.</li>
<li><b>Log management</b> – Healthcare facilities often use a set of proprietary applications and systems that must be linked together within an IT security framework. LogPoint’s highly flexible cybersecurity software architecture addresses this problem and has become the standard cybersecurity tool for log management in the healthcare industry <a href="#ref4"><sup>[4]</sup></a>. Some of the world’s most advanced hospitals are using our next-generation SIEM solution to protect their patient information.</li>
<li><b>Training</b> – Entry-to-service training, regular reminders, additional training for all staff, and, where appropriate, other stakeholders. Malicious activity isn’t the only activity impacting your organization. Human error - as is the case in any industry - is another risk that deserves attention. Incorrect distribution of information and inappropriate handling of sensitive data puts your organization at high risk for data loss.</li>
<li><b>Ransomware</b> – ransomware is another type of direct cybersecurity threat to the healthcare industry. While this type of attack typically cannot confirm a breach, ransomware has the potential to directly affect the privacy, integrity, and availability of critical systems. It is essential to prepare for the possibility of such an incident and harden your security policies accordingly. The recent spikes in ransomware attacks suggest it is a matter of time when online attackers will cycle toward any possible company. The best move is to expect a blow from that angle and get prepared on that front.</li></ul>
<h2>The potential role of AI for health application security</h2>
<div><p>It is no longer a secret: ensuring the security of information systems is one of the significant challenges in companies. The fight against cybercrime has experienced a small revolution in recent years, thanks to the application of artificial intelligence. Through machine learning, we can discover how threats operate and evolve and use that information for a more precise counter-measure.</p><p>The number one difficulty in cybersecurity is the realization that criminals are always one step ahead of companies: they look for security holes, that someone working for the company is likely to overlook. Also, there is the exponential and ultra-rapid development of <b><a href="https://codecoda.com/en/blog/entry/new-tech-in-ecommerce">new technologies</a></b>, particularly cloud and mobile. Hackers are quick to learn how new tech can be used to their advantage, and cybersecurity experts must keep up, keeping up with their, looking to predict, and dismantle their attempts.</p><p>Most basic security solutions focus on understanding malware and preventing infiltration. Thus, rather than being in action, they will instead react to present and incoming danger. This passive threat-response strategy requires regular updates, among other things, and their use alone proves to be insufficient. A more sophisticated cyber solution finds an ally in Artificial Intelligence (AI). Machines have the intensity and relentlessness needed when battling cyber threats and are preferred tools of veteran cybersecurity experts.</p><p>AI can proactively identify and mitigate a threat even before a patch is developed and released <a href="#ref5"><sup>[5]</sup></a>. Its main advantage is its ability to relieve the human factor of tedious and time-consuming tasks, and this with a better reaction capacity in the treatment of alerts that flood computer systems daily.</p><p>AI then makes it possible to spot, analyze, and respond to cyber-attacks faster than a human. It provides an instrument which, when applied to cybersecurity, improves the efficiency and strengthens the protection of information technologies, for companies constrained by time and resources, financial or human.</p><p>It is on the processing of data between applications that AI can have a considerable impact. Robotics quickly analyzes a large amount of data from which it can spot anomalies or signal potential threats. Machines learn from a growing set of data and, over time, become more and more precise at detecting abnormalities. Today, Machine Learning finally gains the power to support human expertise in decision-making.</p><p>The future of cybersecurity is about embracing and innovating to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications">https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450431</guid>
            <pubDate>Sat, 12 Sep 2020 06:50:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EduTech Spyware Is Still Spyware: Proctorio Edition]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24450248">thread link</a>) | @some_furry
<br/>
September 11, 2020 | https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Spyware written for educational institutions to flex their muscles of control over students and their families when learning from their home computer is still, categorically, spyware.</p>



<p>Depending on your persuasion, the previous sentence sounds like either needless pedantry, or it reads like tautology. But we need to be clear on our terms.</p>



<ol><li>Educational spyware is still spyware.</li><li>Spyware is categorized as a subset of malware.</li></ol>



<p>When vulnerabilities are discovered in malware, the normal rules of <a href="https://adamcaudill.com/2015/11/19/responsible-disclosure-is-wrong/">coordinated disclosure</a> are out of scope. Are we clear?</p>







<p>So let’s talk about Proctorio!</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">For anyone unfamiliar with it, Proctorio is a browser extension used to eliminate cheating through intense surveillance techniques. It records the computer screen while you take the exam to ensure you don’t look anything up. However, it’s more than that. (Thread 1/11)</p>— Cassie (@Angry_Cassie) <a href="https://twitter.com/Angry_Cassie/status/1301360994044850182?ref_src=twsrc%5Etfw">September 3, 2020</a></blockquote></div>
</div><figcaption>The entire thread is unrolled <a href="https://threadreaderapp.com/thread/1301360994044850182.html">here</a>.</figcaption></figure>



<p>I won’t go into the details of Proctorio or why it’s terrible for (especially disadvantaged) students. Read Cassie’s Twitter thread for more context on that. Seriously. I’m not gonna be one of those guys that <em>talks over</em> women, and neither should you.</p>



<p>What I am here to talk about today is these dubious claim about the security of their product:</p>







<h2 id="zero-knowledge">Zero-Knowledge Encryption? OMGWTFBBQ!</h2>



<p>In cryptography, there are a class of algorithms called Zero-Knowledge Proofs. In a Zero-Knowledge Proof, you prove that you possess some fact without revealing any details <em>about</em> the fact.</p>



<p>It’s kind of abstract to think about (and until we’re ready to talk about Pedersen commitments, I’m just going to defer to <a href="https://openprivacy.ca/work/swisspost-scytl-evoting/">Sarah Jamie Lewis</a>), but the only thing you need to know about “Zero Knowledge” in Cryptography is that the output is a boolean (True, False).</p>



<p>You can’t use “Zero Knowledge” <em>anything</em> to encrypt. So “Zero-Knowledge Encryption” is a meaningless buzzword.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">As a cryptographer, I would like details on how on Earth it is using zero knowledge proofs in this situation. In all likelihood they're not doing what "zero knowledge" usually means, which quite frankly has me more worried about the security, not less.</p>— Buchberger's algorithm fan account (@SchmiegSophie) <a href="https://twitter.com/SchmiegSophie/status/1304407483658592256?ref_src=twsrc%5Etfw">September 11, 2020</a></blockquote></div>
</div></figure>



<p>So what are they actually describing when they say Zero Knowledge Encryption?</p>







<p>Okay, so they’ve built their own key distribution system and are encrypting with AES-GCM… and shipped this in a Chrome extension. But before we get to that, look at this <strong>Daily Vulnerability Tests</strong> claim.</p>



<div><figure><img data-attachment-id="1204" data-permalink="https://soatok.blog/soatoktelegrams2020-04/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-04" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png 512w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Bullshit.</figcaption></figure></div>



<p>Running Nessus (or equivalent) on a cron job isn’t meaningful metric of security. At best, it creates alert fatigue when you accidentally screw up a deployment configuration or forget to update your software for 4+ years. (Y’know, like JsZip 3.2.1, which they bundle.)</p>



<p>A dumb vulnerability scan isn’t the same thing as a routine (usually quarterly) penetration test or a code audit. And if you’re working in cryptography, <em>you better have both</em>!</p>



<h2 id="vulnerability">Timing Leaks in Proctorio’s AES-GCM Implementation</h2>



<p>If you download version 1.4.20241.1.0 of the Proctorio Chrome Extension, run <code>src/assets/J5HG.js</code> through a JS beautifier, and then look at its contents, you will quickly realize this is a JavaScript cryptography library.</p>



<p>Since the “zero knowledge” encryption they’re so proud about uses AES-GCM, let’s focus on that.</p>



<p>Proctorio’s AES-GCM implementation exists in an object called <code>dhs.mode.gcm</code>, which is mildly obfuscated, but contains the following functions:</p>



<ul><li><code>encrypt()</code> – Encrypt with AES-GCM</li><li><code>decrypt()</code> – Decrypt with AES-GCM</li><li><code>aa()</code> – GHASH block multiplication</li><li><code>j()</code> – XOR + GMAC utility function</li><li><code>O()</code> – Called by encrypt() and decrypt(); does all of the AES-CTR + GMAC fun</li></ul>



<p>If you’re not familiar with <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">AES-GCM</a>, just know this: <a href="https://cryptologie.net/article/361/breaking-https-aes-gcm-or-a-part-of-it/">Timing leaks</a> can be used to leak your GMAC key to outside applications, which completely breaks the authentication of AES-GCM and opens the door to chosen-ciphertext attacks.</p>



<p>So is their implementation of AES-GCM constant-time? Let’s take a look at <code>aa()</code>:</p>


<pre title="">aa: function(a, b) {
  var c, d, e, f, g, h = dhs.bitArray.ba;
  for (e = [0, 0, 0, 0], f = b.slice(0), c = 0; 128 &gt; c; c++) {
    for (
      (d = 0 !== (a[Math.floor(c / 32)] &amp; 1 &lt;&lt; 31 - c % 32)) &amp;&amp; (e = h(e, f)),
        g = 0 !== (1 &amp; f[3]),
        d = 3;
      d &gt; 0;
      d--
    )
      f[d] = f[d] &gt;&gt;&gt; 1 | (1 &amp; f[d - 1]) &lt;&lt; 31;
    f[0] &gt;&gt;&gt;= 1,
    g &amp;&amp; (f[0] ^= -520093696)
  }
  return e
},
</pre>


<p>This is a bit obtuse, but this line leaks the lowest bit of <code>f</code> with each iteration: <code>g = 0 !== (1 &amp; f[3])</code>.</p>



<p>Since <code>f</code> gets bitwise right-shifted 128 times, this actually leaks the bit of every value of <code>f</code> in each block multiplication, since the execution of <code>(f[0] ^= -520093696)</code> depends on whether or not <code>g</code> is set to <code>true</code>.</p>



<div><figure><img data-attachment-id="1387" data-permalink="https://soatok.blog/soatoktelegrams2020-11/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-11" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Timing leaks? So much for “zero-knowledge”!</figcaption></figure></div>



<p>Also, they claim to be FIPS 140-2 compliant, but this is how they generate randomness in their cryptography library.</p>



<figure><div>

</div></figure>



<p>(Although, <a href="https://csrc.nist.gov/projects/cryptographic-module-validation-program/validated-modules/search?SearchMode=Basic&amp;Vendor=Proctorio&amp;CertificateStatus=Active&amp;ValidationYear=0">that’s probably a lie</a>.)</p>



<p>To mitigate these vulnerabilities, one needs look no further than <a href="https://soatok.blog/2020/08/27/soatoks-guide-to-side-channel-attacks/#conditional-select">the guide to side-channel attacks</a> I published last month. </p>



<p>(Also, use WebCrypto to generate entropy! What the fuck.)</p>



<h2>If Proctorio is Insecure, What Should We Use Instead?</h2>



<p><strong>Nothing.</strong></p>



<p>Schools that demand students install spyware on their personal computers are only a step removed from domestic abusers who install stalkerware on their victims’ phones.</p>



<p>Proctorio isn’t the problem here, they’re only a symptom.</p>



<p>Schools that insist on violating the integrity and parental dominion of their students’ home computers are the problem here.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Zoom school is really showing how much of American Education is just about controlling and punishing children and not actually, you know, teaching and educating them</p>— Lawrence of A Labia (@lex_about_sex) <a href="https://twitter.com/lex_about_sex/status/1304156305398140928?ref_src=twsrc%5Etfw">September 10, 2020</a></blockquote></div>
</div><figcaption>Preach!</figcaption></figure>



<p>If you want to ensure the integrity of students’ education, try teaching them about consent and ethical computing. (Y’know, concepts that are fundamentally incompatible with the business model of Proctorio and Proctorio’s competitors.)</p>



<h2 id="timeline">Disclosure Timeline</h2>



<p>Really? <em>Really?</em></p>



<p>This was a zero-day disclosure, because full disclosure is the responsible choice when dealing with spyware. Don’t even @ me.</p>



<div><figure><img data-attachment-id="70" data-permalink="https://soatok.blog/soatok_stickerpack-hacker/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="soatok_stickerpack-hacker" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Disclaimer: This security research was conducted by Soatok– some furry on the Internet–while bored on his off-time and does not reflect the opinions of any company.</figcaption></figure></div>



<h2 id="sinkhole">Domains to Sinkhole</h2>



<p>If you’re looking to protect your home network from this spyware, here are a list of domains to sinkhole (i.e. with <a href="https://pi-hole.net/">Pi-Hole</a>).</p>



<ul><li>proctorauth.com</li><li>proctordata.com</li><li>getproctorio.com</li><li>proctor.io</li><li>proctor.in</li><li>az545770.vo.msecnd.net</li></ul>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450248</guid>
            <pubDate>Sat, 12 Sep 2020 06:09:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: WebGL Rubik's Snake]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24450171">thread link</a>) | @nopjia
<br/>
September 11, 2020 | https://www.iamnop.com/snake/ | <a href="https://web.archive.org/web/*/https://www.iamnop.com/snake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.iamnop.com/snake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450171</guid>
            <pubDate>Sat, 12 Sep 2020 05:49:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make a Harmonograph?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24449813">thread link</a>) | @alikayaspor
<br/>
September 11, 2020 | https://abakcus.com/diy/how-to-make-a-harmonograph/ | <a href="https://web.archive.org/web/*/https://abakcus.com/diy/how-to-make-a-harmonograph/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<div id="primary">
<main id="main">
<div data-elementor-type="single" data-elementor-id="951" data-elementor-settings="[]">
<div>
<section data-id="af02520" data-element_type="section">
<div>
<div>
<div data-id="2bf189ef" data-element_type="column">
<div>
<div>
<section data-id="8f0e9bd" data-element_type="section">
<div>
<div>
<div data-id="815ec86" data-element_type="column">
<div>
<div>
<div data-id="67b5cbf" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
<div>
<div>
<picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-500x750.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-683x1024.jpg.webp 683w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-300x450.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project.jpg.webp 800w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201152'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1152" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201152'%3E%3C/svg%3E" alt="How to make a harmonograph DIY Project" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-500x750.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-683x1024.jpg 683w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-300x450.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project.jpg 800w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg">
</picture>
 </div>
</div>
</div>


<div data-id="410565ac" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>This project belongs to a <a href="https://en.m.wikipedia.org/wiki/Computer_graphics">computer graphics</a> artist and researcher, Karl Sims, who is best known for using <a href="https://en.m.wikipedia.org/wiki/Particle_systems">particle systems</a> and <a href="https://en.m.wikipedia.org/wiki/Artificial_life">artificial life</a> in computer animation.</p>
<p>A harmonograph is a mechanical device that uses swinging pendulums to draw pictures, believed to be initially invented in 1844 by Scottish mathematician&nbsp;<a target="_blank" href="https://en.wikipedia.org/wiki/Hugh_Blackburn" rel="noreferrer noopener">Hugh Blackburn.</a>&nbsp;This 3-pendulum rotary type of harmonograph gives a wide variety of satisfying results. It is reasonably easy to build once you’ve settled on a design and have acquired the appropriate materials and tools. Harmonograph is a great project to do with kids and can result in endless experiments creating new geometric designs.</p>
<p><strong>Ingredients:</strong></p>
<ul><li><strong>Lumber</strong><ul><li>1 &nbsp; 3/4″ x 3’x3′ plywood for table top</li><li>4 &nbsp; 1½” x 1½” x 40″ for legs (about 14′ total)</li><li>4 &nbsp; 1½” x 8″ x 12″ for leg braces (about 4′ total)</li><li>4 &nbsp; 3/4″ x 4′ dowels for pendulums and pen lifter (make sure they are straight)</li><li>1 &nbsp; 3/4″ x 1½” x 30″ oak to cut for pendulum supports, and other</li><li>1 &nbsp; 11″ x 11″ x 1/8″ board for platform to hold paper</li></ul></li><li><strong>Hardware Store</strong><ul><li>3 &nbsp; 3/4″ x 5″ long metal pipe nipples (plumbing section)</li><li>3 &nbsp; 3/4″ to 1″ metal pipe bushings</li><li>3 &nbsp; 1″ steel clamps</li><li>4 &nbsp; 1¼” x 4″ metal plates (or 2&nbsp; 1¼” x 8″ plates cut in half)</li><li>1 &nbsp; large metal washer with 2½” outer diameter, 1″ inner diameter, for gimbal</li><li>1 &nbsp; screw-eye for pen lifter</li><li>various drill bits: 3″ circular, 3/4″, 1/8″, etc.</li><li>various #10 screws (1″, 1¼”, 1½”, 1¾”, 2″, 3″)</li><li>a few thin nails</li><li>tools: drill, saw, hammer, tape measure, file, sand paper, etc.</li></ul></li><li><strong>Sporting goods store:</strong><ul><li>2½ lb weights with 1″ hole, at least 8 of them</li></ul></li><li><strong>Art supplies store</strong>:<ul><li>2 &nbsp; 1/2″ x 1/4″ x 30″ balsa (and maybe a spare or two)</li><li>various pens such as: Silver Uni-Ball GEL Impact, and Staedtler Triplus Rollerball</li><li>some string and rubber bands</li><li>paper, 8½” x 11″ (or 9″ x 12″) some black, some white</li></ul></li></ul>
<h2>STEP 1</h2>
<p><strong>Table.</strong> Start by building a sturdy table. This table-top is a 3’x3′ square of 3/4″ thick plywood. The legs are 1½” x 1½” square and about 37″ long, with triangular braces cut from 1½” x 8″x 12″ wooden pieces. The legs are splayed out slightly to give the table strength and allow the rotary pendulum to swing without hitting a leg.</p>
<div><p><strong>Tip:</strong> screw and/or glue the braces to the legs first, and then cut their tops together at a slight angle with a table or circular saw. Adjust the leg lengths to give a table-top height of about 37″.</p><p><strong>Note:</strong> if you want to fit the table through doorways without taking off the legs, you might need slightly shorter legs and pendulums.</p></div>
<h2>STEP 2</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg">
</picture>
<figcaption><strong>Holes for Pendulums</strong>. Drill 3 holes of 3″ diameter through the table surface for the pendulums to hang through. The rotary pendulum’s hole should be centered in a corner about 8″ from each side just clear of the leg brace underneath. The other two holes should be aligned near the opposite edges, about 8″ from the common side, and 3″ from the other. You’ll need a particular sizeable circular drill bit for this. Alternatively, you can first drill a smaller hole, and then cut a wider opening with a jigsaw.</figcaption></figure>
<h2>Step 3</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg">
</picture>
<figcaption><strong>Plates to support pendulums</strong>. Mount two metal plates (about 1¼” x 4″) on the sides of the two lateral pendulum holes and drill a small indentation in each plate’s center. <p><strong>Tip:</strong> first, start the indentation in the metal plate with a small drill bit (such as 1/8″) and then continue with a larger bit (such as 1/4″). Be careful not to drill all the way through. Tip: unless you have a good drill press, it may be easier to position the indentations of the plates on the table after you create the fulcrum blocks with protruding screws below, because it can be harder to accurately position the screws in the blocks later to align with the indentations.</p></figcaption></figure>
<h2>Step 4</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20887%20665'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 887px) 100vw, 887px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20887%20665'%3E%3C/svg%3E" alt="" width="887" height="665" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-768x576.jpg 768w" data-lazy-sizes="(max-width: 887px) 100vw, 887px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg">
</picture>
<figcaption><strong>Pendulums.</strong> The rotary pendulum needs a gimbal mechanism that allows it to swing in any direction. This is made from a large metal washer with 2½” outer and 1″ inner diameter. The washer rests on screw tips protruding from under the table, and then the pendulum rests on the washer. Drill pairs of indentations into the washer on each side, off 90 degrees between the sides, to allow rocking on two perpendicular axes.<p>Here are views of the rotary pendulum gimbal from above and below the table. In the picture from below, note the oak blocks (3/4″ x 1½” x 5″) supporting the two screws (1¾” #10) protruding upwards and diagonally. File down the bottom edges of these blocks as needed, so the pendulum doesn’t hit them when it swings. Likewise, file down the corners of the fulcrum block if necessary so it doesn’t hit the table when swinging.</p></figcaption></figure>
<h2>Step 5</h2>
<figure><ul><li><figure><picture data-id="11158" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal-2/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11158" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal-2/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg">
</picture>
</figure></li><li><figure><picture data-id="11159" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11159" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg">
</picture>
</figure></li></ul><figcaption><strong>Gimbal.</strong> The rotary pendulum needs a gimbal mechanism that allows it to swing in any direction. This is made from a large metal washer with 2½” outer and 1″ inner diameter. The washer rests on screw tips protruding from under the table, and then the pendulum rests on the washer. Drill pairs of indentations into the washer on each side, off 90 degrees between the sides, to allow rocking on two perpendicular axes. <p>Here are views of the rotary pendulum gimbal from above and below the table. In the view from below, note the oak blocks (3/4″ x 1½” x 5″) supporting the two screws (1¾” #10) protruding upwards and diagonally. File down the bottom edges of these blocks as needed so the pendulum doesn’t hit them when it swings. Likewise file down the corners of the fulcrum block if necessary so it doesn’t hit the table when swinging.</p></figcaption></figure>
<h2>Step 6</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-300x400.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-300x400.jpg 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg">
</picture>
<figcaption><strong>Weights.</strong> 2½ lb lifting weights from a sporting goods store work well, but typically have a 1″ interior hole. You can stack several weights and slide them together onto the 3/4″ pendulum dowel by using a 5″ long 3/4″ metal pipe nipple, with a 3/4″ to 1″ bushing screwed onto the lower end. A 1″ steel clamp attached to the dowel fixes the weights from sliding off and allows easy adjustment of the weight’s height to give different swinging frequencies.</figcaption></figure>
<h2>Step 7</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-300x400.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-300x400.jpg 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg">
</picture>
<figcaption><strong>Paper Platform. </strong>Cut about 1″ off the top of the rotary pendulum dowel, so it is slightly lower than the other two. Then mount an 11″x11″ square of thin 1/8″ board to the top of this pendulum, using a small oak block glued to it for support, with a 3/4″ hole for the dowel. Wrap some tape around the dowel’s top to get a tight fit, or glue it on.<p>*** Use two rubber bands, or some clips, to hold the paper in place on the platform. If the form slips on the platform, spray a thin layer of temporary adhesive on the platform to make it slightly sticky.</p></figcaption></figure>
<h2>Step 8</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-300x400.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-scaled.jpg.webp 1536w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-300x400.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-1152x1536.jpg 1152w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-scaled.jpg 1536w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg">
</picture>
<figcaption><strong>Arms.</strong> Connect a 30″ long balsa stick to the top of each lateral pendulum using a thin nail. Bend the nail back and forth a little in the balsa to allow the arm to rotate smoothly and move up and down slightly. The nail hole will slowly loosen further during use.<p>To make a simple pen-holder, drill a 1/2″ hole on the end of one arm, and cut about 4″ down the arm’s center to make a clothes-pin like a device. Alternatively, glue a real clothes-pin to the end of one of the arms. Pictures of both versions are shown.</p><p>Finally, attach the two arms with a doubled-over rubber band, as shown.</p><p>Note that if you plan to use your harmonograph regularly, such as in a museum setting, a more robust solution for these arms that won’t wear as quickly might be necessary.&nbsp;</p><p><strong>Note:</strong>&nbsp;An alternate version of the arm-pendulum connection is shown to the right that uses a magnetic ball joint instead of the simple nail method above. Glue one 3/8″ spherical magnet to the arm (making sure the N/S alignment is horizontal by connecting a second magnet). File a hole in the side of a nylon cylinder (1″ height, 1/2″ outer and 3/8″ inner diameter) and use smaller cylinders (3/8″ outer diameter) to hold another magnet inside that can rotate freely. Then glue the cylinder to the top of the pendulum.</p></figcaption></figure>
<h2>Step 9</h2>
<figure><ul><li><figure><picture data-id="11163" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter-2/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-768x576.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg.webp 1600w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11163" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter-2/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-768x576.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1536x1152.jpg 1536w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg 1600w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg">
</picture>
</figure></li><li><figure><picture data-id="11164" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-300x400.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg.webp 1536w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-id="11164" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-300x400.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-1152x1536.jpg 1152w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg 1536w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg">
</picture>
</figure></li></ul><figcaption><strong>Pen Lifter.</strong> It is convenient to raise and lower the pen gently without disturbing the motion of the pendulums. To do this, insert a 30″ pole into a hole near the center of the table, just far enough from the paper platform that it won’t be hit by it (about 12″ from the rotary pendulum hole). Attach an oak block under the table for a deeper hole and better support. Tie a string to the balsa arms where they are connected, lead it through a screw-eye on top of the pole, and back down to a small jam cleat or groove where it can hold the pen in place above the paper until you are ready to lower it.</figcaption></figure>
<h2>Step 10</h2>
<p><strong>Pens.</strong> Experiment with pens and markers of various types and colors. Generally, wide pens or thin markers seem to work best. Here are some I’ve had good luck with so far:</p>
<ul><li>Uniball GEL Impact in Silver, use on black or dark paper.</li><li>Staedtler Triplus Rollerball Pens (.4mm) in various colors</li><li>Pigma Graphic 1 (1.0mm) in black</li><li>Sakura Identi Pen in black, purple, etc.</li></ul>
<p>but many other types of pens may also work well.</p>
<h2>Adjustments</h2>
<p><strong>Weight Height</strong>. Adjust a pendulum’s weight height to change its swinging frequency. The frequency of a pendulum varies with the inverse of the square root of its length, so to swing twice as fast, the length between the fulcrum and its center-of-mass would need to be 1/4 of the original length (which may not be practical with this harmonograph). For a 3:2 or 4:3 frequency increase, the weights would be raised around 19″ or 15″ respectively, although you should probably do some timing tests to find and mark these heights experimentally.</p>
<p><strong>Weight Amount</strong>. Add more weight to a pendulum to counteract friction and make the swinging last longer. I’ve found that 5 lb (2 x 2½) on the rotary pendulum, and 7½ lb (3 x 2½) on the other two works reasonably well. Note that adding more weight does not generally change the frequency of the pendulum.</p>
<p><strong>Phase and Amplitude</strong>. Each time you swing the pendulums to make a new drawing, each pendulum’s relative phases, and amplitudes will vary. Try somewhere the rotary pendulum, and the lateral pendulums are initially making circles in the same or opposite directions. Try somewhere the lateral pendulums are initially swinging in phase to make a diagonal line.</p>
<h2>Results</h2>
<p><strong>Two-pendulum results</strong>. To simplify things, you can lock …</p></div></div></div></div></div></div></div></section></div></div></div></div></div></section></div></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abakcus.com/diy/how-to-make-a-harmonograph/">https://abakcus.com/diy/how-to-make-a-harmonograph/</a></em></p>]]>
            </description>
            <link>https://abakcus.com/diy/how-to-make-a-harmonograph/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24449813</guid>
            <pubDate>Sat, 12 Sep 2020 04:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is benchmarketing and why is it bad?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24449144">thread link</a>) | @bitsondatadev
<br/>
September 11, 2020 | https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/ | <a href="https://web.archive.org/web/*/https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>There's something I have to get off my chest. If you really need to, just read the TLDR and listen to the Justin Bieber parody posted below. If you’re confused by the lingo, the rest of the post will fill in any gaps.</p><div><p>TL;DR: Benchmarketing, the practice of using benchmarks for marketing, is bad. Consumers should run their own benchmarks and ideally open-source them instead of relying on an internal and biased report.</p><p>Enjoy the song I wrote about this silly practice.</p></div><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/FSy8V-R0_Zw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>For the longest time, I have wondered what is the point of corporations, specifically in the database sectors, running their own benchmarks. Would a company ever have any incentive to post results from a benchmark that didn't show its own system winning in at least the majority of cases? I understand that these benchmarks have become part of the furniture we come to expect to see when visiting any hot new database's website. I doubt anybody in the public domain gains much insight out of these results, to begin with, at least nothing they weren't expecting to see. </p><p>Now to be clear, I am in no way indicating that companies running their own internal benchmarks to analyze their own performance in comparison to their competitors is a bad thing. It’s when they take those results and intentionally skew the methods or data from these benchmarks for sales or marketing purposes that is the problem we’re discussing here. Vendors that take part in the practice, not only use these benchmarks to show their systems succeeding a little but rather perversely taint their methodology with settings, caching, and other performance enhancements, while leaving their competition’s settings untouched. </p><p>This should be obvious that this is NOT what benchmarking is about! If you read about the history of the <a href="http://www.tpc.org/information/about/history5.asp">Transaction Processing Performance Council (TPC)</a> you come to understand that this is the very wrongdoing that the council was created to address. But like with any proxy involving measurements, the measurements are inherently pliable.</p><blockquote>By the spring of 1991, the TPC was clearly a success. Dozens of companies were running multiple TPC-A and TPC-B results. Not surprisingly, these companies wanted to capitalize on the TPC's cachet and leverage the investment they had made in TPC benchmarking. Several companies launched aggressive advertising and public relations campaigns based around their TPC results. In many ways, this was exactly why the TPC was created: to provide objective measures of performance. What was wrong, therefore, with companies wanting to brag about their good results? What was wrong is that there was often a large gap between the objective benchmark results and their benchmark marketing claims--this gap, over the years, has been dubbed "benchmarketing." So the TPC was faced with an ironic situation. It had poured an enormous amount of time and energy into creating a good benchmark and even a good benchmark review process. However, the TPC had no means to control how those results were used once they were approved. The resulting problems generated intense debates within the TPC.</blockquote><p>This benchmarketing ultimately fails the clients that these companies are marketing to. It demonstrates not only a lack of care for addressing the users' actual pain but a lack of respect by intentionally pulling the wool over their eyes simply in an attempt to mask that their performance isn't up to par with their competitors. <strong>This leads to consumers not being able to make informed decisions as most of our decisions are made from gut instincts and human emotion which these benchmarks aim to manipulate.</strong></p><p>If you’re not sure exactly how a company would pull this off, an example of might be that database A enables using a cost-based optimizer that requires precomputing statistics about different tables involved in the computation, while database B is running a query against this table without any type of stats based optimization made available to it. Database A will clearly dominate as now it can reorder joins and apply better execution plans while database B is going to go with the simplest plan and run much slower in most scenarios. The company whose product depends on database A will then hone in on the numerical outcomes of this report. Even if they're decent enough to report the methods they skewed to get these results, they bury it within their report and focus on advertising the outcome of what would otherwise be considered an absurd comparison. Companies will even go as far as to say that their competition's database wasn't straight forward to configure when they were setting up optimizations. If you're not capable of understanding how to make equivalent changes to both systems, well then I guess you don't get to run that comparison until you figure it out. &nbsp;</p><p>Many think that consumers are not susceptible to such attacks and would be able to see right through this scheme, but these reports appeal to any of us when we don't have the necessity or resources to thoroughly examine all the data. Many times we have to take cues from our gut when a decision needs to be made and the time to make it is constrained by our time and other business needs. We see this type of phenomenon described in the book, <em>Thinking Fast and Slow</em> by Daniel Kahneman. To briefly summarize the model they use, there are two modes that humans use when they reason about their decisions, System 1 and System 2.</p><blockquote>Systems 1 and 2 are both active whenever we are awake. System 1 runs automatically and System 2 is normally in comfortable low-effort mode, in which only a fraction of its capacity is engaged. System 1 continuously generates suggestions for System 2: impressions, intuitions, intentions, and feelings. If endorsed by System 2, impressions and intuitions turn into beliefs, and impulses turn into voluntary actions. When all goes smoothly, which is most of the time, System 2 adopts the suggestions of System 1 with little or no modification. You generally believe your impressions and act on your desires, and that is fine — usually.</blockquote><p>No surprise, that’s usually the part where we get into trouble. While we like to think that we are generally thinking in the logical System 2 mode, we don't have time or energy to live in this space for long periods throughout the day and we find ourselves very reliant on System 1 for much of our decision making.</p><blockquote>The measure of success for System 1 is the coherence of the story it manages to create. The amount and quality of the data on which the story is based are largely irrelevant. When information is scarce, which is a common occurrence, System 1 operates as a machine for jumping to conclusions.</blockquote><p>This is why benchmarketing can be so dangerous because it is so effective at manipulating our belief in claims that simply aren't true. These decisions affect how your architecture will unfold, your time-to-value, and lost hours for your team and customers. It makes having these systems that fairly compare the performance and merits of two systems all-the-more paramount.</p><figure><img src="http://bitsondata.dev/content/images/2020/09/significant.png" alt=""><figcaption><a href="https://xkcd.com/882/">https://xkcd.com/882/</a></figcaption></figure><p>So why am I talking about this now?</p><p>I have become a pretty big fanboy of a <a href="https://prestosql.io/">Presto</a>, a distributed query engine that runs interactive queries from many sources. I have witnessed firsthand how fast a cluster of Presto nodes are able to process through a huge amount of data at blindingly fast speeds. When you dive into how these speeds are achieved you find that this project is an incredible modern feat of solid engineering that makes interactive analysis over petabytes of data a reality. Going into all the reasons I like this project would be too tangential but it fuels the fire for why I believe this message needs to be heard.</p><p>Recently there was a "benchmark" that came out comparing the performance of a commercial competitor and Presto open-source and enterprise versions, touting performance improvements over Presto by an amount that would have been called out as too high in a CSI episode <a href="https://www.youtube.com/watch?v=hkDD03yeLnU">&lt;insert canonical csi clip here&gt;</a>. If you need to find out what I’m talking about, simply google "presto benchmark 3000" and you will find the benchmark along with plenty of other hype they've generated around these "findings". <a href="https://blog.yugabyte.com/yugabytedb-vs-cockroachdb-bringing-truth-to-performance-benchmark-claims-part-1/">Presto isn't the only system in the data space to come under similar types of attacks.</a> It makes sense too, as this type of technical peacocking is common as it successfully gains attention. </p><p>Luckily, as more companies strive to become transparent and associate themselves with open-source efforts, we are starting to see a relatively new pattern of open-source efforts emerge. Typically, you're used to hearing about open-source within the context of software projects maintained by open-source communities. We are now arriving at the age of any noun being able to be used in an open-source framework. There is open-source music, open-source education, and even open-source data. So why not reach a point where open-source benchmarking through consumer collaboration is a thing. This is not just for the sake of the consumers of these technologies who simply want to have more data to inform their design choices to better serve their clients, it's also unfortunate that this affects developer communities that are putting in a lot of hard work on these projects, only to have that hard work get berated unintelligibly by the likes of some corporate status competition.</p><p>Now I'm clearly a little biased when I tell you that I think Presto is currently the best analytics engine on the market today. When I say this, you really should be skeptical too. Really, I encourage it. You should verify in some way beyond a shadow of a doubt that:</p><p> &nbsp;1. Any TPC or other benchmarks are validated and no "magic" was used to improve their performance.</p><figure></figure><p> &nbsp;2. using your own use cases to make sure the system you choose is going to meet the needs of your particular use case.<br></p><p>While this may seem like a lot of work, with cloud infrastructure and simplicity of deploying different …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/">https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/</a></em></p>]]>
            </description>
            <link>https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24449144</guid>
            <pubDate>Sat, 12 Sep 2020 01:42:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I used GCP to create the transcripts for my Podcast]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24448922">thread link</a>) | @simonebrunozzi
<br/>
September 11, 2020 | https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/ | <a href="https://web.archive.org/web/*/https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-577">
		<div>
		<p><span><span>Reading Time: </span> <span>4</span> <span>minutes</span></span></p><p>I’m currently working on a series of episodes for a Podcast I’ll be publishing soon. The Podcast will be in Italian and I wanted to make sure to publish the episode transcripts together with the audio episodes.</p>



<p>The idea of manually typing all the episodes text wasn’t really appealing to me so I started looking around.</p>



<h2>What are the tools out there?</h2>



<p>From a quick Google search, it seems that some companies are offering a mix of automated and human-driven transcription services.</p>



<p>I wasn’t really interested in that for now. I was, of course, just interested in consuming an API I could push my audio to and get back some text in a reasonable amount of time.</p>



<p>For this reason, I started looking for <em>speech-to-text</em> APIs and, of course, the usual suspects figured among the first results.</p>



<ul><li><a href="https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/">Microsoft Cognitive Services</a></li><li><a href="https://www.ibm.com/cloud/watson-speech-to-text">IBM Watson Speech-to-Text</a></li><li><a href="https://www.speechmatics.co/">SpeechMatics</a></li><li><a href="https://aws.amazon.com/transcribe/">Amazon Transcribe</a></li><li><a href="https://cloud.google.com/speech-to-text">Google Cloud Speech-to-Text</a></li></ul>



<p>To be quite honest, I didn’t spend too much time investigating the solutions above. I probably spent more time reading about them to write this blog post.</p>



<p>I decided to go with Google Cloud because I’ve never used GCP before and wanted to give it a try. Additionally, the documentation for it seemed quite straightforward, as well as the support for Italian as language to transcribe from (the podcast is in Italian). I also had a few free credits available because I’ve never used GCP for personal use before.</p>



<h2>Setting up</h2>



<p>If you want to try transcribing your episodes too, follow this quick setup guide to get started.</p>



<p>Head over to <a href="https://cloud.google.com/">Google Cloud</a> and set up an account. Make sure you create a project and enable the Speech-to-Text API. If you forget to do so <code>gcloud</code> will be able to take care of that for you, later.</p>



<div><figure><img loading="lazy" width="509" height="99" src="https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59.png" alt="Google Cloud Speech-to-Text" srcset="https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59.png 509w, https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59-300x58.png 300w" sizes="(max-width: 509px) 100vw, 509px"><figcaption>Google Cloud Speech-to-Text</figcaption></figure></div>



<p>Second thing I did was installing <code><a href="https://cloud.google.com/sdk/docs/quickstarts">gcloud</a></code>, the CLI Google Cloud provides for interacting with the APIs. This time I was only interested in testing the API so it seemed to me that this tool was the only way to get started quickly.</p>



<p>Additionally, there’s not much you can do from the Google Cloud Web Console if you want to deal with Speech-to-Text APIs.</p>



<h3>Get your file ready for transcription</h3>



<p>Sampling rate for your audio file should be at least 16 kHz for better results. Additionally, GCP recommends a lossless codec. I only had an mp3 of my episode handy at the time so I gave it a try anyway and it worked well enough.</p>



<p><strong>Make sure you know the sample rate of your file, though, because specifying a wrong one might lead to poor results.</strong></p>



<p>You can usually verify the sample rate by getting info on your file from your Mac’s Finder:</p>







<p>You can read more about the recommended settings on the <a href="https://cloud.google.com/speech-to-text/docs/best-practices">Best Practices</a> section.</p>



<h3>Upload your episode to the bucket</h3>



<p>GCP needs your file to be available from a Storage Bucket so, go ahead and <a href="https://cloud.google.com/storage/docs/creating-buckets">create one</a>.</p>



<figure><img src="https://cloud.google.com/storage/images/create-bucket.png" alt=""><figcaption>Storage Bucket creation example</figcaption></figure>



<p>You’ll be able to upload your episode from there.</p>



<h2>Time to transcribe</h2>



<p>Once you have your episode file up there in the cloud go back to your local machine terminal were you have configured the <code>gcloud</code> tool.</p>



<figure><img loading="lazy" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1024x175.png" alt="" width="580" height="99" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1024x175.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-300x51.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-768x131.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1536x263.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1.png 2048w" sizes="(max-width: 580px) 100vw, 580px"><figcaption>Gcloud used to trigger the speech-to-text transcription</figcaption></figure>



<p>If your episode lasts longer than 60 seconds (😬) you’ll want to use <code>recognize-long-running</code> and most likely specify <code>--async</code>. </p>



<p>As I said before, make sure you specify the right <code>--sample-rate</code>: in my case 44100. This will help GCP transcribe your file with better results.</p>



<p>The <code>--async</code> switch creates a long-running asynchronous operation. It took around 5 minutes for me to have the operation complete. </p>



<p>Oddly, I wasn’t able to find any reference to the asynchronous operation from my Google Cloud Console. So, if you want to be able to know what happened to your transcription job, make sure you take note of the operation identifier. You’ll need it to query the <code>speech operations</code> API for information about your transcription job.</p>



<figure><img loading="lazy" width="1024" height="268" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1024x268.png" alt="" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1024x268.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-300x79.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-768x201.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1536x402.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The speech operation metadata</figcaption></figure>



<h2>The transcribed data</h2>



<p>Once your transcription operation is complete the <code>describe</code> command will return the transcript excerpts, together with the confidence rate.</p>



<figure><img loading="lazy" width="1024" height="641" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1024x641.png" alt="" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1024x641.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-300x188.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-768x481.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1536x962.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The speech transcript excerpt</figcaption></figure>



<p>I wasn’t particularly interested in the <code>confidence</code> rate, I only wanted a big blob of text to be able to review and use for SEO purposes as well as to be able to include it with the episode. For this reason, <strong><em>jq to the resque!</em></strong></p>



<p>I love <code><a href="https://stedolan.github.io/jq/">jq</a></code>, you can achieve so much with when it comes to manipulate JSON.</p>



<p>In my case, I only wanted to concatenate all the <code>transcript</code> fields and save them to a file. Here’s how I did:</p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$ ./bin/gcloud ml speech operations describe &lt;your-transcription-operation-id&gt; | jq '.response.results[].alternatives[].transcript' &gt; my-transcript.txt</pre>



<p>And that’s it!</p>



<h2>Conclusion</h2>



<p>I thought of sharing the steps above because they’ve been useful to me in producing the transcripts. I think GCP Speech-to-Text works quite well with Italian but, of course, the transcript is not suitable to be used as it is, unless your accent is perfect. Mine wasn’t 😅.</p>



<p>If you want to know more about my journey towards publishing my first podcast <strong><a href="https://twitter.com/alediaferia">follow me on Twitter</a></strong> were I’ll be sharing more about it.</p>



<p>Photo by <a href="https://unsplash.com/@maltewingen?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Malte Wingen</a> on <a href="https://unsplash.com/s/photos/podcast?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448922</guid>
            <pubDate>Sat, 12 Sep 2020 00:58:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sketching Algorithms for High Dimensional, Large Datasets]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24448669">thread link</a>) | @ArtWomb
<br/>
September 11, 2020 | https://www.sketchingbigdata.org/fall20/ | <a href="https://web.archive.org/web/*/https://www.sketchingbigdata.org/fall20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            



<h2 id="cs-294-165-fall-2020-syllabus-fall20-syllabus">CS 294-165 - Fall 2020 (<a href="https://www.sketchingbigdata.org/fall20/syllabus">Syllabus</a>)</h2>

<p><strong><strong>Sketching algorithms</strong></strong> compress data in a way that is still useful for answering some pre-specified family of queries, possibly across datasets by comparing sketches. This course will cover mathematically rigorous models for developing such algorithms, as well as some provable limitations of algorithms operating in those models. Some topics covered include:</p>

<ul>
<li><p><strong>Streaming algorithms.</strong> Compute useful statistics over a dataset making only one pass over it, while using little memory.</p></li>

<li><p><strong>Dimensionality reduction.</strong> General techniques and impossibility results for reducing data dimension while still preserving geometric structure.</p></li>

<li><p><strong>Randomized linear algebra.</strong> Algorithms for big matrices (e.g. a user/product rating matrix for Netflix or Amazon). Regression, low rank approximation, clustering, etc.</p></li>

<li><p><strong>Compressed sensing.</strong> Recovery of (approximately) sparse signals based on few linear measurements.</p></li>
</ul>

<p>This is a graduate course, though there may be room for a limited number of advanced undergraduate students satisfying the following prerequisites: mathematical maturity and comfort with algorithms (e.g. CS 170), discrete probability, and linear algebra.</p>

</div></div>]]>
            </description>
            <link>https://www.sketchingbigdata.org/fall20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448669</guid>
            <pubDate>Sat, 12 Sep 2020 00:08:38 GMT</pubDate>
        </item>
    </channel>
</rss>
