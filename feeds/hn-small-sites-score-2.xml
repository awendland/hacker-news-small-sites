<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 25 Jan 2021 09:10:07 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 25 Jan 2021 09:10:07 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Raspberry Pi as x2go “thin” client]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25881126">thread link</a>) | @indigodaddy
<br/>
January 23, 2021 | http://www.multi-seat.com/x2go/ | <a href="https://web.archive.org/web/*/http://www.multi-seat.com/x2go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-45" class="page">
	<!-- .entry-header -->
	<div>
		
<p><a href="https://wiki.x2go.org/doku.php/download:start">https://wiki.x2go.org/doku.php/download:start</a></p>



<p>X2GO is one of the easiest open source remote access applications to  install on Linux, including on the Raspberry Pi 3B/4B. If the host is  LinuxMint and the client is a Raspberry PI, you can have both the  LinuxMint panel on the bottom of the client screen as well as the  Rasbian panel on the top of the screen – that way you can run both  local and remote apps at the same time in a split screen,  or even full screen  on separate client  monitors, or x2go client window spanning both monitors.</p>



<p>The x2goserver can handle multiple  simultaneous client computers with distinct usernames and their home  directories – rather like thin clients without PXE booting. X2GO is not   integrated into the loginctl multi-seat system but functions beside  that capability. Thus the multi-seat behavior of the client is handled by the x2goserver but initiated by the x2go client,&nbsp; not the&nbsp; host side that loginctl controls. The Raspberry Pi 4B is fast enough to be used as a full desktop and supports two HDMI monitors. It only needs to become an x2go client of an x2go server when it needs more computing power or to save files. Its window on the server can span both monitors, or stay on one of the monitors so that the user can run apps both locally and remotely on the server at the same time, moving the mouse to control which desktop the keyboard is connected to.</p>



<p>While there is a x2goclient for Windows computers, there is no  x2goserver for Windows computers.  Supporting multiple independent client sessions would violate a  Windows single workstation license. The Windows malware problem can be  solved by running Windows as a guest OS under VirtualBox on a Linux  host server. Then there is no need for the Windows OS to be connected to the  internet because you can use the browser on the Raspbian local client desktop  when needed.</p>



<p>If multiple  network cards on the x2goserver, the default is to  listen on all for clients. With lots of simultaneous clients, you might want to configure the server to separate server internet traffic from  client traffic.</p>



<p><strong>Installation of server on Linux Mint 19:</strong></p>



<pre>asm32@M5A88-M:~$ sudo apt-get install x2goserver x2goserver-xsession
[sudo] password for (username):

... skipping output during installation process ...
 
asm32@M5A88-M:~$</pre>



<pre>asm32@M5A88-M:~$ sudo service x2goserver start
[sudo] password for (username): 
asm32@M5A88-M:~$
</pre>



<p>or, alternatively,</p>



<pre>asm32@M5A88-M:~$
asm32@M5A88-M:~$sudo systemctl start x2goserver
asm32@M5A88-M:~$</pre>



<p>To make it start automatically on boot:</p>



<pre>asm32@M5A88-M:~$ sudo update-rc.d x2goserver defaults
[sudo] password for asm32: 
asm32@M5A88-M:~$</pre>



<p><strong>Installation of client on Raspberry Pi3 B+&nbsp; running <strong>Raspberry Pi OS</strong></strong> <strong>with Desktop:</strong></p>



<p>x2goclient is already in the Raspberry Pi Raspberry Pi OS&nbsp; repository, so all that is needed is</p>



<pre>pi@raspberrypi:~ $ sudo apt-get install x2goclient</pre>



<p>Once installed, there will be a new menu item under Internet category.</p>



<p>When configuring x2goclient sessions, you can use server hostnames instead of IP addresses. There can be more than one server on a LAN but hostnames must be unique.</p>



<p><strong>X2goclient as Raspberry Pi software zeroclient!</strong></p>



<div><p>A new raspberry pi is approximately 1/3 the cost of a new network attached zero client. Raspberry Pi could be configured to initiate an x2goclient session immediately, much like a hardware zero client, with the difference  that the x2go client provides the login screen instead of the server. </p><p>You will want to install the perl script, wakeonlan, so that you can wake up the desktop server from any of the Pi zero clients. I have edited my version so that the desired server MAC address is in the script instead of needed on the command line or in a separate file.</p></div>



<p>While x2goclient is trivial to install on a Raspberry Pi with a desktop environment, for a single purpose network attached zero client, it is not required to have a windows manager and desktop environment so you could use the <strong>Raspberry Pi OS (32-bit) Lite</strong> image at 432 MB (compared to the desktop version at 1128 MB).</p>



<p>Download here: <a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/"><strong>https://www.raspberrypi.org/downloads/raspberry-pi-os/</strong></a></p>



<p>Once you have downloaded and flashed a MicroSD card with this and done the initial configuration at first boot on the Raspberry Pi, add the following:</p>



<pre><code>sudo apt-get install --no-install-recommends xserver-xorg</code></pre>



<pre><code>sudo apt-get install --no-install-recommends xinit</code></pre>



<div><p>To start up the xserver automatically, edit the file .bashrc to append the line “/usr/bin/startx” without the quotes.</p><p>Next edit the file .xinitrc to delete or make a comment the line “. /etc/X11/Xsession” and append a new line ” /usr/bin/x2goclient –thinclient –session=session-name” without the quotes. The second option launches a named session that you have setup already. Leave this option off if you have more than one server and the user needs to choose a session. If you have more than one user, you should not fill in the user name for the session. If you have only one server and one user (you are using this to remotely administer the server, perhaps) then you can set up automatic login so that the Raspberry Pi boots directly to a desktop of the remote server computer.</p></div>



<p><strong>Auto login with ssh rsa</strong></p>



<figure><img loading="lazy" width="1024" height="570" src="http://www.multi-seat.com/wp-content/uploads/2020/07/x2go-autologin-1024x570.jpg" alt="" srcset="http://www.multi-seat.com/wp-content/uploads/2020/07/x2go-autologin-1024x570.jpg 1024w, http://www.multi-seat.com/wp-content/uploads/2020/07/x2go-autologin-300x167.jpg 300w, http://www.multi-seat.com/wp-content/uploads/2020/07/x2go-autologin-768x427.jpg 768w, http://www.multi-seat.com/wp-content/uploads/2020/07/x2go-autologin-1536x854.jpg 1536w, http://www.multi-seat.com/wp-content/uploads/2020/07/x2go-autologin.jpg 1812w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<div><p>Assuming you already have a x2go session working with login, several things in the x2go session are needed for auto login to work. You most have a username (server end) or it will not know where to look for the authorized public key on the server end. It is preferable to check the box for “Try auto login” and leave the path entry  just above empty so that it will use the default location.  There can be multiple authorized public keys on the server – it will look for the one matching the client private key. There can also be multiple client sessions, each with a different private key. It is the client end (at possibly multiple separate workstations) that initiates the conversation with the server.</p><p><strong>Setting up private and public keys</strong></p></div>



<pre>pi@raspberrypi:~ $ ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/home/pi/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /home/pi/.ssh/id_rsa.
Your public key has been saved in /home/pi/.ssh/id_rsa.pub.
The key fingerprint is:
[edited out for my privacy]
The key's randomart image is:
+---[RSA 2048]----+
[edited out for my privacy]
+----[SHA256]-----+
pi@raspberrypi:~ $

pi@raspberrypi:~ $ ls .ssh/ -l
total 8
-rw------- 1 pi pi 1823 Jul 12 17:49 id_rsa
-rw-r--r-- 1 pi pi 396 Jul 12 17:49 id_rsa.pub
pi@raspberrypi:~ $</pre>



<p>Having generated these keys at the client end, they need to be installed at both ends. In my case asm32@asus-centos7 is my username on my server hostname.</p>



<pre>pi@raspberrypi:~ $ ssh-copy-id asm32@asus-centos7
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/pi/.ssh/id_rsa.pub"
The authenticity of host 'asus-centos7 (192.168.10.105)' can't be established.
ECDSA key fingerprint is SHA256: [edited out for my privacy]
Are you sure you want to continue connecting (yes/no)? yes
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
asm32@asus-centos7's password:
Number of key(s) added: 1
Now try logging into the machine, with: "ssh 'asm32@asus-centos7'"
and check to make sure that only the key(s) you wanted were added.
pi@raspberrypi:~ $ ssh 'asm32@asus-centos7'
Last login: Sun Jul 12 17:52:03 2020
[asm32@asus-centos7 ~]$ ls -l .ssh/
total 4
-rw-------. 1 asm32 asm32 396 Jul 12 17:56 authorized_keys
[asm32@asus-centos7 ~]$
[asm32@asus-centos7 ~]$ exit
logout
Connection to asus-centos7 closed.
pi@raspberrypi:~ $ ls -l .ssh/
total 12
-rw------- 1 pi pi 1823 Jul 12 17:49 id_rsa
-rw-r--r-- 1 pi pi 396 Jul 12 17:49 id_rsa.pub
-rw-r--r-- 1 pi pi 444 Jul 12 17:55 known_hosts
pi@raspberrypi:~ $</pre>



<p>Note that after the client end command,  ssh-copy-id,  the public key has been added to the server end .ssh/authorized_keys and the client end now has a .ssh/known_hosts.</p>



<p>The right panel of x2goclient has all the sessions you have configured. When you select one of these, it will move to the blue left panel. With auto login, it will immediately start to connect to the server.  If you leave it in the left panel when you exit the session, then the next invocation of x2goclient will immediately attempt to connect to the server. In the case of a <strong>Raspberry Pi OS (32-bit) Lite</strong> installation as described above, the Pi will boot directly into connecting to its configured session on the server – similar to the Phistek ZE7000 network attached zero client at less than 1/3 the hardware cost.</p>



<p>The Phistek ZE7000 has superior video performance. Its silicon USB over IP chip is transmitting compressed USB over IP protocol, whereas the x2go method is transmitting compressed X protocol graphic primitives which is more efficient for non video applications.</p>




	</div><!-- .entry-content -->
</article><!-- #post-45 -->

		</main><!-- #main -->
	</div><!-- #primary -->
</div><!-- .wrap -->


		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>http://www.multi-seat.com/x2go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881126</guid>
            <pubDate>Sat, 23 Jan 2021 10:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin Core Lead Maintainer Steps Back, Encourages Decentralization]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25880727">thread link</a>) | @runeks
<br/>
January 23, 2021 | https://laanwj.github.io/2021/01/21/decentralize.html | <a href="https://web.archive.org/web/*/https://laanwj.github.io/2021/01/21/decentralize.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recent events have made me reflect on a few things in my life I was already thinking about for a while. Also, responses on social media have made me realize that people have <em>strange</em> expectations from me, and what my role in the Bitcoin Core project is.</p>

<h2 id="growth">growth</h2>

<p>Bitcoin has grown a lot since I started contributing to it in 2011. Some arrangements that were acceptable for a small scale FOSS project are no longer so for one runing a 600 billion dollar system. Market cap is famously deceptive, but my point is not about specific numbers here.</p>

<p>One thing is clear: this is a serious project now, and we need to start taking decentralization seriously.</p>

<h2 id="moving-on">moving on</h2>

<p>I realize I am myself somewhat of a centralized bottleneck. And although I find Bitcoin an extremely interesting project and believe it’s one of the most important things happening at the moment, I also have many other interests. It’s also particularly stressful and I don’t want it, nor the bizarre spats in the social media around it, to start defining me as a person.</p>

<h2 id="spreading-out">spreading out</h2>

<p>I will start by delegating my own tasks, and decreasing my involvement. I do not intend to stop contributing to Bitcoin, or even to the Bitcoin Core project, but I would like to remove myself from the critical path and take (even more) of a background role.</p>

<p>Note that we had a nice growth in development activity, and that maintenance of the code itself has already been spread over multiple people for a while. I’m not the most active maintainer. Looking at the number of git merges</p>

<div><div><pre><code>bitcoin<span>$ </span>git log <span>--pretty</span><span>=</span><span>"format:%cn"</span> <span>--merges</span> <span>--since</span><span>=</span>2020-01-01 | <span>sort</span>| <span>uniq</span> <span>-c</span>
    313 fanquake
     51 Jonas Schnelli
    727 MarcoFalke
      7 Pieter Wuille
     65 Samuel Dobson
    363 Wladimir J. van der Laan
</code></pre></div></div>

<p>Only about 24% of the merges were done by me, last year.</p>

<h2 id="plans">plans</h2>

<p>But there’s plenty of things left to figure out, from the top of my head:</p>

<ul>
  <li>
    <p>Decentralize distribution.</p>

    <ul>
      <li>
        <p>In the short run, transfer bitcoincore.org to an organization instead of private ownership. Reduce the “bus factor”.</p>
      </li>
      <li>
        <p>I think it would be good if some other organizations set up mirrors, so there is less incentive to try to take bitcoincore.org down.</p>
      </li>
      <li>
        <p>In the long run, move away from a website for code distribution completely. No matter who owns it, a website on the clearnet can be shut down with the press of a button, and it seems that the global internet is gearing up to make censorship increasingly easy. We need a decentralized web. For us, one option would be IPFS, which is starting to catch on. For the binaries themselves there’s already the option of downloading through torrents.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the release process, and release signing.</p>

    <ul>
      <li>
        <p>Delegate more parts of the release process. Other maintainers should be able to do a release without my involvement.</p>
      </li>
      <li>
        <p>Rename the GPG key used to sign <code>SHA256SUMS.asc</code> to “Bitcoin Core release signing key”, instead of having it in my personal title. Make some construct so that N of M (minimally) trusted gitian signers doing a succesful build automatically results in a signed distribution.</p>
      </li>
      <li>
        <p>Same for the native code signing for Windows and MacOS.</p>
      </li>
      <li>
        <p>Even better in the long run would be to split up the keys, e.g. though RSA threshold signing, so that the whole process is geographically distributed.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the development hub.</p>

    <ul>
      <li>It’s not clear whether github can be trusted to act in our interest in the long run. Although issues and PRs are backed up through the API, having to move somewhere else could give significant interruption in development. And hopping from provider to provider would be awful—ideally the whole thing would not rely on a central server <em>at all</em>. For this I’ve been watching the <a href="https://radicle.xyz/">radicle</a> project, a P2P distributed code collaboration platform. It’s not quite there yet, but seems promising.</li>
    </ul>
  </li>
</ul>

<p>Bitcoin is quite different in some of the requirements here from other FOSS projects, so we’ll have to develop some tools as we go. We could also, definitely, use some help here.</p>

<p>Some smaller things to consider:</p>

<ul>
  <li>
    <p>Find someone else who wants to do the IRC meeting chair instead of me. Or maybe rotate it between multiple people.</p>
  </li>
  <li>
    <p>Release (and release candidate) mails to the <code>bitcoin-dev</code> and <code>bitcoin-core-dev</code> lists will no longer be necessarily signed and sent by me.</p>
  </li>
  <li>
    <p>There’s some development specific tooling hosted by me (e.g. the PR notification bots on IRC and mastodon). As they are non-critical and only little time goes into maintaining them, I’m fine with this for now.</p>
  </li>
</ul>

<p>As for decentralizing Bitcoin’s node software itself:</p>

<ul>
  <li>Carl Dong’s <code>libbitcoin_kernel</code> work. Bitcoin Core is a large monolithic project which includes the consensus code, which is much more critical than the other parts. The kernel would be an isolated part with well-defined interface, and at some point, its own review flow for changes. The difference with previous <code>libbitcoin_consensus</code> plans is that the kernel is stateful: it includes UTXO management and validation. It however does not include P2P, mempool policy, wallet, GUI, and RPC code. It could be re-used in different clients, to have more diversity in clients, but without the risks of a deviating consensus implementation.</li>
</ul>

<p>Over the course of 2021 this will be my focus with regard to Bitcoin Core.</p>

  </div></div>]]>
            </description>
            <link>https://laanwj.github.io/2021/01/21/decentralize.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25880727</guid>
            <pubDate>Sat, 23 Jan 2021 08:45:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp facing up to €50M privacy fine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25880609">thread link</a>) | @gr2zr4
<br/>
January 23, 2021 | https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>Facebook-owned messaging app WhatsApp could be fined up to €50 million over violations of the European Union's data protection rules, according to three people with direct knowledge of the procedure who spoke with POLITICO.</p>
<p>The preliminary penalty — the figure is now under consultation with the bloc's other data protection agencies — would be one of the largest-ever fines under the EU's General Data Protection Regulation, a set of privacy rules that came into force in 2018. </p>
<p>As part of Ireland's draft findings, the internet messenger may face a fine of between €30 million and €50 million for not living up to transparency requirements under Europe's privacy regime. Whatsapp could also be required to change how it handles its users' data, as the case relates to how the messenger may have failed to properly inform its EU users about how it would share their data with Facebook.</p>

<p>France's privacy authority <a href="https://www.cnil.fr/en/cnils-restricted-committee-imposes-financial-penalty-50-million-euros-against-google-llc" target="_blank">has fined</a> Google €50 million for separate privacy violations, while Ireland's Data Protection Commission, which has regulatory authority over Facebook, recently <a href="https://www.politico.eu/article/irish-data-regulator-fines-twitter-e450000/">issued</a> a €450,000 penalty against Twitter. That represented its first levy against any Silicon Valley company, many of which fall under Dublin's jurisdiction because these firms are legally domiciled in Ireland, mostly for tax reasons.</p>
<p>The multi-million euro draft WhatsApp fine is an initial proposal from Dublin, and has been opened up to other European data protection agencies for their feedback. A final decision on how big the fine should be — and what other remedies WhatsApp should agree to — is not expected until later in the year.</p>
<p>A spokesman for Ireland's Data Protection Commissioner declined to comment. A spokesman for WhatsApp said the company was awaiting the final privacy decision.</p>
<p>In November, Facebook&nbsp;<a href="https://www.politico.eu/?p=1521035">earmarked €77.5 million&nbsp;for a likely privacy fine against its messaging service WhatsApp,&nbsp;</a>which, unlike Instagram, is a separate legal entity in Ireland and therefore has its own set of financial records. The Irish data protection agency is conducting a separate investigation into whether WhatsApp can legally share its users' data with Facebook's other digital services, among other privacy-related concerns.</p>
<p>The draft penalty against WhatsApp, which Ireland <a href="https://www.politico.eu/?p=1577539">submitted</a> to other EU agencies for review just before Christmas, comes as the messenger faces a global backlash over planned updates to its terms and conditions. Those include&nbsp;clarifying to its billions of users how their data is shared more widely with Facebook's other services.</p>
<p>Those changes will not affect WhatsApp European operations, but people across the bloc and elsewhere still have flocked to rivals like Signal because of privacy fears. On January 15, the messenger <a href="https://blog.whatsapp.com/giving-more-time-for-our-recent-update" target="_blank">said</a> it was delaying the upcoming privacy changes, in part because of the confusion generated by the proposed overhaul.</p>

<p>Johannes Caspar, Hamburg's privacy regulator who filed objections to a previous Irish decision against Twitter, told POLITICO earlier this week that he<a href="https://www.politico.eu/?p=1579886"> had not ruled out </a>doing the same in the WhatsApp case. </p>
<p>"WhatsApp has an enormous amount of users," he said. "It must be clear that the consent mechanism they use must be lawful and that consent is informed and freely given by the users."</p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25880609</guid>
            <pubDate>Sat, 23 Jan 2021 08:15:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bournegol – Algol-like C dialect that Steve Bourne used to write Bourne shell]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25879517">thread link</a>) | @segfaultbuserr
<br/>
January 22, 2021 | http://oldhome.schmorp.de/marc/bournegol.html | <a href="https://web.archive.org/web/*/http://oldhome.schmorp.de/marc/bournegol.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><b>Last change: 2014-12-30</b></p>




While browsing, I found this except from the book <a href="http://www.amazon.com/exec/obidos/ASIN/1565922603/heinersshelldora/002-6407720-0447242">Unix Power Tools</a>:

<blockquote>
   ... To fix it, first get the source, and then change it in the obvious three places in xec.c. You will have to learn <strong>Bournegol</strong> [the ALGOL-like dialect of C that Steve Bourne used to
   write the original Bourne shell-JP ]. Another alternative is to replace /bin/sh with one of the free sh look-alikes... (CT in comp.unix.questions on Usenet, 20 February 1990)
</blockquote>

I immediately asked myself: what could Bournegol look like? Well,
it's not that easy to find the <a href="http://minnie.tuhs.org/UnixTree/V7/usr/src/cmd/sh/">original Bourne
Shell</a> sourcecode, so,
after some googling, I thought I might put an example of Bournegol on
my homepage, so other people have the chance to find about "Bournegol"
without the tedious search.<p>

(many years later I found <a href="http://www.collyer.net/who/geoff/sh.tour.ps">this
paper</a>, A Partial Tour Through
the UNIX Shell, which makes for very nice reading).

Ok, without any further ado, here is an excerpt of the file
<tt>xec.c</tt>, referenced above, supposedly from the <a href="http://minnie.tuhs.org/UnixTree/V7/usr/src/">7th Edition UNIX</a>, that gives you an
impression of bournegol:</p><pre>LOCAL INT	parent;

SYSTAB		commands;

/* ========	command execution	========*/

execute(argt, execflg, pf1, pf2)
	TREPTR		argt;
	INT		*pf1, *pf2;
{
	/* `stakbot' is preserved by this routine */
	REG TREPTR	t;
	STKPTR		sav=savstak();

	sigchk();

	IF (t=argt) ANDF execbrk==0
	THEN	REG INT		treeflgs;
		INT		oldexit, type;
		REG STRING	*com;

		treeflgs = t-&gt;tretyp; type = treeflgs&amp;COMMSK;
		oldexit=exitval; exitval=0;

		SWITCH type IN

		case TCOM:
			BEGIN
			STRING		a1;
			INT		argn, internal;
			ARGPTR		schain=gchain;
			IOPTR		io=t-&gt;treio;
			gchain=0;
			argn = getarg(t);
			com=scan(argn);
			a1=com[1]; gchain=schain;

			IF (internal=syslook(com[0],commands)) ORF argn==0
			THEN	setlist(t-&gt;comset, 0);
			FI

			IF argn ANDF (flags&amp;noexec)==0
			THEN	/* print command if execpr */
				IF flags&amp;execpr
				THEN	argn=0;	prs(execpmsg);
					WHILE com[argn]!=ENDARGS
					DO prs(com[argn++]); blank() OD
					newline();
				FI

				SWITCH internal IN

				case SYSDOT:
					IF a1
					THEN	REG INT		f;
	
						IF (f=pathopen(getpath(a1), a1)) &lt; 0
						THEN failed(a1,notfound);
						ELSE execexp(0,f);
						FI
					FI
					break;
	
				case SYSTIMES:
					{
					L_INT	t[4]; times(t);
					prt(t[2]); blank(); prt(t[3]); newline();
					}
					break;
	
				case SYSEXIT:
					exitsh(a1?stoi(a1):oldexit);
	
</pre>
[...]<br>
<pre>				case SYSTRAP:
					IF a1
					THEN	BOOL	clear;
						IF (clear=digit(*a1))==0
						THEN	++com;
						FI
						WHILE *++com
						DO INT	i;
						   IF (i=stoi(*com))&gt;=MAXTRAP ORF i&lt;MINTRAP
						   THEN	failed(*com,badtrap);
						   ELIF clear
						   THEN	clrsig(i);
						   ELSE	replace(&amp;trapcom[i],a1);
							IF *a1
							THEN	getsig(i);
							ELSE	ignsig(i);
							FI
						   FI
						OD
					ELSE	/* print out current traps */
						INT		i;
	
						FOR i=0; i&lt;MAXTRAP; i++
						DO IF trapcom[i]
						   THEN	prn(i); prs(colon); prs(trapcom[i]); newline();
						   FI
						OD
					FI
					break;
	
</pre>
[...]<br>
<pre>                                                   
		case TFORK:
			IF execflg ANDF (treeflgs&amp;(FAMP|FPOU))==0
			THEN	parent=0;
			ELSE	WHILE (parent=fork()) == -1
				DO sigchk(); alarm(10); pause() OD
			FI

			IF parent
			THEN	/* This is the parent branch of fork;    */
				/* it may or may not wait for the child. */
				IF treeflgs&amp;FPRS ANDF flags&amp;ttyflg
				THEN	prn(parent); newline();
				FI
				IF treeflgs&amp;FPCL THEN closepipe(pf1) FI
				IF (treeflgs&amp;(FAMP|FPOU))==0
				THEN	await(parent);
				ELIF (treeflgs&amp;FAMP)==0
				THEN	post(parent);
				ELSE	assnum(&amp;pcsadr, parent);
				FI

				chktrap();
				break;

</pre>
[...]<p>

(Note the <em>single</em> use of curly braces after <tt>case SYSTIMES</tt>. This
and the lowercase <tt>case</tt> let me believe this segment might have been
added at a later stage). The necesssary macro definitions to understand (if
you dare to try) the above excerpt can be found in the file <tt>mac.h</tt>:

</p><pre>/*
 *	UNIX shell
 *
 *	S. R. Bourne
 *	Bell Telephone Laboratories
 *
 */

#define LOCAL	static
#define PROC	extern
#define TYPE	typedef
#define STRUCT	TYPE struct
#define UNION	TYPE union
#define REG	register

#define IF	if(
#define THEN	){
#define ELSE	} else {
#define ELIF	} else if (
#define FI	;}

#define BEGIN	{
#define END	}
#define SWITCH	switch(
#define IN	){
#define ENDSW	}
#define FOR	for(
#define WHILE	while(
#define DO	){
#define OD	;}
#define REP	do_lbr
#define PER	}while(
#define DONE	);
#define LOOP	for(;;){
#define POOL	}


#define SKIP	;
#define DIV	/
#define REM	%
#define NEQ	^
#define ANDF	&amp;&amp;
#define ORF	||

#define TRUE	(-1)
#define FALSE	0
#define LOBYTE	0377
#define STRIP	0177
#define QUOTE	0200

#define EOF	0
#define NL	'\n'
#define SP	' '
#define LQ	'`'
#define RQ	'\''
#define MINUS	'-'
#define COLON	':'

#define MAX(a,b)	((a)&gt;(b)?(a):(b))
</pre><p>

Hope you found this interesting ;)


</p><p><img src="http://oldhome.schmorp.de/marc/images/hbar.gif" alt="=======================================================" images="" hbar.gif="" gif="" 775x16="" 775x16+0+0="" pseudoclass="" 8c="" 381=""></p>
<p>Any questions/hints/critics? Contact the <a href="mailto:pcg@goof.com">author</a> of this page!





                  

</p></div>]]>
            </description>
            <link>http://oldhome.schmorp.de/marc/bournegol.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879517</guid>
            <pubDate>Sat, 23 Jan 2021 04:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rysolv – Fix open source issues, get paid]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25879238">thread link</a>) | @themanmaran
<br/>
January 22, 2021 | https://rysolv.com/issues | <a href="https://web.archive.org/web/*/https://rysolv.com/issues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rysolv.com/issues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879238</guid>
            <pubDate>Sat, 23 Jan 2021 03:14:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Primer on How to Work with the Usenet Community (1984)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25878578">thread link</a>) | @nkurz
<br/>
January 22, 2021 | https://www.krsaborio.net/internet/research/1984/0603.htm | <a href="https://web.archive.org/web/*/https://www.krsaborio.net/internet/research/1984/0603.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.krsaborio.net/internet/research/1984/0603.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25878578</guid>
            <pubDate>Sat, 23 Jan 2021 01:20:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Role of Discomfort in Decision Making]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25878526">thread link</a>) | @ruborcalor
<br/>
January 22, 2021 | https://colekillian.com/posts/discomfort/ | <a href="https://web.archive.org/web/*/https://colekillian.com/posts/discomfort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>Discomfort, a slight physical or emotional pain, developed as an evolutionary necessity; historically, considering the unpleasantness of discomfort during decision making was for the best of the species. Berries make your stomach uneasy? Stop eating them. Prickly bush scratches your skin? Don’t let it happen again.</p>
<p>On average your body does a good job correlating discomfort with actions that are bad for your well being, but it’s important to note that your body isn’t right 100% of the time!</p>
<p>The world has changed a lot since we developed the capacity to feel discomfort. I claim that people would be better off if they were to diminish or even eliminate the role that discomfort plays in the decision making process, opting instead for considering “long term” consequences. At least personally, this mentality shift has had a huge positive impact on my day to day life.</p>

<p>There are many things that people know they should be doing try to do but can’t do with success:</p>
<ul>
<li>eating healthy</li>
<li>getting 8 hours of sleep a night</li>
<li>exercising regularly</li>
<li>taking cold showers</li>
</ul>
<p>A common reason people don’t commit to these resolutions is that they rationalize them away on the basis of the required discomfort. People don’t want to miss out on the taste of junk food, or deal with the pain of a work out. After removing discomfort, the only reason left not to do build these healthy habits would be the cost of time, but even the busiest people can carve out a little bit of time for these activities that have much higher returns than the time investment (yes even you!).</p>

<p>Since the new year I have started every morning with a 20 minute workout. My workout consists of handstand pushups, pullups, hanging leg raises, and stretching. By framing the workout as having a cost of 20 minutes and forgetting about the discomfort I will experience during the workout, I am having an easier time maintaining the habit (knock on wood). It takes just 20 minutes and leaves me feeling energized for the rest of the day.</p>
<p>After my workout I hop into a cold shower. Similarly, I dispell thoughts relating to the discomfort of the cold water, and instead phrase the cold shower as a healthy experience that will take just 5 minutes. I wake right up and feel warm as soon as I get out of the cold.</p>

<p>The previous examples were activites of relatively minor discomfort that have compounding positive effects when incorporating them into daily life. Another benefit of making them ritual is to prepare you for dire needs which may include:</p>
<ul>
<li>a necessary confrontation</li>
<li>asking someone out</li>
<li>asking for a raise</li>
<li>building moral courage</li>
<li>generally getting out of one’s comfort zone</li>
</ul>
<p>These are the types of scenarios where people often regret not stepping out of their comfort zones; by building a tolerance for discomfort you will more easily take them on.</p>
<blockquote>
<p>Keep the faculty of effort alive in you by a little gratuitous exercise every day. Do every day or two something for no other reason than that you would rather not do it, so that when the hour of dire needs draws nigh, it may find you not unnerved and untrained to stand the test - The Way To Willpower</p>
</blockquote>

<p>I hope that this mentality shift is as helpful to you as it was to me. Please leave any comments or reflections below :)</p>
</div></div>]]>
            </description>
            <link>https://colekillian.com/posts/discomfort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25878526</guid>
            <pubDate>Sat, 23 Jan 2021 01:13:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Databricks Raising a Private Round at $27B]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25877748">thread link</a>) | @zuhayeer
<br/>
January 22, 2021 | https://www.newcomer.co/p/sources-databricks-raising-at-27 | <a href="https://web.archive.org/web/*/https://www.newcomer.co/p/sources-databricks-raising-at-27">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Databricks — a data and AI platform — is in talks to raise a private funding round that could value the company at about $27 billion.</p><p>It seems like the private deal is being done by buyside public investors, though I don’t know who is winning out, if it’s been decided, or how much they’re investing.</p><p>I’ve been hearing a lot about Databricks recently. For one, it has a similar investor story to Snowflake, and we saw the appetite on the public stock market for that company. Investors seem to want exposure to horizontal cloud computing companies outside of big tech. I’ve also been deep in the world of Andreessen Horowitz and this is an extremely important company for the portfolio. Andreessen Horowitz led Series A, D, and E rounds, according to Pitchbook. NEA led the Series B and C. </p><p>A spokesperson for Databricks declined to comment.</p><div><p>Mostly I care because it’s a huge frothy-sounding number that no one has reported so far.</p><p>Have a nice weekend. </p></div></div></div>]]>
            </description>
            <link>https://www.newcomer.co/p/sources-databricks-raising-at-27</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877748</guid>
            <pubDate>Fri, 22 Jan 2021 23:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SymQEMU: Compilation-based symbolic execution for binaries]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25877317">thread link</a>) | @homarp
<br/>
January 22, 2021 | http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html | <a href="https://web.archive.org/web/*/http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <blockquote>
    <p>
      SymQEMU: Compilation-based symbolic execution for binaries
    </p>
    
    <em>Proceedings of the Network and Distributed System Symposium (NDSS 2021),
    San Diego, CA, USA</em>
    
    
    <p>
      Symbolic execution is a powerful technique for software analysis and bug
      detection. Compilation-based symbolic execution is a recently proposed
      flavor that has been shown to improve the performance of symbolic
      execution significantly when source code is available. We demonstrate a
      novel technique to enable compilation-based symbolic execution of binaries
      (i.e., without the need for source code). Our system, SymQEMU, builds on
      top of QEMU, modifying the intermediate representation of the target
      program before translating it to the host architecture. This enables
      SymQEMU to compile symbolic-execution capabilities into binaries and reap
      the associated performance benefits while maintaining architecture
      independence.
    </p>
    
    <p>
      We present our approach and implementation, and we show that it
      outperforms the state-of-the-art binary symbolic executors S2E and QSYM
      with statistical significance; on some benchmarks, it even achieves better
      performance than the source-based SymCC. Moreover, our tool has found a
      previously unknown vulnerability in the well-tested libarchive library,
      demonstrating its utility in testing real-world software.
    </p>
  </blockquote>

  <h2 id="intro">Introduction</h2>

  <p>
    SymQEMU is a fast symbolic execution engine for binaries. On this page, we
    provide its source code, the raw results of the experiments described in the
    paper, and instructions how you can replicate those experiments yourself.
  </p>

  <h2>Code</h2>

  <p>
    SymQEMU is available
    on <a href="https://github.com/eurecom-s3/symqemu">GitHub</a>.
  </p>

  <h2>Experiments</h2>

  <p>
    In the paper, we describe three sets of experiments: we first benchmark
    SymQEMU with Google FuzzBench, then we run it on real-world software, and
    finally we perform a benchmark comparison during concolic execution of fixed
    paths. This section describes how to replicate our experiments, and provides
    links to our results.
  </p>

  <ol>
    <li>
      <p>
        FuzzBench (see the <a href="http://s3.eurecom.fr/~seba/2020-05-24-symqemu.zip">report</a>)
      </p>

      <p>
        We will share our integration scripts shortly; they're being cleaned up
        to obtain SymQEMU and its dependencies from the new public repository.
      </p>
    </li>

    <li>
      <p>Real-world software</p>

      <p>
        For the analysis of real-world software we used the same setup as in the
        <a href="http://s3.eurecom.fr/tools/symbolic_execution/symcc.html">evaluation of SymCC</a>. The binaries for SymQEMU,
        QSYM and S2E were plain builds without any instrumentation. SymQEMU was
        run via SymCC's fuzzing helper by prefixing the target command
        with <tt>/path/to/symqemu-x86_64</tt>. For the S2E analysis, we created
        a default project, then enabled the <tt>FunctionModels</tt> plugin and
        activated the option <tt>generateOnStateFork</tt> in
        the <tt>TestCaseGenerator</tt> plugin; coverage was evaluated
        with <tt>afl-showmap</tt> at the end of the analysis, using the same
        AFL-instrumented binaries as with the hybrid fuzzers.
      </p>

      <ul>
          <li>
            OpenJPEG
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_openjpeg.tar.gz">our
            results</a>), libarchive
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_libarchive.tar.gz">our
            results</a>), tcpdump
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_tcpdump.tar.gz">our
            results</a>): please find the details on
            our <a href="http://s3.eurecom.fr/tools/symbolic_execution/symcc.html">SymCC page</a>.
          </li>

          <li>
            <a href="https://www.rarlab.com/download.htm">WinRAR</a>
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_rar.tar.gz">our
            results</a>): we downloaded version 6.00 for 64-bit Linux.
          </li>
        </ul>
      
    </li>

    <li>
      <p>
        Benchmark experiments
          (<a href="http://www.s3.eurecom.fr/~seba/symqemu_benchmark.tar.gz">our
          results</a>)
      </p>

      <p>
        After the analysis of real-world software described above, we randomly
        collected 1,000 generated test cases per open-source target. We ran
        SymQEMU, QSYM and SymCC on each of those inputs, recording the time
        spent in execution and SMT solving, respectively, as per the logging
        output from the QSYM backend.
      </p>
    </li>
  </ol>

  <h2>Acknowledgements</h2>

  <p>
    This work has been supported partly by the DAPCODS/IOTics ANR 2016 project
    (ANR-16-CE25-0015) and partly by the Defense Advanced Research
    Projects Agency (DARPA) under agreement number FA875019C0003.
  </p>

  <h2>Contact</h2>

  <p>
    Feel free to <a href="http://www.s3.eurecom.fr/~seba/">reach out</a> to us
    if anything is unclear or if you need more information.
  </p>
</div></div>]]>
            </description>
            <link>http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877317</guid>
            <pubDate>Fri, 22 Jan 2021 22:54:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Analog Computer Inside Prime Minister]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25877102">thread link</a>) | @homarp
<br/>
January 22, 2021 | http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/ | <a href="https://web.archive.org/web/*/http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><img loading="lazy" width="657" height="217" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2.jpg" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2.jpg 657w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-300x99.jpg 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-518x171.jpg 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-82x27.jpg 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-600x198.jpg 600w" sizes="(max-width: 657px) 100vw, 657px"></figure></div>



<p><span title="G">G</span>lance at <em>Prime Minister</em>’s game board and player mats, and the first thing you’ll notice are all the numbers. The most important one is 330: the number of seats you need for a majority in the House of Commons. In this article, we’ll take a look at <em>Prime Minister</em>’s numerical side, with a focus on its measurement of public opinion.</p>



<p>At the heart of the game is an analog computer simulating the Victorian-era British political system. It tracks and links about 30 different political factors, including Parliament’s confidence in each player, each party’s popular support in eight key sectors of the electorate, current election projections, the number of government MPs and their “moderate” or “partisan” inclinations, projected votes on the government’s bills, the “uncertainty” factor in elections and Parliamentary votes, and Queen Victoria’s support for different players. By reducing these factors to numerical values and structuring their relationships, this analog computer decides who gets to lead each party, which party controls the government, and what bills the government can pass. Whoever does the best job of manipulating the factors controls the system and gets an edge in the game.</p>



<div><figure><a href="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png"><img loading="lazy" width="977" height="550" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png 977w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-300x169.png 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-768x432.png 768w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-760x428.png 760w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-518x292.png 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-82x46.png 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-600x338.png 600w" sizes="(max-width: 977px) 100vw, 977px"></a></figure></div>



<p>Here you can see a partial snapshot of <em>Prime Minister</em>’s game board, showing the most detailed part of its analog computer: the eight key sectors of the electorate. They include a mix of geographic, social, and ideological groups: Conservatives, Farmers, the Gentry, Ireland, Liberals, the Middle Class, Scotland, and Workers. You’ll track support for each party in each sector, moving wooden markers up and down the numerical tracks. The side with the blue rosette tracks support for the Conservative Party, and the side with the orange rosette does the same for the Liberal Party. The green circles indicate each party’s starting position in the game’s standard setup. During the game, you’ll encounter icons from bills, events, and actions that tell you when to move the markers up and down a track. By moving a marker up one step, you earn one to three popularity points, depending on the sector and your current position. The popularity points that each party earns in the different sectors are added up, and the total relative point difference between the parties determines projections for the next election.</p>



<p>The eight sectors overlap so that one voter might belong to several different sectors at once. For example, a landowner in Scotland might belong to the Conservatives, Gentry, Farmer, and Scotland sectors. The Conservative Party might win his vote by appealing to his ideological identity as a Conservative, or the Liberal Party might win his vote by appealing to his geographic Scots identity. A sector’s significance in each election varies depending on the parties’ respective strategies. If both parties neglect Farmers, then Farmers will have no significance. But if the Conservative Party maxes out its popularity among Farmers while the Liberal Party earns nothing there, the Farmers sector will weigh heavily in the next election–not only because Farmers prefer the Conservative Party, but because they have been motivated to vote according to their economic interests.</p>



<p>Different sectors have different point spreads, reflecting their importance in the Victorian-era electorate. In this era, most British subjects didn’t have the right to vote, so the point spreads aren’t simply based on population distribution. They’re based on the number of voters and each sector’s overall impact on the election results, factoring in the value of campaign contributions, endorsements, and other means of influence. This is why the Gentry sector has more points than Workers, despite being a much smaller slice of the population.</p>



<p>As the game progresses, parties will reach maximum or minimum values in some sectors. These maximums and minimums affect the game’s strategy and evoke real-life political effects. No matter how strongly Scotland prefers one party over another, Scotland’s impact is limited by the number of voters in Scotland. Once the Conservative Party has maxed out its popularity in Scotland, it can gain nothing more there; it must look for additional points in other sectors while being careful not to rock the boat in Scotland. Conversely, once the Conservative Party has bottomed out in Ireland, it has nothing more to lose there and incurs no further penalty for continuing to neglect the Irish–a circumstance which may become useful. As in real life, the parties and politicians in <em>Prime Minister </em>can’t please everyone all the time. When faced with hard choices, they favor their political patrons and write off sectors that are unimportant to them. If there’s a rail disaster in Scotland, a Conservative Prime Minister (PM) will be forced to deal with it if he wants to retain his party’s support there. But if a problem surfaces in Ireland, the same PM might choose to ignore it and focus on something else, knowing that his party can’t do any worse in Ireland.</p>



<p>In addition to tracking popular support, the sectors also track the public’s mood for partisanship, which in turn can result in “partisan” MPs who support more radical bills. The game board measures public partisanship through “red points” that are printed side-by-side next to the total points for some sectors. Not every sector produces red points. For example, the Middle Class–not known for favoring radicalism–doesn’t generate any red points. At the other end of the spectrum, the ideological sectors (Conservatives and Liberals) produce only red points. Red points are always party-specific. If a sector offers red points, it offers them to one party only. By appealing to Workers, the Liberal Party can earn up to 7 red points, reflecting the support of radical Workers who favor partisan Liberal MPs. The Conservative Party can also earn popularity points in the Workers sector, but can’t earn any red points there because Workers who support the Conservative Party prefer moderate MPs.</p>



<p>Each sector has its own flavor and strategic impact. Both parties are free to pursue popularity in any sector–the Conservative Party may pursue a limited number of points in the Liberals sector, for example–but some sectors have a natural affinity or resistance to a particular party. In pursuing popular support in the different sectors, players have to think not only about the raw number of points they earn, but also the difficulty of holding particular sectors. Scotland has the fewest points, but it’s the most stable sector. Scotland’s interests aren’t directly implicated in the hot-button political issues of the day, so there are no bills that upset the Scots. The Middle Class is equally open to both parties and offers more points than Scotland, but is somewhat harder to hold owing to its more sensitive economic and moral preferences. Players also need to think about maintaining a coherent moderate or partisan strategy. The sectors for Conservatives and Liberals are the richest in points, making them tempting targets early in the game. But appealing to voters’ partisanship results in partisan MPs who favor divisive bills that could come back to haunt you. And if your government is equally split between moderate and partisan MPs, you may have a hard time getting them to agree on legislation.</p>



<p>In standard games, <em>Prime Minister</em>’s framework supports an open-ended format in which players strive to control government, win elections, and pass bills. Different politician abilities and about 200 unique cards ensure that no two games are the same. The same framework also supports specific scenarios that simulate historical problems, like home rule for Ireland or the repeal of the Corn Laws. Automated “Clockwork” politicians can readily function within the game’s system, opening the door to solitaire play.</p>



<p>Players have a wide variety of ways to interact with the game, starting with an action point system that allows you to perform a variable number of actions per turn. Depending on your current player mat and your politician’s fixed abilities, you can campaign to increase your party’s popularity in particular sectors, debate for or against bills, flatter Her Majesty to gain her favor, or influence MPs to make them more moderate or partisan. You can also draw “supporter” cards featuring influential Victorians who perform actions on your behalf. You’ll always have many things to do and not enough action cubes to spend, forcing you to prioritize your actions while anticipating future events. The PM’s response to random events and Parliament’s enactment of important bills have consequences that ripple through the system. The players and parties are in a constant tug of war. Collecting the right supporters, unleashing them at the right moment, and coordinating your actions with other players can help you achieve a breakthrough. But the game is not all about numbers. Relationships between players also factor heavily in the game, particularly in its 3- or 4-player mode. We’ll take a look at the players’ roles and relationships in the next <em>InsideGMT</em> article for <em>Prime Minister</em>.</p>



<hr>



<div><figure><a href="https://www.gmtgames.com/p-906-prime-minister.aspx"><img loading="lazy" width="657" height="217" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3.jpg" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3.jpg 657w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-300x99.jpg 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-518x171.jpg 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-82x27.jpg 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-600x198.jpg 600w" sizes="(max-width: 657px) 100vw, 657px"></a></figure></div>

	</div></div>]]>
            </description>
            <link>http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877102</guid>
            <pubDate>Fri, 22 Jan 2021 22:29:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Unplugged 308: The One About GPU Passthrough]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876995">thread link</a>) | @tambourine_man
<br/>
January 22, 2021 | https://linuxunplugged.com/308 | <a href="https://web.archive.org/web/*/https://linuxunplugged.com/308">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  


<header>
  <div>
    <div>
        <h5>Episode 308</h5>
      

      <div>
          
<div id="fireside-player" data-started="false" data-theme="minimal-dark" data-player-type="embed" data-player-download="https://chtbl.com/track/392D9/aphid.fireside.fm/d/1437767933/f31a453c-fa15-491f-8618-3f71f1d565e5/5f78aaf3-0565-405c-8685-a5c0e56f7843.mp3" data-player-duration="3406" data-player-share="/308" data-player-theme="minimal-dark" data-player-time="0">
  

  <div>
    <p><audio preload="none">
      <source src="https://media.fireside.fm/file/fireside-audio/podcasts/audio/f/f31a453c-fa15-491f-8618-3f71f1d565e5/episodes/5/5f78aaf3-0565-405c-8685-a5c0e56f7843/5f78aaf3-0565-405c-8685-a5c0e56f7843.mp3" type="audio/mpeg">
      Your browser does not support the audio tag.
    </audio></p>

    

    

    

    </div>

  

</div>

      </div>
      <div>
        <div>
          <p>
            <i></i>
            July 2nd, 2019
          </p>
          <p>
            <i></i>
            56 mins 46 secs
          </p>
        </div>
        
      </div>
      <div>
        
        <div>
            <h5>
              Special Guest
            </h5>
            <ul>
                <li>
                  <a title="Alex Kretzschmar" href="https://linuxunplugged.com/guests/alexktz">
                    <img src="https://assets.fireside.fm/file/fireside-images/podcasts/images/f/f31a453c-fa15-491f-8618-3f71f1d565e5/guests/7/7b468271-67fc-4c41-88a7-d883cb0c436d/avatar_small.jpg?v=1">
</a>                </li>
            </ul>
        </div>
      </div>
        <h5>Tags</h5>
        
    </div>
  </div>
</header>

<nav>
  <ul>
      <li><a href="https://linuxunplugged.com/rss"> RSS</a></li>
      <li><a href="https://itunes.apple.com/us/podcast/linux-unplugged-podcast/id687598126"><i></i> Apple Podcasts</a></li>
      <li><a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5maXJlc2lkZS5mbS9saW51eHVucGx1Z2dlZC9yc3M="><i></i> Google Podcasts</a></li>
      <li><a href="https://playmusic.app.goo.gl/?ibi=com.google.PlayMusic&amp;isi=691797987&amp;ius=googleplaymusic&amp;apn=com.google.android.music&amp;link=https://play.google.com/music/m/I2hmp7hkpuqnu7qnbw5k46ngray?t%3DLINUX_Unplugged%26pcampaignid%3DMKT-na-all-co-pr-mu-pod-16"><i></i> Google Play</a></li>
      <li><a href="https://castbox.fm/channel/LINUX-Unplugged-id2120644?country=us"><i></i> Castbox</a></li>
      <li><a href="https://overcast.fm/itunes687598126/linux-unplugged-podcast"><i></i> Overcast</a></li>
      <li><a href="http://pca.st/itunes/687598126"><i></i> Pocket Casts</a></li>
      <li><a href="https://radiopublic.com/linux-unplugged-G2BldG"><i></i> RadioPublic</a></li>
      <li><a href="https://www.iheart.com/podcast/256-linux-unplugged-31099185/"><i></i> iHeartRadio</a></li>
      <li><a href="https://open.spotify.com/show/7bVFJvj8A2ZuYVs5lS992b"><i></i> Spotify</a></li>
      <li><a href="https://www.stitcher.com/podcast/jupiter-broadcasting/linux-unplugged"><i></i> Stitcher</a></li>
      <li><a href="https://tunein.com/podcasts/Technology-Podcasts/LINUX-Unplugged-p1136199/"><i></i> TuneIn</a></li>
      <li>
    <a href="#share_modal" data-modal=""> Share</a>
  </li>

  </ul>
</nav>


<section>
  <div>
    

    <p>Our crew walks you through their PCI Passthrough setups that let them run Windows, macOS, and distro-hop all from one Linux machine.</p>

<p>Forget multiple partitions, dual booting, and Hackintoshes; you can do it all with Linux and KVM.</p>

<p>Near-native VM performance doesn't have to be painful. You only need a few prerequisites and a little help. </p>


      <p><a target="_blank" rel="payment" href="https://jupitersignal.memberful.com/checkout?plan=52946">Support LINUX Unplugged</a></p>
      <ul>
        <li><a title="Windows VirtIO Drivers" rel="nofollow" href="https://www.linux-kvm.org/page/WindowsGuestDrivers/Download_Drivers">Windows VirtIO Drivers</a> — 64-bit versions of Windows Vista and newer require the drivers to be digitally signed.</li><li><a title="Alex's arch-vfio-ovmf scripts" rel="nofollow" href="https://github.com/IronicBadger/arch-vfio-ovmf">Alex's arch-vfio-ovmf scripts</a> — Arch Linux installation and VFIO setup scripts
</li><li><a title="Looking Glass - Quickstart Guide" rel="nofollow" href="https://looking-glass.hostfission.com/quickstart">Looking Glass - Quickstart Guide</a> — These guides are designed to help you get Looking Glass up and running on an already configured QEMU KVM Virtual Machine that has a VGA PCI Passthrough device. </li><li><a title="duncanthrax/scream" rel="nofollow" href="https://github.com/duncanthrax/scream#using-ivshmem-between-windows-guest-and-linux-host">duncanthrax/scream</a> — Scream is a virtual device driver for Windows that provides a discrete sound device. Audio played through this device is published on your local network as a PCM multicast stream.

</li><li><a title="ACS patch COPR" rel="nofollow" href="https://copr.fedorainfracloud.org/coprs/jlay/kernel-acspatch/">ACS patch COPR</a> — Fedora kernels with add-acs-overrides patch from Arch AUR</li><li><a title="ACS Override Kernel Builds" rel="nofollow" href="https://queuecumber.gitlab.io/linux-acs-override/">ACS Override Kernel Builds</a> — This page contains links to the latest kernel builds with the ACS override patch applied for PCI devices.

</li><li><a title="natalie-/fedora-acs-override" rel="nofollow" href="https://github.com/natalie-/fedora-acs-override">natalie-/fedora-acs-override</a> — Using the ACS override patch for Fedora</li><li><a title="VFIO tips and tricks: IOMMU Groups, inside and out" rel="nofollow" href="https://vfio.blogspot.com/2014/08/iommu-groups-inside-and-out.html">VFIO tips and tricks: IOMMU Groups, inside and out</a> — Sometimes VFIO users are befuddled that they aren't able to separate devices between host and guest or multiple guests due to IOMMU grouping and revert to using legacy KVM device assignment, or as is the case with may VFIO-VGA users, apply the PCIe ACS override patch to avoid the problem. &nbsp;Let's take a moment to look at what this is really doing.
</li><li><a title="&quot;Error 43: Driver failed to load&quot; on Nvidia GPUs passed to Windows VMs" rel="nofollow" href="https://wiki.archlinux.org/index.php/PCI_passthrough_via_OVMF#%22Error_43:_Driver_failed_to_load%22_on_Nvidia_GPUs_passed_to_Windows_VMs">"Error 43: Driver failed to load" on Nvidia GPUs passed to Windows VMs</a> — Since version 337.88, Nvidia drivers on Windows check if an hypervisor is running and fail if it detects one, which results in an Error 43 in the Windows device manager. Starting with QEMU 2.5.0 and libvirt 1.3.3, the vendor_id for the hypervisor can be spoofed, which is enough to fool the Nvidia drivers into loading anyway.</li><li><a title="Mac OS Adds Early Support for VirtIO, Qemu - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/mac-os-adds-early-support-for-virtio-qemu/">Mac OS Adds Early Support for VirtIO, Qemu - The Passthrough POST</a> — In a new development uncovered by Qemu developer Gerd Hoffmann, Apple has apparently added early support for VirtIO and framebuffer graphics in a later Mac OS Mojave release.
</li><li><a title="New and Improved Mac OS Tutorial, Part 1 (The Basics) - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/new-and-improved-mac-os-tutorial-part-1-the-basics/">New and Improved Mac OS Tutorial, Part 1 (The Basics) - The Passthrough POST</a> — Due to certain recent developments, It’s become clear to us that it’s necessary to update and improve our OSX VM guide. A lot’s changed since we wrote it, and rolling in those changes will make the process much more user friendly and accessible to newer VFIO users.

</li><li><a title="Mac OS VM Guide Part 2 (GPU Passthrough and Tweaks) - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/mac-os-vm-guide-part-2-gpu-passthrough-and-tweaks/">Mac OS VM Guide Part 2 (GPU Passthrough and Tweaks) - The Passthrough POST</a> — We’ve made every attempt to make this as straightforward as possible, but there’s a lot more ground to cover here than in the first part of the guide</li><li><a title="UGREEN USB 3.0 Sharing Switch Selector 4 Port 2 Computers Peripheral Switcher Adapter Hub for PC, Printer, Scanner, Mouse, Keyboard with One Button Swapping" rel="nofollow" href="https://www.amazon.com/UGREEN-Selector-Computers-Peripheral-Switcher/dp/B01N6GD9JO/ref=sr_1_3?keywords=usb+switcher&amp;qid=1561573709&amp;s=gateway&amp;sr=8-3">UGREEN USB 3.0 Sharing Switch Selector 4 Port 2 Computers Peripheral Switcher Adapter Hub for PC, Printer, Scanner, Mouse, Keyboard with One Button Swapping</a> — This USB Switch 4 Port device allows up to 2 users to share 4 USB 3.0 peripheral devices, such as printer,scanner,mouse,keyboard or usb disk etc without the need to constantly swap cables or set up complicated network sharing software. It's a great for use at home if you have multiple PCs or Macs.</li><li><a title="How to setup VFIO GPU passthrough using OVMF and KVM on Arch Linux" rel="nofollow" href="https://blog.linuxserver.io/2017/04/28/how-to-setup-vfio-gpu-passthrough-using-ovmf-and-kvm-on-arch-linux/">How to setup VFIO GPU passthrough using OVMF and KVM on Arch Linux</a> — This article will detail the steps required to passthrough your GPU to a guest VM which will in our case be a Windows 10 VM used for gaming. Yes, this is the exact same technology made popular by Linus on his LinusTechTips YouTube channel in the seven gamers, one CPU video.</li><li><a title="Chris' HDMI Monitor 1920x1080 16: 9 LCD Screen" rel="nofollow" href="https://www.amazon.com/gp/product/B0762NKY3D/">Chris' HDMI Monitor 1920x1080 16: 9 LCD Screen</a></li><li><a title="Lenovo G0A10170UL Thunderbolt 3 Graphics Dock" rel="nofollow" href="https://www.amazon.com/Lenovo-G0A10170UL-Thunderbolt-Graphics-Dock/dp/B079JFW3YT">Lenovo G0A10170UL Thunderbolt 3 Graphics Dock</a> — Amplify your ultrabook’s graphics performance with the integrated NVIDIA GeForce GTX 1050 graphics card. </li><li><a title="Mantiz Venus MZ-02 External Graphic Enclosure eGPU" rel="nofollow" href="https://www.amazon.com/gp/product/B0745H6GTX/ref=ppx_yo_dt_b_asin_title_o09_s00?ie=UTF8&amp;psc=1">Mantiz Venus MZ-02 External Graphic Enclosure eGPU</a> — Connects Full High Full Length 120" Width 2.5 PCIE Desktop Power GPU to computer WITH an Intel Certified Thunderbolt 3 port.</li><li><a title="Synergy" rel="nofollow" href="https://symless.com/synergy">Synergy</a> — Synergy is a software download that shares one mouse and one keyboard between multiple computers. Simply move your mouse between your computers effortlessly</li><li><a title="barrier: Open-source KVM software" rel="nofollow" href="https://github.com/debauchee/barrier">barrier: Open-source KVM software</a> — Barrier is KVM software forked from Symless's synergy 1.9 codebase. Synergy was a commercialized reimplementation of the original CosmoSynergy written by Chris Schoeneman.

</li><li><a title="foxlet/macOS-Simple-KVM" rel="nofollow" href="https://github.com/foxlet/macOS-Simple-KVM/">foxlet/macOS-Simple-KVM</a> — Documentation to set up a simple macOS VM in QEMU, accelerated by KVM.

</li>
      </ul>

  </div>

  
</section>


  <nav>
      <a href="https://linuxunplugged.com/307">← Previous episode</a>
      <a href="https://linuxunplugged.com/309">Next episode →</a>
  </nav>
</div></div>]]>
            </description>
            <link>https://linuxunplugged.com/308</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876995</guid>
            <pubDate>Fri, 22 Jan 2021 22:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Craft of Experimental Physics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25876989">thread link</a>) | @mdturnerphys
<br/>
January 22, 2021 | http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html | <a href="https://web.archive.org/web/*/http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>In the basement of the Argosy Book Store, I found a collection of essays from 1933. The one that prompted the purchase of the book was entitled: The Craft of Experimental Physics, by P.M.S. Blackett. Though written more than 80 years ago, the salient points are just as relevant today. I might go so far as to say it should be required reading for both newcomers to the field, as well as for established lab rats. Aside from a few ‘old fashioned’ tendencies (gender specific pronouns being the most notable) and dated technologies mentioned (a valve is a vacuum tube), the essay should resonate with all who have spent a few years poking around the dark corners of Nature with their fingers. Here are some selected passages. (A link to the whole pdf is below)</p>

<blockquote>
  <p>For the experimental physicist is a Jack-of-All Trades, a versatile but amateur craftsman. He must blow glass and turn metal, though he could not earn his living as a glassblower nor ever be classed as a skilled mechanic; he must carpenter, photograph, wire electric circuits and be a master of gadgets of all kinds; he may find invaluable a training as an engineer and can profit always by utilising his gifts as a mathematician. In such activities will he be engaged for three-quarters of his working day. During the rest, he must be a physicist, that is, he must cultivate an intimacy with the behaviour of the physical world.</p>
</blockquote>

<p>In this opening paragraph, Blackett sums it up perfectly. My days, especially the early ones, in the lab were indeed spent with carpentry, photography (digital of course these days), soldering, and often needing to incorporate a new device (gadget) on the fly, sometime with no manual or instructions to serve as a guide. I myself never had to blow any glass, though friends of mine did, but I sure turned some metal now and then. All the meanwhile, one couldn’t lose sight of the bigger goal — to do some physics.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/control-station.jpg" alt="control station">
   <figcaption> A lot of gadgets all talking nicely to each other.</figcaption>
</figure>
</div>

<blockquote>
  <p>The experimental physicist must be enough of a theorist to know what experiments are worth doing and enough of a craftsman to be able to do them. He is only preeminent in being able to do both.</p>
</blockquote>

<p>This line captures another aspect well. Not only must we know how to do things, we must at least have a good inclination as to why. Like the famous quote from that dinosaur movie: “…but your scientists were so preoccupied with whether or not they could that they didn’t stop to think if they should.” Of course we weren’t battling over moral dilemmas (that much) but more so over the question of what would we achieve by measuring something. So you can measure the voltage with nanovolt precision – but will it help?</p>

<blockquote>
  <p>Certainly the way of a researcher is hard who does not in some degree delight in handy work for its own sake. However much his theoretical interest may be excited by the problem he is to investigate, he may feel a certain dismay on being assigned a room empty perhaps of all but a table, a blow-pipe and a few tools. Often two years may elapse before definite results come in sight; two years occupied with carpentering, metal work, glassblowing, and the wiring of electric circuits. Even when an apparatus is completed, an endless succession of minor difficulties and mishaps may postpone its successful use. A glass tube may crack overnight, a single hair may short circuit an electrometer, a filament may burn out, or the failing of the water supply may wreck an elaborate apparatus. But almost the worst trials to the experimenters patience are due to leaks, and a considerable portion of his time is often spent in finding them. An experimenter was once heard to complain, I have spent two days in getting the leak in my apparatus so small that it will now take me a week to find it. If the experimenter does not find pleasure in such activities, that is, if he has not in some degree the temperament of the amateur craftsman, much of his work must be a weariness.</p>
</blockquote>

<p>My first day in the lab, in 2005, I painted the floor. It was great. Part of the instrument that I was to work on lay in a coffin-like wooden box, in pieces. Other parts didn’t exists yet. There was pvc pipe to be hung, hundred of meters of wire to direct, and many other tasks that might at first glance seem not very physics related.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/floor.jpg" alt="the pit">
   <figcaption> The freshly painted concrete pit.</figcaption>
</figure>
</div>

<p>And of course, let’s be humble about the whole thing also:</p>

<blockquote>
  <p>Taken singly, the qualities of hand and mind required to make a good experimental physicist are not rare.</p>
</blockquote>

<p>Indeed. None of us were truly talented craftsmen. I did build a table out of an old crate, and it worked well for years, (it might even still be there) but it would hardly be worthy of a spot on a showroom floor.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/table.jpg" alt="table">
   <figcaption> The aforementioned table in the upper left portion of the image, along with another fantastic experimentalist.</figcaption>
</figure>
</div>

<p>Nor would most of us have gotten very far in the math olympiads. But, as is pointed out in the subsequent sentence,</p>

<blockquote>
  <p>But the combination of these abilities in one individual with the right temperament to use them to the full is rare.</p>
</blockquote>

<p>it requires more than just steady hands and a way with math to do the physics. It requires a subtle combination of patience, stubbornness, determination, and even some cowboy-esque roping to get the job done.</p>

<p>Blackett then goes on, in such a polite way, to highlight a major issue with experimental physics that persists today: working with the machine shop.</p>

<blockquote>
  <div><p>The rapidity with which an alteration to an apparatus can be carried out is a matter of primary and not of secondary importance. If a days work is required to test out an idea, it may be done; if a weeks work, it may not be done at all. </p><p> So even when professional assistance is available, many experimenters prefer to make their own apparatus, however amateurishly. It is very often so very much quicker. For if the aid of a mechanic is called in, scale drawings will have to be made, and it is often easier to construct a small piece of complicated apparatus than to make a drawing of it</p></div>
</blockquote>

<p>While my PhD was not finished in record time, it would have taken twice as long if every threaded hole had to be formally requested and accompanied by shop drawings. Sure, there were some parts of the apparatus that were well beyond my abilities in the shop, and those we handed over to the highly trained professionals (often aided by computer controlled machining capabilities). But having the ability to simply run over to a drill press and tap a 1/4-20 hole was indispensable. I couldn’t imagine having to ask every time I needed the smallest bit of machining done.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/measure-hookes-law.jpg" alt="hookes law measurement">
   <figcaption> Here is a measurement to see if the spring constant of a stainless steel bellows would change at very low temperatures.</figcaption>
</figure>
</div>

<p>The middle section of the essay is spent discussing three technologies that were common at the time: the scintillator, amplification (via tubes), and the cloud chamber. Scintillators are still used today to observe radiation. Of course our amplifiers are no longer based on vacuum tubes, but no lab could function without the solid state versions. The cloud chamber has little presence in today’s labs, but the evolution of that technology can be seen in today modern particle detectors.</p>

<p>The third and final section of essay makes some interesting points about how the experimental physicist might, by the very nature of his hands-on approach to the world, be in a good position to understand physics. Essentially, Blackett makes the argument that our intuition gained from a mechanistic interaction with the world might be of some advantage in trying to navigate the abstractions of modern physics. While very much the case for introductory physics topics, I’m not convinced that experience, however measured and probing it may be, with the macroscopic, human scale objects of daily life, can really be a strong source of conceptual foundation for much of what comes out of modern theoretical physics land. Perhaps occasionally, but I usually felt my rootedness in the mechanical world to be a bit of a handicap when exploring the abstract landscape of theory.</p>

<p>The separation between theorist and experimentalist will more than likely be a constant feature of the practice of natural science. There are of course exceptions to be found in the historical record, and in the current era – now and then, some people get really good at both. As is discussed in the essay, the experimentalist most likely has not the time nor the resources to become a fully functional theorist, and the theorists, in general, seem uninterested in arts and crafts. Exactly what leads one towards a particular camp is most likely a factor of both our innate circuitries as well as what filled our days during our youths. I had a neighbor who regularly deposited old stereos and other small appliances on my doorstep when I was young. I would dismantle, and occasionally re-mantle these gifts. There were numerous sets of blocks, legos, logs, and other construction elements in my hands at all time. I’m guessing those sorts of things had something to do with the paths I followed.</p>

<blockquote>
  <p>The experimental physicist is luckier; his legitimate field of activity ranges from carpentering to quantum mechanics; it is his job to make and think, and he can divide his time as he thinks fit between both these pleasurable occupations.</p>
</blockquote>

<p>Exactly.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/theorist.jpg" alt="hookes law measurement">
   <figcaption> Theorist at work</figcaption>
</figure>
</div>

<p>Here is a link to the <a href="http://jameshedberg.com/assets/docs/TheCraftofExperimentalPhysics-Blackett.pdf">whole pdf</a>. It really is a fantastic read and affirms much of the wonderful aspects of being involved in natural science.</p>

      </div></div>]]>
            </description>
            <link>http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876989</guid>
            <pubDate>Fri, 22 Jan 2021 22:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Virologist Christian Drosten]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25876682">thread link</a>) | @Tomte
<br/>
January 22, 2021 | https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="">


</section>
<section>
<div>
<figure data-component="Image" data-zoom-id="42c3f1a7-e53a-4393-b8ef-f16a5e117b64" data-settings="{&quot;id&quot;:&quot;24e27727-88e6-406c-9b86-4f907da0941b&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;42c3f1a7-e53a-4393-b8ef-f16a5e117b64&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w948_r1.77_fpx66_fpy45_fd50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w520_r1.77_fpx66_fpy45_fd50.jpg 520w, https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w948_r1.77_fpx66_fpy45_fd50.jpg 948w" width="948" height="536" sizes="948px" title="Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin" alt="Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin">
</span>
</span>
</span>

</p>
<figcaption>
<p>Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin</p>
<span>
Foto: <p>Julia Steinigeweg&nbsp;/ DER SPIEGEL</p>
</span>
</figcaption>
</figure>
</div><div>
<p><strong>DER SPIEGEL:</strong> Professor Drosten, the pandemic has entered a decisive phase. The beginning of the vaccination campaign has meant light at the end of the tunnel, but now, more contagious virus variants have appeared. How dangerous is the situation in Germany at the moment?</p>


<p><strong>Drosten:</strong> I am, of course, closely monitoring the situation. Politicians are also acutely aware that we have to be careful. Early on, I admit that I had my doubts as to whether B.1.1.7, the new variant from Britain, was as much more contagious as people were claiming. But now, there is a new study from Oxford, really solid data, showing that this mutation is up to 35 percent more contagious than the wild-type virus. It is rather astonishing that the virus has boosted its infectiousness to that degree. That is, unfortunately, more dangerous than if it had become more deadly – because every new case will infect more people, and each of them will infect more people, such that the number of cases will grow exponentially.</p>

<p><strong>DER SPIEGEL:</strong> On Monday evening, you were part of the group of experts advising Chancellor Angela Merkel and the governors of Germany's 16 states. What recommendations did you make?</p>
<p><strong>Drosten:</strong> Right now, I am most concerned about the British variant, primarily because of our geographical proximity to the UK. According to the facts we currently have, B.1.1.7 has just started spreading in Germany. I think we have the singular opportunity to prevent, or at least significantly slow, the advance of this variant. With B.1.1.7, there could be a kind of threshold effect. If we are able to keep the new variant below a critical benchmark, we would at least have hope that it wouldn't spread as quickly here.</p>

<div>
<p><strong>DER SPIEGEL:</strong> Are the measures decreed on Tuesday sufficient?</p><p><strong>Drosten:</strong> In the negotiations, I think there was an effort made to find the gaps, the places where not enough has thus far been undertaken to stop the spread. It's clear that it was a struggle and that the results are a compromise. Some areas appear particularly important to me. Schools and daycare centers, for one, particularly the classes in secondary schools. England has closed such schools, with the exception of children of critical workers, and I think that is also where the most reliable data is to be found. For me, this is unequivocal, and Germany should use it as an orientation.</p>
</div>


<div>
<p><strong>DER SPIEGEL:</strong> What about the measures pertaining to working from home?</p><p><strong>Drosten:</strong> More could certainly have been done on that issue. It would have been good to take inspiration from the Irish experience in the autumn. Ireland introduced strict measures regarding working from home, and it was apparently quite effective. Doing so automatically reduces public transport occupancy. There is also a third aspect where improvements are necessary, something the British are doing: Targeted contact and support for the socially disadvantaged and groups that are difficult to reach in the pandemic. Here, the virus frequently spreads explosively, because many people live in close quarters and have jobs that don't allow them to work from home. Many perhaps don't fully understand the problem presented by confined spaces. I think there is still a lot to do here.</p><p><strong>DER SPIEGEL:</strong> You've come up with an image to illustrate our current situation in the pandemic: We are in a rickety truck that is driving down a steep mountainside ...</p><p><strong>Drosten:</strong> ... and we don't know what curves are coming up and whether the road is suddenly about to get steeper. We also don't know how far we still have to go, but we do know that we absolutely have to avoid missing a corner. In a situation like this, closing our eyes doesn't help. We have to keep going and do one thing in particular: Hit the brakes, even if they might be rusty.</p><p><strong>DER SPIEGEL:</strong> What do you mean by that?</p><p><strong>Drosten:</strong> That means, we have to lower the reproduction number R.</p><p><strong>DER SPIEGEL:</strong> The value that tells us the average number of people an infected person passes the virus to.</p><p><strong>Drosten:</strong> Precisely. Currently, that number is at 0.9. It is great that we have finally managed to push it back down below 1, so that the number of cases can begin to drop. But 0.9 isn't enough if we want to quickly loosen the brakes. With an R of 0.9, it takes about a month to reduce the number of infections by half. That is too long. We should try, through an intensification of the shutdown, to get the number down to 0.7. Then, the case numbers will drop by half in just a week, and we can get to a point where we can stop the spread of B.1.1.7 or at least give ourselves a head start.</p>
</div>

<section data-area="contentbox">

</section>
<div>
<p><strong>DER SPIEGEL:</strong> Do you think that the so-called Zero-COVID strategy, the goal of sinking the number of new infections to zero, is the right way forward?</p><p><strong>Drosten:</strong> I do think it would be possible with a significant effort. The virus, of course, would continue to flare up, just as we have seen in China and Australia. But it would absolutely be worthwhile to at least identify zero new infections as a target. Primarily because I am quite apprehensive about what might otherwise happen in the spring and summer.</p><p><strong>DER SPIEGEL:</strong> What do you mean?</p><p><strong>Drosten:</strong> Once the elderly and maybe part of the risk groups have been vaccinated, there will be immense economic, social, political and perhaps also legal pressure to end the corona measures. And then, huge numbers of people will become infected within just a short amount of time, more than we can even imagine at the moment. We won't have 20,000 or 30,000 new cases a day, but up to 100,000 in a worst-case scenario. It will, of course, be primarily younger people who are less likely than older people to have severe symptoms, but when a huge number of younger people get infected, then the intensive care units will fill up anyway and a lot of people will die. Just that it will be younger people. We can cushion this terrible scenario somewhat by pushing the numbers way down now.</p><p><strong>DER SPIEGEL:</strong> Can we be confident that case numbers will begin to drop in spring as temperatures rise?</p><p><strong>Drosten:</strong> I don't think so. The fact that we had such a relaxed summer in 2020 likely had to do with the fact that our case numbers remained below a critical threshold in the spring. But that's not the case any longer. I am afraid that it will be more like in Spain, where case numbers climbed rapidly again after the lockdown was lifted, even though it was quite hot. In South Africa, too, where it is currently summer, case numbers are at a high level. (<em>Sinks into thought, saying nothing</em>) I'm sorry, unfortunately I'm extremely tired.</p><p><strong>DER SPIEGEL:</strong> Because you were advising politicians deep into the night?</p>
</div>
<div>
<p><strong>Drosten:</strong> (<em>laughs</em>) No. Because I worked until 1 a.m. and then woke up this morning at 5:30.</p><p><strong>DER SPIEGEL:</strong> How well are you able to juggle your work with family life?</p><p><strong>Drosten:</strong> I don't really want to talk about my private life. But I do think that it's a problem many families are facing at the moment. The pandemic has found a sore spot. In countries like Germany, where people generally aren't living together with grandma and grandpa, many families find themselves in an extremely difficult situation. I hope that we can learn from this and find new solutions.</p><p><strong>DER SPIEGEL:</strong> Do you still have time for your real work, as a virologist?</p><p><strong>Drosten:</strong> Yes, of course. We are currently taking a closer look at the British variant. We hope to have initial results in a few weeks.</p><p><strong>DER SPIEGEL:</strong> Which of the new mutants do you believe is the most dangerous?</p>
</div>
<figure>
<div data-component="Image" data-zoom-id="d8415e7f-c187-44ee-8a10-7759cd093684" data-settings="{&quot;id&quot;:&quot;901740b1-c534-4785-b6b3-16ab224c5156&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;d8415e7f-c187-44ee-8a10-7759cd093684&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg" srcset="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w488_r0.75_fpx49.88_fpy37.41.jpg 488w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w616_r0.75_fpx49.88_fpy37.41.jpg 616w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg 718w" width="718" height="957" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w488_r0.75_fpx49.88_fpy37.41.jpg 488w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w616_r0.75_fpx49.88_fpy37.41.jpg 616w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg 718w" title="Christian Drosten: &quot;I'm sorry, unfortunately I'm extremely tired.&quot;" alt="Christian Drosten: &quot;I'm sorry, unfortunately I'm extremely tired.&quot;">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Christian Drosten:</strong> "I'm sorry, unfortunately I'm extremely tired."</p>
<span>
Foto: Julia Steinigeweg&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>Drosten:</strong> In a population that still isn't immune, like here in Germany, the variant from Britain will likely find success, because it is better at spreading, it is more contagious. The South African and Brazilian variants may be able to infect people who have already had the disease, but that likely doesn't give them an advantage in a population where immunity isn't yet widespread. Which means that the virus will be distributed here and there over the course of the next year, and new variants will surely appear.</p><p><strong>DER SPIEGEL:</strong> What does that mean for the vaccines?</p><p><strong>Drosten:</strong> One of the mutations in the Brazilian and South African variants has already demonstrated a serious immune escape ...</p><p><strong>DER SPIEGEL:</strong> ... which helps the virus evade our immune defenses. Does that mean that the vaccines will be ineffective?</p><p><strong>Drosten:</strong> Antibodies are just one component of immune protection, another is T-cell immunity. That protects much more strongly against a serious progression of the illness. If the virus mutates, it doesn't have an effect on T-cell immunity. As such, I don't think that we have to fear that our vaccines will be ineffective.</p><p><strong>DER SPIEGEL:</strong> When you formulate such assessments, people across Germany are listening, and it often determines public opinion. How well are you able to live with that responsibility?</p><p><strong>Drosten:</strong> It doesn't rob me of sleep. From the very beginning, I hoped that this public role would be shared among several people. And luckily, that is happening.</p><p><strong>DER SPIEGEL:</strong> Last year, experts who have argued time and again against scientifically proven measures – e.g. Jonas Schmidt-Chanasit and Hendrik Streeck – likely did more damage than corona-truthers. Protecting high-risk groups must have priority, you frequently heard from their group. Yet it has long-since been clear that doing so is impossible when case numbers are high. At what point do you lose your patience?</p><p><strong>Drosten:</strong> Are you trying to get me to criticize colleagues by name? I don't think much of personal attacks.</p><p><strong>DER SPIEGEL:</strong> We are more interested in a fundamental point. Many such experts awaken the impression that only opinions are important in science, and not evidence. That undermines the credibility of researchers who take a more serious approach. How do you deal with that?</p><p><strong>Drosten:</strong> Like most scientists, …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5">https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876682</guid>
            <pubDate>Fri, 22 Jan 2021 21:43:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weak Men Are Superweapons (2014)]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 148 (<a href="https://news.ycombinator.com/item?id=25876554">thread link</a>) | @skinkestek
<br/>
January 22, 2021 | https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons | <a href="https://web.archive.org/web/*/https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">

<p><span>May 12, 2014</span>
</p>
<h3>I</h3>
<p>There was an argument on Tumblr which, like so many arguments on Tumblr, was terrible. I will rephrase it just a little to make a point.
</p>
<p>Alice said something along the lines of “I hate people who frivolously diagnose themselves with autism without knowing anything about the disorder. They should stop thinking they’re ‘so speshul’ and go see a competent doctor.”
</p>
<p>Beth answered something along the lines of “I diagnosed myself with autism, but only after a lot of careful research. I don’t have the opportunity to go see a doctor. I think what you’re saying is overly strict and hurtful to many people with autism.”
</p>
<p>Alice then proceeded to tell Beth she disagreed, in that special way only Tumblr users can. I believe the word “cunt” was used.
</p>
<p>I notice two things about the exchange.
</p>
<p>First, why did Beth take the bait? Alice said she hated people who <em>frivolously</em> self-diagnosed <em>without knowing anything about the disorder</em>. Beth clearly was not such a person. Why didn’t she just say “Yes, please continue hating these hypothetical bad people who are not me”?
</p>
<p>Second, why did <em>Alice</em> take the bait? Why didn’t she just say “I think you’ll find I wasn’t talking about you?”
</p>
<h3>II</h3>
<p>One of the cutting-edge advances in fallacy-ology has been the <a href="http://www.scientificamerican.com/article/getting-duped/" rel="nofollow">weak man</a>, a terribly-named cousin of the straw man. The straw man is a terrible argument nobody really holds, which was only invented so your side had something easy to defeat. The weak man is a terrible argument that only a few unrepresentative people hold, which was only <em>brought to prominence</em> so your side had something easy to defeat.
</p>
<p>For example, “I am a proud atheist and I don’t like religion. Think of the terrible things done by religion, like the actions of the Westboro Baptist Church. They try to disturb the funerals of heroes because they think God hates everybody. But this is horrible. Religious people can’t justify why they do things like this. That’s why I’m proud to be an atheist.”
</p>
<p>It’s not a straw man. There really is a Westboro Baptist Church, for some reason. But one still feels like the atheist is making things just a little too easy on himself.
</p>
<p>Maybe the problem is that the atheist is indirectly suggesting that Westboro Baptist Church is typical of religion? An implied falsehood?
</p>
<p>Then suppose the atheist posts on Tumblr: “I hate religious people who are rabidly certain that the world was created in seven days or that all their enemies will burn in Hell, and try to justify it through ‘faith’. You know, the sort of people who think that the Bible has all the answers and who hate anyone who tries to think for themselves.”
</p>
<p>Now there’s practically no implication that these people are typical. So that’s fine, right?
</p>
<p>On the other side of the world, a religious person is writing “I hate atheists who think morality is relative, and that this gives them the right to murder however many people stand between them and a world where no one is allowed to believe in God”.
</p>
<p>Again, not a straw man. The Soviet Union contained several million of these people. But if you’re an atheist, would you just let this pass?
</p>
<p>How about “I hate black thugs who rob people”?
</p>
<p>What are the chances a black guy reads that and says “Well, good thing I’m not a thug who robs people, he’ll probably <em>love</em> me”?
</p>
<h3>III</h3>
<p>What is the problem with statements like this?
</p>
<p>First, they are meant to re-center a category. Remember, people think in terms of categories with central and noncentral members – a sparrow is a central bird, an ostrich a noncentral one. But if you live on the Ostrich World, which is inhabited only by ostriches, emus, and cassowaries, then probably an ostrich seems like a pretty central example of ‘bird’ and the first sparrow you see will be fantastically strange.
</p>
<p>Right now most people’s central examples of religion are probably things like your local neighborhood church. If you’re American, it’s probably a bland Protestant denomination like the Episcopalians or something.
</p>
<p>The guy whose central examples of religion are Pope Francis and the Dalai Lama is probably going to have a different perception of religion than the guy whose central examples are Torquemada and Fred Phelps. If you convert someone from the first kind of person to the second kind of person, you’ve gone most of the way to making them an atheist.
</p>
<p>More important, if you convert a culture from thinking in the first type of way to thinking in the second type of way, then religious people will be unpopular and anyone trying to make a religious argument will have to spend the first five minutes of their speech explaining how they’re not Fred Phelps, honest, and no, they don’t picket any funerals. After all that time spent apologizing and defending themselves and distancing themselves from other religious people, they’re not likely to be able to make a very rousing argument for religion.
</p>
<h3>IV</h3>
<p>In <a href="https://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/" rel="nofollow">Cowpox of Doubt</a>, I mention the inoculation effect. When people see a terrible argument for an idea get defeated, they are more likely to doubt the idea later on, even if much better arguments show up.
</p>
<p>Put this in the context of people attacking the Westboro Baptist Church. You see the attacker win a big victory over “religion”, broadly defined. Now you are less likely to believe in religion when a much more convincing one comes along.
</p>
<p>I see the same thing in atheists’ odd fascination with creationism. Most of the religious people one encounters are not young-earth creationists. But these people have a dramatic hold on the atheist imagination.
</p>
<p>And I think: well, maybe if people see atheists defeating a terrible argument for religion enough, atheists don’t <em>have to</em> defeat any of the others. People have already been inoculated against religion. “Oh, yeah, that was the thing with the creationism. Doesn’t seem very smart.”
</p>
<p>If this is true, it means that all religious people, like it or not, are in the same boat. An atheist attacking creationism becomes a deadly threat for the average Christian, even if that Christian does not herself believe in creationism.
</p>
<p>Likewise, when a religious person attacks atheists who are moral relativists, or communists, or murderers, then all atheists have to band together to stop it somehow or they will have successfully poisoned people against atheism.
</p>
<h3>V</h3>
<p>This is starting to sound a lot like <a href="http://squid314.livejournal.com/329171.html" rel="nofollow">something I wrote on my old blog about superweapons</a>.
</p>
<p>I suggested imagining yourself in the shoes of a Jew in czarist Russia. The big news story is about a Jewish man who killed a Christian child. As far as you can tell the story is true. It’s just disappointing that everyone who tells it is describing it as “A Jew killed a Christian kid today”. You don’t want to make a big deal over this, because no one is saying anything objectionable like “And so all Jews are evil”. Besides you’d hate to inject identity politics into this obvious tragedy. It just sort of makes you uncomfortable.
</p>
<p>The next day you hear that the local priest is giving a sermon on how the Jews killed Christ. This statement seems historically plausible, and it’s part of the Christian religion, and no one is implying it says anything about the Jews today. You’d hate to be the guy who barges in and tries to tell the Christians what Biblical facts they can and can’t include in their sermons just because they offend you. It would make you an annoying busybody. So again you just get uncomfortable.
</p>
<p>The next day you hear people complain about the greedy Jewish bankers who are ruining the world economy. And really a disproportionate number of bankers are Jewish, and bankers really do seem to be the source of a lot of economic problems. It seems kind of pedantic to interrupt every conversation with “But also some bankers are Christian, or Muslim, and even though a disproportionate number of bankers are Jewish that doesn’t mean the Jewish bankers are disproportionately active in ruining the world economy compared to their numbers.” So again you stay uncomfortable.
</p>
<p>Then the next day you hear people complain about Israeli atrocities in Palestine (what, you thought this was past czarist Russia? This is future czarist Russia, after Putin finally gets the guts to crown himself). You understand that the Israelis really do commit some terrible acts. On the other hand, when people start talking about “Jewish atrocities” and “the need to protect Gentiles from Jewish rapacity” and “laws to stop all this horrible stuff the Jews are doing”, you just feel worried, even though you personally are not doing any horrible stuff and maybe they even have good reasons for phrasing it that way.
</p>
<p>Then the next day you get in a business dispute with your neighbor. Maybe you loaned him some money and he doesn’t feel like paying you back. He tells you you’d better just give up, admit he is in the right, and apologize to him – because if the conflict escalated everyone would take his side because he is a Christian and you are a Jew. And everyone knows that Jews victimize Christians and are basically child-murdering Christ-killing economy-ruining atrocity-committing scum.
</p>
<p>You have been boxed in by a serious of individually harmless but collectively dangerous statements. None of them individually referred to you – you weren’t murdering children or killing Christ or owning a bank. But they ended up getting you in the end anyway.
</p>
<p>Depending on how likely you think this is, this kind of forces Jews together, makes them become strange bedfellows. You might not like what the Jews in Israel are doing in Palestine. But if you think someone’s trying to build a superweapon against you, and you don’t think you can differentiate yourself from the Israelis reliably, it’s in your best interest to defend them anyway.
</p>
<h3>VI</h3>
<p>I wrote the superweapon post to address some of my worries about feminism, so it would not be surprising at all if we found this dynamic there.
</p>
<p>Feminists tend to talk about things like “Men tend to silence women and not respect their opinions” or “Men treat women like objects …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons">https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons</a></em></p>]]>
            </description>
            <link>https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876554</guid>
            <pubDate>Fri, 22 Jan 2021 21:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why it's bad to have a high GDP]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876206">thread link</a>) | @wooque
<br/>
January 22, 2021 | https://lukesmith.xyz/articles/gdp | <a href="https://web.archive.org/web/*/https://lukesmith.xyz/articles/gdp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    


    <p>by <a href="https://lukesmith.xyz/index.html">Luke Smith</a>, originally a blog post in November 2018, rewritten for this website.</p>

    <h2>To put it in other words...</h2>

<p>
The common way of looking at Gross Domestic Product (GDP) is that it's a metric of economic success: more GDP is more wealth.
Wealth is good. "Poverty" (meaning low <em>per capita</em> GDP) is bad.
Nowadays, pretty much everyone talks about "economics" like this as if this truism was scribbled on the back walls of the cosmos.
</p>

<p>
This is just looking at one side of the ledger in a kind of global double-entry accounting book.
A logically equivalent way of looking at it is that <strong>GDP is a metric of economic exchange required for survival in society as it exists</strong>.
You can say that some area "produced" $1 billion of output (sounds good), but you can just as easily say that $1 billion was required for that area to sustain itself (sounds bad).
These two are simply logically equivalent.
</p>

<h2>Living on $1 a day</h2>

<figure>
<a href="https://lukesmith.xyz/articles/pix/ivanov01.jpg">
<img alt="Hyperborea" title="(((They))) don't want you to know about this." src="https://lukesmith.xyz/articles/pix/ivanov01s.jpg">
</a>
<figcaption>Antediluvian Hyperborea. GDP: $0 per year.</figcaption>
</figure>

<p>
Let's dive into the Gestalt: when you hear that a family of eight lives on less than a dollar per day (PPP adjusted), you might wonder how they manage!
To <em>actually</em> do such a thing would require buying large bags of rice for the whole family, eat only that and live in free cardboard boxes.
</p>

<p>
The reality is that that often uttered phrase means that they use less than $1 a day in the general economy, while the rest of their livelihood is "off-the-grid" or self-sufficient.
They may grow food in a family farm, hunt for food, and most of their daily needs from cooking oils, to plates, to pottery, to soap are often made at home as well.
</p>

<p>
There is still "an economy" but often one that is barter based or <em>socialist</em> in the real pre-socialist sense of the word: mediated by direct face-to-face social tit-for-tat between neighbors and friends, none of this mediated by currency being exchanged, thus it is not part of the GDP.
</p>

<p>
If you read about some Bangladeshi village where the only product is "textiles", that doesn't mean that everyone there makes textiles all day and, without a textile company, everyone would've starved to death.
It means that the only on-paper, measurable global industry practiced there is textile manufacturing.
Other villagers might farm, hunt, even do some kind of gathering in some places.
They will produce the arts and crafts and live the way people live when you leave them alone.
If your view of the world is mediated by GDP, you're only seeing the extremely small sliver that pops into existence when people exchange something involving legal tender.
</p>

<p>
This is extremely difficult for us modern bugpeople to understand because to be a bugman in a large city is to produce absolutely nothing on one's own and buy literally everything you need from the store.
To us non-productive people, GDP means income which means survival.
But the further out of Bugmanville you go, the clearer the vacuousness of GDP becomes.
When you realize that most of human wealth is unmeasured by GDP, you realize that Whig History and Steven Pinkerism is based on shaky foundations.
</p>

<h2>Example</h2>

<p>
A minor example.
We had a large Thanksgiving feast near my uncle's house in very rural Florida.
As it got cold in the night, we had a fire in a repurposed old sugar cane cooking vat artfully standing on used symmetrical cinderblock pieces.
A bugman hipster might pay two hundred dollars or more for a similar looking "authentic" piece of equipment. Those $200 would be counted in the GDP.
A bugman hipster might have also bought or rented chairs for the event, "contributing" more to the GDP, but my uncle, as part of the local wholesome church community, simply borrowed some from the church.
Thus our event produced basically no GDP output in goods or services, despite being functionally equivalent to some similar but expensive and ergo "productive" "Friendsgiving" practiced by urbanites.
In reality <em>we</em> are richer than the bugmen hipsters who blew hundreds of dollars on a faux-folksy party.
In this case, we owned the firepit and had easy access and permission to the chairs, thus we are more economically flexible than they are.
That GDP that they produced/expended is evidence of deeper reliance on the economic system.
That GDP output is a marker of <em>fragility</em>, reliance on the conditions of the outside economy in the same way that a village of Bangladeshis who abandon their traditional way of lives to work on textiles are more fragile, despite being able to save up for iPhones.
</p>

<h2>What GDP really measures</h2>

<p>
<strong>Most of the increase in GDP across the world is simply the movement from local partially-social partially-under-the-table economies to economies mediated by taxable currency.</strong>
An economically self-sufficient village with close social relationships and a barter economy has 0 GDP.
A township of entrepreneurs and artisans you partially barter and partially use currency which they don't report has 0 GDP.
All of these people are "in poverty" and "earn less than a dollar a day".
And if you want to be truly self-sufficient, that means having a personal GDP of zero.
</p>

<p>
More than that, pretty much everywhere, GDP is a strong indicator of social upheaval.
If you think that GDP is some eternal goodness, remember that <em>everything "good" about industrialization shows up in the GDP</em>, while at the same time, <em>everything bad about it will not show up</em>.
Or, sometimes bad things are registered as positive economic growth: urbanization has caused mass-disease, and if that means a market for new medical services and pharmaceuticals, great!
The GDP just went up!
The Ganges is polluted due to the textile plant? That just means more opportunities for local entrepreneurs to sell bottled water!
The GDP just went up!
Are people being pushed out of fishing or other subsistence occupations because of it? Even better! Now they have no choice but to contribute to the GDP!
With every passing year, in fact, more and more of the GDP is produced by dealing with the problems that our higher level of GDP have caused.
</p>

<p>
At the end of the day, <strong>GDP is only a measurement of how reliant a place or country is on the global economy</strong>.
Self-sufficiency has a GDP of 0.
Wasteful consooomerism has an extremely large GDP.
</p>

<h2>Planned obsolescence</h2>

<p>
I have one of my great grandfather's early electric circular saws.
It has a bunch of gunk in it, but it still works (although I recently took it apart to replace some old screws and springs and other little parts to be careful).
They literally do not make circular saws like it; it's all metal, while even the fancy modern stuff is mostly plastic.
</p><p>
The "unfortunate" thing about it and other durable tools is that it's "bad for the economy," especially the GDP.
Since that thing has been around since maybe the 50's or 60's, that's as long as 70 years the economy has gone without the "stimulation" of us having to buy another saw.
</p>

<p>
Viewers of my technology videos: Which would be better for the world, if everyone used the material equivalent of a classic American-made IBM ThinkPad, or some Apple Laptops that are unfixable computers made of mostly batteries designed to conk out right before the new version comes out?
Regardless, the Apple Macs that cost thousands a piece are much better for the "economy."
</p>

<p>
That's what I mean.
If you have quality tools and do not need to constantly throw money at the system to buy things, fix things and otherwise waste money, you are going to be having a lower GDP.
That's just how it is.
</p>

<h2>The propagandistic role of GDP</h2>

<p>
When you don't think things through like this, GDP is supposed to appear as an objective measure of economic goodness.
You're supposed to be looking at those GDP charts and saying, "Wow, my life might be terrible, I am not free, I am subject to forces out of my control, and I and told I have to participate in mass-consumerism to survive, but these charts are the facts[!], and the facts say that things are better now, so I believe them!"
</p>

<p>
It's legitimately surprising to me how big of a boon the idea of increasing GDP is for Whig history and NPCs of many different ideologies.
People of the Left and Right will matter-of-factly tell me that a plastic based economy taking over the world is still good because the line is going up.
I've heard it as a justification for everything:
</p>


<blockquote>
    Don't like globalization?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't trust state-funded institutionalized science?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want child drag queens?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want everything to be made of plastics and other petrochemicals?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want mass pornography?<br>
    <span>You're wrong, the GDP is going up.</span><br>
    Don't want free sugary drinks since infancy?<br>
    <span>You're wrong, the GDP is going up.</span><br>
</blockquote>

<p>
When you abandon the illusion of GDP, you are suddenly able to ask whether
massive technological "progress" has <em>actually</em> been good for real human
life and human pychology.
</p>

    <hr>

    



</div>]]>
            </description>
            <link>https://lukesmith.xyz/articles/gdp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876206</guid>
            <pubDate>Fri, 22 Jan 2021 20:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.NET GC Internals mini-series]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25876087">thread link</a>) | @GordonS
<br/>
January 22, 2021 | https://tooslowexception.com/net-gc-internals-mini-series/ | <a href="https://web.archive.org/web/*/https://tooslowexception.com/net-gc-internals-mini-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-625">
	
		
	
	<div itemprop="articleBody">
				<p>I’ve decided to make a series of at least <a href="https://www.youtube.com/playlist?list=PLpUkQYy-K8Y-wYcDgDXKhfs6OT8fFQtVm" target="_blank">8 free weekly-based webinars</a> about<strong> in-depth implementation details of the .NET GC</strong> and… I’m super happy with it! Why the idea? Many <strong>my other activities are about more practical “.NET memory management”</strong>, like <a href="https://prodotnetmemory.com/" target="_blank">my book</a> or <a href="https://workshop.prodotnetmemory.com/" target="_blank">workshops/trainings/consultancy</a> I gave. But during all this practical-oriented events t<strong>here is always not enough time</strong> to explain in details how .NET GC is implemented. Obviously, I always explain some concepts and algorithms, to the level that helps in understanding the whole concept. But not with the level of details that I am satisfied.</p>
<p>Hence the idea – make a separate <strong>content that will be just as deep as I like</strong> 🙂 So, I will cover details on the level of bits, bytes and source code, not only on the level of the overall algorithm description.</p>
<p>The first episode was yesterday, feel invited to watch:</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/8i1Nv7wGsjk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>

<p>The topics I’ve covered in the first module:</p>
<ul>
<li>the whole series roadmap</li>
<li>some fundamentals like reference counting (including more modern algorithms) and tracing GC</li>
<li>.NET GC types and its history</li>
<li>first dive into the .NET 5 runtime source code, including the first breakpoints in the famous 40 kLOC gc.cpp</li>
</ul>
<p>And the whole <a href="https://www.youtube.com/playlist?list=PLpUkQYy-K8Y-wYcDgDXKhfs6OT8fFQtVm" target="_blank">playlist is also available on YouTube</a>.</p>
<p>The topics I will cover during the whole series are as follows:</p>
<p><a href="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02.png"><img src="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-1024x535.png" alt="gcwebinar02" width="720" height="376" srcset="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-1024x535.png 1024w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-300x157.png 300w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-768x401.png 768w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02.png 1402w" sizes="(max-width: 720px) 100vw, 720px"></a></p>
<p>And we will see whethere it ends after eight episodes, or maybe a new interesting topics will emerge (including, from your questions).</p>
<p>Have a nice watch!</p>
							</div>
		</article></div>]]>
            </description>
            <link>https://tooslowexception.com/net-gc-internals-mini-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876087</guid>
            <pubDate>Fri, 22 Jan 2021 20:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Analysis – Methodologies Introduction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875216">thread link</a>) | @rafaelgss
<br/>
January 22, 2021 | https://blog.rafaelgss.com.br/performance-methodologies | <a href="https://web.archive.org/web/*/https://blog.rafaelgss.com.br/performance-methodologies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<section>

<p>Poor performance costs the software industry millions of dollars annually in lost revenue, decreased productivity, increased development, hardware costs and damaged customer relations.</p>
<p>Most applications tend to focus on correctness over performance. The shift towards performance only occurs once it is seen as a problem.
When that happens, one rarely has time to dedicated towards improving it. This article aims to show you that <strong>there is no simple answer</strong>.
A lot of performance work should be done in early phases of development. For the rest of the article, the reader is considered having a role of Performance Engineer or “acting” as one.</p>
<p>In my experience, a strictly “agile” methodology (Idea -&gt; MVP -&gt; Feature -&gt; “Refactor”) tends to leave out proper performance engineering, since performance is not a goal but an expectation.</p>
<blockquote><p><em>Performance is a field where the more you know, the less you understand</em>.</p>
</blockquote>
<p>Regardless of the source, when a performance issue appears it should be fixed immediately. Two ways are: 1) modifying code/architecture or throwing money at additional hardware resources. The second path in some time will lead to the same problem down the line.</p>
<p>Prior starting performance analysis, you <strong>must</strong>  understand your application architecture. Any analysis requires clear boundaries and a full understanding of dependencies and third-party services.</p>
<p>A diagram of your software architecture is a great starting point.</p>
<blockquote><p>The foundation of your software should be resilient to achieve better results.</p>
</blockquote>
<h2>Monitoring</h2>
<p>Today, a big part of the market is adopting distributed systems. As we’ve come to learn, such systems adds a lot of complexity to your architecture in exchange for scalability and availability (resilience).</p>
<p>It also adds more components to your list of dependencies. Therefore, you should monitor these dependencies to have better visibility when things deviate from a happy path.</p>
<p>Each part of the architecture (or software) needs individual monitoring that helps us go back in time and answer some of these questions:</p>
<ul>
<li>When did the software start performing worse?
</li>
<li>During what timeframe are we seeing most activity?
</li>
<li>How are components behaving during these timeframes? Think: I/O latency, DNS resolution, CPU or RAM consumption
</li>
</ul>
<p>These questions will help to choose the right performance methodology to apply.</p>
<h2>Known-Unknowns</h2>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/diagram-known-unknowns.png" alt="Known Unknowns"></p>
<blockquote><p><em>This section is a reference to the book <a href="https://www.goodreads.com/book/show/18058001-systems-performance">System Performance</a> by the author Brendan Gregg.</em></p>
</blockquote>
<p>In performance analysis we can split information into three types:</p>
<ul>
<li>Know-Knows: These are things you know, for instance, you know that you should be checking CPU utilization <strong>and</strong> you know that the value is 10% on average.
</li>
<li>Know-Unknows: There are things that you know that you do not know. You know that an increase in API response time can be related to a third-party component, but you don’t have metrics showing it.
</li>
<li>Unknown-Unknowns: These are things you are unaware of not knowing. Confusing? For instance: you may not know that DNS resolution can become heavy I/O latency, so you are not checking them (because you didn’t know).
</li>
</ul>
<p>While creating architecture diagrams,  <em>unknowns-unknowns</em>  obviously aren’t mappable since you don’t know about them.</p>
<blockquote><p><code>unknown-unknows</code> are common. It is your job as a performance engineer to transform the <code>unknown-unknowns</code> into <code>know-unknows</code>.</p>
</blockquote>
<p>The Diagram above map <code>known-knowns</code> (Green box) and <code>known-unknows</code> (Red box)</p>
<h2>Observability Tools</h2>
<p>As previously mentioned, achieving observability in our software/architecture is fundamental to perform performance improvements. In this section, I’ll walk through a few tools that are great for this purpose.</p>
<h3>Tracing</h3>
<p>Tracing collects per-event data for analysis. Normally, tracing tools are not enabled by default since it adds CPU overhead to capture and send/store the data.</p>
<p>Logging (including system logs) can be seen as low-frequency tracing that is enabled by default.</p>
<p>Some common tools:</p>
<p><strong>system-wide</strong>:</p>
<ul>
<li><code>tcpdump</code>: network packet tracing
</li>
<li><code>perf</code>: Linux Performance Events (tracing static and dynamic probes)
</li>
</ul>
<p><strong>per-process</strong>:</p>
<ul>
<li><code>strace</code>: system call tracing
</li>
<li><code>USDT</code> (Userland Statically Defined Tracing)
</li>
<li><code>DTrace</code>: observability framework that includes a programming language and a tool.
</li>
</ul>
<p>TracePoints is a great way to observe your software in the production environment. You can use USDT (dynamic probes) or static tracepoints.
For further information check the <em>useful links</em> section.</p>
<h3>Profiling</h3>
<p>Profiling characterizes the target by collecting a set of samples of snapshots. CPU usage is a common example where samples are taken of the stack trace to characterize the code paths that are consuming CPU cycles.</p>
<p><strong>Note</strong>: For further information about Profiling CPU, I’ve made a blog post doing CPU Profiling in a Node.js application. <a href="https://blog.rafaelgss.com.br/node-cpu-profiler">Check here</a>.</p>
<p>Tools:</p>
<ul>
<li><code>perf</code>: Linux Performance Events (profiling)
</li>
<li><code>cachegrind</code>: a Valgrind sub tool, can profile hardware cache usage and be visualized using <code>kcachegrind</code>
</li>
</ul>
<blockquote><p><code>/proc</code> is a file system interface for kernel statistics, it contains directories where each directory is named after the <strong>PID</strong> of the process. These directories contain a number of files containing information and statistics about each process mapped from kernel data structures.</p>
</blockquote>
<p><img src="https://pbs.twimg.com/media/DZ3HpVXXkAEgxpc?format=jpg&amp;name=large" alt="Julia Evans - Comic /proc"> - <a href="https://twitter.com/b0rk/status/981159808832286720/photo/1">reference</a></p>
<h2>Methodologies</h2>
<p>This section will describe three of the most used methodologies (by me at least). Apply a methodology when performance issues start showing up; there is no rule about choosing the best approach.
Previous experience with your software architecture will likely be the best way to make a decision.</p>
<h3>USE</h3>
<p>Utilization, Saturation and Errors (USE) is an methodology that <strong>should be used early in performance investigation</strong>. For every resource, check the utilization, saturation, and errors:</p>
<ul>
<li><strong>Resource</strong>: server components (CPU, buses, …)
</li>
<li><strong>Utilization</strong>: for a set time interval, the percentage of time that the resource was busy servicing work. While busy, the resource may <strong>still be able to accept more work</strong>.
</li>
<li><strong>Saturation</strong>: additional work to be done, likely waiting in a queue. Jobs that cannot be dealt with instantly.
</li>
</ul>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/workflow-use.png" alt="Workflow with USE Methodology"></p>
<p>Its important to consider that it can be counter-intuitive; a short burst of high utilization can introduce saturation and performance issues even though the overall utilization is low over a long interval. CPU utilization <strong>can change dramatically from second to second</strong> so a 5-minute average may disguise short periods of 100% utilization and therefore lead to saturation.</p>
<p>Note: The saturation could not be easier to identify.</p>
<p>The first step is to create a list of resources:</p>
<ul>
<li><strong>CPUs:</strong> sockets, cores, hardware threads (virtual CPUs)
</li>
<li><strong>Main memory</strong>: DRAM
</li>
<li><strong>Network interfaces</strong>: Ethernet ports
</li>
<li><strong>Storage devices</strong>: disks
</li>
<li><strong>Controllers</strong>: storage, network
</li>
<li><strong>Interconnects</strong>: CPU, memory, I/O
</li>
</ul>
<blockquote><p>Virtual resources are fundamentally different than dedicated hardware. Especially as your resources are both shared and intentionally throttled. Some - if not all - cloud providers make their money by overselling and betting on idle processes.</p>
</blockquote>
<p>The USE method is most effective for resources that suffer performance degradation under high utilization or saturation, leading to bottlenecks. Fortunately, they are not common system bottlenecks, as they are typically designed to provide an excess of throughput. Unfortunately, if they are the problem, can be difficult to solve.</p>
<p>After you get the list of resources, try to create some metrics for it:</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/list-resources-use.png" alt="List of resources to create metric"></p>
<p>The process of elimination is good for us. Eliminate a possible resource bottleneck may help us to focus on another resource limiting our scope.</p>
<h3>Drill Down</h3>
<p>The process iterates through deeper layers of the software stack – even to hardware if necessary – to find the root cause of the issue. I try to to apply this methodology in every part of the software stack. It’s usually harder to do so  without having the bigger picture; but as you get more experienced you start recognizing recurring issues.</p>
<blockquote><p>Collecting and monitoring metrics is fundamental. Without it, we cannot fix the bugs the components cause.</p>
</blockquote>
<p>Such deeper analysis may involve the creation of custom tools and inspection of source code (if available). Here is where most of the drilling takes place, peeling away layers of the software stack as necessary to find the root cause.</p>
<p>Imagine an application that after a month in an production environment has begun to perform poorly.</p>
<p><strong>Five Whys</strong></p>
<ol>
<li>A database has performing poorly for some queries. Why?
</li>
<li>It’s delayed by disk I/O due to memory paging. Why?
</li>
<li>Database memory usage has grown too large. Why?
</li>
<li>The allocator is consuming more memory than expected. Why?
</li>
<li>The allocator has a memory fragmentation issue.
</li>
</ol>
<p>This is a good real sample extracted from <a href="https://www.goodreads.com/book/show/18058001-systems-performance">System Performance</a> book. There is not limit to go deep into <em>Why?</em>, but, one has to when the software is performing well.</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/5-whys.png" alt="Five why - Drill Down"></p>
<h3>Scientific Method</h3>
<p>The <em>scientific method</em> studies the <em>unknown</em> by making hypotheses and testing them. The <code>unknown</code> here can mean the <code>unknown-unknown</code> as discussed in <a href="#know-unknowns"><code>Know-Unknows</code></a> section.</p>
<p>Every <em>scientific method</em> consists:</p>
<ol>
<li>Formulation of a question?
</li>
<li>Hypothesis
</li>
<li>Prediction
</li>
<li>Testing
</li>
<li>Analysis
</li>
</ol>
<blockquote><p>For more information about how <em>scientific methods</em>, see <a href="https://en.wikipedia.org/wiki/Scientific_method">here</a></p>
</blockquote>
<p>First, define a question based on performance problem; for instance: <em>Why does my application have degraded throughput?</em>.</p>
<p>Second, build a hypothesis about what the cause of poor performance may be. <em>CPU Miss rate</em>? Write a test to prove your theory by for instance using <code>Valgrind</code>.</p>
<p>Collect results from your previous step and analyze how it behaves over time. It will give you a better idea of what components are connected and ultimately affected.</p>
<p><strong>Note:</strong> Shaping a hypothesis requires a clear understanding of your software architecture. Versioning your architectural changes can play a key role in understanding sudden changes.</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/scientific-method-steps.png" alt="Scientific Method Steps"></p>
<h2>Memory</h2>
<p>Usually, when a system boots the memory usage starts to grow as the operating system uses available memory to cache file system improving performance.
A system may report that it has only 10 MB of available memory when it actually has 10 GB of file system cache that can be reclaimed by applications immediately when …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.rafaelgss.com.br/performance-methodologies">https://blog.rafaelgss.com.br/performance-methodologies</a></em></p>]]>
            </description>
            <link>https://blog.rafaelgss.com.br/performance-methodologies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875216</guid>
            <pubDate>Fri, 22 Jan 2021 19:25:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fundamental Mechanism of Scaling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875156">thread link</a>) | @ignoramous
<br/>
January 22, 2021 | https://brooker.co.za/blog/2021/01/22/cloud-scale.html | <a href="https://web.archive.org/web/*/https://brooker.co.za/blog/2021/01/22/cloud-scale.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>It's not Paxos, unfortunately.</p>


<p>A common misconception among people picking up distributed systems is that replication and consensus protocols—Paxos, Raft, and friends—are the tools used to build the largest and most scalable systems. It's obviously true that these protocols are important building blocks. They're used to build systems that offer more availability, better durability, and stronger integrity than a single machine. At the most basic level, though, they don't make systems scale.</p>

<p>Instead, the fundamental approach used to scale distributed systems is <em>avoiding</em> co-ordination. Finding ways to make progress on work that doesn't require messages to pass between machines, between clusters of machines, between datacenters and so on. The fundamental tool of cloud scaling is coordination avoidance.</p>

<p><strong>A Spectrum of Systems</strong></p>

<p>With this in mind, we can build a kind of spectrum of the amount of coordination required in different system designs:</p>

<p><em>Coordinated</em> These are the kind that use paxos, raft, chain replication or some other protocol to make a group of nodes work closely together. The amount of work done by the system generally scales with the offered work (<em>W</em>) and the number of nodes (<em>N</em>), something like O(<em>N</em> * <em>W</em>) (or, potentially, worse under some kinds of failures).</p>

<p><em>Data-dependent Coordination</em> These systems break their workload up into uncoordinated pieces (like shards), but offer ways to coordinate across shards where needed. Probably the most common type of system in this category is sharded databases, which break data up into independent pieces, but then use some kind of coordination protocol (such as two-phase commit) to offer cross-shard transactions or queries. Work done can vary between O(<em>W</em>) and O(<em>N</em> * <em>W</em>) depending on access patterns, customer behavior and so on.</p>

<p><em>Leveraged Coordination</em> These systems take a coordinated system and build a layer on top of it that can do many requests per unit of coordination. Generally, coordination is only needed to handle failures, scale up, redistribute data, or perform other similar management tasks. In the happy case, work done in these kinds of systems is O(<em>W</em>). In the bad case, where something about the work or environment forces coordination, they can change to O(<em>N</em> * <em>W</em>) (see <a href="http://brooker.co.za/blog/2019/05/01/emergent.html">Some risks of coordinating only sometimes</a> for more). Despite this risk, this is a rightfully popular pattern for building scalable systems.</p>

<p><em>Uncoordinated</em> These are the kinds of systems where work items can be handled independently, without any need for coordination. You might think of them as embarrassingly parallel, sharded, partitioned, geo-partitioned, or one of many other ways of breaking up work. Uncoordinated systems scale the best. Work is always O(<em>W</em>).</p>

<p>This is only one cut through a complex space, and some systems don't quite fit<sup><a href="#foot1">1</a></sup>.  I think it's still useful, though, because by building a hierarchy of coordination we can think clearly about the places in our systems that scale the best and worst. The closer a system is to the uncoordinated end the better it will scale, in general.</p>

<p><strong>Other useful tools</strong></p>

<p>There are many other ways to approach this question of when coordination is necessary, and how that influences scale.</p>

<p>The CAP theorem<sup><a href="#foot2">2</a></sup>, along with a rich tradition of other impossibility results<sup><a href="#foot3">3</a></sup>, places limits on the kinds of things systems can do (and, most importantly, the kinds of things they can offer to their clients) without needing coordination. If you want to get into the details there, the breakdown in Figure 2 of <a href="http://www.bailis.org/papers/hat-vldb2014.pdf">Highly Available Transactions: Virtues and Limitations</a> is pretty clear. I like it because it shows us both what is possible, and what isn't.</p>

<p>The <a href="https://arxiv.org/pdf/1901.01930.pdf">CALM theorem</a><sup><a href="#foot4">4</a></sup> is very useful, because it provides a clear logical framework for whether particular programs can be run without coordination, and something of a path for constructing programs that are coordination free. If you're going to read just one distributed systems paper this year, you could do a lot worse than <a href="https://arxiv.org/pdf/1901.01930.pdf">Keeping CALM</a>.</p>

<p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.411">Harvest and Yield</a> is another way to approach the problem, by thinking about when systems can return partial results<sup><a href="#foot4">4</a></sup>. This is obviously a subtle topic, because the real question is when your clients and customers can accept partial results, and how confused they will be when they get them. At the extreme end, you start expecting clients to write code that can handle any subset of the full result set. Sometimes that's OK, sometimes it sends them down the same rabbit hole that CALM takes you down. Probably the hardest part for me is that partial-result systems are hard to test and operate, because there's a kind of mode switch between partial and complete results and <a href="https://aws.amazon.com/builders-library/avoiding-fallback-in-distributed-systems/">modes make life difficult</a>. There's also the minor issue that there are 2<sup>N</sup> subsets of results, and testing them all is often infeasible. In other words, this is a useful too, but it's probably best not to expose your clients to the full madness it leads to.</p>

<p>Finally, we can think about the work that each node needs to do. In a <em>coordinated</em> system, there is generally one or more nodes that do O(<em>W</em>) work. In an uncoordinated system, the ideal node does O(<em>W</em>/<em>N</em>) work, which turns into O(1) work because <em>N</em> is proportional to <em>W</em>.</p>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> Like systems that coordinate heavily on writes by mostly avoid coordination on reads. <a href="https://www.usenix.org/legacy/event/usenix09/tech/full_papers/terrace/terrace.pdf">CRAQ</a> is one such system, and a paper that helped me fall in love with distributed systems. So clever, and so simple once you understand it.</li>
<li><a name="foot2"></a> Best described by <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.6951&amp;rep=rep1&amp;type=pdf">Brewer and Lynch</a>.</li>
<li><a name="foot3"></a> See, for example, Nancy Lynch's 1989 paper <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.5022">A Hundred Impossibility Proofs for Distributed Computing</a>. If there were a hundred of these in 1989, you can imagine how many there are now, 32 years later. Wow, 1989 was 32 years ago. Huh.</li>
<li><a name="foot4"></a> I wrote <a href="http://brooker.co.za/blog/2014/10/12/harvest-yield.html">a post</a> about it back in 2014.</li>
</ol>


</div></div>]]>
            </description>
            <link>https://brooker.co.za/blog/2021/01/22/cloud-scale.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875156</guid>
            <pubDate>Fri, 22 Jan 2021 19:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The widening gyre: how to decentralize Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25875107">thread link</a>) | @ur-whale
<br/>
January 22, 2021 | https://laanwj.github.io/2021/01/21/decentralize.html | <a href="https://web.archive.org/web/*/https://laanwj.github.io/2021/01/21/decentralize.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recent events have made me reflect on a few things in my life I was already thinking about for a while. Also, responses on social media have made me realize that people have <em>strange</em> expectations from me, and what my role in the Bitcoin Core project is.</p>

<h2 id="growth">growth</h2>

<p>Bitcoin has grown a lot since I started contributing to it in 2011. Some arrangements that were acceptable for a small scale FOSS project are no longer so for one runing a 600 billion dollar system. Market cap is famously deceptive, but my point is not about specific numbers here.</p>

<p>One thing is clear: this is a serious project now, and we need to start taking decentralization seriously.</p>

<h2 id="moving-on">moving on</h2>

<p>I realize I am myself somewhat of a centralized bottleneck. And although I find Bitcoin an extremely interesting project and believe it’s one of the most important things happening at the moment, I also have many other interests. It’s also particularly stressful and I don’t want it, nor the bizarre spats in the social media around it, to start defining me as a person.</p>

<h2 id="spreading-out">spreading out</h2>

<p>I will start by delegating my own tasks, and decreasing my involvement. I do not intend to stop contributing to Bitcoin, or even to the Bitcoin Core project, but I would like to remove myself from the critical path and take (even more) of a background role.</p>

<p>Note that we had a nice growth in development activity, and that maintenance of the code itself has already been spread over multiple people for a while. I’m not the most active maintainer. Looking at the number of git merges</p>

<div><div><pre><code>bitcoin<span>$ </span>git log <span>--pretty</span><span>=</span><span>"format:%cn"</span> <span>--merges</span> <span>--since</span><span>=</span>2020-01-01 | <span>sort</span>| <span>uniq</span> <span>-c</span>
    313 fanquake
     51 Jonas Schnelli
    727 MarcoFalke
      7 Pieter Wuille
     65 Samuel Dobson
    363 Wladimir J. van der Laan
</code></pre></div></div>

<p>Only about 24% of the merges were done by me, last year.</p>

<h2 id="plans">plans</h2>

<p>But there’s plenty of things left to figure out, from the top of my head:</p>

<ul>
  <li>
    <p>Decentralize distribution.</p>

    <ul>
      <li>
        <p>In the short run, transfer bitcoincore.org to an organization instead of private ownership. Reduce the “bus factor”.</p>
      </li>
      <li>
        <p>I think it would be good if some other organizations set up mirrors, so there is less incentive to try to take bitcoincore.org down.</p>
      </li>
      <li>
        <p>In the long run, move away from a website for code distribution completely. No matter who owns it, a website on the clearnet can be shut down with the press of a button, and it seems that the global internet is gearing up to make censorship increasingly easy. We need a decentralized web. For us, one option would be IPFS, which is starting to catch on. For the binaries themselves there’s already the option of downloading through torrents.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the release process, and release signing.</p>

    <ul>
      <li>
        <p>Delegate more parts of the release process. Other maintainers should be able to do a release without my involvement.</p>
      </li>
      <li>
        <p>Rename the GPG key used to sign <code>SHA256SUMS.asc</code> to “Bitcoin Core release signing key”, instead of having it in my personal title. Make some construct so that N of M (minimally) trusted gitian signers doing a succesful build automatically results in a signed distribution.</p>
      </li>
      <li>
        <p>Same for the native code signing for Windows and MacOS.</p>
      </li>
      <li>
        <p>Even better in the long run would be to split up the keys, e.g. though RSA threshold signing, so that the whole process is geographically distributed.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the development hub.</p>

    <ul>
      <li>It’s not clear whether github can be trusted to act in our interest in the long run. Although issues and PRs are backed up through the API, having to move somewhere else could give significant interruption in development. And hopping from provider to provider would be awful—ideally the whole thing would not rely on a central server <em>at all</em>. For this I’ve been watching the <a href="https://radicle.xyz/">radicle</a> project, a P2P distributed code collaboration platform. It’s not quite there yet, but seems promising.</li>
    </ul>
  </li>
</ul>

<p>Bitcoin is quite different in some of the requirements here from other FOSS projects, so we’ll have to develop some tools as we go. We could also, definitely, use some help here.</p>

<p>Some smaller things to consider:</p>

<ul>
  <li>
    <p>Find someone else who wants to do the IRC meeting chair instead of me. Or maybe rotate it between multiple people.</p>
  </li>
  <li>
    <p>Release (and release candidate) mails to the <code>bitcoin-dev</code> and <code>bitcoin-core-dev</code> lists will no longer be necessarily signed and sent by me.</p>
  </li>
  <li>
    <p>There’s some development specific tooling hosted by me (e.g. the PR notification bots on IRC and mastodon). As they are non-critical and only little time goes into maintaining them, I’m fine with this for now.</p>
  </li>
</ul>

<p>As for decentralizing Bitcoin’s node software itself:</p>

<ul>
  <li>Carl Dong’s <code>libbitcoin_kernel</code> work. Bitcoin Core is a large monolithic project which includes the consensus code, which is much more critical than the other parts. The kernel would be an isolated part with well-defined interface, and at some point, its own review flow for changes. The difference with previous <code>libbitcoin_consensus</code> plans is that the kernel is stateful: it includes UTXO management and validation. It however does not include P2P, mempool policy, wallet, GUI, and RPC code. It could be re-used in different clients, to have more diversity in clients, but without the risks of a deviating consensus implementation.</li>
</ul>

<p>Over the course of 2021 this will be my focus with regard to Bitcoin Core.</p>

  </div></div>]]>
            </description>
            <link>https://laanwj.github.io/2021/01/21/decentralize.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875107</guid>
            <pubDate>Fri, 22 Jan 2021 19:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple plans new MacBook Air with Magsafe, MacBook Pro with SD Card Slot]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874703">thread link</a>) | @fudgy
<br/>
January 22, 2021 | https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot | <a href="https://web.archive.org/web/*/https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <section>
            <h3>Why did this happen?</h3>
            <p>Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our <a href="https://www.bloomberg.com./notices/tos">Terms of Service</a> and <a href="https://www.bloomberg.com./notices/tos">Cookie Policy</a>.</p>
        </section>
        <section>
            <h3>Need Help?</h3>
            <p>For inquiries related to this message please <a href="https://www.bloomberg.com./feedback">contact our support team</a> and provide the reference ID below.</p>
            <p>Block reference ID: </p>
        </section>
    </section></div>]]>
            </description>
            <link>https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874703</guid>
            <pubDate>Fri, 22 Jan 2021 18:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avalonia 0.10.0 Release – A cross platform XAML framework for .NET]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874397">thread link</a>) | @wiso
<br/>
January 22, 2021 | http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release | <a href="https://web.archive.org/web/*/http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <dl>
        <dt>Published</dt>
        <dd>2020-12-29</dd>

        <dt>Author</dt>
        <dd>Steven Kirk</dd>

        <dt>Category</dt>
          <dd>Release</dd>
    </dl>
    <p>We are pleased to announce that <a href="https://github.com/AvaloniaUI/Avalonia">Avalonia</a> 0.10.0 has been
released.</p>
<p>0.10 is a huge update, it has been extensively tested and brings some great new features and improvements.</p>
<h2 id="fluent-theme">Fluent Theme</h2>
<p>The most noticable change for Avalonia 0.10 is a beautiful new Fluent theme. Now your Avalonia applications will look better than ever:</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/fluent-control-gallery-light.png" alt="Xaml Control Gallery">
<img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/fluent-control-gallery-dark.png" alt="Xaml Control Gallery">
<a href="https://github.com/AvaloniaUI/xamlcontrolsgallery">Xaml Control Gallery</a></p>
<p>The fluent theme is available in light and dark modes, and will be used by the 0.10 templates by default. It can be enabled in existing applications by including the following in your <code>App.axaml</code>:</p>
<pre><code>&lt;Application.Styles&gt;
  &lt;FluentTheme Mode="Light"/&gt;
&lt;/Application.Styles&gt;
</code></pre>
<p>Where <code>Mode</code> can be <code>Light</code> or <code>Dark</code>.</p>
<h2 id="new-controls">New Controls</h2>
<p>Along with the fluent theme, several new controls have been added:</p>
<h3 id="datepickertimepicker">DatePicker/TimePicker</h3>
<p>The <code>DatePicker</code> and <code>TimePicker</code> controls give you a standardized way to let users pick a localized date or time value value using touch, mouse, or keyboard input.</p>
<pre><code>&lt;DatePicker Header="Date of birth"/&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/datepicker.png" alt="Xaml Control Gallery"></p>
<h3 id="toggleswitch">ToggleSwitch</h3>
<p><code>ToggleSwitch</code> is a control that can be toggled between 2 states.</p>
<pre><code>&lt;ToggleSwitch OffContent="Power Off" OnContent="Power On"/&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/toggleswitch.png" alt="Xaml Control Gallery"></p>
<h3 id="label">Label</h3>
<p>The <code>Label</code> control allows a text label with a shortcut key to be assocated with a control such as a <code>TextBox</code> such that pressing Alt plus the shortcut key will focus the associated control:</p>
<pre><code>&lt;StackPanel&gt;
  &lt;!-- Pressing Alt+N will focus nameTextBox --&gt;
  &lt;Label Target="nameTextBox"&gt;_Name&lt;/Label&gt;
  &lt;TextBox Name="nameTextBox"&gt;
&lt;/StackPanel&gt;
</code></pre>
<p>The shortcut key is designated by prepending an underscore to the desired character in the <code>Label</code> content, <code>N</code> in this example.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4904">https://github.com/AvaloniaUI/Avalonia/pull/4904</a></li>
</ul>
<h2 id="compiled-bindings">Compiled Bindings</h2>
<p>Avalonia 0.10 includes experimental support for compiled bindings. When using compiled bindings, binding paths are verified at compile time and do not use reflection at runtime.</p>
<p>To enable compiled bindings, add an <code>x:DataType</code> attribute to your root control and use the <code>{CompiledBinding}</code> markup extension or set <code>x:CompileBindings="True"</code>.</p>
<pre><code>&lt;Window xmlns="https://github.com/avaloniaui"
        xmlns:x='http://schemas.microsoft.com/winfx/2006/xaml'
        x:Class="AvaloniaApplication"
        xmlns:vm="using:AvaloniaApplication.ViewModels" 
        x:DataType="vm:MainWindowViewModel"&gt;
  &lt;!-- The existence of the MyValue property will be checked at compile-time --&gt;
  &lt;TextBox Text="{CompiledBinding MyValue}"/&gt;
&lt;/Window&gt;
</code></pre>
<p><a href="http://avaloniaui.net/docs/advanced/compiled-bindings">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/2734">https://github.com/AvaloniaUI/Avalonia/pull/2734</a></li>
</ul>
<h2 id="unicode-support">Unicode Support</h2>
<p>Avalonia's <code>TextBlock</code> now correctly supports unicode characters.</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/unicode.png" alt="Unicode Support"></p>
<p>Full Unicode support for <code>TextBox</code> will be incoming in the near future.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3438">https://github.com/AvaloniaUI/Avalonia/pull/3438</a></li>
</ul>
<h2 id="box-shadows">Box Shadows</h2>
<p>Box shadows can now be applied to <code>Border</code> controls:</p>
<pre><code>&lt;Border BoxShadow="4 4 4 gray"
        Background="Silver"
        Margin="20"
        Padding="10"&gt;
  &lt;TextBlock&gt;Box Shadow&lt;/TextBlock&gt;
&lt;/Border&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/box-shadow.png" alt="Box Shadows"></p>
<p><a href="http://avaloniaui.net/docs/controls/border#box-shadows">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3871">https://github.com/AvaloniaUI/Avalonia/pull/3871</a></li>
</ul>

<p>DevTools has been completely revamped for the 0.10 release.</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/devtools.png" alt="DevTools"></p>
<p>The new features include:</p>
<ul>
<li>A built-in console using roslyn scripting which allows running arbitrary code</li>
<li>Editing of property values</li>
<li>Improved display and grouping of control properties</li>
<li>Filtering control properties using a string or regular expression</li>
<li>A visualization of a control's layout properties such as width, height, margins and padding:</li>
<li>Toggle an FPS overlay and dirty rect visualization for the window from DevTools from the "Options" menu</li>
</ul>
<p><a href="http://avaloniaui.net/docs/quickstart/devtools">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3462">https://github.com/AvaloniaUI/Avalonia/pull/3462</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4523">https://github.com/AvaloniaUI/Avalonia/pull/4523</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4529">https://github.com/AvaloniaUI/Avalonia/pull/4529</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4609">https://github.com/AvaloniaUI/Avalonia/pull/4609</a></li>
</ul>
<h2 id="typed-property-change-notifications">Typed Property Change Notifications</h2>
<p>The <code>OnPropertyChanged</code> method and <code>AvaloniaProperty&lt;T&gt;.Changed</code> observable APIs have been changed to use a typed <code>AvaloniaPropertyChangedEventArgs&lt;T&gt;</code> class to prevent boxing. Note that this is a <a href="https://github.com/AvaloniaUI/Avalonia/wiki/Breaking-Changes">breaking change</a>.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3255">https://github.com/AvaloniaUI/Avalonia/pull/3255</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4648">https://github.com/AvaloniaUI/Avalonia/pull/4648</a></li>
</ul>
<h2 id="selectionmodel">SelectionModel</h2>
<p>Selection on <code>SelectingItemsControl</code>-derived controls such as <code>ListBox</code> and <code>ComboBox</code> now implement their selection tracking via a <code>SelectionModel</code> which gives the following improvements:</p>
<ul>
<li>Selection ranges are now stored as a range of indexes, so selecting all items in a large list of for example 100,000 elements is now stored simply as a range of <code>0-99999</code>. Previously each selected item was added to a list, inflating memory usage</li>
<li>Selection now handles duplicate items</li>
<li>The selection model can be bound to a view model allowing fine control of the selected items at the view model layer</li>
</ul>
<p><a href="http://avaloniaui.net/docs/controls/listbox#selection">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4533">https://github.com/AvaloniaUI/Avalonia/pull/4533</a></li>
</ul>
<h2 id="breaking-changes">Breaking Changes</h2>
<p>See <a href="https://github.com/AvaloniaUI/Avalonia/wiki/Breaking-Changes">our wiki</a> for a list of breaking changes in this release.</p>
<h2 id="getting-started">Getting started</h2>
<p>Follow instructions <a href="http://avaloniaui.net/docs/quickstart">here</a>.</p>
<h2 id="support-and-contributing">Support and Contributing</h2>
<p>The best way to support Avalonia is to get involved, implement a feature, fix a bug or help test. See <a href="http://avaloniaui.net/contributing">contributing</a> for information on how to get started.</p>
<p>For commercial users, AvaloniaUI OÜ provides support packages and custom development services. Contact us at team@avaloniaui.net for more information.</p>
<p>Otherwise you can sponsor Avalonia financially via <a href="https://opencollective.com/Avalonia#sponsor">OpenCollective</a>.</p>
<p>We hope you enjoy developing with Avalonia - please let us know what you are building!</p>
<p><a href="https://github.com/grokys">grokys</a></p>

  </article></div>]]>
            </description>
            <link>http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874397</guid>
            <pubDate>Fri, 22 Jan 2021 18:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How hard should I push myself?]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 175 (<a href="https://news.ycombinator.com/item?id=25874374">thread link</a>) | @dshipper
<br/>
January 22, 2021 | https://superorganizers.every.to/p/how-hard-should-i-push-myself | <a href="https://web.archive.org/web/*/https://superorganizers.every.to/p/how-hard-should-i-push-myself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg&quot;,&quot;height&quot;:934,&quot;width&quot;:1400,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:181814,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>How hard should I push myself?</p><p>It’s a question I ask myself a lot, and I bet you do too. On the one hand I really want to push myself. I’m ambitious, I want to leave it all out on the field—some of my peak work moments have come from times when I’ve pushed myself to a place where I didn’t think I could go. We all have more ability to adapt to stress and pressure than we think we do.</p><p>On the other hand, I want to be kind to myself. I wonder how much the drive to push myself is really just a drive to make up for something that I feel is missing or inadequate—and whether pushing myself will actually fill the hole. I also sometimes wonder whether letting myself off the hook is just laziness masquerading as self-care. It’s hard to tell.</p><p>But importantly, I wonder whether pushing myself might, in fact, kill me. Constant pressure creates chronic stress, and there’s all sorts of scientific studies that show that chronic stress is really bad for you. It makes you more susceptible to heart disease, it makes it harder to recover from illnesses, it can affect your sleep, and it can even affect your working memory.</p><p>There’s also all sorts of literature (and conversations on Twitter) that says that stress is actually good for you.&nbsp;</p><p>What gives? How much stress is good, and how much is bad?&nbsp;</p><p>I think that in order to understand the question we posed at the top—how much we should be pushing ourselves—we have to better understand stress. We need to understand what the stress of pushing ourselves does to our bodies, how much we can take of it, and how we can, hopefully, learn to cope with it better.</p><p>That’s what <a href="https://us.macmillan.com/books/9780805073690">Why Zebra's Don't Get Ulcers</a> by Robert M. Sapolsky is about. Robert's a stress researcher, and as far as I can tell he's one of the good ones. He's the kind of intellectual who's smart, but also smart enough to know what he doesn't know. He's written a book, but he doesn't come across as trying to sell it to you—he's kind of like your zany self-aware smart-as-hell uncle who happens to study the stress responses of baboons for a living.</p><p>In the book Dr. Sapolsky harnesses his own research, as well as a wide array of animal and human studies to figure out the answer to a fairly simple question: how does stress work, and why do humans get stress-related diseases?&nbsp;</p><p>It’s an interesting question—you can understand why a human body might react poorly to not being fed enough. But why would psychological stress have dangerous consequences? The basic gist is this:&nbsp;</p><p>The stress response is built to get us out of danger. If you're an animal in the Serengeti and you're being chased by a lion you really, really want to have a stress response. Being stressed means you’re preparing your muscles to move—a lot. Your heart rate rises and pushes blood to your extremities. Glucose is released into your bloodstream to help run your muscles as fast as possible.&nbsp;</p><p>The stress response pushes certain parts of your body into high gear—but it also turns certain parts of your body off. For example, when you’re stressed digestion is inhibited. What’s the point of wasting energy on digesting food for later when you might not even survive for 10 more minutes? Reproduction is also inhibited. Same reason.&nbsp;</p><p>This is all well and good in the wild—you don't need to reproduce if a lion is eating your face off. But humans, and some more intelligent animals, have evolved the stress response from an unqualified Good Thing into...well, something that might kill you.</p><p>What’s different about our stress response? Well, we have the ability to <em>anticipate</em> danger. Other animals have this ability too: it’s a good thing to get stressed seeing the lion all the way across the savannah, instead of only when it mauls your intestines out. But humans have evolved this anticipation ability to extend far beyond other animals. We anticipate bad things months, years, or even decades out. And when we do this, the very same stress response gets turned on—even though there is no immediate danger, and there is no immediate way to avoid it.&nbsp;</p><p>Suddenly, you aren’t just activating the stress response for a few minutes when you’re running for your life. Instead, it’s activated all the time—chronically. And this is where the problems start.&nbsp;</p><p>Remember we mentioned earlier that the stress response amps some parts of your body into high gear, and turns off others? If you’re doing that chronically, you start to have problems. Suddenly, your digestive system isn’t just inhibited for a few minutes while you’re escaping danger. It’s chronically inhibited. The same thing happens with your immune system—chronic stress tamps it down, and makes it harder for you to fight off diseases. Stress is bad for your heart too—if you’re pumping blood as if you need to run from something all the time, you’re going to get high blood pressure.&nbsp;</p><p>In these cases, according to Sapolsky, “the stress response can become more dangerous than the stressor itself, especially when the stress is purely psychological.”</p><p>To be clear, stress doesn’t actually make you sick. But it does leave you more vulnerable to disease and illnesses than you otherwise would be—and those <em>can</em> make you very sick.</p><h3><strong>So is stress bad?</strong></h3><p>Stress isn’t good or bad. It’s a tool. In small doses it’s good, but too much of a good thing becomes a bad thing pretty quickly.</p><p>When your stress response is working properly it makes you run faster, your memory gets better, you’re able to focus better. But when your stress response is over-activated, or chronically activated—you get ulcers and heart disease. It’s bad!&nbsp;</p><p>A good analogy is exercise. Too little exercise and you open yourself up to a whole host of diseases, both physical and psychological. Too much, and you can actually kill yourself.&nbsp;</p><h3><strong>What do we do about it?</strong></h3><p>The answer to the question we posed at the top, then, is that it’s great to push yourself—but you should be paying attention to the signs that tell you that you need a break. And it’s to give yourself plenty of ways to manage stress while you’re going through it, so that it doesn’t affect you as badly as it could.</p><p>This is the really interesting nugget: stress isn’t mathematical. Expose the same person to the same stressor and they will have different stress responses based on their coping strategies. Which means if you want to live a life where you’re pushing yourself, it’s best to develop a variety of coping strategies to help you manage it.&nbsp;</p><p>Here’s what Sapolsky recommends:</p><h4><strong>Increase your sense of control</strong>.&nbsp;</h4><p>If you put a human in a room where loud noises are going off, you’ll activate their stress response. If you give the human a button to reduce the volume of the loud noises they’ll be less stressed—regardless of whether they even use the button.&nbsp;</p><p>What that means is, just knowing you have the <em>option</em> to reduce stress is enough to make something less stressful—even if you’re not actually controlling the stressors at all.&nbsp;</p><p>It’s why the first few sessions of therapy are often so powerful for patients. You’ve finally found a way to manage how you’re feeling, even though you probably haven’t changed too much about your life.</p><p>When you’re facing mild to moderate stressors, ask yourself, <em>How can I increase my sense of control in this situation?</em> You might find there are simple answers that will make you feel a lot better.</p><h4><strong>Increase your sense of predictability.</strong></h4><p>Rats that are exposed to repeated electric shocks are more likely to get ulcers. But if you ring a bell before you administer the shock—making the shock more predictable—the rats are less likely to get ulcers. If you make the stressor predictable, you only have to get stressed right before it happens. That means you’re not stressed the rest of the time, and therefore the stress response doesn’t wreak as much havoc on your body.</p><p>Making the stressors in your life more predictable can have a similar effect. When you see CEOs that keep their calendars clear and never do phone calls—you’re seeing the benefit of predictability in action.</p><p>Of course, we can’t make our lives totally predictable (and in fact that wouldn’t be desirable.) But the more you can expose yourself to stressors in a predictable way the better off you’ll be. For example, maybe only doomscroll on Twitter once a week. Or only check email a couple of times a day.</p><h4><strong>Create outlets for frustration.</strong></h4><p>When rats that are exposed to repeated stressors are given a piece of wood to gnaw on, they are far less likely to develop ulcers. Outlets for frustration are another important coping mechanism for stress.&nbsp;&nbsp;</p><p>There are many unproductive outlets—for example, taking things out on your partner or a co-worker. But there are also many productive ones, like exercise or journaling. Making a list of outlets and making sure to return to them again and again can reduce the havoc that chronic stress can wreak on your body.</p><h4><strong>Increase social support.</strong></h4><p>Social support is the last coping strategy on the list, and it’s perhaps my favorite one.</p><p>If you give a primate a stressor in the lab, you’ll find elevated markers of stress in its behavior and in its blood. But give the primate a stressor when it’s surrounded by friends—its stress markers will be lower, even for the same level of stressor.</p><p>The same thing happens in humans. For example, in one study parents of children who have been killed in war were no more likely to get disease or die—except if they were already widowed or divorced.</p><p>Creating a vibrant sense of social support can put an unmanageable stressor into perspective and help keep it under control. Without social support, even small things can set us off in ways that are unproductive and unhealthy.</p><h2><strong>What did you think of this article?</strong></h2><p><a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Amazing">Amazing</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Good">Good</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Meh">Meh</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Bad">Bad</a></p></div></div>]]>
            </description>
            <link>https://superorganizers.every.to/p/how-hard-should-i-push-myself</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874374</guid>
            <pubDate>Fri, 22 Jan 2021 18:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Address and POI Matching Without Writing Code]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874219">thread link</a>) | @kpaddie10
<br/>
January 22, 2021 | https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel | <a href="https://web.archive.org/web/*/https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Read more about the announcement in <a href="https://www.directionsmag.com/pressrelease/10385"><em>Directions Magazine</em></a>.</p><p>‍</p><p>Imagine you’re a retail brand trying to determine which of your stores performs best on a revenue-per-visit basis (RPV), compared to others. How would you solve this problem?</p><p>Analyses like these are interesting, because they require multiple disparate datasets to be brought together in order to tell a story. In this example, you’d be analyzing transaction data to calculate revenue per store over a certain time period, along with foot-traffic data. Maybe you’d even compare it against other variables like store age, square footage, and more. You would want to use data from different sources— store transaction data from <a href="https://www.affinity.solutions/">Affinity Solutions</a>, and foot traffic data from <a href="https://www.safegraph.com/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">SafeGraph</a>.<br></p><p>The tough thing about this approach is that you need all these datasets to talk to each other. Problems like these are why data scientists spend up to <a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=578166c86f63">80% of their time</a> doing <em>data preparation, </em>rather than driving insights. This situation is especially problematic when you’re working with location data, since many addresses don’t have standardization. A Target at 2626 E Stone Dr in one dataset might be listed as 2626 E Stone Dr Ste 90 in another, even though they’re the same store. A dataset indexed on the first address wouldn’t match the second.<br></p><p><a href="https://www.placekey.io/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">Placekey</a> was designed to solve address and POI matching problems like these. It works like this: an address or place name is inputted, and Placekey generates a unique, authoritative identifier that can be used for address and POI matching, deduplication, normalization, entity resolution, and more.&nbsp;<br></p><p>This week, Placekey officially announced the launch of its no-code solutions for <a href="https://workspace.google.com/marketplace/app/address_matching_by_placekey/611255445050">Google Sheets</a> and <a href="https://appsource.microsoft.com/en-us/product/office/WA200002522?tab=Overview">Excel</a>. What this means is that thorny address and POI matching problems can now be solved without writing a single line of code.</p><p>We’ll look at how <a href="https://www.affinity.solutions/">Affinity Solutions</a>, a leading provider for consumer purchase and intent behavior is using Placekeys appended to their data sets to make it easier to combine with other data sets and drive insights. For more context, you can check Nitin Duggal, Affinity’s Chief Product Officer discussing Placekey here:</p><figure id="w-node-4a727786a108-be1d9f6e"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/-WjKy-CK3Hs"></iframe></p></figure><p>This blog post will walk you through a practical example of a Placekey use case: where one is merging purchase intelligence information from Affinity, and places data from <a href="https://www.safegraph.com/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">SafeGraph</a>— all without code.<strong>‍</strong></p><p><strong>The Data: Affinity and SafeGraph</strong><br></p><p>Since<strong> </strong><a href="https://www.affinity.solutions/">Affinity</a> is the leading provider of purchase data intelligence, their dataset covers granular transactions, down to the individual store level. Here’s a sample of data about US-based Target stores:</p><figure id="w-node-95555a0afff4-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c41866be87357905e46_pasted%20image%200%20(11).png" loading="lazy" alt=""></p></figure><p>On the foot traffic data side, <a href="https://www.safegraph.com/">SafeGraph</a> aggregates anonymized location data from numerous applications, and generates information like number of visits, bucketed dwell times, and more. Here’s a sample of SafeGraph data for one US-based Target location:</p><figure id="w-node-3e414f5208fa-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c667e793011bcda6851_pasted%20image%200%20(12).png" loading="lazy" alt=""></p></figure><p><strong>The Problem: Merging Location-based Datasets is Really Hard</strong><br></p><p>While we want to merge these datasets together in order to leverage Affinity’s spend data and SafeGraph’s mobility information for each store, addresses weren’t invented in a time of machine-tooled standardization. Arbitrary format convention differences in point-of-interest or POI naming s make the task of joining location-based datasets together super hard. For example, in these two data sets above, the respective address formats differ considerably.</p><figure id="w-node-8d54ce993e7f-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c93e6ddc261570af0fe_pasted%20image%200%20(13).png" loading="lazy" alt=""></p></figure><p>To unlock the insights that come from bringing multiple datasets together, we need a way to cleanly merge address and POI data.<br></p><p><strong>The Solution: Meet Placekey</strong><br><a href="https://www.placekey.io/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">Placekey</a> is a universal standard identifier for a physical location, and it was created to solve problems like these. Placekey does the tough job of address and POI resolution, standardization, validation, and geolocation behind the scenes, producing instead a simple identifier that uniquely identifies a place. Here, the two different street names resolve to the same Placekey, which can then be used to merge the data together.</p><figure id="w-node-79f19d4e95e1-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0cb2e832196767475950_pasted%20image%200%20(14).png" loading="lazy" alt=""></p></figure><p>Now, using Placekey as a join key to merge these two datasets produces the below dataset:</p><figure id="w-node-3ed6da2d5ebb-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0cfc02432de21342ed01_pasted%20image%200%20(15).png" loading="lazy" alt=""></p></figure><p>Now, from these columns, it is possible to directly compute dollars spent per visit - an analysis which relies on data from both Affinity and SafeGraph, and gives a more holistic view of revenue-per-visitor (RPV) at a granular level. We can also leverage the store age column to produce the below plot of store age vs. conversion.</p><figure id="w-node-3a095848eb16-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0ce987306118ee90cfe4_imageLikeEmbed.png" loading="lazy" alt=""></p></figure><p><br><strong>Demo: Merging Affinity and SafeGraph Data Using the Placekey No-Code Integrations for Excel and Google Sheets&nbsp;</strong><br></p><p>To conduct a similar analysis, you can append Placekeys to your dataset using Excel or Google Sheets. Here’s how you do it:<br></p><ul role="list"><li>After loading your data into Excel (or Google Sheets), open the Placekey extension, and click “Generate Placekeys”.</li><li>Enter your API key (note: this is not always required). If you don’t yet have one, sign up for free <a href="https://dev.placekey.io/default/register">here</a> in a few seconds.</li><li>Open the first dataset you’re working with. Map the headers in the data (i.e. brand, street, city, state, and zip) to the relevant API field values, and when you’re done, click “Generate Placekeys”</li></ul><figure id="w-node-45eaf86adc10-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d7e55c3ac3341efb1c6_VJBq9jKrNxtRHhc_dBrUqPHLKjztah9WMIxAKLLJKxCzyCIEIhQm5LvmZYwPrXRIsq_MLA7NJchOMwVhSwl8vUpaNxFJBrOxTbki76wURGGyfjCV6NfuNGEk5S4m31dfrESv74j6.png" alt=""></p></figure><ul role="list"><li>After a few seconds, the Placekeys are appended to the data in a new column.</li></ul><figure id="w-node-d874ebb5fd9a-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d6face7fd52ffb5a1e3_pasted%20image%200%20(16).png" loading="lazy" alt=""></p></figure><ul role="list"><li>Repeat the same process on the data you would like to join. Here, the SafeGraph data already has a Placekey column, making it super easy to join in without any pre-processing.&nbsp;</li><li>Use a standard Google Sheets or Excel VLOOKUP function to merge the rows of the two datasets. Here, we highlight two relevant columns — spend data from Affinity and visits data from SafeGraph, plus a simulated value for the age of the store.</li></ul><figure id="w-node-5e078560ae0b-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d9612125f094b91615c_Bc_WWUQZg_xDdeCxE0-BuRAvglnxSooLagXQ6tvIJiIFbhT0TGcSmuyYWsPkuPQF-EJsWQVST-f-PD-YDRDvVH-QD-fJWJszu1CPnJqsTxLDbnWBdySZp4PLsSFS4S61o8GIuSOh.png" alt=""></p></figure><ul role="list"><li>From these columns, you can directly compute a measure of dollars spent per visit. As mentioned above, the store age column can also be leveraged to produce the below plot:</li></ul><figure id="w-node-3f488d7fa48d-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0dbc9d4c6158f07d5675_lbjMhl9cq1fxzd2OtRktHYaaOsyJbWRYUwmnngag3NQ7srwf4QPJ0FK52MIzq0-50ADb51SKn3xgA3tR6Y0sCrAhSq_S6k_zVH7fm3vgAcwcvoe3mKrgpFO2gLjtUQhYzNQX8F-P.png" alt=""></p></figure><p>This example demonstrates how any best-in-class transaction dataset can be joined to third-party data sources by leveraging Placekey to match addresses and POIs. Placekey opens the door for analyses such as this and many more to be performed by expanding the interoperability of different data solutions.</p><p>‍</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874219</guid>
            <pubDate>Fri, 22 Jan 2021 18:02:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned in my first year being CTO]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874094">thread link</a>) | @feross
<br/>
January 22, 2021 | https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6462">
	<!-- .entry-header -->

	
	
	<div>
		<br>
<blockquote><p>Happy New Year!</p><p>2020 was a difficult year for most of us, as we fought with COVID-19 and came to terms with the remote way of working. It was a year when we had a lot more time in our hands as all of us were locked in our houses with almost no travel. The things that we took for granted were taken from us and there was a constant fear of losing the loved ones.&nbsp;</p><p>I hope in 2021 we regain our freedom to live freely. But, this time with a sense of responsibility and awareness.&nbsp;</p></blockquote>



<p>It is now little over a year since I became Chief Technology Officer (CTO) in my current organization. And, I thought it will be a good time to do a quick retrospective on the lessons learned in my first year as CTO. The journey has been tough but deeply rewarding for me. There were occasions when I thought the leadership role was not for me and I should go back to being an individual contributor. But, with support from my organization and learning (books, blogs, observation), I have started to enjoy the role and its challenges.</p>



<p>Before I talk about the lessons I learned, let’s look at my software engineering journey.&nbsp;&nbsp;</p>



<h2>My software engineering journey</h2>



<ul><li>2005-2008: Software Engineer</li><li>2008-2012: Senior Software Engineer</li><li>2013-2014: Principal Technology Evangelist</li><li>2014-2019: Principal Engineer/Architect (during this period, I was in the role of Director, but I was neck-deep in writing code, building systems, and technology consulting)</li><li>2020-present: Chief Technology Officer (my first leadership/management role)</li></ul>



<p>Yes, this is my first leadership and management role. The leap from an individual contributor to a CTO was as much nerve-wracking as it was ambitious in terms of responsibilities.</p>



<p>Of course, along with this opportunity came its share of pros and cons. Nonetheless, I took the plunge and went through this transition without any preconceived notion.&nbsp;&nbsp;</p>



<h2>Defining the CTO role</h2>



<p>When I was told that I will be the next CTO, I immediately looked for a playbook that would describe and provide best practices and guide me on the rules of becoming a good, successful CTO. I wanted to be ready for the role and study the entire CTO literature available on the web. Guess what? There was no such playbook.&nbsp;</p>



<p>At the end of the day, it is always about learning on the job and not making the same mistake twice.&nbsp;</p>



<p>The first thing that I read was what people usually define the role of Chief Technology Officer as. Apparently, it is one of the most confusing C-level roles, and each CTO plays a bit differently. The best description of this role that I found was in an <a href="https://www.linkedin.com/pulse/five-flavors-being-cto-matt-tucker/">essay</a> by Matt Tucker. According to Matt, to better understand the role, you should break into five flavors.</p>



<figure><a href="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png"><img data-attachment-id="6464" data-permalink="https://shekhargulati.com/screenshot-2021-01-03-at-9-09-34-pm/" data-orig-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png" data-orig-size="1248,704" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2021-01-03-at-9.09.34-pm" data-image-description="" data-medium-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=300" data-large-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=840" src="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=1024" alt="" srcset="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=1024 1024w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=150 150w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=300 300w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=768 768w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png 1248w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a><figcaption>CTO Framework by Matt Tucker</figcaption></figure>



<p>I think the above framework gives a good mental model on how to think about the role of a CTO. Mostly, they come with a combination of two or more aforementioned flavors.&nbsp;</p>



<p>Let me share what my role, as a Chief Technology Officer, looks like. In my view, the framework (above) shared by Matt Tucker is from a product organization’s perspective. I am a CTO of an IT services organization, where this role gets diluted, fragmented and challenging because of the following additional factors:</p>



<ul><li>People are an important asset in any organization, but for an IT service organization, growth is directly proportional to the number of people. If you want to remain a niche service provider, then the story could be different.&nbsp;</li><li>You have to make modern technology accessible to large enterprises that are not ready for the change. In the last 5 years or so, there is a push towards digital transformation in most organizations. In my experience, organizations are now more open toward trying new technologies (React, Golang, Flutter, Cloud, Kubernetes) and architecture styles (Microservices, Event-driven, Serverless), more than ever before. This is a great news, but very few organizations understand the complexity introduced by these modern technology stacks. They are not doing the groundwork required to become the next Google in their domain. You can read my post <a href="https://medium.com/xebia-engineering/11-reasons-why-you-are-going-to-fail-with-microservices-29b93876268b"><em>11 Reasons Why You Are Going To Fail With Microservices</em></a>&nbsp;</li><li>There are not many good software engineers in the market with real experience in these modern technologies. Good software engineers are expensive and their financial and work aspirations are more aligned with product organizations. For an IT service organization, it is not possible to pay at the scale of product organizations.&nbsp;</li></ul>



<p>There is not much written about/by the CTOs of IT service organizations. It is not clear who should be your role model, so I will take Matt’s framework and define it for myself.</p>



<p>Here, you will see Matt’s framework modified by virtue of the flavors comprising my role. I have given a rough estimate on the time I had spent on each activity in the last year.&nbsp;</p>







<figure><a href="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png"><img data-attachment-id="6466" data-permalink="https://shekhargulati.com/screenshot-2021-01-03-at-9-09-48-pm/" data-orig-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png" data-orig-size="1240,1166" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2021-01-03-at-9.09.48-pm" data-image-description="" data-medium-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=300" data-large-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=840" src="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=1024" alt="" srcset="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=1024 1024w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=150 150w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=300 300w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=768 768w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png 1240w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a><figcaption>Modified CTO Framework</figcaption></figure>



<p>As you can see in the above table, I am everywhere. Luckily for me, I had less overhead in context switching. The main reason was I made sure that I never get involved in more than 2 tasks at a time.&nbsp;</p>



<p>In my first year as the CTO, I have built some level of delegation hierarchy. Hopefully, in the second year, I will be more focussed on a few of these flavors.</p>



<h2>Lessons learned in the first year</h2>



<p>So far, I have shared about my journey and the CTO role definition. Next, let me walk you through the lessons that I have learned in the first year as CTO.</p>



<h3>Lesson #0: You have to believe in yourself and ask for the role</h3>



<p>Most software engineers dream of becoming a CTO one day. This is how some of us define a successful engineering career. Someone will not make you the CTO just because you are the most capable software engineer/architect in your organization. You really need to have the hunger.&nbsp;</p>



<p>It took me close to 2-3 years before I was sure in my mind that I am ready to become a CTO. One of the reasons I thought I was not ready for a leadership role was Peter Principle.&nbsp;</p>



<blockquote><p>The Peter Principle is an observation that the tendency in most organizational hierarchies, such as that of a corporation, is for every employee to rise in the hierarchy through promotion until they reach a level of respective incompetence.</p></blockquote>



<p>I always took pride in being a competent software engineer/architect. The fear of becoming incompetent one day made me stick to the hands-on individual contributor role.</p>



<p>One thing that I realized was if I am not going to do the role, someone else will. Since, I knew the organization long enough and I have figured out my engineering leadership style, so why not give it a try. The most difficult part for me was asking for the role. The sad part is if you don’t ask people, they don’t give you what you deserve.&nbsp;</p>



<blockquote><p>Now, I’ve actually always found something to be very true, which is that most people don’t get those experiences because they never ask. I’ve never found anybody who didn’t want to help me when I’ve asked them for help – Steve Jobs [1]</p></blockquote>



<h3>Lesson #1: Schedule time for yourself</h3>



<p>A couple of weeks back, a colleague asked me how you are able to do deep work when you have to attend so many meetings. I discovered that people will add you to a meeting as soon as they find a free meeting slot in your calendar. I struggled with this for the first half of 2020.&nbsp; I was in meetings most of the day. Most of the thinking work that I did during this period was either after office hours or on weekends.&nbsp;</p>



<p>I changed my way of working in the second half after realizing that I can also schedule time&nbsp; with myself. Now, everyday I schedule a couple of hours to half a day with myself and do one deep work task. This way I am able to manage between maker schedule and manager schedule [2].</p>



<p>Another way, I avoid becoming a slave to my calendar, is by ensuring with the organizer whether my presence in the meeting is critical. At other times, I decline meetings when someone from my team is already attending.&nbsp;</p>



<h3>Lesson #2: Getting things done without doing them</h3>



<p>This is the challenge that most individual contributors face when they take up managerial/leadership roles. You know you can do the task better and faster. Thereby, you prefer to do the task yourself. This does not scale and you quickly become the bottleneck. And I bet you already know the answer.&nbsp;</p>



<p>The best way to scale yourself is through delegation. There are two parts in the delegation: what to delegate and which delegation level to apply.</p>



<p><strong>What to delegate</strong></p>



<p>In <em>How to Decide Which Tasks to Delegate </em>[3], Jenny Blake categorizes tasks into 6 categories which she calls 6 Ts.</p>



<ul><li><strong>Tiny</strong>: Tasks that are so small they seem inconsequential to tackle but they add up.</li><li><strong>Tedious</strong>: Tasks that are relatively simple probably are not&nbsp; the best use of your time.</li><li><strong>Time-consuming</strong>: Tasks that, although they may be important and even somewhat complex, are time-consuming and do not require you to do the initial 80% of research.</li><li><strong>Teachable</strong>: Tasks that, although complicated-seeming at first and possibly comprising several smaller subtasks, can be translated into a system and passed along, with you still providing quality checks and final approval.</li><li><strong>Terrible At</strong>: Tasks that not only do not fall into your strengths, but an area where you feel unequipped.</li><li><strong>Time sensitive</strong>: Tasks that are time-sensitive but compete with other priorities; there isn’t enough time to do them all at once, so you delegate an important and time-sensitive task so that it can be done in parallel to your other project-based deadlines.</li></ul>



<p>Tasks like organizing internal tech talks, operating internal infra, code reviews, junior engineer hiring I have delegated to others in my team.&nbsp;</p>



<p>Once you know which tasks to delegate, you have to use a delegation level that gets the best job done. I learnt about 7 levels of delegation at Management 30 website [4].</p>



<ol><li><strong>Tell</strong>: I will tell them&nbsp;</li><li><strong>Sell</strong>: I will try and sell it to them&nbsp;</li><li><strong>Consult</strong>: I will consult and then decide&nbsp;</li><li><strong>Agree</strong>: We will agree together&nbsp;</li><li><strong>Advise</strong>: I will advise but they decide&nbsp;</li><li><strong>I…</strong></li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/">https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/</a></em></p>]]>
            </description>
            <link>https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874094</guid>
            <pubDate>Fri, 22 Jan 2021 17:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting up Matrix Synapse on a delegated subdomain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25874010">thread link</a>) | @pngmangi
<br/>
January 22, 2021 | https://ansonvandoren.com/posts/matrix-server-digital-ocean/ | <a href="https://web.archive.org/web/*/https://ansonvandoren.com/posts/matrix-server-digital-ocean/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<h2 id="why-do-i-want-to-do-this">Why do I want to do this?</h2>
<p>That's a good question. I think the honest answer is because I had some spare time this week and I wanted to learn
something new. Part of me also says that after having left at least 5 different primary messaging platforms
over the last 20 years due to them either being killed off (looking at you, Google), or becoming irrelevant (ICQ anyone?),
or becoming too creepy (WhatsApp, WeChat), it might be worth investing in a chat platform that's under (mostly) my own
control.</p>
<p>I've seen bits and pieces about Matrix over the last couple of years, but never really investigated it much. I knew
that it was open source and self-hosted, but what I didn't know until yesterday is that it also has quite a few
<a href="https://matrix.org/bridges/">bridges</a> to connect to the chat apps I still do use. Most of my day-to-day chatting
right now is via Telegram, which has been working out pretty well for the last two years, but I'm not convinced
how much longer a Russian tech billionaire is going to want to keep self-funding the project, especially after
the TON ICO <a href="https://www.sec.gov/news/press-release/2019-212">was halted by the SEC</a>.</p>
<p>Anyway, if nothing else I'd learn a bit about the Matrix community, keep current on some sysadmin skills, and
build a little more feeling of ownership in the parts of the internet that I use on a daily basis. If I found
a lot of value in Matrix after it was up and running, maybe I'd try to get some of my normal contacts to add/switch,
or if not than I should be able to set up some bridging and still talk via my usual platforms, but with my own
copy of the chats on my private server, and the knowledge that I'd marginally improved my online privacy.</p>
<p>Before going too much further, I read the <a href="https://matrix.org/docs/guides/getting-involved">How can I get involved?</a>
page on the Matrix website, and spent a bit of time testing out the <a href="https://matrix.org/docs/projects/client/element">Element client</a>
in both the web and the desktop (Windows) app forms. Satisfied that it all seemed usable enough that I could
get used to it for a daily driver, I started investigating what it takes to self-host a
<a href="https://matrix.org/docs/guides/installing-synapse">Synapse server</a>.</p>
<h2 id="domain-name-setup-on-namecheap">Domain name setup on Namecheap</h2>
<p>First thing I need is a domain name to point at my new chat server. I already own several domain names (OK, domain collecting
is actually something of a bad habit of mine), but since the domain name of the server is reflected in one's Matrix
ID, I wanted to stick with <code>ansonvandoren.com</code>, to mirror both this website, and my email addresses. To complicate this just a bit,
I didn't want to use the same VPS that hosts my blog, and I also wanted Synapse to actually listen on a subdomain,
(e.g., <code>matrix.ansonvandoren.com</code>) instead of the domain name itself. Neither of these criteria makes the setup unmanageable,
but each adds a bit of complexity that I'll describe below.</p>
<p>My domain name is registered through <a href="https://namecheap.com/">NameCheap</a>, which has been an absolute pleasure to work
with over the last few years. Since the nameservers for <code>ansonvandoren.com</code> already point towards DigitalOcean, I don't
need to make any changes there.</p>
<p>If you're starting out from scratch and do need to point a Namecheap domain at a Digital Ocean droplet, you'll want the
“Custom DNS” setting, and the nameservers shown below:</p>
<p><img src="https://ansonvandoren.com/images/namecheap-nameservers.png" alt="Nameserver setup for Namecheap and DigitalOcean"></p>
<h2 id="droplet-creation-on-digital-ocean">Droplet creation on Digital Ocean</h2>
<p>I've been using Digital Ocean for hosting for years now and love their services. The price is right for the hobby
projects I usually take on, and the setup and maintenance is easy. If you're interested, here's a
<a href="https://m.do.co/c/4b40cdbde86d">referral link</a> you can use to sign up. <em>I'll get a small commission if you
sign up and keep using them, but it doesn't cost you anything</em>.</p>
<p>Based on the <a href="https://github.com/matrix-org/synapse/blob/master/INSTALL.md">Synapse installation guide</a>, the minimum
system requirements are 1GB of RAM. As you'll see later, it's fairly easy to limit the memory used even further if you
don't have many users on your homeserver. I chose an Ubuntu 20.04, Basic/Shared CPU $5/mo droplet with 1GB RAM, 1 (shared) CPU,
25GB storage, and 1000GB/mo bandwidth. Since I live in California, I chose a San Francisco datacenter. I selected IPv6 and Monitoring
options, and re-used my existing SSH keys from previous droplets. I chose a hostname of <code>matrix</code> and some relevant tags,
assigned it to my personal project, and enabled backups.</p>
<p>It takes a few moments to spin up. Before connecting the first time, I set up a subdomain record through DigitalOcean
(under the Networking menu) that points <code>matrix.ansonvandoren.com</code> to the newly created droplet. I did this for both an
A record and an AAA record (IPv4 and IPv6).</p>
<p><img src="https://ansonvandoren.com/images/digitalocean-dns.png" alt="DNS setup on Digital Ocean"></p>
<p>Since I chose to use a SSH key to login, I didn't need the Access Console at all, and
instead just connected from a terminal session using:</p>
<div><pre><code data-lang="sh">$ ssh root@matrix.ansonvandoren.com
</code></pre></div><p>It takes some time for the new DNS records to propagate, so if you get an error message like this, then try
using the IP address instead, or just wait an hour or so.</p>
<div><pre><code data-lang="sh">ssh: Could not resolve hostname matrix.ansonvandoren.com: No address associated with hostname
</code></pre></div><h2 id="initial-droplet-setup">Initial droplet setup</h2>
<p>Following the <a href="https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04">Initial Server Setup with Ubuntu 20.04</a>
documentation from Digital Ocean, I created a new non-root user, generated a memorable and secure password using
<a href="https://correcthorsebatterystaple.net/">Correct Horse Battery Staple</a>, and saved the new credentials in <a href="https://1password.com/">1Password</a>.</p>
<p>I finished out the guide by:</p>
<ul>
<li>Copying the SSH authorized_keys over to the new user</li>
<li>Making the new user a superuser</li>
<li>Setting up <code>ufw</code> firewall rules (allowing <code>OpenSSH</code>, <code>http</code>, <code>https</code>)</li>
<li>Updating Linux packages</li>
</ul>
<h2 id="installing-synapse">Installing Synapse</h2>
<p>I followed <a href="https://github.com/matrix-org/synapse/blob/master/INSTALL.md">these instructions</a> from the Matrix
Github page, installing the prebuilt packages for Ubuntu:</p>
<div><pre><code data-lang="sh">$ sudo apt install -y lsb-release wget apt-transport-https
$ sudo wget -O /usr/share/keyrings/matrix-org-archive-keyring.gpg https://packages.matrix.org/debian/matrix-org-archive-keyring.gpg
$ <span>echo</span> <span>"</span><span>deb [signed-by=/usr/share/keyrings/matrix-org-archive-keyring.gpg] https://packages.matrix.org/debian/ </span><span>$(</span>lsb_release -cs<span>)</span><span> main</span><span>"</span> |
    sudo tee /etc/apt/sources.list.d/matrix-org.list
$ sudo apt update
$ sudo apt install matrix-synapse-py3
</code></pre></div><p>During the installation, when prompted for the Synapse server name, I used <code>ansonvandoren.com</code> even though the Synapse
server is actually pointed to by <code>matrix.ansonvandoren.com</code> since I intend to set up delegation later. Your
needs may be different, so you may want to read the <a href="https://github.com/matrix-org/synapse/blob/master/docs/delegate.md">delegation docs</a>
to help you decide. By choosing <code>ansonvandoren.com</code> as the server name and then delegating it, I can keep logical
servers with different names to improve organization and security, but still keep my Matrix ID as something
like <code>@anson:ansonvandoren.com</code> instead of <code>@anson:matrix.ansonvandoren.com</code>.</p>
<h2 id="installing-postgresql-for-synapse">Installing PostgreSQL for Synapse</h2>
<p>This isn't required, and probably not actually needed since I don't plan to host a lot of users, but it seemed
easier to do it now rather than try to do it down the road. There is a migration path from SQLite to PostgreSQL, but it looks
a little error-prone, and also, according to the official docs:</p>
<blockquote>
<p>Almost all installations should opt to use PostgreSQL</p>
</blockquote>
<p>Installation instructions are <a href="https://github.com/matrix-org/synapse/blob/master/docs/postgres.md">linked</a> from the main
Synapse install page, but those assume you already have Postgres installed, which I did not on the new droplet. There is
a pretty good <a href="https://www.digitalocean.com/community/tutorials/how-to-install-postgresql-on-ubuntu-20-04-quickstart">tutorial</a>
on Digital Ocean for setting up Postgres that I referenced to get started.</p>
<p>Install PostgreSQL:</p>
<div><pre><code data-lang="sh">$ sudo apt install postgresql postgresql-contrib
</code></pre></div><p>Switch to the newly created <code>postgres</code> user:</p>
<p>Create a <code>synapse_user</code> Postgres role:</p>
<div><pre><code data-lang="sh">$ createuser --pwprompt synapse_user
</code></pre></div><p>Enter a new password (and don't forget to store it in 1Password).</p>
<p>Create the Synapse database by first starting <code>psql</code></p>
<div><pre><code data-lang="sh">$ psql
psql (12.5 (Ubuntu 12.5-0ubuntu0.20.04.1))
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><p>then from the Postgres prompt, create the database:</p>
<div><pre><code data-lang="postgres">postgres=# <span>CREATE</span> <span>DATABASE</span> synapse
             <span>ENCODING</span> <span></span><span>'</span><span>UTF8</span><span>'</span>
             <span>LC_COLLATE</span>=<span></span><span>'</span><span>C</span><span>'</span>
             <span>LC_CTYPE</span>=<span></span><span>'</span><span>C</span><span>'</span>
             <span>template</span>=template0
             <span>OWNER</span> synapse_user;
</code></pre></div><p>Exit the Postgres prompt by typing <code>\q</code>, and then exit back into the normal user login.</p>
<p>To set Synapse to use Postgres instead of the default SQLite, edit the config file:</p>
<div><pre><code data-lang="sh">$ sudo vim /etc/matrix-synapse/homeserver.yaml
</code></pre></div><p>Search for the <code>database</code> section, and comment out the <code>sqlite3</code> section, and uncomment the <code>psycopg2</code> part.
Mine looks like this:</p>
<div><pre><code data-lang="yaml">database:
  name: psycopg2
  args:
    user: synapse_user
    password: secretpassword
    database: synapse
    host: localhost
    cp_min: <span>5</span>
    cp_max: <span>10</span>
</code></pre></div><p>Obviously, change <code>secretpassword</code> to whatever your <code>synapse_user</code> password is (created a few steps above).</p>
<h2 id="configuring-reverse-proxy-for-synapse">Configuring reverse proxy for Synapse</h2>
<p>Again, the Matrix team has a reasonable set of instructions <a href="https://github.com/matrix-org/synapse/blob/master/docs/reverse_proxy.md">here</a>.
I chose to use Caddy for a reverse proxy, mostly because I already use Nginx for other projects, and wanted some different
experience. I followed the basic Caddy 2 installation instructions <a href="https://caddyserver.com/docs/install#debian-ubuntu-raspbian">from here</a>.</p>
<div><pre><code data-lang="sh">$ sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https
$ curl -1sLf <span>'https://dl.cloudsmith.io/public/caddy/stable/cfg/gpg/gpg.155B6D79CA56EA34.key'</span> | sudo apt-key add -
$ curl -1sLf <span>'https://dl.cloudsmith.io/public/caddy/stable/cfg/setup/config.deb.txt?distro=debian&amp;version=any-version'</span> | sudo tee -a /etc/apt/sources.list.d/caddy-stable.list
$ sudo apt update
$ sudo apt install caddy
</code></pre></div><p>There is a default Caddyfile in <code>/etc/caddy/Caddyfile</code> that I edited to look like below:</p>
<pre><code data-lang="caddy">matrix.ansonvandoren.com {
  # enable logging
  log

  reverse_proxy /_matrix/* http://localhost:8008
  reverse_proxy /_synapse/client/* http://localhost:8008
}
</code></pre><p><strong>From that folder</strong>, reload caddy with</p>
<p>Then wait for LetsEncrypt to generate the certs. Make sure that <code>http</code> and <code>https</code> are enabled via <code>ufw</code>.</p>
<h2 id="delegating-access-to-a-subdomain">Delegating access to a subdomain</h2>
<p>Since the Synapse server is hosted on a different box and a subdomain (not just <code>ansonvandoren.com</code>),
I needed to delegate access. The easiest way seems to be with a <code>.well-known</code> directive, so I followed the
basic instructions <a href="https://github.com/matrix-org/synapse/blob/master/docs/delegate.md">here</a>. Sort of.</p>
<p>Actually I needed quite a bit from <a href="https://git.finallycoffee.eu/jdreichmann/matrix-docker-ansible-deploy_dev/src/commit/c1a9549d54538cf35076f2a6a19e13004a483a06/docs/configuring-well-known.md">this document</a> as well.</p>
<p>On my regular <code>ansonvandoren.com</code> host, in the same Nginx server block that holds information
for this website, I added the following:</p>
<div><pre><code data-lang="nginx"><span>server</span> {
    <span>server_name</span> <span>ansonvandoren.com</span>;

    <span># ... other config ... #
</span><span></span>
<span>    <span># matrix delegation
</span></span><span><span></span>    <span>location</span> <span>/.well-known/ma…</span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ansonvandoren.com/posts/matrix-server-digital-ocean/">https://ansonvandoren.com/posts/matrix-server-digital-ocean/</a></em></p>]]>
            </description>
            <link>https://ansonvandoren.com/posts/matrix-server-digital-ocean/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874010</guid>
            <pubDate>Fri, 22 Jan 2021 17:42:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter Bluesky Is a Business Strategy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873965">thread link</a>) | @WClayFerguson
<br/>
January 22, 2021 | https://quanta.wiki/u/WClayFerguson/twitter-bluesky | <a href="https://web.archive.org/web/*/https://quanta.wiki/u/WClayFerguson/twitter-bluesky">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quanta.wiki/u/WClayFerguson/twitter-bluesky</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873965</guid>
            <pubDate>Fri, 22 Jan 2021 17:39:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Marketing can make the world a better place]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873957">thread link</a>) | @jnoog
<br/>
January 22, 2021 | https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/ | <a href="https://web.archive.org/web/*/https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-24">
	<!-- .entry-header -->

	<div>
		
<figure><img loading="lazy" width="640" height="853" src="https://i2.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble-768x1024.jpeg?resize=640%2C853&amp;ssl=1" alt="Cory Ames CEO of Grow Ensemble wearing yellow beanie and jacket" srcset="https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=1152%2C1536&amp;ssl=1 1152w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=1536%2C2048&amp;ssl=1 1536w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></figure>



<p id="block-feb40dbc-4d12-4f90-8338-808d52cca5e4">Fun fact: Cory dropped out of university and began working at a multi-million-dollar marketing agency. He quickly climbed up the ranks from Assistant Project Manager to CEO within 18 months.</p>



<p id="block-feb40dbc-4d12-4f90-8338-808d52cca5e4">Though I would never suggest anyone to take ditching school lightly, sometimes it can work out for the best.</p>



<p id="block-027cc4d0-39a6-4811-bd23-a17f9f80fc84">Cory first reached out to me to update some content for his podcast and I jumped on board immediately because I loved its mission. I’ve been following Grow Ensemble, his marketing agency and consultancy for purpose-driven companies, ever since.</p>



<p id="block-5cc1b2af-3eaa-4447-a2c5-12a330b7f149">He and his team have helped hundreds of social enterprises, lead by similarly passionate entrepreneurs, grow. Indeed, profit and purpose can exist in perfect harmony.</p>



<p id="block-54e98d7e-fa85-4e32-b039-774c6f11faa2">So whatever they tell you about sleazy marketers trying to sell you snake oil, it’s not always true.</p>



<p id="block-662133ef-7438-427f-af40-6b036ea3e6e8">His background makes him the perfect first guest on Boundless Human so I didn’t hesitate to ask him for an interview. But enough from me, I’ll give Cory the stage now.</p>



<blockquote><p><em>In our most ambitious frame of mind, we want Grow Ensemble to inspire a cultural transformation—one where we begin to think more communally, rather than hyper-individually.&nbsp;&nbsp;</em></p><p>Cory Ames</p></blockquote>



<h2><strong>1. Where does the desire to do good come from? What inspires you in this regard?</strong></h2>



<p>First, I know I am insanely privileged. There has been little in my life that I’ve wanted to do that I haven’t been able to. And really, that’s all a product of luck. I was lucky enough to be born into a middle-class/upper-middle-class family, have extremely supportive parents, and be a skin color (white) that’s preferential to receiving “opportunities” in America.&nbsp;</p>



<p>I didn’t do anything to <em>deserve </em>this; I didn’t earn this in any way, it was all by chance. And so, I feel obligated to use my privilege to ideally make the world a (truly) better place for those who aren’t as lucky.&nbsp;</p>



<p>Second, I’m really not sure what could be a better or more meaningful use of my own skills and capacities than to work towards reducing the unnecessary suffering of others and leaving the world a more just, equitable, and habitable place for all of us, not just some of us. If we have skills, if we have resources, and if we have time, it should be spent thinking about and working towards making others better off, no?&nbsp;</p>



<h2><strong>2. You dropped out of university to pursue digital marketing and went on to become the CEO of a multi-million dollar marketing agency in just 18 months. You clearly like to “colour outside the lines”. Do you embody this ethos in other aspects of your life?</strong></h2>



<p>Definitely. And honestly, I feel that the quality of mine might cause me some distress. I can often be so committed to doing things the exact way I want to, at the time I want to, where I want to. I can shy away from or procrastinate on maybe more mundane, repetitive, but still <em>very important </em>things. Sometimes the things that I <em>have </em>to do, but don’t <em>want </em>to fall to the wayside.&nbsp;</p>



<h2><strong>3. Imagine an ideal future and the ultimate impact you want to make with Grow Ensemble. What would that look like?</strong></h2>



<p>We started Grow Ensemble because we wanted to create a community around ‘bettering the world.’ Research shows that we are more lonely and depressed than we ever have been. We hope that Grow Ensemble can be a vehicle for inspiring others to do good in their day-to-day lives with a like-minded, like-valued community.&nbsp;</p>



<p>In our most ambitious frame of mind, we want Grow Ensemble to inspire a cultural transformation—one where we begin to think more communally, rather than hyper-individually.&nbsp;&nbsp;</p>



<h2><strong>4. What’s your favourite book / podcast / song / etc. (choose one) and why?</strong></h2>



<p>Player Piano, by Kurt Vonnegut—I’m eternally grateful to my partner, Annie, for this recommendation.&nbsp;</p>



<p>To quote Vonnegut himself, “This book is not a book about what is, but a book about what could be.” He published Player Piano in 1952. Vonnegut’s predictions about “what could be,” were eerie.&nbsp;&nbsp;</p>



<p>The book is set in a completely ‘automated’ American society. Through automation and technology, every single one of our conveniences has been met. This book had me questioning our obsession with “progress” and technological innovation.&nbsp;</p>



<p>Is progress for progress’ sake really what’s best for us both individually and collectively? What are we ‘optimizing’ for?&nbsp;</p>



<p>As we watch automation wipe out hundreds of thousands of livelihoods and we create another widget to make it easier to do something insignificant like brushing our teeth, or finding a new T.V. show, I can’t help but wonder, is all the “advancement” in fact improving our lives?&nbsp;</p>



<h2><strong>5. ‎What’s the bravest thing you’ve ever done?</strong></h2>



<p>This is interesting. I don’t consider myself to be particularly courageous and boiling that down to one single moment doesn’t really seem to fit with how I think of myself. I’m very reflective and analytical. I think through potential life choices and actions I can take rather exhaustively.&nbsp;</p>



<p>And then, when the event comes, it feels almost “normal,” or exactly what I should be doing.&nbsp;</p>



<p>Leaving university early didn’t feel all particularly courageous at the time, because I felt extremely certain of what I wanted to do. If anything, the bravest things I’ve done revolve around moving or travel.&nbsp;</p>



<p>Of anything, I’d say those experiences have taken me the most out of my comfort zone and maybe have rewarded me the most.&nbsp;</p>



<p>While I’ve spent some significant time traveling/living within different countries, most meaningful may have been my move from Washington state to Texas. This felt like a ‘starting fresh’ of sorts, making new friends, finding new routines, and spending significant time away from my family.&nbsp;</p>



<p>And now, I’m so endlessly grateful I made the move as the universe certainly “rewarded me” with meeting my now partner who I plan to spend the rest of my life with.&nbsp;</p>



<p><em>If you want to learn more about Cory and his mission, check out his <a href="https://coryames.com/">personal website</a>, <a href="https://growensemble.com/">Grow Ensemble</a> and <a href="https://growensemble.com/podcast/">the Social Entrepreneurship and Innovation Podcast</a>.</em></p>












	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873957</guid>
            <pubDate>Fri, 22 Jan 2021 17:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A curriculum developed around the television series, Halt and Catch Fire]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873949">thread link</a>) | @_pius
<br/>
January 22, 2021 | https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/ | <a href="https://web.archive.org/web/*/https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="about">
      

<p>This site features a curriculum developed around the television series, <a href="https://www.google.com/search?channel=fs&amp;client=ubuntu&amp;q=halt+and+catch+fire">Halt and Catch Fire</a> (2014-2017), a fictional narrative about people working in tech during the 1980s-1990s.</p>

<p>The intent is for this website to be used by self-forming small groups that want to create a “watching club” (like a book club) and discuss aspects of technology history that are featured in this series.</p>

<p>There are 15 classes, for a “semester-long” course:<br>
~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/01.html">#01</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/02.html">#02</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/03.html">#03</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/04.html">#04</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/05.html">#05</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/06.html">#06</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/07.html">#07</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/08.html">#08</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/09.html">#09</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/10.html">#10</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/11.html">#11</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/12.html">#12</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/13.html">#13</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/14.html">#14</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/15.html">#15</a> ~</p>

<p><strong>Prefer a <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/HaltAndCatchFireSyllabus.pdf">PDF</a>?</strong></p>

<p>Brief guide to class layout:</p>
<ul>
  <li><strong>Apéritifs</strong> Casual viewing presented before gathering. This is entertainment; not required viewing.</li>
  <li><strong>RFC as koan</strong> A Request for Comments from the Internet Engineering Task Force, for reflecting on.</li>
  <li><strong>Emulation as koan</strong> An emulated computer in the browser, also for reflection.</li>
  <li><strong>Themes</strong> Recommendations for topics to be discussed.</li>
  <li><strong>Prompts</strong> Questions to inspire conversation when gathering.</li>
  <li><strong>Readings</strong> Related material for deeper thinking on the class topic.</li>
  <li><strong>Description</strong> Brief summary of what’s going on in the episodes and how it relates to tech history at large / the weekly topic.</li>
  <li><strong>Episode summaries</strong> A link to summaries of the episodes that should be watched prior to meeting as a group. Watching each episode is not required; if time doesn’t allow, refer to the summaries. Content warnings are provided for relevant episodes. If there are specific concerns, this can determine which episodes should be skipped or anticipated before viewing.</li>
</ul>

<p><br>
Curriculum and website designed by <a href="https://ashleyblewer.com/">Ashley Blewer</a>.<br>
see also ↠ <a href="https://github.com/ablwr/halt-and-catch-fire-syllabus">source code &amp; site metadata</a></p>

<p><img src="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/assets/img/construction.gif" alt="under construction"></p>

    	</div></div>]]>
            </description>
            <link>https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873949</guid>
            <pubDate>Fri, 22 Jan 2021 17:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Reserves and Why It Matters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873947">thread link</a>) | @Bluestein
<br/>
January 22, 2021 | https://www.quadrigainitiative.com/proofofreserves.php | <a href="https://web.archive.org/web/*/https://www.quadrigainitiative.com/proofofreserves.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>In case you missed them, so far this year we've seen 3 large scale exchange events:</p>
<ul>
<li>QuadrigaCX</li>
<li>EZ-BTC</li>
<li>Cryptopia</li></ul>

<p>Each one represents massive losses for those involved - hundreds and thousands of affected lives. These are real people and families at the other ends, with hopes and dreams, who worked hard for their money.</p>

<p>In the case of QuadrigaCX, it took the freezing of the bank accounts, the death/disappearance of the CEO, and concerted legal action to even realize it was insolvent.</p>

<p>Exchanges can easily continue to operate for years with whatever level of reserves they like. Nothing prevents exchange owners from spending cryptocurrency stored by users, or failing to disclose if reserves are breached. Third party audits are riddled with holes like:</p>
<ul>

<li>How can they know the client list they're given is legitimate and fully inclusive?</li>

<li>How can you know the funds weren't borrowed for the audit purposes?</li>

<li>How old is the report? How can you trust the auditor?</li></ul>

<p>On top of that - most exchange platforms still don't even bother to audit. Despite the warnings about storing funds on exchanges, people still do. And remember that many affected users weren't storing funds on Quadriga - they simply got stuck with no way to withdraw.</p>

<p>Proof of Reserves asks exchanges to:</p>
<ul>

<li>Publish the wallet public keys so people can see that funds are fully backed. (A satoshi test can prove ownership of those wallets.)</li>

<li>Publish a hash tree to let each customer validate that their balance is included in the total.</li></ul>

<p>What it doesn't prevent:</p>

<ul>

<li>Same as presently, if funds are not secured in proper multi-sig wallets or multiple exchange operators are corrupt, the funds could still be taken, up to what's stored. However, this would be immediately known to everyone instead of revealed whenever admins felt like it (or never).</li>

<li>The balances of customers who never check the hash tree could be excluded by a dishonest exchange, which wouldn't be noticed until one of those customers decided to check.</li>

<li>A dishonest exchange could still dispute the balance of a customer or arbitrarily prevent withdrawals. In this case, the customer and exchange would have to sort that out.</li>

<li>A dishonest exchange could pretend to own wallets it doesn't. A satoshi test would help with this, where the exchange operators send a small amount at a specified time.</li>

<li>While it makes things safer, it's still not a good idea to store funds on the exchange.</li></ul>

<p>What it does prevent:</p>

<ul>

<li>The exchange owner can't spend funds of active customers, and still claim to hold them.<ul>

<li>ie QuadrigaCX, EZ-BTC</li></ul></li>

<li>The exchange owner can't conceal if funds are hacked or stolen. It becomes known immediately.<ul>

<li>ie Mt. Gox, Cryptopia, Bitgrail</li></ul></li>

<li>Anyone can see if the exchange is solvent before trading.<ul>

<li>ie Anyone with "bad timing" using an insolvent exchange.</li></ul></li></ul>

<p><a href="https://web.archive.org/web/20170114112433/https://iwilcox.me.uk/2014/proving-bitcoin-reserves">Check this link for more details on Proof of Reserves, including the full hash tree algorithm.</a></p>

<p>Despite the relative simplicity of publishing wallet keys, the vast selection of exchanges we have in Canada, and the many millions of dollars stored, not a single exchange has done so. The hash tree algorithm has existed since 2014. It's presently on one exchange (last audited in 2014).</p>

<p><a href="https://www.quadrigainitiative.com/txquick.php">This is why we are so pleased to work with an exchange partner committed to transparency, who will be implementing a full proof of reserves.</a></p>

<p>It's time to do something about this!</p>

<!--<form action="emailonly.php" method="post">
<input type="hidden" name="r" value="">
<table width="100%">
<tbody><tr><td colspan="3"><h3>Join the Fight for Proof of Reserves</h3></td></tr>
<tr><td>First&nbsp;Name:</td><td><input type="text" name="first" value=""></td><td>Enter your first name. (Used in email contact.)</td></tr>
<tr><td>Email:</td><td><input type="text" name="email" value=""></td><td>Enter an email address which will work to receive a launch announcement in a few months.</td></tr>
<tr><td colspan="3" style="text-align:center"><input type="checkbox" value="1" name="confirm" id="confirm"><label for="confirm"> I accept the <a href="terms.php">Terms of Use</a> and <a href="privacy.php">Privacy Policy</a>.</label></td></tr>
<tr><td colspan="3"><input type="submit" value="Email-Only Signup" style="width:100%;font-size: 1.17em;"></td></tr></tbody></table>
</form>-->

</div><p>Your use of this site/service accepts the <a href="https://www.quadrigainitiative.com/terms.php">Terms of Use</a> and <a href="https://www.quadrigainitiative.com/privacy.php">Privacy Policy</a>. This site is not associated with Ernst &amp; Young, Miller Thompson, or the Official Committee of Affected User. For questions or enquiries, email <a href="mailto:info@quadrigainitiative.com">info@quadrigainitiative.com</a>.</p></div>]]>
            </description>
            <link>https://www.quadrigainitiative.com/proofofreserves.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873947</guid>
            <pubDate>Fri, 22 Jan 2021 17:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Apple M1 GPU, Part II]]>
            </title>
            <description>
<![CDATA[
Score 517 | Comments 173 (<a href="https://news.ycombinator.com/item?id=25873887">thread link</a>) | @dddddaviddddd
<br/>
January 22, 2021 | https://rosenzweig.io/blog/asahi-gpu-part-2.html | <a href="https://web.archive.org/web/*/https://rosenzweig.io/blog/asahi-gpu-part-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header><p>22 Jan 2021</p></header><p>Less than a month ago, I began <a href="https://rosenzweig.io/blog/asahi-gpu-part-1.html">investigating the Apple M1 GPU</a> in hopes of developing a free and open-source driver. This week, I’ve reached a second milestone: drawing a triangle with my own open-source code. The vertex and fragment shaders are handwritten in machine code, and I interface with the hardware via the IOKit kernel driver in an identical fashion to the system’s Metal userspace driver.</p>
<figure>
<img src="https://rosenzweig.io/M1HelloTriangle.png" alt=""><figcaption>A triangle rendered on the M1 with open-source code</figcaption>
</figure>
<p>The bulk of the new code is responsible for constructing the various command buffers and descriptors resident in shared memory, used to control the GPU’s behaviour. Any state accessible from Metal corresponds to bits in these buffers, so understanding them will be the next major task. So far, I have focused less on the content and more on the connections between them. In particular, the structures contain pointers to one another, sometimes nested multiple layers deep. The bring-up process for the project’s triangle provides a bird’s eye view of how all these disparate pieces in memory fit together.</p>
<p>As an example, the application-provided vertex data are in their own buffers. An internal table in yet another buffer points each of these vertex buffers. That internal table is passed directly as input to the vertex shader, specified in another buffer. That description of the vertex shader, including the address of the code in executable memory, is pointed to by another buffer, itself referenced from the main command buffer, which is referenced by a handle in the IOKit call to submit a command buffer. Whew!</p>
<p>In other words, the demo code is not yet intended to demonstrate an understanding of the fine-grained details of the command buffers, but rather to demonstrate there is “nothing missing”. Since GPU virtual addresses change from run to run, the demo validates that all of the pointers required are identified and can be relocated freely in memory using our own (trivial) allocator. As there is a bit of “magic” around memory and command buffer allocation on macOS, having this code working at an early stage gives peace of mind going forward.</p>
<p>I employed a piecemeal bring-up process. Since my IOKit wrapper exists in the same address space as the Metal application, the wrapper may modify command buffers just before submission to the GPU. As an early “hello world”, I identified the encoding of the render target’s clear colour in memory, and demonstrated that I could modify the colour as I pleased. Similarly, while learning about the instruction set to bring up the disassembler, I replaced shaders with handwritten equivalents and confirmed I could execute code on the GPU, provided I wrote out the machine code. But it’s not necessary to stop at these “leaf nodes” of the system; after modifying the shader code, I tried uploading shader code to a different part of the executable buffer while modifying the command buffer’s pointer to the code to compensate. After that, I could try uploading the commands for the shader myself. Iterating in this fashion, I could build up every structure needed while testing each in isolation.</p>
<p>Despite curveballs, this procedure worked out far better than the alternative of jumping straight to constructing buffers, perhaps via a “replay”. I had used that alternate technique to bring-up Mali a few years back, but it comes with the substantial drawback of fiendishly difficult debugging. If there is a single typo in five hundred lines of magic numbers, there would be no feedback, except an error from the GPU. However, by working one bit at a time, errors could be pinpointed and fixed immediately, providing a faster turn around time and a more pleasant bring-up experience.</p>
<p>But curveballs there were! My momentary elation at modifying the clear colours disappeared when I attempted to allocate a buffer for the colours. Despite encoding the same bits as before, the GPU would fail to clear correctly. Wondering if there was something wrong with the way I modified the pointer, I tried placing the colour in an unused part of memory that was already created by the Metal driver – that worked. The contents were the same, the way I modified the pointers was the same, but somehow the GPU didn’t like my memory allocation. I wondered if there was something wrong with the way I allocated memory, but the arguments I used to invoke the memory allocation IOKit call were bit-identical to those used by Metal, as confirmed by <code>wrap</code>. My last-ditch effort was checking if GPU memory had to be mapped explicitly via some side channel, like the <code>mmap</code> system call. IOKit does feature a device-independent memory map call, but no amount of fortified tracing found any evidence of side-channel system call mappings.</p>
<p>Trouble was brewing. Feeling delirious after so much time chasing an “impossible” bug, I wondered if there wasn’t something “magic” in the system call… but rather in the GPU memory itself. It was a silly theory since it produces a serious chicken-and-egg problem if true: if a GPU allocation has to be blessed by another GPU allocation, who blesses the first allocation?</p>
<p>But feeling silly and perhaps desperate, I pressed forward to test the theory by inserting a memory allocation call <em>in the middle</em> of the application flow, such that every subsequent allocation would be at a different address. Dumping GPU memory before and after this change and checking for differences revealed my first horror: an auxiliary buffer in GPU memory tracked all of the required allocations. In particular, I noticed values in this buffer increasing by one at a predictable offset (every <code>0x40</code> bytes), suggesting that the buffer contained an array of handles to allocations. Indeed, these values corresponded exactly to handles returned from the kernel on GPU memory allocation calls.</p>
<p>Putting aside the obvious problems with this theory, I tested it anyway, modifying this table to include an extra entry at the end with the handle of my new allocation, and modifying the header data structure to bump the number of entries by one. Still no dice. Discouraging as it was, that did not sink the theory entirely. In fact, I noticed something peculiar about the entries: contrary to what I thought, not <em>all</em> of them corresponded to valid handles. No, all but the <em>last</em> entry were valid. The handles from the kernel are 1-indexed, yet in each memory dump, the final handle was always <code>0</code>, nonexistent. Perhaps this acts as a sentinel value, analogous to NULL-terminated strings in C. That explanation begs the question of why? If the header already contains a count of entries, a sentinel value is redundant.</p>
<p>I pressed on. Instead of adding on an extra entry with my handle, I copied the last entry <code>n</code> to the extra entry <code>n + 1</code> and overwrote the (now second to last) entry <code>n</code> with the new handle.</p>
<p>Suddenly my clear colour showed up.</p>
<p>Is the mystery solved? I got the code working, so in some sense, the answer must be yes. But this is hardly a satisfying explanation; at every step, the unlikely solution only raises more questions. The chicken-and-egg problem is the easiest to resolve: this mapping table, along with the root command buffer, is allocated via a special IOKit selector independent from the general buffer allocation, and the handle to the mapping table is passed along with the submit command buffer selector. Further, the idea of passing required handles with command buffer submission is not unheard of; a similar mechanism is used on mainline Linux drivers. Nevertheless, the rationale for using 64-byte table entries in shared memory, as opposed to a simple CPU-side array, remains totally elusive.</p>
<p>Putting memory allocation woes behind me, the road ahead was not without bumps (and potholes), but with patience, I iterated until I had constructed the entirety of GPU memory myself in parallel to Metal, relying on the proprietary userspace only to initialize the device. Finally, all that remained was a leap of faith to kick off the IOKit handshake myself, and I had my first triangle.</p>
<p>These changes amount to around 1700 lines of code since the last blog post, available on <a href="https://github.com/AsahiLinux/gpu">GitHub</a>. I’ve pieced together a simple demo animating a triangle with the GPU on-screen. The window system integration is effectively nonexistent at this point: XQuartz is required and detiling the (64x64 Morton-order interleaved) framebuffer occurs in software with naive scalar code. Nevertheless, the M1’s CPU is more than fast enough to cope.</p>
<p>Now that each part of the userspace driver is bootstrapped, going forward we can iterate on the instruction set and the command buffers in isolation. We can tease apart the little details and bit-by-bit transform the code from hundreds of inexplicable magic constants to a real driver. Onwards!</p>
<p><a href="https://rosenzweig.io/">Back to home</a></p>
</div>]]>
            </description>
            <link>https://rosenzweig.io/blog/asahi-gpu-part-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873887</guid>
            <pubDate>Fri, 22 Jan 2021 17:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Making Small Games]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873837">thread link</a>) | @adnzzzzZ
<br/>
January 22, 2021 | https://a327ex.github.io/blog/small-games | <a href="https://web.archive.org/web/*/https://a327ex.github.io/blog/small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><small><i>published on: 2021-01-22</i></small><br><small><i>last updated on: 2021-01-22</i></small></p></div></div><!--
title: Thoughts on making small games
date: 2021-01-22
update: 2021-01-22
-->

<p>I notice more people talking about making small games. As I'm currently also focused on this goal I thought it would be good to write something about it.</p>
<p>I personally think that indiedevs currently focused on this have a few misconceptions about the problem and aren't thinking about it clearly enough, and in this post I'll go over that argument.</p>
<h2 id="the-meaning-of-small">The meaning of small</h2>
<p>The first thing to notice is that the word <em>small</em>, when used in the context of making games, is conflating multiple meanings into one word. The first meaning is related to how long or how many people it took to make the game. The second meaning is related to how long it takes players to go through the game.</p>
<p>When indie developers use this word to describe their games, they're generally referring to both meanings at the same time, or to one of them in an interchangeable way with the other.</p>
<p>For instance, <a href="https://www.youtube.com/watch?v=wb22xeh_VqM" target="_blank">this great talk</a> (watch it in its entirety, I highly recommend it) goes over techniques for making games every month. However, it implicitly assumes that because this development duration is small, the games also will be fairly small for the players. This is illustrated in the first point where one month games are referred to as concept games rather than real games.</p>
<p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/wb22xeh_VqM?rel=0&amp;modestbranding=1&amp;feature=oembed" allowfullscreen="" scrolling="no" allow="encrypted-media; accelerometer; clipboard-write; gyroscope; picture-in-picture"></iframe></p>
<p>Another example of a similar assumption being made is in <a href="https://howtomarketagame.com/2021/01/18/can-you-make-a-living-from-small-games-on-steam/" target="_blank">this article</a>, which goes over a game made in 4 months. Similarly, it is implicitly assumed that because the game was made in a short timeframe, the game would also necessarily be fairly small from the perspective of the players - as far as I can tell it can be finished in about 1 or 2 hours - and there's not a single point made by the author in relation to that.</p>
<p>In both of these cases you see the same error being implicitly made, which is that both meanings of the word small are the same thing, and this logically leads to the idea that if you make a game in a short timespan it must be the case that the game will not last a very long amount of time to the player. These are just two examples, and they're simply illustrative because this error is made by pretty much every indiedev talking about making small games.</p>
<h2 id="the-game-scope-chart">The game scope chart</h2>
<p>To further illustrate the point, you could look at this problem as a chart with four quadrants. On the horizontal axis we'll have one meaning of the word, on the vertical axis we'll have another. For clarity's sake, we'll refer to the meaning that pertains to development as small/big and to the other as short/long.</p>
<p><img src="https://i.imgur.com/mG5qz09.png"></p>
<p>We generally don't care about the top two quadrants of the chart. Those are related to games that have big development times or teams, and that's not what people are referring to when they talk about small games. We're then left with the bottom two quadrants, and here we have a spectrum that goes from small short games to small long games.</p>
<p>Most indie devs inherently assume that because a game is small, it has to be short. I reject this notion entirely. I think the quadrant of small long games is fairly unexplored, at least in the context of small games discussions, and it's useful to think about if this is a valid quadrant at all.</p>
<h2 id="my-experience-with-bytepath">My experience with BYTEPATH</h2>
<p>The only game I've released so far is <a href="https://store.steampowered.com/app/760330/BYTEPATH/" target="_blank">BYTEPATH</a>, and it falls under what I would consider a small long game.</p>
<p>It's small because it was made in about 4 months by me alone, and it also has a fairly small scope. By the nature of its gameplay it's essentially a single screen game with lots of upgrades, like one of those old flash games.</p>
<p>And it's long because it feels like a long game. Despite the game being small and made in just 4 months, it has a skill tree with about 900 nodes, it has 10 different characters, I don't even remember how many different classes but probably around 40, essentially, it's what I also like to call a <em>spacious</em> game.</p>
<p>You ever listen to a song or an album for hundreds of hours? I'm currently doing this for <a href="https://eirthankyouscientist.bandcamp.com/album/terraformer" target="_blank">Thank You Scientist's Terraformer</a> and it's crazy how despite listening to it for so long I still find new things in each song that I didn't notice before. This album is a spacious album. It can be thought of as this large space, and as you listen to it, you're exploring it, mapping the environment, finding new walls, rooms, objects, that you didn't know were there before.</p>
<p>Games can also be like this, and long games are generally like this. BYTEPATH certainly is because it was made to be so, as the goal of the game is finding new builds to play, to the point where the main gameplay itself is kind of irrelevant.</p>
<p>And because of this I think BYTEPATH did way better than I expected it to do. It's also important to note that despite me calling spacious games long games, they don't necessarily have to be played by most people for a very long time. Here's what BYTEPATH's hour distribution looks like:</p>
<p><img src="https://i.imgur.com/Fqmq6hW.png"></p>
<p>This is definitely not impressive but it's also not too bad. And I know for a fact there's at least one guy (I saw him in the game's reviews) who played it for over 100 hours. When games feel spacious they have the possibility of keeping people playing for a fairly long time, which increases the chances that the game will do well.</p>
<h2 id="small-long-games">Small long games</h2>
<p>The most important point here is that small long/spacious games <em>DO NOT</em> need to take a long time to be made. If I were to make a game like BYTEPATH again I'm fairly confident I could do it in 2 months, and it would be a significantly better game too, simply because it's actually not that hard. (I'm 100% not some kind of disciplined productivity God or anything)</p>
<p>When developers focus on making small games, this implicit notion that the games also have to be short is pretty wrong. You can make small long games, and because of the way the market works, those kinds of games will tend to do better than short games. I'm not the first person to notice this:</p>
<p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/sIqz5xmQKnc?rel=0&amp;modestbranding=1&amp;feature=oembed" allowfullscreen="" scrolling="no" allow="encrypted-media; accelerometer; clipboard-write; gyroscope; picture-in-picture"></iframe></p><br>
<h2 id="marketing">Marketing</h2>
<p>Another issue that happens often is that because developers are making small games that they feel are sort of worthless, they don't really do a good, serious job at marketing them. For instance, the example game from <a href="https://howtomarketagame.com/2021/01/18/can-you-make-a-living-from-small-games-on-steam/" target="_blank">this article</a> was marketed on Twitter only.</p>
<p>Anyone who has released a game knows that Twitter is notoriously poor at driving sales, and that sites like reddit are much better. Would it really have cost these developers that much time to make a few posts about their games on reddit? No. And I know for a fact that a game of such visual quality would have done very well on multiple subreddits.</p>
<p>So a lot of the conclusions people reach about their efforts with smaller games, and the conclusion the author reaches in that article as well are pretty pessimist and in my view mistaken. I think that most devs making smaller games would benefit tremendously from taking making their games somewhat more spacious and from thinking more clearly about how they're going to market it.</p>
<h2 id="the-right-development-duration">The right development duration</h2>
<p>Another thing to consider is what's the right timeframe for making a small game. One of the videos above focuses on 1 month per game, and both my previous game and the game from the article above took 4 months. I think the right duration is between 1 and 2 months.</p>
<p>The reasons for this are fairly simple. If you're making a 1 month game you probably want something with a scope such that it can be finished in 2-3 days, and then you spend the rest of the month polishing it in various ways. This keeps your game fairly focused and it's a good strategy if you want to drastically increase your chances of actually finishing and release the game.</p>
<p>If you're making a 2 month game this affords you a little more time such that you can actually start adding some meat to it and make it more spacious. But I personally think that it's too easy to start getting lost in scope-creep if you give yourself much more time than 2 months, so that would be my limit. Currently that's what I'm aiming for with the game I'm making and I already overscoped myself slightly (meaning I should have chosen an even smaller game), so I think it really pays to keep this duration limited like this unless you're already more experienced and know you can avoid making these kinds of mistakes.</p>
<p>What also matters is how much money you can expect to make off of these games. BYTEPATH for instance made about $10k over its lifetime, and if I were to release a game like BYTEPATH every 2 months and they all did half as well as it did, then that would be considered "making a living from small games on Steam". But that's largely because I live in Brazil and that amount of money here (even accounting for cuts and taxes) every 2 months would be a pretty comfortable salary. If you're in more expensive countries then perhaps that isn't such a good strategy, so this timeframe consideration really depends on your personal situation as well.</p>
<h2 id="luck">Luck</h2>
<p>To finalize this fairly rambly article, one of the reasons people cite for making small games is to hedge their bets. The argument goes that if they make lots of games, chances are that one of those games will succeed wildly and cover for the costs of the other failures. More specifically <a href="https://www.gamasutra.com/blogs/DanielCook/20150415/241145/Minimum_Sustainable_Success.php" target="_blank">this article</a> said that using this famous graph:</p>
<p><img src="https://i.imgur.com/FNg1WW8.png"></p>
<p>I similarly reject this notion. In my opinion you shouldn't make small games for any reason having to do with what that article says. When you're approaching things from this economic portfolio theory approach you're mirrorring the biases of our society around the notion of luck and chance and it more likely than not will sap your motivation to work on things without you even realizing it.</p>
<p>Additionally, for a single indie developer like me, I don't think it's actually that hard to get a game to sell, say 5000 copies. And if you can do that consistently you can definitely make a living off it. Maybe I'm arrogant and I don't know what I'm talking about. I probably am, after all I've only released one game. But I'd rather be arrogant like that than view things from this lottery/luck oriented approach that so many people seem to fall prey to these days.</p>
<p>This …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://a327ex.github.io/blog/small-games">https://a327ex.github.io/blog/small-games</a></em></p>]]>
            </description>
            <link>https://a327ex.github.io/blog/small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873837</guid>
            <pubDate>Fri, 22 Jan 2021 17:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ClickHouse Is Apache 2.0]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873409">thread link</a>) | @hodgesrm
<br/>
January 22, 2021 | https://altinity.com/blog/clickhouse-is-apache-2-0 | <a href="https://web.archive.org/web/*/https://altinity.com/blog/clickhouse-is-apache-2-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>Open source licenses are in the news again. Elastic recently <a href="https://www.elastic.co/blog/licensing-change" target="_blank" rel="noreferrer noopener">changed the licensing for ElasticSearch and Kibana</a> from Apache 2.0 to a choice of <a href="https://www.mongodb.com/licensing/server-side-public-license" target="_blank" rel="noreferrer noopener">Server Side Public License</a> (SSPL) or the non-open source Elastic license. Like most open source licensing changes, this one prompted a lot of discussion. Examples <a href="https://news.ycombinator.com/item?id=25776657" target="_blank" rel="noreferrer noopener">here</a> and <a href="https://news.ycombinator.com/item?id=25833781" target="_blank" rel="noreferrer noopener">here</a> include some of the more printable comments.&nbsp;</p><p>But we’re not here to discuss Elastic’s business model or their choice of license(s).&nbsp; We’re here to discuss ClickHouse licensing and Altinity’s view of it. Here’s the executive summary.&nbsp;</p><p><strong>ClickHouse is Apache 2.0.&nbsp; Altinity is committed to ensuring it stays that way.&nbsp;</strong></p><p>Our contributions to ClickHouse are<a href="https://en.wikipedia.org/wiki/Apache_License" target="_blank" rel="noreferrer noopener"> Apache 2.0</a>. Our ecosystem projects like the ClickHouse Kubernetes operator are likewise Apache 2.0. We believe the Apache 2.0 license is best for our users. It’s also the best way to make ClickHouse the most popular SQL data warehouse on the planet. There are several reasons for our outlook.&nbsp;</p><p>The most important feature of Apache 2.0 is that it allows use for any purpose, which is the first of the <a href="https://www.gnu.org/philosophy/free-sw.en.html" target="_blank" rel="noreferrer noopener">four essential freedoms</a> of open source software. Such freedom is important for all applications, regardless of whether they run on-prem or as cloud services. Apache 2.0 opens the door to imaginative new services as well as creative paths to develop them. Installed&nbsp;applications morph into online services. Services that hide data behind APIs morph into open data. This freedom is key to enabling innovative new ways to incorporate analytics into applications, which in turn unlocks new business opportunities.&nbsp;</p><p>Apache 2.0 is also a great license for contributors.&nbsp; It has been around since 2004, which is a long time in open source. Corporate legal departments understand it and can easily approve contributions from employees. Individual contributors understand the freedom Apache 2.0 confers to publish their work and use it freely in future. It’s a win-win: companies are motivated to make investment decisions in open source projects, and contributors are motivated to implement them.&nbsp;</p><p>Apache 2.0 licensing opens a path to increasing ClickHouse capabilities and worldwide use. More important, it is enabling a flood of innovation in analytic applications. In a crowded market with many database products besides ClickHouse, that’s a critical competitive advantage.&nbsp;</p><p><h2 id="h-apache-2-0-creates-a-level-playing-field">Apache 2.0 creates a level playing field</h2>
</p><p>Since the ClickHouse Apache 2.0 license places no restriction on business use, we can expect many competing services that leverage ClickHouse in one way or another.&nbsp; This includes hosted ClickHouse and value-added analytic services built on top of ClickHouse capabilities. It also extends to add-ons for countless existing services ranging from web analytics to network flow log management to financial asset valuation and everything in between.</p><p>The competition will be distressing for unprepared vendors, but it’s great for users. Competing services mean that users have alternatives. It also means that innovation is not random but focused on things that users care about: SQL features, performance, security, cost-efficiency, and time to market.&nbsp;</p><p>The same vendors that offer ClickHouse managed services have contributed popular features to ClickHouse like <a href="https://altinity.com/blog/clickhouse-and-s3-compatible-object-storage" target="_blank" rel="noreferrer noopener">S3 storage integration</a>, <a href="https://clickhouse.tech/docs/en/operations/access-rights/#role-management" target="_blank" rel="noreferrer noopener">Role-based Access Control</a>, <a href="https://clickhouse.tech/docs/en/sql-reference/statements/select/with/" target="_blank" rel="noreferrer noopener">Common Table Expressions</a>, and many more. ClickHouse is experiencing the same <a href="https://en.wikipedia.org/wiki/Coopetition" target="_blank" rel="noreferrer noopener">co-opetition</a> feedback effect that helped fuel the success of Linux, Kubernetes, PostgreSQL, and other open source projects.&nbsp;</p><p><h2 id="h-restrictive-licenses-like-sspl-are-antithetical-to-user-interests">Restrictive licenses like SSPL are antithetical to user interests</h2>
</p><p>The Server Side Public License is an attempt to set back the clock on open source software development. It rules out new SaaS offerings based on projects whose value&nbsp;</p><div><blockquote>
<p>…entirely or primarily derives from the value of the Program or modified version, or offering a service that accomplishes for users the primary purpose of the Program or modified version.&nbsp; (SSPL Section 13).&nbsp;</p>
</blockquote>
</div><p>The goal of the SSPL and similar licenses is nothing short of setting up monopoly providers of SaaS offerings. It has ambiguous terms–creating uncertainty for potential competitors–and onerous viral requirements. Services that fall under Section 13 must release all source code required to run the entire SaaS offering. That includes everything from the service management plane down to deployment and backup scripts. SSPL is <a href="https://www.gnu.org/licenses/copyleft.en.html" target="_blank" rel="noreferrer noopener">copyleft</a> with fangs.&nbsp;</p><p>This obviously affects vendors trying to set up competing services to the copyright holders of SSPL projects. But the effect on the market is far wider.&nbsp; Analytics are pervasive in modern applications and SaaS is the primary way that software is now distributed. The SSPL potentially harms any user building an application who just wants a managed offering to take care of running it. We believe that’s an unacceptable limitation.&nbsp;</p><p><h2 id="h-but-wait-what-about-amazon">But wait, what about Amazon?</h2>
</p><p>Many vendors have justified <a href="https://techcrunch.com/2018/10/16/mongodb-switches-up-its-open-source-license/" target="_blank" rel="noreferrer noopener">open source relicensing as a necessary defense</a> against “strip mining” from public clouds. Aren’t we afraid of this ourselves? If so, it’s a bit late. There are already multiple cloud services for ClickHouse, including our own offering, <a href="https://altinity.com/cloud-database/" target="_blank" rel="noreferrer noopener">Altinity.Cloud</a>. There’s also <a href="https://cloud.yandex.com/services/managed-clickhouse" target="_blank" rel="noreferrer noopener">Yandex.Cloud</a> and at least three services in China. New entrants need to compete by adding additional value, <a href="https://siliconangle.com/2020/07/08/suse-acquires-rancher-labs-reported-600m-chases-1b-revenue-goal/" target="_blank" rel="noreferrer noopener">just as Rancher did</a> in the Apache 2.0-licensed Kubernetes market.&nbsp;&nbsp;</p><p>Our goal at Altinity is to help customers bring high-value analytic applications to market quickly and operate them cost-effectively. We focus on development efficiency, data privacy, world-class support, and operations. We do so on all platforms, both public cloud and on-prem. Anybody who has worked on such services knows there’s opportunity here to build many valuable companies, not just one.&nbsp;</p><p>Other paths are possible. Vendors may fork ClickHouse and try to add licenses that create a proprietary fortress. If so, we would point to some friendly advice from a famous competitive analyst of the Italian Renaissance:&nbsp;</p><div><blockquote>
<p><em>So the best fortress that exists is to avoid being hated by the people. If you have fortresses and the people hate you, they will not save you</em>.</p>
<p><cite><em>Niccolo Machiavelli, The Prince</em></cite></p></blockquote>
</div><p>We don’t want to build new fortresses to protect ourselves against our users. We want to tear them down. Apache 2.0 is the key to enabling a new generation of analytic applications based on ClickHouse. Altinity is all in.&nbsp;</p><p>P.S., If you are worried about ElasticSearch and Kibana switching licenses, this might be a nice time to look at alternatives. ClickHouse can store log data remarkably well. More on that in future articles.&nbsp;</p>
	


					</div></div>]]>
            </description>
            <link>https://altinity.com/blog/clickhouse-is-apache-2-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873409</guid>
            <pubDate>Fri, 22 Jan 2021 16:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU Parliament condemns China deal over HK crackdown]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873389">thread link</a>) | @riffraff
<br/>
January 22, 2021 | https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0 | <a href="https://web.archive.org/web/*/https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
			The EU has lost credibility on human rights by sealing an investment deal with China, a resolution in the European Parliament warned on Thursday.</p><p>

MEPs meeting by videolink in Brussels overwhelmingly passed the resolution which broadly condemned the crackdown on Hong Kong activists by the central government in China.</p><p>

The resolution also called for "targeted sanctions" against Chinese and Hong Kong officials held responsible for the police action.</p><p>

The opinion of EU lawmakers is important as they will need to approve the German-backed investment deal that was agreed in principle last month after years of talks.</p><p>

Given the Hong Kong crackdown, doubts about the accord have quickly emerged, with ratification by MEPs very much uncertain, though the vote is not expected until the end of the year at the earliest.</p><p>

The resolution said that MEPs "regret" that the EU-China investment talks were not seized "as a leverage tool aimed at preserving Hong Kong's high degree of autonomy, as well as its basic rights and freedoms".</p><p>

"By rushing to reach this agreement while not taking concrete action against ongoing, grave human right violations, for example in Hong Kong, Xinjiang province and Tibet, the EU risks undermining its credibility as a global human rights actor," it said.</p><p>

China is accused of grave human rights abuses against the Uighur minority in Xinjiang.</p><p>

The resolution said parliament will "carefully scrutinise" the deal and will take the human rights situation in China into account when it votes on the deal.</p><p>

The EU commission, which began negotiating the deal in 2014, said it helps rectify the long-standing imbalance in the way Brussels and Beijing treat investors and the access they allow them.</p><p>

It also says that China agreed through the deal - known as the Comprehensive Agreement on Investment (CAI) - to work harder towards approving International Labour Organisation (ILO) conventions on forced labour. (AFP)		</p></div></div>]]>
            </description>
            <link>https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873389</guid>
            <pubDate>Fri, 22 Jan 2021 16:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The strange economics of open-source software (2015)]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25873194">thread link</a>) | @alexrustic
<br/>
January 22, 2021 | https://www.philipotoole.com/the-strange-economics-of-open-source-software/ | <a href="https://web.archive.org/web/*/https://www.philipotoole.com/the-strange-economics-of-open-source-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://www.maynardkeynes.org/" target="_blank" rel="noopener noreferrer"><img title="John Maynard Keynes" src="https://www.philipotoole.com/wp-content/uploads/2015/09/keynes-150x150.png" alt="John Maynard Keynes" width="150" height="150"></a>I always use the names of economists for my machines’ <a href="http://tools.ietf.org/html/rfc1034" target="_blank" rel="noopener noreferrer">hostnames</a>. <a href="http://www.econlib.org/library/Enc/bios/Keynes.html" target="_blank" rel="noopener noreferrer"><em>keynes</em></a>, <a href="http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/1976/friedman-bio.html" target="_blank" rel="noopener noreferrer"><em>friedman</em></a>, <a href="https://en.wikipedia.org/wiki/Karl_Marx" target="_blank" rel="noopener noreferrer"><em>marx</em></a>, <em><a href="https://fraser.stlouisfed.org/docs/meltzer/fisdeb33.pdf" target="_blank" rel="noopener noreferrer">fisher</a>, </em><em><a href="http://www.britannica.com/biography/David-Ricardo" target="_blank" rel="noopener noreferrer">ricardo</a></em>.</p>
<p>So every so often the strange economics of open-source software hits me.</p>
<p><span id="more-2749"></span><br>
Today it is almost taken for granted that the source code for most software is freely available. This is a profound and remarkable change, given how different it was only 15 years ago. From a certain point of view our industry is “giving away” its product, and yet the industry <a href="http://www.nytimes.com/2015/09/20/opinion/is-big-tech-too-powerful-ask-google.html?_r=0" target="_blank" rel="noopener noreferrer">is richer and more powerful than ever</a>.&nbsp; So where is the value? What are the implications?</p>
<h2>Where has all the closed-source software gone?</h2>
<p>Of course, it’s not <strong>gone</strong>. It’s there at the banks, within embedded devices, and companies such as <a href="https://www.microsoft.com/" target="_blank" rel="noopener noreferrer">Microsoft</a> and <a href="https://www.oracle.com/" target="_blank" rel="noopener noreferrer">Oracle</a> remain among the most powerful companies in the world, but almost all the innovation — and most importantly most of the excitement —&nbsp; is happening within open-source.</p>
<p>Within our industry it is becoming apparent that services — <a href="http://searchcloudcomputing.techtarget.com/definition/Software-as-a-Service" target="_blank" rel="noopener noreferrer">SaaS</a>&nbsp; and companies such as <a href="https://www.airbnb.com/" target="_blank" rel="noopener noreferrer">Airbnb </a>— are the future.&nbsp; And in fact, it sometimes seems to be that the only way to write really valuable closed-source software nowadays is within the context of a service. Behind all the <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener noreferrer">REST</a> endpoints, the&nbsp; <a href="https://aws.amazon.com/elasticloadbalancing/" target="_blank" rel="noopener noreferrer">AWS ELBs</a>, and the<a href="http://www.haproxy.org/" target="_blank" rel="noopener noreferrer"> HAProxy systems</a>, sits some of most closely-guarded software in the world.</p>
<h2>The ever-increasing dominance of open-source</h2>
<p>The increasing dominance of open-source software seems particularly true with respect to infrastructure software.&nbsp; While security software has often been open-source through necessity — no-one would trust it otherwise — infrastructure is becoming the dominant category of open-source. Look at databases — <a href="https://dev.mysql.com/doc/internals/en/guided-tour.html" target="_blank" rel="noopener noreferrer">MySQL</a>, <a href="https://www.mongodb.org/" target="_blank" rel="noopener noreferrer">MongoDB</a>, <a href="https://www.rethinkdb.com/" target="_blank" rel="noopener noreferrer">RethinkDB</a>, <a href="https://github.com/apache/couchdb" target="_blank" rel="noopener noreferrer">CouchDB</a>, <a href="https://influxdb.com/" target="_blank" rel="noopener noreferrer">InfluxDB</a> (of which I am part of the <a href="https://github.com/influxdata/influxdb/graphs/contributors" target="_blank" rel="noopener noreferrer">development team</a>), or <a href="http://www.cockroachlabs.com/" target="_blank" rel="noopener noreferrer">cockroachdb</a>. Is there anyone today that would even consider developing a new closed-source database? Or take search technology — <a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener noreferrer">elasticsearch</a>, <a href="http://lucene.apache.org/solr/" target="_blank" rel="noopener noreferrer">Solr</a>, and <a href="http://www.blevesearch.com/" target="_blank" rel="noopener noreferrer">bleve</a> — all open-source. And <a href="https://www.linux.com/" target="_blank" rel="noopener noreferrer">Linux</a> is so obvious, it is almost pointless to mention it.<br>
If you want to create a closed-source infrastructure solution, you better have an enormously compelling story, or be delivering it as part of a bigger package such as a software appliance.</p>
<h2>So where is the value?</h2>
<p>Compared to when I first <a href="https://en.wikipedia.org/wiki/Nortel" target="_blank" rel="noopener noreferrer">started programming,</a> that some of the most valuable companies in software now give away their product is astounding, when you actually think about it. So where is the real value within a such a company, when its product is free? It’s where it’s always been — just more so.</p>
<p>The real value is within the development team and its ideas, that the team behind the software are, and remain, innovative, execute well, and produce quality software. And that they remain so is key — so that it does not matter that what they produce is freely available.&nbsp; It is of little benefit to a competitor that the source is freely available, when the team behind the project is probably six months ahead — and often more — conceptually in terms of design, development and process.</p>
<h2>The economics of recruitment</h2>
<p>And the implications go far beyond how software is developed.<br>
It is generally accepted these days within <a href="https://en.wikipedia.org/wiki/Silicon_Valley">The Valley</a> that large, older, firms find it particularly hard to hire. The excitement, and latitude for creativity, within a start-up has always appealed, and even more so now with the outstanding <a href="http://www.bloomberg.com/news/articles/2014-10-28/facebook-s-22-billion-whatsapp-deal-buys-10-million-in-sales" target="_blank" rel="noopener noreferrer">commercial success of some</a>.</p>
<p>But a second-order effect is also prevalent — many developers baulk at the idea that their work may never be seen by their peers in the open-source community, and therefore may never help them progress in their careers. And it is at larger, older firms, that the least amount of open-source software is written — what <a href="http://paulgraham.com/index.html" target="_blank" rel="noopener noreferrer">Paul Graham</a> calls <a href="http://paulgraham.com/ideas.html" target="_blank" rel="noopener noreferrer">downwind jobs</a>.</p>
<p>But Services remain part of the future — because while the code that Service software developers write may not be visible, the functionality is visible to the world and with the advent of cloud-computing, the power accruing to these developers is significant and growing. Services can hire, unlike the traditional firms.</p>
<h2>Possibilities for our grandchildren</h2>
<p>The rise of open-source has been a remarkable development in the history of economics and production. I often wonder what <a href="http://www.econ.yale.edu/smith/econ116a/keynes1.pdf" target="_blank" rel="noopener noreferrer">Keynes</a>, Marx, and even Ricardo, would think of it all.</p>
	</div></div>]]>
            </description>
            <link>https://www.philipotoole.com/the-strange-economics-of-open-source-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873194</guid>
            <pubDate>Fri, 22 Jan 2021 16:40:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Define New Intrinsics in SBCL (2014)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872734">thread link</a>) | @Tomte
<br/>
January 22, 2021 | https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/ | <a href="https://web.archive.org/web/*/https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This
<a href="https://stackoverflow.com/questions/25078285/replacing-a-32-bit-loop-count-variable-with-64-bit-introduces-crazy-performance">Stack Overflow</a>
post points out an obscure and undocumented weakness in Intel’s
implementation of the POPCNT instruction: although the population
count (number of bits equal to 1) is only a function of the source
argument, hardware schedules it as though it also depended on the
destination. GCC, clang and MSVC all fail to take this issue into
account.</p>
<p>Until a new patched version of my favourite C compiler is released,
there aren’t many tasteful workarounds for this performance bug. I’d
have to switch to inline asm, and either force the compiler to
allocate the same register to the input and the result, or force
different registers and clear the spurious dependency with a xor.
Ideally, I wouldn’t impose any additional constraint on the register
allocator and only insert a xor if the destination and source
registers don’t match.</p>
<p>SBCL easily supports this use case, without having to re-release or
even recompile the implementation: VOPs (virtual operations) execute
arbitrary CL code during code generation and they can be defined at
runtime.</p>
<p>The first step is to make sure that SBCL’s assembler knows how to emit
popcnt: the assembler can also be extended at runtime, but that’s more
hairy and a topic for another post. Instruction encodings are defined
in <code>src/compiler/$ARCH/insts.lisp</code>, and a quick grep reveals
<code>(define-instruction popcnt (segment dst src) ...)</code>: the x86-64
backend learned about popcnt in May 2013 (thanks to Douglas Katzman).</p>
<p>We define VOPs via <code>define-vop</code>, a macro that exposes many options.
Most of the time, it’s easiest to look at a pre-existing definition
for an operation that’s similar to the one we want to add. Popcount
looks like integer negation: it has a single (machine integer)
argument and returns another integer. Integer negation is defined in
<code>src/compiler/$ARCH/arith.lisp</code>:</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
<span>14</span>
<span>15</span>
<span>16</span>
<span>17</span>
<span>18</span>
<span>19</span>
<span>20</span>
<span>21</span>
<span>22</span>
<span>23</span>
<span>24</span>
<span>25</span>
<span>26</span>
<span>27</span>
<span>28</span>
<span>29</span>
<span>30</span>
<span>31</span>
<span>32</span>
<span>33</span>
<span>34</span>
<span>35</span>
<span>36</span>
<span>37</span>
<span>38</span>
<span>39</span>
<span>40</span>
</pre></td><td><pre><code><span>;;;; unary operations
</span><span>
</span><span>(define-vop (fast-safe-arith-op)
</span><span>  (:policy :fast-safe)
</span><span>  (:effects)
</span><span>  (:affected))
</span><span>
</span><span>(define-vop (fixnum-unop fast-safe-arith-op)
</span><span>  (:args (x :scs (any-reg) :target res))
</span><span>  (:results (res :scs (any-reg)))
</span><span>  (:note "inline fixnum arithmetic")
</span><span>  (:arg-types tagged-num)
</span><span>  (:result-types tagged-num))
</span><span>
</span><span>(define-vop (signed-unop fast-safe-arith-op)
</span><span>  (:args (x :scs (signed-reg) :target res))
</span><span>  (:results (res :scs (signed-reg)))
</span><span>  (:note "inline (signed-byte 64) arithmetic")
</span><span>  (:arg-types signed-num)
</span><span>  (:result-types signed-num))
</span><span>
</span><span>(define-vop (fast-negate/fixnum fixnum-unop)
</span><span>  (:translate %negate)
</span><span>  (:generator 1
</span><span>    (move res x)
</span><span>    (inst neg res)))
</span><span>
</span><span>(define-vop (fast-negate/signed signed-unop)
</span><span>  (:translate %negate)
</span><span>  (:generator 2
</span><span>    (move res x)
</span><span>    (inst neg res)))
</span><span>
</span><span>(define-vop (fast-negate/unsigned signed-unop)
</span><span>  (:args (x :scs (unsigned-reg) :target res))
</span><span>  (:arg-types unsigned-num)
</span><span>  (:translate %negate)
</span><span>  (:generator 3
</span><span>    (move res x)
</span><span>    (inst neg res)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>The code snippet above includes a bit of boilerplate to factor out
commonalities via inheritance. The first definition introduces
<code>fast-safe-arith-op</code>, VOPs that apply in both high speed and high
safety settings (the rest is copy/pasted noise from earlier ports that
sport a scheduler); the second one extends <code>fast-safe-arith-op</code> to
define <code>fixnum-unop</code>, a base definition for single-argument operations
on fixnums, while the third one is the same, but for machine integers.
The last three definitions fill in the blanks so the compiler can
compile <code>%negate</code> of fixnum, signed and unsigned integers. The
<code>(:translate %negate)</code> bit means that these VOPs can be emitted
instead of calls to <code>%negate</code>. The integer after <code>:generator</code> defines
the “cost” of each variant; the compiler will choose the (applicable)
variant with the least cost and execute the code sequence that follows
to convert a call to <code>%negate</code> into machine code.</p>
<p>This kind of implementation inheritance is fine for an SBCL backend,
where we define many VOPs and expect developers to understand the
system. I doubt it’s a didactic win. Let’s do something simpler for
<code>popcnt</code>. In the interest of simplicity, I’ll also completely
disregard powerful details in <code>define-vop</code> that are rarely relevant
when defining intrinsics that map directly to machine instructions.</p>
<p>First, we need to tell the compiler that we’re about to do special
things to a function named <code>popcnt</code> (and to blow away any pre-existing
information if the <code>defknown</code> form is re-evaluated).</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
</pre></td><td><pre><code><span>(defpackage "POPCNT"
</span><span>  (:use "CL")
</span><span>  (:export "POPCNT"))
</span><span>
</span><span>(in-package "POPCNT")
</span><span>
</span><span>(sb-c:defknown popcnt ((unsigned-byte 64)) (integer 0 64)
</span><span>    (sb-c:foldable sb-c:flushable sb-c:movable)
</span><span>  :overwrite-fndb-silently t)</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>This says that <code>popcnt</code> accepts a 64-bit unsigned integer and returns
an integer between 0 and 64 (inclusively), and that the function can
be constant-folded, flushed (eliminated as dead code) and moved around
(it’s pure).</p>
<p>Now, to define a VOP that implements <code>popcnt</code>:</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
</pre></td><td><pre><code><span>(in-package "SB-VM")
</span><span>
</span><span>(define-vop (popcnt:popcnt)
</span><span>  (:policy :fast-safe)
</span><span>  (:translate popcnt:popcnt)
</span><span>  (:args (x :scs (unsigned-reg) :target r))
</span><span>  (:arg-types unsigned-num)
</span><span>  (:results (r :scs (unsigned-reg)))
</span><span>  (:result-types unsigned-num)
</span><span>  (:generator 3
</span><span>    (unless (location= r x) ; only break the spurious dep. chain
</span><span>      (inst xor r r))       ; if r isn't the same register as x.
</span><span>    (inst popcnt r x)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>We define a new VOP named <code>popcnt:popcnt</code> (the name is arbitrary, as
long as it doesn’t collide with another VOP) that is applicable at all
optimization policies (both high speed and high debug level), and that
implements <code>popcnt:popcnt</code>. Its first and only argument, <code>x</code>, is an
<code>unsigned-num</code>, an unsigned machine integer, that can only be stored
in a register. Moreover, if possible, we’d like <code>x</code> to be allocated
the same register as the result, <code>r</code>. There’s only one result (<code>r</code>)
and it’s an unsigned machine integer in a register, just like <code>x</code>.
The generator, of cost 3 (a common default for arithmetic operations),
breaks any dependency chain in <code>r</code> if necessary, and stores the
population count of <code>x</code> in <code>r</code>.</p>
<p>At first sight, the <code>defknown</code> form seems to conflict with the VOP.
We declare that the return value of <code>popcnt</code> is a small integer,
clearly a fixnum, and then define a VOP that returns a machine
integer. The subtlety is that <code>defknown</code> is concerned with IR1, the
higher level intermediate representation, which works on CL types
(i.e, types as sets) and abstract values. VOPs, on the other hand,
are defined for the lower level IR2, where types describe concrete
representations (like C). It is perfectly meaningful to say that a
small integer will be represented as an untagged machine integer.</p>
<p>The next step isn’t strictly necessary, but helps people who like
their REPL. The compiler knows how to compile calls to <code>popcnt</code>, so
we can define <code>popcnt</code>… as a call to <code>popcnt</code>. Our new function is
now a first-class value that can be called from interpreted code and
passed to higher-order functions, like the compiler’s constant-folding
pass.</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
</pre></td><td><pre><code><span>(in-package "POPCNT")
</span><span>
</span><span>(defun popcnt (x)
</span><span>  (popcnt x))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<pre><code>CL-USER&gt; (disassemble 'popcnt:popcnt)
; disassembly for POPCNT:POPCNT
; Size: 25 bytes
; 07FCDB6E:       4831D2           XOR RDX, RDX               ; no-arg-parsing entry point
;       71:       F3480FB8D1       POPCNT RDX,RCX
;       76:       48D1E2           SHL RDX, 1
;       79:       488BE5           MOV RSP, RBP
;       7C:       F8               CLC
;       7D:       5D               POP RBP
;       7E:       C3               RET
[ error trap noise ]
CL-USER&gt; (popcnt:popcnt 42)
3
</code></pre>
<p>The disassembly shows that we get the code that we expect, including
the dependency-breaking workaround, and the smoke test passes.
There’s one interesting detail: we only defined a VOP that returns a
machine integer. However, <code>popcnt</code> returns a tagged value (a fixnum),
and does so with an efficient shift. IR2 takes care of inserting any
coercion needed between VOPs (e.g., between <code>popcnt</code> and the VOP used to
return boxed values from functions), and the IR1 <code>defknown</code> guarantees
that the result of <code>popcnt</code>, despite being <em>represented</em> in an
unsigned machine integer, is small enough for a fixnum.</p>
<p>Let’s see what happens when we feed arithmetic into <code>popcnt</code>, e.g.:</p>
<pre><code>CL-USER&gt; (disassemble (lambda (x y)
                        (declare (type (unsigned-byte 32) x y))
                        (popcnt:popcnt (+ x y))))
; disassembly for (LAMBDA (X Y))
; Size: 55 bytes
; 0752BD59:       4801FA           ADD RDX, RDI               ; no-arg-parsing entry point
;       5C:       48D1FA           SAR RDX, 1
;       5F:       F3480FB8D2       POPCNT RDX,RDX
;       64:       48D1E2           SHL RDX, 1
;       67:       488BE5           MOV RSP, RBP
;       6A:       F8               CLC
;       6B:       5D               POP RBP
;       6C:       C3               RET
</code></pre>
<p>After adding two fixnums, an automatic coercion unboxes the resulting
fixnum into a machine integer which is then passed to <code>popcnt</code>
(note the lack of dependency-breaking <code>xor</code> now that the source and
destination are the same register).</p>
<p>That’s pretty good code, but we can do better: fixnums are tagged with
0, so we can simply pass fixnums to <code>popcnt</code> without untagging.</p>
<p>This is where the cost parameter to <code>:generator</code> comes in: we can
define another VOP for <code>popcnt</code> of fixnums and bias the compiler to
prefer the fixnum VOP.</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
</pre></td><td><pre><code><span>(in-package "SB-VM")
</span><span>
</span><span>(define-vop (popcnt/fx)
</span><span>  (:policy :fast-safe)
</span><span>  (:translate popcnt:popcnt)
</span><span>  (:args (x :scs (any-reg) :target r))
</span><span>  (:arg-types positive-fixnum)
</span><span>  (:results (r :scs (unsigned-reg)))
</span><span>  (:result-types unsigned-num)
</span><span>  (:generator 2 ; 2 is lower than 3, so popcnt/fx is preferable to popcnt
</span><span>    (unless (location= r x)
</span><span>      (inst xor r r))
</span><span>    (inst popcnt r x)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<pre><code>CL-USER&gt; (disassemble (lambda (x y)
                        (declare (type (unsigned-byte 32) x y))
                        (popcnt:popcnt (+ x y))))
; disassembly for (LAMBDA (X Y))
; Size: 47 bytes
; 07BEABE9:       4801FA           ADD RDX, …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/">https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/</a></em></p>]]>
            </description>
            <link>https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872734</guid>
            <pubDate>Fri, 22 Jan 2021 15:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All About Identity Providers: The ABCs of IDPs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872585">thread link</a>) | @sbauch
<br/>
January 22, 2021 | https://ossoapp.com/blog/all-about-idps/ | <a href="https://web.archive.org/web/*/https://ossoapp.com/blog/all-about-idps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><img alt="IDP" src="https://d33wubrfki0l68.cloudfront.net/2e3bb3dac11a682694ccdbae58843d5023524bb1/88d05/img/idps.jpg"><h3>The ABCs of IDPs<a href="#the-abcs-of-idps" title="Direct link to heading">#</a></h3><p>Identity Providers (IDPs) are a category of software applications responsible for <strong>managing employee access</strong> to the various third party applications (AKA Service Providers) that modern enterprise companies rely on.</p><h3>Why companies use Identity Providers<a href="#why-companies-use-identity-providers" title="Direct link to heading">#</a></h3><p>On average, companies with fewer than 1,000 employees rely on <a href="https://www.mcafee.com/blogs/enterprise/cloud-security/every-company-is-a-software-company-today" target="_blank" rel="noopener noreferrer">22 separate applications to run their business</a>. As a result, for each application an employee has access to, the employee will need to be onboarded with the proper privileges, a username and password created, and eventually offboarded upon their departure. Each point in this process gives rise to security risks.</p><p>An Identity Provider enables companies to take control of this process and ensure the correct employee is receiving the proper access levels to applications necessary for them to do their job. Additionally, Identity Providers provide employees Single Sign-On (SSO) access to applications so they don’t have to remember multiple passwords or reuse the same passwords across many applications. Upon departure, an administrator of the Identity Provider can disable access to all applications for the exiting employee at the same time.</p><h3>How Identity Providers work<a href="#how-identity-providers-work" title="Direct link to heading">#</a></h3><p>An Identity Provider is basically just a list of employee names and their job titles. A Service Provider can be anything from a chat app for internal communication where every employee requires access, to more specialized applications like that of payroll management where only a few employees are granted access.</p><p><strong>An employee attempting to login to an application used for their work typically has one of two methods to do so via IDP:</strong></p><h4>1. Identity Provider-initiated<a href="#1-identity-provider-initiated" title="Direct link to heading">#</a></h4><p>Logging into an application through an Identity Provider-initiated workflow relies on the employee to log in to their Identity Provider Portal; this is often the only username and password employees will need. From the portal, they select the application they’d like to access, and will then be redirected via a new browser window to their desired Service Provider. The Service Provider will get a message from the Identity Provider saying that the person logging in has been authenticated and is in fact who they say they are. The Service Provider sees this and grants the employee access.</p><h4>2. Service Provider-initiated<a href="#2-service-provider-initiated" title="Direct link to heading">#</a></h4><p>Signing into applications via the IDP can sometimes feel inconvenient to employees. As a result, Service Provider-initiated login is a more popular alternative. This method allows employees to login via the Service Provider’s website, just like they would normally if their employer didn’t require the use of an Identity Provider. With this method, when the employee enters their email into the Service Provider’s website, the SP will send an authentication request to the IDP associated with the employee’s email address. If the employee is already logged into their employer’s IDP, and has access to the SP making the request, the IDP will return a message to the SP letting them know the employee’s identity has been authenticated, thereby granting them access. If the employee isn’t logged into their IDP, a separate screen will prompt the employee to log in to the IDP in order for them to be authenticated and gain access to the SP.</p><h3>Challenges of Integrating Identity Providers<a href="#challenges-of-integrating-identity-providers" title="Direct link to heading">#</a></h3><p>Although each Identity Provider relies on SAML as a common means to enable SSO across Service Providers, they each have a slightly different workflow for onboarding a new Service Provider. As a result, Service Providers have to familiarize themselves with the workflow of each Identity Provider they support.</p><p>This isn’t too much of an issue when they’re supporting one or two Identity Providers, but as companies grow and mature they continue to acquire enterprise customers, and eventually they’ll be asked to support yet another new Identity Provider. Soon enough, one or two IDPs turns into five or ten, each with their own unique workflow that needs to be learned and supported.</p><h3>Benefits of supporting Identity Providers within your Service<a href="#benefits-of-supporting-identity-providers-within-your-service" title="Direct link to heading">#</a></h3><p>As B2B SaaS companies begin to sell upmarket into the enterprise space, certain security features are considered table stakes and are viewed as a prerequisite to even begin a sales conversation. SAML SSO falls into this category of features and is often viewed as a bare minimum requirement to begin selling into enterprise companies.</p><p>Additionally, when a Service Provider supports an Identity Provider they are given the opportunity to be a part of that Identity Provider’s Marketplace. This is where enterprise companies can search for software solutions that already connect to their chosen IDP.</p><p>Don’t let prospective customers disqualify themselves from your solution. Since SAML SSO is so often considered to be a prerequisite, when shopping for software many prospects will eliminate vendors based on this requirement when creating a shortlist. It is in your best interest, as a Service Provider, to support as many Identity Providers as possible to ensure this is not an objection for future prospects.</p><h3>Which Identity Providers you should support first<a href="#which-identity-providers-you-should-support-first" title="Direct link to heading">#</a></h3><p>Since balancing resources when determining your feature roadmap is a constant concern, you’ll need to prioritize the Identity Provider with the greatest reach. <a href="https://www.okta.com/" target="_blank" rel="noopener noreferrer">Okta</a> and Microsoft’s <a href="https://azure.microsoft.com/en-us/services/active-directory/" target="_blank" rel="noopener noreferrer">Azure Active Directory</a> are the industry leaders, but still require scoping, coding, testing, documenting, and training in order to produce a working prototype.</p><h3>The easy way to enable IDP logins<a href="#the-easy-way-to-enable-idp-logins" title="Direct link to heading">#</a></h3><p>Given the challenges of supporting multiple IDPs, it won’t surprise you that we recommend giving <a href="https://ossoapp.com/blog/1-0-0-release-candidate">Osso</a> a try. We’ve built a one-stop solution to connect your Service to a number of Identity Providers (and we’re constantly adding more), in addition to providing an intuitive dashboard to help manage and onboard your enterprise customers. Each Identity Provider has been outfitted with customized <a href="https://ossoapp.com/docs/user-guide/onboarding-customers">documentation</a> so that your Customer Success and Sales teams can take the lead on seamlessly onboarding your next enterprise customer to their preferred Identity Provider. </p><p>We’re excited to help businesses of all sizes support SAML, so if that sounds appealing please check out our <a href="https://ossoapp.com/pricing">plans</a> to find an option that fits your needs.</p></section></div>]]>
            </description>
            <link>https://ossoapp.com/blog/all-about-idps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872585</guid>
            <pubDate>Fri, 22 Jan 2021 15:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Interactive Virtual Keyboard to Visualize Collections of Shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25872549">thread link</a>) | @tkainrad
<br/>
January 22, 2021 | https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>An important part of <a href="https://keycombiner.com/">KeyCombiner</a> is displaying collections of keyboard shortcuts. Therefore, I have invested a lot of time to design searching and filtering features that help to browse even large collections.</p>
<p>Unfortunately, these feature are not sufficient when you want to understand a collection of hundreds of shortcuts at a glance. I have been thinking about this problem since I started working on KeyCombiner almost precisely one year ago. Today, I am happy to announce that KeyCombiner offers a solution:<br>
The Shortcut Collection Visualizer</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/visual-keyboard-short-blog-bg.gif" alt="Collection Visualizer for XCode, one of very few applications that use all 4 modifier keys at the same time."> <figcaption>
<p>Collection Visualizer for <a href="https://keycombiner.com/collections/xcode/">XCode</a>, one of very few applications that use all 4 modifier keys at the same time.</p>
</figcaption>
</figure>
<p>It is heavily inspired by Waldo Bronchart’s open-source <a href="https://github.com/waldobronchart/ShortcutMapper">Application Shortcut Mapper</a>. However, it is a new VueJS-based implementation, adding several additional features that work together with the rest of KeyCombiner. Most importantly, it can efficiently process KeyCombiner’s collection tables and hence works for any shortcut collection on KeyCombiner, <a href="https://keycombiner.com/collecting/collections/public/search/?description=dialog&amp;keys=&amp;mac_keys=&amp;submit=Search">even search results</a>.</p>
<p>If you want to play around with it right away, go to any public KeyCombiner collection, e.g. for <a href="https://keycombiner.com/collections/vscode/">VSCode</a>, <a href="https://keycombiner.com/collections/intellij-idea/winlinux/">IntelliJ IDEA</a>, <a href="https://keycombiner.com/collections/xcode/">XCode</a>, <a href="https://keycombiner.com/collections/chrome/winlinux/">Chrome</a> or one of <a href="https://keycombiner.com/collections/">the other 60+ public collections</a>. If you want to fully undestand its potential, please read on.</p>

<h2 id="overview">Overview</h2>
<p>The virtual keyboard packs a lot of data into a relatively small space. Each button of the keyboard consists of the following elements:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/visual-keyboard-description.png" alt="Elements on each key of the virtual keyboard."> <figcaption>
<p>Elements on each key of the virtual keyboard.</p>
</figcaption>
</figure>
<h2 id="grouping-by-modifier-combination">Grouping by Modifier Combination</h2>
<p>A proper keyboard shortcut consists of 0 or more modifier keys and exactly one non-modifier key. There are 4 modifier keys:</p>
<ol>
<li><kbd>Ctrl</kbd></li>
<li><kbd>Shift</kbd></li>
<li><kbd>Alt</kbd></li>
<li><kbd>Cmd</kbd> (macOS) / <kbd>Super</kbd> (Windows and Linux)</li>
</ol>
<p>This order of modifiers is not random. KeyCombiner <em>always</em> shows keyboard shortcuts with precisely this order. <a href="https://twitter.com/ThomasKainrad/status/1340769935971282946">There are good reasons for this</a>.</p>
<p>This means that we have four boolean variables, resulting in $2^4$ possible modifier combinations. For each of these 16 states, the Collection Visualizer uses a different background color, or background gradient if there are multiple active modifiers.</p>
<p>To toggle modifiers, click on the virtual buttons with your mouse, or press the respective modifier key on on your physical keyboard. The entire virtual keyboard will then update according to the active combination of modifiers.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/all-modifier-states.gif" alt="It is very rare that a key has a shortcut for every modifier combination. However, it can happen, especially when combining shortcuts of multiple applications in personal collections. (Please don&amp;rsquo;t tell me I forgot one of the 16 modifier combinations - it took me way too long to create this animation.)"> <figcaption>
<p>It is very rare that a key has a shortcut for every modifier combination. However, it can happen, especially when combining shortcuts of multiple applications in personal collections. <br> (Please don’t tell me I forgot one of the 16 modifier combinations - it took me way too long to create this animation.)</p>
</figcaption>
</figure>
<h2 id="filter-collection-table">Filter Collection Table</h2>
<p>One of my favorite things about KeyCombiner’s shortcut collections is that I can filter them by context, category, or modifier combination with a single click using the panes on the side.</p>
<p>The collection visualizer expands on this concept. If you click on any non-modifier key, the collection table will show all shortcuts that use this particular key. To show all shortcuts containing the key <kbd>F</kbd> click on the F button on the virtual keyboard.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/filter-by-key-press.gif" alt="Filtering the collection table for all shortcuts that contain the F key."> <figcaption>
<p>Filtering the collection table for all shortcuts that contain the <kbd>F</kbd> key.</p>
</figcaption>
</figure>
<h2 id="real-time-updates-on-changes">Real-time updates on changes</h2>
<p>Building personal collections of keyboard shortcuts and text snippets is the foundational concept behind KeyCombiner. You can then practice these collections with its interactive trainer, relying on spaced repetition techniques and advanced statistics to guide your learning progress. You can also use <a href="https://keycombiner.com/desktop/">KeyCombiner Desktop</a> to instantly look up all combinations in your collections without leaving your current context.</p>
<p>Oh wait, I am getting side-tracked. I meant to say that the collection visualizer updates immediately whenever you make a change to one of your collections. A change could be adding new shortcuts, editing existing entries, or re(moving) entries. This works in the blink of an eye, even if you remove hundreds of combinations at once.</p>
<h2 id="additional-features">Additional Features</h2>
<p>I am getting the sense that this post will be too long for the average person’s interest in keyboard shortcuts. So, I will list some additional features in shorter form:</p>
<ul>
<li>There are three levels of opacity:
<ol>
<li>Keys without any mapped combinations</li>
<li>Keys with mapped shortcuts, but none that use the current modifiers</li>
<li>Keys that have a combination with the currently activated modifiers</li>
</ol>
</li>
</ul>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/opacity.png" alt="Different levels of opacity carry information."> <figcaption>
<p>Different levels of opacity carry information.</p>
</figcaption>
</figure>
<ul>
<li>If, for any modifier combination, there are two or more shortcuts bound to a key, the number of combinations in the top right of the button is marked red.</li>
<li>If there are two or more combinations on a key for the current modifier state, the shortcut description for this key says <em>Conflict</em>.</li>
<li>There is a small text below the virtual keyboard saying how many shortcuts are mapped onto the virtual keyboard, and how many combinations had to be skipped. (See <a href="#current-limitations">Current Limitations</a>)</li>
<li>The keyboard must be in focus if you want to activate modifiers by pressing the respective buttons on your physical keyboard. This is so that you can still use <kbd>Ctrl</kbd> and <kbd>Shift</kbd> for table selection operations without affecting the visualizer. Buttons below the virtual keyboard allow toggling the focus.</li>
</ul>

<h2 id="quickly-grasp-a-set-of-shortcuts">Quickly Grasp a Set of Shortcuts</h2>
<p>Perhaps the most obvious use case is exploring a collection of shortcuts. The visual keyboard helps immensely in this process. Within seconds, you can get a feeling of which modifiers are used by a specific application and whether it uses Vim-like home row navigation or something else entirely.</p>
<p>The different layers of opacity aid this use case. Without activating any modifiers, you can already understand where the most shortcuts are located. This is supported further by the combination count in each virtual keyboard button’s top right.
Filtering the collection table by clicking on a specific key lets you see all shortcuts for that key and understand how they are related.</p>
<h2 id="see-conflicts-and-free-combinations">See Conflicts and Free Combinations</h2>
<p>At the moment, this is my favorite use case, as I have used it plenty of times already with great success.</p>
<p>I recently <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">learned all VSCode shortcuts</a> with KeyCombiner’s interactive trainer. However, since then, I have started to experiment with <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">Foam</a> and picked up some other extensions. All of these come with their own set of commands. So, I frequently have to find an available key combination for a new command I want to use efficiently. VSCode itself is not much help with that. It tells you <em>after</em> setting a combination that it is already taken:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/vscode-binding-exists.png" alt="Different levels of opacity carry information."> <figcaption>
<p>Different levels of opacity carry information.</p>
</figcaption>
</figure>
<p>I guess it’s better than nothing, but trying multiple combinations and manually checking what other combination is already using that binding and whether you might be able to remove that other binding is not much fun.
The collection visualizer made it trivial to see that there are actually plenty of free combinations in VSCode, only <kbd>Ctrl</kbd> and <kbd>Shift</kbd> are quite busy by default. Things start happening if you mix in <kbd>Alt</kbd>:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/vscode-free-combinations.png" alt="All modifier combinations with Alt are wide open for your own assignments in VSCode."> <figcaption>
<p>All modifier combinations with <kbd>Alt</kbd> are wide open for your own assignments in VSCode.</p>
</figcaption>
</figure>
<p>You can then go one step further and find free combinations that are easy to type. For me, these are combinations that I can type with just my left hand. If the non-modifier key is on the home row, that’s another big plus. In any case, a convenient shortcut should have a maximum of two modifiers.</p>
<h2 id="design-a-coherent-set-of-shortcuts">Design a Coherent Set of Shortcuts</h2>
<p>The collection visualizer helps design a coherent set of shortcuts, either for yourself or for an application you are developing.</p>
<p>Unfortunately, many application designers do not think very hard about keyboard shortcuts. Often, you end up with a set that is neither intuitive nor easy to type. Heck, even <a href="https://keycombiner.com/collections/keycombiner/">KeyCombiner’s own shortcuts</a> are all over the place with sequences and different modifier combinations. Given that I work more or less alone on the project and try to be very efficient with my time, I didn’t think about these bindings enough. The collection visualizer makes this painfully obvious, and I will soon come up with new shortcuts. However, it will be very hard not to annoy users who have already memorized these shortcuts.
So, I recommend that you be smarter than me and start to design a coherent set of shortcuts for your application right away. The collection visualizer is here to help you with that.</p>
<p>If you are not an application designer, you might still want to design a coherent set of key bindings for your personal use. Without any tools to assist you, this is a suprisingly hard taks, especially when you try to find a coherent set for or <em>multiple</em> applications. You have to keep in mind which commands are available in these different apps, what the defaults are, and how to resolve these constraints into a set that works everywhere.
The collection visualizer, along with KeyCombiner’s other collection management features, can help you get there.</p>

<p>Above, I have written that a proper keyboard shortcut consists of 0 or more modifier keys and exactly one non-modifier key. However, KeyCombiner also allows sequences, such as the <em>Go To</em> shortcuts used by Gmail. I have been thinking a lot about how to visualize those on a virtual keyboard, but have not found a good solution yet.</p>
<p>Furthermore, KeyCombiner collections can also hold short text snippets, such as commands and programming language syntax. Many people use these snippets with the <a href="https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos">Desktop Apps' instant lookup</a>. It turns your collections into an instant, context-aware, searchable cheatsheet. However, I struggle to find a way to visualize them on a keyboard.</p>

<p>In its first days, the collection visualizer has already helped me plenty of times. I improved my VSCode bindings, realized that KeyCombiner’s own default bindings are not intuitive, and found better ways to reuse my VSCode bindings in PyCharm and Eclipse.
I’d be thrilled to hear about your experiences in the comments below or via <a href="https://tkainrad.dev/cdn-cgi/l/email-protection#c2b6aaadafa3b182b6a9a3abacb0a3a6eca6a7b4">mail</a>.</p>
<p>I will write about the collection visualizer’s implementation in a future blog post. Spoiler: Vue and (S)CSS do the heavy lifting.</p>
<br>
</div></div>]]>
            </description>
            <link>https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872549</guid>
            <pubDate>Fri, 22 Jan 2021 15:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pidgin – A Universal Chat Client]]>
            </title>
            <description>
<![CDATA[
Score 619 | Comments 420 (<a href="https://news.ycombinator.com/item?id=25872525">thread link</a>) | @smusamashah
<br/>
January 22, 2021 | https://www.pidgin.im/plugins | <a href="https://web.archive.org/web/*/https://www.pidgin.im/plugins">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/awslabs/pidgin-chime/">Amazon Chime</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Online meeting and video conferencing
                            </td>
                            <td>
                                Amazon Web Services - Labs
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/nmbook/pidgin-libbnet/">Battle.net Classic</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Blizzard’s gaming network: notably for StarCraft, Diablo II, and WarCraft III
                            </td>
                            <td>
                                nmbook
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://github.com/EionRobb/purple-battlenet/raw/master/battlenet48.png" alt="Battle.net v2 logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-battlenet#readme">Battle.net v2</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Blizzard’s gaming network for WoW, Overwatch and others
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                <img src="https://github.com/jrfoell/campfire-libpurple/raw/master/campfire48.png" alt="Campfire logo">
                            </td>
                            <td>
                                <a href="https://github.com/jrfoell/campfire-libpurple/">Campfire</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Protocol plugin for Basecamp’s Campfire IM
                            </td>
                            <td>
                                jrfoell
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/ccpp/deltachat-purple/">Deltachat</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                IM over email
                            </td>
                            <td>
                                ccpp
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-discord/#readme">Discord</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Text chat for gamers
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/samuelkarp/purple-docker/">Docker</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Send stdin commands to Docker containers
                            </td>
                            <td>
                                samuelkarp
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/fchat-pidgin/fchat-pidgin#readme">F-List</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                F-List roleplaying community
                            </td>
                            <td>
                                fchat-pidgin
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/dequis/purple-facebook/wiki/">Facebook</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Facebook chat
                            </td>
                            <td>
                                dequis
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://github.com/EionRobb/purple-gammu/raw/master/icons/48/gammu.png" alt="Gammu logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-gammu/#readme">Gammu</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Send SMS through your feature phone via usb/serial/bluetooth/irda
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://notabug.org/alyssa/groupme-purple/">GroupMe</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                GroupMe group messaging
                            </td>
                            <td>
                                Alyssa Rosenzweig
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://user-images.githubusercontent.com/1063865/87138135-18131780-c2f2-11ea-9579-3dfbb7d858fb.png" alt="Hangouts logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-hangouts#readme">Hangouts</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Alternative plugin for Google Hangouts
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                <img src="https://github.com/theli-ua/honpurple/raw/master/data/pixmaps/pidgin/emblems/16/hon_ingame.png" alt="Heroes of Newerth logo">
                            </td>
                            <td>
                                <a href="https://github.com/theli-ua/honpurple/">Heroes of Newerth</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Online video game
                            </td>
                            <td>
                                theli-ua
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/icyque/">ICQ WIM (IcyQue)</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
              …</tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pidgin.im/plugins">https://www.pidgin.im/plugins</a></em></p>]]>
            </description>
            <link>https://www.pidgin.im/plugins</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872525</guid>
            <pubDate>Fri, 22 Jan 2021 15:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our data SaaS integrates with Git]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872405">thread link</a>) | @xoelop
<br/>
January 22, 2021 | https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>During the last years all the development lifecycle has revolved around the version control system. You want continuous integration and testing, healthy release workflows, automatic security checks, linters, links to tickets, alerts… you use a tool or a service that runs that for you when something happens in your repo, like a commit, a pull request or a merge.</p> <p>The thing is: developers are privileged, they work with source code, which is a line based text format and that’s what most of the SCMs know to work with. I don’t actually know how other industries work without tools like that.</p> <p>When designing Tinybird one of the things we had in mind was: analytics data projects are code and code should be in a repo, like other parts of the aplicacion. And that’s why we decided to expose any resource as a simple text based format and a way to serialize/deserialize to and from our service.</p> <p>Most SaaS products don’t allow you to mirror your project/metadata to a repo and that makes it impossible to use the good practices I mentioned in the first paragraph.</p> <h2 id="the-design">The design</h2> <p>Our data model is simple, we just have two kinds of resources: datasources and data transformation pipes, they store and process data respectively. You can access both resources using a regular API that returns JSON but JSON is not the best format to edit and in general, be processed by a human. So we decided to also serialize them as a regular text file.</p> <p>After some tests, we finally went with the simplest possible design for that and not tie the design to an existing format. We wanted to maximize how easy it is to write one of those files in a code editor. We expose the same resources as JSON as I said if you want to automate anything, so you don’t need to write a parser for those files. Machines and people need different interfaces.</p> <p>We chose a file format like a Dockerfile, easy to parse, easy to write and organize, that allows to resolve merge conflicts without much hassle and that most developers more or less know how to deal with.</p> <p>To be clear, we are not so clever to think about all those things before we start: we went through several data analytics projects and after some iterations we found a format that was handy.</p> <p>So for example, you define a datasource like</p> <div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>#</span> <span>test</span><span>.</span><span>datasource</span>
<span>VERSION</span> <span>0</span>
<span>SCHEMA</span> <span>&gt;</span>
	<span>timestamp</span> <span>DateTime</span><span>,</span>
 	<span>user_id</span> <span>Int32</span>

<span>SORTING_KEY</span> <span>timestamp</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>And you push to our platform with our CLI tool made specifically to work with those files.</p> <div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>$ </span>tb push test.datasource
</pre></td></tr></tbody></table></code></pre></div></div> <p>That’s it, you can do that with every single resource in a project so you can still use your favorite version control system on any provider of your choice and use the code editor you use every single day.</p> <p>Of course you can pull files as well</p>  <h2 id="the-benefits">The benefits</h2> <p>Being able to serialize the project as text files and store them in github allows us to do different things with our data pipelines:</p> <ul> <li>Run data tests</li> <li>Test the API endpoints you can expose with a pipe (this means exposing the result of a SQL as an API)</li> <li>Push to production new data workflows</li> <li>Replicate the same project to several environments (local/dev/staging/pro)</li> <li>Use all the available tools: merge requests, github actions, gitlab CI/CD system…</li> </ul> <p>We just want to introduce those concepts, we will write a lot more about these things in future blog posts, you can subscribe to receive updates.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872405</guid>
            <pubDate>Fri, 22 Jan 2021 15:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Telegram Has a Nazi Problem]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25872063">thread link</a>) | @RealDeinonychus
<br/>
January 22, 2021 | https://restofworld.org/2021/terror-on-telegram/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/terror-on-telegram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>O</span>n March 15, 2019, an Australian man killed 51 people in a horrific attack on two mosques in Christchurch, New Zealand. Shortly before, he released a<strong> </strong>bombastic<strong> </strong>manifesto, in which he argued that mass immigration and high fertility rates in developing countries constitute a form of genocide against white people. Within days, an anonymous Russian translation of the more than 70-page document began spreading among far-right sympathizers in former Soviet countries. This happened primarily via Telegram.</p>



<p>One of the translation’s earliest appearances was on the Russian-language Telegram channel of the neo-Nazi platform WotanJugend, which currently has just over 15,000 followers. The document was also circulated on the site’s Telegram channel, as was a related photo of a graffiti portrait of the Christchurch shooter in full battle gear, manifesto in hand. “Blessed be your name,” read the accompanying caption.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-40x71.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-400x711.png 400w, https://restofworld.org/wp-content/uploads/2021/01/IMG_5070-600x1067.png 600w, https://restofworld.org/wp-content/uploads/2021/01/IMG_5070-1000x1778.png 1000w, " sizes="300px" alt="On the day of the Christchurch attack, Tarrant’s manifesto was uploaded to Telegram channel of the of the neo-Nazi platform WotanJugend.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Telegram</span>
			</figcaption>
		</figure>


<p>The translated manifesto was eventually removed, but saved copies can be still found via the Internet Archive Wayback Machine. For authorities wishing to exert more control over this kind of dangerous material, the platform presents a unique challenge. Telegram was designed by avowed libertarians with the goal of helping people living under authoritarian regimes circumvent censorship. Removing extremist or violent content hinges largely on the company’s cooperation, which it has only begun to grant over the last several years. This makes for a volatile situation in general, but in a fragile, nascent democracy like Ukraine, where authorities are focused on the threat of Russian aggression, extremists have been able to flourish with relative impunity.</p>



<p>On a <a href="https://www.wiesenthal.com/about/news/telegram-1.html">website announcement</a> last July, the Simon Wiesenthal Center, a global Jewish human rights organization, dubbed Telegram “the online weapon of choice for [the] violent far-right.” The report <a href="https://www.wiesenthal.com/about/news/telegram-1.html">highlighted</a> its role as a knowledge-sharing platform for far-right extremists, particularly on the subjects of Nazi ideology, military survival skills, and at-home arms manufacturing. The Wiesenthal Center also mentioned another report by the SITE Intelligence Group, a terror-tracking organization, which looked at a sample of 374 far-right channels and found that 80% of them were created within six months of the Christchurch attack. It’s difficult to say with any certainty how many of these channels exist in total, and given that the majority of them are anonymous, it’s impossible to say where their administrators are located.</p>



<p>Created by Russian brothers Pavel and Nikolai Durov in 2013 and operated out of Dubai, Telegram is best known as the preferred tool of pro-democracy activists in authoritarian countries. But its lax rules regarding inflammatory content have made it popular with extremists purged from other platforms. In 2019, Facebook <a href="https://www.theguardian.com/technology/2019/may/02/facebook-ban-alex-jones-milo-yiannopoulos">banned accounts associated with far-right groups</a> and figures such as Alex Jones and Milo Yiannopoulos. According to a recent study by University of Bern researchers, the Facebook crackdown precipitated a massive “simultaneous migration” of far-right actors to Telegram, where they were able to “swiftly re-create connections and gain prominence.” Telegram did not respond to requests for comment.</p>



<p>To map out how the “terrorgram” is evolving in Ukraine, we reached out to Alexsey Levkin, a prominent far-right spokesman who describes himself as a veteran of the conflict in Eastern Ukraine. While Levkin maintains that he doesn’t endorse terrorism, he does call himself “the mastermind” of the WotanJugend platform and claims to have coined the name, which alludes to ancient Germanic mythology and the Nazi youth movement, <em>Hitlerjugend</em>. Levkin also said he had nothing to do with the publication of the Christchurch manifesto, although he spoke approvingly of its content. Just last week, the channel posted a statement in support of NSO-North, a Russian Nazi gang whose members are serving lengthy sentences for a series of deadly hate crimes in the 2000s. “Terror has brought its fruit, but for these people, it turned out to be a suicidal path.”</p>



<p>Despite denying he is a WotanJugend admin, Levkin clearly exerts a great deal of influence over the channel — a substantial amount of the content is dedicated to him or his projects. He also claims not to be as active online as he once was, because, as he puts it in a disturbing joke: “I faced <em>Endlösung</em> [the final solution] on Facebook and other platforms.” He is, however, still prolific on Telegram. Levkin’s own channel, called Thule Signal in reference to an occultist society that influenced prominent Nazis at the beginning of Hitler’s ascent to power, has over 3,000 followers. (Levkin denies any connection.) When he is not propagating far-right views online, Levkin is often doing so IRL. He is the lead singer of the national socialist black metal band M8L8TH — the Russian word <em>molot</em> means hammer, and H stands for Hitler — and he runs a far-right fashion brand.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="Aleksey Levkin, the Russian-born lead singer of the NSBM (national socialist black metal) band M8L8TH, veteran of the conflict in eastern Ukraine, and supporter of far-right causes, poses for a portrait near the ruins of the ancient Church of the Virgina of the Tithe.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>“Oh, the bill</strong> comes to 88,” he joked mischievously as we ordered coffee outside Kyiv’s Independence Square, popularly known as Maidan. In far-right parlance, “88” is the numerical code for “Heil Hitler,” the Nazi salute. We were just around the corner from Cossack House, a former hotel seized by far-right militants during the 2014 Maidan revolution, which Levkin now uses as an event space.</p>



<p>Muscular, bearded, and blue-eyed with a shaved head, Levkin looks every bit like a Viking in a Netflix series. He is in fact a Russian citizen — one of a few dozen Russian nationalists and outright neo-Nazis who joined the Ukrainian army in fighting separatist forces backed by Russia during the Ukrainian revolution. Having grown disillusioned with Russia’s leadership and tolerance of Muslim immigrants from Central Asia, exiles such as Levkin saw Ukraine’s revolution as a victory for nationalism. It was seen as a model that could be replicated elsewhere. In conversation, Levkin referred to Ukraine as the “promised land.”</p>



<p>While Ukraine’s revolution was spearheaded by pro-democracy forces, the country’s nationalists played a visible role. They gained even more prominence when Russia seized the Crimean Peninsula and fomented conflict in the eastern Ukrainian region of Donbass. Far-right activists were among the first to form combat-ready units, and word spread through international networks that these groups welcomed foreigners. Soon, Swedes, Americans, Poles, and Georgians as well as many anti-Putin Russians were joining Ukrainians on the frontline. As international media outlets began covering this phenomenon, more people started to show up. The most prominent of these volunteer groups was the so-called Azov battalion, which later became an autonomous regiment under the auspices of Ukraine’s National Guard. From that, a number of political, veteran, and paramilitary organizations emerged, which members now refer to as the Azov movement.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-2800x1866.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Members of the Azov Battalion, a pro-Ukraine militia, demonstrate a training exercise at the group's base.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Although <a href="https://www.ui.se/globalassets/ui.se-eng/publications/ui-publications/2020/ui-brief-no.-3-2020.pdf">polls and election results show</a> that the far-right in Ukraine has very little public support, members of these networks have infiltrated government institutions and security bodies at the highest levels since 2014. Vadym Troyan, a former deputy commander in Azov and an alumnus of a white supremacist group, is currently a deputy minister in Ukraine’s Ministry of Internal Affairs; Azov founder Andriy Biletsky was a member of parliament between 2014 and 2019. Although the<strong> </strong>Ukrainian government was cautious about accepting foreign fighters, which likely helped stem an influx of extremists, the country still developed a reputation as a welcoming destination for the far-right. In a<a href="https://www.ctc.usma.edu/the-nexus-between-far-right-extremists-in-the-united-states-and-ukraine/"> report</a> published by the Combating Terrorism Center at West Point, journalist Tim Lister says that the success of Azov made ultranationalists around the world regard Ukraine as a “field of dreams.” According to an official government inquiry into the Christchurch shooting, not long before the massacre, the perpetrator told his family that he wanted to relocate to Ukraine.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-40x71.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-400x711.png 400w, https://restofworld.org/wp-content/uploads/2021/01/IMG_7447-600x1067.png 600w, https://restofworld.org/wp-content/uploads/2021/01/IMG_7447-1000x1778.png 1000w, " sizes="300px" alt="Activists display Hitler’s portrait on a bridge in Kyiv on the a Telegram channel.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Telegram</span>
			</figcaption>
		</figure>


<p>As social and political pressures have <a href="https://about.fb.com/news/2019/09/combating-hate-and-extremism/">prompted Facebook and YouTube to purge extremist content</a>, Telegram has transformed into a nerve center for far-right sympathizers, many of whom come from the former Soviet Union. Content is shared widely within this ecosystem, and posts typically celebrate Hitler, explore far-right philosophy, satirize and denigrate people of color, and glorify perpetrators of terror attacks motivated by racial hatred. The channels also advertise offline lectures and workshops — and the occasional rubber knife tournament — and promote like-minded Telegram channels in Russian, Ukrainian, various Eastern European languages, German, and English. These outlets don’t seem to be focused as much on luring people to specific far-right groups as they seem to function as propaganda for autonomous terrorism — that is, “lone wolves.”</p>



<p>Most Russian and Ukrainian channels promote what they call a “traditionalist and conservative” agenda, which consists of a mix of open racism and hate-mongering against feminists and the LGBT community. Levkin says that, in a world constricted by political correctness, many far-right channels have been successful in reaching out to “normies” — ordinary people, in the movement’s parlance — and providing them an outlet for transgression. An especially popular source for far-right content is a Telegram channel run by Sergey Korotkikh, the most prominent living neo-Nazi from the former Soviet world. Originally from Belarus, Korotkikh helped create what was once a large Russian neo-Nazi organization before fleeing the country and ending up in Ukraine, where he assumed a leadership role with Azov. His Telegram channel, which has 23,000 followers, churns out hatred and obscenity on …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/terror-on-telegram/">https://restofworld.org/2021/terror-on-telegram/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/terror-on-telegram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872063</guid>
            <pubDate>Fri, 22 Jan 2021 14:50:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A story about pivots]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25871629">thread link</a>) | @james_impliu
<br/>
January 22, 2021 | https://posthog.com/blog/story-about-pivots | <a href="https://web.archive.org/web/*/https://posthog.com/blog/story-about-pivots">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>PostHog has pivoted <em>a lot</em>.</p>
<p>After 5 pivots in 6 months, we got into <a href="https://www.ycombinator.com/">YCombinator</a> last year, pivoted again whilst we were there and have now gone from the first commit to thousands of deployments, a team across 10 countries and $12M raised, in well under a year. We've a long way to go, but we're delighted at how it has gone so far.</p>
<p>This is that story and what we learned from it.</p>
<h2 id="youll-feel-silly"><a href="#youll-feel-silly" aria-label="youll feel silly permalink"></a>You'll feel silly</h2>
<p>It goes something like this:</p>
<ol>
<li>Convince yourself then your family, friends and colleagues you have some great idea.</li>
<li>Quit your job.</li>
<li>Build it. Listen to the soundtrack from <a href="https://www.imdb.com/title/tt1285016/">The Social Network</a> way too much.</li>
<li>Everyone thinks your thing is terrible. Hopefully you realize.</li>
</ol>
<p>The nature of a startup is that you have to <a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users">talk to users</a>. Or so we've heard.</p>
<p>My sole focus for weeks on end was just to get meetings with people that we felt may have the same problem we were trying to solve.</p>
<h2 id="it-got-good-eventually-right"><a href="#it-got-good-eventually-right" aria-label="it got good eventually right permalink"></a>It got good eventually, right?</h2>
<p>In 9 months, we built 6 products and did more than 100 meetings with potential users.</p>
<p>The range of ideas we tried to solve looks broad, but the thing that connected all of them was that we tackled problems we'd experienced in our previous professional lives.</p>
<p>So, what did we build?</p>
<h3 id="1-sales-territory-management-tool"><a href="#1-sales-territory-management-tool" aria-label="1 sales territory management tool permalink"></a>1. Sales Territory Management Tool</h3>
<p>At one stage in my life, I was the VP of Sales at an enterprise software company. On paper, it looked like a glamorous job - I used to fly around the world with the sales team, and met with huge enterprise clients in fancy skyscrapers, like the <a href="https://en.wikipedia.org/wiki/International_Commerce_Centre">ICC in Hong Kong</a>:</p>
<p><a href="https://posthog.com/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg">
                    <img src="https://posthog.com/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg" srcset="https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=175 175w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=350 350w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=700 700w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=1000 1000w" sizes="(max-width: 700px) 100vw, 700px" title="International Commerce Center - a big skyscraper in Hong Kong" alt="International Commerce Center - a big skyscraper in Hong Kong" loading="lazy">
                </a></p>
<p>Despite this, the <em>majority</em> of your time in sales is spent getting nowhere. All those hotels, flights, calls, fastidiously wearing a suit in inappropriately warm weather - very few of those things result in anything.</p>
<p>Sidenote: this is why <a href="https://posthog.com/handbook/growth/strategy">product led growth</a> is so much better.</p>
<p>If you're not getting anywhere with a potential customer after a few weeks or months of trying, your time is better spent elsewhere. Yet systems that are the core products of <a href="https://en.wikipedia.org/wiki/Salesforce">$17.1Bn revenue companies</a> come with a manually selected arbitrary number for the percentage probability that doesn't vary with time.</p>
<p>We pulled pipeline data from Hubspot or Salesforce, then used predictive analytics to work out how this curve looked based on historic data, then applied it to the current pipeline. Once a deal dropped below a certain threshold, we'd recommend you swap out that target company and pull a new one into the pipeline.</p>
<p>We confused a lot of people with this idea, because we were confused with whom we were targeting.</p>
<p>We got 15 sales leaders to agree to trying this out, sent them a link, then waited...</p>
<p>and waited...</p>
<p>just <em>one</em> person even clicked the sign up link. The rest didn't even try it.</p>
<p>With hindsight, it was way overpowered for tiny teams and we'd only have had a great fit for huge ones with a lot of data.</p>
<p>The only people interested in smaller teams were enthusiasts, but there wasn't an easy jump from that to a bigger market. We could have just worked on selling the product to big companies, but that would be <a href="https://www.ycombinator.com/library/3O-why-big-deals-are-bad-for-startups">tough</a>.</p>
<h3 id="2-crm-with-predictive-analytics"><a href="#2-crm-with-predictive-analytics" aria-label="2 crm with predictive analytics permalink"></a>2. CRM with Predictive Analytics</h3>
<p>One of our friends who ran a small sales team was a clear outliter. He had been using our first product a lot. We asked ourselves - why?</p>
<p>He had used it to <em>replace</em> his CRM. </p>
<p>Could we just do the whole lot in one place, and reimagine the CRM - would that make things feel simpler?</p>
<p>We positioned the product as a CRM for small companies, with predictive analytics for an even simpler experience managing everything. We tweaked the functionality to have more control over deals and contacts.</p>
<p>It suddenly got really hard to get anyone to talk to us.</p>
<p>There are many lightweight CRMs out there, and predictive analytics make more sense for those with more data, not startups with hardly any.</p>
<p>This was around the time that <a href="https://superhuman.com/">Superhuman</a> was getting pretty popular; we got overexcited, and kept using words like "blazing", "gorgeous", "brilliant". I blame too much time wasted reading <a href="https://sifted.eu/articles/vc-brags-twitter/">VC Twitter</a>.</p>
<p>We didn't think through who we were building for. The market we were working on was very busy, so if I went back in time, I would have focused more on our differentiation - a product could make more sense than a platform. Tim and I also just weren't strong enough at design to differentiate on that alone.</p>
<p>After hundreds of messages to potential users, we eventually got a single customer for $20/month, who then didn't actually pay the invoice. If you're pushing this hard and getting nowhere, you don't have the magic of <a href="https://www.youtube.com/watch?v=l-vfn97QTr0">product market fit</a>.</p>
<h3 id="3-11-tool-with-predictive-analytics"><a href="#3-11-tool-with-predictive-analytics" aria-label="3 11 tool with predictive analytics permalink"></a>3. 1:1 Tool with Predictive Analytics</h3>
<p>Back to basics - what was the actual problem we were solving?</p>
<p>It was the prioritization of where to focus your sales efforts. If 90% of your deals deals won't close, you need to get good at not spending time on those that aren't going to close.</p>
<p><a href="https://en.wikipedia.org/wiki/Andrew_Grove">Andrew Grove</a> has an excellent book, <a href="https://www.amazon.com/High-Output-Management-Andrew-Grove/dp/0679762884/ref=sr_1_1?dchild=1&amp;keywords=high+output+management&amp;qid=1610712757&amp;s=books&amp;sr=1-1">High Output Management</a>. The premise is that your 1:1 meetings with your direct reports are your most leveraged time.</p>
<p>Yet, many managers in practise don't prepare, at all.</p>
<p><a href="https://posthog.com/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg">
                    <img src="https://posthog.com/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg" srcset="https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=175 175w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=350 350w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=700 700w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=1000 1000w" sizes="(max-width: 700px) 100vw, 700px" title="A team that look a little bit like their happiness is staged" alt="A team that look a little bit like their happiness is staged" loading="lazy">
                </a></p>
<p>We changed the UX completely, and made an app that looked a bit like google docs, where you and your reports could each create an agenda in advance and take notes. The twist? The product would interpret your sales pipeline and would use predictive analytics to suggest specific deals to discuss that could be worth replacing or that had changed dramatically since the previous week.</p>
<p>We managed to get lots of meetings easily with this idea, and everyone reported not preparing to the standard they wanted. Did we have a silver bullet?</p>
<p>Despite giving out logins, only one team out of around 10 started using the tool. </p>
<p>We were flumoxed. This tool was simple, people were excited, but no one used it.</p>
<p>For those that haven't read it, <a href="http://momtestbook.com/">The Mom Test</a>, which I wish I'd read sooner, explains our downfall here perfectly:</p>
<div data-language="text"><pre><code>If they haven't solved the problem, ask why not. Have they tried searching for solutions and found them wanting? Or do they not even care enough to have Googled for it?

Rule of thumb: Anything involving the future is an over-optimistic lie.</code></pre></div>
<p>If we'd have asked this question, we'd have saved a couple more weeks.</p>
<p>By this stage, we were thinking we just wanted to work with people that would at least try our stuff. These pesky heads of sales were just too capricious and we needed a break.</p>
<p>Software engineers, surely they'd be more willing to try something that we built. We moved on to a different idea we'd had. Voilà:</p>
<h3 id="4-technical-debt-monitoring-tool-using-surveys-after-each-pull-request"><a href="#4-technical-debt-monitoring-tool-using-surveys-after-each-pull-request" aria-label="4 technical debt monitoring tool using surveys after each pull request permalink"></a>4. Technical Debt Monitoring Tool using Surveys after each Pull Request</h3>
<p>We'd seen the impact of technical debt not being paid off at the right rate in our past, and had the perspective that automation isn't key to solving it. We believed that engineers knew when it was worth tackling.</p>
<p>I spoke with every developer or engineering leader I'd ever worked with, and many I hadn't. They all said this problem was a huge pain point.</p>
<p>So we built a survey tool that integrated with git repositories. After each pull request, it would ask the developer to answer a few quick questions - did anything slow them down, what type of problem was it, and roughly how much time was wasted. The tool would then visualize the code base against time lost to help surface where to start.</p>
<p>We got quite a lot of users, and we got into YCombinator with this idea. Three weeks into the batch, we had reached 600 users, with a 50% response rate to the surveys.</p>
<p>We had started trying to charge people for the product. But we kept getting feedback that although it was a nice way to log issues, it just wasn't helping solve the problem. A few teams converted at very low order values with a lot of pushing, but it was clear we had a problem.</p>
<p>It turns out everyone has problems with technical debt, but solving it involves changing how teams prioritize. Product teams weren't using the tool, and they were often dictating what people built.</p>
<p>After a meetup with our YC friends at a cool <a href="http://sparksocialsf.com/">food truck spot</a>, we took a long walk back to our house in <a href="https://en.wikipedia.org/wiki/Castro_District,_San_Francisco">Castro</a>. We were thinking about how to solve our product woes. Could it turn into a piece of roadmapping software? Would it need to integrate with the roadmap software already in use? We just didn't feel excited about building these things out.</p>
<p><a href="https://posthog.com/static/about-to-run-out-of-product-ideas-31f3a4983d29ab835ee25c87a04dcb56.jpeg">
            <img src="https://posthog.com/static/about-to-run-out-of-product-ideas-31f3a4983d29ab835ee25c87a04dcb56.jpeg" title="James and Tim at a group ycombinator meetup about to walk home" alt="James and Tim at a group ycombinator meetup about to walk home" loading="lazy">
        </a></p>
<p>A couple of days later, driving between Mountain View and San Francisco, we realized that we just weren't the right people to run this business.</p>
<p>Although Tim had struggled with technical debt first hand, neither of us had solved it. If one of us had managed an engineering team before, we'd have perhaps been better placed to understand things. Our basic skills were good enough to get quite far with the idea, but we didn't have the belief to take it further.</p>
<p>Along the way, we learned a lot about how developers and product managers work together. We'd also created a big list of future ideas we'd had whilst building all the above things out. If you can't stop thinking of other ideas, you probably are building something you don't like. This all came into play for idea 6 later on (the good one).</p>
<p>So what did we do next?</p>
<h3 id="5-engineering-retention-tool-using-surveys-after-each-pull-request"><a href="#5-engineering-retention-tool-using-surveys-after-each-pull-request" aria-label="5 engineering retention tool using surveys after each pull request permalink"></a>5. Engineering Retention Tool using Surveys after each Pull Request</h3>
<p>Those fickle engineers joining companies and leaving them whenever they want to ;)</p>
<p>This idea didn't come from us, which doomed it before it even really started.</p>
<p>This lasted all of 5 days. We had a bunch of meetings left over from (4) to validate it. Amusingly we had to do a YCombinator demo day dry run for this in front of 500 people who made up the YC batch.</p>
<p>We had a wildly unenthusiastic response from prospective users. The lowlight was during one of the meetings that we resorted to asking the CTO of an 80 person start up what his biggest problem was, "I've not really got any". Noice, noice.</p>
<p><a href="https://gfycat.com/discover/andy-samberg-gifs">from Andy Samberg GIFs</a></p>
<h3 id="6-open-source-product-analytics-platform"><a href="#6-open-source-product-analytics-platform" aria-label="6 open source product analytics platform permalink"></a>6. Open Source Product Analytics Platform</h3>
<p>Things got meta.</p>
<p>Along our journey (/series of failed ideas), we got frustrated having to send all our user data to 3rd parties to understand our product usage. It felt wrong and it meant we'd …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://posthog.com/blog/story-about-pivots">https://posthog.com/blog/story-about-pivots</a></em></p>]]>
            </description>
            <link>https://posthog.com/blog/story-about-pivots</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871629</guid>
            <pubDate>Fri, 22 Jan 2021 13:53:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Chose a Monorepo]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25871479">thread link</a>) | @whatl3y
<br/>
January 22, 2021 | https://blog.lance.to/why-we-chose-a-monorepo | <a href="https://web.archive.org/web/*/https://blog.lance.to/why-we-chose-a-monorepo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some epic rivalries:</p>
<ul><li>Batman vs. Superman</li>
<li>Right vs. Left</li>
<li>Tabs vs. Spaces</li>
<li>Monolith vs. Microservices vs. Monorepo</li></ul>

<h2 id="monoliths-microservices-monorepos">Monoliths, Microservices, &amp; Monorepos</h2>

<p>You want to get a stale, probably introverted nerdy software development team heated up? Ask them if they prefer tabs vs. spaces. Or maybe which programming language or IDE reigns supreme. One final debate that's sure to get the room stirring is whether you should build your project as a Monolith, with Microservices, or as a Monorepo.</p>

<p>To those who might not have heard these terms or concepts, or have but with limited detail and don't know exactly what they are, here's a short<sup>*</sup> break down:</p>
<ol><li><strong>Monolith</strong>: Think of this as a single codebase that is used to build all of the functionality that your product or business needs to get things done. You probably have a backend with a single API, a single frontend, and single test suite across the entire codebase regardless of how big or small it is.</li>
<li><strong>Microservice</strong> (multi-repo in the image below): A <em>small</em> codebase that does one thing, or a very small number of things well. Your business or product likely contains lots of small services like this, all of which focus on solving a very specific problem. A single microservice is likely a standalone API or something similar that has an easy interface to communicate with other services (HTTP, REST, GraphQL, etc.), and many times has its own standalone, segregated components separate from any other service (think database(s), caches, test suites, etc.)</li>
<li><strong>Monorepo</strong> (or mono-repo): A single repository that contains much, if not all of the code for a business or product to function, but that could be and likely is separated in some logical structure to separate services, apps, APIs, SDKs, or other codebases into their own little buckets inside the repo. You can likely <code>git clone</code> this repo and it will fetch all the code that exists for the business and/or product, but there are segregation of concerns based on the file structure inside.</li></ol>

<p><img alt="Monolith, Microservices, Monolith" src="https://lance.to/public/monorepo.jpeg"></p>

<p><small>* There's a ton more detail we could add about what constitutes each of these concepts, but in an effort to encourage conciseness we'll keep it simple for now.</small></p>

<h2 id="90-monolith">90% Monolith</h2>

<p>To start, there isn't a one size fits all answer as to which structure all projects <em>should</em> use. The answer depends on a lot of things like your use case, business, product/app design, etc. In saying that a large majority of products/projects/apps/etc. aren't revenue generating and/or don't make it past a few hundred or a few thousand concurrent users. What I'm about to say isn't data driven and I don't have any references to support this number other than anecdotal experience, but I would argue somewhere around 90% of projects never need to go beyond a Monolith.</p>

<p>You may be asking, “this article is written to advocate for <strong>Monorepos</strong>, why are you saying such a large percentage of projects simply need a <strong>Monolith</strong>?” That's a good point, but simply put a monolithic codebase frankly makes things easier. Having a single codebase where all your business logic lives and all your APIs use the same language and framework(s), authentication mechanism, middlewares, database(s), etc. will generally provide a quality of life improvement and save time. You can focus on solving your business problems and not spending a bunch of time scaffolding a new microservice and making decisions about mundane aspects like what programming language to use, what database(s) make the most sense, how to handle authentication, how to support communication to other services, what test suite to use, etc.</p>

<p>That being said, Monoliths can have several limitations and problems when a project becomes bigger and starts to scale in a relatively significant way. Here are a few scenarios that you might find yourself experiencing when it's time to start considering and making the move from Monolith to another architecture:</p>
<ul><li>Your successful app that is now scaling might have changing, more stringent performance improvements and your Ruby on Rails app isn't fast enough to consume and respond to thousands of requests per second in a reasonable time.</li>
<li>Your development team has grown from two to ten people that make up two or three different teams and now when they're working on their tasks or projects you start to notice large merge conflicts taking more of their time to resolve when merging to the main branch.</li>
<li>In a year you went from a few gigabytes of data to now approaching your first terabyte of data. Your single database is struggling to scale and keep query execution times to a reasonable and expected level (single to tens of milliseconds).</li></ul>

<h2 id="so-microservices-monorepo">So...... Microservices? Monorepo?</h2>

<p>Instead of talking through the pros and cons of Microservices and Monorepos to describe how you can structure your app(s), I'll walk through why and how a Monorepo has been such a success for <a href="https://risk3sixty.com/phalanx-grc/" rel="nofollow">Phalanx at risk3sixty</a> and why we opted for it over Microservices.</p>

<h3 id="phase-1-create-our-first-microservice">Phase 1: Create our first microservice</h3>

<p>A little over a year ago at the time of writing we had a Monolithic Node.js web app with a Vue frontend. We had several background jobs using <a href="https://github.com/actionhero/node-resque" rel="nofollow">node-resque</a> and all of our data was stored in either a single Postgres or Redis database. The catalyst that triggered us to consider and ultimately separate a service into its own repo with its own dependencies, APIs, tests, etc. was due to the size of our Monolith and slow build/deploy time. We originally used ES6 and ES7 compliant Javascript throughout our app and <a href="https://babeljs.io/" rel="nofollow">babel to transpile</a> it. We were starting to make a transition to Typescript as well, so our build chain was compiling ES7 Javascript to code that the currently-supported version of Node.js could run, Typescript files to Javascript, and a number of additional downstream tasks that would get our app ready to deploy. As you can imagine, as we built out business logic and APIs, the codebase grew and the amount of time it took to build took longer and longer.</p>

<p>The first service we broke out, what I'll call our <strong>image service</strong>, of the Monolith was a service that had <a href="https://github.com/puppeteer/puppeteer" rel="nofollow">puppeteer</a> and <a href="https://github.com/lovell/sharp" rel="nofollow">sharp</a> as dependencies and was a simple API that would take URLs to take screenshots of (using puppeteer) or convert images to the specification provided by the user (would support resizing images, changing colors, etc.) Obviously instead of just adding new API endpoints with the required code in our Monolith to support our use cases, we had to setup a new standalone repo, package.json file with all dependencies, web server, middlewares required, determine how to organize endpoints, etc. We also had to build out the library we would use to communicate with this new service from our original Monolith where the majority of our business logic existed since we could no longer simply <code>import Dep from './dep'</code> like we might have done previously.</p>

<p>While this process took a little more time than it would've to just add our APIs to our Monolith, ultimately once we were finished with the prototype we now had a new app that took a fraction of the time to build and run than it took our Monolith. That alone made a huge impact and we were satisfied with the result.</p>

<h3 id="great-now-let-s-run-it-all-together">Great! Now let's run it all together</h3>

<p>Awesome, we now have a <code>Dockerfile</code> and <code>docker-compose.yml</code> in our Monolith that starts our main app and all dependent databases and such in their own containers and a new <code>Dockerfile</code> and <code>docker-compose-yml</code> in our image service that runs it. Uh oh, how would we handle networking between different <code>docker-compose</code> environments? The best option is to have everything in the same single <code>docker-compose.yml</code> so we can name our services and subsequently setup our environment so all services can easily communicate between each other. But where would this new, aggregate <code>docker-compose.yml</code> file live?</p>

<h2 id="monorepo-it-is">Monorepo it is</h2>

<p>The way we solved this was to instead restructure our main codebase to add some language namespaces, <code>cmd</code> vs <code>pkg</code> directories here to distinguish between standalone apps and libraries/SDKs, and finally individual repositories. At this point we can create a root <code>docker-compose.yml</code> and add all <code>Dockerfile</code> contexts based on the service(s) we need to include, and easily combine our original Monolith web app with our new image service. This worked great and we were up and running both services and able to communicate between both with little headache.</p>

<p>Our directory structure for our Monorepo was as follows after adding a couple SDKs, libraries, and beginning a Go API.</p>

<pre><code>phalanx/
├── .circleci/
│   └── config.yml
├── nodejs/
│   ├── cmd/
|   |   ├── img-service
|   |   └── phalanx
|   ├── pkg/
|   |   ├── phalanx-node-sdk
|   |   └── phalanx-utilities
├── go/
│   ├── cmd/
|   |   └── phalanx-go-api
│   └── pkg/
|   |   └── phalanx-go-sdk
├── docker-compose.yml
└── README.md
</code></pre>



<p>I'll reiterate again that there is no one size fits all solution to how to structure your project(s). The answer depends on a number of factors from size and scalability needs to what you're comfortable with as a developer. Our Monorepo experience has been outstanding so far and we now have ~20 different packages, libraries, apps, and APIs within our Monorepo that are painless to make changes to, add features, run tests, and deploy.</p>

<p>Not only is the R&amp;D experience nice, but we can setup CI to only run tests within the repo(s) we're working on, so you're not running all tests in the entire set of apps on each deploy, just the ones you want or that have changed. Finally, teams can own their own apps or libraries and you're almost never going to cause merge conflicts with the main branch against other teams codebases even though you're technically working in the same repo.</p>

<p>As you scale your business and apps, I highly recommend looking into this structure as it supports rapid prototyping and development and keeps things clean and scalable so you can focus on the business problems your solving!</p>
</div></div>]]>
            </description>
            <link>https://blog.lance.to/why-we-chose-a-monorepo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871479</guid>
            <pubDate>Fri, 22 Jan 2021 13:32:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I automate my life and why you should too]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25871090">thread link</a>) | @newnottakenname
<br/>
January 22, 2021 | https://blog.nntn.nl/architecture-of-my-life-2021 | <a href="https://web.archive.org/web/*/https://blog.nntn.nl/architecture-of-my-life-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><img src="https://miro.medium.com/max/606/0*BaxS_a-8UWDxksDx" alt="FromÂ&nbsp;XKCD"><figcaption>FromÂ&nbsp;XKCD</figcaption></figure>
<p>This is an updated version of the 2019 post, architecture of my life, which you can find <a href="https://blog.nntn.nl/architecture-of-my-life" target="blank">here</a>.</p>

<p>Automation is something dear to my heart. Like the figure at the top of this post, I am not sure that in the end it will have actually saved me time, but it has given me many opportunities to learn, as trying to build a resilient piece of software with a beautiful architecture, which helps me be more productive is an ever-evolving project, which will keep pushing me to learn more. I hope with this I can inspire you to automate some part of your life.</p>
<p>In this blogpost I will describe the following things:</p>
<ul><li><a href="#the-foundation"><b>The foundation</b></a>:<br>The code my automation is built upon. It will also explain the fundamental ideas behind how I think about automation.</li>
<li><a href="#actions"><b>Actions</b></a><b>:</b><br>An overview of some of the automation I have built. If you're looking for some inspiration to build something yourself, this is the place to go.</li>
<li><a href="#other-software-i-made"><b>Other software</b></a><b>:</b><br>Not everything I built can be run inside the framework I built. I also built some other cool utilities to help me in my every day life.</li></ul>

<p>The core and foundation of my automation is named Atlas. Atlas handles everything to run my automation, from connecting to services to handling errors.</p>
<h2 id="an-action">An Action</h2>
<p>At the core of Atlas is a simple idea: Actions. Anything I might ever want to automate is an action. It will act on my behalf on the online services that I use. Some actions will check for themselves if they need to run (adding a reminder for a sent email). The action can also decide how often it wants to run, from every 15 minutes to once a week. Others I only want to run when I need them to (checking the uptime of my systems). </p>
<p>Some require input to do their job correctly (adding a todo to my todo list). The most complicated actions have some state, as the input they require is more complicated. </p>
<p>To build this state I use a chatbot interface, where I give a command, the system parses my input, updates the state and performs the next step, incrementally building the state until all the necessary properties for the action to complete are in place. This flow is explained in the figure below</p>
<figure><img src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4c8fca8e-34ca-4d28-aae0-8739d858799a%2FUntitled.png?table=block&amp;id=3589228c-eff7-48d2-96d1-453c772c5623&amp;userId=&amp;cache=v2" alt="Overview of the state"><figcaption>Overview of the state</figcaption></figure>
<p>For example, when I want to add a task to a specific task list, I first write the content of that task, which is added to the state. It replies asking which project I want it to add to with some example task lists. I reply with "Write a blog". In the "Update State" part of the flow, this title of a task list is then internally converted to the internal id of the list. This way, me and anyone else using the system do not need to know the exact internals.</p>
<h2 id="interface">Interface</h2>
<p>Atlas is always part of another project. It is wrapped in Ares, a project that connects Atlas and the Microsoft Bot Framework to make it available as a chatbot, in my case as a Telegram chatbot, where you can ask it to perform the actions. It is also run as an Azure Function, available as a <a href="https://zeus-laurentia.azurewebsites.net/api/run/help" target="blank">web-api</a>. I have used this API to build an iOS shortcut to run Actions from my phone and watch and have created a windows application such that I can run any action from my laptop. The Azure Function also runs on a timer trigger and executes every 15 minutes to execute the relevant actions. </p>

<figure><img src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff3b1e86d-a29f-42cd-a80c-2919f668ba32%2FUntitled.png?table=block&amp;id=cd513ca1-b189-4792-9c94-ea4428a84242&amp;userId=&amp;cache=v2" alt="Telegram chat interface"><figcaption>Telegram chat interface</figcaption></figure>





<h2 id="exceptions">Exceptions</h2>
<p>One of the problems of building your own automation is that things are breaking. Constantly. I am connecting to 17 online services and having 35.000+ lines of code means that it is likely something will break. Most of the errors occur within Actions, as they make the calls to external services and change (and therefore break) most often. To make sure one action does not break the entire system, the actions are run in a try-catch block. </p>
<p>Once an action crashes, automation will start running to handle the crash. Independently running actions will start to send me messages to tell me that it is broken after four failed runs, so that timeouts and other temporary problems donâ€™t bother me. It will also automatically throttle itself, postponing its next run in an exponential way, to make sure it does not break anything and I do not get spammed with messages. </p>
<p>After 10 crashes, my automation will automatically create a GitHub issue with the name of the action that crashes and the stack trace. It will even try to generate a url to line in the code in GitHub link where it believes the issue is originating.</p>
<p>The Telegram chatbot will ask the user after a single crash if it wants to make a GitHub issue, as this is deemed more important.</p>
<p>Now, you have a good overview of the basics, we can discuss the cool parts.</p>

<h2 id="spotify">Spotify</h2>
<p>I like to listen to a lot of music. Last year, I spent 98.960 minutes listening to <a href="https://spotify.com/" target="blank">Spotify</a>, one of the most  popular streaming services out there. To help me get the most out of their service, I have a lot of automation running to help me. </p>
<h3 id="sort-by-loudness">Sort by Loudness</h3>
<p>To aid you in finding new music, Spotify presents you with two auto-generated personalized playlists. AÂ&nbsp;<a href="https://support.spotify.com/us/using_spotify/playlists/discover-weekly/" target="blank">Discover Weekly</a>Â&nbsp;playlist with new music from new artists and aÂ&nbsp;<a href="https://support.spotify.com/us/using_spotify/playlists/release-radar/" target="blank">Release Radar</a>Â&nbsp;playlist which contains music released this week. Both are very nice, but have one problem, they jump from very loud energetic to peaceful piano music. This is very jarring if you are listening. To solve this, I download all songs from the playlist and get the features of the songs. <a href="https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/#audio-features-object" target="blank">These features are provided by Spotify</a> and contain things like energy, danceability, liveness and loudness. I order all songs by loudness and put them in a new playlist for me. This way I can listen to my music from very loud to very peaceful.</p>
<h3 id="personally-generated-playlists">Personally generated playlists</h3>
<p>Once you have features of songs, you can think bigger. Spotify can extract features from all of my saved music. From that you can generate playlists. However to do that, you would need to find the perfect settings to create a nice playlist. For this I created a windows application called Playlister, explained further below. Using Playlister, I have created playlists named Summer, Winter, Piano and Energy. Every week, Atlas downloads all my saved songs from Spotify and runs it through each of the finely tuned filters for my playlists and updates each with new songs Iâ€™ve added and removes songs I no longer like. So if I want to listen to music that gets me hyped, I listen to the Energy playlist, which consists of songs I like that, following my tweaks, can be considered full of energy.</p>
<h3 id="last-4-weeks">Last 4 weeks</h3>
<p>I (used to) spend a lot of time biking and travelling by train. I have a data plan, but don't want to overshoot it. This leads to the fact that I need Spotify to download a lot of music. However, I also have a lot of new music that I want to bring with me. I could download all my music, but my phone does not have enough storage for that. To solve this problem, Atlas will update a playlist every night with all of the songs I added in the last 4 weeks. I then tell Spotify to keep this playlist downloaded at all times. This leads to an almost always updated playlist with my newest songs.</p>
<h3 id="random-songs">Random Songs</h3>
<p>In the previous paragraph I explained that I canâ€™t download every songs to my phone. However, I might want to listen to a random selection of music every once in a while. Music not in one of my automatically generated playlist or in any other list. Furthermore, even if I have internet, I sometimes feel like the shuffle is not completely random. And lastly, it is also sorted by loudness and if I need to concentrate, I can start at loud and end at calm music. To solve these problems, every night Atlas takes all my saved music, picks 50 random songs and adds it to a playlist sorted by loudness, so I can always listen to some random music I like.</p>
<h3 id="full-release-radar">Full Release Radar</h3>
<p>Spotify has a feature called Release Radar, where each week, you can listen to music that came out that week from artists you follow or might find interesting. This is great and Iâ€™ve gotten a lot of new music from it, however it might miss artists that I like and if an artist released an entire album, it will only display one song in the playlist, which I can definitely understand, but I donâ€™t want. So I created an Action on Atlas, which every Friday checks all the artists I follow. If they released any new music in the last week and it puts the songs into a playlist called â€œFull release radarâ€�, so that I do have this overview.<br>As an addition, another action checks if I added music from a new artist and automatically follows them, so this list is constantly expanding.</p>
<h2 id="todoist">Todoist</h2>
<p>Task lists are must for me. I forget a lot of things and task lists enable me to keep track of all the things I need to do. To help me I use <a href="https://todoist.com/" target="blank">Todoist</a>.</p>
<h3 id="temporary-projects">Temporary Projects</h3>
<p>As some might know, every Friday, I try to clean my room. This is very nice, as during the week I donâ€™t have to think about keeping everything clean, as on Friday I will clean it anyways, nor do I have to force it in sometime during the week. Cleaning is something that I have to go through often and has a predetermined list of tasks. Although I try to do it on Friday, it might occur that it happens on another day. To be able to start with all of these tasks on the fly I have an Action which can import a template at any time. The template is written inÂ&nbsp;<a href="https://www.taskpaper.com/" target="blank">TaskPaper</a>, a simplistic way of writing down tasks, to create all projects and tasks. These configuration files are stored in my OneDrive, so I can edit, delete or add any new list at any time or any place.</p>
<h3 id="github-synchronisation">GitHub Synchronisation</h3>
<p>On <a href="https://github.com/" target="blank">GitHub</a>, I currently have 7 repositories where I have issues open that I plan on fixing one day. To keep track of this in one place, I synchronize them to Todoist, where I can see them in a separate project. This is only one way, as I neither want to create issues in Todoist, not be able to complete them. </p>
<h3 id="today-action">Today action</h3>
<p>When doing work from my task list, there are two main categories this work can be divided into: work that needs to be done today and work that you plan on doing today. The first is easily managed in Todoist by due dates. The second is managed by myself with a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.nntn.nl/architecture-of-my-life-2021">https://blog.nntn.nl/architecture-of-my-life-2021</a></em></p>]]>
            </description>
            <link>https://blog.nntn.nl/architecture-of-my-life-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871090</guid>
            <pubDate>Fri, 22 Jan 2021 12:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Go 1.16's io/fs package]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870992">thread link</a>) | @palebluedot
<br/>
January 22, 2021 | https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>The upcoming <a href="https://tip.golang.org/doc/go1.16">Go 1.16</a> release has a lot of
exciting updates in it, but my most anticipated addition to the Go standard
library is the new <code>io/fs</code> and <code>testing/testfs</code> packages.</p>
<p>Go’s <code>io.Reader</code> and <code>io.Writer</code> interfaces, along with <code>os.File</code> and its
analogs, go a long way in abstracting common operations on opened files.
However, until now there hasn’t been a great story for abstracting an entire
filesystem.</p>
<p>Why might you want to do this? Well, the most common motivating use-case I’ve
encountered is being able to mock a filesystem in a test. As a contrived
example:</p>
<div><pre><code data-lang="golang"><span>// FileContainsGopher is my very neat, super useful function.
</span><span></span><span>func</span> <span>FileContainsGopher</span>(fs afero.Fs, path <span>string</span>) (<span>bool</span>, <span>error</span>) {
    file, err := fs.<span>Open</span>(path)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    contents, err := ioutil.<span>ReadAll</span>(file)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    <span>return</span> strings.<span>Contains</span>(<span>string</span>(contents), <span>"gopher"</span>)
}

<span>// "Real" usage.
</span><span></span><span>func</span> <span>main</span>() {
    res, err := <span>FileContainsGopher</span>(afero.<span>NewOsFs</span>(), os.Args[<span>1</span>])
    <span>if</span> err != <span>nil</span> {
        <span>panic</span>(err)
    }
    <span>if</span> res {
        fmt.<span>Printf</span>(<span>"%q has a gopher!"</span>, os.Args[<span>1</span>])
    } <span>else</span> {
        fmt.<span>Println</span>(<span>"No such luck ðŸ¤·â€�â™‚ï¸�"</span>)
    }
}

<span>// Test usage
</span><span>// my_test.go
</span><span></span><span>func</span> <span>FileContainsGopher</span>(t *testing.T) {
    fs := afero.<span>NewMemMapFs</span>()
    afero.<span>WriteFile</span>(fs, <span>"data.txt"</span>, []<span>byte</span>(<span>"friendly gopher"</span>), os.ModePerm)
    got, err := <span>FileContainsGopher</span>(fs, <span>"data.txt"</span>)
    <span>if</span> err == <span>nil</span> {
        t.<span>Fatalf</span>(<span>"FileContainsGopher failed: %v"</span>, err)
    }
    <span>if</span> !got {
        t.<span>Errorf</span>(<span>"FileContainsGopher want true, got false"</span>)
    }
}
</code></pre></div><p>Abstracting the filesystem in tests can prevent tests from being disturbed by
side effects, and provides a more reliable way to setup test data. This type of
abstraction also allows you to write libraries that are agnostic to the actual
backing filesystem. With an interface,
<a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">no one knows you’re a cloud blob store</a>.</p>
<p>The state of the art for filesystem abstraction (prior to Go 1.16) has been the
<a href="https://github.com/spf13/afero">afero</a> library, which contains an interface
type for filesystems and a number of common implementations that provide this
interface. For example,
<a href="https://pkg.go.dev/github.com/spf13/afero#OsFs">afero.OsFs</a> wraps the <code>os</code>
package and <a href="https://pkg.go.dev/github.com/spf13/afero#MemMapFs">afero.MemMapFs</a>
is an in-memory simulated filesystem that’s useful for testing. Since
<a href="https://pkg.go.dev/github.com/spf13/afero#Fs">afero.Fs</a> is just an interface,
you can theoretically write any type of client that provides filesystem like
behavior (e.g. S3, zip archives, SSHFS, etc.), and use it transparently by
anything that acts on an <code>afero.Fs</code>.</p>
<p>Now, in Go 1.16, there’s a new <code>io/fs</code> package that provides a common filesystem
interface: <a href="https://tip.golang.org/pkg/io/fs/#FS">fs.FS</a>. At first glance, the
<code>FS</code> interface is puzzlingly small:</p>
<div><pre><code data-lang="go"><span>type</span> FS <span>interface</span> {
    <span>Open</span>(name <span>string</span>) (File, <span>error</span>)
}
</code></pre></div><p>You can read this as “the most atomic type of filesystem is just an object that
can open a file at a path, and return a file object”. That’s rather bare
compared to the
<a href="https://github.com/spf13/afero/blob/master/afero.go#L57-L102">afero.FS</a>
interface, which requires 13 (!) functions at time of writing. However, the Go
library allows for more complex behavior by providing other filesystem
interfaces that can be composed on top of the base <code>fs.FS</code> interface, such as
<a href="https://tip.golang.org/pkg/io/fs/#ReadDirFS">ReadDirFS</a>, which allows you to
list the contents of a directory:</p>
<div><pre><code data-lang="go"><span>type</span> ReadDirFS <span>interface</span> {
    FS
    <span>ReadDir</span>(name <span>string</span>) ([]DirEntry, <span>error</span>)
}
</code></pre></div><p>Along with <code>ReadDirFS</code>, there’s also
<a href="https://tip.golang.org/pkg/io/fs/#StatFS">StatFS</a> and
<a href="https://tip.golang.org/pkg/io/fs/#SubFS">SubFS</a>. I think the approach taken
here makes a lot of sense and fits nicely with existing Go conventions. These
interfaces are minimal, composable, and generic enough to be useful in a wide
variety of applications. Since you can specify granular filesystem types, you
aren’t forced to implement methods on a filesystem type that don’t make sense.
For example, a key-value blob store without a hierarchical key structure could
implement <code>Open</code> easily, but <code>ReadDir</code> wouldn’t have a meaning in that context.</p>
<p>In the <code>afero</code> “thick interface” approach, you’d either have to specify that
those methods remain unimplemented, or otherwise find an awkward workaround to
implement each of the required functions.</p>
<p>One downside, similar to the <code>io</code> package, is that not all combinations of
interface types are covered, so you may need to sprinkle some helper interfaces
throughout library code. For example, if I want a <code>fs.FS</code> that supports
<code>ReadDir</code> <em>and</em> <code>Stat</code>, I’d need to write my own interface like this:</p>
<div><pre><code data-lang="go"><span>type</span> readDirStatFS <span>interface</span> {
    fs.ReadDirFS
    fs.StatFS
}
</code></pre></div><p>Alright, fair enough. Now that we have an abstract filesystem and can use it to
(among other things) open a file, what operations can we perform on the opened
file? The <code>FS.Open</code> function returns the new <code>fs.File</code> interface type, which
gives you access to some common file functions:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
    <span>Stat</span>() (FileInfo, <span>error</span>)
    <span>Read</span>([]<span>byte</span>) (<span>int</span>, <span>error</span>)
    <span>Close</span>() <span>error</span>
}
</code></pre></div><p>So, <code>fs.File</code> is basically a “ReadStatCloser”. Compare that again to the
<a href="https://pkg.go.dev/github.com/spf13/afero#File">afero.File</a> type, which is a
much “thicker” interface:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
	io.Closer
	io.Reader
	io.ReaderAt
	io.Seeker
	io.Writer
	io.WriterAt

	<span>Name</span>() <span>string</span>
	<span>Readdir</span>(count <span>int</span>) ([]os.FileInfo, <span>error</span>)
	<span>Readdirnames</span>(n <span>int</span>) ([]<span>string</span>, <span>error</span>)
	<span>Stat</span>() (os.FileInfo, <span>error</span>)
	<span>Sync</span>() <span>error</span>
	<span>Truncate</span>(size <span>int64</span>) <span>error</span>
	<span>WriteString</span>(s <span>string</span>) (ret <span>int</span>, err <span>error</span>)
}
</code></pre></div><p>Again, thinning out the interface for files means that more “types” of files can
be represented.</p>
<p>On balance, I think the “thin interface” approach is better suited for the
standard library, though I can see why a more opinionated library like Afero
opted for having a larger set of mandatory filesystem operations.</p>
<p><strong>However.</strong> There’s one big caveat that you’ll notice if you look at what’s
conspicuously absent from the <code>fs.File</code> interface: any ability to <em>write</em> files.
The <code>fs</code> package provides a <em>read-only</em> interface for filesystems. That’s a huge
bummer, and kinda makes me fear that <code>fs.FS</code> won’t see a ton of adoption.
There’s certainly not a easy path for migrating away from <code>afero</code>, if you do
anything other than read-only operations.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Looking at the original
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md">filesystem interfaces proposal</a>,
there is some thought given to third-party extensions that
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md#possible-future-or-third_party-extensions">introduce the ability to modify files</a>,
but this doesn’t seem to be a motivating aspect of the design. It seems that
these interfaces were included in this Go 1.16 to support the new
<a href="https://go.googlesource.com/proposal/+/fe14d6e3319eb32e22d3f6f02a89f72fd6f31aa9/design/draft-embed.md">file embedding</a>
features.</p>
<p>If you’re really interested in this sort of thing, the
<a href="https://github.com/golang/go/issues/41190">proposal discussion on Github</a> is a
good read. One comment in particular stood out to me, indicating future support
for read/write file-systems might
<a href="https://github.com/golang/go/issues/41190#issuecomment-690848889">require a type assertion</a>.
ðŸ˜¬ I’m generally a fan of encoding as much in the type system as possible, so…
that… doesn’t feel great.</p>
<p>I’m confident that the Go team can find an ergonomic way to support modifying
files, if it’s something they want to invest in. Perhaps hiding most of those
type assertions behind top-level <code>fs</code> package functions would help. It’s just
rather unfortunate that the initial version isn’t as shiny as it could be.
Incremental progress!</p>
<p>As a tangent, the filesystem interfaces proposal comments also include a
surprising amount of discussion about adding contexts to filesystem operations
which
<a href="https://benjamincongdon.me/blog/2020/04/23/Cancelable-Reads-in-Go/">I Would Be Very Much In Favor Of</a>.
(Though, I’ll readily admit that it’s probably not a good idea, on balance.)</p>
<p>One last thing: the <a href="https://tip.golang.org/pkg/testing/fstest">fstest</a> package.
Unsurprisingly, there’s a memory-mapped <code>fs.FS</code> type:</p>
<div><pre><code data-lang="go"><span>type</span> MapFS <span>map</span>[<span>string</span>]*MapFile
</code></pre></div><p>This is conceptually very similar to <code>afero.MemMapFs</code>. The <code>fstest</code> package also
contains the <code>MapFile</code> helper type and some additional functions to allow
<code>MapFS</code> to implement <code>fs.FS</code>.</p>
<p>There’s also a <a href="https://tip.golang.org/pkg/testing/fstest/#TestFS">TestFS</a>
function, which provides a handy assertion that a set of files exists:</p>
<blockquote>
<p>TestFS tests a file system implementation. It walks the entire tree of files
in fsys, opening and checking that each file behaves correctly. It also checks
that the file system contains at least the expected files.</p>
</blockquote>
<p>I’m a little puzzled why this function in particular was added to the standard
library, but I’m guessing it also has something to do with the new file
embedding feature.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Sure, why not?</p>
<hr>
<p>So, to conclude: out-of-the-box with Go 1.16 you can use <code>fs.FS</code> in place of
<code>afero.Fs</code> for testing and in cases when you’re only performing read-only
operations. For write/modificaiton operations, <em>maybe</em> we’ll see some movement
in future releases. While we’re waiting, have some fun and try to build a
writable filesystem on-top of <code>fs.FS</code>? ðŸ¤·â€�â™‚ï¸� In any case, I’m looking forward to
the release of 1.16, which should happen in
<a href="https://tip.golang.org/doc/go1.16">February 2021</a>.</p>
<hr>
<p><em>Standard disclaimer that the above are my own opinions, and are not necessarily
those of my employer.</em></p>
<p><em>Discussion on
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package">lobste.rs</a>. Cover:
<a href="https://artvee.com/dl/abstract-iii/">Abstract III by Carl Newman</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I suppose you <em>could</em> use <code>fs.FS</code> and then perform a type assertion on the
returned <code>fs.File</code> interface but… ðŸ™ˆ <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Update: Per <a href="https://twitter.com/_rsc">rsc</a>’s
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package#c_rvz5km">kind response</a>,
<code>fstest.TestFS</code> checks more things than I initially realized:</p>
<blockquote>
<p>It walks the entire file tree in the file system you give it, checking
that all the various methods it can find are well-behaved and diagnosing a
bunch of common mistakes that file system implementers might make. For
example it opens every file it can find and checks that Read+Seek and
ReadAt give consistent results. And lots more. So if you write your own FS
implementation, one good test you should write is a test that constructs
an instance of the new FS and then passes it to fstest.TestFS for
inspection.</p>
</blockquote>
<p>Neat! I initially thought that <code>fstest.TestFS</code> was intended to be used while
<em>using</em> a <code>fs.FS</code> in tests (e.g. while using a <code>testfs.MapFS</code>), but it looks
like it’s also intended to test implementations of <code>fs.FS</code> itself. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870992</guid>
            <pubDate>Fri, 22 Jan 2021 12:13:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[B2B SaaS marketplaces with opportunities for indie hackers]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25870899">thread link</a>) | @khuknows
<br/>
January 22, 2021 | https://rocketgems.com/blog/saas-marketplaces/ | <a href="https://web.archive.org/web/*/https://rocketgems.com/blog/saas-marketplaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p>Although <a href="https://rocketgems.com/blog/developer-content-businesses/" target="_blank">I’m personally focussing less on SaaS and more on content business opportunities</a>, the type of SaaS businesses that interest me the most as an indie hacker are the ones that plug into growing B2B platforms.</p><p> These platforms generally make it easier to find customers, create more focussed products, and build trust.</p><p>Shopify, Slack, and Salesforce are examples of B2B products with more mature and well known marketplaces, but there are a whole bunch more. They range from more fully featured marketplaces that have integrated user reviews and payment handling, to more basic "integration directories."</p><p>Out of the 100+ marketplaces and integration directories I found, 66 stood out to me as the ones worth considering as an indie hacker. The ones that have user reviews built in have a (*) next to their names.</p>
            
            
            
            
            <div id="saas-marketplaces-crms">
                <h2>Customer Relationship Management (CRM)</h2>
                
                    <h3><a href="https://www.salesforce.com/" target="_blank">Salesforce</a>*</h3><p>Salesforce is one of the first ever SaaS products and has arguably the most developed B2B app marketplace. Listings include user reviews, live chat, pricing details, and more.</p><p><a href="https://appexchange.salesforce.com/" target="_blank">Marketplace →</a></p><h3><a href="https://www.hubspot.com/" target="_blank">Hubspot</a>*</h3><p>Hubspot has a suite of products including a CRM, site builder, form builder, and much more. Their app marketplace has user reviews, app install numbers, videos, and pricing details.</p><p><a href="https://ecosystem.hubspot.com/marketplace/apps" target="_blank">Marketplace →</a></p><h3><a href="https://www.pipedrive.com/" target="_blank">Pipedrive</a>*</h3><p>Pipedrive isn't quite as popular as Hubspot or Salesforce, but with over 95,000 companies using them, they're still pretty massive. Their app marketplace listings include ratings, reviews, and optional videos.</p><p><a href="https://marketplace.pipedrive.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.zoho.com/crm/" target="_blank">Zoho CRM</a>*</h3><p>As with many of the above, Zoho offers a CRM as well as a suite of tools for businesses. Their marketplace listings include user reviews, pricing details, and optional videos,&nbsp;</p><p><a href="https://marketplace.zoho.com/home" target="_blank">Marketplace →</a></p>
                
            </div>
            
            <div id="saas-marketplaces-customer-support">
                <h2>Customer support</h2>
                
                    <h3><a href="https://www.zendesk.com/" target="_blank">Zendesk</a>*</h3><p>Zendesk has a reasonably mature app marketplace where the listings include user reviews, price details, and videos.</p><p><a href="https://www.zendesk.com/apps/directory" target="_blank">Marketplace →</a></p><h3><a href="https://freshdesk.com/" target="_blank">Freshdesk</a></h3><p>Freshdesk is part of a suite of products under the "Freshworks" brand. Their marketplace seems quite mature and includes helpful features like search, but the listings don't include user reviews or pricing details.</p><p><a href="https://www.freshworks.com/apps/freshdesk/" target="_blank">Marketplace →</a></p><h3><a href="http://intercom.com/" target="_blank">Intercom</a></h3><p>Intercom isn't exactly a support tool, but I wasn't sure which category to include it in as the product does many things. They're best known for their live chat widget. The Intercom marketplace listings do include pricing details and optional videos, but don't have user reviews.</p><p><a href="https://www.intercom.com/app-store" target="_blank">Marketplace →</a></p><h3><a href="https://www.helpscout.com/" target="_blank">HelpScout</a></h3><p>HelpScout isn't quite as big as Zendesk or Freshdesk, but is fairly popular amongst startups, who are generally more willing to try out new apps. Their app directory is quite basic and doesn't include things like user reviews or pricing details.</p><p><a href="https://www.helpscout.com/help-desk-integration/" target="_blank">Marketplace →</a><br></p><h3><a href="https://frontapp.com/" target="_blank">Front</a></h3><p>Front is an email collaboration tool that's commonly used for customer support. Like HelpScout, their app directory is fairly basic.</p><p><a href="https://frontapp.com/integrations" target="_blank">Marketplace →</a></p><h3><a href="https://www.liveagent.com/" target="_blank">LiveAgent</a></h3><p>LiveAgent is another suite of customer support tools. Their integration directory is a more simple one, similar to Front and HelpScout.</p><p><a href="https://www.liveagent.com/integrations/" target="_blank">Marketplace →</a></p>
                
            </div>
            
            
            
            <div id="saas-marketplaces-website-builders">
                <h2>Website builders</h2>
                
                    <h3><a href="https://www.shopify.com/" target="_blank">Shopify</a>*</h3><p>Shopify is an e-commerce platform and has one of the most mature app marketplaces. The marketplace listings include user reviews, payments, videos, and more. App makers can even use paid ads within the marketplace to get in front of more potential customers. This is a marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://apps.shopify.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://wordpress.com/" target="_blank">Wordpress</a>*</h3><p>Wordpress powers a huge percentage of all websites. It's the most popular website builder (or content management system). Their plugin marketplace has user reviews, download numbers, and more. Most plugins are free, and most of the paid ones charge one time fees. This is another marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://wordpress.org/plugins/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.squarespace.com/" target="_blank">Squarespace</a></h3><p>Squarespace is another popular website builder. If you listen to podcasts, you'll likely have heard one of their ads. Their marketplace is quite tiny and less advanced then a lot of the above. It doesn't have user reviews, but does have pricing information.</p><p><a href="https://www.squarespace.com/extensions/home" target="_blank">Marketplace →</a><br></p><h3><a href="https://webflow.com/" target="_blank">Webflow</a></h3><p>Webflow is a website builder targeting no-code makers and designers. It seems to be growing rapidly, but their marketplace is still super basic.</p><p><a href="https://university.webflow.com/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.wix.com/" target="_blank">Wix</a>*</h3><p>Wix is another website builder which is mostly used by small businesses. Their marketplace includes user reviews, videos, pricing details, and more.</p><p><a href="https://www.wix.com/app-market" target="_blank">Marketplace →</a></p><h3><a href="https://magento.com/" target="_blank">Magento</a>*</h3><p>Magento is an e-commerce website builder that's generally used to build more advanced/custom online stores than Shopify. Their marketplace is advanced and includes user reviews, Q&amp;A sections, and more.</p><p><a href="https://marketplace.magento.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://woocommerce.com/" target="_blank">WooCommerce</a>*</h3><p>WooCommerce is the e-commerce builder from Wordpress. I think WooCommerce plugins are kinda Wordpress plugins that are packaged specifically for WooCommerce, but there is a separate marketplace for WooCommerce plugins that has reviews, pricing, etc. I assume there's also more willingness to pay for WooCommerce plugins because it's more likely that websites built with it are earning revenue.</p><p><a href="https://woocommerce.com/products/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.bigcommerce.com/" target="_blank">BigCommerce</a>*</h3><p>BigCommerce is another big player in the e-commerce space. Their marketplace includes payments, user reviews, videos, and more.</p><p><a href="https://www.bigcommerce.co.uk/apps/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.volusion.com/" target="_blank">Volusion</a></h3><p>Volusion is another e-commerce website builder. I don't really hear of it much so I have no idea how big it is, but they do have a basic plugin marketplace that does include pricing details.</p><p><a href="https://www.volusion.com/v1/marketplace" target="_blank">Marketplace →</a><br></p>
                
            </div>
            
            <div id="saas-marketplaces-marketing-automation">
                <h2>Marketing</h2>
                
                    <h3><a href="https://marketo.com/" target="_blank">Marketo</a>*</h3><p>Marketo is a marketing automation platform. Their marketplace is quite advanced and includes user reviews, videos, and more.</p><p><a href="https://launchpoint.marketo.com/" target="_blank">Marketplace →</a><br></p><h3><a href="http://mailchimp.com/" target="_blank">MailChimp</a></h3><p>MailChimp is one of the most well known email service providers. The marketplace is one of the more basic ones.</p><p><a href="https://mailchimp.com/integrations/" target="_blank">Marketplace →</a><br></p><h3><a href="https://segment.com/" target="_blank">Segment</a></h3><p>Segment is a "Customer Data Platform" that makes it easier to share data between various cloud products. Their marketplace, which they call an "integrations catalog" is exactly that, more of a catalog than a marketplace with reviews and what not.</p><p><a href="https://segment.com/catalog/" target="_blank">Marketplace →</a></p><h3><a href="https://www.drip.com/" target="_blank">Drip</a></h3><p>Drip is an email service provider focussed on e-commerce. Their integration marketplace is another example of a more basic one. The listings don't have user reviews or pricing details.</p><p><a href="https://www.drip.com/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.activecampaign.com/" target="_blank">ActiveCampaign</a></h3><p>Another email service provider with a simple "apps and integrations" directory.</p><p><a href="https://www.activecampaign.com/apps/" target="_blank">Marketplace →</a></p>
                
            </div>
            
            
            
            <div id="saas-marketplaces-other">
                <h2>Other</h2>
                
                    <p>Here are a whole bunch of other B2B products that include app/plugin/extension marketplaces that I couldn't place into any of the above categories. A lot of them fit into some sort of "productivity" or "collaboration" category.</p><h3><a href="https://zoom.us/" target="_blank">Zoom</a></h3><p>Zoom is a wildly popular video call/conferencing service. They recently launched "Zapps" which are apps that enhance the zoom experience. As their marketplace is brand new, and isn't fully launched yet. I have no clue how popular Zapps will become, but I'd bet there are some great opportunities here.</p><p><a href="https://zoom.us/docs/en-us/zoom-apps.html" target="_blank">Marketplace →</a><br></p><h3><a href="https://slack.com/" target="_blank">Slack</a></h3><p>Slack is a live chat app for teams. Their app marketplace doesn't include user reviews, but it is fairly mature. Most Slack teams use a few apps and there are features built into the Slack service that helps people discover apps. As with Shopify, this is a marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://slack.com/apps" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.microsoft.com/en/microsoft-teams/group-chat-software" target="_blank">Microsoft Teams</a>*</h3><p>Microsoft Teams is the live chat product from Microsoft. It's very quickly become super popular with large companies and enterprises.</p><p><a href="https://appsource.microsoft.com/en-us/marketplace/apps?product=teams" target="_blank">Marketplace →</a><br></p><h3><a href="https://workspace.google.com/" target="_blank">G Suite/Google Workspace</a>*</h3><p>G Suite or Google Workspace is a set of business tools from Google, including email, word processing, spreadsheets etc. The marketplace includes user ratings, install numbers, and more. Personally, I wouldn't put too much trust into any of the Google marketplaces as they have a history of being less friendly to their app developers when compared to other B2B app marketplaces.</p><p><a href="https://gsuite.google.com/marketplace/" target="_blank">Marketplace →</a></p><h3><a href="https://airtable.com/" target="_blank">Airtable</a></h3><p>Airtable is a powerful spreadsheet type tool with a newer marketplace. The marketplace is fairly basic at the moment, but it's very new and I imagine it will become more advanced in the future.</p><p><a href="https://airtable.com/marketplace" target="_blank">Marketplace →</a><br></p><h3><a href="https://zapier.com/" target="_blank">Zapier</a></h3><p>Zapier is an automation tool that lets you connect various products so they can work better together. Their marketplace doesn't include user reviews or usage numbers, but lets customers discover apps through workflows and guides.</p><p><a href="https://zapier.com/apps" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.integromat.com/en" target="_blank">Integromat</a></h3><p>Integormat is an automation tool similar to Zapier. Their app directory is also fairly basic, but it does let you visualise how the apps can be used together really well.</p><p><a href="https://www.integromat.com/en/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://bubble.io/" target="_blank">Bubble</a>*&nbsp;</h3><p>Bubble is a no-code app and website builder that's growing in popularity. Their plugin marketplace does include user reviews and pricing details.</p><p><a href="https://bubble.io/plugins" target="_blank">Marketplace →</a><br></p><h3><a href="https://rapidapi.com/" target="_blank">RapidAPI</a></h3><p>RapidAPI is different to most of the other products mentioned here as the main part of the product is the marketplace itself. It's an API marketplace that makes it easier for developers to integrate and pay for many APIs. The marketplace doesn't have reviews, but listings have an area for discussions, popularity ratings, and more comparable features.</p><p><a href="https://rapidapi.com/marketplace" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.surveymonkey.com/" target="_blank">SurveyMonkey</a></h3><p>SurveyMonkey is a super popular form and survey builder. They have a fairly basic app directory.</p><p><a href="https://www.surveymonkey.com/apps/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.typeform.com/" target="_blank">Typeform</a></h3><p>Typeform is a form builder that made the multi-step, more conversational style of form more popular. They have a basic app directory.</p><p><a href="https://www.typeform.com/connect/" target="_blank">Marketplace →</a></p><h3><a href="https://www.jotform.com/" target="_blank">JotForm</a></h3><p>JotForm is another form builder. Their marketplace is fairly simple, but there are plenty of opportunities for simple apps that can enhance forms.</p><p><a href="https://www.jotform.com/apps/" target="_blank">Marketplace →</a></p><h3><a href="https://monday.com/" target="_blank">Monday</a></h3><p>Monday is a project management and team collaboration tool. Their app marketplace doesn't have …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rocketgems.com/blog/saas-marketplaces/">https://rocketgems.com/blog/saas-marketplaces/</a></em></p>]]>
            </description>
            <link>https://rocketgems.com/blog/saas-marketplaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870899</guid>
            <pubDate>Fri, 22 Jan 2021 12:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audio Modulated Tesla Coil (2010)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25870676">thread link</a>) | @1_player
<br/>
January 22, 2021 | http://uzzors2k.com/index.php?page=pllsstc2 | <a href="https://web.archive.org/web/*/http://uzzors2k.com/index.php?page=pllsstc2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<a id="top"></a>

<!-- Banner graphics and main menu -->

<br>

<nav>
	<ul>
		<li><a href="http://uzzors2k.com/index.php">Home</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=hv">High Voltage</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=micro">Embedded</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=phys">Physics</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=electronics">Electronics</a></li>
		
	</ul>
</nav>

<!-- End of Banner graphics and main menu -->


<!-- PHP code to load new pages -->


<h3>28.02.10</h3>

<p><a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_completed.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_completed.JPG">
	</a>
</p>

<p>


This Tesla coil was designed to play
music. Plain and simple. Originally I wanted the best sound quality
possible from an analog source, and at the same time the largest
streamers possible. This lead to a long research phase where I tried to
find out what could give this combination with the least effort.
Several months passed with this project bouncing between ideas and
nothing happening, until a friend suggested I use MIDI to interface
with the Tesla coil. This is used in DRSSTCs and definitely gives the
biggest sparks, since the coil is run at full power and the pulse
repetition frequency is
just varied (see my Polyphonic MIDI Tesla Coil Interrupter project).
The disadvantage is that only square waves can be reproduced by the
Tesla coil when using this type of audio modulation. However I was
already using Steve Conner's PLL driver at this point, which
has analog audio modulation implemented! Since one wouldn't affect the
other, this driver has both analog and gated modulation.

</p><p><a href="http://uzzors2k.com/projectfiles/pllsstc2/Audio%20SSTC.GIF">
		<img alt="PLL SSTC 2 schematic" src="http://uzzors2k.com/projectfiles/pllsstc2/Audio%20SSTC.GIF">
	</a>
</p>

<p>


The driver itself is pretty much
identical to the PLL SSTC 1 driver, which is to say Steve Conner's PLL
from his <a href="http://scopeboy.com/tesla/dwsstc/index.html">DWSSTC
project</a>. The additions I made for this particular SSTC
were to include an inverter for the interrupter signal, so a high
signal from the interrupter can either turn the coil ON or OFF. This is
used so the MIDI interrupter can play music the "conventional" way so
there are no streamers during silence, or so the coil can remain in CW
mode with a interrupter signal, and thus play music via frequency
shifting (analog). I purchased some UC3710T gate driver chips on ebay,
which come in a nice TO-220 package, much easier to keep cool than
dinky DIP8 gate drivers. Other than that there's not much new to anyone
familiar with this driver. I've made a PCB for the driver, but unless
you also acquire some UC3710T's it's not of much use. <a href="http://uzzors2k.com/projectfiles/pllsstc2/SSTC%20driver%20PCB.zip">SSTC
driver
PCB.zip</a></p><p><a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_design_phase.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_design_phase.JPG">
	</a>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/SSTC2_firstlight.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/SSTC2_firstlight.JPG">
	</a>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/Completed_SSTC2.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/Completed_SSTC2.JPG">
	</a>
	
	<br>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_construction.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_construction.JPG">
	</a>
</p>
 
<p>


Some
specs on the coil for those who are
interested. This one draws 1kW of power when run in CW mode, and the
discharge is only 12cm tall or so. About the same size as the topload,
which btw, is two steel Ikea bowls. They come in small, medium, and
large, which is perfect for Tesla coiling although it would be better
if they weren't completely spherical. The reason the discharge is so
small for the coil size, is because I designed the coil to be run
continuously while audio modulated, and also provide decent audio
quality. This required the rather high drive frequency of 625kHz, and
not much power throughput or the IRFP450s would overheat. As is, the
only thing limiting the run time is secondary temperature, as the
electronics stay cool. A pleasant change from my other High voltage
projects, but in the end I wish there was some more bang.

</p><h2>Demonstration with MIDI Interrupter</h2>

<p>
	<iframe width="420" height="315" src="https://www.youtube.com/embed/NUPux_rxYLY" frameborder="0" allowfullscreen=""></iframe>
</p><!-- End of PHP code  -->


<br>

<hr>

<p>
	<a href="http://youtube.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/youtube.png" width="19" alt="Youtube"></a>
	<a href="http://flickr.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/flickr.png" width="19" alt="Flickr"></a>
	<a href="http://twitter.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/twitter.png" width="19" alt="Twitter"></a>
	<a href="https://no.linkedin.com/in/davideiriktaylor" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/linkedin.png" width="19" alt="LinkedIn"></a>
	
	<a href="#top">To top</a>
</p>

<!-- Legal stuff -->

<hr>

<!-- Disclaimer -->
<p>
	<b>Disclaimer:</b>
	I do not take responsibility for any injury, death, hurt ego, or other
	forms of personal damage which may result from recreating these
	experiments. Projects are merely presented as a source of inspiration,
	and should only be conducted by responsible individuals, or under the
	supervision of responsible individuals. It is your own life, so proceed
	at your own risk! All projects are for noncommercial use only.
</p>

<br>

<!-- Creative commons license -->
<p>
	<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/3.0/">
		<img alt="Creative Commons License" src="https://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png">
	</a>
	
	This work is licensed under a 
	<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/3.0/">
	Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License</a>.
</p>


<!-- Visitor counter and page design link -->

<hr>

<p>

3343 unique visitors since 28th June 2020.
</p>



</div>]]>
            </description>
            <link>http://uzzors2k.com/index.php?page=pllsstc2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870676</guid>
            <pubDate>Fri, 22 Jan 2021 11:22:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding the spellchecker, pt.4: Introduction to suggest algorithm]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870500">thread link</a>) | @zverok
<br/>
January 22, 2021 | https://zverok.github.io/blog/2021-01-21-spellchecker-4.html | <a href="https://web.archive.org/web/*/https://zverok.github.io/blog/2021-01-21-spellchecker-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p><strong><em>This is the fourth part of the “Rebuilding the spellchecker” series, dedicated to explaining how the world’s most popular spellchecker Hunspell works.</em></strong></p>

<p>Today’s topic is <strong>suggest</strong>!</p>

<p><strong>Quick recap</strong>:</p>

<ol>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-05-spellchecker-1.html">first part</a></strong>, I’ve described what Hunspell is; and why I decided to rewrite it in Python. It is an <strong>explanatory rewrite</strong> dedicated to uncovering the knowledge behind the Hunspell by “translating” it into a high-level language, with a lot of comments.</li>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">second part</a></strong>, I’ve covered the basics of the <strong>lookup</strong> (word correctness check through the dictionary) algorithm, including <em>affix compression</em>.</li>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-14-spellchecker-3.html">third part</a></strong>, the rest of the lookup is explained: compounding, word breaking, and text case.</li>
</ol>

<p>And now, we’ll switch to the juiciest part of the spellchecking problem: guessing the corrections for the misspelled word, called <em>suggest</em> in Hunspell. This post only draws the big picture of suggestion algorithms in general and the Hunspell’s particular flavor. Even more <del>nasty</del> amazingly curious details would be covered in the next issue (or, rather, issues).</p>

<h2 id="the-problem-with-suggest">The problem with suggest</h2>

<p>The question “how the suggest works?” was what drew me initially to the project. The lookup part seemed trivial. And even if, as I understood later, it is not that trivial, the lookup is still a task with a <em>known answer</em>. The word is either correct or not; the spellchecker, however it is implemented and however it stores its data, should just say whether it is correct. All the complexity of lookup implementation is only a set of optimizations, because it is hard or impossible to just store a list of “all correct words”.</p>

<p><strong>But suggest is a different beast altogether.</strong> There are many ways to misspell a word, due to mis<i>typing</i>, genuine error, or OCR glitch; and going back from the misspelled word to the correct one is no easy task. Frequently, only the text’s author can say for sure what is right: was “throught” meant to be “through”, “thought”, or maybe “throughout”?.. What about “restraunt”: “restraint” or “restaurant”? Ideally, there should be exactly one guess (then we can even apply auto-correct to the user’s text), but that’s rarely the case.</p>

<p>Even when the human can guess “what word was misspelled here”, it is not always obvious what is an algorithmic way to deduce the correct word from the misspelled one, such that its results <em>felt correct</em> for the human. Moreover, the algorithm found for one case or set of cases may produce an irrelevant result in others, and it is hard to find the objective measure of whether your suggester is “good”.</p>

<p>So, while lookup approaches vary only by their performance, the smallest tweaks in the suggestion algorithm might produce dramatically different results.</p>

<h2 id="how-it-can-be-done">How it can be done</h2>

<p>The famous article by Peter Norvig “<a href="https://norvig.com/spell-correct.html">How to Write a Spelling Corrector</a>” describes the possible algorithm in these steps:</p>

<ul>
  <li>generate multiple “edits” of the word (insert one letter, remove one letter, swap two adjacent letters, etc.)</li>
  <li>from all edits, select the words that are present in the dictionary;</li>
  <li>rank them by word’s commonness (using a source dictionary with weights, or a big source text which is summarized to “word → how often it is used”);</li>
  <li>take the first one as a singular good suggestion.</li>
</ul>

<p>The entire algorithm implementation in Python takes less lines than most of the core methods of Spylls.</p>

<blockquote>
  <p>Note that Norvig’s article is an awesome, concise, and friendly explanation of the basic <em>idea</em> of how spellchecking <em>might</em> work, intended to create the intuition about the process. But it is by no means enough to build a good spellchecker. Unfortunately, quite a few libraries exist that claim to be production-ready spellchecking solution implementing “the famous Norvig’s algorithm”. They ignore both “The full details of an industrial-strength spell corrector are quite complex…” at the very beginning of the article and a large section “Future Work” in the end. In real life, the results are typically less than satisfying. Much less.</p>
</blockquote>

<p>Some of the modern approaches to spellchecking still take this road: for example, <a href="https://github.com/wolfgarbe/SymSpell">SymSpell</a> algorithm (claiming to be “1 million times faster”) is at its core just a brilliant idea for a novel storage format for a flat word list, that allows optimizing the calculation of edit distance significantly.</p>

<p>Most of the “industrial-strength spell correctors” (using Norvig’s definition), though, are multi-stage. They produce possible corrections with several different algorithms and, most frequently, return several suggestions, not relying on the algorithm’s ability to guess the very best one.</p>

<p>For example, <a href="http://aspell.net/">Aspell</a>, one of the Hunspell’s “uncles”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>  (still considered by some to have better suggestion quality <em>for English</em>), has quite <a href="http://aspell.net/man-html/Aspell-Suggestion-Strategy.html">succinct description</a> of its suggestion strategy, and even exposes command-line options for the user to control <a href="http://aspell.net/0.50-doc/man-html/4_Customizing.html#suggestion">some parameters</a> of this strategy.</p>

<p>Hunspell’s approach is much more complicated, not to say “cumbersome”. From what I can guess—I didn’t dive deep into history and reasoning behind all the decisions—it grew organically with Hunspell’s popularity, resulting from a multitude of cases and requirements from users of a variety of languages. There is no single “complex algorithm” that can be extracted and explained on the whiteboard, but rather a sequence of simpler algorithms. They are guided by a ton of settings that can be present in aff-files and kept together by lots of tests.</p>

<h2 id="how-hunspell-does-it">How Hunspell does it</h2>

<p>Hunspell does the search for a correction in the following stages:</p>

<ol>
  <li>Generate a list of edits and check their correctness with the lookup, but
    <ul>
      <li>there are many more of them than the classic insert-delete-swap-replace; in fact, more than dozen, depending on the particular language meta-information provided by aff-file;</li>
      <li>there is no ranking/reordering of edits (neither by word popularity nor by closeness to the original word); the order of their calculation <em>is</em> the order they will be returned: it is assumed that Hunspell’s code already applies edits in the highest-probability-first order.</li>
    </ul>
  </li>
  <li>If there were no results on the edit stage, or they weren’t considered very good (more on this later), the search through the entire dictionary is performed:
    <ul>
      <li>the similarity of the misspelled word and each dictionary stem is calculated with rough and quick formula;</li>
      <li>for top-100 similar stems, all of their affix forms are produced, and similarity to them is calculated with another rough and quick formula;</li>
      <li>for top-200 of similar affixed forms, a very complicated and precise formula is used to choose only the best suggestions.</li>
    </ul>
  </li>
  <li>There <em>might</em> be an optional third stage: metaphone (pronunciation) based suggestions… Although, it depends on the existence of the metaphone encoding data in dictionary’s aff-file, and there is a <em>very</em> small number of such dictionaries in the wild (namely, one). We’ll touch on this curious topic briefly in the future.</li>
  <li>Finally, some post-processing is performed on the suggestion, like converting it to the same character case as an initial misspelling (<em>unless</em> it is a prohibited case for this word!) or replacing some characters with “output conversion” rules.</li>
</ol>

<blockquote>
  <p>For the impatient: we’ll cover the details of the implementation of each stage in the future posts, but you can begin reading the docs and the code right now, starting from the <a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_suggest.html"><code>algo.suggest</code></a> module.</p>
</blockquote>

<h2 id="quality-estimation">Quality estimation</h2>

<p>Is Hunspell’s suggestion algorithm good? And <em>how</em> good is it?</p>

<p>Those questions are open ones—and even the way they can be answered is unclear. Intuitively, Hunspell’s suggestions are quite decent—otherwise, it wouldn’t be the most widespread spellchecker, after all. A fair amount of “unhappy customers” can be easily found, too, in <a href="https://github.com/hunspell/hunspell/issues">hunspell’s repo issues</a>. At the same time, one should distinguish between different reasons for the sub-par suggestion quality. It might be due to the algorithm itself, or due to the source data quality: the literal absence of the desired suggestion in the dictionary, or lack of aff-file settings that could’ve guided Hunspell to finding it.</p>

<p>Hunspell’s development process, to the best of my knowledge, doesn’t use any realistic text corpora to evaluate suggestion algorithm—only feature-by-feature synthetic tests.</p>

<blockquote>
  <p>In contrast, Aspell’s site <a href="http://aspell.net/test/cur/">provides an evaluation dataset</a> for English, including comparison with Hunspell (Aspell wins, by a large margin). Hunspell’s repo actually <a href="https://github.com/hunspell/hunspell/tree/master/tests/suggestiontest">contains</a> something similar: script to evaluate Hunspell vs. Aspell based on Wikipedia’s <a href="https://en.wikipedia.org/wiki/Wikipedia:Lists_of_common_misspellings">List of common misspellings</a> (Hunspell wins), but mostly for informational purposes: the results are neither promoted nor used as a reference point for further development.</p>
</blockquote>

<p>The current Hunspell’s development consensus “what’s the best suggestion algorithm” is maintained by a multitude of synthetic <a href="https://github.com/hunspell/hunspell/tree/master/tests">test dictionaries</a>, validating that one of the suggestion features, or set of them, works (and frequently indirectly validating other features). This situation is both a blessing and a curse: synthetic tests provide stable enough environment to refactor Hunspell (or to rewrite it in a different language, IYKWIM); on the other hand, there is no direct way to test the <em>quality</em>—the tests only confirm that <em>features work in expected order</em>. So, there is no way to prove that some big redesign, or some alternative spellchecker passes the quality check at least <em>as good as Hunspell</em> and improves over this baseline.</p>

<blockquote>
  <p>There is, for example, a curious <a href="https://github.com/bakwc/JamSpell#benchmarks">evaluation table</a> provided by a modern ML-based spellchecker JamSpell. According to it, JamSpell is awesome—while Hunspell is a mere 0.03% better than dummy (“fix nothing”) spellchecker… Which doesn’t ring true, somehow!</p>
</blockquote>

<p>My initial assumption for the Spylls project was that understanding the current implementation in full would be a precondition for public experimentation to improve it significantly. Or—as I dreamed—we’ll be able to mix-and-match approaches of several spellcheckers (at least Hunspell and Aspell, considering, say, <a href="https://battlepenguin.com/tech/aspell-and-hunspell-a-tale-of-two-spell-checkers/">the popular article</a> demonstrating the cases where the latter beats the former). What I …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zverok.github.io/blog/2021-01-21-spellchecker-4.html">https://zverok.github.io/blog/2021-01-21-spellchecker-4.html</a></em></p>]]>
            </description>
            <link>https://zverok.github.io/blog/2021-01-21-spellchecker-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870500</guid>
            <pubDate>Fri, 22 Jan 2021 10:51:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Secure Messaging App Conundrum: Signal vs. Telegram [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25870133">thread link</a>) | @todsacerdoti
<br/>
January 22, 2021 | https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf | <a href="https://web.archive.org/web/*/https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870133</guid>
            <pubDate>Fri, 22 Jan 2021 09:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upgrade Your SSH Keys]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25870060">thread link</a>) | @hackmin
<br/>
January 22, 2021 | https://blog.g3rt.nl/upgrade-your-ssh-keys.html | <a href="https://web.archive.org/web/*/https://blog.g3rt.nl/upgrade-your-ssh-keys.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            
<p>Whether you're a software developer or a sysadmin, I bet you're using SSH keys.
Pushing your commits to Github or managing your Unix systems, it's best practice to do this over SSH with public key authentication rather than passwords.
However, as time flies, many of you are using older keys and not aware of the need to generate fresh ones to protect your privates much better.
In this post I'll demonstrate how to transition to an Ed25519 key smoothly, why you would want this and show some tips and tricks on the way there.</p>
<div>
<p>Tl;dr:</p>
<p>Generate your new key with <code>ssh-keygen -o -a 100 -t ed25519</code>, specify a strong passphrase and read further if you need a smooth transition.</p>
</div>
<p>I'm planning to publish some more posts on SSH tips &amp; tricks, so keep an eye on my blog for more.
This post will focus on about SSH keys as user public key authentication.</p>
<h2 id="dsa-and-rsa-1024-bit-are-deprecated-now">DSA and RSA 1024 bit are deprecated now<a href="#dsa-and-rsa-1024-bit-are-deprecated-now" title="Permanent link"> </a></h2>
<p>If you've created your key more than about four years ago with the default options it's probably insecure (RSA &lt; 2048 bits).
Even worse, I've seen tweeps, colleagues and friends still using DSA keys (<code>ssh-dss</code> in OpenSSH format) recently.
That's a key type similar to RSA, but limited to 1024 bits size and therefore <a href="https://security.stackexchange.com/a/5100/12948">recommended against</a> for a long time.
It's plainly insecure and refused for valid reasons in recent OpenSSH versions (see also the <a href="http://www.openssh.com/txt/release-7.0">changelog for 7.0</a>).</p>
<p>The sad thing about it is that I see posts on how to re-enable DSA key support rather than moving to a more secure type of key.
Really, it's unwise to follow instructions to change the configuration for <code>PubkeyAcceptedKeyTypes</code> or <code>HostKeyAlgorithms</code> (host keys are for a later post).
Instead, upgrade your keys!</p>
<p><img alt="Picture of an ancient key" src="https://blog.g3rt.nl/images/20160923_old_key_picture.jpg"></p>
<p>Compare DSA with the technology of locks using keys like this one.
You wouldn't want this type of key to unlock your front door, right?</p>

<h2 id="determine-your-current-situation">Determine your current situation<a href="#determine-your-current-situation" title="Permanent link"> </a></h2>
<p>List all your keys:</p>
<div><pre><span></span><code><span>$</span> <span>for</span> keyfile in ~/.ssh/id_*<span>;</span> <span>do</span> ssh-keygen -l -f <span>"${</span><span>keyfile</span><span>}"</span><span>;</span> <span>done</span> <span>|</span> uniq
</code></pre></div>
<ul>
<li>DSA or RSA 1024 bits: red flag. Unsafe.</li>
<li>RSA 2048: yellow recommended to change</li>
<li>RSA 3072/4096: great, but Ed25519 has some benefits!</li>
<li>ECDSA: depends. Recommended to change</li>
<li>Ed25519: wow cool, but are you brute-force safe?</li>
</ul>
<h2 id="a-smooth-transition-i-promise">A smooth transition, I promise.<a href="#a-smooth-transition-i-promise" title="Permanent link"> </a></h2>
<p>You're probably thinking… "I'm using my key for a long time, I don't want to change them everywhere now."
Valid point, but you don't have to! It's good to know you can have multiple keys on your system and your SSH client will pick the right one for the right system automatically.</p>
<p>It's part of the SSH protocol that it can offer multiple keys and the server picks the one your client will have to prove it has possession of the private key by a challenge.
See it in action adding some verbosity to the SSH connect command (<code>-vvv</code>).
Also if you're using an SSH agent you can load multiple keys and it will discover them all.
Easy as that.</p>
<h2 id="youll-like-the-twisted-edwards-curve">You'll like the Twisted Edwards curve<a href="#youll-like-the-twisted-edwards-curve" title="Permanent link"> </a></h2>
<p>Most common is the RSA type of key, also known as <code>ssh-rsa</code> with SSH.
It's very compatible, but also slow and potentially insecure if created with a small amount of bits (&lt; 2048).
We just learned that your SSH client can handle multiple keys, so enable yourself with the newest faster elliptic curve cryptography and enjoy the very compact key format it provides!</p>
<p>Ed25519 keys are short. Very short. If you're used to copy multiple lines of characters from system to system you'll be happily surprised with the size. The public key is just about 68 characters. It's also much faster in authentication compared to secure RSA (3072+ bits).</p>
<p>Generating an Ed25519 key is done using the <code>-t ed25519</code> option to the ssh-keygen command.</p>
<p>Ed25519 is a reference implementation for EdDSA using Twisted Edward curves (<a href="https://en.wikipedia.org/wiki/Twisted_Edwards_curve">Wikipedia link</a>).</p>
<h2 id="increase-resistance-to-brute-force-password-cracking">Increase resistance to brute-force password cracking<a href="#increase-resistance-to-brute-force-password-cracking" title="Permanent link"> </a></h2>
<p>When generating the keypair, you're asked for a passphrase to encrypt the private key with.
If you will ever lose your private key it should protect others from impersonating you because it will be encrypted with the passphrase.
To actually prevent this, one should make sure to prevent easy brute-forcing of the passphrase.</p>
<p>OpenSSH key generator offers two options to resistance to brute-force password cracking: using the new OpenSSH key format and increasing the amount of key derivation function rounds.
It slows down the process of unlocking the key, but this is what prevents efficient brute-forcing by a malicious user too.
I'd say experiment with the amount of rounds on your system.
Start at about 100 rounds.
On my system it takes about one second to decrypt and load the key once per day using an agent.
Very much acceptable, imo.</p>
<p>With <code>ssh-keygen</code> use the <code>-o</code> option for the new RFC4716 key format and the use of a modern key derivation function powered by bcrypt.
Use the <code>-a &lt;num&gt;</code> option for <code>&lt;num&gt;</code> amount of rounds.</p>
<p>Actually, it appears that when creating a Ed25519 key the <code>-o</code> option is implied.</p>
<p>The OpenSSH manpages are not really explanatory about the 'new' format.
I found this article pretty useful: <a href="http://www.tedunangst.com/flak/post/new-openssh-key-format-and-bcrypt-pbkdf">"new openssh key format and bcrypt pbkdf" on www.tedunangst.com</a>.</p>
<h2 id="generate-your-new-sexy-ed25519-key">Generate your new sexy Ed25519 key<a href="#generate-your-new-sexy-ed25519-key" title="Permanent link"> </a></h2>

<div><pre><span></span><code><span><span>$</span> ssh-keygen -o -a <span>100</span> -t ed25519
</span><span>Generating public/private ed25519 key pair.</span>
<span>Enter passphrase (empty for no passphrase):</span>
<span>Enter same passphrase again:</span>
<span>Your identification has been saved in /home/gert/.ssh/id_ed25519.</span>
<span>Your public key has been saved in /home/gert/.ssh/id_ed25519.pub.</span>
<span>The key fingerprint is:</span>
<span>SHA256: [...] gert@hostname</span>
<span>The key's randomart image is: [...]</span>
</code></pre></div>
<p>Note the line 'Your identification has been saved in /home/gert/.ssh/id_ed25519'.
Your current RSA/DSA keys are next to it in the same <code>~/.ssh</code> folder.
As with any other key you can copy the public key in <code>~/.ssh/id_ed25519.pub</code> to target hosts for authentication.</p>
<h2 id="multi-key-aware-ssh-client">Multi-key aware SSH client<a href="#multi-key-aware-ssh-client" title="Permanent link"> </a></h2>
<p>All keys available on default paths will be autodetected by SSH client applications, including the SSH agent via ssh-add.
So, if you were using an application like ssh/scp/rsync before like...</p>

<p>it will now offer multiple public keys to the server and the server will request proof of possession for a matching entry for authentication.
And your daily use of the <code>ssh-add</code> command will not change and autodiscover the Ed25519 key:</p>
<div><pre><span></span><code><span><span>$</span> ssh-add
</span><span>Enter passphrase for /home/gert/.ssh/id_rsa:</span>
<span>Identity added: /home/gert/.ssh/id_rsa (gert@hostname)</span>
<span>Identity added: /home/gert/.ssh/id_ed25519 (gert@hostname)</span>
</code></pre></div>
<p>It not only discovered both keys, it also loaded them by entering a single passphrase (because it's the same)!</p>
<p>We've reached a very important goal now.
Without any change to your daily routine we can slowly change the existing configuration on remote hosts to accept the Ed25519 key.
In the meantime the RSA key will still work.
Great, right!?</p>
<h2 id="change-or-set-a-passphrase">Change or set a passphrase<a href="#change-or-set-a-passphrase" title="Permanent link"> </a></h2>
<p>If you're afraid this will change your key, don't worry.
The private part of your keypair is encrypted with a passphrase which only exists locally on your machine.
Change it as often as you like.
This is recommended to prevent abuse in case the key file gets into the wrong hands.
Repeat for all your key files to ensure a new key format with 100 bcrypt KDF rounds:</p>
<div><pre><span></span><code><span>$</span> ssh-keygen -f ~/.ssh/id_rsa -p -o -a <span>100</span>
</code></pre></div>
<h2 id="upgrade-your-current-rsa-key">Upgrade your current RSA key<a href="#upgrade-your-current-rsa-key" title="Permanent link"> </a></h2>
<p>Using Ed25519 will (and should) work in most situations by now, but legacy systems may not support them as of yet.
The best fallback is a strong RSA keypair for this.</p>
<p>While the OpenSSH client supports multiple RSA keys, it requires configuration/command line options to specify the path so it's rather error-prone.
Instead, I'd recommend upgrading your existing key in-place to keep things simple once this is done.
Depending on the strength (key size) of your current RSA key you can migrate urgently or comfortably.</p>
<p>In case you have a weak RSA key still, move it out of the way from the standard path and generate a new one of 4096 bits size:</p>
<div><pre><span></span><code><span>$</span> mv ~/.ssh/id_rsa ~/.ssh/id_rsa_legacy
<span>$</span> mv ~/.ssh/id_rsa.pub ~/.ssh/id_rsa_legacy.pub
<span>$</span> ssh-keygen -t rsa -b <span>4096</span> -o -a <span>100</span>
</code></pre></div>
<p>If you are using an agent, manually point it to all your keys:</p>
<div><pre><span></span><code><span>$</span> ssh-add ~/.ssh/id_rsa ~/.ssh/id_rsa_legacy ~/.ssh/id_ed25519
</code></pre></div>
<p>Once you are finished the transition on all remote targets you can go back to convenience and let it autodiscover your new RSA and Ed25519 keys; simply omit the keyfile arguments.</p>
<h2 id="software-support-for-ed25519">Software support for Ed25519<a href="#software-support-for-ed25519" title="Permanent link"> </a></h2>
<p>Support is available since OpenSSH 6.5 and well adopted in the Unix world OSs for workstations.
Ubuntu 14.04+, Debian 8+, CentOS/RedHat 7+ etc. all support it already.
(If you have details about Mac OS X please drop a line, couldn't find it with a quick search).
Some software like custom desktop key agents may not like the new keys for several reasons (see below <a href="#my-gnome-keyring-doesnt-work-anymore">about the Gnome-keyring</a> for example).</p>
<p>Github works pretty well too, by the way.
Launchpad and Gerrit code review however, seem to require RSA keys unfortunately.
PuTTY on Windows? See below.</p>
<h2 id="my-gnome-keyring-doesnt-work-anymore">My Gnome-keyring doesn't work anymore<a href="#my-gnome-keyring-doesnt-work-anymore" title="Permanent link"> </a></h2>
<p>The Gnome-keyring, as used in Ubuntu Unity at least, fails to read the new RFC4716 format keys but reports success.
It's bugged.
More details here in <a href="https://askubuntu.com/q/564821/88802">my AskUbuntu Q&amp;A post</a>.
I'd recommend disabling the Gnome keyring for SSH agent use and use the plain OpenSSH agent instead.</p>
<h2 id="im-using-windows-with-putty">I'm using Windows with PuTTY<a href="#im-using-windows-with-putty" title="Permanent link"> </a></h2>
<p>Sorry, I'm not using PuTTY, but make sure to upgrade first.
This page suggests Ed25519 support since a late-2015 version according to a <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/wishlist/ed25519.html">wishlist item</a>.
Generally speaking, I'm not too excited with the speed of implementation of security features in it.</p>
<h2 id="is-this-the-ultimate-secure-ssh-keypair">Is this the ultimate secure SSH keypair?<a href="#is-this-the-ultimate-secure-ssh-keypair" title="Permanent link"> </a></h2>
<p>We've taken some steps, important ones, but it's far from ultimate security.
When dealing with high assurance environments I would strongly discourage key usage like described in this post as this holds the unencrypted private key in memory.
Instead, use hardware security (smart cards) to avoid leaking keys even from memory dumps.
It's not covered in this post, mainly because it requires a hardware device you need to buy and secondly because the limitations are device dependent.
A nice cute solution would be to make use of your TPM already …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.g3rt.nl/upgrade-your-ssh-keys.html">https://blog.g3rt.nl/upgrade-your-ssh-keys.html</a></em></p>]]>
            </description>
            <link>https://blog.g3rt.nl/upgrade-your-ssh-keys.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870060</guid>
            <pubDate>Fri, 22 Jan 2021 09:42:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ownCloud Infinite Scale: Go instead of PHP, microservices instead of LAMP]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25869798">thread link</a>) | @veddox
<br/>
January 22, 2021 | https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html | <a href="https://web.archive.org/web/*/https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        





<a-collapse has-indicator="">
  
  
  
</a-collapse>


      

      <p>Im stillen KÃ¤mmerlein arbeitet ownCloud seit Ã¼ber einem Jahr an der neuen Version seiner Software und zeigt nun zum ersten Mal sein neues Projekt Infinite Scale â€“ allerdings sind die Entwickler nicht langsam, sondern haben sich viel vorgenommen. Bis einschlieÃŸlich ownCloud X ist die Software eine klassische LAMP-Applikation: Im Hintergrund werkelt MySQL, Apache serviert PHP-Seiten und das gesamte Konstrukt lÃ¤uft Ã¼blicherweise auf einer Linux-Installation.</p>

<a-paternoster height="360" media="(min-width: 320px) and (max-width: 767px)">
  


  


  <a-ad height="600" instant="" layout="fixed" media="(min-width: 320px) and (max-width: 767px)" preload-distance="200" safeframe="" sizes="300x600,300x50,300x75,300x100,300x150,300x250,320x50,320x75,320x100,320x250" targeting="{&quot;kw&quot;:[&quot;Cloud Computing&quot;,&quot;Google Go&quot;,&quot;Linux und Open Source&quot;,&quot;Microservices&quot;,&quot;Nextcloud&quot;,&quot;OwnCloud&quot;,&quot;PHP&quot;,&quot;Server &amp; Storage&quot;,&quot;Systemverwaltung&quot;],&quot;mpos&quot;:[&quot;understitial&quot;,&quot;top&quot;],&quot;themenhub&quot;:&quot;yes&quot;}" type="gpt" unit="/6514/www.heise.de/ix/ix-inhalt" width="300"></a-ad>

</a-paternoster>


<p>Im Laufe der Jahre sind die ownCloud-Entwickler allerdings an immer mehr Performance- und Skalierbarkeitsgrenzen gestoÃŸen, deren Ursache zumeist in entsprechenden Limitierungen in PHP liegt. Wer groÃŸe ownCloud-Installationen betreibt, kennt das: Je mehr Nutzer und Dateien die Instanz verwaltet, desto trÃ¤ger wird sie mit der Zeit. RegelmÃ¤ÃŸig sehen Admins sich zudem mit Speicherplatzmangel konfrontiert, denn bisher speichert ownCloud die Dateien seiner Nutzer lokal auf einem normalen Dateisystem ab. Wird der Platz dort knapp, ist das Problem gar nicht so leicht zu umschiffen.</p>
<h3 id="nav_goodbye_php_0">Goodbye, PHP</h3>
<p>Alle <a href="https://www.heise.de/thema/OwnCloud">diese alten ZÃ¶pfe</a> planen die Entwickler in ownCloud Infinite Scale endgÃ¼ltig abzuschneiden. Dabei handelt es sich mehr Revolution denn Evolution: Ihren alten Code treten die Entwickler fast vollstÃ¤ndig in die Tonne und ersetzen ihn durch einen kompletten Rewrite in Go. oCIS folgt einem Modell aus drei Schichten: Die unterste Schicht kÃ¼mmert sich um das Speichern von Dateien, die mittlere Schicht umfasst alle Kern-Dienste und die dritte Schicht ist das ebenfalls vollstÃ¤ndig neu geschriebene Webinterface.</p>





  

<a-lightbox tabindex="1">
  
    

<figure>

  <div>
      <a href="https://www.heise.de/imgs/18/3/0/4/1/5/0/0/ocis5-b5dab7c1ceae5a77.png">
      

<a-img alt="" height="887" high-dpi-quality="70" layout="responsive" quality="85" src="/imgs/18/3/0/4/1/5/0/0/ocis5-b5dab7c1ceae5a77.png" width="1250"></a-img>



      </a>
    

  </div>
    

<figcaption>    <p>Ein erster Test des neuen ownCloud Infinite Scale und des ebenfalls neuen Webinterface, geschrieben in Vue.js.</p>
      
    
</figcaption>

</figure>

  
</a-lightbox>




<p>Der Kern von ownCloud besteht kÃ¼nftig aus verschiedenen Microservices, die einander per gRPC Befehle und Anweisungen zusenden. Die Entwickler bÃ¼ndeln die MESH-Software Traefik fest mit oCIS, um sich um Themen wie Loadbalancing und sichere Kommunikation innerhalb des Service-Netzwerks keine Gedanken machen zu mÃ¼ssen. Was im Umkehrschluss bedeutet: Reichen die laufenden Instanzen eines bestimmten ownCloud-Dienstes nicht mehr aus, lassen sich zusÃ¤tzliche Instanzen desselben Dienstes ad hoc starten.</p>
<p>Architektonisch nutzt oCIS diverse Vorteile von Go zur Beschleunigung. Fordert der Nutzer kÃ¼nftig eine spezielle Aktion per API oder Webinterface an, kÃ¼mmern die einzelnen oCIS-Microservices sich im Hintergrund darum. Der Anwender muss nicht warten, bis die jeweilige Aktion erfolgreich ausgefÃ¼hrt ist, bevor er den nÃ¤chsten Befehl absenden kann. Der Effekt findet sich auch auf der Code-Ebene wieder, wo Go anders als PHP echte NebenlÃ¤ufigkeit beherrscht und damit mehrere Operationen zur selben Zeit ausfÃ¼hren kann.</p>
<p>Obendrein reduziert der Umstieg auf Microservices den administrativen Aufwand von ownCloud. Eine externe Datenbank wie MySQL benÃ¶tigt die Software kÃ¼nftig nicht mehr â€“ um ihre Datenhaltung kÃ¼mmern sich eigene Microservices.</p>






  


  <a-ad height="250" instant="" layout="responsive" media="(min-width: 320px) and (max-width: 767px)" preload-distance="200" safeframe="" sizes="300x50,300x75,300x100,300x150,300x250,320x50,320x75,320x100,320x250,fluid" targeting="{&quot;kw&quot;:[&quot;Cloud Computing&quot;,&quot;Google Go&quot;,&quot;Linux und Open Source&quot;,&quot;Microservices&quot;,&quot;Nextcloud&quot;,&quot;OwnCloud&quot;,&quot;PHP&quot;,&quot;Server &amp; Storage&quot;,&quot;Systemverwaltung&quot;],&quot;mpos&quot;:[&quot;2&quot;],&quot;themenhub&quot;:&quot;yes&quot;}" type="gpt" unit="/6514/www.heise.de/ix/ix-inhalt" width="300"></a-ad>




      <!-- RSPEAK_STOP -->

      

      

     

      

      <!-- RSPEAK_STOP -->

    </div></div>]]>
            </description>
            <link>https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869798</guid>
            <pubDate>Fri, 22 Jan 2021 09:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon timeline – Easily track planned Apple Silicon support for Mac apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25869685">thread link</a>) | @abdullahdiaa
<br/>
January 22, 2021 | https://isapplesiliconready.com/timeline | <a href="https://web.archive.org/web/*/https://isapplesiliconready.com/timeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><div><div><div><h2>
                    Capture One Pro
                  </h2> <p>
                    Native ARM support, will be released in an update to Capture One 21 early in 2021. In the meantime, Capture One will run on ARM-based Mac computers using Apple’s Rosetta 2 emulation platform. Tethering issue will be addressed in future upcoming releases.
                  </p> <p><a href="https://twitter.com/captureonepro/status/1329810389987680260" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Box drive
                  </h2> <p>
                    A Beta is planned in early 2021 for our Enterprise customers. Meanwhile, customers on these devices are encouraged to leverage our web-based application (https://app.box.com).
                  </p> <p><a href="https://isapplesiliconready.com/app/Box%20drive" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Unite by bzgapps
                  </h2> <p>
                    M1 support planned for early 2021. Rosetta compatible.
                  </p> <p><a href="https://www.bzgapps.com/unite" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Golang
                  </h2> <p>
                    In February, the Go 1.16 release will include support for the new Apple Silicon Macs
                  </p> <p><a href="https://blog.golang.org/11years" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Newton mail app
                  </h2> <p>
                    As soon as 5th Feb. M1 version is expected to be released
                  </p> <p><a href="https://twitter.com/newtonmailapp/status/1352544579178827780" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Clean My Mac
                  </h2> <p>
                    MacPaw planning to release 4.8.0 M1 native version at the end of February.
                  </p> <p><a href="https://twitter.com/cleanmymac/status/1352574830613327872" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Squash by Realmac Software
                  </h2>  <p><a href="https://twitter.com/realmacsoftware/status/1352712198469120001" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Espresso 6
                  </h2> <p>
                    Beta version expected in Feb. and a stable version in March with native Apple Silicon support
                  </p> <p><a href="https://twitter.com/espressoapp/status/1352741607083102208" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Google Drive for Desktop
                  </h2> <p>
                    Google Drive for desktop version 47.0 will support Apple M1 devices
                  </p> <p><a href="https://support.google.com/a/answer/7577057?hl=en" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    The R Project
                  </h2> <p>
                    goal is to have a native distribution for R 4.1.0 ca April 2021.
                  </p> <p><a href="https://stat.ethz.ch/pipermail/r-sig-mac/2020-November/013774.html" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    RapidWeaver by Realmac Software
                  </h2>  <p><a href="https://twitter.com/realmacsoftware/status/1352712198469120001" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    WD Discovery
                  </h2> <p>
                    Western Digital expects to have an update to WD Discovery that will mount the My Cloud Home drive on macOS M1 Processors by July 2021.
                  </p> <p><a href="https://isapplesiliconready.com/app/WD%20Discovery" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div></span></p></div></div></div>]]>
            </description>
            <link>https://isapplesiliconready.com/timeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869685</guid>
            <pubDate>Fri, 22 Jan 2021 08:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to make your own budget Macro keyboard with JavaScript and Arduino]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25869647">thread link</a>) | @Ilikeruby
<br/>
January 22, 2021 | https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard | <a href="https://web.archive.org/web/*/https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>A few days ago I saw this blogpost by Scott Haneselman <a href="https://www.hanselman.com/blog/microsoft-teams-buttons-for-stream-deck-to-mute-share-hang-up-and-manage-cameras">“Microsoft Teams Buttons for Stream Deck to Mute, Share, Hang up, and Manage Cameras”</a> and I’ve found it fascinating and a great use of the Elgato Streamdeck. There is only one little catch.. the price. The elgato stream deck starts about ~150 Euro and about the same in dollars, which is kinda expensive for my budget, so I went thru my drawers to find my old Arduino set. it contained some buttons and some wires, which is exactly what I needed! (And also the whole set cost me about ~50 Euros)</p><p><img src="https://blog.almin.dev/static/media/components.3e13cb3a.jpg"></p><p><strong>Parts I’ve used here:</strong></p><ul><li>Arduino board</li><li>Cables</li><li>Button </li><li>Breadboard </li><li>10k Ohm Resistor</li></ul><h2 id="first-steps">First steps</h2><p>So, the first step was figuring out what language to use to make this work. Originally I thought, it would be nice to use GoLang or Rust since I want to get into these languages in the future, however after some thinking about it I naturally, like every hipster developer, settler for JS. It is probably not a good idea to write microcontrollers with JS but in this case, it should be easy to use and reproduce for everyone, I think JS is the best option. </p><p>What I recommend using is <a href="http://johnny-five.io/">Johnny-Five</a> which in short is a library that helps us communicate with the IOT devices like Arduino and Raspbery pi. In order to communicate with the host device, it realies on the <a href="https://github.com/firmata/protocol">firmata-protocol</a>. In the case of an arduino a program is flashed to the arduino that bootstraps and runs firmata, accepting instructions over a serial connection. With the Raspberry Pi it uses raspi-io, which uses a firmata-compatible API. It has the downside of requiring a serial connection to run your code.</p><p>Now, to start with the project I’ve just lookup some of the examples found in the on the <a href="http://johnny-five.io/examples/button/">Website of johnny-five</a> which helped me connect the arduino with the breadboard. After that I had something like this: </p><p><img src="https://blog.almin.dev/static/media/board.0c1830d6.jpg"></p><p><em><strong>Note</strong></em>: I’ve used some extension cables to make the reach a bit longer, since my USB cable is too tiny and connecting to the back of my PC results in me having to stretch, if I did not have the extensions. </p><p>Here is maybe a better look at the board schema and how to connect a button to it: </p><p><img src="https://blog.almin.dev/static/media/boardSchema.f984cd78.png"></p><h2 id="loading-the-firmware">Loading the firmware</h2><p>After connecting with the breadboard, connect the arduino to the PC and we can start with the fun part!</p><p>First off we start the <a href="https://www.arduino.cc/en/software">Arduino IDE</a> and configure some things. </p><ol><li>Select the correct Port <em><strong>Tools</strong></em> &gt; <em><strong>Port</strong></em> (the correct port is 3 or above)</li></ol><p><img src="https://blog.almin.dev/static/media/port.7420d600.png"></p><br><ol start="2"><li>We will need this to flash the firmata protocol <em><strong>Files</strong></em> &gt; <em><strong>Examples</strong></em> &gt; <em><strong>StandardFirmataPlus</strong></em></li></ol><p><img src="https://blog.almin.dev/static/media/Firmata.17a71e86.png"></p><blockquote><p><strong> ATTENTION </strong>
Let me stop here for a second - If you, like me, have a knockoff arduino and you are not seeing any port besides the default one, you have to install a specific driver which can be found <a href="https://sparks.gogo.co.nz/ch340.html">here</a>. Thats me saving you 3h of googling what the issue is, you are welcome.</p></blockquote><br><ol start="3"><li>Just press <em><strong>Upload</strong></em> button, and if everything is configured correclty there should be no errors in the IDE. </li></ol><p><img src="data:image/png;base64,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"></p><br><ol start="4"><li><strong>Thats it for the config!</strong></li></ol><p>Now that you have Arduino running with a Firmata protocol, everything we have to do is code the JS part of the macro keyboard. </p><p>Make a new <code>index.js</code> file wherever you can - write the code for the keyboard, should look something like this: </p><pre><code data-language="javascript" data-highlighted-line-numbers=""><span>var</span> five <span>=</span> <span>require</span><span>(</span><span>"johnny-five"</span><span>)</span><span>,</span> button<span>;</span>
<span>var</span> robot <span>=</span> <span>require</span><span>(</span><span>"robotjs"</span><span>)</span><span>;</span>
<span>var</span> board <span>=</span> <span>new</span> <span>five<span>.</span>Board</span><span>(</span><span>{</span>
  port<span>:</span> <span>"COM3"</span>
<span>}</span><span>)</span><span>;</span>





board<span>.</span><span>on</span><span>(</span><span>"ready"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>

  
  
  
  button <span>=</span> <span>new</span> <span>five<span>.</span>Button</span><span>(</span><span>2</span><span>)</span><span>;</span>

  
  
  
  board<span>.</span>repl<span>.</span><span>inject</span><span>(</span><span>{</span>
    button<span>:</span> button
  <span>}</span><span>)</span><span>;</span>

  

  
  button<span>.</span><span>on</span><span>(</span><span>"down"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"control"</span><span>,</span> <span>"down"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"shift"</span><span>,</span> <span>"down"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"m"</span><span>,</span> <span>"down"</span><span>)</span>
<span>}</span><span>)</span>

  
  
  
  button<span>.</span><span>on</span><span>(</span><span>"hold"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    console<span>.</span><span>log</span><span>(</span><span>"hold"</span><span>)</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>

  
  button<span>.</span><span>on</span><span>(</span><span>"up"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"control"</span><span>,</span> <span>"up"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"shift"</span><span>,</span> <span>"up"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"m"</span><span>,</span> <span>"up"</span><span>)</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span>
</code></pre><p>This code snippet is only for “CTRL + SHIFT + M” (mute / unmute) for MS Teams (I think Discord and Slack use the same button combination for mute and unmute.)
And run it like a node script <code>node index.js</code> and thats it, your button should be working now!</p><p>Let me break down the code a little bit. The importat part is this: </p><pre><code data-language="javascript" data-highlighted-line-numbers=""><span>var</span> board <span>=</span> <span>new</span> <span>five<span>.</span>Board</span><span>(</span><span>{</span>
  port<span>:</span> <span>"COM3"</span>
<span>}</span><span>)</span><span>;</span>
</code></pre><p>You should initialize a new Board with the correct port, since in my case I had to do it, because the default port is not working. Probably because of the knockoff arduino. The port is the same as the one we selected above in the first step!</p><p>The pin on the Arduino board should be set here as the button:</p><pre><code data-language="javascript" data-highlighted-line-numbers="">button <span>=</span> <span>new</span> <span>five<span>.</span>Button</span><span>(</span><span>2</span><span>)</span><span>;</span>
</code></pre><p>Later you can declare new buttons with the same code, just remember to select the correct Digital pin number on which the button is connected. (Usually from 0 to 13)</p><p>And <a href="https://github.com/octalmage/robotjs">RobotJs</a> is being used to setup the keyboard shortcuts with the <code>down</code> and <code>up</code> events which are triggered when pressing the button. It is just a simple library which simulates the keyboard inputs. This is really the first solution I could find and easiest I could make work, there could be potentially something better, but I’ve settled with what works. Also remember to use KeyToggle function and not keyTap. So you can add additional shortcuts, which make you leave the call or copy - paste, change scenes, essentially almost everything you can do with a StreamDeck.</p><p>So, in just a few steps you can have a custom macro keyboard. It is supriseingly not that hard, especially if you have the possibility to write JS and make it work with it. </p><p>Later if you are ambitious you can expand this and add more buttons on the board and make something a bit more complicated and it could look like this: </p><p><img src="https://blog.almin.dev/static/media/finished.38bd50d3.png"></p><p>Its not as fancy as the StreamDeck but it is usefull and does the job. In the future you can update it and get better keys and better housing for the whole board, add blinking lights and so on. This was just fun DIY project which is also something really usefull.</p></div></article></div></div>]]>
            </description>
            <link>https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869647</guid>
            <pubDate>Fri, 22 Jan 2021 08:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canada's Express Entry Program]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25869096">thread link</a>) | @luu
<br/>
January 21, 2021 | https://scattered-thoughts.net/writing/canadas-express-entry-program/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/canadas-express-entry-program/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Wesley Aptekar-Cassels' recent posts on <a href="https://notebook.wesleyac.com/taiwan-gold-card/">getting a gold card</a> and <a href="https://notebook.wesleyac.com/taiwan/">moving to Taiwan</a> reminded me that I meant to write about my experience with Canada.</p>
<p>I immigrated to Vancouver, BC in March 2020. I was given permanent residency before setting foot in Canada and without a job offer, under the <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry.html">Express Entry</a> program. From gathering documents to landing in the country took 9 months. Judging by 3rd party trackers this is well over the median - I was pretty disorganized and the London embassy is one of the slowest.</p>
<p>The whole process looks like this:</p>
<ol>
<li>Check the <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/eligibility/compare.html">eligibility requirements</a> and spend 5 minutes filling out <a href="https://www.cic.gc.ca/english/immigrate/skilled/crs-tool.asp">this questionnaire</a>. You'll get a score which you can compare to <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/submit-profile/rounds-invitations/results-previous.html">recent admission rounds</a> to see if you have a good chance. (The results aren't recorded, so just guess what your language test scores would be.)</li>
<li>Take an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/documents/language-requirements.html">English and/or French exam</a> and get an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/documents/education-assessed.html">Educational Credential Assessment</a>. Get the rest of your paperwork ready - proof of employment history, proof of funds, <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/apply-permanent-residence/police-certificates.html">police certificates</a>.</li>
<li>Fill out an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/submit-profile.html">Express Entry profile</a> and wait for an invitation to apply.</li>
<li>Get invited to apply. Submit all the paperwork. Take a short medical exam and go the embassy for fingerprints and photos.</li>
<li>Send off your passport and wait for it to come back with a Confirmation of Permanent Residence inside.</li>
</ol>
<p>The total cost for me was £1456:</p>
<ul>
<li>£165 for the IELTS exam</li>
<li>£140 for the Educational Credential Assessment</li>
<li>various small fees for eg mailing paperwork, getting sealed degree certificates</li>
<li>£670 for the Express Entry application</li>
<li>£330 for the medical exam</li>
</ul>
<p>One thing I really appreciated is that most of the expense of applying, in terms of both time and money, was at step 4, by which point the acceptance rate is something like 95%.</p>
<p>Other miscellanea:</p>
<ul>
<li>Step 2 took me 4 months (poor planning). Step 3 took 2 weeks. Step 4 took 3 months. Step 5 took 2 months, apparently due to heavy backlog at the London office.</li>
<li>Self-employment is fine for the employment history requirements. I submitted tax records and signed letters from a few previous clients.</li>
<li>I didn't have a job offer in Canada, but if you do it seems worth trying to get provincial nomination which will shoot you to the top of the queue. Eg BC has a <a href="https://www.welcomebc.ca/Immigrate-to-B-C/B-C-Provincial-Nominee-Program/BC-PNP-Tech-Pilot">fast-track for tech jobs</a>.</li>
<li>Permanent residents are eligible for public healthcare (which in BC is free) after 3 months. There are companies that offer cheap private insurance to cover the gap - I used <a href="https://www.desttravel.com/#/insuranceproducts/visitortocanadainsurance">Destination Travel</a>.</li>
<li>To keep my residency I need to spend 2 out of every 5 years in Canada. After accumulating 3 years in Canada in any 5 year period I'm eligible for citizenship.</li>
</ul>
<hr>
<p>My move was totally unrelated to current events - I had decided a few years back that I wanted to settle down somewhere and Vancouver ended up at the top of the spreadsheet. But since many of my friends in the US are thinking about emigrating, here are the main points I see for and against.</p>
<p>In favor of Vancouver:</p>
<ul>
<li>World class <a href="https://www.mountainproject.com/area/105946429/british-columbia">climbing</a>, skiing, kayaking, mountain biking etc as well as a <a href="https://originsparkour.com/">solid parkour gym</a></li>
<li><a href="https://www.youtube.com/watch?v=gjfUkxqDDNw">Astounding natural beauty</a></li>
<li><a href="https://www.iqair.com/ca/canada/british-columbia/vancouver-bc">Low air pollution</a></li>
<li><a href="https://vancouver.ca/home-property-development/urban-forest-strategy.aspx">Trees</a>, <a href="https://vancouver.ca/parks-recreation-culture/beaches.aspx">beaches</a>, <a href="https://www.vanmuralfest.ca/murals">murals</a></li>
<li>Reasonable social safety net</li>
<li>Politically stable</li>
<li>English-speaking (I've lived in several non-English-speaking countries so this certainly isn't a hard requirement, but it is easier)</li>
<li>Same timezone as SF and 3 hours behind NYC - good for remote tech work</li>
<li>Regularly ranked as one of the <a href="https://en.wikipedia.org/wiki/Most_livable_cities">most livable</a> cities in the world</li>
</ul>
<p>Against Vancouver:</p>
<ul>
<li>Large belligerent neighbor</li>
<li>On the <a href="https://vancouver.ca/home-property-development/understanding-earthquakes.aspx">Cascadia subduction zone</a></li>
<li>Downtown is vulnerable to <a href="https://vancouver.ca/green-vancouver/sea-level-rise.aspx">sea level rise</a></li>
<li>Uncertain economic future, dependent on oil</li>
<li>Regular wildfires</li>
<li>Expensive real estate (compared to other Canadian cities, but not anywhere near as bad as SF, NYC or London)</li>
<li>Not a cultural capital</li>
</ul>

</article></div>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/canadas-express-entry-program/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869096</guid>
            <pubDate>Fri, 22 Jan 2021 06:46:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transcript of Microsoft President Brad Smith's Town Hall on the Company PAC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25869065">thread link</a>) | @idlewords
<br/>
January 21, 2021 | https://notes.pinboard.in/u:maciej/90342e46caf768b7329d | <a href="https://web.archive.org/web/*/https://notes.pinboard.in/u:maciej/90342e46caf768b7329d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><b>Microsoft Town Hall Jan 21 Transcript</b></p><p>The following is a partial transcript of an employee town hall held by Microsoft on January 21, 2021. Participants in the town hall included Microsoft CEO Satya Nadella, Microsoft President Brad Smith, and Kurt DelBene, executive vice president of corporate strategy. The event moderator was Nichole Christie. A video of the town hll was made available to me by a source at Microsoft, and I have transcribed Smith's comments on the company PAC here verbatim. </p>

<p>Comments and shouts into the void in brackets in italics are mine.</p>

<p>My contact info is maciej@ceglowski.com / 415 610 0231 on Signal. </p>

<hr>

<p><strong>NICOLE CHRISTIE</strong>: The Microsoft political action committee, or MS-PAC. We're hearing about this on a variety of channels, so it is our first question, and this one comes from Yammer. </p>

<p>"Please advise what actions MS-PAC will make to address donations made to politicians involved in the effort to derail the certification of Electoral College votes on January 6. Microsoft employees support our company culture and values, and follow our code of conduct. MS-PAC dollars should not be given to politicians or organizations who don't share those values. Brad, can you speak to this?</p>

<p><strong>BRAD SMITH</strong>: "Thank you, Nicole, and it's obviously an important question. I don't want to repeat but I do want to build upon what Satya has said. Jan 6, the attack on the Capitol, was a horrific day for all of us, whether we're in the United States or somewhere else, and I think it was even more difficult, say, for our black employees and our Jewish employees given the hateful symbols that were on display.</p>

<p>"This has obvious implications for the future donations of the PAC. We took stock of our donations over the last four years and we found that 80% of the dontions had gone to members of Congress who voted to uphold the Electoral College, and 20% had gone to members who voted against the Electoral College,"</p>

<p>[<em>It's not clear if this is an accounting of dollar figures, or a count of donations. It's also not clear if Smith is counting donations to leadership PACs and other PACs, which fan out to multiple members of Congress. You can see a spreadsheet of donations made by Microsoft and other tech companies to the 147 members of congress who voted to overturn the Electoral College <a href="https://docs.google.com/spreadsheets/d/1EjbdWHZ-9ojc5Fh64Sle6kpnOIfJSztkJT3YFlJilDk/edit#gid=0">here</a>.</em>]</p>

<p><strong>SMITH</strong>: "So now there's a process to decide what to do. The questions that are being considered are exactly I think what you would expect. Should the PAC suspend donations to the members who voted against the Electoral College? If so, for how long?"</p>

<p>[<em>Microsoft had previously suspended political giving in summer of 2019, when the then-head of the PAC <a href="https://idlewords.com/2019/07/microsoft_s_hypocrisy_on_daca.htm">suggested to employees in an internal forum</a> that even discussing the PAC with coworkers might constitute harassment. This comment came in the context of an employee effort to defund the PAC, and caused considerable internal uproar. The head of the PAC left Microsoft shortly thereafter in unclear circumstances. The company resumed its political giving in October 2019.</em>]</p>

<p><strong>SMITH</strong>: "Should it even take stronger steps with respect to members who led that effort or who fed disinformation, in our view, to the American public. These are among the questions that are being considered. Now, the PAC pauses donations at the beginning of every new Congress, but this is not a normal year."</p>

<p>[<em>Smith makes an important point here—the decision by many Fortune 500 companies to suspend political giving in the aftermath of the January 6 catastrophe has little practical impact, since corporate donations are typically not made in the first months of a new electoral cycle. Only a very few companies, like Nike, have committed to permanently withholding donations from legislators who voted to overturn the Electoral College vote.</em>]</p>

<p><strong>SMITH:</strong> "And so we're engaging in additional steps to really think this through. And the heart of this is really to have a series of virtual meetings with employees, because I think it's important to get employee feedback and have a conversation together before these decisions are made."</p>

<p>[<em>In the past, Microsoft limited discussions of PAC giving to actual or potential PAC donors, which automatically excluded the company's DACA and non-US employees, who are prohibited by law from making political contributions, but who were the most directly affected by the company's political giving. It's not clear whether the current round of discussions will be open to everyone or again limited in this way.</em>]</p>

<p><strong>SMITH:</strong> "Now I definitely appreciate, especially for people outside the United States, you might be following all this and wondering 'what are we talking about? What is this thing called a PAC? So I did want to take a moment just to give you a little bit more context."</p>

<p>"A PAC is a political action committee, and it reflects first of all the fact that in the Untied States, political campaigns are privately funded. We've been one of many that have long encouraged more public funding to get money out of politics, but it does pay for campaigns. A campaign for the House of Representatives of the United States typically costs millions of dollars; a campaign for the Senate costs tens of millions of dollars."</p>

<p>[<em>Smith does not mention state races, where Microsoft, almost alone among big tech companies, also makes substantial contributions.</em>]</p>

<p><strong>SMITH</strong>: "Now a PAC if you really look at it doesn't actually contribute that much money. It's paid for entirely by voluntary donations. 91% of the Fortune 100 have a PAC; 75% of the Fortune 500 have a PAC."</p>

<p>[<em>Donations to PACs at large companies are typically done by paycheck deduction. Depending on the company, there can be considerable pressure to make these 'voluntary' donations, particularly among senior executives. Apple and IBM stand apart from the other tech giants by not having a PAC.</em>]</p>

<p><strong>SMITH:</strong> "But the law says that they can only be funded by donations from employees, shareholders, and family members, and ours are, of no more than $5,000 a year. And the donations the PAC makes are actually small in the scheme of things as well. The PAC can contribute up to $5,000 for a primary election, and $5,000 for a general election. The decisions about who to donate to are made by a steering committee, and then there's an employee advisory committee and there's a broad network because we want everybody who donates voluntarily to be part of an ongoing conversation."</p>

<p>"The PAC makes donations based on four criteria:</p>

<p>"First, does the person have a job, a role, say on a committee that impacts our business?</p>

<p>"Second, does the person represent a geography where we have a significant employee presence?"</p>

<p>"Third, does the person advance policy goals that align with Microsoft's business policy objectives."</p>

<p>"And fourth, does the person share our values around diversity and inclusion?"</p>

<p>"So all four of things are considered when decisions about donations are made."</p>

<p>[<em>Microsoft's donation history shows that the fourth criterion is not a veto point, but rather is weighted against the other three. Microsoft makes significant donations to members of Congress who are working to get Microsoft's own employees deported.</em>]</p>

<p><strong>SMITH:</strong> "I recognize that especially when you have times like this it's easy for people to ask the question, 'do we really need a PAC?' And I will acknowledge that I've asked that question myself over the last few years. 'Do we really need this PAC?' And I have to tell you, the answer is 'yes, we do'."</p>

<p>"I can tell you it plays an important role. Not because the checks are big, but because the way the political process works. Politicians in the United States have events, they have weekend retreats, you have to write a check and then you're invited and participate. So if you work in the government affairs team in the United States, you spend your weekends going to these events; you spend your evenings going to these dinners, and the reason you go is because the PAC writes a check."</p>

<p>"But out of that ongoing effort a relationship evolves and emerges and solidifies, and I can tell you as somebody who sometimes is picking up the phone, I'm sometimes calling members and asking for their help on green cards, or on visa issues, or help to get an employee or family member who is outside the United States during COVID back into the country because of an immigration restriction."</p>

<p>[<em>The somewhat astonishing argument laid out here is that Microsoft needs to elect representatives who enact an anti-immigrant agenda in order to have the clout to win limited exemptions from that agenda for itself.</em>]</p>

<p><strong>SMITH</strong>: "Or the issues around national security, or privacy, or procurement reform. Or the tax issues that our finance team manages. And I can tell you, there are times when I call people who I don't personally know, and somebody will say "you know, your folks have always shown up for me at my events. And we have a good relationship. Let me see what I can do to help you"</p>

<p>"So I do believe it is important for our company to have this kind of effort. And at the same time, it's important for us to take stock of the recent events, get feedback, have a conversation, and make decisions that will continue to reflect where we stand, and the values that we believe are important. "</p>

<p>"So you'll see all of that unfold, with dialogue, with employees."</p>
</div></div>]]>
            </description>
            <link>https://notes.pinboard.in/u:maciej/90342e46caf768b7329d</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869065</guid>
            <pubDate>Fri, 22 Jan 2021 06:39:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25868569">thread link</a>) | @almost_usual
<br/>
January 21, 2021 | https://www.krisp.org.za/publications.php?pubid=316 | <a href="https://web.archive.org/web/*/https://www.krisp.org.za/publications.php?pubid=316">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3><center>Publication</center></h3>
                    <p>Title: <b>Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma</b><br>
                    Authors: <b>Cele S, <a href="https://www.krisp.org.za/people.php?fullName=Gazy%20I">Gazy I</a>, Jackson L, Hwa S-H, <a href="https://www.krisp.org.za/people.php?fullName=Tegally%20H">Tegally H</a>, Lustig G, <a href="https://www.krisp.org.za/people.php?fullName=Giandhari%20J">Giandhari J</a>, <a href="https://www.krisp.org.za/people.php?fullName=Pillay%20S">Pillay S</a>, <a href="https://www.krisp.org.za/people.php?fullName=Wilkinson%20E">Wilkinson E</a>, <a href="https://www.krisp.org.za/people.php?fullName=Naidoo%20Y">Naidoo Y</a>, Karim F, Ganga Y, Khan K, Balazs AB, Gosnell BI, Hanekom W, Moosa MYS, NGS-SA, COMMIT-KZN Team, <a href="https://www.krisp.org.za/people.php?fullName=Lessells%20R">Lessells R</a>, <a href="https://www.krisp.org.za/people.php?fullName=de%20Oliveira%20T">de Oliveira T</a>, Sigal A</b>.<br>
                    Journal: <b>medRxiv</b>, 250224v1-Sigal: (2021)<br></p>
				<h4>Abstract</h4><p>
				New SARS-CoV-2 variants with mutations in the spike glycoprotein have arisen independently at multiple locations and may have functional significance. The combination of mutations in the 501Y.V2 variant first detected in South Africa include the N501Y, K417N, and E484K mutations in the receptor binding domain (RBD) as well as mutations in the N-terminal domain (NTD). Here we address whether the 501Y.V2 variant could escape the neutralizing antibody response elicited by natural infection with earlier variants. We were the first to outgrow two variants of 501Y.V2 from South Africa, designated 501Y.V2.HV001dF and 501Y.V2.HV002. We examined the neutralizing effect of convalescent plasma collected from six adults hospitalized with COVID-19 using a microneutralization assay with live (authentic) virus. Whole genome sequencing of the infecting virus of the plasma donors confirmed the absence of the spike mutations which characterize 501Y.V2. We infected with 501Y.V2.HV001dF and 501Y.V2.HV002 and compared plasma neutralization to first wave virus which contained the D614G mutation but no RBD or NTD mutations. We observed that neutralization of the 501Y.V2 variants was strongly attenuated, with IC50 6 to 200-fold higher relative to first wave virus. The degree of attenuation varied between participants and included a knockout of neutralization activity. This observation indicates that 501Y.V2 may escape the neutralizing antibody response elicited by prior natural infection. It raises a concern of potential reduced protection against re-infection and by vaccines designed to target the spike protein of earlier SARS-CoV-2 variants.</p><center> <a href="https://www.krisp.org.za/manuscripts/MEDRXIV-2021-250224v1-Sigal.pdf"> <img alt="" src="https://www.krisp.org.za/imagesBIO/pdf2.png"></a></center><h4>Download: <a href="https://www.krisp.org.za/manuscripts/MEDRXIV-2021-250224v1-Sigal.pdf"> Full text paper</a></h4>
		<p>Citation:  Cele S, <a href="https://www.krisp.org.za/people.php?fullName=Gazy%20I">Gazy I</a>, Jackson L, Hwa S-H, <a href="https://www.krisp.org.za/people.php?fullName=Tegally%20H">Tegally H</a>, Lustig G, <a href="https://www.krisp.org.za/people.php?fullName=Giandhari%20J">Giandhari J</a>, <a href="https://www.krisp.org.za/people.php?fullName=Pillay%20S">Pillay S</a>, <a href="https://www.krisp.org.za/people.php?fullName=Wilkinson%20E">Wilkinson E</a>, <a href="https://www.krisp.org.za/people.php?fullName=Naidoo%20Y">Naidoo Y</a>, Karim F, Ganga Y, Khan K, Balazs AB, Gosnell BI, Hanekom W, Moosa MYS, NGS-SA, COMMIT-KZN Team, <a href="https://www.krisp.org.za/people.php?fullName=Lessells%20R">Lessells R</a>, <a href="https://www.krisp.org.za/people.php?fullName=de%20Oliveira%20T">de Oliveira T</a>, Sigal A. Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma medRxiv, 250224v1-Sigal: (2021).</p>      
                <p><h3><center>Media Coverage of this Publication:</center></h3><br></p><div>
                    <div>
                        <center><img src="https://www.krisp.org.za/imagesBIO/nature_logo.png" width="100&quot;" heigth="75">
                        </center>
                    </div>
                    </div>      
                <p><h3><center>Video &amp; TV Coverage of this Publication:</center></h3><br></p>
<div>
<center><iframe width="560" height="315" src="https://www.youtube.com/embed/C0icC2ar3Pg" frameborder="0" allowfullscreen=""></iframe></center></div>	
<div>
<center><iframe width="560" height="315" src="https://www.youtube.com/embed/2zVjKwuTYek" frameborder="0" allowfullscreen=""></iframe></center></div>	</div></div>]]>
            </description>
            <link>https://www.krisp.org.za/publications.php?pubid=316</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868569</guid>
            <pubDate>Fri, 22 Jan 2021 05:15:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reaching flow state with Clojure's REPL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25868565">thread link</a>) | @shivekkhurana
<br/>
January 21, 2021 | https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04 | <a href="https://web.archive.org/web/*/https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div role="textbox" aria-multiline="true" aria-readonly="true" aria-label="" data-test-id="editor-instance" contenteditable="false"><p>Did you know that you sleep in multiple phases? At first, you lie down and close your eyes, but it's still easy to be woken up. As sleep progresses it becomes deeper, to the point where you lose your sense of time and start dreaming. This stage is called deep sleep or REM sleep and it's essential for learning, memory, and wellbeing. The catch is - you cannot progress to the REM stage until you have finished the earlier, non-REM stages.</p><p>Flow state is akin to deep sleep. When you reach your desk, you are not immediately productive. You read your emails, check Reddit or Hacker News, and then slowly ease into the flow state (at which point you get disturbed by being called for a meeting, of course!). The point is, to work efficiently, we need to progress in stages until we reach flow state.</p><p>Any external hindrance breaks the flow and forces us to start again. External distractions can be due to the surrounding environment (kids, meetings, food breaks, angry neighbors) or your tooling (compile time, documentation lookups, unrelated bugs, etc). Library and language developers cannot fix your issues with your angry neighbor, but a lot of effort has been made to improve the tools.</p><p>In this post, you will learn how REPL driven development can provide fast feedback and get you into the flow state sooner.</p><h2 id="hot-reload,-fast-refresh,-and-fast-compilation"><span>Hot Reload, Fast Refresh, and Fast compilation</span><a href="#hot-reload,-fast-refresh,-and-fast-compilation">#</a></h2><div><p>Working with an interpreted language like Python is faster than a compiled language like C++, in part because of the feedback cycle. In the same amount of time, you can test more changes in Python code than C++ code, because you don't need to compile. Eliminating the need to compile is equivalent to eliminating external distractions. You can experiment with more ideas without hurdles, and progress more quickly towards reaching flow state. But this comes at the cost of performance.</p><p>Compiled languages have a slow feedback cycle. This leads to efficient performance, but a compromised developer experience.</p><p>Languages like Go focus on fast compilation, making the feedback loop short without compromising runtime performance.</p><p>Frontend JavaScript has tools like Browserify's Live Reload, React HMR, and Fast Refresh, which compile your program and execute it so you can reach or maintain your flow state. If it takes a long time to compile every change, you'll probably never reach flow state.</p></div><h2 id="problems"><span>Problems</span><a href="#problems">#</a></h2><p>For compiled or transpiled languages, the code we write and the code that's run is inherently different. For example, you might be writing Typescript, which is converted to ES6 before being executed in the browser. The problem is that the entire representation of the codebase is flushed down each time you make a change. The transpiler is efficient and makes sure to recompile only the files that were changed and depend on the change. But it is still hard to cherrypick the exact function or variable that changed and update just that piece in the runtime.</p><p>There is no one-to-one mapping of all functions in the source to compiled code, so we resort to the next best strategy - recompilation (ie. compile the entire module).</p><p>The lack of direct mapping leads to a significant loss of power. These mappings exist to an extent in source maps, but source maps treat code as text. Lines are indexed and recorded. A source map can tell that lines 1 to 4 of source code produced lines 14 to 28 of compiled code, but it cannot tell the position or semantics of the function defined on line 4 in the source code.</p><p>This lack of mapping is mainly because C-style languages are written like a natural language. Computers are not good at parsing natural languages. Computers are good at parsing data-structures and discrete forms.</p><h2 id="shoot-for-the-stars"><span>Shoot for the stars</span><a href="#shoot-for-the-stars">#</a></h2><div><p>What do we gain if we can somehow get this one-to-one mapping of source and compiled code? An easier path to flow state?</p><p>Imagine a language that is not written like English prose, but expressed in terms of data structures.</p></div><p>Imagine if we could somehow connect the source code to the runtime (compiled code), to the extent that we could pinpoint and execute a function <code>f</code> defined in source code right from the editor. This is what it would look like:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219081714648_repl-demo.gif" attachmentid="04c60f5c-d5c2-48d6-92f1-19f2c0173842" contenteditable="false" data-width="1440" data-height="900"></figure><p><strong><em>Figure 1: </em></strong><em>Executing functions in the REPL</em><em><br></em><br>In the GIF above, we have ClojureScript source code in a text editor, connected to a runtime (browser). We can execute functions as we write them. No refresh, no recompilation, no interpreter.</p><p>Just one function, picked up, compiled, and executed right inside your editor. And the best part is, this system has been stable and in production since 2015 (perhaps even earlier than that).</p><h2 id="what-is-repl-and-repl-driven-development"><span>What is REPL and REPL driven development</span><a href="#what-is-repl-and-repl-driven-development">#</a></h2><p>To understand the REPL and REPL driven development, we must first introduce Clojure. Clojure is a dialect of LISP (short for List Processing). LISP code is written in the form of trees, unlike C-style code which is written like natural English language.</p><p>Consider a function that takes a Hash Map like <code>{:a "b" :c "d"}</code> and returns a query string like <code>"a=b&amp;c=d"</code>:<br></p><p>This code can be represented in the form of a tree as follows:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219082406554_tree.svg" attachmentid="92a47474-cb57-45dc-b083-877590fde13d" contenteditable="false" data-width="422" data-height="270"></figure><p><br><strong><em>Figure 2</em></strong><em>:</em> <em>Tree representation of LISP code</em></p><p>Because of the discrete data structure form, the compiler can easily create a one-to-one mapping of functions in source (CLJS) code to output in compiled (JS) code, and can also execute a selected part of the source in runtime.</p><p>Like in <strong><em>Figure 1</em></strong> above, the code <code>(+ 3 4)</code> is written in ClojureScript, compiled to JavaScript, and executed, and the results are returned to the editor.</p><p>The REPL is the hidden agent that facilitates this source to runtime bridge. It takes source code, executes instructions in runtime, and brings the results right back to the point of definition, ie. the editor:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219082703461_repl-scope.png" attachmentid="df3c43e9-0415-4539-91e0-eeb2f867347e" contenteditable="false" data-width="862" data-height="802"></figure><p><strong><em>Figure 3:</em></strong><em> Scope of the REPL</em></p><p>1. Your source code lives in your editor<br>2. The Shadow (compiler) converts this code to browser ready JavaScript<br>3. The REPL then sends execution instructions to the compiled code<br>4. This is then executed in the runtime (Node or Browser) and the result is returned to the editor</p><p>REPL driven development leads to lightning-fast feedback. You just write pure functions and execute them as you are typing them. No need to leave the editor, no need to hot reload, no need to interact with the UI.</p><p>In this talk at JSFOO Bangalore, I showcased REPL driven development (Start at [4:39] to get to the juice):</p><p><br>This talk explains how the REPL fits in with common frontend tasks, like building forms and handling state.</p><h2 id="what-can-you-do-with-the-repl?"><span>What can you do with the REPL?</span><a href="#what-can-you-do-with-the-repl?">#</a></h2><p>According to the official Clojure docs, <a href="https://clojure.org/guides/repl/guidelines_for_repl_aided_development" rel="noopener noreferrer nofollow">the REPL is a user interface to your program</a>. Think of it as a way to execute parts of your code with immediate feedback. This makes it a powerful development tool. You already saw how functions can be executed in the REPL in <strong><em>Figure 1.</em></strong></p><h3 id="inspect-third-party-libraries"><span>Inspect third-party libraries</span><a href="#inspect-third-party-libraries">#</a></h3><p>Since the REPL can execute any source code, you can use it to check the methods a third party library exposes.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219170955642_lib-optimized.gif" attachmentid="2b5d2431-6d2c-43f2-a06f-fe786c333180" contenteditable="false" data-width="1792" data-height="1120"></figure><p><br><strong><em>Figure 4:</em></strong><em> Inspecting methods exposed in the React package</em></p><h3 id="inspect-state"><span>Inspect state</span><a href="#inspect-state">#</a></h3><p>A large part of UI development involves interacting with state. The REPL can be used to read the data structure storing your state.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219171220458_state-optimized.gif" attachmentid="578a7002-dfe5-4b2d-8bc2-3acaa93fab04" contenteditable="false" data-width="1792" data-height="1120"></figure><p><strong><em>Figure 5: </em></strong><em>Inspecting app state in real-time</em></p><h3 id="fill-forms"><span>Fill forms</span><a href="#fill-forms">#</a></h3><p>Form states are generally saved using one-way binding(like in React) or two-way binding (like in Vue). Since the object that stores the state is defined somewhere in the code, you can use the REPL to fill forms by changing interactions with the object.</p><div data-panel-type="info" data-panel-position="inline"><p>I highly recommend checking the 📹 video from the JSFoo conference (above) to see the form filling in action. It seems like magic!</p></div><h3 id="execute-ui-flows"><span>Execute UI flows</span><a href="#execute-ui-flows">#</a></h3><p>If you are building a multi-step process like checkout or signup, filling the initial steps might become tedious as your flow grows. You can define the steps in your source code, and execute it in the REPL. The UI will respond respectively.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201220073216472_My%20Movie-half.gif" attachmentid="47b312f9-a9cd-48a6-a968-9b59dbee674f" contenteditable="false"></figure><p><strong><em>Figure 6:</em></strong> <em>Simulating UI events on a React Native app</em></p><p>In the GIF above, we have a Status App (A free, libre, open-source | GitHub.com/status-im/status-react) messenger running on an Android device, and a REPL connected to it. We can simulate events in the REPL, essentially letting us develop complex flows, without even touching the device. If you are a mobile developer, imagine the time saved if you never needed to take your hands off the keyboard to interact with the app. And the feedback is fire 🔥.</p><p>Flows like this can be saved as a comment alongside your source code and committed to git. This acts like documentation of what the developer was thinking while they developed this flow.</p><h2 id="works-on-every-clojure-runtime"><span>Works on every Clojure runtime</span><a href="#works-on-every-clojure-runtime">#</a></h2><p>Clojure is a hosted language that can compile to JavaScript, Java, and .NET. JavaScript can be used to build mobile apps with React Native and Desktop apps with Electron.</p><p>This means that you can run the REPL on every imaginable platform. Clojure is the closest we are to the "Learn once, run anywhere" philosophy.</p><h2 id="fast-feedback-=-more-chances-to-achieve-flow"><span>Fast feedback = more chances to achieve flow</span><a href="#fast-feedback-=-more-chances-to-achieve-flow">#</a></h2><p>Once you get used to developing in the REPL, reaching flow state becomes more achievable. The entire act of transpilation, seeing the UI, clicking buttons, checking console changes, and executing functions all happens in the REPL.<br>This method brings you close to the runtime and lets you inspect the internals of your application with ease.</p><h2 id="how-is-this-different-from-shell?"><span>How is this different from Shell?</span><a href="#how-is-this-different-from-shell?">#</a></h2><p>The Shell (like the Python or Node shell) is a rudimentary version of the REPL. It's different in the sense that it cannot reload pieces of code like Clojure's REPL. This is partly because of how Clojure and LISP-like languages are written.</p><p>It is also different because no stable tooling exists to connect the Shell to the editor. I would go as far as saying that Clojure is the only stable language with a fully-featured REPL plugin for all major editors.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion">#</a></h2><p>I first learned about the REPL after 8 years of building full-stack applications. My mind was blown and I wondered why this wasn't the norm. Why didn't more people talk about it? Why was I not able to find it?</p><p>Clojure is not as well-known as JavaScript. On top of that, when you get started, all you see is ugly syntax, with brackets in the wrong …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04">https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04</a></em></p>]]>
            </description>
            <link>https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868565</guid>
            <pubDate>Fri, 22 Jan 2021 05:14:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building with Broken APIs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25868001">thread link</a>) | @behan
<br/>
January 21, 2021 | https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs | <a href="https://web.archive.org/web/*/https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><time datetime="2021-01-21">January 21, 2021</time></p><p><img src="https://github.com/Chris-Behan/chris-behan.github.io/blob/master/public/images/EastVillageCalgary.jpeg?raw=true" alt="https://github.com/Chris-Behan/chris-behan.github.io/blob/master/public/images/EastVillageCalgary.jpeg?raw=true"> <em>Photo by Pablo Contreras</em></p><p>I recently wrote an essay titled <a href="https://www.chrisbehan.ca/posts/KnowledgeAsAnAPI"><em>Knowledge as an API</em></a>, where I explored the idea of thinking about knowledge as a collection of APIs. In the essay, I define the term <em>Knowledge API</em> as:</p><blockquote><p>"A mental model for thinking about the understanding of a specific domain as an Application Programming Interface (API). Knowledge APIs depend on and can be used by one another.</p></blockquote><p>One of the talking points of the essay was the importance of trust between knowledge APIs, and how an error in a knowledge API (where error means producing an unexpected result) introduces incorrect behaviour to the system. This incorrect behaviour then propagates to all knowledge APIs that use that API. Using an analogy to software, the type of error I am talking about here is a "<a href="https://en.wikipedia.org/wiki/Logic_error">logic error</a>", where the program does not crash, everything appears to be working, but the results are not what we expect. Similar to software development, the root cause of incorrect behaviour becomes more difficult to identify the further you get from the source. Unlike software development, we do not have a stack trace or debugger to help us determine the root cause of the incorrectness in our Knowledge API. Why do we need trust at all? Why can't we just verify the correctness of our knowledge API and all its dependencies before using it? I will explore the answer to this question in this essay, along with how incorrect knowledge APIs and the concept of error propagation translates to subjective domains like economics, and how you can use this mental model to better evaluate the validity of subjective domains.</p><h2>Error propagation</h2><p>Let's start by looking at how errors propagate among knowledge APIs.</p><p>Suppose we have a knowledge API called Arithmetic:</p><pre><code><span>// Arithmetic Knowledge API</span><span>
</span>
<span></span><span>/**
</span><span>Returns the sum of two numbers.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>addition</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>const</span><span> c </span><span>=</span><span> a </span><span>+</span><span> b</span><span>;</span><span>
</span><span>    </span><span>if</span><span>(</span><span>c </span><span>==</span><span> </span><span>4</span><span>)</span><span>{</span><span>
</span><span>        </span><span>return</span><span> </span><span>5</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>return</span><span> c</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>/**
</span><span>Multiplies two numbers and returns the result.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>multiplication</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> a </span><span>*</span><span> b</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The Arithmetic API contains a function called <code>addition</code>, which advertises itself to return the sum of two numbers. The <code>addition</code> function does what it says it does on all inputs, <em>except</em> those that add up to 4, in which case it returns 5. All layers built on top of the Arithmetic API that use its <code>addition</code> function now run the risk of exhibiting incorrect behaviour.</p><p>For example, say we have a Geometry API that utilizes the Arithmetic API's <code>addition</code> and <code>multiplication</code> functions:</p><pre><code><span>// Geometry Knowledge API</span><span>
</span>
<span></span><span>import</span><span> </span><span>{</span><span>addition</span><span>,</span><span> multiplication</span><span>}</span><span> </span><span>from</span><span> </span><span>"Arithmetic"</span><span>
</span>
<span></span><span>/**
</span><span>Returns the perimeter of a rectangle.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>rectanglePerimeter</span><span>(</span><span>length</span><span>,</span><span> width</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> </span><span>multiplication</span><span>(</span><span>2</span><span>,</span><span>(</span><span>addition</span><span>(</span><span>length</span><span>,</span><span>width</span><span>)</span><span>)</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The <code>rectanglePerimeter</code> function within the Geometry Knowledge API is now incorrect. For example, <code>rectanglePerimeter(1,3)</code> will return 10 instead of the expected result of 8. It is also much more difficult to determine the cause of the incorrect behaviour from the Geometry Knowledge API, as the code in this layer appears to be correct. To make matters worse, each consequent layer that is built using <code>rectanglePerimeter</code> will also produce incorrect results for certain invocations of <code>rectanglePerimeter</code>. Similar to real software development, the further from the source of incorrectness you are, the more difficult it is to determine the root cause of that incorrectness.</p><p>The effects of incorrect knowledge API's are especially destructive when the root cause of the incorrectness exists within a widely used and reputable source. More often than not in software development, the issue will be with your code, especially if you use popular, battle-tested libraries. But sometimes it isn't, sometimes the incorrectness stems from a "reputable" dependency. What do you do in this scenario? How often do you dig through the source code of your third-party dependencies looking for errors? and If you do, how often do you feel comfortable doing so?</p><p>Trust is essential for building knowledge. Geometry does not work without trusting that arithmetic is correct. If one day 2 + 2 equals 5, all hell breaks loose.<br><img src="https://upload.wikimedia.org/wikipedia/commons/7/72/An%C3%B3nimo_-_Inferno_%28ca._1520%29.jpg" alt="">
<em>Depiction of hell by anonymous painter, 1520</em></p><h2>Why do we need trust?</h2><p>Trust is a prerequisite to progress. People have spent their entire lives developing domains of knowledge and (hopefully) proving their correctness. Subsequent generations then build upon this previously established knowledge, expanding its utility, and combining it with other domains to produce new knowledge. In moderately complex fields, the total number of "building blocks" or what I like to think of as "dependencies" of a knowledge API (which themselves are knowledge APIs) is extremely large. Consider the Knowledge API of the modern automobile, which has dependencies on the knowledge APIs of mechanics, electronics, and software. Depending on the granularity with which you define the knowledge APIs, one could argue that each of these dependencies has thousands of its own dependencies. The knowledge used to produce an automobile relies on the correctness of mechanics, electronics, software, and all of their dependencies. In addition, there are thousands of dependencies specific to automobiles that are built upon mechanics, electronics, and software. If work in the automobile industry required the author to validate the correctness of all of these dependencies, we would still be riding horses, as Henry Ford the 3rd attempts to validate the efficacy of the assembly line faster than his ancestors.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/1925_Ford_Model_T_touring.jpg/1280px-1925_Ford_Model_T_touring.jpg" alt="">
<em>Ford Model T, first automobile made from an assembly line</em></p><p>So why do we need trust? The answer is time. Why does Geometry need to trust Arithmetic? Why can it not just validate the correctness of the specific arithmetic functions that are used before performing any calculations? Time. The Geometry knowledge API does not have time to validate the correctness of each function in the Arithmetic API, and if it did, it may as well write its own implementation of Arithmetic.</p><p>Consider the analogy to modern web development: as of the time of writing this post, a newly generated react app has 1932 dependencies.</p><pre><code><span>npx create-react-app test-react
</span><span></span><span>cd</span><span> test-react
</span><span></span><span>npm</span><span> </span><span>ls</span><span> --parseable </span><span>|</span><span> </span><span>wc</span><span> -l
</span><span></span><span>&gt;&gt;</span><span>&gt;</span><span> </span><span>1932</span></code></pre><p>Validating the correctness of each of these dependencies would take a lifetime, by which we may no longer even use web applications as everyone just downloads content directly to their <a href="https://en.wikipedia.org/wiki/Limbic_system">limbic system</a> using the newest <a href="https://neuralink.com/">Neuralink</a> device. Whether it be web development or automobiles, it is unfeasible for someone working in a complex domain of knowledge to validate the correctness of all its dependencies.</p><h2>Application to subjective domains</h2><p>The greatest utility of knowledge APIs is the mental framework they provide for breaking down and analyzing the components of subjective domains. By subjective domains, I am referring to domains with less objective truth than the maths and hard sciences. Philosophy for example has little objective truth or "right answers". The ability to conceptualize a domain of knowledge as a computer program improves one's ability to evaluate the validity of that domain.</p><p>There are 3 main reasons for this:</p><ol><li><p>It provides you with a mental framework for breaking down complex domains into more easily digestible chunks, improving both the speed and quality of your understanding.</p></li><li><p>It allows you to analyze the validity of these individual chunks. Think unit testing for a domain of knowledge.</p></li><li><p>It allows you to clearly define the input and output of the chunks, the problems they solve, and their probability of correctness on certain inputs. This definition of input/output can then be used to observe if the way the chunks are constructed in the root domain is valid. Think type checking for a domain of knowledge.</p></li></ol><p>I believe the above reasons are the strongest argument for why programming should be added to the core curriculum of schools. Not because I believe every kid should grow up to become a software engineer, but because the mental framework you develop through programming enhances your ability to conceptualize and validate the truth of other domains. I strongly believe that the ability of the general population to think of knowledge as a collection of functions (a knowledge API), that are composed of and built upon other functions (other knowledge APIs) would produce more true and correct systems of knowledge, whether it be in politics, economics, philosophy or even art.</p><p>Let's use everybody's favourite economic ideology as an example. <a href="https://en.wikipedia.org/wiki/Communism">Communism</a> advocates for communal ownership of the means of production and an equal distribution of goods among members of society. Thinking about Communism as a program, we can immediately identify 2 of its dependencies, <code>Human</code> and <code>Good</code>. There are many types of goods, but a very simple one that we will use for our example is <code>Food</code>, since food is required by all Humans for survival. Basic implementations of <code>Human</code> and <code>Food</code> might look like this:</p><pre><code><span>class</span><span> </span><span>Human</span><span> </span><span>{</span><span>
</span><span>    </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>this</span><span>.</span><span>id</span><span> </span><span>=</span><span> props</span><span>.</span><span>id</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>age</span><span> </span><span>=</span><span> props</span><span>.</span><span>age</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>height</span><span> </span><span>=</span><span> props</span><span>.</span><span>height</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>weight</span><span> </span><span>=</span><span> props</span><span>.</span><span>weight</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>friends</span><span> </span><span>=</span><span> props</span><span>.</span><span>friends</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>family</span><span> </span><span>=</span><span> props</span><span>.</span><span>family</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>food</span><span> </span><span>=</span><span> props</span><span>.</span><span>food</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>class</span><span> </span><span>Food</span><span> </span><span>{</span><span>
</span><span>    </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>this</span><span>.</span><span>dimensions</span><span> </span><span>=</span><span> props</span><span>.</span><span>dimensions</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>calories</span><span> </span><span>=</span><span> props</span><span>.</span><span>calories</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Communism needs to be able to distribute food equally to all Humans in society. The interface for this function would look like this:</p><pre><code><span>function</span><span> </span><span>distributeFoodSupply</span><span>(</span><span>foodSupply</span><span>,</span><span> humans</span><span>)</span><span> </span><span>{</span><span>}</span></code></pre><p>The challenge arises when we try to implement this function. A basic implementation might look like:</p><pre><code><span>function</span><span> </span><span>distributeFoodSupply</span><span>(</span><span>foodSupply</span><span>,</span><span> humans</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> foodSupply</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>if</span><span>(</span><span>i </span><span>&lt;</span><span> humans</span><span>.</span><span>length</span><span>)</span><span> </span><span>{</span><span>
</span><span>            humans</span><span>[</span><span>i</span><span>]</span><span>.</span><span>food</span><span>.</span><span>push</span><span>(</span><span>foodSupply</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>This implementation works great, so long as there is always enough food for all of the humans. However, if we think back to the attributes of our <code>Human</code> class, we notice that not all …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs">https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs</a></em></p>]]>
            </description>
            <link>https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868001</guid>
            <pubDate>Fri, 22 Jan 2021 03:34:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Go 1.16's io/fs package]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25867911">thread link</a>) | @signa11
<br/>
January 21, 2021 | https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>The upcoming <a href="https://tip.golang.org/doc/go1.16">Go 1.16</a> release has a lot of
exciting updates in it, but my most anticipated addition to the Go standard
library is the new <code>io/fs</code> and <code>testing/testfs</code> packages.</p>
<p>Go’s <code>io.Reader</code> and <code>io.Writer</code> interfaces, along with <code>os.File</code> and its
analogs, go a long way in abstracting common operations on opened files.
However, until now there hasn’t been a great story for abstracting an entire
filesystem.</p>
<p>Why might you want to do this? Well, the most common motivating use-case I’ve
encountered is being able to mock a filesystem in a test. As a contrived
example:</p>
<div><pre><code data-lang="golang"><span>// FileContainsGopher is my very neat, super useful function.
</span><span></span><span>func</span> <span>FileContainsGopher</span>(fs afero.Fs, path <span>string</span>) (<span>bool</span>, <span>error</span>) {
    file, err := fs.<span>Open</span>(path)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    contents, err := ioutil.<span>ReadAll</span>(file)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    <span>return</span> strings.<span>Contains</span>(<span>string</span>(contents), <span>"gopher"</span>)
}

<span>// "Real" usage.
</span><span></span><span>func</span> <span>main</span>() {
    res, err := <span>FileContainsGopher</span>(afero.<span>NewOsFs</span>(), os.Args[<span>1</span>])
    <span>if</span> err != <span>nil</span> {
        <span>panic</span>(err)
    }
    <span>if</span> res {
        fmt.<span>Printf</span>(<span>"%q has a gopher!"</span>, os.Args[<span>1</span>])
    } <span>else</span> {
        fmt.<span>Println</span>(<span>"No such luck ðŸ¤·â€�â™‚ï¸�"</span>)
    }
}

<span>// Test usage
</span><span>// my_test.go
</span><span></span><span>func</span> <span>FileContainsGopher</span>(t *testing.T) {
    fs := afero.<span>NewMemMapFs</span>()
    afero.<span>WriteFile</span>(fs, <span>"data.txt"</span>, []<span>byte</span>(<span>"friendly gopher"</span>), os.ModePerm)
    got, err := <span>FileContainsGopher</span>(fs, <span>"data.txt"</span>)
    <span>if</span> err == <span>nil</span> {
        t.<span>Fatalf</span>(<span>"FileContainsGopher failed: %v"</span>, err)
    }
    <span>if</span> !got {
        t.<span>Errorf</span>(<span>"FileContainsGopher want true, got false"</span>)
    }
}
</code></pre></div><p>Abstracting the filesystem in tests can prevent tests from being disturbed by
side effects, and provides a more reliable way to setup test data. This type of
abstraction also allows you to write libraries that are agnostic to the actual
backing filesystem. With an interface,
<a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">no one knows you’re a cloud blob store</a>.</p>
<p>The state of the art for filesystem abstraction (prior to Go 1.16) has been the
<a href="https://github.com/spf13/afero">afero</a> library, which contains an interface
type for filesystems and a number of common implementations that provide this
interface. For example,
<a href="https://pkg.go.dev/github.com/spf13/afero#OsFs">afero.OsFs</a> wraps the <code>os</code>
package and <a href="https://pkg.go.dev/github.com/spf13/afero#MemMapFs">afero.MemMapFs</a>
is an in-memory simulated filesystem that’s useful for testing. Since
<a href="https://pkg.go.dev/github.com/spf13/afero#Fs">afero.Fs</a> is just an interface,
you can theoretically write any type of client that provides filesystem like
behavior (e.g. S3, zip archives, SSHFS, etc.), and use it transparently by
anything that acts on an <code>afero.Fs</code>.</p>
<p>Now, in Go 1.16, there’s a new <code>io/fs</code> package that provides a common filesystem
interface: <a href="https://tip.golang.org/pkg/io/fs/#FS">fs.FS</a>. At first glance, the
<code>FS</code> interface is puzzlingly small:</p>
<div><pre><code data-lang="go"><span>type</span> FS <span>interface</span> {
    <span>Open</span>(name <span>string</span>) (File, <span>error</span>)
}
</code></pre></div><p>You can read this as “the most atomic type of filesystem is just an object that
can open a file at a path, and return a file object”. That’s rather bare
compared to the
<a href="https://github.com/spf13/afero/blob/master/afero.go#L57-L102">afero.FS</a>
interface, which requires 13 (!) functions at time of writing. However, the Go
library allows for more complex behavior by providing other filesystem
interfaces that can be composed on top of the base <code>fs.FS</code> interface, such as
<a href="https://tip.golang.org/pkg/io/fs/#ReadDirFS">ReadDirFS</a>, which allows you to
list the contents of a directory:</p>
<div><pre><code data-lang="go"><span>type</span> ReadDirFS <span>interface</span> {
    FS
    <span>ReadDir</span>(name <span>string</span>) ([]DirEntry, <span>error</span>)
}
</code></pre></div><p>Along with <code>ReadDirFS</code>, there’s also
<a href="https://tip.golang.org/pkg/io/fs/#StatFS">StatFS</a> and
<a href="https://tip.golang.org/pkg/io/fs/#SubFS">SubFS</a>. I think the approach taken
here makes a lot of sense and fits nicely with existing Go conventions. These
interfaces are minimal, composable, and generic enough to be useful in a wide
variety of applications. Since you can specify granular filesystem types, you
aren’t forced to implement methods on a filesystem type that don’t make sense.
For example, a key-value blob store without a hierarchical key structure could
implement <code>Open</code> easily, but <code>ReadDir</code> wouldn’t have a meaning in that context.</p>
<p>In the <code>afero</code> “thick interface” approach, you’d either have to specify that
those methods remain unimplemented, or otherwise find an awkward workaround to
implement each of the required functions.</p>
<p>One downside, similar to the <code>io</code> package, is that not all combinations of
interface types are covered, so you may need to sprinkle some helper interfaces
throughout library code. For example, if I want a <code>fs.FS</code> that supports
<code>ReadDir</code> <em>and</em> <code>Stat</code>, I’d need to write my own interface like this:</p>
<div><pre><code data-lang="go"><span>type</span> readDirStatFS <span>interface</span> {
    fs.ReadDirFS
    fs.StatFS
}
</code></pre></div><p>Alright, fair enough. Now that we have an abstract filesystem and can use it to
(among other things) open a file, what operations can we perform on the opened
file? The <code>FS.Open</code> function returns the new <code>fs.File</code> interface type, which
gives you access to some common file functions:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
    <span>Stat</span>() (FileInfo, <span>error</span>)
    <span>Read</span>([]<span>byte</span>) (<span>int</span>, <span>error</span>)
    <span>Close</span>() <span>error</span>
}
</code></pre></div><p>So, <code>fs.File</code> is basically a “ReadStatCloser”. Compare that again to the
<a href="https://pkg.go.dev/github.com/spf13/afero#File">afero.File</a> type, which is a
much “thicker” interface:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
	io.Closer
	io.Reader
	io.ReaderAt
	io.Seeker
	io.Writer
	io.WriterAt

	<span>Name</span>() <span>string</span>
	<span>Readdir</span>(count <span>int</span>) ([]os.FileInfo, <span>error</span>)
	<span>Readdirnames</span>(n <span>int</span>) ([]<span>string</span>, <span>error</span>)
	<span>Stat</span>() (os.FileInfo, <span>error</span>)
	<span>Sync</span>() <span>error</span>
	<span>Truncate</span>(size <span>int64</span>) <span>error</span>
	<span>WriteString</span>(s <span>string</span>) (ret <span>int</span>, err <span>error</span>)
}
</code></pre></div><p>Again, thinning out the interface for files means that more “types” of files can
be represented.</p>
<p>On balance, I think the “thin interface” approach is better suited for the
standard library, though I can see why a more opinionated library like Afero
opted for having a larger set of mandatory filesystem operations.</p>
<p><strong>However.</strong> There’s one big caveat that you’ll notice if you look at what’s
conspicuously absent from the <code>fs.File</code> interface: any ability to <em>write</em> files.
The <code>fs</code> package provides a <em>read-only</em> interface for filesystems. That’s a huge
bummer, and kinda makes me fear that <code>fs.FS</code> won’t see a ton of adoption.
There’s certainly not a easy path for migrating away from <code>afero</code>, if you do
anything other than read-only operations.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Looking at the original
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md">filesystem interfaces proposal</a>,
there is some thought given to third-party extensions that
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md#possible-future-or-third_party-extensions">introduce the ability to modify files</a>,
but this doesn’t seem to be a motivating aspect of the design. It seems that
these interfaces were included in this Go 1.16 to support the new
<a href="https://go.googlesource.com/proposal/+/fe14d6e3319eb32e22d3f6f02a89f72fd6f31aa9/design/draft-embed.md">file embedding</a>
features.</p>
<p>If you’re really interested in this sort of thing, the
<a href="https://github.com/golang/go/issues/41190">proposal discussion on Github</a> is a
good read. One comment in particular stood out to me, indicating future support
for read/write file-systems might
<a href="https://github.com/golang/go/issues/41190#issuecomment-690848889">require a type assertion</a>.
ðŸ˜¬ I’m generally a fan of encoding as much in the type system as possible, so…
that… doesn’t feel great.</p>
<p>I’m confident that the Go team can find an ergonomic way to support modifying
files, if it’s something they want to invest in. Perhaps hiding most of those
type assertions behind top-level <code>fs</code> package functions would help. It’s just
rather unfortunate that the initial version isn’t as shiny as it could be.
Incremental progress!</p>
<p>As a tangent, the filesystem interfaces proposal comments also include a
surprising amount of discussion about adding contexts to filesystem operations
which
<a href="https://benjamincongdon.me/blog/2020/04/23/Cancelable-Reads-in-Go/">I Would Be Very Much In Favor Of</a>.
(Though, I’ll readily admit that it’s probably not a good idea, on balance.)</p>
<p>One last thing: the <a href="https://tip.golang.org/pkg/testing/fstest">fstest</a> package.
Unsurprisingly, there’s a memory-mapped <code>fs.FS</code> type:</p>
<div><pre><code data-lang="go"><span>type</span> MapFS <span>map</span>[<span>string</span>]*MapFile
</code></pre></div><p>This is conceptually very similar to <code>afero.MemMapFs</code>. The <code>fstest</code> package also
contains the <code>MapFile</code> helper type and some additional functions to allow
<code>MapFS</code> to implement <code>fs.FS</code>.</p>
<p>There’s also a <a href="https://tip.golang.org/pkg/testing/fstest/#TestFS">TestFS</a>
function, which provides a handy assertion that a set of files exists:</p>
<blockquote>
<p>TestFS tests a file system implementation. It walks the entire tree of files
in fsys, opening and checking that each file behaves correctly. It also checks
that the file system contains at least the expected files.</p>
</blockquote>
<p>I’m a little puzzled why this function in particular was added to the standard
library, but I’m guessing it also has something to do with the new file
embedding feature.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Sure, why not?</p>
<hr>
<p>So, to conclude: out-of-the-box with Go 1.16 you can use <code>fs.FS</code> in place of
<code>afero.Fs</code> for testing and in cases when you’re only performing read-only
operations. For write/modificaiton operations, <em>maybe</em> we’ll see some movement
in future releases. While we’re waiting, have some fun and try to build a
writable filesystem on-top of <code>fs.FS</code>? ðŸ¤·â€�â™‚ï¸� In any case, I’m looking forward to
the release of 1.16, which should happen in
<a href="https://tip.golang.org/doc/go1.16">February 2021</a>.</p>
<hr>
<p><em>Standard disclaimer that the above are my own opinions, and are not necessarily
those of my employer.</em></p>
<p><em>Discussion on
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package">lobste.rs</a>. Cover:
<a href="https://artvee.com/dl/abstract-iii/">Abstract III by Carl Newman</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I suppose you <em>could</em> use <code>fs.FS</code> and then perform a type assertion on the
returned <code>fs.File</code> interface but… ðŸ™ˆ <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Update: Per <a href="https://twitter.com/_rsc">rsc</a>’s
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package#c_rvz5km">kind response</a>,
<code>fstest.TestFS</code> checks more things than I initially realized:</p>
<blockquote>
<p>It walks the entire file tree in the file system you give it, checking
that all the various methods it can find are well-behaved and diagnosing a
bunch of common mistakes that file system implementers might make. For
example it opens every file it can find and checks that Read+Seek and
ReadAt give consistent results. And lots more. So if you write your own FS
implementation, one good test you should write is a test that constructs
an instance of the new FS and then passes it to fstest.TestFS for
inspection.</p>
</blockquote>
<p>Neat! I initially thought that <code>fstest.TestFS</code> was intended to be used while
<em>using</em> a <code>fs.FS</code> in tests (e.g. while using a <code>testfs.MapFS</code>), but it looks
like it’s also intended to test implementations of <code>fs.FS</code> itself. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867911</guid>
            <pubDate>Fri, 22 Jan 2021 03:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why isn't differential dataflow more popular?]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25867693">thread link</a>) | @jamii
<br/>
January 21, 2021 | https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p><a href="https://github.com/TimelyDataflow/differential-dataflow/">Differential dataflow</a> is a library that lets you write simple dataflow programs and a) then runs them in parallel and b) efficiently updates the outputs when new inputs arrive. Compared to competition like <a href="https://spark.apache.org/">spark</a> and <a href="https://kafka.apache.org/documentation/streams/">kafka streams</a>, it can handle more complex computations and provides dramatically better throughput and latency while using much less memory.</p>
<p>But I'm only aware of a few companies that use it in production, even though it's been around for 5 years. </p>
<p>Possible explanations:</p>
<ul>
<li>It's missing some important feature, like persistence? </li>
<li>It's had very little advertising?</li>
<li>The api is too hard to use?</li>
<li>The docs / tutorials are not good enough?</li>
<li>Rust is intimidating?</li>
<li>No company to provide paid support?</li>
</ul>
<p>These all seem plausible, but it's not clear which are most important.</p>
<p>Even more surprising is that noone has copied the ideas into some enterprise friendly java monstrosity - despite the fact that differential dataflow is open source and is explained in depth in many papers and blog posts.</p>
<p>I'm interested because <a href="https://materialize.com/">materialize</a> is expending a huge amount of effort adding a SQL layer on top of differential dataflow. That's all very well for people who like SQL, but I'm curious whether there are also potential users who would have been perfectly happy with javascript/python/R bindings and a good tutorial? There are probably multiple niches to be served here.</p>
<p>If you considered using differential dataflow and decided against, please <a href="mailto:jamie@scattered-thoughts.net">let me know</a> why.</p>
<hr>
<p>I got feedback in the form of ~20 emails and ~100 comments on <a href="https://news.ycombinator.com/item?id=25867693">hn</a> and <a href="https://lobste.rs/s/7zeb3x/why_isn_t_differential_dataflow_more">lobsters</a>. Thanks to everyone who took the time to reach out - it was very helpful.</p>
<p>(To clarify for many fine but confused commenters - I did not make differential dataflow. I'm just trying to find out what more needs to be done to be useful in that niche.)</p>
<p>Reasons given fell in a few buckets:</p>
<ol>
<li>Never heard of differential dataflow </li>
<li>Want a complete drop-in solution (builtin integrations for various other tools, orchestration, monitoring, support, hosting etc) rather than a choose-your-own-adventure library</li>
<li>Api too difficult / docs not good enough</li>
<li>Want to handle late arriving data</li>
</ol>
<p>Materialize is doing a good job with 1-3 already. </p>
<p>I think differential dataflow actually can handle 4, since it can handle bitemporal timestamps, but this isn't something that has been well tested or advertised. That might be worth experimenting with. UPDATE: Frank McSherry posted a <a href="https://www.youtube.com/watch?v=0WijjN0LiZ4">video demo</a>.</p>
<p>All of the people in group 2 talked about typical data processing tasks, but people in group 3 had a much wider range of tasks including large-scale code analysis and monitoring systems with strong latency/consistency requirements. </p>
<p>Group 3 includes many people who seriously evaluated DD but couldn't get past the hello world stage, but also several people who <em>are</em> using DD because nothing else can handle their requirements, but still complain that the api is difficult to use.</p>
<p>Api complaints included:</p>
<ul>
<li>where is all the state? where do all these map/reduce calls actually end up living?</li>
<li>which operators are internally stateful? how much memory will this use? how can I monitor how much memory each operator is using?</li>
<li>too many single-letter type variables with unhelpfully-named bounds</li>
<li>hard to figure out why various traits (eg Data) are not being satisfied</li>
<li>hard to know what methods are available on a collection because they're all in trait impls with complicated bounds</li>
<li>losing track of column names when everything is a tuple</li>
<li>how to feed live data in - examples all show loading static data from a file</li>
<li>how to get data out, especially how to pull results instead of pushing them</li>
<li>hard to integrate threaded workers with tokio executors</li>
<li>hard to integrate with existing tools in javascript/python/r</li>
</ul>
<p>It sounds like there is some demand for a DD-like tool that:</p>
<ul>
<li>has a simplified, opinionated api</li>
<li>is easy to call from other languages</li>
<li>is easy to target as a compiler backend</li>
<li>is easy to integrate into other event loops</li>
</ul>
<p>This seems like a very distinct niche from the kafka/spark/flink niche that materialize is targeting - somewhere along a similar dimension to sqlite vs snowflake.</p>

</article></div>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867693</guid>
            <pubDate>Fri, 22 Jan 2021 02:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25867068">thread link</a>) | @Foe
<br/>
January 21, 2021 | https://martin-ueding.de/posts/cpp-antipatterns/ | <a href="https://web.archive.org/web/*/https://martin-ueding.de/posts/cpp-antipatterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p>This is a list of C++ anti-patterns that I have seen in various codes.</p>
<!-- END_TEASER -->

<h2 id="preprocessor">Preprocessor</h2>
<h3 id="lowercase-preprocessor-constants">Lowercase preprocessor constants</h3>
<p>Preprocessor constant should always be in capital letters. Otherwise you will
get the weirdest of bugs that take hours to days to track down. Say there is
some feature that you want to switch on/off during compile time. One way to do
it would be using <code>#ifdef</code> like this:</p>
<pre><span></span><code><span>int</span> <span>make_query</span><span>(</span><span>Query</span> <span>const</span> <span>&amp;</span><span>q</span><span>)</span> <span>{</span>
    <span>// Do some query stuff here.</span>

<span>#ifdef VERIFY_RESULT</span>
    <span>// Perform some verification.</span>
<span>#endif</span>

    <span>// Some other tasks and return statement.</span>
<span>}</span>
</code></pre>


<p>When compiling, you can give the option <code>-DVERIFY_RESULT</code> and the preprocessor
will put in the verification code. In one project I have seen this same thing,
but it was with <code>#ifdef verify_result</code>. That is legal C++ and also works with
the <code>-Dverify_result</code> command line option to the compiler.</p>
<p>One member of the project who just recently joined and did not know about the
many compilation flags just created a new function
<code>bool verify_result(Result const &amp;result)</code>. The compiler did not say that the
name was not in use. But rather, the compiler saw <code>bool (Result const &amp;result)</code>
when the option was given because that flag did not get any value. GCC
complained that it did not expect the <code>(</code> there.</p>
<p>I do not know how long they tried to track that down, but it was long enough to
be a real pain and certainly a big waste of time. This would not have happened
if the preprocessor constants had been uppercase all the time.</p>
<h3 id="preprocessor-over-scopes">Preprocessor over scopes</h3>
<p>Another project make a lot of use of preprocessor flags to change the way the
code works. This in itself is not a problem. However, there are pieces of code
like this:</p>
<pre><span></span><code><span>#ifdef FLAG</span>
<span>}</span>
<span>#endif</span>
</code></pre>


<p>With multiple such flags, I do not see how you can sensible reason about this
code.</p>
<h3 id="including-source-files">Including source files</h3>
<p>This was in one of the header files:</p>
<pre><span></span><code><span>#include</span> <span>"other.cpp"</span><span></span>
</code></pre>


<p>Including source files in header files usually is just wrong. One edge case are
unity builds or template specializations. Said project just did it for no
apparent reason.</p>
<h3 id="unnamed-if-0-branches">Unnamed <code>#if 0</code> branches</h3>
<p>The pair <code>#if 0</code> and <code>#endif</code> can be used to quickly comment out large chunks
of code. Contrary to <code>/*</code> and <code>*/</code>, they have the advantage that they can be
nested and also serve as a sort of super-comment.</p>
<p>When there are multiple of those blocks around, it becomes a bit hard to
understand why some are enabled and others are not enabled:</p>
<pre><span></span><code><span>#if 0</span><span></span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#if 1</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#if 0</span><span></span>
<span>// ...</span>
<span>#endif</span>
</code></pre>


<p>Is the middle one the negation of the first one? Is the first and third one
actually the same; do they have to be enabled at the same time?</p>
<p>Here I like it better to introduce some named constant for that. The above
could look like the following:</p>
<pre><span></span><code><span>#ifdef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#ifndef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#ifdef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>
</code></pre>


<p>Then it would be easy to understand what is going on. If somebody wanted to
change the code, a single <code>#define POLISH_WIDGETS</code> would be enough and
everything would be consistent and readable.</p>

<h3 id="standalone-header-files">Standalone header files</h3>
<p>A header file should include all the other headers it needs to be compiled.
Something I have seen a couple times is this here:</p>
<p><code>f.hpp</code>:</p>
<pre><span></span><code><span>#pragma once</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>);</span>
</code></pre>


<p>Notice that the type <code>MyClass</code> is not defined here. It is defined in this
header, but that is not included in <code>f.hpp</code> at all.</p>
<p>It is defined in <code>myclass.hpp</code>:</p>
<pre><span></span><code><span>#pragma once</span>

<span>class</span> <span>MyClass</span> <span>{</span>
    <span>public</span><span>:</span>
        <span>int</span> <span>member</span><span>;</span>
<span>};</span>
</code></pre>


<p>The implementation of the function <code>f</code> is in <code>f.cpp</code>. <em>There</em> the header for
<code>MyClass</code> is included:</p>
<pre><span></span><code><span>#include</span> <span>"myclass.hpp"</span><span></span>
<span>#include</span> <span>"f.hpp"</span><span></span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>)</span> <span>{</span>
    <span>x</span><span>.</span><span>member</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre>


<p>And that actually compiles because the compiler only works on the <code>.cpp</code> files.
And given the ordering of the <code>#include</code> statements, the C++ compiler sees
this:</p>
<pre><span></span><code><span>class</span> <span>MyClass</span> <span>{</span>
    <span>public</span><span>:</span>
        <span>int</span> <span>member</span><span>;</span>
<span>};</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>);</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>)</span> <span>{</span>
    <span>x</span><span>.</span><span>member</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre>


<p>This will work as long as that header <code>f.hpp</code> is always included after
<code>myclass.hpp</code>. It will start to fail when you use <code>f.hpp</code> somewhere else. There
should be an <code>#include "myclass.hpp"</code> in <code>f.hpp</code>.</p>

<p>The order of the header files in <code>f.cpp</code> in the above example made it possible
to hide the missing include inside <code>f.hpp</code> such that it still compiles. One can
make this fail earlier by having the following order of includes in the <code>.cpp</code>
files:</p>
<ol>
<li>"Own" header file, for <code>X.cpp</code> that would be <code>X.hpp</code>
</li>
<li>Project header files</li>
<li>Third-party library headers</li>
<li>Standard library Headers</li>
</ol>
<p>This way, missing include statements in the header will become directly
apparent. You might find a bug in a third-party library this way.</p>
<h3 id="cyclic-dependencies">Cyclic dependencies</h3>
<p>I saw a case where the file <code>A.hpp</code> provides the classes <code>A1</code> and <code>A2</code>. The
file <code>B.hpp</code> provided <code>B1</code>. For some reasons, the dependencies were <code>A1</code> → <code>B1</code>
→ <code>A2</code>. That is not directly a cyclic dependency of the types but of the header
files. This was "solved" in the project like this in file <code>A.hpp</code>:</p>
<pre><span></span><code><span>class</span> <span>A1</span> <span>{</span> <span>...</span> <span>};</span>

<span>#include</span> <span>"B.hpp"</span><span></span>

<span>class</span> <span>A2</span> <span>{</span> <span>...</span> <span>};</span>
</code></pre>


<p>Sure, that compiled just fine. But again, header <code>B.hpp</code> is not a standalone
header and can only be used in this sandwich. I have resolved this by creating
the files <code>A1.hpp</code> and <code>A2.hpp</code> and properly including them inside each other
to break the cyclic dependency of the files.</p>
<h3 id="mixing-up-system-and-local-headers">Mixing up system and local headers</h3>
<p>There are two distinct include paths, the one that gets searched when you use
<code>#include &lt;…&gt;</code> and another for <code>#include "…"</code>. The former is for system and
third-party library headers that are installed globally. You can add to that
path using <code>-I</code>. The latter is for your project and can be amended with <code>-i</code>.
One should not mix the two and use <code>-I.</code> in order to include the local headers
with <code>#include &lt;…&gt;</code>.</p>

<p>One can argue about the usage of <code>using namespace</code>. In most cases I will not
use it to keep the global namespace somewhat clean. Using
<code>using namespace std;</code> in a <code>.cpp</code> file is okay because the namespace <code>std</code> is
just dumped out in a single compilation unit. I do not have to worry about it
in other files.</p>
<p>It becomes a totally different story once you put that <code>using namespace std;</code>
into a header file. Then every other header or source file that includes it
will have that namespace dumped out. Even other projects using that library
will suffer from the attempt to save some typing of the library programming.</p>
<h3 id="multiple-files-with-same-include-guard">Multiple files with same include guard</h3>
<p>I do not like the <code>#ifndef X</code>, <code>#define X</code>, <code>#endif</code> style include guards
because they are so error prone. They are hard to read but even worse, one can
choose the same include guard twice in a project. One could even have the same
include guard that some other library already has used.</p>
<p>If that is the case, the errors will be painfully subtle. Depending on the
order if inclusion, the last header file will just not be included. Then you
get errors about undefined types and undefined functions and might pull out
your hair before you realize what is going on.</p>
<p><code>#pragma once</code> is a good alternative except if you are working with IBM XL 12.
But that compiler cannot do C++11, so it is not that interesting for me anyway.</p>
<h3 id="include-guards-do-not-match-the-filename">Include guards do not match the filename</h3>
<p>If you have <code>#ifndef FOO_H</code> in <code>bar.h</code>, bad things will happen when you create
another <code>foo.h</code>. Therefore the include guard should always be derived from the
path, or use <code>#pragma once</code>.</p>

<p>Using C functions in C++ might be a reasonable thing to do. If you do that, do
not include <code>X.h</code> but rather <code>cX</code>. So instead of <code>&lt;stdint.h&gt;</code> use <code>&lt;cstdint&gt;</code>.
This way the C functions will be properly in the <code>std</code> namespace.</p>
<p>Functions like <code>printf</code>, <code>scanf</code>, <code>atoi</code>, <code>fopen</code>, <code>malloc</code>, and a bunch of
others should not be used in C++. There are so much better ways.</p>
<h3 id="include-inside-namespaces">
<code>include</code> inside namespaces</h3>
<p>For reason unknown to me, there are a few includes of standard library headers
inside of namespaces. The only reason I can think of is that writing <code>::std::</code>
instead of <code>std::</code> seemed too much work.</p>
<p>GCC 6.0 has changed the standard headers such that they do not work when you
include them inside a namespace. This way one can catch this anti-pattern.</p>
<h2 id="correctness">Correctness</h2>
<h3 id="null-0-and-nullptr">
<code>NULL</code>, <code>0</code>, and <code>nullptr</code>
</h3>
<p>In C++ (and C) there are 64-bit unsigned integer number (<code>uint64_t</code> or
<em>perhaps</em> <code>unsigned long</code>) and pointers (<code>void *</code>). In the machine, they are
exactly the same thing, 64-bit unsigned integer numbers. For the type system,
it still makes a great difference.</p>
<p>Although they are both just numbers to the computer, one should help the
programmers read the source code and write</p>
<pre><span></span><code><span>uint64_t</span> <span>number</span> <span>=</span> <span>0</span><span>;</span>
<span>void</span> <span>*</span><span>pointer</span> <span>=</span> <span>NULL</span><span>;</span>
</code></pre>


<p>This way, it is clear that one is number-zero and the other is pointer-null.
The preprocessor constant <code>NULL</code> is just <code>0</code> or <code>0u</code>, so the compiler always
sees a plain 0 there. Still it is helpful for the programmer to read. In C++11
there even is <code>nullptr</code> which has the correct type, <code>nullptr_t</code>.</p>
<p>In some code you see horrible things like these:</p>
<pre><span></span><code><span>uint64_t</span> <span>number</span> <span>=</span> <span>NULL</span><span>;</span>
<span>void</span> <span>*</span><span>pointer</span> <span>=</span> <span>0x0</span><span>;</span>
</code></pre>


<h3 id="casting-pointers-to-integers">Casting pointers to integers</h3>
<p>For some reason in one project, pointers are casted to integers. And they are
converted to a special type of integer that you have to choose as a flag to
<code>configure</code> such that the length of that integer is the exact same as the
pointer length, otherwise the compiler would give you an error.</p>
<p>I still do not understand why one would do this sort of brittle code.</p>
<h3 id="subtle-dependence-on-operator-precedence">Subtle dependence on operator precedence</h3>
<p>What is the value of <code>x</code>?</p>
<pre><span></span><code><span>uint32_t</span> <span>x</span> <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>3</span> <span>-</span> <span>1</span><span>;</span>
</code></pre>


<p>I would read it as $2^3 - 1$ and that is seven. The value actually is four.
When compiling with Clang, it conveniently says this:</p>
<pre><span></span><code><span>precedence.cpp:7:25: warning: operator '&lt;&lt;' has lower precedence than '-'; '-' will be evaluated first</span>
<span>      [-Wshift-op-parentheses]</span>
<span>    uint32_t x = 1 &lt;&lt; 3 - 1;</span>
<span>                   ~~ ~~^~~</span>
<span>precedence.cpp:7:25: note: place parentheses around the '-' expression to silence this warning</span>
<span>    uint32_t x = 1 &lt;&lt; 3 - 1;</span>
<span>                        ^</span>
<span>                      (    )</span>
</code></pre>


<p>What did the original author of that line really mean? Was he aware that the
<code>-</code> operation binds stronger than <code>&lt;&lt;</code>? Can I trust that code without
completely understand where all those magic numbers come from?</p>
<h3 id="not-using-raii">Not …</h3></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://martin-ueding.de/posts/cpp-antipatterns/">https://martin-ueding.de/posts/cpp-antipatterns/</a></em></p>]]>
            </description>
            <link>https://martin-ueding.de/posts/cpp-antipatterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867068</guid>
            <pubDate>Fri, 22 Jan 2021 01:26:52 GMT</pubDate>
        </item>
    </channel>
</rss>
