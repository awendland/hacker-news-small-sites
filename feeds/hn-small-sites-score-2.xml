<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 02 Nov 2020 12:24:43 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 02 Nov 2020 12:24:43 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[I Failed 2 Side Projects in Under a Year and Lessons Learned]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950005">thread link</a>) | @moeminm
<br/>
October 31, 2020 | https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><code>I feel like I should start off this blog post by mentioning that I am a Product Designer with little to no development skills, so I heavily rely on no-code tools to get my side projects up and running.</code></p>
<p>The idea of creating something that thousands of users could potentially use was just so exciting to me. Over the course of just shy of a year, I worked on 2 projects that made me less than $20, <strong>combined</strong>, so I feel like it's safe to say I can share my experience with you guys and hopefully you'll learn from my mistakes.</p>

<p> <img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604131920818/D9DxXPfJk.png?auto=format&amp;q=60" alt="Custom Size â€“ 3.png"></p>
<p>Oof, designtarget was a wild ride. On 18-8-2019, god knows what happened but I just hopped on Namecheap and purchased the domain <a href="http://designtarget.org/" target="_blank">designtarget.org</a> with no prior experience in web development. I was just so into the idea of creating the 'ultimate design directory' that I really didn't think anything through. How would I monetize the platform? Do I even have a list of resources that I can work with? Where will I market the website? So many questions, and little to no answers.</p>
<p>I remembered seeing an ad for a visual editor plugin on Wordpress called Elementor, it seemed intuitive so I go to Namecheap's cPanel and install Wordpress, purchase a year's subscription to Elementor and I get building. Literally next day I was done, I didn't think the design through, I just wanted to get an MVP out right away, and this atrociousness was born, but I was proud of it. I had no web development knowledge and I made a website, and it felt great.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604132243316/TKr68CyWaA.png?auto=format&amp;q=60" alt="Web 1920 â€“ 1.png"></p>
<p>Naturally, I wanted people to see what I had built, so I go on Reddit and post the website on /r/webdev - no it wasn't a Saturday(you can only post your work on Feedback Saturday on /r/webdev), yes the post was locked. But that doesn't matter, why you ask?</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604132936013/UONs_j1_Z.png?auto=format&amp;q=60" alt="Mask Group 1.png"></p>
<p>8.5k visitors in less than 2 hours of being on reddit when I wasn't supposed to. I knew I was onto something, but a little after the hype died down, it dawned on me, I just missed a huge chance to build an audience. I rushed creating the website that I missed some essentials such as <strong>creating a newsletter sign up</strong> or even just a <strong>blog</strong>.</p>
<p>Fast-forward a few months, I eventually create a newsletter, Instagram page, and even a blog. </p>
<p>ðŸ“§ ~300 newsletter subscribers.</p>
<p>ðŸ“¸ ~400 Instagram followers.</p>
<p>and most importantly, my blogs were ranking on Google. I don't have Search Console screenshots but I had ranked around ~11th or so for a few articles. </p>
<p>I had solved the traffic problem of any side project, but monetization was where this project went downhill. I simply had no monetization plan whatsoever. And this is where the story of designtarget, ends, well, I sold off the project for a measly amount but that was it.</p>
<h3 id="lessons-learned">Lessons learned:</h3>
<p>ðŸ‘‰ No matter how excited you are, keep cool and think things through.</p>
<p>ðŸ‘‰ Traffic is easy, business is hard. </p>
<p>ðŸ‘‰ Think things through, but also do not spend much time working on an MVP.</p>
<p>ðŸ‘‰ It is fine to not know what you're doing.</p>

<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604133785236/39YjxeLlg.png?auto=format&amp;q=60" alt="screencapture-moeminm-github-io-goodcode-2020-10-31-10_42_27.png"></p>
<p>This one is close to my heart, it really is. You can read my <a target="_blank" href="https://www.indiehackers.com/product/good-code/temporarily-pausing-work-on-good-code--MKnKtlnidKMGLMQAuyr">post on IndieHackers</a> to know why I stopped working on Good Code.</p>
<p>The idea originally came to me when I discovered  <a target="_blank" href="http://frontendmentor.io/">Frontend Mentor</a>, by then I had learned HTML, CSS, and a little bit of JavaScript and wanted to improve my skills. I liked FEM, but the free templates were just not the level of design I wanted to work on, queue Good Code.</p>
<p>This time, I was ready, monetization plan was straight-forward, content was ready, community building was in place, newsletter was in place. I cook up a static version of the website using HTML and CSS and release it on Github Pages, you can view Good Code  <a target="_blank" href="https://moeminm.github.io/goodcode">here</a> and straight to reddit I go (and IndieHackers this time as well). </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604134249747/BPvkUcJ5j.png?auto=format&amp;q=60" alt="Mask Group 2.png"></p>
<p>September 3rd, to September 15th. I was onto something, again. Shortly after launching, I view my Gumroad page only to find 2 customers have purchased templates for a total of $10. My first internet money! </p>
<p>I also had people posting their solutions on the <a target="_blank" href="https://www.reddit.com/r/GoodCodeChallenge/">subreddit</a>  I created just for this website, it felt great.</p>
<p>I really wanted to continue working on Good Code, as it stands, it's only hosted on GH Pages, so there's a good chance there <em>could</em> have been more sales had it been on an actual domain. I might resume working on Good Code in a future date, but for now, I'm pausing for reasons listed in the  <a target="_blank" href="https://www.indiehackers.com/product/good-code/temporarily-pausing-work-on-good-code--MKnKtlnidKMGLMQAuyr">IndieHackers post</a>. </p>
<h3 id="lessons-learned">Lessons learned:</h3>
<p>ðŸ‘‰ Spin ideas. I could have just released this as just another website selling Adobe XD templates, but I feel like the 'improve your HTML and CSS skills' twist was what brought this to life.</p>
<p>ðŸ‘‰ Create a community for your side-project.</p>
<p> ðŸ‘‰ Don't be afraid to shut down.</p>
<p>To wrap things up, had I not started designtarget, I wouldn't have learned how to code (albeit being bad at it), had I not learned how to code, I wouldn't have started Good Code and made my first $ from a side-project, who knows what my next had I not started is going to be, but I feel like it might be success.</p>
</div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950005</guid>
            <pubDate>Sat, 31 Oct 2020 09:12:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity in Operating Systems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949983">thread link</a>) | @quyleanh
<br/>
October 31, 2020 | https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html | <a href="https://web.archive.org/web/*/https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Over the last years Iâ€™ve been working on very different operating
systems. Operating systems are usually incredibly complex beasts. I
think there are mainly three drivers of this complexity. Surprisingly
enough, neither of these is having to deal with hardware.</p>

<p>The first one is resource <strong>discovery</strong>, i.e. figuring out how the
computer the OS is running on actually looks like. On x86, this
involves parsing countless bitfields, tables, executing byte code
provided by the firmware, probing individual features, etc. The most
painful example of this Iâ€™ve seen so far is figuring out which
interrupt a particular PCI interrupt line is routed to. Itâ€™s worth a
set of posts, but until then, feel free to checkout <a href="https://habr.com/en/post/501912/">this
description</a>. (If itâ€™s down, itâ€™s
also cached by
<a href="https://webcache.googleusercontent.com/search?q=cache:CXZUV61m7hwJ:https://habr.com/en/post/501912/+&amp;cd=1&amp;hl=en&amp;ct=clnk">Google</a>.)</p>

<p>The second issue is <strong>resource management</strong>. Essentially, how do you
hand out and eventually reclaim all the resources you discovered. For
some workloads performance matters here, so this code is usually
written with speed in mind.</p>

<p>The third reason is that at compile time the <strong>workload</strong> is
unclear. So the kernel has to assume the worst. It must be ready to
start a couple of hundred VMs or create a thousand TCP sockets in a
blink of an eye, because there is no way to know whatâ€™s going to
happen or what the actual requirements are.</p>

<p>A fun exercise is to checkout the <a href="https://elixir.bootlin.com/linux/v5.9.1/source/virt/kvm/kvm_main.c#L739">KVM code for creating
VMs</a>. Try
to follow
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/x86.c#L9904">the</a>
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/vmx/vmx.c#L7059">code</a>
to where the actual VM is created in hardware. <em>Spoiler:</em> There is
none. Itâ€™s all figuring out what the platform can do and then setting
up a bunch of spinlock, mutexes, lists, arrays, structs, â€¦</p>

<p>I donâ€™t want to pick on KVM in particular. I think itâ€™s pretty ok as
far as Linux kernel code goes. Operating System kernel code is mostly
like this: A lot of really mind numbing platform discovery and
resource management code written for speed assuming the worst case
requirements in a language that doesnâ€™t do parsing, resource
management or concurrency well (among other things).</p>

<p>People take this all for granted. But when I look around, I see many
systems that donâ€™t need this complexity and where it is only a safety
and security burden. Consider most appliance-type products, e.g. a
Wi-Fi router. Or a system that runs one service on a cloud VM. You
know everything in advance!</p>

<p>If you read until this point, you are probably asking yourself, where
I am going with this. If you think <a href="https://en.wikipedia.org/wiki/Separation_kernel">separation
kernel</a>, you are
right. My rough plan to write a couple of more posts to flesh out the
idea of doing all the complicated OS parts at compile time and how
this results in an incredibly simple, secure, and efficient system at
runtime. There will be <a href="https://riscv.org/">RISC-V</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://dhall-lang.org/">Dhall</a>,
and <a href="https://www.rust-lang.org/">Rust</a> content.</p>

<p>Stay tuned.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949983</guid>
            <pubDate>Sat, 31 Oct 2020 09:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finland's Covid sniffer dog trial 'extremely positive': researchers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949592">thread link</a>) | @respinal
<br/>
October 30, 2020 | https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nav-container="">
                                        

                
                <div>
                                <nav>
    <ol>
                    <li>                                        <a href="https://www.rfi.fr/en/" aria-label="Back to homepage"><svg xmlns="http://www.w3.org/2000/svg" viewBox="9299 -3984 9.748 12"><path fill="currentColor" d="M-1805,3480h-3v-7.125l4.875-4.875,4.874,4.875V3480H-1801v-4h-4v4Z" transform="translate(11107 -7452)"></path></svg>
</a></li>
                    <li><span>/</span>                                        <a href="https://www.rfi.fr/en/live-news/">Live news</a></li>
            </ol>
</nav>
    
                
    <article>
        

                        

            

                            <p><span>Issued on: <time datetime="2020-10-28T16:38:05+00:00" pubdate="pubdate">28/10/2020 - 17:38</time></span></p>
                    

    
                                    <div>
                                                                                                                
<figure>
    <p><img src="https://s.rfi.fr/media/display/7006f538-193c-11eb-bfd9-005056a964fe/w:310/p:16x9/61e9874f1c836ef58147abd96c3dad75be8c1d7f.jpg" alt="Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall." data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/7006f538-193c-11eb-bfd9-005056a964fe\/&quot;,&quot;filename&quot;:&quot;61e9874f1c836ef58147abd96c3dad75be8c1d7f.jpg&quot;,&quot;ratio&quot;:null,&quot;displayFormat&quot;:&quot;16x9&quot;}">
    </p>
                        <figcaption>
                <span>Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall.</span>                <span>Lehtikuva/AFP</span>            </figcaption>
            </figure>
                                                            </div>
                    
                

    
            <div>
            
                            <p>Vantaa (Finland) (AFP)</p>
                        <p>A pilot project using sniffer dogs to provide instant and pain-free coronavirus testing at Helsinki airport has shown promising early results and proven popular with travellers, researchers said on Wednesday.</p><p>Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall, and have found the virus in 0.6 percent of travellers.</p><p>Although the research is not due for completion until December, the team say the initial findings appear broadly in line with detection rates of the nasal PCR tests also conducted on arriving travellers.</p><p>"We have done 16-17,000 PCR tests at the airport and less than one percent are positive," Timo Aronkyto, deputy mayor of Vantaa, told reporters.</p><p>Compared to the results found by the dogs, "they are about the same, I don't think there is a statistical difference," Aronkyto said.</p><p>The researchers are now analysing how closely the two sets of test results match each other -- whether the dogs found coronavirus in passengers whose infection was confirmed by a PCR test -- and hope to publicise their findings at the end of the year.</p><p>Preliminary experiments in the first major wave of infections earlier in the year suggested the dogs can detect the virus with close to 100 percent accuracy, up to five days earlier than a PCR test.</p><p>Feedback from arriving passengers, who take the free-of-charge test voluntarily, "has been exceptionally positive," project manager Soile Turunen said. </p><p>Around 100 travellers a day have been queuing up for the test, which involves wiping a swab onto the skin which is then put in front of the dog, who will quickly pass over a negative sample but will be attracted to a positive one.</p><p>"People don't complain about the queues, in fact it's the opposite," Turunen said. </p><p>"They're coming up to us to to say 'Hi' from morning until evening," she added.</p><p>A fourth dog, a German shepherd called Valo, is currently in training to begin work at the airport testing booth.</p><p>The Helsinki University researchers behind the trial, working with sniffer-dog specialists from the organisation Wise Nose, hope that their research will persuade the government to fund a rollout of the dogs for other uses, such as at tourist hotspots or large public gatherings.</p><p>Although sniffer dog trials have been undertaken elsewhere, such as in the UAE, France, Ruussia and Chile, use of canine scent-detectors to bolster coronavirus testing has not yet been widely adopted by authorities, in part because of a lack of peer-reviewed literature, some researchers believe.</p><p>Dog handling charities have previously worked with dogs to detect cancers, Parkinson's disease and bacterial infections using samples taken from humans.</p>
            <p>Â© 2020 AFP</p>        </div>

            
                </article>
            
        
                                            
                                    </div>
            </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949592</guid>
            <pubDate>Sat, 31 Oct 2020 06:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LIL: Little Interpreted Language]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949515">thread link</a>) | @marttt
<br/>
October 30, 2020 | http://runtimeterror.com/tech/lil/ | <a href="https://web.archive.org/web/*/http://runtimeterror.com/tech/lil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p><b>LIL</b> (stands for <b>L</b>ittle <b>I</b>nterpreted <b>L</b>anguage)
is a small highly dynamic scripting language inspired by Tcl and
unix shells. LIL has two implementations, one written in <b>C</b>,
which consists of a pair of <tt>.c</tt> and <tt>.h</tt> files
and one in <b><a href="http://freepascal.org/">Free Pascal</a></b>,
which consists of a single <tt>pas</tt> file (a unit). Also a
<a href="http://lazarus-ide.org/">Lazarus</a> package for the
latter is provided.</p>

<h2>Contents</h2>

<menu>
  <li><a href="#downloads">Downloads</a>
  <menu>
    <li><a href="#latestversion">Latest version</a>
    </li><li><a href="#olderversions">Older versions</a>
    </li><li><a href="#winlil">WinLIL</a>
    </li><li><a href="#lilgui">LILGUI</a>
  </li></menu>
  </li><li><a href="#stability">API stability and compatibility</a>
  </li><li><a href="#documentation">Documentation</a>
  </li><li><a href="#status">Status</a>
  </li><li><a href="#license">License</a>
</li></menu>

<h2><a name="downloads"></a>Downloads</h2>

<p>LIL is currently available as source code snapshots of both
the C and the Free Pascal version combined in a single ZIP file.
These snapshots are versioned using their release date. Note that
the interpreter's reflect version command will report <i>0.1</i>
regardless of date versioning. Both of these will change at some
point in the future to provide proper versioned releases.</p>

<h3><a name="latestversion"></a>Latest version</h3>

<p>The latest version of LIL is <a href="http://runtimeterror.com/tech/lil/lil20190821.zip">lil20190821.zip</a>
(159KB). This is an extract from my private Fossil repository
(the files are mostly the same as the older archives, but this
also includes a full changelog from the repository going back
to 2010 and the LIL logo as an XCF image which can be opened with
GIMP).</p>

<p>Please note that <b>20190821</b> contains slightly altered
behavior for line breaking during list parsing that <i>could</i>
affect some scripts, especially with lists that contain code inside
square brackets, however the previous behavior was completely
broken (e.g. having multiple commands inside brackets in a list
would merge all commands into a single one and if a semicolon
was used for the multiple commands, the entire command wouldn't
be parsed properly). Because of that i expect any reliance on
the previous behavior to be accidental (and in practice i do not
really expect any such script to even exist). Also in the same
version a Bash script is introduced to check the differences between
different executables by running the same scripts under both and
comparing the results, which show that FPLIL contains a few incompatibilities
with C LIL. At this moment FPLIL doesn't implement the changes
mentioned so far - all these incompatibilities and changes will
be fixed in a later release.</p>

<h3><a name="olderversions"></a>Older versions</h3>

<p>Some older versions are also available in case you need them.
LIL should be mostly backwards compatible (see below), but right
now there is no promise for strict API or ABI compatibility.</p>

<ul>
  <li><a href="http://runtimeterror.com/tech/lil/lil20190819.zip">lil20190819.zip</a> (155KB)<a href="http://runtimeterror.com/tech/lil/lil20190818.zip"></a>
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190818.zip">lil20190818.zip</a> (154KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190114.zip">lil20190114.zip</a> (91KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20161129.zip">lil20161129.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160812.zip">lil20160812.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160603.zip">lil20160603.zip</a> (88KB)
</li></ul>

<h3><a name="winlil"></a>WinLIL</h3>

<p>If you are using Windows you can also download <b>WinLIL</b>,
a small Windows-based environment with editor, console and extra
graphics functions that can be used to experiment with LIL. It
is self-contained in a single executable, including the LIL documentation.</p>

<p>The latest version is <a href="http://runtimeterror.com/tech/lil/winlil14.zip">WinLIL 1.4</a>
(204KB) based on <i>C LIL 20190821</i>. <a href="http://runtimeterror.com/tech/lil/winlil.png">Here
is a screenshot</a> of it in action. Also a small doodle program
can be <a href="http://runtimeterror.com/tech/lil/doodle.lil">downloaded here</a> and a <a href="http://runtimeterror.com/tech/lil/doodle.gif">screenshot
seen here</a>. <a href="http://runtimeterror.com/tech/lil/winlil20190821231511.zip">This archive</a>
(45KB) contains the source code, but note that it uses the original
Borland C++ Builder and to compile with a newer version (such
as the free Community Edition) you'll need to recreate the project
file and make a few modifications to the code.</p>

<p>Older versions of WinLIL can be found in these files: <a href="http://runtimeterror.com/tech/lil/winlil13.zip">winlil13.zip</a>
(1.3 binary), <a href="http://runtimeterror.com/tech/lil/winlil20190524200539.zip">winlil20190524200539.zip</a>
(1.3 source), <a href="http://runtimeterror.com/tech/lil/winlil20170425.zip">winlil20170424.zip</a>
(binary), <a href="http://runtimeterror.com/tech/lil/winlilsrc20161220.7z">winlilsrc20161220.7z</a>
(source).</p>

<h3><a name="lilgui"></a>LILGUI</h3>

<p><b>LILGUI</b> is an experimental API specification for GUI
applications that provide scripting functionality through LIL
to expose a simple GUI API. It is mainly intended for creating
embeddable GUIs (e.g. a panel in a sidebar) although it can also
be used for popup windows and dialogs. Currently the only implementation
for LILGUI is <b>LazLILGUI</b>, which is a component for Lazarus
that uses LCL to provide the actual GUI functionality.</p>

<p>The latest version of LILGUI files (which include the API spec,
LazLILGUI and a couple of examples) can be <a href="http://runtimeterror.com/tech/lil/lilgui20190708215135.zip">downloaded
here</a> (85KB). A 64bit windows binary for <b>LazLILGUI Notepad</b>,
a text editor that provides a sidebar to try out LILGUI code,
can be <a href="http://runtimeterror.com/tech/lil/llgnotepad20190708.zip">downloaded here</a> (1.3MB).
Also you can see the screenshots of program in action under <a href="http://runtimeterror.com/tech/lil/llgnotepadwin.png">Windows</a>, <a href="http://runtimeterror.com/tech/lil/llgnotepadlin.png">Linux</a>
and <a href="http://runtimeterror.com/tech/lil/llgnotepadosx.png">Mac OS X</a> and also the <a href="http://runtimeterror.com/tech/lil/llgcce.png">Custom Control Example</a> under Windows.</p>

<h2><a name="stability"></a>API stability and compatibility</h2>

<p>Generally speaking, both the C and Free Pascal implementation
APIs are stable <i>for the most part</i>. The <b>C API</b> was
broken only once in middle 2010 when <code>lil_command_t</code>
was renamed to <code>lil_func_t</code> and the <b>C ABI</b> for
the Windows DLL is also backwards compatible since late 2010.
The <b>Free Pascal</b> implementation has a less stable API but
as Free Pascal itself does not support ABI stability, this is
less of a concern.</p>

<p>In the foreseeable future the C API should be stable, but i'd
recommend <i>against</i> building a system-wide shared version
of the library before a proper versioned release is made. Once
a versioned release is made, both the API and ABI will remain
stable for as long as it is technically possible.</p>

<p>Script code should be backwards compatible even as new commands
are introduced since scripts and host applications will redefine
any conflicting functions anyway. The only time script code was
broken was in 2012 when the multiline comments were introduced
so any script that used a comment line like <code>#####</code>
was broken. This was addressed in a fix in 2014 that added a special
check for such cases so that multiline comments can only start
and end with two <code>#</code>s but not three or more (while
this could have broken any script that used three or more <code>#</code>s
to start and end multiline comments, the chances for such a script
are very slim).</p>

<p>Like with the C API, the script backwards compatibility currently
is mostly stable, but minor changes (like the multiline comment
changes mentioned above) might be made until a versioned release
is made or fixes to the script behavior to be closer to what is
described in the documentation or simply fix broken behavior.
At that point no changes will be made that may affect backwards
compatibility.</p>

<p>LILGUI and LazLILGUI are more experimental and may see backwards
incompatible changes in the future.</p>

<h2><a name="documentation"></a>Documentation</h2>

<p>Currently the only documentation is the (lengthy) <tt>readme.txt</tt>
file that <a href="http://runtimeterror.com/tech/lil/readme.txt">you can read here</a> or as part
of the archive containing the source code. At some point i'll
write better formatted documentation. Free Pascal has its own
API documentation <a href="http://runtimeterror.com/tech/lil/pasreadme.txt">readable here</a> and
also as a part of the archive containing the source code.</p>

<p>The LILGUI API can be <a href="http://runtimeterror.com/tech/lil/api.txt">found here</a> and
the documentation for LazLILGUI can be <a href="http://runtimeterror.com/tech/lil/llgreadme.txt">found
here</a>. Both are also part of the LILGUI archive.</p>

<p>Also <a href="http://www.slideshare.net/badsectoracula/lil-presentation">an
old LIL presentation can be found on SlideShare</a>. Please note
that the URLs in the presentation are not valid anymore.</p>

<h2><a name="status"></a>Status</h2>

<p>LIL is practically <i>feature-complete</i> and i do very little
development of it. I do not plan on making it a big and bloated
library that tries to provide everything - if anything, in the
future i might add some conditionals to remove bits of the library
for users who do not need, e.g, the string or list functions.</p>

<p>Further work is mostly "around" LIL and not on the
language itself: improving the documentation, writing a test suite
(currently there are several examples which i run after making
changes and almost half of them come from bug fixes, but i'd like
somethnig more automated), fixing some issues with the Free Pascal
implementation, adding more functions on the C API to access LIL's
state, etc.</p>

<h2><a name="license"></a>License</h2>

<p>Both the C and Free Pascal implementations as well as WinLIL
are licensed under the zlib license below:</p>

<blockquote>
  <pre>LIL - Little Interpreted Language
Copyright (C) 2010-2019 Kostas Michalopoulos

This software is provided 'as-is', without any express or implied
warranty.  In no event will the authors be held liable for any damages
arising from the use of this software.

Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would be
   appreciated but is not required.
2. Altered source versions must be plainly marked as such, and must not be
   misrepresented as being the original software.
3. This notice may not be removed or altered from any source distribution.</pre>
</blockquote>



</div>]]>
            </description>
            <link>http://runtimeterror.com/tech/lil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949515</guid>
            <pubDate>Sat, 31 Oct 2020 06:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about windsocks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949514">thread link</a>) | @oftenwrong
<br/>
October 30, 2020 | https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/ | <a href="https://web.archive.org/web/*/https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949514</guid>
            <pubDate>Sat, 31 Oct 2020 06:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Note Taking Apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949421">thread link</a>) | @finder83
<br/>
October 30, 2020 | https://jself.net/posts/note-taking/ | <a href="https://web.archive.org/web/*/https://jself.net/posts/note-taking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>About every year or so I decide to change note-taking apps. Or at least I change <em>most</em> of my notes to a new app. This time I'm going back to an old app, but because of a "new" note-taking paradigm. The one I'm going back to is <a href="https://orgmode.org/">Org Mode</a>, but with a twist. In this post, I hope to look at some of the new ideas in note-taking and some of the apps available.</p><p>The new paradigm that I'm talking about is backlinking. It's actually not a new idea at all of course, but there have been many apps that have started to take advantage of backlinking. The one that launched off the fad was <a href="https://roamresearch.com/">Roam Research</a>. Many of these tools are based on or enable, a note-taking method called Zettelkasten.</p><p>Zettelkasten is a technique of note taking and indexing popularized by Niklas Luhmann, a German sociologist from the middle of the 20th century. Zettelkasten, literally "slip box", was a note-taking method in which small slips of paper were ID'd and linked to one another, creating a linked system of knowledge that Luhmann could then use in his books, research, and papers. As the links were maintained in two directions, ideas could be backward linked to other ideas. Ideas from various sources could then form a new network and hopefully, new links could be formed between information. There's more to it, such as the idea that each note should be an atomic, well-formed idea. For more information, and because I'm failing to explain it, visit <a href="https://zettelkasten.de/">https://zettelkasten.de/</a>.</p><p>I won't pretend to be an expert in Zettelkasten, and all of this is new to me. Frankly, I'm not even sure that the Zettelkasten method would be useful to me as I need longer form notes on many of the things that I do. But the idea of backlinking notes so that you can refer to notes that refer to the note that you're on seems extremely powerful. It feels like the next innovation in note-taking, beyond simple outlining or linking, precisely because you're essentially forming a distributed network of notes.</p><h2>Backlinks</h2><p>Let me give you an example. Say that I'm working on Kubernetes and can't remember the name of a tool that I had used. I can just pull up the Kubernetes note and look at the backlinks and see which notes are tagged as Kubernetes. Why couldn't I just create a link on the Kubernetes note? Well, of course, I could, but that would require opening that note and adding a link that may have nothing to do with the context for the primary Kubernetes notes.</p><p>Or another example, I am taking notes on a sermon being preached on John 3. I can then dive into John 3's note and look at all other sources tagged with John 3, including sermon notes, book notes, or personal devotional notes. From there I could dive into individual topics such as love or the kingdom of God.</p><p>At least, that's how I hope it will work in practice. Again, I'm just getting started</p><p>It seems that with the release of Roam Research, there have now been a plethora of tools in development that work off of the idea of backlinks, as well as atomic thoughts. I've done a lot of research in the last week, and have formed some opinions about some. Let's start first with the note-taking app I'm coming from:</p><h2>Notion</h2><p><a href="https://www.notion.so/">Notion</a> seemed to take off in 2018-2019 as the premiere note-taking app. Indeed, Notion has introduced backlinks in a recent release.</p><p>I like Notion, and will both keep paying for it and taking notes there. It has a lot of power in organizing and reorganizing notes, as well as pulling in other content such as code, videos, images, etc. It even goes so far as to include database-like tables and Kanban-style boards.</p><p>Backlinks in Notion seem to primarily work at the "page" level, rather than the block//heading level like Roam Research. And while I love Notion as a clean interface for notes, I'm not wild about its lack of capabilities in making TODOs and alerts and finding notes after the fact. Its search is great but basic.</p><h2>Roam Research</h2><p><a href="https://roamresearch.com/">Roam Research</a> seems like a really powerful system, particularly for a research-style Zettelkasten. I honestly have not tried it, both because I didn't get into the trial, but now because of the cost and the concern of people losing notes and the lack of good backups. Most of the posts I've seen about note stability have disappeared, but you can see one graveyard here: <a href="https://www.reddit.com/r/RoamResearch/comments/hsrg0z/lost_all_my_notes_need_recommendations_for/">https://www.reddit.com/r/RoamResearch/comments/hsrg0z/lost_all_my_notes_need_recommendations_for/</a>. There was even a post today about it: <a href="https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</a></p><p>Frankly, I prefer open source and being in control of my own content and notes. I know Notion doesn't fit into that well, but it also seemed ahead of its time to me.</p><h2>TiddlyWiki</h2><p><a href="https://tiddlywiki.com/">TiddlyWiki</a> has been around a while and was the note system I used before Notion. TiddlyWiki is many things, but at its heart, it was a single file HTML that you could download and make changes to in wiki syntax. TiddlyWiki has had backlinks for a while, possibly even before Roam Research, but recently the community has released some versions specifically for backlinking: <a href="https://akhater.github.io/drift/">Drift</a> and <a href="https://kebifurai.github.io/TiddlyResearch/">Tiddly Research</a> are two that I've tried out.</p><p>They're great, but there are a few problems that I've had with TiddlyWiki that just make me hesitant. I had a lot of notes in it as I was working in Seminary, wrote a custom Bible linking plugin, etc, but updating it was a nightmare on the node version with my customization. For each upgrade, I'd have to manually diff my plugin changes against the upgrades. Of course, this may have just been me not knowing what I was doing, but it still wasn't fun. Also, just the speed of entering notes and using the mouse doesn't appeal to me. Being a Vim guy, I like my keyboard.</p><h2>Obsidian</h2><p><a href="https://obsidian.md/">Obsidian</a> is a recent and gorgeous option for note-taking. It was actually my first introduction to backlinking and this whole area of decentralized notes. It's a commercial-style app (more on that below), but also works off of just a directory of markdown files. So you get to keep your content regardless. It feels great to use, I like its editor (not as well as <a href="https://typora.io/">Typora</a> or Notion though), and it's fast, responsive, and the keyboard shortcuts are great. It even has a basic Vim mode.</p><p>My only hangups are: if you use it for commercial purposes, the license becomes a pay-as-you-go SAAS license. The free license is just for personal use. Also, it's not open source, so there's always the risk that the company could go under and disappear, or worse, that they start charging way after I'm invested in it. Sure, they're just markdown files...I could make my own note-taking app if that were the case...but I don't have that much time or interest. Also, the backlinks seem to just be at the note level, but I didn't mind that as much in this app.</p><p>Still, if you're looking for a personal note-taking app that's easy to get into, supports backlinks, has the graph, uses markdown, is modern-looking, and is nice to use, totally give Obsidian a try.</p><h2>Joplin</h2><p><a href="https://joplinapp.org/">Joplin</a> is one that I've just tried a little bit. It looks fine as far as an editor, has nice backlinking, etc. The one hangup that made me put it down quickly is that links are always based on note ID, so you have to find a note to get its ID and insert it. It didn't seem nearly as fast or practical as I wanted. It is open source though, and worth a look.</p><h2>Trilium</h2><p><a href="https://github.com/zadam/trilium">Trilium</a> is an app I see recommended often. It's also free and open source. It claims to have automatic markdown conversion, but I couldn't get it to work. I gave up pretty soon after that.</p><h2>Zim</h2><p><a href="https://zim-wiki.org/">Zim</a> is a desktop wiki that I've used quite a lot in the past. It also has a backlinks plugin. It works great, is open source as well, and is very quick for taking notes. The negatives for this one are that it looks old and that it uses a custom wiki syntax that I don't like as well as markdown or Org.</p><h2>MindForger</h2><p><a href="https://www.mindforger.com/">MindForger</a> kind of does its own thing. It's difficult to explain, but worth checking out. It kind of has backlinks in that it has notes that are related to each other, but in more of an AI/intuitive way than in a manual way. It takes the headlines of Markdown files and makes them notes, but for each note lets you embed other top headlines/etc. It's weird but worth checking out. For a great intro, watch the video at <a href="https://www.youtube.com/watch?v=PlW2e1X3O-I">https://www.youtube.com/watch?v=PlW2e1X3O-I</a>.</p><p>MindForger is open source and seems really powerful. I'm going to keep playing with it. The only negative is that it's got the whole split-screen preview/markdown editor like many of the others on this list, but there's no graphical component to the editor at all. The keyboard shortcuts are multi-key and not configurable as well, but they're intuitive.</p><h2>Foam</h2><p><a href="https://foambubble.github.io/foam/">Foam</a> is a plugin to Visual Studio code that emulates many features from Roam/Obsidian. It has backlinks, a graph, and looks decent.</p><p>Honestly, though, I don't like Visual Studio code, it's not the greatest editing experience, and the backlinks seem majorly delayed from saving. But maybe that was just my experience. This is one that has a lot of promise and I would keep my eye on in the future, but seems it has a little ways to go.</p><p>I'll give an honorable mention to <a href="https://github.com/dendronhq/dendron">Dendron</a>, which seems to be at least on par with Foam. It also has a hierarchical system but seems to keep all of the files in the same directory using a dot-separated notation. Also worth checking out and watching, but also had delayed backlink processing and note a great markdown editing experience.</p><h2>Org-roam</h2><p><a href="https://www.orgroam.com/">Org-roam</a> is where I landed for now. Org-roam is an extension of the famous <a href="https://orgmode.org/">Org Mode</a> for Emacs. I used Org Mode a LOT when I was new to Emacs. It's really crazy how deep the rabbit hole goes for Org Mode. Org Mode is best described as an outliner, journal, day planner, calendar, TODO list, kanban board, interactive coding tool, TODO capture tool (including linking to source code lines, a browser, or even against a pdf as you're reading it), and presentation software. I'm sure there are a dozen or two things I'm missing too.</p><p>I'll caveat this though...you have to be a little crazy to use org-mode. Configuring it alone can be a trial in insanity, but once you master â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jself.net/posts/note-taking/">https://jself.net/posts/note-taking/</a></em></p>]]>
            </description>
            <link>https://jself.net/posts/note-taking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949421</guid>
            <pubDate>Sat, 31 Oct 2020 05:52:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What You Can Expect in Machine Learning Interviews]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949145">thread link</a>) | @nutellalover
<br/>
October 30, 2020 | https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews | <a href="https://web.archive.org/web/*/https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><div id="viewer-3rikt"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews" data-pin-media="https://static.wixstatic.com/media/4feadc_7a6668848e7246daa3e922d0aecdf505~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/4feadc_7a6668848e7246daa3e922d0aecdf505~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-7qfct">It's no surprise that machine learning jobs today are among the hottest on the market. <a href="https://artificialintelligence-news.com/2019/03/15/machine-learning-jobs-high-paying-demand/" target="_blank" rel="noopener"><u>Recent studies</u></a> have shown that the position of <strong>machine learning engineer </strong>commands one of the highest base salaries among surveyed jobs and has seen a 344% increase in number of postings from 2015-2018!</p><p id="viewer-403m8">So these jobs are clearly in high demand. But what does it take to secure one of these highly sought-after positions? Like any job in technology, machine learning positions require candidates to go through a rigorous series of technical interviews. </p><p id="viewer-43gc5">What is the structure of these interviews? What topics are covered? Are these interviews similar to software engineering? (Spoiler: sorta, kinda) Who is paying for lunch? </p><p id="viewer-781mt">There are a lot of questions, but not a lot of answers out there. This is largely because the field of machine learning is still young and learning to stand on its own two feet. </p><p id="viewer-cemkd">This article is intended to be the missing guide for what to expect in a machine learning interview. The observations in this post are born out of collective experiences interviewing for machine learning engineer and scientist positions, comprising over 90 hours of interview time across 80+ interviews at big (FAANG) companies, small (just out of Y-Combinator) companies, and everything in-between.</p><p id="viewer-522i9">Let's get started.</p><h3 id="viewer-32gml"><strong>Machine learning interviews are diverse...sometimes</strong></h3><p id="viewer-ecirs">The machine learning landscape is constantly evolving. If you were entering the world of machine learning ~4 years ago, the most in-demand skill would be the ability to build and debug deep learning models. Today with the rise of tools like PyTorch and Tensorflow, a bigger issue is not so much how to build machine learning prototypes but rather how to take them all the way to a deployed system in production (also called the last-mile problem). </p><p id="viewer-63ac7">What this means is that over the course of several years of interviewing for these positions, we've learned that the nature of these assessments can be incredibly diverse. For example, the following are examples of real interview types/questions that we've had:</p><p id="viewer-ac86k">	1) Read a recent paper on unsupervised learning for noise reduction and whiteboard extensions to the techniques proposed in the paper</p><p id="viewer-aj8c3">	2) Explain the nodes in the Tensorflow computational graph for a feedforward layer of a neural network</p><p id="viewer-5lue8">	3) Give an hour-long talk about some machine learning project you have done and get grilled on its details</p><p id="viewer-4bjvl">	4)  Describe how you would implement Google's autocomplete </p><p id="viewer-2p8og">	5) Explain why L1 regularization encourages sparsity in features</p><p id="viewer-5hjhh">Sound like these questions are all over the place? Don't get overwhelmed: they are.</p><p id="viewer-53d1i">Does that mean you will have to know how to do all of the above for your interview? No, definitely not. This variety is only meant to illustrate that many things are fair game depending on the company you are applying to and what they expect your responsibilities will be. </p><p id="viewer-3hihv">For example, if you are applying to a more research-intensive machine learning position, you may be asked to explain research-caliber work (either yours or that of others). Or if you are going to be a machine learning engineer at a young company, you may have to be more familiar with the internals of a framework or technology stack that is in high-demand. It really depends.</p><p id="viewer-7annu">That being said, as the field has matured, we've seen that the responsibilities of these positions are getting more well-defined leading to more standardized assessment structures.</p><p id="viewer-ciu37">Nowadays for most machine learning engineer positions, you can expect your interview journey to look something like the following:</p><ul><li id="viewer-6irq6"><p>First screening call with a recruiter</p></li><li id="viewer-edt1j"><p>Technical phone interview covering some software engineering and machine learning theory</p></li><li id="viewer-e1103"><p>Onsite (~4-5 interviews)</p></li></ul><p id="viewer-esrfv">                - Software engineering principles (~2 interviews)</p><p id="viewer-62fec">                - Machine learning theory (~1 interviews)</p><p id="viewer-2ugbd">                - Machine learning system design (~1-2 interviews)</p><p id="viewer-es0je">                - Interview with management (cultural fit check, typical in startups)</p><p id="viewer-73jhi">This can be subject to change depending on the company, but we've largely seen that common format across interviews today. Now let's discuss what to expect in terms of specific skills being evaluated.</p><h3 id="viewer-avlia"><strong>Know your machine learning theory</strong></h3><p id="viewer-dob3m">When applying for machine learning jobs you will always be asked about machine learning theory. In a sense, this a "well duh" moment but the <a href="http://www.cs.cmu.edu/~tom/mlbook.html" target="_blank" rel="noopener"><u>machine learning</u></a> <a href="https://web.stanford.edu/~hastie/ElemStatLearn/" target="_blank" rel="noopener"><u>theory</u></a> <a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/" target="_blank" rel="noopener"><u>literature</u></a> is vast so knowing what to focus on rather than working through multiple 1000-page textbooks is the key question.</p><p id="viewer-et0di"> Conceptual questions are asked in one of two forms: 1) in the context of some larger problem (i.e. while describing a system design, discuss model tradeoffs) or 2) in isolation (i.e. spend 30+ minutes describing how your favorite supervised learning algorithm works).</p><p id="viewer-t28k">In either case, the types of questions and concepts you'll be asked about stay pretty consistent. Our survey of past machine learning interviews has shown that you will tend to be tested on topics such as the following:</p><p id="viewer-5srhm">	1) What is the bias-variance tradeoff?</p><p id="viewer-fo0au">	2) What is overfitting/underfitting and how do you know when your model is suffering from those issues?</p><p id="viewer-bg784">	3) How do you evaluate model performance (which metrics are used and why)?</p><p id="viewer-b17gt">	4) Can you explain how some classical machine learning models work (logistic regression, k-nearest neighbors, support vector machines, decision trees, etc.)?</p><p id="viewer-2o3la">	5) What are common techniques for unsupervised learning?</p><p id="viewer-3sb7r">	6) How do you pick the best features for your model?</p><p id="viewer-b7b5m">That being said, because the collection of potential theory topics is so large, we've distilled the key concepts seen in interviews into a <a href="https://www.confetti.ai/assets/ml-primer/ml_primer.pdf" target="_blank" rel="noopener"><u>primer with practice exercises</u></a>. </p><h3 id="viewer-537k4"><strong>Software engineering is still important</strong></h3><p id="viewer-8v5gq">While the focus of machine learning jobs isn't just software engineering, you should still expect to be asked some more traditional coding and algorithms questions. These questions will be very similar, if not identical, to those you would be asked in a standard engineering interview. </p><p id="viewer-27v4b">Although this may seem unrelated to what you would think a machine learning practitioner does, when you are on the job knowing <em>how</em> to theoretically build a model is not the same as doing the actual building. This is true whether or not you are applying to be a machine learning scientist or a machine learning engineer. You need to be proficient in coding, debugging, and thinking through algorithms exercises. As an example of topics you can expect to be asked about:</p><p id="viewer-eal72">	1) Recursion and memoization (you'll basically never use recursion in the real world but 		   it's often used to evaluate your ability to think through an algorithm)</p><p id="viewer-cmind">	2) Memory and run-time complexity analysis</p><p id="viewer-d4m4q">	3) Standard data structures like trees, linked lists, hash maps, and general graphs</p><p id="viewer-9rse9">That being said, the standards for coding may not be the same in your interviews as they would be of someone applying for a pure software development position. In other words your engineering abilities might not need to be as sophisticated, especially if you are just coming out of an advanced graduate degree program in machine learning where your focus was more on pushing state-of-the-art rather than building robust training pipelines. </p><p id="viewer-dkeon">For software engineering, there are a number of popular <a href="http://www.crackingthecodinginterview.com/" target="_blank" rel="noopener"><u>books</u></a> and <a href="https://leetcode.com/" target="_blank" rel="noopener"><u>services</u></a> that can help you practice these skills.</p><h3 id="viewer-76m1h"><strong>Know how to build machine learning systems</strong></h3><p id="viewer-ba220">Knowing how to architect machine learning systems is one of the most important skills you can have going into the field of machine learning. One of the big aspects of machine learning's evolution in the past 1-2 years is that companies are going all-in on integrating data-driven solutions to extract business value across their teams. At scale this can lead to <a href="https://www.kdd.org/kdd2019/accepted-papers/view/150-successful-machine-learning-models-6-lessons-learned-at-booking.com" target="_blank" rel="noopener"><u>tremendous improvements</u></a> in the quality of a service. </p><p id="viewer-2j318">When you are being brought into a team as a machine learning expert, the expectation is that you will be able to apply machine learning skills to improve some existing manual process. Oftentimes you will be presented with very vague problem descriptions (e.g. "I want these recommendations to be better") and you will have to break down and frame the problem in a form where machine learning is applicable.</p><p id="viewer-bj4et">This is the core of designing and architecting machine learning systems. This skill is among the most crucial ones that companies look for when evaluating candidates. A system design interview will involve being presented with a case study (e.g. "we want a tool that can help us detect offensive content on our platform") and then talking through how to set up a machine learning pipeline that can address the problem. Along the way you will be assessed on your ability to:</p><p id="viewer-b3dv8">	1) Gather and validate datasets needed for your models</p><p id="viewer-3ctv5">	2) Build training infrastructure</p><p id="viewer-actbm">	3) Discuss the tradeoffs among potential modelling solutions</p><p id="viewer-7bofr">	4) Know what metrics you will track for model performance</p><p id="viewer-5tid6">	5) Interpret model predictions and do error analysis</p><p id="viewer-b2nej">	6) Architect a deployment solution (e.g. cloud-based, on-device, etc.)</p><p id="viewer-3hr9b">	7) Iterate on user feedback to improve the solution</p><p id="viewer-2fn8e">The important thing to recognize in these types of interviews is that there is never one "correct" answer. Your interviewers are more interested in knowing how you think through a problem. You will be asked to justify your decisions and also adapt them based on new situations (e.g. "now imagine we don't have enough money to gather 1 million annotated images...").</p><p id="viewer-2plnr">When preparing for these types of interviews, there's no substitute for real-world experience. Build projects so you witness firsthand what tradeoffs are necessary to consider. If that's not possible, spend a lot of time reading through company use-cases and learning how others have <a href="https://github.com/eugeneyan/applied-ml" target="_blank" rel="noopener"><u>solved similar problems</u></a>. </p><h3 id="viewer-44oq9"><strong>Technical interviews are just one signal</strong></h3><p id="viewer-dmrea">The last point worth mentioning is that while technical interviews are important signals in determining whether you get the job, they are still only one of many contributing signals. In particular, many startups also place great emphasis on your cultural fit â€¦</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews">https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews</a></em></p>]]>
            </description>
            <link>https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949145</guid>
            <pubDate>Sat, 31 Oct 2020 04:30:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Marketing Framework You'll Ever Need]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948930">thread link</a>) | @mooreds
<br/>
October 30, 2020 | https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf | <a href="https://web.archive.org/web/*/https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

      


      <main id="main">
        
        <div>

          <div>
            <div>
              <div>
                

                <div>
                  <p>When we started Reify, the idea was pretty simple â€“ letâ€™s take the experience weâ€™ve gained as marketers at developer facing companies, and apply that knowledge to as many software companies as we can. Letâ€™s raise the tide for everyone, and help everyone become better marketers. After more than 4 years and 75 clients, weâ€™re extremely happy with the results, and it felt like the right time to take a step back, consider what weâ€™ve accomplished and learned (and, glaringly, what mistakes we made), and try to do what every great marketer and consultant loves to do: define a framework.</p>

<p>Our first few clients, bless their souls, were very patient with us as we slowly but surely codified our methods. What started as a somewhat amorphous (but very enthusiastic, and usually quite successful somehow) â€œprocessâ€ turned into a repeatable set of working sessions, asynchronous assignments for our clients, and research and synthesis on our parts. We figured out just the right way to start with the stakeholders, document their story, do the hard work, and then end up with a <em>messaging framework that succinctly and successfully communicated the value of the product</em>.</p>

<p>Once we settled on the basic outline of the process, we did it again. And again. And again. Weâ€™ve done this essential, foundational marketing engagement with more than 75 companies, from solo bootstrapped founders to public companies, and everything in-between. We expanded our initial notion of working with developer facing companies to working with a wide range of companies from <a href="https://testdouble.com/">award-winning software consultancies</a> to <a href="https://getchannels.com/">TV tech plays</a>, and even <a href="https://omg.network/">blockchain tech</a> (a category that barely existed when we started the company). We partnered with <a href="https://www.brightscout.com/">fabulous designers</a>, <a href="https://devrelate.io/">top content producers and community builders</a>, <a href="https://www.heavybit.com/">VC firms and event producers</a>, and we even started a <a href="https://epicconf.com/">little online conference with our friends.</a></p>

<p>Throughout all of this work, one thing remained very clear:</p>

<blockquote>
  <p>Nothing is more important than the story.</p>
</blockquote>

<p>And so it was a few months back when Brian and I tried to finally put a name to this process weâ€™ve developed that we settled on a name: The Value Story Framework (VSF). This post will focus on what the VSF is, and it will be followed by another post outlining how the VSF can be put to use in nearly any company to start with solid foundations, set reasonable goals, and execute marketing like a pro.</p>

<center><img src="https://www.reifyworks.com/images/vsf1.png"></center>



<h2 id="the-value-story-framework">The Value Story Framework</h2>

<p>The VSF has three concrete outputs:</p>

<ul>
  <li>The <em>value story</em>, which sums up the <em>Why</em> of the product</li>
  <li>The <em>refined persona</em>, which describes the <em>Who</em>, based on the essentials uncovered in the value story</li>
  <li>The <em>messaging framework</em>, which contains the words used to describe <em>What</em>, <em>Why</em>, and <em>How</em> to the refined persona</li>
</ul>

<p>One of the keys to the VSF is that <em>these outputs are entirely driven by inputs from the companyâ€™s key stakeholders</em>. We often tell our clients that they will have all of the good ideas during this process, and our job is to massage words, curate ideas, and present a complete, consistent package of ideas â€“ something that can be difficult to do if youâ€™ve never done it before.</p>

<p>The value storyâ€™s inputs come in the form of answering a series of questions about the origins of the company, focused initially on understanding <em>why</em> the people responsible for forming it came together. Beyond that, a timeline is established, and we also ask questions about other key factors: we get to know the competitive landscape a bit, we discuss important customers, and we discuss companies our clients admire and learn why.</p>

<p>Once weâ€™ve established your <em>value story</em>, we move on to the <em>refined persona</em>. This persona document, which weâ€™ve written about a few times over the years, is designed to allow you to focus in on what really matters when deciding what kind of marketing to do, when to do it, and what kind of content you need to produce. We ask stakeholders to list the key challenges of skills of the target persona, to consider what other tools they use and love, to tell us everything they know about what key roles and responsibilities that individual has at work. Once weâ€™ve honed in on the <em>one initial persona</em> weâ€™re going to use, we give it a memorable nickname and then move on to the part that most people actually think about when they think about marketing: messaging and positioning.</p>

<p>Our <em>messaging framework</em> itself is nothing unique â€“ in fact we cribbed the structure of it by combining two different frameworks we found on the internet back when we were both marketing practitioners 5+ years ago. What does differentiate our process, however, is the process itself. While marketing is often done by thinking of cool sounding phrases and interesting angles first, and then matching the productâ€™s marketing to it, we take the opposite approach.</p>

<blockquote>
  <p>Use your story, focus on your persona, deliver your message</p>
</blockquote>

<p>We ask our clients to, <em>while considering the persona very closely</em>, produce lists of examples that support the basic argument that your product is a great fit for this persona. The messaging framework is assembled by combining existing facts about the product, aimed directly at the persona, in a way that leads us and the clients naturally to the great sounding slogans that companies often come to us in search of.</p>

<h2 id="prove-it">Prove it!</h2>

<p>Weâ€™ve been around a while, and worked with a decent number of clients you may have heard of, but the proof is in the pudding, right? How do you know that this stuff works at all? Beyond the fact that clients of ours who have used our frameworks directly have gone on to raise hundreds of millions of dollars in venture capital, added at least that much in revenue, come to dominate their own market niches, etc., nothing communicates out impact as effectively as their own words. To that end, here are some of our favorite client quotes:</p>

<blockquote>
  <p>â€œReifyâ€™s marketing framework helped us discover and communicate the value of FireHydrant in a way that has really resonated with our core audience.â€ â€“ Robert Ross, CEO, FireHydrant</p>
</blockquote>

<blockquote>
  <p>â€œDetermined AI is a technically complicated product, and communicating our value proposition early on was always a challenge. Reifyâ€™s frameworks helped us calibrate, and we went to market with messaging that helped us communicate clearly and effectively.â€ â€“ <em>Evan Sparks, Founder and CEO, Determined AI</em></p>
</blockquote>

<blockquote>
  <p>â€œReify helped us develop a messaging framework that not only enabled us to level up how we communicate with our customers, but was also instrumental in telling the story that resulted in our recent Series A financing. We have a confidence and focus now that we didnâ€™t before.â€ - <em>Caleb Hailey, CEO, Sensu</em></p>
</blockquote>

<p>And just because we love them so much, here are some of the great brand promises weâ€™ve helped our clients come up with, in the context of any software companyâ€™s core marketing asset, the website homepage:</p>

<center><img src="https://www.reifyworks.com/images/hero_sanity.png"></center>

<center><img src="https://www.reifyworks.com/images/hero_td.png"></center>

<center><img src="https://www.reifyworks.com/images/hero_stackbit.png"></center>

<p>And there are tons more.</p>

<h2 id="so--how-do-i-use-it">So â€¦ How Do I Use It?</h2>

<p>Weâ€™re working on a few different ways to share the VSF with the world. The first step will be a followup to this post, which will contextualize the Value Story, Refined Persona, and Messaging Framework in day to day marketing operations. After that, weâ€™re planning on opening up a software platform version of our framework that will allow <em>anyone to leverage these tools</em> to become the awesome marketers we know theyâ€™re capable of. Yes, after all this time teaching people how to fish, weâ€™re going to be fishing ourselves a bit â€“ and making a small software product to sell to early marketing teams. Sound cool? <strong><a href="https://calendly.com/briandoll/reify-chat">Book a 30-min Session with Reify Right Now</a></strong> to learn more!</p>


                  <hr>
                  <br>
                  
<br>


                </div>

              </div>
            </div>
          </div>
        </div>

      </main>

      
    </div></div>]]>
            </description>
            <link>https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948930</guid>
            <pubDate>Sat, 31 Oct 2020 03:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: TypeScript Hack â€“ Type System Text Adventure]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24948911">thread link</a>) | @ricksharp
<br/>
October 30, 2020 | https://ricklove.me/typescript-type-system-adventure | <a href="https://web.archive.org/web/*/https://ricklove.me/typescript-type-system-adventure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><span>title</span><span>Typescript Type System Adventure</span></span><span><span>date</span><span>2020-10-24</span></span><span><span>path</span><span>/typescript-type-system-adventure</span></span><span><span>author</span><span>Rick Love</span></span><span><span>excerpt</span><span>Text Adventure implemented in the Typescript Type System and Vscode JsDoc Viewer</span></span><span><span>image</span><span>game-screenshot-06-large.png</span></span><span><span>tags</span><span>typescript, type-system, vscode, jsdoc, markdown, hacks, demo, games, text-adventure</span></span></p><div><div><p>tl;dr: Play a text adventure in vscode with the typescript type system.</p><h3>Update - Added Typescript 4.1 Template String Literals</h3><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/typescript-4-1-features.png"></span></p><ul><li><a href="https://github.com/ricklove/rick-love-master/blob/70644a0f6cebf48132fc029e484e6f8db9e3fc19/code/typescript-type-system-adventure/game-type-system.ts#L123">Source on Github</a></li></ul><h3>Summary</h3><p>I've always been a fan of text adventures since I first played Space Quest 1 when I was about 6 (though it was a graphical text adventure technically).</p><p>I've also always been a huge fan of typescript since it came out in 2012.</p><p>Now, since Typescript 4.1 is adding the powerful template-literal-types, I figured I could do something fun with them.</p><p>(I got the idea from here: <a href="https://github.com/codemix/ts-sql">https://github.com/codemix/ts-sql</a>)</p><p>It occured to me, "Hey! Why not a text adventure!"</p><p>Now, it turns out that the way I implemented this game, I don't need the 4.1 features. I'll probably add that in the future to support more dynamic command parsing.</p><p>If you have <code>vscode</code>, you can play now with a quick <code>npm install</code> into any node project. (See below for full installation instructions.)</p><h3>So What?</h3><p>This is a level 99 typescript wizardry demo. </p><p>If you aren't a typescript nerd, you might miss the significance of this, but here is the basic idea:</p><p>First of all, everything you see here is running in the vscode code editor (without any program running). In fact, you can't even run my code. If you compile it to javascript, this is what you will get:</p><div><div><div><div><pre><code><span>export</span> <span>const</span> gameStart = <span>null</span>;</code></pre></div></div></div><p><span>âž–</span></p><p><span>âž•</span></p></div><p>(There might be a little more debris then that, but you get the idea.)</p><p>This screenshot should make it clear that the typescript type system is doing all the work:</p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-04-type-only.png"></span></p><p>However, it's not very convenient to declare all those StepNN types, so I made a fluent mode that reduces the need for those:</p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-01.png"></span></p><p>There is also an easy mode that uses only an object tree. It was very easy to make, but autocomplete ruins the fun by giving all the answers away. </p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-05-easy.png"></span></p><p>In the process of making the game, I discoved that vscode supports jsdoc markdown. So I decided to use that for the game output since it is so rich. It even supports images:</p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-03.png"></span></p><h3>Features</h3><ul><li>Play in vscode using autocomplete and tooltips</li><li>Game output displayed in tooltips using jsdoc3 with markdown (including gifs)</li><li>Implemented using conditional types, string literals, and a minimal state machine</li></ul><h3>How to play</h3><ul><li><code>npm i @ricklove/typescript-type-system-adventure</code></li><li>Create a new <code>play.ts</code> file and add the below code</li><li>Hover over <code>execute</code> to see game output (see screenshots for examples)</li></ul><div><div><div><div><pre><code><span>import</span> { gameStart } <span>from</span> <span>'@ricklove/typescript-type-system-adventure'</span>;

<span>const</span> play = <span><span>()</span> =&gt;</span> {

    <span>return</span> gameStart
        .command(<span>'look'</span>).execute
};</code></pre></div></div></div><p><span>âž–</span></p><p><span>âž•</span></p></div><h3>Tips:</h3><ul><li><code>.command('look').execute</code> will give you an idea of what to do next</li><li><code>.command('help').execute</code> if you get stuck</li><li>If you really get stuck, just hit F12 and read the source code</li><li>You can also play the easy mode with this starter:</li></ul><div><div><div><div><pre><code><span>import</span> { gameStartEasy } <span>from</span> <span>'@ricklove/typescript-type-system-adventure'</span>;

<span>const</span> playEasyMode = <span><span>()</span> =&gt;</span> {
    gameStartEasy
        .begin()
        .look()
};</code></pre></div></div></div><p><span>âž–</span></p><p><span>âž•</span></p></div><h3>Screenshots</h3><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-01.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-02.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-03.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-04-type-only.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-05-easy.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-06-large.png"></span></p><h3>Source Code</h3><p><a href="https://github.com/ricklove/rick-love-master/tree/master/code/typescript-type-system-adventure">https://github.com/ricklove/rick-love-master/tree/master/code/typescript-type-system-adventure</a></p></div></div></div>]]>
            </description>
            <link>https://ricklove.me/typescript-type-system-adventure</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948911</guid>
            <pubDate>Sat, 31 Oct 2020 03:22:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Mousetrap â€“ Converting WebPages to Web APIs]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24948779">thread link</a>) | @shanselman
<br/>
October 30, 2020 | https://turnerj.com/blog/a-better-mousetrap | <a href="https://web.archive.org/web/*/https://turnerj.com/blog/a-better-mousetrap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="article">
<p>Today is a big day for me as after many months (or years depending how you look at it), I've <a href="https://www.producthunt.com/posts/brandvantage">finally launched the first product for my business, BrandVantage</a>.
This post is the story of how I started with one idea and ended up launching with a different one.</p>
<h2>The Original Idea: Let's build a digital brand expert!</h2>
<p>I worked as a web developer for a local web development agency for a number of years and in that time, I learnt a lot about how a variety of different businesses operated online.</p>
<p>There were a few key "problems" I found in common across many of those businesses:</p>
<ul>
<li>Under-utilising analytics</li>
<li>Misunderstanding analytics</li>
<li>Not keeping on top of industry information</li>
<li>Lack of competitor analysis/understanding</li>
<li>Difficulty with Search Engine Optimization (SEO)</li>
</ul>
<p>In moderate-to-large companies where you have marketing departments, most of this stuff can be covered by one or more staff dedicated to these things.
In smaller companies, the business owner is normally the one where these tasks fall on to, but they are already wearing many different hats.
It felt like something was here - if I could automate some of these tasks in different ways, I could both help business owners and earn myself some money along the way.</p>
<p>Automation of tasks, especially ones in analytics or SEO spaces, isn't a new idea.
In fact, I've seen many businesses in a similar space launch on Product Hunt over the years since starting, but that didn't deter me.
I was building <a href="https://idioms.thefreedictionary.com/a+better+mousetrap"><em>a better mousetrap</em></a> and wanting to launch it at a lower price, not something truly innovative so it was going to be an uphill battle.
This area though, helping small businesses online be as efficient in tasks as some bigger businesses can, is something I felt passionately about so I proceeded anyway.</p>
<h3>Attempt One: Very Hacky (in PHP)</h3>
<p>Way back in 2015/16/17, while still at my full-time job, I spent nights and weekends building and tinkering on solutions to the problems business owners face.
It was a hacky PHP solution pulling real-time information from sources like Twitter, Google Analytics and Facebook.
A hacky approach seemed like a good idea as that seemed to be the way people launched things, do the quickest and hackiest thing you can to get it out the door.</p>
<p>While working on it, I had a few interested parties though what I built could barely be considered a prototype.
The thing was a mess.
I could do some basic queries, but it wasn't what I considered sellable and definitely not user-friendly, something I considered key to the product.
I was also running into technical problems with scale - any sufficiently complex query was performed real-time, which was getting more complicated.
Real-time processing had to be out.
I needed to pre-compute and store it in a database.</p>
<p>I wanted to take this more seriously and I didn't feel like a "quick and hacky" approach to building a product was right for me.
With this in mind, it seemed like a good opportunity to change the tech stack to something that would be better long term.</p>
<h3>Attempt Two: Slightly Less Hacky (in .NET)</h3>
<p>Moving to .NET felt like the smart move for me as at my job I had spent a lot more time working in .NET than PHP, plus I vastly prefered the tooling in .NET vs PHP.
That said, the .NET code I had worked on to-date would definitely be considered "legacy code".</p>
<p>My first version in .NET (specifically .NET Framework), predating my use of version control, was trying to keep costs low by using MySQL through Entity Framework.
After a lot of pain and suffering with that, I had a short stint of MSSQL before I settled upon MongoDB.</p>
<p>MongoDB might seem like a weird choice - there are some people that have very strong opinions about which type of database you should use.
Honestly it came down to a gut feel after messing around with it - it seemed more compatible to the way I was approaching problems than a relational database would.
I liked the code-first approach to Entity Framework so much though that I recreated the "feel" of Entity Framework for MongoDB with some custom code.
This later became an open source project of mine called <a href="https://www.mongoframework.com/">MongoFramework</a>.</p>
<p>I'm not going to lie, progress was... slow.
While I was putting quite a lot of time into working on it, it was still an extremely ambitious project.
I have strong feelings about building "MVPs" where some people focus too much on the "minimum" without enough focus on the "viable".
At the end of the day people buy products that meet their needs, and cutting too much out would meet no-ones needs.
If someone was going to use this, in a market with many competitors of varying quality, it had to do its job well.
There didn't seem much I could reasonably cut to make it any more minimal if I wanted people to buy it.</p>
<p>I kept working at it every night, building pieces to extract and store data from a variety of sources.
I was pulling in data from Google Analytics, Google Webmaster Tools (now called Google Search Console), Twitter, Facebook, IP Geolocation, DNS information and also from news articles.
What I thought I could do is once I had the different data sources together, I would write custom rules that could infer insights from individual or combined data sets.
These insights would form the basis of the "digital brand expert".
After all, that was the goal of the idea, something that could help out small business owners.</p>
<p>After 2 years of working on this in my spare time, it felt the right time to leave my job and go into this full time.
I felt like I was <em>so close</em> to launching and I just needed something more than the same day-to-day work.
So I did it - <a href="https://turnerj.com/blog/i-left-my-job-today-after-seven-years">I left my job after 7 years</a>.</p>
<h3>Going Full-time into the Idea</h3>
<p>Right out of the gate, I had moved from .NET Framework to .NET Core, was working on UI/UX improvements for the application and launched the website for it.
I worked with an accountant and a lawyer to setup the business, bought a trade mark for the product name, and I felt good like I was only a few months away from launching.
This feeling didn't last though...</p>
<p>Over time, it felt like I was taking two steps forward then one step back - some technical, some business related.
Sure, that is still progress, but having new issues crop up every day or so can really crush your motivation.</p>
<p>My best/happiest/most productive days were days I ignored or avoided different issues I had.
If I had a problem with the login system, I would focus on how the UX of the menus worked.
If I had a problem with data gathering, I would add more tests to the codebase.
While I didn't entirely ignore the problem, I would wait a week or two before I looked at it again, somewhat hoping it would solve itself - unfortunately that isn't how things work.</p>
<p>In time though, I got to a stage where it felt like I could launch and was hyping myself up until reality struck: I didn't actually build what I set out to build.</p>
<p>The UI/UX was good, I had strategies for deployment and plans for next steps, but it wasn't a "digital brand expert".
It was instead a glorified data store for information that people could better access through existing tools.
That's kinda a big problem!</p>
<p><img src="https://turnerj.com/blog/2020/images/a-better-mousetrap-ive-made-a-huge-mistake.gif" alt="Gob Bluth saying &quot;I've made a huge mistake.&quot; from the TV Show &quot;Arrested Development&quot;"></p>
<p>When realising this I poured time into fixing that huge lapse in judgement, but I couldn't do it.
No matter how I tried, I just couldn't figure out how to build this rules engine.
It was like my entire thought process was just clouded.
I couldn't see the solution to the problem like I can for most other things.</p>
<p>This was depressing and I ended up having a month or so hiatus from working on it.
When I have had stints of not feeling like or not being able to do programming in the past, I try and spur it on again by watching some show or movie which has some strong relation to technology (fictional or not).
My go-to is usually something like <a href="https://www.imdb.com/title/tt0371746/">Iron Man</a>, but this time I was rewatching <a href="https://www.imdb.com/title/tt2543312/">Halt and Catch Fire</a> where I found some inspiration.</p>
<h2>The Pivot: An API to the Internet</h2>
<p>Later in the series a lot of the focus is around the Web, and it was in these episodes where my thoughts about the Internet and the data on it have changed.
There is a quote from one of the main characters at the end of Season 3 that resonates with me:</p>
<div>
<blockquote>
<p>"The moment we decide what the Web is, we've lost. The moment we try to tell people what to do with it, we've lost.
All we have to do is build a door and let them inside."</p>
<p>- Joe MacMillan (Season 3, Episode 10)</p>
</blockquote>
</div>
<p>The Internet is a treasure trove of information, it is searchable but generally unstructured.
People have managed to create all sorts of different pages in HTML, but in the process of making a website everything is designed for a human user.
It is this way for obvious reasons, <em>we</em> are the consumers of web pages after all... aren't we?</p>
<p>Behind these user-friendly web pages are usually other specific bits of markup, providing some level of structured data for specific situations.
Sometimes it is a description metatag for search engines, other times it might be <a href="https://ogp.me/">Open Graph</a> metatags for social media links.
We build these things to help aid computers processing our web pages.</p>
<p>In 2011, <a href="https://schema.org/">Schema.org</a> was created.
This was a collaborative effort between Google, Bing and Yahoo (later that year, Yandex as well) with the mission to "create, maintain, and promote schemas for structured data on the Internet, on web pages, in email messages, and beyond".
Through 3 different encodings (<a href="https://turnerj.com/blog/what-is-microdata-and-why-should-i-care">Microdata</a>, <a href="http://rdfa.info/">RDFa</a> and <a href="https://json-ld.org/">JSON-LD</a>), websites could express detailed structured data.</p>
<p>There is another quote from Halt and Catch Fire which I like:</p>
<div>
<blockquote>
<p>"Computers aren't the thing. They're the thing that gets us to the thing."</p>
<p>- Joe MacMillan (Season 1, Episode 1)</p>
</blockquote>
</div>
<p>As much as I like computers and programming, they are used to help us achieve other goals.
From my attempts of trying to build a "digital brand expert", I knew that data is fundamental to help build more advanced systems and give new insights.
Having easier access to other forms of data from web pages around the world may allow new and different tools to be built.</p>
<p>So I decided rather than try and solve a problem that I was clouded by, I â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turnerj.com/blog/a-better-mousetrap">https://turnerj.com/blog/a-better-mousetrap</a></em></p>]]>
            </description>
            <link>https://turnerj.com/blog/a-better-mousetrap</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948779</guid>
            <pubDate>Sat, 31 Oct 2020 02:49:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Onion for Crypto]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948746">thread link</a>) | @npguy
<br/>
October 30, 2020 | http://doublespend.io/index.php | <a href="https://web.archive.org/web/*/http://doublespend.io/index.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://doublespend.io/index.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948746</guid>
            <pubDate>Sat, 31 Oct 2020 02:43:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why every SSH user should switch to using SSH Certificates]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24948738">thread link</a>) | @dbsentry
<br/>
October 30, 2020 | https://keyper.dbsentry.com/post/sshca/ | <a href="https://web.archive.org/web/*/https://keyper.dbsentry.com/post/sshca/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The last few years have seen rapid automation of many Systems Administration/DevOps tasks. The new mantra is if you need to ssh to a server, your automation is not working right. But even for the occasional ssh access to the servers, the SSH authentication must be managed. Over the years, SSH has added many new features/techniques to enhance authentication and put some governance around it. This article is about the use of SSH Certificate-based authentication and why every organization, using SSH, must use it.</p><p>SSH Key-based authentication (aka passwordless login) has been with us for over two decades now. The mechanism works based on public-key cryptography. One adds his/her RSA/DSA key to the authorized_keys file on the server. The user with the corresponding private key can login without a password. It works great except for a few fundamental problems:</p><ol><li>When a user accesses the server using ssh for the first time, s/he always gets Trust On First Use (TOFU) warning.</li></ol><pre><code>$ ssh -l alice mavrix5.dbsentry.com
The authenticity of host 'mavrix5.dbsentry.com (72.191.40.116)' can't be established.
ECDSA key fingerprint is SHA256:PoK81UWgOBMn6owOoHXjGoBLWqcJ4E9JCiLQyiFF60s.
Are you sure you want to continue connecting (yes/no)? 
</code></pre><p>As the server is not trusted at this point, theoretically a man-in-the-middle attack could be launched. I tried to find damaging incidents of such attacks on the internet but could not find any. Nevertheless, the possibility exists and weâ€™d be better off getting rid of this warning.</p><ol start="2"><li>When the number of servers increases, authorized_keys files proliferate and they are hard to manage. Moreover, once added they are active perpetually and have to be removed manually to block access to its corresponding private key. That is probably the reason why many security guys frown on the use of authorized_keys.</li></ol><p>Fortunately, the newer version of SSH included many improvements that give us the ability to centralize and better manage authorized_keys using <code>AuthorizedKeysCommand</code>. However, the TOFU remains. Although the solutions exist in either the use of SSHFP or SSH Certificates, their usage never caught on.</p><p>Having said that, in addition to taking care of TOFU, SSH Certificates have many more advantages/features (for e.g. certificate expiration, use of principals, etc) that enhance SSH authentication governance and should be used by all organizations that use SSH.</p><p>Instead of using complex X.509 style certificates, SSH chose to use their own simpler format of certificates, which can be easily managed using CLI <code>ssh-keygen</code>. In order to use SSH certificate-based authentication one needs to set up SSH Certificate Authority (CA). So, how does one set up SSH CA?</p><p>SSH Certificate authority can be setup on any computer with <code>ssh-keygen</code>. It is a key pair that is used to sign SSH Public Keys to generate certificates. It is recommended to set up two pairs of CA keys: one for host certificates and others for userâ€™s certificates.</p><p>Use <code>ssh-keygen</code> to genearet CA Keys:</p><pre><code>$ ssh-keygen -t rsa -f ca_host_key
$ ssh-keygen -t rsa -f ca_user_key
</code></pre><p>The above would generate two pairs of SSH Keys. for e.g.</p><pre><code>$ ssh-keygen -t rsa -f ca_host_key
Generating public/private rsa key pair.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in ca_host_key.
Your public key has been saved in ca_host_key.pub.
The key fingerprint is:
SHA256:Epoq1Vy0/orivKOwxepBLqD7mGuaWbUKh+SoycMpKy0 manish@picanmix4
The key's randomart image is:
+---[RSA 2048]----+
|      .          |
|     . .         |
|      +          |
|   o = .         |
|.o. * o S        |
|O+ o . o         |
|X=B .   .        |
|E^=. . .         |
|^XB+. .          |
+----[SHA256]-----+
$ ssh-keygen -t rsa -f ca_user_key
Generating public/private rsa key pair.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in ca_user_key.
Your public key has been saved in ca_user_key.pub.
The key fingerprint is:
SHA256:9cW4eNS9mNUWWeSRDG9ONjMAWfOTpx9kuLfZyHEMAME manish@picanmix4
The key's randomart image is:
+---[RSA 2048]----+
|         .o+==o+*|
|          E. =**=|
|          . o.=/*|
|         . + o%=B|
|        S . ++o=o|
|           . ..==|
|              ooo|
|                 |
|                 |
+----[SHA256]-----+
$ ls -l
total 32
-rw-------  1 alice  staff  1823 Oct 30 13:19 ca_host_key
-rw-r--r--  1 alice  staff   398 Oct 30 13:19 ca_host_key.pub
-rw-------  1 alice  staff  1823 Oct 30 13:19 ca_user_key
-rw-r--r--  1 alice  staff   398 Oct 30 13:19 ca_user_key.pub
</code></pre><p>Optional: In addition you can also setup SSH Key Revocation List (KRL). This is a list of all revoked certificates.</p><pre><code>$ ssh-keygen -k -f ca_krl
</code></pre><p>And, thats it. your SSH CA is in business. Now, going forward, you just need to configure your servers and clients to use certificates with private keys.</p><h2 id="ssh-server-configuration">SSH Server Configuration</h2><p>Follow these steps to configure host to use SSH certificates:</p><ol><li>Copy your servers SSH Public Key, typically located under <code>/etc/ssh/ssh_host_rsa_key.pub</code> or <code>/etc/ssh/ssh_host_dsa_key.pub</code> and get it signed.</li></ol><pre><code>$ ssh-keygen -h -s ca_host_key -z &lt;serial no.&gt; -I &lt;hostname&gt; -V &lt;duration&gt; -n &lt;principal list&gt; ssh_host_rsa_key.pub
</code></pre><p>for e.g</p><pre><code>$ ssh-keygen -vvv -h -s ca_host_key -z 100 -I mavrix2 -V +52w -n mavrix2,mavrix2.dbsentry.com ssh_host_ed25519_key.pub
Signed host key ssh_host_ed25519_key-cert.pub: id "mavrix2" serial 100 for mavrix2,mavrix2.dbsentry.com valid from 2020-10-30T14:46:00 to 2021-10-29T14:47:02
</code></pre><ol start="2"><li>Copy the certifcate back to the host under <code>/etc/ssh</code></li><li>Copy CA User Public Key(<code>ca_user_key.pub</code>) to the host under <code>/etc/ssh</code></li><li>Add the following to <code>sshd_conf</code> file:</li></ol><pre><code>TrustedUserCAKeys /etc/ssh/ca_user_key.pub
HostCertificate /etc/ssh/ssh_host_ed25519_key-cert.pub
</code></pre><p><code>TrustedUserCAKeys</code> directs SSH to trust certificates signed by <code>ca_user_key</code>. And, <code>HostCertificate</code> directs SSH to send the host certificate instead of public key to the client.
5. Restart SSH</p><pre><code>$ sudo systemctl restart sshd
</code></pre><h2 id="ssh-client-configuration">SSH Client Configuration</h2><p>Follow the following steps to configure client/user to use SSH certificates:</p><ol><li>Copy userâ€™s SSH Public Key (typically located under <code>&lt;usershome&gt;/.ssh/id_rsa.pub</code>. If not present, it can be generated using <code>ssh-keygen -t rsa</code>) to the CA host and get it signed</li></ol><pre><code>$ ssh-keygen -s ca_user_key -z &lt;serial no&gt; -I &lt;username&gt; -V &lt;duration&gt; -n &lt;principal list&gt; id_rsa.pub
</code></pre><p>for e.g</p><pre><code>$ ssh-keygen -s ca_user_key -z 100 -I alice -V +2h -n alice,apache id_rsa.pub
Signed user key id_rsa-cert.pub: id "alice" serial 100 for alice,apache valid from 2020-10-30T14:56:00 to 2020-10-30T16:57:51
</code></pre><p>You can look at the content of the certificate using the following command:</p><pre><code>$ ssh-keygen -L -f id_rsa-cert.pub 
id_rsa-cert.pub:
      Type: ssh-rsa-cert-v01@openssh.com user certificate
      Public key: RSA-CERT SHA256:2J9G7t6Dn11nKlI5l9USbHAFRTuBUUVxqbL+uHQaaDc
      Signing CA: RSA SHA256:X75sKpv1L2B6y/mIUYKZc0QVmQD8CgpcBS+ZhRPbRmk (using ssh-rsa)
      Key ID: "alice"
      Serial: 100
      Valid: from 2020-10-30T14:56:00 to 2020-10-30T16:57:51
      Principals: 
              alice
              apache
      Critical Options: (none)
      Extensions: 
              permit-X11-forwarding
              permit-agent-forwarding
              permit-port-forwarding
              permit-pty
              permit-user-rc
</code></pre><ol start="2"><li>Copy certifcate to the client under <code>&lt;userhome&gt;/.ssh</code></li><li>Copy CA Host Public Key (<code>ca_host_key.pub</code>) to the client and put it either in known_hosts file under <code>&lt;userhome&gt;/.ssh</code> (local) or <code>/etc/known_hosts</code> (global) file in the following format:</li></ol><pre><code>@cert-authority *.dbsentry.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDDN4F3JKuAS1V0nQmBRNl5fS8dZS49FKUp5wwy8R0wDcNYdrq+M5/tdS6K/R07445VWpVKwExZGboaQ/YR5iQ392YHM55ThMjSP5CTywmiP033MX3zG5eO9Iec5fz/hHtwrDtxb4Xm3FfGhXjjKTozNf/uMcOjIM1STr/I6t2zfZ42bnCq4DFj1GWHSrOtnxjN0PPOfCLH+1AmKhEUFqf0NBD3CQoPamaRVf4ouAc9KxOLFge+gebJe9jmqkaVHYfZD2CPoLVGHXZCphSQ3gyEKpvgD8VnfU9/la6BNtcK9lSONZWLFcw523HdlnbGVz+t15zZAXLu/3H6yK5SPC/L 
</code></pre><p>Above instructs SSH client to trust host certificate signed by the CA.
4. Test ssh. You should not receive TOFU warning and should not be asked for the password either. The generated certificate should work for the principals (i.e. users on server) for the validity period.</p><h2 id="summation">Summation</h2><p>In this article, I have demonstrated setup of SSH Certifciate Authority and why and how SSH authentication use SSH certificates.</p><p><code>&lt;Shameless-Plug&gt;</code><br>Although the use of certificates results in more secure SSH authentication, SSH CA adds the burden of ssh certificate management. To ease that burden one can use a centralized system such as
<a href="https://keyper.dbsentry.com/" target="_blank" rel="noopener">Keyper</a>. Keyper is an Open Source SSH Key and Certificate-Based Authentication Manager. Keyper acts as an SSH Certificate Authority (CA) and it standardizes and centralizes the storage of SSH public keys and SSH Certificates for all Linux users in your organization saving significant time and effort it takes to manage SSH public keys and certificates on each Linux Server. Keyper also maintains an active Key Revocation List, which prevents the use of Key/Cert once revoked. Keyper is a lightweight container taking less than 100MB. It is launched either using Docker or Podman. You can be up and running within minutes instead of days.<br><code>&lt;/Shameless-Plug&gt;</code></p><p>Thats it folks! Happy more secure SSHâ€™ing.</p></div></div>]]>
            </description>
            <link>https://keyper.dbsentry.com/post/sshca/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948738</guid>
            <pubDate>Sat, 31 Oct 2020 02:41:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS vs. Subscription]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948666">thread link</a>) | @Lukas1994
<br/>
October 30, 2020 | https://www.causal.app/blog/saas-vs-subscription | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/saas-vs-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a></p><p>The three key characteristics of a SaaS company are: subscription, high margin, and scalability. There are so many new business models and new applications of existing business models into new markets that capture one or two of these, but in order to get the high multiples that SaaS companies achieve, it's critical to have all three. In addition, the "rule of thumb" metrics that I previously mentioned don't work so well in the absence of any of these characteristics. While the fundamental subscription math remains true, you have to dig much deeper to understand the impact on the cash flows, working capital needs, scalability, customer lifetime value and long term profitability to be able to assess the health and viability of a business.</p><p>For example, if we look at <a href="https://www.lemonade.com/">Lemonade</a>, which priced its IPO today (<a href="https://www.sec.gov/Archives/edgar/data/1691421/000104746920003943/a2242013z424b4.htm">424B4 here</a>). Lemonade is a technology-enabled insurance company and insurance broker. I think most people would agree that it is not a software company. But if we look through the lens of these three characteristics and some of the key metrics, we can learn a lot about its long term prospects as a business.</p><ol role="list"><li><strong>Subscription:</strong> Insurance is probably one of the original subscription businesses, with people paying annual or monthly premiums. Revenue comes in regularly to support the clientsâ€™ claims.</li><li><strong>Scalability:</strong> Assuming there's access to re-insurance and the capital to back up the insurance plans, this business is highly scalable and in a huge market.</li><li><strong>Margins:</strong> This is where it gets a bit more complicated. This is not a 90% margin, AWS-expense only business. It's a complicated financial cycle and risk assessment business with very different capital, accounting and cash flow dynamics. Lemonade runs a few different businesses with varying risk ownership which have an impact on gross profit, and overall they achieved a gross margin of 17% in 2019.</li></ol><p>Now let's take a look at some of the key metrics:</p><ol role="list"><li><strong>LTV</strong>: In most software businesses, especially those either creating or selling into new markets, it's almost impossible to calculate a lifetime value because we don't have enough data on the lifetime of a customer. In the insurance business, there's tons of data going back decades for hundreds of millions of people. Insurance companies run on actuarial science, which one could argue is the original data science application. To put it lightly, they understand data and have lots of it. While in a new-fangled enterprise or consumer software business, lifetime value is a shot in the dark, in the insurance business it's not, where it's reasonable to expect your customers to stay with you for 25+ years.</li><li><strong>CAC Payback</strong>: Knowing you can keep your customers for a very long time is great and now you can calculate the CAC you can afford to invest in order to acquire them. Lemonade runs efficiently now with $1 of marketing to $2 of in-force premium on their platform. Gross margin-adjusted this obviously shifts the timeline out, but that's OK because the likelihood of keeping the customers for a long time is high. This introduces a new question: capital. With short paybacks, cash management isn't so much of a challenge, but as those payback times increase, so does the need to fund the working capital needs of the business. The time value of money becomes a factor here, but is manageable and calculable.</li></ol><p>So a quick look through the lens of the fundamental subscription concepts makes it clear that even though Lemonade is not a software business, it is a subscription business with some highly favorable business and customer economics.</p><p>And congrats to the Lemonade team on the IPO!</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f6128d02bc85546e3a93976_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Faa34c7a7-d833-453f-a3cb-79b88beb7eda_1536x1025.jpeg" alt=""></p></figure><p>â€</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/saas-vs-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948666</guid>
            <pubDate>Sat, 31 Oct 2020 02:24:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to encode and decode URL with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948588">thread link</a>) | @phongduong
<br/>
October 30, 2020 | https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When you request a third-party API, you may pass parameters that contain special characters. This may cause errors for your request. To avoid this situation, you need to encode the URL before sending the request. </p>
<h2 id="encode-url">Encode URL</h2>
<p>Javascript has 2 functions that help you encode a URL:</p>
<ul>
<li><code>encodeURI()</code>: encode a full URL. It doesn't encode <code>~!@#$&amp;*()=:/,;?+'</code> </li>
<li><code>encodeURIComponent()</code>: encode a part of the URL. It doesn't encode <code>-_.!~*'()</code> </li>
</ul>
<h2 id="examples">Examples</h2>
<h3 id="encode-url-1">Encode URL</h3>
<pre><code><span>const</span> <span>URL</span> <span>=</span> <span>"https://phongduong.dev/blog/kiá»ƒm tra tiáº¿ng Viá»‡t"</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span>encodeURI</span><span>(</span><span>URL</span><span>)</span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span>encodeURIComponent</span><span>(</span><span>URL</span><span>)</span><span>)</span> </code></pre>
<h3 id="encode-parameters">Encode parameters</h3>
<pre><code><span>const</span> <span>URL</span> <span>=</span> <span>"https://phongduong.dev"</span>
<span>const</span> <span>URLParam</span> <span>=</span> <span>"https://example.com"</span>
<span>const</span> queryParam <span>=</span> <span>"ÄÃ¢y lÃ  tiáº¿ng Viá»‡t"</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span><span>`</span><span><span>${</span><span>URL</span><span>}</span></span><span>?url=</span><span><span>${</span><span>encodeURIComponent</span><span>(</span><span>URLParam</span><span>)</span><span>}</span></span><span>`</span></span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span><span>`</span><span><span>${</span><span>URL</span><span>}</span></span><span>?q=</span><span><span>${</span><span>encodeURIComponent</span><span>(</span>queryParam<span>)</span><span>}</span></span><span>`</span></span><span>)</span> </code></pre>
<h2 id="decode-url">Decode URL</h2>
<p>Javascript provides <code>decodeURI()</code> and <code>decodeURIComponent()</code>to decode a URL. You can use them to decode the corresponding encoding function's result</p>
<pre><code><span>console</span><span>.</span><span>log</span><span>(</span><span>decodeURI</span><span>(</span><span>"https://phongduong.dev/blog/ki%E1%BB%83m%20tra%20ti%E1%BA%BFng%20Vi%E1%BB%87t"</span><span>)</span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span>decodeURIComponent</span><span>(</span><span>"https%3A%2F%2Fphongduong.dev%2Fblog%2Fki%E1%BB%83m%20tra%20ti%E1%BA%BFng%20Vi%E1%BB%87t"</span><span>)</span><span>)</span> </code></pre>
<h2 id="summary">Summary</h2>
<p>If you want to encode a full URL, use <code>encodeURI()</code>. </p>
<p>If you want to encode a part of the URL, use <code>encodeURIComponent()</code>. </p>
<p>To decode, use the corresponding function.</p>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948588</guid>
            <pubDate>Sat, 31 Oct 2020 02:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VVC, EVC, LCEVC â€“ MPEG's New Video Codecs â€“ Explainer with Lcevc Results Linked]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948460">thread link</a>) | @ponderingfish
<br/>
October 30, 2020 | https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/ | <a href="https://web.archive.org/web/*/https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-vvc-lcevc-min.png?resize=678%2C381&amp;ssl=1" alt="vvc evc lcevc mpeg" title="evc-vvc-lcevc-min" data-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-vvc-lcevc-min.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>MPEG is releasing three new video codecs in 2020-2021 called Versatile Video Coding (H.266), Essential Video Coding (EVC MPEG-5 Part 1), and Low Complexity Enhancement Video Coding (LCEVC MPEG-5 Part 2). Letâ€™s take a look at the highlights of each of these codecs and what they bring to the table.</strong></p>




<h2 id="video-compression-is-critical-to-your-infrastructure"><span id="Video_Compression_is_Critical_To_Your_Infrastructure"></span>Video Compression is Critical To Your Infrastructure<span></span></h2>



<p>Video traffic is growing by the day and that is not going to stop any time soon. The pandemic might have stymied other industries, but, has actually given a filip to the streaming industry, because people are stuck indoors, and watching videos provides a much-needed escape from the daily routine!</p>



<p>Video Compression is a critical component in the video delivery pipeline and can make a massive make-or-break impression in the minds of the end-user. If you â€œtuneâ€ your encoders to maximize video quality, youâ€™ll have to compromise on compression efficiency and spend more bits; and vice-versa. If you compromise on compression efficiency and create larger files, then you will have to spend more on CDN delivery costs.</p>



<p>So, the goal of every encoder team is to create a fine-balance between quality and bitrate. In other words, balance video quality with dollars.</p>



<p>The easiest way to perform this balancing act is to upgrade to the best encoder or encoding technology on the market. Hypothetically, this is simple, but practically, this is difficult. You need to make sure that the quality-complexity-efficiency trade-offs are met and decoder support is available amongst other things.</p>



<h2 id="the-failure-of-hevc"><span id="The_Failure_of_HEVC"></span>The Failure of HEVC<span></span></h2>



<p>When we talk about encoders, the discussion isnâ€™t complete without mentioning H.264/AVC which is still ruling supreme since its introduction by MPEG (in 2003, I think). The MPEG announced a successor to H.264/AVC and called it H.265/HEVC (High Efficiency Video Coding) that had a slew of new coding tools such as quadtree decomposition, new picture types, SAO filtering, etc.</p>



<p>However, HEVC turned out to be a flop and the failure of HEVC had almost nothing to do with the algorithms. For HEVC R&amp;D teams, getting 20-30% gains over AVC was easy. </p>



<p><strong>You may disagree, but, as someone who wrote HEVC code for years, I stand by what I said.</strong></p>



<p>The â€œfailureâ€ of MPEGâ€™s H.265/HEVC was due to patent-pools and licensing issues and this created the need for a new codec to fill the gap left by HEVC and to replace H.264/AVC (which by-design will struggle to compress 4K, UHD, and large resolutions).</p>



<p>In this regards, MPEG has announced that three new video codecs will soon be standardized and they are :-</p>



<ul><li>Versatile Video Coding (H.266)</li><li>Essential Video Coding (EVC MPEG-5 Part 1)</li><li>Low Complexity Enhancement Video Coding (LCEVC MPEG-5 Part 2)</li></ul>



<p>Letâ€™s take a quick look at the objective of each of these codecs and see what gap theyâ€™re trying to plug, shall we?</p>



<h2 id="versatile-video-coding---vvc--h266"><span id="Versatile_Video_Coding_%E2%80%93_VVC_/_H_266"></span>Versatile Video Coding â€“ VVC / H.266<span></span></h2>



<figure><img data-attachment-id="113" data-permalink="https://ottverse.com/h266_vvc/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=1920%2C1080&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="h266_vvc" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=1024%2C576&amp;ssl=1" loading="lazy" width="1024" height="576" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" alt="versatile video coding vvc h266" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1568%2C882&amp;ssl=1 1568w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?w=1920&amp;ssl=1 1920w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Touted as a successor to HEVC, the Versatile Video Coding standard has a lofty goal of achieving at least a 30% improvement in compression efficiency over HEVC. This should be doable considering the allowance of the â€œ10x complexity increaseâ€ that the committee has provided.</p>



<p>In&nbsp;<a href="https://mpeg.chiariglione.org/sites/default/files/files/standards/parts/docs/w17074.zip" target="_blank" rel="noopener">the MPEG Requirements document</a>&nbsp;for VVC (H.266), a few interesting points stand out with regards to compression efficiency, coding complexity, etc.</p>



<ul><li><strong>A substantial improvement in compression efficiency compared to HEVC Main Profile is required for the target application(s);</strong>&nbsp;at no point of the entire bit rate range shall it be worse than existing standard(s).&nbsp;<strong>30% bitrate reduction for the same perceptual quality is sufficient for some important use-cases and may justify a future video coding standard</strong>. Other use-cases may require higher bit-rate reductions such as 50%.</li><li><strong>Encoding complexity of approximately 10 times or more than that of HEVC</strong>&nbsp;is acceptable for many applications.</li><li><strong>The standard shall enable the use of efficient prediction structures (e.g. so-called open groups of pictures) without compromising from the fast and seamless representation switching capability between representations of different properties, such as different spatial resolutions.</strong></li><li>Support for&nbsp;<strong>progressive scanning shall be required for all Profiles and Levels</strong>.</li></ul>



<p>What stands out to me the most in the Requirements document are the references to â€œ<strong>fast-switching</strong>â€ and â€œ<strong>progressive scanning</strong>â€œ. This is a clear indication of the importance that the MPEG body is placing on OTT streaming&nbsp;<em>(and the implicit absence of interlaced video in OTT)</em>.</p>



<p>This was a HUGE problem in HEVC where interlaced support was an after-thought; and it lead to a lot of code-wrangling to retro-fit interlaced support into commercial codecs. I hope VVC does not tread the same interlaced path.</p>



<p>The second comment about fast-switching is interesting and might put pressure on codec vendors to insert more IDRs in the bitstream to support smaller segment sizes and clean, fast, switching between profiles in the ABR bitrate ladder. The reference to open-gops is interesting, because Open-GOPs are very helpful in increasing compression efficiency â€“ so this is something fun to watch out for.</p>



<p>Whenever a discussion about MPEGâ€™s video codecs comes up, the elephant in the room has to be&nbsp;<strong>licensing</strong>. Fraunhofer HHI said in their&nbsp;<a href="https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1" target="_blank" rel="noopener">newsletter</a>&nbsp;that,</p>



<blockquote><p>A uniform and transparent licensing model based on the FRAND principle (i.e., fair, reasonable, and non-discriminatory) is planned to be established for the use of standard essential patents related to H.266/VVC. For this purpose, the Media Coding Industry Forum (MC-IF) was founded.</p></blockquote>



<p>I hope VVC pans out because Iâ€™d love to see it in action crunching 4K/8K videos!</p>



<p><strong>Read <a href="https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/">OTTVerseâ€™s update of MulticoreWareâ€™s x266 encoder for VVC.</a></strong></p>



<p><strong>Reference</strong>&nbsp;â€“&nbsp;<a href="https://mpeg.chiariglione.org/standards/exploration/future-video-coding/requirements-a-future-video-coding-standard-v5" target="_blank" rel="noopener">Requirements for a Future Video Coding Standard V5</a></p>



<h2 id="essential-video-coding---evc-mpeg-5-part-1"><span id="Essential_Video_Coding_%E2%80%93_EVC_(MPEG5_Part_1)"></span>Essential Video Coding â€“ EVC (MPEG-5 Part 1)<span></span></h2>



<p>MPEG-5 EVC or Essential Video Coding is an MPEG standard backed by Samsung, Huawei, Qualcomm, Divideon as a response to the patent pool mess that HEVC ran it that essentially stymied large-scale adoption of a powerful video compression standard.</p>



<p>The&nbsp;<a href="https://mpeg.chiariglione.org/sites/default/files/files/standards/parts/docs/w17928.zip" target="_blank" rel="noopener">requirements of the EVC standard</a>&nbsp;were very clearly specified by MPEG as follows â€“</p>



<ul><li>The test model should consist of two tool sets:&nbsp;<strong>a base and an enhanced tool set</strong></li><li>The base tool set should be configured with tools that were made public more than 20 years ago or for which a Type 1 declaration is received</li><li>There should be additional tools in the enhanced tool set, each of which shall provide a significant improvement in coding efficiency and be capable of being cleanly switched off on an individual basis</li></ul>



<p>EVCâ€™s aim is crystal-clear â€“ provide a royalty-free option for content producers while also providing adequate tools, algorithms, and knobs to produce higher quality video (than the base tool set). And, the enhancement layerâ€™s tools (also referred to as the Main layer) will be subject to royalties.</p>



<p>Sounds good, eh?</p>



<figure><img data-attachment-id="95" data-permalink="https://ottverse.com/evc-block-diagram-2019/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=700%2C336&amp;ssl=1" data-orig-size="700,336" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="evc-block-diagram-2019" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=300%2C144&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=700%2C336&amp;ssl=1" loading="lazy" width="700" height="336" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=700%2C336&amp;is-pending-load=1#038;ssl=1" alt="Block Diagram of the EVC Codec Presented at IBC2019 showing the Enhancement Layer tools in gray boxes" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?w=700&amp;ssl=1 700w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=300%2C144&amp;ssl=1 300w" data-lazy-sizes="(max-width: 700px) 100vw, 700px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=700%2C336&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Block Diagram of the EVC Codec Presented at IBC2019 showing the Enhancement Layer tools in gray boxes</figcaption></figure>



<p>It is also interesting to note the following sentence from the&nbsp;<a href="https://www.ibc.org/download?ac=10463" target="_blank" rel="noopener">IBC 2019 paper on EVC</a>&nbsp;and I quote,</p>



<blockquote><p>No considerations have been taken on licensing aspects of the technology other than a requirement for FRAND commitment by the contributors.&nbsp;<strong>Commercial aspects, and in particular, licensing aspects have been handled externally and independently of MPEG.</strong></p></blockquote>



<p>Theyâ€™ve been handled, huh? Okay cool, but I still cross my fingers and say a prayer when I hear â€œMPEGâ€ and â€œLicensingâ€ in the same sentence.</p>



<p>Letâ€™s hope that EVC is adopted and supported in the industry quickly â€“ its a good concept and means well.</p>



<p>In a future article, we will do a deep dive into the tools supported in the Base and the Main layers of EVC.</p>



<p><strong>Reference</strong>&nbsp;â€“&nbsp;<a href="https://www.ibc.org/download?ac=10463" target="_blank" rel="noopener">The Emerging MPEG-5 EVC Standard â€“ Applications, Technology, and Results presented at IBC 2019</a></p>



<h2 id="low-complexity-enhancement-video-coding---lcevc-mpeg-5-part-2"><span id="Low_Complexity_Enhancement_Video_Coding_%E2%80%93_LCEVC_(MPEG5_Part_2)"></span>Low Complexity Enhancement Video Coding â€“ LCEVC (MPEG-5 Part 2)<span></span></h2>



<p>MPEG-5 Part 2 LCEVC is being introduced with the aim of increased compression efficiency for existing codecs at little or no-increase in coding complexity by using a base bitstream and an enhancement bitstream.</p>



<p>The LCEVC codecâ€™s output is essentially a combination of a â€œbase bitstreamâ€ produced by an existing video codec such as AVC, HEVC, VP9, AV1, etc. along with enhancement layers that can be used conditionally to improve the quality of the video.</p>



<p>If the decoder/end-device supports LCEVC, the enhancement layers are decoded, else, the base codec alone is used to decode the bitstream and the video is rendered to the user. This ensures backward-compatibility and encourages roll-out of the LCEVC codec without the fear of breaking the end-userâ€™s experience.</p>



<p>This concept is nicely captured in the figure below taken from Guido Meardiâ€™s&nbsp;<a href="https://www.itu.int/en/ITU-T/Workshops-and-Seminars/20191008/Documents/Guido_Meardi_Presentation.pdf" target="_blank" rel="noopener">presentation</a>&nbsp;at the ITU Workshop on the Future of Media in Geneva.</p>



<figure><img data-attachment-id="124" data-permalink="https://ottverse.com/lcevc-layers-video-coding/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" data-orig-size="800,354" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-layers-video-coding" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=300%2C133&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" loading="lazy" width="800" height="354" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=800%2C354&amp;is-pending-load=1#038;ssl=1" alt="lcevc mpeg5 part2" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=300%2C133&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=768%2C340&amp;ssl=1 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=800%2C354&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>For further details on LCEVC, please read </p>



<ul><li>our&nbsp;<a href="https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/">architecture deep-dive</a>&nbsp;on LCEVC.</li><li><a href="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/">comparison of LCEVC against H.264/AVC.</a></li></ul>



<p>On a final note, V-Nova has been instrumental in driving the LCEVC standard through their research and work on the Perseus codec. More information on that&nbsp;<a href="https://www.v-nova.com/v-nova-video-compression-technology/" target="_blank" rel="noopener">here</a>.</p>



<h2 id="what-next"><span id="What_Next"></span>What Next?<span></span></h2>



<p>I think 2020 and 2021 present great challenges and opportunities for the field of video compression.</p>



<p>With consumption increasing due to the COVID-19 situation, most content providers are under the gun to reduce their streaming costs. Dropping the bitrates is one way of reducing your streaming costs, but, conversely, it will be hard to compete with the likes of Netflix, Hulu, HBO, Peacock, fuboTV, DAZN with poor video quality.</p>



<p>If the compression experts can pull off VVCâ€™s goals of 30% bitrate savings over HEVC, then it will be a huge win. The only thing theyâ€™ll have to ensure is that they donâ€™t blow their foot off with licensing issues (<em>a-la-HEVC</em>). If things work out properly, VVC should be a good competitor to AV1 especially at high resolutions such as 4K and 8K.</p>



<p><em><strong>However</strong></em>, that being said, I think that among the three codecs â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/">https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948460</guid>
            <pubDate>Sat, 31 Oct 2020 01:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can we tell that 2â‰ 1?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948031">thread link</a>) | @samm81
<br/>
October 30, 2020 | http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/ | <a href="https://web.archive.org/web/*/http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<!-- .entry-meta -->
<section id="eu_cookie_law_widget-3">
<div data-hide-timeout="30" data-consent-expiration="180" id="eu-cookie-law">
	<p>

	Privacy &amp; Cookies: This site uses cookies. By continuing to use this website, you agree to their use. <br>
To find out more, including how to control cookies, see here:
		<a href="https://automattic.com/cookies/" rel="nofollow">
		Cookie Policy	</a>
</p></div>
</section><p>What if I told you that $2=1$? You may say Iâ€™m wrong. OK, well, what if I proved it to you? We can both agree that thereâ€™s an $x$ and a $y$ where $x = y$. From there, <a href="https://math.hmc.edu/funfacts/one-equals-zero/" target="_blank" rel="noopener noreferrer">multiply, subtract, factorise, divide, substitute, divide again</a>, and you get $2 = 1$.</p>
<p>Still not happy? Youâ€™re probably unconvinced by my so-called â€˜proofâ€™. OK, I say, and, after a minute, hand you a sheet of paper with the following hastily scrawled on it: <a href="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png"><img loading="lazy" src="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=204%2C188" alt="" width="204" height="188" srcset="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=300%2C277 300w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=1%2C1 1w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?w=470 470w" sizes="(max-width: 204px) 100vw, 204px" data-recalc-dims="1"></a>Itâ€™s better, but youâ€™re still displeased. This time, Iâ€™ve made clear what steps Iâ€™m taking from $x = y$ to $2 = 1$. However, you point out, I donâ€™t connect any of these steps. Nodding slowly, I take my time and write out a very nice, orderly proof, complete with justifications for each line:<a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png"><img loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=454%2C241" alt="" width="454" height="241" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?w=1200 1200w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=300%2C160 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=1024%2C544 1024w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=768%2C408 768w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=2%2C1 2w" sizes="(max-width: 454px) 100vw, 454px" data-recalc-dims="1"></a></p>
<p>At this point, you spot my mistake: in going from line 4 to 5, I have divided both sides by $x-y$. But we began with the assumption that $x = y$, meaning that $x-y = 0$, and dividing by 0 is not defined! This means that lines 5 to 7 are operating on nonexistent values and are therefore meaningless.</p>
<p>Youâ€™re happy with yourself, but something is bothering you. To reveal my mistake, you asked me to be more precise. But why stop here? Because you found what you were looking for? Thatâ€™s not how truth is found.</p>
<p>My proof, like all proofs, is a path from one statement to another, just as we may follow the path from $ax^2 + bx + c = 0$ to $x = \big(-b \pm \sqrt{b^2-4ac}\big)/{2a}$, or from the existence of rectangles to the transitivity of parallelism (see below). Along this path I have made several intermediate statements, and linked them together with justifications. You found that one of my links is flawed, and you wonder how we know that the others arenâ€™t also wrong. You begin to question foundational principles, wondering, for instance, <a href="https://math.stackexchange.com/a/805939/24325" target="_blank" rel="noopener noreferrer">why weâ€™re even allowed to do the same thing to both sides of an equation</a>.</p>
<p><strong>Euclidean geometry:</strong> For the unfamiliarâ€”Euclidean geometry (standard geometry on a flat surface) rests on 5 assumptions, one of which (the <em>parallel postulate</em>) has historically been regarded as ugly. In attempting to eliminate the parallel postulate, mathematicians have found numerous other statements that are equivalent to it, such as that a rectangle exists or that parallelism is transitive.</p>
<p>You keep digging deeper and deeper, questioning more and more of what you previously took to be correct. Eventually, you come across a piece of mathematics that is perhaps the most beautiful and elegant thing youâ€™ve ever laid your eyes upon: <em>natural deduction</em>.</p>
<h2>Natural deduction</h2>
<p>Natural deduction is one result of asking for deeper and deeper justification when doing maths. A system of natural deduction is a set of very simple, almost irrefutable rules that act to formalise our intuition about what is <em>definitely true</em>.</p>
<div id="attachment_15535"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png"><img aria-describedby="caption-attachment-15535" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?resize=124%2C71" alt="" width="124" height="71" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?w=293 293w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?resize=2%2C1 2w" sizes="(max-width: 124px) 100vw, 124px" data-recalc-dims="1"></a></p><p id="caption-attachment-15535">Reiteration (R): if $P$, then $P$.</p></div>
<p>These rules include such things as <em>reiteration</em>, which simply allows us to repeat ourselves. Precisely, reiteration says that if you know that a statement $P$ is true, then you can conclude that $P$ is true. This is hardly controversial.</p>
<div id="attachment_15536"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png"><img aria-describedby="caption-attachment-15536" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=193%2C120" alt="" width="193" height="120" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?w=422 422w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=300%2C187 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=2%2C1 2w" sizes="(max-width: 193px) 100vw, 193px" data-recalc-dims="1"></a></p><p id="caption-attachment-15536">Conjunction introduction ($\land$I): if $P$ and $Q$ then $P\land Q$.</p></div>
<p>There are two rules for the natural idea of â€˜andâ€™. First is the so-called <em>conjunction introduction</em> rule, stating that if you know that $P$ and $Q$ are both true, then you may conclude $P \land Q$, pronounced â€˜$P$ and $Q$â€™. On the other side, we have <em>conjunction elimination</em>, stating that if you know that $P \land Q$ is true, then you may conclude $P$ and also may conclude $Q$.</p>
<div id="attachment_15537"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png"><img aria-describedby="caption-attachment-15537" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=176%2C121" alt="" width="176" height="121" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?w=384 384w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=300%2C205 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=1%2C1 1w" sizes="(max-width: 176px) 100vw, 176px" data-recalc-dims="1"></a></p><p id="caption-attachment-15537">Conjunction elimination ($\land$E): if $P\land Q$, then $P$ and $Q$.</p></div>
<p>These rules donâ€™t feel like they do much besides swapping out â€˜andâ€™ for â€˜$\land$â€™; however, doing so is important for formality and precision.</p>
<div id="attachment_15538"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png"><img aria-describedby="caption-attachment-15538" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=172%2C78" alt="" width="172" height="78" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?w=373 373w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=300%2C136 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=2%2C1 2w" sizes="(max-width: 172px) 100vw, 172px" data-recalc-dims="1"></a></p><p id="caption-attachment-15538">Disjunction introduction ($\lor$I): if $P$, then $P\lor Q$.</p></div>
<p>Things start to get tricky with the rules codifying â€˜orâ€™. The first, <em>disjunction introduction</em>, tells us that if $P$ is true, then you may conclude $P \lor Q$, pronounced â€˜$P$ or $Q$â€™: if I am hungry, then itâ€™s also true that Iâ€™m either hungry or tired.</p>
<div id="attachment_15539"><p><a href="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png"><img aria-describedby="caption-attachment-15539" loading="lazy" src="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=258%2C332" alt="" width="258" height="332" srcset="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?w=568 568w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=232%2C300 232w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=1%2C1 1w" sizes="(max-width: 258px) 100vw, 258px" data-recalc-dims="1"></a></p><p id="caption-attachment-15539">Disjunction elimination ($\lor$E): if $P\lor Q$ and from $P$ we can prove $X$ and from $Q$ we can prove $X$, then $X$.</p></div>
<p>The second rule, <em>disjunction elimination</em>, states that if $P \lor Q$ is true, and from $P$ you can prove $X$, and from $Q$ you can prove $X$, then you may conclude $X$. More colloquially, if either $P$ or $Q$ is true, and in both cases $X$ is true, too, then $X$ is true. For example, if Iâ€™m either well-rested or well-fed, and being well-rested makes me happy, and being well-fed makes me happy, then I must be happy.</p>
<div id="attachment_15540"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png"><img aria-describedby="caption-attachment-15540" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=222%2C212" alt="" width="222" height="212" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?w=472 472w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=300%2C287 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=1%2C1 1w" sizes="(max-width: 222px) 100vw, 222px" data-recalc-dims="1"></a></p><p id="caption-attachment-15540">Implication introduction ($\Rightarrow$I): if from $P$ we can prove $Q$, then $P\Rightarrow Q$.</p></div>
<p>Then come the rules regarding implication. We have <em>implication introduction</em>, stating that if from $P$ we can prove $Q$, then we may conclude $P \Rightarrow Q$, pronounced â€˜$P$ implies $Q$â€™. And we have <em>implication elimination</em> (also known as <em>modus ponens</em>), which states that if $P \Rightarrow Q$ is true and $P$ is true, then we can conclude $Q$. If the weather being rainy implies that I am cosy, and the weather is rainy, then I must be cosy.</p>
<div id="attachment_15541"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png"><img aria-describedby="caption-attachment-15541" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=220%2C121" alt="" width="220" height="121" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?w=477 477w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=300%2C165 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=2%2C1 2w" sizes="(max-width: 220px) 100vw, 220px" data-recalc-dims="1"></a></p><p id="caption-attachment-15541">Implication elimination ($\Rightarrow$E): if $P\Rightarrow Q$ and $P$, then $Q$.</p></div>
<p>Finally, we come to the most arcane rules, those handling negation. The negation of $P$ is written $\neg P$ and pronounced â€˜not $P$â€™. Before talking about the $\neg P$ rules, however, we must first introduce a new symbol: $\bot$ (pronounced â€˜bottomâ€™), which represents impossibility or contradiction. We can then introduce <em>bottom introduction</em>, which states that if both $P$ and $\neg P$ are true, which is absurd (usuallyâ€¦ there are systems of logic that admit both $P$ and $\neg P$ at the same time, called <em>paraconsistent</em> logics), then we can conclude $\bot$, to represent this impossibility.</p>
<div id="attachment_15542"><p><a href="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png"><img aria-describedby="caption-attachment-15542" loading="lazy" src="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=195%2C134" alt="" width="195" height="134" srcset="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?w=383 383w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=300%2C206 300w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=1%2C1 1w" sizes="(max-width: 195px) 100vw, 195px" data-recalc-dims="1"></a></p><p id="caption-attachment-15542">Bottom introduction ($\bot$I): if $P$ and $\neg P$, then $\bot$.</p></div>
<p>Weâ€™re then able to make use of $\bot$ through <em>negation introduction</em>, which states that if from $P$ we can prove $\bot$, then we can conclude $\neg P$. This is reasonable; if $P$ being true led to a contradiction, then $P$ isnâ€™t true, so $\neg P$ is.</p>
<div id="attachment_15543"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png"><img aria-describedby="caption-attachment-15543" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=228%2C231" alt="" width="228" height="231" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?w=443 443w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=295%2C300 295w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=1%2C1 1w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=45%2C45 45w" sizes="(max-width: 228px) 100vw, 228px" data-recalc-dims="1"></a></p><p id="caption-attachment-15543">Negation introduction ($\neg$I): if from $P$ we can prove $\bot$, then $\neg P$.</p></div>
<p>Finally we have <em>negation elimination</em>. This one is a nice easy way to end: it says that if we know $\neg \neg P$, then we can conclude $P$. If something isnâ€™t not true, then it must be true!</p>
<div id="attachment_15532"><p><a href="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png"><img aria-describedby="caption-attachment-15532" loading="lazy" src="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=173%2C78" alt="" width="173" height="78" srcset="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?w=372 372w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=300%2C135 300w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=2%2C1 2w" sizes="(max-width: 173px) 100vw, 173px" data-recalc-dims="1"></a></p><p id="caption-attachment-15532">Negation elimination ($\neg$E): if $\neg\neg P$, then $P$.</p></div>
<p>And with that, we have completed (one kind of) natural deduction, laying out a framework for proofs based on undeniable principles so that we can be <em>completely</em> confident in our results.</p>
<p>Now, you may be wondering, hey, maths is about numbers and shapes and functions and vector fields, but all weâ€™ve been working with are $P$s and $Q$s! Not a single $n$ or $x$, let alone an $f$, has been written so far!</p>
<p>Fear not! Purely logical systems such as natural deduction are key ingredient for building typical maths. For example, to define numbers, we may first extend to <a href="https://www.quora.com/What-is-the-precise-difference-between-propositional-and-predicate-logic" target="_blank" rel="noopener noreferrer">predicate logic</a>, then construct the naturals (via the <em><a href="https://en.wikipedia.org/wiki/Peano_axioms" target="_blank" rel="noopener noreferrer">Peano axioms</a></em>), which weâ€™ll use to make the <a href="http://www.math.hawaii.edu/~pavel/syllabi_old/aluffi_321/NZ.pdf" target="_blank" rel="noopener noreferrer">integers</a> and the <a href="https://people.clas.ufl.edu/groisser/files/rationals.pdf" target="_blank" rel="noopener noreferrer">rationals</a> (via equivalence classes), then finally the reals (via <em><a href="https://en.wikipedia.org/wiki/Dedekind_cut" target="_blank" rel="noopener noreferrer">Dedekind cuts</a></em>).</p>
<p>So, in fact, we still we get to work with all the maths weâ€™re used to! Plus, due to the use of natural deduction, we have the added benefit of being confident about what weâ€™re doing at every layer of abstraction!</p>
<p><strong>Predicate and propositional logic:</strong> The logic weâ€™ve been building, with $\land$, $\lor$, $\Rightarrow$, $\neg$, and $\bot$, is known as <em>propositional</em> or <em>zeroth-order logic</em>. <em>Predicate</em> or <em>first-order logic</em> is an extension of propositional logic wherein our statements ($P$, $Q$, $X$, etc) may be parametrised. So as well as having $H$ mean that â€˜I am hungryâ€™, we may also have $\mathcal H(x)$ mean that â€˜$x$ is hungryâ€™. Additionally, predicate logic includes two <em>quantifiers</em>, $\forall$ and $\exists$, which respectively mean â€˜for everyâ€™ and â€˜there existsâ€™: $\forall x \mathcal H(x)$ means that everyone is hungry, and $\exists x \mathcal H(x)$ means that (at least) one person is hungry.</p>
<h2>So what?</h2>
<p>If youâ€™re anything like I was at age 17, or anything like how I portrayed you in the beginning of this article, youâ€™re drooling right now. Itâ€™s like all of your fantasies regarding rigour and precision have been heard and answered by divine mathematicians.</p>
<p>But maybe youâ€™re not intrinsically motivated by rigour, so youâ€™re less excited by natural deduction. Which is fine! Iâ€™m not hurt. Maybe a little bit. Or maybe you just feel that this is overkillâ€”did you <em>really</em> need all this work to know that $2 \neq 1$? Or maybe youâ€™re not convinced that these rules are correct; perhaps you donâ€™t agree that from $\neg \neg P$ we can conclude $P$.</p>
<p><strong>Excluding the middle:</strong> If you donâ€™t agree, you are not alone! That $\neg \neg P$ entails $P$ is a consequence of a rule called the <em>law of excluded middle</em>, which states that $P \lor \neg P$. (This law is built-in to the system of natural deduction that we created.) Some mathematicians (<a href="https://en.wikipedia.org/wiki/Intuitionistic_logic" target="_blank" rel="noopener noreferrer">the <em>intuitionists</em> or <em>constructionists</em></a>) reject the law of excluded middle, thus also forfeiting that $\neg \neg P$ entails $P$. One reason to question the law of excluded middle is that it allows us to state that something exists without stating what it is. For instance, we are able to <a href="https://math.stackexchange.com/a/104121/243259" target="_blank" rel="noopener noreferrer">prove that an irrational number raised to the power of an irrational number can be rational</a>, but <em>without</em> giving an actual example. If we reject the law of excluded middle, then all such proofs must <em>actually construct</em> an example.</p>
<p>Still, I posit, natural deduction is worth your time. Because weâ€™ve been so rigorous in building the system up, we gain the benefit of knowing <em>exactly what weâ€™re talking about</em>. Before establishing such precision, we may have used $P \Rightarrow Q$, but without a sense of â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/">http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/</a></em></p>]]>
            </description>
            <link>http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948031</guid>
            <pubDate>Sat, 31 Oct 2020 00:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Better at CSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24947963">thread link</a>) | @taphangum
<br/>
October 30, 2020 | https://planflow.dev/blog/how-to-get-better-at-css | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/how-to-get-better-at-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The key reason why you (and likely most developers) struggle with CSS, is that you underestimate it.</p><p>Underestimating CSS leads to a strange feeling of tediousness when writing it, which makes having to deal with it a laborious and seemingly unrewarding task. Style by style, div by div, media query by media query. Having to make endless small tweaks in what feels like an open-ended â€˜designâ€™ process with no direction at all can feel like torture to a development-oriented mind.</p><p>Not to mention a complete lack of debugging tools and methods available for when things go wrong.</p><p>This underestimation is a subset of a problem that we developers tend to have with design in general. In short, we donâ€™t think itâ€™s that important. We donâ€™t understand or appreciate its <em>meaning</em>.</p><p>In reality, CSS is as complicated, maybe more so, as any programming language or framework you will ever come across.</p><p>But the general feeling that it is an afterthought within the development process overall, only adds fuel to fire of the thought that leads you to feel that it is tedious.</p><p>The best way to start to get better at it then, is to gain a new appreciation for it, as a 'hard', technical thing. Which it is.</p><p><strong>You do this by reframing how you see it.</strong></p><p>You can start to learn to like CSS by understanding it from a problem solving technical aspect. As an act of 'constructing' a page rather than 'designing' it. By <a target="_blank" title="https://simpleprogrammer.com/information-architecture-developers-learning-design/" href="https://simpleprogrammer.com/information-architecture-developers-learning-design/">engaging the engineering side of your mind</a>.</p><p>Instead of seeing CSS as an annoying way to 'style' pages, see it instead as a visual programming language for constructing visual guides (UI's) for your user.</p><p>You don't 'style' pages, you 'construct' and 'architect' them. It sounds weird to use these words, but they have a massive effect on changing your perception of what you're doing. And that has a massive effect on your impression and willingness to learn how to do it well.</p><p>Essentially, you can properly learn CSS by transforming it in your mind from a 'styling' problem thing, to an 'engineering' problem thing.</p><p>This defeats the feeling of tedium that your mind has when youâ€™re dealing with CSS, and over time, if applied with some of the specific additional tactics that I will explain below, leads to actually _enjoying_ the process of writing CSS.</p><h2>Tactics That Reduce CSS Tediousness &amp; Lead To CSS Enjoyment</h2><p>Once youâ€™ve started to reframe the act of utilizing CSS in your mind, and start to see it as more of a tool for an engineering problem rather than a â€˜designâ€™ problem, embers of enjoyment will start to emerge within you as you are writing your CSS. From here, you can start to add some fuel to the growing fire. </p><p>You can do this by utilizing some strategies, tools and techniques that further reduce the tediousness of CSS. </p><p><strong>Letâ€™s go through them.</strong></p><h3>Use tediousness reducing tools, such as <a target="_blank" title="https://tailwindcss.com/" href="https://tailwindcss.com/">TailwindCSS</a>. So you can abstract CSS.</h3><p>I remember back a few years ago when the <a target="_blank" title="https://laravel.com/" href="https://laravel.com/">Laravel Framework</a> came out. PHP Programmers all over the web were fawning over it. The most common phrase I heard was that it gave programmers â€œtheir enjoyment of programmingâ€ back. This with a language that was notoriously derided as one that was tedious to use.</p><p>What Laravel did was abstract a lot of the annoying parts of most of these developers' workflows when writing PHP code. These developers, at this newfound higher level of abstraction, could now focus on â€˜craftingâ€™ their applications, becoming â€˜artisansâ€™ of their code rather than simply PHP programmers.</p><p>TailwindCSS does the same thing for CSS. Instead of moving from one file to another to define your styles, Tailwind uses standard default class presets that allow you to write your CSS, essentially directly onto your HTML elements. This <a target="_blank" title="https://news.ycombinator.com/item?id=24034619" href="https://news.ycombinator.com/item?id=24034619">might sound weird</a> at first, but in the end, actually results in a LOT of saved time in development.</p><p>Over time, it, along with other tools, such as Flexbox, also massively increases enjoyment, as you start to intuitively â€˜craftâ€™ and construct pages at a higher level of abstraction, rather than simply â€˜styleâ€™ them.</p><p><strong>Fun fact</strong><strong>:</strong> The creator of TailwindCSS, <a target="_blank" title="https://twitter.com/adamwathan" href="https://twitter.com/adamwathan">Adam Wathan</a> actually started out as a Laravel Developer, so maybe that enthusiasm crossed over to his other project areas.</p><p><strong>EDIT</strong><strong>:</strong> I recently came across a very nice feature in Firefox that helps in debugging overflow issues (one of the most common CSS problems). You can see it in action <a target="_blank" title="https://twitter.com/violasong/status/1314406711696912386" href="https://twitter.com/violasong/status/1314406711696912386">here</a>.</p><h3>Understand how to solve common problems in CSS</h3><p>Because of the lack of debugging tools that are currently available for CSS. Most of debugging within it largely consists of cross-referencing ways that others have dealt with the issue youâ€™re currently facing.</p><p>While this is likely not an uncommon practice in your development workflow (its why StackOverflow exists), it is very time consuming if it is the ONLY way that you can debug. </p><p>One way around this issue is to become familiar with the most common pattern of problems that occur within CSS, and then try to build a repository of solutions to those problems in your mind over time. This sounds simple enough but it very dramatically decreases tedium and increases productivity and speed of development, which ultimately increases your enjoyment.</p><p>For example, one of the most common issues, as referenced in the post drawing, is â€˜overflowâ€™ of elements occurring within the page. Sometimes causing the entire page itself to overflow at certain screen sizes. A tutorial like this, outlines the best way to solve this problem.</p><p><strong>Sidenote</strong><strong>:</strong> We are creating a short ebook that deals with this problem, by outlining these most common CSS problems and their solutions, you can sign up for notification of this here: <a target="_blank" title="https://forms.gle/tXRMnpyUZiFmvZwK8" href="https://forms.gle/tXRMnpyUZiFmvZwK8">How To Debug CSS</a>.</p><h3>Master layouts and positioning in CSS (the most tedious aspect of it)</h3><p>As a follow-on to the above point on simply gaining an understanding of the most common aspects of the CSS writing process, the most common of these in terms of general page creation, is that of simply layout out a page, and its elements and making sure that they are positioned and aligned properly. </p><p>The best way to approach problems in a way that solves them most effectively is in an 80/20 way. Mastery of layouts and positioning is the 20% that leads to the 80% of results with CSS. And what will have the most dramatic effect on reducing the tediousness of your CSS writing process.</p><p>Using tools such as Flexbox, as is mentioned above, also makes layouts and positioning twice as easy, once you understand the fundamentals behind it. </p><p>Overall, itâ€™s with this knowledge that you may start to enjoy and view the process as â€˜constructingâ€™ pages, rather than simply â€˜stylingâ€™ them.</p><h3>Practice regularly until it becomes second nature</h3><p>One simple thing that I found, as I started to implement some of the tactics above into my own workflow, was that as I became more proficient in writing CSS and it started to become second nature, my enjoyment of it also started to increase, which lead to a positive feedback loop that kept increasing my overall ability.</p><p>This is a very positive flywheel that I highly encourage. Once youâ€™ve started to change your mindset about CSS and use the right tools to abstract a lot of the tediousness out of it, practicing it regularly is then like adding jet fuel to your workflow. Eventually, CSS will become something you look forward to, rather than an afterthought that you try to avoid.</p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/how-to-get-better-at-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947963</guid>
            <pubDate>Sat, 31 Oct 2020 00:01:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Service to Service Authorization in Go Using X.509 Certificates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947756">thread link</a>) | @regeda
<br/>
October 30, 2020 | https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/ | <a href="https://web.archive.org/web/*/https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Service-to-service authentication is the ability of one service to identify its clients. Itâ€™s a good idea to ensure that a service accepts requests only from specified services. But how to implement access controls (authorization)?</p>
<p>For instance, only the service <code>cart</code> is granted to bind to the service <code>invoice</code>, and only two services <code>invoice</code> and <code>billing</code> are granted to bind to the service <code>payment</code>.</p>
<p><img src="https://regeda.me/s2s_seq.svg" alt="Alt text"></p>
<p>Firstly, we must decide on the unique key of service, the attribute of a caller to be verified by a recipient. Do you think the IP address or hostname is manageable in the infrastructure at scale? Itâ€™s challenging in a multi-tenant environment where different personas can park successively the same network identity in a short period.</p>
<p>Letâ€™s consider an <a href="https://searchsecurity.techtarget.com/definition/X509-certificate">X.509 certificate</a> which is a widely used standard for network security and identity verification.</p>
<h2 id="give-a-secure-identity-to-components">Give a secure identity to components</h2>
<p>We could go over the long way to <a href="https://www.semurity.com/how-to-setup-your-own-certificate-authority-ca-using-openssl/">set up your own Certificate Authority and sign a certificate using OpenSSL</a>. For the sake of simplicity, I use the <a href="https://github.com/cloudflare/cfssl"><strong>sfssl</strong></a> toolkit for certificates management.</p>
<h3 id="installation">Installation</h3>
<div><pre><code data-lang="shell">go get -u github.com/cloudflare/cfssl/cmd/...
</code></pre></div><h3 id="configuration">Configuration</h3>
<p>The <code>sfssl</code> toolkit expects two files to generate a certificate:</p>
<ul>
<li><code>config.json</code> â€“ settings for the issuer</li>
<li><code>csr.json</code> â€“ request for a certificate.</li>
</ul>
<p>The file <code>config.json</code> contains settings for the Certificate Authority. We are interested in the <code>profiles</code> section for our certificates:</p>
<div><pre><code data-lang="json">{
  <span>"signing"</span>: {
    <span>"profiles"</span>: {
      <span>"service"</span>: {
        <span>"usages"</span>: [
          <span>"signing"</span>,
          <span>"key encipherment"</span>,
          <span>"server auth"</span>,
          <span>"client auth"</span>
        ],
        <span>"expiry"</span>: <span>"720h"</span>
      }
    }
  }
}
</code></pre></div><p>The file <code>csr/ca.json</code> contains the request for the Certificate Authority certificate:</p>
<div><pre><code data-lang="json">{
  <span>"CN"</span>: <span>"Demo Citadel"</span>,
  <span>"names"</span>: [
    {
      <span>"C"</span>: <span>"US"</span>,
      <span>"L"</span>: <span>"San Francisco"</span>,
      <span>"O"</span>: <span>"Citadel, Inc."</span>,
      <span>"ST"</span>: <span>"CA"</span>
    }
  ],
  <span>"ca"</span>: {
    <span>"expiry"</span>: <span>"86700h"</span>
  }
}
</code></pre></div><p>The file <code>csr/service.json</code> contains the request for the service certificate:</p>
<div><pre><code data-lang="json">{
  <span>"CN"</span>: <span>"citadel.xyz"</span>,
  <span>"names"</span>: [
    {
      <span>"C"</span>: <span>"US"</span>,
      <span>"L"</span>: <span>"San Francisco"</span>,
      <span>"O"</span>: <span>"Citadel, Inc."</span>,
      <span>"ST"</span>: <span>"CA"</span>
    }
  ]
}
</code></pre></div><h3 id="generating">Generating</h3>
<p>The Certificate Authority certificate:</p>
<div><pre><code data-lang="shell">cfssl gencert -initca csr/ca.json | cfssljson -bare pki/ca â€“
</code></pre></div><p>Meantime, we reached the important step and have to define the unique attribute of service. Usually, the service has a name and it belongs to a company. Hence we need to stamp the identity <code>citadel:srv-invoice</code> into the handcrafted X.509 certificate along with the server hostname <code>host1.infra.citadel.net</code>:</p>
<div><pre><code data-lang="shell">cfssl gencert <span>\
</span><span></span>-ca pki/ca.pem -ca-key pki/ca-key.pem <span>\
</span><span></span>-config config.json <span>\
</span><span></span>-profile service <span>\
</span><span></span>-hostname <span>'host1.infra.citadel.net,citadel:srv-invoice'</span> <span>\
</span><span></span>csr/service.json | cfssljson -bare pki/srv-invoice-host1 -
</code></pre></div><p>Letâ€™s check the resulted alternative name from the issued certificate:</p>
<div><pre><code data-lang="shell">openssl x509 -in pki/srv-invoice-host1.pem -text | grep -A <span>1</span> <span>'Alternative Name'</span>
</code></pre></div><pre><code>X509v3 Subject Alternative Name:
    DNS:host1.infra.citadel.net, URI:citadel:srv-invoice
</code></pre><p>ðŸ’š The service identity <code>citadel:srv-invoice</code> successfully assigned to the server <code>host1.infra.citadel.net</code>.</p>
<h2 id="consume-the-service-identity-in-go">Consume the service identity in Go</h2>
<p>Fortunately, the callback <code>VerifyConnection</code> of <a href="https://golang.org/pkg/crypto/tls/#Config"><code>tls.Config</code></a> was introduced in Go 1.15:</p>
<div><pre><code data-lang="go"><span>package</span> <span>tls</span>

<span>type</span> <span>Config</span> <span>struct</span> {
    <span>VerifyConnection</span> <span>func</span>(<span>ConnectionState</span>) <span>error</span>
}
</code></pre></div><p>The Go documentation says: if the function returns an error, the TLS handshake is aborted. Hence we are enabled to restrain the TLS connection permit by own.</p>
<p>For testing purposes, we make the simplest access control by a prefix:</p>
<div><pre><code data-lang="go"><span>var</span> <span>errAccessForbidden</span> = <span>errors</span>.<span>New</span>(<span>"access forbidden"</span>)

<span>func</span> <span>verifyPeerPrefix</span>(<span>prefix</span> <span>string</span>) <span>func</span>(<span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
	<span>return</span> <span>func</span>(<span>s</span> <span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
		<span>// The first element is the leaf certificate
</span><span></span>		<span>// that the connection is verified against.
</span><span></span>		<span>for</span> <span>_</span>, <span>uri</span> <span>:=</span> <span>range</span> <span>s</span>.<span>PeerCertificates</span>[<span>0</span>].<span>URIs</span> {
			<span>if</span> <span>strings</span>.<span>HasPrefix</span>(<span>uri</span>.<span>String</span>(), <span>prefix</span>) {
				<span>return</span> <span>nil</span>
			}
		}
		<span>return</span> <span>errAccessForbidden</span>
	}
}
</code></pre></div><p>Then prepare <code>tls.Config</code> for the server listener. Necessarily, the callback should be provided in conjunction with the mutual TLS authentication enabled:</p>
<div><pre><code data-lang="go"><span>cfg</span> <span>:=</span> <span>tls</span>.<span>Config</span>{
	<span>ClientAuth</span>:       <span>tls</span>.<span>RequireAndVerifyClientCert</span>,
	<span>VerifyConnection</span>: <span>verifyPeerPrefix</span>(<span>"citadel:srv"</span>),
}
</code></pre></div><blockquote>
<p>The constant <code>tls.RequireAndVerifyClientCert</code> of <a href="https://golang.org/pkg/crypto/tls/#ClientAuthType"><code>tls.ClientAuthType</code></a> indicates the server will request a client certificate and if none is provided the session will terminate, if the client certificate cannot be verified (a corresponding CA (root) certificate cannot be found) the session will also be terminated.</p>
</blockquote>
<p>The full source of the example server:</p>
<div><pre><code data-lang="go"><span>package</span> <span>main</span>

<span>import</span> (
	<span>"crypto/tls"</span>
	<span>"crypto/x509"</span>
	<span>"errors"</span>
	<span>"flag"</span>
	<span>"io"</span>
	<span>"io/ioutil"</span>
	<span>"log"</span>
	<span>"net"</span>
	<span>"strings"</span>
)

<span>var</span> (
	<span>listenAddr</span>   = <span>flag</span>.<span>String</span>(<span>"listen-addr"</span>, <span>"127.0.0.1:8080"</span>, <span>"Listen address for incoming connections"</span>)
	<span>certFile</span>     = <span>flag</span>.<span>String</span>(<span>"cert"</span>, <span>""</span>, <span>"Path to a PEM-encoded certificate"</span>)
	<span>keyFile</span>      = <span>flag</span>.<span>String</span>(<span>"key"</span>, <span>""</span>, <span>"Path to a private key matching the PEM-encoded certificate"</span>)
	<span>caFile</span>       = <span>flag</span>.<span>String</span>(<span>"ca"</span>, <span>""</span>, <span>"Path to a bundle of root certificates"</span>)
	<span>acceptPrefix</span> = <span>flag</span>.<span>String</span>(<span>"accept-prefix"</span>, <span>""</span>, <span>"Accept client certificates only with this prefix"</span>)
)

<span>func</span> <span>main</span>() {
	<span>flag</span>.<span>Parse</span>()

	<span>caCert</span>, <span>err</span> <span>:=</span> <span>ioutil</span>.<span>ReadFile</span>(<span>*</span><span>caFile</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"ca cert file could not be read:"</span>, <span>err</span>)
	}
	<span>rootCAs</span> <span>:=</span> <span>x509</span>.<span>NewCertPool</span>()
	<span>if</span> !<span>rootCAs</span>.<span>AppendCertsFromPEM</span>(<span>caCert</span>) {
		<span>log</span>.<span>Fatal</span>(<span>"ca cert file could not be installed"</span>)
	}

	<span>clientCert</span>, <span>err</span> <span>:=</span> <span>tls</span>.<span>LoadX509KeyPair</span>(<span>*</span><span>certFile</span>, <span>*</span><span>keyFile</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"client cert could not be loaded:"</span>, <span>err</span>)
	}

	<span>cfg</span> <span>:=</span> <span>tls</span>.<span>Config</span>{
		<span>Certificates</span>:     []<span>tls</span>.<span>Certificate</span>{<span>clientCert</span>},
		<span>ClientCAs</span>:        <span>rootCAs</span>,
		<span>ClientAuth</span>:       <span>tls</span>.<span>RequireAndVerifyClientCert</span>,
		<span>MinVersion</span>:       <span>tls</span>.<span>VersionTLS12</span>,
		<span>VerifyConnection</span>: <span>verifyPeerPrefix</span>(<span>*</span><span>acceptPrefix</span>),
	}

	<span>l</span>, <span>err</span> <span>:=</span> <span>tls</span>.<span>Listen</span>(<span>"tcp"</span>, <span>*</span><span>listenAddr</span>, <span>&amp;</span><span>cfg</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"listen failed:"</span>, <span>err</span>)
	}

	<span>log</span>.<span>Println</span>(<span>"Listen:"</span>, <span>*</span><span>listenAddr</span>)

	<span>for</span> {
		<span>conn</span>, <span>err</span> <span>:=</span> <span>l</span>.<span>Accept</span>()
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>log</span>.<span>Println</span>(<span>"ERR! accept failed:"</span>, <span>err</span>)
			<span>continue</span>
		}
		<span>go</span> <span>talk</span>(<span>conn</span>)
	}
}

<span>var</span> <span>errAccessForbidden</span> = <span>errors</span>.<span>New</span>(<span>"access forbidden"</span>)

<span>func</span> <span>verifyPeerPrefix</span>(<span>prefix</span> <span>string</span>) <span>func</span>(<span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
	<span>return</span> <span>func</span>(<span>s</span> <span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
		<span>// The first element is the leaf certificate
</span><span></span>		<span>// that the connection is verified against.
</span><span></span>		<span>for</span> <span>_</span>, <span>uri</span> <span>:=</span> <span>range</span> <span>s</span>.<span>PeerCertificates</span>[<span>0</span>].<span>URIs</span> {
			<span>if</span> <span>strings</span>.<span>HasPrefix</span>(<span>uri</span>.<span>String</span>(), <span>prefix</span>) {
				<span>return</span> <span>nil</span>
			}
		}
		<span>return</span> <span>errAccessForbidden</span>
	}
}

<span>func</span> <span>talk</span>(<span>conn</span> <span>net</span>.<span>Conn</span>) {
	<span>addr</span> <span>:=</span> <span>conn</span>.<span>RemoteAddr</span>()

	<span>defer</span> <span>func</span>() {
		<span>_</span> = <span>conn</span>.<span>Close</span>()
	}()

	<span>log</span>.<span>Println</span>(<span>addr</span>, <span>"connected"</span>)
	<span>_</span>, <span>err</span> <span>:=</span> <span>io</span>.<span>Copy</span>(<span>conn</span>, <span>conn</span>) <span>// send back what we get
</span><span></span>	<span>log</span>.<span>Println</span>(<span>addr</span>, <span>"disconnected:"</span>, <span>err</span>)
}
</code></pre></div><p>Run the server to accept TLS connections from the identity <code>citadel:srv-cart</code> only:</p>
<div><pre><code data-lang="shell">go run main.go -ca pki/ca.pem <span>\
</span><span></span>-cert pki/srv-invoice-host1.pem -key pki/srv-invoice-host1-key.pem <span>\
</span><span></span>-accept-prefix citadel:srv-cart
</code></pre></div><pre><code>2020/10/27 16:58:44 Listen: 127.0.0.1:8080
</code></pre><p>âœ”ï¸ The server is ready. Letâ€™s run the client.</p>
<p>Issue the certificate for the <code>cart</code> service:</p>
<div><pre><code data-lang="shell">cfssl gencert <span>\
</span><span></span>-ca pki/ca.pem -ca-key pki/ca-key.pem <span>\
</span><span></span>-config config.json <span>\
</span><span></span>-profile service <span>\
</span><span></span>-hostname <span>'host2.infra.citadel.net,citadel:srv-cart'</span> <span>\
</span><span></span>csr/service.json | cfssljson -bare pki/srv-cart-host2 -
</code></pre></div><p>Then run the client:</p>
<div><pre><code data-lang="shell">openssl s_client <span>\
</span><span></span>-connect 127.0.0.1:8080 <span>\
</span><span></span>-cert pki/srv-cart-host2.pem <span>\
</span><span></span>-key pki/srv-cart-host2-key.pem -CAfile pki/ca.pem
</code></pre></div><pre><code>CONNECTED(00000003)
depth=1 C = US, ST = CA, L = San Francisco, O = "Citadel, Inc.", CN = Demo Citadel
verify return:1
depth=0 C = US, ST = CA, L = San Francisco, O = "Citadel, Inc.", CN = citadel.xyz
verify return:1
---
Certificate chain
 0 s:/C=US/ST=CA/L=San Francisco/O=Citadel, Inc./CN=citadel.xyz
   i:/C=US/ST=CA/L=San Francisco/O=Citadel, Inc./CN=Demo Citadel
...
    Verify return code: 0 (ok)
---
</code></pre><p>ðŸ’š The command <code>openssl</code> is hanging and waiting for the input. It means that the client granted successfully to bind the server.</p>
<p>ðŸ˜’ <strong>What happens if the client identity doesnâ€™t match the server expectations?</strong></p>
<p>Restart the server with the parameter <code>-accept-prefix citadel:srv-noname</code>. Then the same client terminates with non-zero code and the output contains the error:</p>
<div><pre><code data-lang="shell">openssl s_client <span>\
</span><span></span>-connect 127.0.0.1:8080 <span>\
</span><span></span>-cert pki/srv-cart-host2.pem <span>\
</span><span></span>-key pki/srv-cart-host2-key.pem -CAfile pki/ca.pem
</code></pre></div><pre><code>...
4613156460:error:14020412:SSL routines:CONNECT_CR_SESSION_TICKET:sslv3 alert bad certificate:/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/libressl/libressl-47.140.1/libressl-2.8/ssl/ssl_p
kt.c:1200:SSL alert number 42
4613156460:error:140200E5:SSL routines:CONNECT_CR_SESSION_TICKET:ssl handshake failure:/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/libressl/libressl-47.140.1/libressl-2.8/ssl/ssl_pkt.c:5
85:
...
</code></pre><p>ðŸ’š The server <em>declines</em> the connection because the prefix <code>citadel:srv-noname</code> doesnâ€™t match the client identity <code>citadel:srv-cart</code>:</p>
<div><pre><code data-lang="shell">go run main.go -ca pki/ca.pem <span>\
</span><span></span>-cert pki/srv-invoice-host1.pem -key pki/srv-invoice-host1-key.pem <span>\
</span><span></span>-accept-prefix citadel:srv-noname
</code></pre></div><pre><code>2020/10/27 17:22:02 Listen: 127.0.0.1:8080
2020/10/27 17:22:10 127.0.0.1:50161 connected
2020/10/27 17:22:10 127.0.0.1:50161 disconnected: access forbidden
</code></pre><h2 id="summary">Summary</h2>
<p>Hooray! We implemented service-to-service authorization based on well-known standards (X.509 certificates and the TLS protocol) with vital features out of the box:</p>
<ul>
<li><strong>Identity issuing</strong> through the standard toolkit for generating certificates.</li>
<li><strong>Identity verification</strong> by the trusted Certificate Authority</li>
<li><strong>Identity expiration and revocation</strong>  to be confident that the temporary access or a compromised certificate have never been used for years.</li>
</ul>
<p>And the approach has the undeniable advantage to be fluently integrated into the running infrastructure leveraging the TLS protocol. For instance, traffic in Service Mesh is not only secured by TLS, but itâ€™s also hardened by access and identity management through X.509 certificates.</p>
<p>Your home task is to â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/">https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/</a></em></p>]]>
            </description>
            <link>https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947756</guid>
            <pubDate>Fri, 30 Oct 2020 23:15:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amiga Boing Ball in WebGL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24947254">thread link</a>) | @doener
<br/>
October 30, 2020 | http://clb.confined.space/amiga/ | <a href="https://web.archive.org/web/*/http://clb.confined.space/amiga/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://clb.confined.space/amiga/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947254</guid>
            <pubDate>Fri, 30 Oct 2020 21:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thread-per-Core Buffer Management for a Modern Kafka-API Storage System]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947251">thread link</a>) | @fpina
<br/>
October 30, 2020 | https://vectorized.io/tpc-buffers/ | <a href="https://web.archive.org/web/*/https://vectorized.io/tpc-buffers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><div><main><section><p><a href="https://vectorized.io/redpanda-raison-detre">As I have previously observed</a>, software does not run on category theory, it runs on superscalar CPUs with wide, multi-channel GB/s memory units and NVMe SSD access times in the order of 10-100â€™s of microseconds. The reason some software written a decade ago - on a different hardware platform - feels slow is because it fails to exploit the advances in modern hardware.</p>
<p>The new bottleneck in storage systems is the CPU. SSD devices are 100-1000x faster than spinning disks and are 10x cheaper today[1] than they were a decade ago, from $2,500 down to $200 per Terabyte. Networks have 100x higher throughput in public clouds from 1Gbps to 100Gbps.</p>
<p>Although computers did, in fact, get faster, single-core speeds remain roughly the same. The reason being that CPU frequency has a cubic dependency on power consumption, and weâ€™ve hit a wall. Instruction level parallelism, prefetching, speculative execution, branch prediction, deep hierarchy of data caches and instruction caches, etc, have contributed to programs <em>feeling</em> faster when you interact with them, but in the datacenter, the material improvements have come from the rise in core count. While the instructions per clock are 3x higher than a decade ago, core count is up 20x.</p>
<p>This is all to say that the rise of readily available, many-core systems necessitates a different approach for building infrastructure. Case in point[9]: in order to take full advantage of 96 vCPUs on a i3en.metal on AWS, youâ€™ll need to find a way to exploit sustained CPU clock speed of 3.1 GHz, 60 TB of total NVMe instance storage, 768 GiB of memory and NVMe devices capable of delivering up to 2 million random IOPS at 4 KB block sizes. This kind of beast necessitates a new kind of storage engine and threading model that leverages these hardware advances.</p>
<p><a href="https://vectorized.io/tpc-buffers/vectorized.io/redpanda">Redpanda</a> - a Kafka-API compatible system for mission critical workloads[3] - addresses all of these issues. It uses a thread-per-core architecture with Structured Message Passing (SMP) to communicate between these pinned threads. Threading is a foundational decision for any application, whether you are using a thread-pool, pinned threads with a network of Single Producer Single Consumer SPSC[7] queues, or any other of the advanced Safe Memory Reclamation (SMR) techniques, threading is your ring-0, the true kernel of your application. It tells you what your sensitivity is for blocking - which for Redpanda is less than 500 microseconds - otherwise, Seastarâ€™s[4] reactor will print a stack trace warning you of the blocking since it effectively injects latency on the network poller.</p>
<p>Once you have decided on your threading model, the next step is your memory model and ultimately, for storage engines, your buffer management. In this post, weâ€™ll cover the perils of buffer management in a thread-per-core environment and describe <code>iobuf</code>, our solution for a 0-copy memory management in the world of Seastar.</p>
<h2 id="Request-Flow-Architecture">Request Flow Architecture<a href="#Request-Flow-Architecture" aria-label="Request Flow Architecture permalink"></a></h2>
<p>As mentioned earlier, Redpanda uses a <em>single</em> pinned thread per core architecture to do everything. Network polling, submitting async IO to the kernel, reaping events, triggering timers, scheduling compute tasks, etc. Structurally, it means nothing can block for longer than 500 microseconds, or youâ€™ll be introducing latency in other parts of your stack. This is an incredibly strict programming paradigm, but this opinionated idea forces a truly asynchronous system, whether you like it or not as the programmer.</p>
<p><img src="https://vectorized.io/31d1a730c507b605e6c1ebea60eb1e56/flow.svg" alt="Kafka request flow">
<small>
Figure 1: request flow architecture. Core-0 accepts the connection from the Kafka Java client and becomes the source core. After the request goes through the metadata cache(valid request) it filters through the partition router which decides to send the request to core-1, the destination core. Core-1 then accepts the write through the Raft-log interface and saves it to disk.
</small></p>
<p>The challenge in a TpC (thread-per-core) architecture[8] is that all communication between cores is explicit. This muscles the programmer into implementing algorithms that favor core-locality (d-cache, i-cache) over the straightforward multi-threaded implementations via mutexes. This imperative has to be co-designed with the asynchronicity of a <strong>future&lt;&gt;</strong>-based implementation.</p>
<p>For our Kafka-API implementation as shown in Figure 1, we explicitly trade memory usage to reduce latency and increase throughput by materializing key components. The metadata Cache is materialized on every core since every request has to know if the partition exists, and that that particular machine is, in fact, the leader of the partition. The Partition Router maintains a map of which logical core actually owns the underlying Kafka partition on the machine. Other things like Access Control Lists (ACLs) are deferred until the request reaches the destination core since they can get unwieldy in memory footprint.  We have no hard and fast rule of what we materialize on every core vs. what is deferred for the destination core, and itâ€™s often a function of memory (smaller data structures are good candidates for broadcast), computation (how much time is spent deciding) and frequency of access (very likely operations tend to get materialized on every core).</p>
<p>One question remaining is how, exactly, does memory management work in a TpC architecture? How does data actually travel from L-core-0 to L-core-66 safely using a network of SPSC queues within a fully asynchronous execution model where things can suspend at any point in time?</p>
<h2 id="struct-iobuf--">struct iobuf { };<a href="#struct-iobuf--" aria-label="struct iobuf   permalink"></a></h2>
<h3 id="Redpandas-0-copy-buffer-management-for-TpC">Redpandaâ€™s 0-copy buffer management for TpC<a href="#Redpandas-0-copy-buffer-management-for-TpC" aria-label="Redpandas 0 copy buffer management for TpC permalink"></a></h3>
<p>To understand <strong>iobuf</strong>, we need to understand the actual memory constraints of Seastar, our TpC framework. During program bootstrap, Seastar allocates the full memory of the computer and splits it evenly across all the cores. It consults the hardware to understand what memory belongs to each particular core, reducing inter-core traffic to main memory.</p>
<p><img src="https://vectorized.io/efa273909c5b695bf7f978f77b32c12b/seastar_model.svg" alt="Seastar mental model">
<small>
Figure 2: Copy from alexgallego.org (<a href="https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html" target="_self" rel="nofollow">https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html</a>) Seastar threading model. Seastar uses a network of SPS queues to send messages to neighboring cores. Similar to other message passing or actor models like Erlang, Orleans and Pony, once a function is futurized, transitive functions too will become futurized. Both approaches, however, are intrinsically safe. The programmer worries about correctness and construction while the frameworks worry about efficient execution. Counter to general wisdom, it is actually faster and more scalable than the synchronous approach. While the machine does more work, it is executing your code simultaneously. This simultaneity is the key to finishing work sooner.
</small></p>
<p>As Figure 2 suggests, memory allocated on core-0, <em>must</em> be deallocated on core-0. However, there is no way to guarantee that a Java or Go client connecting to Redpanda will actually communicate with the exact core that owns the data.</p>
<p>At its core, an iobuf is a ref-counted, fragmented-buffer-chain with deferred deletes that allows Redpanda to simply share a view of a remote coreâ€™s parsed messages as the fragments come in, without incurring a copy overhead.</p>
<p><img src="https://vectorized.io/6df6fc00e05201d068dc5d03e080606a/iobuf.svg" alt="iobuf architecture"></p>
<p>The fragmented buffers abstraction is not new. The linux kernel has <strong>sk_buff</strong>[5] and the freebsd kernel has an <strong>mbuf</strong>[6] which are roughly similar. The additional extension of an iobuf is that it works in the TCP model leveraging Seastarâ€™s network of SPSC queues to have proper deletes in addition to being able to share sub-views arbitrarily, tailored for a storage-like workload.</p>
<p>Removing the C++ templates, allocators, pooling, pointer caching, etc, one could think of an iobuf as being equivalent to:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>fragment</span> <span>{</span>
    <span>void</span> <span>*</span> data<span>;</span>
    size_t ref_count<span>;</span>
    size_t capacity<span>;</span>
    size_t size<span>;</span>

    fragment<span>*</span> next<span>;</span>  
    fragment<span>*</span> prev<span>;</span>
<span>}</span>
<span>struct</span> <span>iobuf</span> <span>{</span>
    fragment<span>*</span> head<span>;</span>
<span>}</span><span>;</span></code></pre></div>
<p>The origins of iobuf are rooted in one of our central product tenets for building a KafkaÂ® replacement for mission critical systems - giving users 10x lower tail latencies for most workloads. Aside from a thread-per-core architecture, the memory management would have been our second bottleneck if not designed from the ground up for latency. On long running storage systems, memory fragmentation is a real problem, and one that is eventually either met with a proper solution (iobuf), stalls or an OOM.</p>
<p>Like its predecessors skbuff and mbuff, iobuf allows us to optimize and train our memory allocator with predictable memory sizes. Here is our iobuf allocation table logic:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>io_allocation_size</span> <span>{</span>
   <span>static</span> <span>constexpr</span> size_t max_chunk_size <span>=</span> <span>128</span> <span>*</span> <span>1024</span><span>;</span>
   <span>static</span> <span>constexpr</span> size_t default_chunk_size <span>=</span> <span>512</span><span>;</span>

   
   
   
   
   
   
   <span>static</span> <span>constexpr</span> std<span>::</span>array<span>&lt;</span><span>uint32_t</span><span>,</span> <span>15</span><span>&gt;</span> alloc_table <span>=</span>
     
     <span>{</span><span>{</span><span>512</span><span>,</span>
       <span>768</span><span>,</span>
       <span>1152</span><span>,</span>
       <span>1728</span><span>,</span>
       <span>2592</span><span>,</span>
       <span>3888</span><span>,</span>
       <span>5832</span><span>,</span>
       <span>8748</span><span>,</span>
       <span>13122</span><span>,</span>
       <span>19683</span><span>,</span>
       <span>29525</span><span>,</span>
       <span>44288</span><span>,</span>
       <span>66432</span><span>,</span>
       <span>99648</span><span>,</span>
       <span>131072</span><span>}</span><span>}</span><span>;</span>

   <span>static</span> size_t <span>next_allocation_size</span><span>(</span>size_t data_size<span>)</span><span>;</span>
<span>}</span><span>;</span>   </code></pre></div>
<p>Predictability, memory pooling, fixed sizes, size capping, fragmented traversal, etc, are all known techniques to reduce latency. Asking for contiguous and variably sized memory could cause the allocator to compact all of the arenas and reshuffle a lot of bytes for what could be a short-lived request, not only injecting latency on the request path, but for the entire system since we have exactly one thread performing all operations.</p>
<p>Hardware is the platform. When we ask the network layer to give us exactly 11225 bytes in contiguous memory, we are simply asking the allocator to linearize an empty buffer of that exact size and for the network layer to copy bytes as the fragments come from the hardware into the destination buffer. There is ultimately no free lunch when it comes to trying to squeeze every single ounce of performance of your hardware and often it requires re-architecting from zero.</p>
<p>If you made it this far, I encourage you to sign up for our <a href="https://vectorized.io/slack" target="_self" rel="nofollow">Community Slack (here!)</a> and ask us questions directly or engage with us on twitter via <a href="https://twitter.com/vectorizedio" target="_self" rel="nofollow">@vectorizeâ€¦</a></p></section></main></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/tpc-buffers/">https://vectorized.io/tpc-buffers/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/tpc-buffers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947251</guid>
            <pubDate>Fri, 30 Oct 2020 21:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Members of Congress leaking constituent data overseas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946745">thread link</a>) | @ianthiel
<br/>
October 30, 2020 | https://adalytics.io/blog/is-congress-leaking-your-data | <a href="https://web.archive.org/web/*/https://adalytics.io/blog/is-congress-leaking-your-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>The vast majority (98.9%) of US Senators and Congressional Representatives are sending certain data points about their constituents, including potentially minors, to for-profit companies such as Google, Facebook, LiveRamp, or Oracle. They are doing this through the use of third party tracking scripts, cookies, and pixels which they have embedded on their taxpayer funded official .house.gov and .senate.gov domains. This includes notable consumer privacy advocates such as Senator Elizabeth Warren, Maria Cantwell, Ed Markey, Josh Hawley, and Ron Wyden, as well as the Senate and House leaders who are in charge of the subcommittees that focus on consumer data privacy and big tech antitrust.&nbsp;
</p><p>A handful of congressmen also have installed an impressive array of advertising and marketing tech on their .gov websites, sending data about their .gov websitesâ€™ visitors to both domestic and foreign data brokers and advertising exchanges such as Avocet, OnAudience, Adobe Demdex, Eyeota, and Weborama. Several congressional websites use more than fifteen times as many third party tracking scripts as ebay.com. Multiple sites also utilize a social media feed widget that communicates with servers belonging to a company based on the outskirts of Moscow, Russia when users open their websites. One congressman even has actual Google Ads iframes embedded on his .house.gov domain.&nbsp;</p><p>A few congressmen may be utilizing their taxpayer funded .gov websites to gather data for their re-election campaigns, which may potentially be in violation of Congressional ethics rules, Federal Election Commission regulations, and Constitutional protections against unwarranted government surveillance.</p>

<ol id="table-of-contents">
	<li>
		<a href="#introduction">Introduction</a>
	</li>

	<ol>
		<li>
			<a href="#background">Background</a>
		</li>

		<li>
			<a href="#context">Context</a>
		</li>

		<li>
			<a href="#methodology">Methodology</a>
		</li>
	</ol>

	<li>
		<a href="#results">Results from scanning 537 Congressional .gov websites</a>
	</li>

	<ol>
		<li>
			<a href="#google-facebook-tools">Use of Google Analytics, Facebook Pixel, and other third party trackers</a>
		</li>
		<li>
			<a href="#third-party-cookies">Use of third party cookies</a>
		</li>
		<li>
			<a href="#third-party-tracking-scripts">Use of third party tracking scripts</a>
		</li>
	</ol>

	<li>
		<a href="#analysis">Analysis</a>
	</li>

	<ol>
		<li>
			<a href="#senate-committees">Senate antitrust &amp; consumer privacy committee members</a>
		</li>
		<li>
			<a href="#house-committees">House antitrust &amp; consumer privacy committee members</a>
		</li>
		<li>
			<a href="#data-brokers">Use of data brokers, audience management, and adtech by Congress</a>
		</li>
		<li>
			<a href="#data-sharing-foreign-companies">Sharing of browsing data with foreign companies</a>
		</li>
		<li>
			<a href="#pages-intended-for-children">Congressional web pages intended for children</a>
		</li>
		<li>
			<a href="#privacy-policies">Privacy policies</a>
		</li>
		<li>
			<a href="#google-ads-on-house-gov">Google Ads iframes loading on a congressional website</a>
		</li>
		<li>
			<a href="#privacy-respecting-members-of-congress">Privacy respecting Members of Congress</a>
		</li>
	</ol>

	<li>
		<a href="#conclusion">Conclusion</a>
	</li>

	<ol>
		<li>
			<a href="#caveats">Caveats &amp; Limitations</a>
		</li>
		<li>
			<a href="#discussion">Discussion</a>
		</li>
		<li>
			<a href="#journalists-and-legal-scholars">Possible future investigations by journalists or legal scholars</a>
		</li>
		<li>
			<a href="#take-away-points">Take away points &amp; recommendations for Congress</a>
		</li>
	</ol>
</ol><p>If you are a technically minded individual or want to jump straight into interesting findings, I recommend you go directly to the Results and Analysis sections. If you want some background on consumer privacy and how tracking tech works, this Introduction section is designed to provide some background context.</p><h2 id="background">Background</h2><p>In recent months, there have been increased calls in the US Capitol for strengthening consumer privacy protections and to evaluate the amount of influence tech giants such as Facebook and Google wield over social media, digital advertising, and news dissemination.</p><p>
These two companies command over <a href="https://www.marketwatch.com/story/as-demand-for-digital-advertising-plummets-google-and-facebook-could-have-shrinking-revenues-2020-04-28">70 percent</a> of the U.S. market share for digital ads. Google and Facebook built their sprawling billion-dollar businesses by providing a myriad of â€˜freeâ€™ services - social media, content feeds, search results, video, photo sharing, email, and messenger services. They also provide free software tools such as Google Analytics and Facebook Pixel, which website developers can embed within their pages to track user behavior. These consumer and business tools follow hundreds of millions of users around on the internet, placing cookies on usersâ€™ browsers and tracking scripts on websites to log peoplesâ€™ visits, thereby building detailed profiles of consumers based on their browsing habits and interests. These datasets can then be used to target potential consumers with targeted shoe, vacation, housing, job or political ads.</p><p>
Google and Facebookâ€™s tracking scripts and pixels are among their most popular â€˜freeâ€™ software tools, and they appear on websites in every corner of the internet. Even lawmakers calling for greater privacy protections use these tools on their congressional .gov websites purportedly to â€œimproveâ€ their websites. What they may actually be doing is sending their constituentsâ€™ data to Google and Facebook, thereby augmenting Google and Facebookâ€™s virtual profiles of users.</p><p>There is no shortage of lawmakers on both sides of the aisle clamoring to crown themselves as the champions of our right to privacy online.&nbsp;
</p><p>Senator Elizabeth Warren (MA), one of the most vocal critics of Big Tech, <a href="https://www.vox.com/policy-and-politics/2019/12/3/20965463/tech-2020-candidate-policies-online-data-equifax">argues</a> that breaking up Big Tech would drive accountability into their models and give â€œpeople more control over how their personal information is collected, shared, and sold.â€&nbsp;</p><p>
Senator Josh Hawley (MO), a rising Republican star, teamed up with Senator Mark Warner (VA) to introduce the <a href="https://www.hawley.senate.gov/senators-warner-and-hawley-introduce-bill-force-social-media-companies-disclose-how-they-are">Do Not Track Act</a> to allow Americans to opt-out of having their data collected. Sen. Hawley explains, â€œWhen a big tech company says its product is free, consumers are the ones being sold. These 'free' products track everything we do so tech companies can sell our information to the highest bidder and use it to target us with creepy ads.â€ He continues, â€œTech companies do their best to hide how much consumer data is worth and to whom it is sold.â€</p><p>Senator Ron Wyden (D-Ore.) put forward the Mind Your Own Business Act, which he bills&nbsp; as â€œthe strongest-ever protections for Americansâ€™ private dataâ€ that â€œgoes further than Europeâ€™s General Data Protection Regulation (GDPR).â€&nbsp;</p><p>
<strong>Given these lawmakersâ€™ promises to protect Americansâ€™ online privacy, I was curious how their own, taxpayer funded, .</strong><strong><em>gov</em></strong><strong> websites fare in protecting and respecting usersâ€™ privacy?</strong> Do their congressional websites, paid for and maintained with taxpayer funds, hold up to their own standards?</p><p>A few months ago, while I was working on a <a href="https://adalytics.io/">chrome extension</a> to collect and analyze digital ads, I noticed many representativesâ€™ websites host dozens of 3rd party cookies and tracking scripts on their .house.gov and .senate.gov websites. This means that the moment you (or a child in your household) visits your Senator or Congresspersonâ€™s website, all sorts of information about you--your IP address, physical location, how much time you spend on the page, what browser youâ€™re using, the dimensions of your computer monitor, your computerâ€™s operating system, social media identifiers -- can potentially be sent over to Google, Facebook, and other third party companies.</p><h2 id="context">Context</h2><p>So how exactly do data brokers or tech companies track users across different internet domains? Here I will provide a quick background on the technical means through which tracking tools operate.</p><p>When you open a website such as example.com, your computerâ€™s browser makes a network call over the internet to that domainâ€™s servers, which return an initial HTML document. That document contains instructions your browser parses to show text and styling, as well as further instructions for loading images or dynamic Javascript elements.</p><p>By making that initial request to example.com, your device established a quick internet connection that allowed example.comâ€™s servers to see a few pieces of information about your browser, including your IP address. Services such as <a href="https://ipinfo.io/">ipinfo.io</a> allow one to translate a numeric IP address into a geographic location, such as that of your house or the cafe whose WiFi you are using.&nbsp;</p><p>If a web developer installed third party javascript files on a website, this serves as an embedded instruction to make your browser fetch additional files from another domain besides the one you are currently perusing. Tracking scripts such as Google Analytics or Facebook Pixel can be loaded this way, and they then act as data sensors, transmitting additional data points back not only to example.com, but also to Google and Facebookâ€™s servers. Certain audience management or data brokers operate on this principle - a developer installs the data brokerâ€™s Javascript on their website, and then the data broker can gather information about the websiteâ€™s visitors and cross-reference with other websiteâ€™s data, as well as real world data such as credit cars, public records, and real estate ownership records.&nbsp;</p><p>In addition to javascript, many trackers load tiny, transparent images referred to as <a href="https://adtechbook.clearcode.cc/user-identification/">pixels</a>. Facebook <a href="https://themarkup.org/blacklight/2020/09/22/how-we-built-a-real-time-privacy-inspector#facebook-pixel">Pixel</a> is such an image. When a website configures Facebook Pixel on its pages, that causes usersâ€™ browsers to make a network call to Facebookâ€™s servers to retrieve that tiny image. Facebook Pixel can identify a particular userâ€™s Facebook account ID and relay that over the network. This information can then be used to target ads, including potentially <a href="https://www.americanbar.org/groups/crsj/publications/human_rights_magazine_home/voting-in-2020/political-advertising-on-social-media-platforms/">political</a> ads. Facebook Pixel can track activity even when a user is not logged into their Facebook account. Facebookâ€™s targeted ad system â€˜learnsâ€™ from Pixel events as well as custom user profile lists marketers can upload to create a target audience profile.&nbsp;</p><p>When your browser fetches images, javascript, or other resources after parsing a webpageâ€™s HTML instructions, it can also receive instructions to store short pieces of text known as â€˜cookiesâ€™. A first party cookie is one that is set by the domain you are currently visiting - so if you are on example.com, any cookies from example.com are first party. First party cookies can only be read by code sent from example.com.</p><p>If your browser receives instructions to store a cookie from Facebook or Youtube, those are <a href="https://ico.org.uk/for-organisations/guide-to-pecr/guidance-on-the-use-of-cookies-and-similar-technologies/what-are-cookies-and-similar-technologies/">third</a> party cookies. First party cookies are frequently used to maintain user login state or save website specific preferences. Third party cookies can serve an additional purpose, which is to allow userâ€™s behavior and usage across different web properties to be tracked. When you navigate to a different website, those third party cookies can be used to identify you as the user that was previously on â€¦</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adalytics.io/blog/is-congress-leaking-your-data">https://adalytics.io/blog/is-congress-leaking-your-data</a></em></p>]]>
            </description>
            <link>https://adalytics.io/blog/is-congress-leaking-your-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946745</guid>
            <pubDate>Fri, 30 Oct 2020 20:47:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity in Operating Systems]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24945856">thread link</a>) | @fcambus
<br/>
October 30, 2020 | https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html | <a href="https://web.archive.org/web/*/https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Over the last years Iâ€™ve been working on very different operating
systems. Operating systems are usually incredibly complex beasts. I
think there are mainly three drivers of this complexity. Surprisingly
enough, neither of these is having to deal with hardware.</p>

<p>The first one is resource <strong>discovery</strong>, i.e. figuring out how the
computer the OS is running on actually looks like. On x86, this
involves parsing countless bitfields, tables, executing byte code
provided by the firmware, probing individual features, etc. The most
painful example of this Iâ€™ve seen so far is figuring out which
interrupt a particular PCI interrupt line is routed to. Itâ€™s worth a
set of posts, but until then, feel free to checkout <a href="https://habr.com/en/post/501912/">this
description</a>. (If itâ€™s down, itâ€™s
also cached by
<a href="https://webcache.googleusercontent.com/search?q=cache:CXZUV61m7hwJ:https://habr.com/en/post/501912/+&amp;cd=1&amp;hl=en&amp;ct=clnk">Google</a>.)</p>

<p>The second issue is <strong>resource management</strong>. Essentially, how do you
hand out and eventually reclaim all the resources you discovered. For
some workloads performance matters here, so this code is usually
written with speed in mind.</p>

<p>The third reason is that at compile time the <strong>workload</strong> is
unclear. So the kernel has to assume the worst. It must be ready to
start a couple of hundred VMs or create a thousand TCP sockets in a
blink of an eye, because there is no way to know whatâ€™s going to
happen or what the actual requirements are.</p>

<p>A fun exercise is to checkout the <a href="https://elixir.bootlin.com/linux/v5.9.1/source/virt/kvm/kvm_main.c#L739">KVM code for creating
VMs</a>. Try
to follow
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/x86.c#L9904">the</a>
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/vmx/vmx.c#L7059">code</a>
to where the actual VM is created in hardware. <em>Spoiler:</em> There is
none. Itâ€™s all figuring out what the platform can do and then setting
up a bunch of spinlock, mutexes, lists, arrays, structs, â€¦</p>

<p>I donâ€™t want to pick on KVM in particular. I think itâ€™s pretty ok as
far as Linux kernel code goes. Operating System kernel code is mostly
like this: A lot of really mind numbing platform discovery and
resource management code written for speed assuming the worst case
requirements in a language that doesnâ€™t do parsing, resource
management or concurrency well (among other things).</p>

<p>People take this all for granted. But when I look around, I see many
systems that donâ€™t need this complexity and where it is only a safety
and security burden. Consider most appliance-type products, e.g. a
Wi-Fi router. Or a system that runs one service on a cloud VM. You
know everything in advance!</p>

<p>If you read until this point, you are probably asking yourself, where
I am going with this. If you think <a href="https://en.wikipedia.org/wiki/Separation_kernel">separation
kernel</a>, you are
right. My rough plan to write a couple of more posts to flesh out the
idea of doing all the complicated OS parts at compile time and how
this results in an incredibly simple, secure, and efficient system at
runtime. There will be <a href="https://riscv.org/">RISC-V</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://dhall-lang.org/">Dhall</a>,
and <a href="https://www.rust-lang.org/">Rust</a> content.</p>

<p>Stay tuned.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945856</guid>
            <pubDate>Fri, 30 Oct 2020 19:20:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Neighbourly Solution to the 'X Is Deprecated? ' Conundrum]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24945538">thread link</a>) | @zdw
<br/>
October 30, 2020 | https://www.divergent-desktop.org/blog/2020/10/29/improving-x/ | <a href="https://web.archive.org/web/*/https://www.divergent-desktop.org/blog/2020/10/29/improving-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <article lang="en">
          
          <p>Recent posts about the state of Xorg and its future has been stirring the
internets as of late and, as almost always, it is best to stay clear of the
comments sections. The more insightful post is <a href="https://ajaxnwnk.blogspot.com/2020/10/on-abandoning-x-server.html">On Abandoning the X Server</a>.</p>

<p>There are a few details in it that should be emphasised before we move on.</p>

<div><div><pre><blockquote>Though the code happens to implement an unfortunate
specification, the code itself is quite well structured, easy to hack on, and
not far off from being easily embeddable.</blockquote></pre></div></div>

<p>From my own experiences with Xorg internals, I agree completely. A whole lot
of the code there is noticably better than corresponding paths in certain
Wayland compositors. There is more thought; domain expertise; engineering and
pure elbow grease behind it than you might have been led to believe -- if you
have only listened in to the collective moans in various discussion groups.</p>

<div><div><pre><blockquote>So is Xorg abandoned? To the extent that means using it to actually
control the display, and not just keep X apps running, I'd say yes. But xserver
is more than xfree86. Xwayland, Xwin, Xephyr, Xvnc, Xvfb: these are projects
with real value that we should not give up. A better way to say it is that we
can finally abandon xfree86.</blockquote></pre></div></div>

<p>There are some nuances here that many will miss as it requires you to know
something about the architecture of the X server. The main thing is to not
conflate â€˜xfree86â€™ with rest of what you think of as X, hence why the blog post
separates out XFree86-the-project from 'xfree86 the hardware driver'. It is
unfortunate that the predecessor to Xorg was also called XFree86. Naming
things is hard and all that.</p>

<p>If you look at the xorg code, recommended reading for many who can
understand the language, you will see that the device-dependent code used to
drive displays (hw/ in the source tree) has a few backends, mentioned above.
Venture into the hw/xfree86 part and you will hopefully see why Adam Jackson
and others deserve the software engineering equivalent of a Purple Heart for
their service to your desktop, possibly alongside anyone that ever had to work
on ASN.1.</p>

<p>
<i>Rightfully throw Xorg-xfree86 into the fires of Mt. Doom. If you
still need Xorg-xfree86 to be your graphics card driver, you have bigger things
to worry about, such as plain old bitrot.</i></p>

<p>Is there something else? Yes. Iâ€™m not going to say <a href="https://arcan-fe.com/">Arcan</a> â€“ it is <i>very</i> likely that there
is only a small percentage of the stakeholders we would ever get along with.
That is fine. The goals and agenda reach much further than many will ever care
to travel -- unless you really want to push the boundaries of computing, or you
are actively targeted by nefarious individuals; our funding is not based on
popularity or mass adoption, but rather sticking to the shadows.</p>

<h2>The Compromise</h2>
<p>So what can we do instead? The current Wayland maintainer has
<a href="https://github.com/emersion/libliftoff">libliftoff</a> for smoothing
over the rather â€˜unergonomicâ€™ APIs that are used to get the open, modern,
graphics stack up and running. <em>Write a DDX backend that uses it.
hw/liftoff!</em></p>

<p>This will get liftoff the lift-off and mileage it needs to become good
enough for Wayland compositors to use as their default, and as a slightly more
polite migration path in order for NVIDIA to be less contemptible in the
unlikely event that they are one day struck by some capitalist version of
religious insight. Thus, it improves parts of the Wayland compositor situation
that is, politely put, chaotic.</p>

<p>Those that donâ€™t care about what Wayland tries to achieve can stay with X and
not worry about their graphics breaking after a kernel update, or well, more
than usual -- Linux gotta Linux. NVIDIA blob users can continue down that path
and stop bothering Wayland developers, yet still run their Steam games without
submitting to open source ideals.</p>

<p>Next steps. This is for the window managers. Take libarcan-shmif-server and
embed as a module in Xorg, fork it off even. If you are unaware, this is the
IPC system part of Arcan. Both the server and the client sides of it are fairly
trivial to use and are written with developers, not toolkits, in mind.</p>

<p>It is beyond feature parity with the rest of X, but has a comparable view on
capabilities and division of responsibility. You will only get a fraction of
the benefits of Arcan as a display server, but without other dependencies or
friction - many of the problems that X clients are plagued with can be worked
around while leaving the X11 protocol and its family of extensions to rest.
Hacks relying on facilities like uinput can be put down.</p>

<p>The security around these clients will be much tighter and they can be
gradually tuned to the specification of the developer. It lets XFCE, AwesomeWM,
WindowMaker and the tens to hundreds of others WM projects to continue to
improve their respective ecosystems, specialized widgets and other tools,
rather than to burn resources they don't have to rewrite themselves with bugs
that won't be discovered or fixed in time to matter.</p>

<p>It also gives the conservative side of BSDs a portable way of improving
their use of the graphics stack without reworking fundamentals they care little
about. The OpenBSD fork 'Xenocara' can be dropped.</p>

<p>This way, the heritage is preserved and kept alive, with a band aid to live
out another decade or three. It will still work for the marginalized that have
little interest- or option- in going elsewhere. It will be less painful to
maintain and work with.</p>

<h2>The Reality</h2>
<p>Wayland only is not an option that will ever work across the board. It is
not a replacement, it is a fundamental change of principles. Stop trying to
market it as some kind of inevitable transition. There are strong differences
that will not get smoothed over regardless of how many 'protocols' you define;
<i>Wayland is Policy over Mechanism, X11 is Mechanism over Policy</i>. This is
the real barrier. Not unsubstantiated claims of 'security'. It is a tectonic
shift and no matter your feelings about that, we won't all be in the same
country or continent anymore.</p>

<p>Heralding a 'Screenshot Protocol' and similar exercises as the fix that will
bridge this gap will only serve to distract from the fact that the power of all
these little tools and hacks from the crowd of X11 users comes from the
'screenshot' being just one case of <i>'give me the contents of a specific
window and all of its children'</i> or <i>'composite these windows to an
offscreen buffer and send me the results'</i> as the building blocks
available to be creative with.

</p><p>The mechanism approach provides a huge set of possibilities and opens up for
experimentation and 'works for me' kind of hacks. The downside is that it
surrenders control on the server side and are much harder to make robust.</p>

<p>The policy aproach will only do what both sides agree to, and <i>that
	agreement has the final say</i>. If you violate this contract, you are to be
blamed. However, that contract has to be bikeshedded to near state-space
exhaustion and carefully screened for conflicts as more contracts are added to
the pile.</p>

<p>The current trajectory is Gnomelanders and Swaylanders and Kwinners and so
on continuing to lock down singular uses cases and with political gunplay try
to push that as the one solution that will convince a few more bread crumbs.
The hand that controls the toolkit will eventually just decide. <i> This will
erode the strength of the policy contract</i>.</p>

<p>This has already led to a substantial amount of dissonance -- it turns out
that the 'opting-server-side decoration protocol' in the mix had implications
for how to interpret the 'subsurface protocol' and the 'redshift gamma
protocol' will clash with whatever 'color management protocol' that materialize
and so on. To get a feel for how involved such policies become, just <a href="https://github.com/wayland-project/wayland-protocols/blob/3a74660e94d85fde24f504cc9d4375d42192e84a/stable/xdg-shell/xdg-shell.xml#L402">
read the specification</a> and you will see why no implementation arrives at
the same calculation.</p>

<p>Take the perspective of a client developer chasing after the tumbleweed of
'protocols' drifting around and try to answer 'what am I supposed to implement
and use'? To me it looked like like a Picasso painting of ill-fitting- and
internally conflicted ideas. Let this continue a few cycles more and X11 will
look clean and balanced by comparison. Someone should propose a desktop icon
protocol for the sake of it, then again, someone probably already has.</p>

<h2>In Conclusion</h2>
<p>This approach will force Wayland to demonstrate its worth through the
virtues of its properties alone or by inventing actually compelling features
rather than by throwing shade on the elderly; or reimplementing the past
through rebranded and traced outlines from shadows cast by grander window
managers of yore.</p>

<p>The proposal leaves us with three well-defined paths.</p>

<ul>
<li>Wayland lets your own solipsist thiefdoms expand towards the horizon,
while trying to save embedded from the Android expanse.</li>
<li>People that have invested their hearts and souls into the X ecosystem can
continue to use their computers without fear of a kernel upgrade leaving them
with broken graphics, or a switch of display server paradigm leaving them with
an incompatible mental model of how system graphics work, and perhaps, one day,
stop whining about Wayland ruining their day and leave the devs alone.</li>
<li>Arcan lets you play with crazy ideas at a low initial cost. The ones
that might revolutionise your world or fail miserably. It will continue to
pushing things towards whatever is beyond the Twilight Zone in order to answer
profound questions such as 'what happens to productivity if your heartbeat
aligns with the blink rate of the cursor' (well that's actually be done since
forever and the RESULTS WOULD SHOCK YOU! - but it still illustrates the
point).</li>
</ul>

<p>It might even turn out so well that one of these paths will have a
fighting chance against the open desktop being further marginalised as a thin
client in the Azure clouded future; nothing more than a silhouette behind
unwashed Windows, a virtualized ghost of its former self.</p>

        </article>
	     </div>
     </div></div>]]>
            </description>
            <link>https://www.divergent-desktop.org/blog/2020/10/29/improving-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945538</guid>
            <pubDate>Fri, 30 Oct 2020 18:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Political Playing Cards over the Centuries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24945531">thread link</a>) | @tapneal
<br/>
October 30, 2020 | https://solitaired.com/political-card-decks-over-the-centuries | <a href="https://web.archive.org/web/*/https://solitaired.com/political-card-decks-over-the-centuries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Playing cards have been around for much longer than any of us think. Even though the cards we use today are relatively recent, the earliest records of playing cards date back to the Tan dynasty around the 9th century AD. Even though card games were called leaf games back in 868AD when princess Tongchang played with them, the concept remains the same.</p>
<p>Playing card design has been used as a means of political expressions over the centuries, and represent a glimpse into political feelings of the time. WeÃ¢â‚¬â„¢ve compiled some of the most interesting political decks below. </p>
<h3 id="1973politicalplayingcards">1973 Political Playing Cards</h3>
<p>Released by Fournier in 1973, the deck contains humorist drawings of politicians and other kinds of leaders from the 20th century, including religious leaders, despots, dictators, presidents, and more.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/spain.jpg"></p>
<h3 id="antifascistpropaganda">Anti-Fascist Propaganda</h3>
<p>An anti-fascist card deck from 1943, designed and printed by order of Stalin with a goal of making fun of the German empire from that era.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/antifacist.png"></p>
<h3 id="antinapoleon">Anti-Napoleon</h3>
<p>Most likely German-made around 1815, this deck of cards was designed and printed to portray the liberation war between Napoleon and the opposing forces.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/napoleon.png"></p>
<h3 id="backtotheussr">Back to the USSR</h3>
<p>Designed and printed mainly for the Russian market back in 1995, the cards portray the most popular leaders and politicians from USSR history.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ussr.png"></p>
<h3 id="bicyclecivilwardeck">Bicycle Civil War Deck</h3>
<p>Aimed at showing important historical characters from the American civil war era, these playing cards are relatively new and came into production in 2017. <a href="https://www.wopc.co.uk/usa/uspcc/bicycle-civil-war" rel="Ã¢â‚¬ï¿½nofollowÃ¢â‚¬ï¿½">Check it out.</a></p>
<h3 id="cartesimperialesetroyales">Cartes Imperiales et Royales</h3>
<p>Going back to the mid-19th century, we have cards that show consorts and imperial rulers from England, Austria, France, and Russia.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/royals.png"></p>
<h3 id="churchillinww2">Churchill in WW2</h3>
<p>An entire deck dedicated to Winston Churchill in World War 2 shows him in multiple positions as an officer, politician, writer, and salesman.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/church.png"></p>
<h3 id="dutchroyalfamily1879">Dutch Royal Family 1879</h3>
<p>A deck of cards dedicated to King William III's second marriage to Princess Emma of Waldeck-Pyrmont, where most of the cards consist of Dutch Royalty and soldiers.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/dutch.png"></p>
<h3 id="imperialroyalpack">Imperial Royal Pack</h3>
<p>Published in London in 1828, the Imperial Royal Pack contains portraits of important people from the Spanish, Turkish, French, and English empires.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/imperial.png"></p>
<h3 id="frenchrevolution">French Revolution</h3>
<p>A French Revolution deck printed in 1793 on woodblocks with stencils coloring showing the plain old people of France, including farmers and philosophers.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/french.png"></p>
<h3 id="satireofolivercromwellsgovernmentfrom1679">Satire of Oliver CromwellÃ¢â‚¬â„¢s Government from 1679</h3>
<p>Quite older than most here, this desk was engraved and was intended to mock the government of Oliver Cromwell during the Rump Parliament era.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/cromwell.png"></p>
<h3 id="tripoliwar1815">Tripoli War 1815</h3>
<p>A scarce set of cards, printed around 1815 and designed with courts that aimed to commemorate the Tripoli War. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="Ã¢â‚¬ï¿½nofollowÃ¢â‚¬ï¿½">Learn more</a></p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/tripoli.png"></p>
<h3 id="mortimernelsoncivilwarconfederategenerals">Mortimer Nelson Civil War Confederate Generals</h3>
<p>52 card deck designed and printed in 1863 with the goal of painting a picture of the Confederate officers or officials from that era. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="Ã¢â‚¬Å“nofollowÃ¢â‚¬ï¿½">Learn more</a>.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/civilwar.png"></p>
<h3 id="ahcaffeecomicalpoliticalplayingcards1888onpresidentialelection">A.H. Caffee Comical Political Playing Cards 1888 on Presidential Election</h3>
<p>This deck of cards was designed and printed back in 1888 to honor Cleveland and Harrison's contest for president. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="Ã¢â‚¬Å“nofollowÃ¢â‚¬ï¿½">Learn more</a>.</p>
<h3 id="biermansworldwariplayingcards1915">Biermans World War I Playing Cards 1915</h3>
<p>Printed and designed by Biermans in 1915, the cards were supposed to paint a satirical picture of the German military's politicians and army personnel. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="Ã¢â‚¬Å“nofollowÃ¢â‚¬ï¿½">Learn more</a>.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ww1.png"></p>
<h3 id="ww1commemorative">WW1 Commemorative</h3>
<p>To celebrate the victory in World War 1, Belgium printed these cards to commemorate presidents, kings, and queens as well as generals from their allying countries.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ww1c.png"></p>
<h3 id="kennedykards">Kennedy Kards</h3>
<p>Humor House released the cards in 1963, showing all Kennedy family members as well as JFK's successor president, LBJ.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/kennedy.jpg"></p>
<p>Many of these decks were found on <a href="https://www.wopc.co.uk/" rel="Ã¢â‚¬Å“nofollowÃ¢â‚¬ï¿½">World of Playing Cards</a>, a great resource for historical playing card. </p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/political-card-decks-over-the-centuries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945531</guid>
            <pubDate>Fri, 30 Oct 2020 18:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Apply Mindful UX to Your Daily Life]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945364">thread link</a>) | @parsecs
<br/>
October 30, 2020 | https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life | <a href="https://web.archive.org/web/*/https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a7abb749998f8defa959"><div><p>Mindful UX protects users' mental health, privacy, and mental state. It's inclusive and accessible. It aims to prevent harm and to help recover from it.</p><h2>Managing the level of interruptions</h2><p>A product has various ways to communicate information. Visual and auditive senses are the most commonly used. Digital items sometimes use touch, for instance with haptic feedback. Some notifications require your attention immediately, for instance if your cooking timer goes off and you don't want to burn your shakshuka. Some are neither urgent nor important. Yes, airline company newsletter, I'm looking at you, especially at the moment. Finally, some don't have any fixed level of urgency or importance: you will adapt them to your contextual needs. My phone is always in silent mode, but I'll activate the ringtone if I'm expecting an important call.</p><p>We can admire Slack's fantastic workflow for notifications. (<a href="https://slack.engineering/reducing-slacks-memory-footprint/" target="_blank">Source</a>)</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_6648"><div><p>In real life, how do you decide on the way you're communicating news with someone? It can depend on:</p><ul data-rte-list="default"><li><p>Your interlocutor (professional relation, family, long lost friend)</p></li><li><p>The number of interlocutors</p></li><li><p>The nature of the news (sensitive or not)</p></li><li><p>The urgency</p></li><li><p>The importance: paying your taxes might not be urgent if the deadline is 2 months from now, but it is important as you certainly don't want to miss it</p></li></ul><p>Based on all of that, are you going to call, email, text, video call, send a Twitter DM, leave a post-it note? Are you going to send reminders?</p><h2>Limiting distractions, protecting your attention</h2><p>We all know about this, you don't need me to spell it out: everyone is competing for our attention. You might have already taken measures to limit distractions: your phone might be in silent mode, you might even disable some notifications, block ads, disable autoplay, etc. Android and iOS even carry <a href="https://www.theverge.com/2018/6/5/17426922/apple-digital-health-vs-google-wellbeing-time-well-spent-wwdc-2018" target="_blank">native features to help us protect our attention</a>.</p><p>Apart from the digital measures I've just mentioned, there's another way you can mitigate distractions. If you share your physical work space with others - like I am doing in our current lockdown - you can signal when you're available to be interrupted and when you're not. Leave a sign on your door, place an object on your desk, etc.</p><p>There are even different levels for that:</p><ul data-rte-list="default"><li><p>Available</p></li><li><p>Only disturb if urgent</p></li><li><p>Do not disturb under any circumstances</p></li></ul><h2>Paying attention to accessibility</h2><p>An accessible product is a product that's usable by everyone. The quintessence of inaccessible design are Terms &amp; Conditions. Never-ending walls of text with little to no page layout, all written in legalese. For those of you who don't know, "legalese" represents legal lingo that's completely closed off to the uninitiated.</p><p>An easy way to be more mindful of accessibility in your daily life, is to adapt your communication. If you want to use jargon with people who might not be familiar with it, explain what it means - just like I did above with "legalese". In a group discussion, give background and context so that everyone has the same level of information and everyone can follow. When writing up a document, highlight the key information to make it easily scannable.</p><h2>Removing visual clutter</h2><p>We are well aware that visual overstimulation is detrimental for us. I even asked people on Twitter about it, and the results are telling.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_11640"><div><p>Whether it's in your room or at your desk, trimming down the visual clutter allows by contrast to shine more light on what's important, on the few things that you decide to leave in sight. Not only does that make it easier for you to find something you're looking for, but it's also nicer and less stressful on the eyes, because you have less visual stimuli.</p><p>The same applies to your digital places. Leaving white space and room to breathe is beneficial and so much more relaxing. Here's what my phone and laptop screens look like: much better than having files and apps filling up the space.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_30876"><div><h2>Avoiding cognitive overload</h2><p>Cognitive load refers to the mental effort we have to make to use a product, achieve a task, etc. We've all known someone who had the bad habit of starting Matryoshka sentences - or Russian dolls sentences if you prefer. "<em>I had a call with Tamara, because we have a group chat with Marie, and by the way did you know Marie and Tamara had never met? Because last time we met with Awa and had delicious ice cream, I can give you the address, and it was such a sunny day</em>" and this sentence alone tackled 6 different topics. Yes, some people talk like that, and it exhausts me because I can't follow.</p><p>Some strategies to make it easier:</p><h3>Chunking</h3><p>Do you write phone numbers as 0123456789 or 01.23.45.67.89? Splitting your content in smaller chunks makes it easier to both <a href="https://www.nngroup.com/articles/chunking/" target="_blank">scan</a> and <a href="https://www.zora.uzh.ch/id/eprint/151291/1/Thalmann.et.al.Chunking.final.pdf" target="_blank">memorise</a>.</p><h3>Reducing the number of options</h3><p>You don't have to go all the way and reduce your wardrobe to 15 items, but... I suppose that's the spirit? In UX, this is known as <a href="https://lawsofux.com/hicks-law" target="_blank">Hick's law</a>. Choosing what to have between 10 options will take longer than between 3 options. That won't stop me from having 10 different teas at home though. ðŸ˜Œ This isn't something to apply religiously, just to be aware of and to use whenever relevant.</p><h3><a href="https://www.nngroup.com/articles/recognition-and-recall/" target="_blank">Recognition rather than recall</a></h3><p>Yet another interesting UX principle for your daily life. Recognition leaves cues (e.g. "<em>Are mint &amp; lime in a mojito?</em>â€), whereas recall doesn't ("<em>What are the main ingredients in a mojito?</em>"). The end goal of these questions is the same, but the former is easier to answer: you just have to recognise whether the information given to you is accurate.</p><p>You can then make your environment work for you. I leave my keys in the lock, so that I'm naturally prompted to take them with me as I go out, I don't need to remember it. If I want to wear something specific the next day, I'll take it out of the wardrobe and leave it in plain sight. If I need to eat something soon, as it expires the next day, I'll place it on the kitchen counter.</p><h2>Choosing between streaks or flexible goals</h2><p>Several products use streaks to entice you into practicing something daily. Headspace does it for meditation, Github does it with your code commits. Streaks can be useful, but they shouldn't be a default goal for any habit you want to learn. Aiming to be flexible, and to complete a task 3 or 5 times per week, is much more realistic than sticking to it everyday, especially if you're just getting started. Streaks create pressure to perform everyday, while more manageable goals leave room for contigencies.</p><p>Additionally, since you're more likely to complete <a href="https://nesslabs.com/flexible-consistency" target="_blank">flexible goals</a>, you can observe your own progress, which encourages you to keep going. Finally, it's important to differenciate whether your completion of a task comes from pressure or from desire. Daily streaks are more likely to be completed from internal coercion, and malleable goals from desire, because if you don't feel like doing it on Monday, it's no big deal. Listen to yourself, listen to what you feel like doing in the moment, and adapt.</p></div></div></div>]]>
            </description>
            <link>https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945364</guid>
            <pubDate>Fri, 30 Oct 2020 18:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New social media platform, Lighf, looking forward to welcoming its future users]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24945358">thread link</a>) | @imanonymous
<br/>
October 30, 2020 | https://lighf.com/request-lighf/ | <a href="https://web.archive.org/web/*/https://lighf.com/request-lighf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div text-align:="" center;"=""><p><span>lighf</span> doesnâ€™t store your IP address or any other identifiable data about you. By default your layers (privacy) are to set to <em>None</em> but you can add additional layers.</p>
<p><em>Encrypted</em>, means your email address is encrypted the second you create an account and only unencrypted, with your permission, at times when you need to recover your password.Ã‚&nbsp; The draw back is you wonâ€™t be able to get <span>lighf</span> updates by email, only In-App and Push (coming soon).</p>
<p>To go <em>Email-less</em> means no email address is linked to your <span>lighf</span> Account. Like the Encrypted option, you wonâ€™t receive any updates by email, only In-App and Push (coming soon). The draw back is that you wonâ€™t be able to reset your password or <span>lighf</span>Name (username) or recover your Account.</p>
<p><a title="Tap this link to close." href="#">Got It!</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://lighf.com/request-lighf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945358</guid>
            <pubDate>Fri, 30 Oct 2020 18:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Scala in your early stage startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945145">thread link</a>) | @vlehuger
<br/>
October 30, 2020 | https://www.actiondesk.io/blog/why-use-scala | <a href="https://web.archive.org/web/*/https://www.actiondesk.io/blog/why-use-scala">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Why use Scala? We listed the advantages of Scala we see in our startup. See whether the benefits of Scala could help you too.</p><p>1. Focus on what matters: Expressiveness + High order functions</p><p>2. Get less bugs: Statically typed + Clean error management by design</p><p>3. Benefit from JVM ecosystem: Performant libraries + Good tooling environment</p><p>4. Attract talents</p><p>â€</p><p>â€</p><p>Scala is a JVM based language. Itâ€™s flexible, you can write code in both imperative or functional styles. Scala is a pragmatic language that mixes the best of functional and object-oriented programming. It basically means that you can create classes to encapsulate state and methods but you canâ€™t mutate them.</p><p>â€</p><p>â€</p><p>The main power of Scala is to let the developers focus on whatâ€™s most important.</p><p>â€</p><h2><strong>Expressiveness</strong></h2><p>Running on the JVM, Scala is as powerful as Java but it is way clearer and more concise. It makes the code easier (and faster) to write and read!</p><p>For example, look at how we create a list of string in Java vs Scala:</p><h4><strong>Java:</strong></h4><figure id="w-node-069225ecd5f7-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df66d44ec7c4592663ddc_20201019%20Scala%20Article_1.png" loading="lazy" alt="how we create a list of string in Java"></p></figure><h4><strong>Scala:</strong></h4><figure id="w-node-713e2fe2bca1-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df6bca2fdb8e00bb006a6_20201019%20Scala%20Article_2.png" loading="lazy" alt="how we create a list of string in Scala"></p></figure><h2><strong>High order function</strong></h2><p>High order functions are functions that abstract some control structure like a loop to update every element of an array.</p><p>Theyâ€™re the functions we use most in Scala. They work by taking a function as a parameter. Used with anonymous functions, theyâ€™re perfect to focus on implementing the business logic instead of juggling with indexes to increment and stop conditions.</p><p>Look at how we can convert this list of string into a list of integers:</p><figure id="w-node-b9f12ec503cb-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df77fa26c394e0b5e18b1_20201019%20Scala%20Article_3.png" loading="lazy" alt="how to convert a list of string into a list of ints in Scala"></p></figure><p>â€</p><p>We can also compute the sum of it by using the high-order function fold:</p><figure id="w-node-dc33ae72b25f-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df7b68e690322a1f2341e_20201019%20Scala%20Article_4.png" loading="lazy" alt="How to compute the sum by using the high-order function fold in Scala"></p></figure><p>â€</p><p>â€</p><p>â€</p><h2><strong>Statically typed</strong></h2><p>By checking the type during the compilation, Scala type system reduces considerably the amount of bugs caused by type errors.</p><p>Type inference allows typing without being too verbose:</p><p>def square(x: Int) = x * x&nbsp;</p><p>Here the type of square (Int) is inferred from the * operator which multiplies an Int by an Int giving an Int in output.</p><p>And thanks to pattern matching, we can still write flexible code:</p><figure id="w-node-5d4c922f320c-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df82d19cead6575ed2edd_20201019%20Scala%20Article_5.png" loading="lazy" alt="How to decompose an object to pattern match on its attributes, add pattern guards, pattern match a regex or the elements of a List in Scala"></p></figure><p>Here we can even decompose an object to pattern match on its attributes. We can even add pattern guards (if condition in a case), pattern match a regex or the elements of a List.</p><p>â€</p><h2><strong>Clean error management by design</strong></h2><h3><strong>Option and Either</strong></h3><p>There are some useful standard types in Scala to manage errors. The most commonly used are Option and Either. An Option can either be a class Some containing a value or a None object. So we can associate a valid result to Some and an error to None. Let's write a function to safely update a String to Int.</p><figure id="w-node-60c03b54f3c2-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df92687207e98effd9699_20201019%20Scala%20Article_6.png" loading="lazy" alt="How to to safely update a String to Int in Scala"></p></figure><p>â€</p><p>And if we need an error message we can use the Either class that will return a Right containing the value or a Left with an error type.</p><figure id="w-node-b021a222808e-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8dfb98068c68637d53699d_20201019%20Scala%20Article_7.png" loading="lazy" alt="If we need an error message we can use the Either class that will return a Right containing the value or a Left with an error type in Scala"></p></figure><p>â€</p><p>Try is also a great type to manage error, especially to encapsulate every call to Java functions that can throw errors.</p><p>â€</p><h3><strong>Combine them with for-comprehension</strong></h3><p>Option, Either or Try allow us to return a result or an error and not throw it to whatever will catch it. And thanks to a special Scala control structure, the â€œfor-comprehensionâ€, we can easily combine them to return the first error encountered.</p><figure id="w-node-c336c52f22b2-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df9f519cead4e10ed589d_20201019%20Scala%20Article_8.png" loading="lazy" alt="The Scala control structure â€œfor-comprehensionâ€ allows to easily combine Option, Either and Try to return the first error encountered."></p></figure><p>dividend on the left part of dividend &lt;- convertStringToInt(dividendStr) is the value in the Right of the convertStringToInt(dividendStr) result. If convertStringToInt(dividendStr) returns an error, it will stop immediately and return that error in a Left for safeStringDivision.</p><p>â€</p><h3><strong>Perfect to handle asynchronous code</strong></h3><p>â€œfor-comprehensionâ€ are also amazing to work with asynchronous code like HTTP calls encapsulated in a Future. We can combine them and return an error for the first error we encounter.</p><figure id="w-node-6dcad4d139cc-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8dfab1a0c47639e33ad40f_20201019%20Scala%20Article_9.png" loading="lazy" alt="In Scala, for-comprehension are also amazing to work with asynchronous code like HTTP calls encapsulate in a Future."></p></figure><p>â€</p><p>We can even combine Future with other error types like Either by using functional libraries like <a href="https://typelevel.org/cats/datatypes/eithert.html" target="_blank">cats</a>.</p><p>â€</p><p>â€</p><p>â€</p><h2><strong>JVM allows to use powerful java libraries</strong></h2><p>For example we use db connectors, libraries to manage timestamps, logging &amp; monitoring clients and more!</p><p>â€</p><h2><strong>Good tooling environment</strong></h2><p>There is a great IDE with Intellij Idea. The community also built a very efficient alternative Metals, a plugin that can transform your VS Code in Scala IDE.</p><p>Another useful tool we use is sbt-docker. It allows you to simply build a docker container embedding your application.</p><p>â€</p><p>Such powerful language attracts skilled engineers who are curious and keen to test new tools, who have the willingness to discover new paradigms, new perspectives to see the world of programming... And this is the perfect mindset to join a startup as Engineer 1 to 10!</p><p>By the way, <a href="https://angel.co/company/actiondesk/jobs" target="_blank">weâ€™re hiring</a> if you want to join us at <a href="http://actiondesk.io/" target="_blank">Actiondesk</a>.</p><p>â€</p></div></div></div>]]>
            </description>
            <link>https://www.actiondesk.io/blog/why-use-scala</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945145</guid>
            <pubDate>Fri, 30 Oct 2020 18:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolution of Adobe and Future of Creative Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944961">thread link</a>) | @yarapavan
<br/>
October 30, 2020 | https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software | <a href="https://web.archive.org/web/*/https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><div><h3><em>By <a href="https://www.linkedin.com/in/meha-patel/">Meha Patel</a> and <a href="https://www.linkedin.com/in/nnamdiokike/">Nnamdi Okike</a></em></h3><hr><p><img alt="mark-cruz-VW2oU66mwbc-unsplash" src="https://images.ctfassets.net/clfay1lxzjey/4Kivkm0e0GJ1RL4PmWU3qG/5856ffca944fe78f0164a9bb467dbffb/mark-cruz-VW2oU66mwbc-unsplash.jpg"></p><hr><p>Over the past 38 years, Adobe has built itself into a ~$245 billion market cap company by introducing and then dominating a new category: creative software. Over the next decade and beyond, we see this market evolving and enabling the emergence of multiple billion dollar startups that build upon Adobeâ€™s foundation. These include several companies already well on their way such as Canva, Figma, and others. </p><p>In this article, we: i) introduce a framework for evaluating Adobe as a platform company; ii) analyze Adobeâ€™s history and the factors that enabled its rise, iii) describe the technology &amp; behavioral waves catalyzing innovation, and iv) suggest areas of opportunity for emerging startups. More specifically, we highlight video workflows, analytics capabilities, and document alternatives as 3 key areas of opportunity, and also link a growing <a href="https://airtable.com/invite/l?inviteId=invL8RfK15a1yqHG1&amp;inviteToken=752ceb35a51bae83e02f6f454798d979e147d6f162b3bb3ad10ca0bc0b95a15c">repository</a> of startups in various creative software categories. Please feel free to read the entire article, or skip to the section(s) that are most interesting to you.</p><hr><h2>I. Introduction</h2><hr><p>Over the past few years, much attention has been paid to the â€œunbundlingâ€ of companies including eBay, Craigslist, and Linkedin. The basis of the unbundling concept is that while the aggregation of multiple products and services initially results in network effects and scale economies in the first wave of a technology market, it also limits personalization, customization, and quality of experience. This creates an opportunity for new startups to displace the incumbent by providing more customized solutions as the market matures.</p><p>While the unbundling approach has worked well for startups attacking certain incumbents, it has limitations as a framework. This is particularly true for platform companies upon which new startups rely on in order to successfully build and distribute products. In these markets, innovation takes a more layered approach, with newer companies building upon a foundation laid by an incumbent. Rather than unbundling, we call this <em>an evolution</em> of a platform, and we believe that this is the best framework for evaluating Adobe, its innovation track record, and the startups innovating in this market today. </p><p>In comparison to better-known software giants in Silicon Valley, Adobe has flourished relatively quietly for much of its 38-year history. What began as a small publishing software company has now expanded into a conglomerate providing an extensive suite of products across its Creative, Document, and Experience Clouds. Today, Adobe employs over 22,000 employees and generates over $11 billion in revenue annually, with a market capitalization of ~$245 billion. <a href="">1</a></p><p>Along the way, it has made numerous transformative acquisitions, including Macromedia ($3.4 billion), Omniture ($1.8 billion), and Marketo ($4.8 billion). Its acquisition of Behance ($150 million) also enabled it to build the leading online platform to showcase and discover creative work. It has also successfully expanded into new pockets of creative software, which eventually yielded large business lines. Adobeâ€™s ability to consistently innovate through organic and inorganic growth, while successfully transitioning leadership between different CEOs over multiple decades, is one of the tech industryâ€™s great overlooked stories. The companyâ€™s Creative Cloud launch and move to a subscription-based pricing model at the end of 2013 precipitated a quadrupling of its market cap since that time. <a href="">2</a></p><p><img alt="Screen Shot 2020-10-14 at 12.09.42 PM" src="https://images.ctfassets.net/clfay1lxzjey/7nSKcMyD30evkeX4plmIQa/b0fb3bc9358b4724e76df9b2ae2b20bc/Screen_Shot_2020-10-14_at_12.09.42_PM.png"></p><blockquote><blockquote><p><strong><em>Adobeâ€™s Stock Price Has Skyrocketed over the Past Two Decades</em></strong></p></blockquote></blockquote><p>As we explain below, we believe Adobe is entering a new phase, where new startups are building upon its platform and legacy. The growth of this new generation of startups is driven by technological and behavioral inflections. Rather than replace Adobeâ€™s products, these startups are innovating  upon Adobeâ€™s foundation to build a new generation of creative software. </p><hr><h2>II. The Growth of Adobe and its Significance</h2><hr><p>Adobe was founded by Chuck Geschke and John Warnock (above) to enable more accessible publishing and printing software.Throughout its first decade, Adobe aggressively targeted designers and creative professionals, creating new categories of software across graphics, photo, video, and publishing. Along with Apple, Adobe helped bring about the desktop publishing revolution, launching products such as Illustrator, Photoshop, and Acrobat. Over the past two decades, Adobe then made several transformative acquisitions, enabling it to expand into web-based products (Macromedia), enterprise analytics (Omniture), e-commerce software (Magento), and marketing automation software (Marketo). </p><p>We believe that Adobeâ€™s success has been driven largely by the following three characteristics:</p><p>1) <strong>Successful Partnerships:</strong> From the very beginning, Adobe has secured successful partnerships through a thoughtful and strategic approach to choosing the right partners. Adobeâ€™s first product, PostScript, was a page description language, which allowed users to print to external printers. Adobe understood that the proliferation of its software was dependent on high-quality hardware, and it strategically chose to partner with the best hardware company for creative users, Apple. In 1985, Apple debuted the LaserWriter printer with Postscript, and it was the first printer to use the language. Combined with a third partnership with Aldus Software, the trio established the desktop publishing revolution, and elevated Adobeâ€™s positioning within the corporate ecosystem. Taking this further, Adobe capitalized on this position and cultivated deep partnerships with other large technology companies, such as IBM and Microsoft, ensuring it is deeply entrenched as the defacto creative software suite. </p><p>2) <strong>Ability to Bundle Products:</strong> Adobe has consistently been able to bundle its products into an integrated suite, while ensuring that value was strong enough for customers to pay a premium price for the bundle. In its early years, Adobe quickly amassed a wide variety of capabilities and was able to bundle new offerings with existing products to accelerate adoption. The company understood that the customer of that time wasnâ€™t seeking point solutions, and instead wanted an integrated software solution that could solve multiple needs. Adobe has built on this strategy over time, culminating in the launch of its full product suite in 2003. What has been most unique about Adobeâ€™s bundling approach is its ability to charge premium prices for the full subscription offering. For example, Adobeâ€™s Creative Cloud offering is currently $80 per month for the base business license, or almost $1k per year. Adobe has an estimated 15 million paying subscribers today, evidencing the power of its integrated suite and the fact that Adobe is the standard. The network effects of Adobeâ€™s products also enhance its lock-in. </p><p>3) <strong>Successful Acquisitions:</strong> Throughout its tenure, Adobe strategically selected acquisitions to enter into new markets, often choosing to buy versus build, and then subsequently successfully integrated those acquisitions. Adobeâ€™s acquisition strategy is differentiated due to the fact that the company is not afraid to make large, bold bets, at same time dedicating the time and resources over a long period to ensure that these bets pay off. For example, Adobeâ€™s $1.8 billion acquisition of Omniture in 2009 was seemingly off strategy and non-complementary. Why was a creative/design software company making such a large bet to acquire the leading player in enterprise analytics? Adobe understood that the future of marketing was uniting content creation with marketing analytics. Disciplines that were historically the purview of different enterprise departments would merge, and the rise of web/mobile analytics would enable a much tighter feedback loop within content creation and design. More than ten years later, the deal is seen as a brilliant strategic move that enabled Adobe to build its Experience Cloud.</p><p><img alt="Screen Shot 2020-10-14 at 12.14.59 PM" src="https://images.ctfassets.net/clfay1lxzjey/4E8RcynEAKHogL4YZDJccI/ebebfd21f11b47ddbe794c2778afa757/Screen_Shot_2020-10-14_at_12.14.59_PM.png"></p><blockquote><blockquote><p><strong><em>Adobe Has Made Several Successful Acquisitions over the Past Two Decades</em></strong></p></blockquote></blockquote><p>4) <strong>Transition to Cloud-based Company:</strong> In 2012, Adobe released Creative Cloud and fundamentally changed the way its products were offered, updated, and priced. While risky at the time, it enabled Adobe to transform the types of users they targeted and more importantly, stay relevant as more cloud-based competitors emerged. Growth in subscriptions for the Creative Cloud over the two years following launch can be seen below.</p><p><img alt="Screen Shot 2020-10-14 at 12.17.42 PM" src="https://images.ctfassets.net/clfay1lxzjey/16qjRVLN4x3x0fpmLeZHeB/18dbd03bacb9f8e0bbdfd8937dbbbd01/updated_chart.jpg"></p><p>How did Adobe accomplish its transition to becoming a cloud company, and why did they succeed where many large companies have stumbled? They succeeded through a series of strategic moves led by CEO Shantanu Narayen. These included the acquisition of Omniture, which enabled Adobe to immediately become the leader in enterprise cloud analytics. It also included the $150m acquisition of Behance, which provided the company with a large community of designers who desired to showcase creative work. By 2018, Behance had over 10 million users, 10x the number when it was acquired by Adobe.</p><p>Adobe was also willing to absorb the financial impact of switching from a one-time license of ~$1800 to a per-month subscription of $50 for its Creative Cloud software, which results in an initial revenue shortfall. Adobe did this over five years, first introducing Creative Cloud in April 2012, and not retiring its license option until January 2017.</p><p>Finally, Adobe displayed pragmatism in listening to the market where its products were not well-received. By far the most notable example was Adobe Flash. In 2010, Steve Jobs posted his letter â€œThoughts on Flash,â€ which criticized Flash and stated why Flash would not be allowed on iPhone, iPod Touch and iPad. While Adobeâ€™s CEO Narayen initially fired back at Jobs, Adobe eventually decided to discontinue Flash and focus resources on HTML5. Through this move, Adobe displayed pragmatism, realizing that there was more money in building and acquiring SaaS apps than supporting media software on hardware â€¦</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software">https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software</a></em></p>]]>
            </description>
            <link>https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944961</guid>
            <pubDate>Fri, 30 Oct 2020 17:53:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recovering Lost Roam Notes]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24944574">thread link</a>) | @jchen42
<br/>
October 30, 2020 | https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post dives deep into a scary data loss scenario - we'll cover identifying the data loss, investigating the root cause, and finally recovering the data.</p>
<p><strong>This bug affected Readwise users who exported their highlights (both manually &amp; automatically) to Roam on 10/27. If you are one of those users, you should contact Roam support &amp; use <a href="https://github.com/jchen1/roam-restore" target="_blank" rel="nofollow noopener noreferrer">my recovery code</a> ASAP!</strong></p>
<!-- excerpt -->
<h2>Background</h2>
<p><a href="https://roamresearch.com/" target="_blank" rel="nofollow noopener noreferrer">Roam</a> is a "note-taking tool for networked thought". It supports all sorts of cool things - what's relevant here is that it automatically creates a new page for every day, your Daily Notes. Recently, I started using <a href="https://readwise.io/" target="_blank" rel="nofollow noopener noreferrer">Readwise</a>, which ingests Kindle highlights and uses <a href="https://en.wikipedia.org/wiki/Spaced_repetition" target="_blank" rel="nofollow noopener noreferrer">spaced repetition</a> to help you remember what you read. Readwise has a Roam integration, which automatically adds Kindle highlights to Roam. Unfortunately, since Roam doesn't have a public API yet, Readwise's integration seems to be effectively using Selenium - clicking on elements and pasting highlights which is inherently flaky.</p>
<p>Yesterday, I woke up without my Daily Notes from the day before. Disaster! Fortunately, with the help of the Roam Slack group and Tristan from Readwise, I was able to isolate the cause of note deletion and even restore my lost data. Here's what happened:</p>
<h2>Roam architecture</h2>
<p>Roam uses <a href="https://github.com/tonsky/datascript" target="_blank" rel="nofollow noopener noreferrer">Datascript</a> for its client-side database. Like Datomic, Datascript stores data as a <code>datom</code>, defined as <code>[e a v tx]</code>, or <code>entity</code>, <code>attribute</code>, <code>value</code>, and <code>transaction-id</code> (incrementing integer). If you're interested in learning more, <a href="https://tonsky.me/blog/datascript-internals/" target="_blank" rel="nofollow noopener noreferrer">Datascript's author has an excellent overview</a>.</p>
<p>Importantly for us, Roam differs from other webapps in that it doesn't store all state and history in its backend. Instead, Roam's backend just stores a snapshotted Datascript database (updated ~daily as far as I can tell) and the list of transactions since that last snapshot. If we can download those two things before Roam's next snapshot, we have two breadcrumbs towards recovery: 1. We can find the transaction that deleted my Daily Notes page 2. We can also reconstruct our Datascript database, replaying transactions up until the point of deletion, and recover our Daily Notes from that!</p>
<h2>Capturing state</h2>
<p>Our first step is to store Roam's database snapshot and transaction list. Instead of REST API calls, Roam uses a Websocket connection to send these to its web client. This complicates things for us: instead of just saving API responses with <code>curl</code>, we need to download a <a href="https://en.wikipedia.org/wiki/HAR_%28file_format%29" target="_blank" rel="nofollow noopener noreferrer">HAR file</a>, which, fortunately for us, includes Websocket traffic with more recent Chrome versions. HAR files are just JSON archives stored in chronological order - it's easy to select just the Websocket traffic:</p>
<pre><code>(<span><span>defn</span></span> parse-har
  [harfile]
  (<span><span>let</span></span> [json (<span>json/parse-string</span> (<span><span>slurp</span></span> harfile) <span>true</span>)
        ws-messages (<span><span>-&gt;&gt;</span></span> json <span>:log</span> <span>:entries</span> (<span><span>filter</span></span> #(<span>some?</span> (<span>:_webSocketMessages</span> %))) second <span>:_webSocketMessages</span>)
        ws-data (<span><span>map</span></span> <span>:data</span> ws-messages)]
    ws-data))</code></pre>
<p>Inspecting this data more closely, it appears that Roam's websocket messages are generally JSON strings (and occasionally numbers). When a message is more than 16KB, it's split into multiple messages without wrapping - so we'll need to stitch these bigger messages together. One way to detect a non-split-message is to just try and parse it as JSON - if it's valid, we can say it's non-split. (There's an edge case we're unlikely to hit here: if the 16KB chunk just so happens to be valid JSON as well we'll be out of luck. Lucky for us, I didn't run into this!) Now, we can extend <code>parse-har</code> as follows:</p>
<pre><code>(<span><span>defn</span></span> parse-har
  [harfile]
  (<span><span>let</span></span> [json (<span>json/parse-string</span> (<span><span>slurp</span></span> harfile) <span>true</span>)
        ws-messages (<span><span>-&gt;&gt;</span></span> json <span>:log</span> <span>:entries</span> (<span><span>filter</span></span> #(<span>some?</span> (<span>:_webSocketMessages</span> %))) second <span>:_webSocketMessages</span>)
        ws-data (<span><span>map</span></span> <span>:data</span> ws-messages)
        try-parse #(<span><span>try</span></span> (<span>json/parse-string</span> % <span>true</span>)
                        (<span>catch</span> Throwable _ <span>nil</span>))
        
        
        
        ws-json (<span><span>reduce</span></span> (<span><span>fn</span></span> [{<span>:keys</span> [done partial]} next]
                          (<span><span>let</span></span> [potential-json-str (<span><span>str</span></span> partial next)]
                            (<span><span>if-let</span></span> [json (<span>try-parse</span> potential-json-str)]
                              {<span>:done</span> (<span><span>conj</span></span> done json)
                               <span>:partial</span> <span>""</span>}
                              {<span>:done</span> done
                               <span>:partial</span> potential-json-str})))
                        {<span>:done</span> [] <span>:partial</span> <span>""</span>}
                        ws-data)]
    (<span><span>assert</span></span> (<span><span>=</span></span> (<span>:partial</span> ws-json) <span>""</span>))
    (<span>:done</span> ws-json)))</code></pre>
<h2>Finding the culprit</h2>
<p>Armed with our parsed websocket messages, we can see that many of them look like transactions. One that looks particularly suspicious has a nested field named <code>tx-meta</code> with the value <code>delete-page</code>! The transaction looks something like this:</p>
<pre><code>{<span>:app-version</span> <span>"0.7.4"</span>,
 <span>:email</span> <span>"hello@jeff.yt"</span>,
 <span>:session-id</span> <span>"uuid95d98efd-c8fa-4412-87a4-e7b7201bee24"</span>,
 <span>:t</span> <span>1603947791561</span>,
 <span>:time</span> <span>1603947791542</span>,
 <span>:tx</span> <span>"[[\"^ \",\"~:block/uid\",\"ogCRjInhE\",\"~:block/string\",\"some-text-here\",\"~:edit/time\",1603947791363,\"~:edit/email\",\"hello@jeff.yt\"],[\"^ \",\"^0\",\"4CpSytRnt\",\"^1\",\"Highlights first synced by #Readwise October 28th, 2020\",\"^2\",1603947791364,\"^3\",\"hello@jeff.yt\"],[\"^ \",\"^0\",\"C-IOsE50G\",\"^1\",\"New highlights added October 28th, 2020 at 11:03 PM\",\"^2\",1603947791364,\"^3\",\"hello@jeff.yt\"],[\"~:db.fn/retractEntity\",[\"^0\",\"hLBqaz4gS\"]],[\"^4\",[\"^0\",\"vwD08rqdT\"]],[\"^4\",[\"^0\",\"6VWOGgeAd\"]],[\"^4\",[\"^0\",\"P56-fWN2O\"]],[\"^4\",[\"^0\",\"SffV3NfN2\"]],[\"^4\",[\"^0\",\"qnZBZCGCv\"]],[\"^4\",[\"^0\",\"10-28-2020\"]]]"</span>,
 <span>:tx-meta</span> {<span>:event-id</span> <span>"uuid719b009f-b969-47b6-b2db-41542d10b328"</span>,
           <span>:event-name</span> <span>"delete-page"</span>,
           <span>:tx-id</span> <span>"uuid289e80fc-4c27-4d54-9df4-d83ac0ceeaed"</span>,
           <span>:tx-name</span> <span>"delete-page"</span>}}</code></pre>
<p>I omitted ~90% of the transaction to save space - but it's more of the same. This definitely looks like the transaction that deleted my Daily Notes page: I see <code>db.fn/retractEntity</code> as well as <code>10-28-2020</code> in the transaction. Interestingly, this transaction captures two Readwise interactions as well. It's not a smoking gun, but it's definitely suspicious that Readwise was operating on my database at the <strong>exact same time</strong> that my page was mysteriously deleted!</p>
<p>Let's pause here, and check in with the Roam Slack group. Someone else has already started a thread about data loss! They and others quickly confirm that they also all have Readwise's auto-export enabled. Again, it's not confirmation that Readwise is to blame, but it's enough for me to stop what I'm doing and disable my Readwise integration! We'll also share our knowledge in the Slack thread and ask affected users to save their Roam HAR file like we did.</p>
<p>Later, <a href="https://twitter.com/homsiT" target="_blank" rel="nofollow noopener noreferrer">Tristan, founder of Readwise</a>, pops into Slack and quickly confirms that <a href="https://twitter.com/homsiT/status/1321856588022513665" target="_blank" rel="nofollow noopener noreferrer">a recent Roam behavior change combined with the Readwise integration can cause deleted pages</a>. Huge props to Tristan who responds perfectly: he triages the issue, disables the feature to prevent any more users from hitting it, and fixes &amp; re-enables auto-export all within a couple hours! Tristan also remains communicative and takes full responsibility, even offering refunds, though I'd argue that these hiccups are bound to happen when Roam still hasn't opened up their public API.</p>
<h2>Deserializing the database</h2>
<p>Peeking again at our parsed HAR file, we see what appears to be our serialized database - it's stored like this:</p>
<pre><code>{<span>:split-db</span> {<span>0</span> <span>"transit-encoded-str-0"</span>
            <span>1</span> <span>"transit-encoded-str-1"</span>
            ...}}</code></pre>
<p>Each string looks something like this:</p>
<pre><code>[\\\"^P\\\",[1641,\\\"^H\\\",\\\"zeciaTJfg\\\",536877373]],[\\\"^P\\\",[1641,\\\"^17\\\",\\\"hello@jeff.yt\\\",536877373]],[\\\"^P\\\",[1641,\\\"^18\\\",1583270770601,536877373]],[\\\"^P\\\",[1641,\\\"^R\\\",\\\"hello@jeff.yt\\\",536877373]],[\\\"^P\\\",[1641,\\\"^S\\\",1583270784121,536877377]],[\\\"^P\\\",[1642,\\\"^E\\\",1643,536877384]]
</code></pre>
<p>This looks like Transit! <a href="https://github.com/cognitect/transit-format" target="_blank" rel="nofollow noopener noreferrer">Transit</a> is a JSON-like format for sending data between applications (<a href="https://blog.klipse.tech/clojure/2016/09/22/transit-clojure.html" target="_blank" rel="nofollow noopener noreferrer">this post</a> is a good introduction). Datascript has its own <a href="https://github.com/tonsky/datascript-transit/" target="_blank" rel="nofollow noopener noreferrer">set of Transit handlers</a> - let's import that and see if we get a working database! Of course, we'll also need to combine <code>split-db</code> by smashing the Transit-encoded strings together.</p>
<pre><code>(<span>require</span> '[datascript.transit <span>:as</span> dt])

(<span><span>defn</span></span> parse-db
  [parsed-har]
  (<span><span>let</span></span> [db-str (<span><span>-&gt;&gt;</span></span> parsed-har
                    
                    (<span><span>filter</span></span> #(<span>some-&gt;</span> % <span>:d</span> <span>:b</span> <span>:d</span> <span>:split-db</span>))
                    first <span>:d</span> <span>:b</span> <span>:d</span> <span>:split-db</span>
                    vals
                    (<span>string/join</span> <span>""</span>))]
    (<span>dt/read-transit-str</span> db-str)))</code></pre>
<p>Voila - a real Datascript database! We can confirm it's my Roam database by querying it:</p>
<pre><code>(<span>require</span> '[datascript.core <span>:as</span> d])
(<span><span>let</span></span> [db (<span><span>-&gt;</span></span> harfile (<span>parse-har</span>) (<span>parse-db</span>))
      conn (<span>d/conn-from-db</span> db)]
  (<span>d/q</span> '[<span>:find</span> ?e <span>:where</span> [?e <span>:node/title</span> <span>"Daily Template"</span>]] @conn))

</code></pre>
<p>With a working Roam database, our next step is to apply all of the transactions we have up until the deletion event. Transactions are Transit-encoded, and we'll have to do quite a bit of data manipulation to get a list of them. Once we have that list, we can sort the transactions and apply them sequentially:</p>
<pre><code>(<span><span>defn</span></span> apply-transactions-until
  [db parsed-har until-time]
  (<span><span>let</span></span> [transactions-to-apply (<span><span>-&gt;&gt;</span></span> parsed-har
                                   (<span><span>map</span></span> #(<span>some-&gt;</span> % <span>:d</span> <span>:b</span> <span>:d</span>))
                                   (<span><span>filter</span></span> seqable?)
                                   (<span><span>apply</span></span> concat)
                                   (<span><span>filter</span></span> #(<span>string/starts-with?</span> (<span><span>-&gt;</span></span> % first name) <span>"-MK"</span>))
                                   (<span><span>map</span></span> second)
                                   (<span><span>filter</span></span> #(<span><span>&lt;</span></span> (<span>:time</span> %) until-time))
                                   (<span><span>sort-by</span></span> <span>:time</span>)
                                   (<span><span>map</span></span> <span>:tx</span>)
                                   (<span><span>map</span></span> dt/read-transit-str))
        conn (<span>d/conn-from-db</span> db)]
    (<span><span>doseq</span></span> [tx transactions-to-apply]
      (<span>d/transact!</span> conn tx))
    (<span>d/db</span> conn)))</code></pre>
<p>Here, <code>until-time</code> is the time of the deletion transaction. We're so close now! We've managed to materialize my Roam database from <strong>right before my notes were deleted</strong>! All we need to do now is pull that deleted page, and we'll be done!</p>
<h2>Recoverinâ€¦</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</a></em></p>]]>
            </description>
            <link>https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944574</guid>
            <pubDate>Fri, 30 Oct 2020 17:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why to Be Prolific]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944562">thread link</a>) | @jerodsanto
<br/>
October 30, 2020 | https://www.chrismytton.com/be-prolific/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/be-prolific/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>Thereâ€™s a story about an art teacher that split their class in half. They told one half of the students that theyâ€™d be graded based on a single piece of work, and the other half that they would be graded on the quantity of work produced.</p>

<p>The half that was being graded on quantity ended up producing higher quality pieces.</p>

<p>By iterating and learning from their mistakes they actually ended up producing better work than the students that only had to produce one piece.</p>

<p>Quantity leads to quality.</p>



<p>Sharing work helps you to think and develop. The feedback you get feeds into the next iteration.</p>

<p>If youâ€™ve enjoyed creating something then thereâ€™s a good chance that at least a handful of people in the world will enjoy seeing it or hearing about it.</p>

<p>Promoting yourself and your work can be a good way to clarify your thinking and future direction.</p>

<h2 id="get-better-by-creating-more">Get better by creating more</h2>

<p>Produce lots of stuff and share it.</p>

<p>Being prolific doesnâ€™t mean that everything you produce has to be absolute gold. But the process of producing large quantities of work ultimately leads to a higher quality of work.</p>

<hr>

<p><a href="https://news.ycombinator.com/item?id=24866706" target="_blank">Discussion on Hacker News</a>.</p>

<p><a href="https://eduardoorige.com.br/posts/seja-prolifico/index.html" target="_blank">Portuguese translation</a> by Eduardo Orige.</p>

<p><a href="https://farzat.online/2020/10/28/be-prolific/" target="_blank">Arabic translation</a> by Farzat Al Chayah.</p>

    </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/be-prolific/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944562</guid>
            <pubDate>Fri, 30 Oct 2020 17:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Revenue Takes Care of Itself]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24944559">thread link</a>) | @yarapavan
<br/>
October 30, 2020 | https://boz.com/articles/revenue | <a href="https://web.archive.org/web/*/https://boz.com/articles/revenue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>Bill Walsh is one of the greatest coaches in the history of the NFL. He
started with a 49ers team that only won two games and within two years they
had won their first Super Bowl. He retired after 10 years but before he was
done they would win two more. A decade later more than half of the head
coaches in the NFL had once served on his staff.</p>
<p>Just before he passed away he wrote a book on leadership entitled â€œ<a href="https://www.amazon.com/Score-Takes-Care-Itself-Philosophy/dp/1591843472/">The Score
Takes Care of
Itself</a>.â€
His idea was simple enough: you donâ€™t win football games by trying to score.
You donâ€™t build championship teams by trying to win.  Instead he set a high
standard of performance and held people to it on the execution of every play.
He believed there were good losses and bad wins. He believed that if you had
good people, a good culture, and strong guiding principles then the score
would take care of itself.</p>
<p>If you go back to 2012 there are some analogies one could draw between the
49ers of that era and the performance of Facebook ads. I donâ€™t know if we even
had two wins before 2012. But after? Well, they donâ€™t give out Lombardi
trophies for digital advertising but I think if they did weâ€™d be a contender.</p>
<p>The far more interesting connection between these stories is the approach. We
didnâ€™t establish ourselves as a leading digital advertising platform by
focusing on the obvious metric of revenue. We realized that when it came to
revenue there were good losses and bad wins. We explicitly focused on
advertiser value and consumer value even when it came at the cost of revenue.
This wasnâ€™t just cultural; our ranking systems and auction focus on optimizing
advertiser value and consumer experience rather than revenue to Facebook. By
focusing on our people, on our culture, and on strong guiding principles we
have been able to demonstrate that the revenue takes care of itself.</p>
<p>Focusing on metrics has <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">well established
problems</a>, but in the case of
revenue there are two even more pathological ones.</p>
<p>Revenue is a trailing indicator. When people are just getting started with a
new service they donâ€™t just dive in with their full budget. They invest a
little and revise their budget allocation incrementally. If you push too hard
on revenue you can get 100% of the budget they allocated you today but you are
missing the bigger opportunity to give them outsized returns which is what
will cause them to allocate you more of their budget in the future.</p>
<p>Revenue is short term. In many of our products a focus on maximizing revenue
would lead us down a very different path than maximizing value. Maximizing
value often requires long term investments whose return profile is risky or
entirely unknown. But we know that without those types of long term
investments our business growth will start to plateau as we saturate the value
created by existing solutions.</p>
<p>Mark had a famous line in the S-1 we filed for our IPO: â€œWe donâ€™t build
products to make money, we make money to build great products.â€ I agree
wholeheartedly which is why the mission of the Facebook ads organization isnâ€™t
to make money. It is to make meaningful connections between people and
businesses. And we take that seriously.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/revenue</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944559</guid>
            <pubDate>Fri, 30 Oct 2020 17:20:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KDE.org migrated to Hugo]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24944537">thread link</a>) | @ognarb
<br/>
October 30, 2020 | https://carlschwan.eu/2020/10/30/kde-org-hugo.html | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2020/10/30/kde-org-hugo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img src="https://carlschwan.eu/assets/img/heading_hugo.png" alt="Screenshot KDE.org"></p>

<p><a href="https://kde.org/">KDE.org</a> now uses <a href="https://gohugo.io/">Hugo</a>. Hugo is a fast and modern static site
generator written in Go. It provides a few improvements over the old system that was
using plain PHP. A large part of the work was done by Anuj during GSoC 2020. This
was a massive work, converting the repository storing more than 20 years of KDE
history.</p>

<p>The website is now generated once and no longer uses PHP to generate itself at runtime.
This improves the loading speed of the website, but the speed boost is not significant,
since the PHP code used before was quite small and KDEâ€™s servers are powerful.</p>

<p>But the biggest improvement is in terms of features. We are now working with markdown
files instead of raw HTML files, this makes the life of the promo team much easier.</p>

<p>The internationalization of the website now creates a unique URL per language, this
should allow Google to link to the version of the website using the correct language.
A <a href="https://kde.org/fr/">French</a>, <a href="https://kde.org/uk/">Ukrainian</a>,
<a href="https://kde.org/ca/">Catalan</a>, <a href="https://kde.org/nl/">Dutch</a>, and a few more languages
are already available. There is also a proper language selector! We also donâ€™t need
to manually tag each string for translations.</p>

<p>There is also now an <a href="https://kde.org/announcements/index.xml">RSS feed</a> with all the
latest announcements. Another big improvement is that the announcements list is
autogenerated and no longer modified by hand and with the help of the release scripts.</p>

<p>Another nice change for website developers is that now the SCSS code for the individual
pages is located in the kde-org repository itself instead of another repository.
Overall the developer experience is much better, there is no need to set up an apache
server and to the PHP configs to include the <a href="https://invent.kde.org/websites/capacity">capacity framework</a>, just to get the
website running locally. Now you only need to download the Hugo binary from their
release page and run it on the repo.</p>

<h2 id="hugo-and-gettext">Hugo and Gettext</h2>

<p>The internationalization of KDE.org was quite a challenge. When working on a multilingual
website with Hugo, Hugo expects a markdown document per language for each translated
page.</p>

<div><div><pre><code>plasma-desktop.md
plasma-desktop.es.md
plasma-desktop.fr.md
plasma-desktop.uk.md
...
</code></pre></div></div>

<p>The problem is that traditional translations workflow rely on a string-based approach,
where a document is split in paragraphs and translated individually. So I couldnâ€™t
just put each file markdown file as big blobs in the po files. To solve this problem,
I created a python script splitting the markdown files in paragraphs, simplifying
the markdown syntax (removing leading <code>#</code> and <code>+</code> for heading and list item). This
script also handles Hugo shortcodes transforming:</p>

<div><div><pre><code>
{{&lt; img caption="My figure caption" alt="My accessible description" src="..." &gt;}}

</code></pre></div></div>

<p>in two strings:</p>

<ul>
  <li>My figure caption</li>
  <li>My accessible description</li>
</ul>

<p>The script can obliviously put the individual strings back in place. The scripts also
handle the menu translation, and the translations of the strings in the footers.
For now, the script is just a file in the kde-org repository, but I would like to
transform it to a standalone library so that other gettext and Hugo users can
translate their website.</p>

<p>Using Hugo API, the language selector was trivial to write:</p>

<div><div><pre><code>
&lt;ul class="navbar-nav ml-auto"&gt;
  {{ if .IsTranslated }}
    &lt;li class="nav-item dropdown" aria-describedby="language-picker-description"&gt;
      &lt;p class="sr-only" id="language-picker-description"&gt;{{ i18n "Select-your-language" }}&lt;/p&gt;
      &lt;a class="nav-link dropdown-toggle" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"&gt;
        &lt;img src="/Language-Icons/icon20x24px-exported-transparent.png" alt="" /&gt;
        &lt;span&gt;{{ i18n "translations" }}&lt;/span&gt;
      &lt;/a&gt;
      &lt;div class="dropdown-menu dropdonw-trans" role="listbox"&gt;
        &lt;a class="dropdown-item" aria-selected="true" hreflang="{{ .Site.Language.Lang }}" role="option" lang="{{ .Site.Language.Lang }}" href="{{ .Permalink }}"&gt;{{ .Site.Language.LanguageName }}&lt;/a&gt;
        {{ range .Translations }}
          &lt;a class="dropdown-item" hreflang="{{ .Language.Lang }}" role="option" lang="{{ .Language.Lang }}" href="{{ .Permalink }}"&gt;{{ .Language.LanguageName }}&lt;/a&gt;
        {{ end }}
      &lt;/div&gt;
    &lt;/li&gt;
  {{ end }}
&lt;/ul&gt;

</code></pre></div></div>

<p>This is a bit verbose because this selector is also fully accessible for screen readers.</p>

<p>There are a few more tricks employed in kde.org to improve the internationalization, for
example when a page doesnâ€™t exist in a language, there is an Apache rule redirecting it
to the English version. Another nice trick is that there is a special Hugo shortcode
called <code>i18n_var</code> and used to parametrize the strings. For example:</p>

<div><div><pre><code>
{{&lt; i18n_var "Today KDE releases a bugfix update to KDE Plasma 5, versioned %[1]s" "5.20.2" &gt;}}

</code></pre></div></div>

<p>And the extractor is clever and only extract the part that needs to be translated.</p>

<p><a href="https://invent.kde.org/websites/kde-org/-/blob/master/translations.py">The script</a></p>

<p>You can comment this post on <a href="https://www.reddit.com/r/kde/comments/jl1pim/kdeorg_migrated_to_hugo/?">r/kde</a>
and <a href="https://news.ycombinator.com/item?id=24944537">HN</a>.</p>
</section></div>]]>
            </description>
            <link>https://carlschwan.eu/2020/10/30/kde-org-hugo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944537</guid>
            <pubDate>Fri, 30 Oct 2020 17:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mendoza: Use stack machines to compute efficient JSON diffs]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24943775">thread link</a>) | @evenw
<br/>
October 30, 2020 | https://www.sanity.io/blog/mendoza | <a href="https://web.archive.org/web/*/https://www.sanity.io/blog/mendoza">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When we started work on the recently released feature <a href="https://www.sanity.io/blog/review-changes">Review Changes</a>, we needed a way to keep a significant part of the edit history of a document in the browser memory to be able to respond quickly to different user interface states. As the user picked various document versions to compare we wanted to be able to quickly reconstruct a specific section of the history of a document. </p><figure><div role="button"><div data-has-aspect="false"></div></div><figcaption>Review Changes for Sanity Studio. Powered by Mendoza.</figcaption></figure><p>For text diffs, we use the <a href="https://github.com/google/diff-match-patch">diff-match-patch format</a>, and we just assumed someone would have implemented a similarly efficient and compact diff format for JSON documents, but no such luck. If we wanted a general JSON diff format that was super compact and fast to apply, we would have to invent it ourselves. And thus, Mendoza, the totally non-human readable diff format for structured JSON documents, was born.</p><p>Mendoza is:</p><ul><li>Lightweight JSON format</li><li>A flexible format that can accommodate more advanced encodings in the future</li><li>As a Go library for encoding and decoding</li><li>A JavaScript library for decoding</li><li>Efficient handling of the renaming of fields</li><li>Efficient handling of reordering of arrays</li><li>Not designed to be human-readable</li></ul><p>Mendoza differs (hah!) from normal diffs as they are:</p><ul><li>Made for humans to read and understand and based on simple operations (like keep, insert, and delete text)</li><li>Possible to apply even if the source has changed a bit by including some of the contexts around every part that has changed</li><li>Designed for text, and not structured documents</li></ul><p>Now, this is great when you are collaborating with humans on code development and use something like git to track your changes. What it isnÃ¢â‚¬â„¢t great for, however, is expressing differences between structured documents (such as JSON) in a compact manner that can be efficiently transferred over the network and parsed in JavaScript inside of browsers.</p><div data-block-key="27e85758c59a"><h2><a id="most-diffs-arent-meant-for-machines-27e85758c59a"></a><a href="#most-diffs-arent-meant-for-machines-27e85758c59a"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>Most diffs aren't meant for machines</h2></div><p>Most diff formats are made to be human-readable. Take these two documents, where a key and the array have some changes between them:</p><p>If these where two commits, the Git diff between them would be expressed like this:</p><p>This makes it somewhat practical for humans to understand what is going on when the latter change is applied. But as you can see, in terms of pure data, there is a lot of repetition going on. and expressing all changes with only plusses and minuses isn't very efficient.</p><p>The same diff with Mendoza is expressed like this:</p><p>Mendoza constructs a minimal recipe for transforming a document into another. All it really does is to compare two JSON documents and figure out the most minimal way to express their difference as strings and integers in an array. You can use this difference to reconstruct the first document to the other.</p><div data-block-key="308db67aa205"><h2><a id="how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"></a><a href="#how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>How to read a Mendoza patch (even though you shouldn't)</h2></div><p>A Mendoza patch consists of an array of integers and strings. The integers are <em>opcodes</em> (short for Ã¢â‚¬Å“operation codesÃ¢â‚¬ï¿½), 8-bit numbers that correspond to an operation. Opcodes take parameters as strings, positive numbers, or JSON values (that is: the actual data that is changing). The list of available opcodes is as follows, notice that 10-18 are composites of the preceding ones:</p><ul><li>0 <code>Value<!-- -->Ã¢â‚¬â€¹ </code></li><li>1 <code>Copy<!-- -->Ã¢â‚¬â€¹ </code></li><li>2 <code>Blank<!-- -->Ã¢â‚¬â€¹</code></li><li>3 <code>ReturnIntoArray<!-- -->Ã¢â‚¬â€¹ </code></li><li>4 <code>ReturnIntoObject<!-- -->Ã¢â‚¬â€¹ </code></li><li>5 <code>ReturnIntoObjectSameKey<!-- -->Ã¢â‚¬â€¹ </code></li><li>6 <code>PushField<!-- -->Ã¢â‚¬â€¹ </code></li><li>7 <code>PushElement<!-- -->Ã¢â‚¬â€¹ </code></li><li>8 <code>PushParent<!-- -->Ã¢â‚¬â€¹ </code></li><li>9 <code>Pop<!-- -->Ã¢â‚¬â€¹ </code></li><li>10 <code>PushFieldCopy</code></li><li>11 <code>PushFieldBlank</code></li><li>12 <code>PushElementCopy</code></li><li>13 <code>PushFieldBlank</code></li><li>14 <code>ReturnIntoObjectPop</code></li><li>15 <code>ReturnIntoObjectSameKeyPop</code></li><li>16 <code>ReturnIntoArrayPop</code></li><li>17 <code>ObjectSetFieldValue</code></li><li>18 <code>ObjectCopyField</code></li><li>19 <code>ObjectDeleteField</code>Ã¢â‚¬â€¹ </li><li>20 <code>ArrayAppendValue</code>Ã¢â‚¬â€¹ </li><li>21 <code>ArrayAppendSlice<!-- -->Ã¢â‚¬â€¹</code></li><li>22 <code>StringAppendString<!-- -->Ã¢â‚¬â€¹</code></li></ul><p>Mendoza reads these opcodes from the patch and produces the resulting document from them. Depending on the patch, Mendoza might choose not to strictly follow the opcodes but take a simpler path. If every field and value has changed, for example, itÃ¢â‚¬â„¢s more efficient just to replace the whole document with the new data without going through all the operations. Or if you have a list of objects where one has moved to another position and changed a key-value, Mendoza will manage to go back to the original and represent the change in a cheap way.</p><p>Mendoza is implemented in Go and can be found in this <a href="https://github.com/sanity-io/mendoza">GitHub repository</a>. We have also made <a href="https://github.com/sanity-io/mendoza-js">a parser for Mendoza patches in JavaScript</a>, that you can use in your own application. </p><p>Of course, you can dive into <a href="https://github.com/sanity-io/sanity/blob/a3f7158016d63728a9b435e6ab444ff2b90fd424/packages/%40sanity/desk-tool/src/panes/documentPane/documentHistory/history/timeline.ts#L421">the source code for the Sanity Studio</a> and explore how Mendoza is used there. If you want a slightly simpler use-case, you can also <a href="https://github.com/sanity-io/groq-store/blob/main/src/patch.ts">check out how weÃ¢â‚¬â„¢re using Mendoza to simulate a part of SanityÃ¢â‚¬â„¢s real-time datastore</a> in the browser to power the <a href="https://github.com/sanity-io/next-sanity">real-time preview for Next.js</a>. </p><p>Naming a project is always difficult. Since this project is focused on representing changes between <em>JSON</em> documents I naturally started thinking about names like "JSON differ, JSON changes, JSON patch, Ã¢â‚¬Â¦". However, most of these names have already been used by existing projects. While I was muttering "JSON, JSON, JSON" it suddenly turned into "JSON, JSON, Jason, Jason Mendoza".</p><p>Jason Mendoza is a character from the show The Good Place, and while this project has little in common with the stupidest DJ from Florida, at least it's short and catchy.</p><p>Since a Mendoza patch is just describing the effect of a change it is also limited to work for the documents it was based on. It doesnÃ¢â‚¬â„¢t come with guarantees for consistency if the document you apply it on has changed from the original in meanwhile. This is one of the tradeoffs that we needed to do to make it really compressed. </p></div></div></div>]]>
            </description>
            <link>https://www.sanity.io/blog/mendoza</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943775</guid>
            <pubDate>Fri, 30 Oct 2020 16:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pondering Amazon's Manyrepo Build System]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24943737">thread link</a>) | @nephics
<br/>
October 30, 2020 | http://beza1e1.tuxen.de/amazon_manyrepo_builds.html | <a href="https://web.archive.org/web/*/http://beza1e1.tuxen.de/amazon_manyrepo_builds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>A while ago,
<a href="http://beza1e1.tuxen.de/monorepo_vcs.html">I pondered monorepo version control systems</a>.
This article is at the opposite end of the spectrum: Manyrepos.</p>
<h2>Why Manyrepo?</h2>
<p>Monorepos are alluring since Google, Facebook, and Microsoft use that approach.
Is that a part of their secret sauce or accidental?
There is another big tech company which does the opposite.
At Amazon, teams work more independently.
Some use different version control systems which are not git
like Subversion and Perforce.
I guess that most companies do <em>not</em> have a monorepo
because it is really easy to split of a separate project
but hard to merge them just from an organizational point of view.
So maybe we can learn more from Amazon than Google?</p>
<p>A common pattern is that Amazon like the others built its own infrastructure
and engineers love it and miss it after they leave.</p>
<blockquote>
<p>I've heard descriptions and seen blog entries about many other large companies build systems, but to be honest, nothing even comes close to the amazing technology Amazon has produced.
I would probably argue that what Google, Facebook, and most other companies of comparable size and larger do is at best objectively less good and at worst wasting millions of dollars of lost productivity.
â€“<a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0">terabyte</a></p>
<p>Once you understand the build and deployment tools you first wonder how you ever did anything before and then start to fear how you'll do anything once you leave.
â€“<a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0#gistcomment-3356000">hohle</a></p>
</blockquote>
<p>Just like Ex-Googlers reinvented their build system on the outside
with <a href="https://www.pantsbuild.org/docs">Pants</a>
and <a href="https://buck.build/">Buck</a>.
Likewise <a href="https://qbtbuildtool.com/">QBT</a> reinvents the Amazon build system.
Unfortunately, QBT is less known and less mature.</p>
<h2>Amazon's Build System</h2>
<p>There is less information about Amazon unfortunately.
Mine is from <a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0">this gist</a>
and discussions on 
<a href="https://news.ycombinator.com/item?id=24722214">HN</a> and
<a href="https://lobste.rs/s/ykk54d/amazon_s_build_system">lobste.rs</a>.
If I got something wrong, please tell me.
The short version is that Amazon's "Brazil" tool is
more of a package system than a build system.
It is closer to Nix than to Bazel.</p>
<p><a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0#gistcomment-3356000">Brazil delegates the actual build process to language-specific tools</a>.
Tools, like tmux, are also packaged with Brazil.
The interesting part is how packages are managed
and the core concept to understand is <em>version set</em>.</p>
<p>If you create a package at Amazon,
you specify an <em>interface version</em> like "1.1".
As long as changes are backwards-compatible,
the interface version is not changed.
When Brazil builds a package,
it appends an additional number to turn it into a <em>build version</em>
like "1.1.3847523".
You can only specify dependencies on interface versions.</p>
<p>Another thing Brazil does when building a package
is to record the transitive closure of dependencies
with their build versions.
Modern packaging tools differ between
"dependencies you want"
and "dependencies you actually used".
For example, <a href="https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html">Cargo.toml and Cargo.lock in Rust</a>.</p>
<p>A <em>version set</em> is a collection of packages.
The "live" package is the special global one
which corresponds to a trunk branch in version control.
When you build a package "against" a version set,
the tests of all packages in the version set are executed,
and the version set is incremented.
Thus the individual package is updated
(or published if it was not part of the version set before).</p>
<p>Brazil dependencies are classified as runtime, build, and test dependencies.
So for deployment, it can strip everything but the runtime dependencies
from a version set.</p>
<p>Dependencies must be carefully managed in this environment
as a "dependency hell" scenario is possible.</p>
<blockquote>
<p>One of the biggest ways that brazil was misused was around handling of major versions [aka interface version].
For context, only a single major version of a package is allowed to exist in a versionset at a time. If you tried to merge in a different major version of a package into your versionset, your pipeline would fail to build due to "Major version conflicts". One of the biggest sins was around bumping the major versions of the dependencies in a library without bumping the major version of that library at the same time. This would lead to many broken pipelines. Let's say you have a library Foo-1.0 with a bunch of users on other teams. You decide to bump up the Guava version from 25 to 29 and publish the new version of Foo-1.0. Anyone consuming Foo-1.0 would automatically pick up the new version of that lib because it's just a minor version change, however the merge would fail with a "major version conflict" because the major version of Guava they're using in their versionset is still 25. This means you would either have to pin that library back at a previous version, or bump your dependency on Guava in all of you packages to 29.
â€“<a href="https://news.ycombinator.com/item?id=24731537">pentlander</a></p>
</blockquote>
<p>This is an insight that generalizes:
Updating a dependency major version is a breaking change
even if your API is stable.</p>
<h2>The Point?</h2>
<p>Overall, it sounds a lot like a distribution package manager like apt or Nix.
The difference of version sets is
that they provide a branching mechanism
and this is how teams can work independently.
How is that unique though?
You can fork with apt and Nix as well.
In a monorepo, it would be a branch.
It must be about something different.</p>
<p>One advantage of monorepos is that one can track all users.
Version sets in Brazil provide a similar mechanism
since it is a <em>central</em> database.
This is important in case of security updates, for example.
Unfortunately, in manyrepo environments this information is usually not available
and when an issue arise it must be arduously researched.
So maybe companies should build such infrastructure
instead of dreaming about monorepos?</p>
<p>Coming back to the advantage of manyrepos,
refering to Amazon we can describe it concretely:
Version sets allow you to use multiple interface versions of the same package
at once (not multiple build versions though).
This mixture is not technically possible with a git monorepo
(but with Subversion or Perforce).
This is at least one example of the general tradeoff.</p>
<blockquote>
<p>I donâ€™t really think thereâ€™s a better or worse between the Amazon and Google/FB style build/deploy/source control systems, itâ€™s primarily a reflection of the org/team structure and what they prioritize - thereâ€™s tension between team independence/velocity and crosscutting changes that optimize the whole codebase.
â€“<a href="https://lobste.rs/s/ykk54d/amazon_s_build_system#c_fzyzg6">revert</a></p>
</blockquote>
<p>I would like to see more discussion online about this.
Many companies should value the team independence over the crosscutting changes.
So the question is:
How to get the advantages we currently uniquely attribute to monorepos
in a manyrepo setting?
Amazon's Brazil has valuable ideas to contribute
and should be more widely known.</p>

</article><p>Amazon's build system provides valuable insights for manyrepo environments.</p></div>]]>
            </description>
            <link>http://beza1e1.tuxen.de/amazon_manyrepo_builds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943737</guid>
            <pubDate>Fri, 30 Oct 2020 16:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useless Inventions:Is Your Product a Solution in Search of a Problem?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943717">thread link</a>) | @rjyoungling
<br/>
October 30, 2020 | https://www.younglingfeynman.com/essays/uselessinventions | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/uselessinventions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ba977392c5ff62ef784f"><div><p>In Japanese, thereâ€™s a word for thatâ€¦</p><blockquote><p><a href="https://en.wikipedia.org/wiki/Chind%C5%8Dgu" target="_blank">â€œChindÅgu</a> (çé“å…·) originated in Japan and is characterized by the invention of ingenious everyday gadgets that seem to be ideal solutions to particular problems, but which, in fact, cause more problems than they solve.â€</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604071674616_51027"><div><p>Even though chindÅgu (which translates to strange tools), is more about making people laugh at the inventions that create more problems than they solve, I can't help but wince.</p><p>Aren't we guilty of that often?<br></p><p>There are voices that promote this approach but for most of us, it's a recipe for disaster. [1] It's just much easier to start with a lock and build a key than to create a key and then go into the world in search of a lock that it can open. [2]</p><p>If you start with the solution, you'll struggle with:</p><ol data-rte-list="default"><li><p>Finding the problem that it solves</p></li><li><p>Finding the people who have that problem.</p></li><li><p>Finding a group of people for whom that problem is actually a REAL problem.</p></li><li><p>Finding the people in the intersection between â€œitâ€™s a real problemâ€ and â€œIâ€™ll pay for your solution.â€</p></li></ol><p>Instead, if you want to maximize the probability of success, start with one of the following approaches:</p><ol data-rte-list="default"><li><p><strong>AUDIENCE-FIRST:</strong> Pick a tiny audience (&lt;10 people), and identify a problem that they have. Keep iterating problems and solutions until you've stumbled onto something that makes them say WOW!! instead of ehâ€¦ [3] E.g. <a href="https://medium.com/@rrhoover/building-a-startup-build-an-audience-first-9fbba4f1fa15" target="_blank">Ryan Hoover with Product Hunt</a>.</p></li><li><p><strong>PROBLEM-FIRST:</strong> Notice a problem you have in your own life, then build something that solves it. That way you know for sure it's not an imaginary problem and you have a user that can help you iterate (you). E.g. Wozniak with the Apple I. <a href="https://www.younglingfeynman.com/essays/airbnb2?rq=wozniak" target="_blank"><em>More on that here</em></a><em>.</em></p></li><li><p><strong>NEEDS-BASED: </strong>Create something you just really want to see in the world. So the problem it solves for you is just, I want this and it doesn't exist. I'm not the biggest fan of this approach in general but it can work. E.g. Jack Dorsey with Twitter.</p></li></ol><p><em>[1] From </em><a href="https://www.younglingfeynman.com/essays/2019/3/8/start-with-the-who-or-with-the-what?rq=andy" target="_blank"><em>Start With The Who Or With The What?</em></a></p><blockquote><p><em>"â€¦And Andy Rachleff (Benchmark Capital, Wealthfront) is of the mind that you should change the who, not the what. Starting with the market, leads to common and uninteresting problems, but if you start with the what, then you can find the right people."</em></p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604071674616_53117"><div><p><em>[2] Even worse is that most of us often build the most expensive, overengineered key. We build some perfect product with tons of infrastructure in anticipation of the immediate exponential growth weâ€™ll get when we launch. But when it turns out the dogs arenâ€™t eating the dog food, those resources are wasted. More on this in </em><a href="https://www.younglingfeynman.com/essays/paradigm?rq=success" target="_blank"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a><em>.</em></p><p><em>[3] More on that in </em><a href="https://www.younglingfeynman.com/essays/livewithout" target="_blank"><em>Create A Product Thatâ€™s Hard To Live Without</em></a><em>. I disagree with the notion that it needs to be a "hair on fire problem." The hypothesis that you need to sell painkillers not vitamins seems plausible as a metaphor but empirically it doesn't pan out. There are tons of successful founders that solved something that was just an annoyance for their customers. Just focus on making something they love so much that it's hard to live without.</em></p></div></div></div>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/uselessinventions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943717</guid>
            <pubDate>Fri, 30 Oct 2020 16:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye IFTTT]]>
            </title>
            <description>
<![CDATA[
Score 332 | Comments 149 (<a href="https://news.ycombinator.com/item?id=24943685">thread link</a>) | @todsacerdoti
<br/>
October 30, 2020 | https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I was a power user of <a href="https://ifttt.com/">IFTTT</a> for many years, so I had mixed
feelings recently about <a href="https://archive.is/zpx2r">their decision</a> to change
their pricing model. Under IFTTT's new pricing, you can only have 3 â€œcustomâ€
actions created/enabled at any time â€“ which is quite a downgrade from the
current unlimited free plan. On the one hand, I'm glad to see IFTTT take
necessary steps to ensure it has long-term financial stability, but on the other
hand, I don't personally get enough value from their service anymore to justify
a recurring cost. (The plan will likely be
$4/month<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, but if you sign up before a deadline, you
can lock in a price as low as $2/month)</p>
<p>IFTTT was an awesome and uniquely easy-to-use service when it first came out,
but now there are better options for personal automation for people like me, who
like to tinker with this sort of thing. Systems like
<a href="https://nodered.org/">node-red</a> and iOS shortcuts can be self hosted or run on
device, and they provide more sophisticated logic for workflows than IFTTT.</p>
<p>I stayed on IFTTT this long mostly due to inertia, and it's fantastically long
list of supported services. If I needed to throw together a quick
spreadsheet-recording automation, or cron-like trigger, IFTTT was a great
starting place. However, it does have limitations. Until now (though it seems
like this might change with their premium offering), IFTTT basically only did
what its name implied: â€œif this, then thatâ€. No â€œif X then Y else Zâ€, no â€œif X
and Z then Yâ€, etc. Often times, you don't need any complicated logic or
filtering, but it was frustrating that there wasn't the option for more advanced
automation. Ultimately, IFTTT had a great â€œon-rampâ€, but once you were on board
with their system, you realize how shallow it is. Excellent breadth, mediocre
depth.</p>
<p>Similarly, in the past couple years IFTTT's UI has leaned heavily into the
â€œappletâ€ metaphor, with these big goofy toggle switches to enable/disable
automations. The site also transitioned towards a focus on community- (or, more
often corporate-) created automations, at the expense of the experience for
creating your own applets. Like seriously, why is 30% of the UI for an applet
<em>details page</em> (!) taken up by the connection status toggle?</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt.png">
        
            
                
                
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt_hu1a43e8a517283105e03bcbb0c4894a01_37903_0x300_resize_lanczos_2.png" loading="lazy"> 
        </a>
</figure>

<p>The settings page, too, is woefully information sparse. As a user, this makes me
feel that desktop-usability was not high on IFTTT's design priorities. You have
to scroll the page to begin to start to see what the automation is doing:</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt-settings.png">
        
            
                
                
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt-settings_hub4acc09d90c5c0c4cbf3054a07fa3040_91989_0x400_resize_lanczos_2.png" loading="lazy"> 
        </a>
</figure>

<p>Eventually, the UI got to the point where it felt like using
<a href="https://en.wikipedia.org/wiki/Lego_Duplo">Duplos</a> or something. It didn't have
to be this way! There are great low-to-no-code tools that have much more usable
interfaces, like
<a href="https://en.wikipedia.org/wiki/Scratch_(programming_language)">Scratch</a>.</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/scratch.png">
        
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/scratch.png" loading="lazy"> 
        </a>
</figure>

<p>So, I decided to migrate away, since the move to premium was already going to
substantially limit what I could do with IFTTT. In going through my catalog of
IFTTT â€œappletsâ€, I identified 3 main patterns of automations that I used IFTTT
for: (1) triggering an action to happen at a specific time, (2) triggering an
action to happen in response to a location change (i.e. geofencing), or (3)
triggering an action to happen in response to an event in a web service.</p>
<p>Of these 3 buckets, iOS shortcuts readily handles the first 2: as of iOS 14,
Shortcuts can be triggered in the background at a specific time of day, or in
response to entering/leaving a geofence. Shortcuts also has a much more
sophisticated integration with iOS than any of IFTTT's apps, so more exciting
mobile automation becomes possible â€“ for example, setting my phone to Low Power
Mode once the battery drops below a certain threshold. Of course, you are
restricted to apps/services that support Shortcuts, and the number of supported
services is considerably smaller than IFTTT.</p>
<p>Node-red handles buckets 1 and 3: it has good support for time-based actions,
and can receive webhooks to respond to events from external services. It also
has a great plugin ecosystem, so it's support begins to rival IFTTT's impressive
selection of supported services. Additionally, node-red has many â€œescape
hatchesâ€ that IFTTT does not: you can use it to make raw HTTP requests and write
your own plugins/logic in Javascript, allowing for much more complex automation.</p>
<p>Neither node-red nor iOS shortcuts are as easy to use as IFTTT for putting
together a simple automation, which is a shame. However, between them (and other
alternative automation frameworks that I've trialed, like <a href="https://n8n.io/">n8n</a>
and <a href="https://github.com/huginn/huginn">huginn</a>), I've more than covered my
personal automation needs.</p>
<p>And so, goodbye IFTTT! Ã°Å¸â€˜â€¹ I'm not put off by them charging for their service; I
think charging for software is a good thing! It's just that this was the nudge I
needed to move my automations to infrastructure that I have more control over,
which has other benefits outside the scope of this article. I'm thankful that a
service like IFTTT continues to exist; I still think it's a fantastic tool to
â€œon-rampâ€ less technical folks into automation and no-code tools.</p>
<p><em>Cover art:
<a href="https://artvee.com/dl/the-village-of-murnau/">The Village Of Murnau (1908)</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>A previous version of this article stated that the price for IFTTT Pro was
$10/month. While the original press release, as covered <a href="https://www.theverge.com/2020/9/10/21430265/ifttt-pro-subscriptions-free-controversy">here</a> indicated a $10/month
price, and the current suggested price for IFTTT Pro on their signup form is
$10/month, it seems like going forward the Pro price will be $4/month. I
apologize for the inaccuracy. <a href="#fnref:1" role="doc-backlink">â†©ï¸Ž</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943685</guid>
            <pubDate>Fri, 30 Oct 2020 16:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peer Assessment Bias]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24943216">thread link</a>) | @rmulholland21
<br/>
October 30, 2020 | https://www.ryansmulholland.com/writing/peer-assessment-bias | <a href="https://web.archive.org/web/*/https://www.ryansmulholland.com/writing/peer-assessment-bias">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-63067710b8dc43d7e49b"><div><p><strong>Whatâ€™s the difference between you and an expert?</strong></p><p>Itâ€™s kind of obvious, isnâ€™t it? Television appearances, thousands of dollars, and an audience of fans that accept ideas as thought leadership.</p><p>But seriously, what even <em>is</em> an expert?</p><p>Experts are peers whoâ€™ve had their ideas catch on through hard work, exhibition of talent, or luck.</p><p>I believe that statement, but it drastically simplifies everything thatâ€™s gone into someone establishing themselves as an expert. Itâ€™s not easy to get to the place where people assume you know what youâ€™re talking about. It takes time, effort, and passion to get there. Overnight experts only exist in viral moments, it takes real expertise to have staying power.</p><p>The experts of the pre-internet age almost always hailed from academia. Earning credentials and conducting research was the only way to prove to others that you know what the hell youâ€™re talking about. There was a gatekeeper to every distribution vessel and no public forum where a great idea from anyone could win the day.</p><p>Now we have that forum. The internet is full of people who are trying to be experts â€” people who think theyâ€™re experts â€” and as a result, thereâ€™s a monsoon of content on any given topic. And with access to information on anything, itâ€™s the top 1% of information that we rely on, which usually belongs to...experts.</p><p>But experts are peers, remember? Just really fancy ones.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_6131"><div><p>So why donâ€™t we consider the ideas of our peers in the same way we adopt the ideas of established thinkers?</p><p>To you, my peers, Iâ€™d like to present Peer Assessment Bias.</p><h3><strong>Peer Assessment Bias</strong></h3><p>Peer Assessment Bias is why this essay wonâ€™t be read tens of thousands of times. Itâ€™s why your best original ideas arenâ€™t being talked about in bestselling books. Itâ€™s why you read something that a friend wrote and thought, â€œhmm, that was pretty good,â€ but not, â€œpress the pause button on life, I need to take notes!â€</p><p><strong>Peer Assessment Bias is the natural inclination to be more skeptical of the ideas of those perceived as peers, more so than the ideas of those perceived as experts.</strong></p><p>Simply put, when itâ€™s your friendâ€™s idea itâ€™s solid, but when itâ€™s coming from Peter Thiel, itâ€™s genius.</p><p>Thereâ€™s an overlap here with another bias that you may be familiar with. Survivorship Bias.</p><p>Survivorship Bias is a cognitive error that occurs when a successful subgroup is mistaken as an <em>entire</em> group due to the visibility of the successful group and the invisibility of the unsuccessful group (<a href="https://fs.blog/2020/10/sharks-survivorship-bias/" target="_blank">link here to illustrate</a>).</p><p>As it applies here, most of the ideas we consume come from experts. This is because theyâ€™ve already defeated the gatekeeper and have been elevated to the point where their thoughts matter more than others. Theyâ€™re the successful survivors.</p><p>So whatâ€™s the difference between my idea of Peer Assessment Bias and good old Survivorship Bias? And how do they overlap?</p><p>Survivorship Bias is a layer of Peer Assessment Bias, but theyâ€™re not the same.</p><p>Survivorship Bias, as it relates to assessment, would lead us to believe that the best ideas come from the people who have the largest audiences. We perceive these successful survivors as experts and give more weight to the ideas they produce, even those unrelated to why they became successful in the first place. This doesnâ€™t explain what happens on the peer side of the equation.</p><p>Peer Assessment Bias is about how we perceive those â€œat the same levelâ€ as us, and itâ€™s especially focused on those who are unestablished. â€œExpertsâ€ were once peers and have now moved on to an evolved state. Becoming an expert takes time, and many of the strong ideas that experts share are ideated during the time when they were an unheard of â€œpeer.â€</p><p>Peer Assessment Bias has less to do with the success of the idea and more to do with the source of it. Itâ€™s different because we may very well look a great idea straight in the face and treat it as a commoner instead of as the royalty that it is.</p><h3><strong>PAB Awareness</strong></h3><p>Why does any of this matter?</p><p>Because itâ€™s important to recognize good ideas when you hear them.</p><p>There are two sides to Peer Assessment Bias to be aware of.</p><ol data-rte-list="default"><li><p><strong>Donâ€™t automatically elevate ideas from experts</strong></p></li><li><p><strong>Donâ€™t automatically dismiss ideas from peers</strong></p></li></ol><p>Experts, the people we look up to, are placed on a pedestal. Theyâ€™re given status as infallible.&nbsp;</p><p>This is wrong.</p><p>Yes, the people whoâ€™ve earned their expertise are most likely to keep producing thoughts or content thatâ€™s worth consuming, but never blindly. â€œBecause Musk said it,â€ is not reason enough to accept an idea.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_8762"><div><p>But you know this already, youâ€™re a responsible human. So letâ€™s take a look at the other side of Peer Assessment Bias, the side that doesnâ€™t come naturally.</p><p><strong>Donâ€™t automatically dismiss ideas from peers.</strong></p><p>Pay attention to those around you. They can have ideas that are just as strong as those whoâ€™ve already earned the worldâ€™s attention. Often itâ€™s not perfectly polished, not precisely explained, and never published in the Washington Post, but it could be just as good.</p><p>Allow me to illustrate.</p><p>This is Ayomide:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_10888"><div><p>Sure, heâ€™s a doctor, so heâ€™s a proven smart guy, but the point is that you donâ€™t know him. Ayomide is in my writing community, <a href="https://writersblochq.com/" target="_blank">Writerâ€™s Bloc</a>, and Iâ€™ve had the pleasure of reading some of his work in the draft phase.</p><p>In August, he wrote this essay called â€œ<a href="https://docayomide.com/love/" target="_blank">Love Your Neighbor Doesnâ€™t Mean What We Think</a>.â€ Itâ€™s excellent, you should read it. But to summarize, it comes down to this one sentence:</p><blockquote><p>â€œAct in your neighborâ€™s interest as if it was your own.â€</p></blockquote><p>Thatâ€™s an objectively brilliant way of reframing â€œlove your neighbor as yourself.â€ It may not seem like it, but that little tweak makes things click mentally in a different way than weâ€™re used to.</p><p>Ayomide isnâ€™t an established personality. Heâ€™s not looked upon by thousands as a brilliant mind to be listened to or read each week.</p><p>But he has some fantastic ideas worth reading, and so do your peers.&nbsp;</p><h3><strong>Empower Your Peers</strong></h3><p>The moral of this story is to cut your peers some slack.</p><p>The path to expertise is filled with early days of thoughts sent out into an empty void and then slowly adopted by a group of early fans. Those early fans are peers, and peer fans are the most important fans you can have. A show of support, a reliable voice for feedback, or a bit of help from someone promoting your work is sometimes all you need to keep pushing on to the point where you become an expert.</p><p>Iâ€™m no scientist, but thereâ€™s no doubt weâ€™re harsher critics of our peers than we are of others we donâ€™t know. Does this stem from personal self-doubt (I couldnâ€™t do that, so they couldnâ€™t do it either), a hint of jealousy, or another psychological misplacement? Maybe. But it does happen.</p><p>We have a mental bias to keep peers as peers and experts as experts. This is a bias like any other. One worthy of acknowledging and defeating.</p><p>Cut your peers some slack. Read their work. Promote their content. Champion their ideas. Stand behind them. Encourage their efforts.</p><p>To steal from my peer Ayomide; believe in your peerâ€™s work the same way you believe in your own.</p><p>Now, go forth and lift up your peers.</p></div></div></div>]]>
            </description>
            <link>https://www.ryansmulholland.com/writing/peer-assessment-bias</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943216</guid>
            <pubDate>Fri, 30 Oct 2020 15:25:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACM for Nitro Enclaves â€“ How Secure Are They?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942832">thread link</a>) | @donkersgood
<br/>
October 30, 2020 | https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The new EC2 Nitro Enclaves enable virtual machines to process private data without exposing its encryption key to the parent instance. In this post we will explore how Nitro Enclaves are used to securely process private keys stored in ACM.</p>
<p>This is part 2 in a two-part article. In the first part we review why Nitro Enclaves matter and how they can benefit your sensitive workloads: <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">ACM for Nitro Enclaves - Itâ€™s a Big Deal</a>.</p>
<h3>Overview</h3>
<p>This article follows the steps outlined in AWSâ€™ documentation: <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html">AWS Certificate Manager for Nitro Enclaves</a>. In their article, AWS builds the following architecture.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/4volL2Vsj6GH8kyvLASvYq/ceb73ac4e50f8779794628e56900f2b7/refarch.png?fit=scale&amp;w=1330" alt="ACM Reference Architecture"></p>
<p>As discussed in <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">part 1</a>, itâ€™s essential for private keys stored in ACM to never be exposed. As such, itâ€™s interesting to see how AWS keeps these private keys secure, while still hosting them on your (relatively insecure) EC2 instance. The answer, of course, lies in the new <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">Nitro Enclaves</a>.</p>
<p>The two main topics for this post are:</p>
<ul>
<li>How are private keys transmitted (and can we intercept them)?</li>
<li>How are permissions assigned to the Nitro Enclave (and can we assume them)?</li>
</ul>
<h3>Launching an EC2 instance</h3>
<p>The first step is to launch an Enclave-enabled EC2 instance. From the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave.html#nitro-enclave-reqs">requirements</a> we learn this can be any Nitro instance with an Intel or AMD processor. Further digging shows that the minimum size is an <code>m5a.xlarge</code>.</p>
<p>The operating system needs to be Linux. On Amazon Linux 2 the Nitro CLI is available in a yum repository. Installation instructions for other operating systems can be found on the Nitro Enclaves CLI <a rel="noopener noreferrer" href="https://github.com/aws/aws-nitro-enclaves-cli">Github page</a>.</p>
<p>Amazon has provided ready-to-go AMIs with NginX and the Nitro CLI pre-installed, so for this article we will use those. We will assign an IAM role with admin permissions to the instance so we wonâ€™t be limited in exploring access methods.</p>
<p>With the pre-build AMI deployed in a default VPC and an IAM role with admin permissions, our current architecture looks like this:</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/4HFodRfnVjsleJ2YI6pVgg/66fce88c7b5ea3ba5234ae1bdee35d5e/deployment-1.png?fit=scale&amp;w=1330" alt="Deployment 1"></p>
<h3>Creating an ACM certificate</h3>
<p>ACM certificates are free, but we do need a valid domain name. Iâ€™ve once purchased <code>vpcdemo.net</code>, so thatâ€™s what I will use for this article.</p>
<p>After weâ€™ve moved through the steps of requesting a certificate, it shows as <code>Issued</code> and has an ARN. We will need this ARN in the next step.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5Oxxf6wRYgkMm7QgYxHyq/6933f73ec20c723ed0bd6a790e43b9d9/valid_cert.jpg?fit=scale&amp;w=1330" alt="Valid Certificate"></p>
<h3>Associating the IAM role with the certificate</h3>
<p>This is where it gets interesting. The <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html#role-cert">next step</a> in the process is to â€œAssociate the role with the ACM certificateâ€.</p>
<p>The command to achieve this is <code>aws ec2 --region [region] associate-enclave-certificate-iam-role --certificate-arn [certificate_ARN] --role-arn [role_ARN]</code></p>
<p>This means weâ€™re telling ACM that our EC2 instance role is allowed to access this certificate and private key. But we havenâ€™t created a Nitro Enclave yet, and this role is assigned to an EC2 instance <strong>we</strong> control. Does that mean we will be able to access the private key from our instance? Letâ€™s find out.</p>
<p>Running the command above yields the following output:</p>
<pre><code>aws ec2 --region eu-central-1 associate-enclave-certificate-iam-role --certificate-arn arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 --role-arn arn:aws:iam::123412341234:role/admin-role
{
    "EncryptionKmsKeyId": "cb8e3d89-cd82-4560-867c-641c0008fab2", 
    "CertificateS3BucketName": "aws-ec2-enclave-certificate-eu-central-1-prod", 
    "CertificateS3ObjectKey": "arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103"
}
</code></pre>
<p>This output obviously refers to three things:</p>
<ul>
<li>An S3 bucket (owned by AWS)</li>
<li>An S3 object (that likely contains our certificate and private key)</li>
<li>A KMS key (that is likely used to decrypt sensitive data)</li>
</ul>
<p>In the next step, AWS describes we should assign new permissions to our EC2 instanceâ€™s IAM role:</p>
<pre><code>{
  "Version": "2012-10-17",
  "Statement": [
    {
        "Effect": "Allow",
        "Action": [
            "s3:GetObject"
        ],
        "Resource": ["arn:aws:s3:::aws-ec2-enclave-certificate-eu-central-1-prod/*"]
    },
    {
        "Effect": "Allow",
        "Action": [
            "kms:Decrypt"
        ],
        "Resource": "arn:aws:kms:eu-central-1:*:key/cb8e3d89-cd82-4560-867c-641c0008fab2"
    }
  ]
}
</code></pre>
<p>These permissions allow our role to fetch an object from the AWS-owned S3 bucket, and to use the AWS-owned KMS key to decrypt data. Letâ€™s update our architecture diagram with these new components.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/7MJ5bL64JTG0hyNkvSiMhp/485436f06a14e2c4165a4ec00c940209/deployment-2.png?fit=scale&amp;w=1330" alt="Deployment 2"></p>
<h3>Retrieving the file from S3</h3>
<p>The <code>CertificateS3BucketName</code> and <code>CertificateS3ObjectKey</code> clearly identify where the ACM files are stored. Since our IAM Role now has all the necessary permissions, we can try to download the file.</p>
<pre><code>[ec2-user@ip-172-31-42-108 ~]$ aws s3 cp s3://aws-ec2-enclave-certificate-eu-central-1-prod/arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 .
download: s3://aws-ec2-enclave-certificate-eu-central-1-prod/arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 to ./f2bb1a6e-5704-4702-beb7-a2c3f36e7103
</code></pre>
<p>Lo and behold: it worked! We now have the ACM certificate files on our local machine. The million dollar question is what they contain.</p>
<h3>Analyzing the file contents</h3>
<p>Weâ€™ll output the file and run it through <code>jq</code>:</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/XdI3Sa3jYldy7criKPzHb/7ca202e4e65aaec1061f4400ee683073/file-contents.png?fit=scale&amp;w=1330" alt="File Contents"></p>
<p>The contents are in JSON format, with four keys:</p>
<ul>
<li><code>certificate</code></li>
<li><code>certificateChain</code></li>
<li><code>encryptedPrivateKey</code></li>
<li><code>encryptionMethod</code></li>
</ul>
<p>The first two values are unencrypted, but these are the public certificate files anyone visiting <code>vpcdemo.net</code> would receive. No secrets there.</p>
<p>The third value is the private key weâ€™re looking for. Obviously, itâ€™s been encrypted. However, we also got access to a KMS keyâ€¦ Letâ€™s see if we can use that to decrypt this value!</p>
<h3>Decrypting the private key</h3>
<p>First weâ€™ll store the <code>encryptedPrivateKey</code> in a variable: <code>PRIVKEY=$(cat f2bb1a6e-5704-4702-beb7-a2c3f36e7103 | jq -r '.encryptedPrivateKey')</code>.</p>
<p>Then weâ€™ll run the private key through KMS: <code>aws kms --region eu-central-1 decrypt --ciphertext-blob fileb://&lt;(echo $PRIVKEY | base64 -d) --output text --query Plaintext</code>.</p>
<p>Unfortunately, but expectedly, this results in the following output:</p>
<pre><code>An error occurred (AccessDeniedException) when calling the Decrypt operation: The ciphertext refers to a customer master key that does not exist, does not exist in this region, or you are not allowed to access.
</code></pre>
<p>So this doesnâ€™t work. Letâ€™s find out why. Weâ€™ll start by looking at CloudTrail. It shows an interesting line:</p>
<pre><code>"errorMessage": "User: arn:aws:sts::123412341234:assumed-role/admin-role/i-025be0b6a191a2cde is not authorized to perform: kms:Decrypt on resource: arn:aws:kms:eu-central-1:194321236082:key/cb8e3d89-cd82-4560-867c-641c0008fab2",
</code></pre>
<p>This shows us that the KMS key is stored in account <code>194321236082</code>, and that our role was not allowed to use it. This is interesting, because we did exactly follow AWSâ€™ instructions, which added permissions for our role to use this KMS key. The answer must lie somewhere in the Nitro Enclaves.</p>
<h3>Running NginX with Nitro Enclaves</h3>
<p>After walking through the last few steps in the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html#config-nginx">AWS docs</a> weâ€™ve got a running server with HTTPS:</p>
<pre><code>âžœ  ~ curl -I -XGET https://vpcdemo.net
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Fri, 30 Oct 2020 13:24:26 GMT
Content-Type: text/html
Content-Length: 3520
Last-Modified: Wed, 24 Jun 2020 18:17:11 GMT
Connection: keep-alive
ETag: "5ef398a7-dc0"
Accept-Ranges: bytes
</code></pre>
<p>In the NginX configuration at <code>/etc/pki/nginx/nginx-acm.conf</code> we see the following lines:</p>
<pre><code>ssl_certificate_key "engine:pkcs11:pkcs11:model=p11ne-token;manufacturer=Amazon;token=nginx-acm-token;id=%01;object=acm-key;type=private?pin-value=8c9d293b5fcbe9bc5f70fa400822a936";
ssl_certificate "/run/nitro_enclaves/acm/nginx-cert-6e67696e782d61636d2d746f6b656e.pem";
</code></pre>
<p>So the Nitro Enclave was able to download and decrypt my certificate, even though the parent instance wasnâ€™t. The next question is how AWS has secured their KMS key so the parent instance canâ€™t use it, but the Nitro Enclave using the same IAM Role <em>can</em>.</p>
<h3>Attestation</h3>
<p>The answer can be found in Jeff Barrâ€™s <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">blog post</a> and the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/set-up-attestation.html">Cryptographic attestation</a> chapter in the documentation. When a new enclave image file (the OS and code that runs in the enclave) is created, it will automatically hash its contents in various ways. These are then returned as platform configuration registers (PCRs). There are eight PCRs:</p>
<ul>
<li>PCR[0]: a hash of the enclave image file</li>
<li>PCR[1]: a hash of the Linux kernel and bootstrap</li>
<li>PCR[2]: a hash of the application</li>
<li>PCR[3]: a hash of the IAM role assigned to the parent instance</li>
<li>PCR[4]: a hash of the Instance ID of the parent instance</li>
<li>PCR[8]: a hash of the Enclave image file signing certificate</li>
</ul>
<p>The first one (PCR0) can be used in a KMS condition. From the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/kms/latest/developerguide/policy-conditions.html">KMS docs</a>:</p>
<blockquote>
<p>The kms:RecipientAttestation:ImageSha384 condition key allows the kms-decrypt, kms-generate-data-key, and kms-generate-random operations from an enclave only when the image hash from the signed attestation document in the request matches the value in the condition key. The ImageSha384 value corresponds to PCR[0] in the attestation document. This condition key is effective only when you call these APIs from an enclave using the Nitro Enclaves SDK.</p>
</blockquote>
<p>And from Jeff Barrâ€™s blog post: â€œIn a real-world environment, I would create a KMS key policy that checks the PCR value as part of a Condition statement:â€</p>
<pre><code>"Condition": {
"StringEqualsIgnoreCase": {
 "kms:RecipientAttestation:ImageSha384": "ecfd7aa6d1dcca1e0bba646e7d49ede2761651c68f13cee68b1141c182cd836baae37d05dd8e6260aa847369a7b27e24"
}
</code></pre>
<p>In simple terms: every enclave image has a signature that changes when the content of the enclave image changes. By setting the PCR[0] value at the time the image was built as a condition in KMS, the <code>Decrypt</code> operation will only be allowed when executed by this exact version of the enclave image. When somebody tampers with the image - or tries to use the role from the parent instance as we did above - the PCR0 will change, the KMS condition will no longer match, and access will be denied.</p>
<h3>Conclusion</h3>
<p>In this post we have analyzed the steps AWS â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942832</guid>
            <pubDate>Fri, 30 Oct 2020 14:52:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACM for Nitro Enclaves â€“ It's a Big Deal]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942831">thread link</a>) | @donkersgood
<br/>
October 30, 2020 | https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The new AWS Nitro Enclaves allow EC2 instances to spin up an isolated child VM for cryptographic operations. This unlocks new security features, the first and maybe most important of which is ACM on EC2.</p>
<p>In this post we will explore why Nitro Enclaves are important. Specifically, weâ€™ll discuss why Amazon Certificate Manager (ACM) on EC2 matters. This is part 1 in a two-part article. In the second part - <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">ACM for Nitro Enclaves - How Secure Are They?</a> - we will do a deep dive on the internal mechanisms that make Nitro Enclaves tick.</p>
<h3>A brief introduction to HTTPS</h3>
<p>HTTPS, or HTTP over SSL, encrypts web traffic in transit. This prevents eavesdropping on sensitive information and guarantees that your browser is talking to the right server. To understand ACM, we need a quick overview of the basics of HTTPS. Please note that the details of this process might vary for different versions of SSL, TLS and cypher suites.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/1tLEomZQnmb8bsbzf6IeQM/729a794d26969cdc531622271c8e2b27/handshake.png?fit=scale&amp;w=1330" alt="SSL Handshake"></p>
<p>When a browser connects to a server over HTTPS, it first requests the serverâ€™s public certificate (1). It then verifies if the certificate was signed by a trusted certificate authority (3). This validates that the server is allowed to use this domain name.</p>
<p>Next, the browser generates a new, random key, called the <em>session key</em>. It encrypts this session key with the public key stored in the serverâ€™s certificate. Then it sends the session key back to the server (4).</p>
<p>The server uses the private key it has locally (and privately, hence the name) stored to decrypt the session key (5). It is essential to understand that <em>only</em> this private key can decrypt the session key. If the private key would leak or be stolen, anyone would be able to decrypt traffic destined for this server, or they would be able to impersonate this server.</p>
<p>The server and client use the session key to encrypt all traffic from that moment on, and the communication between browser and server is secured.</p>
<p>For additional context, check out my YouTube session on <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=IUpUIw5zH2g&amp;list=PLeJgtCMvQjZd0kuK82-Et9IYcp6EiOeYa&amp;index=10&amp;ab_channel=SentiaCloud">SSL and Scaling</a>.</p>
<h3>Introducing ACM</h3>
<p>From the introduction to HTTPS it should be clear that the private key is an extremely sensitive piece of data and should be protected at all costs. However, the web server <em>needs</em> access to the private key to decrypt traffic. Classically, this meant that any user or administrator with access to the server might also gain access to the private key and use it to nefarious ends.</p>
<p>This is where Amazon Certificate Manager comes in. ACM allows you to generate and store certificates in a highly secure Amazon environment. Specific trusted services, like Elastic Load Balancers and CloudFront, integrate with ACM and are allowed to retrieve the private keys stored in ACM. They then use these private keys to decrypt your traffic and forward the unencrypted traffic to your EC2 instances. The core feature of ACM is that it will <strong>never</strong> expose your private keys.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/65dW6dIbfPccC4HHz48dUS/1e53a34ad6880bae189ff27e3b08867e/acm-intro.png?fit=scale&amp;w=1330" alt="ACM Intro"></p>
<p>With the traffic to EC2 decrypted, there is no reason to store private keys on the EC2 instances anymore. This reduces the impact of users gaining access to your servers, regardless whether they are malicious or not.</p>
<h3>End-to-end encryption</h3>
<p>The attentive reader will have noticed that this solution does not result in end-to-end encryption. The unencrypted traffic stays within Amazonâ€™s boundaries, but strict industries like finance or healthcare will not appreciate their data being plainly transmitted - inside or outside of Amazonâ€™s virtual walls.</p>
<p>This means that if end-to-end encryption is a requirement, we need to go back to the drawing board. Amazon offers CloudHSM, which can do SSL offloading for EC2 instances in a very secure way, but CloudHSM is very expensive. The cost for a single CloudHSM instance in Ireland is $1.47 per hour. In a highly available setup you need to, at $2.94 per hour, or over $2000,- per month. Strict security requirements obviously come at a cost.</p>
<p>Additionally, CloudHSM does not integrate with ACM, which often means youâ€™re managing your certificates in more than one place.</p>
<h3>The new Nitro Enclaves</h3>
<p>The <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">new Nitro Enclaves</a> change this landscape significantly. You can now have end-to-end encryption without CloudHSM, while keeping your private keys secure.</p>
<p>With Nitro Enclaves, you separate part of your virtual machineâ€™s hardware - for example 1 CPU and 512MB of its memory - to run as an independent virtual machine. This VM runs in full isolation. You canâ€™t access its disk or network, you canâ€™t login to it, you can do hardly anything with it. The only interaction you can have is over a <code>vsock</code> interface that is mounted on your parent instance.</p>
<p>In the second part of this article (<a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">ACM for Nitro Enclaves - How Secure Are They?</a>) we will go into the inner workings of this process. The important details for now are that the Nitro Enclave <em>can</em> access the KMS service through a KMS proxy running on the parent host, and that the Nitro Enclave is cryptographically signed. This means that when the enclave connects to KMS, KMS can verify that the request is coming from a trusted enclave. Because the enclave is isolated, KMS can securely transfer data to the enclave, without any risk of that data being intercepted or retrieved.</p>
<h3>The result for ACM on EC2</h3>
<p>Letâ€™s look at how the Nitro Enclaves enable end-to-end encryption. As discussed before, the essence of ACM is that it will never expose your private keys. Nitro Enclaves, on the other hand, run in full isolation but can securely communicate with KMS. ACM for Nitro Enclaves combines these properties by sending encrypted traffic to the parent EC2 instance, which requests its child Nitro Enclave to decrypt the traffic. The Nitro Enclave securely communicates with ACM to fetch the private key, and all requirements are met.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/79B9BqMV4DUxzpWvYcIFq5/4fa51c30ce67678a905cf69bd8ed234f/enclave-kms-acm.png?fit=scale&amp;w=1330" alt="ACM, KMS, Enclave"></p>
<h3>Technological marvel</h3>
<p>AWS are flexing their technological prowess here - big time. The ACM and KMS part is impressive, but mostly an elaboration on existing technologies. The Nitro Enclaves themselves, however, are taking virtualization to a whole new level. Taking a virtual machine and carving out CPU cores and memory to run <em>another</em> virtual machine in isolation, while the machine is running? Consider my mind blown.</p>
<p>This is the point where we see Amazonâ€™s lead versus their competitors. While other public cloud providers are still building multi-AZ designs and getting their networking backbone in order, AWS has built a foundation that allows them to capitalize on completely new technologies and solutions.</p>
<p>I believe the Nitro architecture is still in its early days, and many more futuristic virtualization features await.</p>
<h3>Caveats</h3>
<p>No solution is perfect, and there are a few things you should know before rushing to implement Nitro Enclaves. First, there is instance sizing. Currently, the smallest supported instance for Nitro Enclaves is an <code>m5a.xlarge</code> with four vCPUs. You will likely split this into two vCPUs for the parent instance and two vCPUs for the enclave. Technically, youâ€™re reserving an <code>m5a.large</code>'s worth of CPU for your enclave. In Ireland, this will cost $0.096 per hour, or about $70,- per instance per month. This is significantly cheaper than CloudHSM, but itâ€™s not free either.</p>
<p>Second, only Linux and NginX currently support ACM for Nitro Enclaves. This means that if youâ€™re running Apache, Tomcat, IIS or another solution for your web servers, you will need to wait for future support.</p>
<h3>Conclusion</h3>
<p>The new Nitro Enclaves unlock new ways to securely process sensitive data. ACM is a first example, but Iâ€™m sure many other implementations will soon be released. This article has explored why being able to process private data on an EC2 instance is a big deal. If you want to learn more about the technical implementation, check out <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">part 2</a> of this article.</p>
<p>I share posts like these and smaller news articles on <a rel="noopener noreferrer" href="https://twitter.com/donkersgood">Twitter</a>, follow me there for regular updates! If you have questions or remarks, or would just like to get in touch, you can also find me on <a rel="noopener noreferrer" href="https://www.linkedin.com/in/donkersgoed/">LinkedIn</a>.</p>
</div></div>]]>
            </description>
            <link>https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942831</guid>
            <pubDate>Fri, 30 Oct 2020 14:52:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The â€œI Suckâ€ Awards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942461">thread link</a>) | @mcrittenden
<br/>
October 30, 2020 | https://critter.blog/2020/10/30/the-i-suck-awards/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/30/the-i-suck-awards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2627">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>One of my favorite team retrospective activities is what I call the â€œI Suckâ€ awards. </p>



<p>Itâ€™s simple. Hereâ€™s the process:</p>



<ul><li>Step 1: Someone kicks it off by saying why they suck at that moment</li><li>Step 2: The rest of the team laughs or empathizes or whatever the situation calls for</li><li>Step 3: Repeat steps 1 and 2 until everyone has said why they suck</li><li>Step 4: Vote on the winner of the â€œI Suckâ€ award, aka the person with the most impressive suckitude that time around. </li></ul>



<p>Everyone sucks for some reason at any given time. Maybe they procrastinated. Maybe they missed an obvious bug. Maybe they keep forgetting to update the sprint board. Maybe they have been talking too much on calls. Maybe they didnâ€™t submit their dang timesheet. Whatever it is, everyone has one.</p>



<p>There are a few reasons why I love this activity:</p>



<ul><li>Itâ€™s fun and often hilarious</li><li>It discourages <a href="https://en.wikipedia.org/wiki/Cover_your_ass">Cover Your Ass (CYA)</a> Engineering</li><li>It gives people a chance to drop some tips for next time</li><li>Itâ€™s great for <a href="https://critter.blog/2016/10/27/the-whys-and-hows-of-jelling-teams/">team jelling</a> </li><li>It lets us learn from each otherâ€™s mistakes</li><li>It reduces the sense of <a href="https://critter.blog/2020/10/26/you-cant-fail-at-experiments/">shame that accompanies messing up</a></li></ul>



<p>I stole the idea from Radical Candor, which calls it the â€œ<a href="https://www.radicalcandor.com/encourage-feedback/#:~:text=Introduce%20Whoops-a-Daisy">Whoops-A-Daisy</a>â€œ. </p>



<p>Itâ€™s powerful and itâ€™s fun, so give it a shot! Why do you suck?</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/30/the-i-suck-awards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942461</guid>
            <pubDate>Fri, 30 Oct 2020 14:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golang game engine v2 released]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24942250">thread link</a>) | @nargella
<br/>
October 30, 2020 | https://ebiten.org/blog/v2.0.0.html | <a href="https://web.archive.org/web/*/https://ebiten.org/blog/v2.0.0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p lang="en">We are very happy to announce the release of v2.0.0 (<a href="https://ebiten.org/documents/2.0.html">Release Note</a>).</p>
    <p lang="ja">v2.0.0 ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸ! è©³ã—ãã¯<a href="https://ebiten.org/documents/2.0.html">ãƒªãƒªãƒ¼ã‚¹ãƒŽãƒ¼ãƒˆ</a>ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>
    <p lang="en">I appreciate all the contributors and <a href="https://github.com/sponsors/hajimehoshi">all the sponsors</a>. Thank you very much!</p>
    <p lang="ja">ã™ã¹ã¦ã®ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼ã¨<a href="https://github.com/sponsors/hajimehoshi">ã‚¹ãƒãƒ³ã‚µãƒ¼ã®çš†æ§˜</a>ã«æ„Ÿè¬ã„ãŸã—ã¾ã™ã€‚ã©ã†ã‚‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™!</p>
    <p lang="en">v2.0 doesn't have any new features. The features are same as v1.12. As there are breaking changes in the API, please refer <a href="https://ebiten.org/documents/to_v2.html">Ebiten 2.0 migration guide</a> for the details.</p>
    <p lang="ja">v2.0 ã«ã¯æ–°æ©Ÿèƒ½ãŒä¸€åˆ‡ã‚ã‚Šã¾ã›ã‚“ã€‚æ©Ÿèƒ½çš„ã«ã¯ v1.12 ã¨åŒç­‰ã§ã™ã€‚ API ã®ç ´å£Šçš„å¤‰æ›´ãŒã‚ã‚Šã¾ã™ã®ã§ã€è©³ã—ãã¯ã€Œ<a href="https://ebiten.org/documents/to_v2.html">Ebiten 2.0 ç§»è¡Œã‚¬ã‚¤ãƒ‰</a>ã€ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>
    <p lang="en">The master branch has already been v2.1. Only bug fixes will be merged to v2.0 and v1.12. We plan to release v2.1.0 in March 2021. After releasing v2.1.0, v1.12 will no longer be maintained.</p>
    <p lang="ja">master ãƒ–ãƒ©ãƒ³ãƒã¯ã™ã§ã« v2.1 ã¨ãªã£ã¦ã„ã¾ã™ã€‚ v2.0 ã¨ v1.12 ã¯ä»Šå¾Œãƒã‚°ä¿®æ­£ã®ã¿ãŒå…¥ã‚Šã¾ã™ã€‚ v2.1.0 ã®ãƒªãƒªãƒ¼ã‚¹ã¯ 2021 å¹´ 3 æœˆé ƒã®äºˆå®šã§ã™ã€‚ v2.1.0 ã®ãƒªãƒªãƒ¼ã‚¹å¾Œã€ v1.12 ã¯ãƒ¡ãƒ³ãƒ†ã•ã‚Œãªããªã‚‹äºˆå®šã§ã™ã€‚</p>
    <p lang="en">Enjoy!</p>
  </div></div>]]>
            </description>
            <link>https://ebiten.org/blog/v2.0.0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942250</guid>
            <pubDate>Fri, 30 Oct 2020 14:01:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dish-o-tron â€“ an ironic (hopefully) fun deep learning tutorial]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24942115">thread link</a>) | @mamikl
<br/>
October 30, 2020 | https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/ | <a href="https://web.archive.org/web/*/https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Sadly, to tell you the truth, doing dishes is still a thing. However, so far most of our readers still like our non-standard Deep Learning tutorial.</em></p><p>Typically, AI is demonstrated as solving various toy problems. AI plays chess and Go, AI plays video games, AI makes people dance. It is time to stop this madness and finally apply AI in a meaningful way. Therefore, we proudly present the dish-o-tron. The dish-o-tron is an AI system designed to solve an actual real-world problem impacting millions of people around the world every day: facing dirty dishes in the community kitchen sink.</p><div id="attachment_77683"><p><a href="https://blog.codecentric.de/files/2020/09/real_world_problem.png"><img aria-describedby="caption-attachment-77683" loading="lazy" src="https://blog.codecentric.de/files/2020/09/real_world_problem-250x107.png" alt="dirty dishes in the community kitchen sink" width="250" height="107" srcset="https://blog.codecentric.de/files/2020/09/real_world_problem-250x107.png 250w, https://blog.codecentric.de/files/2020/09/real_world_problem-700x300.png 700w, https://blog.codecentric.de/files/2020/09/real_world_problem-768x329.png 768w, https://blog.codecentric.de/files/2020/09/real_world_problem-1536x659.png 1536w, https://blog.codecentric.de/files/2020/09/real_world_problem-120x51.png 120w, https://blog.codecentric.de/files/2020/09/real_world_problem.png 1600w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77683">dirty dishes in the community kitchen sink â€“ a real-world problem</p></div><p>Reading this blog series will equip you with the ultimate power to solve this long-lasting problem in your community kitchen once and for all by using state-of-the-art AI technology.</p><h2>The dish-o-tron</h2><p>At first glance, the dish-o-tron is an inconspicuous, well-positioned webcam in the kitchen observing the shared kitchen sink. In its natural state the dish-o-tron is just happy and enjoys life. The dish-o-tron doesnâ€™t care whether you prefer tea or coffee and it likes all kinds of kitchen talk. However, there is one single thing that the dish-o-tron absolutely hates: watching someone put dirty dishes in the community sink.</p><p>Detecting dirty dishes in the sink enrages the peace-loving dish-o-tron so much that it starts beeping. The only way to return it to its natural peaceful state and thus stopping the noise is to admit oneâ€™s mistake and remove all dirty dishes from the community sink, leaving it neat and clean again.</p><div id="attachment_78576"><p><a href="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen.png"><img aria-describedby="caption-attachment-78576" loading="lazy" src="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-250x166.png" alt="respect privacy in the kitchen" width="250" height="166" srcset="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-250x166.png 250w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-700x465.png 700w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-768x510.png 768w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-1536x1020.png 1536w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-120x80.png 120w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen.png 1984w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-78576">privacy in the kitchen has to be respected.</p></div><p>Building the dish-o-tron requires three high-level steps:</p><ul><li>Gathering and preparing data</li><li>Training an AI model</li><li>Deployment of the model</li></ul><p>In the following, we will discuss these steps further.</p><h2>Gathering and preparing data</h2><p>Trying to solve real-world problems with AI often starts with the realisation that there is little or even no data available. This issue prevents many problem solvers from actually solving the problem. â€œIf only data collection had started years ago!â€, they say, â€œthen we could now actually solve the problemâ€. While this is a reasonable thought, it simply doesnâ€™t help.</p><p>Consoling users currently facing a problem by saying that it is necessary to gather lots of data for quite some time before we can start building a solution is at least challenging. Typically a more promising approach is to build a system addressing the problem which is able to improve over time.</p><p>In this way, we will not solve the problem completely in the first step; however, we will tackle the problem right away and put ourselves in a position to iteratively adjust the solution to match the requirements which also become more and more clear while working on the problem.</p><p>Since our problem is unique in a sense that there is no Kaggle dataset readily available, we start our journey to building the dish-o-tron by doing our best to collect a suitable dataset for a first working system. Here, we will make videos of various kitchen sinks clean and not clean and split them up into a first labeled dataset.</p><p>In this way, we started collecting the DIRTY-DISHES-DATASET with thousands of pictures that we will share with you in the next article.</p><div id="attachment_77687"><p><a href="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset.png"><img aria-describedby="caption-attachment-77687" loading="lazy" src="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-250x151.png" alt="sample images from the dirty-dishes dataset" width="250" height="151" srcset="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-250x151.png 250w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-700x424.png 700w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-768x465.png 768w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-120x73.png 120w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset.png 1004w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77687">sample images from the dirty-dishes dataset</p></div><h2>Training an AI model</h2><p>Not so long ago, training an AI model was tedious and required expert knowledge. In many cases this is still true today. Depending on the problem, we have to figure out a suitable model architecture and feature engineering and this requires some experimentation before we can train a suitable AI model. This is another issue which prevents problem solvers from building a solution tackling the whole problem even if data is available.</p><p>Fortunately, image classification is one of the best understood use cases in AI. There are lots of established best practices regarding model architectures and training of models. Among others this led to two things:</p><ul><li>High-level software libraries such as fast.ai which abstract away lots of the nitty-gritty details of image classification, providing a black-box kind of approach where state-of-the-art practises are simply utilised without burdening the user with the details.</li><li>Machine Learning as a service offerings from various public cloud providers such as automl and rekognition allowing training of image classification models on custom data in a few simple steps.</li></ul><p>Both approaches will typically not lead to the absolutely best solution. However, most of the time this is not necessary and â€˜good enoughâ€™ will be just fine and a nice trade-off between time &amp; money spent vs. result. For our first version of the dish-o-tron, we will employ the <a href="https://cloud.google.com/automl" target="_blank" rel="noopener noreferrer">AutoML Service</a> from Google Cloud to train a first model.</p><p>We can use various tools to inspect the model and try to explain if the black box learns what we expect.</p><div id="attachment_77689"><p><a href="https://blog.codecentric.de/files/2020/09/explain_model.png"><img aria-describedby="caption-attachment-77689" loading="lazy" src="https://blog.codecentric.de/files/2020/09/explain_model-250x191.png" alt="visualizing what the dish-o-tron model has actually learned" width="250" height="191" srcset="https://blog.codecentric.de/files/2020/09/explain_model-250x191.png 250w, https://blog.codecentric.de/files/2020/09/explain_model-700x535.png 700w, https://blog.codecentric.de/files/2020/09/explain_model-768x587.png 768w, https://blog.codecentric.de/files/2020/09/explain_model-120x92.png 120w, https://blog.codecentric.de/files/2020/09/explain_model.png 1412w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77689">Visualizing what the model has actually learned.</p></div><p>The training of the AI model with AutoML and its technical details will be discussed in a follow-up blog post.</p><h2>Deployment of the model</h2><p>Having an AI model generally will not solve an actual real-life problem. For a viable solution, the AI model has to be integrated into a suitable context. Many times, this is the key step to generating any value at all. Nevertheless, this step is often postponed to the distant future after â€œcollecting high quality dataâ€ and â€œbuilding the best AI modelâ€. This is, more often than not, a mistake because integrating the model into its context poses various challenges on its own. Hence, it should not be ignored and instead tackled early in order to learn and identify the associated challenges.</p><p>While building the dish-o-tron, we tried multiple options to run the model. We deployed it on a Pi Zero which is a really small and cheap device that can be glued anywhere with a small powerbank. But it is rather slow. We ran the model in the browser using our notebookâ€™s webcam with TensorFlow.js. We used the Google AIY Kit, which is much faster than the Pi Zero and also comes with a beeper and blinking lights (but it is quite old and deploying state-of-the-art models is hacky). Finally, we used the Google Coral device, which is made for this kind of workload and well-integrated into Google AutoML but comes with a price tag.</p><p>The community kitchen is a special place. Itâ€™s a place where rumors are born, where gossip is produced and where you can openly chat about the most secret secrets of your company! Thatâ€™s why dish-o-tron is living on the edge. Edge devices enable you to run audio and video analytics AND respect the privacy of your community kitchen. No image is transferred to the cloud. Nothing is saved. Dish-o-tron sees and forgets.</p><div id="attachment_77691"><p><a href="https://blog.codecentric.de/files/2020/09/various_edge_devices.png"><img aria-describedby="caption-attachment-77691" loading="lazy" src="https://blog.codecentric.de/files/2020/09/various_edge_devices-250x85.png" alt="various edge devices" width="250" height="85" srcset="https://blog.codecentric.de/files/2020/09/various_edge_devices-250x85.png 250w, https://blog.codecentric.de/files/2020/09/various_edge_devices-700x237.png 700w, https://blog.codecentric.de/files/2020/09/various_edge_devices-768x261.png 768w, https://blog.codecentric.de/files/2020/09/various_edge_devices-1536x521.png 1536w, https://blog.codecentric.de/files/2020/09/various_edge_devices-2048x695.png 2048w, https://blog.codecentric.de/files/2020/09/various_edge_devices-120x41.png 120w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77691">Various edge devices</p></div><p>Moreover, the hardware we consider and buy in order to actually build the dish-o-tron will establish basic conditions for our solution space. In other words, we have to mind that it is possible to painlessly deploy the AI model on our preferred edge device. For the first version of the dish-o-tron, we decided to use a Google AIY kit (see video below). For the next version, we chose a Google Coral edge device, which allows us to run advanced computer vision tasks on a Raspberry-size mini computer. Fortunately, AutoML allows us to export models in a viable format.</p><div id="attachment_77693"><p><a href="https://blog.codecentric.de/files/2020/09/google_coral_device.png"><img aria-describedby="caption-attachment-77693" loading="lazy" src="https://blog.codecentric.de/files/2020/09/google_coral_device-250x131.png" alt="Google coral device" width="250" height="131" srcset="https://blog.codecentric.de/files/2020/09/google_coral_device-250x131.png 250w, https://blog.codecentric.de/files/2020/09/google_coral_device-700x366.png 700w, https://blog.codecentric.de/files/2020/09/google_coral_device-768x401.png 768w, https://blog.codecentric.de/files/2020/09/google_coral_device-1536x803.png 1536w, https://blog.codecentric.de/files/2020/09/google_coral_device-120x63.png 120w, https://blog.codecentric.de/files/2020/09/google_coral_device.png 1600w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77693">Google coral device</p></div><p>The construction of the dish-o-tron including the deployment of the model on the Coral device and its technical details will be discussed in an upcoming blog post.</p><h2>Conclusion</h2><p>AI research has brought us new technology that can solve problems that couldnâ€™t be solved before. Have you read the book <em>AI superpowers</em> by Kai-Fu Lee? He says that you donâ€™t need to be one of the best AI researchers any more to apply AI and find new business opportunities. You need to collect (lots of) data and can â€œjustâ€ use existing algorithms, services and open source frameworks. Well, in our opinion building AI solutions is not easy â€“ but it is indeed getting easier and easier every day.</p><p>See the first prototype running on the google AIY kit here (mind the green/red LED at the box):</p><p>Follow this blog series if you want to know how to build and run such a model on an edge device yourself. Building the dish-o-tron will fundamentally change the way you experience the community kitchen. Instead of being a place of constant anger and hostility, the community kitchen will become a peaceful meeting ground for sharing ideas and connecting with co-workers.</p><p>In the upcoming blog posts, we will guide you through the process of building your own dish-o-tron for your community kitchen sink. Hence, we will tackle a real-world problem and playfully learn how to build and improve an AI system from scratch. Stay tuned!</p><p>Continue with the <a href="https://blog.codecentric.de/en/2020/09/dish-o-tron-gather-that-data-you-must/">the second part of our series</a> where we start with gathering data.</p></div></div>]]>
            </description>
            <link>https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942115</guid>
            <pubDate>Fri, 30 Oct 2020 13:46:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brazil will launch its first nationwide digital instant-payment system]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942060">thread link</a>) | @imartin2k
<br/>
October 30, 2020 | https://restofworld.org/2020/cash-debit-or-pix/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cash-debit-or-pix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Next month, Brazil will launch its first nationwide digital instant-payment system. On November 16, Pix will go live on banking apps, digital wallets, and other services throughout Latin Americaâ€™s largest financial market.&nbsp;</p>



<p>Pix was created by Brazilâ€™s <a href="https://content.next.westlaw.com/w-006-8837?transitionType=Default&amp;contextData=(sc.Default)&amp;__lrTS=20191105091102789&amp;firstPage=true">Central Bank</a>, which has the power of life and death over all Brazilian financial institutions. The system is virtually free to use, a novelty in a country with a very efficient but expensive banking system.</p>



<p>Although it will be mandatory only for the largest banks, Pix will be available for all Brazilians whose bank or credit union opts in. Already, people are embracing the new system; on the first registration day ahead of launch, <a href="https://neofeed.com.br/blog/home/no-pix-uma-lista-e-a-chave-da-discordia-entre-bancos-e-fintechs/">millions of users</a> signed up for the service.&nbsp;</p>



<p>But not everyone is so enthusiastic. Pixâ€™s simplicity and low cost will eat into the revenue streams of big banks, which typically charge users for fast transfers. It also complicates the business models of some of Brazilâ€™s most successful startups. And by combining these features with a countrywide mandate, Pix might finally accomplish something that up until a few years ago was unthinkable: killing cash transactions in Brazil.</p>



<h3><strong>Why did the Brazilian Central Bank create Pix?</strong></h3>



<p>Pix has been in the works<a href="https://www.bcb.gov.br/estabilidadefinanceira/gtpaginst_reunioes"> since mid-2018</a>. Back then, there were a few instant-payment systems available in Brazil. Yet those that did exist were either limited to a specific bankâ€™s clientele or had been launched by startups.&nbsp;</p>



<div><p>â€œWe had been signaling the need for instant payments to the market since 2013,â€ said Mayara Yano, an analyst at the Central Bank. But, according to Yano, there were too many barriers and not enough incentives for a private company to create a service to be adopted by the banking system as a whole.</p><p>With Pix, the Central Bank also means to restrain the use of paper money, still popular in everyday life. Itâ€™s typical of mom and pop shops to offer 5% to 10% discounts for cash payments to avoid card-processing fees, for example.</p></div>



<p>Limiting paper currency with Pix would help the Central Bank with two other problems: limit its expenses with producing and distributing bills and coins, and boost the governmentâ€™s investigations of financial fraud, <a href="https://www.bloomberg.com/news/articles/2020-10-07/bolsonaro-declares-brazil-corruption-free-and-ends-carwash-probe">a hot-button issue in Brazil</a>. After all, cash transactions are almost impossible to track, but Pix payments will be all saved in their usersâ€™ banking apps.<br></p>



<p>Pix isnâ€™t the first government-imposed payment mandate in Brazilâ€™s history. In 2002, the Central Bank created a money transfer mechanism that took less than one hour on weekdays and would be completed by the next working day on weekends and holidays. The mechanism, called TED, was mandatory for all banks.</p>



<p><br>Pix, of course, isnâ€™t mandatory for everybody. But it may as well be, since it is mandatory for banks with more than 500,000 clients; the group comprises 34 banks, which serve 90% of the <a href="https://www1.folha.uol.com.br/mercado/2020/10/pandemia-leva-a-bancarizacao-de-quase-10-milhoes-de-pessoas.shtml">175.4 million Brazilians who own bank accounts</a>. It is optional for smaller banks, fintech startups, credit unions, and other financial service providers.</p>



<h3><strong>How will it work?</strong></h3>



<div><p>Pix relies on identifiers like QR codes, email addresses, and telephone numbers to perform money transfers in up to 10 seconds, including on weekends and holidays. It will be incorporated into banking and payment apps, digital wallets, and other kinds of financial services. Once available, Pix will provide an alternative to existing fast money transfers, which cost an average of 10 Brazilian reais each in fees ($2).</p><p>The system functions virtually for free<strong>; </strong>the Central Bank charges financial institutions just 1 Brazilian centavo ($0.0018) for every 10 Pix transactions, and itâ€™s up to them if they will pass along that cost to their clients.</p><p>To sign up, a user must submit up to five pieces of personal information, such as an email address, a cell phone number, or a tax ID, that will be used as a â€œPix keyâ€ to identify them in a money transfer. Users will also be given a QR code, which can be used to send or receive payments. If they have a bank account, they can use their checking account information to process a Pix transaction, much like a traditional bank transfer.</p></div>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-40x79.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-400x786.jpg 400w, https://restofworld.org/wp-content/uploads/2020/10/pix-registry3-600x1180.jpg 600w, " sizes="300px" alt="During the sign-up, users need to enroll a key (" chaves="" pix")="" consisting="" of="" a="" piece="" personal="" information."="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<h3><strong>How will Pix affect Brazilian banks and fintech startups?</strong></h3>



<p>The government hasnâ€™t disclosed any studies of how Pix could impact Brazilâ€™s economy. But itâ€™s clear that the new technology will hit big banks the hardest, as well as big-name payment intermediaries, like point-of-sale and card-machine operators Cielo and Rede. German consulting group Roland Berger forecasts that the latter could lose up to <a href="https://valorinveste.globo.com/mercados/renda-variavel/empresas/noticia/2020/07/03/pix-tira-ate-r-13-bi-de-credenciadoras.ghtml"></a><a href="https://valorinveste.globo.com/mercados/renda-variavel/empresas/noticia/2020/07/03/pix-tira-ate-r-13-bi-de-credenciadoras.ghtml">13 billion reais</a> ($2.6 billion).&nbsp;</p>



<p>Pix also threatens what has been a lucrative revenue stream for Brazilâ€™s â€œBig Fiveâ€ banks â€” ItaÃº, Bradesco, Santander, Banco do Brasil, and Caixa EconÃ´mica Federal â€” which collectively make 2.2 billion reais ($440 million) a year from fees for same-day money transfers.</p>







<p>But a potential loss in transfer revenues isnâ€™t the only danger to the Big Five. Now that theyâ€™re on the same footing when it comes to transfer fees, they risk losing clients to digital wallets and online-only banks. As of 2019, more than <a href="https://www.bcb.gov.br/content/publicacoes/relatorioeconomiabancaria/REB_2019.pdf">80% of Brazilâ€™s total credit operations</a>, valued at 2.90 trillion reais ($580 billion), were concentrated in the Big Five. â€œPix will challenge the entire market to provide quality digital services at lower prices,â€ said ClÃ¡udio GuimarÃ£es JÃºnior, executive director of the Brazilian Association of Banks.&nbsp;</p>



<p>Traditional banks such as ItaÃº e Bradesco<a href="https://einvestidor.estadao.com.br/ultimas-noticias/itau-e-do-bradesco-chamam-atencao-para-seguranca-e-defendem-pix"> have voiced concerns</a> about the systemâ€™s security and complained that the launch date is too early. â€œ[Battling Pix] is like trying to stop the wind with your hands,â€ said JoÃ£o BraganÃ§a, specialist in payment methods at Roland Berger.&nbsp;</p>



<div><p>But the effects of Pix could cut both ways. Established digital payment startups like <a href="https://labsnews.com/en/news/business/brazilian-instant-payment-pix-will-allow-withdrawals-in-retail-stores/">PicPay</a>, with its 20 million active users, and <a href="https://www.nasdaq.com/articles/brazils-pagseguro-digital-raises-23-billion-ipo-stock-jumps-2018-01-24">PagSeguro</a>, which raised about 13.2 billion reais ($2.3 billion) during its initial public offering on Nasdaq, may be in trouble. One of their services is instant digital payments, something Pix will provide universally and for free.</p><p>But whether youâ€™re a big bank or a small fintech firm, thereâ€™s no fighting the Central Bank. The Brazilian government will also allow big retailers to adopt Pix as a payment option, often with cashback offers, a novelty in Brazil. In order to compete, PicPay and other digital-payment companies will need to diversify their services.&nbsp;</p></div>






		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-40x20.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-400x200.png 400w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-600x299.png 600w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-1000x499.png 1000w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-1600x798.png 1600w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-2800x1397.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="The system will mitigate cost for end-users and charge 0.001 reais per transaction from the banks and fintech.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://www.bcb.gov.br/estabilidadefinanceira/negociopix" target="_blank" rel="noopener noreferrer">https://www.bcb.gov.br</a></span>
			</figcaption>
		</figure>


<h3><strong>What will change for Brazilians?</strong></h3>



<p>Even with Brazilians being as fond of cash as they are now, financial experts are expecting Pix to gain a stranglehold on non-cash payments and money transfers within the next few years. An analysis by Accenture anticipates some <a href="https://labsnews.com/en/articles/technology/brazils-instant-payments-system-can-reach-20-million-users-in-its-first-year/">48 billion reais</a> ($9.6 billion) to move through the Pix system by the end of its first year.&nbsp;</p>



<p>The study predicts that Pix will achieve mass adoption (i.e., be used for 25% of all household payments) within five years and move between 1 trillion reais ($200 billion) and 1.5 trillion reais ($300 billion) per year. Thatâ€™s close to 20% of Brazilâ€™s current GDP of 7.3 trillion reais ($1.46 trillion). â€œThe Brazilian card industry, both debit and credit, moved 1.8 trillion reais ($360 billion) in 2019. So Pix can have practically that same size in 2025,â€ said Ricardo Pandur, payment specialist at Accenture.</p>



<p>But it remains to be seen who exactly will turn to Pix. The Central Bank is betting on its appeal to the <a href="https://www1.folha.uol.com.br/mercado/2020/10/pandemia-leva-a-bancarizacao-de-quase-10-milhoes-de-pessoas.shtml">36 million Brazilians</a> with no bank accounts. For them, Pix could serve as an entry point to financial services.</p>


<div>

<div>

<div>
<table>
<tbody>
<tr><td>Name:</td><td>Pix</td></tr>
<tr><td>Owner:</td><td>Brazilâ€™s Central Bank</td></tr>
<tr><td>Start date:</td><td>November 16, 2020</td></tr>
<tr><td>Number of users expected by the end of first year:</td><td>30 million</td></tr>
<tr><td>Total payments processed (forecast):</td><td>$200 billion (R$1 trillion) by the end of 2025
</td></tr>
<tr><td>*Source:</td><td>Accenture</td></tr>
</tbody></table>
</div>
</div>
</div>


<div><p>For consumers, Pix will be an alternative to cash and debit cards, a cheap, fast method of money transfer, and even an easy way to pay taxes. For retailers, Pix will be cheaper than card operators, with potentially zero cost to them or their customers.</p><p>But access to Pix is conditional on access to a smartphone or a computer as well as a stable data connection. Even with increased connectivity and phone use, <a href="https://www.pewresearch.org/global/wp-content/uploads/sites/2/2019/02/Pew-Research-Center_Global-Technology-Use-2018_2019-02-05.pdf">40% of all Brazilian adults</a> still donâ€™t have a smartphone. Potential users might have trouble understanding the system of personal keys and QR codes. â€œUnderstanding a payment mechanism is not as simple as learning to use social media,â€ said Ricardo Rocha, a professor of finance at Insper in SÃ£o Paulo.</p></div>



<div><p>With new technology comes new vulnerabilities to scams and phishing attempts. Pix will be incorporated into banksâ€™ native apps and websites and have the added benefit of encrypted transactions. But it will be up to the same banks to explain the risks while pushing for widespread adoption.</p><p>Some startups might have been pushing for adoption a little too far.&nbsp;Clients of online banks <a href="https://restofworld.org/2020/david-velez-nubank/">Nubank</a> and C6 and digital wallets PagSeguro and MercadoPago took to social media to complain that the companies registered their keys <a href="https://g1.globo.com/economia/noticia/2020/10/19/procon-notifica-nubank-e-mercado-pago-sobre-cadastramento-de-chaves-no-pix.ghtml">without their explicit consent</a>. The Central Bank started a <a href="https://exame.com/seu-dinheiro/bc-investiga-denuncia-de-cadastramento-indevido-das-chaves-do-pix/">formal investigation</a> and Brazilâ€™s primary consumer defense entity <a href="https://g1.globo.com/economia/noticia/2020/10/19/procon-notifica-nubank-e-mercado-pago-sobre-cadastramento-de-chaves-no-pix.ghtml">questioned</a> their methods, but the corporations claimed they followed all guidelines and that their clients were notified via apps.</p></div>



<p>Even so, the future of Pix looks promising. Between October 5, when the Central Bank started to allow users to enroll their Pix keys ahead of the November launch date, and October 22, there have been 50 million enrollments. On the first day alone, 3.5 million keys entered the system, and the demand was so high that many banking apps crashed.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cash-debit-or-pix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942060</guid>
            <pubDate>Fri, 30 Oct 2020 13:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mobile Apps for US-Based Electronic Health Record Software Provider]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942018">thread link</a>) | @_Tata_
<br/>
October 30, 2020 | https://www.ego-cms.com/centralreach | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/centralreach">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>The process</h2><p>The first thing to consider when developing a healthcare app is <a href="https://www.hhs.gov/sites/default/files/ocr/privacy/hipaa/administrative/securityrule/techsafeguards.pdf" rel="nofollow" target="_blank"><span><strong>compliance with HIPAA security standards</strong></span></a><span>.</span> With our background in creating medical apps, we know how to combine HIPAA compliance, an emotional UI, and a smart UX into a handy app.</p></div><p>To make the development process more efficient, we used the <a href="https://visualstudio.microsoft.com/ru/xamarin/?rr=https%3A%2F%2Fmy.readymag.com%2Fedit%2F889974%2Fpreview%2F5%2F" rel="nofollow" target="_blank">Xamarin</a> cross-platform framework. Xamarin lets us deliver apps on two platforms quickly and cost-effectively.</p><p>We collaborated closely with CentralReachâ€™s Lead Server Engineer and their web development team to convert tasks into designs and code. As a result, we developed iOS and Android apps that perfectly integrate with the CentralReach web application.</p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team.png" sizes="(max-width: 767px) 88vw, (max-width: 991px) 94vw, 100vw" srcset="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team-p-500.png 500w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team-p-800.png 800w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team.png 1024w" alt=""></p><p>Our PM during a meeting with the CentralReach Team</p></div><div><p>We decided to start the design process with defining and building a core app structure and navigation. This strategy helped us create the appâ€™s logic.</p></div></div></div><div><div><div><div><div><div data-w-id="7722f573-02ad-1641-54fe-1d32747c43e3"><div><p><strong><em>The application supports the fingerprint authentication feature for both iOS and Android</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>In-app navigation represented with the simple side drawer.</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>We integrated Google Maps for Android and Apple Maps for iOS devices to implement a route guidance feature.</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>In addition to being HIPAA-compliant, client data is further protected by a lockscreen feature. Users may also log out via lockscreen, in case the app is being used by several specialists within one organization</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>Modal View with different file options</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>To prevent the app from â€œhoggingâ€ all the memory on a device, services providers can decide for themselves how much space the app will use to store files and can control the storage level, conveniently in the app settings</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div></div></div></div></div></div></div><div><div><h2><strong>Wireframes</strong></h2><p>We started with sketches on paper. After discussing a lot of different concepts, we came up with high fidelity wireframes.</p></div></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dcf12b4a76d20253a856f_6_messags_wf.png" alt=""></p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd2c5358ee938831cce18_6_new_message_wf.png" alt=""></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567232"><p><em>Everything you need is in your hands. Track, manage, and plan your day with scheduling functionality.</em></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd991b1d7895fc14f0da6_6_dashboard_wf.png" alt=""></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567238"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d30888f26763453d6ea2924_6_notes_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d3089bcc13cb6741a4bdf8f_6_add_lable_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf456723d"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308a84be811898d72d5438_6_map_wf.png" alt=""></p><p><strong><em>Service providers can easily get driving directions to their session locations.</em></strong></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567244"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308c3ec13cb6e62d4bec08_6_pin_code_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308d392676347329ea3e44_6_chat_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567249"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308dcb85ef61da385eb0bc_6_signature_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308eacc13cb6004a4bf8ab_6_settings_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf456724e"><p><em>Simple login that supports fingerprint authentication.</em></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308f57c13cb6f0c04bfd11_6_signin_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d3090a9b0d1302b2de24127_6_menu_wf.png" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d309144267634838cea5498_6_edit_location_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567258"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd2c5358ee938831cce18_6_new_message_wf.png" alt=""></p></div></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dc69bb78ea802a0854413_phone.png" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dc69bb4a76db0ce3a5a81_6_app_animation_in_phone.gif" alt=""></p></div></div></div></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2.jpg" sizes="(max-width: 1800px) 100vw, 1800px" srcset="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2-p-1600.jpeg 1600w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2.jpg 1800w" alt=""></p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c1474313d9a85005a91aa_9_pin_code.png" alt=""><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c1474e11fbe43926197e1_9_signature.png" alt=""><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c14747ec3662314bea542_9_lable.png" alt=""></p><div><div><h2><strong>Functionality</strong></h2><p>The CentralReach platform has a wide range of features, but we identified just three core features to include in the first version of the mobile app. This let us get initial user feedback before developing the remaining features. Weâ€™ve already implemented scheduling and messaging, and weâ€™re planning to develop the file management system in the next iteration.</p></div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d668a6bb072640aafc73144_Scheduling2.gif" alt=""></p><div data-w-id="d1f156ec-c5b8-93ad-fbf7-bd55568c57f3"><h2><strong>Scheduling</strong></h2><p>With the <strong>scheduling feature,</strong> service providers can organize their schedules from anywhere at any time using the built-in calendar.</p><p>Intuitive navigation allows service providers to easily access their scheduled appointments, see appointment details, change the date and time of appointments, and subsequently communicate those changes to clients. This ensures that clients and services providers are kept in sync in real-time through the app.</p></div></div></div><p>Each appointment is available on the home screen, allowing service providers and clients to easily view essential information including:</p><div><div data-w-id="062a8657-b820-edff-b4c7-9b7aa16f24db"><h2><strong>Messaging</strong></h2><p>To make conversations between service providers and clients easier and more convenient, we integrated secure real-time in-app messaging thatâ€™s <strong>HIPAA-compliant.</strong></p><p>At CentralReachâ€™s request, we implemented an in-app messaging system using <a href="https://quickblox.com/" target="_blank"><strong>Quickblox</strong></a><strong>,</strong> which provided us with the infrastructure required for chat functionality. With in-app chat, service providers and patients no longer need to use third-party messaging apps. Their private conversations are secured within the app.</p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d668bde453152190f9c5dea_11_messages2.gif" alt=""></p></div><div data-w-id="41a2d73b-be20-40f9-b8f2-d17f25f09844"><div><h2><strong>File management system</strong></h2><p>This project is ongoing, and in the next version weâ€™re planning to implement a feature that enables service providers to access files they need while theyâ€™re on the go, even without an internet connection. This file management system will allow service providers to:</p></div><div><div data-w-id="ed7bb160-c295-cfd2-068b-bbb565e9c96d"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c32007ec36600c7bf7ba6_12_icon_cloud_cross.png" alt=""></p><p><h3><strong>Access essential files in<br>offline mode</strong></h3></p></div><div data-w-id="ed7bb160-c295-cfd2-068b-bbb565e9c96e"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3201e11fbe7615625f7b_12_icon_lock.png" alt=""></p><p><h3><strong>Control document accessibility (for example, mark as read-only)</strong></h3></p></div><div data-w-id="78e7c47c-c9db-f6de-981f-9aaf0b5a8140"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3200e11fbe7f1c625f79_12_icon_folder.png" alt=""></p><p><h3><strong>Organize files and sort them <br>into folders</strong></h3></p></div></div><div><div data-w-id="c2f09bd3-612c-f089-d576-7f2f4bfe3137"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c32005c898042edbfa77a_12_icon_doc.png" alt=""></p><p><h3><strong>Work with a wide range of <br>file types</strong></h3></p></div><div data-w-id="c2f09bd3-612c-f089-d576-7f2f4bfe3140"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3201e11fbe2643625f7a_12_icon_cloud.png" alt=""></p><p><h3><strong>Upload, share, and view files on<br>any device</strong></h3></p></div></div></div></div><div><div><p>CentralReach tested the waters by working on this project with us. Weâ€™ve <span><strong>successfully launched</strong></span> the first version of this app, and weâ€™re continuing to build our project team and crank out amazing new features.</p></div></div><div><div><section><div data-ix="in-5-fade-300"><h2>Weâ€™re Sure You Have an Amazing Idea</h2><p>Letâ€™s discuss how to bring it to life.</p><a href="https://www.ego-cms.com/contact-us" data-w-id="c66f8563-c48c-2b07-207c-728c2ca3b362"><p>CONTACT US</p></a></div></section></div></div></div></div>]]>
            </description>
            <link>https://www.ego-cms.com/centralreach</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942018</guid>
            <pubDate>Fri, 30 Oct 2020 13:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn setting up Google Tag Manager with this tutorial]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941974">thread link</a>) | @arctic-hunter
<br/>
October 30, 2020 | https://bluerivermountains.com/en/google-tag-manager-setup | <a href="https://web.archive.org/web/*/https://bluerivermountains.com/en/google-tag-manager-setup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><main role="main"><div><figure><div></div></figure><p>As a <a href="https://bluerivermountains.com/en/google-tag-manager-consultant">Google Tag Manager consultant</a>, I've set up GTM on <b>100+ client websites</b>. This Google Tag Manager tutorial is where I teach you the process I've refined over the years, step by step, with examples and videos for you to learn.</p><p>Further down, you can <a href="https://bluerivermountains.com/en/google-tag-manager-setup#download-gtm-config-container-file">download a GTM setup configuration file</a> with all of the following best practices to import into your container.</p><p>If you can't wait, jump right into the <a href="https://bluerivermountains.com/en/google-tag-manager-setup#install-google-tag-manager-on-your-website">installation</a> tutorial or learn <a href="https://bluerivermountains.com/en/google-tag-manager-setup#how-to-set-up-google-tag-manager">how to set up Google Tag Manager</a>. But if you are a <b>beginner</b> it is important to first understand <em>how</em> to use a <a href="https://bluerivermountains.com/en/tag-management">tag management system</a> together with other tools.</p><p>So keep on reading below first.</p><h2 id="how-to-use-google-tag-manager"><a href="#how-to-use-google-tag-manager" aria-label="How to use Google Tag Manager?" title="Right click to copy link to paragraph"></a>How to use Google Tag Manager?</h2><p>I assume you already know <a href="https://bluerivermountains.com/en/what-is-google-tag-manager">what Google Tag Manager is</a>. So lets talk about how GTM works and how to use it.</p><p>Ideally, you only want to have <b>one</b> 3rd-party tag in the source code of your website or web app.</p><a href="https://twitter.com/intent/tweet?text=The%20only%203rd-party%20tag%20on%20your%20website%20should%20be%20the%20Google%20Tag%20Manager%20code%20snippet.%20-%20via%20undefined" target="_blank"><section><p><b>The only 3rd-party tag on your website should be the Google Tag Manager code snippet.</b></p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>All other tags are then implemented through the tag manager itself. Other marketing and tracking tags are e.g. Google Analytics (GA), Facebook, Twitter, Linkedin, AdWords, DoubleClick and god knows what.</p><p>The primary reason are the <a href="https://bluerivermountains.com/en/google-tag-manager-benefits">advantages of Google Tag Manager</a>:</p><ul><li><b>easier &amp; faster</b> implementation of marketing tags</li><li>scalability on every page and across multiple domains</li><li><b>built-in triggers</b> for form submissions, scroll tracking&nbsp;&amp; video tracking</li><li>manage users with multiple gtm accounts</li><li>a bit <a rel="noopener" target="_blank" href="https://marketingland.com/audit-of-online-retailer-sites-shows-tag-management-systems-improve-load-times-reduce-errors-62173">faster site load speed</a></li></ul><p>Due to these advantages, already <a target="_blank" href="https://w3techs.com/technologies/overview/tag_manager">30% of all websites on the internet use a tag manager</a>. And among them Google Tag Manager has a market share of <a target="_blank" rel="noopener" href="https://trends.builtwith.com/analytics/tag-management/traffic/Entire-Internet">94%</a>.</p><p>So, unless you have a solid reason not to add a tag to GTM, as a general rule of thumb, <b>add all tags to the GTM container</b>.</p><a href="https://twitter.com/intent/tweet?text=Use%20GTM%20like%20a%20connecting%20layer%20between%20your%20website%20and%203rd-party%20tags.%20-%20via%20undefined" target="_blank"><section><p><b>Use GTM like a connecting layer between your website and 3rd-party tags.</b></p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>Use GTM like a <b>middle-layer</b> between your website and 3rd-party services. Without it, your site and 3rd party tags are not in direct connection. Those services are mostly JavaScript libraries for marketing or tracking tools that are implemented with a tag. But any other tags apply as well.</p><p>The only exception to the rule applies when you do&nbsp;conversion optimization&nbsp;with split-testing tools.</p><p>Because during conversion rate optimization, A/B tests are going to load different variants of a page. So the visitor may see how the content is re-rendered for a split-second.</p><p>To avoid CSS flicker and ensure that variant tests load fast, a split-testing tag may also go directly into the source code.</p><p>Now that we have this out of the way, letâ€™s look at the implementation.</p><h2 id="install-google-tag-manager-on-your-website"><a href="#install-google-tag-manager-on-your-website" aria-label="Install Google Tag Manager on your website" title="Right click to copy link to paragraph"></a>Install Google Tag Manager on your website</h2><p>Let's start the Google Tag Manager tutorial by showing you where to get the Google Tag Manager code snippet and then where to install it on the website. You can log in just by using your usual Google account.</p><ol><li><h3 id="create-a-google-tag-manager-account"><a href="#create-a-google-tag-manager-account" aria-label="Create a Google Tag Manager account" title="Right click to copy link to paragraph"></a>Create a Google Tag Manager account</h3>To install GTM, you first have to go to the <a rel="noopener" target="_blank" href="https://tagmanager.google.com/">official website</a> and create a new Google Tag Manager account.<br><figure><div></div><figcaption>First, create a Google Tag Manager account, and choose a container name, like your website name and then get the code snippet.</figcaption></figure></li><li><h3 id="create-a-web-property"><a href="#create-a-web-property" aria-label="Create a web-property" title="Right click to copy link to paragraph"></a>Create a web-property</h3>Select the <b>Web</b> property to get a code for a website or web app.<br><figure><div></div><figcaption>There are multiple types of containers available in a GTM account. For websites, choose web. Note that there are other tag manager container types for AMP pages, iOS and Android too.</figcaption></figure></li><li><h3 id="implement-the-google-tag-manager-code"><a href="#implement-the-google-tag-manager-code" aria-label="Implement the Google Tag Manager code" title="Right click to copy link to paragraph"></a>Implement the Google Tag Manager code</h3><ul>Afterwards, you will be shown the Google Tag Manager code to implement on your website.<br><figure><div></div><figcaption>This is the Google Tag Manager container tag. It has two parts. The instructions how to implement the script tags are written above each part.</figcaption></figure><li>Take the <b>first part</b> of the container tag and put it as high as possible in the <b>head</b> tag on every page of your website. This ensures that you can fire tags early during page loads.</li><li>The <b>second part</b> is an iframe to run in browsers that have JavaScript disabled. Install the tag as high as possible in the <b>body</b> tag on each page of your website.<br><figure><div></div><figcaption>The first tag in the &lt;head&gt; is a data layer. Don't worry if you don't know yet what that is (first arrow). Next is the first part of the GTM tag (second arrow). Finally, the other part of the GTM tag is implemented high up in the &lt;body&gt; element.  or JavaScript code can be implemented in between, but a data layer is always implemented before the GTM tag and the &lt;noscript&gt; GTM tag is always last.</figcaption></figure></li></ul></li></ol><p>This is the common method to implement GTM.</p><p>Do you use a popular content management system? If yes, you can also use a <b>plugin</b> that takes care of the Google Tag Manager installation.</p><p>That said:</p><a href="https://twitter.com/intent/tweet?text=If%20your%20CMS%20also%20offers%20you%20a%20plugin%20to%20install%20other%20tags,%20don%27t%20use%20yet%20another%20plugin%20to%20install%20Google%20Analytics,%20Facebook%20or%20Google%20Ads.%20Instead,%20use%20GTM%20to%20install%20those%20tags.%20-%20via%20undefined" target="_blank"><section type="info"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+PGc+PHJlY3QgZmlsbD0ibm9uZSIgaGVpZ2h0PSIyNCIgd2lkdGg9IjI0Ii8+PC9nPjxnPjxnPjxnPjxwYXRoIGQ9Ik05LDIxYzAsMC41NSwwLjQ1LDEsMSwxaDRjMC41NSwwLDEtMC40NSwxLTF2LTFIOVYyMXogTTEyLDJDOC4xNCwyLDUsNS4xNCw1LDljMCwyLjM4LDEuMTksNC40NywzLDUuNzRWMTcgYzAsMC41NSwwLjQ1LDEsMSwxaDZjMC41NSwwLDEtMC40NSwxLTF2LTIuMjZjMS44MS0xLjI3LDMtMy4zNiwzLTUuNzRDMTksNS4xNCwxNS44NiwyLDEyLDJ6IE0xNCwxMy43VjE2aC00di0yLjMgQzguNDgsMTIuNjMsNywxMS41Myw3LDljMC0yLjc2LDIuMjQtNSw1LTVzNSwyLjI0LDUsNUMxNywxMS40OSwxNS40OSwxMi42NSwxNCwxMy43eiIvPjwvZz48L2c+PC9nPjwvc3ZnPg==" alt="tip" height="42px"><p><b>If your CMS also offers you a plugin to install other tags</b></p><div><p>Don't use yet another plugin to install Google Analytics, Facebook or Google Ads.</p><p>Instead, <b>use GTM to install those tags</b>.</p><br><ol><li>It will result in a faster page load speed</li><li>It gives you more options to configure the tag</li></ol></div><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>The GTM user interface also receives updates with new features regularly, so you are almost always better off implementing other marketing tags directly with it than with another integration.</p><p>Plus, the gains in load time are good for your bounce rate and help SEO.</p><h3 id="use-a-plugin-to-implement-gtm"><a href="#use-a-plugin-to-implement-gtm" aria-label="Use a plugin to implement GTM" title="Right click to copy link to paragraph"></a>Use a plugin to implement GTM</h3><p>Below a list of the most common content management systems and their plugins to install Google Tag Manager.</p><h4 id="wordpress"><a href="#wordpress" aria-label="WordPress" title="Right click to copy link to paragraph"></a>WordPress</h4><p>There are two WordPress plugins to implement GTM that I would use. <b>First</b>, there is the classic option called <a rel="noopener" target="_blank" href="https://wordpress.org/plugins/duracelltomi-google-tag-manager/">Google Tag Manager for WordPress</a>.<br>The <b>second</b> option is <a rel="noopener" target="_blank" href="https://wordpress.org/plugins/google-site-kit/">Site Kit by Google</a>. It primarily allows you to add a dashboard to your Worpress backend showing information from your Google Analytics account and Google Search Console data - which is pretty sweet. And it also allows you to install GTM.</p><h4 id="shopify"><a href="#shopify" aria-label="Shopify" title="Right click to copy link to paragraph"></a>Shopify</h4><p>For Shopify, there is a <b>free</b> plugin for GTM installation creatively called <em><a rel="noopener" target="_blank" href="https://apps.shopify.com/trafficguard?surface_detail=google+tag+manager&amp;surface_inter_position=1&amp;surface_intra_position=6&amp;surface_type=search">Google Tag Manager Installer</a></em>.</p><h4 id="squarespace"><a href="#squarespace" aria-label="Squarespace" title="Right click to copy link to paragraph"></a>Squarespace</h4><p>For Squarespace, there is no GTM extension or plugin. But you can add the GTM tag manually, by visiting <b>sidebar</b> &gt; <b>settings</b> &gt; <b>advanced</b> &gt; <b>code injection</b>.</p><figure><div></div><figcaption>In Squarespace you can implement GTM under Settings &gt; Advanced &gt; Code Injection</figcaption></figure><p>Next, you paste the GTM tag into the form fields like this:</p><figure><div></div><figcaption>Put the first part of the GTM code in the header field. The Second part goes into the footer field.</figcaption></figure><h4 id="wix"><a href="#wix" aria-label="Wix" title="Right click to copy link to paragraph"></a>Wix</h4><p>Visit the main menu for your Wix website on the left sidebar. From there visit <b>Marketing &amp; SEO</b> and then click on <b>Marketing Integrations</b> further down in the sidebar.<br>Then you will find multiple Wix integrations for Google Analytics, the Facebook pixel and also one Wix extension to implement Google Tag Manager.</p><figure><div></div><figcaption>In Wix use the marketing integration for Google Tag Manager.</figcaption></figure><p>Click on connect and get Google Tag Manager installed.</p><h2 id="how-to-check-if-gtm-is-working"><a href="#how-to-check-if-gtm-is-working" aria-label="How to check if GTM is working?" title="Right click to copy link to paragraph"></a>How to check if GTM is working?</h2><a href="https://twitter.com/intent/tweet?text=When%20you%20first%20log%20in%20to%20GTM...Go%20to%20the%20submit%20button%20and%20publish%20an%20empty%20container.%20Otherwise,%20once%20you%20test%20if%20GTM%20works,%20the%20script%20will%20return%20a%20400%20response%20error%20and%20you%20will%20spend%20hours%20debugging%20why.%20%F0%9F%98%AD%20-%20via%20undefined" target="_blank"><section type="info"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+PGc+PHJlY3QgZmlsbD0ibm9uZSIgaGVpZ2h0PSIyNCIgd2lkdGg9IjI0Ii8+PC9nPjxnPjxnPjxnPjxwYXRoIGQ9Ik05LDIxYzAsMC41NSwwLjQ1LDEsMSwxaDRjMC41NSwwLDEtMC40NSwxLTF2LTFIOVYyMXogTTEyLDJDOC4xNCwyLDUsNS4xNCw1LDljMCwyLjM4LDEuMTksNC40NywzLDUuNzRWMTcgYzAsMC41NSwwLjQ1LDEsMSwxaDZjMC41NSwwLDEtMC40NSwxLTF2LTIuMjZjMS44MS0xLjI3LDMtMy4zNiwzLTUuNzRDMTksNS4xNCwxNS44NiwyLDEyLDJ6IE0xNCwxMy43VjE2aC00di0yLjMgQzguNDgsMTIuNjMsNywxMS41Myw3LDljMC0yLjc2LDIuMjQtNSw1LTVzNSwyLjI0LDUsNUMxNywxMS40OSwxNS40OSwxMi42NSwxNCwxMy43eiIvPjwvZz48L2c+PC9nPjwvc3ZnPg==" alt="tip" height="42px"><p><b>When you first log in to GTM</b></p><div><p>Go to the submit button and publish an <b>empty container</b>.</p><div><p>Otherwise, once you test if GTM works, the script will return a <b>400 response error</b> and you will spend hours debugging why. ðŸ˜­ </p><p>It's a classic ðŸ˜‰</p></div></div><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>After you implemented the GTM script and <b>published a container</b> version (important), you can test if Google Tag Manager is working by doing any of these checks:</p><ol><li><h3 id="preview-and-debug-mode"><a href="#preview-and-debug-mode" aria-label="Preview and debug mode" title="Right click to copy link to paragraph"></a>Preview and debug mode</h3>Log into your GTM account and click on <b>preview</b>. Then, open a new tab in the browser and visit your website. The GTM debugger window should pop open on the bottom of the window if GTM works correctly.<br><figure><div></div><figcaption>Activate the GTM debugger mode to check if GTM is working correctly.</figcaption></figure></li><li><h3 id="chrome-developer-tools"><a href="#chrome-developer-tools" aria-label="Chrome Developer Tools" title="Right click to copy link to paragraph"></a>Chrome Developer Tools</h3><b>Open Chrome Developer Tools</b> with a right-click on any page of your site and select <em>inspect</em> (Alternatively F12 on Windows and Shift+CTRL+J on Mac).<br>Then you go to the <b>network</b> tab and <b>simultaneously reload the web page</b> (F5 on Windows and CMD+Shift+R on Mac). The network tab will fill with all network requests necessary to load the page.<br>In the filter field in the top-left, type <em>gtm.js</em> to find the request for your JavaScript code and verify it has a <b>status code of 200</b>.<p>Let me show you:</p><video loading="lazy" title="Check if Google Tag Manager is working" loop="" controls=""><source src="https://bluerivermountains.com/video/check-if-gtm-is-working.mp4" type="video/mp4"></video><br><b>If you donâ€™t have a 200 status code, maybe you forgot to submit and publish a container first in GTM?</b></li><li><h3 id="google-tag-assistant"><a href="#google-tag-assistant" aria-label="Google Tag Assistant" title="Right click to copy link to paragraph"></a>Google Tag Assistant</h3>Install the <a rel="noopener" target="_blank" href="https://chrome.google.com/webstore/detail/tag-assistant-by-google/kejbdjndbnbjgmefkgdddjlbokphdefk">Google Tag Assistant</a> Chrome extension and start it on your site. It should call out a GTM container ID.<br><div width="452px"><figure><div></div><figcaption>You can also use the Chrome Extension Google Tag Assistant to ensure Google Tag Manager is working correctly.</figcaption></figure></div></li></ol><h2 id="how-to-set-up-google-tag-manager"><a href="#how-to-set-up-google-tag-manager" aria-label="How to set up Google Tag Manager?" title="Right click to copy link to paragraph"></a>How to set up Google Tag Manager?</h2><p>When setting up Google Tag Manager you can make many advanced configurations. So <b><em>how</em></b> you set up GTM, depends on what other tools you plan to use in your <a href="https://bluerivermountains.com/en/tag-management">tag management system</a>.</p><p>That's why I brought together all relevant tutorials that cover whatever you could possibly want to set up in your GTM account - with examples. Simply follow this Google Tag&nbsp;Manager guide and thereby create a solid tag management foundation for your site.</p><p>Only the tutorial on implementing a data layer requires coding skills or potentially web developers.</p><p><b>Note</b>: In this Google Tag Manager tutorial, we will use GTM by <b>manually</b> setting up new tags and triggers for each event. The approach is not super scalable, but it is fast enough and easy, while meeting most tracking ambitions and still being applicable to other advanced setups.</p><p>Larger websites and e-commerce stores require a <b>scalable tag management solution</b>. Therefore a <a href="https://bluerivermountains.com/en/datalayer">data layer</a> is implemented as the central piece to track events. With such a setup, you can use event handlers instead of setting up tags, triggers and variables for each event.</p><ol><li><h3 id="set-up-google-analytics-tracking"><a href="#set-up-google-analytics-tracking" aria-label="Set up Google Analytics tracking" title="Right click to copy link to paragraph"></a>Set up Google Analytics tracking</h3><p>This is the first step for everybody. Learn in this guide how to implement solid Google Analytics tracking, with Goals, Funnels, and your own visits excluded from the traffic. Plus more best practices.</p><a href="https://bluerivermountains.com/en/google-analytics-setup"></a></li><li><h3 id="set-up-event-tracking"><a href="#set-up-event-tracking" aria-label="Set up event tracking" title="Right click to copy link to paragraph"></a>Set up event tracking</h3><p>Once the fundamental tracking implementation is running as it should, you will also want to learn tracking user engagement. How often, for example, does a visitor send form submissions and click on a submit button or another HTML element? My <a href="https://bluerivermountains.com/en/event-tracking">event tracking</a> guide explains exactly that for a <b>button click</b> and you can use the same method for any other click tracking.</p><a href="https://bluerivermountains.com/en/event-tracking"></a></li><li><p>The most common use-case for GTM <em>after</em> installing GA is adding remarketing tags to a website. After all, they make the majority of 3rd-party marketing tags and tracking codes that â€¦</p></li></ol></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bluerivermountains.com/en/google-tag-manager-setup">https://bluerivermountains.com/en/google-tag-manager-setup</a></em></p>]]>
            </description>
            <link>https://bluerivermountains.com/en/google-tag-manager-setup</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941974</guid>
            <pubDate>Fri, 30 Oct 2020 13:29:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Edge Caching and Computing by PicoNETS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941965">thread link</a>) | @ponderingfish
<br/>
October 30, 2020 | https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/ | <a href="https://web.archive.org/web/*/https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/piconets-deep-edge-caching-featured-images.png?resize=678%2C381&amp;ssl=1" alt="piconets-deep-edge-caching-featured-images" title="piconets-deep-edge-caching-featured-images" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/piconets-deep-edge-caching-featured-images.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>In this edition of the <a href="https://ottverse.com/category/industry-spotlight/">Industry Spotlight</a> series, we take a look at <a href="https://www.piconets.com/" target="_blank" rel="noopener">picoNETS</a>; a startup focused on building Deep Edge Content Delivery Networks or Deep Edge Caching for Telcos and Content Providers.</p>



<p>Letâ€™s take a look at their product, journey, USP, and what sets them apart from the rest, shall we?</p>




<h2><span id="Who_is_picoNETS"></span>Who is picoNETS?<span></span></h2>



<p>picoNETS is a&nbsp;<strong>Deep Edge Content Delivery Network</strong>&nbsp;provider started in 2016, and they primarily work with telecom and content providers. Some of their USPs and accomplishments are â€“</p>



<ul><li>They are a Deep Edge CDN for media delivery and also provide edge computing resources.</li><li>picoNETS is a partner of the&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://ruralcloud.com/">Rural Cloud Initiative</a>&nbsp;in the US and is engaged with top OTT platforms in India</li><li>They are live in 5G Labs for a US Telco and have gained traction with Carriers, Telcos, and ISPs in the US, UK, India, Singapore, South Korea, Vietnam, Indonesia, Bangladesh, and Fiji.</li></ul>



<h2><span id="How_does_picoNETS%E2%80%99_Edge_Caching_Work"></span>How does picoNETSâ€™ Edge Caching Work?<span></span></h2>



<p>Before we dive into the â€œhow,â€ letâ€™s understand why there is a need for a&nbsp;<strong>deep edge CDN</strong>&nbsp;like the one offered by picoNETS.</p>



<p>Letâ€™s take the example of rural America. </p>



<p>A recent article from&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.theverge.com/21504476/online-school-covid-pandemic-rural-low-income-internet-broadband">The Verge</a>&nbsp;highlighted the struggle faced by rural Americans in their pursuit of high speed Internet and how this problem was exacerbated in the face of the COVID-19 pandemic. A&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.reddit.com/r/technology/comments/j6wor7/americas_internet_wasnt_prepared_for_online/">raging debate on the same article in Reddit</a>&nbsp;underscored the struggle of everyday, rural America.</p>



<p>In addition to a lack of high-speed internet, if a CDN provider does not have a point of presence (PoP) near your city/town/village, then you are going to face problems with streaming video. </p>



<p>Video streaming problems manifest in different ways â€“ a long delay in showing the first picture (startup delay or latency), buffering issues during playback, or while seeking back or forth in the video, and in the worst case, complete stalls or fatal errors. Apart from these problems, a low-bandwidth connection is quite likely to result in a low resolution (or bitrate) video being delivered to your device.</p>



<p>All of these problems amount to an abysmal viewing experience, right?</p>



<p>So whatâ€™s the solution to these problems?</p>



<p>Well, one could argue that itâ€™s up to the CDN provider to establish more POPs (geographically distributed) and improve their coverage. While this is a reasonable argument, it can be challenging in terms of infrastructural costs and the RoI for the CDN provider.</p>



<p>However, if you continue this train of thought, you end up with a business model that establishes POPs at a much more granular level.</p>



<p>What do I mean by this?</p>



<p>Well, instead of establishing a POP in every town or city, why not go deeper and install a POP at every airport, shopping mall, school, university, or post office?</p>



<p>Is it possible? Well, it sure is and <strong>this is the USP of picoNETS.</strong></p>



<p>picoNETS go â€œdeepâ€ and establish â€œdeep edge cachesâ€ right next to your underserved target audience to ensure that they get a fantastic QoE.</p>



<p>A prototypical customer of picoNETS could be a university that uses the deep edge cache to provide buffer-free, high quality, online classes for their students (live or on-demand).</p>



<p>Here is an illustration of the concept we just discussed. </p>



<figure><img data-attachment-id="1128" data-permalink="https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/piconets/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=960%2C540&amp;ssl=1" data-orig-size="960,540" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="picoNETS" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=960%2C540&amp;ssl=1" loading="lazy" width="960" height="540" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" alt="picoNETS edge caching" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?w=960&amp;ssl=1 960w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=678%2C381&amp;ssl=1 678w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<h2><span id="The_benefit_of_using_picoNETS"></span>The benefit of using picoNETS<span></span></h2>



<p>Now that weâ€™ve established that picoNETS brings caching closer to your customer (the â€œwhyâ€ and the â€œhowâ€), the benefits are evident and critical to a good user experience. </p>



<p>With picoNETS, you get,</p>



<ul><li><strong>low latency media delivery</strong>&nbsp;â€“ this is important in reducing stalls, and time-to-first-byte, startup-delay</li><li><strong>reduced buffering</strong>&nbsp;during playback and during seeks.</li><li>the ability to <strong>scale and deliver media</strong> when content goes viral especially, in a geo-localized manner. </li></ul>



<p>Another cool use-case for picoNETS is in the online multiplayer gaming industry. </p>



<p>It is important for gaming engines to synchronize each playerâ€™s location with the rest of the players, or else the game-play is spoiled, and there could be unfair advantages to certain players over others.</p>



<p>picoNETS tries to solve such problems by&nbsp;<strong>providing edge-computing</strong>&nbsp;in addition to their edge caching capabilities. By moving the decision and synchronization engines closer to the players (edge, i.e.), game-play is improved, and the latency incurred in player-synchronization is reduced.</p>



<p>All this sounds nice, right? But, my mind went straight to a commercial deployment scenario and I wasnâ€™t sure how picoNETS would work alongside a traditional CDN. Do you need to use both or either one?</p>



<p>Well, letâ€™s find out. </p>



<h2><span id="How_Do_You_Choose_Between_a_CDN_and_picoNETS_Deep_Edge_Cache"></span>How Do You Choose Between a CDN and picoNETS Deep Edge Cache?<span></span></h2>



<p>While speaking to&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.linkedin.com/in/ashishrbedekar">Ashish Bedekar</a>, picoNETSâ€™ COO, I asked him what a typical deployment looks like and how does it impact their customersâ€™ operations?</p>



<p>He mentioned that the deployment is quite straightforward (similar to other CDN deployments). And, the decision to switch between a customersâ€™ incumbent, traditional CDN and picoNETS happens at the CMS level.</p>



<p>At the CMS, a decision is taken to playback a stream using the CDN or with the picoNETS Deep Edge Cache. The decision is based on the ASN value, and Ashish told me that the rules could be more fine-grained as needed.</p>



<p>For example, their multi-CDN router allows you to add rules to direct premium subscribersâ€™ traffic vs. others. Also, they have fail-over policies to ensure that the end-user is never left hanging!</p>



<p>This multi-CDN approach is smart and allows you to fine-tune your deployment to take advantage of each service (CDN &amp; picoNETS) in its â€œarea of strengthâ€.</p>



<p>Hereâ€™s an example of their architecture that demonstrates this. </p>



<figure><img data-attachment-id="1090" data-permalink="https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/image-2/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=1202%2C706&amp;ssl=1" data-orig-size="1202,706" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" alt="picoNETS edge cache" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=300%2C176&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=768%2C451&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1200%2C705&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?w=1202&amp;ssl=1 1202w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Again, itâ€™s best to get in touch with picoNETS to discuss specifics.</p>



<h2><span id="Get_in_touch_with_picoNETS"></span>Get in touch with picoNETS<span></span></h2>



<p>To learn more about their technology and to talk to the picoNETS team for further information, you can either <a href="https://www.piconets.com/" target="_blank" rel="noopener">visit their website</a> or <a href="mailto:ashish.bedekar@piconets.com">email Ashish Bedekar</a>.</p>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>It is critical to get your content delivery strategy on point when it comes to OTT and I think there is a lot of scope for improving the current techniques used in CDNs, Edge Caching, P2P, etc. with the ultimate goal of providing a sublime viewing experience for the end-users.</p>



<p>I think the work that picoNETS is doing is great, serves a very underserved segment of our population, and helps them enjoy the same benefits as those in urban areas!</p>



<p>Do share this article with your friends on LinkedIn, Twitter, and Facebook. Until next time, take care, <a href="https://ottverse.com/subscribe/">Subscribe</a>, and continue reading OTTVerse.com! </p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941965</guid>
            <pubDate>Fri, 30 Oct 2020 13:27:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Happier You Are, the Less Likely Youâ€™re to Experience Memory Decline]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941953">thread link</a>) | @conse_lad
<br/>
October 30, 2020 | https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/ | <a href="https://web.archive.org/web/*/https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
		Study says happy people are less likely to experience memory decline with age.	</p><div>
		
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->

<p>The structure and function of brain cells continues to change throughout life, and most of its aspects decline as we age in response to a number of lifestyle factors. As these cells lose their ability to communicate with each other, our ability to retain memory disintegrates. But, is there a way to stop it from happening, or at least slow it down a bit?</p>
<p>Yes, and thatâ€™s by keeping a positive outlook in life.</p>
<p>A <a href="https://www.psychologicalscience.org/news/releases/2020-oct-positive-outlook-memory.html" target="_blank" rel="noopener noreferrer">new study</a> at Association for Psychological Science has revealed that people who lead a cheerful, enthusiastic life full of pride and joy are less likely to experience memory decline as they age. Psychologists have a term for it, and itâ€™s called â€œ<a href="https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-79061-9_2193" target="_blank" rel="noopener noreferrer">positive affect</a>â€. So the more a person experiences a positive affect, the more he or she is likely to retain memories, of which some could even last a lifetime.</p>
<p><img data-attachment-id="39297" data-permalink="https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/happy-people-are-less-likely-to-experience-memory-decline-with-age/" data-orig-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=1920%2C1280&amp;ssl=1" data-orig-size="1920,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="happy people are less likely to experience memory decline with age." data-image-description="" data-medium-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=780%2C520&amp;ssl=1" loading="lazy" src="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=780%2C520&amp;ssl=1" alt="happy people are less likely to experience memory decline with age" width="780" height="520" srcset="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?w=1920&amp;ssl=1 1920w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1536%2C1024&amp;ssl=1 1536w" sizes="(max-width: 780px) 100vw, 780px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?w=1920&amp;ssl=1 1920w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1536%2C1024&amp;ssl=1 1536w" data-lazy-src="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=780%2C520&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->


<p>For the study, the team looked at data from 991 adults who took part in a national study conducted three times between 1995 and 1996, 2004 and 2006, and 2013 and 2014.</p>
<p>Researchers then gauged the reports on a range of positive emotions the participants had experienced over the past 30 days. They also asked participants to take part in a memory test which consisted of recalling words immediately after a presentation and again 15 minutes later.</p>
<p>After successfully examining the association between positive affect and memory decline, while accounting for factors like age, gender, education, depression, negative affect, and extraversion, they found that individuals with higher levels of positive affect had a better memory retention over the course of almost a decade compared to those that had experienced lesser positive affect.</p>
<p>Positive affectivity has been tied to a <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2895001/" target="_blank" rel="noopener noreferrer">number of favourable health outcomes</a>, including lowering the levels of stress, minimizing severity of depression, promoting longevity and other physiological functioning. And this new finding adds to a burgeoning area of research on the role of positive affect in healthy aging.</p>
<p>The study entitled <strong>â€œ</strong><span><strong>Positive Affect Is Associated With Less Memory Decline: Evidence From a 9-Year Longitudinal Studyâ€</strong>&nbsp;</span>has been published in the journal <em><a href="https://journals.sagepub.com/doi/10.1177/0956797620953883" target="_blank" rel="noopener noreferrer">Psychological Science</a></em>.</p>


<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->



	</div></div>]]>
            </description>
            <link>https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941953</guid>
            <pubDate>Fri, 30 Oct 2020 13:24:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional Programming in JavaScript, part I â€“ Composition]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941678">thread link</a>) | @chrismiaskowski
<br/>
October 30, 2020 | https://11sigma.com/blog/functional-programming-in-js-part-i-composition | <a href="https://web.archive.org/web/*/https://11sigma.com/blog/functional-programming-in-js-part-i-composition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote><p>This article was originally published on Mateusz's <a href="https://dev.to/mpodlasin/functional-programming-in-js-part-i-composition-currying-lodash-and-ramda-1ohb">dev.to profile</a>.</p><p>Mateusz says about himself: "I write in-depth articles about JavaScript, React and functional programming."</p></blockquote><p>In this series of articles, we will go through a soft introduction to functional programming in JavaScript.</p><p>Each article will be devoted to a different aspect of functional programming. After the theoretical introduction, we will see how those concepts are then used in actual, real world JavaScript libraries.</p><p>This mix of theory and practice will ensure that you get a deep understanding of all the concepts while being able to use them effortlessly in practice in your day to day work.</p><p>Please be aware that this series assumes that you already have some proficiency in writing code with arrays' methods such as <code>map</code>, <code>filter</code>, and <code>reduce</code>. If they still confuse you, let me know, and I will write an article explaining them in-depth.</p><p>Ready? Let's get started!</p><h2>Composition</h2><p>If I had to name in one word what this first article will focus on, it would be <em>composition</em> or <em>composability</em>.</p><p>More specifically, I mean here the art of composing your code from small, reusable functions, almost like composing a lego set from smaller pieces.</p><p>It turns out that a properly written functional code is very composable. What does it mean? It means that it is extremely easy to take a small piece of that code and reuse it in a completely different situation.</p><p>Take a look at this code, written in traditional style:</p><pre><code><span>let</span> result <span>=</span> <span>[</span><span>]</span><span>;</span>

<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>,</span> i <span>&lt;</span> data<span>.</span><span>length</span><span>,</span> i<span>++</span><span>)</span> <span>{</span>
    <span>const</span> num <span>=</span> <span>parseInt</span><span>(</span>data<span>[</span>i<span>]</span><span>,</span> <span>10</span><span>)</span><span>;</span>

    <span>if</span> <span>(</span>num <span>&lt;</span> <span>5</span><span>)</span> <span>{</span>
        result<span>.</span><span>push</span><span>(</span>num<span>)</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre><p>and now compare it to:</p><pre><code><span>const</span> <span>stringToInt</span> <span>=</span> <span>str</span> <span>=&gt;</span> <span>parseInt</span><span>(</span>str<span>,</span> <span>10</span><span>)</span><span>;</span>
<span>const</span> <span>lessThan</span> <span>=</span> <span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span>

<span>const</span> result <span>=</span> data
    <span>.</span><span>map</span><span>(</span>stringToInt<span>)</span>
    <span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span><span>;</span></code></pre><p>Those two snippets do the same thing. We first take the <code>data</code> array, which is filled with some strings. We then transform those strings into integers. And finally, we store only those integers that are strictly smaller than 5 in a new array. We keep that array under the <code>result</code> variable.</p><p>So if we got an <code>["1", "6", "3"]</code> array, we would return <code>[1, 3]</code> as a result.</p><p>Depending on which style you are more accustomed to, you will find one of the two above snippets more readable. I believe that the second one is more readable because - not taking into the account little helper functions that we defined - it reads almost like English:</p><p>Take <code>data</code>, <code>mapEach</code>, <code>stringToInt</code> and then <code>filter</code> only those values that are <code>lessThan(5)</code>.</p><p>However, if you are not used to functional style, this second snippet will seem awkward and needlessly convoluted. Are there any objective benefits of writing the code in that style?</p><p>Of course! And that benefit is exactly the composability. Note that we went out of our way to define even the simplest pieces of our code as functions. Thanks to that, we can now use those snippets in entirely new situations without ever writing the same code twice.</p><p>Of course, those reusable <code>stringToInt</code> and <code>lessThan</code> functions are extremely simple, to the point where it arguably is not worth reusing them like that. But keep in mind that this example only serves as a motivation for the whole approach.</p><p>In more complex applications, those functions would be getting more and more complicated. The approach of reusing the most amount of code possible and composing new code from previously written functions will have much more apparent benefits in a bigger codebase.</p><p>Note also that apart from the simplest possible reusability - simply using <code>stringToInt</code> and <code>lessThan</code> functions in different contexts - we also see examples of using higher-order array functions - <code>map</code> and <code>filter</code>. It is key to note that they possess an immense power - they allow you to use functions defined for singular values (for example, strings) on whole arrays of those values (for instance, on arrays of strings).</p><p>This is the first moment when you can see the power of that approach. You wrote two functions - <code>stringToInt</code> and <code>lessThan</code> - that are not supposed to be used on arrays. And yet, by wrapping them in only a few more characters - <code>.map(stringToInt)</code>, <code>.filter(lessThan(5))</code> - you suddenly possess the power to use those functions on whole arrays of values.</p><p>This is precisely what we meant at the beginning. The functional approach allows you to use the same code in entirely different contexts - in fact, here, the same code is even used on completely different types of values! A function that was meant to work only on strings can now work on arrays of strings! That's pretty cool.</p><h2>Currying</h2><p>Perhaps you have already asked yourself - "wait, what is this weird definition of <code>lessThan</code> about?".</p><p>If I asked you to write a <code>lessThan</code> function, you would probably do it like that:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>(</span><span>num<span>,</span> compareTo</span><span>)</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>And yet we did it like that:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>Not only arguments are switched, but also the syntax of a function definition is different. Is this some new, exotic addition to the JavaScript standard?</p><p>In fact, no. What we did here is that we wrote a function that returns another function.</p><p>Function that we are returning is:</p><pre><code><span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>And then we wrap it in another function, that finally provides <code>compareTo</code> variable for it:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>(</span><span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>)</span><span>;</span></code></pre><p>This time we wrapped the returned function in parentheses for better readability.</p><p>Note that we used here the fact that in an arrow function, we can provide returned value directly, instead of the function body. If we wanted to write the body, we might rewrite the above example like so:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span>
<span>}</span><span>;</span></code></pre><p>In fact, this pattern doesn't really rely on ES6 arrow function syntax. Me might have as well written it in old school function syntax:</p><pre><code><span>function</span><span>(</span><span>compareTo</span><span>)</span> <span>{</span>
    <span>return</span> <span>function</span><span>(</span><span>num</span><span>)</span> <span>{</span>
        <span>return</span> num <span>&lt;</span> compareTo<span>;</span>
    <span>}</span><span>;</span>
<span>}</span></code></pre><p>What ES6 arrow syntax does, however, is that it makes that monstrous code look much nicer:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>That pattern is called currying.</p><p>If you take a function taking some number of parameters:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>(</span><span>a<span>,</span> b<span>,</span> c</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>you can "curry" it (or produce its "curried" version), which looks like that:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>a</span> <span>=&gt;</span> <span>b</span> <span>=&gt;</span> <span>c</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>In this case, the original function accepts three parameters.</p><p>After currying it, we get a function that accepts one parameter <code>a</code>, returns a function that takes one parameter <code>b</code>, then returns a function that accepts one parameter <code>c</code> and finally executes the original function's body.</p><p>Ok, we explained <em>how</em> that mechanism works, but we didn't explain why we even decided to write our functions like that.</p><p>Frankly, the answer is extremely simple. The only reason is so that we could later use the <code>lessThan</code> function like so:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span></code></pre><p>Note that if we used our first definition of that function:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>(</span><span>num<span>,</span> compareTo</span><span>)</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>then applying it in the <code>filter</code> method wouldn't be nearly as nice. We would have to write that code like so:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>num</span> <span>=&gt;</span> <span>lessThan</span><span>(</span>num<span>,</span> <span>5</span><span>)</span><span>)</span></code></pre><p>So again, you see that we wrote our function in a way that makes it compose nicely with methods such as <code>filter</code>.</p><p>It also composes nicely with a <code>map</code>. Writing code like this:</p><pre><code>numbers<span>.</span><span>map</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span></code></pre><p>would return an array of booleans saying if the number on a given place in the array is smaller than 5. For example, running that code on an array <code>[5, 1, 4]</code>, would return an array <code>[false, true, true]</code>.</p><p>So you can see that <code>lessThan</code> function composes now much nicer with other, higher-order functions.</p><p>On top of that, assume we noticed that we use <code>lessThan</code> very often with a number 5 specifically. Maybe that's a very important number, let's say a number of the servers we have in the company.</p><p>This number now appears in several places in our code. But having it hard-coded like that is a very bad practice. What if that number changes at some point, for example, to a 6? We would have to search for all those appearances of 5 and change them to 6 manually. This would be both too cumbersome and error-prone.</p><p>The first solution that comes to mind is to store that number in a variable, a constant with some semantic name that describes what this number means:</p><pre><code><span>const</span> <span>NUMBER_OF_SERVERS</span> <span>=</span> <span>5</span><span>;</span></code></pre><p>Now we can use the constant instead of the number:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>NUMBER_OF_SERVERS</span><span>)</span><span>)</span></code></pre><p>If that number changes (for example, our company buys more servers), we can update it in one place, where that constant is defined.</p><p>This is certainly nicer and very readable, but it's still a tiny bit cumbersome to import two distinct values (<code>lessThan</code> and <code>NUMBER_OF_SERVERS</code>) even though we always want to use them together.</p><p>However, the way we defined the <code>lessThan</code> function allows us to fix that. We can store the returned function in another variable!</p><pre><code><span>const</span> lessThanNumberOfServers <span>=</span> <span>lessThan</span><span>(</span><span>NUMBER_OF_SERVERS</span><span>)</span><span>;</span></code></pre><p>Now, whenever we want to use that function with that specific value, we can import it once and use it directly:</p><pre><code><span>.</span><span>filter</span><span>(</span>lessThanNumberOfServers<span>)</span></code></pre><p>Our function is more composable with other functions, but it also allows us to define new functions in a very easy manner.</p><p>Very often certain values in our functions are only some kind of configuration. Those values do not change very often. In fact, you will often find yourself hard-coding those values inside your functions:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>(</span><span><span>...</span>someArguments</span><span>)</span> <span>=&gt;</span> <span>{</span>
   <span>const</span> <span>SOME_VALUE_THAT_WILL_PROBABLY_NOT_CHANGE</span> <span>=</span> <span>5</span><span>;</span>

   <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>It's sometimes a good idea to put such value as an argument of a curried function and simply create a new function, with this value already set to a value we expect to be the most common:</p><pre><code><span>const</span> <span>someBiggerFunction</span> <span>=</span> <span>(</span><span>someValueThatWillProbablyNotChange</span><span>)</span> <span>=&gt;</span> <span>(</span><span><span>...</span>someArguments</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span>

<span>const</span> someFunction <span>=</span> <span>someBiggerFunction</span><span>(</span><span>5</span><span>)</span><span>;</span></code></pre><p>This pattern is handy because it ultimately gives you the same result - a function with a value hard-coded inside. But at the same time, you get much bigger flexibility. When it turns out it is necessary to set that variable to some â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://11sigma.com/blog/functional-programming-in-js-part-i-composition">https://11sigma.com/blog/functional-programming-in-js-part-i-composition</a></em></p>]]>
            </description>
            <link>https://11sigma.com/blog/functional-programming-in-js-part-i-composition</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941678</guid>
            <pubDate>Fri, 30 Oct 2020 12:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering TorchScript: Tracing vs. Scripting, Device Pinning, Graph Modification]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941642">thread link</a>) | @briggers
<br/>
October 30, 2020 | https://paulbridger.com/posts/mastering-torchscript/ | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/mastering-torchscript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>October 29, 2020</h5>



  
  
  

  


  <h2 id="intro">
  Intro
  <a href="#intro">#</a>
</h2>
<p>TorchScript is one of the most important parts of the Pytorch ecosystem, allowing portable, efficient and nearly seamless deployment. With just a few lines of <code>torch.jit</code> code and some simple model changes you can export an asset that runs anywhere <code>libtorch</code> does. Itâ€™s an important toolset to master if you want to run your models outside the lab at high efficiency.</p>
<p>Good <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">introductory material</a> is already available for starting to work with <a href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> including <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">execution in the C++ <code>libtorch</code> runtime</a>, and <a href="https://pytorch.org/docs/stable/jit_language_reference.html">reference material</a> is also provided. This article is a collection of topics going beyond the basics of your first export.</p>
<h2 id="tracing-vs-scripting">
  Tracing vs Scripting
  <a href="#tracing-vs-scripting">#</a>
</h2>
<p>Pytorch provides two methods for generating TorchScript from your model code â€” tracing and scripting â€” but which should you use? Letâ€™s recap how they work:</p>
<ul>
<li>
<p><a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html"><strong>Tracing.</strong></a> When using <code>torch.jit.trace</code> youâ€™ll provide your model and sample input as arguments. The input will be fed through the model as in regular inference and the executed operations will be traced and recorded into TorchScript. Logical structure will be frozen into the path taken during this sample execution.</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/generated/torch.jit.script.html"><strong>Scripting.</strong></a> When using <code>torch.jit.script</code> youâ€™ll simply provide your model as an argument. TorchScript will be generated from the static inspection of the <code>nn.Module</code> contents (recursively).</p>
</li>
</ul>
<p>Itâ€™s not obvious from the tutorial documentation, but choosing which method to use is a fairly simple and fluid choice:</p>
<h3 id="use-scripting-by-default">
  Use Scripting by Default
  <a href="#use-scripting-by-default">#</a>
</h3>
<p>Because <code>torch.jit.script</code> captures both the operations and full conditional logic of your model, itâ€™s a great place to start. If your model doesnâ€™t need any <a href="https://pytorch.org/docs/stable/jit_unsupported.html">unsupported Pytorch functionality</a> and has logic restricted to the <a href="https://pytorch.org/docs/stable/jit_builtin_functions.html#python-built-in-functions">supported subset of Python functions</a> and <a href="https://pytorch.org/docs/stable/jit_python_reference.html">syntax</a>, then <code>torch.jit.script</code> should be all you need.</p>
<p>One major advantage of scripting over tracing is that an export is likely to either fail for a well-defined reason â€” implying a clear code modification â€” or succeed without warnings.</p>
<blockquote>
  <p><strong>Unlike Python, TorchScript is Statically Typed</strong></p>
<p>You will need to be consistent about container element datatypes, and be wary of implicit function signatures. A useful practice is to use type hints in method signatures.</p>

</blockquote>

<p>Despite TorchScriptâ€™s ability to capture conditional logic it does not allow you to run arbitrary Python within <code>libtorch</code> â€” a popular misconception.</p>
<h3 id="use-tracing-if-you-must">
  Use Tracing if You Must
  <a href="#use-tracing-if-you-must">#</a>
</h3>
<p>There are a few special cases in which <code>torch.jit.trace</code> may be useful:</p>
<ul>
<li>If you are unable to modify the model code â€” because you do not have access or ownership â€” you may find scripting the model simply will not work because it uses unsupported Pytorch/Python functionality.</li>
<li>In pursuit of performance or to bake in architectural decisions the logic freezing behavior of tracing might be preferable â€” similar to inlining C/C++ code.</li>
</ul>
<blockquote>
  <p><strong>Pay Close Attention to Tracer Warnings</strong></p>
<p>Due to how tracing can simplify model behavior, each warning should be fully understood and only then ignored (or fixed). Also, be sure to trace in eval mode if you are exporting a model for production inference!</p>

</blockquote>

<h3 id="use-both-together">
  Use Both Together
  <a href="#use-both-together">#</a>
</h3>
<p>Scripted and traced code can be freely mixed, and this is often a great choice. See the existing <a href="https://pytorch.org/">pytorch.org</a> documentation for <a href="https://pytorch.org/docs/stable/jit.html#mixing-tracing-and-scripting">details</a> and <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#mixing-scripting-and-tracing">examples</a>.</p>
<h2 id="device-pinning">
  Device Pinning
  <a href="#device-pinning">#</a>
</h2>
<p>If you find yourself using <code>torch.jit.trace</code> on some code, youâ€™ll have to actively deal with some of the gotchas or face performance and portability consequences. Besides addressing any warnings Pytorch emits, youâ€™ll also need to keep an eye out for device pinning. Just like <code>torch.jit.trace</code> records and freezes conditional logic, it will also trace and make constant the values resulting from this logic â€” this can include device constants.</p>
<p>Using this sample code:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>X</span><span>.</span><span>size</span><span>(</span><span>0</span><span>))</span></code></pre></div>
<p>If we trace while executing on CPU or GPU we get this TorchScript (scroll to the right on mobile):</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>ops</span><span>.</span><span>prim</span><span>.</span><span>NumToTensor</span><span>(</span><span>torch</span><span>.</span><span>size</span><span>(</span><span>X</span><span>,</span> <span>0</span><span>))</span>
  <span>_1</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>annotate</span><span>(</span><span>number</span><span>,</span> <span>_0</span><span>),</span> <span>dtype</span><span>=</span><span>None</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>)</span>
  <span>return</span> <span>_1</span></code></pre></div>
<!-- raw HTML omitted -->
<p>You can see that <code>torch.device("cpu")</code> has been inserted as a constant into the generated TorchScript. If we try to get clever with this code:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>X</span><span>.</span><span>size</span><span>(</span><span>0</span><span>),</span> <span>device</span><span>=</span><span>X</span><span>.</span><span>device</span><span>)</span></code></pre></div>
<p>Tracing will now result in TorchScript that is pinned to the tracing device. When traced on GPU, we see this:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span>
    <span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>ops</span><span>.</span><span>prim</span><span>.</span><span>NumToTensor</span><span>(</span><span>torch</span><span>.</span><span>size</span><span>(</span><span>X</span><span>,</span> <span>0</span><span>))</span>
  <span>_1</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>annotate</span><span>(</span><span>number</span><span>,</span> <span>_0</span><span>),</span> <span>dtype</span><span>=</span><span>None</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cuda:0"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>)</span>
  <span>return</span> <span>_1</span></code></pre></div>
<!-- raw HTML omitted -->
<blockquote>
  <p><strong>Tensors Created During Tracing Will Have Their Device Pinned</strong></p>
<p>This can be a significant performance and portability problem.</p>

</blockquote>

<h3 id="performance-and-portability">
  Performance and Portability
  <a href="#performance-and-portability">#</a>
</h3>
<p>If we later deserialize and run this TorchScript in <code>libtorch</code> the <code>arange</code> tensor will always be created on the device that is pinned â€” <code>torch.device("cpu")</code> or <code>torch.device("cuda:0")</code> in the examples above. If the rest of the model is running on a different device this can result in costly memory transfers and synchronization.</p>
<p>This device pinning issue extends to multi-GPU scenarios as well. If you have traced and exported a model on <code>cuda:0</code> and then run it on <code>cuda:1</code> youâ€™ll see transfers and synchronization between the devices. Not good. Perhaps even worse, if such a model is run in an environment without any CUDA-capable device it will fail since <code>cuda:0</code> doesnâ€™t exist.</p>
<blockquote>
  <p><strong>Replace Tensors Created During Execution With Parameters</strong></p>
<p>Tensors created in the execution path while tracing will have their device pinned. Depending on model logic, these can often be turned into Parameters created during construction.</p>

</blockquote>

<p>An example of the problem looks like this in Nsight Systems:</p>








<a href="https://paulbridger.com/posts/mastering-torchscript/images/pinned_devices.png">
    <figure>
        <img src="https://paulbridger.com/posts/mastering-torchscript/images/pinned_devices_hub20c76c57b334a1bd11edec46dac0166_414004_896x580_fill_box_top_2.png" width="896" height="580">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<h3 id="tensor-subscript-mask-and-indexing-will-pin-devices">
  Tensor Subscript Mask and Indexing Will Pin Devices
  <a href="#tensor-subscript-mask-and-indexing-will-pin-devices">#</a>
</h3>
<p>Unlike their more explicit counterparts (<code>masked_select</code> and <code>index_select</code>), using tensor subscripting will pin the mask or indexes to the tracing device:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>X</span><span>[</span><span>X</span> <span>&gt;</span> <span>1</span><span>]</span></code></pre></div>
<p>Generates this TorchScript:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>torch</span><span>.</span><span>to</span><span>(</span><span>torch</span><span>.</span><span>gt</span><span>(</span><span>X</span><span>,</span> <span>1</span><span>),</span> <span>dtype</span><span>=</span><span>11</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>,</span> <span>non_blocking</span><span>=</span><span>False</span><span>,</span> <span>copy</span><span>=</span><span>False</span><span>,</span> <span>memory_format</span><span>=</span><span>None</span><span>)</span>
  <span>_1</span> <span>=</span> <span>annotate</span><span>(</span><span>List</span><span>[</span><span>Optional</span><span>[</span><span>Tensor</span><span>]],</span> <span>[</span><span>_0</span><span>])</span>
  <span>return</span> <span>torch</span><span>.</span><span>index</span><span>(</span><span>X</span><span>,</span> <span>_1</span><span>)</span></code></pre></div>
<!-- raw HTML omitted -->
<p>Whereas:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>X</span><span>.</span><span>masked_select</span><span>(</span><span>X</span> <span>&gt;</span> <span>1</span><span>)</span></code></pre></div>
<p>Generates this TorchScript:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>torch</span><span>.</span><span>masked_select</span><span>(</span><span>X</span><span>,</span> <span>torch</span><span>.</span><span>gt</span><span>(</span><span>X</span><span>,</span> <span>1</span><span>))</span>
  <span>return</span> <span>_0</span></code></pre></div>
<!-- raw HTML omitted -->
<p>The same pattern holds for <code>tensor[indexes]</code> and <code>tensor.index_select(0, indexes)</code>. This device pinning carries the same performance and portability risks as noted above.</p>
<blockquote>
  <p><strong>Replace Tensor Subscripting With <code>masked_select</code> and <code>indexed_select</code></strong></p>
<p>Subscript-based masking and indexing will always pin the tracing device into generated TorchScript. :(</p>

</blockquote>

<h2 id="direct-graph-modification">
  Direct Graph Modification
  <a href="#direct-graph-modification">#</a>
</h2>
<p>Once weâ€™ve used <code>torch.jit.script</code> or <code>torch.jit.trace</code> to generate a ScriptModule or ScriptFunction we can use <code>.graph</code>, <code>.inlined_graph</code> or <code>.code</code> to understand exactly what TorchScript has been generated. Though it has an entirely undocumented interface it is possible (and fun) to access and modify the generated TorchScript AST directly via the <code>.graph</code> method.</p>
<p>The most useful parts of the API are defined in <a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/python/python_ir.cpp">torch/csrc/jit/python/python_ir.cpp</a>. As you can see, all the basic functionality is present for finding and changing the graph nodes you want. If you change nodes or arguments and then persist the module your subsequent TorchScript load and inference will reflect your changes, though modules cannot be changed recursively in this way (<code>torch.jit.freeze</code> can be useful here).</p>
<p>An example of the kind of graph modification that is possible:</p>
<div><pre><code data-lang="python"><span>def</span> <span>undevice</span><span>(</span><span>tsc</span><span>):</span>
    <span># use ::to variant which does not hardcode device</span>
    <span>for</span> <span>to_node</span> <span>in</span> <span>tsc</span><span>.</span><span>graph</span><span>.</span><span>findAllNodes</span><span>(</span><span>'aten::to'</span><span>):</span>
        <span>i</span><span>,</span> <span>dtype</span><span>,</span> <span>layout</span><span>,</span> <span>device</span><span>,</span> <span>pin_mem</span><span>,</span> <span>non_blocking</span><span>,</span> <span>copy</span><span>,</span> <span>mem_format</span> <span>=</span> <span>list</span><span>(</span><span>to_node</span><span>.</span><span>inputs</span><span>())</span>
        <span>to_node</span><span>.</span><span>removeAllInputs</span><span>()</span>
        <span>for</span> <span>a</span> <span>in</span> <span>[</span><span>i</span><span>,</span> <span>dtype</span><span>,</span> <span>non_blocking</span><span>,</span> <span>copy</span><span>,</span> <span>mem_format</span><span>]:</span>
            <span>to_node</span><span>.</span><span>addInput</span><span>(</span><span>a</span><span>)</span>

    <span>for</span> <span>constant</span> <span>in</span> <span>tsc</span><span>.</span><span>graph</span><span>.</span><span>findAllNodes</span><span>(</span><span>'prim::Constant'</span><span>):</span>
        <span>if</span> <span>not</span> <span>constant</span><span>.</span><span>hasUses</span><span>():</span>
            <span>constant</span><span>.</span><span>destroy</span><span>()</span></code></pre></div>
<p>The above code will modify a traced graph, changing <code>aten::to</code> to use an overload which doesnâ€™t change memory location.</p>
<p>But what is this really useful for? As an undocumented API youâ€™d be unwise to use this capability in a production pipeline unless you like maintenance coding. I would only recommend it for research, as in the above example which I used to understand and profile the transfer/synchronization behavior of tensor subscripting.</p>
<blockquote>
  <p><strong>Donâ€™t Bother With Direct Graph Modification</strong></p>
<p>For legitimate production use-cases you can almost always find a way to modify your model code to generate the TorchScript you want.</p>

</blockquote>

<h2 id="rewrite-for-onnxtensorrt-export">
  Rewrite for ONNX/TensorRT Export
  <a href="#rewrite-for-onnxtensorrt-export">#</a>
</h2>
<p>You can get some <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/#stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">awesome results with TensorRT</a> but exporting a model from Pytorch to TensorRT is far from a sure thing. The export path to ONNX and then to TensorRT can fail due to missing or incompatible operations at either step and this can be frustrating.</p>
<p>After the obligatory Google search, Iâ€™ve found a reasonable hail-mary approach is to rewrite your tensor processing code to avoid unsupported operators. I canâ€™t give general advice for this but let me show you an example of how this can be possible: <code>repeat_interleave</code>.</p>
<div><pre><code data-lang="python"><span>class</span> <span>RI</span><span>(</span><span>torch</span><span>.</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>,</span> <span>repeat</span><span>):</span>
        <span>return</span> <span>X</span><span>.</span><span>repeat_interleave</span><span>(</span><span>repeat</span><span>,</span> <span>dim</span><span>=</span><span>0</span><span>)</span>

<span>inputs</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>),</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>3</span><span>))</span>
<span>torch</span><span>.</span><span>onnx</span><span>.</span><span>export</span><span>(</span><span>RI</span><span>(),</span> <span>inputs</span><span>,</span> <span>'please_work.onnx'</span><span>,</span> <span>opset_version</span><span>=</span><span>11</span><span>)</span></code></pre></div>
<p>Doesnâ€™t work:</p>
<div><pre><code data-lang="bash">RuntimeError: Exporting the operator repeat_interleave to ONNX opset version <span>11</span> is not supported. Please open a bug to request ONNX <span>export</span> support <span>for</span> the missing operator.</code></pre></div>
<p>However, the behavior of <code>repeat_interleave</code> with a fixed <code>dim</code> argument can be replicated in a form that will export to ONNX â€¦</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/mastering-torchscript/">https://paulbridger.com/posts/mastering-torchscript/</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/mastering-torchscript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941642</guid>
            <pubDate>Fri, 30 Oct 2020 12:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MCS-48: The quest for 16-bit division on the 8-bit CPU which canâ€™t divide]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24941189">thread link</a>) | @noexani
<br/>
October 30, 2020 | http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/ | <a href="https://web.archive.org/web/*/http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4862">
	
	<!-- .entry-header -->

		<div>
		
<p>Recently while working on my <a href="http://tech.mattmillman.com/projects/an-intel-mcs-48-based-dual-temperature-sensor/">MCS-48 temperature sensor</a> project I had to confront one of the largest challenges, which is to implement an option where changing a jumper displayed Fahrenheit instead of Celsius. The output from the DS18B10 temperature sensors is Celsius only, as it should be, so a conversion would need to be performed.</p>



<figure><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/CodeCogsEqn.gif" alt=""><figcaption>A quick reminder of the conversion needed to be performed</figcaption></figure>



<p>In my case itâ€™s +320 as Iâ€™m using fixed point arithmetic i.e. 15.3Â° = 153. This is a tough conversion to perform on an MCS-48 as a slew of different operations are required:</p>



<ul><li>16-bit negate (more about that below)</li><li>16-bit unsigned multiply</li><li>16-bit unsigned divide</li><li>16-bit add with wrap-around</li></ul>



<p>A tall order for a CPU which has just <em>one </em>math instruction: 8-bit add. To perform all of this, one must sling a long sequence of primitive instructions together. Since this is an assembly language only architecture, I couldnâ€™t cheat by compiling it in C and pinching the resulting instructions as I have done for PIC16 in the past.</p>



<p><em>Edit: Since publishing this a cornucopia of different approaches to this problem have been proposed to me. Iâ€™m happy with implementation as it currently stands. It works, it makes very efficient use of program memory, the improved performance is not required, and the above math routines are re-used for other tasks in the project.</em></p>



<p>The best place to find such examples is in the MCS-48 assembly language manual:</p>



<figure><a href="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual.jpg"><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-800x638.jpg" alt="" srcset="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-800x638.jpg 800w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-300x239.jpg 300w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-150x120.jpg 150w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-768x612.jpg 768w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-1536x1224.jpg 1536w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-2048x1633.jpg 2048w" sizes="(max-width: 800px) 100vw, 800px"></a></figure>



<p>(A scan of it can be viewed <a href="http://www.nj7p.org/Manuals/PDFs/Intel/9800255D.pdf">here</a>). Everything I needed was in there, except how to divide. There is no mention whatsoever in that manual of how to perform any kind of division operation, <em>but</em>, tacked in the back of the 1980 edition MCS-48 handbook, I found this:</p>



<figure><a href="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv.png"><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-623x800.png" alt="" srcset="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-623x800.png 623w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-233x300.png 233w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-117x150.png 117w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-768x987.png 768w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-1195x1536.png 1195w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv.png 1263w" sizes="(max-width: 623px) 100vw, 623px"></a><figcaption>Woohoo! A working divide routine for MCS-48. It wouldnâ€™t OCR, so I typed it up.</figcaption></figure>



<p>Unfortunately that routine only has an 8-bit quotient, which isnâ€™t much use for my application because it would overflow in most cases.</p>



<p>I was easily able to work around that with the following implementation (pseudo code):</p>



<pre><code>if (celsius &lt; 0)
{   // If negative, note it, and make it positive
    // so we can work with simpler unsigned routines below
    celsius = -celsius;
    is_negative = 1;
}

fahrenheit = multiply_16x8r16(celsius, 9);

// Divide by 50 so the result of divide_16x8r8 doesn't overflow
fahrenheit = divide_16x8r8(fahrenheit, 50, &amp;remainder);

// Multiply it back up
fahrenheit = multiply_16x8r16(fahrenheit, 10);

// Factor remainder
remainder = multiply_16x8r16(remainder, 10);

// Divide and add remainder
fahrenheit += divide_16x8r8(remainder, 50, NULL);

if (is_negative)
{   // Make it negative again, if it was previously
    is_negative = 1;
}

// Add 32. Requires a 16-bit add with wrap around to
// correctly handle negative temperatures
fahrenheit += 320</code></pre>



<p>While that does the job, itâ€™s poo poo. What I really want is that complicated looking divide routine to have a 16-bit quotient, so I can do the division in a single operation. To help me understand it, I translated it to C code:</p>



<pre><code>uint8_t mcs48_divide(uint16_t dividend, uint8_t divisor, uint8_t *remainder)
{
    if ((dividend &gt;&gt; 8) &gt;= divisor)
        goto mcs48_div_exit; // Impossible. Result would
                             // overflow. Bail.

    for (int i = 0; i &lt; 8; i++) // One pass for each bit of result
    {
        uint8_t msb;
        uint8_t bit15_was_set = 0;

        if (dividend &amp; 0x8000)
            bit15_was_set = 1; // Note if this was set,

        dividend &lt;&lt;= 1; // Next bit

        msb = (dividend &gt;&gt; 8);
        if (msb &gt;= divisor || bit15_was_set)
        {
            // Subtract remainder from MSB,
            // preserve and increment quotient
            dividend = (((msb - divisor) &lt;&lt; 8) | (dividend &amp; 0xFF)) + 1;
        }
    }

mcs48_div_exit:
    *remainder = (dividend &gt;&gt; 8);
    return (dividend &amp; 0xFF);
}</code></pre>



<p>Itâ€™s immediately clear that itâ€™s a <a href="https://www.wikihow.com/Divide-Binary-Numbers">binary division</a> implementation. What wasnâ€™t immediately clear is how to make the change I wanted. I put the question to <a href="https://stackoverflow.com/questions/64544654/can-anyone-figure-out-how-to-extend-this-software-divide-routine-to-have-a-16-bi/64549557#64549557">stack overflow</a>, and on the face of it, it looked like a dumb question, i.e. just double the integer type sizes, <em>stupid</em>. predictably I got punished with a bunch of down-votes.</p>



<p>Yes we can do that, but itâ€™s not what I want to do to the assembly routine that Iâ€™m trying to modify, so perhaps I didnâ€™t quite ask the question as well as I could have done. The answer provided sent me in the right direction, in that the working accumulator needs to be larger, 24-bits in my case, and the 16-bit shift needs to be a 24-bit.</p>



<pre><code>uint16_t mcs48_div16(uint16_t dividend, uint8_t divisor, uint8_t *remainder)
{
    uint32_t accumulator = dividend;

    for (int i = 0; i &lt; 16; i++) // One pass for each bit of result
    {
        uint8_t msb;
        uint8_t bit24_was_set = 0;

        if (accumulator &amp; 0x800000)
            bit24_was_set = 1; // Note if this was set,
                               // can't check if after shift.

        accumulator &lt;&lt;= 1; // Next bit
        accumulator &amp;= 0xFFFFFF; // Simulate 24 bit type

        msb = (accumulator &gt;&gt; 16);
        if (msb &gt;= divisor || bit24_was_set)
        {
            // Subtract remainder from MSB,
            // preserve and increment quotient
            accumulator = (((msb - divisor) &lt;&lt; 16) | (accumulator &amp; 0xFFFF)) + 1;
        }
    }

mcs48_div_ext_exit:
    *remainder = (accumulator &gt;&gt; 16);
    return (accumulator &amp; 0xFFFF);
}</code></pre>



<p>Above is the pseudo code of my routine after the changes. In the final implementation registers A, R1 and R2 hold the 24-bit accumulator, so this doesnâ€™t translate too well to C because there isnâ€™t a 24-bit integer type.</p>



<p>The final changes to the routine can be viewed <a href="https://github.com/inaxeon/mcs48temp/compare/e006467..a531d32">here</a>.</p>



<p>Ah, thatâ€™s better.</p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941189</guid>
            <pubDate>Fri, 30 Oct 2020 11:39:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Awk: `Begin { ` Part 1]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 96 (<a href="https://news.ycombinator.com/item?id=24940661">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://jemma.dev/blog/awk-part-1 | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/awk-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, I was watching Bryan Cantrillâ€™s 2018 talk, <a href="https://www.youtube.com/watch?v=2wZ1pCpJUIM">Rust, and Other Interesting Things</a>, and he made an offhanded comment while discussing values of different programming languages and communities. He said, â€œIf you get the <a href="https://www.gnu.org/software/gawk/manual/gawk.html">awk programming language manual</a>â€¦youâ€™ll read it in about two hours and then youâ€™re done. Thatâ€™s it. You know all of awk.â€</p>

<p>Only two hours to learn an entire language?! â€¦. Challenge accepted!</p>

<p>I had previously used snippets of awk here and there. Most of them were given to me by Stack Overflow answers when googling for niche data file manipulations. But, I did not know enough to successfully write an awk program from scratch. I definitely did not have a real grasp on the language nor its power. And, a couple of hours sounded like a relatively small time investment to learn what Bryan Cantrill said was a language he used three times a day.</p>

<p>It turns out it takes more than two hours to learn awk, and I am by no means an expertâ€¦ yet (growth mindset!). But, I now know enough to write a little about the essentials. Here goes!</p>

<h3 id="what-is-awk-useful-for">What is awk useful for?</h3>

<p>Awk is useful for data file manipulation. Already, having used it for a few days only, I wish I had invested time in learning it earlier. My usual workflow when encountering a data file is to import it into Google Sheets and use their builtin functions. If those werenâ€™t enough, I would write little code snippets to somewhat awk..wardly get the information I want. Awk is way more powerful than what I was doing before. Letâ€™s take a look:</p>

<h3 id="running-awk-programs">Running awk programs</h3>

<p>If weâ€™re going to learn awk, we need to know how to run an awk program. The syntax to run an awk program in a shell is:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'awk_program_contents'</span> data-file-1 data-file-2
</code></pre></div></div>
<p>We can also write a longer awk program to run instead of writing the awk code inline. We could write a file with awk codeand then pass inline to awk with <code>-f &lt;awk-program-filename&gt;</code></p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>-f</span> awk-program.awk data-file-1 data-file-2
</code></pre></div></div>

<h3 id="awk-program-contents">awk program contents</h3>

<p>Well, what is an awk program? We know it is best used for simple data reformatting or manipulation. The way it does this is by performing different actions on different patterns within a data file. The basic syntax of an awk program depends on these pattern and actions.</p>

<div><div><pre><code>pattern <span>{</span> action <span>}</span>
pattern <span>{</span> action <span>}</span>
...
</code></pre></div></div>

<p>We can give as many <code>pattern { action }</code> pairs as we want. Each pair will be executed independently of the others. This means if a line matches more than one pattern, it will have more than one corresponding action. In the example above we use newlines to separate distinct pairs. Similar to bash, we can also use <code>;</code> to separate commands and put everything on one line: <code>pattern { action }; pattern { action }</code></p>

<h3 id="awk-with-data-files">awk with data files</h3>

<p>But, it turns out awk is much more useful (and fun!) with a data file. The UN has a few <a href="https://data.un.org/">publicly available datasets</a>. I picked <a href="https://data.un.org/_Docs/SYB/CSV/SYB62_309_201906_Education.csv">this one</a> on education at the primary, secondary and tertiary levels to delve into first.</p>

<p>Letâ€™s start by using awk to get a sense of what the data looks like.  <code>NR</code> is a predefined variable which records the number of rows read in a file so far. We can use it to look at the first few lines of a program. In this case, our pattern will be <code>NR &lt;= 5</code>, and by not including an action, the implied action will be <code>print</code>:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &lt;= 5'</span> education.csv
T07,<span>"Enrolment in primary, secondary and tertiary education levels"</span>,,,,,
Region/Country/Area,,Year,Series,Value,Footnotes,Source
1,<span>"Total, all countries or areas"</span>,2005,Students enrolled <span>in </span>primary education <span>(</span>thousands<span>)</span>,<span>"678,991.6070"</span>,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
1,<span>"Total, all countries or areas"</span>,2005,Gross enrollement ratio - Primary <span>(</span>male<span>)</span>,104.9360,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
1,<span>"Total, all countries or areas"</span>,2005,Gross enrollment ratio - Primary <span>(</span>female<span>)</span>,99.9214,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
</code></pre></div></div>
<p>Okay, so looks like this is giving us a bit of information about our file. Notably:</p>
<ol>
  <li>There are two header rows: a title row, and a row telling us what the fields are</li>
  <li>The file is comma separated</li>
  <li>â€¦ except there are sometimes commas within double quoted strings: <code>"Total, all countries or areas"</code></li>
</ol>

<p>Letâ€™s address these one by one!</p>



<p>We can ignore the first two header rows by using our nifty <code>NR</code> moving forward. We can pattern match that <code>NR &gt; 2</code>. Note: awk is 1-indexed.</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &gt; 2'</span> education.csv
</code></pre></div></div>

<h3 id="field-separators">Field Separators</h3>

<p>awkâ€™s <a href="https://www.gnu.org/software/gawk/manual/gawk.html#Default-Field-Splitting">default field separator</a> is a space. We can actually see this by printing the first field. To access the value of a field, we use <code>$&lt;field_index&gt;</code>. So <code>$1</code> is the first field, <code>$2</code> the second, and so on. <code>$0</code> refers to the entire row.</p>

<p>If we try this:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &lt;= 5 { print $1 }'</span> education.csv
T07,<span>"Enrolment
Region/Country/Area,,Year,Series,Value,Footnotes,Source
1,"</span>Total,
1,<span>"Total,
1,"</span>Total,
</code></pre></div></div>
<p>we can confirm that weâ€™re splitting on spaces. awk has the option to specify a different field separator with the <code>-F 'separator'</code> flag:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>-F</span> <span>','</span> <span>'NR &lt;= 5 { print $1 }'</span> education.csv
T07
Region/Country/Area
1
1
1
</code></pre></div></div>

<p>Great! Butâ€¦. we had commas embedded within strings with double quotes. Sure enough, if we print the second field (<code>$2</code>), we see:</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>-F</span> <span>','</span> <span>'NR &lt;= 5 { print $2 }'</span> education.csv
<span>"Enrolment in primary

"</span>Total
<span>"Total
"</span>Total
</code></pre></div></div>

<p>Hmmm. What we want here is to split fields by <em>content</em>. Which awk does not have, but gawk (GNU awk) does: <a href="https://www.gnu.org/software/gawk/manual/gawk.html#Splitting-By-Content">FPAT</a>! From the gawk manual: â€œAll properly written awk programs should work with gawk. So most of the time, we donâ€™t distinguish between gawk and other awk implementations.â€</p>

<p>Sounds like we can use gawk here instead then. Letâ€™s try pattern matching. Iâ€™m not going to go into regex here, but the pattern we want, defined by <code>"[^,]*|\"[^\"]+\""</code> is anything that either starts with a non-comma character, or starts with a double quote, contains only non-quote characters, and ends with a double quote:</p>

<div><div><pre><code><span>$ </span>gawk <span>'BEGIN { FPAT = "[^,]*|\"[^\"]+\"" } NR &lt;= 5 { print $2 }'</span> education.csv
<span>"Enrolment in primary, secondary and tertiary education levels"</span>

<span>"Total, all countries or areas"</span>
<span>"Total, all countries or areas"</span>
<span>"Total, all countries or areas"</span>
</code></pre></div></div>

<p>I snuck a <code>BEGIN</code> in there without explaining it. Letâ€™s go on a brief tangentâ€¦</p>

<h3 id="begin--tangent-">BEGIN { tangent }</h3>

<p>Beyond the pattern and actions, awk also has a concept of <code>BEGIN</code> and <code>END</code> blocks. The <code>BEGIN</code> is executed before any of the data is processed. It can be useful for declaring variables or printing text to appear at the beginning. Analogously, the <code>END</code> is executed after the data is processed. It can be useful for performing manipulations on aggregates of the data, like averaging a sum.</p>

<p>This means if we wanted to write a little â€œHello, awk!â€ program, we could do it without even needing a data file.</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>'BEGIN { print "Hello, awk!" }'</span>
Hello, <span>awk</span><span>!</span>
</code></pre></div></div>

<h3 id="end--tangent-">END { tangent }</h3>

<p>â€¦back to our example. In our case, we used a <code>BEGIN</code> block to declare the <code>FPAT</code> <em>before</em> reading our data file.</p>

<p>But, weâ€™ve only looked at the first 5 lines. For all we know, the rest of the file could look completely different. Letâ€™s use <code>NR</code> again to see some more of the file. First, letâ€™s figure out how long the file is. We can use the <code>END</code> block here. After weâ€™ve parsed the whole file, we can see what the value of <code>NR</code> is, and thatâ€™ll tell us how many lines it is:</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>'END { print NR }'</span> education.csv
8630
</code></pre></div></div>

<p>Okay, so maybe if we print every 500 lines, weâ€™ll get a sense of what data weâ€™re looking at. We can set our pattern to be only if <code>NR</code> is a multiple of <code>500</code>:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR % 500 == 0'</span> education.csv
</code></pre></div></div>

<p>â€¦ and Iâ€™m going to leave this blog post on a real cliff hanger. Mostly because it already feels too long! Thereâ€™s <a href="https://jemma.dev/blog/awk-part-2">a second post</a> about awk actually looking at the data and manipulating it to figure out which countries have stark differences in number of males and females that they educate.</p>

<h3 id="tldr-or-tlskimmed-far-enough-to-get-here-please-give-me-the-shorter-version">TL;DR or TL;Skimmed far enough to get here, please give me the shorter version:</h3>
<p>To rehash what weâ€™ve learned about awk:</p>
<ul>
  <li>awk is run using <code>awk 'awk_program' data-file</code></li>
  <li>awk programs have the form <code>pattern { action }; pattern { action };</code></li>
  <li><code>BEGIN</code> blocks are executed before reading data files</li>
  <li><code>END</code> blocks are executed after reading data files</li>
  <li><code>NR</code> is a variable that tells us the number of rows read</li>
  <li><code>-F '&lt;separator&gt;'</code> is how we can define a field separator for a file</li>
  <li>Space is the default field separator</li>
  <li><code>FPAT="..."</code> is a way to use regex to define a pattern for each field</li>
  <li><code>FPAT</code> is only defined in gawk</li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/awk-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940661</guid>
            <pubDate>Fri, 30 Oct 2020 09:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Backtest Trading Strategies: A Quantopian Alternative]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24940644">thread link</a>) | @hydershykh
<br/>
October 30, 2020 | https://www.tradytics.com/backtester | <a href="https://web.archive.org/web/*/https://www.tradytics.com/backtester">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div>
          <p>
            <h4>Trading Strategies Backtester</h4>
            <h5>Backtest your favorite technical analysis based strategies with our backtester.</h5>
          </p>
          
        </div>

        <div>
          

          <div>
            <div>
              <p>
                <h5>Buy Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonBuy">
                    <p onclick="make_current_ta('RSI')">RSI</p>
                    <p onclick="make_current_ta('CCI')">CCI</p>
                    <p onclick="make_current_ta('MFI')">MFI</p>
                    <p onclick="make_current_ta('MACD')">MACD</p>
                    <p onclick="make_current_ta('ATR')">ATR</p>
                    <p onclick="make_current_ta('ADX')">ADX</p>
                    <p onclick="make_current_ta('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremade">
                    <p onclick="make_current_strategy('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy('lband < Price')">LowerBollinger &lt; Price</p>
                    <!--<p class="dropdown-item" onclick="make_current_strategy('At Support')">At Support</p>
                    <p class="dropdown-item" onclick="make_current_strategy('At Resistance')">At Resistance</p>-->
                  </div>
                </div>
                </div>
            </div>
          </div>



          <div>
            <div>
              <p>
                <h5>Sell Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonSell">
                    <p onclick="make_current_ta_sell('RSI')">RSI</p>
                    <p onclick="make_current_ta_sell('CCI')">CCI</p>
                    <p onclick="make_current_ta_sell('MFI')">MFI</p>
                    <p onclick="make_current_ta_sell('MACD')">MACD</p>
                    <p onclick="make_current_ta_sell('ATR')">ATR</p>
                    <p onclick="make_current_ta_sell('ADX')">ADX</p>
                    <p onclick="make_current_ta_sell('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremadeSell">
                    <p onclick="make_current_strategy_sell('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy_sell('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy_sell('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy_sell('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy_sell('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy_sell('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy_sell('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy_sell('lband < Price')">LowerBollinger &lt; Price</p>
                  </div>
                </div>
                </div>
            </div>
          </div>
          
          
        </div> <!-- row -->


         <!-- row -->

         <!-- row -->

         <!-- row -->

        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="activity"></i> Win Rate</h6>
                </p>
                <p>Win rate of this strategy.</p>
                
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="corner-right-down"></i> Biggest Drawdown</h6>
                </p>
                <p>Highest loss incurred in a trade.</p>
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="navigation-2"></i> Biggest Win</h6>
                </p>
                <p>Highest profit gained in a trade.</p>
                
              </div>
            </div>
          </div>
        </div> <!-- row -->


        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-up"></i> Long Only</h6>
                </p>
                <p>Profits and losses from long positions.</p>
                
              </div> 
            </div>
          </div>

          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-down"></i> Short Only</h6>
                </p>
                <p>Profits and losses from short positions.</p>
                
              </div> 
            </div>
          </div>
        </div> <!-- row -->

        
        

      </div></div>]]>
            </description>
            <link>https://www.tradytics.com/backtester</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940644</guid>
            <pubDate>Fri, 30 Oct 2020 09:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Nailing Your First Launch by Adam Wathan]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940629">thread link</a>) | @reconquestio
<br/>
October 30, 2020 | https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Iâ€™ve just watched the talk Â«Nailing Your First LaunchÂ» (MicroConf Starter 2018) by Adam Wathan and I
took notes that Iâ€™d like to share and re-visit them in the future. Some of them are just text from his screens, some thoughts are mine.</p>
<p>But donâ€™t let me steal the video from you by providing a digested summary.
In my humble opinion, the main idea of watching talks or reading something is to change your mind
model of seeing this topic.
Donâ€™t hesitate and start watching the video before proceeding to notes.
The notes are here just to come back from time to time and re-call some especially useful highlights.</p>
<p><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">https://www.youtube.com/watch?v=ajrDxZRpP9M</a></p>
<hr>

<h3 id="one-time-purchase-products-are-way-easier-to-sell">One-time purchase products are way easier to sell</h3>
<ul>
<li>Harder to convince people that for $9 dollars per month theyâ€™d have value.</li>
<li>But itâ€™s a very frequent case when people buy $100 courses and donâ€™t even watch them.</li>
<li>One-time payments are much easier to go away with.</li>
</ul>
<h3 id="they-can-be-done">They can be â€œdoneâ€</h3>
<ul>
<li>You donâ€™t have to maintain them forever.</li>
<li>A course can be finished. A book can be finished.</li>
</ul>
<h3 id="you-can-put-one-together-in-3-months-of-nights-and-weekends">You can put one together in 3 months of nights and weekends</h3>
<ul>
<li>Easier to plan.</li>
</ul>
<h3 id="they-put-money-in-the-bank-fast-then-drop-off-opposite-to-saas">They put money in the bank fast then drop off (opposite to SAAS)</h3>
<ul>
<li>One-time projects do have a more clear cliff of death, but they produce more money than saas during
launch days.</li>
</ul>
<hr>

<h3 id="building-an-audience">Building an audience</h3>
<ul>
<li>
<p>Having a big audience can compensate for almost any mistake made in marketing/sales.</p>
</li>
<li>
<p>Huge audience + bad sales plan produces way more profit than no audience + good sales plan.</p>
</li>
<li>
<p>Produce blog posts, tutorials, podcasts, screencasts, interview people</p>
</li>
<li>
<p>You should be worth following (provide a value for your audience)</p>
</li>
<li>
<p>Help people where they already are (Wes Bos)</p>
</li>
<li>
<p>Specific tactics for tech guys: tweet your hacks (like some tricks with css) that save you time.</p>
</li>
</ul>
<h3 id="picking-the-right-idea">Picking the right idea</h3>
<ul>
<li>Have an idea
<ul>
<li>what are you already putting out there that peoeple seem excited about?</li>
<li>what are you excited about that you think others will get excited about?</li>
<li>what do people think youâ€™re better at than they are?</li>
<li>what have you learned outside your community would benefit from?</li>
<li>what did you have to figure out yourself but was really helpful to learn?</li>
</ul>
</li>
<li>Test it
<ul>
<li>
<p>Â«First thing to do is to put a landing page and start emailing.Â»</p>
<p>Itâ€™s not a bad way, but itâ€™s not the first thing that you should do.
Especially it doesnâ€™t work if you have no audience. People wouldnâ€™t trust you.</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Collect feedback from tweets, have a catalog of them. Can be used later for your landing/sales pages.</p>
</blockquote>
<h3 id="define-the-product">Define the product</h3>
<ul>
<li>Plan small, it will end up bigger than you think anyway
<ul>
<li>Donâ€™t worry about size. A short book is still a book.</li>
<li>3 hours of a video course is plenty.</li>
<li>Actually, not everyone is looking for a full knowledge base on a specific topic and read
500 pages on that. Collection of great ideas (like tweets) on that specific topic works
too.</li>
</ul>
</li>
</ul>
<blockquote>
<p>In general, courses are easier to sell at higher prices because people expect products such as
books to be in a specific cost range, even if they understand that it brings a high value.</p>
</blockquote>
<h3 id="landing-page">Landing page</h3>
<p>The goal is to collect e-mail addresses.</p>
<p>Example of Adamâ€™s landing page can be seen on 19:33 - 22:25</p>
<ul>
<li>Promise something in advance (sign up for free screencasts and a big discount)</li>
<li>You can put your catalog of feedback on your landing page to earn more trust.</li>
</ul>
<h3 id="pre-sell">Pre-sell</h3>
<h4 id="advantages">Advantages</h4>
<ul>
<li>Best form of product validation</li>
<li>Youâ€™ll make more money</li>
<li>More motivation to finish</li>
<li>Can buy you the time to focus on the product</li>
</ul>
<h4 id="disadvantages">Disadvantages</h4>
<ul>
<li>Selling multiple tiers is trickier</li>
<li>Canâ€™t easily change scope</li>
<li>Like taking on debt, can be extremely stressful. People paid you 50k$ and you have to return
it as the value in N months. (impostor syndrome?)</li>
</ul>
<h3 id="building-your-email-list">Building Your Email List</h3>
<ul>
<li>Always tell your audience.</li>
</ul>
<blockquote>
<p>Announce the announcement â€” Â«about to announce the next big project Iâ€™m working on; if you check
it out and are excited about it, Iâ€™d love any help spreading the word!Â»</p>
</blockquote>
<ul>
<li>Share progress. Send an update every week or so.</li>
<li>Repurpose content (Take a chapter from a book, make it a blog post and share it)</li>
</ul>
<h3 id="getting-it-finished">Getting it finished</h3>
<p>A few strategies to finally finish it:</p>
<ul>
<li>Make promises (Â«this week Iâ€™m going to deliver a screencastÂ»)</li>
<li>Email on a schedule</li>
<li>Reduce scope. (the project/book gets bigger and bigger, the best way to cross the finish line</li>
</ul>
<h3 id="figuring-pricing">Figuring pricing</h3>
<ul>
<li>Itâ€™s hard to sell tiers during pre-sales.</li>
<li>Sell pre-orders with top tier price.</li>
</ul>
<h4 id="single-tier">Single tier</h4>
<ul>
<li>Can be fine if you can charge enough</li>
<li>Often necessary if pre-selling</li>
<li>Nice if you canâ€™t figure out a way to add additional tiers that actually feel valuable</li>
<li>In general, prefer multiple tiers</li>
</ul>
<h4 id="two-tiers">Two tiers</h4>
<ul>
<li>Usually a price anchoring strategy, first tier makes second tier look like better deal</li>
<li>Second tier is usually the â€œrealâ€ product</li>
<li>Prices are often close-ish, maybe 1x and 1.5x</li>
<li>Works well with video courses where easy to cut content for budget version</li>
</ul>
<h4 id="three-tiers">Three tiers:</h4>
<ul>
<li>Great for books if you can come up with the bonus content (videos?)</li>
<li>Makes it easier to evaluate as its own product instead of compring to Amazon book prices</li>
<li>Prices are usually 1x, ~2x, ~5x</li>
<li>This will make you a lot more money from a book than just selling the book on its own</li>
</ul>
<blockquote>
<p><strong>Adamâ€™s case</strong></p>
<ul>
<li>First tier: The Bare Essentials, $39
<ul>
<li>The 158-page book in pdf format</li>
<li>Comprehensive set of exercises</li>
</ul>
</li>
<li>Second tier: The Premium Training Package, $79
<ul>
<li>Over 4 hours of screencasts, covering all of the book examples</li>
<li>Three additional advanced tutorials</li>
</ul>
<ul>
<li>all from first tier</li>
</ul>
</li>
<li>Third tier: The complete Reference Package, $179
<ul>
<li>The source code of Nitpick CI, a production Laravel application that makes heavy
use of collection pipelines</li>
</ul>
<ul>
<li>all from second tier</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="launch-discounts">Launch discounts</h3>
<ul>
<li>Discount it by enough to be appealing, at least 30%</li>
<li>Use stepped discounts; lower discount on cheaper tiers and better discount on higher tiers</li>
<li>Reverse engineer non-discounted price from your planned discounted price, itâ€™ll help you charge more</li>
</ul>
<h3 id="nailing-the-launch">Nailing the launch</h3>
<ul>
<li>
<p>Build the sales page 39:13</p>
<ul>
<li>Still include an email sign up that sends preview content for new traffic (sign up to get
four free preview lessons)</li>
<li>Testimonials and social proof are important; use feedback from preview content to start</li>
<li>Sort tiers from highest price to lower price, use visuals to communicate value of higher
tiers (ui/ux hacks, make more important text bold, more physical things on a picture)</li>
</ul>
</li>
<li>
<p>Announce the launch details</p>
<ul>
<li>Include all package and pricing details</li>
<li>Complete TOC or content list</li>
<li>Final free content preview if possible</li>
</ul>
</li>
<li>
<p>Launch it</p>
<ul>
<li>Easiest part. Send an email â€” â€œxxx is now available!â€, include discount</li>
<li>Launch on tuesday, no evidence, but it seems at least as good as any other day for Adam</li>
<li>Morning EST works well too</li>
</ul>
</li>
<li>
<p>Leverage early feedback</p>
<ul>
<li>Collect and catalog feedback after the launch.</li>
<li>Send new reviews to other people who hasnâ€™t bought the course/book yet. Send them preview
of another chapter.</li>
</ul>
</li>
<li>
<p>Closing the launch</p>
<ul>
<li>Close the discount. Announce closing it. (â€œHey, this is the last week of the launchâ€)</li>
<li>But donâ€™t specify a closing date in advance</li>
</ul>
</li>
</ul>
<hr>
<h3 id="links">Links</h3>
<ul>
<li><a href="https://gist.github.com/adamwathan/30dc4230ac575cfa3425b39ca11ea859">Gist with useful links by Adam</a></li>
<li><a href="https://twitter.com/adamwathan">Twitter: @adamwathan</a></li>
<li><a href="https://adamwathan.me/">Blog: adamwathan.me</a></li>
<li><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">Talk on youtube</a></li>
</ul>
<p>
    Follow me on Twitter:
    <a target="_blank" href="https://twitter.com/reconquestio">@reconquestio</a>
    </p>

    <hr>
    <b>Comments</b>
    
    
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940629</guid>
            <pubDate>Fri, 30 Oct 2020 09:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka nightmare replication issues on FreeBSD (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940623">thread link</a>) | @letientai299
<br/>
October 30, 2020 | https://stacksoft.io/blog/kafka-troubles/ | <a href="https://web.archive.org/web/*/https://stacksoft.io/blog/kafka-troubles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        <div>
		  

<p>I recently created a tool for a client to export some data from a Kafka topic and after waiting about 10 minutes for it to export, the program returned a rather bizarre error:</p>

<pre><code>kafka: error while consuming telemetry/0: kafka server: Message contents does not match its CRC.

</code></pre>

<p>Intuition gave me a bad feeling about that error, but I was not prepared for what was going to come next. I decide to look up the error quickly and the error indicated that the CRC calculated by the consumer was not matching the message header. Huh, what was going on here?</p>

<p>Before I dive into this article, itâ€™s helpful to learn a little bit about the software that was being run when we started running into this problem. We had 3 VMs on an Azure cluster that were running FreeBSD. The producers were using <a href="https://github.com/Shopify/sarama">https://github.com/Shopify/sarama</a> and the consumers were using <a href="https://github.com/bsm/sarama-cluster">https://github.com/bsm/sarama-cluster</a></p>

<p>Whatâ€™s also interesting is, no matter how many machines we might have had in the cluster (if they were all FreeBSD), we most likely would have experienced failure across the board. This wasnâ€™t really great since the entire point of replicating the cluster across N machines was to prevent complete system failure. In this case, it really wouldnâ€™t have helped us. A tear falls down my cheek for failed distributed programming promises.</p>

<table>
<thead>
<tr>
<th>Software</th>
<th>Version</th>
</tr>
</thead>

<tbody>
<tr>
<td>FreeBSD</td>
<td>11.0-RELEASE-p8</td>
</tr>

<tr>
<td>ZFS</td>
<td>-</td>
</tr>

<tr>
<td>Kafka</td>
<td>0.10.2</td>
</tr>

<tr>
<td>Zookeeper</td>
<td>3.4.10</td>
</tr>

<tr>
<td>OpenJDK</td>
<td>1.8.0_121-b13</td>
</tr>

<tr>
<td>Sarama</td>
<td>5e8fd95863bd4a894fcd29225547d56967f189ad</td>
</tr>

<tr>
<td>Sarama-cluster</td>
<td>d98592677c0aa08d8aafb882d344fb461682b722</td>
</tr>
</tbody>
</table>

<p>A little bit after my export tool ran, I got a ping on Slack that one of the services that uses this Kafka topic was no longer working. I check the logs of that service, and sure enough, the same error:</p>

<pre><code>kafka: error while consuming topic/0: kafka server: Message contents does not match its CRC.

</code></pre>

<p>Because this was a live running service, my first thought was to use the power of Kafka to shift the offset by 1 for this particular consumer so we can skip this corrupt message and get everything running again quickly.</p>

<p><code>kafka-consumer-groups.sh</code> is a command line tool that letâ€™s you do exactly this, except it doesnâ€™t work on <code>kafka-0.10.2</code>. That was a little bit of a surprise to me, I assumed one of the coolest things about Kafka is that you can pick an offset to consume from. The libraries we were using also had no way to manually select an offset to start from.</p>

<p>Okay, crap, so I need to upgrade Kafka to shift the offsets. This is a good opportunity to get on <code>1.0.0</code> anyway and perhaps restarting the services will actually fix the problem. I update my Ansible scripts for <code>kafka 1.0.1</code> and start reading the upgrade guide for a live running environment: <a href="https://kafka.apache.org/documentation/#upgrade">https://kafka.apache.org/documentation/#upgrade</a>.</p>

<p>Great, weâ€™re on <code>1.0.1</code>, but the problem still exists. I have the ability to move the offet over, so I shift the offset by 1.</p>

<pre><code>./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group "api-consumer-group" --topic "telemetry:0" --reset-offsets --shift-by 1 --execute
</code></pre>

<p>I restart the service and the error comes up again. Darn. So itâ€™s not only one message that is corrupt, itâ€™s a range, thatâ€™s not great. I decided to commit to this strategy because this service needed to be up and running for a live demo in the coming week.</p>

<p>So instead, my idea was to shift the offset by a larger number until I find a number that actually works. Once I find a number that works, I can do a manual binary search to find the exact offset where the corruption started and shift it by 1.</p>

<p>After doing a manual binary search, I have found that the corrupted records are between <code>23769420-23772231</code> inclusive and corrupted, so good messages begin at <code>23772232</code> so 2811 corrupted messages. I run <code>./kafka-consumer-groups.sh</code> again, but this time I specify the exact offset to start from instead of using <code>shift-by</code></p>

<p>I restart the service again, and it works! Great, letâ€™s hope this monkey patch works until the live demo. Nope, the next day, the same message appears again.</p>

<p>At this point, Iâ€™ve had my fair share of complicated problems, and I have a deep gut instinct that itâ€™s most likely not the code weâ€™ve written because the problem started to appear on multiple other topics in the cluster and the problem was produced by multiple independent services.</p>

<p>Of course, the book Pragmatic Programmer still pops up in my head:</p>

<p><em>â€œselectâ€ Isnâ€™t Broken</em>:</p>

<blockquote>
<p>It is rare to find a bug in the OS or the compiler, or even a third-party product or library. The bug is most likely in the application.</p>
</blockquote>

<p>So I focus on starting from the application and then working outwards, I upgrade our libraries used in our code. I upgrade Sarama to <code>1.6.0</code> and I upgrade <code>sarama-cluster</code> to <code>master</code>. I run our deployment scripts and everything is running again.</p>

<p>I do the ridiculous offset binary-search trick again to shift everything and sure enough the issue comes up again with our Kafka libraries upgraded to the latest version. I decide to look at the logs of the broker themslelves and this is what I see;</p>

<pre><code>[2018-03-17 20:11:58,551] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition telemetry-0 to broker 3:org.apache.kafka.common.errors.CorruptRecordException: This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt. (kafka.server.ReplicaFetcherThread)
[2018-03-17 20:11:58,747] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition topic-2 to broker 2:org.apache.kafka.common.errors.CorruptRecordException: This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt. (kafka.server.ReplicaFetcherThread)
</code></pre>

<p>Looking at that error message, it appears that the replica thread inside of Kafka is running into exactly the same problem as our consumers. Uh oh, at this point I know itâ€™s definitely not our application code, so much for that Pragmatic Programmer tip, gut instinct all the way!</p>

<p>There is a Kafka tool to letâ€™s you see deeper into the health of your cluster <code>./kafka-topics.sh --zookeeper localhost:2181 --describe</code>. Hereâ€™s the output:</p>

<pre><code>Topic:telemetry PartitionCount:6 ReplicationFactor:3 Configs:
 Topic: telemetry Partition: 0 Leader: 2 Replicas: 2,1,3 Isr: 2
 Topic: telemetry Partition: 1 Leader: 3 Replicas: 3,2,1 Isr: 3
 Topic: telemetry Partition: 2 Leader: 1 Replicas: 1,3,2 Isr: 1
 Topic: telemetry Partition: 3 Leader: 2 Replicas: 2,3,1 Isr: 2
 Topic: telemetry Partition: 4 Leader: 3 Replicas: 3,1,2 Isr: 3
 Topic: telemetry Partition: 5 Leader: 1 Replicas: 1,2,3 Isr: 1
</code></pre>

<p>If you look at the <code>Isr</code> column, it stands for <code>In-Sync</code> replica. It appears that this cluster is not healthy because only the leader broker is in sync while all the other brokers cannot replicate that partition. Our goal here is to get that <code>Isr</code> column back to <code>1,2,3</code>.</p>

<p>So at this point, here are the options:</p>

<ul>
<li>- Hardware failure, such as disk failure, or network connectivity issues.</li>
<li>- The cluster is misbehaving because of resource allocation issues, perhaps itâ€™s going OOM, or weâ€™re out disk space.</li>
<li>- A bug with the Kafka version we were using</li>
<li>- An OpenJDK bug</li>
</ul>

<p>I decide to quickly look into our various servers to see if this is a resource allocation issue that is causing Kafka to misbehave. This was a red herring, one of the servers that was responsible for pushing to this topic actually filled its root partition and for a second I thought that might have been the issue, but that issue was fixed and the issue still remained.</p>

<p>The actual Kafka instances seemed to be fine, they were nowhere near capacity in terms of disk space, and the chances of having hardware failure across 3 machines was unlikely.</p>

<p>it gets a little confusing on what could be wrong and I start to realize that this is becoming a difficult problem and we have to get this live system working. I canâ€™t just adjust things at random and hope that the problem is fixed. Itâ€™s time to dig deeper, itâ€™s time to look at what Kafka is actually writing to disk.</p>

<h3 id="digging-deeper">Digging deeper</h3>

<p>Kafka writes the messages it receives into a log folder. The log folder contains a folder for each topic and partition combo. This is how it might look for this particular topic weâ€™re having issues with:</p>

<pre><code>.
|-- telemetry-0
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003859610.index
|   |-- 00000000000003859610.log
|   |-- 00000000000003859610.snapshot
|   |-- 00000000000003859610.timeindex
|   |-- 00000000000008551431.index
|   |-- 00000000000008551431.log
|   |-- 00000000000008551431.snapshot
|   |-- 00000000000008551431.timeindex
|   |-- 00000000000012458429.snapshot
|   `-- leader-epoch-checkpoint
|-- telemetry-1
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003854233.index
|   |-- 00000000000003854233.log
|   |-- 00000000000003854233.timeindex
|   |-- 00000000000008541867.index
|   |-- 00000000000008541867.log
|   |-- 00000000000008541867.timeindex
|   `-- leader-epoch-checkpoint
|-- telemetry-2
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003850719.index
|   |-- 00000000000003850719.log
|   |-- 00000000000003850719.timeindex
|   |-- 00000000000008543680.index
|   |-- 00000000000008543680.log
|   |-- 00000000000008543680.timeindex
|   `-- leader-epoch-checkpoint

</code></pre>

<p>The <code>.log</code> file is where the messages we push to Kafka are stored. Weâ€™re going to attempt to extract the offset that is corrupt to see what exactly is corrupt about it. If youâ€™re curious on learning about the internals of Kafka, check out this article, it was a lot simpler than I thought: <a href="https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026">https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026</a></p>

<p>Kafka provides a tool, <code>kafka.tools.DumpLogSegments</code> that lets you dive into these log files and grab more details about individual records that are in the file. Hilariously enough, when I ran this tool, it bails right when it hits a corrupt message.</p>

<pre><code>Excâ€¦</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stacksoft.io/blog/kafka-troubles/">https://stacksoft.io/blog/kafka-troubles/</a></em></p>]]>
            </description>
            <link>https://stacksoft.io/blog/kafka-troubles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940623</guid>
            <pubDate>Fri, 30 Oct 2020 09:45:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Concurrency â€“ Understanding the Basics of Threads]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940545">thread link</a>) | @turkogluc
<br/>
October 30, 2020 | https://turkogluc.com/java-concurrency-basics-of-threads/ | <a href="https://web.archive.org/web/*/https://turkogluc.com/java-concurrency-basics-of-threads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p>Java <code>Thread</code> objects allow us to run our code in separate threads. When an application starts JVM creates the initial thread named <code>main</code>. The main method is run on the main thread. Inside the application we can create new threads to execute other tasks in parallel with the main thread.</p><p>Java uses native operating system threads. So one java thread is mapped by one OS thread.</p><h3 id="creating-threads">Creating Threads</h3><p>The constructor of the <code>Thread</code> class takes a <code>Runnable</code> object. Runnable interface has an abstract <code>run</code> method which is called by <code>Thread#start()</code> method. It object can be instantiated by a lambda, anonymous class or a class which implements Runnable method. </p><figure><img src="https://turkogluc.com/content/images/2020/10/Screenshot-2020-10-29-at-20.03.52.png"></figure><p>Using lambdas are generally easier and more compact:</p><pre><code>Thread thread = new Thread(() -&gt; {
    // content of run command
});
thread.start();</code></pre><p>Thread lives as long as the its run hook method has not returned. The scheduler can suspend and run the Thread many times. For a thread to execute forever, it needs an infinite loop that prevents it from returning. </p><p><code>Join</code> method allows one thread to wait for the completion of another. This is a simple form of barrier synchronisation.</p><figure><img src="https://turkogluc.com/content/images/2020/10/Screenshot-2020-10-29-at-20.19.19.png"></figure><h3 id="java-thread-types-user-and-daemon-threads">Java Thread Types: User and Daemon Threads</h3><p>When JVM start it contains a single User thread, named Main thread. The main difference between User and Daemon threads are what happens when they exit.</p><ul><li>A user thread continues its lifecycle even if the main thread exits.</li><li>However all Daemon threads terminates when all the user threads exits.</li><li>JVM itself exits when all the user threads has exited.</li></ul><p>Thread class contains boolean <code>daemon</code> field to specify whether the thread is daemon. It can be set at the time of creation by the constructor or by setter method.</p><pre><code>Thread thread = new Thread(getRunnable());
thread.setDaemon(true);
thread.start();</code></pre><p>By default daemon field is false, so most of the Threads that we generate is a User Thread. Threads copy the <code>isDaemon</code> status of the parent threat if it is not specified. Java uses Daemon thread in some places such as <code>ForkJoinPool</code> and <code>Timer</code>. To illustrate we can use the following example:</p><pre><code>public class Main {

    public static void main(String[] args) throws InterruptedException, ExecutionException {
//        runDeamonThread();
        runUserThread();
        System.out.println(getCurrentThreadName() + " exits");
    }

    private static void runDeamonThread() throws ExecutionException, InterruptedException {
        ExecutorService executorService = Executors.newWorkStealingPool(10);
        executorService.execute(getRunnable());
    }

    private static void runUserThread() {
        Thread thread = new Thread(getRunnable());
        thread.start();
    }

    private static Runnable getRunnable() {
        return () -&gt; {
            for (int i = 0; i &lt;= 200; i++) {
                System.out.print(".");
                Thread.yield();
            }
            System.out.println(getCurrentThreadName() + " exits. isDeamon: " + isDaemon());
        };
    }

    private static boolean isDaemon() {
        return Thread.currentThread().isDaemon();
    }

    private static String getCurrentThreadName() {
        return Thread.currentThread().getName();
    }
}</code></pre><ul><li>When we invoke <code>runUserThread</code> method it show the following example output:</li></ul><pre><code>................................................
main exits
........................................................................................
Thread-0 exits. isDeamon: false</code></pre><ul><li>The second case is invoking the <code>runDeamonThread</code> which uses <code>ForkJoinPool</code> as an example of Daemon Threads. I could simply use <code>setDaemon(true)</code> method, but wanted to give an example usage. Output:</li></ul><pre><code>main exits</code></pre><p>So when the main method exits, all the user threads are terminated and JVM exits and kills all daemon threads, so that we did not even have a chance to see output from daemon threads.</p><h3 id="stopping-threads">Stopping Threads</h3><p>Compared to creating, stopping a thread is quite hard thing. Once thread starts running it diverges from the caller and it has it is own lifecycle anymore. It can either complete the task and exits or if it does a long running operation it can work forever. Java does not provides us a method (non-deprecated) to stop the thread voluntarily. </p><ol><li>A naive approach could be using a stop flag:</li></ol><pre><code>volatile boolean isStopped = false;

public void test() {
    new Thread(() -&gt; {
        while (!isStopped) {
            System.out.print(".");
        }
        System.out.println("Child Exits");
    }).start();

    try {
        Thread.sleep(100);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
    isStopped = true;
    System.out.println("Main exits");
}</code></pre><p>Note that the flag is <code>volatile</code> in order to make its up-to-date value visible for both threads. However this approach fails if the thread is doing blocking operations such as <code>sleep</code>, <code>wait</code>, <code>join</code> or blocking I/O operations.</p><p>2. Another way to stop the tread is to use <code>interrupt()</code> method of the thread. </p><blockquote>An interrupt request to a thread is an indication that it should stop what it is doing and do something else. It is up to the programmer to decide exactly how a thread responds to an interrupt but it is very common for the tread to terminate.</blockquote><p>For the interrupt mechanism to work correctly, the interrupted thread must support its own interruption mechanism. There are 2 cases we can examine for interruption:</p><ul><li>Non Blocking and Long Running Tasks</li></ul><p>In this case calling the <code>thread.interrupt()</code> method will set the interrupt flag of the that thread but if the task itself does not check the status of the interrupted flag it will not have any impact. For example:</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        while (true) {
            System.out.print(".");
        }
    });

    thread.start();
    thread.interrupt();
    
    thread.join();
    System.out.println("Main exits");
}</code></pre><p>In order for the thread to catch the interrupt, it should iteratively check the status of the interrupt flag so that it can understand if there are any pending interruption request and handle the request accordingly. </p><p>So we can check the flag in our while loop in if it is true we can return or break the loop. In the lambda expression it is not possible to throw an exception but in appropriate places we can throw <code>InterruptedException</code> as well.</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        while (true) {
            if (Thread.interrupted()) {
                break;
            }
            System.out.print(".");
        }
        System.out.println("Child exits");
    });

    thread.start();
    thread.interrupt();

    thread.join();
    System.out.println("Main exits");
}</code></pre><p>Note the <code>Thread.interrupted()</code> method returns the value of the flag and clears it if it has been true. So if we want to keep the state of the Thread as interrupted for the upper level of stack, we can set it back with <code>Thread.currentThread().interrupt();</code> </p><ul><li>Blocking Tasks</li></ul><p>If a thread frequently calls the blocking methods such as <code>wait</code>, <code>join</code>, <code>sleep</code>, <code>blocking I/O</code> which are all run interruptively, these methods internally check if they have been interrupted and if so they automatically throw <code>InterruptedException</code>. This exception should be caught and handled in the appropriate context. The following example uses the interruption to break the loop in a blocking <code>sleep</code> operation:</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        try {
            while (true) {
                Thread.sleep(10000);
            }
        } catch (InterruptedException e) {
            System.out.println("Thread interrupted: " + e.getMessage());
        }
        System.out.println("Child Exits");
    });

    thread.start();
    thread.interrupt();

    thread.join();
    System.out.println("Main exits");
}</code></pre><p>There are patterns for dealing with Java <code>InterruptedException</code>:</p><ul><li>One approach is propagating the exception to the callers, so higher layer would be responsible.</li><li>Before re-throwing, we can do task specific clean up.</li><li>If it is not possible to re-throw, we can set the interrupted status to true again with <code>Thread.currentThread().interrupt()</code> to preserve the evidence if the higher layers want to check it.</li></ul><p>So as a conclusion if we want to implement cancellable tasks we need to periodically check the status of the interrupt status and handle the interruption in a way that thread will exit.</p><h3 id="thread-groups">Thread Groups</h3><p>In order to simplify thread management, multiple threads &nbsp;can be organised with <code>java.lang.ThreadGroup</code> objects that group related threads. Each Thread Group needs to have a parent group. In the hierarchy, there is the <code>Main</code> group which is the parent of the other groups or threads we create in the program. We can create <code>ThreadGroup</code> by calling its constructor with a parent group and/or name. To add the Threads in a group we need to specify the group in the Thread's constructor.</p><pre><code>public void test() {
    ThreadGroup tg1 = new ThreadGroup("Thread-group-1");
    ThreadGroup tg2 = new ThreadGroup(tg1, "Thread-group-2");

    Thread thread1 = new Thread(tg1,"thread-1");
    Thread thread2 = new Thread(tg2,"thread-2");
    Thread thread3 = new Thread(tg2,"thread-3");

    thread1.start();
    thread2.start();
    thread3.start();
    
    Thread[] threads = new Thread[tg2.activeCount()];
    tg2.enumerate(threads);

    Arrays.asList(threads).forEach(t -&gt; System.out.println(t.getName()));
    tg1.list();
}</code></pre><p>We can iterate over the threads by calling the <code>enumerate</code> method, which fills the given array with the thread references of the group.</p><p>We can implement a Thread Pool by making use of Thread Groups:</p><pre><code>public class ThreadPool {
    // Create a thread group field
    private final ThreadGroup group = new ThreadGroup("ThreadPoolGroup");
    // Create a LinkedList field containing Runnable
    private final List&lt;Runnable&gt; tasks = new LinkedList&lt;&gt;();

    public ThreadPool(int poolSize) {
   â€¦</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turkogluc.com/java-concurrency-basics-of-threads/">https://turkogluc.com/java-concurrency-basics-of-threads/</a></em></p>]]>
            </description>
            <link>https://turkogluc.com/java-concurrency-basics-of-threads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940545</guid>
            <pubDate>Fri, 30 Oct 2020 09:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CMAF is available in Ant Media Server v2.2]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24940533">thread link</a>) | @kerrarbone
<br/>
October 30, 2020 | https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/ | <a href="https://web.archive.org/web/*/https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Weâ€™re happy to announce that Ant Media Server v2.2 is out with CMAF support. Before giving more highlights for the new version, just let us thank all you guys out there that make Ant Media Server become a worldwide product in 121 countries. Itâ€™s great to help lots of people around the world for their video streaming projects. After this introduction, let me give the highlights for the v2.2.</p>
<h2>Low Latency (CMAF) vs. Ultra Low Latency (WebRTC)</h2>
<p>Ant Media Server right now supports both LL(CMAF) and ULL(WebRTC). Here is the some basic information about these technologies. CMAF provides low latency(3-5 secs) in live streaming, on the other hand WebRTC provides Ultra Low Latency(0.5 secs) in live streaming. Then which one is good for your streaming project, CMAF or WebRTC?</p>
<h4>Which one to use?</h4>
<p>Both technologies have advantages and disadvantages. You can pick the correct one according to your use case.&nbsp; CMAF is good if there is no interactivity between broadcasters and viewers. Itâ€™s easier to scale with CMAF with CDNs.&nbsp; Itâ€™s not much affected by instant network fluctuations because latency is about 3-5 seconds. On the other hand,&nbsp; itâ€™s good to use WebRTC if there is interactivity between broadcasters and viewers. You need to manage the edge WebRTC servers to scale.&nbsp; Itâ€™s affected by instant network fluctuations(jitter, congestion) because itâ€™s about 0.5 secs latency.</p>
<div id="attachment_34297"><p><img aria-describedby="caption-attachment-34297" src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/Chunked-encoding-slide-CMAF.png" alt="CMAF" width="626" height="347" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/Chunked-encoding-slide-CMAF.png 626w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/Chunked-encoding-slide-CMAF-300x166.png 300w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/Chunked-encoding-slide-CMAF-600x333.png 600w" sizes="(max-width: 626px) 100vw, 626px" title="Adventure Continues: CMAF is available in Ant Media Server v2.2 1"></p><p id="caption-attachment-34297">CMAF</p></div><h4>How to use CMAF?</h4>
<p>Firstly, you need to enable it on your applicationâ€™s configuration file. Letâ€™s assume that youâ€™ve already running Ant Media Server v.2.2 Enterprise on your server then weâ€™re going to use WebRTCAppEE for CMAF streaming.</p>
<ul>
<li>Open the following file with your favorite editor <pre>/usr/local/antmedia/webapps/WebRTCAppEE/WEB-INF/red5-web.properties</pre> </li>
<li>Enable DASH by adding following property to the file above <pre>settings.dashMuxingEnabled=true</pre> </li>
<li>Restart the Ant Media Server <pre>sudo service antmedia restart</pre> </li>
<li>Send WebRTC stream to Ant Media Server on WebRTC publisher page. Letâ€™s assume your stream id is â€œstream1â€ <pre>https://YOUR_DOMAIN:5443/WebRTCAppEE</pre> </li>
<li>Play the stream with CMAF on the following url <pre>https://YOUR_DOMAIN:5443/WebRTCAppEE/play.html?id=stream1&amp;playOrder=dash</pre> </li>
</ul>
<p>Measure the latency. Youâ€™ll see something between 3-5 secs. Let us give further configuration parameters for DASH muxing.</p>
<ul>
<li><em>settings.dashSegDuration </em>: Duration of segments in DASH. Default value is 2</li>
<li><em>settings.dashFragmentDuration </em>: Duration of fragments. Default value is 0.5</li>
<li><em>settings.dashTargetLatency </em>: Target latency for measurement. Default value is 3.5.</li>
<li><em>settings.dashWindowSize </em>:&nbsp; DASH window size. Number of files in manifest. Default value is 5</li>
<li><em>settings.dashExtraWindowSize </em>: DASH extra window size. Number of segments kept outside of the manifest before removing from disk. Default value is 5</li>
<li><em>settings.deleteDASHFilesOnEnded </em>: Delete DASH files after streaming is ended.&nbsp; Default value is true</li>
</ul>
<h2>Kubernetes Support</h2>
<p>Weâ€™ve been getting requests for supporting Kubernetes(K8s) from our users for a while. So that weâ€™ve decided to support Kubernetes in Ant Media Server. Weâ€™ve added extra parameters to start the server in the container.</p>
<div id="attachment_34272"><p><img aria-describedby="caption-attachment-34272" src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/kubernetes.png" alt="Adventure Continues: CMAF is available in Ant Media Server v2.2 1" width="600" height="300" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/kubernetes.png 600w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/kubernetes-300x150.png 300w" sizes="(max-width: 600px) 100vw, 600px" title="Adventure Continues: CMAF is available in Ant Media Server v2.2 2"></p><p id="caption-attachment-34272">Kubernetes is supported in Ant Media Server</p></div><p>Moreover, weâ€™ve prepared the documentation for the Kubernetes. All kubernetes files(service, deployment) and dockerFile are available <a href="https://github.com/ant-media/Ant-Media-Server/wiki/Getting-Started-with-Ant-Media-Server-Kubernetes" target="_blank" rel="noopener">in the documentation.</a> The critical thing for running Ant Media Server is that deployment uses hostNetwork which means that you can use one Ant Media Server pod in a node.</p>
<h2>Long live the new King: Java 11</h2>
<p>We donâ€™t mean the â€œThe king is deadâ€ because Java 8 is still the most used Java version. On the other hand, for compatibility with tools and improvements in Java 11, weâ€™ve migrated to Java 11 in Ant Media Server. In addition, weâ€™ve monitored some performance improvements on Java 11. We plan to provide more performance metrics for this release later.&nbsp; All install scripts and docker files are updated to use Java 11.</p>
<div id="attachment_34273"><p><img aria-describedby="caption-attachment-34273" src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/java_11.png" alt="Java 11 is supported in Ant Media Server" width="400" height="225" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/java_11.png 400w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/java_11-300x169.png 300w" sizes="(max-width: 400px) 100vw, 400px" title="Adventure Continues: CMAF is available in Ant Media Server v2.2 3"></p><p id="caption-attachment-34273">Ant Media Server v2.2 is running in Java 11</p></div><h2>Apache Portable Runtime(APR) and HTTP/2</h2>
<p>Weâ€™ve updated Tomcat version to 8.5.58 and compiled native Apache Portable Runtime libraries for improving the performance. <span>Tomcat can use the&nbsp;</span><a href="https://apr.apache.org/" rel="nofollow noopener" target="_blank">Apache Portable Runtime</a><span> to provide superior scalability, performance, and better integration with native server technologies. Last but not the least, weâ€™ve also enabled HTTP/2.0 in Ant Media Server.</span></p>
<p><img src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/http_2.png" alt="Adventure Continues: CMAF is available in Ant Media Server v2.2 2" width="280" height="280" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/http_2.png 280w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/http_2-150x150.png 150w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/http_2-160x160.png 160w" sizes="(max-width: 280px) 100vw, 280px" title="Adventure Continues: CMAF is available in Ant Media Server v2.2 4"></p>
<p>If you want to take a look at the whole changes, please <a href="https://github.com/ant-media/Ant-Media-Server/releases/tag/ams-v2.2.0" rel="follow noopener" target="_blank">visit this link</a>.</p>
<p>We continue our adventure to create something challenging and unique in the upcoming versions and projects(Spaceport â€“ Volumetric Video).</p>
<p><a href="https://antmedia.io/#contact">Please keep in touch if we can help you with anything.</a></p>
</div></div>]]>
            </description>
            <link>https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940533</guid>
            <pubDate>Fri, 30 Oct 2020 09:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24939875">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scopeâ€‰â€”â€‰rust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You donâ€™t need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
Itâ€™s not about implementing crazy lock-free schemes, itâ€™s about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesnâ€™t have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of â€œyour codeâ€ vs â€œframework codeâ€ when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still donâ€™t really believe this :)
rust-analyzer started from zero, it didnâ€™t have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But itâ€™s hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rustâ€™s surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>Itâ€™s easy to characterize Kotlinâ€™s learning curveâ€‰â€”â€‰it is nearly zero.
Iâ€™ve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, itâ€™s hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that â€œwhy no one does modules right?â€ is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crateâ€™s public API matters, and it is crystal clear what crateâ€™s public API is.
Moreover, crates are anonymous, so you donâ€™t get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, itâ€™s not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing projectâ€™s build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rustâ€™s build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
Itâ€™s not perfect, but it is a breath of fresh air after Javaâ€™s <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargoâ€™s trick is that it doesnâ€™t try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
Itâ€™s impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like Iâ€™ve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradleâ€™s user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for â€œperfectâ€ library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and boltsâ€‰â€”â€‰structs, enums, functions, etc.
This is not specific to Rustâ€‰â€”â€‰any ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatchâ€‰â€”â€‰which code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
Itâ€™s better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rustâ€™s humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are â€¦</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939875</guid>
            <pubDate>Fri, 30 Oct 2020 07:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Flexbox with 30 Code Tidbits]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939224">thread link</a>) | @nilsandrey
<br/>
October 29, 2020 | https://www.samanthaming.com/flexbox30/ | <a href="https://web.archive.org/web/*/https://www.samanthaming.com/flexbox30/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app" data-server-rendered="true"><div><p>
      ðŸ”¥ NEW Code Tidbit Every Week ðŸ”¥
    </p> <header><nav data-v-51356df1=""><div data-v-51356df1=""> <ul data-v-51356df1=""><li data-v-51356df1=""><a href="https://www.samanthaming.com/" name="Go to Home Page - SamanthaMing.com" data-v-51356df1=""><img src="https://www.samanthaming.com/images/samantha-ming-logo.svg" alt="Samantha Ming Logo" data-v-51356df1=""> <span data-v-51356df1="">Samantha Ming</span></a></li> <li data-v-51356df1=""><a href="https://www.samanthaming.com/tidbits/" data-v-51356df1="">
          Tidbits
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/blog/" data-v-51356df1="">
          Blog
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/courses/" data-v-51356df1="">
          Courses
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/contact/" data-v-51356df1="">
          Contact
        </a></li></ul> <div data-v-51356df1=""></div></div></nav> </header>  <main><div><div><div><a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/"><img src="https://samanthaming.gumlet.io/courses/flexbox30.jpg.gz?format=auto" alt="Flexbox30" data-v-067b84ea=""> <p>
            Start Course
          </p></a></div></div> <div><div><div><div> <p>
      Learn Flexbox with 30 Code Tidbits âœ¨
      <a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/">
        Start Course
      </a> </p></div></div></div></div></div> <div><ul><li><a href="https://twitter.com/intent/tweet?text=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8&amp;url=https://www.samanthaming.com/flexbox30/&amp;via=samantha_ming" title="Share this course on Twitter" rel="noopener noreferrer" target="_blank" data-analytics-social="Twitter"> <span>Share to Twitter</span> <span>Twitter</span></a></li><li><a href="https://www.facebook.com/sharer/sharer.php?text=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8&amp;u=https://www.samanthaming.com/flexbox30/" title="Share this course on Facebook" rel="noopener noreferrer" target="_blank" data-analytics-social="Facebook"> <span>Share to Facebook</span> <span>Facebook</span></a></li><li><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.samanthaming.com/flexbox30/&amp;smid=li-share&amp;title=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8" title="Share this course on LinkedIn" rel="noopener noreferrer" target="_blank" data-analytics-social="LinkedIn"> <span>Share to LinkedIn</span> <span>LinkedIn</span></a></li><li><a href="https://reddit.com/submit?url=https://www.samanthaming.com/flexbox30/&amp;smid=re-share&amp;%20%20%20%20%20%20%20%20title=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8" title="Share this course on Reddit" rel="noopener noreferrer" target="_blank" data-analytics-social="Reddit"> <span>Share to Reddit</span> <span>Reddit</span></a></li><li><a href="https://news.ycombinator.com/submitlink?u=https://www.samanthaming.com/flexbox30/" title="Share this course on Hacker News" rel="noopener noreferrer" target="_blank" data-analytics-social="Hacker News"> <span>Share to Hacker News</span> <span>Hacker News</span></a></li><li><a href="mailto:?subject=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8%20|%20SamanthaMing.com&amp;body=Learn%20Flexbox%20with%2030%20code%20tidbits.%20Become%20a%20flexbox%20ninja%20with%20this%20FREE%20course!%0A%0Ahttps://www.samanthaming.com/flexbox30/" title="Share this course on Email" rel="noopener noreferrer" target="_blank" data-analytics-social="Email"> <span>Email</span> <span>Email</span></a></li></ul></div> <section><div><div><h2>
          Flexbox Core Concepts
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/" aria-label="Read the article for Introduction" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/1-flexbox-intro.jpg.gz?format=auto&amp;width=256" alt="Introduction" data-v-067b84ea=""><span>1</span></p></a> <h3 data-v-605d1001="">
    Introduction
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/2-flex-container-flex-items/" aria-label="Read the article for Flex Container &amp; Flex Items" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/2-flex-container-flex-items.jpg.gz?format=auto&amp;width=256" alt="Flex Container &amp; Flex Items" data-v-067b84ea=""><span>2</span></p></a> <h3 data-v-605d1001="">
    Flex Container &amp; Flex Items
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/3-immediate-child-only/" aria-label="Read the article for Immediate Child Only" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/3-immediate-child-only.jpg.gz?format=auto&amp;width=256" alt="Immediate Child Only" data-v-067b84ea=""><span>3</span></p></a> <h3 data-v-605d1001="">
    Immediate Child Only
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/4-flexbox-axes/" aria-label="Read the article for Flexbox Axes" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/4-flexbox-axes.jpg.gz?format=auto&amp;width=256" alt="Flexbox Axes" data-v-067b84ea=""><span>4</span></p></a> <h3 data-v-605d1001="">
    Flexbox Axes
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/5-flexbox-module/" aria-label="Read the article for Flexbox Module" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/5-flexbox-module.jpg.gz?format=auto&amp;width=256" alt="Flexbox Module" data-v-067b84ea=""><span>5</span></p></a> <h3 data-v-605d1001="">
    Flexbox Module
  </h3></li></ul></div><div><h2>
          Parent Properties
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/6-parent-properties/" aria-label="Read the article for Parent Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/6-parent-properties.jpg.gz?format=auto&amp;width=256" alt="Parent Properties" data-v-067b84ea=""><span>6</span></p></a> <h3 data-v-605d1001="">
    Parent Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/7-display/" aria-label="Read the article for display" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/7-display.jpg.gz?format=auto&amp;width=256" alt="display" data-v-067b84ea=""><span>7</span></p></a> <h3 data-v-605d1001="">
    display
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/8-block-vs-inline/" aria-label="Read the article for block vs inline" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/8-block-vs-inline.jpg.gz?format=auto&amp;width=256" alt="block vs inline" data-v-067b84ea=""><span>8</span></p></a> <h3 data-v-605d1001="">
    block vs inline
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/9-flex-direction/" aria-label="Read the article for flex-direction" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/9-flex-direction.jpg.gz?format=auto&amp;width=256" alt="flex-direction" data-v-067b84ea=""><span>9</span></p></a> <h3 data-v-605d1001="">
    flex-direction
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/10-flex-wrap/" aria-label="Read the article for flex-wrap" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/10-flex-wrap.jpg.gz?format=auto&amp;width=256" alt="flex-wrap" data-v-067b84ea=""><span>10</span></p></a> <h3 data-v-605d1001="">
    flex-wrap
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/11-flex-flow/" aria-label="Read the article for flex-flow" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/11-flex-flow.jpg.gz?format=auto&amp;width=256" alt="flex-flow" data-v-067b84ea=""><span>11</span></p></a> <h3 data-v-605d1001="">
    flex-flow
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/12-justify-content-row/" aria-label="Read the article for justify-content [row]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/12-justify-content-row.jpg.gz?format=auto&amp;width=256" alt="justify-content [row]" data-v-067b84ea=""><span>12</span></p></a> <h3 data-v-605d1001="">
    justify-content [row]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/13-justify-content-column/" aria-label="Read the article for justify-content [column]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/13-justify-content-column.jpg.gz?format=auto&amp;width=256" alt="justify-content [column]" data-v-067b84ea=""><span>13</span></p></a> <h3 data-v-605d1001="">
    justify-content [column]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/14-space-around-vs-space-evenly/" aria-label="Read the article for space-around vs space-evenly" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/14-space-around-vs-space-evenly.jpg.gz?format=auto&amp;width=256" alt="space-around vs space-evenly" data-v-067b84ea=""><span>14</span></p></a> <h3 data-v-605d1001="">
    space-around vs space-evenly
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/15-align-items-row/" aria-label="Read the article for align-items [row]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/15-align-items-row.jpg.gz?format=auto&amp;width=256" alt="align-items [row]" data-v-067b84ea=""><span>15</span></p></a> <h3 data-v-605d1001="">
    align-items [row]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/16-baseline/" aria-label="Read the article for baseline" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/16-baseline.jpg.gz?format=auto&amp;width=256" alt="baseline" data-v-067b84ea=""><span>16</span></p></a> <h3 data-v-605d1001="">
    baseline
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/17-align-items-column/" aria-label="Read the article for align-items [column]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/17-align-items-column.jpg.gz?format=auto&amp;width=256" alt="align-items [column]" data-v-067b84ea=""><span>17</span></p></a> <h3 data-v-605d1001="">
    align-items [column]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/18-align-content/" aria-label="Read the article for align-content" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/18-align-content.jpg.gz?format=auto&amp;width=256" alt="align-content" data-v-067b84ea=""><span>18</span></p></a> <h3 data-v-605d1001="">
    align-content
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/27-flex/" aria-label="Read the article for flex" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/27-flex.jpg.gz?format=auto&amp;width=256" alt="flex" data-v-067b84ea=""><span>27</span></p></a> <h3 data-v-605d1001="">
    flex
  </h3></li></ul></div><div><h2>
          Child Properties
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/19-child-properties/" aria-label="Read the article for Child Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/19-child-properties.jpg.gz?format=auto&amp;width=256" alt="Child Properties" data-v-067b84ea=""><span>19</span></p></a> <h3 data-v-605d1001="">
    Child Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/20-order/" aria-label="Read the article for order" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/20-order.jpg.gz?format=auto&amp;width=256" alt="order" data-v-067b84ea=""><span>20</span></p></a> <h3 data-v-605d1001="">
    order
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/21-flex-grow/" aria-label="Read the article for flex-grow" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/21-flex-grow.jpg.gz?format=auto&amp;width=256" alt="flex-grow" data-v-067b84ea=""><span>21</span></p></a> <h3 data-v-605d1001="">
    flex-grow
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/22-flex-grow-calculation/" aria-label="Read the article for flex-grow calculation" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/22-flex-grow-calculation.jpg.gz?format=auto&amp;width=256" alt="flex-grow calculation" data-v-067b84ea=""><span>22</span></p></a> <h3 data-v-605d1001="">
    flex-grow calculation
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/23-flex-shrink/" aria-label="Read the article for flex-shrink" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/23-flex-shrink.jpg.gz?format=auto&amp;width=256" alt="flex-shrink" data-v-067b84ea=""><span>23</span></p></a> <h3 data-v-605d1001="">
    flex-shrink
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/24-flex-shrink-calculation/" aria-label="Read the article for flex-shrink calculation" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/24-flex-shrink-calculation.jpg.gz?format=auto&amp;width=256" alt="flex-shrink calculation" data-v-067b84ea=""><span>24</span></p></a> <h3 data-v-605d1001="">
    flex-shrink calculation
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/25-flex-basis/" aria-label="Read the article for flex-basis" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/25-flex-basis.jpg.gz?format=auto&amp;width=256" alt="flex-basis" data-v-067b84ea=""><span>25</span></p></a> <h3 data-v-605d1001="">
    flex-basis
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/26-flex-basis-vs-widths/" aria-label="Read the article for flex-basis vs widths" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/26-flex-basis-vs-widths.jpg.gz?format=auto&amp;width=256" alt="flex-basis vs widths" data-v-067b84ea=""><span>26</span></p></a> <h3 data-v-605d1001="">
    flex-basis vs widths
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/28-align-self/" aria-label="Read the article for align-self" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/28-align-self.jpg.gz?format=auto&amp;width=256" alt="align-self" data-v-067b84ea=""><span>28</span></p></a> <h3 data-v-605d1001="">
    align-self
  </h3></li></ul></div><div><h2>
          Summary
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/29-flexbox-properties/" aria-label="Read the article for Flexbox Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/29-flexbox-properties.jpg.gz?format=auto&amp;width=256" alt="Flexbox Properties" data-v-067b84ea=""><span>29</span></p></a> <h3 data-v-605d1001="">
    Flexbox Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/30-flexbox-cheatsheet/" aria-label="Read the article for Flexbox Cheatsheet" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/30-flexbox-cheatsheet.jpg.gz?format=auto&amp;width=256" alt="Flexbox Cheatsheet" data-v-067b84ea=""><span>30</span></p></a> <h3 data-v-605d1001="">
    Flexbox Cheatsheet
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/31-flexbox-with-auto-margins/" aria-label="Read the article for Bonus: Flexbox with Auto Margins" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/31-flexbox-with-auto-margins.jpg.gz?format=auto&amp;width=256" alt="Bonus: Flexbox with Auto Margins" data-v-067b84ea=""><span>31</span></p></a> <h3 data-v-605d1001="">
    Bonus: Flexbox with Auto Margins
  </h3></li></ul></div></div></section> <section><div><hr> <div><h2>
        More Courses
      </h2> <!----> </div></div> <ul><li><a href="https://www.samanthaming.com/codetidbits30/"><div><h3>
          CodeTidbits30
        </h3> <p>
          30 days of the best JS, CSS, HTML tidbits ðŸŽ„
        </p></div></a></li><li><a href="https://www.samanthaming.com/basics/"><div><h3>
          Web Basics
        </h3> <p>
          Web Basics Explained with Tidbits ðŸŽ
        </p></div></a></li><li><a href="https://www.samanthaming.com/pictorials/"><div><h3>
          Pictorials
        </h3> <p>
          Step by Step Code Tutorials ðŸ‘£
        </p></div></a></li></ul></section> <section><div><hr> <div><h2><a href="https://www.samanthaming.com/tidbits/"><span>
      Top Tidbits
    </span> </a></h2> <!----> </div></div> <div><ul> <li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/29-check-if-number-is-positive-or-negative/" aria-label="Read the article for Math.sign: How to Check if Number is Negative or Positive in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/29-check-if-number-is-positive-or-negative.jpg.gz?format=auto" alt="Code snippet on Math.sign: How to Check if Number is Negative or Positive in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Math.sign: How to Check if Number is Negative or Positive in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/11-setting-default-parameters/" aria-label="Read the article for Setting Default Parameters in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/11-setting-default-parameters.jpg.gz?format=auto" alt="Code snippet on Setting Default Parameters in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Setting Default Parameters in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/45-pretty-json-output/" aria-label="Read the article for Pretty JSON output" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/45-pretty-json-output.jpg.gz?format=auto" alt="Code snippet on Pretty JSON output" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Pretty JSON output
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/50-how-to-deep-clone-an-array/" aria-label="Read the article for How to Deep Clone an Array in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/50-how-to-deep-clone-an-array.jpg.gz?format=auto" alt="Code snippet on How to Deep Clone an Array in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        How to Deep Clone an Array in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/89-how-to-check-if-variable-is-array/" aria-label="Read the article for How to check if Variable is an Array in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/89-how-to-check-if-variable-is-array.jpg.gz?format=auto" alt="Code snippet on How to check if Variable is an Array in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        How to check if Variable is an Array in JavaScript
      </h3></p></a></li> <p>
      hi</p></ul></div></section> </main>  </div></div></div>]]>
            </description>
            <link>https://www.samanthaming.com/flexbox30/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939224</guid>
            <pubDate>Fri, 30 Oct 2020 04:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research discovers breakthrough with potential to prevent, reverse Alzheimer's]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939160">thread link</a>) | @walterbell
<br/>
October 29, 2020 | https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers | <a href="https://web.archive.org/web/*/https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <div>

                
                                
                                                  <div>
                                                                                        <p><span><span>A research team at the University of Calgaryâ€™s <a href="https://cumming.ucalgary.ca/">Cumming School of Medicine</a> (CSM) led by Dr. S.R. Wayne Chen, PhD, has made an exciting breakthrough with the potential to prevent and reverse the effects of Alzheimerâ€™s disease.</span></span></p>

<p><span><span>The team discovered that limiting the open time of a channel called the ryanodine receptor, which acts like a gateway to cells located in the heart and brain, reverses and prevents progression of Alzheimerâ€™s disease in animal models. They also identified a drug that interrupts the disease process.</span></span></p>

<p><span><span>The effect of giving the drug to animal models was remarkable: After one month of treatment, the memory loss and cognitive impairments in these models disappeared. </span></span></p>

<p><span><span>â€œThe significance of identifying a clinically used drug that acts on a defined target to provide anti-Alzheimerâ€™s disease benefits canâ€™t be overstated,â€ says Chen, a member of the <a href="https://libin.ucalgary.ca/">Libin Cardiovascular Institute</a> and the <a href="https://hbi.ucalgary.ca/">Hotchkiss Brain Institute</a> at the CSM.&nbsp;</span></span><span lang="EN-US"><span><span><span>Dr. Jinjing Yao, PhD, a student of Chen, is the first author of the study.</span></span></span></span></p>

<p><span><span>The results of this groundbreaking study were recently published in the peer-reviewed journal, <a href="https://www.cell.com/cell-reports/fulltext/S2211-1247(20)31158-X"><em>Cell Reports</em></a>.&nbsp;</span></span></p>

<p><span><span>This work is potentially highly impactful as more than half a million Canadians live with Alzheimerâ€™s disease and other dementias, suffering memory loss and other cognitive impairments with a negative impact on quality of life. </span></span></p>

<h3><strong><span><span><span><span>The science behind the findings</span></span></span></span></strong></h3>

<p><span><span>Previous research has shown that the progression of Alzheimerâ€™s disease is driven by a vicious cycle of the protein amyloid Î² (AÎ²) inducing hyperactivity at the neuron level. However, the mechanism behind this wasnâ€™t fully understood nor were there effective treatments to stop the cycle. &nbsp;</span></span></p>

<p><span><span>Chenâ€™s team used a portion of an existing drug used for heart patients, carvedilol, to treat mice models with Alzheimerâ€™s symptoms. After a month of treatment, researchers tested animal models with very promising results. </span></span></p>

<p><span><span>â€œWe treated them for a month and the effect was quite amazing,â€ says Chen, explaining the drug was successful in reversing major symptoms of Alzheimerâ€™s disease. â€œWe couldnâ€™t tell the drug-treated disease models and the healthy models apart.â€ </span></span></p>

<p><span><span>Chen, a Clarivate Highly Cited Researcher, is optimistic about the future of this research, however, there are many steps to be taken before this finding would lead to a clinical trial.&nbsp;</span></span></p>

<p><span><span>If you are interested in finding out about clinical trials that are underway related to Alzheimerâ€™s you can go to <a href="https://www.ucalgary.ca/research/participate/node/13200">Participate in Research</a>. There youâ€™ll find a number of studies looking for participants including control subjects, people not living with a specific condition. </span></span></p>

<p><em><span><span>Wayne Chen is a professor in the Department&nbsp;of Physiology and Pharmacology, Biochemistry and </span></span><span><span>Molecular Biology at the CSM.&nbsp;</span></span></em><span><span><em><span lang="EN-US"><span><span>Led by the&nbsp;</span></span></span></em><a href="http://www.hbi.ucalgary.ca/"><em><span><span><span><span><span>Hotchkiss Brain Institute</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>,&nbsp;</span></span></span></em><a href="http://www.ucalgary.ca/research/brain-and-mental-health"><em><span><span><span><span><span>Brain and Mental Health</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>&nbsp;is one of six research strategies guiding the University of Calgary toward its&nbsp;Eyes High&nbsp;goals. The strategy provides a unifying direction for brain and mental health research at the university.</span></span></span></em></span></span></p>



                                                                                                                                                                                                                                      

  
    

    
  <div data-history-node-id="23525" role="article" about="/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers" typeof="schema:Article">
    <div>
      <div>
                          <div>
            <div>
              <div>
                <div>
                                        <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8 1x" media="all and (min-width: 992px)" type="image/jpeg">
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_tablet/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=5tYigcJ8 1x" media="all and (min-width: 768px)" type="image/jpeg">
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_mobile/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=-CoV0v5E 1x" media="all and (max-width: 767px)" type="image/jpeg">
            <!--[if IE 9]></video><![endif]-->
            <img src="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8" alt="Dr. Wayne Chen, PhD" title="Dr. Wayne Chen, PhD" typeof="foaf:Image">

  </picture>

                                    </div>
                                  <p>Dr. Wayne Chen, PhD</p>
                                                  <p>Britton Ledingham for the Libin Cardiovascular Institute</p>
                              </div>
            </div>
          </div>
              </div>
          </div>
  </div>


                                                                                    </div>
                
                
              </div>
              
            </div>

          </div>
        </div></div>]]>
            </description>
            <link>https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939160</guid>
            <pubDate>Fri, 30 Oct 2020 04:27:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SM2 (Chinese) National Secret algorithm is accepted into Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24938686">thread link</a>) | @hyiltiz
<br/>
October 29, 2020 | https://www.codetd.com/en/article/12031985 | <a href="https://web.archive.org/web/*/https://www.codetd.com/en/article/12031985">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        <p><span>
                            <a href="https://www.codetd.com/en/cat/17746/1">News</a>
                        </span>
                            <span>2020-10-27 14:44:54</span>
                            <span>views: null</span>
                        </p>

                    </div><div><div> 
  
 <p><span><span>On October 25, a developer posted that the SM2 national secret algorithm was finally accepted by the Linux kernel community. </span><span>The author stated that the SM2 patch has been updated to version v7. This version of the patch was finally accepted by the community. It has been </span></span><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&amp;q=Tianjia+Zhang"><span><span>merged into the 5.10-rc1 of the Linux mainline</span></span></a><span><span> . If nothing </span><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&amp;q=Tianjia+Zhang"><span>else</span></a><span> , it will be officially released in the 5.10 kernel version.</span></span></p> 
 <p><span><span>National Secret is the abbreviation of National Commercial Encryption. The National Encryption Administration Bureau formulates algorithm standards, and it also formulates a large number of product and interface specifications and application scenarios. </span><span>Since 2012, the State Cryptography Administration has successively published SM2/SM3/SM4 and other cryptographic algorithm standards and their application specifications in the form of the "People's Republic of China Password Industry Standards". </span><span>Among them, "SM" stands for "commercial secret", which is a cryptographic technology used for commercial use that does not involve state secrets.</span></span></p> 
 <p><span><span>According to the author, the current Linux kernel has well supported the SM3 and SM4 algorithms, thanks to the widespread use of wireless LAN standards. </span><span>However, the SM2 algorithm and the national secret certificate have not been supported for a long time, and it is impossible to establish full-stack trust and integrity verification in the kernel based on the national secret. Therefore, it has become urgent to support this system in the kernel.</span></span></p> 
 <p><span><span>It took 7 rounds for the kernel community to accept SM2. </span><span>The initial consideration was to migrate from openssl, but the openssl architecture and infrastructure code needed to be ported because of the huge workload. </span><span>After several rounds of discussion and testing, I found that the existing libgcrypt already has a complete elliptic curve basic algorithm, so I tried to implement SM2 in libgcrypt first, and finally the SM2 algorithm was accepted by the community as a sub-algorithm of ECC. </span><span>After that, SM2 was gradually accepted by the kernel community.</span></span></p> 
 <p><span><span>At present, libgcrypt has fully supported the national secret algorithm SM2/3/4, and these implementations will be officially released in the next version 1.9.0. </span><span>At the same time, as a user-mode tool for IMA integrity signatures, ima-evm-utils' support for national secrets has not fallen. </span><span>Click to view </span></span><a href="https://sourceforge.net/p/linux-ima/ima-evm-utils/ci/ceecb28d3b5267c7d32c6e9401923c94f5786cfb/log/?path="><span><span>related submissions</span></span></a><span><span> .</span></span></p> 
 <p><span><span>Finally, the author also summarizes the known issues of SM2:</span></span></p> 
 <ul> 
  <li><span><span>To support national secret certificate verification, SM2 either does not compile, or it must be built-in compilation, and does not support compilation into modules. </span><span>Of course, SM2, as an asymmetric algorithm, only signs a hash or IMA verification based on national secrets, and there is no such limitation.</span></span></li> 
  <li><span><span>The IMA signature tool ima-evm-utils and the national secret algorithm used by the kernel to calculate the SM3 hash of the file do not add Za. This is a little difference from the specification.</span></span></li> 
 </ul> 
 <p><a href="https://linux.cn/article-12751-1.html"><span><span>Reference reading</span></span></a></p> 
</div></div></div>]]>
            </description>
            <link>https://www.codetd.com/en/article/12031985</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938686</guid>
            <pubDate>Fri, 30 Oct 2020 03:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Messy, Booming Business of Recycling Cruise Ships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938508">thread link</a>) | @finphil
<br/>
October 29, 2020 | https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(Bloomberg) -- Carnival Fantasy was a ship famous for its outlandish dÃƒÂ©cor, all-night revelry and its sizeÃ¢â‚¬â€back when 2,000 was an incredible number of passengers. The Ã¢â‚¬Å“Fun ShipÃ¢â‚¬ï¿½ vibe it introduced in 1990 came with such whimsical spaces as an Egyptian-themed piano bar, decorated with a fake sarcophagus, and a glitzy glass-topped atrium that was the hub of the social scene.</p><p>Today the Fantasy is attracting a whole different breed of booty-seeker. In July, the 30-year-old ship sailed to the Aegean Sea, wrapping its final voyageÃ‚&nbsp;in the shipbreaking capital of Aliaga, Turkey.</p><p>Its resting place there isÃ‚&nbsp;aÃ‚&nbsp;demolition yard where old cargo ships, tankers, research vesselsÃ¢â‚¬â€and now cruise ships retired during the Covid-19 pandemicÃ¢â‚¬â€get torn apart and broken into pieces. In this case, theyÃ¢â‚¬â„¢re not being broken in half to  get upgraded and stitched back together. Instead,Ã‚&nbsp;circling the FantasyÃ¢â‚¬â„¢s partially deconstructed innards are buyers from all sorts of industries, looking for rock bottom deals on everything from artwork and kitchenwares to electrical wires and stainless-steel sinks.</p><p>For the cruise company, itÃ¢â‚¬â„¢s an opportunity to recoup at least some value from an asset thatÃ¢â‚¬â„¢s currently acting as dead weight; while shipsÃ¢â‚¬â„¢ values  declineÃ‚&nbsp;with age, the Fantasy was originally built for about $225 million. And for the recycling companies that buy the vesselÃ‚&nbsp;for cash and take on the hazardous task of emptying all its valuables, itÃ¢â‚¬â„¢s a matter of a months-long salvage resale on steroids.</p><p>Cutting the Losses</p><p>ItÃ¢â‚¬â„¢s hard to gauge how exactly much money is made off of cruise ship recycling. Companies donÃ¢â‚¬â„¢t immediately disclose the sale prices of the vessels after relinquishing ownership, and the resale value of their most sought-after commodity, scrap steel, fluctuates in each global market on a daily basis.Ã‚&nbsp;</p><p>But the business is booming.</p><p>Next to Carnival Fantasy in Aliaga are two otherÃ‚&nbsp;Fantasy-class ships built in the late 1990s. And next to them are two former Royal Caribbean vessels (scrapped by RoyalÃ¢â‚¬â„¢s Spanish partner line Pullmantur Cruceros). The ships all had big fan bases, even as they aged. Fantasy and its sister ships started 2020 full of passengers bent on fun-in-the-sun activities in the Caribbean, Bahamas, and Mexican Riviera.</p><p>The ships would have left the fleet in coming years even in a healthy industry; the pandemic sped up the process, with owners of idled vesselsÃ‚&nbsp;hemorrhaging cashÃ‚&nbsp;and looking to cut their losses.</p><p>In its third quarter filing, Carnival Corporation said it planned to sell 18 Ã¢â‚¬Å“less efficientÃ¢â‚¬ï¿½ ships in 2020, resulting in a 12% reduction of its nine-brand fleet. Ã¢â‚¬Å“Those ships were giving us a bad drain,Ã¢â‚¬ï¿½ Carnival CEO Arnold Donald said during a recent webinar with the Society of American Travel Writers.</p><p>Going, Going, Gone</p><p>Without much of a market for second-hand tonnage, the main worth of the ships is the steel that makes up the superstructure.</p><p>If, for instance, Carnival Fantasy has 15,000 tons of steel in its superstructure, the scrap may sell for upwards of $4.7 million based on current global market pricesÃ¢â‚¬â€though other factors also come into play, such as local prices and demand.</p><p>Along with the risk of these market fluctuations, the buyer also takes on the uncertainty of just how much metal can be salvaged. Pre-1990s ships tend to have more steel in their hulls and underwater plating, but those built in the Ã¢â‚¬â„¢90s and after can bear lighter and stronger alloys.</p><p>Either way, steel and metal scraps will travel to a smelter to make rebar for construction projects around the world. Steel from some other dismantled ships can find its way to TurkeyÃ¢â‚¬â„¢s  large car manufacturing industry, where it might become parts for a Toyota orÃ‚&nbsp;a Ford.</p><p>Aluminum, copper, and stainless steel are also salvaged and resold, along with other valuable commodities that mostly remain in Turkey. The ripped out teak decks on Fantasy may end up in local shops, restaurants, and homes. Theater scenery and lighting may find its way into show productions. Even the tackiest artwork has some value, and can end up in restaurants throughout the country.</p><p>Buyers come to the yard for everything down to the bolts and nuts. Even if a used toilet sells for a fraction of the shelf price, multiply that amount by a few thousandÃ¢â‚¬â€given the number of cabins and public spaces on each shipÃ¢â‚¬â€and it can add up to a substantial sum.</p><p>According to Orbay Simsek, vice president of the Aliaga-based Simsekler Ship Recycling Company, there are even markets for kitchenware, closets, and blankets.Ã‚&nbsp;</p><p>Basically anything and everything that can be sold, sells. Everything must go. Even the sarcophagus.</p><p>Eco-friendly Shipbreaking</p><p>Taking apart ships is a controversial topic, thanks to concerns over both human and environmental risks. ItÃ¢â‚¬â„¢s one of the most dangerous jobs in the world, according to Wouter Rozenveld, director of Sea2Cradle (SC2), an expert in green ship recycling who was hired by Carnival to oversee the safe dismantling of its ships. Each Carnival vessel may take up to nine months to break down, he says, and the blowtorch-based work comes with constant fire hazards.</p><p>Those hazards are amplified when the recyclable component pieces, like furniture, cabling, piping, and machinery inside each deck have to be carefully taken apart and separated says Ehud Bar-Lev, who overseesÃ‚&nbsp;assessment services at maritime specialist LloydÃ¢â‚¬â„¢s Register.</p><p>The extra steps in disassembly also increase potential for hazardous waste spills, containing everything from oily residues to sludge, asbestos, and coolants in fridges.</p><p>To prevent those incidents, the Turkish shipbreaking yard undertakes its work in a concrete holding area that catches debris; in similar facilities throughout India and Bangladesh, the process may happen on the beach. Rather thanÃ‚&nbsp;letting toxic chemicals spew into the water, the Turkish yard collects the materials, has them cataloged by Sea2Cradle, and then hands them over toÃ‚&nbsp;the government-runÃ‚&nbsp;Ship Recycling Association of Turkey for proper disposal.</p><p>Carnival Corporation saw these precautions as a marketingÃ‚&nbsp;opportunity, making aÃ‚&nbsp;highly unusual move to publicize its efforts as Ã¢â‚¬Å“responsible recycling.Ã¢â‚¬ï¿½ But it was the shipbreaking yard, not Carnival, that saw the biggest windfall as a result:Ã‚&nbsp;never before hasÃ‚&nbsp;AliagaÃ‚&nbsp;seen five mega cruise ships in its harbor.</p><p>There may be more coming in the months ahead.</p><p>Ã¢â‚¬Å“The longer the pandemic rages on in the world, the more cruise ships will end up in scrapyards, and my guess is at an increasingly younger age,Ã¢â‚¬ï¿½ says ManWo Ng, a maritime management professor at VirginiaÃ¢â‚¬â„¢s Old Dominion University. Ã¢â‚¬Å“Even if a vaccine becomes available, how many of us will be comfortable jumping right back on cruise ships?Ã¢â‚¬ï¿½</p><p>Ã‚Â©2020 Bloomberg L.P.</p></div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938508</guid>
            <pubDate>Fri, 30 Oct 2020 02:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Clojure?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938484">thread link</a>) | @simonpure
<br/>
October 29, 2020 | https://jeffchen.dev/posts/Why-Clojure/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Why-Clojure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One piece of unattributed wisdom that's stuck with me is "don't take more than one technology bet". At Ladder, our big bet is using <a href="https://clojure.org/" target="_blank" rel="nofollow noopener noreferrer">Clojure</a> for fullstack app development. Ladder's used Clojure since day 1 in 2015, and we wouldn't want it any different! In particular, Clojure's Lisp heritage, focus on pure functions and immutable data structures, unified client-server support, and superior developer experience have helped us write higher quality code faster.</p>
<!-- excerpt -->
<h2>Pure functions and immutability</h2>
<p>One of the challenges with ordinary, imperative programming languages like Javascript or Python is the increasing complexity of state management. As your application grows, it becomes harder and harder to isolate where in the codebase specific changes to your application state occur. This is because with typical application architectures in those languages, any function can perform <a href="https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29" target="_blank" rel="nofollow noopener noreferrer">side effects</a> or modify incoming or global state. On the other hand, Clojure strongly emphasizes working with <a href="https://en.wikipedia.org/wiki/Pure_function" target="_blank" rel="nofollow noopener noreferrer">pure functions</a> (well, if you discount I/O...) and <a href="https://clojure.org/about/state" target="_blank" rel="nofollow noopener noreferrer">immutable data structures</a>. A Clojure programmer must be explicit when defining and modifying mutable state - this helps minimize its usage and makes it easier to reason about.</p>
<p>Immutable data structures and pure functions also lend themselves well to concurrent programming. We rarely find ourselves worrying about locks and shared data in a multi-threaded environment, because our functions are rarely modifying shared state. And when we do, Clojure provides <code>atom</code>, a thread-safe wrapper around ordinary data structures. Behind the scenes, setting an <code>atom</code>'s value calls <code>compare-and-set!</code>. That means no fussing around with locks or mutexes and no worrying about your data changing before you modify it. With this one simple construct, Clojure removes 99% of our concurrency headaches.</p>
<h2>Clojure is a Lisp</h2>
<p>There are probably enough Lisp arguments on the Internet already - I'll defer to <a href="https://clojure.org/about/rationale#_lisp_is_a_good_thing" target="_blank" rel="nofollow noopener noreferrer">Rich Hickey</a> (Clojure's creator) and <a href="http://www.paulgraham.com/avg.html" target="_blank" rel="nofollow noopener noreferrer">Paul Graham</a> instead of adding another rehash. That said, Clojure provides some advantages over other Lisps like Common Lisp and Scheme:</p>
<ul>
<li>CL only includes lists in its core language spec. Clojure introduces vectors, sets, and maps which makes reading and writing code so much less tedious. Of course Scheme has all of these except sets.</li>
<li>Clojure's core data structures are immutable which, as discussed above, makes reasoning about code, especially concurrent code, much easier.</li>
</ul>
<h2>Clojure runs everywhere</h2>
<p>Clojure provides first class support for sharing code between platforms with <a href="https://clojure.org/guides/reader_conditionals" target="_blank" rel="nofollow noopener noreferrer">reader conditionals</a>. Most of our namespaces at Ladder take advantage of this and are shared across our client (Clojurescript) and server (Clojure). In fact, all of our client React code (aside from browser-specific API calls like clipboard, input handlers, etc) supports being run on the JVM. This lets us run what we call "full-stack tests" entirely within a Java process. For example, we can run full user flows like "user can accept a life insurance policy" and assert against both client and server state <strong>in the same test</strong>. The closest analogue without this superpower would be running a Selenium test against a running webserver, which introduces all sorts of potential flakiness. For more on full-stack tests, check out <a href="https://www.youtube.com/watch?v=qijWBPYkRAQ&amp;t=346s" target="_blank" rel="nofollow noopener noreferrer">this talk</a> two of our engineers gave at Clojure West in 2017.</p>
<p>Clojure also provides easy <a href="https://clojure.org/guides/reader_conditionals#_host_interop" target="_blank" rel="nofollow noopener noreferrer">host interop</a> for each supported platform. This lets us leverage the full JVM (and Javascript) ecosystem. For example, we use popular Java libraries like <a href="https://www.eclipse.org/jetty/" target="_blank" rel="nofollow noopener noreferrer">Jetty</a>, <a href="https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients" target="_blank" rel="nofollow noopener noreferrer">kafka-clients</a>, <a href="https://github.com/google/tink" target="_blank" rel="nofollow noopener noreferrer">Tink</a>, and more. On the frontend, we use React, and can easily include other Javascript libraries for analytics, error handling, and session replays.</p>
<h2>Developer experience</h2>
<p>When Iâ€™ve worked with Typescript and Python in the past, I was constantly waiting for my development server to reload. Clojure makes updating code on your local server as simple as reloading the updated namespace in your REPL. If you want, you can even <a href="https://github.com/nrepl/nrepl" target="_blank" rel="nofollow noopener noreferrer">update remote, (hopefully) non-production webservers</a>! Being able to evaluate code in a REPL and have your running web server update in less than a second makes exploration and iteration on your actual backend so much faster. Instant feedback makes developers more playful and experimental. Ultimately, it helps them write better code faster.</p>
<p>Itâ€™s also super easy to run small chunks of code in the REPL. Ladder, like other Clojure shops, has a convention of documenting namespace usage with a <code>comment</code> block at the bottom. Developers can use the code within to learn the namespaceâ€™s API, run commonly used procedures, or test changes to the rest of the namespace - all without leaving their editor!</p>
<h2>Why not Clojure?</h2>
<p>While we're extremely satisfied with our choice of Clojure, we've had our fair share of headaches. First, Clojure processes take a long time to start up - especially as the size of the application grows. Our webserver at Ladder takes a full minute before it can accept web requests. This makes autoscaling in response to load more challenging - some of our load can spike in well under a minute, so we have to be consistently overprovisioned to handle it. Second, Clojure produces pretty big artifacts. This matters less on the backend, where our webserver JAR is over 1.5GB, but hurts us on the frontend. We still have work to do here, but our initial bundle is 7.2MB uncompressed (1.0MB gzipped)! If raw performance or bundle size is your primary concern, you might be better off choosing another language.</p>
<h2>Conclusion</h2>
<p>As a small company, we have more ideas to try than we have bandwidth to implement. Using Clojure has helped our team be more iterative and more productive, so we can ship more experiments and projects than we would otherwise be able to. I feel super lucky that Ladder introduced me to Clojure - and I'm excited to see how Clojure and our use of it continues to evolve!</p>
</div></div>]]>
            </description>
            <link>https://jeffchen.dev/posts/Why-Clojure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938484</guid>
            <pubDate>Fri, 30 Oct 2020 02:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Path for Mastering Japanese]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938456">thread link</a>) | @sova
<br/>
October 29, 2020 | https://japanesecomplete.com/path/ | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/path/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">    
    <!-- Hero section -->
    <section id="hero">
      <!-- Navigation -->
      <nav id="tmNav">              
        
      </nav>
      
      <div>
        <div>
            <h2>Mastering Japanese</h2>
            <p>
              Getting to Native-Level Japanese
              <br>A Straightforward <strong>Path to Mastery</strong>

              <br>by <span>Hake Hayashi</span><br>
              <span>27 October 2020</span>
            </p>
        </div>        
      </div>

            
    </section>

    <section id="introduction">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/castle-sunset.jpg" alt="Japanese Castle at Sunset">
          </p>
          <div>
            <div>
                <h2>The Syllabaries</h2>
                <div><p>
                  The Japanese language, called æ—¥æœ¬èªžï¼ˆã«ã»ã‚“ã”ï¼‰[knee-hohn-go] is composed of 2 major syllabaries, <strong>Hiragana and Katakana.</strong> Made up of <strong>Consonant-Vowel pairs</strong> [ka, ga, ta, su, mu] as opposed to single letters that can be combined in variety, Hiragana and Katakana are two versions of the same collection, Katakana being used for <strong>foreign loan words</strong> since the reorganization of public education in 1962.</p><p>
                  In addition to Hiragana (the native script) and Katakana (reserved for foreign loan-words post-62), Japan imported symbolic glyphs from mainland Asia and they are referred to as æ¼¢å­—ï¼ˆã‹ã‚“ã˜ï¼‰ kanji â€” letters of the Han Dynasty.
              </p></div>
                <p>
                  You can learn the Hiragana in the inside front cover of our <a href="https://japanesecomplete.com/guide">guide</a> that contains information on essential grammar, sentence structure, sound-effect language, and covers some of the more nuanced aspects of the language in plain English.</p>
                  
            </div>
          </div>
        </div>

        <div>
          <div>
            <h4>Hiragana ã²ã‚‰ãŒãª</h4>
            <p>Warm and curvy, the ã²ã‚‰ãŒãª [hiragana] are used for native Japanese words and are the primary phonetic syllabary of Japanese.
            </p>
            <p>ã‚ã€€ã„ã€€ã†ã€€ãˆã€€ãŠ</p>
            <p>ã‹ã€€ãã€€ãã€€ã‘ã€€ã“</p>
            <p>ã•ã€€ã—ã€€ã™ã€€ã›ã€€ã</p>
            <p>ãŸã€€ã¡ã€€ã¤ã€€ã¦ã€€ã¨</p>
            <p>ã¾ã€€ã¿ã€€ã‚€ã€€ã‚ã€€ã‚‚</p>
            <p><a href="https://japanesecomplete.com/guide">Full Hiragana Chart in our Guideâ€¦</a></p>
          </div>
        
        <div>
          <h4>Katakana ã‚«ã‚¿ã‚«ãƒŠ</h4>
          <p>
            The ã‚«ã‚¿ã‚«ãƒŠ [katakana] are sharp and angular, and while letters to friends have been written entirely in Katakana (and Kanji), <a href="https://upload.wikimedia.org/wikipedia/commons/3/3f/Masabumi_Hosono_titanic_diary.jpg">such as this beautiful letter recovered from the Titanic,</a> since 1962 the ã‚«ã‚¿ã‚«ãƒŠ [katakana] have been reserved for foreign loan-words such as "computer" ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ [konpyuuta] and "glass" ã‚¬ãƒ©ã‚¹ [garasu].  <br>ã‚«ã‚¿ã‚«ãƒŠ [katakana] have a one-to-one correlation with the ã²ã‚‰ãŒãª [hiragana] similar to how English has print and cursive.
          </p>
        </div>
        <div>
          <h4>Kanji æ¼¢å­—ï¼ˆã‹ã‚“ã˜ï¼‰</h4>
          <p>
           The æ¼¢å­—ï¼ˆã‹ã‚“ã˜ï¼‰ [kanji] were imported lock, stock, and barrel from mainland Asia starting in the 5th century.  Fewer than 4% of them are pictographs, and over 90% of the kanji are "meaning and sound borrowers."  You can read more about the <a href="https://learnjapanesebest.wordpress.com/2019/12/11/the-four-types-of-kanji/">four types of kanji here.</a>
          </p>
        </div>
      </div>
    </div></section> <!--end part1-->

      <section id="part2">
      <div>
        <div>
          <div>
            <div>
                <h2>Practice Listening + Identifying</h2>
                <p>
                  ã€Œèžãå–ã‚Œãªã„ã€ï¼ˆããã¨ã‚Œãªã„ï¼‰[kiki-torenai] is the Japanese expression for "unable to get a clear ear grab" of a sound or a term when listening.  The audible morphemes of Japanese require plenty of exposure to be able to distinguish them easily, due in part to the clunkiness of the syllabaries, the ã²ã‚‰ãŒãª Hiragana and ã‚«ã‚¿ã‚«ãƒŠ Katakana.  
              </p>
              <p>
                Japanese Complete provides a <a href="https://japanesecomplete.com/path/japanesecomplete.com/hiragana">ã²ã‚‰ãŒãª Hiragana listening challenge</a> for free to all; our ã‚«ã‚¿ã‚«ãƒŠ Katakana listening challenge is available to <a href="https://japanesecomplete.com/purchase">premium subscribers</a>
              </p>
                <p>
                  The site <a href="https://supernative.tv/">SuperNative.tv</a> has an incredible cornucopia of film and television show clips that one can watch on replay with subtitles and fill-in-the-blank exercises to practice the ability to "ear catch" or "ear grab" the audible morphemes of Japanese.  We highly recommend this resource for new learners to get an "ear grip" of the common Japanese sounds and how they are actually pronounced.  Naturally, real-life speech and the way it is written down may not appear to match up perfectly until one has plenty of exposure.</p>
                  
            </div>
          </div>
          <p><img src="https://japanesecomplete.com/img/sakura-close.jpg" alt="Image">
          </p>
        </div>
    </div></section> <!--end part 2-->

  <section id="part3">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/shinkansen-night.jpg" alt="Image">
          </p>
          <div>
            <div>
                <h2>Grammar: Particles</h2>
                <p>
                  Rather than relying on word sequence, Japanese relies on particles to partner with words in order to indicate the role of the word in the sentence.  Think of particles as dancing partners wearing brightly colored clothing who let you know the current occupation of their partner.  A subject dances with a pink-scarf wearing dancer.  A topic dances with a blue-scarf wearing dancer.  A destination of travel dances with a green-scarf wearing dancer.  When we look at the dancers, we can see clearly who they are dancing with, letting us know what the sentence means.  
              </p>
              <p>Particles are used to explain the <strong>who, what, when, where, and how</strong> of Japanese sentences and they are in <strong>post-fix position</strong>, meaning that they follow the words to which they snap.</p>
              <p>Mastery of particles is essential to having a native-level understanding of Japanese.  In fact, by exploring a frequency dictionary or the <a href="https://pj.ninjal.ac.jp/corpus_center/bccwj/en/">Balanced Corpus of Contemporary Written Japanese,</a> one will find that <em>of the 37 most frequent words, 17 of them are particles (45%).</em></p>
                <p>
                  In Japanese Complete we teach particles using a method devised specifically for Japanese Complete and not available elsewhere: <strong>the bunsetsu jar</strong>.  Every jar (which contains a person, place, or thing) needs a lid (which contains a grammatical particle).</p>
                  
            </div>
          </div>
        </div>
    </div></section> <!--end part3-->

      <section id="part4">
      <div>
        <div>
          <div>
            <div>
                <h2>Kanji: Meanings</h2>
                <p>
                  Japan imported symbolic glyphs from mainland Asia and they are referred to as æ¼¢å­—ï¼ˆã‹ã‚“ã˜ï¼‰ kanji â€” letters of the Han Dynasty and there are <a href="https://learnjapanesebest.wordpress.com/2019/12/11/the-four-types-of-kanji/">four types of kanji</a> where only 4% are simple pictographs and over 90% are "meaning-and-sound borrowers."
              </p>
              <p>In acquiring Japanese, modern learners often rely on methods inspired by <a href="https://smile.amazon.com/Remembering-Kanji-Complete-Japanese-Characters/dp/0824835921?pldnSite=1">Heisig's Remembering the Kanji,</a> a book written by James Heisig after he had arrived in Japan too late to take the introductory course; upon asking his friends what the hardest part of the language was, he was quickly informed that the Kanji are a most formidable adversary.  He took the spare time before the next semester started to try his best to conquer this formidable opponent, and in the process discovered that he could break the kanji down section-by-section, part-by-part, and develop clever mnemonic devices and imaginary scenes to remember their <strong>general meanings</strong> for the long-term.
              </p>
                <p>
                  Heisig only provides clear and concise mnemonics for the first hundred-or-so kanji in his series, which is quite deflating to the beginner, leaving much of the creative and mental work to the learner when they could be absorbing, rather than generating, content.  This is the reason that we have taken it upon ourselves at Japanese Complete to provide detailed mnemonic lessons for the kanji we teach.  You can see the most frequent 777 kanji on our <a href="https://japanesecomplete.com/777">777 kanji list.</a></p>
                
            </div>
          </div>
          <p><img src="https://japanesecomplete.com/img/shrine-green.jpg" alt="Image">
          </p>
        </div>
    </div></section> <!--end part 4-->

  <section id="part5">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/himeji-sky.jpg" alt="Image">
          </p>
          <div>
            <div>
                <h2>Verbs: Meanings, Connotations</h2>
                <p>
                  Every Japanese sentence ends with a verb.  Our classification scheme in Japanese Complete comes from conversations with expert language teachers from University College London and Middlebury College, schools renowned for their East Asian studies and language departments.  While normal textbooks try to wedge Japanese grammar as a round peg into the square-hole shape of English, Japanese Complete strives to simplify the equation as much as possible while retaining all the fidelity and integrity of real Japanese.  Our <a href="https://japanesecomplete.com/reverse-engineer/">Reverse Engineering a Japanese Sentence</a> page details how our classification of verbs and nouns differs from common textbooks, and illustrates how they are more coherent with actual Japanese.
              </p>
              <p>In general, verbs are the missing piece of every Japanese sentence and we must wait until the end of the sentence or phrase to hear or read them.  This is what makes translation and interpretation notoriously difficult, for a translator needing a verb to connect two thoughts, nouns, or ideas, must allow the Japanese speaker to complete the phrase, adding a significant delay to the process, all-the-while needing to be able to perceive the beginning of the next phrase.  The latency effect in translating and interpreting Japanese makes this skill quite coveted in tourism, national and international diplomacy, and any role where interpretation in real-time is a must.
              </p>
                <p>
                By learning a large subset of verbs in their "plain-form" first, and then learning how to transform verbs into their variety of tenses and aspects, one builds a solid foundation for understanding written and oral Japanese.  <strong>It is wise to familiarize oneself with the great variety of tenses, active and passive constructions, and formality levels early on, so that they are not completely foreign when encountered later on in advanced studies.</strong>  In Japanese Complete, we teach politeness levels, active and passive tenses, and the variety of verbs early on so that learners have a solid foundation and are not surprised to find whole new constructions in years 3 or 4, but instead are immediately confronted with the variegated tones of the language and its inflexions.
                </p>
                
            </div>
          </div>
        </div>
    </div></section> <!--end part 5-->

      <section id="part6">
      <div>
        <div>
          <div>
            <div>
                <h2>Kanji: Masking</h2>
                <p>
                  Have you ever written a message using emoji only?  Did you know that emoji is a word imported from Japanese?  
              </p>
              <p>
                Just as there are ways to communicate entirely using emoji, Japanese adopted a way early on of using â€¦</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japanesecomplete.com/path/">https://japanesecomplete.com/path/</a></em></p>]]>
            </description>
            <link>https://japanesecomplete.com/path/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938456</guid>
            <pubDate>Fri, 30 Oct 2020 02:19:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting the stock market impact of the Presidential election outcome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938426">thread link</a>) | @greatwave1
<br/>
October 29, 2020 | https://www.quiverquant.com/blog/092420 | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/blog/092420">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="presentation" width="100%"><tbody><tr><td><div id="hs_cos_wrapper_module_16009687456759" data-hs-cos-general-type="widget" data-hs-cos-type="module"><div id="hs_cos_wrapper_module_16009687456759_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><p>The effect of the election on health technology and health services stocks will likely depend not only on who wins the Presidency but also on whether or not Republicans maintain control of the Senate.</p>

<p>If Democrats win both the White House and the Senate (and maintain control of the House) youâ€™ll see revived efforts to pick up the pieces of the Affordable Care Act and continue to transform the U.S. healthcare system. This transformation is likely to come at the expense of private healthcare companies' bottom lines.</p>

<p>On the other hand, Republicans maintaining control of the White House and/or Senate would likely result in a divided government, with no significant legislation on healthcare being passed.</p>

<p><span><strong>Cannabis</strong></span></p>
<p>Not surprisingly, most major cannabis stocks have a very low Trump Beta, meaning they are likely to perform well if Biden is elected.</p>

<p><a href="https://www.quiverquant.com/dashboard/cgc?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">Canopy Growth Corp ($CGC)</a> has a Trump Beta of -0.20, <a href="https://www.quiverquant.com/dashboard/gwph?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">GW Pharmaceuticals ($GWPH)</a> comes in at -0.29, and <a href="https://www.quiverquant.com/dashboard/cron?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">Cronos Group ($CRON)</a> has a Trump Beta of -0.31.</p>

<p>Though Biden took a tough stance on federally controlled substances back in the 1980s and 1990s, he has recently embraced a platform of decriminalizing marijuana. Additionally, running mate Kamala Harris is known as an advocate for legalization. As a junior senator in California, she sponsored the Marijuana Opportunity Reinvestment and Expungement (MORE) Act, which the Democrat-controlled House Judiciary Committee passed last November. The bill hasnâ€™t gotten anywhere yet, but many suppose that a democratic sweep this November could lead to marijuana legalization.</p>

<p>On the other hand, cannabis legislation has not been a priority under Trump, and there is no reason right now to believe that this will change during a second term.</p>

<p><span><strong>Large-cap Tech Companies</strong></span></p>
<p>Companies in the technology services and electronic technology sectors have an average Trump Beta of 0.12 and 0.15, respectively. This is primarily driven by the large-cap tech companies that dominate their industries, with Microsoft, Google, Apple, and Adobe all showing strong positive correlations with a Trump re-election.</p></div></div></td></tr></tbody></div></div>]]>
            </description>
            <link>https://www.quiverquant.com/blog/092420</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938426</guid>
            <pubDate>Fri, 30 Oct 2020 02:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Audio Visualizations Working with Web Audio API]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24938292">thread link</a>) | @arcatech
<br/>
October 29, 2020 | https://dwayne.xyz/post/audio-visualizations-web-audio-api | <a href="https://web.archive.org/web/*/https://dwayne.xyz/post/audio-visualizations-web-audio-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>Web Audio API</h2>
<p>Iâ€™ve been working on getting WebRTC video chat working here on the website for a few weeks now. I finally got to the point where both text, video chat, and screen sharing all work really well, but somewhere in the back of my mind I kept thinking about complaints about â€œ<a href="https://www.psychologytoday.com/us/blog/brain-waves/202007/why-zoom-fatigue-is-real-and-what-you-can-do-about-it">Zoom fatigue</a>â€ during the pandemic:</p>
<blockquote>
<p>Zoom fatigue, Hall argues now, is real. â€œZoom is exhausting and lonely because you have to be so much more attentive and so much more aware of whatâ€™s going on than you do on phone calls.â€ If you havenâ€™t turned off your own camera, you are also watching yourself speak, which can be arousing and disconcerting. The blips, delays and cut off sentences also create confusion. Much more exploration needs to be done, but he says, â€œmaybe this isnâ€™t the solution to our problems that we thought it might have been.â€ Phone calls, by comparison, are less demanding. â€œYou can be in your own space. You can take a walk, make dinner,â€ Hall says.</p>
</blockquote>

<p>Itâ€™s kind of an interesting thing to have on your mind while spending weeks writing/debugging/testing video chat code.</p>
<p>So I decided to add an audio-only mode. And if I was gonna do that, I had to show something cool in place of the video. So I figured I would try to add audio visualizations when one or both of the users didnâ€™t have video on. Using the relatively recent<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> seemed like the right way to go.</p>
<p>Hereâ€™s what I came up with:</p>
<div><video controls="" muted="" autoplay="" playsinline="" loop=""><source src="https://media.dwayne.xyz/blog/audio-visualization.mp4" type="video/mp4"></video><p>Screen recording of the local audio visualization. I cycle through bar graph in light mode, bar graph in dark mode, sine wave in dark mode, then sine wave in light mode.</p></div>
<h2>Creating and hooking up an AnalyserNode</h2>
<p>To create audio visualizations, the first thing youâ€™ll need is an <code>AnalyserNode</code>, which you can get from the <code>createAnalyser</code> method of a <code>BaseAudioContext</code>. You can get both of these things pretty easily<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> like this:</p>
<pre><span>1</span><span>const</span> audioContext <span>=</span> <span>new</span> <span>window</span>.AudioContext();
<span>2</span><span>const</span> analyser <span>=</span> audioContext.createAnalyser();
</pre><p>Next, create a <code>MediaStreamAudioSourceNode</code> from an existing data stream (I use either the local or remote data streams from either <code>getUserMedia</code> or from the â€˜trackâ€™ event of <code>RTCPeerConnection</code> respectively) using <code>AudioContext.createMediaStreamSource</code>. Then you can connect that audio source to the analyser object like this:</p>
<pre><span>1</span><span>const</span> audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(stream);
<span>2</span>audioSource.connect(analyser);
</pre>
<h2>Using requestAnimationFrame</h2>
<p><code>window.requestAnimationFrame</code> is nice. Call it, passing in your drawing function, and then inside that function call <code>requestAnimationFrame</code> again. Get yourself a nice little recursive loop going thatâ€™s automatically timed properly by the browser.</p>
<p>In my situation, there will either be 0, 1, or 2 visualizations running, since either side can choose either video chat, audio-only (â€¦except during screen sharing), or just text chat. So I have one loop that draws both. It looks like this:</p>
<pre><span>1</span><span>const</span> drawAudioVisualizations <span>=</span> () =&gt; {
<span>2</span>    audioCancel <span>=</span> <span>window</span>.requestAnimationFrame(drawAudioVisualizations);
<span>3</span>    localAudioVisualization.draw();
<span>4</span>    remoteAudioVisualization.draw();
<span>5</span>};
</pre><p>I created the class for those visualization objects, and they handle whether or not to draw. They each contain the analyser, source, and context objects for their visualization.</p>
<p>Then when I detect that loop doesnâ€™t have to run anymore, I can cancel it using that <code>audioCancel</code> value:</p>
<pre><span>1</span><span>window</span>.cancelAnimationFrame(audioCancel);
<span>2</span>audioCancel <span>=</span> <span>0</span>;
</pre>
<h2>Configuring the Analyser</h2>
<p>Like in the <a href="https://github.com/mdn/voice-change-o-matic/blob/gh-pages/scripts/app.js">example youâ€™ll see a lot</a> if you look at the MDN documentation for this stuff, I provide options for two audio visualizations: frequency bars and a sine wave. Hereâ€™s how I configure the analyser for each type:</p>
<pre><span> 1</span><span>switch</span> (<span>this</span>.type) {
<span> 2</span>    <span>case</span> <span>'frequencybars'</span><span>:</span>
<span> 3</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span> 4</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span> 5</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.85</span>;
<span> 6</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>256</span>;
<span> 7</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.frequencyBinCount;
<span> 8</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span> 9</span>        <span>break</span>;
<span>10</span>    <span>default</span><span>:</span>
<span>11</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span>12</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span>13</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.9</span>;
<span>14</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>1024</span>;
<span>15</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.fftSize;
<span>16</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span>17</span>        <span>break</span>;
<span>18</span>}
</pre><div><p>Iâ€™ve adjusted these numbers a lot, and Iâ€™m gonna keep doing it. A note about <code>fftSize</code> and <code>frequencyBinCount</code>: <code>frequencyBinCount</code> is set right after you set <code>fftSize</code> and itâ€™s usually just half the <code>fftSize</code> value. These values are about the amount of data you want to receive from the main analyser functions Iâ€™m about to talk about next. As you can see, they directly control the size of the data array that youâ€™ll use to store the audio data on each draw call.
</p></div>
<h2>Using the Analyser</h2>
<p>On each draw call, depending on the type of visualization, call either <code>getByteFrequencyData</code> or <code>getByteTimeDomainData</code> with the array that was created above, and itâ€™ll be filled with data. Then you run a simple loop over each element and start drawing. Hereâ€™s my sine wave code:</p>
<pre><span> 1</span><span>this</span>.analyser.getByteTimeDomainData(<span>this</span>.dataArray);
<span> 2</span><span>this</span>.ctx.lineWidth <span>=</span> <span>2</span>;
<span> 3</span><span>this</span>.ctx.strokeStyle <span>=</span> audioSecondaryStroke;
<span> 4</span>
<span> 5</span><span>this</span>.ctx.beginPath();
<span> 6</span>
<span> 7</span><span>let</span> v, y;
<span> 8</span><span>for</span> (<span>let</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>this</span>.bufferLength; i<span>++</span>) {
<span> 9</span>    v <span>=</span> <span>this</span>.dataArray[i] <span>/</span> <span>128.0</span>;
<span>10</span>    y <span>=</span> v <span>*</span> height <span>/</span> <span>2</span>;
<span>11</span>
<span>12</span>    <span>if</span> (i <span>===</span> <span>0</span>) {
<span>13</span>        <span>this</span>.ctx.moveTo(x, y);
<span>14</span>    } <span>else</span> {
<span>15</span>        <span>this</span>.ctx.lineTo(x, y);
<span>16</span>    }
<span>17</span>
<span>18</span>    x <span>+=</span> width <span>*</span> <span>1.0</span> <span>/</span> <span>this</span>.bufferLength;
<span>19</span>}
<span>20</span>
<span>21</span><span>this</span>.ctx.lineTo(width, height <span>/</span> <span>2</span>);
<span>22</span><span>this</span>.ctx.stroke();
</pre><div><p>The fill and stroke colors are dynamic based on the website color scheme.
</p></div>
<h2>Good ol' Safari</h2>
<p>So I did all of this stuff I just talked about, but for <strong>days</strong> I could <em>not</em> get this to work in Safari. Not because of errors or anything, but because both <code>getByteFrequencyData</code> and <code>getByteTimeDomainData</code> just filled the array with 0s every time. No matter what I did. I was able to get the audio data in Firefox just fine.</p>
<p>So at first, I figured it just didnâ€™t work at all in Safari and I would just have to wait until Apple fixed it. But then I came across <a href="https://mdn.github.io/voice-change-o-matic/">this sample audio project</a> and noticed it worked just fine in Safari.</p>
<div><p>So I studied the code for an hour trying to understand what was different about my code and theirs. I made a lot of changes to my code to make it more like what they were doing. One of the big differences is that theyâ€™re connecting the audio source to different audio distortion nodes to actually change the audio. I just want to create a visualization so I wasnâ€™t using any of those objects.
</p></div>
<h3>Audio Distortion Effects</h3>
<p>The <code>BaseAudioContext</code> has a few methods you can use to create audio distortion objects.</p>
<ul>
<li><code>WaveShaperNode</code>: Use <code>BaseAudioContext.createWaveShaper</code> to create a non-linear distortion. You can use a custom function to change the audio data.</li>
<li><code>GainNode</code>: Use <code>BaseAudioContext.createGain</code> to control the overall gain (volume) of the audio.</li>
<li><code>BiquadFilterNode</code>: Use <code>BaseAudioContext.createBiquadFilter</code> to apply some common audio effects.</li>
<li><code>ConvolverNode</code>: Use <code>BaseAudioContext.createConvolver</code> to apply reverb effects to audio.</li>
</ul>
<p>Each one of these objects has a <code>connect</code> function where you pass another context, output, or filter. Each one has a certain number of inputs and outputs. Hereâ€™s an example from that sample project of connecting all of them:</p>
<pre><span>1</span>source <span>=</span> audioCtx.createMediaStreamSource(stream);
<span>2</span>source.connect(distortion);
<span>3</span>distortion.connect(biquadFilter);
<span>4</span>biquadFilter.connect(gainNode);
<span>5</span>convolver.connect(gainNode);
<span>6</span>gainNode.connect(analyser);
<span>7</span>analyser.connect(audioCtx.destination);
</pre><p><strong>Note</strong>: Donâ€™t connect to your audio context <code>destination</code> if youâ€™re just trying to create a visualization for a call. The user will hear themselves talking.</p>
<div><p>Anyway, I tried adding these things to my code to see if that would get it working in Safari, but I had no luck.
</p></div>
<h2>Figuring out the Safari issue</h2>
<p>I was starting to get <em>real</em> frustrated trying to figure this out. I was gonna let it go when I thought Safari was just broken (because it usually is), but since I knew it <em>could</em> work in Safari, I couldnâ€™t leave it alone.</p>
<p>Eventually I downloaded the actual HTML and Javascript files from that sample and started removing shit from their code, running it locally and seeing if it worked. Which it did. So now Iâ€™m editing my own code, and <em>their code</em>, to get them to be pretty much the same. Which I did. And <strong>still</strong> theirs worked and mine didnâ€™t.</p>
<p>Next I just started desperately logging every single object at different points in my code to figure out what the fuck was going on. Then I noticed something.</p>
<div><p><img src="https://media.dwayne.xyz/blog/audio-context-suspended.png" alt="Dev console showing the output of logging this.audioContext. The state attribute is shown as suspended"></p><p>Output of logging the audio context object.</p></div>
<p>The <code>state</code> is â€œsuspendedâ€? Why? I donâ€™t know. I did the same log in the sample code (that I had downloaded and was running on my machine) and it was â€œrunningâ€.</p>
<p>This is the code that fixes it:</p>
<pre><span>1</span><span>this</span>.audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(<span>this</span>.stream);
<span>2</span><span>this</span>.audioSource.connect(<span>this</span>.analyser);
<span>3</span><span>this</span>.audioContext.resume(); <span>// Why??????
</span></pre><div><p>Calling <code>resume</code> changes the state and then everything works. To this day I still donâ€™t know why the sample code didnâ€™t need that line.
</p></div>
<h2>Drawing the image and supporting light/dark modes</h2>
<p>Like everything else on my site, all of this must support different color schemes (and screen sizes, and mobile devices). That was surprisingly difficult when trying to draw an SVG on the canvas.</p>
<p>Iâ€™m using <a href="https://fontawesome.com/">FontAwesome</a> for all my icons on the site. I wanted to use one of them for these visualizations. The FontAwesome files are all SVGs (which is great), but I didnâ€™t know how to draw the image in different colors in Javascript. The way I decided to do this was to load the SVG file into a Javascript <code>Image</code> object, then draw that onto the canvas each draw call.</p>
<p>That worked, but it only drew it black even after changing the fill and stroke colors. So after some web searching I read about someone deciding to draw out an image on an offscreen canvas, reading all the image data, and â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dwayne.xyz/post/audio-visualizations-web-audio-api">https://dwayne.xyz/post/audio-visualizations-web-audio-api</a></em></p>]]>
            </description>
            <link>https://dwayne.xyz/post/audio-visualizations-web-audio-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938292</guid>
            <pubDate>Fri, 30 Oct 2020 01:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantbase â€“ Deploy your own algo trader in 5 minutes with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938082">thread link</a>) | @tjs8rj
<br/>
October 29, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of usersâ€™ algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938082</guid>
            <pubDate>Fri, 30 Oct 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vega-Lite: A Grammar of Interactive Graphics]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24937954">thread link</a>) | @tosh
<br/>
October 29, 2020 | https://vega.github.io/vega-lite/ | <a href="https://web.archive.org/web/*/https://vega.github.io/vega-lite/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <section>
    <p>
  <strong>Vega-Lite</strong> is a high-level grammar of interactive graphics. It provides a concise, declarative JSON syntax to create an expressive range of visualizations for data analysis and presentation.
</p>

<p><span>
  <span>
    Vega-Lite specifications describe visualizations as encoding mappings from data to <strong>properties of graphical marks</strong> (e.g., points or bars).
    The Vega-Lite compiler <strong>automatically produces visualization components</strong> including axes, legends, and scales.
    It determines default properties of these components based on a set of <strong>carefully designed rules</strong>.
    This approach allows Vega-Lite specifications to be concise for quick visualization authoring, while giving user control to override defaults and customize various parts of a visualization.
    As we also designed Vega-Lite to support data analysis, Vega-Lite supports both <strong>data transformations</strong> (e.g., aggregation, binning, filtering, sorting) and <strong>visual transformations</strong> (e.g., stacking and faceting).
    Moreover, Vega-Lite specifications can be <strong>composed</strong> into layered and multi-view displays, and made <strong>interactive with selections</strong>.
  </span>
  <span>
  <a href="https://vega.github.io/vega-lite/tutorials/getting_started.html">Get started<br><small>Latest Version: 4.17.0</small></a>
  <a href="https://vega.github.io/editor/#/custom/vega-lite">Try online</a>
  </span>
</span></p>

<p>Compared to <a href="https://vega.github.io/vega">Vega</a>, Vega-Lite provides a more concise and convenient form to author common visualizations. As Vega-Lite can compile its specifications to Vega specifications, users may use Vega-Lite as the <em>primary</em> visualization tool and, if needed, transition to use the lower-level Vega for advanced use cases.</p>

<p>For more information, read our <a href="https://medium.com/@uwdata/de6661c12d58">introduction article to Vega-Lite v2 on Medium</a>, watch our <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">OpenVis Conf talk about the new features in Vega-Lite v2</a>, see the <a href="https://vega.github.io/vega-lite/docs/">documentation</a> and take a look at our <a href="https://vega.github.io/vega-lite/examples/">example gallery</a>. Follow us on <a href="https://twitter.com/vega_vis">Twitter at @vega_vis</a> to stay informed about updates.</p>

<h2 id="example">Example</h2>



<h2 id="additional-links">Additional Links</h2>

<ul>
  <li>Award winning <a href="https://idl.cs.washington.edu/papers/vega-lite">research paper</a> and <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">video of our OpenVis Conf talk</a> on the design of Vega-Lite</li>
  <li>Listen to a Data Stories episode about <a href="http://datastori.es/121-declarative-visualization-with-vega-lite-and-altair-with-dominik-moritz-jacob-vanderplas-kanit-ham-wongsuphasawat/">Declarative Visualization with Vega-Lite and Altair</a>
</li>
  <li>
<a href="http://json-schema.org/">JSON schema</a> specification for <a href="https://github.com/vega/schema">Vega-Lite</a> (<a href="https://vega.github.io/schema/vega-lite/v4.json">latest</a>)</li>
  <li>Ask questions about Vega-Lite on <a href="https://stackoverflow.com/tags/vega-lite">Stack Overflow</a> or <a href="https://bit.ly/join-vega-slack-2020">Slack</a>
</li>
  <li>Fork our <a href="https://bl.ocks.org/domoritz/455e1c7872c4b38a58b90df0c3d7b1b9">Vega-Lite Block</a>, or <a href="https://beta.observablehq.com/@domoritz/vega-lite-demo">Observable Notebook</a>.</li>
</ul>

<h2 id="users">Users</h2>

<p>Vega-Lite is used by thousands of data enthusiasts, developers, journalists, data scientists, teachers, and researchers across many organizations. Here are some of them. Learn about integrations on our <a href="https://vega.github.io/vega-lite/ecosystem.html">ecosystem page</a>.</p>



<h2 id="team">Team</h2>

<p>The development of Vega-Lite is led by the alumni and members of the <a href="https://idl.cs.washington.edu/">University of Washington Interactive Data Lab</a> (UW IDL), including <a href="https://twitter.com/kanitw">Kanit â€œHamâ€ Wongsuphasawat</a> (now at Apple), <a href="https://twitter.com/domoritz">Dominik Moritz</a> (now at CMU / Apple), <a href="https://twitter.com/arvindsatya1">Arvind Satyanarayan</a> (now at MIT), and <a href="https://twitter.com/jeffrey_heer">Jeffrey Heer</a> (UW IDL).</p>

<p>Vega-Lite gets significant contributions from its communityâ€“in particular <a href="https://willium.com/">Will Strimling</a>, <a href="https://github.com/YuhanLu">Yuhan (Zoe) Lu</a>, <a href="https://github.com/invokesus">Souvik Sen</a>, <a href="https://github.com/chanwutk">Chanwut Kittivorawong</a>, <a href="https://github.com/mattwchun">Matthew Chun</a>, <a href="https://github.com/AkshatSh">Akshat Shrivastava</a>, <a href="https://github.com/Saba9">Saba Noorassa</a>, <a href="https://github.com/sirahd">Sira Horradarn</a>, <a href="https://github.com/donghaoren">Donghao Ren</a>, and <a href="https://github.com/haldenl">Halden Lin</a>. Please see the <a href="https://github.com/vega/vega-lite/graphs/contributors">contributors page</a> for the full list of contributors.</p>

  </section>
</div></div>]]>
            </description>
            <link>https://vega.github.io/vega-lite/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937954</guid>
            <pubDate>Fri, 30 Oct 2020 00:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standard Bits, an ultra lo-fi video game named after the Mac's graphics blitter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937606">thread link</a>) | @doomlaser
<br/>
October 29, 2020 | https://doomlaser.itch.io/standardbits#game | <a href="https://web.archive.org/web/*/https://doomlaser.itch.io/standardbits#game">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="view_game_page_57023"><p>A downloadable game for Windows and macOS</p><div><div><div><div><div><table><tbody><tr><td>Updated</td><td><abbr title="10 October 2020 @ 02:00"><span></span> 23 days ago</abbr></td></tr><tr><td>Status</td><td><a href="https://itch.io/games/released">Released</a></td></tr><tr><td>Platforms</td><td><a href="https://itch.io/games/platform-windows">Windows</a>, <a href="https://itch.io/games/platform-osx">macOS</a></td></tr><tr><td>Rating</td><td><div title="5.0" itemprop="aggregateRating" itemtype="http://schema.org/AggregateRating" itemscope=""><div content="5.0" itemprop="ratingValue"></div><p><span content="3" itemprop="ratingCount">(3)</span></p></div></td></tr><tr><td>Author</td><td><a href="https://doomlaser.itch.io/">Doomlaser</a></td></tr><tr><td>Genre</td><td><a href="https://itch.io/games/genre-adventure">Adventure</a></td></tr><tr><td>Tags</td><td><a href="https://itch.io/games/tag-abstract">Abstract</a>, <a href="https://itch.io/games/tag-artgame">artgame</a>, <a href="https://itch.io/games/tag-atmospheric">Atmospheric</a>, <a href="https://itch.io/games/tag-experimental">Experimental</a>, <a href="https://itch.io/games/tag-exploration">Exploration</a>, <a href="https://itch.io/games/tag-glitch">glitch</a>, <a href="https://itch.io/games/tag-minimalist">Minimalist</a>, <a href="https://itch.io/games/tag-psychedelic">psychedelic</a>, <a href="https://itch.io/games/tag-walking-simulator">Walking simulator</a>, <a href="https://itch.io/games/tag-weird">weird</a></td></tr><tr><td>Average session</td><td><a href="https://itch.io/games/duration-minutes">A few minutes</a></td></tr><tr><td>Inputs</td><td><a href="https://itch.io/games/input-keyboard">Keyboard</a>, <a href="https://itch.io/games/input-x360">Xbox controller</a>, <a href="https://itch.io/games/input-gamepad">Gamepad (any)</a>, <a href="https://itch.io/games/input-joystick">Joystick</a>, <a href="https://itch.io/games/input-wiimote">Wiimote</a>, <a href="https://itch.io/games/input-playstation">Playstation controller</a>, <a href="https://itch.io/games/input-joy-con">Joy-Con</a></td></tr><tr><td>Accessibility</td><td><a href="https://itch.io/games/accessibility-highcontrast">High-contrast</a>, <a href="https://itch.io/games/accessibility-textless">Textless</a></td></tr><tr><td>Links</td><td><a rel="nofollow noopener" href="http://doomlaser.com/trekking-across-the-northeast-for-gamma-256-and-blip/">Homepage</a></td></tr></tbody></table></div></div></div><div><h2 id="comments">Comments</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fdoomlaser.itch.io%2Fstandardbits" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_widget_28149"><div><div data-post="{&quot;user_id&quot;:43197,&quot;id&quot;:424865}" id="post-424865"><div><a href="https://itch.io/profile/toster12d3"></a><div><div><p>Omg I saw this game on ExperimentalGameplayDotCom years ago!</p><p>It's one of my favorite hm.. objects from there. A pure exploration experience. Thank you for that!<br></p></div></div></div></div></div></div></div></div><div><div><p id="video_embed_widget_99876"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/4mkonvxtT9Y"></iframe></p></div><p><a href="https://img.itch.zone/aW1hZ2UvNTkyMDEvMjY2MjcyLmdpZg==/original/bgTKnU.gif" target="_blank" data-image_lightbox="true"><img src="https://img.itch.zone/aW1hZ2UvNTkyMDEvMjY2MjcyLmdpZg==/347x500/X9%2Bu4%2F.gif"></a></p></div></div></div></div>]]>
            </description>
            <link>https://doomlaser.itch.io/standardbits#game</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937606</guid>
            <pubDate>Fri, 30 Oct 2020 00:02:02 GMT</pubDate>
        </item>
    </channel>
</rss>
