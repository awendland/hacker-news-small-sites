<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 16 Aug 2020 12:24:29 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 16 Aug 2020 12:24:29 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Tell no-one: A century of secret deals between the NSA and the telecom industry]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155374">thread link</a>) | @trymas
<br/>
August 14, 2020 | https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215 | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><a href="https://media.ccc.de/c/31c3">
<img alt="conference logo" src="https://static.media.ccc.de/media/congress/2014/folder-2014.png">
</a>
</p>

<h2>
A century of secret deals between the NSA and the telecom industry
</h2>
</div>
<p>
<span></span>
<a href="https://media.ccc.de/search?p=James+Bamford">James Bamford</a>

</p>
<div data-aspect-ratio="16:9">

<!-- Mediaelement Player -->
<video controls="controls" data-id="2179" data-timeline="https://static.media.ccc.de/media/congress/2014/e8e29f6a-11df-491a-acae-1253879ae8f9-timeline.jpg" height="100%" poster="https://static.media.ccc.de/media/congress/2014/6600-hd_preview.jpg" preload="metadata" width="100%">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/webm-hd/31c3-6600-en-de-Tell_no-one_webm-hd.webm" title="eng 1080p" type="video/webm">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/h264-hd-web/31c3-6600-en-Tell_no-one_hd.mp4" title="eng 1080p" type="video/mp4">
<source data-lang="eng" data-quality="low" src="https://cdn.media.ccc.de/congress/2014/webm-sd/31c3-6600-en-de-Tell_no-one_webm-sd.webm" title="eng 576p" type="video/webm">
<source data-lang="eng" data-quality="low" src="https://cdn.media.ccc.de/congress/2014/h264-sd/31c3-6600-en-de-Tell_no-one_sd.mp4" title="eng 576p" type="video/mp4">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/h264-hd/31c3-6600-en-de-Tell_no-one_hd.mp4" title="eng 1080p" type="video/mp4">
<track kind="metadata" label="thumbnails" src="https://static.media.ccc.de/media/congress/2014/e8e29f6a-11df-491a-acae-1253879ae8f9-thumbnails.vtt" srclang="">

</video>


</div><p>
Playlists:
<a href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/playlist">'31c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/audio">audio</a>
/
<a href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/related">related events</a></p><ul>
<li>
<span></span>
62 min
</li>
<li>
<span title="event and release date"></span>
2014-12-28
</li>
<li>
<span></span>
6224
</li>
<li>
<span></span>
<a href="http://events.ccc.de/congress/2014/Fahrplan/events/6600.html">Fahrplan</a>
</li>
</ul>
<!-- %h3 About -->
<p>For nearly one hundred years, the NSA and its predecessors have been engaging in secret, illegal deals with the American telecom industry, with both virtually immune from prosecution.</p>

<h3>Download</h3>
<div>
<div>
<div>
<p>
<h4>Video</h4>
</p>
<div>
<ul role="tablist">
<li role="presentation">
<a aria-controls="mp4" data-toggle="tab" href="#mp4" role="tab">
MP4
</a>
</li>
<li role="presentation">
<a aria-controls="webm" data-toggle="tab" href="#webm" role="tab">
WebM
</a>
</li>
</ul>
<div>
<div id="mp4" role="tabpanel">
<div>
<a href="https://cdn.media.ccc.de/congress/2014/h264-hd/31c3-6600-en-de-Tell_no-one_hd.mp4">
<p>Download 1080p</p>
<span>eng</span>
<span>484 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/h264-sd/31c3-6600-en-de-Tell_no-one_sd.mp4">
<p>Download 576p</p>
<span>eng</span>
<span>253 MB</span>
</a>
</div>
</div>
<div id="webm" role="tabpanel">
<div>
<a href="https://cdn.media.ccc.de/congress/2014/webm-hd/31c3-6600-en-de-Tell_no-one_webm-hd.webm">
<p>Download 1080p</p>
<span>eng</span>
<span>486 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/webm-sd/31c3-6600-en-de-Tell_no-one_webm-sd.webm">
<p>Download 576p</p>
<span>eng</span>
<span>208 MB</span>
</a>
</div>
</div>
</div>
</div>
</div>
<div>
<p>
<h4>Subtitles</h4>
</p>
<div>
<p><a href="https://www.c3subtitles.de/talk/guid/e8e29f6a-11df-491a-acae-1253879ae8f9" target="_blank">
Help us to subtitle this talk!
</a>
</p></div>
</div>
<div>
<p>
<h4>Audio</h4>
</p>
<div>
<div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/mp3/31c3-6600-en-de-Tell_no-one_mp3.mp3">
<p>Download mp3</p>
<span>eng</span>
<span>85 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/opus/31c3-6600-en-de-Tell_no-one_opus.opus">
<p>Download opus</p>
<span>eng</span>
<span>43 MB</span>
</a>
</div>
</div>
</div>
</div>
</div>

</div>
<h3>Related</h3>
<div>
<div>
<p><a href="https://media.ccc.de/v/32c3-7143-the_state_of_internet_censorship">
<img alt="The state of Internet Censorship" src="https://static.media.ccc.de/media/congress/2015/7143-hd.jpg" title="The state of Internet Censorship">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6175_-_en_-_saal_6_-_201412282300_-_superheroes_still_need_phoneboxes_-_ben_dalton">
<img alt="Superheroes Still Need Phoneboxes" src="https://static.media.ccc.de/media/congress/2014/6175-hd.jpg" title="Superheroes Still Need Phoneboxes">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6121_-_en_-_saal_2_-_201412291715_-_what_ever_happened_to_nuclear_weapons_-_michael_buker">
<img alt="What Ever Happened to Nuclear Weapons?" src="https://static.media.ccc.de/media/congress/2014/6121-hd.jpg" title="What Ever Happened to Nuclear Weapons?">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6595_-_en_-_saal_1_-_201412281900_-_hard_drive_punch_-_aram_bartholl">
<img alt="»Hard Drive Punch«" src="https://static.media.ccc.de/media/congress/2014/6595-hd.jpg" title="»Hard Drive Punch«">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6602_-_en_-_saal_1_-_201412301130_-_the_case_of_chelsea_manning_-_alexa_o_brien_-_nancy_hollander_-_ahmed_ghappour_-_chase_strangio">
<img alt="The case of Chelsea Manning" src="https://static.media.ccc.de/media/congress/2014/6602-hd.jpg" title="The case of Chelsea Manning">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6530_-_en_-_saal_6_-_201412272145_-_in_security_of_mobile_banking_-_ericfiliol_-_paul_irolla">
<img alt="(In)Security of Mobile Banking" src="https://static.media.ccc.de/media/congress/2014/6530-hd.jpg" title="(In)Security of Mobile Banking">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6370_-_en_-_saal_g_-_201412281900_-_internet_of_toilets_-_tbsprs">
<img alt="Internet of toilets" src="https://static.media.ccc.de/media/congress/2014/6370-hd.jpg" title="Internet of toilets">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6430_-_de_-_saal_2_-_201412291130_-_nsa_points_of_presence_in_at_-_erich_moechel">
<img alt="NSA Points of Presence in AT" src="https://static.media.ccc.de/media/congress/2014/6430-hd.jpg" title="NSA Points of Presence in AT">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6244_-_de_-_saal_6_-_201412281245_-_serenitat_anleitung_zum_glucklichsein_-_elektra_-_andrea_behrendt_-_read_delete">
<img alt="Serenität – Anleitung zum Glücklichsein" src="https://static.media.ccc.de/media/congress/2014/6244-hd.jpg" title="Serenität – Anleitung zum Glücklichsein">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_5930_-_en_-_saal_6_-_201412291400_-_funky_file_formats_-_ange_albertini">
<img alt="Funky File Formats" src="https://static.media.ccc.de/media/congress/2014/5930-hd.jpg" title="Funky File Formats">
</a>
</p>
</div>
</div>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>
<div>
<p><a href="https://media.ccc.de/c/31c3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
</p></div>
</div></div>]]>
            </description>
            <link>https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155374</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Save Mozilla]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155372">thread link</a>) | @caisah
<br/>
August 14, 2020 | http://dpk.io/savemozilla | <a href="https://web.archive.org/web/*/http://dpk.io/savemozilla">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  
</header>

<p><i>Disclaimer: I’m not a current or former Mozilla employee and have no other affiliation with Mozilla.</i> This is my own analysis of the publically-available information surrounding Mozilla’s decision to <a href="https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/">radically downsize</a> in a way that seems to further threaten Firefox’s future.

</p><p>A lot of people are very angry at Mozilla’s management for their decision to restructure the foundation, which is <a href="https://twitter.com/withoutboats/status/1217558588857544704">not unreasonable.</a> But seen in context, I think most people would, if in their position, make the same decision.

</p><p>Why is Mozilla cutting staff on its most popular product (Firefox) and refocusing on things that look like unsuccessful stunt projects? <a href="https://medium.com/swlh/could-google-crush-firefox-in-2020-13a55b5d4526">Because they’re about to lose the revenue from it.</a> <em>Google</em> is to blame for not renewing the contract that gives Mozilla a share of the ad revenue from the Firefox search bar. The web browser market has been walking on thin ice since 2008 when Chrome came out, because with Chrome available and under its own control, Google no longer had a reason to support the ecosystem with revenue-sharing deals. Now it seems like Google wants to see just how thin it can make the ice before Mozilla goes under.

</p><p>And why are they focussing on products nobody uses? Because they can make money by selling VPN subscriptions and premium bookmarking accounts without depending on the (obviously limited) goodwill of their competitors.

</p><p>What can you do about this? Here are some suggestions:

</p><ul>
  <li><strong>Buy one of Mozilla’s other products.</strong> It might seem like validating the bad decision made by Mozilla management, but it is reasonable to hope that income from, say, Mozilla VPN might be enough to keep a rag-tag Firefox team going.
  </li><li><strong>Just straight up <a href="https://donate.mozilla.org/">donate to Mozilla.</a></strong> Remember, Mozilla is a non-profit organization. While Google is developing Chrome to strengthen its bottom line and pay out more to shareholders, Mozilla’s interest in the Web platform is actually public-spirited. They fought against DRM in HTML and the mandatory use of patent-encumbered technologies on the open web, and when these efforts failed (largely for the same reasons Google is now able to crush Firefox entirely) they adopted laudable compromises, giving their users a genuine choice about using these technologies. And more than that&nbsp;—&nbsp;they’re actively participating in projects to create new, widely-supported and superior alternatives to these problematic technologies for the future. The web would be a worse place without Mozilla, and for that they deserve your goodwill.
  </li><li><strong>Write to your lawmaker urging an investigation into Google’s anti-competitive practices</strong> in the web browser and web markup space. This could be particularly effective if you live in the EU and write to your European Parliamentarians. Google is probably counting on the Trump administration not caring about their blatant repeat of Microsoft’s anti-trust violations&nbsp;— but other major jurisdictions which still have functioning regulatory systems can make a difference.
  </li><li><strong>Actually use Firefox, or one of its derivatives like the Tor Browser.</strong> One reason Google feels able to do this is probably because of Firefox’s shrinking market share. But Firefox is a vital part of the browser ecosystem, not least as the only major browser left that isn’t based on a WebKit-derivative engine, and as a hackable open-source browser that’s a vital component of equally-vital privacy projects like Tor. And Firefox still has really great features, especially for web developers. Switch back to Firefox&nbsp;— especially if you’re on Chrome!
  </li><li><strong>Switch away from Google products as much as possible.</strong> I know that other web search engines are still embarrassingly bad&nbsp;—&nbsp;I’m not here to guilt-trip anyone into using DuckDuckGo. But if you use Gmail, stop. There are <a href="https://www.fastmail.com/">fantastic</a> <a href="https://protonmail.com/">alternatives</a> out there which, yes, filter spam just as well as Gmail does these days. Use Apple Maps or OpenStreetMap or Yelp instead of Google Maps. Run an ad blocker that blocks YouTube ads, and support your favourite YouTubers directly over Patreon instead.
</li></ul>


</div>]]>
            </description>
            <link>http://dpk.io/savemozilla</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155372</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Epic fight against app store monopolies (Epic Games)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154938">thread link</a>) | @simplertms
<br/>
August 14, 2020 | https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_27_fd5">

<div>
<p>Epic Games introduced an update to their mobile (iOS and Android) version of Fortnite that allows users to buy directly from Epic Games at a 20% discount, removing incentives to pay with the officially sanctioned payment systems on the App Store and Play Store.&nbsp;</p>



<p>Soon after this update, Apple removed Fortnite from its App Store, Google was not far behind in doing the same. In response, Epic Games has filed individual suits against both tech giants claiming that their behaviour is monopolistic control over their respective ecosystems. However, there is some nuance and differences that we should explore between the two ecosystems that could have implications for the validity of the anti-trust lawsuits that Epic will have to contend with.&nbsp;</p>



<p>Looking at the two ecosystems holistically, it is perhaps more appropriate in this case to think of Android and iOS as marketplaces rather than solely focusing on their function as operating systems. The contention is that the marketplaces are being monopolised and controlled to the disadvantage of developers. This is especially true of Apple iOS, where the entire OS is a marketplace, where the App Store is the only access point for third-party applications to the ecosystem. If an application is removed from the App Store, the third-party application simply cannot exist on the iOS ecosystem.&nbsp;</p>



<p>Comparatively, Google’s Android OS functions a little differently. The OS acts as an open ecosystem which is augmented by the Play Store. The Play Store, not the OS, is the marketplace – the place for discovery. The Play Store as a standalone application can have comparative and competitive marketplaces on the Android OS, like the Samsung store. Further, the Android OS allows for third-party installs of applications albeit with security warnings.&nbsp;</p>



<p>Epic might have a hard time arguing that Google is being anti-competitive when it has avenues of access – albeit less direct – outside of the Google Play Store. Applications can still exist within the Android ecosystem even when the Play Store removes listings according to their marketplace rules.</p>



<p>Apple, on the other hand, has its entire ecosystem siloed as a marketplace, with no third-party marketplaces allowed and no ability to legally install third-party applications – placing them in a much more difficult position when it comes to anti-competitive claims. In recent months, Apple has come under increasing scrutiny as they butt heads with application developers, most notably Hey email client, Google’s Stadia platform and Microsoft’s xCloud platform.&nbsp;</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>
</div></div><div data-td-block-uid="tdi_28_955">

<div><h3><span>CONTACT THE EDITOR</span></h3>
<p>We welcome thoughtful discourse on all our content. If you would like to further explore or discuss any of the ideas covered in this article please contact our editors directly.<br><span>Contact Details</span></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154938</guid>
            <pubDate>Fri, 14 Aug 2020 07:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Rust Lambdas in Production]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154506">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://www.cvpartner.com/blog/using-rust-lambdas-in-production | <a href="https://web.archive.org/web/*/https://www.cvpartner.com/blog/using-rust-lambdas-in-production">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-c687bec1ed8c-01d6604b"><p><img src="https://assets.website-files.com/56d31f469aaa616f5089a267/5f23ffebdba110f2cab1d06d_Rust%20Lambda.png" alt=""></p></figure><div><p>Update:&nbsp;Join the discussion over at <a href="https://news.ycombinator.com/item?id=24154506">HackerNews</a>! </p><p>We’ve written in the past about how the CV Partner web application is written in Ruby on Rails. The web application isn’t the whole story, though. Surrounding it are many supporting services, and we are increasingly using Rust to write these services.</p></div><p>We’re also using more Lambdas in our architecture, and we want to use Rust in those as well. The landscape for Rust lambdas isn’t barren, but it’s not well-trodden either.<br></p><p>This post is going to cover how we write, build, and deploy our Rust lambdas. Our lambdas have the following qualities that we’re proud of and want to share with you:<br></p><ol role="list"><li><strong>Fast, standardised build.</strong> All of our lambdas use the same Dockerfile to build, and make good use of Docker’s layer caching. Incremental builds in CI take under a minute.</li><li><strong>Run locally. </strong>If you’re working on a lambda, you don’t want to have to sit through a CI build to see if your changes work. All of our lambdas can run locally and in AWS using the same code.</li><li><strong>Private GitHub dependencies. There aren’t many options out there for private Cargo repositories, so we use private GitHub repositories for our internal libraries.</strong></li></ol><h2>The code<br></h2><p>The starting point for writing a Lambda in Rust is to use the official <a href="https://github.com/awslabs/aws-lambda-rust-runtime">Rust lambda runtime</a>. At the time of writing, the last release of this library is version 0.2, which doesn’t support async/await. Async/await support is present in master, though. Here’s how it looks in practice:</p><div><pre><code>
use lambda::{lambda, Context};
use serde_json::Value;

type Error = Box<dyn std::error::error="" +="" send="" sync="" 'static="">;

#[lambda]
#[tokio::main]
async fn main(event: Value, _: Context) -&gt; Result<value, error=""> {
    Ok(event)
}

</value,></dyn></code></pre></div><p>The problem with this is that you can’t run it locally. The #[lambda] attribute wraps your main function in another main function that calls in to the AWS lambda API.<br></p><p>To get around this, we write two main functions:<br></p><div><pre><code>

#[cfg(feature = "with-lambda")]
use lambda::{lambda, Context};
use serde::{Deserialize, Serialize};

type Error = Box<dyn std::error::error="" +="" send="" sync="" 'static="">;

#[derive(Deserialize, Debug)]
struct Input {
    name: String
}

#[derive(Serialize, Debug)]
struct Output {
    greeting: String
}

async fn handler(input: Input) -&gt; Result<output, error=""> {
    Ok(Output { greeting: format!(“Hello, {}!”, input.name) })
}

#[cfg(feature = "with-lambda")]
#[lambda]
#[tokio::main]
async fn main(input: Input, _: Context) -&gt; Result<output, error=""> {
    handler(input).await
}

#[cfg(not(feature = "with-lambda"))]
#[tokio::main]
async fn main() -&gt; Result&lt;(), Error&gt; {
    let input_str = std::env::args().nth(1);
    if input_str.is_none() {
        panic!(
            "you must pass an input parameter as the first argument, and it must be a JSON string"
        );
    }
    let input = serde_json::from_str(&amp;input_str.unwrap())?;
    let output = handler(input).await?;
    println!("{}", serde_json::to_string(&amp;output)?);
    Ok(())
}

</output,></output,></dyn></code></pre></div><p>We’re making use of Rust’s “feature” flags to compile a different harness around the handle function depending on whether we want to run locally or in AWS.</p><p>Here’s the Cargo.toml file:</p><div><pre><code>
[package]
name = "rust-lambda-template"
version = "0.1.0"
authors = ["Sam Rose <sam@cvpartner.com>"]
edition = "2018"

[dependencies]
lambda = { git = "https://github.com/awslabs/aws-lambda-rust-runtime/", rev = "c8dbcd39e0b1cf9ecf395e2b2f9df6c6c0d97780" }
tokio = { version = "0.2", features = ["full"] }
serde = { version = "1", features = ["derive"] }
serde_derive = "1"
serde_json = "1"

[features]
with-lambda = []

</sam@cvpartner.com></code></pre></div><p>Two noteworthy things:<br></p><ol role="list"><li>We’re using a version of the aws-lambda-rust-runtime that hasn’t officially been released. This isn’t ideal, and we’re eagerly awaiting a 0.3 release.</li><li>We have a features section, which is where we define the with-lambda feature we use in the Rust code shown above.<br></li></ol><p>Running our lambda now gives us the following:</p><div><pre><code>
$ cargo run -- ‘{ “name”: “Sam” }’
{ “message”: “Hello, Sam!” }

</code></pre></div><h2><strong>The Dockerfile</strong></h2><p>All of our lambdas build with the same Dockerfile. I’ll show it in all of its glory and then explain what’s going on bit by bit. Brace yourself.</p><div><pre><code>
# syntax=docker/dockerfile:experimental

FROM rust:latest as cargo-build
ARG name

RUN apt-get update
RUN apt-get install musl-tools -y
RUN rustup target add x86_64-unknown-linux-musl

WORKDIR /usr/src/${name}
COPY Cargo.toml Cargo.toml
RUN mkdir src/
RUN echo "fn main() {println!(\"if you see this, the build broke\")}" &gt; src/main.rs
RUN mkdir -p $HOME/.ssh
RUN ssh-keyscan github.com &gt; $HOME/.ssh/known_hosts
RUN test "$(cat $HOME/.ssh/known_hosts | ssh-keygen -lf -)" = "2048 SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8 github.com (RSA)"
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

RUN rm src/main.rs
COPY src/* src
RUN touch src/**
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo test --features with-lambda --release --target=x86_64-unknown-linux-musl
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

FROM alpine:latest
ARG name
COPY --from=cargo-build /usr/src/${name}/target/x86_64-unknown-linux-musl/release/${name} /usr/local/bin/${name}

</code></pre></div><p>First of all, shout out to Shane Utt whose <a href="https://shaneutt.com/blog/rust-fast-small-docker-image-builds/">blog post</a> we used as a starting point for this.<br></p><p>The first line is a Docker directive that says we want to use some experimental Dockerfile syntax. The syntax in question is the --mount=type=ssh flag to the RUN commands, but we’ll talk about later.</p><div><pre><code>
FROM rust:latest as cargo-build
ARG name

</code></pre></div><p>This next bit says we want to use the latest Rust image, and we’re passing in a build arg called “name.” This is how we’re able to share this Dockerfile between all of our lambdas without having to modify it.</p><div><pre><code>
RUN apt-get update
RUN apt-get install musl-tools -y
RUN rustup target add x86_64-unknown-linux-musl

</code></pre></div><p>Next we run an update on the image, and we install <a href="https://musl.libc.org/">musl</a>. If you’re not familiar, musl is a libc replacement that you can link to statically. This means the resulting binary won’t depend on the system’s libc, which makes it more portable. It’s not a strict requirement for running on AWS Lambda, but it’s good practice.</p><div><pre><code>
WORKDIR /usr/src/${name}
COPY Cargo.toml Cargo.toml
RUN mkdir src/
RUN echo "fn main() {println!(\"if you see this, the build broke\")}" &gt; src/main.rs

</code></pre></div><p>The next few lines set up a pseudo project, where the only things we’re going to compile are our dependencies and a dummy main.rs. The idea behind this is to use Docker’s layer caching to avoid having to compile our dependencies every build. This leads to significantly faster incremental builds in Docker.</p><div><pre><code>
RUN mkdir -p $HOME/.ssh
RUN ssh-keyscan github.com &gt; $HOME/.ssh/known_hosts
RUN test "$(cat $HOME/.ssh/known_hosts | ssh-keygen -lf -)" = "2048 SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8 github.com (RSA)"

</code></pre></div><p>Up until now, we’ve done exactly what Shane Utt did in his version of this. These three lines, though, are new. Because we use SSH to fetch private dependencies (more on this later), we would sometimes find that our builds would fail with the error “host key verification failed.” To get around that we pull down GitHub’s host keys and make sure they’re what we expect them to be based on the values <a href="https://docs.github.com/en/github/authenticating-to-github/githubs-ssh-key-fingerprints">here</a>.</p><div><pre><code>
RUN mkdir -p $HOME/.ssh
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

</code></pre></div><p>Our first bit of experimental syntax! The --mount flag is a new thing introduced with the BuildKit engine for Docker, you can read about it in depth <a href="https://medium.com/@tonistiigi/build-secrets-and-ssh-forwarding-in-docker-18-09-ae8161d066">here</a>. The type=ssh bit is us telling Docker that we want to use an SSH agent for this command. In the docker build invocation, which we’ll see later, we can tell Docker what keys to add to this SSH agent.</p><p>The reason we do this is because it was the only way we could find that let us depend on private GitHub repositories in our Cargo.toml file, in a way that worked both locally and in CI. It means we can do this in our Cargo.toml file:</p><div><pre><code>
[dependencies]
private-library = { git = "ssh://github.com/cvpartner/private-library", tag = "1.0" }

</code></pre></div><p>And it Just Works<strong>™</strong>.</p><p>The rest of the RUN command is our first cargo build. It looks a lot scarier than it is. Most of it is us telling rustc to link against musl instead of the default libc. The only other interesting bit is the --features with-lambda. This matches up with the code we saw earlier to produce a binary that’s going to work properly when deployed in AWS.</p><div><pre><code>
RUN rm src/main.rs
COPY src/* src
RUN touch src/**
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo test --features with-lambda --release --target=x86_64-unknown-linux-musl
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

</code></pre></div><p>Next up, we’re copying over our actual source code. The touch command is necessary for cargo to realise the files are new, because when we created our dummy main.rs file earlier we created a new file with a timestamp later than the one on the real main.rs file. This is different to the approach taken by Shane Utt, as we found that approach would often result in builds where the dummy main.rs file was the one that ended up in the final build.</p><p>Another addition is the cargo test invocation. Tests are good!</p><div><pre><code>
FROM alpine:latest
ARG name
COPY --from=cargo-build /usr/src/${name}/target/x86_64-unknown-linux-musl/release/${name} /usr/local/bin/${name}

</code></pre></div><p>Lastly we create a new build stage and copy over the final executable. The new build stage is in order to keep the final image small. Ours tend to clock in at around 8MB.<br></p><h2><strong>The build script</strong><br></h2><p>Invoking Docker is done in a shell script which is also identical for all of our lambdas.</p><div><pre><code>
#!/usr/bin/env bash

set -e
set -x

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &amp;&amp; pwd )"
cd $DIR

NAME=$(cat Cargo.toml | grep "name" | head -n 1 | sed -E 's/name = "(.*)"/\1/')
DOCKER_NAME="cvpartner/$NAME"

if [[ -z $BUILD_ID ]];
then
  TAG=$DOCKER_NAME
  SSH="--ssh default"
else
  TAG="our.private.docker.registry/$DOCKER_NAME"
  SSH="--ssh default=/home/ci/.ssh/id_rsa"
fi

DOCKER_BUILDKIT=1 docker build $SSH --cache-from $TAG …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cvpartner.com/blog/using-rust-lambdas-in-production">https://www.cvpartner.com/blog/using-rust-lambdas-in-production</a></em></p>]]>
            </description>
            <link>https://www.cvpartner.com/blog/using-rust-lambdas-in-production</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154506</guid>
            <pubDate>Fri, 14 Aug 2020 06:39:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing a Type-safe printf in Rust]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24154263">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://willcrichton.net/notes/type-safe-printf/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/type-safe-printf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; — &nbsp;
    June 21, 2020
  </p>
  <p>I show how to use heterogeneous lists and traits to implement a type-safe printf in Rust. These mechanisms can ensure that two variadic argument lists share important properties, like the number of format string holes matches the number of printf arguments.</p>
  <p><em>Part of an ongoing series about type-level programming in Rust. Consider reading <a href="http://willcrichton.net/notes/type-level-programming/">part one</a> first! All code in this note can be found in <a href="https://gist.github.com/willcrichton/e7fcf1b0e84b4be7f172f0e0245cf149">this gist</a>.</em></p>

<p>Rust has a great printf function, <a href="https://doc.rust-lang.org/std/macro.println.html"><code>println!</code></a>. It has a rich formatting language, but also catches mistakes at compile-time. For example, <code>println!</code> will check that the number of arguments matches the number of holes in the format string:</p>

<div><div><pre><code>error: 2 positional arguments in format string, but there is 1 argument
  --&gt; src/printf.rs:36:13
   |
36 |   println!("{} {}", "Hello");
</code></pre></div></div>

<p>How does the Rust compiler make this check? Because both the format string and the argument are within the macro, Rust will check that the number of holes matches the number of arguments. Consequently, format strings <em>have</em> to be within the macro. If we write:</p>

<div><div><pre><code><span>let</span> <span>s</span> <span>=</span> <span>"{} {}"</span><span>;</span>
<span>println!</span><span>(</span><span>s</span><span>,</span> <span>"hi"</span><span>)</span>
</code></pre></div></div>

<p>This code fails to compile with the error:</p>

<div><div><pre><code>error: format argument must be a string literal
  --&gt; src/printf.rs:42:12
   |
42 |   println!(s, "hi");
</code></pre></div></div>

<p>I’ll show you how to implement type-safe printf without using procedural macros. More generally, this note contains a Rust recipe for functions where:</p>

<ol>
  <li>Arguments are variadic</li>
  <li>Each argument can be a different type (<code>Vec&lt;T&gt;</code> not allowed)</li>
  <li>Multiple variadic inputs share a parallel property, e.g. the number of arguments should match the number of format holes</li>
</ol>

<h2 id="core-mechanism-hlist">Core mechanism: HList</h2>

<p>First, we need to understand the main type-level mechanism: a heterogeneous list (or H-list). An H-list is a sequence of values of potentially different types. For example, <code>[1, "a", true]</code> is an H-list, but not a valid Rust vector. H-lists are implemented in Rust using a linked-list style:</p>

<div><div><pre><code><span>struct</span> <span>HNil</span><span>;</span>
<span>struct</span> <span>HCons</span><span>&lt;</span><span>Head</span><span>,</span> <span>Tail</span><span>&gt;</span> <span>{</span>
  <span>head</span><span>:</span> <span>Head</span><span>,</span>
  <span>tail</span><span>:</span> <span>Tail</span>
<span>}</span>

<span>let</span> <span>example</span><span>:</span> <span>HCons</span><span>&lt;</span><span>i32</span><span>,</span> <span>HCons</span><span>&lt;</span><span>bool</span><span>,</span> <span>HNil</span><span>&gt;&gt;</span> <span>=</span>
  <span>HCons</span><span>{</span><span>head</span><span>:</span> <span>1</span><span>,</span> <span>tail</span><span>:</span> <span>HCons</span><span>{</span><span>head</span><span>:</span> <span>true</span><span>,</span> <span>tail</span><span>:</span> <span>HNil</span><span>}};</span>
</code></pre></div></div>

<p>The key idea is that the type of an H-list changes every time you make a change to it. By contrast, if you push to a <code>Vec&lt;T&gt;</code>, the type of the vector stays the same.</p>

<p>Just like Rust has <code>vec![]</code>, we can use the <a href="https://github.com/lloydmeta/frunk#hlist">frunk</a> crate to get an <code>hlist!</code> macro.</p>

<div><div><pre><code><span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span><span>1</span><span>,</span> <span>true</span><span>];</span> <span>// same as above</span>
</code></pre></div></div>

<h2 id="setting-up-printf">Setting up printf</h2>

<p>Let’s go back to the ingredients of printf. We need a format string and an argument list. The key idea is to represent both with an H-list, and carefully use Rust’s traits to ensure our desired property: the number of arguments should match the number of holes.</p>

<p>First, to represent format strings, we will have a sequence of structs that represent each part of the string.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>FString</span><span>(</span><span>&amp;</span><span>'static</span> <span>str</span><span>);</span>
<span>pub</span> <span>struct</span> <span>FVar</span><span>;</span>

<span>// Assume that we compile "Hello {}! The first prime is {}" into this code.</span>
<span>// That would be a simple syntactic transformation.</span>
<span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span>
  <span>FString</span><span>(</span><span>"Hello "</span><span>),</span> <span>FVar</span><span>,</span> <span>FString</span><span>(</span><span>"! The first prime is "</span><span>),</span> <span>FVar</span>
<span>];</span>
</code></pre></div></div>

<p>To represent arguments, we will use a matching H-list of values. For example:</p>

<div><div><pre><code><span>let</span> <span>args</span> <span>=</span> <span>hlist!</span><span>[</span><span>"world"</span><span>,</span> <span>2</span><span>];</span>
</code></pre></div></div>

<p>Then, our goal is to create a function <code>format</code> such that this is true:</p>

<div><div><pre><code><span>assert_eq!</span><span>(</span>
  <span>example</span><span>.format</span><span>(</span><span>args</span><span>),</span>
  <span>"Hello world! The first prime is 2"</span>
<span>);</span>
</code></pre></div></div>

<p>And this should be a compile-time (NOT run-time) error:</p>

<div><div><pre><code><span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"Only one arg"</span><span>]);</span>
</code></pre></div></div>

<h2 id="the-format-trait">The Format trait</h2>

<p>In the spirit of type-level computation, we start by defining a trait.</p>

<div><div><pre><code><span>trait</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span> <span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>ArgList</span><span>)</span> <span>-&gt;</span> <span>String</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Here, <code>self</code> is the H-list of the format directives, and <code>ArgList</code> is the H-list of the variadic arguments. <code>Format</code> need to take <code>ArgList</code> as a type parameter, because its type will change as we remove elements from the <code>ArgList</code> list.</p>

<p>Now, we proceed to implement the <code>Format</code> trait by cases. First, the base case for reaching the end of the format list <code>HNil</code>:</p>

<div><div><pre><code><span>impl</span> <span>Format</span><span>&lt;</span><span>HNil</span><span>&gt;</span> <span>for</span> <span>HNil</span> <span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_</span><span>args</span><span>:</span> <span>HNil</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>""</span><span>.to_string</span><span>()</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This impl says that when we reach the end of a format list, just return the empty string. And the only argument we will accept is an empty argument list. Combined with the next impls, this inductively ensures that extra arguments are not accepted.</p>

<p>Next, we will implement <code>FString</code>. This implementation should use the string constant contained in the <code>FString</code> struct, and combine it recursively with the rest of the format list. We don’t use variadic arguments for <code>FString</code>, so they get passed along. In Rust, this English specification becomes:</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FString</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span> <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>ArgList</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>self</span><span>.head</span><span>.</span><span>0</span><span>.to_owned</span><span>()</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Note that we have to add <code>FmtList: Format&lt;ArgList&gt;</code> to ensure the recursive call to <code>self.tail.format</code> works. Also note that we aren’t implementing <code>Format</code> directly on <code>FString</code>, but rather on an H-list containing <code>FString</code>.</p>

<p>Finally, the most complex case, <code>FVar</code>. We want this impl to take an argument from the <code>ArgList</code>, then format the remaining format list with the remaining arguments.</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FVar</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span>
  <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span><span>,</span>
  <span>T</span><span>:</span> <span>ToString</span><span>,</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>args</span><span>.head</span><span>.to_string</span><span>()</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>.tail</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Be careful to observe which H-list is being accessed by <code>head</code> and <code>tail</code>. Here, the <code>args</code> H-list provides the data to fill the hole via <code>args.head</code>.</p>

<h2 id="checking-our-properties">Checking our properties</h2>

<p>With this implementation, our correct example successfully compiles and runs:</p>

<div><div><pre><code><span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span>
  <span>FString</span><span>(</span><span>"Hello "</span><span>),</span> <span>FVar</span><span>,</span> <span>FString</span><span>(</span><span>"! The first prime is "</span><span>),</span> <span>FVar</span>
<span>];</span>
<span>assert_eq!</span><span>(</span>
  <span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"world"</span><span>,</span> <span>2</span><span>]),</span>
  <span>"Hello world! The first prime is 2"</span>
<span>);</span>
</code></pre></div></div>

<p>What about our incorrect example? If we write this:</p>

<div><div><pre><code><span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"just one arg"</span><span>]);</span>
</code></pre></div></div>

<p>This code fails to compile with the error:</p>

<div><div><pre><code>error[E0308]: mismatched types
  --&gt; src/printf.rs:48:18
   |
48 |   example.format(hlist!["just one arg"]);
   |                  ^^^^^^^^^^^^^^^^^^^^^^
   |                  expected struct `Cons`, found struct `HNil`
   |
   = note: expected struct `HCons&lt;_, HNil&gt;`
              found struct `HNil`
</code></pre></div></div>

<p>While the error is enigmatic, our mistake is at least correctly caught at compile-time. This is because Rust deduces that <code>example.format()</code> expects an H-list of the shape <code>HCons&lt;_, HCons&lt;_, HNil&gt;&gt;</code>, but it finds <code>HNil</code> too soon in our 1-element H-list. A similar error occurs when providing too many args.</p>

<p>Stupendous! We have successfully implemented a type-safe printf using H-lists and traits.</p>

<h2 id="extending-our-abstraction">Extending our abstraction</h2>

<p>Right now, our <code>Format</code> function just checks that the format list and argument list are the same length. We could extend our format structures, for example to ensure that an <code>FVar</code> must be a particular type, or must use <code>Debug</code> vs. <code>Display</code>. Here’s the sketch of such a strategy:</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>PhantomData</span><span>;</span>

<span>// Add flags for whether using Display or Debug</span>
<span>pub</span> <span>struct</span> <span>FDisplay</span><span>;</span>
<span>pub</span> <span>struct</span> <span>FDebug</span><span>;</span>

<span>// Use a type parameter with PhantomData to represent the intended type</span>
<span>pub</span> <span>struct</span> <span>FVar</span><span>&lt;</span><span>T</span><span>,</span> <span>Flag</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>Flag</span><span>)</span><span>&gt;</span><span>);</span>

<span>// Now, T has to be the same between the format list and arg list</span>
<span>// Also, FDisplay flag requires that `T: Display`</span>
<span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FVar</span><span>&lt;</span><span>T</span><span>,</span> <span>FDisplay</span><span>&gt;</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span>
  <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span><span>,</span>
  <span>T</span><span>:</span> <span>Display</span><span>,</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>// using format! is cheating, but you get the idea</span>
    <span>format!</span><span>(</span><span>"{}"</span><span>,</span> <span>args</span><span>)</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>.tail</span><span>)</span>
  <span>}</span>
<span>}</span>

<span>// Similar impl for `T: Debug` when `FDebug` is used</span>
</code></pre></div></div>

<p>With this approach, if our format list and arg list differ in type:</p>

<div><div><pre><code><span>let</span> <span>fmt</span> <span>=</span> <span>hlist!</span><span>[</span><span>FString</span><span>(</span><span>"n: "</span><span>),</span> <span>FVar</span><span>::</span><span>&lt;</span><span>i32</span><span>,</span> <span>FDisplay</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>)];</span>
<span>fmt</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"not a number"</span><span>]);</span>
</code></pre></div></div>

<p>Then the code will not compile with the error, <code>&amp;'static str is not i32</code>.</p>

<p>Shout-out to <a href="https://www.servant.dev/posts/2018-07-12-servant-dsl-typelevel.html">this blog post</a> from Haskell’s servant framework which got me thinking about adapting their strategy into Rust.</p>

</div></div>]]>
            </description>
            <link>https://willcrichton.net/notes/type-safe-printf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154263</guid>
            <pubDate>Fri, 14 Aug 2020 06:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Save the USPS]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 206 (<a href="https://news.ycombinator.com/item?id=24153311">thread link</a>) | @mooreds
<br/>
August 13, 2020 | https://2pml.com/2020/08/10/usps/ | <a href="https://web.archive.org/web/*/https://2pml.com/2020/08/10/usps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12653">
	<!-- .entry-header -->

	<div>
		<p><img data-attachment-id="12682" data-permalink="https://2pml.com/2020/08/10/usps/cvbbjbi0/" data-orig-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=1600%2C1144&amp;ssl=1" data-orig-size="1600,1144" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cVBbjbi0" data-image-description="" data-medium-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=300%2C215&amp;ssl=1" data-large-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=740%2C529&amp;ssl=1" loading="lazy" src="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=740%2C529&amp;ssl=1" alt="cVBbjbi0" width="740" height="529" srcset="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?w=1600&amp;ssl=1 1600w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=300%2C215&amp;ssl=1 300w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=1024%2C732&amp;ssl=1 1024w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=768%2C549&amp;ssl=1 768w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=1536%2C1098&amp;ssl=1 1536w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?w=1480&amp;ssl=1 1480w" sizes="(max-width: 740px) 100vw, 740px" data-recalc-dims="1"></p>
<p>There are three types of infrastructure. One is visible: roads, dams and bridges. The second is invisible: broadband internet provisions and the entirety of our cellular infrastructure. Both are still vital in building our present. The third form of infrastructure is one being rebuilt in order to be repurposed for future use. I explained in <em>J-Curves and Agglomeration</em>:</p>
<blockquote><p>The U.S. Postal Service is a key component of the eCommerce economy. Packages are just 5% of its shipping volume but eCommerce accounts for nearly 30% of the agency’s revenue. Partnerships with vendors like Amazon (or providers like FedEx and UPS) provide a majority of its package volume but small businesses and direct-to-consumer brands rely on USPS’ pricing. Raising costs on retailers may lead to more attrition. […]</p>
<p>By raising prices to combat Amazon’s growing influence over the economy, disrupting the postal economy is no different than digging up paved roads before a period of heightened freight transit. [<a href="https://2pml.com/2020/05/18/agglomeration/">2PM, 1</a>]</p></blockquote>
<p>The U.S. Postal Service is all three. When an American institution is 250 years old, it may as well be the ground that we stand on. The service has contributed services and innovations that we don’t readily attribute to it. Consider its contribution to the middle class: the U.S. Postal Service is one the country’s biggest employers with nearly 330,000 career employees and an average salary of $50,000. They are building the future of eCommerce, a still-nascent industry.</p>
<p>Critics of the USPS will cite cost of labor as a reason for the service’s obsolescence. A common refrain is “Why couldn’t Amazon takeover the service?” Consider that in the fourth quarter of 2019, eCommerce was just 11.9% of all retail. Amazon constituted right under half of that volume. And without the postal service, Amazon would not exist. The market costs of shipment subsidized a number of Amazon’s operations, allowing it to capture market share.</p>
<h2>“The Ground We Stand On”</h2>
<p>The postal service began before the founding of the United States. Benjamin Franklin was fired from his role as postmaster due to his involvement with the American Revolution. Just one year later in 1775, the Continental Congress appointed Franklin the Postmaster General of the “United Colonies.” His tenure left a mail system that offered service between the then-colonies and Great Britain. By 1802, the first African-Americans to work for the Postal Service were enslaved mail carriers. Senator James Jackson of Georgia, Chairman of the Committee of the Senate on the Post Office Establishment, once wrote:</p>
<blockquote><p>… The most active and intelligent [slaves] are employed as post riders. By travelling from day to day, and hourly mixing with people […] they will acquire information. They will learn that a man’s rights do not depend on his color. They will, in time, become teachers to their brethren.</p></blockquote>
<p>Within two months of Senator Jackson’s proclamation, African-Americans would be banned from the postal service, lasting from 1802 to March 1865, just one month before the conclusion of the Civil War. This disbarment ended by congressional decree.</p>
<blockquote><p>No person, by reason of color, shall be disqualified from employment in carrying the mails. (13 Stat. 515)</p></blockquote>
<p>The next decades would see an unparalleled push for African-American financial stability. Nearly 800 would serve as postal employees prior to the 20th century. More than 200 African Americans are known to have served in the high rank of postmaster prior to the conclusion of Reconstruction and the Progressive Era (1863-1920). Of them, nearly 20 were women. The postal service has always been politicized.</p>
<p>Soon after, the U.S. Government expanded on the postal service’s role in democratizing America, both literally and figuratively. President Theodore “Teddy” Roosevelt expanded on this with the <em>Square Deal</em> in 1902, communicating a fairness policy in hiring and leadership. The result was momentous for many. Roosevelt stated:</p>
<blockquote>
<p>It is and should be my consistent policy in every State, where their numbers warranted it, to recognize colored men of good repute and standing in making appointments to office. […] I can not consent to take the position that the door of hope – the door of opportunity – is to be shut upon any man, no matter how worthy, purely upon the grounds of race or color. <a href="https://about.usps.com/who-we-are/postal-history/african-american-workers-20thc.htm#_edn2" name="_ednref2">[2]</a></p>
</blockquote>
<p>Today, 21% (or nearly 70,000) of the agency’s employees are African-American. However, the postal service was consequential beyond matters of social equity. By 1823, the U.S. Postal Service and the U.S. Government established 80,000 miles of “post roads” to help carriers navigate new rural areas. By 1860, these roads connected nearly 28,000 post offices. Today, the postal service maintains nearly 40,000 post offices, clearing 212 billion letters and mail to 144 million homes.</p>
<blockquote data-card-controls="1" data-card-align="center" data-card-theme="light" data-card-key="3101080c845e4679b6077080f81a573e">
<h4><a href="https://twitter.com/web/status/1292117127055519744">No Title</a></h4>
<p>Save the @USPS.There is no institution more critical to the next phases of our commerce economy.</p>
</blockquote>

<p>Today, the service is tasked with another generational shift: supporting online retail. The pandemic shifted the American consumer towards online retail, this while reducing the number of units shipped. As such, companies like UPS and FedEx have responded by hiking prices. In response to USPS’ distress, FedEx recently stated:</p>
<blockquote>
<p>The COVID-19 pandemic has negatively impacted mail volumes and mix resulting in a further decrease in revenues and negative financial impact for the USPS. Additionally, the USPS continues to experience budgetary uncertainty as well as increased political debate regarding potential privatization or restructuring of its operations.</p>
</blockquote>

<figure id="attachment_12683" aria-describedby="caption-attachment-12683"><img data-attachment-id="12683" data-permalink="https://2pml.com/2020/08/10/usps/sleikjxu/" data-orig-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=2048%2C1259&amp;ssl=1" data-orig-size="2048,1259" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sLEikjXU" data-image-description="" data-medium-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=300%2C184&amp;ssl=1" data-large-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=740%2C455&amp;ssl=1" loading="lazy" src="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=740%2C455&amp;ssl=1" alt="sLEikjXU" width="740" height="455" srcset="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?w=2048&amp;ssl=1 2048w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=300%2C184&amp;ssl=1 300w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=1024%2C630&amp;ssl=1 1024w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=768%2C472&amp;ssl=1 768w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=1536%2C944&amp;ssl=1 1536w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?w=1480&amp;ssl=1 1480w" sizes="(max-width: 740px) 100vw, 740px" data-recalc-dims="1"><figcaption id="caption-attachment-12683">The most popular government sites: June 18, 2020</figcaption></figure>
<p>Cost inflation is the most concerning obstacle ahead for digitally native retailers. Without the treatment that the United States’ oldest civilian service afforded Amazon in its infancy, it will be more difficult to build more businesses of Amazon’s scale. The economics were difficult enough as is; these added costs will only add pressure to pass along costs to consumers, many of whom are facing down one of the most economically vulnerable periods since 2008.We should consider the postal service an investment into our present and future and a monument to our past.</p>
<p>If our economy is to begin addressing the shortfalls caused by the overwhelming contraction in the traditional retail industry, it will need the support of the postal service. For eCommerce, their service is the industry’s last mile for thousands of direct-to-consumer small businesses. The postal service uniquely sits at the intersection of our physical roads and our digital infrastructure. There isn’t a direct substitute and we shouldn’t wait to find out the hard way. Save the USPS. We will need more companies like the the successful hundreds that were built on its 250 year old infrastructure. That includes Amazon.</p>
<p><strong>By Web Smith | Editor: Hilary Milnes | Art by Alex Remy | <a href="http://2pml.com/about">About 2PM</a></strong></p>
			</div><!-- .entry-content -->

	
	</article></div>]]>
            </description>
            <link>https://2pml.com/2020/08/10/usps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153311</guid>
            <pubDate>Fri, 14 Aug 2020 04:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Ruby apps, same code, but different output: what's going on?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152544">thread link</a>) | @vaillancourtmax
<br/>
August 13, 2020 | https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb | <a href="https://web.archive.org/web/*/https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <p><img src="https://images.unsplash.com/photo-1522776851755-3914469f0ca2?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1000&amp;h=500&amp;q=80"></p>

<p>I noticed something odd today while working on two different Ruby codebases. This simple line of Ruby behaved differently in both applications:</p>

<div><div><pre><code><span>"luck"</span><span>.</span><span>casecmp</span><span>(</span><span>"L`auguste"</span><span>)</span>
</code></pre></div></div>

<p>Executing <code>"luck".casecmp("L`auguste")</code> in application A returned <code>-1</code>, while executing it in application B returned <code>1</code>.</p>

<p>â€œDid the alphabet change at some point and I didnâ€™t get the memo?â€�, I thought.</p>

<blockquote>
  <p><strong>Aside</strong></p>

  <p><a href="https://ruby-doc.org/core-2.7.1/String.html#method-i-casecmp"><code>String#casecmp</code></a> is a built-in Ruby method that returns <code>-1</code>, <code>0</code>, <code>1</code>, or <code>nil</code> depending on whether the object on which itâ€™s called is less than, equal to, or greater than the function argument, and it does so in case-insensitive fashion. Here are a few simple examples of how it behaves:</p>

  <div><div><pre><code><span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcde"</span><span>)</span>     <span>#=&gt; 1</span>
<span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcdef"</span><span>)</span>    <span>#=&gt; 0</span>
<span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcdefg"</span><span>)</span>   <span>#=&gt; -1</span>
<span>"abcdef"</span><span>.</span><span>casecmp</span><span>(</span><span>"ABCDEF"</span><span>)</span>    <span>#=&gt; 0</span>
</code></pre></div>  </div>
</blockquote>

<h2 id="looking-for-monkey-patches">Looking for monkey patches</h2>

<p>Seeing as one of the applications is built on top of Ruby of Rails and the other isnâ€™t, my first thought was that maybe there was a Rails and/or ActiveSupport patch on <code>String#casecmp</code> that would change the behavior of this line in one of the applications. However, I didnâ€™t find anything that pointed to this. I kept digging, hoping to maybe find a patch in the <em>other</em> application that could explain this difference in behavior. Again, I didnâ€™t find anything. ðŸ™ˆ</p>

<h2 id="different-rubies">Different Rubies</h2>

<p>Eventually, after exploring a bit more, I realized that both applications ran on different versions of Ruby: application A was on Ruby 2.6, while application B was using Ruby 2.7.</p>

<p>Running the same command on both versions of Ruby indeed gives us different results:</p>

<div><div><pre><code><span>$ </span>~/.rubies/ruby-2.6.6/bin/ruby <span>-e</span> <span>'puts "luck".casecmp("L`Auguste")'</span>
<span>-1</span>

<span>$ </span>~/.rubies/ruby-2.7.0/bin/ruby <span>-e</span> <span>'puts "luck".casecmp("L`Auguste")'</span>
1
</code></pre></div></div>

<p>Ah ha! Weâ€™re getting closer. While I could have called it a day here and simply updated application B to Ruby 2.7 to resolve the issue, I wanted to understand: what causes it?</p>

<h2 id="changelogs--bindingpry">Changelogs &amp; <code>binding.pry</code></h2>

<p>I then started to comb through Ruby changelogs, trying to find if anything changed between Ruby 2.6 and Ruby 2.7 for <code>String#casecmp</code>, or anything somehow related to string comparison. I didnâ€™t find anything.</p>

<p>Of course, it would be nice to debug this using <code>binding.pry</code> or other similar Ruby-level debugging tools by stepping into the <code>String#casecmp</code> call to see whatâ€™s going on inside. However, this doesnâ€™t get us very far, as trying to use Rubyâ€™s <code>Tracer</code> or <code>binding.pry</code> doesnâ€™t really help.</p>

<p>Running this:</p>

<div><div><pre><code><span>$ </span>ruby <span>-r</span> tracer <span>-e</span> <span>'"luck".casecmp("L`Auguste")'</span>
</code></pre></div></div>

<p>â€¦ returns this output:</p>

<div><div><pre><code>#0:-e:1::-: "luck".casecmp("L`Auguste")
</code></pre></div></div>

<p>â€¦ and not much else. Thatâ€™s because <code>String#casecmp</code> is implemented in C, directly inside MRIâ€™s <a href="https://github.com/ruby/ruby/blob/master/string.c"><code>string.c</code></a>, so thereâ€™s no actual Ruby code underneath <code>String#casecmp</code> that we can step into using Ruby-level debugging tools.</p>

<p>Here comes the GDB part: because weâ€™re essentially dealing with C code at this point, we can use GDB to understand what happens inside the call to <code>String#casecmp</code>. So with that, I fired up GDB for the first time in years (I typically work with Ruby, so GDB is not something I commonly use).</p>

<h2 id="identifying-the-root-cause-using-gdb">Identifying the root cause using GDB</h2>

<p>Letâ€™s see how to use GDB to understand why both Ruby 2.6 and Ruby 2.7 behave differently with the same input to <code>String#casecmp</code>.</p>

<p>I first prepared a simple Ruby file containing the source that replicates the issue:</p>

<div><div><pre><code><span># ~/casecmp.rb</span>
<span>puts</span> <span>"luck"</span><span>.</span><span>casecmp</span><span>(</span><span>"L`Auguste"</span><span>)</span>
</code></pre></div></div>

<p>Notice that the second character in the input to <code>casecmp</code> is a backtick (<code>`</code>), which has ASCII code 96. This is relevant for paragraphs below.</p>

<h3 id="in-ruby-270">In Ruby 2.7.0</h3>

<p>Letâ€™s start by firing up GDB with a self-compiled version of Ruby 2.7.0:</p>

<div><div><pre><code><span>$ </span><span>sudo </span>gdb /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby
Reading symbols from /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby...
</code></pre></div></div>

<p>Then, we add a breakpoint on the <code>str_casecmp</code> function so execution pauses once we reach it:</p>

<div><div><pre><code>(gdb) break str_casecmp
Breakpoint 1 at 0x1001fa766: file string.c, line 3371.
</code></pre></div></div>

<p>Perfect. Weâ€™re now ready to run the <code>casecmp.rb</code> Ruby script from above.</p>

<div><div><pre><code>(gdb) run casecmp.rb
Starting program: /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby casecmp.rb
</code></pre></div></div>

<p>We eventually hit the breakpoint we just set:</p>

<div><div><pre><code>Thread 2 hit Breakpoint 1, str_casecmp (str1=4329352680, str2=4329352640) at string.c:3371
3371	    enc = rb_enc_compatible(str1, str2);
</code></pre></div></div>

<blockquote>
  <p><strong>Aside</strong></p>

  <p>Internally, <a href="https://github.com/ruby/ruby/blob/4318aba9c94ebff53e4168886e1a35a24013924f/string.c#L3467-L3468"><code>String#str_casecmp</code></a> is quite simple: it iterates over each character in both inputs by index starting from the first character, converting both characters to the same case so that the function behaves in a case-insensitive way, and returns early if the two currently considered characters from each input are different. In doing so, it determines which character is â€œbiggerâ€� than the other using the character code (an <a href="http://www.asciitable.com/">ASCII code table</a> is a useful asset to have nearby for the rest of this blog post).</p>
</blockquote>

<p>In Ruby 2.7.0, notice that the case conversion <a href="https://github.com/ruby/ruby/blob/e9e4f8430a62f56a4e62dd728f4498ee4c300c12/string.c#L3381-L3382">converts both inputs to lowercase using <code>TOLOWER</code></a>:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>p1</span> <span>&lt;</span> <span>p1end</span> <span>&amp;&amp;</span> <span>p2</span> <span>&lt;</span> <span>p2end</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>*</span><span>p1</span> <span>!=</span> <span>*</span><span>p2</span><span>)</span> <span>{</span>
    <span>unsigned</span> <span>int</span> <span>c1</span> <span>=</span> <span>TOLOWER</span><span>(</span><span>*</span><span>p1</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>unsigned</span> <span>int</span> <span>c2</span> <span>=</span> <span>TOLOWER</span><span>(</span><span>*</span><span>p2</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>if</span> <span>(</span><span>c1</span> <span>!=</span> <span>c2</span><span>)</span>
      <span>return</span> <span>INT2FIX</span><span>(</span><span>c1</span> <span>&lt;</span> <span>c2</span> <span>?</span> <span>-</span><span>1</span> <span>:</span> <span>1</span><span>);</span>
  <span>}</span>
  <span>p1</span><span>++</span><span>;</span>
  <span>p2</span><span>++</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>After navigating in <code>str_casecmp</code> using <code>next</code> a few times, we enter the loop and arrive at a point where we can print <code>c1</code> and <code>c2</code>, which are the codes for the characters at the current index for both inputs:</p>

<div><div><pre><code>3382	                unsigned int c2 = TOLOWER(*p2 &amp; 0xff);
(gdb) print c1
$11 = 108
(gdb) next
3383	                if (c1 != c2)
(gdb) print c2
$12 = 108
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>c1
 â†“
108  ?   ?   ?
 l   u   c   k

108  ?   ?   ?   ?   ?   ?   ?   ?
 l   `   a   u   g   u   s   t   e
 â†‘
c2
</code></pre></div></div>

<p>108 is the decimal ASCII character code representation for the first letter of both inputs: <code>l</code> (lowercase â€œLâ€�), so the loop continues to the next iteration because <code>c1</code> and <code>c2</code> are the same.</p>

<p>On the second iteration of the loop (on the second character of both inputs), we get the following results:</p>

<div><div><pre><code>3382	                unsigned int c2 = TOLOWER(*p2 &amp; 0xff);
(gdb) print c1
$14 = 117
(gdb) next
3383	                if (c1 != c2)
(gdb) print c2
$16 = 96
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>    c1
     â†“
108 117  ?   ?
 l   u   c   k

108  96  ?   ?   ?   ?   ?   ?   ?
 l   `   a   u   g   u   s   t   e
     â†‘
     c2
</code></pre></div></div>

<p><code>c1</code> contains <code>117</code>, which is the decimal ASCII character code representation for <code>u</code>, while <code>96</code> (in <code>c2</code>) is the character code for a backtick (<code>`</code>). We then enter the <code>if (c1 != c2)</code> conditional, and the return value is <code>1</code> because <code>c1 &gt; c2</code> (<code>117 &gt; 96</code>).</p>

<p>Okay. So far so good. This lines up with the initial observation of the issue. How are things different in Ruby 2.6.6?</p>

<h3 id="in-ruby-266">In Ruby 2.6.6</h3>

<p>We do almost the same setup as above (same one-line Ruby script to replicate the issue, same breakpoint on <code>str_casecmp</code>), but we fire up GDB with Ruby 2.6.6:</p>

<div><div><pre><code><span>$ </span><span>sudo </span>gdb /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby
Reading symbols from /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby...

<span>(</span>gdb<span>)</span> <span>break </span>str_casecmp
...

<span>(</span>gdb<span>)</span> run casecmp.rb
Starting program: /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby casecmp.rb

Thread 2 hit Breakpoint 1, str_casecmp ...
</code></pre></div></div>

<p>Letâ€™s look at the loop we presented above in Ruby 2.7.0, but <a href="https://github.com/ruby/ruby/blob/a9a48e6a741f048766a2a287592098c4f6c7b7c7/string.c#L3413-L3414">in Ruby 2.6.6</a> this time:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>p1</span> <span>&lt;</span> <span>p1end</span> <span>&amp;&amp;</span> <span>p2</span> <span>&lt;</span> <span>p2end</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>*</span><span>p1</span> <span>!=</span> <span>*</span><span>p2</span><span>)</span> <span>{</span>
    <span>unsigned</span> <span>int</span> <span>c1</span> <span>=</span> <span>TOUPPER</span><span>(</span><span>*</span><span>p1</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>unsigned</span> <span>int</span> <span>c2</span> <span>=</span> <span>TOUPPER</span><span>(</span><span>*</span><span>p2</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>if</span> <span>(</span><span>c1</span> <span>!=</span> <span>c2</span><span>)</span>
      <span>return</span> <span>INT2FIX</span><span>(</span><span>c1</span> <span>&lt;</span> <span>c2</span> <span>?</span> <span>-</span><span>1</span> <span>:</span> <span>1</span><span>);</span>
  <span>}</span>
  <span>p1</span><span>++</span><span>;</span>
  <span>p2</span><span>++</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Notice that instead of using <code>TOLOWER</code> as in Ruby 2.7.0, Ruby 2.6.6 uses <code>TOUPPER</code>. Interesting.</p>

<p>Letâ€™s fast-forward to the part where we get to <code>c1</code> and <code>c2</code> for the second character in the input:</p>

<div><div><pre><code>3414			unsigned int c2 = TOUPPER(*p2 &amp; 0xff);
(gdb) next
3415	                if (c1 != c2)
(gdb) print c1
$5 = 85
(gdb) print c2
$6 = 96
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>     c1
     â†“
108  85  ?   ?
 L   U   C   K

108  96  ?   ?   ?   ?   ?   ?   ?
 L   `   A   U   G   U   S   T   E
     â†‘
     c2
</code></pre></div></div>

<p><code>c1</code> is <code>85</code>, which is the character code for <code>U</code>, and <code>c2</code> is <code>96</code> (just like in Ruby 2.7.0), which is the character code for a backtick (<code>`</code>).</p>

<p>This time though, the comparison result is different, because <code>c1 &lt; c2</code> (<code>85 &lt; 96</code>), so <code>str_casecmp</code> returns <code>-1</code>.</p>

<p>There it is: because Ruby 2.6 uses <code>TOUPPER</code> and Ruby 2.7 uses <code>TOLOWER</code> before comparing the inputs, and because one of the characters to compare is a backtick (<code>`</code>, which canâ€™t be converted to uppercase or lowercase in any way), the other characterâ€™s code â€œmovesâ€� differently around the â€œfixedâ€� backtick character code, affecting the result of the <code>String#casecmp</code> function.</p>

<hr>

<p>To summarize, the root cause of the issue is that <code>String#casecmp</code> was updated in Ruby 2.7 to <strong>lowercase</strong> the two inputs before comparing them, while Ruby 2.6 used to <strong>uppercase</strong> the two inputs before comparing them. <a href="https://github.com/ruby/ruby/commit/082424ef58116db9663a754157d6c441d60fd101#diff-7a2f2c7dfe0bf61d38272aeaf68ac768">This is the commit where this change was introduced.</a></p>

<p>Fun debugging session. :)</p>

<p><em>Found a typo? Think I could clarify something? Reach out on Twitter (<a href="https://twitter.com/vaillancourtmax">@vaillancourtmax</a>).</em></p>

</article></div>]]>
            </description>
            <link>https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152544</guid>
            <pubDate>Fri, 14 Aug 2020 02:32:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My electricity bill was wrong for two years]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152325">thread link</a>) | @PlanetLotus
<br/>
August 13, 2020 | https://planetlotus.github.io/2020/08/13/meter-mixup.html | <a href="https://web.archive.org/web/*/https://planetlotus.github.io/2020/08/13/meter-mixup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve lived in my house for just under two years. Last summer, I noticed something strange. Our electricity bill increased by 40-90% depending on the month. This year, I finally tracked it down and discovered our meter was being mixed up with our neighbor’s. Here’s how I tracked this down and what you can do to prevent it from happening to you.</p>



<p>I have an amateur interest in electricity, conserving energy, and energy efficiency in general. I care about my carbon footprint, as well as my bill, and I’m passionate about innovation in this space. I’ve made it a habit to have a good idea of how much electricity different appliances use and, in general, I try to be aware of where my electricity is going. Years ago, I bought a simple <a href="https://en.wikipedia.org/wiki/Kill_A_Watt">Kill A Watt</a> to quickly get an idea of how much power things use.</p>



<p>The first time I noticed a problem was when we got our July bill in the summer of 2019. It was about 40% higher than usual. My grandparents stayed with us (in their motorhome) for a week that month, and their motorhome has a big air conditioner, so I chalked it up to that, though that still seemed high.</p>

<p>A couple months passed and the problem got worse. It went from 40% higher than normal, to a peak of about 90%. I couldn’t explain that. We don’t have central air conditioning. Most of our heavy appliances use natural gas. We did use a portable air conditioner briefly, but never for more than a couple hours a night. I also measured the power usage of the A/C and thought, there’s no way this adds up. This confusion continued until we got our October bill and it returned to normal, and I forgot about it for another year.</p>



<p>And…it came back! I first noticed this year in June when the bill jumped about 20%. I figure it’s reasonable for the bill to fluctuate a little, but not by that much. Plus, what made even less sense is that we used supplemental electric heating this winter, so if anything, our bill should’ve been higher in the winter! Again, no central air conditioning, so another unexplained bill. I tracked power usage on everything I could think of, to make sure I hadn’t missed something. For awhile, my big suspect was our fridge. It’s 18 years old, so I figured, maybe there’s a problem with it and it uses more power when it should, especially when the ambient temperature is higher. I cleaned the coils and played around with the fridge settings, then waited for our next bill. It got worse.</p>

<p>This year, I noticed our power company has a cool interface online where you can see your daily power usage. Very handy. I noticed that, in non-summer months, it was very consistent, ranging between 9-12 kWh per day. Then, in the summer months, it just goes all over the place. Sometimes it was 8, other days it went as high as 24! This seemed loosely correlated with the temperature but I just couldn’t explain that, due to a lack of central cooling in our house. I finally decided to call the power company at this point. Naturally, they did not take me too seriously, and were fairly insistent that it was my air conditioning (that I didn’t have). I was told to hire an electrician to investigate.</p>

<p>Then it got weirder. In late July, I noticed that in recent weeks, our daily power usage (according to the power company) dipped as low as 1 kWh per day! That’s just not possible, I thought. My electronics, combined, should use more than that per day, not even counting heavier users like the fridge. The power usage still fluctuated quite a bit, but there were several days where the power usage was as low as 1-3 kWh. I called the power company again and, no surprise, they took this much more seriously and agreed that wasn’t possible. I insisted that the peaks in usage didn’t make sense either, that I couldn’t explain those, but no luck there…they were really only interested in the low days and said they were opening an investigation that could take “at least a few weeks” to finish.</p>



<p>One night, I finally put it together. I wondered if my bill was mixed up with my neighbor’s. My neighbor had moved out in July, and that’s about when the daily power usage fell to almost nothing. I also happened to know that they have central air conditioning. I looked at my bill and noticed it actually has the meter number on it, very helpful! I looked at my meter and the number on the bill wasn’t even remotely close. It wasn’t off-by-one. The format looked consistent, but the values looked randomized. I was wondering whether I was even looking at the right number. So, the next morning, I took a look at my neighbor’s (vacant) house’s meter. Sure enough, it exactly matched what was on my bill.</p>

<p>A few frustrating phone calls later (not important), and the issue is fixed. We got the charges corrected and are enjoying a large credit on our account that ought to last us about 6 months (after having lived here only 2 years).</p>

<p>In any future house I live in, I will be sure to check that my bill’s meter number matches what’s on the property. I highly recommend everyone do the same, because I get the impression this is fairly common. A quick search online and I found about half a dozen news articles about this happening, often more egregious cases than my own. Most of us may not notice a mixup, either because the usage is fairly consistent or we just don’t know how much power we use. Thankfully, you should be able to check the accuracy of your bill in about 5 minutes if your meter is easily accessible. Simply look for the meter number on your bill (hopefully all power companies give this info), and then look physically at the meter for a sticker from your power company, and see if the numbers match.</p>

  </article>

  




</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://planetlotus.github.io/2020/08/13/meter-mixup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152325</guid>
            <pubDate>Fri, 14 Aug 2020 01:57:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning of Sets]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24152216">thread link</a>) | @akosiorek
<br/>
August 13, 2020 | http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html | <a href="https://web.archive.org/web/*/http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In machine learning, we typically work with input pairs (x, y), and we try to figure out how x and y depend on each other.
To do so, we gather many such pairs and hope that the dependence will reveal itself if a) we have enough data, b) our model is expressive enough to approximate this dependency, and c) we get the hyperparameters right.
In the simplest case, both x and y are just scalar values (or vectors \(\mathbf{x}, \mathbf{y}\)); for example, given some measurements of a plant’s shape, we might want to predict its species. The measurements here are real vectors \(\mathbf{x} \in \mathcal{X}\), where the input space \(\mathcal{X} = \mathbb{R}^d\) is usually Euclidean, and the species is a label \(\mathbf{y} \in \mathcal{Y}\) (usually an integer or a one-hot vector), but it is common for \(\mathbf{x}\) and \(\mathbf{y}\) to have more structure.</p>

<p>One of the main assumptions we rely on is that the pairs of (x, y) points are <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">independent and identically distributed (i.i.d.) random variables</a>.
Let us unpack this a bit, starting from the end,</p>

<ul>
  <li><code>random variable</code>: there exists some stochastic generative process from which the variables were randomly sampled,</li>
  <li><code>identically</code>: all samples come from the same probability distribution,</li>
  <li><code>independent</code>: the generative process has no memory of generated samples, and hence any generated sample does not change the distribution over future generated samples.</li>
</ul>

<p>Any structure in \(\mathbf{x}, \mathbf{y}\), or both introduces constraints, and a successful application of an algorithm to a particular problem does heavily depend on whether or not this algorithm takes the relevant constraints into account.
A common constraint in image-related problems is translation equivariance<sup id="fnref:cnnequiv" role="doc-noteref"><a href="#fn:cnnequiv">1</a></sup>—the output of the algorithm should shift with any shifts applied to the image (you can read more about equvariances in <a href="https://fabianfuchsml.github.io/equivariance1of2/">this excellent blog post</a>).
In natural language-related problems, a typical constraint is causality: a token at position t can depend on any previous tokens at position 1:t-1, but it cannot depend on any future tokens<sup id="fnref:languecausality" role="doc-noteref"><a href="#fn:languecausality">2</a></sup>.</p>

<p>In the above examples, the dependencies between points (e.g., autoregressive dependence in NLP) are clear from the context.
However, if a data point is not a vector, matrix, or a sequence of vectors, but it is a <strong>set of vectors</strong>, these dependencies become less clear.
In particular, elements in an input set resemble elements in a dataset (i.e., lack of order), but the critical difference is that they are <strong>not independent</strong>, therefore breaking the i.i.d. assumption.
Accounting for this specific structure in inputs or outputs of an ML model leads to a family of set learning problems, which have recently gained considerable attention in the machine learning community.
I thought it would be useful to delve into the machine learning of sets.
In the following, we will consider set-to-vector, vector-to-set, and set-to-set problems and provide implementations of simple algorithms in <a href="https://github.com/google/jax">JAX</a> and <a href="https://github.com/deepmind/dm-haiku">haiku</a>.</p>

<p>First some imports:</p>

<div><div><pre><code>import jax
import jax.numpy as jnp
import haiku as hk
</code></pre></div></div>


<p>Before we start, it is useful to introduce some notation.
Let \(\mathbf{x} \in \mathbb{R}^d\) be an input vector, \(\mathbf{y} \in \mathbb{R}^k\) the output vector, and let \(X = \{\mathbf{x}_i\}_{i=1}^M\) and \(Y = \{\mathbf{y}_j\}_{j=1}^N\) be sets of \(M\) and \(N\) elements, respectively.
Note that, until now, \(y\) or \(\mathbf{y}\) were simply labels.
From now on, however, \(\mathbf{x}\) and \(\mathbf{y}\) can live in the same space, and simply be elements of different sets.
I will also use \(\mathcal{L}(X, Y)\) as a loss function operating on two sets, and \(l(\mathbf{x}, \mathbf{y})\) will be a loss function for pairs of elements.</p>


<p>This is perhaps the simplest set-learning problem since it only requires permutation invariance.
A function \(f\) is invariant to permutations \(\pi\) if \(\forall \pi\): \(f(X) = f(\pi X)\).
Permutation invariance has always been known in machine learning, as loss functions we use almost never<sup id="fnref:acn" role="doc-noteref"><a href="#fn:acn">3</a></sup> depend on the ordering of elements in our datasets or minibatches.
This is not for the lack of order: to create a minibatch, we stack multiple data elements in an array; this pairs every element in the minibatch with its minibatch index, therefore implicitly creating an order.
Loss functions tend to discard information about the order, usually by taking the mean over data examples.
We can create permutation-invariant functions by following a similar logic.</p>

<p>Examples in a minibatch are processed independently (which reflects their i.i.d. nature), but if each entry in the minibatch contains more than just a single data point (many pixels in an image, points in a point cloud, tokens in a language sentence), then flattening these points into a vector and feeding it into an MLP or a CNN results in different parameters being used for processing different data points, and hence order is used implicitly; feeding the points into an RNN reuses parameters, but introduces an explicit dependence on the order.</p>

<p>A straightforward solution to this issue is to treat points in a single example in the same way we treat examples in the minibatch: treat them independently.
This approach, followed by a permutation-invariant pooling operation such as max or mean pooling, is explored in <a href="https://arxiv.org/abs/1703.06114">Zaheer et al., “Deep Sets”, NeurIPS 2017</a> and is proven to be a universal set-function approximator<sup id="fnref:deepsetdim" role="doc-noteref"><a href="#fn:deepsetdim">4</a></sup>.</p>

<div><div><pre><code>class DeepSet(hk.Module):

  def __init__(self, encoder, decoder):
    super().__init__()
    self._encoder = encoder
    self._decoder = decoder
    
  def __call__(self, x):
    """Compute the DeepSet embedding.

    Args:
      x: Tensor of shape [batch_size, n_elems, n_dim].
    """
    return self._decoder(self._encoder(x).mean(1))
</code></pre></div></div>

<p>While newer approaches with better empirical performance exist, they all draw from the Deep Sets framework<sup id="fnref:setembeddings" role="doc-noteref"><a href="#fn:setembeddings">5</a></sup>.
Another factor contributing to the fact that the set-to-vector problem is quite easy is that pooling operations naturally work with variable-sized sets–there is nothing extra we have to do to handle sets of variable cardinality.
This is not the case in the following two problems, where we have to take the set size into account explicitly.</p>


<p>In vector-to-set, the task is to generate a set of real vectors from some (usually vector-valued) conditioning.</p>

<p>The majority of approaches out there focus on generating ordered sequences instead of unordered sets, and usually of fixed or at least known size.
This allows using MLPs<sup id="fnref:setae" role="doc-noteref"><a href="#fn:setae">6</a></sup> and RNNs<sup id="fnref:order_matters" role="doc-noteref"><a href="#fn:order_matters">7</a></sup> to predict fixed- and variable-length sets, respectively, but at the price of having to learn permutation-equivariance from data.
Learning permutation-equivariance can be induced by data augmentation. It is easy to generate different permutations, but usually comes at a decreased performance and/or longer training times compared to truly permutation-equivariant methods<sup id="fnref:data_augmentation" role="doc-noteref"><a href="#fn:data_augmentation">8</a></sup>.</p>

<div><div><pre><code>  def set_mlp(conditioning, decoder, n_elements):
    """Predicts a set.

    Args:
      conditioning: tensor of shape [batch_size, n_dim].
      decoder: callable, e.g. an MLP.
      n_elements: int.
    """
    z = decoder(conditioning)
    batch_size = conditioning.shape[0]
    # all we can do here is reshape!
    return z.reshape(batch_size, n_elements, -1)

  def set_rnn(conditioning, state, rnn, n_elements):
    """Predicts a set.

    Args:
      conditioning: tensor of shape [batch_size, n_dim].
      state: initial state for the rnn.
      rnn: rnn core.
      n_elements: int.
    """
    zs = []
    for _ in range(n_elements):
      z, state = rnn(conditioning, state)
      zs.append(z[:, None])  # add an axis

    return jnp.concatenate(zs, 1)
</code></pre></div></div>

<h4 id="permutation-invariant-loss-functions">Permutation-Invariant Loss Functions</h4>
<p>Learning to generate sets based on some conditioning typically requires scoring that set against the conditioning.
If we have ground-truth sets at our disposal, we can compare the generated sets against the ground-truth ones for the same conditioning.
This can take the form of supervised learning (think of detecting objects in an image, where we need to generate a set of bounding boxes) or unsupervised learning (autoencoding point-clouds, say).
Since we generally have no guarantee that the generated sets will obey any ordering (why should they?), we have to apply losses invariant to that ordering.
We have two options here:</p>

<ul>
  <li>We can find an optimal matching between two sets<sup id="fnref:bipartite_matching" role="doc-noteref"><a href="#fn:bipartite_matching">9</a></sup>, which comes down to finding a permutation \(\pi\) of one of the sets that minimizes the computed loss, that is: \(\pi^\star = \arg \min_\pi \mathcal{L}( \pi X, Y)\), with \(\mathcal{L}( \pi X, Y) = \sum_i l(\mathbf{x}_{\pi(i)}, \mathbf{y}_i)\). This can be done exactly using the cubic <a href="https://en.wikipedia.org/wiki/Hungarian_algorithm">Hungarian matching</a> algorithm, or approximately using e.g. <a href="https://arxiv.org/abs/1106.1925">optimal-transport</a>- or <a href="https://web.stanford.edu/~bayati/papers/bpmwmIT.pdf">message-passing</a>-based algorithms.</li>
  <li>Instead of finding a matching, we can find a lower bound on what the matched loss would be. A popular choice here is the Chamfer loss<sup id="fnref:chamfer" role="doc-noteref"><a href="#fn:chamfer">10</a></sup>, which computes \(\sum_{x \in X} \min_{y \in Y} l(x, y) + \sum_{y \in Y} \min_{x \in X} l(x, y)\). For every element in one set, it finds the element in the other set that results in the lowest pairwise loss. This loss does not work for multisets as elements can be repeated.</li>
</ul>

<p>If we do not have ground-truth for each conditioning (we have just sets), or if we have many possible sets for each conditioning (e.g., a group of possible sets for one of a few labels), we can instead learn by matching distributions e.g., in the GAN setting.
If we take this approach, we have two problems, really: that of vector-to-set for the generator and set-to-vector for the discriminator. 
Fortunately, we know how to solve the set-to-vector problem with a permutation-invariant neural net, and shortly I am going to describe some permutation-equivariant methods for generation.
This is precisely what we recently explored in <a href="https://oolworkshop.github.io/program/ool_32.html">Stelzner et al., “Generative Adversarial Set Transformers”, ICML 2020 Object-Oriented Learning Workshop</a>.</p>

<p>Coincidentally, sometimes we have to deal with a set of latent variables inside a model. For example in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html">http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html</a></em></p>]]>
            </description>
            <link>http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152216</guid>
            <pubDate>Fri, 14 Aug 2020 01:40:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USPS Releases 2020 Ruth Asawa Stamp]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152035">thread link</a>) | @arunc
<br/>
August 13, 2020 | https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/ | <a href="https://web.archive.org/web/*/https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tc-page-wrap">

  		
  	   	
  		                                                                                    <div id="main-wrapper">

    
    <div role="main">
        <div>

            
                <div id="content">

                    
                        
                                                                                                                              
                                                                    <article id="post-1462">
                                                
                  <section>
              <div id="attachment_1468"><p><img aria-describedby="caption-attachment-1468" src="https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200.jpg" alt="" width="1200" height="769" srcset="https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200.jpg 1200w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-300x192.jpg 300w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-1024x656.jpg 1024w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-768x492.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p id="caption-attachment-1468">© 2020 U.S. Postal Service. All rights reserved.</p></div><p>The U.S. Postal Service honors pioneering Japanese American artist Ruth Asawa (1926-2013). Showcasing Asawa’s wire sculptures, the pane includes 20 stamps, with two each of 10 designs, featuring photographs by Dan Bradica and Laurence Cuneo. The selvage features a photograph of Asawa taken by Nat Farbman in 1954 for <em>Life</em> magazine. Ethel Kessler served as art director and designer.</p>
<p>Customers may purchase stamps and other philatelic products through the Postal Store at <a href="https://store.usps.com/store/product/buy-stamps/ruth-asawa-S_476304" target="_blank" rel="noopener noreferrer">usps.com/shopstamps</a>, by calling 800-STAMP24 (800-782-6724), by mail through USA Philatelic, or at Post Office locations nationwide. Videos of most stamp ceremonies will be available on facebook.com/usps. </p>
<p>The pane includes 20 stamps, featuring photographs by Laurence Cuneo and Dan Bradica for David Zwirner. The selvage features a photograph of Asawa taken by Nat Farbman in 1954 for Life magazine. Ethel Kessler served as art director and designer for this issuance.</p>
<p><a href="https://store.usps.com/store/product/buy-stamps/ruth-asawa-S_476304" rel="noopener noreferrer" target="_blank">Stamps are available now &gt;</a></p>
<p>Information on ordering first-day-of-issue postmarks and covers is at <a href="https://usps.com/shopstamps" target="_blank" rel="noopener noreferrer">usps.com/shopstamps</a> under “Collectors.”</p>
<p>Paul Lanier, son of Ruth Asawa; George Takei of The Japanese American National Museum; and Jonathan Laib, of David Zwirner Gallery participated in the virtual opening event with USPS officials:</p>
<p>The Postal Service receives no tax dollars for operating expenses and relies on the sale of postage, products and services to fund its operations. All images are preliminary and are subject to change prior to printing.</p>
<p><a href="https://ruthasawa.com/art/">Explore galleries of Asawa’s art forms &gt;</a></p>
<p><a href="https://ruthasawa.com/life/">View a timeline of her life &gt;</a></p>
<p><a href="https://ruthasawa.com/view-installation/">Experience an Asawa installation virtually &gt;</a></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->                                                                                </section><!-- .entry-content -->
                                            </article>
                                
                                                                      
                        
                    
                </div><!--.article-container -->

           
        </div><!--.row -->
    </div><!-- .container role: main -->

    
</div><!-- //#main-wrapper -->

                                            		<!-- FOOTER -->
  		
    </div></div>]]>
            </description>
            <link>https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152035</guid>
            <pubDate>Fri, 14 Aug 2020 01:12:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Standards Are Simple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151909">thread link</a>) | @wyclif
<br/>
August 13, 2020 | https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi | <a href="https://web.archive.org/web/*/https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div><p><a href="https://portal.mozz.us/gemini/ebc.li/">Home</a></p>
<p>2020-08-13

If you want to create a truly open standard, you _need_ to make it simple.

There are no exceptions to this rule. When a standard becomes harder to fully implement than what your average motivated programmer can do in two months (max!), it _shouldn't_ be considered "open" anymore.

Why?

</p>
<h2>Complicated Standards Lead to Implementation Monopolies</h2>
<p>Since implementing a complex standard is hard, you will eventually end up with the implementation that started the earliest and maintained since, being the only implementation that is actually usable. And that implementation will most likely be the one created by the standard's creators.

In cases where the standard's creators don't maintain an implementation like "the web"⁰, the only choices are either the standard dying out because of it's complexity, or the actively maintained implementations requiring tons of effort, with (most likely) companies backing said implementations.

</p>
<h2>Implementation Monopolies Lead to Extensions</h2>
<p>If a big implementation just decides one day that your standard is lacking, they can just extend the parts they want. The two outcomes of this being that:

</p>
<ul><li>The other implementations copy their extensions</li>
<li>That one implementation getting more users, and eventually, a near monopoly because of a bigger feature set</li></ul>
<p>
At that point, the "standard" implemented by said implementations is longer the actual defined standard, but because people will inevitably use the said extensions, any new implementation that wants to be considered usable will eventually need to support said proprietary extensions.

</p>
<h2>Too Many Extensions Spoil The Standard</h2>
<p>Even if you have an "open" extension system, where implementations can all propose and agree on extensions to the standard, you need to be able to keep those implementations in check, so their extensions don't overcomplicate the standard.

Remember: Having a simple standard with a million extensions is no better than a complex standard with no extensions.

</p>
<h2>Examples</h2>
<p>Please note that I will be skipping the elephant in the room: "the web", as it has been discussed _to death_.

</p>
<h3>Matrix</h3>
<p>Matrix is _technically_ an open standard. But because of the complexity it has accumulated over the years, Synapse is the only usable server implementation. Even Dendrite, the new implementation by *the same folk that created the standard*, is barely usable after _years_.

The same applies to Matrix clients, with Element being the only usable client implementation. That space definitely seems healthier than the server space, but the same issues are there.

</p>
<h3>Various Programming Languages</h3>
<p>I will not be specifying any language, as I might get any specifics incorrect, but a general pattern I have seen is that most programming languages have only a few compiler/interpreter implementations, even though the language is standardized in some form.

This example actually has some interesting reasoning behind this issue on top of the complicated standards:

</p>
<ul><li>Writing a compiler/interpreter can be hard.</li>
<li>Especially if the current implementations do optimizations or other "clever" tricks.</li></ul>
<p>
These issues can devolve into arguments regarding seeing the complexity of these issues as a part of the standard, and other "technology is too complicated in general" arguments, which I will not dive into here.

</p>
<h3>X Display Server</h3>
<p>The X Display Server standard got so complicated, the people developing it decided to abandon it entirely and create Wayland.

It probably didn't help that most of the standard was no longer being used, and a lot of extensions are required for its use today.

Wayland probably will also suffer the "too many extensions" problem at some point, so I am looking forward to that too...

</p>
<h2>Footnotes</h2>
<p>0: Well, Google, Mozilla and Apple all had a hand in most of the "modern" parts of the standards...
</p></div>
        </div></div>]]>
            </description>
            <link>https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151909</guid>
            <pubDate>Fri, 14 Aug 2020 00:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Valve Index HMD Detailed Teardown]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151496">thread link</a>) | @adwi
<br/>
August 13, 2020 | https://www.thevrist.com//indexteardown | <a href="https://web.archive.org/web/*/https://www.thevrist.com//indexteardown">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>If you have ever wondered what is inside Valve Index, you might have stumbled upon my <a href="https://www.reddit.com/r/ValveIndex/comments/cpayc5/valve_index_disassembly/">reddit post from 2019</a>. I’ve decided to dive into the details of what makes Valve Index great and share my thoughts on tech inside.</p>

<p>Teardown should begin from the simplest parts - remove the face mask (held by just magnets), unplug the main cable, and remove headphones that are held in place by a single screw each. Next remove the rubber cover that is glued around lenses. It’s not that well glued, you can just pull it off.</p>

<p><img src="https://www.thevrist.com/assets/images/index1.jpg" alt="">
<em>Rubber cover that prevents dust from getting inside lenses</em></p>

<p>Let’s start with a front panel - glossy front panel is removed by hand, since it is only held by magnets (but you already knew that from all the numerous pictures of people shoving stuff in the frunk of the headset). The rest of the front panel can be easily split in two parts. First is the frunk section, it will give you access to the main circuit board of the headset. You can remove it quite painlessly if you have the correct screwdriver. This panel does not contain any electronics.</p>

<p><img src="https://www.thevrist.com/assets/images/index-face.jpg" alt="">
<em>Just look at this beauty</em></p>

<p>Second part of the front panel is more complex. It contains tracking points for the SteamVR tracking - you can see them by looking at the plastic at different angles - plastic covering tracking points is thinner so laser beams from base stations could shoot through it. SteamVR trackers are split in two independent parts, which are connected to the main circuit separately. Also this panel contains two front facing cameras, which makes the process of taking it off even more delicate. You have to disconnect two cameras and two halves of the tracking plate’s system to finally fully reveal the main circuit.</p>

<h2 id="main-circuit">Main Circuit</h2>

<p><img src="https://www.thevrist.com/assets/images/index2.jpg" alt="">
<em>The “meat” of Valve Index</em></p>

<p>Finally we get to the main computing power of the headset. You can identify the main points of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index3-1.png" alt="">
<em>This is where all the cables connect to the HMD</em></p>

<p>On the top there is a metal connector with FPC cable going in. It is going to the smaller circuit in the top part of the headset where the cable plugs in the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index4.jpg" alt="">
<em>Circuit board with main cable and 3.5 mm audio port. It also connects to the proximity sensor</em></p>

<p>Same circuit has a 3.5 mm audio port for connecting headphones (I bet you didn’t know there is an audio jack) and proximity sensor between lenses. Last one is used for turning off the screens when the headset is not on the head.</p>

<p><img src="https://www.thevrist.com/assets/images/index2-1.png" alt="">
<em>SteamVR tracking points are connected here</em></p>

<p>On the sides of the main circuit board there are two black FPC cables. Those are going to the SteamVR tracking dots located in the sides of the headsets. Here is a picture of the tracking “web” when taken out of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index5.jpg" alt="">
<em>One side of SteamVR tracking web taken out of the HMD</em></p>

<p>Final two FPC cables are orange color and located at the bottom of the main board. They are connecting to a pair of displays located right behind this circuit.</p>

<h2 id="microchips">Microchips</h2>

<p>Now it is time to dive in a wonderful world of microchips and circuit boards. I want to thank <a href="https://www.linkedin.com/in/popovs/">Sergejs Popovs</a> for helping to identify most of the components on the board.</p>

<p>Let’s start with simple chips. Here are two bluetooth <a href="https://www.nordicsemi.com/Products/Low-power-short-range-wireless/nRF52840">chips from Nordic Semiconductors</a>. Each of these chips is used for connecting one controller with the headset. That’s why there is a limitation of two devices connected to the HMD. If you want to connect more devices (Vive Trackers or other controllers) you will need to use a USB dongle with a separate Bluetooth chip.</p>

<p><img src="https://www.thevrist.com/assets/images/index6.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index7.jpg" alt="">
<em>Bluetooth microchips, each connects to one device</em></p>

<p>Do you remember the USB port in the frunk? Well, this is a <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/USB5744-Data-Sheet-DS00001855J.pdf">chip from Microchip</a> for that USB port - hence USB in the name.</p>

<p><img src="https://www.thevrist.com/assets/images/index4-4.jpg" alt="">
<em>USB chip for USB port next to it</em></p>

<p>Here is a <a href="https://www.via-labs.com/product_show.php?id=96">chip from Via-Labs</a>. It has a purpose of converting USB 3.1 signal to the 2.0 one. Some of the chips on the circuit are not advanced enough to understand 3.1 USB, so this chip “dumbs it down”. When the signal will need to go back to the PC, the chip will convert the signal back to the USB 3.1.</p>

<p><img src="https://www.thevrist.com/assets/images/index8.jpg" alt="">
<em>USB signal converter chip</em></p>

<p>This is a flash memory chip from <a href="https://www.digikey.com/products/en/integrated-circuits-ics/memory/774?k=w25q32jw">Winbond Electronics</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index9.jpg" alt="">
<em>Flash memory can be used for different kinds of tasks</em></p>

<p>Next are these two microchips. The smaller one is a <a href="https://www.analogix.com/en/products/dp-mipi-converters/anx7530">SlimPort® 4K receiver from Analogix</a>. It is capable of receiving Image in 4K at 60 Hz, but since screens in Valve Index are only 1440 by 1600 pixels it allows to process video at 90, 120, and even 144 Hz. It also splits the signal in two allowing each display to get its own image.</p>

<p><img src="https://www.thevrist.com/assets/images/index10.jpg" alt="">
<em>Video chips convert image that you see in your SteamVR mirror in beautiful VR image</em></p>

<p>Larger chip is a multipurpose <a href="https://www.digikey.com/products/en/integrated-circuits-ics/embedded-fpgas-field-programmable-gate-array/696?k=ICE40HX8K">FPGA (Field Programmable Gate Array) chip from Lattice Semiconductor</a>. It is used for tracking - all the data received from the tracking sensors is gathered here. This chip combined with the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-11289-32-bit-Cortex-M4-Microcontroller-SAM-G55_Summary-Datasheet.pdf">Atmel MCU</a> (located on the other side of the circuit board) are doing all the necessary tracking calculations.</p>

<p><a href="http://www.etron.com.tw/cn/products/webcam_detial.php?Product_ID=10">EtronTech microchip</a> is used for merging video feeds from external cameras and transmitting it to your PC.</p>

<p><img src="https://www.thevrist.com/assets/images/index11.jpg" alt="">
<em>Microchip for processing image from webcams</em></p>

<p>Last two chips on this side of the circuit from <a href="https://www.silabs.com/power/efp01-power-management-ic">SiliconLabs</a> are most likely related to power regulation. Both of them are located near the capacitors and an inductor (metal thingy with 150 written on it). These are making sure that nothing will get too hot on your face.</p>

<p><img src="https://www.thevrist.com/assets/images/index12.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index13.jpg" alt="">
<em>Power regulating microchips</em></p>

<p>Next step is to remove the main circuit board and look on its other side. Other side is less interesting and has very little information to offer. Most parts are related to the power regulation mentioned in the previous paragraph.</p>

<p><img src="https://www.thevrist.com/assets/images/index14.jpg" alt="">
<em>Back side of the main circuit board</em></p>

<p>Largest chip is an Atmel MCU, which I’ve already mentioned is related to the tracking system. On the left from it is a <a href="https://www.nxp.com/docs/en/data-sheet/LPC11U1X.pdf">microcontroller from NXP</a>. These are all the chips we managed to identify. One chip that is missing, is the additional Bluetooth module. Unlike Vive and Vive Pro, Index has bluetooth in the headset. It is used for connecting to the base stations, updating base station firmware, and sending them to sleep mode when the headset is turning off. Last one is completely optional - I prefer to keep my base stations 2.0 on all the time.</p>

<p><img src="https://www.thevrist.com/assets/images/index14-2.jpg" alt="">
<em>The only two chips worth noting on this side of the motherboard - larger one is for tracking calculations</em></p>

<p>Why there is no separate Bluetooth chip for this purpose is still a mystery for me. Only possible explanation is that two Bluetooth chips for controllers are capable of switching to different modes and control the base stations.</p>

<h2 id="screens">Screens</h2>

<p>After the circuit is removed you will reveal several key components. First - you can see two displays - quick search shows that those panels are made by BOE Technology - Chinese display manufacturer. Those are 1440×1600, 615PPI 3.5” <a href="https://www.panelook.com/VS035ZSM-NW0-69P0_BOE_3.5_LCM_overview_37926.html">panels</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index15.jpg" alt="">
<em>View of the HMD with main board removed</em></p>

<p>Note some key elements in this view. On the bottom there is a circular mechanism with a metal pin with springs going through the whole headset. Similar pin is barely visible on the top of the headset. This is an IPD adjustment system - movement of the knob at the bottom of the HMD will rotate circular element in the bottom center which will push screens apart.
On the left and right sides of HMD you can see black gears - this is a system for eye relief - rotating a knob on the side of the headset will move the facemask relatively to the screens. Gear system is making sure both sides are rotating simultaneously, without giving too much pressure to the mechanism.</p>

<p><img src="https://www.thevrist.com/assets/images/index16.jpg" alt="">
<em>IPD knob is actually a screw</em></p>

<p>In order to take the central part out from the headset, you will need to take the cap off the IPD adjustment knob and unscrew it.</p>

<p><img src="https://www.thevrist.com/assets/images/index17.jpg" alt="">
<em>Lens chambers with IPD mechanism still attached</em></p>

<p>Next was what I call the “wondering in the dark” part of teardown - for about 30 minutes we were trying to find a way of taking it apart without breaking anything, eventually using force to break one gear inside that was holding display chambers in place.</p>

<p><img src="https://www.thevrist.com/assets/images/index18.jpg" alt="">
<em>Right eye lens chamber removed</em></p>

<p>After this step you can easily take off separate lens chambers and view the details. Chambers are sealed shut so nothing will get inside - they are assembled in perfectly clean conditions with no dust particles. 
In order to take it apart you can probably try to melt glue or something like that. But we are no iFixit, we used good ol’ force. Here you can see the screen separated from the chamber.</p>

<p><img src="https://www.thevrist.com/assets/images/index19.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index20.jpg" alt="">
<em>BOE screen removed from the chamber</em></p>

<p>Screen has a polarised diffuser glued to it, which is particularly difficult to remove. It is made of very thin crystal glass and it cracks easily. You can see that the corners of it are cracked.</p>

<p><img src="https://www.thevrist.com/assets/images/index21.jpg" alt="">
<em>Crystal polarisation diffuser</em></p>

<p>Diffuser is added to blend pixels better, making the screen door effect even lower.</p>

<p><img src="https://www.thevrist.com/assets/images/index22.jpg" alt="">
<em>Fancy multilayered lens</em></p>

<p>Finally - the lenses. I was expecting them to be thicker with the effect that they create. Valve are saying “The custom lenses built into the Valve Index Headset maximize field of view without sacrificing edge-to-edge clarity. High geometric stability allows you to look around the scene by moving your eyes (not just your head) with minimal shape distortion”. I tend to agree that these are the most advanced lenses in modern mass produced HMD, even though they have their own flaws. Main issue is the light spill when using a headset, you can see the bright light’s reflections in spots where they shouldn’t be.</p>

<h2 id="final-thoughts">Final thoughts</h2>

<p>As you can clearly see, it is not possible to replace a damaged screen or scratched lens all by yourself (even though for latter one you might try to take the lens out using a suction cup, however I don’t think that is a good idea, as lenses and screens are calibrated in the factory).</p>

<p><img src="https://www.thevrist.com/assets/images/index-end.jpg" alt="">
<em>Sometimes… I feel like a monster…</em></p>

<p>I am going to put the high-resolution images of the teardown and of the motherboard <a href="https://photos.app.goo.gl/dhuPVWTu6P5XWo4HA">here</a> so you can see and check all the details by yourself. If you have any corrections, notes, or questions, shoot me an <a href="mailto:zegarsilya@gmail.com">email</a> or PM me on <a href="https://twitter.com/GamerToTheEnd">Twitter</a>.</p>

           …</div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thevrist.com//indexteardown">https://www.thevrist.com//indexteardown</a></em></p>]]>
            </description>
            <link>https://www.thevrist.com//indexteardown</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151496</guid>
            <pubDate>Fri, 14 Aug 2020 00:02:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding .NET Generic Host Model]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151361">thread link</a>) | @sahan
<br/>
August 13, 2020 | https://sahansera.dev/dotnet-core-generic-host/ | <a href="https://web.archive.org/web/*/https://sahansera.dev/dotnet-core-generic-host/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article, we will concentrate on how the Generic Host model hosts ASP.NET Core 3.x Web app and a Worker Service. We will first discuss the definition of a <em>Host</em> and its configuration. In the subsequent sections, we will dive into the implementation details from a higher level.</p>
<h3>So what’s the deal with the Generic Host</h3>
<p>With the separation of execution and initialisation, Generic Host provides us with a cleaner way to configure and start up our apps. By default, when you create an ASP.NET Core app now, your application will be hosted using the Generic Host model. If you create a new worker service app, it will be hosted the same way.</p>
<p>Not only that, but this model also provides you standardised configuration, DI, logging, and many more. You can even create a traditional console app, beef it up and make use of Generic Host.</p>
<blockquote>
<p>💡 Follow along with the code from this <a href="https://github.com/sahan91/dotnet-generic-host-example">repository</a></p>
</blockquote>
<h3>The Host</h3>
<p>According to the official documentation, a <code>Host</code> is,</p>
<blockquote>
<p>ASP.NET Core apps configure and launch a host. The host is responsible for app startup and lifetime management. At a minimum, the host configures a server and a request processing pipeline. The host can also set up logging, dependency injection, and configuration.</p>
</blockquote>
<p>Let’s create a new .NET 3.1 WebAPI and a Worker Service project</p>
<div data-language="bash"><pre><code>dotnet new webapi -n WebApplication
dotnet new worker -n WorkerService
dotnet new sln
dotnet sln <span>add</span> WebApplication WorkerService</code></pre></div>
<p>If you open up the solution in an IDE, you will see the following project structure.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-generic-host-1.png" title="dotnet-core-generic-host-1.png" src="https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/0c69d/dotnet-core-generic-host-1.png" srcset="https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/772e8/dotnet-core-generic-host-1.png 200w,
https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/e17e5/dotnet-core-generic-host-1.png 400w,
https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/0c69d/dotnet-core-generic-host-1.png 598w" sizes="(max-width: 598px) 100vw, 598px" loading="lazy">
    </span></p>
<p>They both have a <code>Program.cs</code> which takes care of setting up a host. In the case of the WebApplication project, it sets up a request processing pipeline defined in a <code>Startup.cs</code> and in the WorkerService project, sets a new hosted service which is an essentially an <code>IHostedService</code>.</p>
<p>In the WebApplication project, when you open up the Program.cs file, you will find the following boilerplate code has been added by the template:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>Main</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    <span>CreateHostBuilder</span><span>(</span>args<span>)</span><span>.</span><span>Build</span><span>(</span><span>)</span><span>.</span><span>Run</span><span>(</span><span>)</span><span>;</span>
<span>}</span>

<span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateHostBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span> <span>=&gt;</span>
    Host<span>.</span><span>CreateDefaultBuilder</span><span>(</span>args<span>)</span>
        <span>.</span><span>ConfigureWebHostDefaults</span><span>(</span>webBuilder <span>=&gt;</span>
        <span>{</span>
            webBuilder<span>.</span><span><span>UseStartup</span><span><span>&lt;</span>Startup<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>And, in the WorkerService project we have the following code:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>Main</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    <span>CreateHostBuilder</span><span>(</span>args<span>)</span><span>.</span><span>Build</span><span>(</span><span>)</span><span>.</span><span>Run</span><span>(</span><span>)</span><span>;</span>
<span>}</span>

<span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateHostBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span> <span>=&gt;</span>
    Host<span>.</span><span>CreateDefaultBuilder</span><span>(</span>args<span>)</span>
        <span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>hostContext<span>,</span> services<span>)</span> <span>=&gt;</span>
        <span>{</span>
            services<span>.</span><span><span>AddHostedService</span><span><span>&lt;</span>Worker<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>Except for the <code>ConfigureWebHostDefaults()</code> and <code>ConfigureServices()</code>, everything else is the same.</p>
<h3>Host Configuration</h3>
<p>If you look at the <code>CreateHostBuilder</code> method in the above code, it calls a <code>CreateDefaultBuilder</code> static method from <a href="https://github.com/dotnet/runtime/blob/master/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">Host</a> coming from <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.host.createdefaultbuilder?view=dotnet-plat-ext-3.1">Microsoft.Extensions.Hosting</a> namespace. It looks like that when we scaffold an ASP.NET Core app, it gives us a <em>.NET Generic Host</em> by default now. We used to have Web Host in ASP.NET Core 2.x, which was made deprecated since ASP.NET Core 3.0. For any future applications, it is recommended to use the .NET Generic Host.</p>
<p>This does a few things under the covers by wrapping,</p>
<ul>
<li>Dependency Injection services</li>
<li>HTTP Server implementation (such as Kestrel)</li>
<li>Logging</li>
<li>Configuration etc.</li>
</ul>
<p>In order to get an idea what the above methods do, I looked into the <a href="https://github.com/dotnet/runtime/blob/master/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">source code on Github</a>.</p>
<p>We will start off with CreateDefaultBuilder method first.</p>
<p><strong><a href="https://github.com/dotnet/runtime/blob/6072e4d3a7a2a1493f514cdf4be75a3d56580e84/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">Host.CreateDefaultBuilder()</a></strong></p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateDefaultBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    
    <span><span>var</span></span> builder <span>=</span> <span>new</span> <span>HostBuilder</span><span>(</span><span>)</span><span>;</span>

    
    builder<span>.</span><span>UseContentRoot</span><span>(</span>Directory<span>.</span><span>GetCurrentDirectory</span><span>(</span><span>)</span><span>)</span><span>;</span>

    
    
    builder<span>.</span><span>ConfigureHostConfiguration</span><span>(</span>config <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

    
    
    builder<span>.</span><span>ConfigureAppConfiguration</span><span>(</span><span>(</span>hostingContext<span>,</span> config<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

    
    <span>.</span><span>ConfigureLogging</span><span>(</span><span>(</span>hostingContext<span>,</span> logging<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

    
    <span>.</span><span>UseDefaultServiceProvider</span><span>(</span><span>(</span>context<span>,</span> options<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

    <span>return</span> builder<span>;</span>
<span>}</span></code></pre></div>
<p>As you can see, it pretty much configures a <code>HostBuilder</code> object and returns it. There’s nothing really specific to web hosting in here. This is why it’s common to both HTTP and non-HTTP workloads.</p>
<p>Taking a step further, let’s look at how the web host gets configured. We will now look through <code>ConfigureWebHostDefaults</code> method.</p>
<p><strong><a href="https://github.com/dotnet/aspnetcore/blob/4d4f2fe00ffa7c1b9ea08164f9f26a51a392d007/src/DefaultBuilder/src/GenericHostBuilderExtensions.cs#L26">GenericHostBuilderExtensions.ConfigureWebHostDefaults()</a></strong></p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>ConfigureWebHostDefaults</span><span>(</span><span>this</span> <span>IHostBuilder</span> builder<span>,</span> <span>Action<span>&lt;</span>IWebHostBuilder<span>&gt;</span></span> configure<span>)</span>
<span>{</span>
    <span>return</span> builder<span>.</span><span>ConfigureWebHost</span><span>(</span>webHostBuilder <span>=&gt;</span>
    <span>{</span>
        WebHost<span>.</span><span>ConfigureWebDefaults</span><span>(</span>webHostBuilder<span>)</span><span>;</span>

        <span>configure</span><span>(</span>webHostBuilder<span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Remember that <code>ConfigureWebHostDefaults</code> is used only for HTTP workloads and let’s see what we get as the default web host configuration.</p>
<p><strong><a href="https://github.com/dotnet/aspnetcore/blob/4d4f2fe00ffa7c1b9ea08164f9f26a51a392d007/src/DefaultBuilder/src/WebHost.cs#L215">WebHost.ConfigureWebDefaults()</a></strong></p>
<div data-language="csharp"><pre><code><span>internal</span> <span>static</span> <span><span>void</span></span> <span>ConfigureWebDefaults</span><span>(</span><span>IWebHostBuilder</span> builder<span>)</span>
<span>{</span>
	
    builder<span>.</span><span>ConfigureAppConfiguration</span><span>(</span><span>(</span>ctx<span>,</span> cb<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

	
    builder<span>.</span><span>UseKestrel</span><span>(</span><span>(</span>builderContext<span>,</span> options<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

	
    <span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>hostingContext<span>,</span> services<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

	
    <span>.</span><span>UseIIS</span><span>(</span><span>)</span>
    <span>.</span><span>UseIISIntegration</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>So far, we have seen that both approaches use the same Generic Host paradigm in the two projects. If you are interested in customising the default configuration, head over to <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1#host-configuration">Microsoft Docs’ official documentation</a>.</p>
<h3>Finally, how does it all run?</h3>
<p>Now comes the interesting part.</p>
<p>In both cases, after the configuration sections, we finally call the <code>Run()</code> on <code>IHost</code> object implemented in <code>HostingAbstractionsHostExtensions</code>. This will run the app and block the calling thread until the host is shut down. This is enabled by <code>WaitForShutdownAsync</code> which is called at the beginning of the start-up process, which can be triggered by Ctrl+C/SIGTERM or SIGINIT.</p>
<p>Let’s look at how both web hosts and worker services run.</p>
<p>For a worker service, remember how we registered our Worker class by passing it into <code>ConfigureServices</code> method. This Worker class extends <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.backgroundservice?view=dotnet-plat-ext-3.1"><code>BackgroundService</code></a> which in turn implements <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedservice?view=dotnet-plat-ext-3.1"><code>IHostedService</code></a>. <code>IHostedService</code> provides 2 methods, namely, <code>StartAsync</code> and <code>StopAsync</code>. So when we run our host, it must be retrieving our Worker service and invoking these methods.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-generic-host-2.png" title="dotnet-core-generic-host-2.png" src="https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/5a190/dotnet-core-generic-host-2.png" srcset="https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/772e8/dotnet-core-generic-host-2.png 200w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/e17e5/dotnet-core-generic-host-2.png 400w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/5a190/dotnet-core-generic-host-2.png 800w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/c1b63/dotnet-core-generic-host-2.png 1200w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/29007/dotnet-core-generic-host-2.png 1600w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/575bd/dotnet-core-generic-host-2.png 1791w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p><em>Source: <a href="https://devblogs.microsoft.com/cesardelatorre/implementing-background-tasks-in-microservices-with-ihostedservice-and-the-backgroundservice-class-net-core-2-x/">Microsoft</a></em></p>
<p>In the <code>Host.cs</code> there’s a separate <code>StartAsync</code> method and we can find the following lines inside it.</p>
<div data-language="csharp"><pre><code>_hostedServices <span>=</span> Services<span>.</span><span><span>GetService</span><span><span>&lt;</span>IEnumerable<span>&lt;</span>IHostedService<span>&gt;</span><span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>

<span>foreach</span> <span>(</span><span><span>var</span></span> hostedService <span>in</span> _hostedServices<span>)</span>
<span>{</span>
    
    <span>await</span> hostedService<span>.</span><span>StartAsync</span><span>(</span>combinedCancellationToken<span>)</span><span>.</span><span>ConfigureAwait</span><span>(</span><span>false</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>So our guess was correct. It certainly invokes the <code>StartAsync</code> method of <code>BackgroundService</code>, that calls <code>ExecuteAsync</code> method in which we have ultimately implemented in our <code>Worker</code> class.</p>
<p>For a web host, there’s a little bit of abstraction on top of this before it hits the above section. A summary of how it reaches this as follows;</p>
<ol>
<li>In Program.cs, configure a new webhost builder object in ConfigureWebHostDefaults</li>
<li>Register Startup class</li>
<li><code>GenericHostBuilderExtensions.ConfigureWebHostDefaults</code> method gets called</li>
<li><code>GenericHostWebHostBuilderExtensions.ConfigureWebHost</code> gets called</li>
<li>Register a <code>GenericWebHostService</code> service</li>
</ol>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>ConfigureWebHost</span><span>(</span><span>this</span> <span>IHostBuilder</span> builder<span>,</span> <span>Action<span>&lt;</span>IWebHostBuilder<span>&gt;</span></span> configure<span>)</span>
<span>{</span>
    <span><span>var</span></span> webhostBuilder <span>=</span> <span>new</span> <span>GenericWebHostBuilder</span><span>(</span>builder<span>)</span><span>;</span>
    <span>configure</span><span>(</span>webhostBuilder<span>)</span><span>;</span>
    builder<span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>context<span>,</span> services<span>)</span> <span>=&gt;</span> services<span>.</span><span><span>AddHostedService</span><span><span>&lt;</span>GenericWebHostService<span>&gt;</span></span></span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>return</span> builder<span>;</span>
<span>}</span></code></pre></div>
<p>So what is a <code>GenericWebHostService</code> ? It’s an <code>IHostedService</code> 🤩. Rest of the story is as above as we looked at in the worker service scenario. Because of this nicely decoupled initialisation we are able to run both ASP.NET Core and Worker services on the Generic Host.</p>
<h3>Summary</h3>
<p>To summarise, we looked at what makes the Generic Host <em>generic</em> and dug deeper into the implementation details in .NET Github repo. We also looked at what makes an ASP.NET Core web application and a worker service different, configuration-wise. This post became a bit longer than I initially I thought it would be 😅 Nevertheless, hope you picked up a thing or two.</p>
<p>Cheers!</p>
<h3>References</h3>
<ol>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&amp;tabs=visual-studio">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&amp;tabs=visual-studio</a></li>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1</a></li>
<li><a href="https://andrewlock.net/exploring-the-new-project-file-program-and-the-generic-host-in-asp-net-core-3/">https://andrewlock.net/exploring-the-new-project-file-program-and-the-generic-host-in-asp-net-core-3/</a></li>
</ol></div></div>]]>
            </description>
            <link>https://sahansera.dev/dotnet-core-generic-host/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151361</guid>
            <pubDate>Thu, 13 Aug 2020 23:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google play music shutting down]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24150597">thread link</a>) | @abuckenheimer
<br/>
August 13, 2020 | https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/ | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            
  <article>
    
    


<div>

<section>
    
    <div>
      
      <div>
        <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/GPM_15s_en_US_1.gif" alt="YouTube Music will replace Google Play Music by end of 2020">
        
        </p>
      </div>
      <p>
        <article>
          Today we're announcing two important updates.
        </article>
      </p>
    </div>
  </section>
</div>


    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the past couple of months, we’ve been welcoming Google Play Music listeners to YouTube Music as they <a href="https://youtube.googleblog.com/2020/05/youtube-music-transfer-google-play-music-library.html">effortlessly transfer</a> their music libraries, personal taste preferences and playlists to YouTube Music. Today we're announcing two important updates. First, YouTube Music will replace Google Play Music by December 2020. Users will have the opportunity to transfer their music libraries from Google Play Music to YouTube Music in that timeframe. Second, in the coming months, Google Play Music users will no longer be able to stream from or use the Google Play Music app. Additionally, we are making changes to the Google Play store and Music Manager.&nbsp;</p><p>Starting in September 2020 in New Zealand and South Africa — and in October for all other global markets — users will no longer be able to stream from or use the Google Play Music app. But don’t worry, we will be holding onto things like your playlists, uploads, purchases, likes and more until December 2020 to make your transfer to YouTube Music easier. Users who wish to transfer their music libraries from Google Play Music to YouTube Music, can do so through December 2020, after which their Google Play Music libraries will no longer be available.</p><h2>Simple transfer and additional changes to Music Manager</h2><p>Starting in late August, users will no longer be able to purchase and pre-order music or upload and download music from Google Play Music through Music Manager.&nbsp;</p><p>To ensure users don’t lose any of their content, they’ll need to use the simple<a href="http://music.youtube.com/transfer"> transfer tool</a> to migrate any purchases over to YouTube Music or use<a href="https://takeout.google.com/"> Google Takeout</a> to export data and download their purchased and uploaded music. Once the Music Store is no longer available, users will continue to be able to upload any tracks purchased elsewhere to YouTube Music.</p><p>For Google Play listeners that have not yet started the transfer process over to YouTube Music, now’s the time. Listeners can also choose to delete their Google Play Music data, and we will clearly notify all users before they lose access to their Google Play Music library and data.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/unnamed_1_eb3YIiY.jpg" alt="GPM II">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><h2>Enhancements to your new home for music: YouTube Music&nbsp;&nbsp;&nbsp;</h2><p>Since<a href="https://youtube.googleblog.com/2020/05/youtube-music-transfer-google-play-music-library.html"> introducing the transfer tool in May</a>, we’ve continued to improve and add new features to YouTube Music for all music lovers to enjoy, including many that are important and familiar to Google Play Music users.&nbsp;</p><br><ul><li><p><b>Playlists: We’re continuously evolving the way listeners can create and enjoy playlists, including:</b></p></li><ul><li><p><b>Assistive Playlist Creation </b>- Quickly and easily create playlists by adding recommended songs based on existing songs in the playlist, as well as personalized signals, such as watch history and likes.</p></li><li><p><b>Collaborative Playlists</b> - Collaborate with other music fans to create shared playlists for any occasion.</p></li><li><p><b>New Programmed Playlists </b>- Explore newly launched programmed playlists like <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_mu-BhJj3yO1OXEMzahs_aJVtNWJwAwFEE">Highline</a>, <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_kUFCSc-grF3m-L_49W6p1QyGsMbueEbog">Caribbean Pulse</a>, <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_m0Nsi5Jnn_g6qbvc7fywPRhEv1qN0PcMM">Conditions Underground</a>, and more.</p></li></ul><li><p><b>New Features and Improvements:&nbsp;</b></p></li><ul><li><p><b>Player Page Redesign</b> - Updates to the player page, available for Android mobile users, provides a more modern design that allows better playback controls and easier access to related music and other features like song lyrics.</p></li><li><p><b>Explore Tab</b> -&nbsp;The new Explore tab, available on both mobile and the web is the consistent destination to find new releases including albums, singles, and music videos, as well as browse our vast catalog of diverse playlists through the Moods &amp; Genre section</p></li></ul><li><p><b>More Ways to Enjoy YouTube Music:</b></p></li><ul><li><p><b>Android TV</b> - An update for Android TV brings YouTube Music to the big screen, letting listeners enjoy videos and live performances from their favorite artists, along with all their favorite music.</p></li><li><p><b>Google Maps</b> - The Android integration lets listeners seamlessly listen to music and get personalized music recommendations within the Google Maps interface.</p></li><li><p><b>Discover music with Google Assistant</b> - You can now ask your Google Home and Nest smart speakers, “Hey Google, play recommended music from YouTube Music.” Then, Google Assistant will share personalized recommendations based on your favorite artists and genres.&nbsp;</p></li></ul></ul></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the last few years, we've worked to build a fantastic fan experience on YouTube Music, merging the very best of Google Play Music with the very best of YouTube. For users who decide not to transfer their Google Play Music account to YouTube music, we will be sure to cancel your subscription at the end of your billing cycle so you aren't paying for a subscription. This will happen in September in New Zealand and South Africa and in October for all other markets. And, of course, we will be sure to notify all users ahead of subscriptions being canceled.</p><p>We can’t wait for you to start exploring YouTube Music features and discovering new music favorites along the way. Have more questions or need help? Check out all of our support resources <a href="https://support.google.com/youtubemusic/answer/9698084">here</a>.</p><br></div>
      </div>
      
    </div>
  </div>
</section>

      
    

    


<section>
  <article>
    
  </article>
</section>


    
    
  


  </article>


        </div></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150597</guid>
            <pubDate>Thu, 13 Aug 2020 22:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Face Detection and Recognition Libraries 2020]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24150436">thread link</a>) | @truly_furqan
<br/>
August 13, 2020 | https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/ | <a href="https://web.archive.org/web/*/https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150436</guid>
            <pubDate>Thu, 13 Aug 2020 22:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Blocks of Every Machine Learning Solutions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24150088">thread link</a>) | @FHMS
<br/>
August 13, 2020 | https://datarevenue.com/en-blog/machine-learning-project-architecture | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/machine-learning-project-architecture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Machine learning solutions are used to solve a wide variety of problems, but in nearly all cases the core components are the same. Whether you simply want to understand the skeleton of machine learning solutions better or are embarking on building your own, understanding these components - and how they interact - can help.</p><p>Here’s a visual and written explanation of what these are and what they do.</p><figure id="w-node-1017d6fd20b2-018ecc93"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5f2d1b1667b2cfe2a3ceec18_Q5H2ISpXvST4SJ7rp6-MMChpY5W_Bxul_c1g2CGCSMFSRNT_wlI1PT7XoxABOu-ftF6reUZVHRMHAzRKz7wXgxMz7umLRlFYq6gahk-GdlPW2ZUEL1M8PSuPPnNQK1nXNDV6HP2Y.png" alt="A diagram showing the components of a machine learning solution."></p><figcaption>Machine learning consists of many components, not just an algorithm. (Want more content like this? <a href="https://datarevenue.com/signup">Subscribe</a> to our newsletter).</figcaption></figure><p>‍<strong>The components of a machine learning solution</strong></p><ol role="list"><li><strong>Data Generation: </strong>Every machine learning application lives off data. That data has to come from somewhere. Usually it’s generated by one of your core business functions.</li><li><strong>Data Collection: </strong>Data is only useful if it’s accessible, so it needs to be stored – ideally in a consistent structure and conveniently in one place.</li><li><strong>Feature Engineering Pipeline:</strong> Algorithms can't make sense of raw data. We have to select, transform, combine, and otherwise prepare our data so the algorithm can find useful patterns.</li><li><strong>Training:</strong> This is where the magic happens. We apply algorithms, and they learn patterns from the data. Then they use these patterns to perform particular tasks.</li><li><strong>Evaluation: </strong>We need to carefully test how well our algorithm performs on data it hasn’t seen before (during training). This ensures we don’t use prediction models that work well on “seen” data, but not in real-world settings.</li><li><strong>Task Orchestration:</strong> Feature engineering, training, and prediction all need to be scheduled on our compute infrastructure (such as AWS or Azure) – usually with non-trivial interdependence. So we need to reliably orchestrate our tasks.</li><li><strong>Prediction:</strong> This is the moneymaker. We use the model we’ve trained to perform new tasks and solve new problems – which usually means making a prediction.</li><li><strong>Infrastructure: </strong>Even in the age of the cloud, the solution has to live and be served somewhere. This will require setup and maintenance.&nbsp;</li><li><strong>Authentication:</strong> This keeps our models secure and makes sure only those who have permission can use them.</li><li><strong>Interaction:</strong> We need some way to interact with our model and give it problems to solve. Usually this takes the form of an API, a user interface, or a command-line interface.<strong>‍</strong></li><li><strong>Monitoring: </strong>We need to regularly check our model’s performance. This usually involves periodically generating a report or showing performance history in a dashboard.</li></ol><h2><strong>Building your own ML Architecture</strong></h2><p>Data generation and collection, training, and evaluation are must-haves, but you may need domain-specific components too.</p><p>A <a href="https://datarevenue.com/en-blog/building-ai-projects-or-hiltch-skyline-ai">common mistake we see</a> is people focussing too much on the prediction component and not enough on the feature engineering pipeline (or trying to skip this component completely).</p><p>Do you need a second opinion on how to set up the architecture for your ML applications? <a href="https://datarevenue.com/en-contact">Schedule a call</a> with us.</p></div></div></div></div>]]>
            </description>
            <link>https://datarevenue.com/en-blog/machine-learning-project-architecture</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150088</guid>
            <pubDate>Thu, 13 Aug 2020 22:07:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 33% Memory Reduction by Reordering Struct Fields]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24149637">thread link</a>) | @lanecwagner
<br/>
August 13, 2020 | https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields | <a href="https://web.archive.org/web/*/https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>In past projects at <a href="https://classroom.qvault.io/">Qvault</a> we had an application that typically ran with <strong>~2GB</strong> in memory at any given time. By simply changing the order of some <code>uint</code> variables we managed to drop the memory usage to less than <strong>1.4GB</strong>. The vast majority of this allocated memory is due to an enormous slice of <code>stats</code> structs.</p>



<p>The <code>stats</code> struct has the following type definition:</p>



<pre><code lang="go">type stats struct {
	NumPosts uint8
	Reach    uint16
	NumLikes uint8
}</code></pre>



<p>In theory, this struct will use a measly 4 bytes. Each <code>uint8</code> uses 1 <code>byte</code>, and the single <code>uint16</code> needs 2. We began to suspect that we had some wasteful memory issues, so I built the following little program to show how memory is being used by our struct:</p>



<pre><code lang="go">package main

import (
	"fmt"
	"reflect"
	"runtime"
)

type stats struct {
	NumPosts uint8
	Reach    uint16
	NumLikes uint8
}

func main() {
	typ := reflect.TypeOf(stats{})
	fmt.Printf("Struct is %d bytes long\n", typ.Size())
	n := typ.NumField()
	for i := 0; i &lt; n; i++ {
		field := typ.Field(i)
		fmt.Printf("%s at offset %v, size=%d, align=%d\n",
			field.Name, field.Offset, field.Type.Size(),
			field.Type.Align())
	}

	allStats := []stats{}
	for i := 0; i &lt; 100000000; i++ {
		allStats = append(allStats, stats{})
	}

	printMemUsage()
}

func printMemUsage() {
	var m runtime.MemStats
	runtime.ReadMemStats(&amp;m)
	fmt.Printf("Alloc = %v MiB", bToMb(m.Alloc))
	fmt.Printf("\tTotalAlloc = %v MiB", bToMb(m.TotalAlloc))
	fmt.Printf("\tSys = %v MiB", bToMb(m.Sys))
	fmt.Printf("\tNumGC = %v\n", m.NumGC)
}

func bToMb(b uint64) uint64 {
	return b / 1024 / 1024
}</code></pre>



<p>On my MacBook using Go 1.14.1 the above program prints:</p>



<pre><code lang="bash">Struct is 6 bytes long
NumPosts at offset 0, size=1, align=1
Reach at offset 2, size=2, align=2
NumLikes at offset 4, size=1, align=1
Alloc = 1084 MiB        TotalAlloc = 3012 MiB   Sys = 2713 MiB  NumGC = 19</code></pre>



<p>Notice that even though <code>NumPosts</code> only has a size of 1 byte, the next field, <code>Reach</code>, still starts at offset 2. A whole byte is being wasted! The same thing happens with the <code>NumLikes</code> field, it starts at offset 4 with a size of 1, but the struct still takes up the full 6 bytes.</p>



<p>This may not seem like a big deal, but when you are storing millions of these structs in memory the bloat starts to add up quick.</p>



<p>If we change the <code>stats</code> struct such that the <code>uint16</code> isn’t defined between the <code>uint8</code>s:</p>



<pre><code lang="go">type stats struct {
	Reach    uint16
	NumPosts uint8
	NumLikes uint8
}</code></pre>



<p>Then the output of the program becomes:</p>



<pre><code lang="bash">Struct is 4 bytes long
Reach at offset 0, size=2, align=2
NumPosts at offset 2, size=1, align=1
NumLikes at offset 3, size=1, align=1
Alloc = 694 MiB TotalAlloc = 1927 MiB   Sys = 1391 MiB  NumGC = 19</code></pre>



<p>The total allocated memory drops from 3 GB to less than 2, and each instance of the struct now only uses 4 bytes.</p>



<h2>Why?</h2>



<p>Modern CPU hardware performs reads and writes to memory most efficiently when the data is&nbsp;<em><a href="https://en.wikipedia.org/wiki/Data_structure_alignment" target="_blank" rel="noreferrer noopener">naturally aligned</a></em>. The memory that is stored side by side should be accessible using a common multiple, so the Go compiler makes sure that it is.</p>



<p>With our first struct, the Reach field is between the NumPosts and NumLikes fields, which means that the compiler will add some padding to keep things nice and even. </p>



<figure><img loading="lazy" width="1024" height="645" src="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-1024x645.png" alt="golang memory usage struct alignment" srcset="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-1024x645.png 1024w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-300x189.png 300w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-768x484.png 768w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM.png 1194w" sizes="(max-width: 1024px) 100vw, 1024px" title="Screen Shot 2020 08 07 at 2.51.09 PM"></figure>



<p>In our updated struct however, we have grouped the smaller fields, and since they add up to the same amount of memory as the larger <code>Reach</code> field we can save some space!</p>



<figure><img loading="lazy" width="1024" height="624" src="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-1024x624.png" alt="golang memory usage struct alignment fixed" srcset="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-1024x624.png 1024w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-300x183.png 300w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-768x468.png 768w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM.png 1178w" sizes="(max-width: 1024px) 100vw, 1024px" title="Screen Shot 2020 08 07 at 2.54.26 PM"></figure>



<p>This was is a weird quirk, but making the smal optimizations has made a huge impact on some of our services.</p>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149637</guid>
            <pubDate>Thu, 13 Aug 2020 21:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knurling-Rs Announcement]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24149469">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://ferrous-systems.com/blog/knurling-rs/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/knurling-rs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://ferrous-systems.com/images/knurling-rs.png" alt="Knurling-rs"></p>

<p>Today we're announcing <a href="https://github.com/knurling-rs">Knurling</a> - Ferrous' effort to sustainably build better tooling for developing and debugging Rust software for embedded systems.</p>

<p>To make this a reality, we are opening a <a href="https://github.com/knurling-rs/meta">GitHub organization</a> to collect these efforts, as well as making it possible to <a href="https://github.com/sponsors/knurling-rs">support our efforts through GitHub Sponsors</a>.</p>

<h2 id="the-mission">The Mission</h2>

<p>We believe that developing software for embedded systems should be no more difficult than developing for hosted platforms. It should be possible to use the same workflows and equally powerful tooling to develop applications and libraries for tiny embedded systems as well as server-class hardware.</p>

<p>To that end, we want to enable:</p>

<ul>
  <li>Learning embedded Rust with up to date and maintained teaching material</li>
  <li>Space-efficient and real-time capable logging</li>
  <li>Tools that integrate into your standard cargo run and cargo test workflows</li>
  <li>Execution tracing</li>
  <li>Simple data logging and visualization straight into your IDE or Browser</li>
</ul>

<p>We are already active contributors in the open source ecosystem, but we want to spend more time dedicated to building tools that improve the experience for the entire ecosystem, and we can't do that without <a href="https://github.com/sponsors/knurling-rs">your support</a>.</p>

<h2 id="release-model">Release Model</h2>

<p>We plan to make everything we develop under Knurling to be open source, in order to support the community. This includes all of the tooling, teaching material, and support libraries we develop.</p>

<p>The items we release will all be under <a href="https://opensource.org/licenses/MIT">MIT</a>+<a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache 2.0</a> licenses for code, and <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA 4.0</a> for written material.</p>

<p>Sponsors will also have early access to work in progress tools and libraries before they are released, as well as early access to our training material and exercises before they are made public.</p>

<p>Early Access is available for all sponsors, regardless of tier.</p>

<p>Let's take a quick tour of the things we plan to make possible with <a href="https://github.com/knurling-rs/meta">Knurling</a>:</p>



<blockquote>
  <p>EDIT: This blog post has been updated to reflect the rename of <code>binfmt</code> to <code>defmt</code>.</p>
</blockquote>

<p><img src="https://ferrous-systems.com/images/defmt-teaser.jpg" alt="defmt preview"></p>

<p>We'd like to spend time to make it easier to design, build, debug, and release software components with embedded Rust. This includes developing target-side libraries, as well as host-side applications that interact with these components.</p>

<p>We also want to make it possible to have best-in-class debugging tools, allowing you to monitor, graph, and visualize what your system is doing. We think that it's possible to make developing embedded systems painless through better and extensible tooling!</p>

<p>The first of these tools we plan to release is <code>defmt</code> (in the screenshot above), a tool for efficient logging and tracing in real-time, using a variety of different transport methods like Semihosting, RTT, or even a UART or radio. <code>defmt</code> will allow for logging of data without incurring expensive formatting costs on the device itself.</p>

<p>We'll be talking more about defmt next week on our blog, but you can check it out now if you <a href="https://github.com/sponsors/knurling-rs">become a sponsor today</a>!</p>

<h2 id="more-training-and-learning-examples">More Training and Learning Examples</h2>

<p><img src="https://ferrous-systems.com/images/emb-trainings.png" alt="embedded trainings"></p>

<p>We're already developing open source training material for embedded systems in Rust, including our training material for <a href="https://github.com/ferrous-systems/teaching-material/">basic Rust training</a>, the material for our <a href="https://github.com/ferrous-systems/embedded-trainings">2019 Embedded Trainings</a>, as well as our most recent <a href="https://github.com/ferrous-systems/embedded-trainings-2020">2020 Embedded Trainings</a>.</p>

<p>We plan to develop a new, continuously maintained set of training material that consists of two parts:</p>

<p>The first part is <strong>Knurling Books</strong>, which are written guides that teach general concepts of embedded systems and Rust, and come with associated sample projects demonstrating the concepts. This is a great place for folks to learn embedded systems or embedded systems with Rust!</p>

<p>The second part is <strong>Knurling Sessions</strong>, which are quarterly embedded projects that explore specific projects using generally available hardware, building full systems and components using microcontrollers, sensors, and actuators.</p>

<p>These will be guided, hands-on tutorials for building projects like a CO2 Sensor, Data Loggers, and even robots! For folks that want to learn in a more hands-on way, or want to know "what hardware should I buy to get started", Knurling Sessions are a great option!</p>

<p>Before each session, we'll announce the hardware we'll use and how we'll use it. If you want to follow along and build the project at home, we'll include links to purchase the hardware. We'll reuse components session to session, so you can start building your own collection of parts!</p>

<p>In the future, we plan to also offer video based training and Q&amp;A sessions where we explore the concepts in a deeper and more detailed way, great for learning how and why things are built.</p>

<p>As we mentioned, all of the <strong>Knurling Books</strong> and <strong>Knurling Sessions</strong> will be made public and open source, but <a href="https://github.com/sponsors/knurling-rs">Sponsors</a> will get early access to both!</p>

<p>We'll be announcing our first training books and sessions later in August, so stay tuned!</p>

<h2 id="more-experiments-and-ecosystem-improvements">More Experiments and Ecosystem Improvements</h2>

<p><img src="https://ferrous-systems.com/images/async-on-embedded.png" alt="async on embedded"></p>

<p>In the past, we've done a number of experiments and improvements towards the Rust and Rust Embedded ecosystems. Most recently, we <a href="https://ferrous-systems.com/blog/embedded-async-await/">wrote about</a> making <a href="https://ferrous-systems.com/blog/async-on-embedded/">async/await</a> possible <a href="https://ferrous-systems.com/blog/stable-async-on-embedded/">for embedded systems</a>, and were even able to contribute optimizations that sped up compilation and run time for all users of async/await!</p>

<p>We released these experiments as <a href="https://github.com/ferrous-systems/async-on-embedded">an open source project</a>, and it has already been <a href="https://github.com/rust-embedded-community/async-on-embedded">transferred to community ownership</a>.</p>

<p>We'd like to dedicate more time to these kinds of projects, exploring what could be possible with embedded Rust, bringing crates to a maintained 1.0 status, or improving the compiler to benefit embedded systems developers. You can help us make this happen by <a href="https://github.com/sponsors/knurling-rs">sponsoring our efforts</a>!</p>

<h2 id="thank-you-all">Thank you all!</h2>

<p>We think the embedded Rust ecosystem is already the best way to develop embedded software today, but we can make it even better and easier, whether you are a developer who has never touched a microcontroller before, or you are a developer that is already an expert in embedded Rust.</p>

<p>If you'd like to support these works as an individual or through your company, we'd <a href="https://github.com/sponsors/knurling-rs">appreciate it a lot</a>! If you're interested in more details, or there is something you'd like to see us do, <a href="mailto:knurling@ferrous-systems.com">just drop us an email</a>!</p>
</div></div>]]>
            </description>
            <link>https://ferrous-systems.com/blog/knurling-rs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149469</guid>
            <pubDate>Thu, 13 Aug 2020 21:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Automation: The End of Silos and Rise of Workflows]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24148532">thread link</a>) | @omi1997
<br/>
August 13, 2020 | https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>Tooling has always been a strategically important method for engineering teams to bolster efficiency. The latest research by <a href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-how-software-excellence-fuels-business-performance?cid=soc-app">McKinsey &amp; Company</a>, where 440 senior engineering executives were surveyed, demonstrates that companies are 65% likely to be more innovative with better tooling. </p><p>There’s nothing new here, engineers have always looked at tooling as a source for automation. But with the report revealing that only 5% of executives listed tooling a top three method for software enablement. With technologies rapidly rising and falling, software companies need to be leaner than ever in their adoption of automation tools. </p><p>To master this accelerating shift, technical leaders need to look at automation adoption beyond engineering departments and view the software delivery process as a cross-departmental effort. If you’re one of the many forward-looking technical leads hoping to gain strategic advantages, here’s how to ensure automation success. </p><h2 id="devops-today-and-the-automation-of-tomorrow">DevOps Today and the Automation of Tomorrow</h2><p>Traditionally, the developer tooling market has always been geared towards engineers, where DevOps specialists would craft automation, pipelines, and processes by integrating different technologies for the developer, and the graphic below shows the current tools out there.</p><!--kg-card-begin: image--><figure><img src="https://lh3.googleusercontent.com/rT9GfCt5hb7rwD2AC_bDeFI-pDxKlW8a7SZ8MSQYywCh0hNXj8UxXfs7ZmEpEPeoMB5tWFsxgBr_UpjJrSfroqayELR9eVfvWco1bjr-jOH6P4-zF-Ct97DGJjmjD4cMSzveToM7"></figure><!--kg-card-end: image--><p>In essence, the automation that the tools above provide was built with developers in mind as the end-user. The end result yields greater developer satisfaction, as their talent and imagination are given the means to shine. </p><p>As evidenced by the <a href="https://services.google.com/fh/files/misc/state-of-devops-2019.pdf">2019 State of DevOps reports</a>, the software industry values speed and automation of delivery and tasks, and the report, in particular, asserts that strong tool-chains give developers a culture of “psychological safety,” effectively bolstering team productivity. With <a href="https://stripe.com/en-ca/reports/developer-coefficient-2018">$300 billion being lost annually in developer productivity</a>, we can see a real opportunity for automation to keep saving developers, and the overall business, precious time. </p><h2 id="a-movement-to-workflows">A Movement to Workflows</h2><p>There’s already been a movement in the software industry to streamline processes with automation. For example, GitOps is streamlining source control by tightly integrating it with CI/CD. But that just doesn’t go far enough. As the developer tooling market grows, more and more tools are now required to be integrated into the software delivery process, causing greater market fragmentation. Companies like Salesforce are even launching their own DevOps platforms, meaning vendor-specific integration is more of a challenge than ever before for DevOps teams who are looking to streamline their delivery across their technology portfolio.</p><p>So, as business toolchains grow, it has become more critical than ever to eliminate silos of automation creation and empower other functions across the business, especially that outside of engineering, to be able to automate on their own. Essentially the cost of automation ownership must be lowered to allow for a more frictionless process for automation to take place. In this scenario, we see the rise of the workflow – a set of tasks and processes whereby multiple tools can be seamlessly integrated. As such, businesses must see automation outside the lens of engineering, and look to democratize its extraordinary benefits across the entire business to other departments.</p><p>A great example of a company lowering the barriers to automation is Atlassian. The company announced a <a href="https://www.computerworld.com/article/3532328/atlassian-adds-no-code-automation-to-jira-cloud-products.html">no-code workflow creator</a> for any user across it’s Jira Cloud portfolio. &nbsp; </p><p>In parallel, an interesting insight provided by McKinsey, which was missing from other reports, is the growing benefits of low-code tools. The study reveals that low-code tools help organizations adopt automation advantages at a much lower cost of ownership and allow them to exponentially increase their leverage on their development talent. The study observed that teams were able to adopt automation much faster when the barrier to automation (i.e. code complexity) is lowered. This makes automation accessible to less technical team members and enhances self-service and cross-functional accessibility to automation through workflows that they can create to their own needs. </p><p>At CTO.ai, we rethought automation from the bottom up to address these challenges. We realized that the most obvious solution was not only to lower the cost of automation through low code, but also to bring these developer tools to the place where people meet across the entire organization – Slack – and more specifically, SlackOps or DevOps in Slack (often more generally called ChatOps in the industry).</p><p>We further realized that businesses need an easy platform that all employees can leverage. By bringing the ease of chat and automation in a shared and transparent environment such as Slack, there’s an opportunity for businesses to significantly reduce inefficiencies and turbocharge productivity. </p><h2 id="a-brave-new-automation">A Brave New Automation</h2><p>With automation changing form, there will be winners and losers concerning how businesses approach the new world we’re entering. Businesses that are unwilling to begin implementing changes in their software development tooling and wider business access to workflow creation will be left behind. </p><p>For technical leadership, this is an opportunity to export engineering-based concepts and ideas such as CI/CD, automation testing, and more to other departments. Engineering departments have, generally speaking, long been ahead of other departments in regards to optimization, and use of automation. After all, engineers can code, but other departments don’t have such requirements in their job descriptions. </p><p>We at CTO.ai continue to advocate for greater use of automation for DevOps and all departments. As we continue to iterate our cutting-edge technology for Slack workflows (SlackOps), not only does the rise of the workflow become an important factor in the accessibility of automation, but also the measurement of workflow efficacy becomes even more critical. As such, companies need to be cognizant of their workflow efficacy and therefore must continue to ever optimize for scale. This is why we’re also introducing a Workflow Metrics MVP, the first-concept measurement of workflow efficiency.</p><p><em>Want to see our private demo? Contact us by<a href="https://w.cto.ai/contact-us"> clicking here </a>to see the private Alpha of the MVP.</em></p>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148532</guid>
            <pubDate>Thu, 13 Aug 2020 20:31:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Internationalization and Localization Matters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148141">thread link</a>) | @gsilva49
<br/>
August 13, 2020 | https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html | <a href="https://web.archive.org/web/*/https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>According to the always trustworthy Wikipedia, there are approximately 360 million native English speakers in the world. We, as developers, are so used to write code and documentation in English that we may not realize that this number only represents 4.67% of the world population. It is very useful to have a common language for the communication between developers, but this doesn’t mean that the user shouldn’t feel a little bit more comfortable when using your product.</p>
<p>This post will start discussing the definition of internationalization and localization and why they matter for your application. Then we will go over some of the internationalization tools that developers have available to work on their Python and Django projects. Finally, we will present how we had to adapt our development flow to incorporate the internationalization step.</p>
<h2>Localization vs Internationalization</h2>
<p><strong>Localization (l10n</strong><sup id="fnref:1"><a href="#fn:1">1</a></sup><strong>)</strong> is the process of adapting an application, product or even a document to be more user-friendly to customers from different countries and cultures.</p>
<p>On the other hand, <strong>internationalization (i18n)</strong> is the process of enabling localization of the product on the application. Implementing a software in a way that it will know when and how to show different content depending on the costumer’s locale.</p>
<p>As the Django documentation perfectly summarizes: localization is done by translators and internationalization is done by developers<sup id="fnref:2"><a href="#fn:2">2</a></sup></p>
<p>However, this simplified definition of internationalization and localization may give the wrong impression that this is just about translation. This process entails several other adaptations needed to make users from different cultures feel more comfortable using your product, such as:</p>
<ul>
<li>Date and currency formatting</li>
<li>Currency conversion</li>
<li>Units of measurement conversion</li>
<li>Unicode characters and bidirectional text (see example below)</li>
<li>Time zones, calendar and special holidays</li>
</ul>
<p><img alt="Wikipedia homepage in English" src="https://labcodes.com.br/blog/images/internationalization/wikipedia_english.png">
<em>Wikipedia homepage in English</em></p>
<p><img alt="Wikipedia homepage in Arabic" src="https://labcodes.com.br/blog/images/internationalization/wikipedia_arabic.png">
<em>Wikipedia homepage in Arabic</em></p>
<p>With these adaptations, we can provide a better experience for the customer when using the application.</p>
<h2>How can we do that in Python?</h2>
<h3>GNU gettext</h3>
<p>There are some tools that can help localize your Python application. Starting with the GNU gettext package that is part of the Translation Project<sup id="fnref:3"><a href="#fn:3">3</a></sup>. This package offers:</p>
<ul>
<li>A runtime library that supports the retrieval of translated messages.</li>
<li>A set of conventions about how programs should be written to support message catalogs.</li>
<li>A library supporting the parsing and creation of files containing translated messages.</li>
</ul>
<p>The following code snippet is just a simple Hello World, a <code>app.py</code> file, where we are using the <code>gettext</code> Python module to create a translation object (<code>gettext.translation</code>) for our app domain, specifying a locale directory and the language that we want to translate our strings to. Then, we assign the gettext function to an underscore (a common practice to reduce the overhead of typing <code>gettext</code> for each translatable string) and, finally, we flag the string <code>“Hello World!”</code> to be translated.</p>
<div><pre><span></span><span>import</span> <span>gettext</span>

<span>gettext</span><span>.</span><span>bindtextdomain</span><span>(</span><span>"app"</span><span>,</span> <span>"/locale"</span><span>)</span>
<span>gettext</span><span>.</span><span>textdomain</span><span>(</span><span>"app"</span><span>)</span>
<span>t</span> <span>=</span> <span>gettext</span><span>.</span><span>translation</span><span>(</span><span>"app"</span><span>,</span> <span>localedir</span><span>=</span><span>"locale"</span><span>,</span> <span>languages</span><span>=</span><span>[</span><span>'en_US'</span><span>])</span>
<span>t</span><span>.</span><span>install</span><span>()</span>
<span>_</span> <span>=</span> <span>t</span><span>.</span><span>gettext</span>

<span>greeting</span> <span>=</span> <span>_</span><span>(</span><span>"Hello, world!"</span><span>)</span>
<span>print</span><span>(</span><span>greeting</span><span>)</span>
</pre></div>


<p>After flagging the translatable strings in the code, we can collect them using the GNU <code>xgettext</code> CLI tool. This tool generates a PO file containing all the strings that we have flagged.</p>
<p><code>xgettext -d app app.py</code></p>
<p>The PO file (which stands for Portable Object file) contains a list of entries and here is the basic structure of an entry:</p>
<div><pre><span></span>#  translator-comments
#. extracted-comments
#: reference…
#, flag…
#| msgid previous-untranslated-string
msgid untranslated-string
msgstr translated-string
</pre></div>


<p>We can add comments for translators, some references and flags for the string. Then we have the <strong>entry ID</strong> (<code>msgid</code>), which is the untranslated string flagged in the code and the <strong>entry string</strong> (<code>msgstr</code>) representing the translated version of the string.</p>
<p>When we run <code>xgettext</code> in the command line passing the <code>app.py</code> as input file, this is the PO file that is generated:</p>
<div><pre><span></span><span>"Project-Id-Version: PACKAGE VERSION\n"</span>
<span>"Report-Msgid-Bugs-To: \n"</span>
<span>"POT-Creation-Date: 2019-05-03 13:23-0300\n"</span>
<span>"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"</span>
<span>"Last-Translator: FULL NAME &lt;EMAIL@ADDRESS&gt;\n"</span>
<span>"Language-Team: LANGUAGE &lt;LL@li.org&gt;\n"</span>
<span>"Language: \n"</span>
<span>"MIME-Version: 1.0\n"</span>
<span>"Content-Type: text/plain; charset=UTF-8\n"</span>
<span>"Content-Transfer-Encoding: 8bit\n"</span>

<span>#</span><span>:</span> <span>app</span><span>.</span><span>py</span><span>:</span><span>7</span>
<span>msgid</span> <span>"Hello, world!"</span>
<span>msgstr</span> <span>""</span>
</pre></div>


<p>At the top of the file, we have some metadata about the file, the project and the translation process. Then, we have the untranslated string "Hello, world!" as the <strong>entry ID</strong> and an empty string for the <strong>entry string</strong>. If no translated string is provided for a certain entry, the entry ID will be used in the translation.</p>
<p>Once the PO file is generated, we can start translating our terms to different languages. It is important to notice that the GNU gettext library is going to look for translated PO files in a specific folder path structure (<code>&lt;localedir&gt;/&lt;language_code&gt;/LC_MESSAGES/&lt;domain&gt;.po</code>) and there must be one PO file for each language that you want to support.</p>
<div><pre><span></span>|-- app.py
|-- locale
   |-- en_US
   |   |-- LC_MESSAGES
   |       |-- app.po
   |-- pt_BR
       |-- LC_MESSAGES
       |   |-- app.po
</pre></div>


<p>Here is an example of the same PO file translated to Portuguese:</p>
<div><pre><span></span><span>"Project-Id-Version: PACKAGE VERSION\n"</span>
<span>"Report-Msgid-Bugs-To: \n"</span>
<span>"POT-Creation-Date: 2019-05-03 13:23-0300\n"</span>
<span>"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"</span>
<span>"Last-Translator: FULL NAME &lt;EMAIL@ADDRESS&gt;\n"</span>
<span>"Language-Team: LANGUAGE &lt;LL@li.org&gt;\n"</span>
<span>"Language: \n"</span>
<span>"MIME-Version: 1.0\n"</span>
<span>"Content-Type: text/plain; charset=UTF-8\n"</span>
<span>"Content-Transfer-Encoding: 8bit\n"</span>

<span>#</span><span>:</span> <span>app</span><span>.</span><span>py</span><span>:</span><span>7</span>
<span>msgid</span> <span>"Hello, world!"</span>
<span>msgstr</span> <span>"Olá, mundo!"</span>
</pre></div>


<p>In order to use the translated strings in the code, we need to compile the PO file into MO file using the <code>msgfmt</code> command.</p>
<p><code>msgfmt -o app.mo app.po</code></p>
<p>With the MO file in place, it is possible to change the language of the program to Portuguese in the languages input for the translation function. If we run the following code, the flagged string will get translated to “Olá, mundo!”:</p>
<div><pre><span></span><span>import</span> <span>gettext</span>

<span>gettext</span><span>.</span><span>bindtextdomain</span><span>(</span><span>"app"</span><span>,</span> <span>"/locale"</span><span>)</span>
<span>gettext</span><span>.</span><span>textdomain</span><span>(</span><span>"app"</span><span>)</span>
<span>t</span> <span>=</span> <span>gettext</span><span>.</span><span>translation</span><span>(</span><span>"app"</span><span>,</span> <span>localedir</span><span>=</span><span>"locale"</span><span>,</span> <span>languages</span><span>=</span><span>[</span><span>'pt_BR'</span><span>])</span>
<span>t</span><span>.</span><span>install</span><span>()</span>
<span>_</span> <span>=</span> <span>t</span><span>.</span><span>gettext</span>

<span>greeting</span> <span>=</span> <span>_</span><span>(</span><span>"Hello, world!"</span><span>)</span>
<span>print</span><span>(</span><span>greeting</span><span>)</span>
</pre></div>


<h3>Locale Module</h3>
<p>This module has access to POSIX locale database and is specially useful for handling dates, numbers and currencies format. The following example shows how to use the Locale library:</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>locale</span>

<span>locale</span><span>.</span><span>setlocale</span><span>(</span><span>locale</span><span>.</span><span>LC_ALL</span><span>,</span> <span>locale</span><span>=</span><span>'en_US'</span><span>)</span>
<span>local_conv</span> <span>=</span> <span>locale</span><span>.</span><span>localeconv</span><span>()</span>
<span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>datetime</span><span>.</span><span>now</span><span>()</span>
<span>some_price</span> <span>=</span> <span>1234567.89</span>
<span>formatted_price</span> <span>=</span> <span>locale</span><span>.</span><span>format</span><span>(</span><span>'</span><span>%1.2f</span><span>'</span><span>,</span> <span>some_price</span><span>,</span> <span>grouping</span><span>=</span><span>True</span><span>)</span>
<span>currency_symbol</span> <span>=</span> <span>local_conv</span><span>[</span><span>'currency_symbol'</span><span>]</span>

<span>print</span><span>(</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>'</span><span>%x</span><span>'</span><span>))</span>
<span>print</span><span>(</span><span>f</span><span>'{currency_symbol}{formatted_price}'</span><span>)</span>
</pre></div>


<p>In this example, we are importing the module, changing all locale settings to US English and retrieving the locale conventions. Using the <code>locale.format</code> method, we can format the number without worrying about decimal and thousands separator symbols. Using the <code>%x</code> directive to format the date, it will display day, month and year in the correct order for the locale. From the locale conventions, we are able to get the correct currency symbol.</p>
<p>This is the output of that Python code. We can see that the date is following the format of <code>Month/Day/Year</code>, tthe decimal separator is a dot while the thousands separator is a comma and there is a dollar sign to represent US currency.</p>
<div><pre><span></span>$ python format_example.py
<span>05</span>/03/2019
<span>$1</span>,234,567.89
</pre></div>


<p>Now using the same code, just changing the locale to Portuguese Brazil, we get a different output based on Brazilians conventions for formatting: the date is following <code>Day/Month/Year</code> format, we have comma as the decimal separator, dots as thousands separator and the R$ symbol to represent Brazilian currency Real.</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>locale</span>

<span>locale</span><span>.</span><span>setlocale</span><span>(</span><span>locale</span><span>.</span><span>LC_ALL</span><span>,</span> <span>locale</span><span>=</span><span>'pt_BR'</span><span>)</span>
<span>local_conv</span> <span>=</span> <span>locale</span><span>.</span><span>localeconv</span><span>()</span>
<span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>datetime</span><span>.</span><span>now</span><span>()</span>
<span>some_price</span> <span>=</span> <span>1234567.89</span>
<span>formatted_price</span> <span>=</span> <span>locale</span><span>.</span><span>format</span><span>(</span><span>'</span><span>%1.2f</span><span>'</span><span>,</span> <span>some_price</span><span>,</span> <span>grouping</span><span>=</span><span>True</span><span>)</span>
<span>currency_symbol</span> <span>=</span> <span>local_conv</span><span>[</span><span>'currency_symbol'</span><span>]</span>

<span>print</span><span>(</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>'</span><span>%x</span><span>'</span><span>))</span>
<span>print</span><span>(</span><span>f</span><span>'{currency_symbol}{formatted_price}'</span><span>)</span>
</pre></div>


<div><pre><span></span>$ python format_example.py
<span>03</span>/05/2019
R<span>$1</span>.234.567,89
</pre></div>


<h2>Does it get easier with Django?</h2>
<h3>Translations and Formatting</h3>
<p>Internationalization is enabled by default when you create your Django project. The translation module encapsulates the GNU library and provides the <code>gettext</code> function with translation setup based on the language received in the <strong>Accept-Language</strong> header, that is passed by the browser in the request object. So, all that Python code that we saw before is encapsulated in the django utils translation module so we can jump ahead and just use the gettext function in our view:</p>
<div><pre><span></span><span>from</span> <span>django.http</span> <span>import</span> <span>HttpResponse</span>
<span>from</span> <span>django.utils.translation</span> <span>import</span> <span>gettext</span> <span>as</span> <span>_</span>

<span>def</span> <span>my_view</span><span>(</span><span>request</span><span>):</span>
    <span>greetings</span> <span>=</span> <span>_</span><span>(</span><span>'Hello, World!'</span><span>)</span>
    <span>return</span> <span>HttpResponse</span><span>(</span><span>greetings</span><span>)</span>
</pre></div>


<p>For translations, we can flag translatable strings in both Python and template code (once we load the internationalization tags). The <code>trans</code> template tag translates a single string, while <code>blocktrans</code> tag is able to mark as translatable a block of strings, including variable content.</p>
<div><pre><span></span><span>&lt;</span><span>p</span><span>&gt;</span>{% trans "Hello, World!" %}<span>&lt;/</span><span>p</span><span>&gt;</span>
<span>&lt;</span><span>p</span><span>&gt;</span>{% blocktrans %}This string will have {{ value }} inside.{% endblocktrans %}<span>&lt;/</span><span>p</span><span>&gt;</span>
</pre></div>


<p>Besides the standard <code>gettext</code> function, in Django we can have lazy translations: the flagged string will only be translated when the value is used in a string context, such as in template rendering. This is specially useful for translating <code>help_text</code> and <code>verbose_name</code> attributes in the Django models.</p>
<p>Regarding GNU command line interface, django admin provides equivalent commands for the ones most used in the development process. To …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html">https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html</a></em></p>]]>
            </description>
            <link>https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148141</guid>
            <pubDate>Thu, 13 Aug 2020 20:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research Says Solo Founders Perform Better]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24148113">thread link</a>) | @rmason
<br/>
August 13, 2020 | https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why | <a href="https://web.archive.org/web/*/https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-68erk"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label=""><p><img data-pin-url="https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why" data-pin-media="https://static.wixstatic.com/media/49c34c_add7b504cfd8464abddc1602dcb09c96~mv2.jpg/v1/fit/w_3508,h_1981,al_c,q_80/file.png" src="https://static.wixstatic.com/media/49c34c_add7b504cfd8464abddc1602dcb09c96~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div><p><span>Better to be a Han Solo in startups? Credit: deviantart.com/dzikawa</span></p></div></div></div><p id="viewer-9t57p">A recent <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3107898" target="_blank" rel="noopener"><u>study</u></a> suggests that: </p><blockquote id="viewer-ah7c2">"Solo founders are <!-- -->more than twice as likely to own an ongoing, for-profit venture than two or more founders". </blockquote><p id="viewer-c6nq5">Or to put it in other words, ventures with solo founders are twice as likely to be profitable than ventures with 2 or more founders. See the graph below.</p><div id="viewer-5g984"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why" data-pin-media="https://static.wixstatic.com/media/49c34c_46bd6f501d98445cb0381d51c061589d~mv2.png/v1/fit/w_2560,h_1280,al_c,q_80/file.png" src="https://static.wixstatic.com/media/49c34c_46bd6f501d98445cb0381d51c061589d~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-bd3ie">How can that be true? And what could be the dangers of being a solopreneur that founders should watch out for? Let us explore!</p><h2 id="viewer-674bv">Why solo is better</h2><p id="viewer-bhfs4">As much as it may feel scary to go alone, there are good reasons to consider building a business alone, especially if you are spending a lot of time finding a co-founder.</p><h3 id="viewer-addh7">Reason #1: Speed</h3><p id="viewer-3mptm">As the famous African proverb goes, “If you want to go fast, go alone. If you want to go far, go together.” Solo founders move faster since they don't need to worry about the team alignment on every decision. And being fast can be argued to be the biggest advantage for a startup.</p><h3 id="viewer-d4jnc">Reason #2: Founder disagreements</h3><p id="viewer-bsbd7"><a href="https://www.cbinsights.com/research/startup-failure-reasons-top/#:~:text=Not%20pivoting%20away%20or%20quickly,by%20a%20lack%20of%20progress" target="_blank" rel="noopener"><u>Top 3 reason</u></a><u>s</u> why startups fail is the founder team in-fighting. Sounds wrong to say this, but no co-founders - no problems.</p><h3 id="viewer-8l2gn">Reason #3: Lower costs</h3><p id="viewer-6jfou">It seems like there is no big difference between one person on the team and three, but at the early stage, even small differences matter a lot. Whether you need an office, and how many salaries you need to pay are all crucial questions at the start.</p><h3 id="viewer-6su88">Reason #4: Taking risks</h3><p id="viewer-bg12b">Founding a startup is a big risk. Three people who've already sacrificed quite a bit tend to be more risk-averse and the chances of someone choosing the safer path are higher. </p><h2 id="viewer-f2gim">The dangers of going solo</h2><p id="viewer-fuou5">We will be honest - going solo is not for everyone. Consider the following dangers:</p><h3 id="viewer-3t7ks">Danger #1: Funding</h3><p id="viewer-cdd78">It's the sad truth that due to Y Combinator and Paul Graham's gospel, the Zeitgeist of our times is that being a solo founder means that you just couldn't convince your friends to join and therefore can't be trusted. Solo founders tend to receive considerably less funding, yet it could also play to their advantage, allow them to grow more organically and make fewer stupid mistakes.</p><h3 id="viewer-50pot">Danger #2: Lack of support </h3><p id="viewer-cte29">Loneliness and depression hit entrepreneurs harder and solo founders harder still. Solo founders might also miss on diverse perspectives. I would advise solo founders to get something called a hands-on advisor or joining a supportive community of solo founders like <a href="https://www.growthclub.online/?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_body&amp;utm_campaign=content_promo" target="_blank" rel="noopener"><u>GrowthClub</u></a>. Both of those options are described in <a href="https://www.growthclub.online/post/advice-for-solo-founders?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_body&amp;utm_campaign=content_promo" target="_blank" rel="noopener"><u>my previous article</u></a>.</p><h2 id="viewer-7kknt">In sum  </h2><p id="viewer-9mv3p">Solopreneurs move faster, avoid the drama of teams falling apart, reduce costs by default, and have an easier time taking risks. That being said, they should be aware of fewer funding opportunities and build their own support system.</p><p id="viewer-4an2c">Thanks for sticking till the end! I am a hands-on advisor at<a href="https://www.growthclub.online/?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_footer&amp;utm_campaign=content_promo" target="_blank" rel="noopener"> <!-- -->GrowthClub</a>. GrowthClub is a community of founders with $5K+ MRR where founders exchange growth hacks and build genuine connections in 1-on-1 video calls.</p><p id="viewer-f6iut">I started with GrowthClub as a user. I liked it so much that I ended up helping the founder. Currently, after experiencing a great inflow of founders from our launch on <a href="https://www.producthunt.com/posts/growthclub" target="_blank" rel="noopener"><u>Product Hunt</u></a> and Indie Hackers <a href="https://www.indiehackers.com/post/community-the-new-business-model-for-indie-hackers-01908d3dc3" target="_blank" rel="noopener"><u>featured article</u></a>, we are signing up 30 hand-picked founders to form the core of our platform to actively iterate the product with them.</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148113</guid>
            <pubDate>Thu, 13 Aug 2020 20:12:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comfortable C while Editing with Emacs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148112">thread link</a>) | @daptaq
<br/>
August 13, 2020 | https://zge.us.to/txt/emacs-c.html | <a href="https://web.archive.org/web/*/https://zge.us.to/txt/emacs-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://zge.us.to/txt/emacs-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148112</guid>
            <pubDate>Thu, 13 Aug 2020 20:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In search of the perfect pocket device]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148036">thread link</a>) | @todsacerdoti
<br/>
August 13, 2020 | https://isene.org/2020/08/Nerding.html | <a href="https://web.archive.org/web/*/https://isene.org/2020/08/Nerding.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>In my lock-down geekery, I have been searching for the perfect pocket computer setup.</p>

<p>Having been an <a href="https://youtu.be/czzuz1j364E">HP calculator collector</a> since a couple of decades, I have a passion for pocket computing power with really long battery life.</p>

<p>The <a href="https://isene.org/hp-41/">HP-41</a> is an amazing calculator with months of battery life. But it is still a calculator. I also want real computing power - with the ability to run <a href="https://en.wikipedia.org/wiki/Vim_(text_editor)">VIM</a> for editing text (with a decent keyboard) and as much of other goodies as I can cram into it.</p>

<p><img src="https://isene.org/assets/posts/nerdvana.png" alt=""></p>

<p>I started my quest for the perfect pocket computer with reviving my old <a href="https://en.wikipedia.org/wiki/HP_200LX">HP-200LX</a>. It’s a very early pocket computer running DOS 5.0 - and I have VIM running on it :-) Being a DOS device, it can run <a href="http://mizj.com/">lots of nice programs</a>. Yes, it is slow, but it is cool.</p>

<p>In search for a better keyboard, I got the <a href="http://phonedb.net/index.php?m=device&amp;id=840&amp;c=ericsson_mc218">Ericsson MC218</a> (a <a href="https://en.wikipedia.org/wiki/Psion_Series_5">Psion Series 5</a> pocket computer) up and running, hoping to make it boot Linux. While this is possible, it turns out that the CF card reader on the device was flaky, so I kept searching.</p>

<p>Some forums later, and I stumbled upon an interesting project - the <a href="https://n-o-d-e.net/zeroterminal.html">Zero Terminal</a>. Now we’re talking. A Raspberry PI Zero packed with all sorts of ports and expansion capabilities. But waiting for it? I’m not the patient type…</p>

<p>But wait a minute! I always carry my <a href="https://en.wikipedia.org/wiki/Samsung_Galaxy_S20">Samsung S20 Ultra</a> anyway. Couldn’t it serve all my needs? True, the battery life sucks. But as it is my cell phone, I always have it charged, so that shouldn’t be a problem. And with my <a href="https://www.aliexpress.com/item/33044680958.html?spm=2114.search0303.3.36.3e2f50e4kUuHVD&amp;ws_ab_test=searchweb0_0,searchweb201602_0,searchweb201603_0,ppcSwitch_0&amp;algo_pvid=c05d6fa4-cb6c-4b28-aaa8-9da88e98cd0f&amp;algo_expid=c05d6fa4-cb6c-4b28-aaa8-9da88e98cd0f-5">small, foldable bluetooth keyboard</a>, I have massive computing power with me at all times. An added benefit is that it can easily use a monitor or TV screen via the built-in <i>Smart View</i>.</p>

<p>The real kicker is that it runs VIM in all its galore - even with my <a href="https://isene.org/hyperlist/">HyperList</a> plugin. It runs <a href="https://www.ruby-lang.org/en/">Ruby</a> and my whole <a href="https://isene.org/2018/08/Amar-Tools.html">Amar Tools</a> <a href="https://github.com/isene/Amar-Tools">package</a>. And <a href="https://en.wikipedia.org/wiki/LaTeX">LaTeX</a> and <a href="https://www.ssh.com/ssh/">SSH</a> and <a href="https://weechat.org/">Weechat</a> and… you name it. Lots of terminal/console programs are readily available via <a href="https://termux.com/">Termux</a>.</p>

<p>But that’s not all you can do. With the X Server app <a href="https://play.google.com/store/apps/details?id=x.org.server&amp;hl=en">XSDL</a> and the <a href="https://play.google.com/store/apps/details?id=tech.ula&amp;hl=en">UserLand</a> app, you can in fact install a full Linux distro and fire it up on your Android phone. With the full glory of both terminals and graphical software. Run an <a href="https://i3wm.org/">i3</a> session with <a href="https://wiki.archlinux.org/index.php/Rxvt-unicode">urxvt</a> terminals running <a href="http://zsh.sourceforge.net/">zsh</a>, <a href="https://www.gimp.org/">Gimp</a>, <a href="https://www.libreoffice.org/">LibreOffice</a> and whatnot. Now, that’s Nerdvana!</p>

<p><img src="https://isene.org/assets/posts/userland.png" alt=""></p>

<p>So, from my HP-41, via the HP-200LX, the MC218 and looking at Zero Terminal, I found the answer right here in my pocket. Quite a detour. But ending in bliss :-)</p>

<hr>
<p>Link to this post: <a href="https://isene.org/2020/08/Nerding.html">https://isene.org/2020/08/Nerding.html</a></p>

            </div></div>]]>
            </description>
            <link>https://isene.org/2020/08/Nerding.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148036</guid>
            <pubDate>Thu, 13 Aug 2020 20:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GPT-3 to enrich NPC interactions in MUDs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148003">thread link</a>) | @teebes
<br/>
August 13, 2020 | https://blog.writtenrealms.com/gpt3/ | <a href="https://web.archive.org/web/*/https://blog.writtenrealms.com/gpt3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>How Written Realms is using the latest generation of Artificial Intelligence to animate its fictional worlds.</p><div>
<p>We were fortunate enough to receive an invite to the <a href="https://openai.com/blog/openai-api/">OpenAI private beta</a> a few weeks ago, gaining an interface to their <a href="https://arxiv.org/abs/2005.14165">GPT-3</a> engine. Using AI for mob interactions within <a href="https://writtenrealms.com/">Written Realms</a> had been a long term goal of ours for many years, and we jumped at the opportunity to play with it.</p>
<h2 id="howtheopenaiapiworks">How the OpenAI API works</h2>
<p>The OpenAI API provides a 'completion' endpoint (also available as a Python binding) for interacting with the GPT-3 engine.</p>
<p>Given a text prompt, the API attempts to complete the pattern that you gave it. For example if you give it an input of <code>1 2 4 8</code> and request 1 token back, you will get a response of: <code>16</code>. The API understood the pattern to be a doubling function and gave the next result.</p>
<p>It's not limited to math. If you give as input <code>Barking is to dogs as meowing is to</code>, you will get as a result: <code>cats</code>.</p>
<p>Not only is GPT-3 good at reading comprehension, but it also good at tailoring its output to match the style of the input. Consider the following prompt:</p>
<pre><code>Tom went fishing all afternoon. He comes home to his wife at sunset, who asks him a question.

Question: What did you do today?
Answer:
</code></pre>
<p>The API returns <code>I went fishing.</code> </p>
<p>It is possible to get a more creative answer by providing more information in the prompt and turning up the <code>temperature</code> setting, which gives GPT-3 more of a creative license to make stuff up. For example, if after adding <code>Tom responds enthusiastically, providing many details.</code> to the prompt before the question and turning the temperature to its max value, here's how the API responded: </p>
<pre><code>I went fishing all day, and in the afternoon I fought the biggest fish that I have ever seen before. I just held on for as long as I could, because once I gave up there was no way I was getting the fish back again. I had to pull everything I could, and my catch ended up weighing 3 pounds of flounder and 4 pounds of bluegill.
</code></pre>
<p>Evidently, GPT-3 is quite proficient at making stuff up given the right temperature.</p>
<h2 id="howwereusinggpt3">How we're using GPT-3</h2>
<p>For our first foray into GPT-3, we created a Historian NPC (Non-Player Character) who is able to answer arbitrary questions about Edeus, our flagship world. All of our lore is original and it can be challenging to impart it all to the players at once. An AI able to answer the organic questions of a player in real-time seemed like a perfect use-case.</p>
<p>We already had a feature called 'Reactions' that allows NPCs to respond to something said in their room with predetermined commands. The adjustment made here was to add a <code>gpt</code> flag to the Historian which at reaction time forwards the user's input to OpenAI in order to get the response.</p>
<p>As with the fisherman above, we can use the dialog pattern, and precede it with a certain context, which explains to GPT-3 what the background is for the interactions. In this case, we gave it an excerpt from a fictional history book written by the NPC in question, and then provided a little bit of background about the NPC himself. Here is a sample interaction with him:</p>
<pre><code>You say 'hello there'
Grae the Historian says 'Greetings, traveler.'

You say 'Who are you?'
Grae the Historian says 'I am Historian Grae, a Priest of the Church of Thune.'

You say 'Where are we?'
Grae the Historian says 'You are in Bluefinch, a village in the realm of Saphrin.'

You say 'Is there anything I should be doing?'
Grae the Historian says 'You should be killing orcs.'

You say 'Why? What have the orcs ever done to us?'
Grae the Historian says 'The orcs are evil. They want to destroy us.'

You say 'Okay. Can you tell me more about our origin?'
Grae the Historian says 'Humans were created by Thune, the Allmighty God.'

You say 'Who rules this area?'
Grae the Historian says 'The King of Saphrin, Arctus Kerinin, rules this area.'

You say 'Thanks Grae! You've been very helpful'
Grae the Historian says 'You're welcome.'
</code></pre>
<p>If you want to test this out for yourself, Grae is located 3 north, 1 east of Bluefinch Square in Edeus. We're always tweaking his backstory and various settings so his outputs may (and should!) vary a bit.</p>
<h2 id="theknowledgeexclusionlimitation">The Knowledge Exclusion Limitation</h2>
<p>The main issue we've been running up against is that it's difficult to constrain the AI's knowledge to that of a fictional world. It cannot help knowing things about the real world. For example:</p>
<pre><code>You say 'When was JFK born?'
Grae the Historian says 'John Fitzgerald Kennedy was born on May 29, 1917.'
</code></pre>
<p>Ideally, the historian would not know about anything outside of Edeus. But even though we specify in the prompt's backstory that he only answers questions pertaining to his own world, that distinction is not always understood. It's difficult to exclude knowledge.</p>
<h2 id="futureimprovements">Future Improvements</h2>
<p>We plan to keep iterating and try to make the AI feel as human and authentic as possible. One issue is that currently each interaction with the NPC is its own isolated event. For example:</p>
<pre><code>You say 'What is the name of this village?'
Grae the Historian says 'This village is called Bluefinch.'

You say 'Where did it get its name from?'
Grae the Historian says 'Edeus is named after the two titans that fought in the First Age. Thune and Raeshyk.'
</code></pre>
<p>Clearly the NPC didn't connect that the second question was a follow-up from the first. This is because each time we do a call to OpenAI we append the user's query to the end of the same base prompt, making each a separate interaction. It could be improved upon by including a few of the previous back and forths when generating a new prompt, provided it was the same player.</p>
<p>There's also entirely different ways we could leverage GPT-3. For example, it could be used to generate content like room, character and item descriptions, or even dynamic quests. A text-based platform and a text-based AI share great synergy, and the possible applications of it seem endless to the imaginative.</p></div></div>]]>
            </description>
            <link>https://blog.writtenrealms.com/gpt3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148003</guid>
            <pubDate>Thu, 13 Aug 2020 20:06:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Windows 10 UX deep copy on Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24146508">thread link</a>) | @1337shadow
<br/>
August 13, 2020 | http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w | <a href="https://web.archive.org/web/*/http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="g-page-surround">
                                    

                                            
                <section id="g-top">
                
        
    </section>
                
                                
                
    
                <section id="g-container-9688">
                <div>                    <div>                        

        <div>
             <section id="g-mainbar">
                                        <div>                        

        <div>
             <div>
                                                            <div><div><div itemscope="" itemtype="https://schema.org/Article">
	<meta itemprop="inLanguage" content="pt-BR">
	
		
			
					
		
	
	
		
								<div itemprop="articleBody">
		
<p><a href="https://www.youtube.com/watch?v=gFss_DliNPE" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/desktop_mini.jpg" alt=""></a></p>
<p><span><strong>LINUXFX 10.4.2 WX DESKTOP</strong></span></p>
<p><span><strong>LINUXFX NO TELEGRAM PT-BR :&nbsp;<a href="https://t.me/linuxfxbr">https://t.me/linuxfxbr</a></strong></span></p>
<p><span><strong>LINUXFX NO TELEGRAM EN :&nbsp;<a href="https://t.me/linuxfxen">https://t.me/linuxfxen</a></strong></span></p>

<p><span>O projeto Linuxfx / Windowsfx foi desenvolvido para ajudar usuários do Microsoft© Windows® a migrarem de maneira direta para o Linux, aproveitando toda sua curva de aprendizado. Aproveitar o hardware que não suporta a versão mais nova do&nbsp;Microsoft© Windows® também é uma diretiva do Linuxfx, assim como prover suporte a rede, Active Directory, programas .exe e .msi, navegação segura e proteção contra vírus. Utilizando o Linuxfx / Windowsfx no seu computador, você terá um sistema rápido, que consome pouca memória e é imune a vírus&nbsp;desenvolvido para a plataforma&nbsp;Microsoft© Windows®.</span></p>


<p><span>Linuxfx 10.4 WX Desktop System Core</span></p>
<ul>
<li><span><strong>Tema</strong>: WX Desktop (Windows 10 <a href="https://b00merang.weebly.com/windows-10.html" target="_blank" rel="noopener noreferrer">b00merang theme</a>)</span></li>
<li><span><strong>Gerenciamento de processos de núcleo</strong>: Linuxfx Pro System Pack</span></li>
<li><span><strong>Gerenciador de janelas</strong>: Cinnamon 4.6</span></li>
<li><span><strong>Compatibilidade com rede A.D</strong>: CID, PBIS (beyond trusty)</span></li>
<li><span><strong>Compatibilidade com rede Microsoft®</strong>: SAMBA + Linuxfx Pro Network Tools</span></li>
<li><span><strong>Desktop virtual</strong>: Citrix, Vmware, Rdesktop</span></li>
<li><span><strong>Assistência remota</strong>: Anydesk, Teamviewer</span></li>
<li><span><strong>Compatibilidade com Microsoft® Windows®</strong>: Wine + Linuxfx Pro Cross Specs</span></li>
<li><span><strong>Sistema base</strong>: Ubuntu 20.04 LTS</span></li>
</ul>


<p><span><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><img src="https://dl2.macupdate.com/images/icons256/57903.png?d=1524853176" alt="Resultado de imagem para etcher logo" width="125" height="125"></a></span></p>
<p><span><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><img src="http://resin.io/blog/content/images/2017/02/etcher-logo.jpg" alt="Resultado de imagem para etcher logo" width="424" height="77"></a></span></p>
<p><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><strong><span>UTILIZE O ETCHER PARA GRAVAR O LINUXFX</span><span>&nbsp;</span></strong></a></p>


<p><span><a href="https://sourceforge.net/projects/linuxfxdevil/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/pc.png" alt=""></a></span></p>
<p><span><strong><a href="https://sourceforge.net/projects/linuxfxdevil/" target="_blank" rel="noopener noreferrer">DOWNLOAD X86-64 BITS PC</a></strong></span></p>
<p><span><strong>DUAL CORE + 2GB RAM MIN</strong></span></p>


<p><span><strong><a href="https://sourceforge.net/projects/linuxfxarm/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/rasp.png" alt=""></a></strong></span></p>
<p><span><a href="https://sourceforge.net/projects/linuxfxarm/" target="_blank" rel="noopener noreferrer">DOWNLOAD 32 BITS ARMHF</a></span></p>
<p><span><strong>RASPBERRY PI - 2 - 3 - 4</strong></span></p>


<p><a href="https://sourceforge.net/projects/linuxfxtinker/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/tinker.png" alt=""></a>&nbsp;</p>
<p><span><a href="https://sourceforge.net/projects/linuxfxtinker/" target="_blank" rel="noopener noreferrer">DOWNLOAD 32 BITS ARMHF</a></span></p>
<p><span><strong>ASUS&nbsp;TINKERBOARD</strong></span></p>


<p><a title="Linuxfx DistroWatch.com" href="https://distrowatch.com/table.php?distribution=linuxfx" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/dwbanner.png" alt=""></a></p> 	</div>

	
							</div></div></div>
    
            
    </div>
        </div>
            </div>
            
    </section>
        </div>
            </div>
    </div>
        
    </section>
    
                                
                
                                
                <section id="g-copyright">
                
        
    </section>
                                
                <section id="g-fixedside">
                <div>                                <div>                        

        <div>
             <p><a href="http://www.linuxfx.org/" title="" rel="">
        <img src="http://www.linuxfx.org/templates/rt_kraken/images/logo/logo.png" alt="Linuxfx">
        <span></span>
</a>
            </p>
        </div>
            </div>
                            
                            
            </div>
        
    </section>
            
                        

        </div></div>]]>
            </description>
            <link>http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146508</guid>
            <pubDate>Thu, 13 Aug 2020 18:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handmade Web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146025">thread link</a>) | @cookingoils
<br/>
August 13, 2020 | https://handmade-web.net/fall20/index.html | <a href="https://web.archive.org/web/*/https://handmade-web.net/fall20/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
            “I evoke the term ‘handmade web’ to suggest slowness and smallness as forms of resistance.”<br>
            —— J. R. Carpenter
          </p><p>The hand has become increasingly less present in the web as we know it today. Websites are automated or built from templates, and the knowledge of how to make a website is relegated to a select few. It has only gotten easier to learn and make on the web, but the idea and perceived requirements for a website have become so convoluted and arcane that many avoid the subject. This course seeks to dispel these ideas and will emphasize the hand-quality of websites by developing an understanding of the best practices, language, history, and present context of the web. We will examine the space of the web at large and explore and challenge what a website is and can be with the hopes of reclaiming an important creative space.</p><p>The websites we will make may be small, but their hearts will be big.</p><p>The first half of the class will be technically focused. It will comprise of a series of lessons, readings, workshops, and small projects to develop familiarity and confidence with the language of the web. We will focus on the basic languages of web development: HTML, CSS, and a little Javascript. This class is designed for students with no programming experience at all, but should be friendly to any skill level. The second half will be focused on a larger project website.</p><div>

          
          <p>This class will place heavy emphasis on the hand, craft, and care of your design and code. We will learn how to borrow and learn from others’ code, but we will strive to understand how to code it ourselves. This class will question much of what is commonly understood about the web and technology in general.</p>
          <ul>
            <li>Is tech always the answer? (“There’s an app for that…”)</li>
            <li>Why put something on the web?</li>
            <li>How can we think about accessibility, legibility, efficiency, and speed on the web?</li>
          </ul>

          <hr>

          
          <p>The first goal of this class is to demystify and remove the barrier for entry into web development and programming. Any and all questions are welcome. I will not know every answer, but we can work together to find one (and there are always many when it comes to programming). Learning how to search is the programmer’s greatest tool.</p>
          <p>By the end of the class you will:</p>
            <ul>
              <li>Have a working knowledge of HTML, CSS, and basic Javascript</li>
              <li>Understand the design principles particular to the web and dynamic media</li>
              <li>Have a basic understanding of web publishing</li>
              <li>Have an understanding of the history and present context of web</li>
              
            </ul>

          <hr>

          
          <p>Early in the semester we will set up individual class websites to house all products of this class (projects, writing, anything else…). We will host them using Github Pages and purchase a domain name to attach to it. You can design and organize this however you like, so long all content is accessible and easily found——I will be grading from this!</p>

          <hr>

          
          <p>For assigned readings I will ask you to respond to the reading with a rough written/sketched website concept (or, if you want, a coded sketch of the website) that reacts to the concepts and topics of the reading. Then, upload this response to your class site. Use this as an opportunity to catalogue some ideas for future web projects (either in this class or beyond!).</p>
          <p>There will be some time for reading discussions, but class time will largely be reserved for work, review, and activities. However, these readings will help facilitate a common understanding about the history and present context of the web. Ideally, they will also serve as inspiration for you (as they have been for me!).</p>
          <p>For each week that we have a reading for, only choose 1 to respond to. For example: if there are 3 assigned readings in a week, only respond to one of those.</p>
          <p>More details can be found in the <a href="https://handmade-web.net/fall20/projects/reading.html">project page</a>.</p>

          <hr>

          
          <p>During the first half of the class we will work on a series of smaller projects to practice and experiment with designing for the web:</p>
            <ol>
              <li><a href="https://handmade-web.net/fall20/projects/article.html">Article</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/screensaver.html">Screensaver</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/secret.html">Secret</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/aura.html">Aura</a></li>
            </ol>
          <p>Details for each project will be outlined on the <a href="https://handmade-web.net/fall20/projects/index.html">Projects</a> page.</p>

          <hr>

          
          <p>The final project will take up the last half of the class. It can be anything you like: a project you’ve had in mind for some time; an extension of your practice or an even larger project outside of this class. What is important is the craft, care, and concept of the project. It will be graded on these qualities. It should be unique, personal, and a world of its own.</p>

          <hr>

          
          <p>For each major project there will be an informal presentation and feedback session. As much of this class is focused on technical introduction and skill-building, the finished projects will likely still be works in progress (the web is always under construction). Treat these sessions as opportunities to ask technical or conceptual questions to push your projects further!</p>
          <p>Beyond these review sessions I would encourage everyone to regularly share work and code inside and out of class!</p>

          <hr>

          
          <p>
            40% —— Participation<br>
            40% —— Process<br>
            20% —— Execution
          </p>

          <hr>

          
          <p>This class will require a computer, a text-editor (I recommend <a href="https://atom.io/">Atom</a>), and a browser (<a href="https://www.google.com/chrome/">Chrome</a>). I would also suggest a sketchbook for much encouraged off-screen thinking, note-taking, sketching, and journaling.</p>

          <p>More details can be found in the <a href="https://handmade-web.net/fall20/library.html">Library</a>.</p>

          <hr>

          
          <p>This class will take place entirely online, with some flexibility on potentially meeting in person for individual meetings. Unless stated otherwise, we will regularly meet (synchronously) during the scheduled class times using Zoom.</p>
          <p>You will also have access to the scheduled class space in Pollak Room 317 if you want to use that space during class time, though we will still all collectively meet online through Zoom. One thing to note is that departmental policy, at the time, only allows 10 students in a classroom at a time and only during the scheduled class time. Please make sure to prioritize your own safety and the safety of others when using public spaces!</p>
          <p>We can consider this a feature rather than a hinderance for learning web design as we will inhabit and communicate within the environment that we will be making for!</p>

          <hr>

          
          <p>As this class will take place online, we will be using a <a href="https://discord.com/" target="_blank">Discord</a> server to centralize communication and announcements for the class. The Discord will also serve as a space for feedback and comments during feedback sessions. If there are any updates/changes to the class I will announce them on the Discord, so be sure to check often.</p>

          <hr>

          
          <p>The standard VCU attendance policy states that student absences during the semester are not expected to exceed the number of times the class meets in one week (2). This semester, because we are facing unprecedented circumstances, we will be following a revised policy that addresses larger issues of expected engagement in the course, articulated below. Consistent engagement is a vital component of successful completion of the course objectives.</p>
          <p>The progression of this course requires all participants to be present and actively engaged in class, both during synchronous on-screen meetings, in-person, and with asynchronous activities. Consistency of engagement is vital for a successful completion of the course objectives. Each of us carries different circumstances and capacities; we are accountable for our own agency. This is always true, but especially crucial now.</p>
          <p>If at any point during the semester you are unable to be present, communicate this with me as soon as you can. While presence in class is important, my primary concerns with this class are your wellbeing and an emphasis on not applying unnecessary pressure in an already difficult period. Please remember to prioritize your mental and physical health over school.</p>

          <hr>

          
          <p>The University requires all students and faculty to be aware of policies outlining expectations, requirements and student services related to  academic life. Please visit the following link and review these at the start of each semester: <a target="_blank" href="https://go.vcu.edu/syllabus">go.vcu.edu/syllabus</a>
          </p>

          <hr>

          
          <p>For information regarding institutional adjustments, policies, and safety precautions during COVID-19 please consult the web page for <a target="_blank" href="https://together.vcu.edu/students/">One VCU: Responsible Together</a>.
          </p>

          <hr>

          
          <p>This syllabus and class’s foundation has a number of sources to thank</p>
          <ul>
            <li><a href="http://laurelschwulst.com/">Laurel Schwulst</a> —— whose published syllabi and class portals served as my own unbidden introduction to web design. Much of the pacing and tone of this class is modeled after her approach.</li>
            <li><a href="http://mindyseu.com/">Mindy Seu</a> —— whose classes and workshops have helped expand my thought around digital pedagogy.</li>
            <li>Roy McKelvey —— whose generously provided syllabus has served as the organizational structure of this class.</li>
          </ul>

          <hr>
        </div></div>]]>
            </description>
            <link>https://handmade-web.net/fall20/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146025</guid>
            <pubDate>Thu, 13 Aug 2020 17:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jira Is a Microcosm of What’s Broken in Software Development]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 168 (<a href="https://news.ycombinator.com/item?id=24145665">thread link</a>) | @davetwichell
<br/>
August 13, 2020 | https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>This blog is not about how project management tools are too complex and over-engineered with features dev teams don’t need.</p>



<p>Those complaints are well articulated by others like Justin James, Chief Architect at Cloud Development Resources.</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p><em>“Jira has *never once* made my life as a developer easier or better… It’s overly complicated and the workflow is painful.”&nbsp;</em></p>



<p>Justin goes on to say…&nbsp;</p>



<p><em>“Jira is Word when it had the toolbar filled with tiny little icons for formatting only paralegals or scientists or some other specialized author needed. It does *all this stuff* and none of it is easy or makes sense…”&nbsp;</em></p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>Most popular project management tools are highly configurable which can be a plus and a minus depending on how your company has it set up. </p>



<p>So if project tools have so much flexibility, why do so many organizations configure them in a way that causes their dev teams to complain? </p>







<h4><strong>Project management tools are not perfect but they’re not the problem. The root cause of most complaints devs have with project tools are rooted in bad culture, bad management or bad process. </strong></h4>



<p>Let’s examine 4 of the most common complaints I’ve heard about project management tools from software development teams. </p>







<h3>1. “<strong>Project tools are made with PMs in mind, not dev teams</strong>“</h3>



<p>Justin said <em>“I wish Atlassian would sit down with real-world developers and design this product the way we need it to work.”&nbsp;</em></p>



<p>I’ve heard this complaint from a lot of devs. “Project tools were made with project managers and product managers in mind. Not dev teams.” It is true. Project and product managers (collectively referred to as PMs going forward) are the usually primary buyers and owners of project management systems. Not engineers.&nbsp;</p>



<p>I’ve also heard “the development process is fluid, real-time, and doesn’t always follow a linear path. Project tools force you into a workflow that does not match that reality.” </p>



<p>So why do companies use a tool that works for a few PMs and business leaders when some engineers dislike it so much?&nbsp;</p>



<p><strong>The real issue: Executives force top-down decision making on dev teams</strong></p>



<p>Some companies embrace a mindset of decisions being made by a few people “at the top”. In their world, the planning process is king. The creating process is an afterthought.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>The current software delivery process revolves around pushing decisions down to dev teams and forcing engineers to push status updates back up. This system ensures executives are the only ones who have context and can see the bigger picture while engineers do all of the work.&nbsp;</p>



<p>This is backwards. It holds us back from building the best product and slows us down from delivering faster.&nbsp;</p>



<figure><blockquote><p>Join our mission to end useless status meetings.</p><p><a href="https://linearb.io/status-updates-on/" target="_blank" rel="noreferrer noopener">Click here for access</a>&nbsp;to the dev team dashboard of the future powered by Git data.</p></blockquote></figure>







<h3>2. “<strong>Project tools are plan-first tools, not a develop-first tool</strong>s”</h3>



<p>It makes sense. PM’s, who own Jira, spend a lot of time on ideas, strategy, prioritization, requirements gathering, and preparing for the future. They want a tool that helps them succeed in those areas. Once the iteration starts, PMs shift from being planners to being status communicators. Jira is designed this way. It’s pretty good when you’re in the planning phase and it works well if you’re the PM receiving the status update.</p>



<p>But when you’re in the development phase, it’s not as well suited to dev team tasks. If you’re the engineer who has to constantly manually update the status, it’s annoying. </p>



<p>I see the merit behind this argument. Dev teams live elsewhere like in Git and Slack.&nbsp;Stopping to login in to another system throughout the day is not ideal. </p>



<p>What PMs do is really important – being the voice of the customer, planning, prioritizing and communicating with the rest of the business.  They need tools for this. </p>



<p>I also think dev teams need tools that reflect the fluidity of the development process. It’s sort of like the famous Mike Tyson quote… <em>“Everybody has a plan until they get punched in the mouth.”</em> Once development starts, a million micro-decisions are being made every hour and things change quickly. Most project tools are not set up for this reality.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>The problem is we’re taking different groups of people who spend their time in different ways and forcing them in to one workflow. 80% of the people involved in software development spend 80% of their time in the development phase. In most companies, fewer people spend less time in the planning phase.&nbsp;</p>



<p>So why are we using a plan-first tool to manage the full development lifecycle?&nbsp;</p>



<p><strong>The real issue: Many execs get product strategy but not product development</strong></p>



<p>Most business leaders think like PMs, not like engineers. Executives understand ideas, strategy, and prioritization. They’re also familiar with the process and key metrics of sales and marketing. They know the vocabulary and speak the language.&nbsp;</p>



<p>They do not understand software development as well. They don’t know the terms. When it comes to the dev team, most just want to know “are we on track to deliver feature XYZ by the deadline?”&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>This is dangerous because it holds them back from understanding our process which holds them back from engaging in intelligent conversations with engineering leaders and teams.&nbsp;</p>



<p>If sales miss their number, the CEO has 100 questions ready to analyze what levers they can pull to right the ship. If the dev team misses a deadline, other than maybe asking “do we need to work more hours?”, all they can do is wait or apply (unhelpful) artificial pressure to finish.&nbsp;</p>



<p>How we work matters. Not just the output.&nbsp;</p>







<h3>3. <strong>“Project tools perpetuate synchronous communication, not asynchronous</strong>” </h3>



<p>Project management tools seems like it should encourage asynchronous communication. But in my experience they do the opposite. </p>



<p>When execs have a meeting with a customer or the sales team, they need information about product delivery timelines and they need it now. They ask the PM and the PM sends you an urgent Slack. Or worse, the PM calls you into a meeting to find out what’s going on. Those interruptions are costly.&nbsp;</p>











<p>Why doesn’t the exec or the PM just look at project board? Because it’s not up to date. Why? Things change so rapidly that, in order for the board to be up to date, engineers would need to constantly manually update tickets. One engineering manager told me recently that even teams he’s worked on that really care about project tool hygiene only capture about 60-70% of their real work activity. Most teams are closer to 50%.&nbsp;</p>



<p>Even if the project board was up to date, it’s still missing context.&nbsp;</p>



<p>Execs and PMs want to know:&nbsp;</p>



<ul><li>When is the bug going to be fixed?&nbsp;</li><li>When is the new feature being delivered?&nbsp;</li><li>What risks could stop us from hitting our date?&nbsp;</li><li>Which features are getting attention right now and which aren’t?&nbsp;</li><li>What % of the team is invested in features versus bugs versus non-functional?&nbsp;</li></ul>



<p>There’s nothing on the project board that answers those questions. So they pull you away from deep focus mode to ask you. And it takes you a while to get your focus back. Which slows you down from delivering the thing they want most of all – more features.&nbsp;</p>



<p><strong>The real issue: Companies run on a “manager’s schedule” not a “maker’s schedule”&nbsp;&nbsp;</strong></p>



<p>Paul Graham, computer programmer and co-founder of Y Combinator, explains the disconnect between the way developers and executives get work done in his 2009 essay <em>Maker’s Schedule, Manager’s Schedule</em>.&nbsp;</p>



<p>Here’s a summary:&nbsp;</p>



<ul><li>Bosses (managers) get stuff done through meetings – changing tasks every 60 minutes.</li><li>Developers (makers) and other creators need 3-4 hour blocks of time to get work done.</li><li>Each way of working is perfectly fine by itself but problems arise when the two collide.</li><li>For a maker, a single meeting at the wrong time can disrupt their entire day of work.</li><li>Most powerful people are on a manager schedule and they directly or indirectly force the makers in their company, like software engineers, to revolve around the way they work.&nbsp;</li></ul>







<p>I couldn’t agree more with Paul. The lack of understanding some execs have for the software development process, leads to a lack of empathy for software developers. Companies subject their engineers to the manager’s schedule which disrupts the flow of development.&nbsp;</p>



<p>When engineers point out they could ship more features faster if there were fewer meetings, business leaders hear that as a complaint versus what it really is, a cry for help.&nbsp;</p>







<h3>4. “Project tools <strong>create separation between engineers and PMs</strong>“</h3>



<p>Some devs describe their interactions with their PM in a way that reminds me of <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=Fy3rjQGc6lA&amp;feature=youtu.be" target="_blank">Peter from Office Space</a> when his boss asks him for the new cover sheet on the TPS report.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>In the real world, most devs I know really value their PMs. Great PMs allow engineers to do great work. I’ve worked with some awesome ones. </p>



<p>But the <a rel="noreferrer noopener" href="https://linearb.io/blog/vp-engineering-vp-product-how-to-keep-a-united-front/" target="_blank">PM + engineer relationship is hard to get right</a>. Having additional tension built-in makes it even harder.&nbsp;</p>



<p>It’s just not engineers that don’t like having to share status updates all day. PMs don’t want to bug us either! They feel like babysitters. Imagine what they could be doing instead… talking to customers, writing high-quality user stories… or actually spending their time with us on something useful like brainstorming ideas or sharing customer feedback. </p>



<p><strong>The real issue: Some companies are lacking empathy and understanding between different departments. </strong></p>



<p>I’m lucky to work at a company where our CEO (Ori Keren) and our COO (me) are software engineers. We ensure everyone in the company understands the development process which helps maintain tight alignment between our dev, marketing, customer success, and sales teams.&nbsp;</p>



<p>I think more start-ups should be led by programmers and more big companies should promote their CTOs to CEO.&nbsp;</p>



<p>In the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/">https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145665</guid>
            <pubDate>Thu, 13 Aug 2020 17:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTTP – It's Simpler Than You Think. It's More Complex Than You Think]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145502">thread link</a>) | @Crzymary15
<br/>
August 13, 2020 | http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/ | <a href="https://web.archive.org/web/*/http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <article>
                    <header>
                        
                        <span>
                            
                                Posted in
                                
                                    <a href="http://bluegraybox.com/blog//categories/networking">networking</a>
                                
                            

                            
                        </span>
                         - 
                        <time>Friday, August 29, 2014</time>
                    </header>
                    <section>
                        

<p>I’ve been doing web development for a pretty long time, but just over the last few years I’ve come to really appreciate the fundamentals of HTTP, what’s going on under the hood when I’m building web applications. There are two sides of this. The first is that HTTP is in one sense a very simple protocol. It’s just little text messages going back and forth between your browser and the web server. Whether I’m using Node or Django or some huge WSDL-driven Java XML-Beans monstrosity, what it’s doing isn’t rocket science; it’s just taking care of a bunch of tedious, nit-picky bookkeeping that I don’t want to be bothered with. If I really wanted to, I could just type the messages myself (and we’ll get to that in a minute).</p>

<p>The practical upside of that is that you can use really simple tools to debug big, hairy, complex web applications. A few years ago, I was working in one of those Big Web Services systems with WSDL files and auto-generated Java code and layers and layers of middleware. We’d get some kind of error at the front end, and it’d be really hard to tell which piece had broken. So I ended up writing a bunch of really simple shell scripts to test the web services in isolation. I’d spackle together something using <code>curl</code>, <code>grep</code>, and <code>sed</code> that built up and picked apart the messages as text, without dragging in all that mess of Java code.</p>

<p>The flip side is that HTTP is actually a richer protocol than I’d realized. There’s a lot I didn’t know about it until I started building RESTful web services and trying to understand the “right” way to do it. There’s all this stuff you can do with status codes and headers that I’d been re-implementing at the application level.</p>

<p>To take a recent example, I’ve been working on a web service that talks to other web services. Someone would make a call to us, we’d call the back-end services, they’d time out or barf up some sort of error, and we’d pass back a 500 error to our client. They’d see it and email us asking what was wrong with our service. It’d be nice to let them know it’s not our fault and that they should pester the back-end systems people instead. We could send back a message body that says something like, “Back-end systems failure. Original error message follows,” but it turns out we can say that just by returning a different status code. Not only is there a 502 status code, which means that a back-end system failed, but there’s also a 504, which means that we timed out trying to contact it. That tells our client that they can try again in a little while and the request might go through.</p>

<p>Ok, enough talking. Now code.</p>

<h2 id="goin-all-mechanical-turk-on-this">Goin’ all Mechanical Turk on this</h2>

<p>To illustrate the first point, that this is all just text, I’m going to play human web server, using <code>netcat</code>. If you’re not familiar with it, it’s a standard unix utility that just opens a network connection. Anything you type gets sent along it; anything that comes back gets printed out on your screen. I open up a terminal and type:</p>

<pre><code>nc -l 3333
</code></pre>

<p>That starts up <code>netcat</code> listening on port 3333. Then I switch to my browser and tell it to go to <code>http://localhost:3333/</code>. The “page loading” indicator starts spinning. In the <code>netcat</code> terminal, I see:</p>

<pre><code>GET / HTTP/1.1
Host: localhost:3333
Connection: keep-alive
Cache-Control: max-age=0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
User-Agent: Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36
Accept-Encoding: gzip,deflate,sdch
Accept-Language: en-US,en;q=0.8
</code></pre>

<p>That’s Chrome telling me it wants the root resource (<code>/</code>, which Apache or whatever would normally interpret as <code>index.html</code>). It’s also telling me a lot about what kind of response it can handle. I’m going to ignore all that for now and just type:</p>

<pre><code>HTTP/1.1 200 OK 
Content-type: text/plain
Content-length: 7

Hello!
</code></pre>

<p>Pretty straightforward. The content length is 7 because it includes the return character after “Hello!” Here’s what we see in Chrome:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/hws-1.png" alt="" title="Chrome window with plain text &quot;Hello!&quot;"></p>

<p>Switch back to the browser and go to <code>http://localhost:3333/index.html</code>. In the <code>netcat</code> terminal, we get a request that’s much the same as before, except the first line is:</p>

<pre><code>GET /index.html HTTP/1.1
</code></pre>

<p>Since they asked for HTML, I’ll give them HTML. I type:</p>

<pre><code>HTTP/1.1 200 OK
Content-type: text/html
Content-length: 16

&lt;h1&gt;Hello!&lt;/h1&gt;
</code></pre>

<p>And in Chrome we see:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/hws-2.png" alt="" title="Chrome window with HTML H1 header &quot;Hello!&quot;"></p>

<p>So at some fundamental level, that’s all a web application is. It’s a program that listens for a connection, gets little text messages, interprets them, and sends back responses. How simple can we make that?</p>

<h2 id="restful-web-services-in-bash">RESTful Web Services in Bash</h2>

<p>How about this?</p>

<pre><code>#!/bin/bash

echo "Content-type:text/plain"
echo 
uptime
</code></pre>

<p><code>uptime</code> is a standard unix utility that reports how long the computer has been running and what the 1, 5, and 15 minute system load averages are. That’s marginally useful - I’ve actually used a script much like this for basic server monitoring. Put it in a file, make it executable, run it from the command line, and it’ll spit out something like:</p>

<pre><code>Content-type:text/plain

 21:29:32 up 9 days, 15:17,  5 users,  load average: 0.05, 0.10, 0.18
</code></pre>

<p>From here, if you want to follow along, you’ll need to have Apache set up and configured to let you run CGI scripts in the directory you’re working in. (That’s a whole tutorial on its own, but here’s some <a href="http://www.cgi101.com/book/connect/mac.html">instructions for Mac OS X</a>. Otherwise, Google for “apache enable cgi” and your operating system.)</p>

<p>On my machine, this script is saved as <code>public_html/api/v1/load/index.cgi</code>. That lets me access it as <code>http://localhost/~colin/api/v1/load/</code>, as we can see in Chrome:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/v1-load.png" alt="" title="Chrome showing uptime report"></p>

<p>We can also use <code>netcat</code> in place of Chrome. Instead of listening on a port, we open a connection to the web server’s port:</p>

<pre><code>$ nc -c localhost 80
</code></pre>

<p>Then I type:</p>

<pre><code>GET /~colin/api/v1/load/ HTTP/1.1
Host: localhost
</code></pre>

<p>And I get this back from Apache:</p>

<pre><code>HTTP/1.1 200 OK
Date: Wed, 27 Aug 2014 01:14:11 GMT
Server: Apache/2.4.7 (Ubuntu)
Vary: Accept-Encoding
Transfer-Encoding: chunked
Content-Type: text/plain

46
 21:14:19 up 9 days, 15:01,  5 users,  load average: 0.08, 0.18, 0.28

0
</code></pre>

<p>You can see that Apache includes a bunch of header fields that I didn’t bother to when I was playing web server. (I’ll trim most of these out of later examples to cut down on the clutter.) The more interesting thing is that it doesn’t have a <code>Content-length</code> header. What it has instead is <code>Transfer-Encoding: chunked</code>. That says that its content will be in chunks, prefixed by their size (in hexadecimal). 46 hex is 70, which is the length of the next line (again, counting the return character at the end). The ‘0’ for the next chunk says, “that’s all, folks!”</p>

<p>We can make this a little easier on ourselves by using <code>curl</code> instead of <code>netcat</code>. It’s a somewhat more custom tool for making HTTP requests. We can just run <code>curl -si http://localhost/~colin/api/v1/load/</code> from the command line, and get back:</p>

<pre><code>HTTP/1.1 200 OK
Transfer-Encoding: chunked
Content-Type: text/plain

 22:05:42 up 9 days, 15:53,  5 users,  load average: 0.14, 0.13, 0.19
</code></pre>

<p>That’s the same as what <code>netcat</code> gave us (minus the header clutter), but notice that it combined the chunked response for us. Even at this level, some of the details are being hidden.</p>

<h2 id="status-seeking">Status Seeking</h2>

<p>Let’s take this a step further. The <a href="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/v1/status/index.cgi">status script</a> gets a status message (“GREEN”, “YELLOW”, or “RED”) from a file, and prints it out like so:</p>

<pre><code>$ curl -si http://localhost/~colin/api/v1/status/
HTTP/1.1 200 OK
Content-Length: 4
Content-Type: text/plain

RED
</code></pre>

<p>It also lets us set a new status like so:</p>

<pre><code>$ curl -si -X PUT -d GREEN http://localhost/~colin/api/v1/status/
HTTP/1.1 204 No Content
Content-Length: 0
Content-Type: text/plain
</code></pre>

<p>Note that we used the same URL, but changed the HTTP method to <code>PUT</code> (instead of the default <code>GET</code> - don’t ask me why that’s the <code>-X</code> option) and specified “GREEN” as the data (<code>-d</code>) to be sent along with the request. We get back an exciting new response code: 204! Since we’re telling not asking, it doesn’t make much sense for the server to send anything back. The 204 status just says, “That thing you were doing? It worked.” No reason to have a message body saying “Success!” when the code already tells you that. I’ve definitely been guilty of reinventing that wheel before I ran across this.</p>

<p>What if we try to send a bad status, like ‘BLUE’?</p>

<pre><code>$ curl -si -X PUT -d BLUE http://localhost/~colin/api/v1/status/
HTTP/1.1 400 Bad Request
Content-Type: text/plain

Invalid status code
</code></pre>

<p>400 is the “your mistake” error code, which is pretty generic, so we include a descriptive message in the response body. Since it’s a user error, it’s reasonable to just have a human-readable message.</p>

<p>If you look at the script, you’ll see references to environment variables like <code>$REQUEST_METHOD</code>. That’s how Apache makes information about the request avaliable to the script (as part of the CGI standard). In case you want to see all of them, I’ve added an <a href="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/env/index.cgi">env script</a>, which dumps them all out, plus the content. You can hit it with Chrome or <code>curl</code>, or even <code>netcat</code>. See what’s different between them.</p>

<h2 id="api-documentation">API Documentation</h2>

<p>Ok, great! Now we have two simple yet useful web services. But they’re not so simple that they don’t need any documentation, so let’s add some. We could have some sort of parallel hierarchy for documentation, like <code>/api/docs/v1/load/</code>, etc., but that’s kinda clunky. Instead, let’s rework our services so they give you data when you ask for data, and text when you ask for text. For that, we take advantage of the <code>Accept</code> header. Take a …</p></section></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/">http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/</a></em></p>]]>
            </description>
            <link>http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145502</guid>
            <pubDate>Thu, 13 Aug 2020 16:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Llama Logs – Architecture Diagrams from Your Logs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145223">thread link</a>) | @bakenator
<br/>
August 13, 2020 | https://llamalogs.com/docs/what | <a href="https://web.archive.org/web/*/https://llamalogs.com/docs/what">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <p>Overview</p>
    <div>

        <p>Llama Logs is a brand new tool that turns distributed logs into a <b>real time interactive graph</b>.</p>
        <p>Llama Logs was created to help bring clarity to complex cloud architectures.</p>
        

        <p><img height="auto" width="600px" src="https://llamalogs.com/images/doc-examples/complexArch.gif"></p><p>With Llama Logs, <b>never again</b> will you need to:</p>
        <ul>
            <li>Create and update architecture diagrams by hand.</li>
            <li>Install agents onto your machines.</li>
            <li>Hunt down erors through mulitple machines and log files.</li>
            <li>Struggle to teach new team members your architecture.</li>
            <li>Limit your analytics to the machine level.</li>
        </ul> 

        <p>With <b>only a few log lines</b> in your code base, </p>
        <p><img height="auto" width="600px" src="https://llamalogs.com/images/codeScreenshot.png"></p><p>Llama Logs will instantly create a live visualization of the activity within your system. </p>
        
        <p>Llama Logs is <b>built for developers</b>, so the possibilities are endless!</p>
    </div>


    
    <p>The Llama Logs Graph</p>
    <div>
        <p>The graph is where all of the events from a system are visualized automatically by Llama Logs.</p>
        <p>Below is an example of a Llama Logs graph for a Cloud Architecture with Multiple Cloud Functions and a Database.</p>
        <p>Each one of the circles moving between components represents logged events occurring between those two components.</p>
        
        <p><img src="https://llamalogs.com/images/LlamaStartingDemo.gif"></p><p>Instantly we can see the structure and activity of the entire architecture in real time!</p>
        <p>The graph even shows errors in red that are occuring during the response from one of the modules in the first Cloud Function.</p>

        

        <p>See more examples of Llama Logs system visualizations on our <a href="https://llamalogs.com/docs/examples">examples page</a>.</p>
    </div>
    
    
    <p>Benefits</p>
    <div>
        <p>Llama Logs has tremendous benefits over other types of analytics:</p>
        <ul>
            <li>Aggregates distributed data into a single easy to understand graph.</li>
            <li>Seamlessly bridges the gap between application and infrastructure data layers.</li>
            <li>Handles millions of events per component with ease.</li>
            <li>Allows <b>You</b> to creatively define how your data will be visualized.</li>
        </ul>
    </div>


    
    
    <p>Supported Languages</p>
    
    
    
    <p>Demo</p>
    <div>
        <p>You are only 2 clicks away having a live Llama Logs graph to experiment with.</p>
        <p><a href="https://llamalogs.com/docs/demo" target="_blank">Start The Demo</a>
    </p></div>

    


    <p>Start Using Llama Logs</p>
    

    

    <p>More Info</p>
    

    </div></div>]]>
            </description>
            <link>https://llamalogs.com/docs/what</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145223</guid>
            <pubDate>Thu, 13 Aug 2020 16:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Architecture of Consoles – Nintendo DS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24145124">thread link</a>) | @bobbybabylon
<br/>
August 13, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145124</guid>
            <pubDate>Thu, 13 Aug 2020 16:27:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q&A: How Eventbrite prioritizes developer productivity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144790">thread link</a>) | @kklin
<br/>
August 13, 2020 | https://kelda.io/blog/eventbrite-interview/ | <a href="https://web.archive.org/web/*/https://kelda.io/blog/eventbrite-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><picture id="hero-thumbnail">
<source data-srcset="https://kelda.io/img/blog/interview%20microphone.webp" type="image/webp"></picture><p><h2>Published on Aug 11, 2020</h2></p></section><p>Deciding when to invest in developer productivity improvements is hard. If you’re on the ops side of things, you’re usually concerned about production and releases. If you’re a developer, you’re concerned about getting new features out as quickly as possible.</p><p>Usually, teams make development productivity improvements in two situations. Either the fix is so small that you can just do it in addition to your other work, or development is so painful that making changes has ground to a halt.</p><p>However, there’s still a large murky middle ground: how do you decide that it’s worth investing in a <strong>large change</strong> to your development workflow <strong>before development has ground to a halt?</strong></p><p><a href="https://medium.com/@remy.dewolf">Remy DeWolf</a> spent three years making these sorts of decisions as a <strong>principal engineer on the DevTools team at Eventbrite</strong>. He was part of the decision to build <code>yak</code>, which moved Eventbrite’s development environment into the cloud. This was a highly calculated decision since it cost a few EC2 instances per engineer and <code>yak</code> was built from scratch.</p><p>In this first post, we’ll dig into how Remy made this tough decision, and got buy-in from the rest of the company. In our next post, we’ll get into the nitty-gritty on how their remote development environment works, and what it’s been like for developers.</p><h2 id="how-is-the-eventbrite-application-architected">How is the Eventbrite application architected?</h2><p>This is a common story that you will find in a lot of startups. The founding engineers built a monolith and the strategy was to build features fast and capture the market. It was a very successful approach.</p><p>As the company grew over time, having a large team working on the monolith became challenging. And after a certain size, it was also harder to keep scaling the monolith vertically.</p><p>Over time, some of the monolith was migrated over to microservices. New services are generally containerized, and the monolith is containerized in development but not in production.</p><h2 id="whats-your-development-environment-setup-now">What’s your development environment setup now?</h2><p>Every engineer runs <strong>~50 containers</strong> which corresponds to the monolith, the microservices, the data stores (MySQL, Redis, Kafka…) and various tools (logging, monitoring).</p><p>Developers use <code>yak</code> (which we built internally) to deploy and manage their remote containers.</p><p>We use AWS EKS for the Kubernetes clusters, in which every developer has their own namespace. We have hundreds of developers and many EKS clusters.</p><p><code>yak</code> is very similar to <a href="https://kelda.io/blimp">blimp</a> since it enables the engineers to manage their remote containers without exposing them to the complexity of Kubernetes.</p><h2 id="how-did-you-decide-it-was-time-to-build-yak">How did you decide it was time to build yak?</h2><p>Before <code>yak</code>, each developer ran their development environment locally on their laptop. However, the development environment became so big that it slowed down developer laptops.</p><p>The main issue was that you might not realize that this was an issue because it was creeping one service at a time.</p><p>Once we added instrumentalization to our tools, we started to understand the scale of the problems. Moving to the cloud is expensive but when we were able to put it side by side with the wasted engineering time, the decision was easy for us.</p><p>Another goal of <code>yak</code> was to make Kubernetes easy for developers. We kept it as minimal as possible and the configuration files are plain Kubernetes manifest files. The intent was to feed developer curiosity so they learn more about Kubernetes over time.</p><h2 id="what-areas-do-you-recommend-tracking-regarding-developer-productivity">What areas do you recommend tracking regarding developer productivity?</h2><p>Whenever possible, align the developer productivity goals with the business. Every DevTool team should understand how they contribute to the company goals and vice versa. If this is unclear, I would start with that.</p><p>Next, make sure that developer productivity is part of the plan, not an afterthought. For example, some engineering teams move to microservices and only track the number of services and the uptime in production. These are great metrics, but they’re incomplete. They will generate inconsistency and the developer experience will suffer over time.</p><p>In terms of which metrics to pick, there is no general recommendation. It’s important to understand how developers work, understand how frequently they perform critical tasks, and instrument the tools that they use. With this data, you will be able to identify the most important areas to invest and track the progress over time.</p><p>I would also recommend having a metric about mean time to recovery (MTTR). If a developer is completely stuck, how would you bring them back to a clean state so they can resume their work? For this one, if you run the developer environment locally, you will have many different combinations of OS/tools/versions resulting in many different issues. If you are on the cloud and use a generic solution (e.g. Docker + Kubernetes), this problem will be much easier to solve.</p><h2 id="how-did-you-collect-feedback-at-eventbrite">How did you collect feedback at Eventbrite?</h2><p>We had many channels:</p><ul><li>Instrumentation into the tools. Every time a developer would build, run, or deploy docker images we would send metrics. Similarly, every CI job would do the same. Then we would generate some dashboards for the metrics to track and measure the progress over time. If you are using a tool like Sumologic or Datadog, it’s very easy to send custom metrics and build dashboards.</li><li>Quarterly engagement surveys.</li><li>Demos: invite other engineers to show them the progress and engage with them.</li><li>New hires: these new employees bring a fresh perspective and they are not afraid to ask questions and challenge the status quo.</li><li>Networking: build relationships with other developers (coffee breaks, office visits, lunches, etc..)</li></ul><h2 id="can-you-give-some-examples-of-developer-productivity-okrs">Can you give some examples of developer productivity OKRs?</h2><ol><li><p><strong>Time to start the developer environment is under x min</strong></p><p>This time is usually wasted time, so it’s important to track it and improve it. If the dev stack is unreliable or slow, it would be captured in this OKR.</p></li><li><p><strong>Engagement is over x%</strong></p><p>If you send an engagement survey every quarter, you can have an OKR to make sure the trend is upward. Seeing a drop would mean that the team might not be working on the most relevant projects.</p></li><li><p><strong>Average time from commit to QA/Prod</strong></p><p>This one will capture the CI/CD pipeline effectiveness. If you experience some flaky tests or deployment errors in the pipeline, it would negatively impact the key results.</p></li></ol><p>Over time, some OKRs will be exhausted, so consider renewing them over time. For example, if your survey always has the same questions, developers will eventually stop responding. Also if an OKR has been greatly improved, it’s a good time to shift priorities.</p><p>In my personal experience, I would focus on a few OKRs instead of having too many. Sometimes by trying to please everybody, you will not have a big impact. Some projects might require the full team focus, which can temporarily impact other OKRs. This would be a calculated strategy as these projects would bring huge improvements when delivered.</p><h2 id="are-there-any-warning-signs-people-should-look-out-for-in-order-to-know-their-developer-productivity-is-suffering">Are there any warning signs people should look out for in order to know their developer productivity is suffering?</h2><p>This is where it’s important to have good metrics and monitor them over time. You should be able to feel the pulse of your developers by looking at different data points. Ideally, you would tie these to your OKRs and review the progress every sprint and make adjustments.</p><p>If you don’t have this data there are still warning signs that productivity is suffering:</p><ul><li>Increase in support cases and/or requests for help. If developers need external help to do their work, this is a sign that a process is too hard to use or not well documented.</li><li>On the other hand, I’d be worried if you find out that some processes aren’t working properly but nobody reported them to your team. You want developers to be always looking for improvements and not accepting a broken process.</li></ul><p>Kelda has collaborated with Eventbrite for a long time. We first met when we were building the predecessor to <a href="https://kelda.io/blimp">Blimp</a>, which moves your Docker Compose development environment into the cloud. Eventbrite had already built <code>yak</code> internally, and we were trying to make a general solution. We’ve been trading ideas ever since.</p><p><a href="https://kelda.io/blimp">Check out Blimp</a> to get the benefits of <code>yak</code> without having to build it yourself!</p><h2 id="references">References</h2><p>See <a href="https://kelda.io/blimp/docs/#/usage">Blimp commands and usage</a> in the Docs</p><p>Read <a href="https://kelda.io/blog/common-docker-compose-mistakes/">5 common Docker Compose mistakes</a></p><p><a href="https://medium.com/@remy.dewolf">Remy DeWolf’s Medium</a></p><hr><p>By: Kevin Lin</p></div></div>]]>
            </description>
            <link>https://kelda.io/blog/eventbrite-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144790</guid>
            <pubDate>Thu, 13 Aug 2020 16:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Postgres Row-Level Security in Python and Django]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144405">thread link</a>) | @karlhughes
<br/>
August 13, 2020 | https://pganalyze.com/blog/postgres-row-level-security-django-python | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgres-row-level-security-django-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
Postgres introduced <a href="https://www.postgresql.org/docs/9.5/ddl-rowsecurity.html">row-level security</a> in 2016 to give database administrators a way to limit the rows a user can access, adding an extra layer of data protection. What's nice about RLS is that if a user tries to select or alter a row they don't have access to, their query will return 0 rows, rather than throwing a permissions error. This way, a user can use <code>select * from table_name</code>, and they will only receive the rows they have access to with no knowledge of rows they don't.</p>
<p>Most examples of RLS limit row access by database user. This can be a powerful feature. In this article, we will have a look at how you can make this happen for your Django app. The problem most people run into when trying to implement row level security is that most web applications, including Django applications, connect to the database with a single user, which makes it hard to take advantage of row level security. </p>
<p>One way to get around this is to create a database user for each application user. We’ll start with just the database layer. We’ll build out our tables and create a couple of users, then write our first row level security policy to limit which rows those users can access. Once we have an understanding of how RLS works in Postgres, we’ll expand our project out into Django and see how we can handle working with policies and multiple database users in a web application. </p>

<p><span>
      <a href="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/29114/postgres-row-level-security-django.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Postgres Row-Level Security in Python and Django" title="Postgres Row-Level Security in Python and Django" src="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/8c557/postgres-row-level-security-django.png" srcset="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/4edbd/postgres-row-level-security-django.png 175w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/13ae7/postgres-row-level-security-django.png 350w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/8c557/postgres-row-level-security-django.png 700w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/e996b/postgres-row-level-security-django.png 1050w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/2cefc/postgres-row-level-security-django.png 1400w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/29114/postgres-row-level-security-django.png 1920w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span></p>
<h2 id="how-to-use-rls-at-the-database-level"><a href="#how-to-use-rls-at-the-database-level" aria-label="how to use rls at the database level permalink"></a>How to use RLS at the database level</h2>
<p>Before we get to the Django side of things, let's take a look at how RLS works in Postgres. We'll keep it simple and say we are building an app to help our salespeople keep track of their clients, and we want to make sure no salesperson can access the clients of another salesperson. (These are very competitive, cutthroat salespeople). </p>
<p>First, let's set up our tables and populate them with some data:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> salespeople <span>(</span>id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> name <span>text</span><span>)</span><span>;</span>
<span>CREATE</span> <span>TABLE</span> clients <span>(</span>id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> name <span>text</span><span>,</span> salesperson_id <span>integer</span><span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> salespeople <span>(</span>name<span>)</span> <span>values</span> <span>(</span><span>'Picard'</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> salespeople <span>(</span>name<span>)</span> <span>values</span> <span>(</span><span>'Crusher'</span><span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client1'</span><span>,</span> <span>1</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client2'</span><span>,</span> <span>2</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client3'</span><span>,</span> <span>2</span><span>)</span><span>;</span></code></pre></div>
<p>Now, we have two salespeople. <code>Picard</code> has one client, and <code>Crusher</code> has two clients.</p>
<p>Next, we are going to need some database users, one for each salesperson. Because two salespeople might share the same name, we are going to use the <code>id</code> to create Postgres users. We are also going to create a role called <code>salespeople</code>. This will be the role we grant permissions on, and all of our salespeople can inherit from it.</p>
<div data-language="sql"><pre><code><span>CREATE</span> ROLE <span>"1"</span><span>;</span>
<span>CREATE</span> ROLE <span>"2"</span><span>;</span>
<span>CREATE</span> ROLE salespeople<span>;</span>

<span>GRANT</span> <span>select</span><span>,</span> <span>insert</span> <span>ON</span> clients <span>TO</span> salespeople<span>;</span>
<span>GRANT</span> salespeople <span>TO</span> <span>"1"</span><span>;</span>
<span>GRANT</span> salespeople <span>TO</span> <span>"2"</span><span>;</span></code></pre></div>
<p>This setup will come in handy in the next section when we have to deal with Django's tables in addition to the ones we create for our models.</p>
<p>Now we are ready to set up RLS on our <code>clients</code> table. Our policy will limit access to the Postgres <code>current_user</code> so that they can only view rows where <code>current_user</code> matches <code>salesperson_id</code>. </p>
<div data-language="sql"><pre><code><span>ALTER</span> <span>TABLE</span> clients <span>ENABLE</span> <span>ROW</span> <span>LEVEL</span> SECURITY<span>;</span>
<span>CREATE</span> POLICY salesperson_clients <span>ON</span> clients <span>USING</span> <span>(</span>salesperson_id::<span>text</span> <span>=</span> <span>current_user</span><span>)</span><span>;</span></code></pre></div>
<p>When we create the policy, we give it a name, <code>salesperson_clients</code>, and enter the table we want to set the policy on, <code>clients</code>. Next, we define the policy. In this case, it is very simple: the <code>salesperson_id</code> on the table must be equal to the value of <code>current_user</code>. We have to convert the <code>salesperson_id</code> from an integer to text because our <code>current_user</code> must be a string (we can't create Postgres users with integers as names).</p>
<p>Right now, we are logged in as the <code>postgres</code> user.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>session_user</span><span>,</span> <span>current_user</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code> session_user  | current_user  
---------------+---------------
 postgres      | postgres
(1 row)</code></pre></div>
<p>If we query our <code>clients</code> table, we will be able to see all the rows because <strong>RLS policies do not apply to superusers.</strong></p>

<div data-language="text"><pre><code> id |  name   | salesperson_id 
----+---------+----------------
  1 | client1 |              1
  2 | client2 |              2
  3 | client3 |              2
(3 rows)</code></pre></div>
<p>But if we change the current user, we only get the rows that belong to that user. </p>
<div data-language="sql"><pre><code><span>SET</span> ROLE <span>"1"</span><span>;</span>
<span>SELECT</span> <span>session_user</span><span>,</span> <span>current_user</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code> session_user | current_user 
--------------+--------------
 postgres     | 1
(1 row)</code></pre></div>

<div data-language="text"><pre><code> id |  name   | salesperson_id 
----+---------+----------------
  1 | client1 |              1
(1 row)</code></pre></div>
<h2 id="how-to-use-postgres-row-level-security-in-django"><a href="#how-to-use-postgres-row-level-security-in-django" aria-label="how to use postgres row level security in django permalink"></a>How to Use Postgres Row-Level Security in Django</h2>
<p>Now, how can we translate this to a Django application?</p>
<p>First, we will need to create a database user for each app user we create. One way to accomplish this would be to override the <code>save</code> method on the Salesperson model, but this is a great opportunity to take advantage of <a href="https://docs.djangoproject.com/en/3.0/ref/signals/">Django signals</a> , so we'll create a signal that creates the database user after a new salesperson is saved.  </p>
<p>Next, we'll have to figure out how to switch to the correct user when a salesperson logs in. For this, we can use a middleware that gets the <code>salesperson_id</code> and sets the role in the database. </p>
<h3 id="models"><a href="#models" aria-label="models permalink"></a>Models</h3>
<p>Our models reflect exactly what we set up in our earlier database example. Here I chose to make Salesperson a proxy of Django's built-in <code>User</code> model, but this is not required.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> models
<span>from</span> django<span>.</span>contrib<span>.</span>auth<span>.</span>models <span>import</span> User

<span>class</span> <span>Salesperson</span><span>(</span>User<span>)</span><span>:</span>
    <span>class</span> <span>Meta</span><span>:</span>
        proxy <span>=</span> <span>True</span>
    
<span>class</span> <span>Client</span><span>(</span>models<span>.</span>Model<span>)</span><span>:</span>
    name <span>=</span> models<span>.</span>CharField<span>(</span>max_length<span>=</span><span>50</span><span>)</span>
    Salesperson <span>=</span> models<span>.</span>ForeignKey<span>(</span>Employee<span>,</span> on_delete<span>=</span>models<span>.</span>CASCADE<span>)</span></code></pre></div>
<h3 id="django-signals-creating-our-database-user"><a href="#django-signals-creating-our-database-user" aria-label="django signals creating our database user permalink"></a>Django Signals: Creating Our Database User</h3>
<p>We want to create a new database user every time a new salesperson record is created. We can use Django signals to execute some code after a new record is saved. If you're not familiar with signals, the Django docs on this topic are easy to understand. If this piqued your interest, <a href="https://simpleisbetterthancomplex.com/tutorial/2016/07/28/how-to-create-django-signals.html">this article</a> goes into more detail. </p>
<p>Here is the code for the signal itself, but you'll have to reference the above article to get it registered in your app: </p>
<div data-language="python"><pre><code><span>from</span> <span>.</span>models <span>import</span> Salesperson
<span>from</span> django<span>.</span>db<span>.</span>models<span>.</span>signals <span>import</span> post_save
<span>from</span> django<span>.</span>db <span>import</span> connection

<span>def</span> <span>create_db_user</span><span>(</span>sender<span>,</span> instance<span>,</span> created<span>,</span> <span>**</span>kwargs<span>)</span><span>:</span>
    <span>if</span> created<span>:</span>
        user_id <span>=</span> instance<span>.</span><span>id</span>
        <span>with</span> connection<span>.</span>cursor<span>(</span><span>)</span> <span>as</span> cursor<span>:</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'CREATE ROLE "</span><span><span>{</span>user_id<span>}</span></span><span>"'</span></span><span>)</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'GRANT salespeople TO "</span><span><span>{</span>user_id<span>}</span></span><span>"'</span></span><span>)</span>

post_save<span>.</span>connect<span>(</span>create_db_user<span>,</span> sender<span>=</span>Salesperson<span>)</span> </code></pre></div>
<p>The <code>post_save</code> signal can take a named argument <code>created</code>, which is a boolean. This avoids running the code every time we update the record and ensures it will only run when we create a new salesperson. From there, we can get the user id from the instance and use <code>django.db.connection</code> to run our SQL to create the role and grant permissions. </p>
<p>It's very important to note that if you want to use Django's built-in <code>User</code> model and the authentication that comes with it, you'll need to grant <code>salesperson</code> permissions on the <code>django_admin_log</code> and <code>auth_user</code> tables. That's why it's so helpful to have this parent role that all individual users inherit from.</p>
<h3 id="django-middleware-setting-current-user"><a href="#django-middleware-setting-current-user" aria-label="django middleware setting current user permalink"></a>Django Middleware: Setting Current User</h3>
<p>Now, we can write a <a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/">middleware</a> to switch the database user to the current application user making the request.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> connection

<span>class</span> <span>RlsMiddleware</span><span>(</span><span>object</span><span>)</span><span>:</span>
    <span>def</span> <span>__init__</span> <span>(</span>self<span>,</span> get_response<span>)</span><span>:</span>
        self<span>.</span>get_response <span>=</span> get_response
        
    <span>def</span> <span>__call__</span> <span>(</span>self<span>,</span> request<span>)</span><span>:</span>
        user_id <span>=</span> request<span>.</span>user<span>.</span><span>id</span>
        <span>with</span> connection<span>.</span>cursor<span>(</span><span>)</span> <span>as</span> cursor<span>:</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'SET ROLE "</span><span><span>{</span>user_id<span>}</span></span><span>" '</span></span><span>)</span>

        response <span>=</span> self<span>.</span>get_response<span>(</span>request<span>)</span>
        <span>return</span> response</code></pre></div>
<p>We get the user id from the request object. After that, the code looks pretty similar to our signal. We use the Django <code>db</code> connection again to set the role to the corresponding database user, which should match the application user's id. Don't forget to <a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/#activating-middleware">register your middleware</a> in <code>settings.py</code>.</p>
<p>Now we can use all of Django's built-in query methods while maintaining row-level security in Postgres. What is particularly cool is that, with the role set, all we need to do to get all of a salesperson's clients is call <code>Client.objects.all()</code>, and we can be sure that only the clients related to the salesperson will be returned. If a salesperson tries to query for a client that doesn't belong to them, they'll get zero results.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>In this article we were able to create a simple but powerful row level security policy and, with the help of Django middleware and Django signals, implement the policy at the application level. We saw how to create database users each time we created a new application user, and looked at setting the database role to the correct user after log in, ensuring each application user only had access to the rows that belonged to them. </p>
<p>There are a few caveats here. For one, using the ids <code>1, 2, 3</code> is probably not a good idea in production. You'd want to set up some kind of UUID or some other identifier. Also, creating a new database user for every application user becomes hard to scale at a certain point. Row level security can be a useful tool for limiting access at the database level, and we just scratched the surface of what's possible.</p>
<p>Still, you should be sure RLS is the right solution for your application before trying to implement it. In particular, the performance implications of row-level security, and how the Postgres planner treats it for query plans should not be overlooked. This has been <a href="https://medium.com/@cazzer/designing-the-most-performant-row-level-security-strategy-in-postgres-a06084f31945">significantly improved in Postgres 10</a>, but its still essential to <a href="https://pganalyze.com/postgres-explain">monitor your Postgres query plans</a> when using RLS.</p>
<p>In many cases, RLS is not needed, and you’ll be able to secure your data using the <a href="https://coderbook.com/@marcus/how-to-restrict-access-with-django-permissions/">security measures</a> already built into Django.</p>
<p><strong>Share this article:</strong> If you liked this article you might want to <a href="https://ctt.ac/K5png">tweet it to your peers</a>.</p>
<h2 id="about-the-author"><a href="#about-the-author" aria-label="about the author permalink"></a>About the Author</h2>
<p>Josh is a former educator turned developer with a proven ability to learn …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgres-row-level-security-django-python">https://pganalyze.com/blog/postgres-row-level-security-django-python</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgres-row-level-security-django-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144405</guid>
            <pubDate>Thu, 13 Aug 2020 15:33:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clear is kind, unclear is unkind]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143896">thread link</a>) | @mcrittenden
<br/>
August 13, 2020 | https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-663">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I am terrified of awkwardness. I know nobody likes an awkward moment, but for me it’s downright crippling. I’ve walked out of the room during awkward moments on TV shows. I once faked internet issues to get out of an uncomfortable work call. I’m a huge fan of the Irish goodbye, because dealing with the not-sure-if-we-should-hug thing sucks. It’s been a serious problem in my life.</p>



<p>And wouldn’t you know it – I also hate giving people news that might upset them. Because that’s often pretty dang awkward. I’ve gotten good at figuring out ways to avoid it without feeling like I avoided it. For example:</p>



<ul><li>I’ve given negative feedback about something really tiny and specific in hopes that it would solve the bigger, much more critical problem, because talking about the critical problem may have been awkward. Spoiler: it never worked.</li><li>I’ve flat out avoided giving negative feedback because “they’re already dealing with a lot” or “I’m going to wait until I have a better example to use, or else it wouldn’t be fair to them” or who knows how many other reasons.</li><li>I’ve given negative feedback that really came from me, but I pitched it like “I don’t think this, but I’m wondering if &lt;a coworker&gt; may think it, from their point of view.”</li></ul>



<p>In that way, I convince my monkey brain that I’m being caring because I’m still “delivering feedback” just without the hurt feelings, right? But no, I’m being a jerk, because <a href="https://brenebrown.com/blog/2018/10/15/clear-is-kind-unclear-is-unkind/">clear is kind, and unclear is unkind</a>. </p>



<p>I don’t know where this first came from, but I heard it from Brené Brown and it was a smack in the face. If I’m not being clear, then I’m being unkind. Period. No matter how much I can try to convince myself that it’s not that simple, it really is.</p>



<p>I am changed. With this as my guiding principle, I feel confident in giving tough feedback no matter how awkward it might be, because anything else would be unkind. And even though I hate awkwardness, I hate being unkind even more.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143896</guid>
            <pubDate>Thu, 13 Aug 2020 14:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even Unicorns Get the Blues]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143764">thread link</a>) | @StuntPope
<br/>
August 13, 2020 | https://outofthecave.io/articles/even-unicorns-get-the-blues/ | <a href="https://web.archive.org/web/*/https://outofthecave.io/articles/even-unicorns-get-the-blues/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Heretical Judge Rules that Uber Can’t Externalize its Labour Costs</h3>
<p><img loading="lazy" src="https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy.jpg" alt="" width="693" height="478" srcset="https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy.jpg 800w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-300x207.jpg 300w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-150x104.jpg 150w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-768x530.jpg 768w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-65x45.jpg 65w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-220x152.jpg 220w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-145x100.jpg 145w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-358x247.jpg 358w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-580x400.jpg 580w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-652x450.jpg 652w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-739x510.jpg 739w" sizes="(max-width: 693px) 100vw, 693px"></p>
<p>As I briefly covered <a href="https://axisofeasy.com/aoe/axisofeasy-158-hundreds-of-smartphone-apps-sell-your-location-data-to-government-connected-data-firms/">in my AxisOfEasy tech digest</a> this week, Uber and Lyft were bracing themselves for a ruling by a California judge that threatened to force them into treating their <span>wage slaves</span> drivers as employees. Lyft said if the ruling went against them it would cause “irreparable damage”. Uber CEO Dara Khosrowshahi penned an <a href="https://www.nytimes.com/2020/08/10/opinion/uber-ceo-dara-khosrowshahi-gig-workers-deserve-better.html">op-ed in the New York Times</a> that just so happened to run Monday, pining for a fair shake for gig economy <span>serfs</span> workers.<span id="more-1152"></span></p>
<p>Khosrowshahi, whose compensation package last year clocked in at $45,000,000 USD, waxed pensively,<em> ‘There has to be a “third way” for gig workers.’ .&nbsp;</em>Ideally one in which Uber wouldn’t be on the hook for their benefits and would be able to continue apace as a Silicon Valley unicorn: posting billions of dollars a quarter in losses and <a href="https://www.forbes.com/sites/janetwburns/2020/03/26/uber-and-airbnb-ask-for-bailouts-critics-arent-having-it/#2a5d61ff7639">jockeying for Federal bailouts.</a> Meanwhile the early stage backers, the VC’s and the private equity funds, would continue to live large off of financialization, not having to worry about the consequences of being <em>the&nbsp;</em>driving force in a race to the bottom for everybody else (even Uber’s lümpenvestors who bought into the IPO are still underwater).</p>
<p>As it turned out, <a href="https://www.theverge.com/2020/8/10/21362460/uber-lyft-drivers-employees-california-court-ruling">Judge Schulman ruled</a> that these gig economy workers are to be treated as employees in the State of California, and sure enough, Uber is now <a href="https://ktla.com/news/california/uber-lyft-threaten-to-leave-california-if-court-upholds-ruling-forcing-them-to-treat-drivers-as-employees/">threatening to pick up their ball and go home.</a></p>
<p>People following my writings may be surprised that I’m not approaching this as yet another government inflicted wound against capitalism, like how laws mandating higher minimum wages actually increase unemployment. It’s a fair point.</p>
<p>But we’re not talking about countless mom-and-pops and other main street businesses having their costs jacked up by economically illiterate career politicians. Even in a climate of government mis-micromanagement and overreach, the so called “free enterprise” participants should be competing under the same conditions. If an independently owned and operated driver service in the state has to operate under onerous taxation and terms, then being a Silicon Valley unicorn shouldn’t exempt you from suffering the same conditions.</p>
<p>In this case we’re talking <a href="https://outofthecave.io/articles/wait-why-is-the-fed-buying-my-biggest-competitors-bonds/">about Cantillonaires</a> who feel entitled to special privileges and exemptions but the reality is this:</p>
<h3>These companies were never intended to be economically viable.</h3>
<p><em>Uber and Lyft started the year with $11.3B and $2.8B in cash on their balance sheets respectively. They posted TTM losses of $10B and$ 2B respectively.&nbsp; They are valued around $54B and $9.2B</em></p>
<p>The only thing that mattered from the outset was to cannibilize the entire market, driving down prices and wages while operating at a loss so that they could garner the next financial event, be it a series D, E or F up-round and then eventually some monster acquisition or IPO. Within truly un-manipulated, free market competition, Uber and Lyft would have either had to compete, <em>viably</em>, with numerous entrants and competitors all fighting under their own steam, or else be snuffed out by economic reality.</p>
<p>The truth is that you can’t actually build a business where every transaction and input is subsidized, ultimately by central bank stimulus, while&nbsp; all normal course responsibilities of operations, like expenses, are externalized.</p>
<p>With the Everything Bubble <a href="https://outofthecave.io/articles/unicorn-winter/">finally looking to pop</a>, and pent up reality s-l-o-w-l-y <a href="https://outofthecave.io/articles/the-jackpot-chronicles-scenario-1-force-majeure/">beginning to reassert itself</a>, these Unicorns will have to face the same situation that every other non-unicorn, non Silicon Valley funded business has to face: Whatever your “boil-the-ocean” big idea is, you’re gonna have to do it in an economically viable way, or it’s not going to happen.</p>
<p><em>To follow my work sign up for the&nbsp;<a href="https://outofthecave.io/join/">Out Of The Cave mailing list</a>, or on&nbsp;<a href="https://nojack.easydns.ca/@stuntpope">Mastodon</a>&nbsp;or&nbsp;<a href="https://twitter.com/stuntpope">Twitter&nbsp;</a></em></p>
<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://cdn.printfriendly.com/buttons/printfriendly-button.png" alt="Print Friendly, PDF &amp; Email"></a></p></div></div>]]>
            </description>
            <link>https://outofthecave.io/articles/even-unicorns-get-the-blues/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143764</guid>
            <pubDate>Thu, 13 Aug 2020 14:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Getting F'ed by Technical Recruiters]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24143721">thread link</a>) | @tacomondays
<br/>
August 13, 2020 | https://scottturman.com/stop-getting-fcked-by-technical-recruiters/ | <a href="https://web.archive.org/web/*/https://scottturman.com/stop-getting-fcked-by-technical-recruiters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="69190526" data-element_type="column">
			<div>
					<div>
				<div data-id="11bdfd87" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:50}" data-widget_type="heading.default">
				<p>
			<h2>Get notified when we publish!</h2>		</p>
				</div>
				<div data-id="50628801" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:100}" data-widget_type="heading.default">
				<p>
			<h2>New Book -Stop Getting Fu*ked By Technical Recruiters</h2>		</p>
				</div>
				
				<div data-id="27158996" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:200}" data-widget_type="heading.default">
				<p>
			<h2>You probably never had anyone teach you how to negotiate your salary or benefits. Not your parents, school and certainly not your employer. Learning to negotiate how much you will charge for your labor may be one of the most important life skills you can ever develop as it will set the tone for how well you can live your life.</h2>		</p>
				</div>
				<section data-id="1bc4b15c" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300}">
						<div>
				<div>
				<div data-id="1a9f3005" data-element_type="column">
			<div>
					<div>
				
				<div data-id="53e472ce" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>This book is a collection of what I have learned as to how to accomplish this. I hope you will see the value of this book when you stop and realize that for every $10 more per hour you are able to get from a recruiter/employer will translate into another $20,000’ish more per year to your salary. It is also important to understand that every salary can have an additive effect over the lifetime of your total career earnings.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="562d2017" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300}">
						<div>
				<div>
				<div data-id="4bbccccc" data-element_type="column">
			<div>
					<div>
				
				<div data-id="61cdec01" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>This book is going to teach you to take the power back. You can negotiate a higher rate, as you are the prize. You are the one with the skills needed to make the technology go and the recruiting company is simply one of the many conduits for the work that exists out there in the world.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://scottturman.com/stop-getting-fcked-by-technical-recruiters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143721</guid>
            <pubDate>Thu, 13 Aug 2020 14:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using JDK FlightRecorder and JDK Mission Control]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143664">thread link</a>) | @mfiguiere
<br/>
August 13, 2020 | https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/ | <a href="https://web.archive.org/web/*/https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>At some point we had an issue with application startup performance.
For a bit of context this app runs in a Kubernetes cluster, with k8s it’s possible
to define a <em>rollout policy</em> to avoid service disruption, that what we had, so there’s a
rollout, new pods (a pod is composed of the application container) get created,
new application are started, then Kubernetes has a mean to check when the application is
<strong>ready</strong>, it’s called the readiness probe. This probe can be a call to http endpoint or a script,
ours is an HTTP endpoint.</p>
<p>WHen the probe indicates the application is ready, the application starts receiving traffic,
from this moment latencies increased from 10-20 milliseconds to seconds.</p>
<p>Opening the recording JMC, it will start an automated analysis. Sometime it’s helpful
and warning should be looked at. In this case the issue was elsewhere.</p>
<p>To help in our case, I needed to go in the thread view, which as a <em>thread lanes</em>
which displays each thread as an horizontal bar, and JFR event are painted on the bar
at the time they happened and for how long. At the bottom there’s a the time axis.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-0-thread-lanes.png" alt="startup 0 thread lanes">
</p>
<p>Thread Lanes</p>
</div>
<p>The first things that catch our eyes will be the vertical patterns, especially the one with
yellow and red around 12:51:15. Let’s zoom (you can select and right click, or use arrow keys.).</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-0-threads-lanes-closer.png" alt="startup 0 threads lanes closer">
</p>
<p>Zooming on the problematic</p>
</div>
<p>The vertical pattern is more precise, these vertical pattern indicates a <em>cross
threads phenomena</em>. And we can notice that all thread are not affected the same way.</p>
<p>The lanes in green at the top indicates these threads are progressing normally, nothing’s
wrong with them. However, if we go down there especially, the pattern materialize around
12:51:11.</p>
<p>Each color indicate some events:</p>
<div>
<ul>
<li>
<p>Gray ⇒ the thread does nothing, it’s parked</p>
</li>
<li>
<p>Small dark point ⇒ The park event, the thread was scheduled but was eventually parked</p>
</li>
<li>
<p>Red ⇒ In this case it’s a <em>blocked lock</em></p>
</li>
<li>
<p>Yellow ⇒ Here the yellow events that interests us are thread waiting on a lock</p>
</li>
</ul>
</div>
<p>I’m not well versed in describing colors, so know that there are other events that use
a slightly different tone / shade of red, yellow or else. Just click on the event
to see what’s going on.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-lock-event.png" alt="startup 1 threads jedis lock event">
</p>
<p>monitor blocked</p>
</div>
<p>The UI could be improved but going over the events shows a popup with its details,
for the Monitor Blocked event, there’s the duration this monitor was block, who held
this monitor before, and the monitor address in the heap.</p>
<p>This monitor was held for ~9s, that’s a big bottleneck !</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-monitor-acquire-blocked.png" alt="startup 1 threads jedis monitor acquire blocked">
</p>
</div>
<p>In this case this application had ~200 thread competing for this lock in particular. And finding
the thread that acquired it is not automated, it’s a bit tedious, but in the end didn’t reveal
anything.</p>
<p>However, the Monitor Blocked event has another interesting element, the stacktrace. In the lower
pane of JMC, if the event is selected, we can see the stack trace where this event was emitted.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-monitor-blocked-stack.png" alt="startup 1 threads jedis monitor blocked stack">
</p>
<p>jedis classloading</p>
</div>
<p>Here that’s the JDK classloader. I would never have thought that the JDK code would cause ~9s
contention. But looking at the stacktrace, there <em>jedis</em> (a Redis client) connection pool involved.
Maybe the class have static initialization that does IO, maybe it’s the agent that runs in production
that introduces latencies during this specific classloading.</p>
<p>But all the threads starts working again around 12:51:22, and redis bottleneck is not anymore an issue
afterward. Let’s look at the story on the IO side, open the Socket IO view.</p>
<p>Identify which one is related to redis, either via IP or via port (Redis is <code>6379</code>).</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-socketio-redis-port.png" alt="startup 1 socketio redis port">
</p>
<p>Socket IO with redis port selected</p>
</div>
<p>While we see a total time of 30s, it’s the accumulated time for all thread for the recording duration (6m).
So nothing fancy here. However, we see that actual IO happens later, around 12:51:22.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-socketio-redis.png" alt="startup 1 socketio redis">
</p>
<p>Socket IO actual Redis read / write</p>
</div>
<p>I’m not sure of the cause, we can definitely rule out Redis, the is either in the network, during
connection establishment, or actually during classloading.</p>
<p>In order to remediate that, we noticed this code is called once the application is ready.
So in order to avoid the contention the code was changed to pre-connect to redis during the
application startup before the application is considered ready. And it worked, this
specific issue disappeared.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-thread-lanes.png" alt="startup 2 thread lanes">
</p>
</div>
<p>The issue identified in the first recording showed some contention on redis, this is now gone.
There is however in this second iteration multiple other issues when flying the mouse pointer
over the yellow and red events.</p>
<div>
<p>Incriminating stack traces 1</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-01.png" alt="startup 2 stack 01">
</p>
<p>Jersey’s <code>ListMultiMap</code> classloading</p>
</div>
</div>
</div>
<div>
<p>2</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-02.png" alt="startup 2 stack 02">
</p>
<p>Jackson’s <code>SerializerCache</code> initialization</p>
</div>
</div>
</div>
<div>
<p>3</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-03.png" alt="startup 2 stack 03">
</p>
<p>Jersey’s <code>ImprovedAbstractMap</code> classloading</p>
</div>
</div>
</div>
<div>
<p>4</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-04.png" alt="startup 2 stack 04">
</p>
<p>Jackson’s <code>PropertySerializerMap</code> initialization</p>
</div>
</div>
</div>
<div>
<p>5</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-05.png" alt="startup 2 stack 05">
</p>
<p>Jackson’s <code>TypeFactory</code> initialization</p>
</div>
</div>
</div>
<div>
<p>6</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-06.png" alt="startup 2 stack 06">
</p>
<p>Jackson’s <code>DeserializerCache</code> initialization</p>
</div>
</div>
</div>
<div>
<p>7</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-07.png" alt="startup 2 stack 07">
</p>
<p>Guava’s <code>hash</code> function involving classloading</p>
</div>
</div>
</div>
<div>
<p>8</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-08.png" alt="startup 2 stack 08">
</p>
<p>Newrelic’s <code>SynchronizedCollection.size()</code></p>
</div>
</div>
</div>
<div>
<p>9</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-09.png" alt="startup 2 stack 09">
</p>
<p>Jackson’s <code>PropertySerializerMap</code> initialization</p>
</div>
</div>
</div>
<div>
<p>10</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-10.png" alt="startup 2 stack 10">
</p>
<p>Datastax cassandra driver’s <code>ChainedResultSetFuture</code> involving classloading</p>
</div>
</div>
</div>
<div>
<p>11</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-11.png" alt="startup 2 stack 11">
</p>
<p>Jersey’s <code>AbstractMapBasedMultimap</code> involving classloading</p>
</div>
</div>
</div>
<p>All the stacktraces above have one thing in common, a contention on a lock.
As thread were blocked, and new request appeared, this had the effects of increase the
queuing, and made tomcat creates new <em>http nio</em> worked threads until the maximum is reached
(200 by default). I applied the same trick: i.e before readiness, exercise code paths that
are lazy initialized. And it worked too. Most contention disappeared afterward.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-3-C2-compiler.png" alt="startup 3 C2 compiler">
</p>
<p>Better startup / C2 compiler event</p>
</div>
<p>There was still some potential gain however. I noticed a few C2 compiler related events.
If you don’t know C1 and C2, those are the compilers that transform bytecode to assembly.
C1 interprets the bytecode and may perform some tricks like escape
analysis, but its role is to be fast to execute bytecode and not about optimizing the machine
code assembly. In a second phase C2 may kick in for hot code path that is code that is executed
very often, and its job is to output highly optimized code at the cost of higher computation
resources.</p>
<p>Note this compilation event <strong>is not</strong> blocking threads !</p>
<p>As an experiment I used the Graal compiler, which I believe is the new
generation of compiler that have a chance to replace C2. <a href="https://github.com/oracle/graal/blob/master/compiler/README.md">Graal compiler</a>
is part of the <a href="https://github.com/oracle/graal">GraalVM</a> project.
It ships as an experimental option : <code>-XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler</code>.</p>
<p>And the result for this work load in particular, just activating the Graal compiler between
these two successive rollouts.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-3-grafana.png" alt="startup 3 grafana">
</p>
<p>Improved P99</p>
</div>
<p>This graph is falling under the <a href="https://latencytipoftheday.blogspot.com/2014/06/latencytipoftheday-most-page-loads.html"><em>percentlie</em></a>
but the improvement is still visible.</p>
<p>After that experiment when I analyzed the new profile I noticed that JVM was using a lot of time to
revoke bias locking. Note the events in fushia are custom JFR events that track HTTP requests.
(<a href="https://twitter.com/gunnarmorling">Gunnar Morling</a> has an inspiring
<a href="https://www.morling.dev/blog/rest-api-monitoring-with-custom-jdk-flight-recorder-events/">write up</a> about it).</p>
<p>This VM operation is done during safepoint during which the JVM is paused. At this time a lot of
bias revocation event appears, so we removed them, and it works too.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-4-threads-revoke-biased-locks.png" alt="startup 4 threads revoke biased locks">
</p>
<p>Revoke Bias locking</p>
</div>
<p>The graphic below shows the difference in startup time. Other consuming backend services had to timeout
and eventually perform retries during rollouts which increased the pressure on the application.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-5-before-after.png" alt="startup 5 before after">
</p>
<p>Before ⇒ after</p>
</div>
<p>Other smaller issues could be discovered and tackled, for example I noticed a few gaps
200ms wide at 30/1min intervals that were related to GC pauses.</p>
<div>
<p>GC gaps</p>
<p><span><img src="https://blog.arkey.fr/assets/jfr/startup-9-gc-pause-1.png" alt="startup 9 gc pause 1" title="GC gap 1"></span> <span><img src="https://blog.arkey.fr/assets/jfr/startup-9-gc-pause-2.png" alt="startup 9 gc pause 2" title="GC gap 2"></span></p>
</div>
<p>For this application the GC is working within 20ms excepts for a few larger pauses
during the early minutes of startup:</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-9-thread-lanes-gc-pauses-effect.png" alt="startup 9 thread lanes gc pauses effect">
</p>
<p>GC pauses causes new HTTP worker threads</p>
</div>
<p>Tuning GC is out of scope for this article, but JMC presents a nice view that could help identify GC
causes. In my opinion it’s currently a bit less powerful as GC logs because GC events lack
useful information only found in GC logs with appropriate tags and level.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/jmc-java-application-view.png" alt="jmc java application view">
</p>
<p>Java Application view</p>
</div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/jmc-garbage-collection-view.png" alt="jmc garbage collection view">
</p>
<p>Garbage Collection view</p>
</div>
<p>Anyway from there we could imagine a <em>setting</em> file in the JDK dedicated for GC events.
Instead of parsing log files whose <em>string format</em> that may change a bit over releases
(even with unified logging) GC events could be analyzed leveraging the included JFR schema.</p>
<p>Also, with JFR it’s even possible to record memory leak using the <code>profile</code> <em>settings</em> file,
I never tried that in a real situation though, but if this avoids the need to make a heap dump
and parse it then I’m all in.</p>
</div></div>]]>
            </description>
            <link>https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143664</guid>
            <pubDate>Thu, 13 Aug 2020 14:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Great DevOps Resources for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143403">thread link</a>) | @savovaleks
<br/>
August 13, 2020 | https://microtica.com/great-devops-resources/ | <a href="https://web.archive.org/web/*/https://microtica.com/great-devops-resources/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p>The future of DevOps solutions is bright. The <a href="https://www.marketsandmarkets.com/Market-Reports/devops-824.html" target="_blank" rel="noreferrer noopener">global DevOps market size</a> is expected to <strong>increase from $2.90 billion in 2017 to $10.31 billion by 2023</strong>, at a Compound Annual Growth Rate (CAGR) of 24.7% during the forecast period.&nbsp;</p>



<p>The growing need for fast app delivery is driving the market growth, with organizations that want to achieve both speed and quality.&nbsp;</p>



<p>However, the world is facing <a href="https://www.shuttleops.io/the-shortage-of-devops-skills" target="_blank" rel="noreferrer noopener">a shortage of DevOps skills</a>. That’s why DevOps engineers are highly-paid, with <a href="https://www.glassdoor.com/Salaries/devops-engineer-salary-SRCH_KO0,15.htm" target="_blank" rel="noreferrer noopener">Glassdoor estimating</a> <strong>the average annual pay at around $100,000</strong>.&nbsp;</p>



<p>So, if you’re looking for a career switch or upgrade, learning DevOps is a good idea. From books to podcasts, <em>here are the best DevOps resources to start with:&nbsp;</em></p>



<h2><strong><a rel="noreferrer noopener" href="https://www.bookdepository.com/Phoenix-Project-Gene-Kim/9781942788294?ref=grid-view&amp;qid=1588577029418&amp;sr=1-1" target="_blank">The Phoenix Project</a></strong></h2>



<p>Who would have thought you could write a novel about DevOps? Well, Gene Kim, Kevin Behr, and George Spafford obviously did a great job!&nbsp;</p>



<p><strong>The Phoenix Project </strong>is an amazing novel about DevOps. The story revolves around a fictional company called “Parts Unlimited”, where the IT manager gets promoted into a senior position. Then, he gets a deadline of 90 days to repair “The Phoenix Project”, a failing and messy code project that’s crucial to the future of the company. If he fails, the CEO threatens to outsource the entire IT department and let go of the people working in it.</p>



<p>So, he starts working on it with the help of some board members. The most important thing here is his philosophy called The Three Ways. It consists of (obviously) three parts—maximizing the flow of work from left-to-right, starting from business to development to IT operations to the end-user; increasing the feedback loop from right to left, and developing and nurturing a culture of <a href="https://microtica.com/cracking-the-continuous-deployment-code/" target="_blank" rel="noreferrer noopener">continuous deployment</a> and learning.</p>



<p>This philosophy helps him create <strong>a streamlined workflow in the department</strong>, <a href="https://microtica.com/6-tips-to-solve-miscommunication-in-dev-teams/">improve </a><strong><a href="https://microtica.com/6-tips-to-solve-miscommunication-in-dev-teams/" target="_blank" rel="noreferrer noopener">communication</a> and effectiveness</strong>, and make the IT department really valuable to the company.&nbsp;</p>



<p>I think this is a really great book, especially for beginners. It gives a sense of what problems IT departments face every day, and offers realistic solutions.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.oreilly.com/library/view/infrastructure-as-code/9781491924334/" target="_blank">Infrastructure as Code</a></strong></h2>



<p>Coming from ThoughtWorks, this is another book that focuses on <strong>the entire DevOps movement from a more technical aspect</strong>. This book covers the principles of Infrastructure as Code, practical examples, dynamic infrastructure platforms, various cloud options, tools, patterns, software engineering practices, <a href="https://microtica.com/how-to-create-simple-ci-cd-pipeline/" target="_blank" rel="noreferrer noopener">creation and management of pipelines</a>, workflows, and infrastructure management. They are all divided into three sections—Foundations, Patterns, and Practices.&nbsp;</p>



<p>If you’re interested in similar books, you can check <a href="https://www.amazon.com/Evolutionary-Architecture-Nature-Basis-Design/dp/0471117269" target="_blank" rel="noreferrer noopener">Evolutionary Architecture</a> and <a href="https://www.amazon.com/Building-Microservices-Designing-Fine-Grained-Systems/dp/1491950358/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1508683865&amp;sr=1-1&amp;keywords=microservices" target="_blank" rel="noreferrer noopener">Building Microservices</a>, also by ThoughtWorks.&nbsp;</p>



<h2><a href="https://www.udemy.com/course/linux-academy-devops-essentials/?LSNPUBID=JVFxdTr9V80&amp;ranEAID=JVFxdTr9V80&amp;ranMID=39197&amp;ranSiteID=JVFxdTr9V80-BF4jpUPRiGZluHvCXXjptQ" target="_blank" rel="noreferrer noopener"><strong>DevOps Essentials</strong></a></h2>



<p>This Udemy course has hosted over 40,000 students who gave an average rating of 4.4/5. The course is completely free, covering 2 hours and 15 minutes of video lessons.&nbsp;</p>



<p>This course can give you an understanding of <strong>how DevOps impacts the IT world</strong>. You’ll learn the basic DevOps terminology, the evolution of DevOps, the most important processes, the most common tools used, and the most popular DevOps and cloud providers.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.udemy.com/course/docker-and-kubernetes-the-complete-guide/?ranMID=39197&amp;ranEAID=JVFxdTr9V80&amp;ranSiteID=JVFxdTr9V80-T3DyVhPcjn.KepO0Rg.oZg&amp;LSNPUBID=JVFxdTr9V80" target="_blank">Docker and Kubernetes: The Complete Guide</a></strong></h2>



<p>Another Udemy course with over 120,000 students enrolled and an average rating of 4.6. During 21.5 hours of video materials, you’ll learn everything you need to know about <strong>Docker and Kubernetes</strong>, even if you don’t have previous experience with these topics.&nbsp;</p>



<p>The course starts with a deep dive into the Docker world, showing you all the Docker fundamentals. Then, you’ll learn everything you need to know about setting up a <a href="https://microtica.com/how-to-create-simple-ci-cd-pipeline/" target="_blank" rel="noreferrer noopener">CI/CD pipeline</a> and implementing it on Github and AWS.&nbsp;</p>



<p>Then, you’ll learn to construct a multi-container application utilizing Node, React, Redis, and Postgres. After this, you should be able to <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">deploy both single- and multi-container applications on AWS</a>.</p>



<p>Finally, you’ll learn how to build a <a href="https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/" target="_blank" rel="noreferrer noopener">Kubernetes Cluster</a>. This course even covers setting up HTTPS on Kubernetes.&nbsp;</p>



<p>In their reviews, students say how they loved the way the teacher explains all concepts step-by-step. All in all, it’s one of the best courses on Udemy.&nbsp;</p>



<h2><a href="https://www.udemy.com/course/learn-devops-continuously-deliver-better-software/?LSNPUBID=JVFxdTr9V80&amp;ranEAID=JVFxdTr9V80&amp;ranMID=39197&amp;ranSiteID=JVFxdTr9V80-ImNkBFHUPJQ04wh3qXOm9A" target="_blank" rel="noreferrer noopener"><strong>Learn DevOps: Continuously Deliver Better Software</strong></a></h2>



<p>One of the most detailed courses about DevOps that targets more experienced engineers, System Administrators, IT managers, IT operation members, and other IT professionals.&nbsp;</p>



<p>The lecturer explains how to <strong>improve software delivery with automation, configuration management, provisioning, and deployment.</strong> Docker and Kubernetes are also covered.&nbsp;</p>



<p>Although the course lasts about 4.5 hours, you can add much more by trying everything by yourself. The lecturer even offers support for people who get stuck. Students also have a Facebook group where they post questions and discuss.</p>



<h2><a href="https://netflixtechblog.com/" target="_blank" rel="noreferrer noopener"><strong>The Netflix Tech Blog</strong></a></h2>



<p>The Netflix Tech Blog is a great place where you can find out “how they build code at Netflix.” Developers share literally everything, going beyond DevOps. Here, you’ll learn <strong>how Netflix creates, builds, and manages its system and engineering organizations</strong>.&nbsp;</p>



<p>For example, in one of their blogs, they elaborated on how they applied <a href="https://netflixtechblog.com/applying-netflix-devops-patterns-to-windows-2a57f2dbbf79" target="_blank" rel="noreferrer noopener">Netflix DevOps patterns to Windows</a>, while another one is about their <a href="https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749" target="_blank" rel="noreferrer noopener">hexagonal architecture</a>.&nbsp;</p>



<h2><a href="https://www.reddit.com/r/devops/" target="_blank" rel="noreferrer noopener"><strong>DevOps SubReddit</strong></a></h2>



<p>Although it’s not everyone’s first choice, the DevOps SubReddit has many interesting and useful information software engineers should check out. Here, you’ll find a lot of blog posts, articles, and news about DevOps.</p>



<p>Most importantly, you can <strong>engage in discussions with fellow DevOps enthusiasts </strong>and learn a lot from their knowledge and experience, sharing a lot of practical examples.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.arresteddevops.com/" target="_blank">Podcast: Arrested DevOps</a></strong></h2>



<p>Arrested DevOps is a podcast hosted by Joe Laha, Bridget Kromhout, Matt Stratton, Trever Hess, and Jessica Kerr. They’ve recorded over 130 episodes, with the goal to help developers evolve practices and manage teams that will help them take the maximum out of DevOps.&nbsp;</p>



<p>Listeners can learn more about <strong>DevOps strategies, best tools, and integrations</strong> from delightful guest speakers that come from different parts of the world. The episodes last about 40-45 minutes and are released on a monthly basis.</p>



<p><strong>Here are some other links with DevOps resources you might find useful:&nbsp;</strong></p>



<ul><li><a href="https://techbeacon.com/devops/53-essential-resources-devops-practitioners" target="_blank" rel="noreferrer noopener">53 essential resources for DevOps practitioners</a></li><li><a href="https://aws.amazon.com/devops/resources/" target="_blank" rel="noreferrer noopener">DevOps resources – AWS</a></li><li><a href="https://www.upguard.com/blog/devops-resources-online" target="_blank" rel="noreferrer noopener">The best DevOps resources online</a></li><li><a href="https://opensource.com/article/19/12/devops-resources" target="_blank" rel="noreferrer noopener">8 must-read DevOps articles for success in 2020</a></li></ul>




<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/great-devops-resources/"
    dc:identifier="https://microtica.com/great-devops-resources/"
    dc:title="8 Great DevOps Resources for Beginners &#038; Advanced"
    trackback:ping="https://microtica.com/great-devops-resources/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/great-devops-resources/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143403</guid>
            <pubDate>Thu, 13 Aug 2020 14:00:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Drivers of Corporate Reputation Management]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143280">thread link</a>) | @Gpetrium
<br/>
August 13, 2020 | https://gpetrium.com/drivers-of-corporate-reputation-management/ | <a href="https://web.archive.org/web/*/https://gpetrium.com/drivers-of-corporate-reputation-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gpetrium.com/drivers-of-corporate-reputation-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143280</guid>
            <pubDate>Thu, 13 Aug 2020 13:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralized Finance, the YAM fiasco and the road to DeFi sustainability]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143042">thread link</a>) | @bpierre
<br/>
August 13, 2020 | https://blog.rotki.com/2020/08/13/sustainable-defi/ | <a href="https://web.archive.org/web/*/https://blog.rotki.com/2020/08/13/sustainable-defi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>13 Aug 2020</span></p><ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#what-is-defi">What is DeFi</a>
    <ul>
      <li><a href="#decentralized-exchanges">Decentralized Exchanges</a></li>
      <li><a href="#lendingborrowing-protocols">Lending/Borrowing Protocols</a></li>
      <li><a href="#synthetic-assets">Synthetic Assets</a></li>
    </ul>
  </li>
  <li><a href="#what-new-possibilities-does-defi-unlock">What new possibilities does DeFi unlock?</a></li>
  <li><a href="#the-dark-side-of-defi">The dark side of DeFi</a>
    <ul>
      <li><a href="#yam-finance">YAM finance.</a></li>
    </ul>
  </li>
  <li><a href="#responsible-decentralized-finance">Responsible Decentralized Finance</a>
    <ul>
      <li><a href="#responsible-defi-user">Responsible DeFi user</a></li>
      <li><a href="#responsible-defi-founder">Responsible DeFi founder</a></li>
      <li><a href="#towards-a-sustainable-defi-ecosystem">Towards a sustainable DeFi ecosystem</a></li>
    </ul>
  </li>
  <li><a href="#closing--about-the-author">Closing / About the author</a></li>
</ul>

  

<p>This post explores what is the concept of Decentralized Finance (DeFi), what new possibilities does it unlock and why it’s so cool and hot right now. On the other side of the coin it touches on the dark side of DeFi with the YOLO farming and unaudited contracts most recently highlighted by the YAM fiasco. Finally it takes a look on the road ahead, the lessons that the community needs to learn in order to create sustainable and responsible DeFi for decades to come. Finacial instruments and tools that will not only be used by a few Twitter bros but permisionlessly by everyone around the world.</p>



<p>In one sentence, decentralized finance is the permissionless decentralized version of various traditional financial instruments such as exchanges, lending, borrowing, synthetic assets e.t.c. There has been a lot of innovation in the sector in the past 2 years.</p>

<h2 id="decentralized-exchanges">Decentralized Exchanges</h2>

<p>We have various decentralized exchanges such as:</p>

<ul>
  <li><a href="https://uniswap.org/">Uniswap</a></li>
  <li><a href="https://kyberswap.com/swap">Kyber</a></li>
  <li><a href="https://www.deversifi.com/">Deversifi</a></li>
</ul>

<p>They all operate in a decentralized way and are non-custodial in stark contrast with centralized exchanges such as Binance, Kraken to which you have to first deposit and give custody of your funds.</p>

<h2 id="lendingborrowing-protocols">Lending/Borrowing Protocols</h2>

<p>There are protocols such as <a href="https://app.compound.finance/">Compound</a> and <a href="https://app.aave.com/home">Aave</a> that allow users to lend their assets to earn interest or to borrow assets after staking some collateral. MakerDAO also offers a form of borrowing via <a href="https://oasis.app/borrow">vaults</a> that can mint the DAI stable token after depositing various forms of collateral.</p>

<h2 id="synthetic-assets">Synthetic Assets</h2>

<p>Synthetic asset protocols such as <a href="https://www.synthetix.io/">Synthetix</a> or <a href="https://www.tokensets.com/">Token Sets</a> combine a mix of different assets into a single asset. This way you can get exposure to multiple different assets by just holding a single synthetic asset.</p>



<p>What DeFi does is nothing new. All of this already exist in one form or another in the world of “traditional finance”. What is so amazing and revolutionary about DeFi is that it’s completely decentralized and permissionless. And that it is accessible to everyone regardless of location or background. It’s unlocking a ton of possibilities for people around the world, building a new permisionless financial system in the process.</p>



<p>Just like with everything involving money this sector also attracts short-termed myopic people and projects who are driven by greed.</p>

<p>There is the concept of a yield farmer, someone who provides liquidity or stakes in a protocol in return for interest, fees or some governance token. Yield farming is not bad per se. Everyone who provides liquidity in all the DeFi protocols is essentially yield farming. There is nothing wrong with that.</p>



<p><img src="https://blog.rotki.com/public/post8/defichad.jpeg"></p>



<p>The bad side of farming is the “DeFi chad” or “Defi Degen”. The kind of meme-driven farmer who jumps from protocol to protocol without any thought on contract safety, chasing the biggest yield, dumping their tokens to the new guys and then moving on. A practice that is obviously unsustainable.</p>

<h2 id="yam-finance">YAM finance.</h2>

<p>A very good example of the irresponsible approach to DeFi is YAM. An experiment that did not even manage to last 2 days. It <a href="https://medium.com/@yamfinance/yam-finance-d0ad577250c7">launched</a> in 19:00 UTC, August 11th, 2020 and <a href="https://medium.com/@yamfinance/yam-post-rescue-attempt-update-c9c90c05953f">died</a> 36 hours later.</p>

<h3 id="what-happened">What happened?</h3>

<p>YAM advertised itself as an experiment from the start. It was a mashup of code from various other DeFi projects, completely unaudited and without any safety hatches or deposit limits. For all intents and purposes a completely reckless enterprise. Despite that at its peak it had over $500m locked in it!</p>

<p>For a technical explanation of the bug read <a href="https://medium.com/@yamfinance/yam-post-rescue-attempt-update-c9c90c05953f">their post</a>. In short the bug made it impossible for the YAM holders to reach quorum on anything so essentially the governance part of the protocol was broken and without it the entire protocol could no longer function.</p>

<p>Once people realized that, the market cap of YAM went within minutes from $60m to 0. Everyone left holding YAM they bought took a loss as they can’t sell it, so did uniswap liquidity providers as they took a loss every time someone sold YAM through them.</p>

<h3 id="could-this-have-been-avoided">Could this have been avoided?</h3>

<p>ABSOLUTELY</p>

<p>There were multiple warnings from many prominet people in the crypto sector including myself that this is going to end in tears. The minimum precaution that could have been taken is:</p>

<ul>
  <li>Write contract tests</li>
  <li>Have some sort of security audit of the code</li>
  <li>IF you claim it’s an experiment then treat it as such by:
    <ul>
      <li>Putting deposit limits in the code to protect your users</li>
      <li>Put an escape hatch in the code to protect your users.</li>
    </ul>
  </li>
</ul>

<h3 id="ponzi">Ponzi</h3>

<p>What’s worse is that from the tokenomics of YAM it was obvious that this was a ponzi game. Note the difference between ponzi game and ponzi scheme as explained in <a href="https://jpkoning.blogspot.com/2018/05/ethereum-is-full-of-ponzis-is-that.html">this</a> article.</p>

<p>Every 12 hours the total supply of the token increased but the amount held by each user stayed the same through a process called rebasing. The first farmers were incentivized to pump and shill YAM via social media so they can find victims onto whom to dump their tokens after the rebase. The new holders had the exact same incentives to pump it even more so they can in turn dump their bags onto the poor sods after the second rebase. And so on and so forth.</p>

<p>It was a “fair” and transparent ponzi, but a ponzi nonetheless. And with the amount of due dilligence people do in Crypto I am 100% certain that most of the people who got shilled into it did not realize that and lost money as a result.</p>

<h3 id="shilling-in-twitter">Shilling in Twitter</h3>

<p>What I personally found <strong>absolutely disgusting</strong> was the incessant amount of shilling of YAM in Twitter by many people in the ethereum community whom I actually respect who were also farming it.</p>

<p>It’s inexcusable, reckless and irresponsible. They were shilling a protocol that had not seen any production use yet, had unaudited code, no tests, no deposit limits or anything. They were doing so only to get more people into the Ponzi game to sustain their profits and dump their bags onto them.</p>

<p>I sincerely hope lessons are now learned. If you are shilling an unaudited insecure ponzi you are part of the problem of why this sector is not taken seriously. We can’t have such irresponsible behavior if we are ever going to reach mass adoption.</p>

<h3 id="what-did-it-cost-us">What did it cost us?</h3>

<p><img src="https://blog.rotki.com/public/post8/yamcrash.jpeg"></p>

<p>Some people lost a lot of money</p>

<ul>
  <li>Marketcap dropped from $60m to $0.</li>
  <li>People who bought YAM are left holding a hot potato, got burned and lost everything they invested.</li>
  <li>Uniswap liquidity providers lost money due to providing liquidity for sellers of a dying token.</li>
  <li>Lots of money in gas fees (300+ gwei) for nothing</li>
</ul>

<p>The rest of the non yam farming ethereum users were left with 300 gwei gas prices and could not really use the ethereum blockchain.</p>

<p>And finally and most importantly, outsiders roll their eyes and we lose credibility. Every nocoiner I know that I tried to explain this to just get their view that crypto is only for scams and ponzi schemes reinforced. Can you blame them?</p>



<p>If you are to keep anything from this post as a take-home message let it be this section. DeFi is good and is here to stay. We just all need to be more responsible about it.</p>

<h2 id="responsible-defi-user">Responsible DeFi user</h2>

<p>As a user don’t rush into every new thing that pops up and promises amazing 100%+ returns. Do you due dilligence, demand audit reports, ask people in the community about the history and portfolio of the founders of the protocol and if possible read the code and understand the tokenomics. DYOR. If something sounds too good to be true that’s because it’s probably a scam or a ponzi.</p>

<h2 id="responsible-defi-founder">Responsible DeFi founder</h2>

<p>As a founder/developer for the love of god DO NOT TEST IN PRODUCTION. Be responsible. Users do not heed warnings, or disclaimers. If it’s an experiment and you want to experiment in the mainnet that’s fine. Then put deposit limits and centralized escape hatches for the first X months. The safety of your users is your responsibility. Avoiding that responsbility through the veil of “just an experiment” won’t be accepted.</p>

<h2 id="towards-a-sustainable-defi-ecosystem">Towards a sustainable DeFi ecosystem</h2>

<p>It is only through responsible development and professionalism that this sector can mature. We won’t get any new users with the YOLO yield farming memes. For DeFi to fullfill its goals of a new permisionless financial system it needs to go mainstream. And it will not achieve that through ponzi games and chad memes in Twitter. This will only be achieved when the ecosystem is perceived by normies to be mature enough so that they can also come in and participante in it. Let’s all then do our part to advance the ecosystem through responsible building and sustainable development and build a new financial system for the many and not for the few.</p>



<p>My name is <a href="https://twitter.com/LefterisJP">Lefteris Karapetsas</a>. I am the founder of <a href="https://rotki.com/">Rotki</a>. It is a project that deals with DeFi, among other things, and believes in the dream of a sustainable permissionless new financial system. We are a portfolio tracker and accounting tool that respect our users’ privacy and we are in this game for the long run and not to scam our users for short term gain.</p>

<p>Here is how you can help us:</p>

<ul>
  <li>Try out Rotki’s <a href="https://github.com/rotki/rotki/releases">latest release</a> and use it daily.</li>
  <li><a href="https://rotki.com/products/">Buy</a> a premium subscription to unlock awesome premium features and also support our development.</li>
  <li>Provide us with <a href="https://github.com/rotki/rotki/issues">feedback</a> in the form of bug reports and feature requests.</li>
  <li><a href="https://github.com/rotki/rotki">Star</a> our Github repo and <a href="https://twitter.com/rotkiapp">follow</a> us on Twitter.</li>
  <li>Chat with us and other users of Rotki in <a href="https://discord.gg/aGCxHG7">Discord</a> or in <a href="https://t.me/rotkiportfolio">Telegram</a>.</li>
  <li>Spread the word so that more people get to try and use Rotki and learn how to both manage their finances but also how to protect the privacy of their financial data.</li>
</ul>

</div>

    </div></div>]]>
            </description>
            <link>https://blog.rotki.com/2020/08/13/sustainable-defi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143042</guid>
            <pubDate>Thu, 13 Aug 2020 13:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube's persistent flaws make it a hard app to love]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142790">thread link</a>) | @whalabi
<br/>
August 13, 2020 | https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love | <a href="https://web.archive.org/web/*/https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
      <div>
  <h2 id="the-ludicrousness-of-being-forced-to-watch-youtube-in-480p-on-a-4k-tv">The ludicrousness of being forced to watch YouTube in 480p on a 4K TV</h2>

<p>To watch YouTube videos from my phone, which is where I find them, on my TV, which is where I want to watch them, I’ve long since thrown up my hands and given up using the Cast function of the app. Every time I do, the video shows in 480p, even though I have a fiber connection on which YouTube never buffers. If I change the resolution to 1080p, YouTube stubbornly continues to play the video in a resolution that belongs in the 90s. The issue is <a href="https://support.google.com/chromecast/thread/2308994?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/chromecast/thread/2308994?hl=en">widespread</a>, and pre-dates YouTube’s limitations put in place during the pandemic. My TV is an Android TV, made for Google integration with a built-in YouTube app, and my phone is a Pixel phone. Partially chosen with the hope that they’d work well together.</p>

<p>My connection and TV are perfectly capable of playing the video in 1080p, as I learnt when I discovered a clumsy, irritating workaround: adding videos to my Watch Later list on my phone, then opening the YouTube app on my TV, and fumbling through its clumsy interface with a clumsy remote to pick them up again directly on the TV. Plays in 1080p just fine, no buffering.</p>

<figure><img alt="Thousands of YouTube users frustrated with a long-lived bug" width="840" height="593" src="https://i.imgur.com/zD5nKkS.png"><figcaption>Thousands of YouTube users frustrated with a long-lived bug</figcaption></figure>

<h2 id="have-some-captions-with-that">Have some captions with that</h2>

<p>Even when I’ve given in and kept casting blurry videos, a bizarre issue crops up. After watching for a lengthy period of time, maybe an hour or two, YouTube will decide to pop up English captions over an English video while watching on my English account. I’ll shake my head and switch them off; thankfully at least that setting works even if the quality setting doesn’t. Problem is, when the next video in the queue starts playing, the captions switch themselves back on, for every video thereafter. It’s only rectified by disconnecting my phone from my TV, which loses my queued videos, and starting again. This has been happening for many users, and shockingly, <a href="https://support.google.com/youtube/thread/38916902?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/38916902?hl=en">since 2013</a>.</p>

<p>I can only imagine there’s some kind of complicated machine learning going on here - after all YouTube seems to apply fuzzy logic when it decides to turn captions on or off by itself - the captions come on for some non-English videos but not others. It works a lot of the time and seems fairly smart, but not smart enough: they come on only some of the time I watch a K-pop music video, even by the same artist, for example. Every time this happens, I turn off the captions and rewind the video, providing plenty of data, which I’m sure Google is dutifully recording, about my captioning habits, data it could be using to decide whether to override my choices and turn them back on incessantly.</p>

<p>In a pre-ML world, you might code the captions to come on for non-English videos on an English account, perhaps making a different decision based on music videos, and provide a setting, so the user can decide. This would perfectly suit my needs. The behaviour would be predictable, and in my control. This is a problem with the state of ML these days: the decision is completely opaque, inevitably flawed, and non-overridable.</p>

<h2 id="if-you-cant-guess-just-let-me-choose">If you can’t guess just let me choose</h2>

<p>Playing videos directly on my phone is just as frustrating. Much of the time (but not all of the time) I choose something to watch, it’s 480p on my fiber connection which never buffers. Sometimes the video plays in 1080p, but whether it does or not is completely unpredictable. Now everytime I play a video I immediately open the quality settings and change it over to 1080p and rewind, if it isn’t already. It appears to be happening to <a href="https://support.google.com/youtube/thread/14927224?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/14927224?hl=en">plenty</a> of <a href="https://www.reddit.com/r/youtube/comments/ae5utz/auto_quality_setting_keeps_defaulting_to_the/" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://www.reddit.com/r/youtube/comments/ae5utz/auto_quality_setting_keeps_defaulting_to_the/">users</a>.</p>

<p>If this is the result of YouTube attempting to intelligently guess a resolution that won’t buffer, it’s failing miserably. Were they to provide an option to always stream at a minimum 1080p, users’ experience would be much better - they could even choose auto if they want to let YouTube decide for them. Instead YouTube makes a decision for me with an invisible process I have no say in.</p>

<figure><img alt="YouTube’s widely reviled video suggestions" width="775" height="530" src="https://i.imgur.com/WpPKYs4.jpg"><figcaption>YouTube’s widely reviled video suggestions</figcaption></figure>

<p>Users often take a back seat on YouTube. One of the issues in YouTube’s support forums with the <a href="https://support.google.com/youtube/thread/11285006?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/11285006?hl=en">most upvotes</a> concerns the recommended video thumbnails which can overlap the last <a href="https://support.google.com/youtube/answer/6388789?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/answer/6388789?hl=en">5-20 seconds</a> of the video you chose to watch, causing what is often a significant interruption, or in the case of the support thread above, a critical penalty save in a soccer match. Some argue that it’s up to the uploader to add these or not. It’s up to YouTube whether they appear over the last 1 second or 20, or appear under a video rather in massive intrusive thumbnails over the video. I pay for YouTube, but I have no control over these. If it’s just being provided in the user’s interest, why not give us the option to switch them off?</p>

<h2 id="play-music-or-youtube-music">Play Music or YouTube Music</h2>

<p>Google Play Music is shutting down in favor of YouTube Music, both are services I’ve used for years and pay for. Play Music is different in that it stores your own uploaded music, from back when people had such things. As it’s shutting down, these uploads are being transferred across to YouTube Music. It turns out you <a href="https://support.google.com/youtubemusic/thread/45163028?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtubemusic/thread/45163028?hl=en">can’t transfer your uploaded music to a “Brand account”</a> - I’m not a brand, I have an account which doesn’t use my real name because I prefer to remain anonymous amongst, well, YouTubers. This was made possible when Google <a href="https://www.theguardian.com/technology/2014/jul/16/youtube-trolls-google-real-name-commenter-policy" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://www.theguardian.com/technology/2014/jul/16/youtube-trolls-google-real-name-commenter-policy">backtracked</a> after the disastrous ruckus that began when they tried to enforce a real-name policy.</p>

<p>But it also meant that users ended up with 2 YouTube accounts, unwittingly, one with their Google-set real name, and a so-called brand account. A problem arose. In YouTube Music, I have one account with all my music history, likes, favorites, and recommendations, and another with my substantial uploaded music library. Which means I can’t benefit from recommendations based on my history, without rebuilding it all over again with my real name account (which I’d rather not do, in any case, but have no power over.)</p>

<p>In the <a href="https://support.google.com/youtubemusic/thread/45163028?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtubemusic/thread/45163028?hl=en">YouTube support thread</a> announcing this, Hazel from TeamYouTube happily says “If you have any more questions, let us know in the comments below!”, then received a critical comment, and promptly locked the thread.</p>

<h2 id="let-users-have-some-control-in-the-apps-they-use">Let users have some control in the apps they use</h2>

<p>YouTube, like many big tech companies in the ML age, are using algorithms to govern the experience of their billions of users with inner workings that are invisible to their users, frequently work against their interest, and are unable to be overridden. Worse, whether it’s a bug that’s been around since 2013, a smart AI which isn’t so smart, or a crummy user experience decision, users aren’t being heard or their choices respected.</p>

</div>
</div>
    </div>

          

  </div></div>]]>
            </description>
            <link>https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142790</guid>
            <pubDate>Thu, 13 Aug 2020 12:51:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Significant JavaScript projects from 2006 to 2020]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24142462">thread link</a>) | @michaelrambeau
<br/>
August 13, 2020 | https://bestofjs.org/timeline | <a href="https://web.archive.org/web/*/https://bestofjs.org/timeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bestofjs.org/timeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142462</guid>
            <pubDate>Thu, 13 Aug 2020 12:04:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I'm excited for in Neovim 0.5.0: Language Server Protocol]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142041">thread link</a>) | @numToStr
<br/>
August 13, 2020 | https://nathansmith.io/posts/neovim-lsp | <a href="https://web.archive.org/web/*/https://nathansmith.io/posts/neovim-lsp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The next major release of <a href="https://neovim.io/">Neovim</a>, 0.5.0, is currently in development and has five <a href="https://neovim.io/roadmap/">promised features</a>:</p>
<blockquote>
<ul>
<li>Lua remote plugin host</li>
<li>Lua user-config: init.lua</li>
<li>Treesitter syntax engine</li>
<li>LSP client for code navigation, refactoring</li>
<li>Extended marks (text properties, decorations, virtual text)</li>
</ul>
</blockquote>
<p>Enticed by offerings of the Neovim roadmap, I decided to install the nightly builds of Neovim and try them for myself. This post will be the first in a series where we focus on the features of Neovim 0.5.0. Today, we’ll look at Neovim’s Language Server Protocol.</p>
<h2 id="what-is-language-server-protocol">What is Language Server Protocol?<a href="#what-is-language-server-protocol" aria-label="what is language server protocol permalink"></a></h2>
<p>The <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a>, or LSP, is a JSON RPC protocol introduced in 2016 by Microsoft that defines how an editor should talk to a language server. What is a language server? It’s a small program that runs locally on your computer that can provide information about the code you’re writing. The idea is that you tell the LSP where your project is, it scans all your files, and then has an understanding about your project. It can then provide go-to-definition, type info, compiler errors, completion suggestions, and more back to your editor. As the name implies, each language server generally supports only one language. There’s a <a href="https://langserver.org/">community maintained list</a> of major LSP implementations.</p>
<p>That’s cool, you say, but my editor already supports these features. Why should I start using a language server?</p>
<p>That’s a good question. If your editor already supports typo info, auto-completion, and everything else, you likely don’t need a language server. In fact, the LSP might slow you down – it’s likely a built-in editor feature would be faster than your editor making an RPC request to a server running on your computer.</p>
<p>However, the main advantage of the LSP is that it brings together developers who use different editors. The LSP is editor agnostic – if your editor speaks the protocol, it can talk to the server running. That is, instead of developers having to create an Emacs JavaScript plugin, and a Vim JavaScript plugin, and a VS Code JavaScript plugin, they need only create a single JavaScript language server and language server plugins for each editor.</p>
<p><a href="https://langserver.org/">Langserver.org</a> calls this problem “the matrix”, and it’s easy to see why. If we have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> languages and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> editors, instead of making <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n \times m</annotation></semantics></math></span></span> integrations we only have to create <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> language servers plus <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> editor LSP plugins.</p>
<figure>
    <span>
      <span></span>
  <img alt="The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily." title="The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily." src="https://d33wubrfki0l68.cloudfront.net/12005bad22eafa1b9bdcf4d1d17015b714bded83/b3443/static/96b7982529b79bd6a4f0b7a177abe150/c5bb3/matrix-problem.png" srcset="https://d33wubrfki0l68.cloudfront.net/f19838a5a467210f204603091fc65df562fb57e3/169f6/static/96b7982529b79bd6a4f0b7a177abe150/04472/matrix-problem.png 170w, https://d33wubrfki0l68.cloudfront.net/3424f4fbddec6d16f90e57176654b074aa5cbe2e/17ef2/static/96b7982529b79bd6a4f0b7a177abe150/9f933/matrix-problem.png 340w, https://d33wubrfki0l68.cloudfront.net/12005bad22eafa1b9bdcf4d1d17015b714bded83/b3443/static/96b7982529b79bd6a4f0b7a177abe150/c5bb3/matrix-problem.png 680w, https://d33wubrfki0l68.cloudfront.net/673668b2c637dfeded44b6dc09b1106f9110a2d6/f327d/static/96b7982529b79bd6a4f0b7a177abe150/b12f7/matrix-problem.png 1020w, https://d33wubrfki0l68.cloudfront.net/f2a86b00c660bf46bdd7561e959c2f3e33179bbb/fe4cf/static/96b7982529b79bd6a4f0b7a177abe150/b5a09/matrix-problem.png 1360w, https://d33wubrfki0l68.cloudfront.net/15df038d58e7fa53d1fcbcf5a31b8c4c7d70d78c/91c2c/static/96b7982529b79bd6a4f0b7a177abe150/f2f8c/matrix-problem.png 1490w" sizes="(max-width: 680px) 100vw, 680px" loading="lazy">
    </span>
    <figcaption>The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily.</figcaption>
  </figure>
<p>Okay, you tell me, so now you’ve just proved <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s law</a> also applies to open source. But you didn’t answer my original question: why should I use a language server?</p>
<p>Since the community of all JavaScript developers is a superset of all JavaScript Vim developers, this means that you should see more developers working on a JavaScript language server as opposed to a JavaScript Vim plugin. This should ideally mean a generally better language server.</p>
<p>Additionally, since the community of all Vim developers is also better than all JavaScript Vim developers, this should mean better LSP integration support. Vim users can unite and benefit around building a common language server, even if the day-to-day languages they use are different.</p>
<p>While this may not necessarily be true for all editor plugins, it certainly is for Vim. Vim completion can be done for already existing keywords, dictionary words, ctags results, or omnicomplete. Of these, ctags and omnicomplete are the most IDE-like. In my experience, while ctags is pretty good, it can often give inaccurate results if the same name is used in different contexts across a codebase. And omnicomplete is often left neglected: JavaScript omnicomplete hasn’t been <a href="https://github.com/vim/vim/blob/5be4ceecea5520265066eac972460ebb1cdf05e7/runtime/autoload/javascriptcomplete.vim">updated since 2017</a>, a sign of the matrix problem.</p>
<h2 id="upgrading-to-neovim-nightly">Upgrading to Neovim Nightly<a href="#upgrading-to-neovim-nightly" aria-label="upgrading to neovim nightly permalink"></a></h2>
<p>Okay, so I’ve convinced you to try out an LSP. How does it work in Neovim?</p>
<p>Neovim has <a href="https://github.com/neovim/neovim/wiki/Installing-Neovim">great install instructions</a> for most systems (macOS, Windows, popular Linux distros). I’m on macOS, so I ran:</p>
<div data-language="text"><pre><code>brew install --HEAD neovim</code></pre></div>
<p>From there, you can confirm that the installed version of Neovim has LSP support with <code>:h lsp</code>.</p>
<h2 id="a-note-on-lua">A note on Lua<a href="#a-note-on-lua" aria-label="a note on lua permalink"></a></h2>
<p>Recall the first two features of 0.5.0:</p>
<blockquote>
<ul>
<li>Lua remote plugin host</li>
<li>Lua user-config: init.lua</li>
</ul>
</blockquote>
<p>Vimscript, or VimL, is the de facto configuration of Vim. However, it’s also <a href="https://www.reddit.com/r/vim/comments/1bf672/why_does_viml_suck/">not that great of a language</a>: there are lots of odd quirks and performance issues that come with it. As a result, the Neovim core developers decided to add support for Lua in Neovim. Justin M. Keyes goes over the rationale for this decision in a <a href="https://youtu.be/Bt-vmPC_-Ho">great VimConf presentation</a>. The tl;dr is that Lua is a fast language that already exists and is simpler to learn than Vimscript.</p>
<p>Why does this matter? We were going to go over the LSP today, not Lua, right?</p>
<p>Yes and no. Just as Vimscript is the language for which Vim apis are exposed, Lua is becoming the preferred language for which Neovim apis are being exposed. The LSP api is in Lua, meaning we’ll have to write a little bit of Lua to set it up.</p>
<p>If you haven’t written any Lua, don’t fear! Ample code examples will be provided for your copy/pasting pleasure. Lua is a fairly easy language to read if you know any programming language already. If you’re interested in more Lua, <a href="https://learnxinyminutes.com/docs/lua/">Learn X in Y minutes</a> is a great place to start.</p>
<p>However, most Vimmers don’t currently have any Lua configuration files lying around, so we need to cover the basics of going from an <code>init.vim</code> Vimscript file into triggering Lua code. There are a couple ways to do this.</p>
<h3 id="lua-in-your-vim">Lua in your vim<a href="#lua-in-your-vim" aria-label="lua in your vim permalink"></a></h3>
<p>You can put Lua code directly in vimscript files, like so:</p>
<div data-language="vim"><pre><code>lua <span>&lt;</span><span>&lt;</span> EOF
<span>print</span><span>(</span><span>"hello world"</span><span>)</span>
EOF</code></pre></div>
<p>This is great for small to medium snippets of Lua code.</p>
<h3 id="lua-in-a-file">Lua in a file<a href="#lua-in-a-file" aria-label="lua in a file permalink"></a></h3>
<p>You can also tell Neovim to source lua files, given that that fit a directory structure. In Vimscript:</p>

<p>This will look for the file: <code>nvim/lua/lsp/init.lua</code>. This is great for larger, self-contained chunks of Lua code. I prefer this approach and use it in <a href="https://github.com/nathunsmitty/.config">my dotfiles</a>, since it gives me access to Lua syntax highlighting, linters, etc. while editing.</p>
<h2 id="configuring-support-for-servers">Configuring Support for Servers<a href="#configuring-support-for-servers" aria-label="configuring support for servers permalink"></a></h2>
<p>Neovim provides the LSP client built-in, but it needs to which language servers to run and where on your machine they’re located. There’s a <a href="https://neovim.io/doc/user/lsp.html#lsp-core">Lua api</a> provided that allows you to do this; the following will trigger JavaScript LSP:</p>
<div data-language="lua"><pre><code><span>local</span> root_dir <span>=</span> <span>buffer_find_root_dir</span><span>(</span>bufnr<span>,</span> <span>function</span><span>(</span>dir<span>)</span>
  <span>return</span> <span>is_dir</span><span>(</span><span>path_join</span><span>(</span>dir<span>,</span> <span>'node_modules'</span><span>)</span><span>)</span>
<span>end</span><span>)</span>

<span>local</span> bufnr <span>=</span> vim<span>.</span>api<span>.</span><span>nvim_get_current_buf</span><span>(</span><span>)</span>
<span>local</span> javascript_lsp_config <span>=</span> <span>{</span>
  name <span>=</span> <span>"javascript"</span><span>;</span>
  cmd <span>=</span> <span>{</span> <span>path_join</span><span>(</span>os<span>.</span><span>getenv</span><span>(</span><span>"JAVASCRIPT_LANGUAGE_SERVER_DIRECTORY"</span><span>)</span><span>,</span> <span>"lib"</span><span>,</span> <span>"language-server-stdio.js"</span><span>)</span> <span>}</span><span>;</span>
<span>}</span>

<span>local</span> new_config <span>=</span> vim<span>.</span><span>tbl_extend</span><span>(</span><span>"error"</span><span>,</span> javascript_lsp_config<span>,</span> <span>{</span>
  root_dir <span>=</span> root_dir<span>;</span>
<span>}</span><span>)</span>
client_id <span>=</span> vim<span>.</span>lsp<span>.</span><span>start_client</span><span>(</span>new_config<span>)</span>
vim<span>.</span>lsp<span>.</span><span>buf_attach_client</span><span>(</span>bufnr<span>,</span> client_id<span>)</span></code></pre></div>
<p>(This is adapted from <a href="https://neovim.io/doc/user/lsp.html#lsp-extension-example">an example</a> in the LSP manual.)</p>
<p>However, this is a lot of configuration. Is there a better solution?</p>
<h3 id="nvim-lsp-common-server-configuration">nvim-lsp: Common Server Configuration<a href="#nvim-lsp-common-server-configuration" aria-label="nvim lsp common server configuration permalink"></a></h3>
<p>To give a higher level of abstraction for end users who just want to start using a LSP, Neovim provides an official plugin: <a href="https://github.com/neovim/nvim-lsp">nvim-lsp</a>. This is a collection of common LSPs with integrations ready to go. Let’s install it!</p>
<div data-language="vim"><pre><code>
Plug <span>'neovim/nvim-lsp'</span>

<span>call</span> minpac#<span>add</span><span>(</span><span>'neovim/nvim-lsp'</span><span>,</span> <span>{</span><span>'type'</span><span>:</span> <span>'opt'</span><span>}</span><span>)</span>
packadd nvim<span>-</span><span>lsp</span></code></pre></div>
<p>Note that if you’re using a Vim 8’s native package manager (or a package manager that leverages the native package manager, like <a href="https://github.com/k-takata/minpac">minpac</a>), then you need to add the line <code>packadd nvim-lsp</code>. This is because Neovim <a href="https://github.com/neovim/neovim/issues/12670">currently does not source Lua plugins before your <code>init.vim</code> file</a>, meaning that your LSP config will execute before nvim-lsp is loaded, giving errors. With an older <a href="https://neovim.io/doc/user/options.html#'runtimepath'">runtimepath</a>-based plugin manager like <a href="https://github.com/junegunn/vim-plug">vim-plug</a>, this is not an issue.</p>
<p>Now that we’ve downloaded nvim-lsp, we can configure a language server. To set up the <a href="https://github.com/theia-ide/typescript-language-server">TypeScript language server</a>, we simply need to add:</p>
<div data-language="vim"><pre><code>require<span>'nvim_lsp'</span><span>.</span>tsserver<span>.</span>setup<span>{</span><span>}</span></code></pre></div>
<p>There are also <a href="https://github.com/neovim/nvim-lsp#tsserver">configuration options</a> for which filetypes to run it on, how to detect your project’s root directory, etc.</p>
<p>While we’re configuring stuff, let’s add some nice, vim-like shortcuts for LSP features:</p>
<div data-language="vim"><pre><code>nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>gd</span> <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>definition</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gh     <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>hover</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gD    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>implementation</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>&lt;</span><span>c</span><span>-</span><span>k</span><span>&gt;</span> <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>signature_help</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> 1gD   <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>type_definition</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>gr</span>    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>references</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> g0    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>document_symbol</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gW    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>workspace_symbol</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span></code></pre></div>
<p>Note that these mappings override some Vim defaults, so in order to ensure they only work on</p>
<p>Awesome! However, unless you have the TypeScript language server already installed, you still won’t notice any LSP features. This is because you need to install the language server. The bad news is that each language server has its own installation instructions. The good news is the nvim-lsp takes care of it by providing a <code>LspInstall</code> command. All we have to do is run:</p>

<p>and we’re in business!</p>
<h3 id="even-more-abstractions">Even more abstractions<a href="#even-more-abstractions" aria-label="even more abstractions permalink"></a></h3>
<p>There are a few other optional plugins for Neovim that will improve your LSP quality-of-life. These are by no means necessary, you could implement them with a bit of Vimscript and Lua, but they do provide some more polish to the experience.</p>
<h4 id="completion-nvim">completion-nvim<a href="#completion-nvim" aria-label="completion nvim permalink"></a></h4>
<p><a href="https://github.com/nvim-lua/completion-nvim">completion-nvim</a>, as the name implies, is an autocompletion plugin. It’s similar to something like <a href="https://github.com/ycm-core/YouCompleteMe">YouCompleteMe</a> or <a href="https://github.com/Shougo/deoplete.nvim">Deoplete</a> in that it gives auto popup and other improvements on top of Neovim’s LSP api, as well as some other sources.</p>
<div data-language="vim"><pre><code><span>call</span> minpac#<span>add</span><span>(</span><span>'nvim-lua/completion-nvim'</span><span>,</span> <span>{</span><span>'type'</span><span>:</span> <span>'opt'</span><span>}</span><span>)</span>
packadd completion<span>-</span>nvim</code></pre></div>
<div data-language="lua"><pre><code><span>local</span> on_attach <span>=</span> <span>function</span><span>(</span><span>)</span>
  require<span>'completion'</span><span>.</span><span>on_attach</span><span>(</span><span>)</span>
  require<span>'diagnostic'</span><span>.</span><span>on_attach</span><span>(</span><span>)</span>
<span>end</span>
require<span>'nvim_lsp'</span><span>.</span>pyls<span>.</span><span>setup</span><span>{</span>on_attach<span>=</span>on_attach_vim<span>}</span></code></pre></div>
<h4 id="lsp-statusnvim-statusline-support">lsp-status.nvim: Statusline Support<a href="#lsp-statusnvim-statusline-support" aria-label="lsp statusnvim statusline support permalink"></a></h4>
<p><a href="https://github.com/nvim-lua/lsp-status.nvim">lsp-status.nvim</a> is a Lua plugin that allows you to display information from …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nathansmith.io/posts/neovim-lsp">https://nathansmith.io/posts/neovim-lsp</a></em></p>]]>
            </description>
            <link>https://nathansmith.io/posts/neovim-lsp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142041</guid>
            <pubDate>Thu, 13 Aug 2020 11:07:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business logic is the weakest link in Low-Code security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141927">thread link</a>) | @xiwenc
<br/>
August 13, 2020 | https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/ | <a href="https://web.archive.org/web/*/https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Over the past 5 years <a href="https://trends.google.com/trends/explore?date=2015-01-01%202020-08-02&amp;q=%2Fg%2F11c6cx4nrr">interest in low-code increased 100 folds</a> according to Google Trends:
<img src="https://cinaq.com/media/low-code-trends.png" alt="Low-code development trends">
This correlates with human psychology eager to optimise for efficiency in everything and building software solutions is no exception. As programming is becoming easier and more accessible, in the future, anyone should be able solve their own information automation challenges. Low-code is a relatively new movement that tries to enable those citizen developers with the right tooling lowering the barrier to build applications without writing traditional code. Because most of my professional experience with low-code is around <a href="https://www.mendix.com/">Mendix</a>, I will use it as reference through out this article.</p>

<p>First computer programs were written in machine code by few experts in the early days. This programming ability felt like a super power to many. Just like the Industrial age boosted the human civilisation, the Information Technology age we are currently in is helping the human race reach new heights. Programming languages are invented or improved to enable more efficient or better programming paradigms. This trend in <a href="https://en.wikipedia.org/wiki/History_of_programming_languages">programming languages timeline</a> is recently leading towards visual programming. In the industry this idea is marked as <a href="https://en.wikipedia.org/wiki/Low-code_development_platform">low-code platforms</a>. To me this is currently the highest programming level because of its high productivity characteristics. Low-code is in a nutshell an unification of deployment and composable building blocks nicely packed to play well together reducing the feedback loop at development and runtime.</p>

<p>The cost of higher abstraction which often correlates with higher productivity is <a href="https://en.wikipedia.org/wiki/High-level_programming_language#Abstraction_penalty">Abstraction penalty</a>. As we move up in the pyramid depicted below, we accomplish more with fewer efforts. That little effort however translates to more execute computing instructions. Due to this fact we loose optimisations and also unaware of the extra assumptions made in between. This problem increases more as applications grow larger and depend on libraries. No matter how well documented the libraries are, they are again abstractions of the actual implementation which might be inaccurate or the user of such library might not know or understand the full extends of the functionalities being leveraged on.</p>
<p><img src="https://cinaq.com/media/low-code-productivity-pyramid.png" alt="Higher programming languages result in higher computational instructions count"></p>

<p>A critical aspect of abstraction penalty is the unawareness of implied behaviours. Citizen developers (Low-code developers) leverage a lot from low-code platform itself; often with insufficient experience and knowledge of the underlaying runtime environment. This is a natural cause because these platforms were designed and promoted  for easy adoption. In the case of Mendix a typical security pitfall is negligence of <a href="https://docs.mendix.com/refguide/access-rules">entity access on attributes level</a>. Developers often focus on getting the program to work, in this particular case, a developer would grant access to all users. No matter the seniority, people make mistakes and forget access rule must be refined. In low-code platform like this, it’s very easy to make mistakes and leave open major security holes.</p>
<p>Platforms like Mendix already has <a href="https://www.mendix.com/evaluation-guide/enterprise-capabilities/security">security covered very well</a>. However with a strong platform, you can still build vulnerable applications because the platform does not know or understand your data risk levels. Therefore the weakest link is your business logic on a low-code platform.</p>
<p><img src="https://cinaq.com/media/low-code-mendix-security.png" alt="Business logic is weakest link with Mendix"></p>
<p>A typical example is: developer gives all access to credit card number attribute in the application model. The developer makes a remark to fine tune the access rules later but forgets to do so. Due to time pressure, testers mostly focussed on the happy use cases which did not reveal the CC information leak.</p>
<p>Therefore it’s crucial to have tooling to help detect these mistakes before they hit production. A tool that could reveal more that meets the eye for developers and testers alike. In Mendix, this would mean bypass the View (from <a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller">Model View Controller</a>) showing all accessible data and function calls for a given user. There are few challenges here:</p>
<ul>
<li>How to extensively and automatically collect these data</li>
<li>How to make sense of the collected data to identify security weaknesses</li>
<li>Finally a repeatable and preferably incremental method to assess the security risk coverage</li>
</ul>
<p>Often pentest consultants are called in to assess the security risks of low-code applications. However this process is very labor intensive and error prone. As pointed out, higher generation languages like low-code has a bigger attack vector (related to number of computational instructions together with rapid feature building) requires extensive manual work.</p>

<p>In this article we learned low-code is an upcoming trend and it helps companies innovate faster by increasing the productivity of its developers. However, with the higher abstraction levels, it’s also easier to make security mistakes leaving the application vulnerable to attacks. As the citizen developers group grows, we need tooling in place to help identity security risks with the same low threshold as it requires to develop an app on a low-code platform.</p>

			</div></div>]]>
            </description>
            <link>https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141927</guid>
            <pubDate>Thu, 13 Aug 2020 10:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Danger of Having a B-Team]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141704">thread link</a>) | @svmanager
<br/>
August 13, 2020 | https://staysaasy.com/management/2020/08/11/Team-Topology.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/08/11/Team-Topology.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Make the seniority, talent, and quality-of-mission of your organization’s teams as consistent as possible. The pretstige of team missions and their capability should all be comparable. There should be no dramatic differences between the caliber of your teams.</p>

<h2 id="the-problem">The Problem</h2>

<p>It’s not uncommon for a leader to bucket what needs to get done as a set of hard, medium, and easy missions. The next step they’ll take is to assemble teams of respectively different talent levels and seniority to handle those challenges of different prestige levels. The outcome are teams that vary in their ability and the importance (real or perceived) of their mission. You’ve just turned your department into a caste system.</p>

<p>This creates lots of challenges:</p>
<ul>
  <li>People who are on low-caliber teams know it. This causes morale and retention issues.</li>
  <li>In some cases, people end up selling the company to recruits based off of what the prestigious teams are doing, only to place people into other teams. This causes morale and retention issues.</li>
  <li>The weak-mission teams will often not have a growth path to the highest levels. This essentially means it’s a transient team unless you hire people to stagnate. A great litmus test is: can every team support promotions to the highest level?</li>
  <li>You end up constantly having to field questions around internal transfers to the prestigious teams. Good managers tell the truth when people aren’t ready for the other team or when the team isn’t ready for them. Bad managers give little glimmers of hope that don’t reflect reality and lead to a long tail of frustration.</li>
  <li>Dysfunctional organizations will actually lower the hiring and promotion bars for lower caliber teams for political and morale reasons. This can lead to very, very bad outcomes like reducing the integrity of compensation bands or causing internal strife at the mis-match across teams.</li>
  <li>This set of variables is also very dangerous because internal processes of an organization are based on the people they’re serving. Different cohorts of people need different enablement, onboarding, rules, and rewards. Having major differences amongst teams means it’s harder to have one overarching culture and set of organizational mechanics.</li>
</ul>

<p>How do you fix this? Let’s go back and revisit some assumptions.</p>

<h2 id="assumption-1-we-have-hard-medium-and-easy-missions">Assumption 1: We Have Hard, Medium and Easy Missions</h2>

<p>People get this wrong all the time. When looking at the missions of a team, it’s not uncommon for a leader to have standard biases or an ego that leads to total miscalculations of the difficulty of certain missions.</p>

<p>An example is in software engineering, where leaders might view their team’s goals as fancy backend “hard stuff’’ and simple front-end “easy stuff”. That’s obviously bullshit. Think of all of the terrible UIs you encounter on a day to day basis. If frontend engineering was easy UI would be a solved problem.</p>

<p>Another example is when a leader or a team aren’t executing well on a part of their responsibilities and they end up saying that it just needs to be handled by some other team because it’s easy but distracting. In reality, if it’s easy they’d be doing a good job at it. This kind of thinking can lead teams to push away what is actually more important work in lieu of more interesting (or greenfield, or easy) work.</p>

<p>People often make bad calls on what’s difficult and what’s easy and then make things worse with the second, equally damaging assumption.</p>

<h2 id="assumption-2-easy-missions-should-be-done-by-lower-caliber-teams">Assumption 2: Easy Missions Should Be Done By Lower-Caliber Teams</h2>

<p>Leaders will then compound the problem by staffing teams to get the “easy missions” done with less senior or skillful talent. So they assume a problem is easy, understaff it, and then as things inevitably go wrong they end up blaming either the team, the mission, or anything else but the poor decisions that lead to a self-fulfilling prophecy.</p>

<h2 id="a-better-path">A Better Path</h2>

<p>To solve this problem, take a hard look at the topology of work you’re trying to get done:</p>
<ul>
  <li>If a <em>small</em> volume of work is much simpler than other tasks, you should add it into the responsibilities of your existing teams.</li>
  <li>If a <em>large</em> volume work is much simpler than other work- meaning it’d meaningfully distract your regular teams - you should either contract it out or you build an different organization to handle it.</li>
  <li>Sometimes you’ll have a team who has lower perceived prestigue because it doesn’t contain as many buzzwords or trendy technologies as other teams. Absent active efforts, that team will have a harder time hiring and retaining. To counteract this, you should make sure you’re overloading that team with talent, so that you make up for the team’s perceived mission prestigue with personel prestige.</li>
  <li>In all cases, expectation setting and integrity in decision making is critical. Don’t hire people into roles with the false hope of transferring to other teams if it’s not possible. Don’t transfer people to other teams if they’re not ready.</li>
</ul>

<h2 id="examples">Examples</h2>
<ul>
  <li>Your hot-stuff AI/ML startup has 4 high-powered product teams, but you keep having this pesky problem of a trickle of internal requests from the client-facing teams. You decide to create a team to just handle those requests. You figure it’s not that big of a problem and don’t want to distract your teams, so you hire a junior team to just handle that. You’ve just made a huge mistake. That team will be unhappy and have retention problems forever. You should have either contracted that work or found a process for your other teams to get it done.</li>
  <li>Your hot-stuff AI/ML startup has built out a customer portal that is getting a ton of traction. The work has meaningful challenges and growth opportunities, but it’s very different than your core team’s responsibilities. The people you hire, the promotion paths, the culture needed to execute well, and the evaluation criteria are existentially inconsistent with your other teams. You work with senior management to build out an entirely new organization to work on the portal. Great job, you’ve done the right thing. This was a lot of work that warranted a focused division to manage the mission.</li>
</ul>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/08/11/Team-Topology.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141704</guid>
            <pubDate>Thu, 13 Aug 2020 10:10:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Core Inflation Jumps by Most Since 1991]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24141694">thread link</a>) | @jules-jules
<br/>
August 13, 2020 | https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/ | <a href="https://web.archive.org/web/*/https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12687">
			<!-- .entry-header -->		<div>
			<p>
							<span>
					<a href="https://confoundedinterest.net/category/bubble/" rel="category tag">#bubble</a>, <a href="https://confoundedinterest.net/category/banking/" rel="category tag">Banking</a>, <a href="https://confoundedinterest.net/category/bernanke/" rel="category tag">Bernanke</a>, <a href="https://confoundedinterest.net/category/cmbs/" rel="category tag">CMBS</a>, <a href="https://confoundedinterest.net/category/cre/" rel="category tag">CRE</a>, <a href="https://confoundedinterest.net/category/ecb/" rel="category tag">ECB</a>, <a href="https://confoundedinterest.net/category/economy/" rel="category tag">Economy</a>, <a href="https://confoundedinterest.net/category/fannie-mae/" rel="category tag">fannie mae</a>, <a href="https://confoundedinterest.net/category/fed/" rel="category tag">Fed</a>, <a href="https://confoundedinterest.net/category/freddie-mac/" rel="category tag">Freddie Mac</a>, <a href="https://confoundedinterest.net/category/gdp/" rel="category tag">GDP</a>, <a href="https://confoundedinterest.net/category/housing/" rel="category tag">Housing</a>, <a href="https://confoundedinterest.net/category/inflation/" rel="category tag">Inflation</a>, <a href="https://confoundedinterest.net/category/mortgage/" rel="category tag">Mortgage</a>, <a href="https://confoundedinterest.net/category/pension/" rel="category tag">Pension</a>, <a href="https://confoundedinterest.net/category/powell/" rel="category tag">Powell</a>, <a href="https://confoundedinterest.net/category/reits/" rel="category tag">REITs</a>, <a href="https://confoundedinterest.net/category/treasuries/" rel="category tag">Treasuries</a>, <a href="https://confoundedinterest.net/category/treasury/" rel="category tag">Treasury</a>, <a href="https://confoundedinterest.net/category/uncategorized/" rel="category tag">Uncategorized</a>, <a href="https://confoundedinterest.net/category/volatility/" rel="category tag">Volatility</a>, <a href="https://confoundedinterest.net/category/yellen/" rel="category tag">Yellen</a>				</span></p><!-- .cat-links -->
			
			
			<p><span>
				<time datetime="2020-08-12T12:46:59-04:00">August 12, 2020</time><time datetime="2020-08-12T14:36:15-04:00">August 12, 2020</time>			</span>

			<span>1 Minute</span>		</p></div><!-- .entry-meta -->
	
	<div>
		
<p>Well, The Federal Reserve finally got its wish: INFLATION!</p>



<p><em>U.S. consumer prices&nbsp;rose&nbsp;in July by more than expected on a bounce in auto and apparel costs. <strong>The so-called core figure, which excludes volatile food and fuel costs, climbed 0.6% from the prior month, the biggest surge in almost three decades</strong>, according to a Labor Department report Wednesday. The headline figure also increased 0.6%, following the same gain in June. The trend reflects a rebound in demand for goods and services from the depths of the pandemic-induced lockdowns earlier this year</em>.</p>



<figure><img data-attachment-id="12691" data-permalink="https://confoundedinterest.net/coreinf/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coreinf" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<p>But on a YoY basis, core inflation rose only 1.6%.</p>



<figure><img data-attachment-id="12694" data-permalink="https://confoundedinterest.net/the-core-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the-core-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>







<figure><img data-attachment-id="12697" data-permalink="https://confoundedinterest.net/indl-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="indl-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<p>But rent inflation fell to 2.8% YoY, the lowest since 2015.</p>



<figure><img data-attachment-id="12698" data-permalink="https://confoundedinterest.net/rentcpi-2/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png" data-orig-size="736,529" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rentcpi" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<figure><img data-attachment-id="12709" data-permalink="https://confoundedinterest.net/ogd-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg" data-orig-size="329,750" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ogd-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=132" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=329" src="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=329" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg 329w, https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=66 66w, https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=132 132w" sizes="(max-width: 329px) 100vw, 329px"></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-08-12T12:46:59-04:00">August 12, 2020</time><time datetime="2020-08-12T14:36:15-04:00">August 12, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141694</guid>
            <pubDate>Thu, 13 Aug 2020 10:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Limiting Asynchronous Operations Concurrency in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141535">thread link</a>) | @ziir_hn
<br/>
August 13, 2020 | https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/ | <a href="https://web.archive.org/web/*/https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Today's post is about a little trick I have learned about 2years ago, and that I have since used numerous times in short Node.js scripts I had to write.<br>
It really isn't much, but I guess it may be helpful to others, and probably is an alright first JavaScript post on this blog.</p>
<blockquote>
<p>Say one has a list of things, and for every of these things, one needs to perform an asynchronous operation that returns a Promise, and be notified when all operations have been performed.<br>
How does one limit the number of asynchronous operations being performed conccurently? Without 3rd party dependencies and just a few lines of code?</p>
</blockquote>
<p>Are you seeing the problem yet? Let's build some context:</p>
<h3 id="we-have-a-list-of-99-things%2C-say-resource-identifiers">We have a list of 99 things, say resource identifiers <a href="#we-have-a-list-of-99-things%2C-say-resource-identifiers">#</a></h3>
<pre><code><span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span><br><span>&gt;</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>...</span> <span>99</span><span>]</span></code></pre>
<h3 id="for-each-of-these-things%2C-we-need-to-perform-an-asynchronous-operation">For each of these things, we need to perform an asynchronous operation <a href="#for-each-of-these-things%2C-we-need-to-perform-an-asynchronous-operation">#</a></h3>
<p>First, let's define the function that will perform said asynchronous operation:</p>
<pre><code><br><br><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span><br>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>      console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span><br>      <span>resolve</span><span>(</span><span>)</span><span>;</span><br>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span></code></pre>
<p>Now, we know that we need to call this function of every single thing out of our list of 99 things, every resource id we have in <code>ids</code>.<br>
Our first approach, would be to naively use <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array/map">Array.prototype.map</a> and <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Promise/all">Promise.all</a> and call it a day. But let's have a closer look to this innocent line of code and its implications:</p>
<pre><code><span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span><br>console<span>.</span><span>log</span><span>(</span><span>'All operations performed, moving on to something else now.'</span><span>)</span><span>;</span></code></pre>
<p><em>Note: we might arguably use <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Promise/allSettled">Promise.allSettled</a> in a real world scenario, but let's assume our asynchronous operations cannot fail.</em></p>
<p>Which we would give us the following complete script:</p>
<pre><code><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span><br>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span><br>    <span>resolve</span><span>(</span><span>)</span><span>;</span><br>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span><p><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span><br>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span><br>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></p><p>  <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span><br>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span><br>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span><br><span>}</span></p><p><span>run</span><span>(</span><span>)</span><span>;</span></p></code></pre>
<p>Now, let's run it:</p>
<pre><code>$ node async-operations-promise-all.js
</code></pre>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 338ms, moving on to something else now.
</code></pre>
<p>As we can see, ~all the asynchronous operations were performed <strong>concurrently</strong>, and sometimes, that's perfectly fine and exactly what we want.</p>
<p><em>Note: <code>Promise.all</code> only waits for all the <code>Promise</code>s to be resolved. The actual asynchronous operation is triggered by the function call from <code>Array.prototype.map</code>, creating a new <code>Promise</code> on each call.</em></p>
<h3 id="the-problem-of-performing-operations-concurrently">The problem of performing operations concurrently <a href="#the-problem-of-performing-operations-concurrently">#</a></h3>
<p>Now, let's assume that our <code>performAsyncOperation</code> really performs an HTTP request, an API Call, a database query, or really anything else that would either suffer or punish us for the load we push on to it. It might be a rate-limited API, or a fragile host.</p>
<p><em>Note: in the actual case of an HTTP request, or database query, the Web/Node.js/etc... API being used will already probably limit concurrency, of which value may or may not configurable, but let's assume that we cannot or do not want to change such settings.</em></p>
<p>In such cases, we simply cannot allow our script to perform all these operations concurrently, as it risks getting our API key revoked, our IP blocked, or the target host/database responding unreliably, etc... Thus we will be searching for a way to limit this concurrency to avoid such scenario.</p>
<p><em>Note: depending on the actual work performed by the asynchronous operation, performing many of these concurrently may also make the process running it consuming significant amount of CPU and/or memory resources on the machine it runs.</em></p>
<h3 id="a-solution%3A-performing-asynchronous-operations-sequentially">A solution: performing asynchronous operations sequentially <a href="#a-solution%3A-performing-asynchronous-operations-sequentially">#</a></h3>
<p>The first solution that may come to mind, would be to perform each of these operations <strong>sequentially</strong>:</p>
<pre><code><span><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></span><br><span></span><br><del>  <span>-</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span></del><br><ins>  <span>+</span> <span>for</span> <span>(</span><span>const</span> id <span>of</span> ids<span>)</span> <span>{</span></ins><br><ins>  <span>+</span>   <span>await</span> <span>performAsyncOperation</span><span>(</span>id<span>)</span><span>;</span></ins><br><ins>  <span>+</span> <span>}</span></ins><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p>Which, if we run this script, gives the following output:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 29825ms, moving on to something else now.
</code></pre>
<p>As we'd expect, every operation awaits for the previous one to be completed, and, in a way, we found a succesful solution to our problem.<br>
However, one would probably argue this being far from optimal, and that the system against which we run these asynchronous operations can safely withstand up to 3 concurrent operations, thus, our script could theoretically be ~3 times faster.</p>
<h3 id="the-solution%3A-limiting-concurrency-using-workers">The solution: limiting concurrency using workers <a href="#the-solution%3A-limiting-concurrency-using-workers">#</a></h3>
<p>Now, let's take a look at how we can update our script to perform at most 3 operations concurrently.<br>
For that, let's introduce a <code>worker</code> function, to which we will delegate the job of performing one asynchronous operation at a time.</p>
<pre><code><span>const</span> <span>worker</span> <span>=</span> <span>next_</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>let</span> next<span>;</span><br>  <span>while</span> <span>(</span><span>(</span>next <span>=</span> <span>next_</span><span>(</span><span>)</span><span>)</span><span>)</span> <span>{</span><br>    <span>await</span> <span>performAsyncOperation</span><span>(</span>next<span>)</span><span>;</span><br>  <span>}</span><br><span>}</span><span>;</span></code></pre>
<p><em>Note: such a <code>worker</code> function can be implemented in various ways, this implementation is just an example of what I've used in the past.</em></p>
<p>However big the number of asynchronous operations we wish to perform, we will ever need at most, 3 concurrent <code>workers</code>.</p>
<pre><code><span>const</span> <span>CONCURRENT_WORKERS</span> <span>=</span> <span>3</span><span>;</span></code></pre>
<p>We will then want to give a way to our <code>workers</code> to retrieve the next resource identifier, or thing, to perform the asynchronous operation from.</p>
<pre><code><span>const</span> workers <span>=</span> <span>[</span><span>]</span><span>;</span><br><span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>CONCURRENT_WORKERS</span><span>;</span> i<span>++</span><span>)</span> <span>{</span><br>  <span>const</span> w <span>=</span> <span>worker</span><span>(</span>ids<span>.</span><span>pop</span><span>.</span><span>bind</span><span>(</span>ids<span>)</span><span>)</span><span>;</span><br>  workers<span>.</span><span>push</span><span>(</span><span>w</span><span>(</span>ids<span>)</span><span>)</span><span>;</span><br><span>}</span></code></pre>
<p>Let us update our script:</p>
<pre><code><span><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span></span><br><span>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span></span><br><span>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></span><br><span>    console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span></span><br><span>    <span>resolve</span><span>(</span><span>)</span><span>;</span></span><br><span>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span></span><br><span>  <span>}</span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><ins><span>const</span> <span>worker</span> <span>=</span> <span>next_</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></ins><br><ins>  <span>let</span> next<span>;</span></ins><br><ins>  <span>while</span> <span>(</span><span>(</span>next <span>=</span> <span>next_</span><span>(</span><span>)</span><span>)</span><span>)</span> <span>{</span></ins><br><ins>    <span>await</span> <span>performAsyncOperation</span><span>(</span>next<span>)</span><span>;</span></ins><br><ins>  <span>}</span></ins><br><ins><span>}</span><span>;</span></ins><br><ins></ins><br><ins><span>const</span> <span>CONCURRENT_WORKERS</span> <span>=</span> <span>3</span><span>;</span></ins><br><ins></ins><br><ins><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></ins><br><ins>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></ins><br><ins>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></ins><br><ins></ins><br><ins>  <span>const</span> workers <span>=</span> <span>[</span><span>]</span><span>;</span></ins><br><ins>  <span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>CONCURRENT_WORKERS</span><span>;</span> i<span>++</span><span>)</span> <span>{</span></ins><br><ins>    <span>const</span> w <span>=</span> <span>worker</span><span>(</span>ids<span>.</span><span>pop</span><span>.</span><span>bind</span><span>(</span>ids<span>)</span><span>)</span><span>;</span></ins><br><ins>    workers<span>.</span><span>push</span><span>(</span><span>w</span><span>(</span>ids<span>)</span><span>)</span><span>;</span></ins><br><ins>  <span>}</span></ins><br><ins></ins><br><ins>  <span>await</span> Promise<span>.</span><span>all</span><span>(</span>workers<span>)</span><span>;</span></ins><br><span></span><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><span><span>run</span><span>(</span><span>)</span><span>;</span></span></code></pre>
<p>And run it:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 9948ms, moving on to something else now.
</code></pre>
<h3 id="bonus-solution%3A-batching-concurrent-operations">Bonus solution: batching concurrent operations <a href="#bonus-solution%3A-batching-concurrent-operations">#</a></h3>
<p>There's one more way to look at the problem, and reach another solution: splitting the asynchronous operations to be performed in <strong>batches</strong>.<br>
In our case, if we have 99 operations to perform, we can split these into 33 batches of 3 operations.<br>
With batching, every operation within one batch will be performed conccurently, and the next batch will only be started once the previous one is finished.<br>
How does one implement concurrent operations batching with JavaScript?</p>
<pre><code><span><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></span><br><span></span><br><del>  <span>-</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span></del><br><ins>  <span>+</span> <span>let</span> i <span>=</span> <span>1</span><span>;</span></ins><br><ins>  <span>+</span> <span>while</span> <span>(</span>ids<span>.</span>length<span>)</span> <span>{</span></ins><br><ins>  <span>+</span>   <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>splice</span><span>(</span><span>0</span><span>,</span> <span>3</span><span>)</span><span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>;</span></ins><br><ins>  <span>+</span>   console<span>.</span><span>log</span><span>(</span><span>'Performed async operactions batch number'</span><span>,</span> i<span>)</span><span>;</span></ins><br><ins>  <span>+</span>   i<span>++</span><span>;</span></ins><br><ins>  <span>+</span> <span>}</span></ins><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p>Which gives us the following output:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
Performed async operactions batch number 1
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
Performed async operactions batch number 33
All operations performed in 9981ms, moving on to something else now.
</code></pre>
<h3 id="conclusion">Conclusion <a href="#conclusion">#</a></h3>
<p>Asynchronous JavaScript can be tricky, and though one may argue the language lacks high-level APIs to deal more efficiently with some of these tricky cases like the one we've just covered, it's always worth taking our chance at solving the problems leveraging the features that we're provided by the language.</p>
<p>In this post we've built and lived through a common scenario of managing asynchronous operations concurrency in JavaScript, along with a common pitfall associated with a naive approach, as well as an intermediary solution that is also very useful on some other cases, and finally the optimal solution for dealing with this problem, all without using third party modules. I hope this may be useful to some of you, and that I did not take too many shortcuts in the process.</p>
<p>If you liked this post, feel free to encourage me by saying so on <a href="https://twitter.com/tpillard">my Twitter</a> and/or by liking/retweeting the associated tweet or sharing the article around you.<br>
If, on the contrary, you did not like this post and think I should never write JavaScript and/or on a public medium again, keep it to yourself dude, I know already.<br>
Finally, feel free to share your feedback …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/">https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/</a></em></p>]]>
            </description>
            <link>https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141535</guid>
            <pubDate>Thu, 13 Aug 2020 09:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell to Core: Understanding Haskell Features Through Their Desugaring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141425">thread link</a>) | @NaeosPsy
<br/>
August 13, 2020 | https://serokell.io/blog/haskell-to-core | <a href="https://web.archive.org/web/*/https://serokell.io/blog/haskell-to-core">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This article is based on <a href="https://www.youtube.com/watch?v=fty9QL4aSRc">my talk with the same title</a>, which I gave at the Haskell Love conference in 2020, where I give a cursory overview of GHC’s front-end pipeline, the internal Core language, and the desugaring pass.</em></p><p>Haskell is an expressive language with many features. On the one hand, it makes Haskell convenient, equipping the programmer with a rich arsenal of tools to get the job done and write high-quality software. On the other hand, developing a thorough understanding of these tools, of all the language features, takes time, effort, and experience.</p><p>One way to build an intuition for a language feature is to use it. Practice makes perfect, and by trial and error, you can discover the ins and outs of using certain parts of the language. However, the knowledge acquired this way may be superficial, and the mental model will only be as good as it was needed for the tasks at hand.</p><p>Deeper insight comes from a different perspective: you need to decompose a concept into its basic constituents. For example, what are multi-argument functions? In a curried language, we know that <code>\a b c -&gt; ...</code> is much the same as <code>\a -&gt; \b -&gt; \c -&gt; ...</code>. Thus we have reduced the concept of a multi-argument function into a simpler concept of a single-argument function.</p><p>For a more involved example: what is <code>do</code>-notation? To grasp it, you need to think about how it is desugared into <code>&gt;&gt;=</code> and <code>&gt;&gt;</code> (and also <code>&lt;*&gt;</code> with <code>-XApplicativeDo</code>).</p><p>What about infix operators, if-then-else expressions, list comprehensions, type classes, type families, GADTs? How much Haskell is essential, and how much is sugar on top?</p><p>This becomes clear if we start thinking about the way Haskell programs are desugared into GHC’s Core: a small, elegant language, used as an intermediate representation in GHC’s compilation pipeline. The many features of Haskell are reducible to the few constructs of Core.</p><p>Desugaring translates a program that uses many different language constructs into a program that uses only a few.</p><p>For example, consider this snippet:</p><pre><code><span>product</span> [a + b, c + d]
</code></pre><p>It uses several Haskell features:</p><ol>
<li>Lists literals: <code>[a, b, c, ...]</code></li>
<li>Operator application: <code>x # y</code></li>
<li>Function application: <code>f x</code></li>
</ol><p>But we can rewrite it in such a way that it uses only function application:</p><pre><code><span>product</span> (
  (:) ((+) a b) (
  (:) ((+) c d) (
  [])))
</code></pre><p>Granted, the end result is not as readable. But the building blocks used to write this program are simpler, and that’s the important bit.</p><p>Desugaring is not just an abstract idea: it’s a concrete step of GHC’s pipeline. Every Haskell program is desugared into Core during compilation. So, to see the full picture, it’s helpful to consider the steps that occur prior to desugaring.</p><p>The input to the compiler is a string, a sequence of characters:</p><center><img src="https://serokell.io/files/dy/dy2sc5q9.ParserInput.png" alt="Parser Input"></center><p>Where would one begin to process this sequence? Actually, this is fairly well known. The first step is <strong>lexical analysis</strong>, which groups subsequences of these characters into labeled tokens:</p><center><img src="https://serokell.io/files/mf/mfm4t5lo.LexerOutput.png" alt="Lexer Output"></center><p>Then the tokens are organized into a tree. That’s <strong>syntactic analysis</strong>:</p><center><img src="https://serokell.io/files/oa/oav0bml8.ParserOutput.png" alt="Parser Output"></center><p>The structure of this tree depends on the language we’re working with. In Haskell, a module contains declarations, such as data declarations, class declarations, function/variable definitions, and so on. In this example, we have two value bindings, marked as ‘bind’.</p><p>In a ‘bind’, there’s a pattern on the left-hand side and an expression on the right-hand side. In this example, the patterns are simply variable names, but we could also have as-patterns, view-patterns, matching on specific data constructors, and so on.</p><p>An expression can be one of many forms, but here we have:</p><ul>
<li>‘app’ – function application, consisting of a function and its argument;</li>
<li>‘op app’ – operator application, consisting of two operands and an operator;</li>
<li>‘var’ – references to other named values;</li>
<li>‘lit’ – numeric and string literals.</li>
</ul><p>Then we do <strong>name resolution</strong>, to figure out which name refers to what:</p><center><img src="https://serokell.io/files/8v/8vvt57kn.RenamerOutput.png" alt="Renamer Output"></center><p>Here, ‘print’, ‘+’, and ‘length’ are imported from other modules, whereas ‘x’ is defined in the same module.</p><p>And then, we analyse the program to <strong>check and infer the types</strong> of its expressions and subexpressions:</p><pre><code><span>main</span> :: <span>IO</span> ()
<span>x</span> :: <span>Int</span>
</code></pre><p>So that’s the GHC pipeline, or at least its front-end:</p><p><img src="https://serokell.io/files/sx/sxg6b87v.PipelineGHC.png" alt="sxg6b87v.PipelineGHC.png"></p><ul>
<li>text to tokens;</li>
<li>tokens to a syntax tree;</li>
<li>add scoping information to the syntax tree;</li>
<li>add type information to the syntax tree;</li>
</ul><p>This leaves us with a well-scoped, well-typed syntax tree. This is the input to desugaring. And the output is a Core program, where Core is a language like Haskell, but it’s much smaller and with fewer features.</p><p>To understand how Core is simpler, let’s first take a deeper look at Haskell. To represent a Haskell expression, GHC defines a type called <code>HsExpr</code>. If you open <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Expr.hs">compiler/GHC/Hs/Expr.hs</a></code> in GHC sources, you will see it:</p><pre><code><span><span>data</span> <span>HsExpr</span> p</span>
  = <span>HsVar</span> ...         
  | <span>HsLit</span> ...         
  | <span>HsApp</span> ...         
  | <span>OpApp</span> ...         
  | ...
</code></pre><p>Remember how syntactic analysis creates a node for each subexpression? And these nodes can be of different varieties, such as function application, operator application, variables, literals, etc.? <code>HsExpr</code> has a constructor for each node type: <code>HsVar</code>, <code>HsLit</code>, <code>HsApp</code>, <code>OpApp</code>, and so on.</p><p>And there are lots and lots of node types:</p><pre><code><span><span>data</span> <span>HsExpr</span> p</span>
  = <span>HsVar</span> ...         
  | <span>HsLit</span> ...         
  | <span>HsApp</span> ...         
  | <span>OpApp</span> ...         
  | <span>HsAppType</span> ...     
  | <span>HsLam</span> ...         
  | <span>HsLet</span> ...         
  | <span>ExprWithTySig</span> ... 
  | <span>ExplicitList</span> ...  
  | <span>SectionL</span> ...      
  | <span>SectionR</span> ...      
  | <span>ExplicitTuple</span> ... 
  | <span>HsCase</span> ...        
  | <span>HsLamCase</span> ...     
  | <span>HsIf</span> ...          
  | <span>HsMultiIf</span> ...     
  | <span>HsDo</span> ...          
  | <span>RecordCon</span> ...     
  | <span>RecordUpd</span> ...     
  | <span>ArithSeq</span> ...      
  | <span>HsPar</span> ...         
  | <span>NegApp</span> ...        
  | <span>HsBracket</span> ...     
  | <span>HsSpliceE</span> ...     
  | <span>HsProc</span> ...        
  | <span>HsStatic</span> ...      
  | <span>HsOverLabel</span> ...   
  | ...
</code></pre><p>And that’s just expressions. There are also patterns, defined in <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Pat.hs">compiler/GHC/Hs/Pat.hs</a></code>:</p><pre><code><span><span>data</span> <span>Pat</span> p</span>
  = <span>WildPat</span> ...       
  | <span>VarPat</span> ...        
  | <span>LazyPat</span> ...       
  | <span>BangPat</span> ...       
  | <span>AsPat</span> ...         
  | <span>ParPat</span> ...        
  | <span>ListPat</span> ...       
  | <span>TuplePat</span> ...      
  | <span>ConPat</span> ...        
  | <span>ViewPat</span> ...       
  | <span>LitPat</span> ...        
  | <span>SigPat</span> ...        
  | <span>NPat</span> ...          
  | <span>NPlusKPat</span> ...     
  | <span>SplicePat</span> ...     
  | ...
</code></pre><p>And types, defined in <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Type.hs">compiler/GHC/Hs/Type.hs</a></code>:</p><pre><code><span><span>data</span> <span>HsType</span> p</span>
  = <span>HsForAllTy</span> ...    
  | <span>HsQualTy</span> ...      
  | <span>HsTyVar</span> ...       
  | <span>HsAppTy</span> ...       
  | <span>HsAppKindTy</span> ...   
  | <span>HsFunTy</span> ...       
  | <span>HsListTy</span> ...      
  | <span>HsTupleTy</span> ...     
  | <span>HsOpTy</span> ...        
  | <span>HsParTy</span> ...       
  | <span>HsIParamTy</span> ...    
  | <span>HsStarTy</span> ...      
  | <span>HsKindSig</span> ...     
  | <span>HsSpliceTy</span> ...    
  | <span>HsTyLit</span> ...       
  | <span>HsWildCardTy</span> ...  
  | ...
</code></pre><p>In <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Decls.hs">compiler/GHC/Hs/Decls.hs</a></code> there are data declarations, classes, type families, instances, and so on:</p><pre><code><span><span>data</span> <span>TyClDecl</span> p</span>
  = <span>FamDecl</span> ...       
  | <span>SynDecl</span> ...       
  | <span>DataDecl</span> ...      
  | <span>ClassDecl</span> ...     

<span><span>data</span> <span>InstDecl</span> p</span>
  = <span>ClsInstD</span> ...      
  | <span>DataFamInstD</span> ...  
  | <span>TyFamInstD</span> ...    
</code></pre><p>That’s not all, of course. You can browse <code>compiler/GHC/Hs/...</code> to see more.</p><p>What about Core? Here’s the entirety of its syntax:</p><pre><code><span><span>data</span> <span>Expr</span></span>
  = <span>Var</span>   <span>Id</span>
  | <span>Lit</span>   <span>Literal</span>
  | <span>App</span>   <span>Expr</span> <span>Expr</span>
  | <span>Lam</span>   <span>Var</span> <span>Expr</span>
  | <span>Let</span>   <span>Bind</span> <span>Expr</span>
  | <span>Case</span>  <span>Expr</span> <span>Var</span> <span>Type</span> [<span>Alt</span>]
  | <span>Cast</span>  <span>Expr</span> <span>Coercion</span>
  | <span>Type</span>  <span>Type</span>
  | <span>Coercion</span> <span>Coercion</span>
  | <span>Tick</span>  ...  

<span><span>type</span> <span>Alt</span> = (<span>AltCon</span>, [<span>Var</span>], <span>Expr</span>)</span>

<span><span>data</span> <span>AltCon</span></span>
  = <span>DataAlt</span> <span>DataCon</span>
  | <span>LitAlt</span>  <span>Literal</span>
  | <span>DEFAULT</span>

<span><span>data</span> <span>Bind</span></span>
  = <span>NonRec</span> <span>Var</span> <span>Expr</span>
  | <span>Rec</span> [(<span>Var</span>, <span>Expr</span>)]

<span><span>data</span> <span>Type</span></span>
  = <span>TyVarTy</span> <span>Var</span>
  | <span>AppTy</span> <span>Type</span> <span>Type</span>
  | <span>TyConApp</span> <span>TyCon</span> [<span>Type</span>]
  | <span>ForAllTy</span> <span>TyCoVarBinder</span> <span>Type</span>
  | <span>FunTy</span> <span>Mult</span> <span>Type</span> <span>Type</span>
  | <span>LitTy</span> <span>TyLit</span>
  | <span>CastTy</span> <span>Type</span> <span>Coercion</span>
  | <span>CoercionTy</span> <span>Coercion</span>
</code></pre><p>Its expression syntax has only nine constructs:</p><ul>
<li>variables (<code>Var</code>)</li>
<li>literals (<code>Lit</code>)</li>
<li>function application (<code>App</code>)</li>
<li>lambdas (<code>Lam</code>)</li>
<li>let-bindings (<code>Let</code>)</li>
<li>case-expressions (<code>Case</code>)</li>
<li>casts (<code>Cast</code>)</li>
<li>coercions (<code>Coercion</code>)</li>
</ul><p>If you learn what these are, you know Core. And if you know both Core and how Haskell programs are desugared into it, then you can easily reason about the menagerie of Haskell language features.</p><p>At a first approximation, you can think of Core as a subset of Haskell plus coercions (and casts, these two are closely related). That’s not the full story, though. For example, there are also differences in strictness, as <code>case</code> in Core is always strict. Here are some resources if you want to delve deeper into this:</p><ul>
<li><a href="https://www.youtube.com/watch?v=uR_VzYxvbxg">“Into the Core - Squeezing Haskell into Nine Constructors"</a></li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2007/01/tldi22-sulzmann-with-appendix.pdf">“System F with Type Equality Coercions"</a></li>
<li><a href="https://repository.brynmawr.edu/cgi/viewcontent.cgi?article=1014&amp;context=compsci_pubs">“System FC with Explicit Kind Equality"</a></li>
<li><a href="https://github.com/ghc/ghc/blob/master/docs/core-spec/core-spec.pdf">“System FC, as implemented in GHC"</a></li>
<li>Read the GHC sources (e.g. <code>dsLExpr</code>) and <code>-ddump-simpl</code> output</li>
</ul><p>However, as a starting point, it’s sufficient to assume that Core is a subset of Haskell.</p><p>Now let’s see how Haskell programs are transformed into Core by looking at specific examples. We’ll start with the most basic features and progress to more complex ones.</p><h2 id="infix-operators">Infix Operators</h2><p>Infix operators are translated into function applications:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>a</span> &amp;&amp; b
</code></pre>
</td>
<td>
<pre><code>(&amp;&amp;) a b
</code></pre>
</td></tr></tbody></table><p>There isn’t much to it. But keep in mind that in Core, all variable occurrences have type information, so a more accurate translation would look like this:</p><pre><code>((&amp;&amp;) :: <span>Bool</span> -&gt; <span>Bool</span> -&gt; <span>Bool</span>)
  (a :: <span>Bool</span>)
  (b :: <span>Bool</span>)
</code></pre><p>However, more often than not, I will omit type annotations to save visual space.</p><h2 id="function-bindings">Function Bindings</h2><p>Bindings in Core always have a single variable name on the left-hand side. Function bindings are desugared into lambdas:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> x y = not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>Also, there are no separate type signatures. All type information is stored inline.</p><h2 id="multi-argument-function-bindings">Multi-Argument Function Bindings</h2><p>Multi-argument functions are translated into nested lambdas. In Core, all lambdas are single-argument:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> x y = not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>This is also true for hand-written multi-argument lambdas:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> = \x y -&gt; not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>This treatment of multi-argument functions may be familiar to you if you’ve heard of <a href="https://en.wikipedia.org/wiki/Currying">cu…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/haskell-to-core">https://serokell.io/blog/haskell-to-core</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/haskell-to-core</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141425</guid>
            <pubDate>Thu, 13 Aug 2020 09:22:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Go 1.15 improved converting small integer values to interfaces]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141174">thread link</a>) | @ngaut
<br/>
August 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How Go 1.15 improved converting small integer values to interfaces</h2>

	<p><small>August 12, 2020</small></p>
</div><div><p>In Go, <a href="https://golang.org/ref/spec#Interface_types">interface values</a>
are famously implemented as a pair of pointers (see Russ Cox's <a href="https://research.swtch.com/interfaces">Go
Data Structures: Interfaces</a>);
a pointer to information about the type and a pointer to the value
itself. This generally means that the value must be dynamically
allocated in the <em>heap</em>, which means that it will contribute to the
work that Go's garbage collection does.</p>

<p>The <a href="https://golang.org/doc/go1.15">Go 1.15 release notes</a> mention
an intriguing improvement in <a href="https://golang.org/doc/go1.15#runtime">the runtime section</a>:</p>

<blockquote><p>Converting a small integer value into an interface value no longer
causes allocation.</p>
</blockquote>

<p>When I saw that, I immediately wondered how it works, and especially
if Go's runtime was now sometimes using the value pointer field in
interface values to directly store the value.
(There are a number of languages that do this, using various approaches
like <a href="https://wiki.c2.com/?TagBit">tag bits</a> to tell values from real
pointers.)</p>

<p>The answer turns out to be pretty straightforward, and is in <a href="https://go-review.googlesource.com/c/go/+/216401">Go
CL 216401</a> (merged
in <a href="https://github.com/golang/go/commit/9828c43288a53d3df75b1f73edad0d037a91dff8">this commit</a>,
which may be easier to read). The Go runtime has a special static
array of the first 256 integers (0 to 255), and when it would
normally have to allocate memory to store an integer on the heap
as part of converting it to an interface, it first checks to see
if it can just return a pointer to the appropriate element in the
array instead. This kind of static allocation of frequently used
values is common in languages with lots of dynamic allocation;
Python does something similar for small integers, for example
(<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ObjectIdentityGotcha">which can sometimes surprise you</a>).</p>

<p>(It turns out that Go previously had an optimization where if you were
converting 0 to an interface value, it would return a pointer to a
special static zero value. This new optimization for 0-255 replaces
that.)</p>

<p>There is one special trick that Go plays here. The actual array is
an array of <code>uint64</code>, but it reuses the same array for smaller sized
values as well. On <a href="https://en.wikipedia.org/wiki/Endianness">little endian</a> systems like x86, this
is fine as it stands because a pointer to a 64-bit value is also a
valid pointer to that value interpreted as 32 or 16 bits (or 8
bits). But on big endian systems this isn't the case, so if Go is
running on a big endian machine it bumps up the pointer so that it
works properly (making it point to either the last two bytes or the
last four bytes of the 8-byte value).</p>

<p>(On a little endian machine, the pointer is to the low byte of the
value and the remaining bytes are all zero so it doesn't matter how
many more of them you look at. On a big endian machine, the pointer
is to the high byte, but the low byte is the thing that matters.)</p>

<p>As bonus trivia for this change, this new array of 0-255 <code>uint64</code>
values was then reused for avoiding allocating anything for one-byte
strings in another change (<a href="https://github.com/golang/go/commit/bda42a7a782dbcf4b123d617c5b60f3c848cbb82">this commit</a>,
<a href="https://go-review.googlesource.com/c/go/+/221979">CL 221979</a>).
Go previously had an array of bytes for this purpose, but why have
two arrays. Big endian machines need the same sort of pointer bumping
they did for small integers being converted to interface values,
but little endian machines can once again use the pointers as is.</p>

<p>PS: There are runtime functions for converting 16, 32, and 64 bit
values to interface values, in <a href="https://github.com/golang/go/blob/master/src/runtime/iface.go">runtime/iface.go</a>
(they can be inlined in actual code), but I was puzzled because
there is no runtime function for converting 8 bit values. It turns
out that 8-bit values are directly handled by the compiler in
<a href="https://github.com/golang/go/blob/master/src/cmd/compile/internal/gc/walk.go#L837">walk.go</a>,
where it generates inline code that uses the <code>staticuint64s</code> array.
This may be done directly in the compiler partly because it needs
no fallback path for larger values, unlike the 16, 32, and 64 bit
cases, since an 8 bit value will always be in <code>staticuint64s</code>.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141174</guid>
            <pubDate>Thu, 13 Aug 2020 08:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stopping phishing campaigns with Bash]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 154 (<a href="https://news.ycombinator.com/item?id=24141127">thread link</a>) | @geek_at
<br/>
August 13, 2020 | https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>A few days ago my wife got a text message that was obviously a bad phishing attempt</p>
<figure><img loading="lazy" src="https://pictshare.net/xcz7r5.jpg"><figcaption>It says: Our -bankname- system has noticed that your "pushTAN" service is not active. Click here to activate</figcaption></figure>
<p>I spun up a VM and took a look at the website it linked to, which is <a href="https://www.sso-meinelba.com/">https://www.sso-meinelba.com/</a> (almost like the real domain but with a typo) and of course it was just a copy of a banks login form that had only one change made to it.</p>
<figure><img loading="lazy" src="https://pictshare.net/0fuchr.png"><figcaption>The phishers added a "PIN" field to the logon page</figcaption></figure>
<p>The way these things work is that they act like they're the real login form, <code>steal your credentials</code> and usually send you off to the real bank so you think you made a typo or something.</p>

<p>These phishing backends are usually very simple PHP scripts that just take the data from the submitted form and save them to a file. The phishers then <a href="https://krebsonsecurity.com/2017/12/the-market-for-stolen-account-credentials/">sell them via hidden services</a> (trying real hard not to use the bullshit term <code>darknet</code> here).</p>
<p>If the phishers didn't think too hard about getting garbage data you can have a little fun and poison their loot with fake logins.</p>
<p>So with a few lines of Bash I was able to send a few thousand datapoints to their backend, filling it with garbage.</p>
<pre><code>while :; do

    # generate random numbers for login and password
    verf=$(cat /dev/urandom | tr -dc '0-9' | fold -w 7 | head -n 1)
    pin=$(cat /dev/urandom | tr -dc '0-9' | fold -w 5 | head -n 1)

    # send them to their server as your browser would
    curl 'https://www.sso-meinelba.com/files/index/identifier/verfueger/uz1.php' \
        -H 'authority: www.sso-meinelba.com' \
        -H 'origin: https://www.sso-meinelba.com' \
        -H 'content-type: application/x-www-form-urlencoded' \
        -H 'user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36' \
        -H 'referer: https://www.sso-meinelba.com/files/index/identifier/verfueger/' \
        --data-raw "verfueger=Wien&amp;Verf%C3%BCgernummer=$verf&amp;Pin=$pin&amp;submit=Weiter"

    echo "Sending $verf with pin $pin"
done</code></pre>
<figure>
<video id="video" poster="https://pictshare.net/i3khmn.mp4/preview/i3khmn.mp4" preload="auto" autoplay="autoplay" controls="" muted="muted" loop="loop" webkit-playsinline="">   
    <source src="https://pictshare.net/i3khmn.mp4/raw" type="video/mp4">
</video>
<figcaption>Which was running for about half an hour until I had an idea</figcaption>
</figure>
<h2>The form was limiting my input.. but does the backend too?</h2>
<p>The phishing form limited the account number to 7 digits and the pin to 5 digits but what if I would send a bit more?</p>
<p>So I edited the script to send 256 character account numbers and passwords and then this happened.</p>
<h2>It killed their site (?)</h2>
<figure><img loading="lazy" src="https://pictshare.net/rcr9g6.png"><figcaption>The site didn't like my input</figcaption></figure>
<p>After my first request with two times 256 characters, the site went down. I'm not sure what happened and if it was a big coincidence and they took it down in the exact second I sent the large strings or I activated self destruction but since this request the site is down.</p>
<figure><img loading="lazy" src="https://pictshare.net/b71byj.png"><figcaption>Site is down now. Did I do that?</figcaption></figure>
<p>The server seems up but the content is gone.</p>
<h2>Strange things</h2>
<p>What struck me as odd was that the fake domain <code>sso-meinelba.com</code> had a valid SSL Wildcard certificate from the italian company <a href="https://www.actalis.it/">Actalis</a>. Usually phishers only get free certificates like Let's encrypt but they really seemed to have bought one. Odd</p>
<figure><img loading="lazy" src="https://pictshare.net/1fiexe.png"><figcaption>The certificate</figcaption></figure>
<p>I also noticed that the website was hosted on webx1413.aruba.it. The scammers must have rented a small VPS that hosts the scamming site</p>
<h2>How do they hide their scamming site from being detected?</h2>
<p>Remember the <code>bitly.com</code> link from the screenshot? It actually doesn't point directly to <code>sso-meinelba.com</code> but rather to a sub folder on <a href="https://kls-study.com/">https://kls-study.com</a> which is (as far as I can tell) an old homepage of the italian <a href="http://klm.education/">KLM Education</a> language school.</p>
<p>Obviously the phishers found a bug in their website and used the subdirectory <code>https://kls-study.com/redi/ccui</code> (the last part of the path seems to be random) to forward users to their phishing campaigns.</p>

<p>On the local Austrian subreddit <a href="https://www.reddit.com/r/Austria/comments/i88imh/wei%C3%9F_jemand_wieso_mir_raiffeisen_das_geschickt/">I saw a post describing a similar</a> phishing campaign and I also took a look.</p>
<p>It was the same banking login page but the backend was much more professional. It seems they actively tried to use the login credentials in the backend before saving them because after entering login data I saw this and had to laugh.</p>
<figure><img loading="lazy" src="https://pictshare.net/qm3tsb.png"><figcaption>My IP address in a subfolder called "victims"</figcaption></figure>
<p>This txt file was called once per second and it had the value <code>0</code> in it. I assume they tried to login with the credentials I entered and if it was valid, they'd forward me to the real website of the bank.</p>
<p>Sadly the server didn't enable indexing otherwise I would have seen all victims, but it was funny nonetheless.</p>
<h2>Also attacking this phishing site</h2>
<p>I saw that every request to <code>http://elba-app.com/Raiffeisen/</code> seemed to create a folder with a random string on their server. (eg <code>http://elba-app.com/Raiffeisen/f5255513e44fa68/</code>) so I thought I'd spam them again and it worked well</p>
<figure>
<video id="video2" poster="https://pictshare.net/a1s52s.mp4/preview/a1s52s.mp4" preload="auto" autoplay="autoplay" controls="" muted="muted" loop="loop" webkit-playsinline="">   
                <source src="https://pictshare.net/a1s52s.mp4/raw" type="video/mp4">
</video>
<figcaption>With every request there is a folder generated on their server</figcaption>
</figure>
<p>until</p>
<figure><img loading="lazy" src="https://pictshare.net/dj72f5.png"><figcaption>They blocked my IP</figcaption></figure>
<p>Being a sysadmin this of course is not the only IP at my disposal so I tried the BOMB request (256 instead of 7 characters) again and what happened?</p>
<figure><img loading="lazy" src="https://pictshare.net/r33l7v.png"><figcaption>Their server was not happy with my input</figcaption></figure>
<p>This time the server didn't crash or self destruct, I just seem to produce a lot of error messages on their side.</p>
<p>Also their site is a bit more complex as they don't have a single form where to post login credentials but they have 3 steps:</p>
<p><strong>Step 1:</strong>
Go to <code>http://elba-app.com/Raiffeisen</code> and the server will respond with a 302 redirect to the folder they created for you</p>
<figure><img loading="lazy" src="https://pictshare.net/jilwi2.png"><figcaption>Redirect in the location header</figcaption></figure>
<p><strong>Step 2:</strong>
They send you to a sumbit.php that only takes the account name and redirects you to</p>
<p><strong>Step 3:</strong>
Now they want your pin on <code>/hundle-pin.php</code>. I'm not sure why they did leave in that typo but here we are.</p>

<p>I made a few changes to my script to handle all 3 steps and let it run over night from a dozen different ip addresses.</p>
<p>The result? They stopped their campaign from this Domain</p>
<figure><img loading="lazy" src="https://pictshare.net/17p4v8.png"><figcaption>This phishing site is gone too</figcaption></figure>
<p><a href="https://gist.github.com/geek-at/53768c6b7aee7a973032cfb7daf65107">Here's my updated script</a> for those playing along at home</p>

<p>We saw 2 phishing attacks in different quality. Both sent out as SMS to users who are customers of the same bank.</p>
<p>I wrote a script to poison their data and got both of the sites to stop working. Great success!</p>
                            </div>
                        </div>
                    </div></article></div>]]>
            </description>
            <link>https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141127</guid>
            <pubDate>Thu, 13 Aug 2020 08:25:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS Architecture]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141035">thread link</a>) | @charliechuck
<br/>
August 13, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141035</guid>
            <pubDate>Thu, 13 Aug 2020 08:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla Is Dead]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24140547">thread link</a>) | @kowabit
<br/>
August 12, 2020 | https://kowabit.de/mozilla-is-dead/ | <a href="https://web.archive.org/web/*/https://kowabit.de/mozilla-is-dead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-206394"><div><p><img width="720" height="250" src="https://kowabit.de/wp-content/uploads/2019/02/software.png" alt="" loading="lazy" srcset="https://kowabit.de/wp-content/uploads/2019/02/software.png 720w, https://kowabit.de/wp-content/uploads/2019/02/software-300x104.png 300w" sizes="(max-width: 720px) 100vw, 720px"></p><div><p>If the official news and the unofficial information come true, I believe that Mozilla will die. Ciao Firefox, ciao Thunderbird. Sorry. Also goodbye to all other products that nobody ordered.</p><p>In an <a href="https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/" target="_blank" rel="noopener noreferrer">official blog post</a> and an e-mail (<a href="https://blog.mozilla.org/wp-content/uploads/2020/08/Message-to-Employees-Change-in-Difficult-Times.pdf" target="_blank" rel="noopener noreferrer">PDF</a>) Mozilla announces that a quarter of the employees are to be fired. The current Corona crisis have contributed to this. However, the explanation for this action is only PR-speech. In the message to all employees there is again talk of new products and they are supposed to adopt a new way of thinking. Mozilla has often been criticized in the past. Projects like pocket, Send, Lockwise, Firefox OS were/are either born dead and/or burned a lot of money and resources. I have never met anyone in my professional life who has used the additional products or features. Honestly. Me neither.</p><p>According to unofficial information e.g. via Twitter or Github the documentation team, the Firefox engine team (Gecko) and the security team are affected (<a href="https://twitter.com/MichalPurzynski/status/1293220570885062657" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://twitter.com/gcpascutto/status/1293519587967983616" target="_blank" rel="noopener noreferrer">2</a>, <a href="https://github.com/servo/servo/discussions/27575" target="_blank" rel="noopener noreferrer">3</a>, <a href="https://twitter.com/SteveALee/status/1293487542382333952" target="_blank" rel="noopener noreferrer">4</a>). In a crisis never the responsible head of an organization saying goodbye. The head that should have made its own company crisis-proof. Now the most important organs of the whole body are apparently being removed.</p><p>Which products Mozilla wants to market without these teams remains the secret of the management floor. As an administrator in the main job and helper in the private sphere for some people, Firefox as a browser can no longer be an option. The danger of unpatched security holes and lack of further development in the core area endangers the infrastructure and systems. Decision makers also have to pay attention to this when it comes to equipping company networks with software. An organization that buries the most important committees for the maintenance of its products no longer has a product.</p><p>If Mozilla wants to survive, the management will be fired with unearned compensation, the most important departments will be strengthened, products that nobody ordered will be discontinued and the organization will be limited to its core competence. Browser, email, security, adaptability and the fight for a free Internet. And they work with all their might to ensure that the products will become an integral part of everyday life and all operating systems.</p><p>Three months. That’s all the time they have for a clear signal. After that, users have to make a decision. Unfortunately, it will probably only be something with chromium.</p><p>Poor Internet.</p> <p><span>Tagged <a href="https://kowabit.de/tag/firefox/" rel="tag">Firefox</a>, <a href="https://kowabit.de/tag/gecko/" rel="tag">gecko</a>, <a href="https://kowabit.de/tag/goodbye/" rel="tag">goodbye</a>, <a href="https://kowabit.de/tag/imho/" rel="tag">imho</a>, <a href="https://kowabit.de/tag/mozilla/" rel="tag">mozilla</a>, <a href="https://kowabit.de/tag/security/" rel="tag">security</a>, <a href="https://kowabit.de/tag/thunderbird/" rel="tag">thunderbird</a></span></p></div></div></article></div>]]>
            </description>
            <link>https://kowabit.de/mozilla-is-dead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24140547</guid>
            <pubDate>Thu, 13 Aug 2020 06:30:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we do better than our C compiler?]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24139943">thread link</a>) | @signa11
<br/>
August 12, 2020 | https://briancallahan.net/blog/20200812.html | <a href="https://web.archive.org/web/*/https://briancallahan.net/blog/20200812.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<a name="top"></a>
	<div id="main">
	    
	    <p>academic, developer, with an eye towards a brighter techno-social life</p>
	    <hr>
		
	    <hr>
	</div>
<h5 id="prev"><a href="https://briancallahan.net/blog/20200808.html">[prev]</a></h5>
<h5 id="next">[next]</h5>
    <h2 id="title">2020-08-12: Can we do better than our C compiler?</h2>
<p>Today, I wanted to become a C compiler. I added a <a href="https://github.com/ibara/echo/blob/master/echo.s">hand-compiled assembly version of echo</a> from <a href="https://briancallahan.net/blog/20200808.html">our previous coding exercise</a> and added a new make target, <code>make asm</code>, that will assemble it. Let's look at our hand-compiled assembly and compare it to our C compiler and ask whether or not it was worth it.</p>
<h4>My hand-compiled assembly</h4>
<p>It's quite small.</p>
<pre>	.text
	.p2align 2
	.globl	main
	.type	main,@function
main:
	movq	%rdi, %r15	# Get argc from %rdi, put it in %r15
	movq	%rsi, %r14	# Get argv from %rsi, put it in %r14
loop:
	decl	%r15d		# 47: for (i = 0; i &lt; argc; i++) {
	jz	done		# Rewritten as: while (--argc) {
	addq	$8, %r14	# ++argv
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	(%r14), %rsi	# Second parameter is *argv
	leaq	-1(%rsi), %rdx	# Get *argv[0]
strlen:				# Note: strlen has been inlined
	cmpb	$0, 1(%rdx)	# 36: while (*t != '\0')
	leaq	1(%rdx), %rdx	# 37: t++;
	jne	strlen
	subq	%rsi, %rdx	# 39: return t - s;
	syscall			# 48: write(1, *argv, %rdx);
	cmpl	$1, %r15d	# 49: if (i + 1 != argc)
	je	done		# Rewritten as: if (argc != 1)
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	%r14, %rsi	# Set %rsi back to beginning of *argv
	movb	$32, (%rsi)	# Second parameter is " "
	movl	$1, %edx	# Third parameter is 1
	syscall			# 50: write(1, " ", 1);
	jmp	loop
done:
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	%r14, %rsi	# Set %rsi back to beginning of *argv
	movb	$10, (%rsi)	# Second parameter is "\n"
	movl	$1, %edx	# Third parameter is 1
	syscall			# 52: write(1, "\n", 1);
	xorl	%eax, %eax	# Return value is 0
	retq			# 54: return 0;
	.size	main,.-main
</pre>
<p>The whole source is annotated. Comments that begin with a number are for easy cross-referencing with our <a href="https://github.com/ibara/echo/blob/master/echo.c">C version of echo</a>.</p>
<h4>Better optimization for the C code</h4>
<p>The primary tricks are are a manual inlining of the strlen function and not needing the write and _syscall functions, instead being able to use syscall directly. We could inline strlen in the C code if we wanted, but the compiler is very likely to do that for us anyway. We probably can't avoid the write and _syscall functions in C, as we discussed previously.</p>
<p>There is also some rewriting of loops to avoid the use of variables: the <code>for (i = 0; i &lt; argc; i++)</code> is rewritten as <code>while (--argc)</code> and <code>if (i + 1 != argc)</code> becomes <code>if (argc != 1)</code>, which means that we can get rid of the <code>int i</code> variable and increment through argv with <code>++argv</code>. These changes can of course be applied to the C code as well.</p>
<p>Some other tricks include using *argv as scratch space for our space and newline characters. We don't actually care what the value of *argv is once we've written it out—we only use it the one time. So it becomes free memory space for us to overwrite it with whatever we want (as long as things fit; our space and newline characters are a single byte each so we're safe). We could do this one in C too if we wanted.</p>
<p>If we made these changes, our new main function in C might look like this.</p>
<pre>int
main(int argc, char *argv[])
{

	while (--argc) {
		++argv;
		write(1, *argv, strlen(*argv));
		if (argc != 1) {
			*argv[0] = ' ';
			write(1, *argv, 1);
		}
	}
	*argv[0] = '\n';
	write(1, *argv, 1);

	return 0;
}
</pre>
<h4>Even better assembly?</h4>
<p>If we let our C compiler (clang 10.0.0) compile this to assembly, we get the following.
</p><pre>	.text
	.file	"echo.c"
	.globl	main                    # -- Begin function main
	.type	main,@function
main:                                   # @main
# %bb.0:
	pushq	%r15
	pushq	%r14
	pushq	%r12
	movq	%rsi, %r14
	movl	%edi, %r15d
	pushq	$1
	popq	%r12
.LBB0_1:                                # =&gt;This Loop Header: Depth=1
                                        #     Child Loop BB0_3 Depth 2
	decl	%r15d
	je	.LBB0_6
# %bb.2:                                #   in Loop: Header=BB0_1 Depth=1
	movq	8(%r14), %rdi
	addq	$8, %r14
	leaq	-1(%rdi), %rsi
.LBB0_3:                                #   Parent Loop BB0_1 Depth=1
                                        # =&gt;  This Inner Loop Header: Depth=2
	cmpb	$0, 1(%rsi)
	leaq	1(%rsi), %rsi
	jne	.LBB0_3
# %bb.4:                                #   in Loop: Header=BB0_1 Depth=1
	subq	%rdi, %rsi
	callq	write
	cmpl	$1, %r15d
	je	.LBB0_1
# %bb.5:                                #   in Loop: Header=BB0_1 Depth=1
	movq	(%r14), %rax
	movb	$32, (%rax)
	movq	(%r14), %rdi
	movq	%r12, %rsi
	callq	write
	jmp	.LBB0_1
.LBB0_6:
	movq	(%r14), %rax
	movb	$10, (%rax)
	movq	(%r14), %rdi
	pushq	$1
	popq	%rsi
	callq	write
	xorl	%eax, %eax
	popq	%r12
	popq	%r14
	popq	%r15
	retq
.Lfunc_end0:
	.size	main, .Lfunc_end0-main
                                        # -- End function
	.type	write,@function         # -- Begin function write
write:                                  # @write
# %bb.0:
	movq	%rsi, %rcx
	movq	%rdi, %rdx
	pushq	$4
	popq	%rdi
	pushq	$1
	popq	%rsi
	xorl	%r8d, %r8d
	xorl	%r9d, %r9d
	jmp	_syscall                # TAILCALL
.Lfunc_end1:
	.size	write, .Lfunc_end1-write
                                        # -- End function
	.section	".note.GNU-stack","",@progbits
	.addrsig
</pre>
<p>It seems that both clang and I found very similar ways to optimize the program. According to size, I did a little bit better than clang: my hand-compiled assembly came out to a 104-byte object file whereas clang generated a very heavy 125-byte object file. When factoring in the necessary glue code (_start.s, crt,s, and _syscall.s for the C version), my hand-compiled assembly ended up 152 bytes whereas clang was a distant 197 bytes. But clang had the last laugh: running ls -l on the final binaries resulted in 848 bytes for the hand-compiled assembly and 840 bytes for clang. So there is clearly something else going on under the hood that I am losing out on with my hand-compiled assembly. Perhaps you can do better than me.</p>
<h4>Smarter than me</h4>
<p>As will come as little surprise, a production-ready compiler with large teams of developers and larger pools of money is smarter than I am. But I think I did a decent job at it. I believe that learning assembly for several different processors is worthwhile but I think I will stick to higher level languages for most of my work (unless you're paying me to do otherwise...). Because there is one cost we haven't mentioned yet: time. It took me all of 30 seconds, if that, to optimize the C code whereas it took maybe half an hour to write the assembly version.</p>
<h4>Conclusion</h4>
I enjoy assembly. I teach courses that require a deep knowledge of assembly. But I think I'm going to stick to optimizing higher level code rather than cranking out assembly by hand. Or maybe not. Even our original C code was honestly good enough. I'm glad to live in a world where we have a choice of smart compilers.
<p><a href="#top"><img alt="Top" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAICAYAAADJEc7MAAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH4wkWDyUKJxzXegAAAB1pVFh0Q29tbWVudAAAAAAAQ3JlYXRlZCB3aXRoIEdJTVBkLmUHAAAAUklEQVQY02Ocd/j/fwY0kGjDwMhACPz//5/h////DPMO//8PYxODWXAZOP8Iw39k22F8uBg2G7Gx0cWYGMgEWJ2aaMPAiO5UDOcTGxjogUe2UwHwdJDZUucW5QAAAABJRU5ErkJggg=="></a></p>
<a href="https://briancallahan.net/blog/feed.xml"><img src="https://briancallahan.net/blog/media/pic_rss.gif"></a>
	<br>
	<hr>
	
    

</div>]]>
            </description>
            <link>https://briancallahan.net/blog/20200812.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139943</guid>
            <pubDate>Thu, 13 Aug 2020 04:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I'm 15 and made a bedtime calculator with React JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 119 (<a href="https://news.ycombinator.com/item?id=24139339">thread link</a>) | @joshternyak
<br/>
August 12, 2020 | https://www.sleepsources.com/bed-time-calculator/ | <a href="https://web.archive.org/web/*/https://www.sleepsources.com/bed-time-calculator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sleepsources.com/bed-time-calculator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139339</guid>
            <pubDate>Thu, 13 Aug 2020 02:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being a generalist requires more sleep than specialists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138674">thread link</a>) | @searchableguy
<br/>
August 12, 2020 | https://hndex.org/1730462 | <a href="https://web.archive.org/web/*/https://hndex.org/1730462">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

<a href="https://news.ycombinator.com/item?id=1730462" target="_blank">comments</a> <a href="https://andymckenzie.blogspot.com/2010/09/trade-off-10-plasticity-vs.html" target="_blank">original article</a></header>
<p>In college, I was constantly reading neuro lit extolling the
virtues of neural plasticity, which is the ability of neurons to
change based on feedback from the environment. Plasticity certainly
has huge benefits. Specifically, plasticity allows for a better
match between phenotype and environment across variable
environments than a single, constant phenotype would.</p>
<p>But after a while, the idolatry of plasticity began to annoy me,
in part because much of the lit discussed plasticity <i>as if it
had no downsides</i>, which seems impossible. (If there really were
no costs to plasticity, then evolution should have selected for it
like <i>woah</i>).</p>
<p>The general downside seems to be that plasticity hinders
specialization. That is, if a system has the ability to change
easily (i.e. it has high plasticity), then it will tend to expend
resources on a wide range of trait values, and will have fewer
resources to focus on the most important and relevant traits. A few
examples:</p>
<ul>
<li>Synaptic pruning and other mechanisms for synaptic plasticity
allow for learning and memory, but they are energetically costly.
Indeed, one hypothesis holds that sleep is the price we have to pay
for plasticity the previous day. (see here)</li>
<li>In an evolutionary framework, the major costs to more
plasticity are 1) actually sensing the current environmental
conditions, and 2) producing the actual trait in a less efficient
way. Both of these divert resources from other tasks. (see here and
here)</li>
<li>People with autism spectrum disorders often find it difficult
to parse novel stimuli, but can sometimes concentrate for
especially long periods of time on specific niches. So one might
think of the autistic cognitive style as shifted towards the
specialization side of this trade off. (see here)</li>
</ul>
<p>Despite the many applications, the members of the committee and
I are a bit wary about this trade off. First, its status depends
largely on one's particular definitions of plasticity and
specialization. Also, some think it might just be a specific case
of trade off #3, switching costs vs change gains.</p>
<p>But given our current working definitions (plasticity = the
ability, which is highly correlated with the tendency, for
context-dependent change; specialization = funneling energy
expenditures to a narrow purpose), and because it is sort of one
level "meta" to switching costs vs change gains, we are granting
this trade off its own place in the canon.</p>
<p>(Above photo taken by flickr user uncle beast. Plants are often
studied w/r/t genetic plasticity because they can't simply pack up
shop and move if the environment changes, like an animal or insect
could.)</p>
</article></div>]]>
            </description>
            <link>https://hndex.org/1730462</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138674</guid>
            <pubDate>Thu, 13 Aug 2020 00:19:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 1: back to basics]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24138590">thread link</a>) | @conorh
<br/>
August 12, 2020 | https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-cnct8"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_d714cff5c2c346ca9f3f81a007aa2b44~mv2.jpg/v1/fit/w_900,h_597,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_d714cff5c2c346ca9f3f81a007aa2b44~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-dpa1h">Vitamin D is a big deal. Recent studies have shown that patients with low Vitamin D levels are more likely to die from Covid-19 than their Vitamin D-rich counterparts,(1) and deficiency in the vitamin has been linked to seven of the ten leading causes of death in the U.S.(2) These facts alone have been enough incentive for many people to start supplementing the vitamin. A common question from my patients is: how much Vitamin D should I take? This is a simple question, but there are a lot of assumptions built in. Before you order that case of Vitamin D for you and your family, let’s back up and look a little more at the data.
 </p><p id="viewer-49tlt">First, why I’m interested in Vitamin D: I’m a parathyroid surgeon, and the vitamin is something I track closely in my patients. For background, the parathyroid glands are tiny endocrine organs in your neck that regulate blood calcium levels. They do this partly through the activation of Vitamin D, which helps the intestines absorb calcium. Without Vitamin D, you will have difficulty getting enough calcium, even if you are taking calcium supplements. Your bones need calcium, so a severe deficiency in Vitamin D leads to bone deformities in children (rickets) and bone loss in adults (osteomalacia). </p><div id="viewer-bovng"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_4a3a0724a42049019ad1182bcdb30d79~mv2.png/v1/fit/w_700,h_375,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_4a3a0724a42049019ad1182bcdb30d79~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-csmdc"><em> Normal child femurs compared to femurs of a child with rickets. Rickets is caused by a severe Vitamin D deficiency while bones are growing. This condition is now very rare in the U.S. due to the fortification of almost all milk with Vitamin D.* </em></p><p id="viewer-6lba0">The relationship between parathyroid hormone, calcium, and Vitamin D is complex and fascinating (at least to a parathyroid surgeon), but the vitamin appears to do much more than just influence calcium. We’re still figuring out all that it does, but we have some circumstantial evidence about its roles. Low Vitamin D levels are linked to a variety of illnesses including cancers, hypertension, diabetes, obesity, heart failure, stroke, dementia, autoimmune disease, and respiratory tract infections (including Covid-19). A simple search of the medical literature on PubMed produces page after page of articles on the harms of Vitamin D deficiency. </p><p id="viewer-5l5ac"><strong>Most studies follow this pattern:</strong> Two sets of people are evaluated. One set has a certain disease (diabetes, for example). The other set does not have the disease. Vitamin D levels are measured in both groups. Vitamin D deficiency is found to be much more common in the group of diseased individuals. </p><p id="viewer-4f52t">Using this study method, Vitamin D deficiency is correlated with many diseases. But correlation does not equal causation. The fact that two things are related does not imply that one caused the other. With regard to the vitamin and diabetes, it could be that diabetes causes low Vitamin D. Or it may be that some other health condition causes both low Vitamin D and diabetes. Obesity, for example, is a known risk factor for diabetes, and people who are obese also tend to have low Vitamin D levels, due mostly to the dilution of the fat-soluble vitamin in the larger mass of adipose tissue. The close association between Vitamin D and diabetes could be due simply to the association they both share with obesity. </p><p id="viewer-1plm0">Here is another example: Early interest in respiratory infections and Vitamin D was due to research on hospitalized children. Young children who were hospitalized with respiratory infections were found to have much higher rates of rickets than children hospitalized for other causes.(3) Rickets, of course, is caused by Vitamin D deficiency. If Vitamin D deficiency also causes immune dysfunction, we might come up with an explanation for how low Vitamin D in these children made them more susceptible to infection. But there are other explanations. Children with a serious vitamin deficiency are likely to be less healthy overall compared to non-deficient children. In addition, rickets can cause rib deformities, which are known to make it harder to cough and breathe deeply, leading to an increased risk of respiratory infections. Vitamin D itself is not necessary for explaining the infections in these children. 
 </p><p id="viewer-8d45v">Most researchers understand that correlation does not equal causation. The classic example of this involves the correlation between ice cream and violent crime. As ice cream consumption rises, so does the rate of violent crime. The association is strong, and puzzling, until you remember that more ice cream is sold during warmer months, which is also when violent crime rates rise. Ice cream has no causative connection to crime. </p><div id="viewer-8u104"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_7750c8e0f0804ca7b241349a5caa3f6a~mv2.jpg/v1/fit/w_900,h_720,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_7750c8e0f0804ca7b241349a5caa3f6a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-2muq9"><em>Children about to embark on a life of crime?</em></p><p id="viewer-i9b6"><strong>But the temptation to equate correlation and causation is strong.</strong> Many articles showing a correlation with Vitamin D will add an untested but completely plausible physiological explanation for how low vitamin levels could lead to the disease. Armed with a solid correlation and a reasonable argument for causation, they may feel justified in concluding that the evidence for causation is strong. And once you have made that leap, you are almost obligated in recommending Vitamin D supplementation for anyone affected by or concerned about your disease of interest. </p><p id="viewer-9rfi1">Assuming that the correlations between Vitamin D and various illnesses are accurate, the argument for supplementation then depends on the plausibility of the physiologic mechanism. The numerous conditions associated with the deficiency involve disparate organs and body systems. To understand how one vitamin could be involved in so much, and whether we can explain a disease state by the vitamin's deficiency, it helps to know the basics of what Vitamin D does on a molecular level.</p><p id="viewer-ccvgc"><strong>Vitamin D is a hormone that binds to the Vitamin D Receptor</strong>, a protein made by cells throughout your body. The vitamin acts like a key, while the receptor is a lock. A key and lock are pointless individually, but useful together. Vitamin D and its receptor are inactive until they combine, and then they interact with DNA to produce certain actions within the cell. Based on what we already know, it is easy to understand why the intestines, parathyroids, and bones make Vitamin D Receptors – these organs are all involved in regulating calcium levels, and we know Vitamin D regulates calcium metabolism. But those are not the only organs that have the receptors. We find these receptors all over the place, in the kidneys, lungs, pancreas, uterus, and blood cells involved in immune function, just to name a few.(4,5) </p><p id="viewer-5olt1">Our bodies like to conserve resources, so if an organ or cell uses energy and resources to make these receptors, we can assume that they use them. This is the first solid piece of evidence that Vitamin D is involved in many processes throughout multiple organs. The next goal is to figure out how the organs use Vitamin D. There are various ways to do this. One clever method involves the use of mutant mice called “knockout mice” that have been genetically modified to inactivate a specific gene. In this case, the gene for the Vitamin D Receptor is inactivated, to produce "VDR null" mice. Studies in these animals provide important clues about Vitamin D, since without the lock, or receptor, the key is useless. As expected, these knockout mice have problems with calcium absorption, and the most notable effect is stunted bone growth.(6) This can be mitigated by giving the mice lots of calcium, which makes sense, since it is possible but harder for calcium to be absorbed without Vitamin D.</p><div id="viewer-3qo09"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/a27d24_ea278d26b9924aa2b2b0105b816d4c62~mv2.jpg/v1/fit/w_887,h_377,al_c,q_80/file.png" src="https://static.wixstatic.com/media/a27d24_ea278d26b9924aa2b2b0105b816d4c62~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-75iel"><em>Knockout mice are mice that have been genetically modified to inactivate a specific gene. VDR null mice are knockout mice that do not make Vitamin D Receptors. (The mouse in the photo is just a random mouse. We don't actually grow them in petri dishes.)</em></p><p id="viewer-4s6nd">But we already knew about Vitamin D and calcium. What about those other effects? VDR null mice should be helpful in explaining Vitamin D’s other roles, and we do see some revealing changes: these mutant mice on average have higher blood pressure than normal mice, and mice lacking the receptor specifically on the heart have decreased cardiac function. Certain immune cells also seem to also be impaired in the mutant mice.</p><p id="viewer-fakeg">Following this out a few steps, we could come up with a logical explanation for how Vitamin D helps the immune system, and thus deficiency would lead to impaired immune function, which then lead to increased susceptibility to infections. It sounds reasonable. But there are a few assumptions we are making: 1. We assume that Vitamin D deficiency is similar to a complete absence of the receptor. This is questionable, since even people with severe Vitamin D deficiencies still have some amount of Vitamin D. 2. We also assume that the receptor works exactly the same in mice as it does in humans. Mice and humans are relatively close on the evolutionary tree (when compared to, say, shiitake mushrooms), so this could be true, but maybe not.</p><p id="viewer-5b36s">Maybe we need to go back to humans. Interestingly, there is a very rare condition in humans characterized by ineffective Vitamin D Receptors due to a genetic mutation, similar to the VDR null mice.(7) Like the mice, these individuals will develop severely abnormal bone growth if untreated. Thinking logically and using what we know about the receptor in mice, we might expect that these individuals who cannot process Vitamin D effectively would have immune dysfunction, and perhaps cardiac issues. So far, we have not seen this. They do not appear to have an increased risk of cancer, respiratory infections, diabetes, or any of the other conditions found to be associated with Vitamin D deficiency. This genetic defect is extremely rare, though, and we have not yet been able to study these patients over a lifetime, so we may have more to learn. </p><p id="viewer-1lu5r">Studying the Vitamin D Receptor in living bodies is not the only way to assess Vitamin D’s actions. We can also study Vitamin D in a lab, using living cells in a test tube or culture dish. Much of our evidence for a link between Vitamin D and immunity comes from these <em>in vitro</em> studies. Vitamin D Receptors are …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics">https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138590</guid>
            <pubDate>Thu, 13 Aug 2020 00:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memoization in Dynamic Programming Through Examples]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138567">thread link</a>) | @algodaily
<br/>
August 12, 2020 | https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article | <a href="https://web.archive.org/web/*/https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138567</guid>
            <pubDate>Thu, 13 Aug 2020 00:03:33 GMT</pubDate>
        </item>
    </channel>
</rss>
