<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 15 Jul 2020 20:16:39 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 15 Jul 2020 20:16:39 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Purism-Librem13v4]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830046">thread link</a>) | @luu
<br/>
July 14, 2020 | https://anarc.at/hardware/laptop/purism-librem13v4/ | <a href="https://web.archive.org/web/*/https://anarc.at/hardware/laptop/purism-librem13v4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>The <a href="https://puri.sm/products/librem-13/">Purism Librem 13</a> is a 13" laptop that's similar to the
Macbook Air but slightly heavier and thicker, from what I
understand. I have the <code>v4</code> means it's the fourth hardware version of
the device. This is the latest incarnation of the <a href="https://anarc.at/hardware/angela/">angela</a>
node.</p>

<p>TL;DR: I recommend people avoid the Purism brand and products. I find
they have questionable politics, operate in a "libre-washing" fashion,
and produce unreliable hardware. Will not buy again.</p>





<ul>
<li>Operating system: PureOS</li>
<li>TPM: Included</li>
<li>Battery life: Roughly 7 to 9 hours (actual: more like 6h)</li>
<li>Processor: Core i7 7500U (Kabylake)</li>
<li>Display: 13.3" 1920×1080</li>
<li>Graphics: Intel HD Graphics 620</li>
<li>Memory: Up to 32GB, DDR4 at 2133 MHz</li>
<li>Storage: 2.5" SATA + NVMe-capable M.2 slots</li>
<li>Chassis: Black anodized aluminium</li>
<li>Webcam: 720p 1.0 megapixel</li>
<li>Dimensions: 325×219×18mm</li>
<li>Weight: 1.4kg</li>
<li>Wireless: Atheros 802.11n w/ Two Antenna</li>
<li>Radio hardware killswitch: Yes</li>
<li>Mic and cam killswitches: Yes</li>
<li>Audio port: 1 headphone/line output jack</li>
<li>USB ports: 2 USB 3.0 Ports (1 type C, data transfer only)</li>
<li>External monitor output: 1 HDMI Port (4K capable @ 30Hz max)</li>
<li>Card reader: Yes, 2-in-1 SD/MMC</li>
<li>Backlit keyboard: Yes</li>
<li>Touch interface: Elantech Multitouch Trackpad</li>
<li>Thermal design: Low noise fan (actual: not really, quite noisy when
all CPUs are maxed)</li>
</ul>

<p>The machine came with a 250GB Crucial SSD drive with PureOS
pre-installed, even if I ordered it without storage.</p>

<h2 id="semi-standard-power-connector"><a name="index1h2"></a>Semi-standard power connector</h2>

<p>The power connector is <a href="https://learn.sparkfun.com/tutorials/connector-basics/power-connectors">somewhat standard</a>: 19V DC on a 5.5mm
sleeve with 2.5 positive pin, with a <a href="https://en.wikipedia.org/wiki/IEC_60320#C5/C6_coupler">C5/C6 cable</a> for the AC side
(as opposed to the more standard C13/C14 coupler, mind you). I was
able to find a "universal 19V adapter" for ~60$ at a local store that
also supported other barrel connectors.</p>

<p>It would be better if the laptop would charge through USB-C,
naturally, as <em>that</em> is slowly becoming the standard for charging
computing devices, but that will have to do for now.</p>

<h2 id="good-monitor"><a name="index2h2"></a>Good monitor</h2>

<p>The monitor shipped with the Librem is actually quite good by my
standards (1920x1080 / 1080p / FullHD). It does mean messing around
with <a href="https://wiki.debian.org/MonitorDPI">HiDPI</a> settings which I haven't quite figured out yet.</p>

<p><a href="https://vincent.bernat.ch/en/blog/2018-4k-hidpi-dual-screen-linux">This post</a> seems to have good resources. From what I understand,
the resolution of the screen is actually 166dpi, which takes some
configuring to display properly. This can be computed from the aspect
ratio (16:9), the resolution (1920x1080) and the diagonal of the
screen (13.3"). According to <a href="https://www.sven.de/dpi/">this calculator</a>, this is the
formula:</p>

<pre><code>Display size: 11.59" × 6.52" = 75.59in² (29.44cm × 16.56cm = 487.64cm²) at 165.63 PPI, 0.1534mm dot pitch, 27434 PPI² 
</code></pre>

<p>All this does make my old monitor (which I found in the basement) look
like crap. So I need to find a <a href="https://forums.puri.sm/t/suitable-external-monitor-for-librem-13/5627">new monitor</a>, arguably not a
problem with the Librem per se of course...</p>

<p>It seems the Librem can drive 1440p, so not "4K UHD" (3840x2160), but
"QHD" (2560x1440) which should be more than enough.</p>

<h2 id="liberated-boot"><a name="index3h2"></a>Liberated boot</h2>

<p>The Purism folks did a pretty awesome job at liberating their
BIOS. They run their own version of coreboot they call
<a href="https://docs.puri.sm/PureBoot.html">Pureboot</a>. In theory, it should be easier to setup a trusted,
<a href="http://wiki.debian.org/SecureBoot">SecureBoot</a> but in practice I have yet to set that up.</p>

<p>I did try to configure the laptop with an encrypted <code>/boot</code>, but that
didn't go so well. First, I get a double password prompt: once in
<code>grub</code> and once in the <code>initramfs</code>. But more annoying is the <code>grub</code>
prompt has no retry: if you fail, you drop in the rescue shell which
is really impractical.</p>

<p>(Update: that is, of course, not specific to Purism or PureOS, but a
limitation in grub itself.)</p>

<p>Finally, Pureboot doesn't support encrypted <code>/boot</code> so it actually
makes it <em>harder</em> to implement trusted boot.</p>

<p>The coreboot stuff needs to be updated, and instructions are available
<a href="https://puri.sm/coreboot/">on the Purism website</a>.</p>

<h2 id="excellent-linux-support"><a name="index4h2"></a>Excellent Linux support</h2>

<p>On top of the liberated BIOS, it must be said the device has
<em>excellent</em> support for free operating systems. <em>Every</em> device on the
machine has full support in the Linux kernel, even the "older" version
in Debian stretch (Linux 4.9). No binary blobs, no proprietary
drivers, even for wifi.</p>

<p>That is just awesome. It's the first device, in a long time, that
gives me this freedom, so it should be acknowledged and celebrated.</p>

<p>Update: I still have some <code>non-free</code> packages installed:</p>

<ul>
<li><p>the Intel CPU firmware package (<a href="http://packages.debian.org/intel%2Dmicrocode">intel-microcode</a>)</p></li>
<li><p>I also use some "non-free" documentation packages (<a href="http://packages.debian.org/doc%2Drfc">doc-rfc</a>, <a href="http://packages.debian.org/emacs%2Dcommon%2Dnon%2Ddfsg">emacs-common-non-dfsg</a>, <a href="http://packages.debian.org/make%2Ddoc">make-doc</a>)</p></li>
<li><p>Bluetooth requires <a href="http://packages.debian.org/firmware%2Datheros">firmware-atheros</a></p></li>
</ul>

<p>When building the <code>initramfs</code>, there are warnings about the <code>i915</code>
graphics controller, which is solved by installing the <a href="http://packages.debian.org/firmware%2Dmisc%2Dnonfree">firmware-misc-nonfree</a> package, but the graphics card works without
the firmware. Apparently, the warnings are harmless and indeed PureOS
fixed <a href="https://tracker.pureos.net/T362">the bug</a> by simply <a href="https://source.puri.sm/pureos/core/initramfs-tools/commit/005ca5b834fa7ee44bb913d74b4ff2aa542fc9d1">disabling all such warnings</a>.3</p>

<p>The Debian-specific stuff is also documented in <a href="https://wiki.debian.org/InstallingDebianOn/Purism/Librem%2013">the Debian wiki</a>.</p>

<h2 id="good-speakers"><a name="index5h2"></a>Good speakers</h2>

<p>The builtin speakers sound great.</p>



<p>I have a few issues with the device.</p>

<h2 id="weird-keyboard-layout"><a name="index6h2"></a>Weird keyboard layout</h2>

<p>The <a href="https://forums.puri.sm/t/keyboard-layout-unable-to-recognize-pipe/2022">keyboard layout is strange</a>: the key above <kbd>enter</kbd>,
instead of sending <kbd>\</kbd> or <kbd>|</kbd>, sends
"chevrons". This is due to the Purism folks expecting you to pick the
"US international" keyboard instead of the "US" keyboard, which is a
very strange pick, as the "US" keyboard seems pretty standard. The
workaround is to drop this in your <code>udev</code> configuration, say in
<code>/etc/udev/hwdb.d/90-purism-pipe-symbol-fix.hwdb</code>:</p>

<pre><code>evdev:atkbd:dmi:bvn*:bvr*:bd*:svnPurism:pnLibrem13v4*
 KEYBOARD_KEY_56=backslash
</code></pre>

<p>Then running:</p>

<pre><code>sudo systemd-hwdb update
sudo udevadm trigger
</code></pre>

<p>The keyboard layout, in general, is a little unique: the sound buttons
are split across the <kbd>F4</kbd> key (mute) and
<kbd>-</kbd>/<kbd>=</kbd> (volume up/down keys) for some reason.</p>

<p>The <kbd>PrtSc</kbd> key <a href="https://forums.puri.sm/t/does-alt-sysrq-work-on-librem-laptops/5290/9">can be as SysRq</a> but is <em>backwards</em>
(<kbd>ScrLk</kbd> <kbd>PrtSc</kbd>) to their usual order
(<kbd>PrtSc</kbd> <kbd>ScrLk</kbd>).</p>

<h2 id="limited-usb-c-port"><a name="index7h2"></a>Limited USB-C port</h2>

<p>The USB-C port <a href="https://forums.puri.sm/t/is-hdmi-over-usb-c-possible-on-13v2/2020">does not support video</a> which makes it limited to
charging and data transfer. It can also not charge the laptop itself,
as there's a separate power connector, losing many of the benefits
usually associated with USB-C.</p>

<p>Ideally, a USB-C port might be used as a universal docking port: one
wire to plug and you have power, video, audio, and USB for keyboard
and mouse. Unfortunately, I'm still stuck with about 4 wires to plugin
when I come into the office, something I was hoping to avoid. People
have <a href="https://forums.puri.sm/t/please-recommend-a-port-replicator-docking-station/1115">looked for a dock station</a> without success.</p>

<h2 id="shipping-delays-doa"><a name="index8h2"></a>Shipping delays, DOA</h2>

<p>I waited almost four weeks to have my laptop delivered. Presumably
this was due to a <a href="https://forums.puri.sm/t/where-was-purism-moving/5799/">warehouse move</a> but I found that communication
about the issue could have been better. Worse: the laptop was <a href="https://forums.puri.sm/t/librem-13v3-bricked/5714/19?u=anarcat">dead on
arrival</a> (DOA) so I had to return it, adding another week delay for
getting an actual working laptop. FedEx even charged me for the return
even though Purism actually issued a shipping label, something I still
haven't quite resolved.</p>

<p>Update: I ended up paying over 260$ in shipping fees to Fedex, in the
end. I first paid around 70$ for the first laptop sent, then Fedex
sent me <em>another</em> 200$ bill for the <em>second</em> laptop. Purism were
unable to help me with this issue and Fedex has been totally useless
as well. I've tried to reach to both organizations to get around those
fees but the time wasted waiting on hold and support has outgrown the
possible savings I could to by not paying the damn bill, so I just
paid it now.</p>

<h2 id="bright-leds-not-accessible-when-lid-closed"><a name="index9h2"></a>Bright LEDs, not accessible when lid closed</h2>

<p>There are three leds on the top right of the keyboard: one for wifi,
battery and power. They are very bright and even though they can
technically be dimmed, the firmware is not open so there's <a href="https://forums.puri.sm/t/is-there-a-way-to-dim-the-leds-on-the-13-v2/1172">no way to
dim the LEDs</a>. </p>

<h2 id="no-ethernet-port"><a name="index10h2"></a>No ethernet port</h2>

<p>That was a deal breaker for me originally, but I changed my
mind. First, I don't need gigabit transfer speeds that often. Then my
office doesn't have wired connectivity yet, so it is not that
useful. Plus, I can afford to have a USB dongle there with a gigabit
ethernet port, indeed, I already have one of those USB hubs. So not
that big of a deal.</p>

<h2 id="libre-washing"><a name="index11h2"></a>Libre-washing</h2>

<p>I have found Purism's commitment to free hardware and free software to
be questionable. While, yes, they try to provide a <a href="#liberated-boot">liberated boot</a>
and coreboot-based BIOS, that BIOS is not free software. At best they
"neuter" the Intel Management Engine, but you still require non-free
firmware to operate a Librem Computer, from the CPU down to the
Bluetooth and Wifi hardware. Even if that is a very common pattern on
laptops and phone, it is a huge disconnect with the "purity" and
"freedom" narrative on their website.</p>

<p>For example, the replacement for the Librem 13, called Librem 14,
claims to be:</p>

<blockquote>
  <p><strong>The first 14″ laptop designed to protect your digital life</strong></p>
  
  <p>Ultra-portable workstation laptop that was designed chip-by-chip,
  line-by-line, to respect your rights to privacy, security, and
  freedom.</p>
</blockquote>

<p>Yet it still ships with Intel processors, known for a large variety of
fundamental security issues that are part of the hardware design,
which Intel refuses to fix. That it ships <a href="https://puri.sm/coreboot/">coreboot</a> on top of that
is besides the point: coreboot, as shipped by Purism, is not open
source, or at least ships proprietary blobs.</p>

<p>Compare this with the work System76 has been doing in recent
times. While they brand themselves as just a company shipping Linux
laptops, they <a href="https://blog.system76.com/post/187072707563/the-new-firmware-manager-updating-firmware-across">work with the de-facto standard LVFS</a> (even though
that is a <a href="https://blog.system76.com/post/173801677358/system76-and-lvfs-what-really-happened">bumpy ride</a>), actually <a href="https://blog.system76.com/post/612315972866637824/a-look-back-at-manufacturing">design and prototype their own
hardware</a>, and <a href="https://opensource.com/article/20/1/system76-open-source-firmware">liberated their keyboard microcontroller</a>. They
have even started <a href="https://blog.system76.com/post/186655523269/open-firmware-and-more-news-from-july">working on an open Thunderbolt
microcontroller</a>. And while those might sound like small things
compared to liberating the CPU firmware, I will point out that they
actually <em>succeed</em> in completely liberating those components, while
Purism, in the <em>years</em> they have supposedly been working on those
projects, have only managed to reuse (and, to be fair, improve on) the
work <em>others</em> have done to neutralize the IME.</p>

<p>What has Purism done, in the meantime? Neutralized IME. That's
it. They have not published <em>anything</em> on LVFS. Even closed-source
companies like <a href="https://fwupd.org/lvfs/vendors/#logitech">Logitech</a>, <a href="https://fwupd.org/lvfs/vendors/#synaptics">Synaptics</a>, <a href="https://fwupd.org/lvfs/vendors/#hp-ws">HP</a> and <a href="https://fwupd.org/lvfs/vendors/#dell">Dell</a>
ship their updates on LVFS. Purism <a href="https://fwupd.org/lvfs/vendors/#purism">has a test account</a> and work
has been <a href="https://forums.puri.sm/t/submit-firmware-to-linux-vendor-firmware-service-lvfs-for-easy-updating/4731">stalled for years now</a>.</p>

<h2 id="bullshit-anti-interdiction"><a name="index12h2"></a>Bullshit …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anarc.at/hardware/laptop/purism-librem13v4/">https://anarc.at/hardware/laptop/purism-librem13v4/</a></em></p>]]>
            </description>
            <link>https://anarc.at/hardware/laptop/purism-librem13v4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830046</guid>
            <pubDate>Tue, 14 Jul 2020 09:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Rust NIFs for Elixir with Rustler]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23829651">thread link</a>) | @marcoow
<br/>
July 14, 2020 | https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/ | <a href="https://web.archive.org/web/*/https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>Rustler is a fantastic project built to make writing Rust NIFs a simple process;
and the upcoming v0.22 release will provide a much cleaner syntax to do so. The
library handles encoding and decoding Rust values into Erlang terms, catches
Rust panics before they unwind to C and <em>should</em> make it impossible to crash the
BEAM from a Rust NIF.</p>
<h2 id="getting-started-with-rustler">Getting started with Rustler</h2>
<p>One of my first forays into Rust-implemented NIFs was while building a
micro-library providing Base64 encoding and decoding, creatively named
<a href="https://github.com/niklaslong/base64" target="_blank" rel="noopener">base64</a>. It's utterly pointless as that
functionality comes built-in to Elixir but I wanted to start with something
simple. On the plus side, this meant I could easily compare the performance of
the NIF version to the Elixir implementation which can be found in the
<a href="https://hexdocs.pm/elixir/Base.html" target="_blank" rel="noopener"><code>Base</code> module</a>.</p>
<p>The library consists of two functions: <code>encode/2</code> and <code>decode/2</code> and it's using
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64</a> to do the heavy
lifting in the NIFs. Let's walk through how this all works.</p>
<p>To get started, we need a new mix project with rustler installed as a
dependency.</p>
<pre><code>mix new base64

mix deps.get
mix rustler.new
</code></pre><p>Let's explore the project's resulting structure (I've left out the usual Elixir
files and directories and focused on <code>lib</code> and <code>native</code>):</p>
<pre><code>.
â”œâ”€â”€ lib
â”‚   â””â”€â”€ base64.ex
â””â”€â”€ native
    â””â”€â”€ base64_nif
        â”œâ”€â”€ Cargo.lock
        â”œâ”€â”€ Cargo.toml
        â”œâ”€â”€ README.md
        â””â”€â”€ src
            â””â”€â”€ lib.rs</code></pre><ul>
<li><code>lib</code> will contain Elixir code (like any standard mix project).</li>
<li><code>base64.ex</code> will contain the stubs to our NIFs. This is the Elixir module the
NIF module will be registered to.</li>
<li><code>native</code> will be home to the Rust code. In fact, a cargo package has been
created within this directory (in this case named <code>base64_nif</code>).</li>
<li><code>lib.rs</code> will contain the NIFs.</li>
</ul>
<p>The Rust NIFs are compiled and linked into a shared library loaded by Erlang
code at runtime. Elixir (or Erlang) implementations of the functions are also
necessary. These are usually minimal stubs defining the name and arity of the
NIFs and serve as fallback implementations if the NIFs aren't loaded. Let's
start with the Elixir stubs.</p>
<pre><code>

<span><span>defmodule</span> <span>Base64</span></span> <span>do</span>
  <span>use</span> Rustler, <span>otp_app:</span> <span>:base64</span>, <span>crate:</span> <span>"base64_nif"</span>

  <span>@spec</span> decode(binary, atom) :: binary
  <span><span>def</span> <span>decode</span></span>(_b64, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span>@spec</span> encode(binary, atom) :: binary
  <span><span>def</span> <span>encode</span></span>(_s, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span><span>defp</span> <span>error</span></span>(), <span>do:</span> <span>:erlang</span>.nif_error(<span>:nif_not_loaded</span>)
<span>end</span></code></pre><p>The first line is configuration and lets Rustler know what Rust crate to compile
for the Elixir module.</p>
<p>As mentioned above, <code>decode/2</code> and <code>encode/2</code> don't actually implement any
decoding or encoding; they simply call <code>error/0</code> if the NIFs can't be found.
However, the names and the arguments must match in both the Rust and Elixir
implementations. Both functions take in a <code>binary</code> to be encoded or decoded and
an <code>atom</code> for configuration as different character sets that can be used
(url-safe, without padding, etc...). The default is fittingly set to
<code>:standard</code>. The Rust NIFs are implemented as follows.</p>
<pre><code>

<span>use</span> base64;
<span>use</span> rustler::Atom;

<span>mod</span> atoms {
    rustler::atoms! {
      crypt,
      imap_map7,
      standard,
      standard_no_pad,
      url_safe,
      url_safe_no_pad,
    }
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>decode</span></span>(b64: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    <span>let</span> bytes = base64::decode_config(b64, config).expect(<span>"decode failed: invalid b64"</span>);

    <span>String</span>::from_utf8(bytes).unwrap()
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>encode</span></span>(s: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    base64::encode_config(s.as_bytes(), config)
}

<span><span>fn</span> <span>match_config</span></span>(option: Atom) -&gt; base64::Config {
    
}

rustler::init!(<span>"Elixir.Base64"</span>, [decode, encode]);</code></pre><p>The last line is interesting: <code>rustler::init</code> is a procedural macro that allows
the use of <code>#[rustler::nif]</code> to annotate functions to be wrapped as NIFs. It
takes in the name of the Elixir module in which the stubs are defined (in this
case <code>"Elixir.Base64"</code>) and an array containing the names of the functions
annotated as NIFs (in this case <code>[decode, encode]</code>). In short, this links
everything together.</p>
<p>The use statements at the top of the file are importing the
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64 crate</a> (<code>base64</code>)
mentioned earlier, which we'll use for encoding and decoding, and the
<code>rustler::Atom</code> type which allows us to represent an Elixir/Erlang <code>atom</code> in
Rust. Both the <code>rustler</code> and <code>base64</code> crates have been added to the <code>Cargo.toml</code>
dependencies.</p>
<p>The <code>rustler::atoms</code> macro defines Rust functions that return Erlang atoms; in
this case, the possible options for the <code>encode/2</code> and <code>decode/2</code> functions.</p>
<p>Finally, we come to the NIF definitions. The functions take in a <code>String</code> and a
<code>rustler::Atom</code>, and return a <code>String</code>. This is consistent with the Elixir
stubs, as are the names. In this case, the conversions between Rust values and
Elixir terms are conveniently handled by Rustler. However, for more complex
types, this may need to be implemented manually.</p>
<h2 id="how-does-it-compare-to-the-elixir-implementation">How does it compare to the Elixir implementation?</h2>
<p>Rust is fast. Really fast. This was my set-up (using
<a href="https://github.com/bencheeorg/benchee" target="_blank" rel="noopener">benchee</a>):</p>
<pre><code>Operating System: macOS
CPU Information: Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
Number of Available Cores: 4
Available memory: 16 GB
Elixir 1.10.2
Erlang 22.3.2</code></pre><p>I used <em>hello world</em> as the short string and Sarah Kayâ€™s poem
<em><a href="https://www.youtube.com/watch?v=0snNB1yS3IE" target="_blank" rel="noopener">B (If I Should Have a Daughter)</a></em>
as the longer string.</p>
<p>Decoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif decode           175.74 K
Elixir/Erlang decode        4.35 K - 40.37x slower +224.03 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif decode           953.17 K
Elixir/Erlang decode      555.63 K - 1.72x slower +0.75 Î¼s</code></pre><p>Encoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif encode           203.14 K
Elixir/Erlang encode        6.95 K - 29.23x slower +138.98 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif encode           941.14 K
Elixir/Erlang encode      615.62 K - 1.53x slower +0.56 Î¼s</code></pre><p>As the data to encode or decode becomes larger, the overhead of creating the
NIFs becomes smaller and the gains in speed are impressive. These results were
obtained with fairly small data and so the potential performance gains possible
by leveraging Rust NIFs when dealing with CPU-intensive tasks are exciting.</p>
<p>I left out the memory usage comparisons but the Elixir/Erlang implementations
used 3-5x more memory than the NIFs.</p>
<h2 id="tldr-rustler-makes-it-easy-to-implement-nifs">TL;DR: Rustler makes it easy to implement NIFs</h2>
<p>Other than the <code>#[rustler::nif]</code> function annotations and the <code>rustler::init</code>
call, nothing more is required to implement Rust NIFs with Rustler. The
boilerplate and the complexities of translating Rust values to Erlang terms
being handled by the library, there's little resistance to leveraging the power
of Rust in Elixir/Erlang.</p>

  </div></div>]]>
            </description>
            <link>https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829651</guid>
            <pubDate>Tue, 14 Jul 2020 08:16:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tufte CSS]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23828196">thread link</a>) | @mmastrac
<br/>
July 13, 2020 | https://edwardtufte.github.io/tufte-css/ | <a href="https://web.archive.org/web/*/https://edwardtufte.github.io/tufte-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>Dave Liepmann</p>
      <section>
        <p>Tufte CSS provides tools to style web articles using the ideas demonstrated by Edward Tufte’s books and handouts. Tufte’s style is known for its simplicity, extensive use of sidenotes, tight integration of graphics with text, and carefully chosen typography.</p>
        <p>Tufte CSS was created by <a href="http://www.daveliepmann.com/">Dave Liepmann</a> and is now an Edward Tufte project. The original idea was cribbed from <a href="https://tufte-latex.github.io/tufte-latex/">Tufte-<span>L<span>a</span>T<span>e</span>X</span></a> and <a href="http://rmarkdown.rstudio.com/tufte_handout_format.html">R Markdown’s Tufte Handout format</a>. We give hearty thanks to all the people who have contributed to those projects.</p>
        <p>If you see anything that Tufte CSS could improve, we welcome your contribution in the form of an issue or pull request on the GitHub project: <a href="https://github.com/edwardtufte/tufte-css">tufte-css</a>. Please note the <a href="https://github.com/edwardtufte/tufte-css#contributing">contribution guidelines</a>.</p>
        <p>Finally, a reminder about the goal of this project. The web is not print. Webpages are not books. Therefore, the goal of Tufte CSS is not to say “websites should look like this interpretation of Tufte’s books” but rather “here are some techniques Tufte developed that we’ve found useful in print; maybe you can find a way to make them useful on the web”. Tufte CSS is merely a sketch of one way to implement this particular set of ideas. It should be a starting point, not a design goal, because any project should present their information as best suits their particular circumstances.</p>
      </section>

      <section>
        <h2 id="getting-started">Getting Started</h2>
        <p>To use Tufte CSS, copy <code>tufte.css</code> and the <code>et-book</code> directory of font files to your project directory, then add the following to your HTML document’s <code>head</code> block:</p>

        <pre><code>&lt;link rel="stylesheet" href="tufte.css"/&gt;</code></pre>

        <p>Now you just have to use the provided CSS rules, and the Tufte CSS conventions described in this document. For best results, View Source and Inspect Element frequently.</p>
      </section>

      <section>
        <h2 id="fundamentals">Fundamentals</h2>
        <h3 id="fundamentals--sections-and-headers">Sections and Headings</h3>
        <p>Organize your document with an <code>article</code> element inside your <code>body</code> tag. Inside that, use <code>section</code> tags around each logical grouping of text and headings.</p>
        <p>Tufte CSS uses <code>h1</code> for the document title, <code>p</code> with class <code>subtitle</code> for the document subtitle, <code>h2</code> for section headings, and <code>h3</code> for low-level headings. More specific headings are not supported. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:</p>
        <blockquote cite="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB">
          <p>[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of <em>sentences</em> which then cumulate sequentially into <em>paragraphs</em>, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.</p>
          
        </blockquote>
        <p>As a bonus, this excerpt regarding the use of headings provides an example of block quotes. In Tufte CSS they are just lightly styled, semantically correct HTML using <code>blockquote</code> and <code>footer</code> elements. See page 20 of <a href="https://www.edwardtufte.com/tufte/books_vdqi">The Visual Display of Quantitative Information</a> for an example in print.</p>
        <p><span>In his later books<label for="sn-in-his-later-books"></label></span><span><a href="http://www.edwardtufte.com/tufte/books_be"><em>Beautiful Evidence</em></a></span>, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and the first few words of the sentence set in small caps. For this we use a span with the class <code>newthought</code>, as demonstrated at the beginning of this paragraph. Vertical spacing is accomplished separately through <code>&lt;section&gt;</code> tags. Be consistent: though we do so in this paragraph for the purpose of demonstration, do not alternate use of header elements and the <code>newthought</code> technique. Pick one approach and stick to it.</p>

        <h3 id="fundamentals--text">Text</h3>
        <p>Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. Tufte CSS uses <code>#fffff8</code> and <code>#111111</code> because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. We stick to the greyscale for text, reserving color for specific, careful use in figures and images.</p>
        <p>In print, Tufte has used the proprietary Monotype Bembo<label for="sn-proprietary-monotype-bembo"></label><span>See Tufte’s comment in the <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt">Tufte book fonts</a> thread.</span> font. A similar effect is achieved in digital formats with the now open-source <a href="https://github.com/edwardtufte/et-book">ETBook</a>, which Tufte CSS supplies with a <code>@font-face</code> reference to a .ttf file. In case ETBook somehow doesn’t work, Tufte CSS shifts gracefully to other serif fonts like Palatino and Georgia.</p>
        <p>Also notice how Tufte CSS includes separate font files for bold (strong) and italic (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice.</p>
        <p>If you prefer sans-serifs, use the <code>sans</code> class. It relies on Gill Sans, Tufte’s sans-serif font of choice.</p>
        <p>Links in Tufte CSS match the body text in color and do not change on mouseover or when clicked. Here is a <a href="#">dummy example</a> that goes nowhere. These links are underlined, since this is the most widely recognized indicator of clickable text. <label for="mn-blue-links">⊕</label><span>Blue text, while also a widely recognizable clickable-text indicator, is crass and distracting. Luckily, it is also rendered unnecessary by the use of underlining.</span> However, because most browsers’ default underlining does not clear descenders and is so thick and distracting, the underline effect is instead achieved using CSS trickery involving background gradients instead of standard <code>text-decoration</code>. Credit goes to Adam Schwartz for that technique.</p>
        <p>As always, these design choices are merely one approach that Tufte CSS provides by default. Other approaches can also be made to work. The goal is to make sentences readable without interference from links, as well as to make links immediately identifiable even by casual web users.</p>
      </section>

      <section>
        <h2 id="epigraphs">Epigraphs</h2>
        <div>
          <blockquote>
            <p>The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.</p>
            
          </blockquote>
          <blockquote>
            <p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p>
            
          </blockquote>
          <blockquote>I do not paint things, I paint only the differences between things.</blockquote>
        </div>
        <p>If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. Modeled after chapter epigraphs in Tufte’s books (particularly <em>Beautiful Evidence</em>), these are <code>blockquote</code> elements with a bit of specialized styling. Quoted text is italicized. The source goes in a <code>footer</code> element inside the <code>blockquote</code>. We have provided three examples in the epigraph of this section, demonstrating shorter and longer quotes, with and without a paragraph tag, and showing how multiple quotes within an epigraph fit together with the use of a wrapper class.</p>
      </section>

      <section>
        <h2 id="sidenotes">Sidenotes: Footnotes and Marginal Notes</h2>
        <p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<label for="sn-extensive-use-of-sidenotes"></label><span>This is a sidenote.</span> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p>
        <p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p>
        <p>Sidenotes consist of two elements: a superscript reference number that goes inline with the text, and a sidenote with content. To add the former, just put a label and dummy checkbox into the text where you want the reference to go, like so:</p>
        <pre><code>&lt;label for="sn-demo"
       class="margin-toggle sidenote-number"&gt;
&lt;/label&gt;
&lt;input type="checkbox"
       id="sn-demo"
       class="margin-toggle"/&gt;</code></pre>
        <p>You must manually assign a reference <code>id</code> to each side or margin note, replacing “sn-demo” in the <code>for</code> and the <code>id</code> attribute values with an appropriate descriptor. It is useful to use prefixes like <code>sn-</code> for sidenotes and <code>mn-</code> for margin notes.</p>
        <p>Immediately adjacent to that sidenote reference in the main text goes the sidenote content itself, in a <code>span</code> with class <code>sidenote</code>. This tag is also inserted directly in the middle of the body text, but is either pushed into the margin or hidden by default. Make sure to position your sidenotes correctly by keeping the sidenote-number label close to the sidenote itself.</p>
        <p>If you want a sidenote without footnote-style numberings, then you want a margin note.
          <label for="mn-demo">⊕</label>
          
          <span>
            This is a margin note. Notice there isn’t a number preceding the note.
          </span> On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text. However, on small screens, a margin note is like a sidenote except its viewability-toggle is a symbol rather than a reference number. This document currently uses the symbol ⊕ (<code>&amp;#8853;</code>), but it’s up to you.</p>
        <p>Margin notes are created just like sidenotes, but with the <code>marginnote</code> class for the content and the <code>margin-toggle</code> class for the label and dummy checkbox. For instance, here is the code for the margin note used in the previous paragraph:</p>
        <pre><code>&lt;label for="mn-demo" class="margin-toggle"&gt;&amp;#8853;&lt;/label&gt;
&lt;input type="checkbox" id="mn-demo" class="margin-toggle"/&gt;
&lt;span class="marginnote"&gt;
  This is a margin note. Notice there isn’t a number preceding the note.
&lt;/span&gt;</code></pre>
        </section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edwardtufte.github.io/tufte-css/">https://edwardtufte.github.io/tufte-css/</a></em></p>]]>
            </description>
            <link>https://edwardtufte.github.io/tufte-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828196</guid>
            <pubDate>Tue, 14 Jul 2020 03:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strange public IPv4 address assigned behind NAT (2019)]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23827521">thread link</a>) | @rohan1024
<br/>
July 13, 2020 | https://broadbandforum.co/t/190267/ | <a href="https://web.archive.org/web/*/https://broadbandforum.co/t/190267/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://broadbandforum.co/t/190267/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827521</guid>
            <pubDate>Tue, 14 Jul 2020 01:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking with environment variables]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23827486">thread link</a>) | @pentestercrab
<br/>
July 13, 2020 | https://www.elttam.com/blog/env/ | <a href="https://web.archive.org/web/*/https://www.elttam.com/blog/env/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

<p>On a recent project we gained the ability to specify environment variables but not the process that was executed.
We were also unable to control the contents of a file on disk, and bruteforcing process identifiers (PIDs) and file descriptors found no interesting results, eliminating <a href="https://www.elttam.com/blog/goahead/">remote LD_PRELOAD exploitation</a>.
Fortunately, a scripting language interpreter was executed which enabled us to execute arbitrary commands by specifying particular environment variables.
This blog post discusses how arbitrary commands can be executed by a range of scripting language interpreters when supplied with malicious environment variables.</p>



<p>A quick read of the <code>ENVIRONMENT</code> section of the <code>perlrun(1)</code> man page reveals plenty of environment variables worth investigating.
The <code>PERL5OPT</code> environment variable allows specifying command-line options, but is restricted to only accepting the options <code>CDIMTUWdmtw</code>.
This unfortunately means that <code>-e</code>, which allows supplying perl code to run, is out.</p>

<p>All is not lost though, as demonstrated in the <a href="https://github.com/HackerFantastic/exploits/blob/master/cve-2016-1531.sh">exploit</a> for CVE-2016-1531 by <a href="https://twitter.com/hackerfantastic">Hacker Fantastic</a>.
The exploit writes a malicious perl module to <code>/tmp/root.pm</code> and supplies the environment variables <code>PERL5OPT=-Mroot</code> and <code>PERL5LIB=/tmp</code> to achieve arbitrary code execution.
However this was an exploit for a local privilege escalation vulnerability and a generic technique should ideally not require access to the file system. Looking at <a href="https://twitter.com/bl4sty">blasty</a>’s <a href="https://haxx.in/blasty-vs-exim.sh">exploit</a> for the same CVE, the exploit did not require creating a file and used the environment variables <code>PERL5OPT=-d</code> and <code>PERL5DB=system("sh");exit;</code>.
The same environment variables were also used to <a href="https://old.reddit.com/r/netsec/comments/1dm8fv/hack_this_website_and_win_bitcoins_the_first/c9tm6j4/">solve a CTF challenge</a> in 2013.</p>

<p>One final nicety of a generic technique would be to use a single environment variable instead of two.
<a href="https://twitter.com/justinsteven">@justinsteven</a> found this was possible by leveraging <code>PERL5OPT=-M</code>.
While either <code>-m</code> or <code>-M</code> can be used to load a perl module, the <code>-M</code> option allows adding extra code after the module name.</p>

<h2 id="proof-of-concept">Proof of Concept</h2>

<figure>
  <figcaption>Figure-0: arbitrary code execution achieved using an environment variable against perl running an empty script (/dev/null)</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>--env</span> <span>'PERL5OPT=-Mbase;print(`id`)'</span> perl:5.30.2 perl /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>Reading the <code>ENVIRONMENT VARIABLES</code> section of the <code>python(1)</code> man page, <code>PYTHONSTARTUP</code> initially appears like it may be a piece of a straightforward solution.
It allows specifying a path to a Python script that will be executed prior to displaying the prompt in interactive mode.
The interactive mode requirement didn’t seem like it would be an issue as the <code>PYTHONINSPECT</code> environment variable can be used to enter interactive mode, the same as specifying <code>-i</code> on the command line.
However, the documentation for the <code>-i</code> option explains that <code>PYTHONSTARTUP</code> will not be used when python is started with a script to execute.
This means that <code>PYTHONSTARTUP</code> and <code>PYTHONINSPECT</code> cannot be combined and <code>PYTHONSTARTUP</code> only has an effect when the python REPL is immediately launched.
This ultimately means that <code>PYTHONSTARTUP</code> is not viable as it has no effect when executing a regular Python script.</p>

<p>Other environment variables which looked promising were <code>PYTHONHOME</code> and <code>PYTHONPATH</code>. Both of these will let you gain arbitrary code execution but require you to also be able to create directories and files on the filesystem. It may be possible to loosen those requirements through the use of the proc filesystem and/or ZIP files.</p>

<p>The majority of the remaining environment variables are simply checked if they contain a non-empty string, and if so, toggle a generally benign setting. One of the rare exceptions to this is <code>PYTHONWARNINGS</code>.</p>

<h2 id="making-progress-with-pythonwarnings">Making progress with PYTHONWARNINGS</h2>
<p>The documentation for <code>PYTHONWARNINGS</code> states <code>it is equivalent to specifying the -W option</code>. The <code>-W</code> option is used for warning control to specify which warnings and how often they are printed. The full form of argument is <code>action:message:category:module:line</code>. While warning control didn’t seem like a promising lead, that quickly changed after checking the implementation.</p>

<figure>
  <figcaption>Figure-1: Python-3.8.2/Lib/warnings.py</figcaption>

<figure><pre><code data-lang="python"><span>[...]</span>
<span>def</span> <span>_getcategory</span><span>(</span><span>category</span><span>):</span>
    <span>if</span> <span>not</span> <span>category</span><span>:</span>
        <span>return</span> <span>Warning</span>
    <span>if</span> <span>'.'</span> <span>not</span> <span>in</span> <span>category</span><span>:</span>
        <span>import</span> <span>builtins</span> <span>as</span> <span>m</span>
        <span>klass</span> <span>=</span> <span>category</span>
    <span>else</span><span>:</span>
        <span>module</span><span>,</span> <span>_</span><span>,</span> <span>klass</span> <span>=</span> <span>category</span><span>.</span><span>rpartition</span><span>(</span><span>'.'</span><span>)</span>
        <span>try</span><span>:</span>
            <span>m</span> <span>=</span> <span>__import__</span><span>(</span><span>module</span><span>,</span> <span>None</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>klass</span><span>])</span>
        <span>except</span> <span>ImportError</span><span>:</span>
            <span>raise</span> <span>_OptionError</span><span>(</span><span>"invalid module name: %r"</span> <span>%</span> <span>(</span><span>module</span><span>,))</span> <span>from</span> <span>None</span>
<span>[...]</span></code></pre></figure>

</figure>

<p>The above code shows that as long as our specified category contains a dot, we can trigger the import an arbitrary Python module.</p>

<p>The next problem is that the vast majority of modules from Python’s standard library run very little code when imported. They tend to just define classes to be used later, and even when they provide code to run, the code is typically <a href="https://docs.python.org/3/library/__main__.html">guarded with a check of the <code>__main__</code> variable</a> (to detect if the file has been imported or run directly).</p>

<p>An unexpected exception to this is the <a href="https://xkcd.com/353/">antigravity module</a>. The Python developers included an <a href="https://en.wikipedia.org/wiki/Easter_egg_(media)">easter egg</a> in <a href="https://github.com/python/cpython/commit/206e3074d34aeb5a4d0c1e24d970b6569f7ad702">2008</a> which can be triggered by running <code>import antigravity</code>. This import will immediately open your browser to the xkcd comic that joked that <code>import antigravity</code> in Python would grant you the ability to fly.</p>

<p>As for how the <code>antigravity</code> module opens your browser, it uses another module from the standard library called <code>webbrowser</code>. This module checks your PATH for a large variety of browsers, including mosaic, opera, skipstone, konqueror, chrome, chromium, firefox, links, elinks and lynx. It also accepts an environment variable <code>BROWSER</code> that lets you specify which process should be executed. It is not possible to supply arguments to the process in the environment variable and the xkcd comic URL is the one hard-coded argument for the command.</p>

<p>The ability to turn this into arbitrary code execution depends on what other executables are available on the system.</p>

<h2 id="leveraging-perl-for-arbitrary-code-execution">Leveraging Perl for Arbitrary Code Execution</h2>

<p>One approach is to leverage Perl which is commonly installed on systems and is even available in the standard Python docker image. However, the <code>perl</code> binary cannot itself be used. This is because the first and only argument is the xkcd comic URL. The comic URL argument will cause an error and the process to exit without the <code>PERL5OPT</code> environment variable being used.</p>

<figure>
  <figcaption>Figure-2: PERL5OPT having no effect when a URL is passed to perl</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perl https://xkcd.com/353/
<span>Can't open perl script "https://xkcd.com/353/": No such file or directory</span></code></pre></figure>

</figure>

<p>Fortunately, when Perl is available it also common to have the default Perl scripts available, such as perldoc and perlthanks. These scripts will also error and exit with an invalid argument, but the error in this case happens later than the processing of the <code>PERL5OPT</code> environment variable. This means you can leverage the Perl environment variable payload detailed earlier in this blog post.</p>

<figure>
  <figcaption>Figure-3: PERL5OPT working as intended with perldoc and perlthanks</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perldoc https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)
</span><span>$</span><span> </span>run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perlthanks https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>

<h2 id="proof-of-concept-1">Proof of Concept</h2>

<figure>
  <figcaption>Figure-4: arbitrary code execution achieved using multiple environment variables against Python 2 and Python 3</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:2.7.18 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'

</span><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:3.8.2 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'</span></code></pre></figure>

</figure>



<p>A <a href="https://research.securitum.com/prototype-pollution-rce-kibana-cve-2019-7609/">blog post</a> by <a href="https://twitter.com/securitymb">Michał Bentkowski</a> provided a payload for exploiting Kibana (CVE-2019-7609). A prototype pollution vulnerability was used to set arbitrary environment variables which resulted in arbitrary command execution. Michał’s payload used the <code>NODE_OPTIONS</code> environment variable and the <a href="https://en.wikipedia.org/wiki/Procfs">proc filesystem</a>, specifically <code>/proc/self/environ</code>.</p>

<p>Although Michał’s technique was creative and worked perfectly for their vulnerability, the technique is not always guaranteed to work and has some constraints that would be nice to remove.</p>

<p>The first constraint is that it using <code>/proc/self/environ</code> is only viable if the contents can be made to be syntactically valid JavaScript. This requires being able to create an environment variable and have it appear first in the contents of <code>/proc/self/environ</code>, or knowing/bruteforcing the environment variable’s name that will appear first and overwriting it’s value.</p>

<p>Another constraint, as the first environment variable’s value finishes with a single line comment (<code>//</code>). Therefore, any newline character in other environment variables will likely cause a syntax error and prevent the payload from executing. The use of multi-line comments (<code>/*</code>) will not fix this issue as they must be closed to be syntactically valid. Therefore, in the rare case that an environment variable contains a newline character, it is required to know/bruteforce the environment variable’s name and overwrite it’s value to a new value that does not contain a newline.</p>

<p>Removing these contraints is an exercise left for the reader.</p>

<h2 id="proof-of-concept-2">Proof of Concept</h2>

<figure>
  <figcaption>Figure-5: achieving arbitrary code execution with environment variables against NodeJS by Michał Bentkowski</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'NODE_VERSION=console.log(require("child_process").execSync("id").toString());//'</span> <span>-e</span> <span>'NODE_OPTIONS=--require /proc/self/environ'</span> node:14.2.0 node /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>If you run <code>ltrace -e getenv php /dev/null</code> you will find PHP uses the <code>PHPRC</code> environment variable.
The environment variable is used …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elttam.com/blog/env/">https://www.elttam.com/blog/env/</a></em></p>]]>
            </description>
            <link>https://www.elttam.com/blog/env/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827486</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is QuantGov?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827427">thread link</a>) | @hhs
<br/>
July 13, 2020 | https://www.quantgov.org/about | <a href="https://web.archive.org/web/*/https://www.quantgov.org/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.quantgov.org/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827427</guid>
            <pubDate>Tue, 14 Jul 2020 00:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alex: An Updatable Adaptive Learned Index [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827257">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf | <a href="https://web.archive.org/web/*/https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827257</guid>
            <pubDate>Tue, 14 Jul 2020 00:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond Analytics: The Evolution of Stream Processing Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827170">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://streaming-research.github.io/Tutorial-SIGMOD-2020/ | <a href="https://web.archive.org/web/*/https://streaming-research.github.io/Tutorial-SIGMOD-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <h2 id="tutorial-information">Tutorial Information</h2>
<h3 id="wednesday-june-17-2020">Wednesday, June 17 2020</h3>
<h4 id="join-us-on-zoom-and-slack">Join us on <a href="https://acm-org.zoom.us/j/93450885761?pwd=OGZmekwyRFR2Q3ZTd3VwL3hsc0JlUT09">Zoom</a> and <a href="https://join.slack.com/t/sigmodpods/shared_invite/zt-em1btw2v-tTI9OXRtzi4apsMaCoqjTA">Slack</a></h4>

<h4 id="session-1-1030-am---1200-pm-pdt">Session 1: 10:30 AM - 12:00 PM PDT</h4>
<ul>
  <li>Part I: Introduction &amp; Fundamentals</li>
  <li>Part II: Time, Order, &amp; Progress</li>
  <li>Part III: State Management</li>
</ul>

<h4 id="session-2-130-pm---300-pm-pdt">Session 2: 1:30 PM - 3:00 PM PDT</h4>
<ul>
  <li>Part IV: Fault Recovery &amp; High Availability</li>
  <li>Part V: Load Management &amp; Elasticity</li>
  <li>Part VI: Prospects</li>
</ul>

<h2 id="overview">Overview</h2>
<p>Stream processing has been an active research field for more than 20 years, but it is now witnessing its prime time due to recent successful efforts by the research community and numerous worldwide open-source communities. The goal of this tutorial is threefold. First, we aim to review and highlight noteworthy past research findings, which were largely ignored until very recently. Second, we intend to underline the differences between early (’00-’10) and modern (’11-’18) streaming systems, and how those systems have evolved through the years. Most importantly, we wish to turn the attention of the database community to recent trends: streaming systems are no longer used only for classic stream processing workloads, namely window aggregates and joins. Instead, modern streaming systems are being increasingly used to deploy general event-driven applications in a scalable fashion, challenging the design decisions, architecture and intended use of existing stream processing systems.</p>

<h2 id="presenters">Presenters</h2>

<ul>
  <li><a href="https://www.ri.se/en/paris-carbone">Paris Carbone</a> (RISE)</li>
  <li><a href="http://mariosfragkoulis.gr/">Marios Fragkoulis</a> (Delft University of Technology)</li>
  <li><a href="https://cs-people.bu.edu/vkalavri/">Vasiliki Kalavri</a> (Boston University)</li>
  <li><a href="http://asterios.katsifodimos.com/">Asterios Katsifodimos</a> (Delft University of Technology)</li>
</ul>

<h2 id="slides-and-videos">Slides and Videos</h2>

<ol>
  <li>Introduction and fundamentals <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part1-introduction.pdf">[Slides]</a> <a href="https://youtu.be/6qmwLKzXdgM">[Video]</a></li>
  <li>Time, order, and progress <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part2-time.pdf">[Slides]</a> <a href="https://youtu.be/sWcMx52eP58">[Video]</a></li>
  <li>State management and guarantees <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part3-state-management.pdf">[Slides]</a> <a href="https://youtu.be/Zgy5a5tBOco">[Video]</a></li>
  <li>Advanced fault recovery and high availability <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part4-Fault-HA.pdf">[Slides]</a> <a href="https://youtu.be/p3zXV2w_MgM">[Video - Part I]</a> <a href="https://youtu.be/28CRUcFAGPs">[Video - Part II]</a></li>
  <li>Load management and elasticity <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part5-load-management.pdf">[Slides]</a> <a href="https://youtu.be/Pxe0M-mprOM">[Video]</a></li>
  <li>Prospects and discussion <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part6-prospects.pdf">[Slides]</a> <a href="https://youtu.be/DW9kU7gCL8A">[Video]</a></li>
</ol>

<h2 id="cite-pdf">Cite (<a href="https://dl.acm.org/doi/abs/10.1145/3318464.3383131">PDF</a>)</h2>

<div><div><pre><code>@inproceedings{10.1145/3318464.3383131,
author = {Carbone, Paris and Fragkoulis, Marios and Kalavri, Vasiliki and Katsifodimos, Asterios},
title = {Beyond Analytics: The Evolution of Stream Processing Systems},
year = {2020},
isbn = {9781450367356},
doi = {10.1145/3318464.3383131},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {2651–2658}
}
</code></pre></div></div>



      </section>
    </div></div>]]>
            </description>
            <link>https://streaming-research.github.io/Tutorial-SIGMOD-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827170</guid>
            <pubDate>Tue, 14 Jul 2020 00:12:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826786">thread link</a>) | @elsewhen
<br/>
July 13, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-yui_3_17_2_1_1590947194898_9413"><div><p>Many of the common startup frameworks for tech companies do not apply as well to biotech. I’ve gone through the most common frameworks below, and how they differ for biotech companies. </p><p>I’m defining a tech startup here as a company whose product is largely based off of code. I am not including in my arbitrary categorization ‘deep tech’ (e.g., autonomous trucks, satellite startups, etc), which often face similar challenges as biotech companies. </p><p>Biotech here is a startup developing a drug. </p><p><em>These are generalizations, and many exceptions exist. </em></p><h2><strong>Risks and Finding Product Market Fit</strong></h2><p><span><strong>TECH</strong></span><strong>: Significant market and execution risks<br></strong><span><strong>BIOTECH</strong></span><strong>: Minimal market risk, a lot of technical risk</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_605840"><div><p>In tech, the company often uses a standard software stack and applies it in a novel way (a new product). The question is usually not ‘can this thing be built’, but ‘does anyone want this thing we made’?</p><p>In biotech, this is flipped. The market (a disease) is well established, but the ability to develop a product (a drug) that addresses this market is the core risk. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_607921"><p><span><strong>TECH</strong></span><strong>: Rolling derisking, early signs of product-market fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Derisking comes in bursts over years (biological milestones), early signals less reliable</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_617219"><div><p>In tech, you want the ‘up and to the right’ chart, showing exponential increase of some core metric of the company. Adoption, revenue, and other metrics derisk the company and give early signs of PMF. Early signs can be highly predictive of the company’s eventual success.</p><p>In biotech, derisking the company is predominantly tied to specific biological milestones. These come in bursts, with long periods of waiting in-between. Additionally, early milestones (such as the drug working in mice) aren’t 1-to-1 predictive of eventual success (the drug working in people).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_619233"><p><span><strong>TECH</strong></span><strong>: Iterate to product-market-fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Product (drug) finalized years before on market</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_631626"><div><p>In tech, the product is constant iterates and improves from customer feedback to find the exact product that people want. </p><p>In biotech, due to the extensive regulation, the final product (the drug) is finalized years before it first goes into people. If the drug doesn’t work in people, there is no iterating. If you want to modify the product, you need to restart the entire process over again. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_633705"><div><h2><strong>Founders &amp; Market</strong></h2><p><span><strong>TECH</strong></span><strong>: Founders often bring insight around a market<br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often bring insight around key biology</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_651094"><div><p>In tech, a prototypical founder often worked at the incumbent company or realized a market opportunity by being that market themself. The insight around the market opportunity itself is a core value of the company. </p><p>In biotech, the insight of the founder is around a new or better way to develop a drug for the disease, or a discovery that was made in the laboratory (and the relevant patents around it). </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_665620"><p><span><strong>TECH</strong></span><strong>: Founders often younger, ‘youth wunderkinds’ widely accepted <br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often older due to scientific training or are a professional CEO, rarer to have very young founders </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_678110"><div><p>In tech, the 18-year-old drop-out is lauded and mystified. If anything, older founders may be subconsciously discriminated against in favor for younger founders. </p><p>In biotech, the prototypical founder is older, often a career CEO or exec coming out of a Big Pharma company. At minimum, the founders almost always have significant scientific training - a PhD can take 6-8 years, and post-docs 2-3 years each. It is less common to see founders in their 20s and you almost never see ‘youth wunderkinds’. This is in part due to the conservatism of the industry and in part because extensive scientific training is generally necessary to have enough biological insight to correctly identify an opportunity. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_420694"><p><span><strong>TECH</strong></span><strong>: Can create a new market<br></strong><span><strong>BIOTECH</strong></span><strong>: Markets are diseases and therefore public domain</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_422265"><div><p>In tech, some of the most successful companies created or defined their market - a classic example being ride sharing. Once a new market is validated, other companies/copycats/fast-followers flow in. </p><p>In biotech, the market opportunities are diseases. New markets can somewhat be created (e.g., nootropics, elective medicines, Viagra) but generally speaking the markets are well known. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_423860"><p><span><strong>TECH</strong></span><strong>: Markets are winner-take-all<br></strong><span><strong>BIOTECH</strong></span><strong>: Many winners</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_458802"><div><p>In tech, investors often bet on a specific horse with the hope that the horse will win the race (and all the earnings). Bifurcated markets can be especially dangerous as companies compete on pricing and ‘race to the bottom’.</p><p>In biotech, the markets are <em>so </em>large, and the unmet need so high, that there can and often are many winners in one market (disease). The classic example here are statins, which in 2020 had over $1 trillion in sales across seven market approved statins, with the best-selling Lipitor having peak sales of $12B in the mid-2000s. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_456236"><div><h2><strong>Product Strategy</strong></h2><p><span><strong>TECH</strong></span><strong>: Often develop one product at a time, focus is key <br></strong><span><strong>BIOTECH</strong></span><strong>: Portfolio approach is encouraged to de-risk company, exception is one-asset, repurposing plays</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_482826"><div><p>Focus is crucial for any startup. However, in biotech the most successful and valuable companies often take a portfolio approach to product development - developing multiple products simultaneously. In tech, companies generally focus around one product or core offering, only differentiating once they have earned the right to do so by finding PMF with their first product.</p><p>A significant reason for this is to derisk the company against biological randomness. Instead, focus in a biotech company is usually around a core competency - e.g., a method of discovering drugs, or a way of delivering the drug - and then diversified within this core competency. For example, gene therapy company Spark Therapeutics had a core competency of AAV-based gene therapy (a virus loaded with DNA to treat a genetic disease) but leverages this competency simultaneously across multiple diseases. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_484564"><p><strong>﻿</strong><span><strong>TECH</strong></span><strong>: Outsourcing product development or engineering unadvisable<br></strong><span><strong>BIOTECH</strong></span><strong>: Common to use contractors for key experimental work</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_497310"><div><p>In tech, not having someone technical on the founding team is a classic ‘no no’. You generally should have the ability to build (and therefore rapidly iterate on and improve) your core product within the team. </p><p>In biotech, it is common and often preferred to use contract research organizations (CROs) for much of your experimental work. Some experiments can only be done by specialized CROs, and they often have advantages from scale that a startup cannot hope to replicate. Building and staffing a laboratory, including the multiple six-figure machines necessary, is impracticable and unnecessary for most companies. </p><p>Virtual biotechs - companies with distributed leadership and all research outsourced to CROs - have been popular long before it became the tech zeitgeist.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_499137"><p><span><strong>TECH</strong></span><strong>: Fast-followers and copycats a significant risk<br></strong><span><strong>BIOTECH</strong></span><strong>: Strong patent protection </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_570610"><div><p>In tech, being the first/best product to a new market is so important because once you validate a market’s need for a specific product, it is easy for others to copy and chip at your market share. This is especially common in traditional D2C brands, for example the many bed-in-a-box companies. </p><p>In biotech, patents are king. If you hold the key patent it is impossible for your drug to be copied. Once patents expire, however, there is a whole industry (generics) around copying drugs and selling them cheaper than the branded product. Because of the hundreds of millions it takes to develop a drug, it is almost impossible to commercialize a drug that is not able to be protected by patents, regardless of its efficacy. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_568710"><div><h2><strong>Raising, Spending, and Making Money</strong></h2><p><span><strong>TECH</strong></span><strong>: Primary burn usually people costs <br></strong><span><strong>BIOTECH</strong></span><strong>: Primary burn R&amp;D</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_725052"><p>Biotech companies’ biggest line item is undoubtedly R&amp;D spend - funding to do research experiments necessary to find and develop their drug. This is despite the average salary in biotech also often being higher than tech’s.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_722809"><p><span><strong>TECH</strong></span><strong>: Series Seed and A smaller, with larger subsequent rounds to scale and win market share<br></strong><span><strong>BIOTECH</strong></span><strong>: Capital needs front-loaded, Seeds can be the size of tech Series A’s</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_745080"><div><p>In tech, you can often show proof-of-concept or even begin selling your product with a small team and pre-seed capital. </p><p>Biotech Seeds can often look like tech Series As in magnitude. On the East Coast, the first rounds in biotech companies are more than often in the $10s of millions. This is because of the millions needed to hit biological milestones to push the company forward (and therefore qualify for the next stage of financing).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_742704"><p><span><strong>TECH</strong></span><strong>: Often command higher valuations early on <br></strong><span><strong>BIOTECH</strong></span><strong>: Often command lower valuations early on</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_803591"><div><p>Tech valuations usually optimize for selling 10% - 25% of the company in any one financing. </p><p>In biotech, valuations are historically significantly lower, with many East Coast deals selling 50%+ of the company in one financing. Such huge dilution is less common in West Coast biotech financings, but it is more common sell 33%+ of the company in one financing. Biotech founders also often have less negotiating power here because they have to raise large amounts to bring the company to the next stage. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_805993"><p><span><strong>TECH</strong></span><strong>: Business usually has significant revenue at exit <br></strong><span><strong>BIOTECH</strong></span><strong>: Unlikely to have revenue at exit</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_845025"><div><p>While the company may be far from profitable, tech companies almost always have significant revenue at exit (IPO or acquisition). </p><p>In biotech, companies almost never have revenue at exit. Instead, the value of the company is driven by the increasing probability that their drug will work (and therefore decreasing biological risk). The company is often sold or partnered years before the drug is commercialized.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_836878"><div><h2><strong>Team</strong></h2><p><span><strong>TECH</strong></span><strong>: Core team often younger, primed to take more equity over salary<br></strong><span><strong>BIOTECH</strong></span><strong>: Core team often older due to extensive scientific training, often more risk-adverse or otherwise unable to sacrifice heavily on salary </strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_824365"><div><p>In tech, there is a self-selecting group that aspire to work in or on a startup, and are primed to take the high equity with lower salary in the hope that they pick the company that will become a unicorn and make them rich, too. They are often younger …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.celinehh.com/tech-vs-biotech">https://www.celinehh.com/tech-vs-biotech</a></em></p>]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826786</guid>
            <pubDate>Mon, 13 Jul 2020 23:20:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The AirPods Pro “Rattlegate”]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 314 (<a href="https://news.ycombinator.com/item?id=23826070">thread link</a>) | @dewey
<br/>
July 13, 2020 | https://annoying.technology/posts/abea6876cf4f2e13/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/abea6876cf4f2e13/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/a57da8f4dbb8954a0649e58235d5555af26d4c2f/d294d/media/rattlegate.jpg"></p><p>The AirPods Pro “Rattlegate”</p><p>The first generation of the AirPods was generally regarded as a perfect product. “Apple at its best!” was the universally accepted opinion.</p><p>I used them for a long time. No speaker issues, no battery issues.</p><p>Excited for the noise cancelling feature I ordered the AirPods Pro and for the first few months everything was fine. One day the left AirPod started buzzing every time I was moving my head. Slightly tilting my head would result in a buzzing noise with changing intensity depending on how my head moved.</p><p>Support agreed that this is a problem and sent a new AirPod.</p><p>A few weeks later the right AirPod started to produce weird rattling noises. It sounded like some tiny part fell off and was now bouncing around in the AirPod. It also started to behave weird as soon as there was a bit of wind.</p><p>Support agreed that this is a problem and sent a new AirPod.</p><p>Days later it was the left AirPod’s turn and it’s now rattling again.</p><p>There’s something very wrong with this product line and just getting a new one every few months is — financially and ecologically — not sustainable as they end up in a landfill. I’m also <a href="https://forums.macrumors.com/threads/airpods-pro-rattlegate.2233658/">far from being the only one</a> having this issue.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/abea6876cf4f2e13/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826070</guid>
            <pubDate>Mon, 13 Jul 2020 22:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23825606">thread link</a>) | @refrigerator
<br/>
July 13, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825606</guid>
            <pubDate>Mon, 13 Jul 2020 21:09:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Calculating Churn Rates Wrong]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23825420">thread link</a>) | @cmogni1
<br/>
July 13, 2020 | https://catchjs.com/Blog/Churn | <a href="https://web.archive.org/web/*/https://catchjs.com/Blog/Churn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
<ol>
    <li><a href="https://catchjs.com/Docs">Blog</a></li>
    <li>You're all calculating churn rates wrong</li>
</ol>

        

        
        <p>
            Many smart people will tell you to obsess over your churn rate.
        </p>
        <p>
            <img src="https://catchjs.com/Blog//images/blog/churn/churn_rate_formula2.png" alt="churn rate=(customers lost in month)/(customers at start of month)">
        </p>
        <p>
            According to Andreessen Horowitz, this number is <a href="https://a16z.com/2015/08/21/16-metrics/">one of the top 16 metrics</a>
            to measure a SaaS startup by. Well, sorry Andreessen, and sorry Horowitz, but this just isn't right.
        </p><p>
            It's counterintuitive, but it's a statistical fact: This number actually <b>tells you nothing useful about churn</b>,
            but really relates to the age of the subscriptions you have.
            It will in most cases go down on it's own, and, absurdly, the only way to keep it from going down is to have very
            high growth. So the number will literally <b>only look <i>bad</i> if your business is doing extremely <i>well</i></b>,
            and optimizing for it will be directly counter-productive.
            The error here is a simple statistical mistake that is easy to make, and luckily also easy to understand and avoid.
        </p><p>
            If you run a subscription based SaaS business, you're likely very concerned with how long you can keep your
            customers. We're a JavaScript exception tracking service, and the health of this business is fully determined by how many
            customers we bring in, and how long we can keep them. On the surface, <i>churn rate</i> may seem like a natural proxy for changes
            in <i>customer lifetimes</i>. Let's dig into why that is not true.
        </p>
        <h2>
            The false assumption
        </h2>
        <p>
            Computing a churn rate <b>assumes that a customer is equally likely to leave at any time</b>, no matter how long they've
            been subscribed to you. This is almost certainly not true. In fact, as we will see, having a constant churn probability over time
            essentially implies that you'll <i>never have long term customers</i>.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/expon.png" alt="Hazard function (churn) and the implied survival function (from an Exponential distribution)">
            <figcaption>If a user has a constant churn probability over time, this implies that customer lifetimes come from an Exponential distribution.</figcaption>
        </figure>
        <p>
            If you have a constant churn of <code>c</code> per month, the probability that a customer stays subscribed for <code>n</code> months is <code>(1-c)^n</code>. This implies that customer lifetimes come from the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a>. If customers can quit the subscription at any time, we have continuous time and should use the continuous time analogue, the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential distribution</a>.
        </p>
        <h2>
            What your churn is actually like, with help from K. S. Lomax
        </h2>
        <p>
            The problem is, your customer is not equally likely to cancel their subscription at any time. Most likely, you have a situation where the drop-off in customers is higher in the first few days than it is later. This is even more so if you have a free trial period for your product.
        </p><p>
            If the churn probability gets lower the longer the customer has been subscribed, you could model that as <code>c/(t+1)</code>, where
            <code>t</code> is the timestep (e.g. number of days the customer has been subscribed), and <code>c</code> is some constant.
            In this case, this implies that customer lifetimes comes from a <a href="https://en.wikipedia.org/wiki/Lomax_distribution">Lomax distribution</a>.
            This is equivalent to a Pareto distribution shifted to start at 0.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/lomax.png" alt="Hazard function (churn) and the implied survival function (from a Lomax distribution)">
            <figcaption>The Lomax distribution can express churn probabilities that get lower with time.</figcaption>
        </figure>
        <h2>
            What your churn is actually like, with help from Waloddi Weibull
        </h2>
        <p>
            If you suspect that churn probability per day may <i>increase</i> the longer a user has been subscribed, the Lomax distribution won't
            work for you. Instead you could enlist the help of Swedish statistician Waloddi Weibull.
            The <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull distribution</a> can express both decreasing,
            flat, and increasing probabilities of a customer quitting. This makes it a popular choice for modeling customer lifetimes.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/weibull.png" alt="Hazard function (churn) and the implied survival function (from two Weibull distributions)">
            <figcaption>The Weibull distribution can express both growing and shrinking churn probabilities.</figcaption>
        </figure>

        <h2>
            Optimizing for a falsehood will lead you astray
        </h2>
        <p>
            Now let's see why properly modeling this is important.
        </p><p>
            Let's measure churn the wrong way, and see where it takes us.
            Let's say customer lifetimes come from a Lomax distribution. Let's also say you have a business that is in terrible shape, where
            the number of new sign ups per day is falling by one per day. How will this look on the churn rate? We can simulate it and find out.
        </p>
        <p>
            Keep in mind, in each of the examples below we simulate lifetimes from the same customer lifetime distribution,
            and this distribution <b>does not change</b> over time.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/shrinking_business.png" alt="Shrinking business, churn appears to fall">
            <figcaption>With a shrinking business, churn appears to improve because subscriptions are getting fewer and older.</figcaption>
        </figure>
        <p>
            This is clearly a dying business, yet the churn rate graph is looking great! <b>
                The churn rate per day is falling steadily,
                even if we know that there is no change in customer lifetimes in our model.
            </b>
        </p><p>
            So what's going on? This sharp fall in churn rate is a consequence of the fact that we're not getting new customers.
            Because we're not growing, a bigger share of our customers have been around for a long time, which
            means they're less likely to churn, which means our daily churn graph goes down more than it would otherwise.
            This change on the population level happens despite there being no change in underlying individual customer lifetimes.
        </p><p>
            Let's change this into a scenario where your business is experiencing insane growth. We'll keep the customer lifetimes exactly the same,
            but change it so that the number of new sign ups per day is growing superlinearly.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/growing_business.png" alt="Growing business, churn appears to be flat">
            <figcaption>With a growing business, churn rate appears to not change, only because most subscriptions are new.</figcaption>
        </figure>
        <p>
            Even if the customer lifetimes are unchanged from before, the churn rate graph here is flat. An investor would frown and say
            we're doing nothing to improve how well we retain our customers. In reality, the only reason the graph looks "bad" has nothing to
            do with churn, it is because we're doing insanely well at getting new sign ups.
        </p><p>
            <b>
                If you are steering yourself and your team on the basis of this metric, you're rewarding yourself for stifling growth
                and punishing yourself for growing.
            </b> Obviously, this is 100% counterproductive.
        </p>
        <h2>
            How the h*** do we measure churn then?
        </h2>
        <p>
            As you might have guessed from the previous paragraphs, we should model the <i>distribution of customer lifetimes</i>,
            and we should do it in a <i>statistically sound way</i>. Lomax and Weibull distributions are good choices of model.
        </p><p>
            The part where this gets tricky is that we'll have two types of data: The customers that have quit, and the customers
            that are still subscribed. It's only our ex-customers that give us a total lifetime to work with. For our still-subscribed
            customers, we only know that their subscription has lasted up until now, and we don't know how much longer it will last
            into the future. In statistical lingo, we have what is called <i>right-censored data</i>.
        </p><p>
            Luckily there's a way to use all our data, even from our still-subscribed customers.
        </p>


        <h2>
            Weibull or Lomax?
        </h2>
        <p>
            Choosing between Weibull or Lomax (or any other distribution) has no simple answer. Weibull is more flexible
            in that it can express growing, shrinking and flat churn probabilities. However, this expressive power will
            not help you if your data is fundamentally Lomax-like. First and foremost, base your choice
            on your knowledge of the business that you're in. If you have any prior knowledge about how churn probabilities
            will develop, base your choice of distribution on that. There are also various
            <a href="https://www.weibull.com/hotwire/issue71/relbasics71.htm">goodness of fit</a> tests you could use to
            inform this decision. The truth is, any choice of distribution will be wrong to some degree, so you need to make
            a judgment call as to what fits your situation the best, based both on both your data and your prior knowledge.
            For the purposes of the rest of this post, we'll just fit both distributions and disregard the question of
            which suits us the best.
        </p>

        <h2>
            Let's do some proper statistics
        </h2>
        <p>
            The probability distributions we'll model are defined by their parameters.
            We want to find the parameters that fit the data best. To start, we want to make a guess at these parameters,
            and have a way to tell how good our guess was. Luckily, we have a statistically sound way of knowing how good a guess
            is given the data we have. Extra luckily, this is also true when we have censored data.
            This function that tells us how likely our parameters are given the data we have is called the Likelihood function.
            We get it by looking up the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a>
            value for the uncensored data points and the <a href="https://en.wikipedia.org/wiki/Survival_function">survival function</a> value
            for each of the censored data points, and multiplying all these values together.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/likelihood.png" alt="Likelihood formula with right-censored data">
            <figcaption>
                Likelihood function L for right-censored data. <code>f(.)</code> is the probability distribution function, <code>S(.)</code> is the survival function,
                <code>D</code> is the set of uncensored lifetimes and <code>R</code> …</figcaption></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://catchjs.com/Blog/Churn">https://catchjs.com/Blog/Churn</a></em></p>]]>
            </description>
            <link>https://catchjs.com/Blog/Churn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825420</guid>
            <pubDate>Mon, 13 Jul 2020 20:49:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python malware on the rise]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 58 (<a href="https://news.ycombinator.com/item?id=23824689">thread link</a>) | @vesche
<br/>
July 13, 2020 | https://www.cyborgsecurity.com/python-malware-on-the-rise/ | <a href="https://web.archive.org/web/*/https://www.cyborgsecurity.com/python-malware-on-the-rise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
                        <p>
                July 13, 2020            </p>
            
			
            <hr>
                        <p><img width="2560" height="1646" src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-scaled.jpg" alt="" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-scaled.jpg 2560w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-300x193.jpg 300w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-1024x658.jpg 1024w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-768x494.jpg 768w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-1536x988.jpg 1536w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-2048x1317.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">            </p>
                        <p>The vast majority of serious malware&nbsp;<a href="https://software.imdea.org/~juanca/papers/malsource_raid16.pdf">over the past 30 years</a>&nbsp;has been written in Assembly or compiled languages such as C, C++, and Delphi. However, ever-increasing over the past decade, a large amount of malware has been written in interpreted languages, such as Python. The low barrier to entry, ease of use, rapid development process, and massive library collection has made Python attractive for millions of developers- including malware authors. Python has quickly become a standard language in which threat actors create Remote Access Trojans (RATs), information stealers, and vulnerability exploit tools. As&nbsp;<a href="https://www.techrepublic.com/article/python-is-eating-the-world-how-one-developers-side-project-became-the-hottest-programming-language-on-the-planet/">Python continues to grow radically in popularity</a>&nbsp;and the&nbsp;<a href="https://research.checkpoint.com/2019/malware-against-the-c-monoculture/">C malware monoculture</a>&nbsp;continues to be challenged, it would seem only certain that Python will be increasingly utilized as malware in cyber attacks.</p>

<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth.jpg" alt="" width="770" height="660" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth.jpg 770w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth-300x257.jpg 300w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth-768x658.jpg 768w" sizes="(max-width: 770px) 100vw, 770px"></p>
<p><span>Image Source: Stack Overflow</span></p>

<p>In comparison to a standard compiled language like C, writing malware in Python comes with a whole host of difficulties. The first being that Python is required to be installed on the operating system in order to interpret and execute Python code. However, as we’ll see in the next section, a Python program can easily be converted into a native executable using a variety of different methods.</p>
<p>Malware written in Python will also have adverse effects on file size, memory footprint, and processing power. Serious malware is often designed to be small, stealthy, have low memory footprint, and use limited processing power. A compiled malware sample written in C might be 200 KB, while a comparable malware sample written in Python might be 20 MB after converted into an executable. Both the CPU &amp; RAM usage will also be significantly higher when using an interpreted language.</p>
<p>However, it’s 2020 and the digital landscape isn’t what it once was. The internet is faster than it’s ever been, our computers have more memory &amp; storage capacity than ever, and CPUs get faster every year. Python is also more ubiquitous than ever, coming pre-installed on macOS and most all Linux distributions by default.</p>

<p>Microsoft Windows is still the primary target for most malicious campaigns, and it does not come with Python installed by default. Therefore, for threat actors to distribute their malware effectively they must convert their Python code into an executable format. There are many methods to “compile Python” into a native executable. Let’s take a look at the few most popular methods…</p>
<h3>PyInstaller</h3>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller.png" alt="" width="500" height="100" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller.png 500w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller-300x60.png 300w" sizes="(max-width: 500px) 100vw, 500px"></p>

<p><a href="https://www.pyinstaller.org/">PyInstaller</a>&nbsp;is capable of building Python applications into stand-alone executables for Windows, Linux, macOS and more by “freezing” Python code. It is one of the most popular methods to convert Python code into executable format and has been used widely for both legitimate and malicious purposes.</p>
<p>Let’s create a simple “Hello, world!” program in Python and freeze it into a stand-alone executable using PyInstaller:</p>
<pre><code>$ cat hello.py
print('Hello, world!')

$ pyinstaller --onefile hello.py
...

$ ./dist/hello 
Hello, world!

$ file dist/hello 
dist/hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=294d1f19a085a730da19a6c55788ec08c2187039, stripped

$ du -sh dist/hello 
7.0M    dist/hello
</code></pre>
<p>This process created a portable, stand-alone Linux ELF (Executable and Linkable Format) which is the equivalent to an EXE on Windows. Now let’s create and compile a “Hello, world!” program in C on Linux for comparison:</p>
<pre><code>$ cat hello.c
#include &lt;stdio.h&gt;
int main() {
    printf("Hello, world!");
}

$ gcc hello.c -o hello

$ ./hello 
Hello, world!

$ file hello
hello: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=480c7c75e09c169ab25d1b81bd28f66fde08da7c, for GNU/Linux 3.2.0, not stripped

$ du -sh hello
20K hello
</code></pre>
<p>Notice how much larger the file size is: 7 MB (Python) vs 20 KB (C)! This demonstrates the major drawback we discussed previously about file size and memory usage. The Python executable is so much larger due to the fact it must bundle the Python interpreter (as a shared object file on Linux) inside the executable itself in order to run.</p>
<h3>py2exe</h3>
<p><a href="https://www.py2exe.org/">Py2exe</a>&nbsp;is another popular method to convert Python code into Windows EXE (executable) format that can be run natively. Similar to PyInstaller, it bundles the Python interpreter with your Python code to make a portable executable. Py2exe is likely to fall out of style with time as it has not been supported past Python 3.4, this is due to&nbsp;<a href="https://docs.python.org/3/whatsnew/3.6.html#cpython-bytecode-changes">the bytecode in CPython being heavily changed in Python 3.6 and beyond</a>.</p>
<p>Py2exe utilizes distutils and requires a small&nbsp;<code>setup.py</code>&nbsp;script to be created to produce an executable. Let’s create an example “Hello, world!” executable using py2exe:</p>
<pre><code>&gt; type hello.py
print('Hello, world!')

&gt; type setup.py
import py2exe
from distutils.core import setup
setup(
    console=['hello.py'],
    options={'py2exe': {'bundle_files': 1, 'compressed': True}},
    zipfile=None
)

&gt; python setup.py py2exe
...

&gt; dist\hello.exe
Hello, world!
</code></pre>
<p>The&nbsp;<code>hello.exe</code>&nbsp;created by py2exe is similar in size to PyInstaller coming in at 6.83 MB.</p>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe.png" alt="" width="369" height="508" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe.png 369w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe-218x300.png 218w" sizes="(max-width: 369px) 100vw, 369px"></p>
<h3>Nuitka</h3>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/nuitka.png" alt="" width="120" height="24"></p>
<p><a href="https://nuitka.net/">Nuitka</a>&nbsp;is perhaps the most underutilized, and yet more advanced method of compiling Python code to an executable. It translates Python code into a C program that then is linked against libpython to execute code the same as CPython. Nuitka can use a variety of C compilers including gcc, clang, MinGW64, Visual Studio 2019+, and clang-cl to convert your Python code to C.</p>
<p>Let’s create a “Hello, world!” Python program on Linux and compile it using Nuitka:</p>
<pre><code>$ cat hello.py
print('Hello, world!')

$ nuitka3 hello.py
...

$ ./hello.bin
Hello, world!

$ file hello.bin 
hello.bin: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=eb6a504e8922f8983b23ce6e82c45a907c6ebadf, for GNU/Linux 3.2.0, stripped

$ du -sh hello.bin
432K    hello.bin
</code></pre>
<p>Nuitka produced a portable binary very simply, and at 432 KB is a fraction of the size of what PyInstaller or py2exe can produce! How is Nuitka able to do this? Let’s take a look at the build folder:</p>
<pre><code>$ cloc hello.build/
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
C                               11           2263            709           8109
C/C++ Header                     1              1              0              7
-------------------------------------------------------------------------------
SUM:                            12           2264            709           8116
-------------------------------------------------------------------------------
</code></pre>
<p>Nuitka produced over 8,000 lines of C code from our 1 line Python program. The way Nuitka works is it actually translates the Python modules into C code and then uses libpython and static C files of its own to execute in the same way as CPython does.</p>
<p>This is very impressive, and it seems highly likely the Nuitka “Python compiler” will see further adoption as time goes on. As we’ll see later, Nuitka might have a further, built-in advantage in protection against Reverse Engineering (RE). There already exist several tools to easily analyze binaries produced by PyInstaller and py2exe to recover Python source code. However, by Nuitka translating the Python code to C it is much more difficult to reverse engineer.</p>

<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools.png" alt="" width="557" height="383" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools.png 557w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools-300x206.png 300w" sizes="(max-width: 557px) 100vw, 557px"></p>
<p>Python malware can take advantage of a massive ecosystem of open-source Python packages and repositories. Almost anything you could think of, someone has already built it using Python. This is a huge advantage to malware authors as simplistic capabilities can be cherry-picked from the open web and more complex capabilities likely don’t need to be written from scratch.</p>
<p>Let’s take a look at three simple, yet powerful tool examples:</p>
<ol>
<li>Code Obfuscation</li>
<li>Taking Screenshots</li>
<li>Performing Web Requests</li>
</ol>
<h3>Tool Example 1 – Obfuscation</h3>
<p>Malware authors using Python have many libraries they could use to obfuscate their Python code to make code readability much more difficult, such as:&nbsp;<a href="https://github.com/liftoff/pyminifier">pyminifier</a>&nbsp;and&nbsp;<a href="https://github.com/dashingsoft/pyarmor">pyarmor</a>.</p>
<p>Here’s a small example of how&nbsp;<code>pyarmor</code>&nbsp;can obfuscate Python code:</p>
<pre><code>$ cat hello.py 
print('Hello, world!')

$ pyarmor obfuscate hello.py
...

$ cat dist/hello.py
from pytransform import pyarmor_runtime
pyarmor_runtime()
__pyarmor__(__name__, __file__, b'\x50\x59\x41\x52\x4d\x4f\x52\x00\x00\x03\x08\x00\x55\x0d\x0d\x0a\x04\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x40\x00\x00\x00\xd5\x00\x00\x00\x00\x00\x00\x18\xf4\x63\x79\xf6\xaa\xd7\xbd\xc8\x85\x25\x4e\x4f\xa6\x80\x72\x9f\x00\x00\x00\x00\x00\x00\x00\x00\xec\x50\x8c\x64\x26\x42\xd6\x01\x10\x54\xca\x9c\xb6\x30\x82\x05\xb8\x63\x3f\xb0\x96\xb1\x97\x0b\xc1\x49\xc9\x47\x86\x55\x61\x93\x75\xa2\xc2\x8c\xb7\x13\x87\xff\x31\x46\xa5\x29\x41\x9d\xdf\x32\xed\x7a\xb9\xa0\xe1\x9a\x50\x4a\x65\x25\xdb\xbe\x1b\xb6\xcd\xd4\xe7\xc2\x97\x35\xd3\x3e\xd3\xd0\x74\xb8\xd5\xab\x48\xd3\x05\x29\x5e\x31\xcf\x3f\xd3\x51\x78\x13\xbc\xb3\x3e\x63\x62\xca\x05\xfb\xac\xed\xfa\xc1\xe3\xb8\xa2\xaa\xfb\xaa\xbb\xb5\x92\x19\x73\xf0\x78\xe4\x9f\xb0\x1c\x7a\x1c\x0c\x6a\xa7\x8b\x19\x38\x37\x7f\x16\xe8\x61\x41\x68\xef\x6a\x96\x3f\x68\x2b\xb7\xec\x60\x39\x51\xa3\xfc\xbd\x65\xdb\xb8\xff\x39\xfe\xc0\x3d\x16\x51\x7f\xc9\x7f\x8b\xbd\x88\x80\x92\xfe\xe1\x23\x61\xd0\xf1\xd3\xf8\xfa\xce\x86\x92\x6d\x4d\xd7\x69\x50\x8b\xf1\x09\x31\xcc\x19\x15\xef\x37\x12\xd4\xbd\x3d\x0d\x6e\xbb\x28\x3e\xac\xbb\xc4\xdb\x98\xb5\x85\xa6\x19\x11\x74\xe9\xab\xdf', 1)

$ python dist/hello.py
Hello, world!
</code></pre>

<h3>Tool Example 2 – Screenshots</h3>
<p>Information stealing malware will often come with the capability to take screenshots of the users desktop in order to steal sensitive …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cyborgsecurity.com/python-malware-on-the-rise/">https://www.cyborgsecurity.com/python-malware-on-the-rise/</a></em></p>]]>
            </description>
            <link>https://www.cyborgsecurity.com/python-malware-on-the-rise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824689</guid>
            <pubDate>Mon, 13 Jul 2020 19:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Igalia's open prioritization experiment for contributing to browsers]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23824505">thread link</a>) | @staktrace
<br/>
July 13, 2020 | http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html | <a href="https://web.archive.org/web/*/http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
  <article>
  
  <p>Jul 13, 2020</p>
  <p>As many web platform developer and Firefox users, I believe <a href="https://www.mozilla.org/en-US/mission/">Mozilla’s mission</a> is instrumental for a better Internet. In a recent <a href="https://www.igalia.com/chats/ecosystem-health">Igalia’s chat about the Web Ecosystem Health</a>, participants made the usual observation regarding this important role played by Mozilla on the one hand and the limited development resources and small Firefox’s usage share on the other hand. In this blog post, I’d like to explain an experimental idea we are launching at Igalia to try and make browser development better match the interest of the web developer and user community.</p>

<p><a href="https://www.igalia.com/open-prioritization/">
    <img src="http://frederic-wang.fr/images/open-prioritization.png" width="750" height="255" alt="Open Prioritization by Igalia. An experiment in crowd-funding prioritization.">
  </a>
</p>

<h2 id="igalias-contribution-to-browser-repositories">Igalia’s contribution to browser repositories</h2>

<p>As mentioned in the past in this blog, Igalia has contributed to different part of Firefox such as multimedia (e.g. &lt;video&gt; support), layout (e.g. Stylo, WebRender, CSS, MathML), scripts (e.g. BigInt, WebAssembly) or accessibility (e.g. ARIA). But is it enough?</p>

<p>Although commit count is an imperfect metric it is also one of the easiest to obtain. Let’s take a look at how Igalia’s commits repositories of the Chromium (chromium, v8), Mozilla (mozilla-central, servo, servo-web-render) and WebKit projects were distributed last year:</p>

<figure>
  <img width="374" height="305" src="http://frederic-wang.fr/images/distribution-of-igalia-commits-2019.png" alt="pie chart">
  <figcaption><small>Diagram showing, the distribution of Igalia's contributions to browser repositories in 2019 (~5200 commits). Chromium (~73%), Mozilla (~4%) and WebKit (~23%).</small>
  </figcaption>
</figure>

<p>As you can see, in absolute value Igalia contributed roughly 3/4 to Chromium, 1/4 to WebKit, with a small remaining amount to Mozilla. This is not surprising since Igalia is a consulting company and our work depends on the importance of browsers in the market where Chromium dominates and WebKit is also quite good for iOS devices and embedded systems.</p>

<p>This suggests a different way to measure our contribution by considering, for each project, the percentage relative to the total amount of commits:</p>

<figure>
  <img width="436" height="339" src="http://frederic-wang.fr/images/igalia-commit-percentage-per-project-2019.png" alt="Bar graph">
  <figcaption><small>Diagram showing, for each project, the percentage of Igalia's commits in 2019 relative to the total amount of the project. From left to right:
  Chromium (~3.96%), Mozilla (~0.43%) and WebKit (~10.92%).</small>
  </figcaption>
</figure>

<p>In the WebKit project, where ~80% of the contributions were made by Apple, Igalia was second with ~10% of the total. In the Chromium project, the huge Google team made more than 90% of the contributions and many more companies are involved, but Igalia was second with about 4% of the total. In the Mozilla project, Mozilla is also doing ~90% of the contributions but Igalia only had ~0.5% of the total. Interestingly, the second contributing organization was… the community of unindentified gmail.com addresses! Of course, this shows the importance of volunteers in the Mozilla project where a great effort is done to encourage participation.</p>

<h2 id="open-prioritization">Open Prioritization</h2>

<p>From the commit count, it’s clear Igalia is not contributing as much to the Mozilla project as to Chromium or WebKit projects. But this is expected and is just reflecting the priority set by large companies. The solid base of Firefox users as well as the large amount of volunteer contributors show that the Mozilla project is nevertheless still attractive for many people. Could we turn this into browser development that is not funded by advertising or selling devices?</p>

<p>Another related question is whether the internet can really be shaped by the global community as defended by the Mozilla’s mission? Is the web doomed to be controlled by big corporations doing technology’s “evangelism” or lobbying at standardization committees? Are there prioritization issues that can be addressed by moving to a more collective decision process?</p>

<p>At <a href="https://www.igalia.com/about/">Igalia</a>, we internally try and follow <a href="https://wingolog.org/tags/cooperatives">a more democratic organization</a> and, at our level, intend to make the world a better place. Today, we are launching a new <a href="https://www.igalia.com/open-prioritization/">Open Prioritization</a> experiment to verify whether crowdfunding could be a way to influence how browser development is prioritized. Below is a short (5 min) <a href="https://www.youtube.com/embed/xCRxNVbUqhk">introductory video</a>:</p>

<iframe width="850" height="508" src="https://www.youtube.com/embed/xCRxNVbUqhk" frameborder="0" allowfullscreen=""></iframe>

<p>I strongly recommend you to take a look at the proposed projects and <a href="https://www.igalia.com/open-prioritization/#faq">read the FAQ</a> to understand how this is going to work. But remember <em>this is an experiment</em> so we are starting with a few ideas that we selected and tasks that are relatively small. We know there are tons of user reports in bug trackers and suggestions of standards, but we are not going to solve everything in one day !</p>

<p>If the process is successful, we can consider generalizing this approach, but we need to test it first, check what works and what doesn’t, consider whether it is worth pursuing, analyze how it can be improved, etc</p>

<h2 id="two-crowdfunding-tasks-for-firefox">Two Crowdfunding Tasks for Firefox</h2>

<figure>
  <img src="https://upload.wikimedia.org/wikipedia/commons/0/06/CIELAB_color_space_top_view.png" alt="CIELAB color space*">
  <figcaption><small>Representation of the CIELAB color space (top view)
  <a href="https://commons.wikimedia.org/wiki/File:CIELAB_color_space_top_view.png">by Holger Everding, under CC-SA 4.0</a>.</small>
  </figcaption>
</figure>

<p>As explained in the previous paragraph, we are starting with small tasks. For Firefox, we selected the following ones:</p>

<ul>
  <li>
    <p>CSS <code>lab()</code> colors. This is about giving web developers a way to express colors using the <a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB color space</a> which approximates better the human perception. My colleague Brian Kardell wrote a <a href="https://bkardell.com/blog/Unlocking-Colors.html">blog with more details</a>. Some investigations have been made by <a href="https://bugs.webkit.org/show_bug.cgi?id=205675">Apple</a> and <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1026287">Google</a>. Let’s see what we can do for Firefox !</p>
  </li>
  <li>
    <p>SVG path <code>d</code> attribute. This is about expressing <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1571119">SVG path using the corresponding CSS syntax</a> for example <code>&lt;path style="d: path('M0,0 L10,10,...')"&gt;</code>. This will likely involve a refactoring to use the same parser for both SVG and CSS paths. It’s a small feature but part of a more general <a href="https://www.youtube.com/watch?v=1d--S_wgAJA">convergence effort between SVG and CSS</a> that Igalia has been involved in.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Is this crowd-funded experiment going to work? Can this approach solve the prioritization problems or at least help a bit? How can we improve that idea in the future?…</p>

<p>There are many open questions but we will only be able to answer them if we have enough people participating. I’ll personally pledge for the two Firefox projects and I invite you to at least take a look and decide whether there is something there that is interesting for you. Let’s try and see!</p>

</article>


</div></div>]]>
            </description>
            <link>http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824505</guid>
            <pubDate>Mon, 13 Jul 2020 19:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vessel Finder]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23823963">thread link</a>) | @Mosiout1936
<br/>
July 13, 2020 | https://marinetraffic24.com/pt/vesselfinder/ | <a href="https://web.archive.org/web/*/https://marinetraffic24.com/pt/vesselfinder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://marinetraffic24.com/pt/vesselfinder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823963</guid>
            <pubDate>Mon, 13 Jul 2020 18:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to learn to code 10x faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823899">thread link</a>) | @sameerkapur
<br/>
July 13, 2020 | https://blog.thecodex.me/how-to-code-10x-faster/ | <a href="https://web.archive.org/web/*/https://blog.thecodex.me/how-to-code-10x-faster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            



            <section>
                <div>
                    <h3 id="what-i-ve-learned-from-teaching-500-000-students-to-code-and-building-dozens-of-projects-">What I've learned from teaching 500,000 students to code and building dozens of projects.</h3><p>Avi here. Since I started programming, a question that I've been asked again and again from my students is, "How do I learn faster?" Here's the answer: <strong>Build projects.</strong></p><p>Let me explain with a story of my own. I started programming when I was 10-years-old after a friend showed me that she had built a Python weather dashboard that told her exactly when it would rain. I was astounded. I spent the next day figuring out how I could write my own Python Script to crawl Yahoo's Weather API and 24 hours later I had built my first program. If you had told me I had to take an 8-week long bootcamp to learn how to code or watch monotonous YouTube videos until it clicked, I might have never started in the first place. No one forced me to get into programming - I discovered my passion because I wanted to build this cool idea. StackOverflow became my best friend as I achieved my goal. Along the way, I learned about a variety of concepts from calling APIs in Python to parsing JSON and had plenty of practice applying them in my project. The lesson here: <strong>use projects as motivators to learn. </strong></p><p>Okay so we got that out of the way. Building projects are the key to learning things faster. Now what? How do I pick the right projects? Where do I even start?</p><p>The next big takeaway:<strong> Work on projects that matter to you. </strong>My first project was a simple weather script because my ten-year-old brain thought that was wicked cool, but you probably have other passions and interests. Don't compromise. Build projects around your interests and hobbies. If you are starting a project, make sure that it is something that you deeply resonate with. If you are into cars, build a car speed comparison tool. If you are into productivity, build a time tracker to help you be more productive. Even better, build things you want. When those ideas for a cool app or website pop up in your head, START BUILDING IT because motivation is perishable. As the saying goes, the best time to start was yesterday, the next best time to start is now.</p><p>Good things happen to those who are patient. Here are three magic words: <strong>Repetition, Compounding, and Consistency.</strong> These three words are the key to solidifying programming fundamentals and truly understanding new concepts and ideas as you apply them in projects. You've heard how important spaced repetition is for learning - the same thing applies when learning how to code. Try coding for an hour a day. Don't have an hour a day? Code for 30 minutes. Can't do 30 minutes consistently? Try for 15 minutes. Break tasks down into smaller tasks and knock them out.</p><p>Last but not the least, the tip that changed my life: Teach what you learn. Yes, it sounds simple - teach what you learn - but I can't repeat it enough. Explaining concepts allow you to improve your understanding and solidify your learning. Teaching has positive externalities as well. After I started teaching others how to code and began posting videos on <a href="https://www.youtube.com/c/TheCodex">Youtube</a>, I not only understood each and every concept better, but thousands of others used my videos to learn how to code. My AP Stats teacher had a philosophy that to truly understand any concept you must "learn one, do one, and teach one." Teaching others has helped me hold myself accountable to truly understanding concepts until I feel ready to share my knowledge and it's paved my path in becoming a professional Python Developer and Data Scientist.</p><p>For those of you interested in project walkthroughs: Every Tuesday, I'm releasing a new Python/Data Science Project tutorial. I was honestly just tired of watching webcasted lectures and YouTube videos of instructors droning on with robotic voices teaching pure theory, so I started recording my own fun and practical projects. I posted the first project walkthrough on building a Weather API Dashboard with Flask and you can build the whole project for free <strong><a href="https://thecodex.me/projects/weather-api-dashboard-with-python-and-flask">here</a>.</strong></p><p>Want to get notified every time a new project launches? Click <strong><a href="https://cdn.forms-content.sg-form.com/a9d3bb34-c4a3-11ea-a1ea-52b70f2fc72a">here</a></strong>.</p><hr><p>Hey! I'm Avi - your new Python and data science teacher. I've taught over 500,000 students around the world not just how to code, but how to build real projects. I'm on a mission to help you jumpstart your career by helping you master python and data science. Start your journey on TheCodex here: <a href="https://thecodex.me/">https://thecodex.me/</a></p><figure><img src="https://blog.thecodex.me/content/images/2020/07/avi-emailtxt-min-2.jpg" alt="" srcset="https://blog.thecodex.me/content/images/size/w600/2020/07/avi-emailtxt-min-2.jpg 600w, https://blog.thecodex.me/content/images/size/w1000/2020/07/avi-emailtxt-min-2.jpg 1000w, https://blog.thecodex.me/content/images/size/w1600/2020/07/avi-emailtxt-min-2.jpg 1600w, https://blog.thecodex.me/content/images/2020/07/avi-emailtxt-min-2.jpg 1616w" sizes="(min-width: 720px) 720px"><figcaption>new projects and courses coming soon :)</figcaption></figure>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.thecodex.me/how-to-code-10x-faster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823899</guid>
            <pubDate>Mon, 13 Jul 2020 18:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ETL: Navigating the Cloud Transition (Architectures & Factors to consider)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823680">thread link</a>) | @ibains
<br/>
July 13, 2020 | https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition | <a href="https://web.archive.org/web/*/https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823680</guid>
            <pubDate>Mon, 13 Jul 2020 18:06:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Harold Lloyd Filmed "Safety Last!"]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823505">thread link</a>) | @gus_massa
<br/>
July 13, 2020 | https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/ | <a href="https://web.archive.org/web/*/https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg"><img data-attachment-id="2371" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg" data-orig-size="1853,2365" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="108 – T Lloyd Safety Last Tally’s Broadway Theatre below 2 crp" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=235" data-large-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=640" src="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=118&amp;h=150" alt="108 - T Lloyd Safety Last Tally's Broadway Theatre below 2 crp" width="118" height="150" srcset="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=118&amp;h=150 118w, https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=236&amp;h=300 236w" sizes="(max-width: 118px) 100vw, 118px"></a>The image of Harold Lloyd hanging desperately from the hands of a skyscraper clock during <em>Safety Last! </em>(1923) is one of the great icons of film history.&nbsp; Using maps, aerial views, and vintage photographs, my book <a href="http://www.amazon.com/Silent-Visions-Discovering-Hollywood-Through/dp/1595800573/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1330485203&amp;sr=1-1"><em>Silent Visions</em></a> shows how Harold filmed each of his five stunt-climbing comedies within the downtown Los Angeles Historic Core, while documenting the burgeoning urban skyline as it appears in the background of his films. [Note: <span>I will be introducing <em>Safety Last!</em> on June 25, 2016</span> at the Orpheum Theater as part of the Los Angeles Conservancy’s <a href="https://www.laconservancy.org/events/safety-last-orpheum-theatre">Last Remaining Seats</a>.]</p>
<div data-shortcode="caption" id="attachment_6143"><p><a href="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg"><img aria-describedby="caption-attachment-6143" data-attachment-id="6143" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/pan-04-9/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg" data-orig-size="1800,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="pan 04" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640" src="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640&amp;h=223" alt="On the roof of 908 S. Broadway from Safety Last! and the YouTube video clip" width="640" height="223" srcset="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640&amp;h=223 640w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=1278&amp;h=446 1278w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=150&amp;h=52 150w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=300&amp;h=105 300w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=768&amp;h=268 768w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=1024&amp;h=357 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-6143">The closing scene from <em>Safety Last!</em> (left) was filmed on the roof of 908 S. Broadway, the same building where the clock stunt climbing set was built. The same roof (right), now supporting the steel girder foundation for a large antennae, appears during the Criterion Collection <a href="http://youtu.be/tnrjyjKH5OU"><em>Locations and Effects</em> mini clip</a>.</p></div>
<p>The slides below show how the many <em>Safety Last!</em> stunts were created, and may be downloaded further below as a 14 MB PowerPoint presentation.&nbsp; You can also access a <a href="https://silentlocations.files.wordpress.com/2016/06/los-angeles-conservancy-harold-lloyd-safety-last-tour-bengtson-2016.pdf">self-guided walking tour</a> of the downtown locations appearing in <em>Safety Last!</em>, <em>Never Weaken, </em>and <em>Feet First. </em><a href="https://silentlocations.files.wordpress.com/2019/10/complete-list-of-all-harold-lloyd-stunt-climbing-buildings-updated-2019.pdf">(In all Lloyd employed 17 downtown buildings during his “thrill” comedies – see a PDF list of descriptions here</a><em><a href="https://silentlocations.files.wordpress.com/2019/10/complete-list-of-all-harold-lloyd-stunt-climbing-buildings-updated-2019.pdf">)</a>.<br>
</em></p>
<p>[Note: on the ground, Charlie Chaplin, Buster Keaton and Harold Lloyd <a href="https://silentlocations.com/chaplin-keaton-lloyd-alley/">filmed scenes from their masterpieces <em>The Kid</em> (1921), <em>Cops</em> (1922) and <em>Safety Last!</em> at the same Hollywood alley you can still visit today</a>.]</p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg"><img data-attachment-id="7315" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_01/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_01" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640&amp;h=480" alt="SL short blog_Page_01" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg"><img data-attachment-id="7316" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_02/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_02" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640&amp;h=480" alt="SL short blog_Page_02" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg"><img data-attachment-id="7317" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_03/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_03" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640&amp;h=480" alt="SL short blog_Page_03" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg"><img data-attachment-id="7318" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_04/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_04" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640&amp;h=480" alt="SL short blog_Page_04" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg"><img data-attachment-id="7319" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_05/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_05" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640&amp;h=480" alt="SL short blog_Page_05" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg"><img data-attachment-id="7320" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_06/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_06" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640&amp;h=480" alt="SL short blog_Page_06" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg"><img data-attachment-id="7321" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_07/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_07" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640&amp;h=480" alt="SL short blog_Page_07" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg"><img data-attachment-id="7322" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_08/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_08" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640&amp;h=480" alt="SL short blog_Page_08" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg"><img data-attachment-id="7323" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_09/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_09" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640&amp;h=480" alt="SL short blog_Page_09" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg"><img data-attachment-id="7324" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_10/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_10" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640&amp;h=480" alt="SL short blog_Page_10" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg"><img data-attachment-id="7325" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_11/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_11" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640&amp;h=480" alt="SL short blog_Page_11" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg"><img data-attachment-id="7326" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_12/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_12" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640&amp;h=480" alt="SL short blog_Page_12" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg"><img data-attachment-id="7327" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_13/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_13" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640&amp;h=480" alt="SL short blog_Page_13" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p>Here is the link to download the PowerPoint.&nbsp; Most of the slides are animated, so wait a moment each time before clicking the “next” button.</p>
<div data-shortcode="caption" id="attachment_2367"><p><a href="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg"><img aria-describedby="caption-attachment-2367" data-attachment-id="2367" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/untitled/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg" data-orig-size="609,644" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Untitled" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=284" data-large-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=609" title="Untitled" src="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=283&amp;h=300" alt="" width="283" height="300" srcset="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=283&amp;h=300 283w, https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=566&amp;h=600 566w, https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=142&amp;h=150 142w" sizes="(max-width: 283px) 100vw, 283px"></a></p><p id="caption-attachment-2367">The recent multiple Oscar-winning movie <em>Hugo</em> pays tribute to <em>Safety Last!</em>; first by including a clip of the Lloyd movie within the film, and also when the young hero Hugo Cabret finds himself hanging from a train station clock. <em>Hugo</em> (C) 2011 Paramount Pictures</p></div>
<p><a href="https://silentlocations.files.wordpress.com/2012/02/how-harold-lloyd-filmed-safety-last-by-john-bengtson.ppt">How Harold Lloyd Filmed Safety Last by John Bengtson</a></p>
<p>You will need a PowerPoint viewer to watch the show, and can download a PowerPoint viewer at this <a href="http://www.microsoft.com/downloads/en/details.aspx?displaylang=en&amp;FamilyID=cb9bf144-1076-4615-9951-294eeb832823">site</a>.</p>
<p>You can also check out <a href="https://silentlocations.wordpress.com/category/safety-last/">my other posts about <em>Safety Last! </em>here</a>.</p>
<p>A short segment from the <em>Locations and Effects</em> 2013 documentary with Academy-Award winning effects supervisor Craig Barron and the author filmed for the <a href="http://www.criterion.com/films/28446-safety-last">Criterion Collection release of the <em>Safety Last!</em> Blu-ray </a>appears below.</p>
<p><span><iframe width="560" height="315" src="https://www.youtube.com/embed/tnrjyjKH5OU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p><p><span>To see where Harold filmed his amazing comedies, be sure to check out my book <a href="https://www.amazon.com/Silent-Visions-Discovering-Hollywood-Through/dp/1595800573/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1533680311&amp;sr=1-1&amp;keywords=john+bengtson+silent"><em>Silent Visions</em></a>.&nbsp; </span></p>
<p><span>If you need a good laugh, or want to raise your spirits, just listen to Michael Mortilla’s audio-only recording of the audience laughing and squealing with delight while watching <em>Safety Last!</em>&nbsp; It’s great to play as background music <span>– the swells and squeals of laughter just grow and grow.</span></span></p>
<p><a href="http://www.midilifecrisis.com/Music_and_Sound/SafetyLast_Audience_Michael_Mortilla_Piano.mp3">Michael Mortilla accompanying Safety Last!</a></p>
<p>HAROLD LLOYD images and the names of Mr. Lloyd’s films are all trademarks and/or service marks of Harold Lloyd Entertainment Inc. Images and movie frame images reproduced courtesy of The Harold Lloyd Trust and Harold Lloyd Entertainment Inc.</p>
<p><img data-attachment-id="15216" data-permalink="https://silentlocations.com/chaplin-keaton-lloyd-alley/chaplin-keaton-lloyd-sign/" data-orig-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg" data-orig-size="1570,211" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Chaplin-Keaton-Lloyd-sign" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640" src="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640" alt="Chaplin-Keaton-Lloyd-sign" srcset="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640 640w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=1280 1280w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=150 150w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=300 300w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=768 768w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>Please help support naming the <a href="https://silentlocations.com/chaplin-keaton-lloyd-alley/">Chaplin Keaton Lloyd alley</a> in Hollywood by posting a review on <a href="https://goo.gl/maps/NGK6JpvncU3ejLDX7">Google Maps</a>. Prototype alley sign design by noted Dutch graphic artist – <a href="http://pietschreuders.com/">Piet Schreuders</a>. Download a 4-page brochure <a href="https://silentlocations.files.wordpress.com/2020/02/honor-the-chaplin-keaton-lloyd-alley.pdf">HERE</a>.</p>
<p>The site of the clock set, built on the roof of 908 S. Broadway on Google Maps.</p>

											</div></div>]]>
            </description>
            <link>https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823505</guid>
            <pubDate>Mon, 13 Jul 2020 17:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I started working in the cloud in a matter of days]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823272">thread link</a>) | @markothedev
<br/>
July 13, 2020 | https://microtica.com/an-outstanding-cloud-automation-experience/ | <a href="https://web.archive.org/web/*/https://microtica.com/an-outstanding-cloud-automation-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p><a href="https://microtica.com/" target="_blank" rel="noreferrer noopener">Microtica</a> has the goal to provide the best cloud automation experience for developers from its very beginnings. We are so happy when we hear a success story, especially from developers who weren’t familiar with cloud automation previously.&nbsp;</p>



<p>This is why we decided to bring to you a series of interviews with our customers that experience the benefits of our solution. They jumped into a whole new world in a matter of days instead of months. </p>



<p>We are calling it: <strong>Developers Say.&nbsp;</strong></p>



<p>The first developer we talked to is Marko, a full-stack developer from <a href="https://vertt.ch/">Vertt</a>.&nbsp;</p>



<p><em>You can read more about how Vertt accelerated its DevOps processes with Microtica <a href="https://microtica.com/case-studies/accelerating-devops-processes/" target="_blank" rel="noreferrer noopener">here</a>.</em></p>



<h2><strong>What’s the product you’re developing?</strong></h2>



<p><a href="https://vertt.ch/">Vertt</a> is a Swiss ride-hailing startup that provides a reliable, responsible and secure transportation experience. As a service, Vertt wants to fill in the voids that exist in the Swiss transportation system. We innovate all the time, in order to provide society with a one-stop mobility solution.&nbsp;</p>



<h2><strong>Which technologies did you use when developing the solution?&nbsp;</strong></h2>



<p>You could say we actually have <strong>five applications</strong>. Four are mobile-native iOS and Android applications, two for the passenger experience, and two are for the drivers. We also have <strong>one web application </strong>which is the admin panel for our business team, developed in Angular.</p>



<p>As for the backend and infrastructure part, the solution is built on the latest <strong>microservice technology with AWS as a cloud provider</strong>. The backend is developed in Node.js.&nbsp;</p>



<div><figure><img src="https://media-exp1.licdn.com/dms/image/C5603AQFmUaDjB8TNSg/profile-displayphoto-shrink_800_800/0?e=1599696000&amp;v=beta&amp;t=5D8Bl17XcfwZ91kQIRTsD-_mg_ag4O9jwwGWIAs4Nuc" alt=""><figcaption>Marko from Vertt</figcaption></figure></div>



<h2><strong>Can you tell us about your background as a developer?&nbsp;</strong></h2>



<p>I am a full-stack developer with two years of experience. Vertt is my first major project and my first time working on a project of this magnitude. This project is where <strong>I gained most of my knowledge and learned about the big picture.</strong> I’m developing <strong>the backend logic in NodeJS</strong> for the entire system. I’m also working on the dashboard for our business team in Angular. I’ve worked on just a few projects prior to this. They were mostly small websites that didn’t require a backend component or scalability features.</p>



<h2><strong>Why did you choose a microservice infrastructure for this particular project?</strong></h2>



<p>We often see startups <a href="https://microtica.com/why-transition-from-monolith-to-microservices/" target="_blank" rel="noreferrer noopener">kicking off with a monolithic application</a> just to get something out there. However, when they expand, they face <strong>various problems related to scalability and continuous integration</strong>.&nbsp;</p>



<p><em>We wanted to do it the right way. </em>The <a href="https://microtica.com/everything-about-microservices/" target="_blank" rel="noreferrer noopener">benefits of the microservice architecture</a> are well-known. <strong>Different codebases, separate deployable units performing separate functionalities</strong>, and the most important for us—<strong>scaling individually</strong>.&nbsp;</p>



<h2><strong>How did you deliver software before discovering Microtica?</strong></h2>



<p>We started using <strong>Jenkins </strong>as part of our DevOps process. As our team consists of full-stack and mobile developers, we were really <strong>struggling with all the setup and integration of numerous plug-ins.</strong> We were using Jenkins as a build orchestration tool. We soon became very <strong>limited by the release management</strong> that Jenkins has to offer. Issues like access control management, configuration usability, and scaling began to overwhelm us and defocus us from our daily tasks.</p>



<p>As the team began to grow, tracking and accountability of various team members became a great issue. As we did most deployments and builds via a single user,<strong> tracking was only at the code level </strong>through our source control tool Git.&nbsp;</p>



<h2><strong>What was the biggest challenge you had as a developer working with cloud automation?</strong></h2>



<p>The main challenge for any beginner or intermediate developer is <strong>connecting all pieces together </strong>and making them work as one. Understanding how the entire system is designed and managed behind the curtain in the cloud is a continuous process that consists of <strong>constant learning and hands-on effort.</strong> Coming across stuff like cloud automation, scaling, and continuous delivery is always challenging, especially if you don’t have much experience to get started.&nbsp;</p>



<h2><strong>How did Microtica help you overcome these challenges?</strong></h2>



<p>Microtica made deploying our entire system extremely<strong> easy and effortless.</strong> With just a few clicks and a few extra files, we set up and deployed our entire system consisting of 13 microservices.&nbsp;</p>



<p>After <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">setting up our initial development environment</a> <strong>it only took us one hour to get the test and production environments up and running.</strong> For this, we used the Clone Environment feature. This was really important to us because we wanted to fully migrate to Microtica before going to production.</p>



<p>The integration went <strong>smoothly and pretty fast</strong>. We only needed to create a couple of files in each microservice to create and guide the deployment pipeline. Now we can change parameters and redeploy our services within minutes and with almost no downtime.</p>



<p>It was extremely helpful that we could use their ready-to-use components. This eliminated the need to write complex CloudFormation templates for simple AWS resources. It allowed us to reuse the components by using just the UI.</p>



<h2><strong>How did Microtica help you grow as a developer?</strong></h2>



<p>Before working with Microtica, I didn’t have much experience and knowledge in the cloud automation space. Microtica gave me <strong>an initial push</strong>.  It made me confident enough to <strong>set up and maintain a fully functional system with three environments.</strong> I could create custom infrastructure and deploy microservices in the cloud <strong>in a matter of days.</strong> It allowed me to focus more on the actual development and less on infrastructure maintenance.</p>



<h2><strong>What kind of challenges are ahead of you and your team?</strong></h2>



<p>Our system is expanding on a daily basis along with its complexity. With a new feature every month, it’s crucial for us to have a firm grasp of<strong> the entire system at any time</strong>. Since we made a production release, <strong>stability has become our number one priority.</strong> It’s also probably the biggest challenge that we will face in the future.</p>



<figure><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101"><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg" alt="Start with cloud automation" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-300x180.jpg 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-768x461.jpg 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1536x922.jpg 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-667x400.jpg 667w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01.jpg 2000w" sizes="100vw"></a></figure>



<h2><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101" target="_blank" rel="noreferrer noopener">Sign up for Microtica</a> and start with cloud automation today.</h2>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:identifier="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:title="Developers Say: An Outstanding Cloud Automation Experience"
    trackback:ping="https://microtica.com/an-outstanding-cloud-automation-experience/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/an-outstanding-cloud-automation-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823272</guid>
            <pubDate>Mon, 13 Jul 2020 17:31:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Econometrics with R]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823031">thread link</a>) | @ethanwillis
<br/>
July 13, 2020 | https://www.econometrics-with-r.org/index.html | <a href="https://web.archive.org/web/*/https://www.econometrics-with-r.org/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">
<p>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span>selecting it with the cursor</span> and then click the <i></i> on the pop-up menu. You can also see the annotations of others: click the <i></i> in the upper right hand corner of the page 
</p>

<div id="preface">

<hr>
<center>
<img src="https://www.econometrics-with-r.org/images/cover.png">
</center>
<div><p> Chair of Econometrics <img src="https://www.econometrics-with-r.org/images/logo_claim_en_rgb.png"> <br> Department of Business Administration and Economics <br> University of Duisburg-Essen <br> Essen, Germany <br> <a href="https://www.econometrics-with-r.org//%22mailto:info@econometrics-with-r.org?subject=Econometrics%20with%20R\%22">info@econometrics-with-r.org</a></p><p> Last updated on Friday, August 30, 2019
</p>
</div>
<hr>
<p>Over the recent years, the statistical programming language R has become an integral part of the curricula of econometrics classes we teach at the University of Duisburg-Essen. We regularly found that a large share of the students, especially in our introductory undergraduate econometrics courses, have not been exposed to any programming language before and thus have difficulties to engage with learning R on their own. With little background in statistics and econometrics, it is natural for beginners to have a hard time understanding the benefits of having R skills for learning and applying econometrics. These particularly include the ability to conduct, document and communicate empirical studies and having the facilities to program simulation studies which is helpful for, e.g., comprehending and validating theorems which usually are not easily grasped by mere brooding over formulas. Being applied economists and econometricians, all of the latter are capabilities we value and wish to share with our students.</p>
<p>Instead of confronting students with pure coding exercises and complementary classic literature like the book by <span>Venables &amp; Smith (<a href="#ref-venables2010" role="doc-biblioref">2010</a>)</span>, we figured it would be better to provide interactive learning material that blends R code with the contents of the well-received textbook <em>Introduction to Econometrics</em> by <span>Stock &amp; Watson (<a href="#ref-stock2015" role="doc-biblioref">2015</a>)</span> which serves as a basis for the lecture. This material is gathered in the present book <em>Introduction to Econometrics with R</em>, an empirical companion to <span>Stock &amp; Watson (<a href="#ref-stock2015" role="doc-biblioref">2015</a>)</span>. It is an interactive script in the style of a reproducible research report and enables students not only to learn how results of case studies can be replicated with R but also strengthens their ability in using the newly acquired skills in other empirical applications.</p>
<div id="conventions-used-in-this-book">
<h4>Conventions Used in this Book</h4>
<ul>
<li><p><em>Italic</em> text indicates new terms, names, buttons and alike.</p></li>
<li><p><tt>Constant width text</tt> is generally used in paragraphs to refer to <tt>R</tt> code. This includes commands, variables, functions, data types, databases and file names.</p></li>
<li><p><code>Constant width text on gray background</code> indicates <tt>R</tt> code that can be typed literally by you. It may appear in paragraphs for better distinguishability among executable and non-executable code statements but it will mostly be encountered in shape of large blocks of <tt>R</tt> code. These blocks are referred to as code chunks.</p></li>
</ul>
</div>
<div id="acknowledgement">
<h4>Acknowledgement</h4>
<p>We thank the <em>Stifterverband für die Deutsche Wissenschaft e.V.</em> and the <em>Ministry of Science and Research North Rhine-Westphalia</em> for their financial support. Also, we are grateful to Alexander Blasberg for proofreading and his effort in helping with programming the exercises.
A special thanks goes to Achim Zeileis (University of Innsbruck) and Christian Kleiber (University of Basel) for their advice and constructive criticism. Another thanks goes to Rebecca Arnold from the Münster University of Applied Sciences for several suggestions regarding the website design and for providing us with her nice designs for the book cover, logos and icons. We are also indebted to all past students of our introductory econometrics courses at the University of Duisburg-Essen for their feedback.</p>
<p><br>
<img src="https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc-sa.eu.svg" alt="Creative Commons License"></p>
<p>This book is licensed under the <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
</div>
</div>
<h3>References</h3>
<div id="refs">
<p>Stock, J. H., &amp; Watson, M. W. (2015). <em>Introduction to Econometrics, Third Update, Global Edition</em>. Pearson Education Limited.</p>

</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://www.econometrics-with-r.org/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823031</guid>
            <pubDate>Mon, 13 Jul 2020 17:09:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula Webinar: Infrastructure as Code in OpenNebula using Terraform]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822942">thread link</a>) | @amarti
<br/>
July 13, 2020 | https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw | <a href="https://web.archive.org/web/*/https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Terraform, the open source Infrastructure as Code software tool created by HashiCorp, is a solution for building, changing, and versioning infrastructure safely and efficiently. It allows infrastructure to be expressed as code in a simple, human readable language called HCL. Terraform reads configuration files and provides an execution plan of changes, which can be reviewed for safety and then applied and provisioned automatically.</p><p>What to expect from this webinar?</p><p>- Learn about Terraform’s Infrastructure as Code approach and about its basic uses and capabilities, including the value it provides for managing the full lifecycle of your infrastructure, plan and predict changes, and create reproducible environments.</p><p>- Discover the new version and future roadmap of the OpenNebula Provider, through which cloud admins can use Terraform to interact with OpenNebula cluster resources.</p><p>- Watch a live demo on how this amazing integration is being used in an actual cloud, and how to simplify a real infrastructure workflow by using the OpenNebula Provider for Terraform.</p><p>This webinar will be presented by Michael Abdou (Customer Success Manager at OpenNebula). Our guest speakers for this event will be Taylor Dolezal (Senior Developer Advocate at HashiCorp) and Jean-Philippe Fourès (Cloud Product Manager at Iguane Solutions).</p><p>Press and media, please contact: events@opennebula.io
</p></div></div>]]>
            </description>
            <link>https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822942</guid>
            <pubDate>Mon, 13 Jul 2020 17:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effecftive Poster Design for Science Communication [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23822939">thread link</a>) | @pabloem
<br/>
July 13, 2020 | http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf | <a href="https://web.archive.org/web/*/http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822939</guid>
            <pubDate>Mon, 13 Jul 2020 17:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Open Source, licenses and changes]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 26 (<a href="https://news.ycombinator.com/item?id=23822732">thread link</a>) | @nfrankel
<br/>
July 13, 2020 | https://blog.frankel.ch/on-opensource-licenses-changes/ | <a href="https://web.archive.org/web/*/https://blog.frankel.ch/on-opensource-licenses-changes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting"> <meta itemprop="mainEntityOfPage" content="//on-opensource-licenses-changes/"> <meta itemprop="description" content="">  <figure itemscope="" itemprop="image" itemtype="http://schema.org/ImageObject"> <meta itemprop="url" content="https://blog.frankel.ch/assets/resources/open-source-licenses-changing/OSI_Standard_Logo_0.svg"> </figure> <section> <div itemprop="articleBody"> <p>The subject of Open Source and OS licenses has been waxing and waning over time. Recently, it became hot again. In this post, I’d like to do a quick recap to set the stage. Then, I’ll analyze reasons for license changes.</p> <div> <h2 id="the-rise-of-open-source">The rise of Open Source</h2> <div> <p>Before I actually started my career - even I was before even born - software was provided with its source code. The value was in the hardware. Most customers - if not every one of them - modified and adapted the source code to their hardware. Then, in 1969, the United States' government ruled (against IBM) that the bundling of software and hardware together was <em>anticompetitive</em>. The value moved from hardware to software because of an unexpected side-effect of the previous ruling. Thus began the rise of Microsoft Windows. Interestingly enough, that also changed the way software was delivered. Customers only got the binaries, not the source code. Of course, this is mostly the case today.</p> <p>Around ten years later, a new trend started in reaction to that: some with Richard Stallman decided that releasing the source code was the only <em>right</em> way to deliver software. Furthermore, their position was that software should be free. Because that tiny initiative became a respectable model, this view on things is more than relevant today. Today, Open Source means different things in the mind of different people.</p> </div> </div> <div> <h2 id="open-source-is-a-loaded-term">Open Source is a loaded term</h2> <div> <p>Literally, Open Source is only the delivery of the source code along the binary. No more, no less. For commercial software, if carefully worded in the purchasing contract, that means that the customer should be able to maintain the software if the vendor doesn’t anymore (<em>e.g.</em> goes bankrupt). Yet, according to Stallman’s definition, software needs to be free:</p> <div> <blockquote> <ul><li><span>Free as a bird</span></li><li><span>Free as a beer</span></li></ul> </blockquote> </div> <p>To avoid any confusion, I’d rather use the expression Free Open-Source Software <em>a.k.a.</em> FOSS.</p> </div> </div> <div> <h2 id="what-qualifies-as-open-source">What qualifies as Open Source</h2> <div> <p>This gap in the terms were deeply materialized in tensions in the community between tenants of the business-compatible Open Source and FOSS as defined above. From the former group was born the <a href="https://en.wikipedia.org/wiki/Open_Source_Initiative" target="_blank" rel="noopener">Open Source Initiative</a>. The importance of this organization cannot be understated: it decides what licenses are considered Open Source, based on the <a href="https://en.wikipedia.org/wiki/The_Open_Source_Definition">Open Source definition</a>. Criteria are:</p> <ol><li><span>Free Redistribution</span></li><li><span>Source Code</span></li><li><span>Derived Works</span></li><li><span>Integrity of The Author’s Source Code</span></li><li><span>No Discrimination Against Persons or Groups</span></li><li><span>No Discrimination Against Fields of Endeavor</span></li><li><span>Distribution of License</span></li><li><span>License Must Not Be Specific to a Product</span></li><li><span>License Must Not Restrict Other Software</span></li><li><span>License Must Be Technology-Neutral</span></li></ol> <p>As of the time of writing of this post, licenses that are allowed to be qualified as Open Source are <a href="https://opensource.org/licenses/alphabetical" target="_blank" rel="noopener">limited in number</a>. Here’s a couple of them:</p> <ul><li><span><a href="https://opensource.org/licenses/Apache-2.0">Apache License 2.0</a></span></li><li><span><a href="https://opensource.org/licenses/gpl-license">GNU General Public License (GPL)</a></span></li><li><span><a href="https://opensource.org/licenses/lgpl-license" target="_blank" rel="noopener">GNU Library or "Lesser" General Public License (LGPL)</a></span></li><li><span><a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener">MIT license</a></span></li></ul> <p>Here are two counter-examples:</p> <ul><li><span>The <a href="https://github.com/climate-strike/license" target="_blank" rel="noopener">Climate Strike License</a> is not Open Source, as it’s not in the list above</span></li><li><span><a href="https://creativecommons.org/licenses/">Creative Commons licenses</a> are not Open Source, as they don’t apply to software only</span></li></ul> </div> </div> <div> <h2 id="monetizing-open-source">Monetizing Open Source</h2> <div> <p>Open Source began as a community of like-minded people who wanted to create something together, and were willing to put on the extra effort, after office hours. However, today, the main contributors on the main projects are paid by private companies: they code during office hours. The reason for that is that Open Source - not FOSS - is compatible with business.</p> <p>There are a couple of ways to monetize Open Source software:</p> <div> <dl> <dt>Training and consulting</dt> <dd> <p>If you provide a great software, companies will start using it. At some point, there are chances they will need consulting, for advanced usage. After that, they will also need training to level up their workforce. It has been the traditional way to make money with Open Source. Unfortunately, this doesn’t scale.</p> </dd> <dt>Support</dt> <dd> <p>While consulting is planned, support comes in handy when the sh…​ has already hit the fan. Picture this: it’s 10PM, the monitoring Open Source stack your company uses has crashed, and refuse to start again. One definitely needs support in this case. <em>In general</em>, managers don’t like to use any kind of software - whether FOSS, Open Source or something else - if they don’t have an associated support contract.</p> </dd> <dt>Open Source core</dt> <dd> <p>The software offers features that are Open Source. A set of features available via extensions/plugins operate under a commercial (<em>i.e.</em> paying) license. The respective size of each depends on one’s strategy. The more features in the Open Source part, the more people will use it, but the less money one will get. This is a fine balance to find.</p> </dd> <dt>Dual license</dt> <dd> <p>The software is available under two different licenses, one Open Source, the other commercial. When one uses the software, one needs to choose which license should apply. For this model to work, and companies to decide to pay a license fee, the Open Source license should be a deterrent. The <a href="https://opensource.org/licenses/gpl-license" target="_blank" rel="noopener">GNU General Public License</a> is a solid choice: it mandates that software that embeds the GPL software should be released under the GPL license itself <em>i.e.</em> for free.</p> </dd> </dl> </div> </div> </div> <div> <h2 id="service-wrapping">Service-wrapping</h2> <div> <p>It’s no mystery that "the Cloud" has become ubiquitous since a couple of years, whether you like it or not. As more companies moved their IT-systems to the Cloud, the Cloud service providers became a force to be reckoned with. With that power, they bargained with software vendors on ways to provide the latter’s software on their infrastructure. In general, the deal was pretty much one-sided: Cloud providers got a larger portfolio of services, while software vendors got "free advertisement" for their software, and in the best of case, crumbs of the revenue.</p> <p>But even that was not enough. Some cloud providers became so bold as to stop pretending it was even a deal. They just got they greedy hands on the Open Source software, and service-wrapped it. It was completely legal, as none of the licenses prevents that. However, it raises the question of revenue sharing: one company is paying to develop the software, while another company is getting the biggest share of the revenues, because it controls the marketplace.</p> <p>Because of that, some software vendors decided to change their license to prevent service wrapping. The issue is that no Open Source license is able to achieve that. Hence, those new licenses are not considered Open Source, as per the Open Source Initiative definition.</p> </div> </div> <div> <h2 id="other-license-changes">Other license changes</h2> <div> <p>Changing one’s license is in general not a great idea. When somebody uses your software, they need to be able to trust they can use it in the future under the same terms. The anti-service wrapping changes made sure that was the case.</p> <p>Interestingly enough, I saw recently a license change unrelated to service wrapping. In the light of the CoVid-19 pandemics, somebody thought it would be a good idea to change the license to a new one:</p> <div> <blockquote> <p>CoronaVirus License :</p> <p>The coronavirus is coming to you. It’s coming at an exponential speed: gradually, and then suddenly. It’s a matter of days. Maybe a week or two. When it does, your healthcare system will be overwhelmed. Your fellow citizens will be treated in the hallways. Exhausted healthcare workers will break down. Some will die. They will have to decide which patient gets the oxygen and which one dies. The only way to prevent this is social distancing today. Not tomorrow. Today. That means keeping as many people home as possible, starting now.</p> <p>To use this program, you must</p>  <p>2) Apply social distancing</p> <p>If you live in UK, Europe, North &amp; South America, Iran, Japan, Korea…​ and if you refuse to do so, please uninstall Dummy from your system and do not use this service anymore.</p> </blockquote> </div> <p>While the intention behind this change was commendable, the change was not. This is a sure sign the license cannot be trusted. If it changes today, why cannot it change tomorrow, for other reasons? I’d advise everybody in this situation not to do that.</p> <div> <table> <tbody><tr> <td> <i title="Important"></i> </td> <td> The license change was rollbacked as it was considered at least partially unlawful. </td> </tr> </tbody></table> </div> </div> </div> <div> <h2 id="conclusion">Conclusion</h2> <div> <p>In this post, we described the origin of Open Source Software. We looked at the semantics of the expression "Open Source", and described the difference with <abbr title="Free Open Source Software">FOSS</abbr>. Then, we wrote about the Open Source Initiative, the characteristics it applies to define Open Source, and some licenses that fit this definition. We proceeded to list some ways on how to monetize FOSS. Finally, we described the problematic behavior of some Cloud providers, and how changing the license is a way to avoid it. Other reasons for license changes might break the contrast of trust between a software vendor and its users.</p> </div> </div>    </div> </section>   </article> </div> </div></div>]]>
            </description>
            <link>https://blog.frankel.ch/on-opensource-licenses-changes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822732</guid>
            <pubDate>Mon, 13 Jul 2020 16:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PiHole As-a-Service (On Steroids)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821863">thread link</a>) | @microkernel
<br/>
July 13, 2020 | https://www.gardion.de/english-intro | <a href="https://web.archive.org/web/*/https://www.gardion.de/english-intro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><img src="https://www.gardion.de/assets/svg/devices-37.svg" height="48" alt="Icon"></p><h3>My internet!</h3>
        <p>Facebook is breathing down your neck? Your Xiaomi mobile is spying
          on you? Your app is reporting where you go and which flight you take? Not anymore. Gardion is a filtering VPN
          with the sole purpose to keep you safe and your data private.<mark>Gardion is your internet „invisibility
            cloak“.</mark></p>
      </div><div>
        <p><img src="https://www.gardion.de/assets/svg/science-15.svg" height="48" alt="Icon"></p><h3>Anytime, anywhere</h3>
        <p>Gardion works on all devices, anywhere; be it your smartphone (iOS, Android),
          your tablet or your laptop. Being geeks we made sure that BSD, Linux and other open systems can interface as
          well. <mark>The only requirement: Support for IPSEC or Wireguard</mark>. It works at home, while travelling,
          via WIFI and mobile network.
        </p>
      </div><div>
        <p><img src="https://www.gardion.de/assets/svg/communications-16.svg" height="48" alt="Icon"></p><h3>Trust, instead of Panama</h3>
        <p>The other VPN providers reside in Panama, Romania or the Netherlands Antilles.
          With Gardion you are on the safe side: When you want to work in a strong and trustworthy jurisdiction Germany
          is your choice. <mark>Our headquarter is in Freiburg/Germany and our servers are in Germany as well. No AWS,
            no Google cloud</mark>.
        </p>
      </div></div>]]>
            </description>
            <link>https://www.gardion.de/english-intro</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821863</guid>
            <pubDate>Mon, 13 Jul 2020 15:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deschooling Society (1970)]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 179 (<a href="https://news.ycombinator.com/item?id=23821855">thread link</a>) | @minerjoe
<br/>
July 13, 2020 | https://davidtinapple.com/illich/1970_deschooling.html | <a href="https://web.archive.org/web/*/https://davidtinapple.com/illich/1970_deschooling.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="700">
				<tbody><tr>
					<td><span size="+2">DESCHOOLING SOCIETY</span><p>
						
						&nbsp;
						IVAN ILLICH</p><p>
						
						&nbsp;
						
						&nbsp;
						Contents</p><p>
						
						&nbsp;
						
						Introduction xix </p><p>
						
						<a href="#1">1. Why We Must Disestablish School</a></p><p>
						
						<a href="#2">2. Phenomenology of School<br>
						</a><br>
						<a href="#3">3. Ritualization of Progress<br>
						</a><br>
						<a href="#4">4. Institutional Spectrum</a></p><p>
						
						<a href="#5">5. Irrational Consistencies</a></p><p>
						
						<a href="#6">6. Learning Webs</a></p><p>
						
						<a href="#7">7. Rebirth of Epimethean Man</a></p><p>
						
						&nbsp;
						
						
						
						
						&nbsp;
						
						Introduction</p><p>
						
						
						&nbsp;
						
						I owe my interest in public education to Everett Reimer. Until we first met in Puerto Rico in 1958, I had never questioned the value of extending obligatory schooling to all people. Together we have come to realize that for most men the right to learn is curtailed by the obligation to attend school. The essays given at CIDOC and gathered in this book grew out of memoranda which I submitted to him, and which we discussed during 1970, the thirteenth year of our dialogue. The last chapter contains my afterthoughts on a conversation with Erich Fromm on Bachofen's Mutterrecht.</p><p>
						
						
						Since 1967 Reimer and I have met regularly at the Center for Intercultural Documentation (CIDOC) in Cuernavaca, Mexico. Valentine Borremans, the director of the Center, also joined our dialogue, and constantly urged me to test our thinking against the realities of Latin America and Africa. This book reflects her conviction that the ethos, not just the institutions, of society ought to be "deschooled."</p><p>
						
						
						Universal education through schooling is not feasible. It would be no more feasible if it were attempted by means of alternative institutions built on the style of present schools. Neither new attitudes of teachers toward their pupils nor the proliferation of educational hardware or software (in classroom or bedroom), nor finally the attempt to expand the pedagogue's responsibility until it engulfs his pupils' lifetimes will deliver universal education. The current search for new educational funnels must be reversed into the search for their institutional inverse: educational webs which heighten the opportunity for each one to transform each moment of his living into one of learning, sharing, and caring. We hope to contribute concepts needed by those who conduct such counterfoil research on education--and also to those who seek alternatives to other established service industries.</p><p>
						
						
						On Wednesday mornings, during the spring and summer of 1970, I submitted the various parts of this book to the participants in our CIDOC programs in Cuernavaca. Dozens of them made suggestions or provided criticisms. Many will recognize their ideas in these pages, especially Paulo Freire, Peter Berger, and Jos? Maria Bulnes, as well as Joseph Fitzpatrick, John Holt, Angel Quintero, Layman Allen, Fred Goodman, Gerhard Ladner, Didier Piveteau, Joel Spring, Augusto Salazar Bondy, and Dennis Sullivan. Among my critics, Paul Goodman most radically obliged me to revise my thinking. Robert Silvers provided me with brilliant editorial assistance on Chapters 1, 3, and 6, which have appeared in The New York Review of Books.</p><p>
						
						
						Reimer and I have decided to publish separate views of our joint research. He is working on a comprehensive and documented exposition, which will be subjected to several months of further critical appraisal and be published late in 1971 by Doubleday &amp; Company. Dennis Sullivan, who acted as secretary at the meetings between Reimer and myself, is preparing a book for publication in the spring of 1972 which will place my argument in the context of current debate about public schooling in the United States. I offer this volume of essays now in the hope that it will provoke additional critical contributions to the sessions of a seminar on "Alternatives in Education" planned at CIDOC in Cuernavaca for 1972 and 1973.</p><p>
						
						
						I intend to discuss some perplexing issues which are raised once we embrace the hypothesis that society can be deschooled; to search for criteria which may help us distinguish institutions which merit development because they support learning in a deschooled milieu; and to clarify those personal goals which would foster the advent of an Age of Leisure (schole) as opposed to an economy dominated by service industries. </p><p>
						
						
						IVAN ILLICH</p><p>
						
						
						&nbsp;
						
						
						CIDOC</p><p>
						
						
						Cuernavaca, Mexico</p><p>
						
						
						November, 1970<br>
						<a name="1"></a>.</p><a href="#top"><span size="-1">index&nbsp;</span></a><span size="+1">1.  Why We Must Disestablish School</span><p>
						
						
						&nbsp;
						
						
						Many students, especially those who are poor, intuitively know what the schools do for them. They school them to confuse process and substance. Once these become blurred, a new logic is assumed: the more treatment there is, the better are the results; or, escalation leads to success. The pupil is thereby "schooled" to confuse teaching with learning, grade advancement with education, a diploma with competence, and fluency with the ability to say something new. His imagination is "schooled" to accept service in place of value. Medical treatment is mistaken for health care, social work for the improvement of community life, police protection for safety, military poise for national security, the rat race for productive work. Health, learning, dignity, independence, and creative endeavor are defined as little more than the performance of the institutions which claim to serve these ends, and their improvement is made to depend on allocating more resources to the management of hospitals, schools, and other agencies in question.</p><p>
						
						
						In these essays, I will show that the institutionalization of values leads inevitably to physical pollution, social polarization, and psychological impotence: three dimensions in a process of global degradation and modernized misery. I will explain how this process of degradation is accelerated when nonmaterial needs are transformed into demands for commodities; when health, education, personal mobility, welfare, or psychological healing are defined as the result of services or "treatments." I do this because I believe that most of the research now going on about the future tends to advocate further increases in the institutionalization of values and that we must define conditions which would permit precisely the contrary to happen. We need research on the possible use of technology to create institutions which serve personal, creative, and autonomous interaction and the emergence of values which cannot be substantially controlled by technocrats. We need counterfoil research to current futurology.</p><p>
						
						
						I want to raise the general question of the mutual definition of man's nature and the nature of modern institutions which characterizes our world view and language. To do so, I have chosen the school as my paradigm, and I therefore deal only indirectly with other bureaucratic agencies of the corporate state: the consumer-family, the party, the army, the church, the media. My analysis of the hidden curriculum of school should make it evident that public education would profit from the deschooling of society, just as family life, politics, security, faith, and communication would profit from an analogous process.</p><p>
						
						
						I begin my analysis, in this first essay, by trying to convey what the deschooling of a schooled society might mean. In this context, it should be easier to understand my choice of the five specific aspects relevant to this process with which I deal in the subsequent chapters.</p><p>
						
						
						Not only education but social reality itself has become schooled. It costs roughly the same to school both rich and poor in the same dependency. The yearly expenditure per pupil in the slums and in the rich suburbs of any one of twenty U.S. cities lies in the same range-and sometimes is favorable to the poor. Rich and poor alike depend on schools and hospitals which guide their lives, form their world view, and define for them what is legitimate and what is not. Both view doctoring oneself as irresponsible, learning on one's own as unreliable, and community organization, when not paid for by those in authority, as a form of aggression or subversion. For both groups the reliance on institutional treatment renders independent accomplishment suspect. The progressive underdevelopment of self- and community-reliance is even more typical in Westchester than it is in the northeast of Brazil. Everywhere not only education but society as a whole needs "deschooling."</p><p>
						
						
						Welfare bureaucracies claim a professional, political, and financial monopoly over the social imagination, setting standards of what is valuable and what is feasible. This monopoly is at the root of the modernization of poverty. Every simple need to which an institutional answer is found permits the invention of a new class of poor and a new definition of poverty. Ten years ago in Mexico it was the normal thing to be born and to die in one's own home and to be buried by one's friends. Only the soul's needs were taken care of by the institutional church. Now to begin andend life at home become signs either of poverty or of special privilege. Dying and death have come under the institutional management of doctors and undertakers.</p><p>
						
						
						Once basic needs have been translated by a society into demands for scientifically produced commodities, poverty is defined by standards which the technocrats can change at will. Poverty then refers to those who have fallen behind an advertised ideal of consumption in some important respect. In Mexico the poor are those who lack three years of schooling, and in New York they are those who lack twelve.</p><p>
						
						
						The poor have always been socially powerless. The increasing reliance on institutional care adds a new dimension to their helplessness: psychological …</p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidtinapple.com/illich/1970_deschooling.html">https://davidtinapple.com/illich/1970_deschooling.html</a></em></p>]]>
            </description>
            <link>https://davidtinapple.com/illich/1970_deschooling.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821855</guid>
            <pubDate>Mon, 13 Jul 2020 15:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Virgin YouTube vs. the Chad PeerTube]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23821616">thread link</a>) | @antepodius
<br/>
July 13, 2020 | https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3 | <a href="https://web.archive.org/web/*/https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821616</guid>
            <pubDate>Mon, 13 Jul 2020 15:15:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 rituals I followed to be a better programmer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821485">thread link</a>) | @arpitbbhayani
<br/>
July 13, 2020 | https://arpitbhayani.me/blogs/better-programmer | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/better-programmer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>"How to get better at programming?" is the question I had been asked quite a few times, and today I lay down the 8 rituals I have been following, and action items for each, to be good and get better at programming.</p>

<p>Doing something repeatedly always helps and writing a lot of code will develop our ability to</p>
<ul>
<li>write code while we think</li>
<li>think faster, think better</li>
<li>foresee requirement changes and possible logic extensions</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>One significant contribution to a project every two weeks</li>
<li>Solve at least two programming questions (from <a href="https://www.codechef.com/">Codechef</a>, <a href="https://www.spoj.com/">Spoj</a> or <a href="https://www.hackerrank.com/">HackerRank</a>) every week, till we solve at least 300 questions</li>
</ul>

<p>If we don't do something repeatedly, it becomes extremely hard to get good at it. Writing code consistently helps us</p>
<ul>
<li>define the programmatic and algorithmic flow quickly</li>
<li>build a habit of programming and thinking analytically</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>make one small contribution to anyone project every three days</li>
</ul>

<p>Solving programming questions is about developing logic but things become a little trickier when we build a complex system, as it requires us to take our programming skills to go up a notch. Some examples of complex systems are - a Library management system, a <a href="https://twitter.com/">Twitter</a> clone, an <a href="https://www.instagram.com/">Instagram</a> clone, etc. Building a complex system</p>
<ul>
<li>widens our tech stack</li>
<li>makes us keep our code flexible, extensible and reusable</li>
<li>helps us understand how to split our code into independent segments that work in harmony</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>build one complex system every 4 months</li>
</ul>

<p>After we spend some time writing programs and solving problems, things become monotonous and do not seem to challenge us anymore, so to spice things up a bit we should model something from the real world, like</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Projectile_motion">projectile motion</a></li>
<li><a href="https://en.wikipedia.org/wiki/Double_pendulum">double pendulum</a></li>
<li><a href="https://en.wikipedia.org/wiki/Numerical_model_of_the_Solar_System">solar system simulation</a></li>
</ul>
<p>There are lots of libraries and framework like <a href="https://p5js.org/">p5.js</a> that makes visual programming simple.</p>
<h3>Action Items</h3>
<ul>
<li>once every 6 months model a physical phenomenon</li>
</ul>

<p>It is not only writing code that improves our programming skills but it is reading some quality code written by expert programmers that make the difference. Reading code written by experts improve our programming vocabulary and by doing this we</p>
<ul>
<li>learn the best programming practices</li>
<li>discover the new programming paradigms</li>
<li>find ways to properly structure our code for extensibility</li>
</ul>
<p>The best way to start doing it is by picking up an open-source project and start skimming the code. It is okay to not understand it in the first go but it is important to skim it a few times and get acquainted. After a few skim, everything will fall in place, the code becomes familiar and we start to understand the flow and business logic.</p>
<h3>Action Items</h3>
<ul>
<li>pick an open-source project every 6 months and skim its code once every two months</li>
<li>pick a tiny open-source utility, from an experienced developer, every month and skim it</li>
</ul>

<p>There is always someone sitting on the other side of the globe, who knows a thing or two more than us. Look for them and collaborate on a project. The developer community is filled with super smart and super enthusiastic developers who love to share and collaborate. Use websites like <a href="https://dev.to/">Dev.to</a>, <a href="https://hashnode.com/">Hashnode</a> and <a href="https://twitter.com/">Twitter</a> to find and interact with like-minded people.</p>
<h3>Action Items</h3>
<ul>
<li>collaborate on a project once a year</li>
<li>be active on platforms like <a href="https://dev.to/">Dev.to</a>, <a href="https://hashnode.com/">Hashnode</a> and <a href="https://twitter.com/">Twitter</a></li>
</ul>

<p>A programming language is just a tool to express business logic. While learning a programming language we should try to understand the constructs and paradigms used - for example: <a href="https://en.wikipedia.org/wiki/Functional_programming">Functional programming</a>, <a href="https://en.wikipedia.org/wiki/Polymorphism_(computer_science)">Polymorphism</a>, <a href="https://en.wikipedia.org/wiki/Event-driven_programming">Event driven programming</a>, <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a>, etc. It is important to do so because we could pick constructs from one language and use it in another to solve our problem. For example: picking Functional programming (Callbacks) from Javascript and using it in Python to create generic action functions.</p>
<h3>Action Items</h3>
<ul>
<li>learn one design pattern every month and build a simulation around it</li>
<li>pick a language construct and implement it in some other language</li>
</ul>

<p>Writing code before putting in some thought is degraded the code more often than not. The code written like this lacks simplicity, reusability, and extensibility. Spending some time thinking about problem statement or task at hand and having a rough execution plan always helps.</p>
<h3>Action Items</h3>
<ul>
<li>always define the scope of implementation, create an execution plan and then code</li>
</ul>

<p>These rituals have helped me get better at programming with time and in parallel, I pick at max 3 and act on the action items. Programming is simple but being better than most is difficult. Doing it consistently makes one get better by the day.</p>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/better-programmer</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821485</guid>
            <pubDate>Mon, 13 Jul 2020 15:03:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Income/savings calculator for moving to Canada]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23821323">thread link</a>) | @senecaso
<br/>
July 13, 2020 | https://boomstick.games/northward/index.html | <a href="https://web.archive.org/web/*/https://boomstick.games/northward/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://boomstick.games/northward/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821323</guid>
            <pubDate>Mon, 13 Jul 2020 14:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling to Assembly from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23821305">thread link</a>) | @halst
<br/>
July 13, 2020 | https://keleshev.com/compiling-to-assembly-from-scratch | <a href="https://web.archive.org/web/*/https://keleshev.com/compiling-to-assembly-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        

<p><span id="home"><a title="Home" href="https://keleshev.com/">☰</a></span></p>



<!--



md5-79bfa919c595b8f7aa78f6d429bc2a15


-->

<center><img id="cover" src="https://keleshev.com/compiling-to-assembly-from-scratch.jpg" width="200" height="300"></center>

<center><p> <a href="https://transactions.sendowl.com/products/78310234/604B9EF1/purchase" rel="nofollow"> Pre-order •  <b>$27</b> </a></p></center>

<center><em>TypeScript — ARM  — August 2020</em></center>

<p><big><em>So, you’ve been trying to learn how compilers and programming languages work?</em> </big></p>

<p>Perhaps, you’ve learned about compiling to JavaScript,
or about building an interpreter? Or, maybe, about
compiling to bytecode? All good steps.</p>

<p><em>But there’s a tension building up.</em></p>

<p>Because it feels a bit like cheating.
Because you know that somewhere, somehow, the code you write
is translated to assembly instructions. To the machine language.
That’s where the rubber hits the road. That’s where it gets hot.
And, oh-so-many resources are hesitant to cover this part.
But not this book.</p>

<p>This ebook will show you in detail
how you can build a compiler from scratch
that goes all the way from <em>source</em> to <em>assembly</em>.</p>

<p>The example code is written in <strong>TypeScript</strong>, a dialect of <strong>JavaScript</strong>.
The book describes the design and implementation of a compiler that emits
32-bit <strong>ARM</strong> assembly instructions.</p>



<blockquote>
  <h2>Pre-order and get a draft!</h2>
  
  
  
  <p><strong><em>You get now:</em></strong></p>
  
  <ul>
  <li>Draft <em>(contains full Part I of the book)</em></li>
  <li>PDF-only</li>
  <li>DRM-free</li>
  <li>Source code <em>(link in the book)</em></li>
  <li>Discourse forum: book’s private community <em>(invite in the book)</em></li>
  </ul>
  
  <p><strong><em>You get later</em></strong> <em>(ETA–August 2020)<strong></strong></em><strong><em>:</em></strong></p>
  
  <ul>
  <li>Complete book</li>
  <li>All future revisions</li>
  <li>PDF, EPUB <em>(other formats on request)</em></li>
  <li>DRM-free</li>
  </ul>
  
  <p><em>Note, $27 is pre-order–only price with 40% discount. When the book is out it will be $45.</em>
  <br></p>
</blockquote>



<h2>Why ARM?</h2>

<p>In many ways, the ARM instruction set is what makes this book possible.</p>

<p>Compared to Intel x86-64, the ARM instruction set is a work of art.</p>

<p>Intel x86-64 is the result of evolution from an 8-bit processor,
to a 16-bit one, then to a 32-bit one, and finally to a 64-bit one.
At each step of the evolution, it accumulated complexity and cruft.
At each step, it tried to satisfy conflicting requirements.</p>

<ul>
<li>Intel x86-64 is based on <em>Complex Instruction Set Architecture</em> (CISC),
which was initially optimized for writing assembly by hand.</li>
<li>ARM, on the other hand, is based on <em>Reduced Instruction Set Architecture</em> (RISC),
which is optimized for writing compilers.</li>
</ul>

<p><em>Guess which one is an easier target for a compiler?</em></p>

<p>If this book targeted Intel x86-64 instead of ARM, it would have been two times as long
and — more likely — never written.
Also, with 160 <em>billion</em> devices shipped, we better get used to the fact
that ARM is the dominant instruction set architecture today.</p>

<p>In other words… ARM is a good start.
After learning it, you will be better equipped
for moving to x86-64 or the new ARM64.</p>

<p><em>Will you be able to run the code your compiler produces?</em></p>

<p>I bet you will! The Appendix will contain a bazillion ways
to execute ARM code, starting from Raspberry Pi,
cloud VM, to various ways to emulate ARM on Linux, Windows, and macOS.</p>

<h2>Why TypeScript?</h2>

<p>First of all, you will be able to follow this book in any reasonable programming language.
For me, it was tough to pick one for this job, and I’m pleased I’ve chosen TypeScript.</p>

<p>TypeScript is probably nobody’s favorite, but it’s a good compromise:</p>

<ul>
<li>Are you coming from a dynamic language like JavaScript, Python, or Ruby?
Then if you close your eyes at the
type annotations, TypeScript is just modern-day JavaScript.</li>
<li>If you’re coming from Java or C#, then you will feel right at home,
since TypeScript
is brought to you by the same people who brought you C# <em>(and Turbo Pascal!)</em>.</li>
</ul>

<p>Don’t worry if you’ve never seen TypeScript code before.
If you can read the following, you will most likely be able to pick it up,
as the book goes <em>(real code from the book here!)</em>:</p>

<pre><b>class </b>Label {
  <b>static </b>counter = 0;
  value: number; <em>// Type annotation
</em>
  <b>constructor</b>() {
    <b>this</b>.value = Label.counter++;
  }

  toString() {
    <b>return </b>'.L' + <b>this</b>.value;
  }
}
</pre>

<p>I avoided using any TypeScript- or JavaScript-specific
language features in the code.</p>

<p>If you’re into statically-typed functional programming
languages (Haskell, OCaml, or Reason ML),
you will find that the class structure I used
has a nice translation to an algebraic data type.
It is, in fact, how I wrote it first.</p>



<h2>Book Contents</h2>

<p>The book consists of two parts. Part I
presents a <em>detailed</em>, <em>step-by-step</em> guide on how
to develop a small “baseline” compiler that can compile simple
programs to ARM assembly.</p>

<p>By the end of Part I, you will have a working compiler that can
compile simple functions like this one:</p>

<!--table>
<tr>
<td>


md5-73395652867122248e3299aa94c98c61


</td>
<td>
</td>
</tr>
</table-->

<pre><b>function </b>factorial(n) {
  <b>if </b>(n == 0) {
    <b>return </b>1;
  } <b>else </b>{
    <b>return </b>n * factorial(n - 1);
  }
}
</pre>

<p>Into ARM assembly code like this:</p>

<pre>.global factorial
factorial:
  <b>push </b>{fp, lr}
  <b>mov </b>fp, sp
  <b>push </b>{r0, r1}
  <b>ldr </b>r0, =0
  <b>push </b>{r0, ip}
  <b>ldr </b>r0, [fp, #-8]
  <b>pop </b>{r1, ip}
  <b>cmp </b>r0, r1
  <b>moveq </b>r0, #1
  <b>movne </b>r0, #0
  <b>cmp </b>r0, #0
  <b>beq </b>.L1
  <b>ldr </b>r0, =1
  <b>b </b>.L2
.L1:
  <b>ldr </b>r0, =1
  <b>mov </b>r1, r0
  <b>ldr </b>r0, [fp, #-8]
  <b>sub </b>r0, r0, r1
  <b>bl </b>factorial
  <b>mov </b>r1, r0
  <b>ldr </b>r0, [fp, #-8]
  <b>mul </b>r0, r0, r1
.L2:
  <b>mov </b>sp, fp
  <b>pop </b>{fp, pc}
</pre>

<p>This code won’t win any awards, and an optimizing compiler
could do much better, but it’s a start!</p>

<p>Part II talks about <em>more advanced</em> topics in <em>less details</em>.
It explores several different (often mutually exclusive)
directions in which you can take your compiler.</p>

<center>⁂</center>

<center><a id="excerpt" href="https://keleshev.com/excerpt-compiling-to-assembly-from-scratch.pdf"><img id="excerpt" src="https://keleshev.com/book-preview.png" width="400" height="300"></a></center>

<center><a href="https://keleshev.com/excerpt-compiling-to-assembly-from-scratch.pdf"> Read Excerpt </a></center>

<center><img src="https://keleshev.com/keleshev.jpg" width="200" height="200"></center>

<h2>About me</h2>

<p>My name is Vladimir Keleshev,
I have worked with compilers both commercially
and in open-source.
My fondness of ARM assembly stems from
my previous work in embedded systems.
Currently, I work in finance
with domain-specific languages.
I’m <a href="https://twitter.com/keleshev">@keleshev</a> on Twitter.</p>



<blockquote>
  <h2>Be the first to know when the book is finalized!</h2>
  
  <center>Reading a draft is not your style? I get it. Subscribe to be notified when the book is finalized (and related news about the book and compilers).</center>
  
  <center><a href="https://sellfy.com/p/bkz0pv/" id="bkz0pv" data-text="Pre-order"></a></center>
  
  
  
  <center><small>You can unsubscribe at any time</small></center>
</blockquote>

<!--


md5-7ee03ea5643bff2df00890120280d45e



When I write blog posts I usually spent the first half
of the time writing the code and develoing the idea, and
the second half on the prose.
This book will be no exception.

At the moment I have finished writing
the code, and I am very happy with the results.
I expect the book to be ready early summer 2020, and a draft to
be available even sooner.

-->



<center><img src="https://keleshev.com/dragon.png" width="256" height="260"></center>

<center><em>Illustrations by <a href="https://twitter.com/PbKatiuska">@PbKatiuska</a></em></center>

    

</div>]]>
            </description>
            <link>https://keleshev.com/compiling-to-assembly-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821305</guid>
            <pubDate>Mon, 13 Jul 2020 14:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I made $11,673 in 5 days with an open-source project]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23821220">thread link</a>) | @samuelstancl
<br/>
July 13, 2020 | https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/ | <a href="https://web.archive.org/web/*/https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div v-pre="">
            <p>At the end of June, I launched a business-focused extension to my open-source project. <a href="https://tenancyforlaravel.com/saas-boilerplate/">The multi-tenant SaaS boilerplate for Laravel</a>.</p>

<p>The sales completely exceeded my expectations.</p>

<p>$4,980 within the first 24 hours and $11,673 within the first 5 days.</p>

<p>🤯</p>

<p>Here’s the story leading to this.</p>

<h2>Story of the project</h2>

<p>Exactly 2 years ago (June 2018), I was 16 and I decided to start building my first SaaS application. It was meant to be an e-commerce platform focused on B2B sales.</p>

<p>After working on the project for 9 months, I needed to implement <a href="https://www.indiehackers.com/post/what-is-multi-tenancy-why-you-might-need-it-8a0d64f161">multi-tenancy</a>. I looked at the existing solutions (Laravel packages) and they all felt extremely confusing and complex.</p>

<p>I decided to do the naive thing and write my own package. See, I wasn’t very experienced with Laravel at this point. I’ve only been using it since around July 2018. And this was at the beginning of 2019.</p>

<p>The main thing that I disliked about the existing solutions was that they pretty much required that you rebuild your entire application around their package.</p>

<p>That felt horrifying to me — again, I wasn’t a very experienced developer.</p>

<p>I felt like there should be a solution that just works with an existing application. The basic idea of multi-tenancy is letting customers have separate databases. Why would I have to rewrite my entire application for this? Why can’t I just tell the app to use database X after identifying the customer?</p>

<h3>Version 1</h3>

<p>I released v1 of the package in February. It was limited in features, but it fulfilled my needs. I didn’t have to rewrite my app anymore.</p>

<p>The package didn’t get much traction at this point.</p>

<p><img src="https://samuelstancl.me/assets/img/tenancy-stars-v1.png" alt="The star count for version 1"></p>

<p>On February 17, it got the first star on GitHub. 3 months later, it only had 60 stars.</p>

<p>And my SaaS wasn’t succeeding either. I decided to abandon the project basically immediately after I wrote the multi-tenancy package. I realized how bad the code was. The product market fit was there, but I didn’t want to work on this codebase anymore.</p>

<p>I started some other projects instead. They of course got abandoned too, after a few months. Such is the life of SaaS.</p>

<h3>Version 2</h3>

<p>In July, I decided to double down on the package. I started working on version 2. It added a lot more features and made it less proof-of-concept-y and more production ready. Fulfilled more business needs.</p>

<p>In August, I created a landing page for the project. I started <strong>treating it more as a product</strong>.</p>

<p><img src="https://i0.wp.com/wp.laravel-news.com/wp-content/uploads/2019/10/stancl-tenancy.jpg?fit=2220%2C1125&amp;ssl=1?resize=2200%2C1125" alt="The first landing page">
<small>The first landing page.</small></p>

<p>By the end of August, the project had some 216 stars.</p>

<p>I doubled down on the marketing side of things, got some articles written and by the end of October, the project was at 476 stars.</p>

<h3>Burnout</h3>

<p>At this point, I took a hiatus from the project. I was juggling multiple projects at once and was starting to get severely burnt out.</p>

<p>For the following two months, I got basically zero work done. On any projects. This was the darkest time for me, work and focus-wise.</p>

<p>There’s a positive side to it, though. Experiencing a strong burnout for a manageable period of time is good — if you analyze it well. Teaches you what <strong>not</strong> to do and how much it sucks to be burnt out. After an experience like that, you’ll focus very hard on not getting burnt out.</p>

<p><img src="https://builtwithtailwind.s3.amazonaws.com/237/conversions/tenancy.samuelstancl.me_-featured.jpg" alt="The second landing page">
<small>I finished this period of focusing on the package with a second, better-designed landing page.</small></p>

<h3>The lockdown</h3>

<p>The coronavirus pandemic was a blessing in disguise when it comes to side projects.</p>

<p>Instead of school, I got to stay at home.</p>

<p>In the past few months I didn’t do much work. So working now was actually refreshing!</p>

<p>The timing really couldn’t have been any better. School got closed first week of March. About 2 weeks after I could (and did) legally get my sole proprietor license.</p>

<p>I took on a bit of client work, started making a bit of $ from that, but mostly <strong>I again focused on the package</strong>.</p>

<p>There were some quirks I didn’t like about the architecture of the code. I also didn’t like that the package was making an impression of being too opinionated and not enterprise™ enough.</p>

<p>So I focused on fixing exactly that.</p>

<p>I contacted a person who was interested in me adding some more enterprise-y features back in October. I explained that I’m focusing on the package again and that I’d like to add a lot of things to it.</p>

<p>He was very glad to hear this. We talked for a while and he offered <strong>sponsoring me to add specific features to the open-source package</strong>:</p>

<blockquote>
  <p>Let me know if €5,000 is a good price for you.</p>
</blockquote>

<p>This was huge.</p>

<p>See, the project was released in February 2019. And there were <strong>no donations whatsoever</strong> until October.</p>

<p><img src="https://docs.google.com/spreadsheets/d/e/2PACX-1vSJCo55YgQmuVaJCuyfsKmSs23UIemGD3g198A5fvYhSQeMdzBI7NA7z9NEx0VwbNSEYdj_N4uZEsBx/pubchart?oid=1707722928&amp;format=image" alt="Donations between launch (February 2019 and March 2020)"></p>

<p>And even until March, the donations totaled $111.</p>

<p>5,000 EUR felt massive.</p>

<p>This was at the end of April.</p>

<p>I accepted the offer, expressed great gratitude and got to work.</p>

<p>I decided to focus <strong>FULLY</strong> on the package.</p>

<p>I was writing code and documentation all <strike>days</strike> nights long. Quarantine did its thing on my sleep schedule, but I was happy. Got a ton of work done.</p>

<p>Woke up at 16:00, went to bed at 8:00. Every day.</p>

<p>On May 13th (about 2-3 weeks after the donation) I announced a closed beta.</p>

<p>Why closed? Continue reading.</p>

<h3>Competition</h3>

<p>Like I said, there were other packages.</p>

<p>The project that made me create my own package also had a sister package. It was in development for seemingly forever.</p>

<p>However, in May, Spatie — a web development agency that’s very famous in the Laravel world for their open-source work — started writing their own multi-tenancy package.</p>

<p>This made the other project hurry development too. So in May, these packages were being released:</p>

<ul>
<li>My package’s version 3</li>
<li>Spatie’s new package</li>
<li>tenancy.dev’s new package</li>
</ul>

<p>This got stressful fast.</p>

<p>The Spatie package was built on the same principles as my package. Automatic, no changes needed. Except it was a lot simpler version.</p>

<p>That was no good!</p>

<p>Also remember when I said that I was trying to focus my package more on the enterprise-y needs, like flexibility? That’s what the tenancy.dev package is about, to a large degree.</p>

<p>Hence the closed beta. I ain’t showing no code to competition!</p>

<p><img src="https://samuelstancl.me/assets/img/tenancy-stars-comparison.svg" alt="Comparison of GitHub stars between the packages">
<small>The evolution of GitHub stars — <span>blue</span> is my package, <span>green</span> is the older competing package, <span>yellow</span> is Spatie's new package.</small></p>

<h3>The boilerplate</h3>

<p>With the beta done, it was time to focus on the commercial product.</p>

<p>The idea was this: Even though the package does all the heavy lifting for you, you still need to implement it. And many apps will implement it in the same way.</p>

<p>So there was a place for another project. A boilerplate with all the stuff you’d be writing anyway. This means customer (tenant) onboarding flow, billing logic, an admin panel, domain management, customer HTTPS certificate management etc.</p>

<p>And it also fit perfectly into my beta. I had a beta that I wanted users to test. I also wanted to build an app that would use the package. This would make me see all the missing parts, from the perspective of a <strong>user</strong> of the package.</p>

<p>This took about a month of half-work to build.</p>

<p>Why half-work? Motivation was slowly disappearing, the beta &amp; new marketing website was out, so competition was sort of taken care of. Also a bunch of personal stuff happening.</p>

<h2>The launch</h2>

<p>I was on a family vacation in Southern Europe. I originally wanted to finish all my work before going there, but you know how IT projects are.</p>

<p>I spent the first week doing fun stuff — working out, walking, reading, listening to audiobooks and podcasts.</p>

<p>But after a week of spending my time completely differently than I normally do, I decided to finish the work. So, I spent 3 days inside the apartment. There was no time to go outside, I <strong>had</strong> to finish this.</p>

<p>I was finishing the package’s features alongside the boilerplate.</p>

<p>The package was ready for release. And so was the boilerplate.</p>

<p>This was at <strong>3 AM in the morning</strong>. I was severely overworked and it was time to write an announcement.</p>

<p>I didn’t have enough energy to send an email, do a Twitter thread, make a launch discount or any of the other stuff. Nor did I have the confidence in my abilities to do it well at 3 AM.</p>

<p>But I was glad I managed to get the marketing site done! In some form anyway.</p>

<p>So I went with a <strong>safer approach</strong>. I announced the release on my Discord server. This way only a small portion of my users saw it and if anything was wrong, I’d manage to extinguish the fire before it got too big.</p>

<p>So I made an announcement and went to bed. I didn’t expect much. I actually <strong>don’t know</strong> what I expected.</p>

<p>But I can say that <strong>waking up to $600 in sales surprised me</strong>.</p>

<p>I woke up, went to the bathroom, and went straight to the computer. Inviting people who bought the project to the private community (no automated process — gotta do that MVP!). Improving the marketing page.</p>

<p>Then I got to scheduling a <a href="https://twitter.com/samuelstancl/status/1277920614670577672">Twitter thread</a> on Hypefury and writing a marketing email on Mailchimp.</p>

<p>Then both went out.</p>

<p>And the sales started coming in.</p>

<p>A lot of them.</p>

<p>A <strong>LOT</strong> of them.</p>

<p>My inbox quickly got filled with tens of emails with the subject line of:</p>

<blockquote>
  <p>New sale of Multi-tenant SaaS boilerplate for Laravel - Standard version</p>
</blockquote>

<p><img src="https://i.imgur.com/SaBSah1.png" alt="https://i.imgur.com/SaBSah1.png"></p>

<p>I was incredibly happy.</p>

<p>The first day concluded with a bit over $5000 in sales.</p>

<h2>The selling process</h2>

<p>The product was sold in two tiers. Standard and Enterprise.</p>

<p>The difference between the two versions was that the Enterprise version got priority support and could be used by companies with an annual revenue of $60k and higher. This is the same model <a href="http://nova.laravel.com/">Laravel Nova</a> uses.</p>

<p>I launched the product with <strong>two launch discounts</strong>.</p>

<p>A “generic” one, that I haven’t yet decided when it will end.</p>

<p>And a better one, that <strong>only lasted the first 48 hours</strong>.</p>

<p>The prices were:</p>

<ul>
<li>Standard: $299 -&gt; $199 (generic) -&gt; <strong>$149 (48 hour)</strong></li>
<li>Enterprise: $499 -&gt; $379 (generic) -&gt; <strong>$349 (48 hour)</strong></li>
</ul>

<p>I think given the sales, I hit the nail on the head with the pricing.</p>

<p>It was pretty affordable for solo projects, while also being high enough for the enterprise version.</p>

<p>My project is in this strange space where there are one-man indie hacker projects on one side of the income spectrum, and huge enterprises on the other side of the spectrum. Very little in between.</p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/">https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/</a></em></p>]]>
            </description>
            <link>https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821220</guid>
            <pubDate>Mon, 13 Jul 2020 14:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are not prisoners of groupthink]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23821180">thread link</a>) | @henriquez
<br/>
July 13, 2020 | https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html | <a href="https://web.archive.org/web/*/https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <h2>
            <a href="https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">
                We are not prisoners of groupthink.
            </a>
        </h2>
        <h3>How I stopped worrying about "cancel culture" with this one weird tip.</h3>
        
        <p><em>This is a response to the Gareth Roberts essay titled
<a href="https://unherd.com/2020/07/why-the-prisoner-is-more-accurate-than-orwell/">"We are all prisoners of groupthink".</a></em></p>
<p>A common theme on the Internet is selection bias. We seek out content and
interactions that fit our sensibilities, beliefs and emotional disposition.
Social networks have exploited this tendency, drawing us into
<a href="https://en.wikipedia.org/wiki/Filter_bubble">filter bubbles</a> where we are
algorithmically bombarded with content designed to maximize our "engagement"
with no regard to damage done in terms of our psychological well-being or
intellectual isolation. This makes us better consumers, but reinforces
divisions between individuals and poisons any possibility of meaningful
discourse, instead favoring shit-flinging competitions between so-called
<a href="https://twitter.com/realdonaldtrump/status/1261126114799468549?lang=en">"keyboard warriors."</a>
This is well-documented, the social media companies are aware of it,
and they don't care because <a href="https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499">division makes money.</a></p>
<p>Our filter bubbles are designed to comfort and placate us while we're force-fed
promoted content and offers and idealized imagery. Our collective ability
to think critically has been siphoned away; anything that remotely challenges
our beliefs is seen as a threat or an attack. Over time this has lead to the
ridiculous notion that "words are violence," and from this, the rise of
<a href="https://en.wikipedia.org/wiki/Online_shaming#Call-outs_and_cancellation">cancel culture</a>,
the First World pastime of mobbing, doxing, and socially destroying
anyone who dares to voice an unpopular opinion or do something stupid. This cancel
culture was born of social media. Sure, some might blame other factors like liberal
arts education but really they're nothing new to society. But I'll tell you what changed.</p>

        
            
<p>Back in the good old days (when you didn't need 32gb of
memory to browse the web), Twitter and Facebook used to display a chronological
feed of your friends' posts. This was very functional, but ended up creating a problem
for the social media companies: in order to maximize the amount of time you spend on
their sites they needed you to friend/follow tons of people (even people you aren't really
friends with). But if you did that, your feed would turn into a shitshow, with too
much content for any person keep up with. So Facebook and Twitter went back to the
drawing board and came up with a fantastic innovation: the algorithmic content feed
(aka. the death of society and end of the Internet). The feed algorithm could "get
into your head" with <a href="https://en.wikipedia.org/wiki/Psychographics">psychographic microtargeting</a>,
allowing the machine to recommend content and advertisements that <em>you</em> are likely to
"engage" with—click, like, share,
anything to keep you on the site and viewing more ads a little longer.</p>
<p>The deprecation of the chronological timeline in favor of the
machine-curated content feed had major psychological side effects for everyone involved.
When the machine decided what content to recommend it would favor content that is most
likely to create engagement; this trends toward content that creates an emotional
response, which on the Internet is most often outrageous content that evokes fear or
anger. By bombarding people with upsetting shit and exposing them to "communities" of other
people <a href="https://knowyourmeme.com/memes/circle-jerk">circlejerking</a> about how upsetting
everything is, the machine dialed the filter
bubble effect up to 11, essentially dividing people into groups and then radicalizing
them with increasingly extremist content. And in the process,
<strong>Facebook and Twitter radicalized the actual publishers of content.</strong></p>
<p>Remember when you could pick up a newspaper or turn on
your television and get news coverage that seemed at least superficially factual
and unbiased? Obviously those days are gone. Newspapers are mostly out of business,
TV viewership is down, and the dying husk of our mainstream media is increasingly
obsessed with a contrived "culture war." Traditional media has been superceded by
the Internet, and with social media dominating peoples' time spent on
the Internet, Facebook and Twitter have become gatekeepers between the
publishers and their viewers. Factual and unbiased reporting is simply not engaging
enough and will not appear on peoples' feeds. Only breathless hyperbolic
fear-mongering and rage porn will break through the algorithm and get clicks.
Mainstream publishers have been forced to shift their entire media strategies
around <em>online engagement</em> as they desperately attempt to stay relevant on the Internet.
And what's more engaging than a controversy? Thus,
mainstream publishers have "picked sides" that resonate with their
audiences'
filter bubbles in the artifical culture war, promoting non-newsworthy events
into manufactured controversies, and sparking mob action with headlines like
<a href="https://www.cnn.com/2020/07/11/us/goya-foods-unanue-trump-hispanic-market/index.html">"Here's why [food CEO's] meeting with [world leader] is prObLeMaTiC."</a></p>
<p>And that brings us to recent months, where
after locking every person of fighting age in closet-sized apartments, where peoples' only
access to the outside world was filtered through the toxic lens of social media, and
where the only information available was underpinned by fear and outrage, people
lost their shit. And now we're collectively hand-wringing about cancel culture (but
being real careful not to upset the mob.)</p>
<p>But here's the thing: cancel culture is irrelevant if you don't give a fuck.
You are not a prisoner of groupthink. You might be a prisoner of your belief
that you should give a fuck. But that is under your control. We are not living
a George Orwell hellscape, memes like
<em>"<a href="https://en.wikipedia.org/wiki/Nineteen_Eighty-Four">1984</a> was a warning, not
an instruction manual"</em> fall flat. The premise that we should care what a bunch
of larpy wannabe do-gooders think on Twitter and Facebook is false.
It doesn't matter—you can't lose a game you don't play. Cancel culture was born
of social media. <strong>If we cancel Facebook and Twitter</strong>, we can break the cycle of
extreme division and hyperbolic microtargeting, shatter the filter bubbles,
and reclaim our access to information from monopolistic ad targeting algorithms.
By divorcing our attention from these toxic echo chambers, manufactured controversies
will become less profitable,
people will be able to think more critically and talk to each other more sincerely,
and cancel culture will end organically. There are really no major drawbacks.</p>
<p>So much of our time online is <em>wasted</em> creating, curating, and "defending"
these perfectly plastic personas, avatars, idealized identities that represent
some vague notion of a persistent sense of self on the Internet. And for what?
Do you really talk to your 600 Facebook friends? Do you even give a shit about
who your 10,000 Instagram followers are? Do they give a shit about you? No.
People waste so much of their lives trying to stake out an online identity that
they start to believe it actually matters, <em>but it doesn't.</em>
<strong>A persistent online identity is a liability, not an asset.</strong></p>
<p>We are all tempted by the lie that social networks base their existence on:
that we need to put our "selves" online for all to see. This lie is a mental hack,
exploiting our human need for meaningful interactions with other people,
as well as the dark aspects of human nature: ego, anger and trauma. As society
increasingly isolates and divides humans from one another physically and
socially, we are tempted by the lie that our online personas form a meaningful
extension of our real-world selves.</p>
<p>Sadly, the vast majority of our interactions on social media are hollow, and the
few glimmers of meaningful connections with others that <em>do</em> occur
instill a Pavlovian-style hope, an addictive draw to keep us infinitely scrolling
through our algorithmically-curated content feeds in the vain hope that the
machine will bring meaning to the emptiness of our lives. But social media is little more
than mental masturbation. The service is free but the price we pay is dear.</p>
<p>When you put your real self online, you open yourself up to attack.
Like a federal indictment, the mob can come for anyone at any time. Whether or
not you are a good person is irrelevant, and trying to craft your online persona
to appease the mob is a loser's game. As the filter bubbles increasingly divide-and-circlejerk
people into more extreme viewpoints, what passes for acceptable
behavior today could be heresy tomorrow. And when your name, your employer, and
your family are all connected to your social media presence, you put yourself in
real world danger for very little real world benefit.</p>
<p>So what can you do? <strong>Cancel yourself.</strong> Delete your social media presence.
Sever the link between your online self and your real-world self. Seriously.
<em>You can't lose a game you don't play.</em></p>
<p>But wait, <em>isn't this extreme?</em> Maybe it is, or maybe you're just addicted to
social media. I've talked to a lot of people about this and heard some common
excuses people use to rationalize addictive behavior to themselves.</p>
<ul>
<li><strong>"But social media is an important part of my professional network."</strong></li>
</ul>
<p>I can only speak anecdotally. I've built a successful career without using LinkedIn
or other social networks to promote myself. My work ethic, skill and reputation have
carried me
as far as I care to go in my field. Also anecdotally, when I hired a contractor
to remodel my basement, I didn't check her Facebook page; I saw her work at a
neighbor's house and asked them to put me in touch. She did a great job on
my basement (and later posted photos of it to her Instagram). Good work
promotes itself.</p>
<p>But what doesn't work is when the line between personal and professional gets
blurred, which is almost inevitable on a medium designed around social
interaction. The tension between <em>being a professional</em> and <em>having an opinion</em> is
overwhelming for some people. The person who lists in their Twitter bio that
they "work for Google" and "bash the fash" isn't doing themself or their employer
any favors. Such tact only works for those who stay in the good graces of the mob,
which is, again, a loser's game.</p>
<ul>
<li><strong>"But I use social media to keep in touch with my school friends."</strong></li>
</ul>
<p>No you …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html</a></em></p>]]>
            </description>
            <link>https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821180</guid>
            <pubDate>Mon, 13 Jul 2020 14:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Be More Unlikeable]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 70 (<a href="https://news.ycombinator.com/item?id=23821121">thread link</a>) | @elijahmurray
<br/>
July 13, 2020 | https://www.gritlist.co/be-unlikeable/ | <a href="https://web.archive.org/web/*/https://www.gritlist.co/be-unlikeable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            


                <section>
                    <div>
                        <blockquote>"The reasonable man adapts himself to the world; the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man." - George Bernard Shaw</blockquote><p>I grew up in a family where I was taught to be likable. To please, to impress, and to make others happy. Seems like a pretty good idea, right?</p><p>While likeability is a good trait if you want to be popular it isn't ideal if you want to achieve. Let me explain.</p><p>Popularity feels good. Being liked feels good. Humans evolved as social creatures and we crave attention from each other. This pattern plays out over and over in schoolyards, bars, and workplaces, or anywhere humans meet. And the cooperation needed for our survival can only happen if you're accepted by your tribe.</p><p>However, praise by the masses won't make you successful, let alone fulfilled. Actually it's more likely that <em>popularity will prevent you from being successful.</em></p><p>Movie stars, professional athletes, and a business visionaries–we all want to be them. We grow up trying to be them. Personally, I've long idolized Steve Jobs and Elon Musk. But most of our heroes got to where they are by being unlikeable, not likable.</p><p>We love these men and women for being unique yet we internally berate ourselves for being different. These heroes have been described as annoying, difficult, stubborn, and unreasonable. Not exactly what we strive to read about ourselves in peer reviews. Sure, they have some popularity, but it's not all rainbows. Was Gandhi liked? Yes, but he also had millions of people who were against him, and ultimately murdered him. So if it's the oddballs that we look up to, why do we try to be so likable?</p><p>This aversion to difference starts early. Bullies throughout life pick on the kid who is different, on the easy target. Additionally modern culture has decided that the best path in life is to do as you're told; follow the rules, stay in line, and smile. Follow the leader and be a good girl/boy. The scripture of conformity is pervasive.</p><p>And there is true merit to fitting in. Society can't exist without collectively agreed upon rules. Early on we learn that being a three year old hellion is unacceptable has consequences. If I spit out my Cheerios one more time mom will be angry mom, so I'm going to be nice.</p><p>So we're taught to fit in. Be likable and hide your "flaws". Like the only white fish in a school of black fish you don't want to be the different one when a shark is on the prowl. Blend in and don't stand out. Seek group acceptance.</p><p>While conformity has its place in keeping society running, too much conformity stunts progress.</p><p>Differences are what make you, you and me, me. They're what make change possible. Change comes from differences, not from more of the same. After all, a species evolves based on small aberrations, on "flaws", that turn into strengths and a better way of being.</p><p>All progress comes from those who see the world differently. First they act differently and then they convince others to see differently as well. They don't accept the status quo and they don't assimilate.</p><p>Generally speaking this results in being unpopular. Many of the people who helped change the world aren't liked even in the height of their success. But they kept pushing their indomitable will against the world, and eventually, the world shifted ever so slightly.</p><p>Practice being unreasonable this week. Don't "yes" your way through life, following someone else's path for you. Be a bit more of a jerk. Be more demanding. Piss a few people off.</p><p>And be okay with it. Be okay with people being angry or mad or annoyed with you. Cultivate your ability to keep pushing towards your goals despite what others say.</p><p>And who knows, maybe you'll see the world shift ever so slightly.</p>
                    </div>
                </section>



        </article></div>]]>
            </description>
            <link>https://www.gritlist.co/be-unlikeable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821121</guid>
            <pubDate>Mon, 13 Jul 2020 14:28:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A/B capital for cloud infrastructure and enterprise software]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821049">thread link</a>) | @ekhornung
<br/>
July 13, 2020 | https://upside.fm/saurabh-sharma-jump-capital/ | <a href="https://web.archive.org/web/*/https://upside.fm/saurabh-sharma-jump-capital/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="target-id5f0f381873a36"><p>Saurabh Sharma 0:00<br> All of us come from all varying backgrounds. And I would say that DNA kind of flows in somewhat automatically. You want to roll up your sleeves even to help the companies to the extent they need, right. We’re not enforcing this. And I would say that combined with I would say, yeah, to some extent, and midwest primarily them in building these businesses. I do think that differentiates.</p><p>Jay Clouse 0:20<br> The startup investment landscape is changing. and world class companies are being built outside of Silicon Valley. We find them, talk with them and discuss the upside of investing in them. Welcome to Upside.</p><p>Hello, hello. Hello, and welcome back to the upside podcast, the first podcast finding upside outside of Silicon Valley. I’m Jay Clouse, and I’m accompanied by my co host, mister money mustache himself Eric Hornung.</p><p>Eric Hornung 1:00<br> Unfortunately, Jay, maybe you can’t see it through this pop filter, but the mustache is no longer.</p><p>Jay Clouse 1:06<br> It’s a little stubbly.</p><p>Eric Hornung 1:08<br> Yeah, it’s a little stubbly it’s, it’s my, it’ll be my first full shave. Since I got rid of the mustache. I did the first two months of quarantine with the beard and the mustache. I was doing my best Jay Clouse. And then I said, You know what, I’m just not a beard guy. It’s not. It’s itchy. It’s, um, I think I’ve described it previously on the podcast as pube.</p><p>Jay Clouse 1:32<br> And I cringe every time you say the word pube on the podcast.</p><p>Eric Hornung 1:34<br> Yeah, it’s I’ve probably said it too many times on the podcast, I would say, yeah, once you get rid of once you get rid of the beard, and you’re looking yourself in the mirror and you say, Can I pull this off? If I walk out of this bathroom? Will my fiance kill me? And you just go for it. It’s a magical moment. Jay. When there’s a there’s a shriek and then an acceptance of this is who I am now. I’m a moustache guy.</p><p>Jay Clouse 1:59<br> You sent me the photo and I was like, Oh, I’m so glad that you shaved it in this order and took the time to get a photo of this before it’s gone. And then it stuck around six weeks.</p><p>Eric Hornung 2:09<br> Yeah.</p><p>Jay Clouse 2:10<br> Was it really there for six weeks?</p><p>Eric Hornung 2:11<br> It might have been five weeks but yeah, something like that.</p><p>Jay Clouse 2:13<br> Wow. And and Colleen was okay with it.</p><p>Eric Hornung 2:17<br> I think she liked it better than the beard.</p><p>Jay Clouse 2:20<br> Wow.</p><p>Eric Hornung 2:21<br> Yeah. So it was a nice mustache. I won’t lie we got trimmed it up. I gave it a little bit of love. It’s just you know it the mustache life is tough, Jay because you drink a little bit of milk. Yeah, mustache in your milk, milk in your mustache. Whatever is it.</p><p>Jay Clouse 2:34<br> I actually don’t experience many of the mustache pains myself because my mustache is the weakest part of my beard.</p><p>Eric Hornung 2:39<br> Hmm.</p><p>Jay Clouse 2:40<br> So yeah, I go on enumerate on the number of moose mustache problems.</p><p>Eric Hornung 2:45<br> Yeah, yeah, very eating a hot wing with a mustache. You got hot wing for the next four hours because it’s not leaving your mustache. Anyway, yeah. So the mustache the whole That whole that whole phases is behind me, Jay, but it lives on in memoriam.</p><p>Jay Clouse 3:05<br> Well, I’m glad that you made the jump into not only trying the beard but trying a mustache. And speaking of jump, today we are talking with Saurabh Sharma. He is a partner at Jump Capital, a thesis led sector focused and operating centric venture capital firm specializing in series A and B in growth stage investments, Jump Capital invest in data driven technology companies within the FinTech, B2B SaaS, IT data infrastructure and media sectors. They’re based in both Chicago and New York. Eric, how do we find them capital,</p><p>Eric Hornung 3:43<br> I got connected with Jump Capital, indirectly, I think two years ago, maybe it was via Twitter or via an email or something. And so I don’t exactly remember how it happened. But I’ve been in contact via email with a few of the partners there just because I really like the way that they are structured and set up and what they focus on. And they’re very explicit about what they do, which I find to be refreshing in the venture capital space. And we wanted to have a conversation with them. And you know, we got to have one today.</p><p>Jay Clouse 4:13<br> Jump Capital has invested in a previous Pod Co Balto, they’ve invested in Personal Capital, just to name a couple of companies that you’ve heard of also Lisnr in Cincinnati. He talked about them being explicit and what they actually invest in. They also say on their website that they invest $1 to $10 million in their first investment, when companies have a $1 to $5 million revenue run rate. And typically, less than $10 million of investment so far today, so yeah, very explicit on their website in terms of industry, what types of companies are looking for, even at what stage? You know, the investment, the investment terms are?</p><p>Eric Hornung 4:51<br> Yeah, they have a operating partner model which is much more like private equity than it is a lot of the venture capital firms. We talked to the platform model almost. So when you’re very specific about the types of companies that you’re going to invest in, I think that operating model becomes stronger because you can get the best people to do the specific thing that needs to be done in these four focus areas in that very specific space where its product market fit has been met and it is growth time.</p><p>Jay Clouse 5:21<br> All right. Well, we’d love to hear your thoughts on this episode with Saurabh as we go through, you can tweet at us @UpsideFM or email us Hello@upside.FM. And we’ll get into that interview right after this. This episode of upside is sponsored by Tresta. Tresta is an app for iPhone and Android that lets you do business calling and texting from anywhere with no hardware. Just a smartphone you’re already using. Tresta is the best business phone app on the market. Whether you’re a founder or freelancer, just starting your business or you’re already established. Growing your network and your business is all about communication. You’ve got to be available no matter where you are. Tresta offers the call management features that empower you to communicate smarter and more efficiently, like auto attendance, call recording, user groups and more. And you don’t need any special equipment, just the smartphone you’re already using. Tresta is easy to configure. So you can set everything up yourself all online. Tresta’s virtual phone system makes it easier and more affordable than ever to set up a fully functioning mobile office. It’s just $15 per user per month with no contract. So start your free 30 day trial today at www.tresta.com/upside. That’s www.tresta.com/upside. Saurabh welcome to the show.</p><p>Saurabh Sharma 6:08<br> Thank you folks. Great to be here.</p><p>Eric Hornung 6:47<br> Let’s take it on a rocket ship. How did you get to Jump Capital.</p><p>Saurabh Sharma 6:51<br> Yeah, I mean it’s a kind of an unconventional path. I don’t think I was looking misery your venture capitalist. From a career perspective. I think it’s a three organic way down. Journey has been a little bit all over the place, which I think bodes well to venture frankly, just kind of amalgamation of a bunch of things. But you know, I’m fundamentally I’m an engineer by training and science, grew up in India in engineering there, got a scholarship to Apollo undergrad in France. Finish that became a computer science researcher in France, in the National Research Labs, got an opportunity to come to my masters and possibly a PhD at Cornell, where they’re in just kind of got brainwashed of Academia, by Wall Street, being brothers and all the banks that just go to campus and hire quantum computer science guys, so I just finished my Master’s in Cornell, join Lehman Quanta Algo trading desk was there, you know, the hay days and just perfect time as they’re even open to await the peak of Lehman. And so you know, phenomenal times, obviously, ranging from fairly very large scale architectures for competition trading in New York, London, and some phenomenal desks in the Ritz trading. Bring meeting go face. Solid tobacco was there almost to the end not exactly to the end I had an opportunity to apply for business schools which I had been pushing off and I thought really good time. After 07, there are some signs they might be weaker and then I got my admit I got took some time off and moved to India back to this small snippet of equity for business school, but I didn’t know it was gonna go up. It kind of blew up premier the first week I started my business school in Chicago booths. So the next year was kind of experimenting, starting my own company a bunch of my friends. And then you know, I’m preparing to started doing them for them and post that went back to Wall Street a little bit works on capitals with Bob Lehman at the time realized probably wasn’t for me back Michael was the chief quite a bit to join early stage uncle life Bank of Chicago Southern by April kowski Radke local mountain nurse in the region funded that a startup that I was involved in earlier. And then it allowed us to spend some time with light bank, Eric ended up being the Groupon CEO asked me to come along during some times to kind of turn around the story. And so another kind of run at pretty phenomenal setup of interesting projects of turning around the business. I was involved in an internal data science team run mobile relevant strategy, and then Mary Barra fashion conference in New York. So running operations and marketing for that, for that business in an intersection folks a jump and it was kind of good amalgamation a jump, as we will talk about more it has some relevance to so creating groups, very computational focus. So that can all put it together. You know, I’m actually in background I’ve been venture, I’ve been in tech and to join the joint jump for about four and a half years ago. So again, somewhat unconventional but but took me multiple paths. But I think all that is super …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://upside.fm/saurabh-sharma-jump-capital/">https://upside.fm/saurabh-sharma-jump-capital/</a></em></p>]]>
            </description>
            <link>https://upside.fm/saurabh-sharma-jump-capital/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821049</guid>
            <pubDate>Mon, 13 Jul 2020 14:21:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking the Myth of 10% Brain Usage]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23821046">thread link</a>) | @iuliangulea
<br/>
July 13, 2020 | https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>The human brain is a marvel of biological engineering. It allowed us to accumulate and pass on the knowledge of many prior generations throughout millennia, resulting in a civilization that went into space, taught computers to see and speak, and that continually discovers and investigates the laws of the Universe.</p>
<p>Its complexity is astounding, and we do not fully understand it yet. And because of that, occasionally, myths about the functioning of the brain pop out. Among the most prominent such legends is the one that claims we are dormant geniuses. But before analyzing and debunking that, let’s discuss some brain facts.</p>
<h2 id="size-does-not-matter">Size Does Not Matter</h2>
<p>For instance, did you know that the brain weighs around 1300-1400 grams? It represents only 2% of the total body weight of a 150 pound or 70kg human. However, it requires:</p>
<ul>
<li>15% of total cardiac output (the blood that flows in our body);</li>
<li>20% of total body oxygen;</li>
<li>25% of total body glucose utilization</li>
</ul>
<p><img src="https://iuliangulea.com/images/brain-energy-consumption.png" alt="Human brain weight vs. energy consumption"></p>
<p>That is quite an energy-hungry organ inside our skull! But even that fades away when comparing to children: at around five years old, the human brain takes up as much as 50% of oxygen consumption<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>Surprisingly, the brain’s level of oxygen consumption does not significantly vary when you are resting vs. when you do some cognitively intense work. Overall, measures of the whole brain changes in blood flow during intense mental activity have failed to demonstrate any change. Even <em>local changes</em> in blood flow of the regions involved most in a cognitive task are often 5% or less.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>Conversely, it is well known and demonstrated that glucose is the brain’s “fuel,” therefore increases in blood glucose levels can positively impact cognitive performance in some tasks.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<h2 id="the-mystical-brain-myth">The Mystical Brain Myth</h2>
<p>There is a popular myth that we use our brains at only 10% of its capacity, thus boldly affirming that we have a whopping 90% of dormant potential that we can awaken and become geniuses.</p>
<p>Unlike other widespread myths that started from a single event, or unscientific claims from poorly designed research studies (e.g., <a href="https://en.wikipedia.org/wiki/Andrew_Wakefield">Andrew Wakefield</a> and his fraudulent study than falsely claimed a link between vaccines and autism), the myth that humans use only 10% of their brains started at the end of the nineteenth century and was gradually strengthened by many people since then. The <a href="https://en.wikipedia.org/wiki/Ten_percent_of_the_brain_myth#Origin">Wikipedia</a> article on the subject has a lengthy explanation of the potential origin and evolution of the myth throughout the years.</p>
<h3 id="a-small-confession">A Small Confession</h3>
<p>Before moving on, I have a revelation to make. Occasionally, I might buy a cloth item and wear it once or twice. If I recall correctly, there might have been one or two items in my experience that I have not worn at all. Do you know anyone with similar oddities?</p>
<p>This makes my wardrobe much like the brain described in the myth: I am using around 10% of it, and I can “tap into” the rest of my wardrobe should such need arise.</p>
<h3 id="your-brain-is-not-a-wardrobe">Your Brain Is Not A Wardrobe</h3>
<p>But our brain is not a collection of cloth items. Though there are still unanswered questions regarding some brain functions, brain mapping physiology demonstrates that all its areas have a purpose. And you do not have to be a neuroscientist to prove that, simply recall from your anatomy classes that the brain has different regions, such as the frontal lobe, occipital lobe, cerebellum, and the fact that each of those lobes has its role.</p>
<h2 id="debunking-the-myth">Debunking The Myth</h2>
<p>Let’s address that myth in a more scientific manner.</p>
<p>If we are using only 10% of our brains, that means a person would be fine if the other 90% of the brain got removed. 10% of the 1400g average brain is 140g—that’s the size of a sheep’s brain.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Since I doubt sheep have their own 90% hidden potential myth, it makes no sense that humans have advanced so far as a civilization by using only part of their brains equivalent in size to a sheep’s brain.</p>
<p>There are instances in history when people were injured and got parts of their brain removed (although not as close as even 10%), the most prominent (and among the first recorded ones) being the case of <a href="https://en.wikipedia.org/wiki/Phineas_Gage">Phineas Gage</a>, who survived an accident where a large iron rod was driven through his left part of the head, from the bottom of the cheek, through his left eye and frontal lobe all the way to the top of his head. He lived 12 years more after that accident. There are varying opinions on his recovery, but it took him ~10 years to recover from the unfortunate event.</p>
<p>Another example is the case of <a href="https://en.wikipedia.org/wiki/Lev_Zasetsky">Lev Zasetsky</a>. A bullet entered his left parieto-occipital area and resulted in a long coma. Following this, he became unable to perceive the right side of things. Objects he did see often appeared as fragmented pieces rather than whole objects. He did not recover in the 50 years he lived after the injury.</p>
<p>As mentioned in <a href="https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">How People Learn—The Brain Basics</a>, our brains can rewire through a process called <em>neuroplasticity,</em> which can help regain some of the lost functions as a result of an accident. Unfortunately, that is not always the case. Researchers have found that only 27% of people recover from a <em><strong>concussion.</strong></em><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> That means almost 3 out of 4 people do not fully recover! And this is “just” a concussion—your brain does not lose any of its parts.</p>
<p>If 90% of the brain were unnecessary, it is highly unlikely that we would not have evolved such big brains with irrelevant matter in the first place. There are several factors for that:</p>
<ul>
<li>Historical risk of childbirth deaths due to the big skull size would stress out the selection of offspring with smaller brain sizes.</li>
<li>Natural selection favors characteristics that offer an advantage of some sort over the other. There is no way such a big brain would have formed in the first place if it wouldn’t be necessary for survival.</li>
<li>As already mentioned, the brain requires an enormous amount of energy. Even if we had 90% of the brain unused and suddenly were to “wake” it, we couldn’t provide our brains with enough power, as it already consumes 20%-25% of the entire body resources.</li>
</ul>
<p>All this scientific evidence works against this myth. We indeed use only some areas of the brain at any given time, but throughout the day, we use all of it, not just 10%. And next time you hear about this myth, recall the sheep brain weight.</p>
<hr>
<p>If you liked this article, feel free to subscribe below to be among the first to receive future updates and follow me on twitter (<a href="https://twitter.com/iuliangulea">@iuliangulea</a>) as well.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Kennedy C, Sokoloff L. <a href="https://pubmed.ncbi.nlm.nih.gov/13449166/">An adaptation of the nitrous oxide method to the study of the cerebral circulation in children; normal values for cerebral blood flow and cerebral metabolic rate in childhood.</a> J. Clin. Invest. 1957;36:1130–1137. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>The Effect Of Mental Arithmetic On Cerebral Circulation And Metabolism by Sokoloff L., Mangold, R., Wechsler, R., Kennedy, C. &amp; Kety, S. S. (1955) <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Rachael T. Donohoe, David Benton—<a href="https://www.researchgate.net/profile/David_Benton/publication/12840251_Cognitive_functioning_is_susceptible_to_the_level_of_blood_glucose/links/5489df990cf225bf669c75e5.pdf">Cognitive functioning is susceptible to the level of blood glucose</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Differences Between Human And Sheep Brains—<a href="https://animals.mom.com/differences-between-human-and-sheep-brains-3500869.html">animals.mom.com</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://www.braininjuryaustralia.org.au/research-recovery-concussion/">How Many Make A Full Recovery From A Concussion?</a>—BrainInjuryAustralia.org.au <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    
    
        
    

</div></div>]]>
            </description>
            <link>https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821046</guid>
            <pubDate>Mon, 13 Jul 2020 14:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a DIY Pen Plotter: MidTbot]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820926">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Earlier this year, I built a DIY pen plotter (mostly) from scratch. I'd been
meaning to post a build log, because this was one of the more enjoyable hardware
projects I've worked on recently. However, it's taken a while to write-up this
project because, well,
<a href="https://benjamincongdon.me/blog/2020/03/24/March-Updates/">there was a lot of stuff going on</a>.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter_hu26049e58bcb0e8f71afc8b124b2c5223_266932_0x400_resize_q75_box.jpg" alt="Completed Plotter with Ruler for Scale"> </a><figcaption>
        <p>Completed Plotter with Ruler for Scale</p>
    </figcaption>
    </figure>

<h2 id="why-build-a-plotter">Why Build a Plotter?</h2>
<p>So, why is it worth building a pen plotter? The short answer is, “they're cool”.
The longer answer is that, despite commercial printers (ink jet, laser, etc.)
working better for general purpose printing, the quality of a pen-plotted image
is noticeably different than something that's been traditionally printed.
Plotted images can have a more natural, organic feeling to them, because they're
produced by raising and lowering a pen manually, like a human does.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>I've also had a persistent curiosity with
<a href="https://benjamincongdon.me/blog/2019/03/07/Generative-Doodling/">generative art</a>. Much of the community
built around generative art (colloquially,
<a href="https://twitter.com/hashtag/plottertwitter">#plottertwitter</a>) uses pen plotters
to turn “bits into atoms”. While most folks opt to buy a commercial plotter like
the <a href="https://axidraw.com/">Axidraw</a> or restore vintage plotters from the 1980's,
there's a growing community of people building their own plotters.</p>
<h2 id="assembling-the-components">Assembling the Components</h2>
<p>The first step in the project was collecting the bill of materials (BOM).
There's a well-researched BOM on the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/Docs/mechanical_BOM.md">project Github</a>.
Other than the midTbot PCB, which is for sale
<a href="https://www.tindie.com/products/33366583/midtbot-esp32-v2-controller-kit/">on Tindie</a>,
I had to order:</p>
<ul>
<li>Linear shafts and Linear Bearings (Amazon)</li>
<li>Pulleys and Idler Pulleys (Amazon)</li>
<li>Rubber Timing Belt (Amazon)</li>
<li>2 Stepper Motors (Amazon)</li>
<li>Stepper Motor Controllers (Amazon)</li>
<li>12V 3A Power Supply (Already had one)</li>
<li>Basic Hobby Servo Motor (Already had one from previous Arduino projects)</li>
<li>Assorted M3/M5 Head Screws (Home Depot, Ali Express)</li>
</ul>
<p>I was pleasantly surprised how available most of the parts were online –
everything except for the screws/nuts were available on Amazon.</p>
<p>Once I received my midTbot PCB, there was some soldering and assembly to do. I
followed
<a href="https://github.com/bdring/midTbot_esp32/wiki/Controller-Kit-Assembly-Instructions">these instructions</a>
to attach the homing switches, power supply, and header pins to the board.</p>
<h3 id="printing-the-chassis">Printing the Chassis</h3>
<p>The chassis of the midTbot is entirely 3D printed. There are ~7 things that you
need to print
(<a href="https://github.com/bdring/midTbot_esp32/tree/master/STL">source files</a> on
Github), and they're all fairly simple shapes, so the prints were easy to do.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print_hu632932bafc371cef54c7ef30f19a742b_135778_0x400_resize_q75_box.jpg" alt="Completed prints of the &amp;lsquo;feet&amp;rsquo; and tailblock pieces"> </a><figcaption>
        <p>Completed prints of the ‘feet’ and tailblock pieces</p>
    </figcaption>
    </figure>

<p>The hardest thing to print (and the most finicky part of the project in general)
was the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/STL/midt_esp32_pen_mnt.stl">pen mount</a>.
This piece has some overhangs on it, so it was important to configure the
printer to add support material.</p>
<h2 id="assembly">Assembly</h2>
<p>With the PCB assembled, mechanical parts purchased, and chassis pieces printed,
it was time to do the final assembly. Again, I followed the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Assembly-Instructions">assembly instructions</a>
on the project Github.</p>
<p>The assembly process was straightforward: the PCB gets screwed into one of the
printed pieces, the pulleys and linear rods get screwed in to the “feet” and
carriage block pieces, and the stepper motors are secured to the chassis with
the PCB “sandwiched” in between the chassis and the motors.</p>
<p>One difficult step was attaching the stepper motors to the PCB. Per the project
instructions, you're supposed to solder the stepper motor wires into plastic
<a href="https://en.wikipedia.org/wiki/Pin_header">pin sockets</a>, so you can easily
detach the motors from the PCB. But, after I tried and failed several times to
solder the stepper motors into the female socket block, I simply soldered the
female sockets to the board directly and soldered the stepper motor wires onto
solid-core jumper wires. The end result wasn't as clean as what's shown in the
project instructions, but still allowed me to hot-swap the motors if needed.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics_hu69d27adac9c276a7c142cb42ce695fc5_460646_0x400_resize_q75_box.jpg" alt="Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)"> </a><figcaption>
        <p>Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)</p>
    </figcaption>
    </figure>

<p>Once the main “chunk” of the plotter was assembled (pictured above), the only
things left to do were to thread the timing belt around the pulleys, and attach
both ends of the belt to the pen head with a small amount of tension.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2_hubcee09c1499dfeaed0cdedbd52521e35_510199_0x400_resize_q75_box.jpg" alt="Belt Attach Points (circled)"> </a><figcaption>
        <p>Belt Attach Points (circled)</p>
    </figcaption>
    </figure>

<p>The last step in assembly (and, unfortunately the most fiddly part of the whole
process) was attaching the pen holder to the “head” block. The long screw that
makes the joint between the pen holder and “head” block needs to be tuned
meticulously: If the screw is too tight, then the pen can get stuck in the “up”
position – not returning to the “down” position when the servo retracts. On the
other hand, if the screw is too loose, then this translates to “slop” in the
pen's position, which results in wiggly drawings that are unusable.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo_hu041824ca24038cc947b7d5fa7334f321_403811_0x400_resize_q75_box.jpg" alt="Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)"> </a><figcaption>
        <p>Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)</p>
    </figcaption>
    </figure>

<p>At this point, the bot was assembled! I powered it on and installed a specific
version of the <a href="https://github.com/bdring/Grbl_Esp32">Grbl_Esp32</a> firmware
designed for the midTbot per the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Compiling-Firmware-for-the-MidTBot">project instructions</a>.
Grbl_Esp32 is a really nifty piece of software: it allows you to upload an run
Gcode (basically, machine readable instructions for how to move the pen) on the
plotter's Esp32 controller. Since the Esp32 has built-in wifi (and bluetooth),
its able to serve a basic web UI:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui.png">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui_hu659f08144d7f460a1e53d6a3f50b9a17_60893_0x400_resize_box_2.png" alt="Grbl_Esp32 Web UI"> </a><figcaption>
        <p>Grbl_Esp32 Web UI
            <a href="https://github.com/luc-github/ESP3D-WEBUI">Source: Github</a></p>
    </figcaption>
    </figure>

<p>The Web UI is sufficient for most tasks: homing, minor positioning adjustments,
starting/pausing/resuming prints. There are only a few tasks – like calibration
– that require you to drop down to the Grbl “command line”.</p>
<p>It took me a while to get my midTbot calibrated. The project documentation was a
bit light on the specifics, so there was a lot of trial-and-error and
troubleshooting.</p>
<h2 id="plotting-software">Plotting, Software</h2>
<p>Now that I had a functioning plotter bot, the next thing to do was try it out.
Of course, to do so you need to actually produce Gcode that the bot can use.
There are tons of tools to do this – and a full discussion of Gcode/plotter
software is worth a whole other post. Suffice it to say, there are a variety of
resources on the <a href="https://drawingbots.net/knowledge/tools">Drawing Bots</a>
community page that serve as a good starting point.</p>
<p>I spent most of my time working with <a href="https://inkscape.org/">Inkscape</a>‘s
Gcodetools plugin. Axidraw (which makes a commercial pen plotter) also has some
useful
<a href="https://wiki.evilmadscientist.com/Axidraw_Software_Installation">Inkscape plugins</a>,
although some of the functionality won't work with the midTbot. Gcodetools
nominally allows you to translate SVGs to Gcode, however this is a tedious
process. <em>Not just any</em> SVG will work well with it; the SVG basically already
needs to be a line drawing for Gcodetools to have any hope of working correctly.
It has basic support for infilled regions too, but again you have to be careful
with it – any slight hiccup, and it produces unusable Gcode.</p>
<p>To be honest, the software aspect of pen plotting is the most frustrating part
of the workflow. I haven't yet found a great toolchain for the “art” -&gt; Gcode
pipeline, so there's a lot of finicky steps. (It doesn't help that Inkscape is a
second-class X11 app on macOS…)</p>
<h2 id="additional-hardware-modifications">Additional Hardware Modifications</h2>
<p>After I ordered a midTbot PCB, the creator added me to a Slack group. Some of
the other folks who'd built midTbots contributed back modifications they'd made
to their builds. I took a couple of these and added them to my bot too:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount_hu1f2dbe1c25aab483c480e60644105b8f_437548_0x400_resize_q75_box.jpg" alt="Magnetic Pen Mount with Thumb Screw"> </a><figcaption>
        <p>Magnetic Pen Mount with Thumb Screw</p>
    </figcaption>
    </figure>

<p>First, I ordered heftier thumb screws for the pen attachment (as pictured); the
screws in the original BOM are tricky to manipulate by hand. Second, I printed a
magnetic detachable pen holder (as pictured) which makes it easier to add/remove
pens without disturbing the rest of the setup. If you want to do multicolor
prints, this modification is a must. Finally, I printed wider supports for the
bots frame. Supposedly, this allows you to increase the available print size of
the bot (if you also order longer linear rods). I didn't get around to actually
increasing my bot's print size, but the wider supports made the bot more stable,
and easier to attach to a work table.</p>
<h2 id="results">Results</h2>
<p>After an afternoon of calibrating the bot and installing the mods I discussed
above, I got some prints that I'm pretty happy with.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle_hu7abfc5bba89b65ef467a92e89d404d38_647220_0x400_resize_q75_box.jpg" alt="SierpiÅ„ski triangle"> </a><figcaption>
        <p><a href="https://en.wikipedia.org/wiki/Sierpi%C5%84ski_triangle">SierpiÅ„ski triangle</a></p>
    </figcaption>
    </figure>

<p>Sierpinski's triangle (above) is a single line, but has a lot of intricate
detail. This is a good exercise of the precision of the stepper motors, which as
you can see is quite good. The precision also requires the pen mount to be
calibrated correctly, so that there isn't any “slop” between the pen and the
body of the plotter.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube_hu4580d2579ea2776d604d9e44b4623042_575462_0x400_resize_q75_box.jpg" alt="Isometric Cube"> </a><figcaption>
        <p>Isometric Cube
            <a href="https://github.com/wblut/isogrid">Source: Github</a></p>
    </figcaption>
    </figure>

<p>This was a slightly harder pattern for the bot to draw. The lines are all
straight, but there are a fair number of pen raises. Generally, the more pen
up/down cycles a print has, the greater the likelihood of failure.</p>
<p>I've also noticed that <em>where</em> the pattern is in the print area of the bot makes
a difference. The closer the pen head is to the main bot chassis, the more the
pen is pulled away from the paper due to the counterweight of the “tail”
section. As such, I tried to position the prints as close to the middle of the
print area as possible. Below is what happens when the pen holder misbehaves:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader_hu1a98c8f9a4b8a7a0c3eafda2f5f8180d_194935_0x400_resize_q75_box.jpg" alt="Somewhat failed &amp;lsquo;Space Invaders&amp;rsquo; Print (Note the discontinous/missing lines)"> </a><figcaption>
        <p>Somewhat failed ‘Space Invaders’ Print (Note the discontinous/missing lines)
            <a href="https://github.com/abey79/vpype">Source: vpype Example Code</a></p>
    </figcaption>
    </figure>

<p>The plot isn't a complete failure, but many of the lines don't get drawn or only
get partially drawn. This is often caused by the pen mount screw being too
tight, causing the pen …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</a></em></p>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820926</guid>
            <pubDate>Mon, 13 Jul 2020 14:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Grok with Elasticsearch to add structure to your data]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820793">thread link</a>) | @alexmarquardt
<br/>
July 13, 2020 | https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/ | <a href="https://web.archive.org/web/*/https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div id="primary">
	<main id="main" role="main">
		
<article id="post-1351" class="page">
	<!-- .entry-header -->

	
	<div>
		<p>July 13, 2020</p><p>As well as being a search engine, Elasticsearch is also a <a href="https://www.elastic.co/blog/intro-to-aggregations">powerful analytics engine</a>. However in order to take full advantage of the near-real-time analytics capabilities of Elasticsearch, it is often useful to add structure to your data <em>as it is ingested</em> into Elasticsearch. The reasons for this are explained very well in the <a href="https://www.elastic.co/blog/schema-on-write-vs-schema-on-read">schema on write vs. schema on read</a> article, and for the remainder of this blog, when I talk about structuring data, I am referring to <em>schema on write</em>.</p>

<p>Because of the importance of structuring your data, in this blog I will show you how to add structure to unstructured documents by using an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/ingest.html">ingest node</a> with the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok Processor</a>. Then, I will describe a simple method to construct new Grok patterns, and a method that can be used to debug errors in existing Grok patterns. Finally I will provide links to some publicly available Grok patterns and then briefly mention the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/dissect-processor.html">Dissect Processor</a> as a possible alternative to Grok.</p>

<p>As a side note, if you are going to put in the effort to structure your data, you should consider structuring your data so that it conforms to the <a href="https://www.elastic.co/blog/introducing-the-elastic-common-schema">Elastic Common Schema</a>, which will facilitate the analysis of data from diverse sources.</p>



<p>It is not uncommon to see documents sent to Elasticsearch that are similar to the following.:</p>

<pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre>

<p>The message field in the above document contains unstructured data. It is a series of words and numbers that are not suitable for near-real-time analytics. In order to take full advantage of the powerful analytics capabilities of Elasticsearch, we should parse the message field to extract relevant data. For example, we could extract the following fields from the above message:</p>

<pre>"host.ip": "55.3.244.1"&nbsp;<br>"http.request.method": "GET"<br>"url.original": "/index.html"<br>"http.request.bytes": 15824<br>"event.duration": 0.043</pre>

<p>Adding such a structure will allow you to unleash the full power of Elasticsearch on your data.</p>



<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok</a> is a tool that can be used to extract structured data out of a given text field within a document. You define a field to extract data from, as well as the Grok pattern for the match. Grok sits on top of <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a>. However, unlike regular expressions, Grok patterns are made up of <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">reusable patterns</a>, which can themselves be composed of other Grok patterns.&nbsp;</p>

<p>Before going into details of how to build and debug your own Grok patterns, we first give a quick overview of what a Grok pattern looks like, how it can be used in an ingest pipeline, and how it can be simulated. Don’t worry if you don’t fully understand the details of the Grok expression yet, as these details will be discussed in-depth in the following sections of this blog.</p>

<p>In the previous section we presented an example document that looks as follows:</p><pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p><br>The desired structure can extracted from this example message field by using the following Grok expression:</p>

<pre>%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}</pre>

<p>And we define a pipeline which contains this Grok pattern inside a Grok processor.</p>

<pre>PUT _ingest/pipeline/example_grok_pipeline<br>{<br>  "description": "A simple example of using Grok",<br>  "processors": [<br>    {<br>      "grok": {<br>        "field": "message",<br>        "patterns": [<br>          "%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}"<br>        ]<br>      }<br>    }<br>  ]<br>}</pre>

<p>We can then <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/simulate-pipeline-api.html">simulate the above pipeline</a> with the following command.</p>

<pre>POST _ingest/pipeline/example_grok_pipeline/_simulate<br>{<br>  "docs": [<br>    {<br>      "_source": {<br>        "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>      }<br>    }<br>  ]<br>}</pre>

<p>Which responds with a structured document that looks as follows:&nbsp;</p>

<pre>{<br>  "docs" : [<br>    {<br>      "doc" : {<br>        "_index" : "_index",<br>        "_type" : "_doc",<br>        "_id" : "_id",<br>        "_source" : {<br>          "host" : {<br>            "ip" : "55.3.244.1"<br>          },<br>          "http" : {<br>            "request" : {<br>              "method" : "GET",<br>              "bytes" : 15824<br>            }<br>          },<br>          "message" : "55.3.244.1 GET /index.html 15824 0.043 other stuff",<br>          "event" : {<br>            "duration" : 0.043<br>          },<br>          "url" : {<br>            "original" : "/index.html"<br>          }<br>        },<br>        "_ingest" : {<br>          "timestamp" : "2020-06-24T22:41:47.153985Z"<br>        }<br>      }<br>    }<br>  ]<br>}</pre><p><br>This document contains the original unstructured&nbsp; message field, and it also contains all of the additional fields which have been extracted from the message. We now have a document that contains structured data!</p>



<p>In the above example we <em>simulated</em> execution of an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/pipeline.html">ingest pipeline</a> that contains our Grok pattern, but didn’t actually run it on any real documents. An ingest pipeline is designed to process documents at ingest time, as described in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/ingest.html">ingest node documentation</a>. One way to execute an ingest pipeline is by adding the pipeline name to the <em>PUT</em> command as follows:&nbsp;</p>

<pre>PUT example_index/_doc/1?pipeline=example_grok_pipeline<br>{<br>&nbsp;&nbsp;"message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p>And the document that has been written can be seen by executing:</p><pre>GET example_index/_doc/1</pre><p>Which will respond with the following:</p><pre>{<br>  "_index" : "example_index",<br>  "_type" : "_doc",<br>  "_id" : "1",<br>  "_version" : 2,<br>  "_seq_no" : 2,<br>  "_primary_term" : 1,<br>  "found" : true,<br>  "_source" : {<br>    "host" : {<br>      "ip" : "55.3.244.1"<br>    },<br>    "http" : {<br>      "request" : {<br>        "method" : "GET",<br>        "bytes" : 15824<br>      }<br>    },<br>    "message" : "55.3.244.1 GET /index.html 15824 0.043 other stuff",<br>    "event" : {<br>      "duration" : 0.043<br>    },<br>    "url" : {<br>      "original" : "/index.html"<br>    }<br>  }<br>}</pre><p>Alternatively (and likely preferably), the ingest pipeline can be applied by default to all documents that are written to a given index by adding it to the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/index-modules.html#dynamic-index-settings">index settings</a>:</p>

<pre>PUT example_index/_settings<br>{<br>&nbsp;&nbsp;"index.default_pipeline": "example_grok_pipeline"<br>}</pre>



<p>After adding the pipeline to the settings, any documents that are written to <em>example_index</em> will automatically have the <em>example_grok_pipeline</em> applied to them.&nbsp;</p>

<p>This can be verified by writing a new document to <em>example_index</em> as follows:</p>

<pre>PUT example_index/_doc/2<br>{<br>&nbsp;&nbsp;"message": "66.3.244.1 GET /index.html 500 0.120 new other stuff"<br>} </pre>

<p>And the document that has been written can be seen by executing:</p>

<pre>GET example_index/_doc/2</pre>

<p>Which, as expected will return the document that we just wrote. This document has the new fields that were extracted from the message field:</p>

<pre>{<br>  "_index" : "example_index",<br>  "_type" : "_doc",<br>  "_id" : "2",<br>  "_version" : 3,<br>  "_seq_no" : 2,<br>  "_primary_term" : 1,<br>  "found" : true,<br>  "_source" : {<br>    "host" : {<br>      "ip" : "66.3.244.1"<br>    },<br>    "http" : {<br>      "request" : {<br>        "method" : "GET",<br>        "bytes" : 500<br>      }<br>    },<br>    "message" : "66.3.244.1 GET /index.html 500 0.120 new other stuff",<br>    "event" : {<br>      "duration" : 0.12<br>    },<br>    "url" : {<br>      "original" : "/index.html"<br>    }<br>  }<br>}</pre>



<p>In the previous section, we presented an example document with the following structure:</p><pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p>And we then used the following Grok pattern to extract structured data from the message field:</p>

<pre>"%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}"</pre>

<p>As described in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok Processor documentation</a>, the syntax for Grok patterns comes in three forms: <em>%{SYNTAX:SEMANTIC}, %{SYNTAX}, %{SYNTAX:SEMANTIC:TYPE}</em>, all of which we can see in the above Grok pattern.&nbsp;</p><ul><li>The <em>SYNTAX</em> is the name of the pattern that will match your text. Built-in <em>SYNTAX</em> patterns <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">can be seen on github</a>.</li><li>The <em>SEMANTIC</em> is the name of the field that will store the data that matches the <em>SYNTAX</em> pattern.</li><li>The <em>TYPE</em> is the data type you wish to cast your named field.</li></ul>

<p>The first part of the Grok pattern is the following:</p>

<pre>%{IP:host.ip}</pre>

<p>This declaration matches an IP address (corresponding to the <em>IP</em> Grok pattern) and stores it in a field called <em>host.ip</em>. Four our example data, this will extract a value of <em>55.3.244.1</em> and store it in the <em>host.ip</em> field.</p>

<p>If we want more details on the <em>IP</em> Grok pattern, we can look into the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a>, and we will see the following definition:&nbsp;</p>

<pre>IP (?:%{IPV6}|%{IPV4})</pre>

<p>This means that the <em>IP</em> pattern will match one of the <em>IPV6</em> or <em>IPV4</em> Grok patterns. To understand what the <em>IPV6</em> and <em>IPV4</em> patterns are, once again we can look into the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a> to see their definitions, and so on.&nbsp;</p>

<p>The next part of the Grok pattern is a single whitespace character followed by the following expression:</p>

<pre>%{WORD:http.request.method}</pre>

<p>This portion of the Grok expression extracts the word <em>GET</em> from the <em>message</em>&nbsp;and stores it into the <em>http.request.method</em> field. If we want to understand the definition of the <em>WORD</em> pattern, we can look at the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a>.&nbsp;</p>

<p>One can do the same kind of analysis to understand the patterns that match the <em>url.original</em>, <em>request.bytes</em> and <em>event.duration</em> fields, which we leave as an exercise for the reader</p>

<p>Finally, the last statement in the Grok pattern is the following:</p>

<pre>%{GREEDYDATA}</pre>

<p>This expression does not have a <em>SEMANTIC</em> part, which means that the matching data is not stored into any field.&nbsp; Additionally, the <em>GREEDYDATA</em> Grok pattern will consume as much text as it can, which means that in our example it will match everything after the <em>event.duration</em> field. The <em>GREEDYDATA</em> expression will come in handy when debugging complex Grok patterns, as discussed in the following sections of this blog.&nbsp;&nbsp;</p>



<p>When constructing a new Grok pattern, it is often easiest to construct the Grok pattern incrementally starting from the left and working towards the right side of the unstructured text that we are trying to match.&nbsp;</p>

<p>Two tools that can be helpful for building and …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/">https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/</a></em></p>]]>
            </description>
            <link>https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820793</guid>
            <pubDate>Mon, 13 Jul 2020 13:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple devices are leaking sensitive data over BLE]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23820589">thread link</a>) | @dchest
<br/>
July 13, 2020 | https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/ | <a href="https://web.archive.org/web/*/https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
										
						<p>By <a href="http://perso.citi-lab.fr/gcelosia/">Guillaume Celosia</a> and <a href="https://perso.citi-lab.fr/mcunche/index.html">Mathieu Cunche</a></p>
<h4><a href="https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf"><strong>Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols</strong></a></h4>

<p>We found that Apple devices are leaking sensitive information in the BLE wireless signals they emit. Those issues are associated with the Apple Continuity services and are affecting all Apple devices as well as devices compatible with the Continuity framework. Based on a reverse engineering of Continuity, we identified that the Bluetooth Low Energy (BLE) messages emitted by Apple devices include unencrypted data that can expose sensitive information. We discovered that those data can be easily collected by an eavesdropper and processed in order to: track users, monitor activities in a smarthome, obtain phone number, email addresses and Apple Voice Assistant, Siri, commands, and more.</p>
<p><img src="https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy.png" alt="" width="822" height="385" srcset="https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy.png 822w, https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy-300x141.png 300w, https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy-768x360.png 768w" sizes="(max-width: 822px) 100vw, 822px"></p>

<h2>BLE advertising</h2>
<p>In BLE, devices broadcast short messages, called Advertising Packets, to announce their presence and feature to nearby devices (those messages can be observed from an Android device using an application like <a href="https://play.google.com/store/apps/details?id=com.contextis.android.BLEScanner&amp;hl=en">Ramble</a>). Advertising Packets can include the name of the device, its type, but can also include custom data in a field called Manufacturer specific. This field is typically used by vendors to transmit data for application. Apple make use of this field to include data for its Continuity Protocols.</p>
<h2>Apple Continuity Protocols</h2>
<p>Apple has developed a number of features, called <a href="https://support.apple.com/en-us/HT204681"><i>Continuity</i></a>, that are designed to increase the usability of its products. Those features include: activity transfert, file transfert (airDrop), Wi-Fi password sharing, etc. The communication between nearby devices, required by Continuity services, is done by using BLE. Continuity data are embedded in BLE advertising packets and are broadcast to be picked up by nearby devices.</p>

<h2>Data exposed in cleartext</h2>
<p>We found that, even though some elements are encrypted, most of the data included in Continuity messages is sent in plain text. The exposed data can thus be passively collected by an eavesdropper and exploited to mount one of the attack presented below.</p>
<h2>Tracking users (iPhones, iPad, airpods …)</h2>
<p>We found that the content of <i>Apple Continuity </i>BLE messages can be used to track the device despite the use address randomization. We have identified several elements that remain constant over time or that can undermine the anti-tracking feature mechanism (i.e. address randomization). For instance, we found that messages emitted by earpods include information (battery levels and lid open counter) that can be exploited to track the earpod set. We also discovered a novel attack that would allow tracking by actively replaying BLE messages. An passive attacker could exploit this information to track the the location of individuals in spite of address randomization, the anti-tracking feature of BLE.</p>
<h2>Linking device belonging to the same iCloud account</h2>
<p>We discovered that it is possible to link together devices associated to the same iCloud account. This attack relies on the replay of messages that will trigger a response only from devices associated to the same <i>iCloud</i> account. An attacker could exploit this to identify all the device belonging to a person, and could narrow down its home if some device are left there.</p>
<h2>Monitoring activities in a smart home (Homekit)</h2>
<p>We found that messages emitted by <i>Homekit</i>-compatible devices can betray the activity in a smart-home. <a href="https://developer.apple.com/homekit/"><i>Homekit</i></a> is a smart-home framework developed by <i>Apple</i> and found in <a href="https://www.apple.com/fr/shop/accessories/all-accessories/homekit">devices</a> of <i>Apple</i> and other vendors (…). <i>Homekit</i> devices using BLE continuously emit messages that include an indicator reflecting the device state. For instance, in the case of a lightbulb, this indicator changes only when it is either turned on or turned off. Similarly, in an infrared movement detector, the indicator changes only when a person crosses the detection field. In-lab experiments showed that a passive attacker can leverage Homekit BLE messages to track the evolution of devices in a household and thus monitor the activities of the occupants.</p>
<h2>Device model, software version and more</h2>
<p>We found that a number of messages expose a wide variety of information on the emitting device characteristics and state: device model, OS version, device color, cellular connectivity, battery level, current activity etc.</p>
<h2>E-mail address and Phone numbers (Airdrop &amp; Nearby)</h2>
<p>We found that when using features such as Airdop and Nearby, devices emit messages from which email addresses and phone numbers can be extracted. Continuity services allow to seamlessly share resources with nearby devices: Airdrop to share files, Nearby to share Wi-Fi network credential. Prior exchange of information, the devices establish their identity by exchange identifiers over BLE: email addresses and/or phone numbers. Those identifiers are not sent in clear but are rather hashed using a cryptographic hash-function. This obfuscation can be bypassed in most cases and the identifiers recovered.</p>
<h2>Voice assistant commands (Siri)</h2>
<p>We found that when activated via voice, the Siri voice assistant will generate a message including a digital fingerprint of the command. Although the raw audio signal cannot be reconstructed from it, the fingerprint could be leveraged to infer the command.</p>

<p>The vulnerabilities identified were reported to Apple, Osram and Eve on May 29 th , 2019.</p>

<p>This work was supported by the <a href="http://www.citi-lab.fr/chairs/iot-chair/">INSA Lyon – SPIE ICS IoT chair</a> and the H2020 <a href="https://www.sparta.eu/">SPARTA</a> Cybersecurity Competence Network project.</p>
<p><img src="https://team.inria.fr/privatics/files/2019/10/logo-chaire-e1570022002577.jpg" alt="" width="200" height="66"><img src="https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-150x150.jpg" alt="" width="150" height="150" srcset="https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-150x150.jpg 150w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-300x300.jpg 300w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-144x144.jpg 144w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg.jpg 400w" sizes="(max-width: 150px) 100vw, 150px"></p>

<p>The corresponding research paper, <a href="https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf"><u>Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols</u></a>, will be presented at the <a href="https://petsymposium.org/2020/index.php">20th Privacy Enhancing Technologies Symposium (PETS 2020)</a> on 14-18 July 2020 in Montreal, Canada.</p>
<h3><a name="citeme"></a>APA style citation and bibtex entry</h3>
<p>You can use the following APA style citation or bibtex entry to reference our paper:</p>
<pre>Celosia, G., &amp; Cunche, M. (2020).Discontinued Privacy: Personal Data Leaks
in Apple Bluetooth-Low-Energy Continuity Protocols. <i>Proceedings on Privacy
Enhancing Technologies, 2020</i>(1), 26-46. De Gruyter Open.
@article{celosia2020close,
    title={Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols},
    author={Celosia, Guillaume and Cunche, Mathieu},
    journal={Proceedings on Privacy Enhancing Technologies},
    volume={2020},
    number={1},
    pages={26--46},
    year={2020},
    publisher={De Gruyter Open}
}</pre>
<p><a href="http://creativecommons.org/licenses/by/4.0/">Creative Com</a></p>
								</div></div>]]>
            </description>
            <link>https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820589</guid>
            <pubDate>Mon, 13 Jul 2020 13:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad Habits]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820496">thread link</a>) | @fizentech
<br/>
July 13, 2020 | https://fizentech.com/bad-habits/ | <a href="https://web.archive.org/web/*/https://fizentech.com/bad-habits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Does your organization have habits that are detrimental to their success?&nbsp; The answer of course, is yes - all organizations and their people, have embedded routines and habits that are limiting their success.&nbsp; Changing a habit is challenging and often we don't even realize we have a habit that is limiting our ability to improve.</p>
<p>In the groundbreaking book, The Power of Habit, Charles Duhigg points out that in a paper published by a Duke University researcher, it was <em>found that more than 40 percent of the actions people performed each day weren't due to decision making, but were habits. In a sense, that's alarming because when we're in the middle of a habit, we're thinking less.</em></p>
<p>Well ... hold on, we do NOT want our IT professionals thinking less, we want them actively thinking through problems and critically finding ways to improve the experience of end users.&nbsp; That can become a challenge when working on an IT Help Desk becomes routine, or a strong willed Project Manager is not listening to the input of the team; and resources disengage and come to expect to be led rather than to lead.</p>
<p>As an technology provider, we provide IT Services to a broad range of industries.&nbsp; The variation in organizations we serve has helped us work with many different people, in a variety of geographical areas and countries.&nbsp; We have found that leaders with good habits naturally attract and retain employees with good habits.&nbsp; The culture of the organizations we serve and the attitudes and routines of its employees, often reflect the attitudes, routines and habits of their executive teams and owners.&nbsp; It can be hard medicine to accept, but it is true - you lead from the top (but that doesn't mean you can't be a positive agent for change, whatever your position is within a group).</p>
<p>Starbucks has often been cited for the system they developed for exceptional customer service, now referred to as the LATTE System.&nbsp; They encourage their employees to,</p>
<ul>
<li>Listen to the Customer</li>
<li>Acknowledge their complaint</li>
<li>Take action by solving the problem</li>
<li>Thank them</li>
</ul>
<p>Customers can be a wonderful and often <a href="https://fizentech.com/help-wanted/">free source of advice</a> on what your organization is or is not doing well.&nbsp; We have added an additional ingredient to this wonderful formula, and that is returning back to our customer to make sure systems are still operating as discussed.&nbsp; We want to be sure they are still happy with the outcome; perhaps easier for us as our clients are typically part of ongoing managed service agreements.</p>
<p>A few years ago we were required to roll out endpoint management to a very large customer base.&nbsp; Our product offering includes endpoint monitoring and protection for mobile devices and workstations, and when you're working with large user groups; coordinating the installations can be a real challenge.&nbsp; Nobody wants to be inconvenienced or disrupted by a software installation.</p>
<p>Our client had previous experiences with MDM and RMM roll outs that did not go very well, and we found ourselves listening to their experiences and brainstorming how we could avoid the common approaches used by other IT vendors; forcing installation and maintenance windows on end users.</p>
<p>We found if we put the power of scheduling the installations for end users into their own hands, rather than falling back on the common habit in IT organizations to force installation and maintenance windows; the installation process not only went smoother but completed faster.&nbsp; By providing end users scheduling options they were empowered with autonomy and enjoyed controlling their own downtime.</p>
<p>Willpower is the biggest and most important element of developing good habits for an organization.&nbsp; An essential element of willpower, is autonomy.&nbsp; &nbsp;Everyone wants to believe and feel that they are in control of their lives, schedule and organization.&nbsp; When we take away someone's choices, they become frustrated - but when we provide choices, we find that our ability to coordinate and deliver for a client grows tenfold.</p>
<p>We need to reflect on the processes, systems and rule-sets that are governing how our organizations operate; and by listening to our stakeholders, find new ways to innovate and empower them to be apart of our mission; to keep their IT systems running smoothly.&nbsp; Find ways to engage with your user base, and use their feedback to drive innovative IT Services within their organization; they will thank you.</p>

</div></div>]]>
            </description>
            <link>https://fizentech.com/bad-habits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820496</guid>
            <pubDate>Mon, 13 Jul 2020 13:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How reframing discounts led to a 4x increase in yearly plans]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820462">thread link</a>) | @Mnlfrgr
<br/>
July 13, 2020 | https://manuel.friger.io/blog/reframing | <a href="https://web.archive.org/web/*/https://manuel.friger.io/blog/reframing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <div>
            <p><!--block-->Back in May my wife and I decided to move out of our flat in Bristol.</p>

<p>By then we had already been living for a couple of months with my in-laws and it didn't make sense to keep paying £1k+/month in rent.</p>

<p>After some discussion, we decided to throw some money at the problem and put all our stuff in a storing facility.</p>

<p>I started googling storage companies in Bristol and I was quickly overwhelmed by the number of options (pro tip: don't start a storage business, it's ridicolously competitive).</p>

<p>Every company allowed me you to get an online quote by entering the size of the storing unit and how long I wanted to rent it for.</p>

<p>But one company did things differently.</p>

<p>On top of asking me the same two questions, UK Storage Company also <strong>asked me to choose a discount</strong>.</p>

<div>
<p><span data-trix-cursor-target="left" data-trix-serialize="false">ï»¿</span><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/205/content_Screenshot_2020-07-10_Your_storage_quote_is_below%281%29.png"></p></div>

<p>At first, I was confused.</p>

<p>I wondered why they would allow me to choose my own discount. Then I realised it was the good ol' "the longer you commit, the less you pay" gimmick.</p>

<p><strong>Same technique, different framing.</strong><br>
UK Storage Company put me in the driver's seat and empowered me to make my decision.</p>

<p>That's when my brain started whirring and buzzing, and one question began to form in my head: what if I used the same framing <a href="https://referralhero.com/">for my SaaS product</a>?</p>

<p>After all, cash-flow is king for (bootstrapped) startups and having people commit to yearly plans helps to lower churn.</p>

<p>Would that have any effect on how many people choose the longer plans (biannual or annual) over the monthly one?</p>

<p>That same day I <a href="https://twitter.com/manuel_frigerio/status/1264609587413553155">tweeted about it</a> and updated the checkout page of my app as shown below.</p>

<p><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/206/content_Screenshot_2020-07-10_ReferralHero_-_Advanced_Referral_Marketing_Software_.png"></p>



<h2><!--block-->The results</h2>

<p><!--block-->After 7 weeks the experiment has been a great success.<br>
With the new framing, the percentage of people who chose the biannual or annual plan <strong>has gone from 4.8% to 19%</strong>, a rather nice <strong>395% increase</strong>.<br>
<span data-trix-cursor-target="right" data-trix-serialize="false"><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/207/content_chart.png"></span><br>
I've done several pricing experiments over the years but none of them has been as successful and in such short space of time.</p>

<p>Perhaps even more interesting is that <strong>more than twice as many people chose the annual plan over the biannual plan</strong>.</p>

<p>My hunch is that this is due to the higher discount rate of the annual plan (35% for 12 months vs 15% for 6 months means an extra 5% discount when you choose the annual plan), which increases the perceived value.</p>

<h2><!--block-->Never stop experimenting</h2>

<p><!--block-->There's a small handful of levers you can pull to grow a business and <a href="https://manuel.friger.io/blog/charge-more">pricing is probably the most underutilised one</a>. Most SaaS businesses choose a pricing model and rarely, if ever, review it.</p>

<p>A better (and more profitable) approach is to run small experiments. If they work, incorporate them. If they don't, try something else.</p>

<p>Some people are scared that changing things will upset their customers but the truth is:</p>

<ol>
	<li>
	<p><!--block-->you are allowed to change whatever you want about your business.</p>
	</li>
	<li>
	<p><!--block-->you can always revert back. Nothing is fixed.</p>
	</li>
	<li>
	<p><!--block-->in reality, nobody cares.</p>
	</li>
</ol>

<h2><!--block-->Do it yourself</h2>

<p><!--block-->If you want to try this experiment in your business, here are a couple of suggestions:</p>

<ul>
	<li>
	<p><!--block-->don't <a href="https://medium.com/@FlorentGeerts/the-jam-experiment-how-choice-overloads-makes-consumers-buy-less-d610f8c37b9b">overload people</a> with options; have maximum 3.</p>
	</li>
	<li>
	<p>to nudge people towards one option, offer a substantially higher discount (like I did with the yearly plan)</p>
	</li>
	<li>
	<p>Don't try to be sneaky and word the options properly. As you can see in my example, people know exactly what they get and how much they pay.</p>
	</li>
	<li>
	<p>ask people immediately after sign-up when they are in the right frame of mind. In my experience, asking people to switch to yearly plans a couple of months after they have used your product triggers many more questions in their mind, whereas by asking them before they try your product you're putting them in front of a simple decision: do I want to save money?</p>
	</li>
</ul>

<p><!--block-->As people who work in the tech industry, we are all exposed to the same ideas, patterns and filters. This is why there's so little innovation and everyone just copies what everyone else is doing.</p>

<p>Sometimes all you need to do is to look at what companies in completely different industries operate. You might be suprised what a storage company can teach you.</p>

<p><strong>PS:</strong> If you do try this experiment, <a href="https://manuel.friger.io/cdn-cgi/l/email-protection#6409050a1101082402160d0301164a0d0b">let me know how it goes</a>.</p>

<p><strong>PPS:</strong> You probably want to know if we did hire that storing company in the end. The answer is NO. Eventually, we decided to hire a removal company and have all our stuff with us.</p>

          </div>
        </div>
        
      </div><div>
        <h3>Did you enjoy this?</h3>
        <p>Then you will like <a target="_blank" href="https://manuel.friger.io/join">ðŸ”¥The Fireside</a>, a monthly-ish newsletter about psychology, business, technology and the intersection of those plus any new articles I publish on this blog.</p>
      </div></div>]]>
            </description>
            <link>https://manuel.friger.io/blog/reframing</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820462</guid>
            <pubDate>Mon, 13 Jul 2020 13:24:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russ v7.0 – Services framework/library for Unix sockets]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23820398">thread link</a>) | @johnmdev
<br/>
July 13, 2020 | https://expl.info/display/RUSS/Home | <a href="https://web.archive.org/web/*/https://expl.info/display/RUSS/Home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-type="normal">
<div>
<p>RUSS is a protocol and framework for building service-oriented servers using UNIX/Domain sockets.</p><p>RUSS is an alternative to HTTP/web technologies for services running on UNIX/Linux.</p><p>RUSS is built on some familiar ideas:</p><ul><li>orthogonal operations: execute, help, list</li><li>service path: /-separated list of strings identifying a service and how to get there</li><li>ordered list of string arguments (aka positional arguments)</li><li>unordered collection of string attritubes as key=value pairs (like environment variables)</li><li>exit/return value</li><li>stream I/O over file descriptors (stdin, stdout, stderr)</li></ul><p>The benefits of using UNIX/Domain sockets are:</p><ul><li>performance</li><li>standard part of UNIX/Linux (no kernel modules needed)</li><li>credentials are mediated by the OS</li><li>connection between independent processes (even between different users)</li><li>passing of descriptors between independent processes (even between different users)</li></ul><p>Get started with&nbsp;<a href="https://expl.info/display/RUSS/RUSS+v7+-+Quickstart+Setup">RUSS v7 - Quickstart Setup</a>.</p><p>Further information for users and developers is available in the&nbsp;<a href="https://expl.info/display/RUSS/Documentation">Documentation</a>&nbsp;section:</p><ul><li><a href="https://expl.info/display/RUSS/RUSS+Specification">RUSS Specification</a></li><li><a href="https://expl.info/display/RUSS/RUSS+v7+-+Tools">RUSS v7 - Tools</a></li><li><a href="https://expl.info/display/RUSS/RUSS+v7+-+Core+Servers">RUSS v7 - Core Servers</a></li><li><a href="https://expl.info/pages/viewpage.action?pageId=40501388">pyruss - RUSS for the Python Programming Language</a></li><li><a href="https://expl.info/display/RUSS/goruss+-+RUSS+for+the+Go+Programming+Language">goruss - RUSS for the Go Programming Language</a></li></ul><h2 id="Home-Firstthings">First things</h2><ul><li><code>+</code>&nbsp;-&nbsp;the area that system servers register at; usually under&nbsp;<code>/var/run/russ/services</code><span><code><br></code></span></li><li><span><code>ruls</code>&nbsp;- command line tool to list servers/services (think&nbsp;<code>ls</code>)<br></span></li><li><span><code>ruhelp</code>&nbsp;- command line tool to get help information (think&nbsp;<code>man</code>)</span></li><li><span><code>ruexec</code>&nbsp;- command line tool to execute a service</span></li><li><span><code>pyruss</code>&nbsp;- Python bindings for the C API</span></li><li><span><code>rubb</code>&nbsp;- manage servers/services</span></li></ul><h2 id="Home-ListingServers/Services">Listing Servers/Services</h2><p>What's available?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruls +
debug
exec
plus
proc
set
ssh
tee</pre>
</div></div><p>What services does the&nbsp;<code>debug</code>&nbsp;server provide?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruls +/debug
chargen
conn
daytime
discard
echo
env
exit
request
session
spath</pre>
</div></div><h2 id="Home-GettingHelp-BuiltinManPage">Getting Help - Built in Man Page</h2><p>How do I use the&nbsp;<code>debug</code>&nbsp;services?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruhelp +/debug
Provides services useful for debugging.

/chargen[/...]
    Generate and send characters following the RFC 864 character
    generator protocol sequence.

/conn[/...]
    Report connection information.

/daytime
    Report the date and time.

/discard[/...] [--perf]
    Discard all data received from stdin. If --perf is specified,
    performance feedback is reported to stderr.

/echo[/...]
    Simple echo service: read from stdin and write back to stdout.

/env
    Report server side environ entries.

/exit &lt;value&gt;
    Return with given exit value (between 0 and 255).

/request[/...]
    Report request information.

/session[/...]
    Report session information.

/spath[/...]
    Report service path information.</pre>
</div></div><h2 id="Home-RunningaService">Running a Service</h2><p>Try the character generator:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/debug/chargen
!"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefgh
"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghi
#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghij
^C</pre>
</div></div><p>Show "request" information (as received and sent back by the server):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec -a X=123 -a Y=abc +/debug/request hello there world
protocol string (0010)
spath (/request)
op (execute)
opnum (2)
attrv[0] (X=123)
attrv[1] (Y=abc)
argv[0] (hello)
argv[1] (there)
argv[2] (world)</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/debug/daytime
Friday, February 16, 2018 11:45:50-GMT</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service on another machine "buddy" (<code>ssh</code>&nbsp;must work without user interaction):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/ssh/buddy/+/debug/daytime
Friday, February 16, 2018 11:46:55-GMT</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service from Python:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ PYTHONPATH=/usr/lib/russng python2
&gt;&gt;&gt; import pyruss
&gt;&gt;&gt; rv, ev, out, err = pyruss.execv_wait_inouterr_timeout(1000, "+/ssh/buddy/+/debug/daytime")
&gt;&gt;&gt; print out
Friday, February 16, 2018 11:48:23-GMT</pre>
</div></div><p>Echo a message, hopping through three machines "buddy", "bobby", and "bibby" (as before,&nbsp;<code>ssh</code>&nbsp;must work without user interaction):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ echo "hop hop hop" | ruexec +/ssh/buddy/+/ssh/bobby/+/ssh/bibby/+/debug/echo
hop hop hop</pre>
</div></div></div>
</div></div>]]>
            </description>
            <link>https://expl.info/display/RUSS/Home</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820398</guid>
            <pubDate>Mon, 13 Jul 2020 13:16:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Project over Money, Team over Project]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23820390">thread link</a>) | @strdr4605
<br/>
July 13, 2020 | https://strdr4605.github.io/project-over-money-team-over-project | <a href="https://web.archive.org/web/*/https://strdr4605.github.io/project-over-money-team-over-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><h2>Project over money, team over project</h2><p><time>11.07.2020</time> — <a href="https://strdr4605.github.io/tags/motivation">motivation</a> — <span>2<!-- --> min read</span></p><section><p>Behind any work stands a motivation. Sometimes work is a pleasure, other times you do things that are unpleasant just because you have to.
But in the end motivations like money, common goal, future achievements drive us to work.
When choosing a job as a software engineer, things that motivate me and probable you are the <strong>project</strong> what I will work on,
<strong>team</strong> what I will work with and <strong>money</strong> for my personal need.
When making the final decision I usually value <strong>project over money, team over project</strong>.</p><h2>Team</h2><p>For me, the team that I will work with is the most important aspect when searching for a new job.</p><blockquote><p>“If you are the smartest person in the room, then you are in the wrong room.” ― Confucius</p></blockquote><p>Being in a team with people that are more experienced than you is the key to fast-growing.
But don't just stay and wait when their knowledge will be transferred to you.</p><ul><li>Observe their behaviors</li><li>Make proposals and wait for feedback</li><li>Ask for advice</li><li>Ask "Why?" when they make a decision. "Why this database?" "Why this service?" ...</li></ul><p>Make sure to not push too hard on them. As this can defocus and irritate some people.</p><p>Even if your teammates aren't more experienced than you they may share interesting articles, tips, thoughts.</p><p>In the end, if you have a hard situation, maybe the project is not that interesting (at the moment) or you have problems with finishing a task,
with a great team, you can carry on and pass any issues.</p><h2>Project</h2><p>At this moment in my career, I am really focused on the technical part of a project.
I enjoy learning new tools, libraries that will increase productivity, and when coding I am trying to create a piece of art.</p><p>But also the idea and the product may still be a good motivation and even if the tech stack is not that good,
with a great team, you will refactor everything as long as you believe in the product idea.</p><p>Even if the team is not that good or you don't have a team at all, enjoying the tech stack or believing in the product
will make you continue working and loving your job.</p><p>While at the interview, I try to discover as much as possible about the project stack and idea to understand if
I am willing to accept an offer bellow my initial expectations.</p><h2>Money + benefits</h2><p>Money is important as everyone has their needs and money represent your value as a software engineer.
Employee benefits like included food, gym, short commute time may be also added to the total compensation pack.</p><p>If you have a family and bills to pay money may be a decisive factor.
But still, put everything on the table and before making the final decision ask yourself a question.</p><blockquote><p>What will be your next job after this one?</p></blockquote><p>In other words: Where will this job lead you? How much will your professional skills increase?
Will this job have temporary benefits you will bust your entire career?</p><p>Does it worth an additional 100% salary increase to work with a 5+ year old legacy codebase, old tech stack, and maybe a bad team?</p><h2>Conclusion</h2><p>As everyone has a price I will try to conclude with some compensation examples.</p><p>If I am enjoying the project and/or the team at my current job, I would not accept a 5-15% salary increase offer,
as after 3-6 months I may get even more increase at my current job.
If I don't like the project or the team is toxic, I may accept a lower job offer just because
I will gain more from the new team or new tech stack.</p><p>Focus on your professional skills, gain maximum value from your team (don't forget to also give back and share your knowledge with teammates),
learn your tech stack, enjoy your software engineering career and the money will eventually come to you.</p></section></div></div>]]>
            </description>
            <link>https://strdr4605.github.io/project-over-money-team-over-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820390</guid>
            <pubDate>Mon, 13 Jul 2020 13:15:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Querying 40k Datasets with SQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820382">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/40k-sql-datasets | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/40k-sql-datasets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#introduction" as="#introduction">Introduction</a></li><li><a href="#data-should-be-discoverable-and-composable" as="#data-should-be-discoverable-and-composable">Data should be discoverable and composable</a></li><li><a href="#mounting-vs-cloning-data" as="#mounting-vs-cloning-data">Mounting vs. Cloning Data</a></li><li><a href="#mounting-data-in-splitgraph-cloud" as="#mounting-data-in-splitgraph-cloud">Mounting data in Splitgraph Cloud</a></li><li><a href="#avoiding-the-pull-of-data-gravity" as="#avoiding-the-pull-of-data-gravity">Avoiding the pull of Data Gravity</a></li><li><a href="#looking-to-the-future" as="#looking-to-the-future">Looking to the future</a></li></ol></nav><section><h2 id="introduction">Introduction</h2><p><a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">Splitgraph</a> is a tool and platform for building, versioning, querying and sharing datasets. Inspired by Docker and Git, it works on top of PostgreSQL and integrates seamlessly with anything that uses PostgreSQL. Our <a href="https://www.splitgraph.com/explore" as="https://www.splitgraph.com/explore">data catalog</a> already includes over 40,000 datasets from government open data portals, all queryable via SQL.</p><p>The Splitgraph catalog classifies these datasets as <a href="https://www.splitgraph.com/docs/splitgraph-cloud/external-repositories">external repositories</a>. These are different from the default <a href="https://www.splitgraph.com/docs/concepts/repositories">Splitgraph repositories</a>, which are collections of <a href="https://www.splitgraph.com/docs/concepts/images">Splitgraph images</a>. Yet Splitgraph allows you to query them in the same way as you do Splitgraph images. For example, you can use SQL to query any repository or <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals" as="/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals"><code>JOIN</code> between multiple of them</a>. Or you can use Splitfiles to <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#splitfile" as="/docs/ingesting-data/socrata#splitfile">build reproducible datasets</a> from them. And every external repository includes an <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">auto-generated PostgREST API</a>.</p><p>External repositories allow Splitgraph Cloud to index live data without actually ingesting it. This way, you can use the catalog to discover live data. But you only need to ingest it when you're ready to query it, or snapshot it as part of a Splitgraph image.</p></section><section><h2 id="data-should-be-discoverable-and-composable">Data should be discoverable and composable</h2><p>Many services exist for cataloging data and making it discoverable. For example, <a href="https://datasetsearch.research.google.com/" as="https://datasetsearch.research.google.com/">Google Dataset Search</a> provides a nice interface for searching and discovering datasets (in fact, <a href="https://datasetsearch.research.google.com/search?query=opd%20crimes&amp;docid=jrM9a8yTUXMZaY1QAAAAAA%3D%3D" as="https://datasetsearch.research.google.com/search?query=opd%20crimes&amp;docid=jrM9a8yTUXMZaY1QAAAAAA%3D%3D">it even includes Splitgraph repositories</a>). The problem is, the data is fragmented and siloed across different data portals. It's nice to be able to search for data and download a CSV file. But most datasets are uninteresting in isolation. The real power comes from the ability to combine datasets and query them together.</p><p>Splitgraph does not only provide an index for discovering open data. It also provides the tools for composing open datasets together. For example, mounting the data from the <a href="https://data.cambridgema.gov/" as="https://data.cambridgema.gov">Cambridge</a> and <a href="https://data.cityofchicago.org/" as="https://data.cityofchicago.org">Chicago</a> data portals is as simple as running two commands:</p><pre><code metastring=""><span><span>$</span> <span>sgr <span>mount</span> socrata chicago -o <span>'{"domain": "data.cityofchicago.org"}'</span></span></span>
<span>Connecting to remote server...
Mounting Socrata domain...
Getting Socrata metadata
warning: Requests made without an app_token will be subject to strict throttling limits.
Loaded metadata for 504 Socrata tables

</span><span><span>$</span> <span>sgr <span>mount</span> socrata cambridge -o <span>'{"domain": "data.cambridgema.gov"}'</span></span></span>
<span>Connecting to remote server...
Mounting Socrata domain...
Getting Socrata metadata
warning: Requests made without an app_token will be subject to strict throttling limits.
Loaded metadata for 137 Socrata tables
</span></code></pre><p>At this point, all the datasets in these two data portals are available for querying. You can query them in isolation, or you can query them together. You can use a Splitfile, <code>sgr sql</code>, or any standard SQL client:</p><p><a href="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png" as="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png"><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png" alt="DBeaver overview"></a></p><p>Here's how you can compare daily COVID cases in Chicago and Cambridge (from two separate data portals) with a standard <code>JOIN</code> query:</p><pre><code metastring=""><span>SELECT</span>
    cambridge_cases<span>.</span><span>date</span> <span>AS</span> <span>date</span><span>,</span>
    chicago_cases<span>.</span>cases_total <span>AS</span> chicago_daily_cases<span>,</span>
    cambridge_cases<span>.</span>new_positive_cases <span>AS</span> cambridge_daily_cases
<span>FROM</span>
    chicago<span>.</span>covid19_daily_cases_and_deaths_naz8_j4nc chicago_cases
<span>FULL</span> <span>OUTER</span> <span>JOIN</span>
    cambridge<span>.</span>covid19_cumulative_cases_by_date_tdt9_vq5y cambridge_cases
<span>ON</span>
    date_trunc<span>(</span><span>'day'</span><span>,</span> chicago_cases<span>.</span>lab_report_date<span>)</span> <span>=</span> cambridge_cases<span>.</span><span>date</span>
<span>ORDER</span> <span>BY</span> <span>date</span> <span>ASC</span><span>;</span>
</code></pre><p>(For more details and in-depth instructions, see the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW documentation</a>.)</p><p>Note that this is not limited to combining multiple public datasets. Often, the work of a data analyst includes combining internal data with public or licensed datasets from external vendors. The same semantics of "mounting" data in Splitgraph apply.</p></section><section><h2 id="mounting-vs-cloning-data">Mounting vs. Cloning Data</h2><p>With Splitgraph, there are two primary ways to ingest data: cloning it or mounting it.</p><p><a href="https://www.splitgraph.com/docs/working-with-data/clone-vs-checkout">"Cloning" (and checking-out)</a> an image means downloading a versioned data image, which is a snapshot of a database comprised of delta-compressed diffs. For example, the result of running a Splitfile is an image.</p><p>"Mounting" means establishing a connection to a live data source. The term comes from the idea of "mounting" a filesystem. A mounted table uses a <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction">foreign data wrapper</a> (FDW), and you don't ingest data from it until you query it. For example, the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW</a> translates SQL queries to <a href="https://dev.socrata.com/docs/queries/" as="https://dev.socrata.com/docs/queries/">SoQL queries</a> and forwards them to the Socrata server.</p><p>(For more details on mounting data, FDWs and custom mount handlers, read our recent <a href="https://www.splitgraph.com/blog/foreign-data-wrappers">"foreign data wrappers" blog post</a>.)</p></section><section><h2 id="mounting-data-in-splitgraph-cloud">Mounting data in Splitgraph Cloud</h2><p>Mounting is the key abstraction that allows Splitgraph Cloud to index external repositories with features like an auto-generated REST API. On the backend, the "query API" (a subject for a later post) uses the Splitgraph library and Socrata mount handler to mount repositories on demand. Then it exposes the mounted schemata to a customized version of <a href="http://postgrest.org/" as="http://postgrest.org/">PostgREST</a> which creates the API.</p><p>Separately, a periodic Airflow task queries the Socrata metadata API to discover and index over 40,000 repositories. Conveniently, the same Socrata software powers over 200 government open-data portals, so one mount handler provides a large catalog of useful live data.</p></section><section><h2 id="avoiding-the-pull-of-data-gravity">Avoiding the pull of Data Gravity</h2><p>Mounting is a powerful abstraction because it allows you to interact directly with upstream data sources, avoiding the need for ETL. In 2010, GE Engineer Dave McCrory coined the term "<a href="https://datagravitas.com/2010/12/07/data-gravity-in-the-clouds/" as="https://datagravitas.com/2010/12/07/data-gravity-in-the-clouds/">data gravity</a>." In his blog post, he observed that "data if large enough can be virtually impossible to move."</p><p>Splitgraph, as a data versioning solution, should work with all your data, not just the subsets of it that you can move. Traditional ETL tools force you to ingest or duplicate your data before you can interact with it. With Splitgraph, you only need to pull upstream data into your images at query time. This allows incremental adoption and quick experimentation; there is no need to move your data warehouse to start using Splitgraph. Instead, you only need to setup an FDW.</p><p>Note that the idea of data gravity applies to versioned data images (which you clone) as much as it does to upstream, live data (which you mount). What if you want to import only a subset of data from a large image? This is the use case for <a href="https://www.splitgraph.com/docs/large-datasets/layered-querying">layered querying</a>, which allows you to "check out" an image without downloading it. Instead, Splitgraph creates an FDW that queries only the "layers" of the image necessary to satisfy the query. You can think of layered querying like a mount handler for Splitgraph images.</p></section><section><h2 id="looking-to-the-future">Looking to the future</h2><p>At the moment, Splitgraph Cloud only uses the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW</a> as a mount handler for external repositories, since the <a href="https://www.tylertech.com/products/socrata" as="https://www.tylertech.com/products/socrata">Socrata data platform</a> powers most government open-data portals.  In the future, it could use additional mount handlers to provide access to a wider array of upstream sources. To create an external repository, Splitgraph just needs a suitable FDW and a way to index the upstream data. For example, it's easy to imagine indexing Google BigQuery datasets. More interestingly, an on-premise version of Splitgraph could index private databases or data warehouses behind a firewall.</p><p>Our goal for Splitgraph is to make tools for data science as easy and pleasurable to use as tools for coding. That's why our main philosophy is to "stay out of the way." Mounting data is a great example of this philosophy in action. Why force your data warehouse to talk to Splitgraph, when Splitgraph can talk to your data warehouse?</p><p>In the meantime, make sure to <a href="https://www.splitgraph.com/explore">explore data</a> on Splitgraph. If you know SQL, you can <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">get started</a> in less than 10 minutes.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/40k-sql-datasets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820382</guid>
            <pubDate>Mon, 13 Jul 2020 13:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wallet fingerprinting nearly a third of all Bitcoin transactions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820109">thread link</a>) | @b10c
<br/>
July 13, 2020 | https://b10c.me/mempool-observations/3-blockchaincom-recommendations/ | <a href="https://web.archive.org/web/*/https://b10c.me/mempool-observations/3-blockchaincom-recommendations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p>Transactions sent with Blockchain.com wallets make up for about a third of all
Bitcoin transactions. A methodology to identify these transactions is described
and used. Insights about the wallet-usage are derived from the resulting
dataset. The privacy implications and possible improvements are discussed.</p>
<hr>
<p>One of the first observations made when building the <a href="https://mempool.observer/monitor">Bitcoin Transaction
Monitor</a> was that many transactions precisely follow the recommendations of
a feerate estimator. These transactions appear as horizontal bands, which rise
and sink as the feerate recommendations change.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/bands.png" alt="Transactions following the Blockchain.com feerate recommendations">
    <figcaption><center></center></figcaption>
</figure>
    
<p>Most of these transactions share the same fingerprint. Only P2PKH outputs are
spent. No SegWit and neither multisig are spent. With every transaction, either
one or two outputs are created. When two outputs are created, then at least one
of them is a P2PKH output. The transactions are not time-locked, have a version
of one, and do not signal <a href="https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki">BIP-125 replaceability</a>. However, all are
<a href="https://github.com/bitcoin/bips/blob/master/bip-0069.mediawiki">BIP-69</a> compliant.</p>
<p>This matches the fingerprint of the Blockchain.com wallets: namely a Web, an
iOS, and an Android wallet. The wallets can only receive and spend P2PKH
outputs. While users can pay to all address formats<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the change-output, if
created, is a P2PKH output. The wallets construct the transactions with a
locktime of zero and a transaction version of one. The inputs and outputs are
all lexicographically sorted as specified by BIP-69.</p>
<p>The wallets use the Blockchain.com feerate estimator, which is publicly
accessible via <a href="https://b10c.me/blog/003-a-list-of-public-bitcoin-feerate-estimation-apis/#blockchaininfo-api">an API</a>. The API returns two feerate estimates: <em>priority</em>
and <em>regular</em>. The <em>priority</em> feerate aims for confirmation in the next hour
and the <em>regular</em> feerate for confirmation in an hour or more. By default,
the wallets follow the recommendations closely. Users can set a custom feerate,
but a warning is displayed.</p>
<h3 id="methodology">Methodology</h3>
<p>Combining the feerate estimates and the transaction fingerprints makes it
possible to identify transactions sent with one of the Blockchain.com wallets.
While the majority of the Blockchain.com transactions pay exactly the
recommended feerate, some under- or overpay by a fixed percentage. This is
caused by incorrect assumptions about the transaction size during the
calculation of the transaction fee. The transaction fee is the product of the
targeted feerate and the assumed transaction size. The final and actual
transaction size is only known after adding the signature to the transaction.</p>
<pre>fee  =  target feerate  ×  assumed transaction size
</pre>
<p>All underpaying transactions have two outputs. However, during the fee
calculation, the size of a one-output transaction is assumed. For example, for a
P2PKH <em>1in ⇒ 2out</em> transaction (226 bytes), the size of a <em>1in ⇒ 1out</em>
transaction (192 bytes) is used. This incorrect assumption results in the
transaction only paying around 85% (192 byte / 226 byte) of the recommended
feerate. As the transaction inputs make up for a large part of the transaction
size, the effect is smaller for transactions with more inputs. This behavior was
only present in the Blockchain.com Web wallet. A fix was <a href="https://github.com/blockchain/blockchain-wallet-v4-frontend/releases/tag/v4.32.6">released</a> on
April 21st, 2020.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/over-underpaying.png" alt="Transactions over- and underpaying by a fixed percentage">
    <figcaption><center></center></figcaption>
</figure>
    
<p>The overpaying transactions all have a single output. For these, a second output
is assumed during the fee calculation. To calculate the fee of a P2PKH
<em>1in ⇒ 1out</em> transaction (192 bytes), the size of a <em>1in ⇒ 2out</em> transaction
(226 bytes) is used. This results in the transaction paying about 118% (226 byte
/ 192 byte) of the recommended feerate. Similar to the underpaying transactions,
the effect is smaller for transactions with more inputs. These transactions are
assumed to originate from the Blockchain.com iOS wallet. This has not yet been
confirmed.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/methodology.png" alt="Visual explainer for methodology used to identify Blockchain.com transactions">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    Out of the set of transactions with the Blockchain.com wallet fingerprint, the
transactions paying the feerate recommended by the Blockchain.com feerate
estimator are selected. Transactions broadcast on April 19th, 2020, are shown.
The y-axis is centered around the <em>regular</em> recommendation, which was 3
sat/vbyte for most of the day. Between 12:00 UTC and 17:00 UTC, the <em>regular</em>
recommendation briefly jumped to 4 sat/vbyte for a few minutes each. On other
days the feerate recommendations are usually  more volatile. April 19th is a
Sunday. Sundays are known for less network activity compared to weekdays. This
day has been specifically chosen to showcase the methodology.
</p>
<p>Identifying Blockchain.com wallet transactions with this methodology is not
assumed to be perfectly accurate or reliable. For example, transactions send
with a custom feerate can not be identified and are false negatives.
Transactions constructed by different wallets that pay a similar feerate and
share the fingerprint could be identified as false positives. When the
recommended feerate is volatile, which is often the case for the <em>priority</em>
recommendation (for example, shortly after <a href="https://b10c.me/mempool-observations/2-bitmex-broadcast-13-utc/">the daily BitMEX broadcast</a>),
then some transactions might pay a feerate not recoded by the Bitcoin
Transaction Monitor. Additionally, the wallets could construct a transaction
using an older recommendation, which is different from the recommendation at the
time the transaction is broadcast. These transactions are false negatives as
well.</p>
<h3 id="observations">Observations</h3>
<p>The described methodology is used to identify the transactions send with
Blockchain.com wallets between April 1st and May 20th, 2020. The resulting
dataset spans over 50 days and contains about 4 million transactions. These pay
a total fee of 445.73 BTC and account for about 1.34 GB of block space. Roughly
two-thirds of the Blockchain.com wallet transactions target the <em>regular</em> feerate
while the remaining third targets the <em>priority</em> feerate.</p>
<p>Roughly the same number of outputs are created as are spend. Blockchain.com
wallet transactions have either a single payment-output or a payment-output and
a change-output. As the change-outputs are always P2PKH outputs, it is possible
to determine the payment-output type. Out of all outputs created about 31.7% are
P2PKH, 23.3% are P2SH, 0.34% are P2WPKH, and less than 0.01% are P2WSH
payment-outputs. The remaining 45.5% are P2PKH change-outputs. The most commonly
used input-output combinations are <em>P2PKH ⇒ P2PKH + P2PKH</em> with 33%,
<em>P2PKH ⇒ P2SH + P2PKH</em> with 26%, and <em>P2PKH ⇒ P2PKH</em> with around 7%.</p>
<br>
<!-- raw HTML omitted -->
<p>Users of the Blockchain.com wallet are most active between 15:00 UTC and 18:00
UTC and least active between 4:00 UTC and 5:00 UTC. At around 5:00 UTC, the
number of transactions per minute starts to rise. At this time it is 8am in
Moscow, and 7am in central Europe. Between 5:00 UTC and 10:00 UTC, the number
of transactions per minute rises from about 30 to just above 60. The
transactions per minute remain constant until rising again at noon UTC, which is
8am on the US east coast. The daily maximum is reached at around 16:00 UTC with
just above 75 transactions per minute. From there on, the activity declines
until reaching the minimum number of transactions per minute at around 4:00 UTC
again.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/time-of-day.png" alt="Activity hours of Blockchain.com wallet users.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    The transactions broadcast per minute with Blockchain.com wallets are shown. The
error bands show the standard deviation. The time between 8am and 8pm is
marked for central Asia, Europe, and eastern US timezones.
</p>
<br>
<!-- raw HTML omitted -->
<p><a href="https://thecryptofeed.net/articles/blockchain-com-says-they-account-for-a-third-of-all-bitcoin-transactions/">Reportedly</a>, Blockchain.com claims that their wallets are responsible for
one-third of all Bitcoin transactions. They <a href="https://www.blockchain.com/charts/my-wallet-n-tx">publish</a> the daily number of
transactions sent by their wallets. This lead to a discussion on the accuracy
and correctness of these numbers. The described dataset can be used to verify
this claim. The number of daily transactions in the dataset and the published
numbers can be compared. The total number of transactions sharing the
fingerprint with the Blockchain.com wallet transactions acts as an upper-bound.
The total transactions per day are retrieved from <a href="https://transactionfee.info/charts/transactions-per-day/">transactionfee.info</a> to
calculate Blockchain.com’s share of the network.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/one-third.png" alt="Showing that the Blockchain.com published numbers could be reasonably accurate.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>The daily transaction count published by Blockchain.com translates into a
network share of 30% to 35%. The share of the transactions with the same
fingerprint, the upper-bound, is on average about three absolute percent higher.
The share of the identified transactions in the dataset is about four to five
absolute percent lower than the Blockchain.com reported numbers at around 27% on
average. The transactions account for about 13% of the daily fees paid, and 20%
of the daily block space used.</p>
<p>However, the numbers reported by Blockchain.com still lie in a reasonable range.
There are multiple reasons why the described dataset could contain fewer
transactions than are reported by Blockchain.com. Some users might send
transactions with a custom feerate. These are not picked up by the described
methodology. Furthermore, it’s not clear if the reported numbers include
transactions send with the <a href="https://www.blockchain.com/de/api/blockchain_wallet_api">Blockchain.com Wallet API</a>. The API allows
users to construct transactions sending to multiple recipients which are not
accounted for in the described dataset.</p>
<br>
<!-- raw HTML omitted -->
<p>With the knowledge that the Blockchain.com Web wallet underpaid the recommended
feerate for transactions with two outputs, and the iOS wallet
overpays on transactions with one output, the wallet’s shares can be estimated.
For this, the assumption that the ratio of two-output to one-output transactions
is similar in all wallets must hold. The Web wallet accounts for one-third and
the iOS wallet for half of the Blockchain.com wallet transactions. The Android
wallet probably accounts for a majority of the remaining 17%. However, this can
not be verified as no data is indicating the share of the Android wallet.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/web-wallet-share.png" alt="Share of Web wallet transactions with two outputs.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    Between April 1st and April 22nd, the two-output transactions send with the Web
wallet made up for about a third of all two-output transactions send with
Blockchain.com wallets. The shown mean is weighted with the transaction counts.
A fix <a href="https://github.com/blockchain/blockchain-wallet-v4-frontend/releases/tag/v4.32.6">released</a> on April 21st resolved the underpaying behavior for
two-output transactions in the Web wallet. It took a few days until the release
got deployed.
</p>
<figure></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://b10c.me/mempool-observations/3-blockchaincom-recommendations/">https://b10c.me/mempool-observations/3-blockchaincom-recommendations/</a></em></p>]]>
            </description>
            <link>https://b10c.me/mempool-observations/3-blockchaincom-recommendations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820109</guid>
            <pubDate>Mon, 13 Jul 2020 12:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU: A Heuristic for Bad Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23819964">thread link</a>) | @some_furry
<br/>
July 13, 2020 | https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>If you see the letters GNU in a systems design, and that system intersects with cryptography, I can almost guarantee that it will be badly designed to an alarming degree.</p>



<p>This is as <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">true of GnuPG (and PGP in general)</a> as it is of designs like the proposed <a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html">GNU Name System</a> (IETF draft) and cryptographic libraries like GnuTLS and libgcrypt. In fact, I cannot recall single GNU-branded cryptography project that isn’t a roaring dumpster fire.</p>



<p>I will elaborate.</p>



<h2>Problems with the GNU Name System’s Cryptography</h2>



<h3>Asymmetric Cryptography</h3>



<p>The GNS (GNU Name System) uses an unconventional construction for zones:</p>



<blockquote><p>A zone in GNS is defined by a public/private ECDSA key pair (d,zk), where d is the private key and zk the corresponding public key. GNS employs the curve parameters of the twisted edwards representation of Curve25519 [<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC7748">RFC7748</a>] (a.k.a. edwards25519) with the ECDSA scheme ([<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC6979">RFC6979</a>]).</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-zones">GNU Name System IETF Draft, section 2</a></cite></blockquote>



<p>This is beyond weird: Going out of your way to use the edwards25519 curve from RFC 7748, but not use the Ed25519 signature algorithm, but still choosing to use deterministic ECDSA (RFC 6979).</p>



<p>(If you’re lost, I wrote about digital signature algorithms in <a href="https://soatok.blog/2020/04/26/a-furrys-guide-to-digital-signature-algorithms/">a previous blog post</a>.)</p>



<p>The authors acknowledge the unconventional nature of their design choice in section 9.1 of the RFC draft:</p>



<blockquote><p>GNS uses ECDSA over Curve25519. This is an unconventional choice, as ECDSA is usually used with other curves. However, traditional ECDSA curves are problematic for a range of reasons described in the Curve25519 and EdDSA papers. <strong>Using EdDSA directly is also not possible, as a hash function is used on the private key which destroys the linearity that the GNU Name System depends upon.</strong> We are not aware of anyone suggesting that using Curve25519 instead of another common curve of similar size would lower the security of ECDSA. GNS uses 256-bit curves because that way the encoded (public) keys fit into a single DNS label, which is good for usability.</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-cryptography">GNU Name System IETF Draft, section 9.1</a></cite></blockquote>



<p><s>The bold statement (my emphasis) is nonsense: In any design that uses digital signature algorithms, your system should map a private key (some opaque byte string) to a public key (some other opaque byte string) and signatures should also be opaque byte strings. The inclusion of a hash function under the hood of the signature algorithm is a moot point, especially since RFC 6979 also uses HMAC-SHA2 to generate deterministic nonces, thereby rendering their choice of RFC 6979 a contradiction of their stated goal.</s> Edit: <a href="#update-2020-07-09">see below</a>.</p>



<p>Using Ed25519 with a 32-byte private key (instead of a 64-byte private key) is also trivial. To wit: Libsodium offers <a href="https://libsodium.gitbook.io/doc/public-key_cryptography/public-key_signatures#key-pair-generation">crypto_sign_seed_keypair()</a> for this purpose.</p>



<p>But even worse: ECDSA is less secure and slower than EdDSA, even when you use the same curves, due to how the algorithms are implemented. The authors of the RFC do not defend this design choice beyond this hash function non sequitur.</p>



<div><figure><img data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I can’t be the only one feeling this way right now. Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.</figcaption></figure></div>



<h4 id="update-2020-07-09">(Update) “But They Need Hierarchical Keys”</h4>



<p>After I initially posted this, Redditor Steve132 informed me that <a href="https://www.reddit.com/r/crypto/comments/hnlyp1/gnu_a_heuristic_for_bad_cryptography/fxdbez4/">I overlooked the reason they made this design decision</a>.</p>



<blockquote><p>Take a look at Section 6.1&nbsp;<a rel="noreferrer noopener" href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion" target="_blank">https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion</a></p><blockquote><p>From here, the following steps are recursively executed, in order: Extract the right-most label from the name to look up. Calculate q using the label and zk as defined in Section 4.1.</p></blockquote><p>So then if you go to section 4.1, they do h=H(&lt;address string&gt;), (r,R) is some root keypair, then they do C (a child public key), C=hR, then q=H(C).</p><p>the idea behind the calculation of q is to use the root public key to derive a child public key from ONLY the root public key, exploiting the linearity property that in elliptic curves, if bG=B, then (b+s)G=(sG+B)</p><p>This allows a third party to derive child public keys without any knowledge of the private keys for the root. This technique is also used in bitcoin’s bip32 (<a rel="noreferrer noopener" href="https://en.bitcoin.it/wiki/BIP_0032" target="_blank">https://en.bitcoin.it/wiki/BIP_0032</a>) for ‘unhardened’ derivation scheme.</p><cite>Part of Steve132’s correction</cite></blockquote>



<p>I fully admit, I didn’t absorb this detail in my first pass of the RFC draft. It wasn’t clearly spelled out in Section 9 (which aims to justify their cryptography decisions), and I didn’t read the other sections as carefully. This was my mistake.</p>



<p>However, even with this explanation in mind, my original point that this design choice is both unconventional and unnecessary still stands, because <a href="https://ieeexplore.ieee.org/abstract/document/7966967?section=abstract">BIP32-Ed25519</a> already exists (albeit, it still needs <a href="https://forum.web3.foundation/t/key-recovery-attack-on-bip32-ed25519/44">a carefully designed implementation</a> to be secure against active attackers). </p>



<p>Therefore, the GNU Name System developers didn’t need to roll their own design, they could have used one that’s already seen real-world deployment instead. Why take on unnecessary risk?</p>



<p>Furthermore, trying to push through an implementation of ECDSA over edwards25519 isn’t just unnecessary and weird, it’s also probably dangerous, as Thai Duong noted:</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">While I don't agree that ECDSA is worse than Ed25519 – both have pros and cons — it takes courage to implement ECDSA over Edward25519. Do you know if they published any code?  This unfortunate marriage may introduce fun and unique bugs</p>— thaidn (@XorNinja) <a href="https://twitter.com/XorNinja/status/1281041946538938368?ref_src=twsrc%5Etfw">July 9, 2020</a></blockquote></div>
</div><figcaption>Thai Duong–author of the BEAST attack against SSL/TLS, among <a href="https://github.com/google/tink">other</a> <a href="https://github.com/google/wycheproof">things</a></figcaption></figure>



<p>Of course, all cryptography development can be said to be dangerous, but there are other problems fundamental to the GNU Name System design that makes any departure from a well-tread path very suspect.</p>



<h3>Symmetric Cryptography</h3>



<p>The GNU Name System project doesn’t stop there. It further throws <a href="https://tonyarcieri.com/all-the-crypto-code-youve-ever-written-is-probably-broken">IND-CCA2 security</a> out the window and specifies encrypting with AES and TwoFish in a cipher cascade, using Cipher Feedback (CFB) mode.</p>



<p>The authors do not even attempt to defend this decision. Typically this happens when the authors do not understand the risks involved. I sincerely doubt they’ve heard the words “adaptive chosen-ciphertext attack” in the course of their self-study.</p>



<p>(Because, y’know, attackers will surely never be able to replay UDP traffic if a runtime exception occurs because of corrupted data.)</p>



<h4>“Why Is This Bad?”</h4>



<p>Cipher cascades are usually the result of “we want to defend against a backdoored or broken cipher”. Bear in mind, the cipher itself is rarely the first part of a cryptosystem to be broken.</p>



<p>On that note, TwoFish isn’t <a href="https://blog.cryptographyengineering.com/2012/10/09/so-you-want-to-use-alternative-cipher/">the worst choice</a> of a cascade partner for AES, but I’d prefer a design that employed a different paradigm (since AES is a SPN permutation block cipher, an ARX-based stream cipher like Salsa20 or ChaCha seems reasonable).</p>



<p>AES is a boring choice, because it’s the industry standard. I’m not <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">particularly fond of AES</a> (due to it not being fast and constant-time in pure software implementations), but if you use it in an authenticated mode (AES-GCM, AES-CCM, AES-EAX, AES-OCB3, … I dunno, Poly1305-AES? Just use an AEAD mode!), it’s fine.</p>



<p><strong>Cipher Feedback (CFB) mode is not an authenticated mode.</strong></p>



<p>If you’re publishing a cryptography design in 2020 that fails the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>, you need to go back to the drawing board.</p>



<h4>“But They Use Digital Signatures”</h4>



<p><a href="https://blog.cryptographyengineering.com/2016/03/21/attack-of-week-apple-imessage/">Cough.</a></p>







<h2>Other GNU Projects</h2>



<p>If you want to learn about why GnuPG (and the PGP ecosystem in general) is terrible, I recommend <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">Latacora’s takedown</a>.</p>



<p>GnuTLS is an SSL/TLS library created by the same people who created (and then abandoned) libmcrypt, which was the scourge of <a href="https://meta.stackoverflow.com/questions/293930/problematic-php-cryptography-advice-in-popular-questions">bad cryptography in the PHP ecosystem</a> for many years (until it was <a href="https://wiki.php.net/rfc/mcrypt-viking-funeral">finally excised in PHP 7.2</a>). Consequently, the project’s <a href="https://www.gnutls.org/security-new.html">CVE history</a> should be no surprise.</p>



<p><strong>Quick story:</strong> Many years ago, a few timing attacks were discovered in libgcrypt by regular chatters in Freenode’s ##crypto channel. This led a lot of us <a href="https://lists.gnupg.org/pipermail/gcrypt-devel/2015-November/003618.html">to look at libgcrypt for more bugs</a>.</p>



<p>The general consensus of the ensuing IRC discussion was, roughly, “We probably shouldn’t try to fix them all, because a) that’s way too much effort because there’s too much badness and b) this library will be a ripe target for upcoming cryptanalysis researchers to get their first papers published for many years”. And, indeed, the attack papers that have come out over the years that affect libgcrypt <a href="https://eprint.iacr.org/2020/432">haven’t disappointed</a>.</p>



<p>To be clear, at the time this happened, I was garbage at writing C (and somehow even less confident than capable) and barely making ends meet, so “drop everything and volunteer to fix all the libgcrypt badness” wasn’t a tenable option for me. And since the world is largely moving away from GnuPG and libgcrypt, it honestly isn’t worth the effort trying to fix all the bad when an easier fix is “use something good instead”.</p>



<h2>Takeaway</h2>



<p>If you see the letters GNU anywhere in a project that intersects with cryptography–except for its public license–it’s almost certainly an error-prone cryptographic design.</p>



<p>Or, as my friend Kye calls it:</p>



<figure><div>

</div><figcaption>The Dunning-GNUger Effect.</figcaption></figure>



<h2>What To Use Instead?</h2>



<p>To replace GPG, you want <a href="https://age-encryption.org/">age</a> and <a href="https://jedisct1.github.io/minisign/">minisign</a>.</p>



<p>To replace GnuTLS or libgcrypt, depending on what you’re using it for, you want one of the following: s2n, OpenSSL/LibreSSL, or Libsodium.</p>



<p>For embedded systems, BearSSL is a good options today and <a href="https://www.reddit.com/r/crypto/comments/hdc4o6/new_results_on_gimli_fullpermutation/fvmpnym/">libhydrogen v2</a> will be an attractive choice when it’s released.</p>



<hr>



<p>Header image, like the GnuNet logo <a href="https://commons.wikimedia.org/wiki/File:Official_logo_of_the_GNUnet_project.svg">found here</a>, is available under the&nbsp;<a href="https://en.wikipedia.org/wiki/en:Creative_Commons">Creative Commons</a>&nbsp;<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">Attribution-Share Alike 4.0 International</a>&nbsp;license.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819964</guid>
            <pubDate>Mon, 13 Jul 2020 12:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Douglas Mason: How to Build ML Solutions for Twitter, Pinterest and Amazon Music]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819921">thread link</a>) | @FHMS
<br/>
July 13, 2020 | https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We caught up with <a href="https://www.linkedin.com/in/douglas-mason-9a500713/"><strong>Douglas Mason</strong></a>, data scientist and CEO of <a href="https://www.koyotescience.com/">Koyote Science</a>, where he is building machine learning models to predict COVID-19 outbreaks. He freely shared his wisdom and lessons he has learned from over a decade of data science work, ranging from his PhD at Harvard to his time at large companies such as Pinterest, Twitter, and AWS (Amazon).</p><h2><strong>Douglas’s background</strong></h2><p>Douglas took a unique path to becoming a data scientist. Although computers were always part of his household growing up, he thought they were boring, and he told his family he would “never study computer science.”</p><p>Instead, Douglas went to USC to study filmmaking, thinking he’d follow his dream of becoming a film director. Soon, he realized that filmmaking school wasn’t all he’d imagined it would be, and he took up classical guitar instead. From there, he accidentally discovered a passion for theoretical physics, which he found fascinating (and which paid more than guitar playing).</p><p>Not long after, Douglas discovered his interest in data science and climbed the ranks until he was heading engineering and data science teams at Twitter, Pinterest, and AWS. He describes working in the field as feeling like he’s living in a science fiction film.</p><blockquote>“When I work on that kind of stuff, I feel like Doctor Strange — as if I’m in the Multiverse. You actually get to live this Rick and Morty parallel-universe life.”</blockquote><p>But Douglas wasn’t content with using his expertise to improve revenue at large corporations, so he went on to found his own business, Koyote Science. He’s currently focused on building COVID-19 models to predict outbreaks.</p><h2><strong>Lessons learned from shipping machine learning projects</strong></h2><p>Douglas’s success hasn’t come without some hard-earned lessons. He told us about some of the challenges he’s seen across many of the teams and projects he’s worked on.</p><h3><strong>Lesson 1: Use machine learning to work with users instead of taking over&nbsp;</strong></h3><p>At Twitter, Douglas worked on a feature called “who to follow.” This gives Twitter users personalized recommendations about which accounts might be interesting for them. As a data scientist, Douglas discovered that people used this feature a lot. At first, it seemed great — people were following nearly everyone it recommended. But in the longer term, people who used this feature <strong>visited Twitter less</strong>.&nbsp;</p><p>Their feeds were filled with tweets chosen <strong>by an algorithm</strong>, rather than tweets from people they chose<strong> </strong>themselves — and there were just too many of them.</p><p>By reducing<strong> </strong>the number of “who to follow” recommendations, Douglas improved <strong>long-term</strong> engagement.</p><p>It’s common knowledge that long-term and short-term goals often conflict, but Douglas discovered a deeper lesson here. As machine learning solutions become more capable, it’s often tempting to use them to do too much. This is almost always a mistake. Douglas says:</p><blockquote>“I aim to build products that work with the user rather than trying to take over from the user.”</blockquote><p>AI as depicted in science fiction — with human-level intelligence — is probably to blame for the fact that many people try to <strong>do too much </strong>with machine learning. In many cases, it’s best used to <strong>augment </strong>human actions rather than replace them.</p><h3><strong>Lesson 2: Data pipelines and good engineering are more important than math and algorithms</strong></h3><p>People get very excited about <strong>new machine learning algorithms</strong>. First we had neural networks (NNs), then convolutional neural networks (CNNs), then generative adversarial networks (GANs), transformers, and more. Algorithms are fun and exciting to talk about and explore.</p><p>But Douglas, a self-confessed math nerd, has learned that the math and algorithms tend to get far too much attention, while real success comes from <strong>good data, good engineering, focusing on the customer’s problem, </strong>and <strong>not getting trapped in the math.</strong> He says:</p><blockquote>“It's very, very rare for the algorithm to make the difference. It's almost always the data pipeline. In my work, I have been able to reduce errors by 90% with a data pipeline, compared to 75% with a better algorithm. And yet everyone wants to talk to me about the algorithm, but no one wants to talk about the data pipeline.”</blockquote><p>We use metaphors that associate machine learning algorithms with neuroscientists and data pipelines with plumbing, so it’s not surprising which one grabs popular attention. Douglas found success by focusing on the less glamorous aspects of machine learning. In most cases, deciding <strong>what data to use </strong>and <strong>how to present it to the algorithm</strong> is more important than the algorithm itself.</p><h4>Focus on the customer’s goals</h4><p>Many “AI startups” today talk far more about <strong>the solutions they provide</strong> than the <strong>problems they solve</strong>, and Douglas has learned to maintain a laser focus on customer goals. Sometimes this means pulling himself away from the more enticing theoretical aspects of machine learning. He says:&nbsp;</p><blockquote>“As a mathematician, I love all the nuances of the math, and easily get lost in it. But the reality is that there's an infinite amount of math out there to learn. It's not feasible to lock myself in my room and learn all the math before I focus on customer goals.”</blockquote><p>The truth that many data scientists don’t want to hear is that successful machine learning solutions are not usually about creating something new, powerful, and exciting. More often, seeing problems from the correct angle and using tried and tested approaches is what you need.</p><h4>Work with and learn from experienced engineers</h4><p>Douglas has personally engineered many successful machine learning solutions and led teams of software engineers, but he remains modest about his engineering ability and emphasizes the <a href="https://datarevenue.com/en-blog/hiring-machine-learning-engineers-instead-of-data-scientists">importance of <strong>solid engineering</strong></a>.</p><blockquote>“At Amazon, I let the engineers do as much as possible, because they're better than me at engineering. I would love to give you another answer, but they're efficient, they're thoughtful, they've seen these structures before, so they know about implementation details.”</blockquote><p>It’s not all smooth sailing though. Douglas acknowledges the difficulties of getting different experts to work with each other, especially when highly technical people tend to have very strong opinions about tiny decisions.</p><p>The best way he’s found to get everyone on the same page is by constantly releasing Minimal Viable Products (MVPs), which takes us to our next lesson.</p><h3><strong>Lesson 3: Always build Minimum Viable Products (MVPs)</strong></h3><p>Douglas swears by MVPs, which demonstrate core pieces of a solution, even if many of the features are missing. When developing a machine learning solution, he’ll aim to deliver a new MVP <strong>every week.</strong></p><p>He uses these to:&nbsp;</p><ul role="list"><li><strong>Avoid traps: </strong>If a project is taking too long, the difficulty of building even an MVP can be used to argue that the project should be cut early, before years of effort are wasted. Douglas says:</li></ul><p>“If something ends up being way harder and I keep doing MVPs and never reach the goals, then that gives us information about the difficulty of what we're attempting to do.”</p><ul role="list"><li><strong>Communicate</strong>: Both technical and non-technical people tend to better understand things they can see and use, rather than abstract ideas.</li></ul><p>“People's response to an abstract concept of something is often completely different to their response when they see something real. That's why I'm always putting out MVPs. People who are looking from a higher-level perspective can gain the required intuition to give me feedback.”</p><p>It’s better to have to trash two weeks of work than two months, and MVPs can help with this.</p><p>MVPs have other benefits too. By releasing stripped-down versions of a solution, Douglas often discovers that less is more.</p><blockquote>“What you end up delivering is often much simpler than the thing you originally intended to do, but it's refined.”</blockquote><p>Of course, customers are sometimes unhappy when it turns out that the best solution was the simplest one. Douglas compares building machine learning solutions to creating art: it’s about the time that went into development, not the effort required for the final product.</p><blockquote>“There’s a classic Zen story about a king who hires an artist. The artist works for a year, but then paints the final painting in only three seconds. When the king complains, the artist says, ‘Oh, I spent a year trying to paint much harder things.’”</blockquote><p>MVPs keep you open to finding a <strong>better, simpler </strong>solution, even late in the development process, and it’s important to stay agile so you can pivot to these better solutions if necessary.</p><p>People often think something has to be <strong>complicated </strong>in order to be <strong>powerful</strong>,<strong> </strong>but in fact the opposite is often true.</p><h3><strong>Lesson 4: Control and precision are more important than size and power</strong></h3><p>Large machine learning models, such as GPT-3, are exciting and often make their way into headline news. But Douglas compares large models to early (failed) attempts to build planes. These planes competed against the famous, successful plane built by the Wright Brothers. What made them different? The Wright Brothers focused on <strong>control</strong>,<strong> </strong>while their competitors were going for <strong>size and power.</strong></p><blockquote>“What the Wright brothers did that was so ingenious was that they didn’t go for bigger engines. They were bicycle mechanics. They didn't even use powerful engines. And instead, what they focused on was control.”</blockquote><p>This is similar to machine learning models. As Douglas says:&nbsp;</p><blockquote>“We made the biggest model that does all this stuff. But then people ask, ‘How do I interpret this stuff?’ ‘How do I control it?’ ‘How do I make sure that my models don't go off the rails?’”</blockquote><p>Large machine learning models might often be more powerful, but unless they solve real problems, they’re not useful. If a model produces amazing results <strong>unpredictably</strong> and only <strong>some of the time</strong>, that’s not useful. If a model produces accurate results but we don’t <strong>understand why</strong> and can’t be sure the results will <strong>always be accurate</strong>, then that’s also not useful.</p><p>Instead, smaller, simpler, and arguably less powerful models that offer more <strong>interpretability</strong> and <strong>consistency</strong> are more valuable in nearly every case. Just like with flying, we need to be able to steer and to land, not just to go fast.</p><h2><strong>Shipping machine learning projects …</strong></h2></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819921</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a Data Delivery Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819918">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/data-delivery-network | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/data-delivery-network">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#how-content-delivery-networks-work" as="#how-content-delivery-networks-work">How content delivery networks work</a></li><li><a href="#why-do-you-need-a-backend-anyway" as="#why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</a><ol><li><a href="#alternatives-to-crud-services" as="#alternatives-to-crud-services">Alternatives to CRUD services</a></li><li><a href="#splitgraphs-architecture" as="#splitgraphs-architecture">Splitgraph's architecture</a></li></ol></li><li><a href="#data-delivery-network" as="#data-delivery-network">Data delivery network</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p>Serverless and edge computing have allowed application developers to bring their applications closer to the end user.</p><p>Instead of maintaining a group of servers in a single location, developers can let companies like Cloudflare, Fastly or Akamai handle their content delivery.</p><p>With <a href="https://en.wikipedia.org/wiki/Function_as_a_service" as="https://en.wikipedia.org/wiki/Function_as_a_service">Function as a service</a>, companies pay for what they use. They can avoid having to provision a server that stays idle most of the time.</p><p>In this article, we want to talk about these trends and how we can apply them to databases. We'll also talk about our decision to make the API for our Splitgraph registry work over a public SQL connection. We'll use this experience to propose the idea of a <strong>data delivery network</strong>.</p><section><h2 id="how-content-delivery-networks-work">How content delivery networks work</h2><p>Content delivery networks provide a straightforward way to scale a read-only HTTP layer. They use existing HTTP cache semantics like the Cache-Control header. The developer only needs to point their DNS records to use the CDN's nameservers. The CDN handles everything else for them. It has points of presence around the world and peering agreements with other ISPs. It can selectively cache data, handle DDoS protection and offer extra services on top.</p><p>The value proposition behind edge computing is simple. For a lot of companies, scaling compute is not their core competency. They can spend time and money provisioning servers and configuring something like Varnish. Or, they can use services that will handle scaling and caching for them.</p><p>However, applications still need to run SQL queries. A CDN doesn't completely help an application that performs client-side rendering. The database becomes the next performance bottleneck in scaling a service.</p><p>There are many ways to scale a database, for example, replication or sharding. But again, this requires specialist knowledge about a database that is easy to get wrong.</p></section><section><h2 id="why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</h2><p>Let's change gears and consider a classic Web application. It consists of the frontend, the backend and the database.</p><p>There are several purposes that a backend serves:</p><ul><li><p><strong>Business logic</strong>. The backend converts higher level API calls into low-level SQL queries. It prepares data for presentation and writes it back when needed.</p></li><li><p><strong>Authorization</strong>. The backend acts as a security barrier, validating API calls. This is necessary because the frontend is running on the user's machine: the client is not trusted.</p></li><li><p><strong>Multiplexing</strong>. A database connection has a larger overhead than an HTTP connection. A backend can shunt hundreds of simultaneous clients over to a few database connections.</p></li></ul><section><h3 id="alternatives-to-crud-services">Alternatives to CRUD services</h3><p>One big issue with writing RESTful backends is that there's a lot of boilerplate. The programmer has to write very similar code to handle every action. They have to care of validation, typechecking and handling edge cases.</p><p>Libraries like <a href="https://postgrest.org/en/latest/" as="https://postgrest.org/en/latest/">PostgREST</a> and <a href="https://www.graphile.org/postgraphile/" as="https://www.graphile.org/postgraphile/">Postgraphile</a> have helped developers decrease iteration times. They introspect database schemas and generate REST and GraphQL APIs for them.</p><p>PostgREST and Postgraphile perform their authorization using database methods like <a href="https://postgrest.org/en/v7.0.0/auth.html" as="https://postgrest.org/en/v7.0.0/auth.html">row level security</a>. In essence, they decrease the size of the <a href="https://en.wikipedia.org/wiki/Trusted_computing_base" as="https://en.wikipedia.org/wiki/Trusted_computing_base">"trusted computing base"</a>.</p><p>Often, services that use these kinds of tools don't even have a separate backend. Client side code can call the automatically generated GraphQL/REST API directly.</p></section><section><h3 id="splitgraphs-architecture">Splitgraph's architecture</h3><p>The database can perform a lot of work that the backend does more quickly and more efficiently.</p><p>We use this idea in the API for the Splitgraph registry that allows you to push and pull <a href="https://www.splitgraph.com/docs/concepts/images">data images</a>. A <a href="https://www.splitgraph.com/docs/architecture/sgr-client">Splitgraph client</a> can access it over a normal PostgreSQL connection to <code>postgresql://data.splitgraph.com:5432/sgregistry</code>.</p><p>Our API implements all <strong>business logic</strong> as PostgreSQL functions. This has a few immediate advantages:</p><ul><li>Lets PostgreSQL precompile them</li><li>Avoids an extra hop from the backend, decreasing latency</li><li>Makes basic validation and type checking trivial. It's not possible to call a function with a wrong number of arguments or different types.</li></ul><p>For more complex logic, we wrote it in higher-level languages like <a href="https://www.postgresql.org/docs/current/plpython.html" as="https://www.postgresql.org/docs/current/plpython.html">PL/Python</a> or PL/Lua. PostgreSQL even supports languages like C or JavaScript.</p><p>We solved the problem of <strong>multiplexing and authorization</strong> by adding <a href="https://www.pgbouncer.org/" as="https://www.pgbouncer.org/">PgBouncer</a>, a connection pooler, in front of our database. Our fork of PgBouncer injects a signed cookie into every transaction as a local variable. Downstream procedures validate this cookie for authentication and authorization. This lets us decouple PostgreSQL users from application users. Multiple inbound sessions can use the same connection.</p><p>Our fork of PgBouncer even inspects queries on the fly and filters them. This makes sure that the client can only call Splitgraph SQL API functions.</p><p>For the web frontend at <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com/">www.splitgraph.com</a>, we use Postgraphile. Besides not having to write an extra API server, it lets us generate TypeScript client code.</p></section></section><section><h2 id="data-delivery-network">Data delivery network</h2><p>We can apply these ideas and concepts to the problem of building a <strong>"data delivery network"</strong>. Such a network would completely abstract away all the issues around making sure that data is available at the edge. It can also provide plenty of other useful services.</p><p>Here's a quick sketch of what a DDN's administration interface would look like:</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200713-data-delivery-network/admin-panel.png"></p><p>To use a DDN, a developer would create a read-only account on their database and give the DDN the credentials. It will then make a few services available:</p><p>The DDN will create an <strong>SQL endpoint</strong>. Any existing SQL client or application will be able to connect to it and run queries.</p><p>Besides SQL, the DDN will also be able to introspect the origin database and provide <strong>REST and GraphQL API endpoints</strong>. A client, running in the user's web browser, can use these endpoints instead of a backend server.</p><p>The DDN will be able to <strong>cache</strong> read-only SQL transactions with configurable policies. It will only forward the query to the origin database if there's a cache miss or expiry.</p><p>The client code doesn't need to be trusted. The DDN can intercept and <strong>firewall</strong> queries or <strong>rate limit</strong> them. To simplify migrations, the DDN can <strong>rewrite</strong> queries on the fly before forwarding them.</p><p>The DDN's work doesn't need to stop at handling queries. It can also manage <strong>data imports and exports</strong>. For example, it can make data from other services available to clients. Or, it can export data to Google Sheets or a data warehouse.</p><p>In the case of Splitgraph, we envision you being able to even run a <code>JOIN</code> across a public Splitgraph image and your private data.</p></section><section><h2 id="conclusion">Conclusion</h2><p>The database is the next frontier of serverless and edge computing. One of Splitgraph's goals is building a data delivery network to handle these problems.</p><p>If you're interested in learning more about Splitgraph, you can check our <a href="https://www.splitgraph.com/docs/getting-started/frequently-asked-questions">frequently asked questions</a> section, follow our <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">quick start guide</a> or visit our <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">website</a>.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/data-delivery-network</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819918</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp GUI Toolkits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819896">thread link</a>) | @ogogmad
<br/>
July 13, 2020 | https://lispcookbook.github.io/cl-cookbook/gui.html | <a href="https://web.archive.org/web/*/https://lispcookbook.github.io/cl-cookbook/gui.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" <p=""><p>Lisp has a long and rich history and so does the development of
Graphical User Interfaces in Lisp. In fact, the first GUI builder was
written in Lisp (and sold to Apple. It is now Interface Builder).</p>

<p>Lisp is also famous and unrivalled for its interactive development
capabilities, a feature even more worth having to develop GUI
applications. Can you imagine compiling one function and seeing your
GUI update instantly? We can do this with many GUI frameworks today,
even though the details differ from one to another.</p>

<p>Finally, a key part in building software is how to build it and ship
it to users. Here also, we can build self-contained binaries, for
the three main operating systems, that users can run with a double
click.</p>

<p>We aim here to give you the relevant information to help you choose
the right GUI framework and to put you on tracks. Don’t hesitate to
<a href="https://github.com/LispCookbook/cl-cookbook/issues/">contribute</a>, to
send more examples and to furnish the upstream documentations.</p>



<p>In this recipe, we’ll present the following GUI toolkits:</p>

<ul>
  <li><a href="https://www.tcl.tk/">Tk</a> with <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a></li>
  <li><a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a> with <a href="https://github.com/Shinmera/qtools">Qtools</a></li>
  <li><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> with <a href="https://github.com/lispnik/iup/">lispnik/iup</a></li>
  <li><a href="https://www.gtk.org/">Gtk3</a> with <a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a></li>
  <li><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> with <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a></li>
</ul>

<p>In addition, you might want to have a look to:</p>

<ul>
  <li>the <a href="http://www.lispworks.com/products/capi.html">CAPI</a> toolkit (Common Application Programming Interface),
which is proprietary and made by LispWorks. It is a complete and cross-platform
toolkit (Windows, Gtk+, Cocoa), very praised by its users. LispWorks
also has <a href="http://www.lispworks.com/products/lw4mr.html">iOS and Android
runtimes</a>. Example
software built with CAPI include <a href="https://scorecloud.com/">ScoreCloud</a>. It is possible to
try it with the LispWorks free demo.</li>
  <li><a href="https://franz.com/products/allegro-common-lisp/acl_ide.lhtml">Allegro CL’s IDE and Common Graphics windowing system</a> (proprietary): Allegro’s IDE is a general environment for developing applications. It works in concert with a windowing system called Common Graphics. The IDE is available for Allegro CL’s Microsoft Windows, on x86 Linux platforms, and on the Mac.</li>
  <li><a href="https://ccl.clozure.com/docs/ccl.html#the-objective-c-bridge">CCL’s built-in Cocoa
interface</a>,
used to build applications such as <a href="https://opusmodus.com/">Opusmodus</a>.</li>
  <li><a href="https://github.com/plkrueger/CocoaInterface/">CocoaInterface</a>, a
Cocoa interface for Clozure Common Lisp. Build Cocoa user interface
windows dynamically using Lisp code and bypass the typical Xcode
processes.</li>
  <li><a href="https://common-lisp.net/project/mcclim/">McCLIM</a> and <a href="https://github.com/earl-ducaine/cl-garnet">Garnet</a> are toolkit in 100% Common Lisp. McClim even has <a href="https://techfak.de/~jmoringe/mcclim-broadway-7.ogv">a prototype</a> running in the browser with the Broadway protocol and Garnet has an ongoing interface to Gtk.</li>
  <li><a href="https://github.com/Shirakumo/alloy">Alloy</a>, another very new toolkit in 100% Common Lisp, used for example in the <a href="https://github.com/shinmera/kandria">Kandria</a> game.</li>
  <li><a href="https://notabug.org/cage/nodgui">nodgui</a>, a fork of Ltk, with syntax sugar and additional widgets.</li>
  <li><a href="https://gitlab.com/eql">eql, eql5, eql5-android</a>, embedded Qt4 and Qt5 Lisp, embedded in ECL, embeddable in Qt. Port of EQL5 to the Android platform.</li>
  <li>this <a href="https://github.com/defunkydrummer/abcl-jazz">demo using Java Swing from ABCL</a></li>
  <li><a href="https://github.com/mifpasoti/Gtk-Demos">examples of using Gtk without C files with SBCL</a>, as well as GTK-server.</li>
  <li>and, last but not least, <a href="http://ceramic.github.io/">Ceramic</a>, to ship a cross-platform web app with Electron.</li>
</ul>

<p>as well as the other ones listed on <a href="https://github.com/CodyReichert/awesome-cl#Gui">awesome-cl#gui</a> and <a href="https://www.cliki.net/GUI">Cliki</a>.</p>

<h2 id="tk-ltk">Tk (Ltk)</h2>

<p><a href="https://www.tcl.tk/">Tk</a> (or Tcl/Tk, where Tcl is the programming language) has the
infamous reputation of having an outdated look. This is not (so) true
anymore since its version 8 of 1997 (!). It is probably better than
you think:</p>

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/gui/ltk-on-macos.png" alt=""></p>

<p>Tk doesn’t have a great choice of widgets, but it has a useful canvas,
and it has a couple of unique features: we can develop a graphical
interface <strong>fully interactively</strong> and we can run the GUI <strong>remotely</strong>
from the core app.</p>

<p>So, Tk isn’t fancy, but it is an used and proven GUI toolkit (and
programming language) still used in the industry. It can be a great
choice to quickly create simple GUIs, to leverage its ease of deployment, or
when stability is required.</p>

<p>The Lisp binding is <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a>.</p>

<ul>
  <li><strong>Written in</strong>: Tcl</li>
  <li>
    <p><strong>Portability</strong>: cross-platform (Windows, macOS, Linux).</p>
  </li>
  <li>
    <p><strong>Widgets</strong>: this is not the fort of Tk. It has a <strong>small set</strong> of
default widgets, and misses important ones, for example a calendar. We
can find some in extensions (such as in <strong>Nodgui</strong>), but they don’t
feel native, at all.</p>
  </li>
  <li>
    <p><strong>Interactive development</strong>: very much.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no</p>
  </li>
  <li><strong>Other features</strong>:
    <ul>
      <li><strong>remote execution</strong>: the connection between Lisp and Tcl/Tk is
done via a stream. It is thus possible to run the Lisp program on
one computer, and to display the GUI on another one. The only
thing required on the client computer is tcl/tk installed and the
remote.tcl script. See <a href="http://www.peter-herth.de/ltk/ltkdoc/node46.html">Ltk-remote</a>.</li>
    </ul>
  </li>
  <li><strong>Bindings documentation</strong>: short but complete. Nodgui too.</li>
  <li><strong>Bindings stability</strong>: very stable</li>
  <li><strong>Bindings activity</strong>: low to non-existent.</li>
  <li><strong>Licence</strong>: Tcl/Tk is BSD-style, Ltk is LGPL.</li>
  <li>Example applications:
    <ul>
      <li><a href="https://notabug.org/cage/fulci/">Fulci</a> - a program to organise your movie collections.</li>
      <li><a href="https://github.com/mijohnson99/ltk-small-games">Ltk small games</a> - snake and tic-tac-toe.</li>
      <li><a href="https://github.com/vindarel/cl-torrents">cl-torrents</a> - searching torrents on popular trackers. CLI, readline and a simple Tk GUI.</li>
    </ul>
  </li>
</ul>

<p><strong>List of widgets</strong></p>

<p>(please don’t suppose the list is exhaustive)</p>

<pre><code>Button Canvas Check-button Entry Frame Label Labelframe Listbox
Menu Menubutton Message
Paned-window
Radio-button Scale
Scrollbar Spinbox Text
Toplevel Widget Canvas

Ltk-megawidgets:
    progress
    history-entry
    menu-entry
</code></pre>

<p>Nodgui adds:</p>

<pre><code>treelist tooltip searchable-listbox date-picker calendar autocomplete-listbox
password-entry progress-bar-star notify-window
dot-plot bar-chart equalizer-bar
swap-list
</code></pre>



<p>Do we need to present Qt and <a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a>? Qt is huge and contains
everything and the kitchen sink. Qt not only provides UI widgets, but
numerous other layers (networking, D-BUS…).</p>

<p>Qt is free for open-source software, however you’ll want to check the
conditions to ship proprietary ones.</p>

<p>The <a href="https://github.com/Shinmera/qtools">Qtools</a> bindings target Qt4. The Qt5 Lisp bindings are
yet to be created.</p>

<p>A companion library for Qtools, that you’ll want to check out once you
made your first Qtool application, is
<a href="https://github.com/Shinmera/qtools-ui">Qtools-ui</a>, a collection of
useful widgets and pre-made components. It comes with short
<a href="https://www.youtube.com/playlist?list=PLkDl6Irujx9Mh3BWdBmt4JtIrwYgihTWp">demonstrations
videos</a>.</p>

<!-- possible future: gobject-introspection -->

<ul>
  <li><strong>Framework written in</strong>: C++</li>
  <li><strong>Framework Portability</strong>: multi-platform, Android, embedded systems, WASM.</li>
  <li>
    <p><strong>Bindings Portability</strong>: Qtools runs on x86 desktop platforms on Windows, macOS and GNU/Linux.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: Web browser, a lot more.</p>
  </li>
  <li><strong>Bindings documentation</strong>: lengthy explanations, a few examples. Prior Qt knowledge is required.</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: active</li>
  <li><strong>Qt Licence</strong>: both commercial and open source licences.</li>
  <li>Example applications:
    <ul>
      <li>https://github.com/Shinmera/qtools/tree/master/examples</li>
      <li>https://github.com/Shirakumo/lionchat</li>
      <li>https://github.com/shinmera/halftone - a simple image viewer</li>
    </ul>
  </li>
</ul>

<h2 id="gtk3-cl-cffi-gtk">Gtk+3 (cl-cffi-gtk)</h2>

<p><a href="https://www.gtk.org/">Gtk+3</a> is the primary library used to build <a href="https://www.gnome.org/">GNOME</a>
applications. Its (currently most advanced) lisp bindings is
<a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a>. While primarily created for GNU/Linux, Gtk
works fine under macOS and can now also be used on Windows.</p>

<ul>
  <li><strong>Framework written in</strong>: C</li>
  <li>
    <p><strong>Portability</strong>: GNU/Linux and macOS, also Windows.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li><strong>Graphical builder</strong>: yes: Glade.</li>
  <li>
    <p><strong>Other features</strong>: web browser (WebKitGTK)</p>
  </li>
  <li><strong>Bindings documentation</strong>: very good: http://www.crategus.com/books/cl-gtk/gtk-tutorial.html</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: low activity, active development.</li>
  <li><strong>Licence</strong>: LGPL</li>
  <li>Example applications:
    <ul>
      <li>an <a href="https://github.com/ralph-schleicher/atmosphere-calculator">Atmosphere Calculator</a>, built with Glade.</li>
    </ul>
  </li>
</ul>

<h2 id="iup-lispnikiup">IUP (lispnik/IUP)</h2>

<p><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> is a cross-platform GUI toolkit actively developed
at the PUC university of Rio de Janeiro, Brazil. It uses <strong>native
controls</strong>: the Windows API for Windows, Gtk3 for GNU/Linux. At the
time of writing, it has a Cocoa port in the works (as well as iOS,
Android and WASM ones). A particularity of IUP is its <strong>small API</strong>.</p>

<p>The Lisp bindings are <a href="https://github.com/lispnik/iup/">lispnik/iup</a>. They are nicely
done in that they are automatically generated from the C sources. They
can follow new IUP versions with a minimal work and the required steps
are documented. All this gives us good guarantee over the bus
factor.</p>

<p>IUP stands as a great solution in between Tk and Gtk or Qt.</p>

<ul>
  <li><strong>Framework written in</strong>: C (official API also in Lua and LED)</li>
  <li>
    <p><strong>Portability</strong>: Windows and Linux, work started for
Cocoa, iOS, Android, WASM.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: medium.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes: <a href="http://webserver2.tecgraf.puc-rio.br/iup/en/iupvisualled.html">IupVisualLED</a></p>
  </li>
  <li>
    <p><strong>Other features</strong>: OpenGL, Web browser (WebKitGTK on GNU/Linux), plotting, Scintilla text editor</p>
  </li>
  <li><strong>Bindings documentation</strong>: good examples and good readme, otherwise low.</li>
  <li><strong>Bindings stability</strong>: alpha (but fully generated and working nicely).</li>
  <li><strong>Bindings activity</strong>: low but steady, and reactive to new IUP versions.</li>
  <li><strong>Licence</strong>: IUP and the bindings are MIT licenced.</li>
</ul>

<p><strong>List of widgets</strong></p>

<pre><code>Radio, Tabs, FlatTabs, ScrollBox, DetachBox,
Button, FlatButton, DropButton, Calendar, Canvas, Colorbar, ColorBrowser, DatePick, Dial, Gauge, Label, FlatLabel,
FlatSeparator, Link, List, FlatList, ProgressBar, Spin, Text, Toggle, Tree, Val,
listDialog, Alarm, Color, Message, Font, Scintilla, file-dialog…
Cells, Matrix, MatrixEx, MatrixList,
GLCanvas, Plot, MglPlot, OleControl, WebBrowser (WebKit/Gtk+)…
drag-and-drop
</code></pre>

<!-- editor's note: found missing a list view with columns. -->

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/iup-demo.png" alt=""></p>

<h2 id="nuklear-bodge-nuklear">Nuklear (Bodge-Nuklear)</h2>

<p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a small <a href="https://en.wikipedia.org/wiki/Immediate_mode_GUI">immediate-mode</a> GUI toolkit:</p>

<blockquote>
  <p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a minimal-state, immediate-mode graphical user interface toolkit written in ANSI C and licensed under public domain. It was designed as a simple embeddable user interface for application and does not have any dependencies, a default render backend or OS window/input handling but instead provides a highly modular, library-based approach, with simple input state for input and draw commands describing primitive shapes as output. So instead of providing a layered library that tries to abstract over a number of platform and render backends, it focuses only on the actual UI.</p>
</blockquote>

<p>its Lisp binding is <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a>, and its higher level companions <a href="https://github.com/borodust/bodge-ui">bodge-ui</a> and <a href="https://github.com/borodust/bodge-ui-window">bodge-ui-window</a>.</p>

<p>Unlike traditional UI frameworks, Nuklear allows the developer to take
over the rendering loop or the input management. This might require
more setup, but it makes Nuklear particularly well suited for games,
or for applications where you want to create new controls.</p>

<ul>
  <li><strong>Framework written in</strong>: ANSI C, single-header library.</li>
  <li>
    <p><strong>Portability</strong>: where C runs. Nuklear doesn’t contain
platform-specific code. No direct OS or window handling is done in
Nuklear. Instead <em>all input state has to be provided by platform
specific code</em>.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: small.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lispcookbook.github.io/cl-cookbook/gui.html">https://lispcookbook.github.io/cl-cookbook/gui.html</a></em></p>]]>
            </description>
            <link>https://lispcookbook.github.io/cl-cookbook/gui.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819896</guid>
            <pubDate>Mon, 13 Jul 2020 12:13:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“johnyj12345” exposing self-hosted Gitlab's secrets to the public]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819885">thread link</a>) | @ferruck
<br/>
July 13, 2020 | https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/ | <a href="https://web.archive.org/web/*/https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <h2><a href="https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" rel="bookmark">Possible Gitlab Hack</a></h2>
                <p>Today I noticed a new and unknown user on our company's Gitlab
instance: "johnyj12345". We immediatly took down our instance as it
seems as if that Johny was able to extract our secrets. You should
probably do so, too.</p>
                <p><i>Published <time datetime="2020-07-13T12:05:42+02:00">Monday, 13 July 2020</time> by <a href="https://blog.philipp-trommler.me/author/philipp-trommler.html">Philipp Trommler</a>. This article has also been translated to: <a href="https://blog.philipp-trommler.me/de/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" hreflang="de">de</a>.</i></p>
                <p>Searching the web <a href="https://www.google.com/search?q=johnyj12345">for the
username</a> (attention: Google link!)
reveals that many self-hosted Gitlab instances are affected. The publicly
visible procedure is always the same: Johny creates one or more issues that are
linked with each other and at the end of the link cascade there's either an
attached file or a link to a file which holds Gitlab's <code>secrets.yml</code>.</p>
<p>From the web search it seems like the hack started on Saturday, though that may
be a false conclusion. In any case, you should probably take down your Gitlab
instance if you're affected since the <code>secrets.yaml</code> contains Gitlab's base key
and the database encryption key which should better be private AFAIK. This may
or may not be an immediate attack surface, but better safe than sorry,
especially since the files can be easily found via Google.</p>
<p>We're currently looking for a sane and safe way of rotating the keys within that
file. Any help would be appreciated.</p>
                <p><i>Filed under <a href="https://blog.philipp-trommler.me/category/security.html">Security</a>. Tags: <a href="https://blog.philipp-trommler.me/tag/git.html">git</a>, <a href="https://blog.philipp-trommler.me/tag/gitlab.html">gitlab</a>, <a href="https://blog.philipp-trommler.me/tag/hacking.html">hacking</a>, <a href="https://blog.philipp-trommler.me/tag/web.html">web</a>.</i></p>
                <p><i>Want to comment on this article? Write me at blog [at] philipp-trommler [dot] me!</i></p>
            </article></div>]]>
            </description>
            <link>https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819885</guid>
            <pubDate>Mon, 13 Jul 2020 12:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Mock Interviews – learn about data and SQL by solving interview tasks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819221">thread link</a>) | @makaronich
<br/>
July 13, 2020 | https://www.sqlhabit.com/about-mock-interviews | <a href="https://web.archive.org/web/*/https://www.sqlhabit.com/about-mock-interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<div>
  <div>
    <section>
      
<div>
  

  <div><p>
    Mock Interviews will help you to get ready for an upcoming SQL interview. It's also a great way to learn and practice Data Analytics with SQL. The format is simple:
    </p>
  </div>

  <p><a href="https://www.sqlhabit.com/signup">
    Try Mock Interviews <br>for free
</a></p></div>

    </section>

    <section>
      <div>
        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews@2x-7a6e7ee7be9670546e04b57481518131981519804003b13c30b96beb72b70db9.jpg 2x">
    <img alt="Prepare for an interview" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg">
  </picture>

  <div>
    <h2>
      Prepare for an interview
</h2>
    <p>
      Mock Interviews are based on SQL challenges from Data Analysis, Product Management and Marketing interviews. Youâ€™ll have 45 minutes to solve 2 challenges varying in difficutly: easy, medium, hard and hardcore. <img title=":rocket:" alt="ðŸš€" src="https://twemoji.maxcdn.com/2/svg/1f680.svg">

    </p>
  </div>
</div>

        </div>

        

        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents@2x-b68c6ed4cd81b4a5d61ed804f4a8960e4ad180d40ff917f40e5e5deba66ba0fa.jpg 2x">
    <img alt="Master Data Analysis with SQL Habit course" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg">
  </picture>

  <div>
    <h2>
      Master Data Analysis with SQL Habit course
</h2>
    <p>
      Go beyond Mock Interviews and learn specifics of Data Analysis with SQL Habit course. Youâ€™ll not only master SQL, but learn how to apply it in different scenarios from Product Management and Marketing. All based on a story of a startup. <img title=":books:" alt="ðŸ“š" src="https://twemoji.maxcdn.com/2/svg/1f4da.svg">

    </p>
  </div>
</div>

        </div>
      </div>
    </section>

    <section>
      
<div id="pricing">
  <h2>
    Buy unlimited access to SQL Habit
  </h2>

  <div>
    <div>
      
<div>
  <p>
    FUNDAMENTALS
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>25 free</strong> lessons and exercises
          </p>
        </div>
        
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://www.sqlhabit.com/signup">Sign up</a></p><p>
        *no credit card required
      </p>

  </div>
</div>

    </div>
    <div>
      
<div>
  <p>
    COMPLETE PACKAGE
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>200+</strong> lessons and exercises
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to SQL Habit, forever
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to Mock Interviews
          </p>
        </div>
        <div>
          


          <p>
            Verified <strong>LinkedIn certificate</strong>
          </p>
        </div>
        <div>
          


          <p>
            A <strong>private Telegram group</strong> with the author and your fellow course participants
          </p>
        </div>
        <div>
          


          <div>
            <p><strong>Monthly live Q&amp;A sessions</strong>, next one is scheduled for August, 1 </p>

          </div>
        </div>
        <div>
          


          <p><strong>1 year of Datagrip</strong> for free
          </p>
        </div>
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://gum.co/kwYeT">Buy now</a></p>

  </div>
</div>

    </div>
  </div>
</div>

    </section>

    <section>
        <section>
          <div>
  <h2>
    Reviews
  </h2>

  

  <div>
      <div>
        <p><span>SQL habit is the best online course I have done! It is my number one recommendation when it comes to learn SQL, for a beginner or even an advanced user.</span>

Anatoli has a gift to teach through examples in a very fun and playful way. The course covers real life example of the data analysis function of a company, starting with accessible SQL (read no prior experience needed), to very advanced SQL (yes, I mean...
        </p>

          
      </div>
      <div>
        <p><span>I am so excited that I have finally learnt SQL and realised how much I can gain from it in my daily work! The course gave me a better understanding of Marketing and Product Analytics</span> â€” how data is tracked, stored and interpreted â€” on web and for mobile apps. I can't wait to put my new skills into practice! I have tested few SQL courses and I would highly recommend SQL Habit without a doubt! Thank you very...
        </p>

          <p>
            Artur, Marketing Analyst @ Babbel
          </p>
      </div>
      <div>
        <p>
          SQL was something I never touched before starting this course. But being a Product Designer, I often asked my colleagues about how many users saw a specific landing page, where did they come from, how many people signed up, etc. It made me want to learn more about the data behind those magic numbers I got from them all the time. <span>This course was an incredible help to understand exactly that and it made me way more...
        </span></p>

          <p>
            Franziska, Product Designer
          </p>
      </div>
  </div>
</div>

        </section>
    </section>

    <section>
      
<div>
  <h2>
    Frequently Asked Questions
  </h2>

  <div>

      <div>
    <p>Can I try the course for free?</p>

    <p>Absolutely. The first 33 lessons and exercises are free. Just <a href="https://www.sqlhabit.com/users/new">signup</a> with your email, no credit card info required.</p>
  </div>
  <div>
    <p>Do you accept PayPal purchases?</p>

    <p>SQL Habit uses Gumroad to accept payment and Gumroad supports PayPal.</p>
  </div>
  <div>
    <p>Can I get an invoice?</p>

    <p>Absolutely! Right after purchasing youâ€™ll get a receipt which includes a link to generate an invoice with any extra information you need to add for your own accounting purposes.</p>
  </div>
  <div>
    <p>Do you have monthly subscription?</p>

    <p>Nope, one time purchase allows you to access it <strong>forever</strong>. Honestly, I believe itâ€™ll take you 1-2 months to really develop this strong SQL Habit. <img draggable="false" title=":muscle:" alt="ðŸ’ª" src="https://twemoji.maxcdn.com/2/svg/1f4aa.svg"></p>
  </div>
  <div>
    <p>Can I purchase SQL Habit for my team/company?</p>

    
  </div>
  <div>
    <p>What if I realize itâ€™s not for me?</p>

    <p>No problem! Ping me at <a href="mailto:support@sqlhabit.com">support@sqlhabit.com</a> and youâ€™ll be refunded in full, no questions asked (except feedback).</p>
  </div>

  </div>
</div>

    </section>
  </div>
</div>

    </div></div>]]>
            </description>
            <link>https://www.sqlhabit.com/about-mock-interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819221</guid>
            <pubDate>Mon, 13 Jul 2020 10:32:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A $50.000/year streaming service]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819201">thread link</a>) | @gianlucahmd
<br/>
July 13, 2020 | https://blog.gianlucamauro.com/post/harvard-online-learning/ | <a href="https://web.archive.org/web/*/https://blog.gianlucamauro.com/post/harvard-online-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <section>
  
</section>










        

<section>

    <section id="articleHero">
    <div>
        <header>
            
            <div>
                <div>
                    


    
            
    



<p>
                    July 10, 2020
                     • 3 min read
                </p></div>
            </div>
        </header>
        
        
        
    </div>
</section>

    

    <article id="articleContent">
        <p>Harvard University announced that next academic year will be 100% online.</p>
<p>And the tuition won’t be a dime cheaper.</p>
<p><img src="https://blog.gianlucamauro.com/images/harvard.png" alt=""></p>
<p>Why does it matter?</p>
<p>I don’t want to question the worthiness of such an investment. Yet, I can’t help but wonder if you’ll loose some of your returns by switching from the Harvard University halls to your web browser.</p>
<p>When you give $50.000 to a University like Harvard, you’re paying for a bunch of stuff. Mainly:</p>
<ul>
<li>Prestige</li>
<li>The network (your network is your net worth, right?)</li>
<li>Learning, obviously</li>
</ul>
<p>How will the new experience impact these aspects?</p>
<p>The prestige will stay intact. You can show off your Harvard badge on LinkedIn without having to specify where you studied.</p>
<p>I don’t think that you’ll get exposure to the same network as with physical classes. Human connection is paramount to build strong social ties. Yes, you can talk to people trough Zoom and stuff. But let’s stop hiding: Zoom is a poor quality proxy for face to face interaction. Hopefully when Covid will be over students will catch up with the social interactions they missed.</p>
<p>Let’s talk about learning now.</p>
<p>For years, online learning has been seen as a “second choice” learning format. Yes, it’s more comfortable and democratic than “real” university learning, but at the cost of some quality. I have to admit, I was guilty myself of this bias a few years ago.</p>
<p><strong>By changing medium without touching its price tag, Harvard changed the game. Harvard stated loud and clear that online learning is still learning. And it’s worth as much.</strong></p>
<p>This is a huge win for people like me that work hard to create the best online educational content possible.</p>
<p>This legitimates online learning. It acknowledges that the medium does not devaluate the knowledge, passion and teaching skills of the teacher.</p>
<p>Among all the change that Covid has brought to our lives, some will stick forever. Once the stigma around online learning will be gone, we’ll be left with a more democratic way of learning.</p>
<p>Who has something to teach will be free of sharing his experience without fear. Who wants to improve herself will be free to do so without the entry barriers of the Harvard halls.</p>
<p>And my biggest wish of all: <strong>companies will treat people that built their education online with the same respect of who spent $200.000 to sit in Harvard’s classrooms.</strong></p>
<blockquote>
<p>Let the future tell the truth, and evaluate each one according to his work and accomplishments - Nikola Tesla</p>
</blockquote>

    </article>
    
    

<section id="subscriptionSection">
    <div>
        <div>
            <h3>
                Get my thoughts in your inbox
            </h3>
            <p>
                Join my subscribers to get curated emails with my posts. 
                No spam, no marketing bullshit. Opt-out at anytime. You have my word I won't not spam your inbox or share your email with any third parties.
            </p>


            

        </div>
    </div>
</section>











    
    
    
        
    




<section id="articleNext">
    
    
    
</section>


</section>







 

        
        
    

    </div></div>]]>
            </description>
            <link>https://blog.gianlucamauro.com/post/harvard-online-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819201</guid>
            <pubDate>Mon, 13 Jul 2020 10:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meddling Middlemen of Academia]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23819130">thread link</a>) | @Topolomancer
<br/>
July 13, 2020 | https://bastian.rieck.me/blog/posts/2020/middlemen/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/middlemen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>One of the strangest phenomena in academia is the reliance on publishing
companies. In this article, I want to outline some of the issues that
arise when working with publishers. I shall also endeavour to provide
some solutions to improve this collaboration.</p>
<p>Before we start, a brief <strong>disclaimer</strong>: this article will use an
amalgamation of different incidents that involved either myself, my
colleagues, or my friends.  Names&nbsp;(of the publishing companies)
have been withheld because I do not think it fair to use my ‘soapbox’
without giving the <em>other</em> side a chance to respond. Moreover,
everything I write here pertains to publishing your research in
a journal. Conference publishing—at least in machine learning—is
a joy<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. Plus, there <em>are</em> good examples of journals for machine
learning papers, foremost of them the <a href="http://www.jmlr.org/">Journal of Machine Learning
Research</a>. The ‘adversaries’ in this article are
rather the ‘big’ publishing companies and their practices. With that out
of the way, let us take a look at the state of the art!</p>

<p>If you are new to science, at some point, you will probably have to deal
with an established publishing company to get your article published.
The deal usually works like this:</p>
<ol>
<li>
<p>You look for a journal you want to publish in and submit your article
to the journal. This already often involves jumping through some
hoops. Without knowing the eventual fate of your article, you often
already have to abide by certain arbitrary formatting guidelines or
completely ‘butcher’ your article for the submission<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> by shifting
content around. However, this can be all accepted and endured because
of course, you want something from <em>them</em>, i.e. a published,
citable publication!</p>
</li>
<li>
<p>The journal then receives your submission—often through a web
interface that was developed with all the UX/UI knowledge of the
1980s<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> and has <em>never</em> been updated since—and this is where it gets
slightly <em>murky</em>. Another person—typically the editor of the
journal—now decides whether to accept the paper for reviewing, or
whether to provide you with a desk reject. A desk reject usually cannot
be appealed. It just shows you the door and leaves you to try again
with another journal&nbsp;(more murkiness here). For early-career
researchers like Ph.D. students submitting their first paper,
this can be highly discouraging. I see the reason for reducing the
workload on reviewers, of course, but I also heard of academic feuds
that were carried out on the backs of Ph.D. students and their
publications.</p>
</li>
<li>
<p>Assuming your paper ‘survived’ the desk reject, it will now be sent
to reviewers or referees. Their job is to review your paper
thoroughly, provide feedback, and in general give this whole business
a formal veneer. Setting aside problems in the reviewing
process—which I discussed <a href="http://bastian.rieck.me/blog/posts/2019/reviewing/">in another blog post</a>—this again opens up a portal into
a strange dimension: working as a reviewer for a journal is usually
a job that is provided for free&nbsp;(same goes for editorial
duties). Notice that this is <em>despite</em> the fact that those journals
are charging money to readers and universities. ETH Zurich, my
current employer, describes their experiences of the <a href="https://www.library.ethz.ch/en/Services/Using-ordering-resources/National-negotiations-with-publishers-Read-publish-reorganised">negotiations
with
publishers</a>
and mentions an expenditure of 6.4 million EUR&nbsp;(roughly 7.25
million USD) per year for being allowed to access journal articles.
That is a lot of money.</p>
<p>Setting aside the actual numbers here, let me just point out how
strange it is that companies are relying on <em>unpaid labour</em>, and this
reliance is <em>crucial</em> to their business model. They often do not
employ people that are qualified to judge the content that they want
to publish! But of course, reviewers and editors get the benefit of
<em>exposure</em>—that wonderful currency that is supposed to help your
career along! Even stranger: journals often charge hefty sums for
accessing your own research articles. To me, it is super weird that
research that is often <em>funded</em> by the taxpayer cannot be <em>accessed</em>
by the taxpayer.</p>
</li>
<li>
<p>Supposing your article got sufficiently good reviews to be published,
the next stage of the process starts. This is where the <em>meddling</em>
begins in earnest. After a little back and forth, you article will be
changed according to some arbitrary rules: the last period of every
sentence in an image caption will be removed, footnotes will be put
into the text—because for some reason, footnotes are permitted in
virtually every template and publishing medium, but deemed somewhat
uncouth by certain publishers—and you might have to redo certain
parts of your paper because of subtle font changes or what have you.</p>
<p>Again, lest you think of me as a particularly cranky person prone to
grumbling and finding faults, you are getting the wrong idea here.
I do not object to these changes, but I <em>do</em> object to the fact that
these meddlesome changes often decrease the quality of your paper.
Here are some irksome changes:</p>
<ul>
<li>
<p>Footnotes will be inserted willy-nilly into the text, regardless of
whether they make sense or not. That might break the flow of your
paper, but that is <em>your</em> problem.</p>
</li>
<li>
<p>Some ‘publisher house rules’ conflict with proper nomenclature in
a field. For example, the journal might have the ‘rule’ that all
fields in a table have to be capitalised. If this clashes with
nomenclature in your field, it is—you guessed it—<em>your</em> problem.</p>
</li>
<li>
<p>Your equations will typically be typeset yet
another time for you<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, which might introduce subtle changes: symbols
will change and you have to be go through your own paper once again
line-by-line to see whether anything untoward happened. Again, I am
primarily objecting to the substandard quality of this meddling:
the work that you put into writing your equations is completely
ignored, and now you have to chase—often very subtle—changes in
your own text. For mathematical typesetting, precision is crucial,
and it is unbecoming when people who do not <em>care</em> about this
precision create more work for you.</p>
</li>
<li>
<p>As a last example, your figures might be meddled with: you might be
forced to convert them into obsolete file formats&nbsp;(because
apparently, EPS is still the best format available), or, more
appallingly, vector graphics might be converted to raster
images&nbsp;(judging from the experiences of my friends and myself,
this is unfortunately relatively common!). This might sound like a tiny
problem again, but it decreases readability and accessibility for
some readers, and, more to the point of this post, it is somewhat
unnecessary meddling.</p>
</li>
</ul>
<p>Let me re-iterate my main point: I do not object to changing my
paper, I merely object to meddlesome changes that are just generating
useless work. For example, there is no need whatsoever to typeset
your equations again—this is quite literally the definition of
negative work.</p>
</li>
<li>
<p>If you survived this ordeal intact, you now must <em>pay</em>. To be fair,
not all journals charge you for normal articles, but <em>most</em> of them
charge you for open access publishing. In other words: if I want my
research, which is generously funded<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> by the Swiss taxpayers, to
be available to those selfsame taxpayers, I have to pay. The amounts
vary a little bit, of course, but we are talking upwards of a few
hundred USD at least. Luckily, this is <em>not</em> a problem for my
research group; my postdoctoral adviser, <a href="https://bsse.ethz.ch/mlcb/karsten.html">Prof. Karsten
Borgwardt</a> ensures that
sufficient funds for open access publications are available.</p>
<p>Interestingly, sometimes the cost is fielded by a conference; this
happens when the conference has a contract that ensures that its
publications will be available as special issue of some journal.
This might seem nice because it <em>shifts</em> the costs away from authors,
but it is also somewhat non-transparent; conference costs being high
already, I find it strange that some of the money goes into the
pockets of another party.</p>
<p>After all this negativity, it is time for a <em>positive example</em>:
NeurIPS, one of the flagship machine learning conferences, is
partnered with a publisher and makes <em>all</em> papers available for free
online. I <em>gladly</em> pay the conference fee for this!</p>
</li>
</ol>

<p>How can this process be improved? I have a few suggestions:</p>
<ol>
<li>
<p><strong>Transparency</strong>: publishers should make it clear <em>where</em> the funds are
going. Are we increasing shareholder value by working for free? How
are profits split and used?</p>
</li>
<li>
<p><strong>Giving back</strong>: it is generally understood that everyone needs to eat
and no one should have to work for free. Why is then that this
completely different in publishing? Almost all the profits are
essentially generated because editors and reviewers work for free.
I know that being remunerated for your reviewing work might raise
some questions about impartiality etc., so I think <em>paying</em> people to
write reviews might be somewhat problematic.</p>
<p>However, closely related to my point about transparency, publishers
could be more upfront about how they user their funds and <em>give back</em>
to the community. For example, publishers could sponsor students so
that they can visit a conference for free, or publishers could
sponsor the conferences themselves.</p>
<p>If you, as a publisher, engage the community and give back a little,
the community will be all the more happy to work with you. We need
you, but you also need us. Without the scientists, you cannot be
a scientific publisher.</p>
</li>
<li>
<p><strong>Commitment to excellence</strong>: publishers should commit to the highest
quality and the highest standards. Employ people that are capable of
working <em>with</em> the scientists, not <em>for</em> the scientists. Train your
employees to be experts in typography, typesetting, and pair them
with domain experts so that they do not create more work for the
authors by inadvertently destroying equations, figures, and so on.</p>
<p>This goal is not necessarily orthogonal to maximising your profits,
by the way: if you lower your standards, your reputation as
a publisher will suffer, meaning that scientists in the long
run&nbsp;(!) might not be willing to publish with you any more. If
you commit to excellence, by contrast, we will flock to you.</p>
<p>I know that working with a publisher that <em>cares</em> about the end
product as much as I do is a heavenly match! So we should endeavour
to make such …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bastian.rieck.me/blog/posts/2020/middlemen/">https://bastian.rieck.me/blog/posts/2020/middlemen/</a></em></p>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/middlemen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819130</guid>
            <pubDate>Mon, 13 Jul 2020 10:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real World Programming in SWI-Prolog]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23818901">thread link</a>) | @luu
<br/>
July 13, 2020 | http://www.pathwayslms.com/swipltuts/ | <a href="https://web.archive.org/web/*/http://www.pathwayslms.com/swipltuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>This is a hopefully ever expanding collection of tutorials on aspects of the SWI-Prolog environment.
Our emphasis is on learning to write <b>real world</b> applications in SWI-Prolog.</p>

<ol>
<li><a href="http://www.pathwayslms.com/swipltuts/dcg/index.html">Definite Clause Grammars</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/html/index.html">Web Applications</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/clpfd/clpfd.html">Constraint Logic Programming over Finite Domains</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/message/index.html">Printing Messages in SWI-Prolog</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/chr/index.html">Constraint Handling Rules</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
</ol>

<h2>Stuff that's in the general vein of the <i>Real World</i> tutorials, but are by others</h2>
<ul>
<li>There is a <a href="http://swish.swi-prolog.org/example/dict.swinb">SWISH tutorial on the dict structure</a> that was introduced with revision 7.0</li>
<li>There is a <a href="http://swish.swi-prolog.org/example/tabling.swinb">SWISH tutorial on tabling</a> that was introduced with 7.2.3</li>
<li>Michael Richter maintains a tutorial on using modules with SWI-Prolog <a href="http://chiselapp.com/user/ttmrichter/repository/gng/doc/trunk/output/tutorials/swiplmodtut.html">Using Modules with SWI-Prolog</a></li>
<li>Michael Hendricks has a tutorial for his vastly nifty pack "Julian" for reasoning about dates and times <a href="http://mndrix.github.io/julian/index.html">Julian tutorial</a></li>
<li>The Amzi Corporation maintains a useful introduction to expert systems <a href="http://www.amzi.com/ExpertSystemsInProlog/">Expert Systems in Prolog</a></li>
</ul>

<h2>Other stuff by me (Anne Ogborn) about Prolog</h2>
<li><a href="http://www.pathwayslms.com/swipltuts/student/index.html">FAQ For The ##Prolog Channel</a> by Anne Ogborn and Michael Richter</li>
<li>A little story about <a href="http://www.pathwayslms.com/swipltuts/teacher/index.html">teaching Programming Languages courses that include Prolog</a></li>
<li><a href="https://www.youtube.com/watch?v=JmOHV5IlPyU">Youtube video (35 mins) of my tutorial on Pengines at Strange Loop 2014</a></li>
<li><a href="https://www.youtube.com/watch?v=G_eYTctGZw8">Youtube video (40 mins)</a> of Michael Hendricks' talk on Production Prolog, with great hints on practical Prolog</li>
<li>I gave a workshop on SWI-Prolog web development at <a href="https://thestrangeloop.com/">Strangeloop 2013</a> The workshop materials were basically the set of html tutorials collected into a single program. <a href="https://github.com/Anniepoo/strangeloop">You can get them here</a>.</li>

<h2>Selected other folks' tutorials and info about prolog</h2>
<ul>
<li>Roman Bartok maintains a great <a href="http://kti.ms.mff.cuni.cz/~bartak/prolog/index.html">tutorial introduction to Prolog</a></li>
<li>The introductory book <a href="http://lpn.swi-prolog.org/lpnpage.php?pageid=online">Learn Prolog Now</a> is online, and has embedded SWISH so you can run the examples right in the text</li>
<li>Help, my brain is melting <a href="http://www.pathwayslms.com/swipltuts/())).pl">())).pl</a></li>
</ul>

<h2>Contribute!</h2>
<p>We'd love to have more contributors of tutorials. Areas we'd love to see covered: Pldoc, The IDE, CLP, Expert Systems, aggregator library, and whatever else excites you.</p>



</div>]]>
            </description>
            <link>http://www.pathwayslms.com/swipltuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818901</guid>
            <pubDate>Mon, 13 Jul 2020 09:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark Web Price Index 2020]]>
            </title>
            <description>
<![CDATA[
Score 282 | Comments 197 (<a href="https://news.ycombinator.com/item?id=23818727">thread link</a>) | @known
<br/>
July 13, 2020 | https://www.privacyaffairs.com/dark-web-price-index-2020/ | <a href="https://web.archive.org/web/*/https://www.privacyaffairs.com/dark-web-price-index-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><b>The dark web has a longstanding reputation as a haven for the worst kinds of criminal activity. This reputation is not wholly unjustified, as there are indeed terrible things happening around the world that can be bought and sold on the dark web. </b></p><p><span>The privacy offered by software such as TOR creates an environment where criminals can sell their wares on the dark web without the worry of law enforcement.</span></p><p><span>What’s more, many will have heard the horror stories of people’s bank accounts being cleaned out, or their identity stolen and turning up in custody in Mexico. Again, not unjustified horror.</span></p><p><span>You might be asking yourself, just how easy is it to obtain someone else’s personal information, documents, account details?&nbsp;</span></p><p><span>We certainly were.</span></p><p><span>To see just how prevalent such items of personal data are being listed, and at what price, we sent our researchers on a data-gathering mission into the dark web.</span></p><table><tbody><tr><td>Category</td><td>Product</td><td>Avg. dark web Price (USD)</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#2">Credit Card Data</a></td><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td></td><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td></td><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td></td><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td></td><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td></td><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td></td><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td></td><td>Walmart account with credit card attached</td><td>$10</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#3">Payment processing services</a></td><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td></td><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td></td><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td></td><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#4">Forged documents</a></td><td>US driving license, average quality</td><td>$70</td></tr><tr><td></td><td>US driving license, high quality</td><td>$550</td></tr><tr><td></td><td>Auto insurance card</td><td>$70</td></tr><tr><td></td><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td></td><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td></td><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td></td><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td></td><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td></td><td>Europe national ID card</td><td>$550</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#5">Social Media</a></td><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td></td><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td></td><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td></td><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td></td><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td></td><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td></td><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td></td><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td></td><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td></td><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td></td><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td></td><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td></td><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td></td><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td></td><td>Instagram likes x 1000</td><td>$6</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#6">Malware</a></td><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td></td><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td></td><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td></td><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td></td><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td></td><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td></td><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td></td><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td></td><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td></td><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td></td><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td></td><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td></td><td>Android x 1000</td><td>$600</td></tr><tr><td></td><td>Premium x 1000</td><td>$6000</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#7">DDoS Attack</a></td><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td></td><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table></section><div><section id="1"><h2>What We Found</h2><p>Whilst there are many marketplaces on the dark web, there are even more forum posts warning of scammers. This makes verified prices difficult to obtain without ordering the items to find out, which of course we didn’t.</p><p>Our methodology was to scan dark web marketplaces, forums, and websites, to create an index of the average prices for a range of specific products.</p><p>We were only interested in products and services relating to personal data, counterfeit documents, and social media.</p><p>This is what we found.</p></section><section id="2"><h2>Cloned credit cards and associated data</h2><table><tbody><tr><td>Product</td><td>Average dark web Price (USD)</td></tr><tr><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td>Walmart account with credit card attached</td><td>$10</td></tr></tbody></table><p>Credit card details usually come in the format CC|MM|YY|CVV|HOLDER_NAME|ZIP|CITY|ADDRESS|EMAIL|PHONE with the first 4 sections being the details on the card and the rest the details of the account holder. This will definitely cause a major inconvenience, but the prospect of someone using your online banking logins to gain full access to your account is far more daunting.</p><p><a href="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png"><img src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" data-src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" alt="Dark web credit card price" width="840" height="447"></a></p><p>Vendors tend to offer a guarantee of 80%. Meaning that two of every ten cards either won’t work or will have less than the advertised balance. We didn’t order any so can’t verify whether this is true, but the prevalence of these claims alongside the well documented increase in identity fraud cases suggests that there is a high turnover of such data.</p></section><section id="3"><h2>Payment processing services</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr></tbody></table><p>PayPal account details were easily the most common items listed, and extremely cheap. More expensive was actual transfers from a hacked account.</p><p>Another very common item for sale was guides on how to “cash out” – actually get the money in a way that doesn’t alert the authorities. These guides go for a few cents, but whether or not they actually work is not what we were looking for.</p></section><section id="4"><h2>Forged documents</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>US driving license, average quality</td><td>$70</td></tr><tr><td>US driving license, high quality</td><td>$550</td></tr><tr><td>Auto insurance card</td><td>$70</td></tr><tr><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td>Europe national ID card</td><td>$550</td></tr></tbody></table><p>These documents came with a range of guarantees and are available with any details the buyer chooses. With just a few pieces of real information about someone, a criminal could create a whole file of official documents to be used for all sorts of fraudulent activities. This one way in which an identity is stolen.</p><h3>Counterfeit money</h3><p>Counterfeit banknotes are extremely common, mainly in 20 or 50 denominations.</p><p>We came across USD, EUR, GBP, CAD, AUD most often. Some come with a UV pen test guarantee. The “quality” ones tend to cost around 30% of the banknote value.</p></section><section id="5"><h2>Social media</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td>Instagram likes x 1000</td><td>$6</td></tr></tbody></table><p>Offers to hack accounts or sell them were relatively scarce, but not non-existent. Perhaps due to a lack of demand for the product coupled with increased security practices. Hackers trying to get the social media credentials from their victims mostly have to resort to using <a href="https://www.getsafeonline.org/blog/what-is-pii-and-how-do-you-keep-it-private/">social engineering techniques</a>, which have a very high effort input for relatively low success ratio.</p><p>The extremely low cost for social engagement should seriously make you question an account’s validity before blindly trusting their wealth of social currency.</p></section><section id="6"><h2>Malware</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td>Android x 1000</td><td>$600</td></tr><tr><td>Premium x 1000</td><td>$6000</td></tr></tbody></table><p>Malicious tools are installed on comprised systems (Windows, Android and others) which gives attackers access to the system. Initial installation is via fake online casino, FB/social networks, warez websites etc.</p><p>Some forms of malware may simply use your computer’s resources for activities such as cryptocurrency mining. Others may be used to steal credentials as you enter them on a website. For each 1000 installs, hackers can often steal tens of thousands of dollars.</p></section><section id="7"><h2>DDoS attack</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table><p>A distributed denial of service (DDoS) attack aims to take a website offline by sending thousands of requests per second in order to overload the website’s server, causing it to crash.</p></section><section id="8"><h2>Why This Data Is Important</h2><p>For the average person, underground market data isn’t necessarily going to provide much use as they most likely aren’t shopping around for stolen card data or PayPal accounts. Though this is true, the prices at which these items sell provide a powerful perspective.</p><p>If someone gets their hands on your financial details or social media credentials, the prices mentioned above is basically what it’s worth to them. There’s a good chance that you value these things much more than they do, as to them you’re just another mark for a quick buck.</p><p>For far less than the amount your data would sell for on the black market, you can protect it from ever having to reach their hands with a couple of simple rules and habits. With this knowledge, there’s no excuse not to do what you can to protect your data.</p><p>Nothing is foolproof however, and …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.privacyaffairs.com/dark-web-price-index-2020/">https://www.privacyaffairs.com/dark-web-price-index-2020/</a></em></p>]]>
            </description>
            <link>https://www.privacyaffairs.com/dark-web-price-index-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818727</guid>
            <pubDate>Mon, 13 Jul 2020 09:08:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial sites treating FreeBSD like a Linux distro]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 77 (<a href="https://news.ycombinator.com/item?id=23818702">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>On the Gold Coast in January, Deb Goodkin from the FreeBSD Foundation began her Linux.conf.au talk with an intentionally-provocative slide: <em>FreeBSD, that’s just another Linux distro, right?</em> It was said in jest to highlight what a common misconception it is.</p>
<p>One way this manifests is through introductory FreeBSD guides online, usually on blogs with the words sysadmin, cookbook, or tutorial in their names; you know the ones I’m talking about. Invariably they advise updating the base system and pkgng, then immediately installing bash, nano, htop, lsof, coreutils, proc, and more. Some go as far as aliasing these over the built-in tools, and even setting bash as the root shell. From then on, you barely have to touch the FreeBSD userland.</p>
<p>Like a poorly-maintained cheese utensil, this used to grate. If you’re installing an entire GNU toolchain, why not use a Linux distribution, or Debian/kFreeBSD, or a Nexenta-like OS that’s built specifically for those tools? You’re not learning about FreeBSD’s features, nor are you taking advantage of any of its benefits beyond the kernel and base. It’s wasted opportunity, and could render future project contributions more difficult because of misunderstood assumptions about how the system works.</p>
<p><img src="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg" srcset="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg 1x, https://rubenerd.com/files/2020/usebsd-pillow@2x.jpg 2x" alt="A photo of a pillow saying: Use BSD"></p>
<p>I’ve since changed my tune somewhat, with a caveat. I also want to take this opportunity— not a sponsor—to spruik Jay Patel’s <a href="https://www.redbubble.com/people/jaypatelani/shop">RedBubble store</a> for your BSD laptop and loungeroom. I’ve already added some to next sticker batch.</p>
<p>What was I talking about?</p>
<p>We should be encouraging Linux people to try FreeBSD, and if giving them their familiar tooling gets their foot in the door, it’s worth it. I personally learn things the quickest by jumping in the deep end, but I know others want to take things a step at a time.</p>
<p>What also gets lost in the fray is FreeBSD, even with all those Linux-focused tools, is still a compelling and useful operating system. It’s a feature not a bug to be able to have all these tools available, and at times run them faster than Linux could on the same hardware. It may even integrate better into shops that otherwise entirely run Linux, given the motivation to write portable, POSIX-compliant code and applications is no longer a priority for most people (sadface).</p>
<p>So rather than saying those guides aren’t useful or even misrepresent FreeBSD, we need to reframe them. Instead of <em>introductions to FreeBSD</em>, say they’re <em>FreeBSD for Linux people</em>. This shouldn’t be constued as criticism; the latter kinds of post would be <em>hugely</em> useful. It’s also then easier to introduce BSD-specific tools and ideas, either inline after each Linuxism you introduce, or in a follow-up post where you compare and contrast.</p>
<p>We need more bridge-building and outreach between the two communities, and anything to make FreeBSD relatable to people coming from Linux, or any other operating system, is useful.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818702</guid>
            <pubDate>Mon, 13 Jul 2020 09:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Erasmus University Rotterdam builds first virtual campus in the Netherlands]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23818681">thread link</a>) | @vinrob92
<br/>
July 13, 2020 | https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands | <a href="https://web.archive.org/web/*/https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-history-node-id="61036"><p><span><p><time datetime="2020-07-09T12:13:58Z">Thursday, 9 Jul 2020</time></p> </span><span><p>Press release</p> </span></p> <figure> </figure><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Erasmus University Rotterdam (EUR) has re-created their Woudestein campus in the Minecraft platform to provide students and staff a sense of purpose and community during the Covid-19 crisis, a first for the Netherlands. The first blocks of the campus were laid by a small team of enthusiastic students and the project has since then mushroomed to include all buildings on campus, a secret underground labyrinth which players need to find, a treasure hunt for the 17 SDGs (de UN Sustainable Development Goals) and much more. </span></span></span></span></span></span></span></p><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Expansion plans are in the works for the Erasmus Medical Centre and the Erasmus University College. Through this project, EUR aims to fight the Covid-19 setback to the start of the academic year 2020-2021, by giving a platform to the Erasmus community to engage with each other.</span></span></span></span></span></span></span></p><div> <article data-video-provider="YouTube" data-video-id="cQ_Ke1z_Cjo"><div> <picture> <!--[if IE 9]><video style="display: none;"><![endif]--> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=7Ncx-0nR 1x" media="(min-width: 992px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_desktop/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=pjuiFzAV 1x" media="(min-width: 768px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_tablet/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=SqdQGgEy 1x" media="(min-width: 480px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ 1x" type="image/png"> <!--[if IE 9]></video><![endif]--> <img src="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ" alt="Introducing The Virtual Campus - Erasmus University Rotterdam"> </picture></div><div> <h2>Introducing The Virtual Campus - Erasmus University Rotterdam</h2></div></article></div><div><h2>Campus recreated brick by brick</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>It started off as a project to provide students an opportunity for social engagement outside of the Zoom-filled lectures after the Covid-19 pandemic brought universities to a physical shutdown. After a research the Erasmus University Rotterdam (EUR) conducted into the effects of the Corona Crisis on the well-being of its students and staff members, the results strongly pointed towards the need for something to keep the Erasmus community together. People started to feel lonely and missed the ability to socially interact with each other, exactly that what a physical campus is able to provide a podium for. In an attempt to tackle this issue, ErasmusX – a disruptive innovative unit of the university – launched a creative project whereby students and staff could recreate their beloved Woudestein campus in the virtual gaming platform Minecraft. The very first building blocks were laid by members of the student-led Erasmus E-sports Community, and thereafter a professional Minecraft building team helped polish up the final product.</span></span></span></span></span></span></span></p></div><div><h2>"What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale"</h2></div><div><div><h2>Woudestein: a place to meet friends</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>To the EUR community, the campus is not just a place you go to in order to study and work. It is a place where you meet your friends (that perhaps have become like family), where you develop yourself as a human being, where you hang out and where you dream about the opportunities life has in store for you. It almost feels like a small village. “This feeling was so apparent when we saw the many emotional reactions from students and colleagues when they first see the virtual campus – they tell us that navigating the campus makes them feel like they are there again”, states Alexander Whitcomb, a project team member. “What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale. So walking from one end of the campus to the other with your avatar in Minecraft takes exactly the same amount of time as it would do in real life.“</span></span></span></span></span></span></span></p></div></div><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>The Minecraft campus has two main purposes. First it will be used for various planned activities such as onboarding all new incoming students during the famous EurekaWeek 2020, virtual tours for prospective students and the ErasmusX team is also exploring the game platform for educational and research purposes. Secondly, the campus is designed as a creative space, a way for students and staff to design their own interactions and discover new, innovative ways of engaging with one another through the virtual campus. The platform will be moderated by the Erasmus E-sports Community and all ideas are welcomed.</span></span></span></span></span></span></span></p><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Ultimately, the campus in Minecraft is there to strengthen the community of Erasmians, in an academic year where physical interactions are limited by Covid-19, and a ‘normal’ university experience remains unavailable until further notice.</span></span></span></span></span></span></span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818681</guid>
            <pubDate>Mon, 13 Jul 2020 08:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM64 Popcount in Golang and Assembler]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818574">thread link</a>) | @fanf2
<br/>
July 13, 2020 | https://barakmich.dev/posts/popcnt-arm64-go-asm/ | <a href="https://web.archive.org/web/*/https://barakmich.dev/posts/popcnt-arm64-go-asm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Apropos of Apple’s ARM announcment, I thought I might write up a post on a recent bit of code I wrote that specifically looks at ARM64, and its benchmarks on various hardware.</p><p>I’ve been implementing some compact data structures for a project. One of the CPU hotspots for the implementation is the need to run a quick population count across a potentially large bit of memory.</p><p>If you’ve never seen population count before, it’s the count of the number of set 1 bits in a byte (or list of bytes) – for example:</p><div><pre><code data-lang="text">0xF3 == 0b11110011
popCount(0xF3) == 6
</code></pre></div><p>Now, every reasonable x86_64/amd64<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> CPU in the past decade or so has a built-in instruction for this: <a href="https://en.wikipedia.org/wiki/SSE4#POPCNT_and_LZCNT"><code>POPCNT</code></a>. It works like this (in Go Assembler):</p><div><pre><code data-lang="text">MOV    $0xF3, R10  // Store a constant
POPCNT   R10, AX   // AX now equals 6
</code></pre></div><p>Go uses the built-in instruction for this in the <code>math/bits</code> via SSA compiler rewrites (which it added in 1.9), but only up to a uint64 at a time; using assembly to loop over a <code>[]byte</code> is considerably more efficient</p><p><a href="https://github.com/tmthrgd"><code>@tmthrgd</code></a> created a really nice little x86_64-assembly-optimized package at <a href="https://github.com/tmthrgd/go-popcount">github.com/tmthrgd/go-popcount</a>. It works great, works around a weird little Intel bug (see the helpful comments) and is still faster than looping and using the Go standard library, which it helpfully benchmarks as well.</p><p>Recently, I picked up one of the new 8GB Raspberry Pi 4s. Loaded it up with the nice new <a href="https://manjaro.org/">Manjaro 20.06</a> and set up my usual environment. As a test, I wanted to try my latest WIP data structure code.
Of course, the bottleneck was right where I expected it to be: in the population count.</p><h3 id="implementing-it">Implementing it</h3><p>I discovered that ARM64 has a <code>POPCNT</code>-like instruction, logically enough called <code>CNT</code>. I thought, since I’ve been playing with Go assembly for memmove, why not try my hand at the new architecture?</p><p>Go already has the SSA-rewrite for OnesCount on ARM (added in 1.11), but again, only a uint64 at a time. There might be some performance on the table.</p><p><a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">Official architecture guide</a> at the ready, I got to work. And there was a lot to learn. Some notes:</p><h4 id="1-its-part-of-the-vector-suite-neon">1. It’s part of the vector suite, NEON</h4><p>NEON is the name for the addition of vector instructions to the ARM architecture, so I’d be working with both an unfamiliar architecture <em>and</em> its vector instructions.</p><p>In x86-land, <code>POPCNT</code> and vectorization are two separate concepts. <code>POPCNT</code>, as an instruction, deals with everyday, 64-bit integer registers, and not the vector registers (even though it appeared approximately the same time as the addition to vector instructions, SSE4)<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p><p>ARM/NEON did <code>CNT</code> differently. Since you can load an array of items (say, 16 bytes, in the ARM64 vector registers), <code>CNT</code> will count them individually. In fact, you can <em>only</em> do it in vectors of single bytes.</p><p>So this means that the following signatures are approximately the way to think about it:</p><div><pre><code data-lang="go"><span>func</span> <span>popCountx86</span><span>(</span><span>in</span> <span>uint64</span><span>)</span> <span>uint64</span> <span>// register-at-a-time, 64-bit (8 bytes)
</span><span></span>
<span>func</span> <span>popCountNeon</span><span>(</span><span>in</span> <span>[</span><span>16</span><span>]</span><span>byte</span><span>)</span> <span>[</span><span>16</span><span>]</span><span>uint8</span> <span>// 16 bytes all counted in parallel.
</span></code></pre></div><p>This ends up being really effective, as it turns out (below).</p><h4 id="2-gos-assembler-documentation-is-barebones">2. Go’s assembler documentation is barebones</h4><p>Writing instructions so that Go’s assembler is happy with the instructions you’re giving it is a bit frustrating.</p><p>There’s a good gloss at <a href="https://golang.org/pkg/cmd/internal/obj/arm64/">golang.org/pkg/cmd/internal/obj/arm64</a> which gives an overview of many of the differences.
For example, all vector instructions start with <code>V</code>, different than what ARM64 switched to (they used to commonly start with V on 32-bit ARM) – so while I understand the desire for continuity (and even subtly like it, knowing it’s a vector op) it’s just makes another little difference to remember vs. the original documentation.</p><p>But more frustrating is, even if your instruction is supported (and most of them are) knowing how to <em>use</em> the instruction in Go assembler boils down to “assume data goes left-to-right and hope there’s an example <a href="https://github.com/golang/go/blob/master/src/cmd/asm/internal/asm/testdata/arm64enc.s">in the test suite</a>”</p><p>I’m a big Go fan, yet Go’s history into Plan 9 and accompanying assembler (and, relatedly, odd calling conventions) is one of my gripes about Go, even more than lack of generics (which is a topic for another day).
Sure, there were some good ideas in Plan 9 that influenced the design of Go – from a design level, it’s great! – but on the implementation level, this is one place where I kinda wish it had followed precident.
Take whichever side you want in the Intel vs GNU syntax debate, <a href="https://xkcd.com/927/">creating a third option</a> means relearning all the quirks from scratch, and ignoring any documentation that already exists.</p><h3 id="putting-it-all-together">Putting it all together</h3><p>The end result is my friendly fork of <code>go-popcount</code>: <a href="https://github.com/barakmich/go-popcount">github.com/barakmich/go-popcount</a></p><p>Really, it’s more of an extension than a fork – it provides the same API, just with handwritten assembly for ARM64 chips.</p><h4 id="how-it-works">How it works</h4><p>The vectorization works really well. The process is:</p><ul><li>Load a set of vector registers, 16 bytes each</li><li>popCount them</li><li>Vector sum their partial results (up to 32 individual vectors, to fit the 8-bit counts), trying to avoid a data dependency</li><li>Finally, sum (“widening”, in vector terms) the final vector</li><li>Add it to the final output</li></ul><p>The other thing to balance was how much to load from memory vs. how much work to do to optimize throughput. That ended up being about 8 vectors (128 bytes) at a time.
That may vary as a function of CPU, but it’s a good place to start.</p><h4 id="arm64-feels-nice">ARM64 feels nice</h4><p>This is purely subjective, but there were a number of moments where I felt “hey, that’s handy” in writing ARM64 assembly.
Of course modern x86_64 chips account for all of these differences and makes them performant – through deeper instruction pipelines or having <a href="http://sunnyeves.blogspot.com/2009/07/intel-x86-processors-cisc-or-risc-or.html">micro-op instruction queues</a> that ultimately pull the same tricks.
But at the same time, when you’re dropping down to work at the instruction level, it’s kind of a breath of fresh air.</p><h5 id="pre-and-post-increment">Pre-and-post increment</h5><p>A lot of the time when you’re working with an array of whatever you’re pulling a chunk of memory into registers, doing some transform, and putting it back.</p><div><pre><code data-lang="asm"><span>VLD1.P</span> <span>64</span><span>(</span><span>R1</span><span>),</span> <span>[</span><span>V16.B16</span><span>,</span> <span>V17.B16</span><span>,</span> <span>V18.B16</span><span>,</span> <span>V19.B16</span><span>]</span>
</code></pre></div><p>Reads as load 1-byte*size structures into the following vector registers – so far so good, this is similar to the <a href="https://www.felixcloutier.com/x86/movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64"><code>VMOVDQU</code></a> instruction family (though the size-structure variants on that instruction are a recent addition) on x86. It has a similar ability to load many registers in multiple back-to-back instructions through address/offset/size calculation, but ARM has a nice one-liner that way.</p><p>But I really like the auto-increment of <code>R1</code> by the read size (64) after loading – hence post-increment. Many loads from memory have a similar flag. It’s very descriptive and means things like “increment the offset register and decrement the size register and test” things live with their appropriate parts of the code, instead of having to increment later (and finding the optimal time)</p><h5 id="consistency-of-style">Consistency of style</h5><p>This is a holdover from history, but the consistency of having fixed-size instructions is a nice thing when trying to hand-assemble an instruction. I had to do some hand-assembly when <a href="https://github.com/golang/go/issues/39445">I discovered and reported a bug in Go</a>. It was silently writing the wrong version of the instruction while accepting the correct one as input. Kudos to the Go community – it was fixed by an expert within a day or two, so I’m looking forward to the next version that contains the fix!</p><p>Still, this meant with a <a href="https://xkcd.com/378/">steady hand</a> and a copy of <a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">the architecture guide</a> I could feasibly implement any instructions that were missing.</p><p>Also in consistency-land, most binary operations take <code>input1_reg, input2_reg, output_reg</code> with few exceptions. Omitting the output_reg is Go’s assembler syntactic sugar to set output to input2. x86, again for historical reasons (trying to keep instructions small), often has the store-to-the-second-register as the primary or only version of an operation, which can lead to more operations overall (and cognitive overhead IMO).</p><h3 id="benchmarking-on-arm">Benchmarking on ARM</h3><p>So let’s take a look at some benchmarks.
The most interesting thing about looking at population count is that this little routine does something useful and shows tradeoffs between CPU bounds and memory bandwith between the CPU, the on-chip caches, and main memory.
At array sizes small enough to fit into CPU cache (but big enough to run the compute loop a few times), the CPU is the limiting factor – how many bits it can count.
For larger data sizes, the memory bandwidth becomes the bound; the CPU is waiting on getting enough data to crunch through.</p><p>To this end, the benchmark curves in the repository max out in throughput at about 16K (most work possible, while still being in cache) and then trail down into a steady state as memory becomes the bound. So I’ll truncate the full benchmarks to compare peak throughput and long tail.</p><p>Some findings and commentary:</p><h4 id="raspberry-pi-4">Raspberry Pi 4</h4><div><pre><code data-lang="text">Unoptimized (Go implementation):
BenchmarkCountBytesGo/16K              297778          8056 ns/op     2033.78 MB/s
BenchmarkCountBytesGo/512M                  8     279380432 ns/op     1921.65 MB/s

Optimized (My hand-rolled assember):
BenchmarkCountBytes/16K                520807          2303 ns/op     7113.24 MB/s
BenchmarkCountBytes/512M                    8     131214574 ns/op     4091.55 MB/s
</code></pre></div><p>This was my finished product on my local Pi. I may be able to do better, but varying the block sizes between grabbing from memory and doing the vector addition for popcount topped out about here, so I’m fairly satisfied.</p><p>Interestingly, the ~4.1GB/s memory bandwidth follows exactly with <a href="https://hackaday.com/2019/07/10/raspberry-pi-4-benchmarks-processor-and-network-performance-makes-it-a-real-desktop-contender/">initial read benchmarks of the Pi 4</a> suggesting it’s close to saturation, which is good news.</p><h4 id="ampere-emag">Ampere eMag</h4><p>So my next thought was to spin up an ARM64 server with my old friends at <a href="https://packet.net/">Packet</a>. They have a <a href="https://www.packet.com/cloud/servers/c2-large-arm/">c2.large.arm</a> and it’s gonna be great!</p><div><pre><code data-lang="text">Unoptimized:
BenchmarkCountBytesGo/16K      	   69939	     17208 ns/op	 952.09 MB/s
BenchmarkCountBytesGo/512M     	       2	 582293709 ns/op	 921.99 MB/s

Optimized:
BenchmarkCountBytes/16K        	  458394	      2614 ns/op	6267.80 MB/s
BenchmarkCountBytes/512M       	      12	  93371433 ns/op	5749.84 MB/s
</code></pre></div><p>…but I was rather underwhelmed.</p><p>This isn’t necessarily Packet’s fault – they were early onto having ARM hardware available and it’s …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://barakmich.dev/posts/popcnt-arm64-go-asm/">https://barakmich.dev/posts/popcnt-arm64-go-asm/</a></em></p>]]>
            </description>
            <link>https://barakmich.dev/posts/popcnt-arm64-go-asm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818574</guid>
            <pubDate>Mon, 13 Jul 2020 08:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Consolidation of the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817946">thread link</a>) | @Fizzadar
<br/>
July 13, 2020 | https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/ | <a href="https://web.archive.org/web/*/https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
 
<div>

        <h2>
            On the Consolidation of the Web
            <span>Wed 29 July 2020</span>
        </h2>

        <p>In recent years, the web has been consolidating. From the servers to the apps, a growing majority of the web is controlled by a small pool of companies. When AWS was founded in 2006 I was just starting out with my first VPS, running this blog on WordPress (the good ol' days!). For the last 10 years I have part-run a small VPS (“cloud server”) host called <a href="https://afterburst.com/">Afterburst</a>. Throughout these years I have watched this consolidation, and these are my observations.</p>

<h3>The Pre-Cloud Days</h3>

<p>Way back in 2009 blogs were booming. The market for personal servers was growing rapidly. People often used forums (remember those?) to find providers. Providers would compete to attract the most eyeballs to their sale posts.</p>

<p>The quality and cost of hosting varied wildly. During summer there would be a huge influx of budget “summer hosts” during school holidays. The majority of these would then fold only two months later. Thinking back, it was The While West. Of course there were big players; but the smaller hosts had the cheapest offers and captured the market for personal servers.</p>

<p>I believe that this was a great market for all. Buyers had a wealth of choice of companies tiny to massive. Providers were kept in check by thriving forum communities, leading to better services. The smaller providers would offer a personal touch, often partaking in forums alongside their customers. To me, this was an amazing environment in which I learnt a huge amount about servers but also customer service.</p>

<h3>The Clouds Ascend</h3>

<p>The VPS market was exploding when we started Afterburst in 2010. Shared hosting/PHP was stagnating and the prices had bottomed out. Shared hosting was consolidating fast, hosts were folding daily. Dedicated server and VPS markets remained strong and WebHostingTalk (our “home” forum) was buzzing with activity. The competition for the best VPS was in full swing.</p>

<p>And then came DigitalOcean.</p>

<p>When DO arrived in 2011 everything changed. They managed to make the much hyped “cloud” accessible to everyone where AWS had so far struggled. You could click a button and have a cloud server available within minutes. The all-SSD package, “cloud” marketing and a wave of free launch coupons caused them to explode onto the scene.</p>

<p>It was fascinating to watch the “cloud” hype train. “Cloud servers” were, almost overnight, seen as superior to “VPS”. This is despite most “cloud server” providers offering nothing different to VPS. Now I totally get that The Cloud goes way beyond servers. The offerings today include a staggering number of services. But an individual looking for a server to host their blog? They don’t need any of that, just the server space.</p>

<p>In the years since DO arrived they, AWS and later Azure/GCloud boomed. Cloud was/is the future - we must move everything “to the cloud” many a huge tech company would say. As much as it was marketing hype, the individual started to follow. The cloud was only a little more expensive and came with fancy UI and excellent developer tooling. It was cool to be using the cloud. The small/traditional VPS provider market began to slow, and later reduce. The golden days were over.</p>

<p>Whilst this was very frustrating at the time it also forced us to review and improve our marketing and customer experience. We started marketing cloud servers and optimised the checkout and customer sign-up flow. The competition led to an improved service for existing and new customers.</p>

<h3>So - where are we now?</h3>

<p>10 years later, we’re still here! The consolidation of providers has slowed and many continue to survive. Forums like WHT struggle on but are shadows of their former selves. There’s still a market for individual servers - people have a natural desire to tinker in ways that specific services cannot provide.</p>

<p>I think there will remain a cohort of individual bloggers and websites. But I also believe the web is dividing. On one side a small number of platforms the vast majority of “normal” people consume from and share to. And elsewhere a separate “old style” web of fragmented loosely connected websites/forums/blogs formed by those who tinker. Perhaps something will merge the two together in the future.</p>

<p>It’s like supermarkets consuming ‘Mom and Pop shops’, a trend that goes back decades now. Yet small greengrocers and butchers still live on. There are signs of people returning to these shops in growing numbers. Perhaps this is the start of a reverse trend, could the web follow suit? I’d like to think so.</p>
</div>
    
    </section></div>]]>
            </description>
            <link>https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817946</guid>
            <pubDate>Mon, 13 Jul 2020 07:18:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Sourcing Company Culture]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817799">thread link</a>) | @soorajchandran
<br/>
July 12, 2020 | https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/ | <a href="https://web.archive.org/web/*/https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-318">

	

	
	<div>
		
<figure><img data-attachment-id="353" data-permalink="https://blog.oysterhr.com/adobestock_32068789/" data-orig-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png" data-orig-size="1491,1008" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="adobestock_32068789" data-image-description="" data-medium-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300" data-large-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=750" src="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024" alt="" srcset="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024 1024w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=150 150w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300 300w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=768 768w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png 1491w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>TL;DR: <em>Companies that have recently gone fully-remote can draw inspiration from open source. Doing so provides helpful ways to think about attracting talent and building culture.&nbsp;</em></p>



<p><strong>Fully-Distributed is Taking Off</strong></p>



<p>Though the headlines have focused on the <a rel="noreferrer noopener" href="https://www.cnn.com/2020/05/22/tech/work-from-home-companies/index.html" target="_blank">big name companies</a> and their announcements about going remote, events of the last four months have undoubtedly created a lot of new fully-distributed companies you’ve <a rel="noreferrer noopener" href="https://www3.nhk.or.jp/nhkworld/en/news/videos/20200622091038913/" target="_blank">never heard of</a>. This includes organizations that may have been partially or even fully-colocated (office-based) before Coronavirus. And this is happening in part because remote working has worked out so well for so many of them, and in part because it has proven difficult for many companies to scale down to a “reduced” real estate footprint — to serve a subset of their employees. Hybrid is <a rel="noreferrer noopener" href="https://www.linkedin.com/pulse/remote-work-having-moment-future-isnt-hybrid-sid-sijbrandij/" target="_blank">harder</a> than fully-distributed, we keep hearing. And the truth is that returning to the office is still an open discussion (fraught with overwhelming <a rel="noreferrer noopener" href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank">emergent</a><a href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank" rel="noreferrer noopener"> logistical considerations</a>) even for companies that really want to.</p>



<p>We have also no doubt seen in the last four months an acceleration in the rate of creation of new fully-distributed startups that reject offices altogether, and that do not expect their people to meet physically to get work done. This was already a trend, and any founders who may have been hesitant before Coronavirus because they were worried about investor bias or their own inexperience with remote leadership, now have <a href="https://techcrunch.com/sponsor/oyster/the-dawn-of-the-distributed-age/" target="_blank" rel="noreferrer noopener">enormous encouragement</a> to kick the office to the curb.</p>



<p>This means, however, that now many, many more companies, not just the ones that were already on the fully-distributed bandwagon before COVID-19, are going to face the challenges unique to fully-distributed organizations.</p>



<p><strong>Next-Level Guidance is Needed</strong></p>



<p>There’s been a great outpouring of new content from the community on the basic how-to’s of remote working. We have also seen that the “bibles of remote working” (that have been around for years from the pioneering remote working companies like <a rel="noreferrer noopener" href="https://distributed.blog/" target="_blank">Automattic</a>, <a href="https://about.gitlab.com/company/culture/all-remote/guide/">Gitlab</a>, and <a href="https://basecamp.com/remote-resources">Basecamp</a>, etc) are getting the reference attention they deserve. These basics (like asynchronous communication) are of course essential principles that have to be properly installed for a fully-distributed team to walk and run. But there are other challenges that come with being a fully-remote organization for which there’s less explicit guidance.</p>



<p>Two such challenges we keep hearing about are:</p>



<ul><li>How do you attract and recruit great talent from around the world (<em>whom you may never meet in person</em>)?, and</li><li>How do you create and sustain great culture (<em>when everything is virtual</em>)?</li></ul>



<p><strong>Open Source, a Model of Distributed Success</strong></p>



<p>To these important challenges of fully-distributed organizations, the <a href="https://www.redhat.com/en/topics/open-source/what-is-open-source" target="_blank" rel="noreferrer noopener">principles and history of Open Source</a> would seem to offer a lot.&nbsp;</p>



<p>We often hear that software “eats” things. An aspect of that is that the ways of software development continue to penetrate into the ways other types of work are done. That open source should provide ways of thinking and working that are helpful to fully-distributed organizations may be yet another example of something that started in software development spreading more generally into business. Like <a rel="noreferrer noopener" href="https://agilemanifesto.org/principles.html" target="_blank">Agile</a> and <a rel="noreferrer noopener" href="https://www.agilealliance.org/glossary/kanban/" target="_blank">Kanban</a> have. This keeps happening because these “frameworks from another domain” offer avenues to better ways of working, even when what you’re doing is some other type of knowledge work.&nbsp;</p>



<blockquote><p>Whether or not they are a software company, fully-distributed organizations are going to have to become more like software companies in their ways of working.</p><a href="http://twitter.com/share?&amp;text=Whether%20or%20not%20they%20are%20a%20software%20company%2C%20fully-distributed%20organizations%20are%20going%20to%20have%20to%20become%20more%20like%20software%20companies%20in%20their%20ways%20of%20working.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=HeyOyster" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>This shift will be necessary for non-software development knowledge work to be done well in a fully-distributed organization. Naturally, that has deep implications for how technology will support knowledge work in the future. For that reason, we’re also going to see a pattern where new tools are going to be created that allow non-software developer knowledge workers to work more like developers do. This was also probably a trend well in evidence before Coronavirus, now greatly accelerated.</p>



<p>Once your organization is thinking and working a bit more like a fully-distributed software company (especially if you ARE a software company), it shouldn’t be too difficult to aspire to some of the attributes of an open source project.&nbsp;&nbsp;</p>



<p>Open source is worthy to provide guidance and inspiration to any fully-distributed company because it demonstrates a model through which great talent is not only attracted but also uniquely enabled and remotely synchronized to produce semi-miraculous results.&nbsp;</p>



<p>There is no better example of this than Linux.</p>



<blockquote><p>“Linux was the first project for which a conscious and successful effort to use the entire world as its talent pool was made.”</p><cite><em>Eric Steven Raymond, <a rel="noreferrer noopener" href="http://www.catb.org/~esr/writings/cathedral-bazaar/cathedral-bazaar/ar01s11.html" target="_blank">The Social Context of Open-Source Software</a></em></cite></blockquote>



<p>Successful open source projects like Linux should inspire fully-distributed companies because they demonstrate the extraordinary productivity potential of organized knowledge work performed by a team of people who didn’t ever have to meet in person to accomplish it.</p>



<p><strong>Becoming a Beacon for Global Talent</strong></p>



<p>Organizations who’ve let go of their offices and have recently made the transition to fully-distributed are probably still focused on getting things back on track, and on fostering the healthy continuity of the pre-existing team. Though hiring may not be the present priority, they must surely be thinking about how recruitment will work as a fully-remote company. Whether they are fully-distributed or just have newly-created remote roles, as organizations shift their recruiting perspective from thinking locally to thinking globally, this is going to radically transform the recruiting process as we have known it.&nbsp;</p>



<p>Even for companies that decide they will only hire in a subset of timezones (to facilitate synchronous work, like <a href="https://www.quora.com/q/quora/Remote-First-at-Quora" target="_blank" rel="noreferrer noopener">Quora</a>), the size of the available talent pool would still overwhelm the traditional recruitment approaches of “publishing” their open roles and waiting for “applicants” to express an interest in them. The new pervasiveness of remote working and highly-distributed companies is going to create unprecedented liquidity in the global talent marketplace. This is great for all parties, but it also means that everyone’s game has to change.&nbsp;</p>



<p>Thinking and acting like an open source project may be a good way for fully-distributed companies to evolve their talent acquisition game. Reflect on the Linux example in a post-Coronavirus talent market. When the most talented individuals can work for any company in the world, how will your company compete? How can your company distinguish itself amongst a much larger number of prospective employers?</p>



<blockquote><p>The downside for employers gaining access to the global talent pool is that they are also suddenly competing with every company in the world for talent.</p><a href="http://twitter.com/share?&amp;text=The%20downside%20for%20employers%20gaining%20access%20to%20the%20global%20talent%20pool%20is%20that%20they%20are%20also%20suddenly%20competing%20with%20every%20company%20in%20the%20world%20for%20talent.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=2hp" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>One approach is to become like an open source project, whose first organizing principle is attracting people who care deeply about the same thing. This of course requires knowing what that special thing (of singular and obsessive focus) is for your organization. I think most companies can find their unique <a href="https://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action" target="_blank" rel="noreferrer noopener">Why</a>, if they try. And I think it’s a good thing that prospective global employers should feel they have to produce a thoughtful and compelling expression of their purpose to compete for global talent.</p>



<p><strong>Creating Culture on Purpose</strong></p>



<p>Perhaps your company is bootstrapping its culture for the first time as a brand new fully-distributed startup. Or perhaps you’re an established organization now transitioning from an office-based culture. Either way, you may as a leader be wondering how to develop and nurture culture when everything is virtual and everyone’s remote.</p>



<p>Attracting people who share a common passion is potentially more than just a way to acquire talent. It can also be a terrific way to instantiate culture. But attracting talent like an open source project, however, is not just about having a clear and compelling purpose. It’s also about calling those talented people to come work on that purpose together in a <strong>particular</strong> way.</p>



<blockquote><p>“Culture is a pattern of basic assumptions — invented, discovered, or developed by a given group as it learns to cope with its problems of external adaptation and internal integration — that has worked well enough to be considered valid and, therefore, to be taught to new members as the correct way to perceive, think, and feel in relation to those problems.”</p><cite><em>Edgar Schein, <a rel="noreferrer noopener" href="https://agustinazubair.files.wordpress.com/2013/04/13-organizational_culture_and_leadership_3rd_edition-p-4581.pdf" target="_blank">Organizational Culture and Leadership</a></em></cite></blockquote>



<p>In other words, culture is inherently linked to a particular problem space, and isn’t directly about people or their attributes. Organizational culture is about how people decide to work together on a specific set of problems.</p>



<p>For many office-based companies, the “Our values” plaque that hangs on the wall is just a list of nice ideas. And though that list of values is intended to be the codification of their culture, those values may not relate in any useful way to the work to be done, and therefore probably don’t drive much useful behavior. The experience and the effects of culture, therefore, are organic, accidental, and overly-dependent on physical proximity.</p>



<blockquote><p>“Running a remote work environment effectively, requires amongst other things a deliberate approach to culture development. </p><p>Transitioning from an office to remote is not going to be easy for a lot of companies. The reason for this is leaders took the human proximity, camaraderie, informal comms &amp; ‘water cooler moments’ for granted. </p><p>The majority of CEOs who ran office-based businesses before the pandemic and didn’t invest in their culture unknowingly relied on their office space environment to hold their unwritten culture together.”</p><cite><em>Bretton Putter (via <a rel="noreferrer noopener" href="https://twitter.com/BrettonPutter/status/1263829426258817025" target="_blank">Twitter</a>)</em></cite></blockquote>



<p>As human beings we abhor vacuums, particularly social ones. This is the reason why, in the face of non-deliberate culture, we are able to “fill in” …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</a></em></p>]]>
            </description>
            <link>https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817799</guid>
            <pubDate>Mon, 13 Jul 2020 06:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817638">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-yui_3_17_2_1_1590947194898_9413"><div><p>Many of the common startup frameworks for tech companies do not apply as well to biotech. I’ve gone through the most common frameworks below, and how they differ for biotech companies. </p><p>I’m defining a tech startup here as a company whose product is largely based off of code. I am not including in my arbitrary categorization ‘deep tech’ (e.g., autonomous trucks, satellite startups, etc), which often face similar challenges as biotech companies. </p><p>Biotech here is a startup developing a drug. </p><p><em>These are generalizations, and many exceptions exist. </em></p><h2><strong>Risks and Finding Product Market Fit</strong></h2><p><span><strong>TECH</strong></span><strong>: Significant market and execution risks<br></strong><span><strong>BIOTECH</strong></span><strong>: Minimal market risk, a lot of technical risk</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_605840"><div><p>In tech, the company often uses a standard software stack and applies it in a novel way (a new product). The question is usually not ‘can this thing be built’, but ‘does anyone want this thing we made’?</p><p>In biotech, this is flipped. The market (a disease) is well established, but the ability to develop a product (a drug) that addresses this market is the core risk. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_607921"><p><span><strong>TECH</strong></span><strong>: Rolling derisking, early signs of product-market fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Derisking comes in bursts over years (biological milestones), early signals less reliable</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_617219"><div><p>In tech, you want the ‘up and to the right’ chart, showing exponential increase of some core metric of the company. Adoption, revenue, and other metrics derisk the company and give early signs of PMF. Early signs can be highly predictive of the company’s eventual success.</p><p>In biotech, derisking the company is predominantly tied to specific biological milestones. These come in bursts, with long periods of waiting in-between. Additionally, early milestones (such as the drug working in mice) aren’t 1-to-1 predictive of eventual success (the drug working in people).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_619233"><p><span><strong>TECH</strong></span><strong>: Iterate to product-market-fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Product (drug) finalized years before on market</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_631626"><div><p>In tech, the product is constant iterates and improves from customer feedback to find the exact product that people want. </p><p>In biotech, due to the extensive regulation, the final product (the drug) is finalized years before it first goes into people. If the drug doesn’t work in people, there is no iterating. If you want to modify the product, you need to restart the entire process over again. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_633705"><div><h2><strong>Founders &amp; Market</strong></h2><p><span><strong>TECH</strong></span><strong>: Founders often bring insight around a market<br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often bring insight around key biology</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_651094"><div><p>In tech, a prototypical founder often worked at the incumbent company or realized a market opportunity by being that market themself. The insight around the market opportunity itself is a core value of the company. </p><p>In biotech, the insight of the founder is around a new or better way to develop a drug for the disease, or a discovery that was made in the laboratory (and the relevant patents around it). </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_665620"><p><span><strong>TECH</strong></span><strong>: Founders often younger, ‘youth wunderkinds’ widely accepted <br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often older due to scientific training or are a professional CEO, rarer to have very young founders </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_678110"><div><p>In tech, the 18-year-old drop-out is lauded and mystified. If anything, older founders may be subconsciously discriminated against in favor for younger founders. </p><p>In biotech, the prototypical founder is older, often a career CEO or exec coming out of a Big Pharma company. At minimum, the founders almost always have significant scientific training - a PhD can take 6-8 years, and post-docs 2-3 years each. It is less common to see founders in their 20s and you almost never see ‘youth wunderkinds’. This is in part due to the conservatism of the industry and in part because extensive scientific training is generally necessary to have enough biological insight to correctly identify an opportunity. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_420694"><p><span><strong>TECH</strong></span><strong>: Can create a new market<br></strong><span><strong>BIOTECH</strong></span><strong>: Markets are diseases and therefore public domain</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_422265"><div><p>In tech, some of the most successful companies created or defined their market - a classic example being ride sharing. Once a new market is validated, other companies/copycats/fast-followers flow in. </p><p>In biotech, the market opportunities are diseases. New markets can somewhat be created (e.g., nootropics, elective medicines, Viagra) but generally speaking the markets are well known. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_423860"><p><span><strong>TECH</strong></span><strong>: Markets are winner-take-all<br></strong><span><strong>BIOTECH</strong></span><strong>: Many winners</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_458802"><div><p>In tech, investors often bet on a specific horse with the hope that the horse will win the race (and all the earnings). Bifurcated markets can be especially dangerous as companies compete on pricing and ‘race to the bottom’.</p><p>In biotech, the markets are <em>so </em>large, and the unmet need so high, that there can and often are many winners in one market (disease). The classic example here are statins, which in 2020 had over $1 trillion in sales across seven market approved statins, with the best-selling Lipitor having peak sales of $12B in the mid-2000s. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_456236"><div><h2><strong>Product Strategy</strong></h2><p><span><strong>TECH</strong></span><strong>: Often develop one product at a time, focus is key <br></strong><span><strong>BIOTECH</strong></span><strong>: Portfolio approach is encouraged to de-risk company, exception is one-asset, repurposing plays</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_482826"><div><p>Focus is crucial for any startup. However, in biotech the most successful and valuable companies often take a portfolio approach to product development - developing multiple products simultaneously. In tech, companies generally focus around one product or core offering, only differentiating once they have earned the right to do so by finding PMF with their first product.</p><p>A significant reason for this is to derisk the company against biological randomness. Instead, focus in a biotech company is usually around a core competency - e.g., a method of discovering drugs, or a way of delivering the drug - and then diversified within this core competency. For example, gene therapy company Spark Therapeutics had a core competency of AAV-based gene therapy (a virus loaded with DNA to treat a genetic disease) but leverages this competency simultaneously across multiple diseases. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_484564"><p><strong>﻿</strong><span><strong>TECH</strong></span><strong>: Outsourcing product development or engineering unadvisable<br></strong><span><strong>BIOTECH</strong></span><strong>: Common to use contractors for key experimental work</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_497310"><div><p>In tech, not having someone technical on the founding team is a classic ‘no no’. You generally should have the ability to build (and therefore rapidly iterate on and improve) your core product within the team. </p><p>In biotech, it is common and often preferred to use contract research organizations (CROs) for much of your experimental work. Some experiments can only be done by specialized CROs, and they often have advantages from scale that a startup cannot hope to replicate. Building and staffing a laboratory, including the multiple six-figure machines necessary, is impracticable and unnecessary for most companies. </p><p>Virtual biotechs - companies with distributed leadership and all research outsourced to CROs - have been popular long before it became the tech zeitgeist.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_499137"><p><span><strong>TECH</strong></span><strong>: Fast-followers and copycats a significant risk<br></strong><span><strong>BIOTECH</strong></span><strong>: Strong patent protection </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_570610"><div><p>In tech, being the first/best product to a new market is so important because once you validate a market’s need for a specific product, it is easy for others to copy and chip at your market share. This is especially common in traditional D2C brands, for example the many bed-in-a-box companies. </p><p>In biotech, patents are king. If you hold the key patent it is impossible for your drug to be copied. Once patents expire, however, there is a whole industry (generics) around copying drugs and selling them cheaper than the branded product. Because of the hundreds of millions it takes to develop a drug, it is almost impossible to commercialize a drug that is not able to be protected by patents, regardless of its efficacy. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_568710"><div><h2><strong>Raising, Spending, and Making Money</strong></h2><p><span><strong>TECH</strong></span><strong>: Primary burn usually people costs <br></strong><span><strong>BIOTECH</strong></span><strong>: Primary burn R&amp;D</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_725052"><p>Biotech companies’ biggest line item is undoubtedly R&amp;D spend - funding to do research experiments necessary to find and develop their drug. This is despite the average salary in biotech also often being higher than tech’s.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_722809"><p><span><strong>TECH</strong></span><strong>: Series Seed and A smaller, with larger subsequent rounds to scale and win market share<br></strong><span><strong>BIOTECH</strong></span><strong>: Capital needs front-loaded, Seeds can be the size of tech Series A’s</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_745080"><div><p>In tech, you can often show proof-of-concept or even begin selling your product with a small team and pre-seed capital. </p><p>Biotech Seeds can often look like tech Series As in magnitude. On the East Coast, the first rounds in biotech companies are more than often in the $10s of millions. This is because of the millions needed to hit biological milestones to push the company forward (and therefore qualify for the next stage of financing).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_742704"><p><span><strong>TECH</strong></span><strong>: Often command higher valuations early on <br></strong><span><strong>BIOTECH</strong></span><strong>: Often command lower valuations early on</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_803591"><div><p>Tech valuations usually optimize for selling 10% - 25% of the company in any one financing. </p><p>In biotech, valuations are historically significantly lower, with many East Coast deals selling 50%+ of the company in one financing. Such huge dilution is less common in West Coast biotech financings, but it is more common sell 33%+ of the company in one financing. Biotech founders also often have less negotiating power here because they have to raise large amounts to bring the company to the next stage. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_805993"><p><span><strong>TECH</strong></span><strong>: Business usually has significant revenue at exit <br></strong><span><strong>BIOTECH</strong></span><strong>: Unlikely to have revenue at exit</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_845025"><div><p>While the company may be far from profitable, tech companies almost always have significant revenue at exit (IPO or acquisition). </p><p>In biotech, companies almost never have revenue at exit. Instead, the value of the company is driven by the increasing probability that their drug will work (and therefore decreasing biological risk). The company is often sold or partnered years before the drug is commercialized.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_836878"><div><h2><strong>Team</strong></h2><p><span><strong>TECH</strong></span><strong>: Core team often younger, primed to take more equity over salary<br></strong><span><strong>BIOTECH</strong></span><strong>: Core team often older due to extensive scientific training, often more risk-adverse or otherwise unable to sacrifice heavily on salary </strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_824365"><div><p>In tech, there is a self-selecting group that aspire to work in or on a startup, and are primed to take the high equity with lower salary in the hope that they pick the company that will become a unicorn and make them rich, too. They are often younger …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.celinehh.com/tech-vs-biotech">https://www.celinehh.com/tech-vs-biotech</a></em></p>]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817638</guid>
            <pubDate>Mon, 13 Jul 2020 06:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Evolutionary Psychology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817470">thread link</a>) | @ghosthamlet
<br/>
July 12, 2020 | https://www.deepideas.net/introduction-to-evolutionary-psychology/ | <a href="https://web.archive.org/web/*/https://www.deepideas.net/introduction-to-evolutionary-psychology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				<div>
					


<div> <!-- start fusion sticky header wrapper -->
	<div>
		<div>
							<div data-margin-top="31px" data-margin-bottom="0px" data-margin-left="0px" data-margin-right="0px">
			<a href="https://www.deepideas.net/">

						<!-- standard logo -->
			<img src="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png" srcset="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png 1x" width="332" height="102" alt="deepideas.net Logo" data-retina_logo_url="">

			
					</a>
		
<div>
			<h3>
			a blog on cognitive science and artificial intelligence, dedicated to the deep thinkers of this world		</h3>
	</div>
</div>
								
			
					</div>
	</div>
	
</div> <!-- end fusion sticky header wrapper -->
				</div>
				
			</header>
						
			
		
				
			
			

						<main id="main">
				<div>

<section id="content">
			
	
					<article id="post-648">
						
														
						
																									<div>
				<p>Evolutionary psychology is an approach to understand human behavior that combines insights gained from evolutionary biology, the computational sciences and the study of ancestral living conditions. It has been put forward as an opposing view to what Tooby and Cosmides (1992) call the <em>Standard Social Science Model</em> (SSSM), which has dominated the social and behavioral sciences throughout most of the 20th century. According to the SSSM, the mental organization of adult human beings is not caused by human nature. Rather, humans acquire their mental organization almost entirely from their sociocultural and physical environment. Human beings, on this view, only have a minimal amount of innate impoverished drives (like hunger, thirst, sexual motivation, etc.) and, independently of these, a capacity to be socialized through learning.</p>
<p>A prominent argument given in favor of the SSSM is the fact that genetically determined behavior might be maladaptive due to changing environmental conditions, and therefore the mind evolved towards general-purpose and domain-general learning systems. On this view, the phenotype’s behavior is plastic and tailored toward maximizing individual fitness under changing environmental circumstances. The selective pressures of ancestral environments gave rise to this plasticity, but the concrete adaptive problems that have been faced in these environments play only a minor role in explaining the behavior of modern humans. This is the reason why many social scientists study human behavior in modern conditions more or less independently from their evolutionary history.</p>
<p>Evolutionary psychology, in contrast, holds that psychological mechanisms are evolved adaptations to ancestral adaptive problems. An analogy is drawn here between organs in the body and “cognitive programs” or “mental organs”: Analogous to how organs in the body evolved to solve a particular adaptive problem, e.g. digesting food, cognitive programs evolved to solve a particular adaptive information processing problem, e.g. predator/prey distinction, kin detection, language, etc.</p>
<p>In the following, we will break down the individual tenets of evolutionary psychology and review the arguments that are given in support of these tenets. Since not all tenets are shared by all evolutionary psychologists, we will focus here on the formulation given by Cosmides and Tooby (1987) and Tooby and Cosmides (2005). The tenets are not listed explicitly, but can be reconstructed implicitly from these texts. I will go through each tenet in turn and present a reconstruction of the arguments that motivate these tenets.</p>
<h3>Tenet 1: The brain evolved to be a computer that solves information processing problems.</h3>
<p>This tenet is motivated as follows: Environments pose adaptive information processing problems to organisms. Hence, the genes of organisms that successfully solve these information processing problems spread in the gene pool and such organisms are, by definition, computers.</p>
<p>This tenet, Tooby and Cosmides (2005, p. 31) argue, is shared by proponents of the SSSM. Even a domain-general learning mechanism would be an innate information processing mechanism that evolved at some point to solve adaptive problems. For example, operant conditioning presupposes an innate mechanism to alter the probability of behaviors based on their intrinsically reinforcing consequences (like food or pain). Similarly, classical conditioning presupposes innate unconditioned stimuli and a method to calculate contingencies. Consequently, Tooby and Cosmides (2005, p. 32) conclude that “learning is not an alternative explanation to the claim that natural selection shaped the behavior” and that “a behavior can be, at one and the same time, cultural, learned, and evolved”. This means that the commonly perceived controversy between innateness/evolvedness on the one hand and learnedness on the other is based on a false dichotomy. Rather, it is proposed, evolution created programs as learning mechanisms, and these mechanisms are a prerequisite for learning to be able to occur. The disagreement between the SSSM and evolutionary psychology, therefore, only regards the structure of the evolved learning mechanisms, not the question whether such learning mechanisms evolved at all.</p>
<p>When we accept the theory of evolution through natural selection, it arguably becomes theoretically impossible to deny that the brain evolved to be a computer that solves adaptive information processing problems – unless we claim that (A) evolution hasn’t found this path yet, (B) evolution cannot find this path in principle since it would lead through a fitness valley or (C) adaptive problems aren’t information processing problems and therefore a computer would not be the ideal solution. Discussing these possibilities would be beyond the scope of this introduction, so I am going to suppose (A), (B) and (C) to be false for the rest of this discussion. This leads us to accept this tenet.</p>
<h3>Tenet 2: The brain is not a “blank slate” domain-general fitness-maximizing machine.</h3>
<p>Cosmides and Tooby (1987, p. 47) and Tooby and Cosmides (2005, pp. 294- 299) argue that there is no domain-general success criterion that is correlated with fitness and, therefore, a domain-general mechanism would not be successful at actually maximizing fitness and could therefore not have evolved. This argument can be summarized as follows: If no domain-specific innate knowledge is present in the organism, then it can only acquire knowledge that can be inferred from perceptual inputs, without relying on innate perceptual heuristics. Similarly, it can learn behaviors only through trial and error learning, which would amount to generating random sequences of actions, observing the fitness outcome (e.g. the number of produced offspring) and then reinforcing or mitigating behaviors based on this outcome. Proposing instead that the mechanism could rely on perceptual cues like smell or taste as a proxy for expected fitness, they argue, amounts to “admitting domain-specific innate knowledge”.</p>
<p>However, when observing a certain positive or negative fitness outcome (like an increase or decrease in the produced offspring), it is virtually impossible to trace it back to the precise actions or sequences of actions that caused it, since virtually any action taken before in the organism’s life could have caused it. Furthermore, whether a sequence of action promotes fitness is highly context-sensitive. Thus, due to the resulting combinatorial explosion, behaviors cannot reliably be reinforced or mitigated and behavior stays more or less random. Therefore, an organism with adequate innate domain-specific knowledge, perceptual heuristics and perception-action patterns would have a fitness advantage over an organism that only has a domain-general fitness-maximizing mechanism, consequently triggering selection for organisms with these traits.</p>
<h3>Tenet 3:&nbsp;The brain executes innate, domain-specific, functionally isolable cognitive programs that generate particular behaviors in response to particular external or internal informational inputs. Most or even all of these programs evolved as a response to a particular adaptive information processing problem.</h3>
<p>It should be noted that it is not claimed that all cognitive programs generate behavior deterministically based on the current perceptual input. Rather, some of these programs exhibit what is commonly called <em>experience-dependent plasticity</em>: They are able to learn based on the input they receive throughout the organism’s development (Cosmides and Tooby, 1987, p. 284). For example, the language program learns to acquire the language of a person’s surrounding community. The programs, therefore, did not evolve to produce a certain kind of behavior, but they evolved to produce a mapping from current inputs and the sequence of inputs they received throughout development to behaviors. Different programs have different degrees of experience-dependent plasticity, depending on the fitness advantage that plasticity would provide over genetic determinism in the program’s adaptive domain.</p>
<p>In a similar fashion, programs are <em>experience-expectant</em>: They evolved to be able to develop only if they receive certain informational inputs at critical periods throughout development (Tooby and Cosmides, 2005, p. 34-35). This entails that a program’s innateness does not mean that it is present at birth – much like teeth are innate but not present at birth. Rather, a cognitive program can develop at any point in an organism’s life, depending on whether it is relevant at that point in life and whether the developmentally relevant informational inputs have been received. Tooby and Cosmides (2005, p. 35) stress that this developmentally relevant information consists not only of contingencies in physical laws and the behavior of other organisms, but also of the physical and cultural environment. The latter comprise a second inheritance system that co-evolves with the genes, and changes in these environments can lead to significant alterations in the operation of the cognitive programs, or even a failure of certain cognitive programs to develop.</p>
<p>It should also be noted that it is not claimed that the cognitive programs can&nbsp;only generate behavior according to their original adaptive function. For example, the language program, which arose as an adaptation for spoken language, can learn to acquire reading and writing (Tooby and Cosmides, 2005, p. 26). The ability to learn reading and writing is not an adaptation but a by-product of the adaptation for spoken language.</p>
<p>However, it is claimed that the …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepideas.net/introduction-to-evolutionary-psychology/">https://www.deepideas.net/introduction-to-evolutionary-psychology/</a></em></p>]]>
            </description>
            <link>https://www.deepideas.net/introduction-to-evolutionary-psychology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817470</guid>
            <pubDate>Mon, 13 Jul 2020 05:32:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Is Surprisingly Good as a Server Language]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 326 (<a href="https://news.ycombinator.com/item?id=23817464">thread link</a>) | @signa11
<br/>
July 12, 2020 | https://stu2b50.dev/posts/rust-is-surpris76171 | <a href="https://web.archive.org/web/*/https://stu2b50.dev/posts/rust-is-surpris76171">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
      <div id="main">
        

    

    <div>
        
<p>At some point, I got tired of my old static site generator setup for my blogs and other pages. It was annoying to ssh every time I wanted to make a modification, it was annoying to sftp or sshfs all my images, and so forth. And god forbid, if you ever wanted someone else to write something or make an edit, let me tell you, most people are not particularly happy when you tell him "hey, I'll make you a user on my server, give me your public key so you can ssh in".</p>
<p>I wanted something with a <em>little</em> more dynamism. </p>
<p>So that was the project: a small scope blog, where a few, already <em>trusted</em> users can make, edit, and post new pages in markdown (with a nice markdown editor courtesy of <a href="https://simplemde.com/">SimpleMDE</a>). Additionally, I want a built in jank verison of imgur so I can satisfy my need to be self sufficient without going crazy.</p>
<p>So while I could whip something up in an afternoon with Django, I could also experiment with other languages. The project is simple enough that I can't imagine being too limited by any language's ecosystem. And I've been itching to write something substansive in Rust...</p>
<h3>Which framework?</h3>
<p>The biggest framework is probably <code>actix-web</code>. But</p>
<ol>
<li>When I was scoping out my options months ago, actix-web's maintainer quit with a bunch of drama</li>
<li>At least from what I could tell reading the docs, it seems more suited to APIs rather than servers serving templated HTML</li>
<li>With the above, I wanted this to be a weekend project, not a weekly project, so the more batteries included the better</li>
<li>I really don't want to figure out which async library is considered better. And note that with each async library, comes its own ecosystem of libraries, which only work with that async library, so it's a pretty hard decision to reverse after you made it.</li>
</ol>
<p>So Rocket it is. </p>

<p>Something I didn't realize until I started scoping out this project is that on servers... the memory model is actually pretty simple! </p>
<p>Much of your state is just handled by your database. I <em>never</em> actually fought with the borrow checker. I never had to. For the most part, everything had exactly one owner, and exactly one lifetime: the function that's handling the request. </p>
<p>Rocket, too, has a surprising amount of "magic":</p>
<pre><code>#[get("/posts/&lt;slug&gt;/"]
pub fn post_view(slug: String) -&gt; Option&lt;Template&gt; {
    ...
		
    Some(Template::render("/posts/post", hashmap! { "post" =&gt; post}))
}
</code></pre>
<p>As opposed to Flask's</p>
<pre><code>@app.route("/posts/&lt;string:slug&gt;")
def post_view(slug):
    ...
		
    return render_template("posts/post.html", post=post)
</code></pre>
<p>Rust's macro system has really impressed me so far. Not only is there a shocking amount of "just works", but it's all statically typed and compiled.</p>
<p>The closest analogue to Rocket is flask + all the flask adjacent libraries (SQLAlchemy-flask, etc). Rocket, through the power of 3rd party integrations, comes with two template engines (handlebars, and Tera, which is basically Jinja2), database pooling support for quite a few ORMs/DB drivers, and more.</p>
<p>It's still at the point where you have to roll your own auth, though.</p>
<p>While I've heard comparisons to Django/Rails, it doesn't really seem like they're going that direction. Django/Rails purposefully put you, the developer, on the metaphorical rails, dictating best practices from everything from where the files go, to how you update your models and views. Rocket doesn't do that, and I'm not sure it should ever.</p>
<p>I also had, for the most part, the experience that "if it compiles, it works". Most of my runtime errors were in the templates, which incidentally is the only thing that's not statically typed. </p>
<p>I guess that's really what surprised me. For a lot of it, "it just works"! There's not a lot of boilerplate syntax, type inference keeps your functions clean, and I didn't write a <em>single</em> lifetime annotation at any point. My rust server really didn't look that different from my flask server, or my Django server, and honestly it looks cleaner than my Java server. All with no garbage collector or runtime.</p>

<p>Next, I'll talk about Diesel, which as far as I can see, is the most mature ORM available. While I do have my gripes, it's not really anything "objectively" bad. I suppose it's more on tradeoffs, and Diesel chooses to go light on the magic. </p>
<p>For one, it's annoying to make two structs for each table. You need one to represent the table, and one to insert with (with any autogenerated columns like the primary key removed). For instance, I have</p>
<pre><code>#[derive(Identifiable, Queryable, Associations, PartialEq, Debug, Serialize)]
#[belongs_to(BlogPosts, foreign_key="post_id")]
#[table_name = "tags"]
pub struct Tag {
    id: i32,
    tag_name: String,
    post_id: i32,
}

#[derive(Insertable)]
#[table_name = "tags"]
pub struct InsertTag {
    tag_name: String,
    post_id: i32
}
</code></pre>
<p>Additionally, while in some ORMs you write your table models, and the ORM generates your SQL migrations, in Diesel, you write your SQL migrations by hand, and the ORM generates a <code>schema.rs</code> file that contains the mappings. I actually don't mind that one too much.</p>
<p>Diesel also only supports parent-child relationships, and you have to be quite explicit. There's no magic field on your parent, that magically gives you a list of its children. No, you just have to write the query and call it. In some sense it's more like using a slightly fancier query builder.</p>
<p>Dipping down from that level of magic, it's not really a <em>bad</em> thing per se. By being explicit, you prevent users from believing too much in that magic, and shooting themselves in the foot, like N+1 selects. </p>
<p>But I'm not going to say it didn't slow me down quite a bit, either. And to be honest, writing joins was a humongous pain in the ass. Maybe that's how it should be, but maybe that also caused a generation of NoSQL databases. 🤷</p>

<p>Here's how you upload an image in flask</p>
<pre><code>@app.route('/images/upload')
def upload_file():
	files = request.files['file']
	if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
</code></pre>
<p>Here's the "simpler" example, while using a <em>third party library in addition</em> from abonader</p>
<p><a href="https://github.com/abonander/multipart/blob/master/examples/rocket.rs"><strong>See the whole thing here</strong></a></p>
<pre><code>#[post("/upload", data = "&lt;data&gt;")]
// signature requires the request to have a `Content-Type`
fn multipart_upload(cont_type: &amp;ContentType, data: Data) -&gt; Result&lt;Stream&lt;Cursor&lt;Vec&lt;u8&gt;&gt;&gt;, Custom&lt;String&gt;&gt; {
    // this and the next check can be implemented as a request guard but it seems like just
    // more boilerplate than necessary
    if !cont_type.is_form_data() {
        return Err(Custom(
            Status::BadRequest,
            "Content-Type not multipart/form-data".into()
        ));
    }

    let (_, boundary) = cont_type.params().find(|&amp;(k, _)| k == "boundary").ok_or_else(
            || Custom(
                Status::BadRequest,
                "`Content-Type: multipart/form-data` boundary param not provided".into()
            )
        )?;

    match process_upload(boundary, data) {
        Ok(resp) =&gt; Ok(Stream::from(Cursor::new(resp))),
        Err(err) =&gt; Err(Custom(Status::InternalServerError, err.to_string()))
    }
}

fn process_upload(boundary: &amp;str, data: Data) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {
    let mut out = Vec::new();

    // saves all fields, any field longer than 10kB goes to a temporary directory
    // Entries could implement FromData though that would give zero control over
    // how the files are saved; Multipart would be a good impl candidate though
    match Multipart::with_body(data.open(), boundary).save().temp() {
        Full(entries) =&gt; process_entries(entries, &amp;mut out)?,
        Partial(partial, reason) =&gt; {
            writeln!(out, "Request partially processed: {:?}", reason)?;
            if let Some(field) = partial.partial {
                writeln!(out, "Stopped on field: {:?}", field.source.headers)?;
            }

            process_entries(partial.entries, &amp;mut out)?
        },
        Error(e) =&gt; return Err(e),
    }

    Ok(out)
}
</code></pre>
<p>Now, to be fair, Rocket is in version 0.4.5. From <a href="https://github.com/SergioBenitez/Rocket/issues/106"><strong>this github issue</strong></a>, multipart form support is coming in 0.5.0. But it doesn't change the fact that right now, the current libraries are somewhat immature still. They lack some of the edge features, especially for more traditional web servers that serve templated HTML, as opposed to pure API servers, or an SPA. </p>
<hr>
<p>Rust's errors are quite good, usually. But that's before you get into, well, libraries that try to do a bit more. I ran into some... interesting error messages, mostly from macros in Rocket and Diesel. Take a look at this one, for instance.</p>
<pre><code>the trait bound `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32): diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not satisfied

the trait `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not implemented for `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32)`

help: the following implementations were found:
        &lt;(A, B, C, D, E, F, G, H, I) as diesel::Queryable&lt;(SA, SB, SC, SD, SE, SF, SG, SH, SI), __DB&gt;&gt;
note: required because of the requirements on the impl of `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stu2b50.dev/posts/rust-is-surpris76171">https://stu2b50.dev/posts/rust-is-surpris76171</a></em></p>]]>
            </description>
            <link>https://stu2b50.dev/posts/rust-is-surpris76171</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817464</guid>
            <pubDate>Mon, 13 Jul 2020 05:31:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The three levels of Hindu philosophy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817439">thread link</a>) | @paraschopra
<br/>
July 12, 2020 | https://invertedpassion.com/three-levels-of-hindu-philosophy/ | <a href="https://web.archive.org/web/*/https://invertedpassion.com/three-levels-of-hindu-philosophy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-511">
		<!-- .entry-header -->
	<div>
		
		
<p><strong>1/</strong> The first level related to the metaphysical and spiritual domain.</p>



<p>It says that Brahman is all that exists and our material world (Maya) comes from ignorance.</p>



<p>The Brahman is not a God. It is beyond any quality – it isn’t intelligent, good or bad. It just is.</p>



<p><strong>2/</strong> It also suggests that if we strip away all ignorance, we will discover that the self – the atman – is one and the same thing as the Brahman.</p>



<p>At its core, this level denies the duality of subject and object and says they both are the same.</p>



<p><strong>3/</strong> The second level has more religious connotations because, like all religions, its purpose is the stabilization of society.</p>



<p>The concept of Karma and Dharma ensures that society has net positive interactions. And the rituals and idol worship ensures everyone knows who is in the camp.</p>



<p><strong>4/</strong> This level ensures an ethical code exists and that it’s clear who all share that same ethical code.</p>



<p>The symbols – the idols, the chants, the rituals – take a spiritual dimension on their own, but these are subservient to the belief in one Brahman – the essence of the world.</p>



<p><strong>5/</strong> The third level is psychological – to give guidance to an individual on how to live his/her life.</p>



<p>The suggestion in <a href="https://invertedpassion.com/what-gita-teaches-us-and-what-it-doesnt/">Gita</a> that one must do work without an expectation of reward is towards minimizing psychological anguish.</p>



<p><strong>6/</strong> To reiterate, the three levels of Hindu philosophy are:</p>



<ul><li>METAPHYSICAL: <a href="https://en.wikipedia.org/wiki/Mah%C4%81v%C4%81kyas">Tat tvam asi.</a> You’re it [it = Brahman]</li><li>SOCIETAL: Rebirth, Karma, Dharma, and Rituals</li><li>PSYCHOLOGICAL: Expect no reward</li></ul>



<p><strong>7/</strong> Of course, everyone has their interpretation. Unlike Judeo-Christian religions, there are no definitive books on Hindusim.</p>



<p>Rather than a bug, I think it’s a feature.</p>



<p>It ceases to be a philosophy if you can’t interpret it on your own.</p>



<p><strong>8/</strong> There are some beautiful ideas in Hinduism, though I’m not sure I agree with all of them.</p>



<p>If you have your favorite ideas, let me know. I love diving deep into Indian philosophy.</p>



<p><em>This essay is a lightly-edited version of a <a href="https://twitter.com/paraschopra/status/1104658952061681665">Twitter thread I posted</a>.</em></p>



<p>Someone made an image out of the three levels:</p>



<figure><img src="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg" alt="" srcset="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg 756w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-221x300.jpg 221w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-768x1041.jpg 768w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-1134x1536.jpg 1134w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq.jpg 1338w" sizes="(max-width: 756px) 100vw, 756px"><figcaption>Made by <a href="https://twitter.com/nisacharan">@nishacharan</a></figcaption></figure>



<p><span><strong>Have an opinion on this essay?</strong></span> You can send your feedback on <a href="https://invertedpassion.com/cdn-cgi/l/email-protection#4838293a293b7971707f6321382e2d2d2c2a292b23082f25292124662b2725">email</a> to me.


</p>



			</div><!-- .entry-content -->
						<!-- .entry-footer -->
		</article></div>]]>
            </description>
            <link>https://invertedpassion.com/three-levels-of-hindu-philosophy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817439</guid>
            <pubDate>Mon, 13 Jul 2020 05:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Butt Pomodoro – A butt triggered pomodoro timer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817401">thread link</a>) | @Abishek_Muthian
<br/>
July 12, 2020 | https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A need gap of <a href="https://needgap.com/problems/130-remind-me-to-take-break-when-working-from-home-wfh-activity" target="_blank">Remind me to take break when working from home</a> was recently posted. Forgetting to take regular breaks when immersed with work in front of a computer is a common problem, especially when working from home.</p><p>On the flip side, <a href="https://needgap.com/problems/30-getting-things-done-at-individual-level-productivity-taskmanagement" target="_blank">getting distracted from completing a task</a> is also a common problem.</p><h3 id="why-pomodoro">Why pomodoro?</h3><p><a href="https://en.wikipedia.org/wiki/Pomodoro_Technique" target="_blank">Pomodoro technique</a> is to work in 25 minutes intervals called pomodoro, taking 5 minutes break every pomodoro and taking a 30 minutes break after 4 pomodoros.</p><p>This helps in mitigating <a href="https://needgap.com/problems/93-focus-drift-cognitivescience-neuroscience" target="_blank">focus drift</a>, burn outs and enables us to complete our tasks.</p><h3 id="why-butt-triggered">Why butt triggered?</h3><p>There are no dearth of pomodoro timer based apps in the market, but they require manual trigger of the timer each time we are about to start a task, this is a huge overhead as stated by in the first problem statement.</p><p>I personally feel that the activity of constantly interacting with the pomodoro timer is counter-intuitive for productivity and so to address that it needs to be triggered seamlessly without any user action.</p><p>Most of us work with the computer while seated on a chair, I figured that triggering the pomodoro timer with a sensor under the seat would fulfil my goals.</p><h3 id="design-goals">Design goals</h3><h4 id="simple">Simple</h4><p>The solution should be simple enough to be easily reproducible by many, even by those without the technical know-how of the solution.</p><h4 id="portable">Portable</h4><p>Setup should be easily transportable to any chair, be it at home or office. Hence, facial recognition with machine learning based solution is not being considered.</p><h4 id="inexpensive">Inexpensive</h4><p>Components should be easily available and inexpensive.</p><h3 id="design-choices">Design choices</h3><h4 id="sensor">Sensor</h4><p>Sensor is needed to trigger the timer when I sit on the chair, basically to serve as a switch.</p><p>I started with a pressure sensor made with Velostat fabric, since its light weight and could seamlessly fit between the seat cushion and the chair. But the resistance varied too much in my test to serve as a reliable switch and I didn’t like the possibility conductive threads setting my ass on fire if they get shorted.</p><p><amp-accordion id="velostat-accordian" disable-session-states=""><section><h5>Click to see Velostat with Conductive Threads</h5><amp-img alt="Velostat with conductive thread" src="/images/Velostat_Conductive_Thread.jpg" width="3915" height="3813" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="trigger">Trigger</h4><p>Then I experimented with a standard 12mm momentary button switch on a 170 holes mini breadboard and it served the purpose well. Depending upon your chair, seat cushion and your weight; you might have to choose a button which works well for you.</p><p><amp-accordion id="button-accordian" disable-session-states=""><section><h5>Click to see Momentary Button</h5><amp-img alt="Button" src="/images/Momentary_Button.jpg" width="2863" height="3451" layout="responsive"></amp-img></section><section><h5>Click to see Mini Breadboard</h5><amp-img alt="Button" src="/images/Mini_Breadboard.jpg" width="1670" height="1365" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="microcontroller">Microcontroller</h4><p>Microcontroller is needed process the input signal from the button, compute the timers and send message to the notifications.</p><p>ESP8266 based NodeMCU is being used the microcontroller for this as it has WiFi for communication.</p><p><amp-accordion id="nodemcu-accordian" disable-session-states=""><section><h5>Click to see NodeMCU</h5><amp-img alt="NodeMCU" src="/images/ESP8266_NodeMCU.jpg" width="962" height="1451" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="power">Power</h4><p>I’m supplying 5V power over microUSB with 18650 power-bank to the NodeMCU.</p><p><amp-accordion id="powerbank-accordian" disable-session-states=""><section><h5>Click to see 18650 Power-Bank</h5><amp-img alt="18650 Power-Bank" src="/images/18650_Power-Bank.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><p><em>Note: The reliability of this power-bank is questionable as I’ve had failures, so I would suggest using a simple battery holder instead.</em></p><p><amp-accordion id="battery_holder-accordian" disable-session-states=""><section><h5>Click to see the setup with battery holder, terminals secured with solder, hot glue and tape</h5><amp-img alt="Butt Pomodoro with Battery Holder" src="/images/Butt_Pomodoro_Battery_Holder.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="computation">Computation</h4><p>My initial plan was to use the NodeMCU itself for computation as that’s what microcontrollers are used for, but stopping the timers at will was bit of a hassle with Arduino code on NodeMCU and decided to leverage the comfort of Go with <a href="https://gobot.io/documentation/platforms/esp8266/" target="_blank">Gobot</a> using Firmata firmware.</p><p>Gobot allows client-server architecture on IoT devices, so NodeMCU can be controlled remotely from a client. The main advantage of using Gobot is that it allows me to modify the code and test it without having to flash it on the NodeMCU each time. I’m running Gobot client on a Raspberry Pi 2 after flashing firmata server on NodeMCU.</p><p><em>Update: Starting and stopping timers with Gobot on NodeMCU within different Goroutines resulted in unnecessary race conditions, deadlocks hence I resorted to calculating elapsed time manually and simple flags to start the timers. I guess, this method could have been easily implemented directly on the NodeMCU with Arduino code, but due to other advantages of using Gobot I’m continuing with it.</em></p><h4 id="communication">Communication</h4><p>I’m using <a href="http://mqtt.org/" target="_blank">MQTT protocol</a> for communication between the devices. <a href="https://appcodelabs.com/introduction-to-iot-build-an-mqtt-server-using-raspberry-pi" target="_blank">A MQTT broker(server) runs on the Raspberry Pi</a> along with the Gobot client which acts as the MQTT publisher.</p><p><a href="https://play.google.com/store/apps/details?id=in.dc297.mqttclpro" target="_blank">MQTT Client android app</a> is the MQTT subscriber. <a href="https://play.google.com/store/apps/details?id=net.dinglisch.android.taskerm" target="_blank">Tasker android app</a> creates a notification when MQTT client receives the message, displays the notification via <a href="https://play.google.com/store/apps/details?id=com.joaomgcd.autonotification" target="_blank">Auto Notification Tasker plugin</a>(paid) and <a href="https://play.google.com/store/apps/details?id=com.rageconsulting.android.lightflow" target="_blank">Light Flow android app</a>(paid) reads out the notification message and creates custom LED light.</p><p>The notification is further received at my desktop smart clock, which is an old android wear smartwatch modified to receive latest Google Play services updates.</p><p><amp-accordion id="communication-accordian" disable-session-states=""><section><h5>Click to see MQTT Client</h5><amp-img alt="MQTT Client" src="/images/MQTT_Client.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Tasker profile</h5><amp-img alt="Tasker Profile" src="/images/Tasker-profile.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Notification Configuration</h5><amp-img alt="Auto Notification Configuration" src="/images/AutoNotification.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Light Flow Configuration</h5><amp-img alt="Light Flow Configuration" src="/images/LightFlow_configuration.jpg" width="1080" height="1920" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="circuit">Circuit</h4><p><amp-accordion id="circuit-accordian" disable-session-states=""><section><h5>Click to see the circuit diagram</h5><amp-img alt="Butt pomodoro circuit diagram" src="/images/Circuit.png" width="614" height="587" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="setup">Setup</h4><p>Here is the overview of the complete architecture and the setup.</p><p><amp-accordion id="architecture-accordian" disable-session-states=""><section><h5>Click to see the architecture diagram</h5><amp-img alt="Butt pomodoro architecture" src="/images/Butt_pomodoro_architecture.png" width="686" height="660" layout="responsive"></amp-img></section><section><h5>Click to see the Butt pomodoro setup</h5><amp-img alt="Butt pomodoro setup" src="/images/Butt_pomodoro_setup.jpg" width="6000" height="4000" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="code">Code</h4><p>Source code for the Gobot client is available over the <a href="https://github.com/heavyinfo/buttpomodoro" target="_blank">GitHub</a>.</p><h4 id="demo">Demo</h4><h5 id="demo-video-enable-audio">Demo Video (enable audio)</h5><p><amp-accordion id="demo_video-accordian" disable-session-states=""><section><h5>Click to see video from Twitter (Fast loading, requires loading of twitter script)</h5><amp-twitter width="375" height="472" layout="responsive" data-tweetid="1281998220118249472"></amp-twitter></section></amp-accordion></p><p><a href="https://abishekmuthian.com/videos/Butt-Pomodoro-Demo.mp4" target="_blank">Click to see video from local .mp4 source, Slow loading, Requires HTML5 video support</a></p><p><a href="https://abishekmuthian.com/videos/Butt_Pomodoro.webm" target="_blank">Click to see video from local .webm source, Slow loading, Requires HTML5 video support</a></p><h3 id="enhancements">Enhancements</h3><p>Further enhancements which could improve the usability of the Butt Pomodoro -</p><pre><code>* Using a PIR (Passive Infrared) sensor as a trigger for contact less butt detection.

* Using a Bluetooth LE based microcontoller to communicate directly with the smartphone for cutting down the separate compute module.

* Custom app record the data on completed pomodoros, incomplete pomodoros, breaks and displaying it with cool visualisations. Of course, for notifications as well.
</code></pre><p>Tweet to me <a href="https://twitter.com/heavyinfo" target="_blank">@heavyinfo</a>.</p><h3 id="business-plan">Business Plan</h3><p>Do you think Butt Pomodoro is something people want?</p><p>Would you like to build Butt Pomodoro as a commercial product? I have <a href="https://hitstartup.com/business-plans/" target="_blank">business plan at hitstartup</a> to help you get started.</p></div></div>]]>
            </description>
            <link>https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817401</guid>
            <pubDate>Mon, 13 Jul 2020 05:17:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting audio code from C to rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817392">thread link</a>) | @est31
<br/>
July 12, 2020 | https://jneem.github.io/nnnoiseless/ | <a href="https://web.archive.org/web/*/https://jneem.github.io/nnnoiseless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    <time datetime="2020-07-12T00:00:00+00:00">July 12, 2020</time>
  </header>
<p>I ported a C library to rust last week, and it went pretty smoothly. This is
the story, and <a href="https://github.com/jneem/nnnoiseless">here</a> is the repo.</p>

<p>The library in question is <a href="https://github.com/xiph/rnnoise">RNNoise</a>, a
library for removing noise from audio. It works well, it runs fast, and best of
all it has no knobs that you need to tune. There’s even a <a href="https://github.com/RustAudio/rnnoise-c">rust
binding</a>.</p>

<p>So why bother porting it?
Well, I need to patch it so that it would compile with MSVC, but my PR went
unnoticed for a month. I thought about maintaining my own fork, but it’s been
more than 10 years since I last wrote anything in C or C++.
And that’s how I ended up porting RNNoise to rust. It probably wasn’t the most
efficient use of my time, but I had fun and learned something.</p>

<p>There’s a lot of information out there about porting C to rust, but the most
useful resource for me was the fantastic
<a href="https://github.com/carols10cents/rust-out-your-c-talk">talk</a> by Carol (Nichols
|| Goulding). It lays out a simple process for porting one function
at a time: first, you set up the cargo to compile as a static library and you
set up the C build system to link that static library into the C library
(see the slides for the relevant Makefile and Cargo.toml snippets).
Then you can port one function at time: the C code goes like this:</p>

<div><div><pre><code><span>+</span><span>extern</span> <span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>);</span>
<span>+</span><span>void</span> <span>__celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>-</span><span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>{</span>
    <span>/* C body of _celt_lpc */</span>
<span>}</span>
</code></pre></div></div>

<p>and the rust code goes like this:</p>

<div><div><pre><code><span>+</span><span>#[no_mangle]</span>
<span>+</span><span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>_</span><span>celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span> <span>ac</span><span>:</span> <span>*</span><span>const</span> <span>f32</span><span>,</span> <span>p</span><span>:</span> <span>c_int</span><span>)</span> <span>{</span>
<span>+</span>    <span>unsafe</span> <span>{</span>
<span>+</span>        <span>let</span> <span>lpc_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts_mut</span><span>(</span><span>lpc</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span><span>);</span>
<span>+</span>        <span>let</span> <span>ac_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>ac</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span> <span>+</span> <span>1</span><span>);</span>
<span>+</span>        <span>rs_celt_lpc</span><span>(</span><span>lpc_slice</span><span>,</span> <span>ac_slice</span><span>);</span>
<span>+</span>    <span>}</span>
<span>+</span><span>}</span>
<span>+</span>
<span>+</span><span>fn</span> <span>rs_celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>],</span> <span>ac</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>])</span> <span>{</span>
<span>+</span><span>// rust body of celt_lpc</span>
<span>+</span><span>}</span>
</code></pre></div></div>

<p>If you’ve watched the talk (which you should), you might notice that this is a
tiny bit different from what they recommend: I’ve renamed the original C
function instead of deleting it. I found that this helped me narrow down porting
mistakes, because it made it easy to switch back and forth between the C and
rust implementations.</p>



<p>Most of the porting process was mechanical and easy. One of the less fun parts was
porting code involving C structs. RNNoise has structs that (when ported to
rust) look like this:</p>

<div><div><pre><code><span>#[repr(C)]</span>
<span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>*</span><span>const</span> <span>RnnModel</span><span>,</span>
    <span>// Various buffers, whose sizes are determined by some subfields of `model`.</span>
    <span>vad_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>An idomatic rust version might look something like</p>
<div><div><pre><code><span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>&amp;</span><span>'static</span> <span>RnnModel</span><span>,</span>
    <span>vad_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>
<p>but this isn’t layout-compatible with the original C version, and so I need to
stick with the original struct for as long as <code>RnnState</code> is being accessed by
both C and rust code. This increases the amount of <code>unsafe</code> sprinkled around
the rust code, and it was also the source of an annoying bug of the sort that I
thought I had left behind by moving to rust.</p>



<p>At some point during the porting process, my tests started failing in release mode,
but not in debug mode. Most likely some undefined behavior triggered by my amateurish
attempts at unsafe code, but I couldn’t quickly spot the problem and the prospect of
a more careful round of debugging didn’t spark a whole lot of joy. So I did something
that I never would have dared to do in my C/C++ days: I ignored the problem and kept
porting; after all, the tests were still working in debug mode. And sure enough,
a few more ported functions later and <code>rustc</code> found the problem for me: in a function
taking a <code>&amp;RnnState</code> parameter, I was modifying data in the <code>vad_gru_state</code> buffer.
Since I was using unsafe code, <code>rustc</code> didn’t complain at first. But once I ported
the <code>RnnState</code> struct to safe and idiomatic rust, the compiler flagged the problem
immediately.</p>



<p>After getting everything to 100% safe (if not particulary idiomatic) rust, it was time
to check whether performance had suffered.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark.svg" alt="initial benchmark"></p>

<p>Yes, apparently, by about 50%. The most obvious culprit was bounds checking: there was
a lot of indexing in the C code, and some of it wasn’t trivial to convert to a more
rust-friendly, iterator-based version. First priority was the neural network evaluation:</p>

<div><div><pre><code><span>let</span> <span>m</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 114.</span>
<span>let</span> <span>n</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 96.</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span><span>;</span>
    <span>for</span> <span>j</span> <span>in</span> <span>0</span><span>..</span><span>m</span> <span>{</span>
        <span>output</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>layer</span><span>.input_weights</span><span>[</span><span>j</span> <span>*</span> <span>n</span> <span>+</span> <span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>*</span> <span>input</span><span>[</span><span>j</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>I can already see you shaking your head. I’m doing naive matrix-vector multiplication
with a 100x100ish matrix in
<a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">column-major format</a>?
Not only is this costing me bounds checks, it’s terrible for memory locality.
Swapping the weights storage from column- to row-major order only made things
about 1.5% faster, but more importantly it made the whole thing iterator-friendly.
Converting to zips and sums bought another 15%, leaving me only about 25-30% slower
than the C code.</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span>
        <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>+</span> 
        <span>layer</span><span>.input_weights</span><span>[(</span><span>i</span> <span>*</span> <span>m</span><span>)</span><span>..</span><span>((</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>*</span> <span>m</span><span>)]</span>
            <span>.iter</span><span>()</span>
            <span>.zip</span><span>(</span><span>input</span><span>)</span>
            <span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span>
            <span>.sum</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>For my next optimization opportunity, I moved on to the function
that
computes <a href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlations</a>.
The un-optimized version of this function looks like</p>

<div><div><pre><code><span>fn</span> <span>pitch_xcorr</span><span>(</span><span>xs</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>ys</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>xcorr</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>])</span> <span>{</span>
    <span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>()</span> <span>{</span>
        <span>xcorr</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>&amp;</span><span>ys</span><span>[</span><span>i</span><span>..</span><span>])</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>();</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>but the C code contained a massive, manually-unrolled version. I’d skipped
it while porting, but maybe I’d gain something from porting it over. Here’s
an abbreviated version of the optimized function, assuming that all
lengths are a multiple of 4 (the real code also handles the case that they aren’t).</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>(</span><span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>())</span><span>.step_by</span><span>(</span><span>4</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>c0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>let</span> <span>mut</span> <span>y0</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>0</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y1</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y2</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>2</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y3</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>3</span><span>];</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>[(</span><span>i</span> <span>+</span> <span>4</span><span>)</span><span>..</span><span>]</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>

        <span>y0</span> <span>=</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>

        <span>y1</span> <span>=</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>

        <span>y2</span> <span>=</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>

        <span>y3</span> <span>=</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Basically, both inner and outer loops have been unrolled four times, and I’ve
exploited the inner loop’s unrolling to optimize the memory access pattern.
Thanks to the amazing <a href="https://github.com/gnzlbg/cargo-asm"><code>cargo asm</code></a>, I
can happily report that there’s no bounds-checking in the inner loop and that
all the arithmetic has been <a href="https://en.wikipedia.org/wiki/Automatic_vectorization">auto-vectorized</a>
to work four <code>f32</code>s at a time. (Maybe it would get even faster if I unrolled 8 times and
compiled with AVX enabled; I haven’t tried that yet.)</p>

<p>This change more than doubled the speed of <code>pitch_xcorr</code>, and gained me about 10% overall.
More importantly, it showed me how to coerce the compiler into auto-vectorizing something
that it hadn’t auto-vectorized before. I went back to the neural network code and
replaced things like</p>

<div><div><pre><code><span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>ys</span><span>)</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>()</span>
</code></pre></div></div>

<p>with things like</p>

<div><div><pre><code><span>{</span>
    <span>let</span> <span>mut</span> <span>sum0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>sum0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>sum1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>sum2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>sum3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
    <span>sum0</span> <span>+</span> <span>sum1</span> <span>+</span> <span>sum2</span> <span>+</span> <span>sum3</span>
<span>}</span>
</code></pre></div></div>

<p>for another 20% improvement.</p>

<p>Current score: the rust version (still 100% safe) is about 15% faster, and there’s probably plenty more
still on the table.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark_after.svg" alt="final benchmark"></p>

<p>The performance lesson I learned from this is that bounds checking can be expensive in numerical code
and iterator-style code can help a bit, but if you really want faster numerical code then you need
to write in a style that the auto-vectorizer likes. (Or you could use the <a href="https://doc.rust-lang.org/core/arch/index.html">SIMD intrinsics</a>
directly, but that’s another story.)</p>



<p>Like I wrote above, it’s been a while since I did any C/C++, and because of that I’ve started to take tools
like cargo for granted. This little porting project brought back some memories, mostly because about half of the
code in RNNoise was actually “vendored” from <a href="https://gitlab.xiph.org/xiph/opus">opus</a>. I put “vendored”
in quotes because I usually think of vendoring as involving a subdirectory (maybe even a git submodule if
I’m lucky) with its own build artifacts. That’s not what’s going on here, though; I’m just talking about files
that were copied from the source directory of one project to the source directory of another, complete with
never-used functions and never-def’ed ifdefs. The thing is, though, that I understand exactly why they did it:
it’s by far the easiest way to share code between C projects. So I just want to finish by saying a big “thank you”
to <code>cargo</code> and <code>crates.io</code> for making me not have to deal with C dependency management any more.</p>


  
  
</article></div>]]>
            </description>
            <link>https://jneem.github.io/nnnoiseless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817392</guid>
            <pubDate>Mon, 13 Jul 2020 05:14:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Artificial Neural Networks Closer to Animal Brains]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23817347">thread link</a>) | @hardmaru
<br/>
July 12, 2020 | https://maraoz.com/2020/07/12/brains-vs-anns/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/12/brains-vs-anns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p><img src="https://maraoz.com/img/brains-vs-anns/cover.jpg"></p>

<p>Lately, I’ve been thinking and reading a lot about consciousness and how the human mind works. A question that emerges all the time is whether machines can <a href="https://en.wikipedia.org/wiki/Turing_test">emulate human thought</a>. An even more interesting one is whether consciousness (a subjective experience) can arise from a machine, but I’ll leave that discussion for a future post (I’ll need ~20 more years to think about that before I can write about it).</p>

<p>So, how far are we from _behaviorally _imitating a human? Truth is, we achieved a lot in the past 5 years (see <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a>, <a href="https://openai.com/blog/better-language-models/">OpenGPT-2</a>, <a href="https://openai.com/blog/jukebox/">OpenAI Jukebox</a>, <a href="https://en.wikipedia.org/wiki/Tesla_Autopilot">Tesla Autopilot</a>, <a href="https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning">Alphastar</a>, <a href="https://openai.com/blog/openai-five-defeats-dota-2-world-champions/">OpenAI Dota2 Team</a>, <a href="https://openai.com/blog/openai-api/">OpenAI API</a>), but we’re still quite not there. My hunch is that we still can learn a lot from biology’s state of the art. I’ve done some research on differences in how human brains work and how we emulate them using deep neural networks, and what follows is a summary of what I’ve found (and some new ideas).</p>

<figure>
  <img src="https://maraoz.com/img/brains-vs-anns/image1.png">
  <figcaption>
    I find it encouraging that John Carmack is studying human brains for his AI research. <a href="https://twitter.com/ID_AA_Carmack/status/1280693213549002752">Source</a>.
  </figcaption>
</figure>

<h2 id="morphology">Morphology</h2>

<p>The most surprising difference between artificial and human brains is how <em>sequential</em> our artificial neural networks (ANN) are, compared to the richly interconnected biological counterparts.</p>

<p>I’m always amazed by the sheer amount of layers that are stacked on top of each other <a href="https://jalammar.github.io/illustrated-gpt2/">in the latest deep learning models</a>. The largest GPT-3 model (with 175B parameters) uses 96 attention layers, each with 96x 128-dimension heads. <a href="https://arxiv.org/pdf/2005.14165.pdf">Their paper</a> shows that language model performance scales as a power-law with model size.</p>

<p>However, this assumes the size of the network can only increase by adding more layers, making it “deeper”. Using layers enables for great performance in training via <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">backpropagation/ADAM</a>, but I think the current mostly-sequential approach to scaling ANNs is limiting. Some ideas:</p>

<h3 id="wide-vs-deep-neural-networks">Wide (vs. Deep) Neural Networks</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image8.png">
<img src="https://maraoz.com/img/brains-vs-anns/image3.png"></p>

<p>A promising approach is exploring other kinds of architectures, where the concept of “layer” is forgotten, and networks are built more freely (with connections being modelled at the neuron level, and allowing for loops and more complex topologies). This <a href="https://en.wikipedia.org/wiki/Boltzmann_machine">has been somewhat explored in the past</a>, but I haven’t seen recent studies where today’s computing power is thrown at such architectures. Additionally, <a href="https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies">Ken Stanley’s NEAT (2002)</a> and derivatives are a very promising way of finding new topologies via evolution.</p>

<h3 id="neural-grids">Neural Grids</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image6.png"></p>

<p>Another idea worth exploring: grid-like structures where each cell communicates only with its neighbors. In this neural net model, potential is not only passed forward, but also “upward” and “downward”, or even diagonally. This would emulate more closely, I think, a real brain’s connectivity. A related approach is <a href="https://www.mitpressjournals.org/doi/abs/10.1162/artl.2009.15.2.15202">Hypercube-based NEAT (2009)</a>, which allows exploiting the task’s geometry by mapping its regularities onto the topology of the network.</p>

<h3 id="artificial-cortical-columns">Artificial Cortical Columns</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image9.png">
<img src="https://maraoz.com/img/brains-vs-anns/image5.png"></p>

<p>Human’s brain neocortex seems to have a surprisingly self-repeating pattern, called <a href="https://youtu.be/x2mYTaJPVnc?t=98">cortical columns</a>. Each column can be thought of as a reusable ~110 neuron module that appears (with variations) across neocortex areas associated with such different functions as vision, motor control, auditory perception, decision-making, planning, etc. <a href="https://numenta.com/neuroscience-research/cortical-columns/">Studying these structures</a> and applying similar concepts/topologies to ANNs seems like a promising approach. Cortical columns provide amazingly generic hierarchical information processing capabilities, feedback mechanisms, and layered communication with other parts of the brain.</p>

<h3 id="generative-architectures-arising-from-growth">Generative architectures arising from growth</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image10.png"></p>

<p>What if neural net architecture is determined by a generative / procedural algorithm on runtime, instead of being defined by researchers? The seed could be random or evolved through genetic algorithms too. I think that somehow mimicking <a href="https://www.youtube.com/watch?v=BtLyik7oAxc&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=4">neurulation of human embryos</a> via simple models could lead to finding better-performing architectures. Human brains grow into existence, and maybe that matters for high-level intelligence.</p>

<h2 id="function">Function</h2>

<h3 id="evolve-first-learn-later">Evolve first, Learn later.</h3>

<p>Some techniques use <a href="https://www.nature.com/articles/s42256-018-0006-z">neuroevolution used to automate network design</a> or <a href="https://blog.otoro.net/2017/11/12/evolving-stable-strategies/">evolutionary strategies finding network weights instead of gradient descent</a>. It’d be interesting to see hybrid approaches where network structure is evolved and <em>later</em> allowed to learn in an environment (like humans!). Additionally, as I learnt from <a href="https://www.nature.com/articles/s41467-019-11786-6">this fascinating paper by Tony Zador</a> (2019), “A large component of an animal’s behavioral repertoire is not the result of supervised or unsupervised learning, but rather of behavior programs already present at birth”. Learning is actually one of such behaviors, so… shouldn’t researchers be focusing more on optimizing the lower-level mechanism of evolution instead of polishing our “hand-crafted” learning algorithms and architectures?</p>

<p>On a similar ‘meta-learning’ vein, the comically named <a href="http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf">Learning to learn by gradient descent by gradient descent</a> (2016) paper shows that you can train a network to optimize other networks, and they perform better than hand-crafted learning algorithms like <a href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c">ADAM</a> and <a href="https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a">RMSProp</a>.</p>

<h3 id="continuous-vs-discrete-neuron-firing">Continuous (vs. discrete) neuron firing</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image4.png"></p>

<p>Instead of processing inputs in discrete events, our networks could ‘stare’ at inputs for a couple iterations, and neurons can ‘store-up’ potential until they fire. This aims to mimic how we humans can look at something we don’t understand, but after a couple of seconds we “get it”. This could also enable the emergence of “memories” in the form of stored potential, too, analogous to the hidden state vector of LSTMs. Check out <a href="https://www.youtube.com/watch?v=lddzHEtu934">Gabriel Kreiman’s related work (2018)</a> on improving object detection in occluded or distorted conditions. Regardless of the specific implementations mentioned above, biological brains clearly have a temporal dimension (for example, <a href="https://www.youtube.com/watch?v=aFrG7KdjUOs&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=32">neurons in the visual motion MT area respond to direction of motion</a>), which we need to understand better to inform construction of artificial ones. Another interesting time-related property of biological brains is <a href="https://youtu.be/fki7AmLma_I?t=450">the difference between tonic vs bursting modes of neuron firing</a>.</p>

<h3 id="connecting-functional-building-blocks">Connecting functional building blocks</h3>

<p>Animal brains are surprisingly pre-wired and connected since birth, and it’s still not clear in general which behaviors are learned through experience and which are innate. Moreover, a big field of study in neuroscience is understanding how the human brain is wired, mostly via <a href="https://en.wikipedia.org/wiki/Tractography">diffusion tractography</a>, and in some cases <a href="https://youtu.be/KFfaBoDANNI?t=134">it’s been shown that connectivity can predict function</a>. However, the fascinating <a href="https://www.youtube.com/watch?v=8Bvblav-BQk&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=65">‘rewired ferrets’ experiments</a> showed that training input also conditions function strongly (newborn ferrets with auditory cortex rewired to receive visual input still learn to see). This implies that animal brains have a very optimized initial configuration, but also the flexibility to adapt to structural damages or drastical environmental condition changes.</p>

<p>Many well-performing techniques simply stack two architectures that work for two separate domains (eg: CNN visual embedder and LSTM language model) and re-train them for a new combined task (eg: image captioning).</p>

<p><img src="https://maraoz.com/img/brains-vs-anns/image7.png">
<img src="https://maraoz.com/img/brains-vs-anns/image2.png"></p>

<p>I suggest trying to mimic what we know today of how the human brain is wired (from <a href="http://www.humanconnectomeproject.org/">the Human Connectome Project</a>, for example), and plugging in some state-of-the-art modules for vision, language, and audio-processing.</p>

<h3 id="slow-and-data-light-learning">Slow and Data-Light Learning</h3>

<p>Humans seem to learn slowly (in real time, it takes a human ~2 years to learn a language at a basic level, and ~18 years to learn advanced level language usage or complex language tasks like translation) but with few examples. Machines, on the other hand, learn very fast (in the order of weeks to achieve state of the art in some tasks) but are very data-hungry. Some techniques require less training data but might take longer to train, like <a href="https://medium.com/@SmartLabAI/a-brief-overview-of-imitation-learning-8a8a75c44a9c">Imitation Learning</a>, <a href="https://openai.com/blog/competitive-self-play/">Competitive Self-Play</a>, and <a href="https://arxiv.org/abs/2005.11212">Symbolic Pregressions (2020)</a> and could be key to getting closer to human intelligence.</p>

<h3 id="intermixing-learning-techniques">Intermixing Learning Techniques</h3>

<p>A combination of learning strategies could be necessary for human-level intelligence, as Yann LeCun suggests with his cake analogy: “If intelligence is a cake, the bulk of the cake is <a href="https://ai.stackexchange.com/a/10624">self-supervised learning</a>, the icing on the cake is <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, and the cherry on the cake is <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>.”</p>

<p>Humans train by learning from others (supervised learning) <em>and</em> experimenting on our own (unsupervised/self-supervised learning). For example, a chess student first talks to a teacher, then plays some games. They wouldn’t go to a chess tournament after just talking to a teacher or playing games alone. Can we combine/emulate these kinds of training efficiently in ML too?</p>

<h2 id="final-words--further-studying">Final words &amp; further studying</h2>

<p>What do you think of these approaches? Have you actually seen any of these used in the wild (with success or otherwise)? Which do you think may have merits? Let me know if you do some experiments to try them out.</p>

<p>If you’ve been intrigued by the potential of imitating biological brains, here are some up-to-date resources to dig deeper, in order of relevance:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=i1pdQjdAndc&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0">Nancy Kanwisher’s The Human Brain course on YouTube</a> (2018)</li>
  <li><a href="https://www.youtube.com/watch?v=8-KF0rnhKTU&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=2">Ninja Nerd Lectures on Embryology</a> (2019)</li>
  <li><a href="https://www.nature.com/articles/s41467-019-11786-6">A critique of pure learning and what artificial neural networks can learn from animal brains by Anthony M. Zador</a> (2019)</li>
  <li><a href="https://www.youtube.com/watch?v=pkJkHB_c3nA">AI for physics &amp; physics for AI by Max Tegmark</a> (2020)</li>
  <li><a href="https://www.youtube.com/watch?v=x2mYTaJPVnc">Brains Explained video on cortical columns</a> (2017)</li>
  <li><a href="https://www.youtube.com/watch?v=h0InlY2WKc0">Deciphering Brain Codes to Build Smarter AI by Gabriel Kreiman</a> (2020)</li>
</ul>

<p><em>Thanks to Javi Silveira, <a href="https://twitter.com/hardmaru">David Ha (@hardmaru)</a>, <a href="https://twitter.com/alcuadrado">Pato Palladino (@alcuadrado)</a> and <a href="https://twitter.com/itsladywhite">Lady White (@itsladywhite)</a> for providing feedback and pointers.</em></p>

<p><em>Image by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">David Clode on Unsplash</a>.</em></p>


  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/12/brains-vs-anns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817347</guid>
            <pubDate>Mon, 13 Jul 2020 05:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$15 HDMI Capture Card Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817119">thread link</a>) | @rubatuga
<br/>
July 12, 2020 | https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><br>
<video src="https://www.naut.ca/videos/smash60fps.mp4" poster="https://www.naut.ca/videos/smash60fps.jpg" preload="none" controls="" playsinline=""></video>

<p>Above is a sample of 60fps Super Smash Bros Ultimate gameplay (I'm a Jigglypuff main) recorded with the $15 HDMI Capture Card and OBS. This card has been making the rounds last month on <a href="https://twitter.com/Ascii211/status/1268631069051453448">Twitter</a>, as well as on <a href="https://www.youtube.com/watch?v=daS5RHVAl2U">YouTube</a>, mainly due to its low, low price of $15 USD. I've decided to get one myself and take a look. The chipset contained in the card is the MacroSilicon MS2109. Here is the review, as well as a discussion of the potential use-cases.</p>
<h3 id="operatingsystem">Operating System</h3>
<p>This card, surprisingly enough, works on Windows, macOS and Linux! This is because it implements the UVC standard, a USB device that is OS agnostic. Getting it working on Linux is a bit of a hassle, but you can find out how <a href="https://bigl.es/friday-fun-10-hdmi-to-usb-capture/">here</a>.</p>
<p>I noticed that using the capture card on Linux or macOS resulted in significantly more framedrops and synchronization issues, when compared to Windows (although the macOS issues might be due to weak CPU). If you are okay with slightly choppy or stuttery recordings, then feel free to use the card on macOS or Linux. The Windows UVC driver captures more frames, and has the most options of the three. Most of the guide will be focusing on the Windows driver. The controls that are listed in OBS for each operating system are shown below.<br>
<img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-7.13.22-PM.jpg" alt="Screen-Shot-2020-07-09-at-7.13.22-PM"></p>
<h3 id="yuy2vsmjpeg">YUY2 vs MJPEG</h3>
<p>Windows and Linux both support the YUY2 and MJPEG video format, while macOS only supports MJPEG. YUY2 in this context refers to an almost uncompressed form of data (except for colour information), while MJPEG uses lossy JPEG compression on every frame. This means that YUY2 provides a cleaner image with no compression artifacts, while MJPEG has a noisier and blockier image. Compare the two capture formats below:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.33.23-AM.png" alt="Screen-Shot-2020-07-09-at-12.33.23-AM"></p>
<p>As you can see MJPEG has degraded the image data, which is necessary to compress each frame to a small size. Only MJPEG can achieve high framerates with this card because the interface it uses, USB 2.0, caps out around 50 MB/s. For reference, a YUY2 1280x720 60fps signal would exceed 100 MB/s. If you want a card that supports a 60fps YUY2 signal, you can expect to pay in the range of hundreds of dollars.</p>
<p>Both the YUY2 and MJPEG video formats from this card use something called <a href="https://en.wikipedia.org/wiki/Chroma_subsampling">chroma subsampling</a>, a data saving trick that takes advantage of the human eye's decreased colour resolution. It essentially deletes colour data, while keeping brightness data intact. I tested both formats, and they are outputting a 4:2:2 signal (50% of the colour data is deleted). You can see that the horizontal axis changes colour at 2 pixel boundaries, while the vertical axis changes at 1 pixel boundaries.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.32.56-AM.png" alt="Screen-Shot-2020-07-09-at-12.32.56-AM"></p>
<h3 id="resolutionandframerate">Resolution and Framerate</h3>
<p>A wide variety of resolutions and framerates are supported on the input side of the device. It even supports input at 4K 60fps! From the NVIDIA Control Panel, here is an abridged list of the resolutions and framerates supported on the <strong>input side</strong>:</p>
<pre><code>4K    60,59,50,30,29,25,24,23Hz
1080p 60,59,50Hz
720p  60,59,50Hz
576p  50Hz
480p  60,59Hz
PC    60Hz
</code></pre>
<p>To clarify, just because this card can accept or capture a 4K signal, does not mean that it can send the full signal to your computer. This card contains a scaler, which scales the image down (or up, depending on the input) in resolution before it is sent. With reference to the OBS properties window, here is an abridged list of the resolutions and max framerates as seen by my Windows PC:</p>
<pre><code>1920x1080 MJPEG:30fps, YUY2:5fps
1600x1200 MJPEG:30fps, YUY2:5fps
1360x768  MJPEG:30fps, YUY2:?
1280x960  MJPEG:50fps, YUY2:?
1280x720  MJPEG:60fps, YUY2:10fps
1024x768  MJPEG:60fps, YUY2:10fps
800x600   MJPEG:60fps, YUY2:20fps
720x480   MJPEG:60fps, YUY2:30fps
</code></pre>
<p>Each resolution dictates a maximum framerate for the device, limited by the bandwidth of the USB interface. To summarize, this card supports an output of 1920x1080 30fps and 1280x720 60fps with the MJPEG format.</p>
<h3 id="resolutionandframeratecaveats">Resolution and Framerate Caveats</h3>
<p>First I'll talk about framerate. I noticed that recording or streaming from the card at 60fps tends to repeat or skip a frame every few seconds, even with buffering on. Make sure to keep buffering on, otherwise you will lose frames at 30fps as well. I have confirmed this by recording videos in OBS and analyzing them frame by frame.</p>
<p>If you want virtually perfect frame capture at both 720p and 1080p, you should use 30fps with buffering!</p>
<p>Also, you may notice that there are 29.97fps and 59.94fps options in OBS. Only use these if you are absolutely sure that your device needs these values. You will likely run into desynchronization issues if you accidentally use these framerates.</p>
<p>Next, when I tested the 1920x1080 capture, I was shocked by how blurry it was. It turns out that this card doesn't actually do true 1080p! Here's a screenshot of Wikipedia, compared to what was captured at 1920x1080.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-2.48.49-AM.png" alt="Screen-Shot-2020-07-09-at-2.48.49-AM"></p>
<p>It looks like the card is capturing the vertical resolution fine, but the horizontal resolution is a soft mess. I tried out 1280x720, and everything looked crisp and fine, leading me to suspect that the card was capturing internally at a resolution of 1280 columns. I ended up using display calibration images from <a href="http://www.lagom.nl/lcd-test/sharpness.php">Lagom LCD</a> to see how the pixels in the capture were behaving. Right click the following image and choose Open/View Image for a better view.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-3.05.56-AM.png" alt="Screen-Shot-2020-07-09-at-3.05.56-AM"></p>
<p>Using the reference on the left, we can see that 1280x720 has correct vertical and horizontal resolution. 1360x768 and 1920x1080 also have correct vertical resolution, but the columns are turning grey. This is because adjacent white and black pixels from the high input resolution are merged into a lower resolution, i.e. from 1920 columns into 1280 columns. If you also noticed that pixel columns are brighter than the rows, I will be talking about that in the next section.</p>
<p>As a quick aside, everything above was for progressive video input. Interestingly, this card also supports an input of 1080i/interlaced video, which I tested with macOS and my Canon 600D camera. Using 1080i was absolutely horrible for desktop recording, since the card uses a brainless deinterlacing algorithm that halves the vertical resolution to 540. Yes, it actually looks that bad. As for my camera, it was decent, but the edges were kind of funny.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.01.51-AM.png" alt="Screen-Shot-2020-07-09-at-5.01.51-AM"></p>
<h3 id="imageaccuracycaveats">Image Accuracy Caveats</h3>
<p>This card needs "Color Range" set to "Full" in the OBS Capture Card Properties. Any devices that are connected to the card input need to have their HDMI "Range" set to "Limited". This is the only correct combination, otherwise highlights and shadows in the video are clipped. The following shows the effects of the device range options.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.53.19-PM.png" alt="Screen-Shot-2020-07-09-at-5.53.19-PM"></p>
<p>As you might have noticed from the previous section, the 1280x720 capture is brightening the columns. This indicates that the card is performing image sharpening only in the horizontal direction. You can find evidence of this type of sharpening wherever there are sharp edges:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.21.58-AM.png" alt="Screen-Shot-2020-07-09-at-5.21.58-AM"></p>
<p>This is a bad feature, as all image sharpening should be done after the capture. Fortunately, there is a way to get around this for 1280x720 content. Simply set your device to 1280x720, and then capture at 1920x1080. The image loses some clarity in brightness changes, due to the unnecessary resize, but all the sharpening has disappeared! Furthermore, since we are receiving 1920x1080 data, we now have better colour resolution as well, close to 4:3:3 chroma subsampling.</p>
<p>The 1920x1080 MJPEG capture also has significantly less compression artifacts than the 1280x720 MJPEG capture, which is probably due to different framerate support. From the image below, you can see that the 1080p capture is the winner all around (sharpening was applied post-capture for comparison with 720p).</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.25.44-PM.png" alt="Screen-Shot-2020-07-09-at-5.25.44-PM"></p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>
<p>If you are capturing slower gameplay, i.e. only 30fps, set your device to 1920x1080 and then capture at 1920x1080. This provides the most brightness and colour resolution at 30fps.</p>
</li>
<li>
<p>If you have 1280x720 content, capture at 1920x1080. This will result in the least amount of sharpening and MJPEG artifacts.</p>
</li>
<li>
<p>If you are capturing a desktop screen or anything with thin lines and pixels, then set your device to 1280x720 and then capture at 1280x720.</p>
</li>
<li>
<p>If you need 60fps content, i.e. for gaming, then set your device to 1920x1080 and then capture at 1280x720. This disables sharpening. The sample at the beginning of the article was encoded with "x264" at the "veryfast" setting.</p>
</li>
</ul>
<p>Warning: if you see a listing for a $20 USD capture card that claims to support USB 3.0 and 1080p 60fps, it's a scam. I've already bought two of them from Amazon and eBay, and had to return both because they turned out to be a repackaging of the product I just reviewed!</p>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817119</guid>
            <pubDate>Mon, 13 Jul 2020 04:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 in schoolchildren – A comparison between Finland and Sweden [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 93 (<a href="https://news.ycombinator.com/item?id=23816709">thread link</a>) | @mrfusion
<br/>
July 12, 2020 | https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf | <a href="https://web.archive.org/web/*/https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816709</guid>
            <pubDate>Mon, 13 Jul 2020 02:50:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Features are a better abstraction than issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816682">thread link</a>) | @gauthamshankar
<br/>
July 12, 2020 | https://zepel.io/blog/how-issue-tracking-hurts-development/ | <a href="https://web.archive.org/web/*/https://zepel.io/blog/how-issue-tracking-hurts-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>The short answer is yes. Let me explain.</p><p>I’ve been working with developers and designers my entire life. </p><p>I’ve built a couple of products, worked at a young startup, and I’m now at Zepel helping development teams build better software.</p><p>I’ve spoken to 1000+ development teams while at Zepel alone. <strong>And it's evident that the way we build products is broken.</strong></p><p>There’s so much disconnect between how you and I talk about building products and how our teams actually build them.</p><p>For all the talk of scrum and agile and getting feedback quickly, there’s so much that’s broken in how we act on the feedback and build the feature.</p><p>Teams spend so much time and effort getting a deeper understanding of customers’ needs. And yet distil everything down to a simple two-line ticket and a couple of lines of markdown description.</p><p>This is hurting your developers. And it’s hurting your business.</p><blockquote>Nothing is more frustrating than having to understand what an entire feature should or shouldn’t do from a two-line ticket filled with ten bullet points of acceptance criteria.</blockquote><p><em>*Here are five prioritized tickets for the upcoming sprint. We have to ship them on time!*</em></p><p>On the other hand, you have teams who are able to build top quality software. They’re the ones who can concentrate on the fine implementation details without losing focus on the broader purpose of the feature as a whole.</p><p>Everyone wants to get to that level. But instead, teams do the exact opposite.</p><p><strong>Teams think in issues and tickets, instead of the feature as a system.</strong></p><hr><h2 id="development-teams-are-not-ticket-movers-">Development teams are not ticket movers!</h2><p>Today, everything is about moving a ticket from “Todo” to “Done” as quick as possible. And watching <a href="https://zepel.io/agile/reports/burndown/">burndown charts</a>. And customizing the tool to the extent that the developer only views a single ticket.</p><p><em>*“What’s the velocity of our team?” is simply another way of asking how quickly can my team move an issue from “Todo” to “Done”.*</em></p><p>Pieces of that stuff are important for productivity and shipping on time.</p><p>But seriously, how is your team supposed to ship anything of value if you narrow their focus down to the smallest unit of work without any context of why it’s needed or how it connects to the whole feature?!</p><p>Overall, we’ve lost our way. Product development today has become more about checking items off a list as quickly as possible. </p><p><strong>It isn’t enough to write multiple user stories and share a Figma link if you want to ship quality software.</strong></p><hr><h2 id="how-software-product-teams-really-build-software-together">How software product teams really build software together</h2><p>Development teams build better software together when they have the complete context of what and why something is being built.</p><p>To achieve this, the foundational elements need to change.</p><p>And it starts with getting the right abstractions and naming conventions.</p><p><strong>The names you choose determine the perception and the quality of conversations you have. </strong>It’s why top developers spend time obsessing over names for classes, functions, and variables.</p><p>When you open up a VS Code and see a function called <code>send_signup_email</code>, you have a certain sense of what’s going to be inside and why that’s there.</p><p>The right abstractions can drive the team towards asking the right questions. And this is critical.</p><p><strong>Because when you’re tracking issues and tickets in isolation you have no choice but to measure only outputs.</strong></p><p>And teams today don’t want to measure only the outputs. They want to measure <em>outcomes</em>.</p><hr><h2 id="what-s-the-right-abstraction">What’s the right abstraction?</h2><p>The right abstraction is the one that prioritizes people over processes and tools. It's the one you and I use every day — it's Features.</p><p>When a squad creates a Feature and opens it, they’ll get to look at the entire feature as a unit. A <a href="https://zepel.io/agile/user-stories/">user story</a> inside it might describe a specific functionality. But the difference is, now each developer and designer know how it connects to the larger scheme of things for the entire feature.</p><blockquote>A feature forces inept managers to stop focussing on output-oriented questions like “how can we work faster”. <p>And shifts the focus on outcome-oriented questions like “why should we prioritize this feature” and “how does this feature tie to the OKR”.</p></blockquote><p>Miscellaneous tasks and incoming bugs can be tracked on a separate “List”, so high-priority bugs don't get missed out. And of course, when it comes to tracking them, they can all be tracked on a Sprint or on a Kanban Board.</p><p><strong>Feature as an abstraction is the right middle ground that lets you focus on the output as well as the outcome.</strong> It lets you zoom in and track what's happening today. It also allows you to zoom out and track a feature's progress across multiple disciplines. And it enables you to see how a feature moves from a feature request all the way to prioritization and development.</p><p>Simple issue trackers and project management tools have shoehorned teams into ticket-movers and have made them think in outputs. Metrics get feigned to show productivity. Thinking in outcomes has become ridiculously hard. And it's hurting businesses.</p><p>It's time for tools to reflect the reality of product development. It's time to remove the disconnect between development teams and what your customers really want. </p><p>It's time to stop thinking in isolated tickets and start thinking in features as a system!</p><hr><p>If you liked what you read, I think you’ll love what we have in store for you. Go ahead and <a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=product-development-is-broken">try Zepel for free</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://zepel.io/blog/how-issue-tracking-hurts-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816682</guid>
            <pubDate>Mon, 13 Jul 2020 02:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Website allows you to experience what it is like to live with dyslexia]]>
            </title>
            <description>
<![CDATA[
Score 420 | Comments 175 (<a href="https://news.ycombinator.com/item?id=23816678">thread link</a>) | @colinprince
<br/>
July 12, 2020 | http://geon.github.io/programming/2016/03/03/dsxyliea | <a href="https://web.archive.org/web/*/http://geon.github.io/programming/2016/03/03/dsxyliea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        


<div>
  <div>
    
<p>A friend who has dyslexia described to me how she experiences reading. She <em>can</em> read, but it takes a lot of concentration, and the letters seems to “jump around”.</p>

<p>I remembered reading about <a href="https://en.wikipedia.org/wiki/Typoglycemia">typoglycemia</a>. Wouldn’t it be possible to do it interactively on a website with Javascript? Sure it would.</p>

<p>Feel like making a bookmarklet of this or something? <a href="https://github.com/geon/geon.github.com/blob/master/_posts/2016-03-03-dsxyliea.md">Fork it</a> on github.</p>

<blockquote>
  <p>Dyslexia is characterized by difficulty with learning to read fluently and with accurate comprehension despite normal intelligence. This includes difficulty with phonological awareness, phonological decoding, processing speed, orthographic coding, auditory short-term memory, language skills/verbal comprehension, and/or rapid naming.</p>
</blockquote>

<blockquote>
  <p>Developmental reading disorder (DRD) is the most common learning disability. Dyslexia is the most recognized of reading disorders, however not all reading disorders are linked to dyslexia.</p>
</blockquote>

<blockquote>
  <p>Some see dyslexia as distinct from reading difficulties resulting from other causes, such as a non-neurological deficiency with vision or hearing, or poor or inadequate reading instruction. There are three proposed cognitive subtypes of dyslexia (auditory, visual and attentional), although individual cases of dyslexia are better explained by specific underlying neuropsychological deficits and co-occurring learning disabilities (e.g. attention-deficit/hyperactivity disorder, math disability, etc.). Although it is considered to be a receptive language-based learning disability in the research literature, dyslexia also affects one’s expressive language skills. Researchers at MIT found that people with dyslexia exhibited impaired voice-recognition abilities.</p>
</blockquote>

<p><em>Source: <a href="http://en.wikipedia.org/wiki/Dyslexia">Wikipedia</a></em></p>






    <hr>
    
    <hr>
    


  


<p><a href="http://disqus.com/">blog comments powered by </a>




  </p></div>
  
  
</div>


      </div></div>]]>
            </description>
            <link>http://geon.github.io/programming/2016/03/03/dsxyliea</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816678</guid>
            <pubDate>Mon, 13 Jul 2020 02:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Host a Wiki or Knowledge Base for Your Team]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23816462">thread link</a>) | @chsasank
<br/>
July 12, 2020 | http://chsasank.github.io/outline-self-hosted-wiki.html | <a href="https://web.archive.org/web/*/http://chsasank.github.io/outline-self-hosted-wiki.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>How is your startup sharing knowledge with the rest of your team?
We’ve been using slack’s <code>#general</code> or <code>#random</code> channels to make announcements.
We regularly post documents and PPTs slack channels so that they can be used by other people. We have a channel called <code>#setup</code> to post all IT related information like how to login to VPN etc.</p>

<p>But after a few weeks, these docs/notes become super hard to find. As good slack’s search is, you have to precisely know what you’re looking for. What we needed was a centralized knowledge base website - something like <a href="https://www.atlassian.com/software/confluence">Confluence</a></p>

<p>But Confluence is clunky and slow, and not cheap ($5/user). We experimented with <a href="https://tiddlywiki.com/">TiddlyWiki</a>. It calls itself ‘a non-linear personal web notebook’. It’s an opensource software which you can host on your servers or AWS. But its non linear organization makes it super unintuitive and confusing.</p>

<h2 id="why-outline">Why Outline?</h2>

<p>Then, I found <a href="https://www.getoutline.com/">outline</a>! Outline is similar to TiddlyWiki in that it’s opensource and free to self-host. Its UI is a great balance between simplicity of plain text notes and feature creep of Confluence. Login to outline is through your slack - so one less password to remember (or save). You can create private notebooks for a team or just for yourself. You can create a public link of a note so that you can share it with people outside your team - say via email.</p>

<p><span>
    Outline has great UI
</span>
<img src="https://www.getoutline.com/images/screenshot.png"></p>

<p>Best part of all of this is that <em>data doesn’t leave your servers</em> if you self-host it!
We already have a server lying around on AWS to host our own <a href="https://en.wikipedia.org/wiki/Python_Package_Index">python package server, pypi</a>. Since neither hosting pypi nor hosting outline are particularly intensive, we’ve hosted outline on this machine as <code>wiki.qure.ai</code>.</p>

<h2 id="install-outline">Install Outline</h2>

<p>Unfortunately, documentation for self-hosting outline is limited. There’s no robust docker-compose avaialable that you can use to directly create your server. In the rest of this post, I’ll show you how to host in your laptop or server. Before starting, make sure to install <a href="https://docs.docker.com/get-docker/">docker</a> and <a href="https://docs.docker.com/compose/install/">docker-compose</a>.</p>

<div><div><pre><code>git clone https://github.com/chsasank/outline-wiki-docker-compose.git
cd outline-wiki-docker-compose
make install
</code></pre></div></div>
<p><span>
    make install
</span>
<img src="http://chsasank.github.io/assets/images/outline/make_install.png"></p>

<p>Follow the instructions. You’ll have to create a slack app.
<span>
   Slack app
</span>
<img src="http://chsasank.github.io/assets/images/outline/slack_app.png"></p>

<p>If you want to install HTTPS:</p>



<p>Run the server:</p>



  </section></div>]]>
            </description>
            <link>http://chsasank.github.io/outline-self-hosted-wiki.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816462</guid>
            <pubDate>Mon, 13 Jul 2020 02:00:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Biotech]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23816390">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/how-to-build-a-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/how-to-build-a-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

      

        

        <div data-content-field="main-content">
          <div data-type="page" data-updated-on="1594684464227" id="page-5e0541ebe2b52a3155df2dcb"><div><div><div data-block-type="2" id="block-3ee5a93fdab84f05b621"><p><h3>The Summer of 2019, I gave a series of lectures to Longevity Fund’s Venture Fellows on the basics of building a biotechnology company. This is the write up of those lectures, with some additions by Laura Deming &amp; myself. </h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1577404962916_9483"><div><h2>First Steps</h2><p>You’re intrigued by biotech and want to explore ideas in the area. Where do you start? </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1577402821118_87823"><div><h2>Raising Money</h2><p>Science is expensive! One way to fund your work is to get venture capital (VC) investment. It’s a very different process from applying for an academic research grant. </p><p>There are a lot of excellent resources out there on raising capital.* Because of this I’ve focused here on “SF style” biotech investing, and the areas where the advice for a bio company differs from that of a tech company. </p><h3><a href="https://www.celinehh.com/vc101">VC for Bio 101</a> </h3><h3><a href="https://www.celinehh.com/investment-memo">Biotech investment memos</a></h3><p><a href="https://pmarchive.com/guide_to_startups_part1.html">*Marc Andreessen’s guide to startups</a>, the <a href="http://paulgraham.com/articles.html">PG essays</a>, and <a href="https://www.amazon.com/Venture-Deals-Smarter-Lawyer-Capitalist/dp/1118443616">Venture Deals</a> are three classics</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1577402821118_96448"><div><h2>Building in Bio</h2><p>A bit of a deeper dive into the predominant types of drugs and the considerations around each of them. The type of drug you select impacts the safety, dosing strategy, potential efficacy, downstream price &amp; profit margin, and competitiveness of your drug. </p></div></div></div></div></div>
        </div>
      
    </div></div>]]>
            </description>
            <link>https://www.celinehh.com/how-to-build-a-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816390</guid>
            <pubDate>Mon, 13 Jul 2020 01:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bringing GPU Acceleration to Inkscape, Week 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816235">thread link</a>) | @shahreel
<br/>
July 12, 2020 | https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/ | <a href="https://web.archive.org/web/*/https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
      
<h2>
  Bringing GPU Acceleration to Inkscape, Week 2
</h2>
<p>Published the <time datetime="2020-06-12T20:02:31+02:00">2020-06-12</time></p>
<p>Hello everyone!</p>
<p>For the past two weeks since the beginning of this <a href="https://summerofcode.withgoogle.com/organizations/6070010742571008/#5859756641615872">GSoC
2020</a>
I have attempted to integrate <a href="https://github.com/servo/pathfinder">Pathfinder</a>
into Inkscape, in order to draw (and refresh!) the canvas much faster by using
your GPU.</p>
<p>After some early attempts, where I created a C++ Inkscape extension opening
Pathfinder’s demo on the current SVG, and another extension which was basically
a copy of <a href="https://github.com/servo/pathfinder/blob/master/examples/c_canvas_glfw_minimal/c_canvas_glfw_minimal.c">Pathfinder’s C canvas
example</a>,
I’ve started to properly integrate it into Inkscape’s widgets.</p>
<p>That’s where the fun began, here is a small tour of the fun bugs I encountered:</p>
<h3 id="using-apitrace-on-wayland-can-be-interesting">Using <code>apitrace</code> On Wayland Can Be Interesting</h3>
<p><a href="https://apitrace.github.io/"><code>apitrace</code></a> is a very handy tool for debugging
OpenGL applications, it avoids having to understand the code’s structure, and
allows me to focus on the actual behaviour from the driver’s point of view.</p>
<pre><code><span>glXGetCurrentContext() not found: /usr/bin/../lib/apitrace/wrappers/egltrace.so: undefined symbol: glXGetCurrentContext
apitrace: warning: caught signal 6
</span></code></pre>
<p>I was a bit sad to see that a bug I found at the intersection of
<a href="https://github.com/apitrace/apitrace/issues/380">apitrace</a> and
<a href="https://github.com/anholt/libepoxy/issues/68">libepoxy</a> back in 2015
reappeared now, this time caused by GDK doing the same.  In the end I rebuilt
both libepoxy and GTK+ with only their Wayland backend so they wouldn’t be
tempted to call GLX symbols.  This breaks Firefox and probably some other
software which link against their X11 symbols, but on my build/testing machine
it’s fine.</p>
<p>Speaking of running a (soon-to-be) OpenGL program on a remote machine,
<a href="https://gitlab.freedesktop.org/mstoeckl/waypipe">waypipe</a> from last year’s
GSoC is extremely useful, it feels almost instantaneous on my 900&nbsp;KiB/s down
80&nbsp;KiB/s up ADSL connection.  For comparison, I also tried X11 forwarding over
ssh which only shows Inkscape’s window after 1:05, and also mounting the build
directory over sshfs where it takes 1:20 to do the same, and 6:40 (!) to
generate a stack trace in case of a panic.  I probably should have figured that
out during the community bonding period, but I didn’t think of it.</p>
<h3 id="pathfinder-doesn-t-like-to-draw-into-gtk-glarea-very-much">Pathfinder Doesn’t Like To Draw Into <code>Gtk::GLArea</code> Very Much</h3>
<p>I spent quite a few days trying to get Pathfinder to draw into a GTK+ widget,
first inside of Inkscape, then in a <a href="https://linkmauve.fr/files/pathfinder-glarea.tar.xz">testcase
application</a>.  The
<code>Gtk::GLArea</code> widget lets an application draw using OpenGL.  I want it to
eventually replace Inkscape’s <code>SPCanvas</code>, once I’m done and <a href="https://wiki.inkscape.org/wiki/index.php?title=Inkscape_Canvas">Tavmjong as
well</a>, but in
the meantime I’ll keep them both side-by-side in order to compare their
rendering more easily.</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/empty-glarea.png" alt=""></p>
<p>Despite the rendering being done, according to <code>apitrace</code>’s step-by-step
debugging, the <code>Gtk::GLArea</code> stayed hopelessly black.  Even though I could
render a simple solid colour using <code>glClearColor()</code> and
<code>glClear(GL_COLOR_BUFFER_BIT)</code>, as soon as I tried to render using Pathfinder
it went back to a solid black.</p>
<p>Experimenting with the OpenGL contexts, I could make Pathfinder render its
iconic tiny house everywhere but where I wanted it:</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/almost-but-not-quite.png" alt=""></p>
<p>Here is a particularly trippy rendering I got, when <code>Gtk::GLArea</code> is reading
from a framebuffer Pathfinder hasn’t written into:</p>

<p>It was only with the help of <a href="https://github.com/s3bk">sebk</a> that I finally
figured out that I wasn’t passing the correct
<a href="https://www.khronos.org/opengl/wiki/Framebuffer_Object">fbo</a> to Pathfinder.  I
was passing <code>0</code> which means the default (display’s) framebuffer instead of the
one created for me by GTK+.  With this fixed, everything rendered fine, even on
resize:</p>

<p>After that it was a simple matter of <a href="https://github.com/servo/pathfinder/pull/357">adding some API to Pathfinder’s C
bindings</a> and I can render the
same SVG as Inkscape!</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/same-svg.png" alt="">
On the left hand side we can see <a href="https://poez.io/">poezio</a>’s logo rendered by
Inkscape with cairo; on the right hand side the same logo being serialised and
passed to Pathfinder to be rendered on the GPU.</p>
<p>And this concludes my first progress report of this GSoC, a big thanks to
ebassi, halfline and Neville[m] from
<a href="xmpp:%23gtk%irc.freenode.net@irc.jabberfr.org?join">#gtk</a>, and especially sebk
from <a href="xmpp:%23pathfinder%23mozilla.org@matrix.org?join">#pathfinder</a>, who
helped me a lot in that process!</p>


    </div>
  </section></div>]]>
            </description>
            <link>https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816235</guid>
            <pubDate>Mon, 13 Jul 2020 01:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uncleftish Beholding: An Uploosening of English Cleanness (2018)]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 27 (<a href="https://news.ycombinator.com/item?id=23815161">thread link</a>) | @samclemens
<br/>
July 12, 2020 | https://words.usask.ca/helus/2018/03/27/uncleftish-beholding/ | <a href="https://web.archive.org/web/*/https://words.usask.ca/helus/2018/03/27/uncleftish-beholding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							<p><span><a href="https://words.usask.ca/helus/2018/03/27/uncleftish-beholding/#comments">Jump to Comments</a></span></p><p><strong>Alexei Muzyka</strong></p>

<p>Many English words are directly borrowed from, or take influence from many other languages. Loanwords can fill lexical gaps, increase the ways people can say what they want to, and increase the precision of communication in a language. English has borrowed so many foreign words that it might seem impossible that the complex ideas of today’s world could be communicated without loans. However, doing so can show one where English receives new words from, which languages contribute heavily to certain word categories, and how loans are more helpful than harmful.</p>

<p>The practice of removing loans form English is known as by many names like: Pure Anglo-Saxon, or, informally, Anglish (Hofstadter 218). For consistency I will refer to it as Anglish throughout. This form of English seek to eliminate as many non-English, or non-Germanic words as possible from the lexicon and replace them with English or Germanic equivalents. An example of this is the following text, <a href="https://warwick.ac.uk/fac/cross_fac/complexity/people/students/dtc/students2011/maitland/fun/">“Uncleftish Beholding” by Poul Anderson</a>, which aims to explain a complex scientific topic using Anglish (below is the first and last part of the text)(Anderson):</p>
<blockquote><p>For most of its being, mankind did not know what things are made of, but could only guess. With the growth of worldken, we began to learn, and today we have a beholding of stuff and work that watching bears out, both in the workstead and in daily life.</p>

<p>The underlying kinds of stuff are the *firststuffs*, which link together in sundry ways to give rise to the rest. Formerly we knew of ninety-two firststuffs, from waterstuff, the lightest and barest, to ymirstuff, the heaviest. Now we have made more, such as aegirstuff and helstuff.</p>

<p>The firststuffs have their being as motes called *unclefts*. These are mightly small; one seedweight of waterstuff holds a tale of them like unto two followed by twenty-two naughts. Most unclefts link together to make what are called *bulkbits*. Thus, the waterstuff bulkbit bestands of two waterstuff unclefts, the sourstuff bulkbit of two sourstuff unclefts, and so on. (Some kinds, such as sunstuff, keep alone; others, such as iron, cling together in ices when in the fast standing; and there are yet more yokeways.) When unlike clefts link in a bulkbit, they make *bindings*. Thus, water is a binding of two waterstuff unclefts with one sourstuff uncleft, while a bulkbit of one of the forestuffs making up flesh may have a thousand thousand or more unclefts of these two firststuffs together with coalstuff and chokestuff…</p>

<p>Today we wield both kind of uncleftish doings in weapons, and kernelish splitting gives us heat and bernstoneness. We hope to do likewise with togethermelting, which would yield an unhemmed wellspring of work for mankindish goodgain.</p>

<p>Soothly we live in mighty years!</p></blockquote>
<p>Much of this text sounds silly and almost incomprehensible at some points, but upon closer inspection the words that are substituted seem like plausible replacements. Starting with the title “Uncleftish Beholding” is, according to Anderson’s translation, the Anglish equivalent of <em>atomic theory</em>; <em>uncleft</em> meaning unsplittable (<em>atom</em> meaning “indivisible” in Greek) and <em>beholding</em> meaning “to see” (<em>theory</em> meaning “contemplation”<em>, </em>or “spectator” in Greek) (OED s.v <em>atomic</em>, adj, and n. <em>Theory</em>, n). Some more words that are important in the text are: <em>Worldken</em> (meaning “physics”, <em>world </em>“nature” + <em>ken </em>“perception”), <em>firststuff</em> (meaning “element”, <em>first </em>“principle/ fundamental” + <em>stuff </em>“part”), <em>mote</em> (meaning “particle”), <em>kernel </em>(meaning “nucleus”, “nut/ inner part”), and <em>waterstuff </em>(meaning “hydrogen”, <em>water </em>+ <em>stuff </em>“born from/ component”) (OED s.v <em>physics, </em>n, sense 1a<em>. Element, n, </em>sense 1c<em>. Nucleus, </em>n, sense 8<em>. Hydrogen, </em>n, sense a). Also, looking at the context of the words later in the text can show their meaning. For example the sentence says that “Water is a binding of two waterstuff unclefts with one sourstuff uncleft,” which reveals that waterstuff is hydrogen and sourstuff is oxygen, since 2 hydrogen atoms and one oxygen atom make water.</p>
<p>This text can tell one about what English words might be used if we did not have foreign loans, but more importantly why certain words are used, and how they came into English. Many of the replaced words have roots in Greek and Latin, but do not reach the English lexicon directly from those languages. Instead many technical vocabulary that is originally from those two languages arrives through the French language (Durkin 307). An example is the previously mentioned <em>hydrogen</em> (<em>waterstuff</em>). It comes from the French <em>hydrogène</em>, which itself is made from the Greek <em>ὕδωρ</em> (<em>ýdor</em> “water”), and <em>γενής </em>(<em>genís</em> “born from”) (OED s.v, <em>Hydrogen, </em>n, sense a). This is due to scientists still using Latin and sometimes Greek as languages of science throughout Europe during the time these discoveries were being made (Durkin 341). This is also seen as a spike in the influx of Latin and Greek words, along with technical vocabulary into English around the same time (Durkin 309). Texts like “Uncleftish Beholding” show clearly which languages contribute which kind of words. One would expect French to occupy prestige and fashion words, because of its historic relation to England (Durkin, 307). Looking at this text it is clear that Latin and Greek influence lies in the realm of technical and scientific vocabulary. That is not to say that Latin only contributes technical vocabulary; it contributes other words like <em>family, involve,</em> or <em>produce</em> (Márquez 712). These scientific words, like <em>hydrogen, oxygen,</em> and many others, are very important since they filled lexical gaps that English had.</p>
<p>English is known for its robbery from the lexicons of other languages, but this is not a bad thing. Loanwords improve the precision of speech by providing more options to say one thing by filling lexical gaps. At this stage in the history of English the attempt to remove these words would only do more harm than good. Pieces of literature like “Uncleftish Beholding”, however, provide insight into where loans come from and what we would lose if they were given up. Although it would be possible to throw away all loans the benefits that come with them are too valuable to give up.</p>
<p><em>Works Cited:</em></p>
<p>Anderson, Poul (1989). “Uncleftish Beholing.” Warwick, February 12, 2018, <a href="https://warwick.ac.uk/fac/cross_fac/complexity/people/students/dtc/students2011/maitland/fun/">https://warwick.ac.uk/fac/cross_fac/complexity/people/students/dtc/students2011/maitland/fun/</a>. Accessed March 22, 2018.</p>
<p>Durkin, Philip. <em>Borrowed Words: A History of Loanwords in English</em>. Oxford Scholarship Online, 2014. Web. DOI: DOI:10.1093/acprof:oso/9780199574995.001.0001.</p>
<p>Hofstadler, R. Douglas. “Speechstuff and Thoughtstuff: Musings on the Resonances Created by Words and Phrases via the Subliminal Perception of their Buried Parts.” <em>Of Thoughts and Words: The Relation Between Language and Mind</em>, edited by Sture Allén, Imperial College Press, 1995, pp. 217-266. https://doi.org/10.1142/9781908979681_0023.</p>
<p>Marquez, Miguel Fuster. “Renewal of Core English Vocabulary: A Study Based on the BNC.” <em>English Studies</em>, vol. 88, no. 6, Dec. 2007, pp. 699-723. https://doi.org/10.1080/00138380701706385.</p>
<p>[OED]. Oxford English Dictionary Online. Oxford University Press, June 2017, www.oed.com.cyber.usask.ca/view/Entry/89974. Accessed 10 March 2018.</p>
<p><em>Reference:</em></p>
<p>Wikipedia. “Linguistic Purism in English.” Wikipedia, 18 February 2018, <a href="https://en.wikipedia.org/wiki/Linguistic_purism_in_English">https://en.wikipedia.org/wiki/Linguistic_purism_in_English</a>. Accessed March 22, 2018.</p>

							

						</div></div>]]>
            </description>
            <link>https://words.usask.ca/helus/2018/03/27/uncleftish-beholding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23815161</guid>
            <pubDate>Sun, 12 Jul 2020 22:05:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The fastest way to learn a new language]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23815088">thread link</a>) | @william_blount
<br/>
July 12, 2020 | https://www.adamtank.com/new-blog/2020/3/2/the-fastest-way-to-learn-a-new-language-act-like-a-child | <a href="https://web.archive.org/web/*/https://www.adamtank.com/new-blog/2020/3/2/the-fastest-way-to-learn-a-new-language-act-like-a-child">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1583206699770" id="item-5e5dd025f31d6249a33b8964"><div><div><div data-block-type="2" id="block-16ea368387762e4de2e8"><div><p>I was two months into my new job in Rio de Janeiro when I asked my co-worker to hand me a hard penis.</p><p>His gaze shifted towards me and his eyes paused, narrowed, and a cheeky grin slowly came across his face. Within ten seconds the normally stoic Jose was on the floor, doubled over laughing. “Oh shit,” I thought, “What did I just say?”</p><p>It wasn’t the first time I’d made a mistake when learning Portuguese and it wouldn’t be the last. Confusing ‘pão duro’ for ‘pau duro’ (the squiggly line, the tilde, above the ‘a’) proved to be the fatal error – instead of asking for bread, like I had intended, I had asked Jose for something very different.</p><p>The nasal tone of the tilde is a critical distinction among many similarly sounding words in Brazilian Portuguese. But no matter how many times I had tried learning the language with audio tapes, YouTube videos, or through immersion, the lesson had never really sunk in until that one fatal error I made with Jose.</p><p>I now pay <em>very close attention</em> to the tilde when speaking Portuguese.</p><p>---------------------------------</p><p>There is a commonly held belief that children learn new languages faster than adults. This is largely attributed to the fact that children’s brains can form new neural pathways at rates far greater than adults – a term known as ‘neuroplasticity’.</p><p>Most parents will tell you their kids have brains like sponges – they soak up anything and everything they hear – and are quick to repeat it. Interestingly, kids seem to exhibit this sponge- like behavior in public places where they utter something like “That’s bullshit!” and leave mom and dad looking at one another thinking ‘I wonder who she heard that from?’</p><p>I agree with science - a child’s developing brain is far more adept at learning new concepts and lessons than your average adult brain. Consequences are high if they don’t – a child that doesn’t learn concepts of hot and cold, safe vs. danger, ways of expressing their wants and needs, or how to play with others is a child that falls behind, often for life. Brains <strong>have to be extremely moldable in youth</strong> – it’s how children learn the lessons required for survival into and throughout adulthood.</p><p>However, when it comes to learning new languages, I believe the science is overvalued and social factors are significantly undervalued. Adults can learn new languages just as fast, if not faster, than children given the same environment, tools, and social support systems.</p><p>Here are a few of the reasons this is true. Some of these I’ve discovered for myself, others are anecdotal:</p><p><strong>1. Adults punish themselves and one another for making speaking mistakes - children don’t.</strong></p><p>Children that misspeak, stutter, or call things by the wrong names don’t criticize themselves or laugh at one another – they just move on with life. Adults often think it’s endearing to hear kids speak to one another with such imperfection and innocence.</p><p>On the other hand, adults that misspeak, stutter, or screw up are made fun of or feel ashamed or embarrassed. There is no safe environment to practice speaking and to become better without the social stigma associated with screwing up.</p><p>The sooner you come to terms with the fact that you will sound completely, utterly, and fabulously stupid when beginning to learn a new language the sooner you will be successful.</p><p>Anxiety, embarrassment, blanking out, and stuttering will be the RULE, not the exception. Learning a new language will not be an overnight success. It will take failure and practice.</p><p><strong>2. Adults try to learn languages by learning grammar. Children learn language through basic stories, songs, and activities.</strong></p><div><p>About every child in the United States knows the book <em>One Fish, Two Fish, Red Fish, Blue Fish</em>. If you haven’t heard of it, here is a sample excerpt:</p><p><em>Brush Brush Brush</em><br><em>Comb Comb Comb</em><br><em>Blue hair is fun to brush and comb.</em><br><em>All girls who like to brush and comb,</em><br><em>Should have a pet like this at home.</em></p></div><p>This is not a book meant to win the Pulitzer prize. Instead, it’s meant to teach kids the importance of simple, basic phrases and words through repetition and rhyming schemes.</p><p>So why is it when adults are learning new words that we feel the need to start by reading the translated equivalent of Shakespeare? Does anyone truly enjoy learning about verb conjugations, grammar rules, tonality, and writing repetitive sentences over and over until their hands hurt?</p><p>The key to learning a new language is to start simple and work your way up, but to do it through the lens of how a child would learn. Read kids books, listen to kids music, watch kids shows, play kids games. Even something as simple as a game of Tag will teach you a great deal about language and tenses – “I’m it!” vs. “You’re it!” vs. “I <em>was</em> it!” vs. “You’re <em>going to be</em> it!”</p><p><strong>3. Adults learn languages because they are forced to. Children learn language because they don’t know any better.</strong>&nbsp;&nbsp;</p><p>Think about the first time you learned any new skill – let’s take riding a bike as an example. You had to be willing to fall and scrape your knees over and over until you finally learned to ride. As a kid learning to ride a bike was something you needed to do to play with the other kids, and falling was part of the learning curve. It was a way of life, just like having to speak in a certain language with your parents or learn to say certain words because you needed to use them.</p><div><p>Adult speakers of multiple languages often say the best way to learn is through immersion - move to the geography the language is spoken and try not to speak your native language at all. Surround yourself in the language from every angle - before long you’ll start picking language up without even knowing it. </p><p>Not everyone can pack up and move to a new country. But everyone can put themselves in situations where they are unknowingly picking up tidbits of a new language and have fun during the experience. Anybody can try meals at new restaurants where the owners/operators speak a different language, search for new Spotify stations that have music in another tongue, or attend local cultural events where someone can learn to appreciate the contrasts and similarities between their language and someone else’s. </p></div><p>-----------</p><p>If learning Portuguese taught me one thing it was this: change the environment, change the outcome. I could’ve never become as proficient in a new language without completely immersing myself, making mistakes, and enjoying the experience for what it was -&nbsp; a chance to learn more about myself and others through a common understanding of language.&nbsp;</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.adamtank.com/new-blog/2020/3/2/the-fastest-way-to-learn-a-new-language-act-like-a-child</link>
            <guid isPermaLink="false">hacker-news-small-sites-23815088</guid>
            <pubDate>Sun, 12 Jul 2020 21:53:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating randomness Without Math.random]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23814713">thread link</a>) | @healeycodes
<br/>
July 12, 2020 | https://healeycodes.com/creating-randomness/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/creating-randomness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In JavaScript, you can create random numbers using <code>Math.random()</code>. But what if we wanted to create our own random values in the browser without this function?</p>
<p>The <a href="https://tc39.es/ecma262/#sec-math.random">ECMAScript Language Specification</a> defines the requirements of <code>Math.random()</code>:</p>
<blockquote>
<p>Returns a Number value with positive sign, greater than or equal to 0 but less than 1, chosen randomly or pseudo randomly with approximately uniform distribution over that range, using an implementation-dependent algorithm or strategy. This function takes no arguments.</p>
</blockquote>
<blockquote>
<p>Each Math.random function created for distinct realms must produce a distinct sequence of values from successive calls.</p>
</blockquote>
<h2 id="number-generation"><a href="#number-generation" aria-label="number generation permalink"></a>Number Generation</h2>
<p>Here’s an example of a number generator. It uses a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures">closure</a> to maintain internal state and creates a sequence of numbers based off an initial seed value. Here the seed is fixed and is always initialized to <code>0</code>.</p>
<div data-language="javascript"><pre><code>Math<span>.</span>random <span>=</span> <span>(</span><span>function</span> <span>(</span><span>)</span> <span>{</span>
  <span>let</span> seed <span>=</span> <span>0</span>
  <span>return</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
    seed <span>+=</span> <span>1</span>
    <span>return</span> seed
  <span>}</span>
<span>}</span><span>)</span><span>(</span><span>)</span>


Math<span>.</span><span>random</span><span>(</span><span>)</span> 
Math<span>.</span><span>random</span><span>(</span><span>)</span> 
Math<span>.</span><span>random</span><span>(</span><span>)</span> </code></pre></div>
<p>A <strong>pseudorandom number generator</strong> (PRNG) works in a similar manner. A PRNG maintains an internal state and applies math to that state every time a new random number is requested. The seed can be manual or automatic. In the <a href="https://golang.org/pkg/math/rand/#New">Go programming language</a>, you must seed <code>math/rand</code> yourself. In the browser, <code>Math.random</code> requests random data under the hood from the operating system (OS) to use as a seed.</p>
<p>PRNGs are deterministic. The same seed will always produce the same sequence of numbers. Often, a deterministic outcome is preferred. For example, to generate the same random events on all clients without them having to talk over a network. Or for reproducible performance benchmarks.</p>
<p>A hash function can be used to create a PRNG. In <a href="https://github.com/v8/v8/blob/4b9b23521e6fd42373ebbcb20ebe03bf445494f9/benchmarks/spinning-balls/v.js">spinning-balls</a>, one of Chrome’s benchmarks, we can see an example of this:</p>
<div data-language="javascript"><pre><code>



Math<span>.</span>random <span>=</span> <span>(</span><span>function</span> <span>(</span><span>)</span> <span>{</span>
  <span>var</span> seed <span>=</span> <span>49734321</span>
  <span>return</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
    
    seed <span>=</span> seed <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>+</span> <span>0x7ed55d16</span> <span>+</span> <span>(</span>seed <span>&lt;&lt;</span> <span>12</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>^</span> <span>0xc761c23c</span> <span>^</span> <span>(</span>seed <span>&gt;&gt;&gt;</span> <span>19</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>+</span> <span>0x165667b1</span> <span>+</span> <span>(</span>seed <span>&lt;&lt;</span> <span>5</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span><span>(</span>seed <span>+</span> <span>0xd3a2646c</span><span>)</span> <span>^</span> <span>(</span>seed <span>&lt;&lt;</span> <span>9</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>+</span> <span>0xfd7046c5</span> <span>+</span> <span>(</span>seed <span>&lt;&lt;</span> <span>3</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>^</span> <span>0xb55a4f09</span> <span>^</span> <span>(</span>seed <span>&gt;&gt;&gt;</span> <span>16</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    <span>return</span> <span>(</span>seed <span>&amp;</span> <span>0xfffffff</span><span>)</span> <span>/</span> <span>0x10000000</span>
  <span>}</span>
<span>}</span><span>)</span><span>(</span><span>)</span></code></pre></div>
<p>Like our number generator, it alters its internal state while calculating the next random number. This state-change allows the next call to produce a different number.</p>
<h2 id="more-on-pseudorandom-number-generators"><a href="#more-on-pseudorandom-number-generators" aria-label="more on pseudorandom number generators permalink"></a>More on Pseudorandom Number Generators</h2>
<p>One of the oldest and most well known types of PRNG is the <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">linear congruential generator</a> (LCG). Which, despite its somewhat scary name, does not require many lines of code.</p>
<p>@bryc provides an example and <a href="https://github.com/bryc/code/blob/master/jshash/PRNGs.md#lcg-lehmer-rng">a warning</a>:</p>
<blockquote>
<p>Commonly called a Linear congruential generator (LCG), but in this case, more correctly called a Multiplicative congruential generator (MCG) or Lehmer RNG. It has a state and period of 2^31-1. It’s blazingly fast in JavaScript (likely the fastest), but its quality is quite poor.</p>
</blockquote>
<div data-language="javascript"><pre><code><span>function</span> <span>LCG</span><span>(</span><span>a</span><span>)</span> <span>{</span>
  <span>return</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
    a <span>=</span> Math<span>.</span><span>imul</span><span>(</span><span>48271</span><span>,</span> a<span>)</span> <span>|</span> <span>0</span> <span>%</span> <span>2147483647</span>
    <span>return</span> <span>(</span>a <span>&amp;</span> <span>2147483647</span><span>)</span> <span>/</span> <span>2147483648</span>
  <span>}</span>
<span>}</span></code></pre></div>
<p>(This is the first time I’ve come across <code>Math.imul()</code> — which provides <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/imul#Description">C-like 32-bit multiplication</a> of the two parameters.)</p>
<p>What does @bryc’s comment, “its quality is quite poor” mean in this context? Well, given certain even seeds, this algorithm has a pattern when the final step (the division) is removed.</p>
<div data-language="javascript"><pre><code>






<span>const</span> <span>LCG</span> <span>=</span> <span>(</span><span>s</span><span>)</span> <span>=&gt;</span> <span>(</span><span>_</span><span>)</span> <span>=&gt;</span> <span>(</span>s <span>=</span> Math<span>.</span><span>imul</span><span>(</span><span>48271</span><span>,</span> s<span>)</span> <span>&gt;&gt;&gt;</span> <span>0</span><span>)</span>
<span>const</span> nxt <span>=</span> <span>LCG</span><span>(</span><span>3816034944</span><span>)</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>9</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>nxt</span><span>(</span><span>)</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span><span>)</span>
<span>}</span>

</code></pre></div>
<p>There are <a href="https://en.wikipedia.org/wiki/Diehard_tests">many</a> ways to test the quality of randomness. Some of the methodology and results of these tests can be understood by a layperson. One of the <a href="https://en.wikipedia.org/wiki/Diehard_tests">Diehard battery of tests</a> plays 200000 games of craps and looks at the distribution of wins and the number of throws each game.</p>
<p>There’s also a test for LCGs called the <a href="https://en.wikipedia.org/wiki/Spectral_test">spectral test</a> which plots the sequence in two or more dimensions. In the example below, we can see the <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplanes</a> that the spectral test measures for.</p>
<center>
<p><img src="https://d33wubrfki0l68.cloudfront.net/940b3280e30ebce96af63d654d461af46f2afc28/26139/9e8cfab758735e8c6d06f733460f6a3f/lcg-3d.gif" alt="Hyperplanes of an LCG in three dimensions"></p>
</center>
<p>A PRNG eventually repeats its sequence. In this context, the <em>period</em> is the length of steps until the cycle repeats. Simpler PRNGs such as <a href="https://github.com/bryc/code/blob/master/jshash/PRNGs.md#mulberry32">Mulberry32</a> have a period as low as ~4 billion whereas the <a href="https://stackoverflow.com/a/38838863">Mersenne Twister</a> has a period of <code>2^19,937 - 1</code>. In 2015, the V8 team <a href="https://v8.dev/blog/math-random">said</a> that their implementation of <code>Math.random()</code> uses an algorithm called <a href="http://vigna.di.unimi.it/ftp/papers/xorshiftplus.pdf">xorshift128+</a> which has a period of <code>2^128 - 1</code>. Its introduction can been seen in <a href="https://github.com/v8/v8/blob/085fed0fb5c3b0136827b5d7c190b4bd1c23a23e/src/base/utils/random-number-generator.h#L102">this diff</a>.</p>
<p>If a PRNG eventually repeats itself, you might wonder why we call it repeatedly. Why not use the first number and then reset the internal state with a new seed? The problem with this is that the seed needs to originate from somewhere. If we continue to ask the OS for more random data there is a chance that the call may block (as the OS waits for more randomness to be generated) and our program will stall.</p>
<h2 id="entropy-required"><a href="#entropy-required" aria-label="entropy required permalink"></a>Entropy Required</h2>
<p>So you’ve settled on a PRNG and replaced <code>window.Math.random</code>. You’ve shipped it to your users and, at first, everyone seems to be happy.</p>
<p>But wait! You forgot about the seed. And now your users are complaining about the sequence of random numbers they get. It’s the same every time their customers’ page loads. All of their software is predictable. As a result, the web games they built are easy to beat.</p>
<p>Huzaifa Sidhpurwala <a href="https://www.redhat.com/en/blog/understanding-random-number-generators-and-their-limitations-linux">reminds us</a>:</p>
<blockquote>
<p>Entropy is the measurement of uncertainty or disorder in a system. Good entropy comes from the surrounding environment which is unpredictable and chaotic.</p>
</blockquote>
<p>When required, the generation of securely random numbers in the browser is performed by <code>Crypto.getRandomValues()</code> from the <a href="https://www.w3.org/TR/WebCryptoAPI/#Crypto-method-getRandomValues">Web Cryptography API</a>. Which is seeded by “a platform-specific random number function, the Unix <code>/dev/urandom</code> device, or other source of random or pseudorandom data.”</p>
<p>The Linux <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/drivers/char/random.c">source</a> suggests where this pseudorandom data can come from:</p>
<blockquote>
<p>Sources of randomness from the environment include inter-keyboard timings, inter-interrupt timings from some interrupts, and other events which are both (a) non-deterministic and (b) hard for an outside observer to measure.</p>
</blockquote>
<p>There are also hardware devices that use <a href="https://en.wikipedia.org/wiki/Hardware_random_number_generator#Quantum_random_properties">quantum mechanical physical randomness</a>.</p>
<p>You can find many <a href="https://en.wikipedia.org/wiki/Random_number_generator_attack#Prominent_examples">prominent examples</a> of random number generator attacks which occurred because the wrong type (or not enough) entropy was used. Cloudflare <a href="https://www.cloudflare.com/learning/ssl/lava-lamp-encryption/">famously</a> uses lava lamps as an entropy source. Since we are not attempting to create a secure algorithm, predictable sources of entropy like time are fine.</p>
<p>We can use <code>Date.now()</code> our seed state. This means that we will get a different random sequence for every millisecond. We could also use <code>performance.now()</code> which returns the length of time since the <a href="https://developer.mozilla.org/en-US/docs/Web/API/DOMHighResTimeStamp#The_time_origin">time origin</a>.</p>
<p>Other possible ways of getting entropy in the browser:</p>
<ul>
<li><code>crypto.getRandomValues</code>, <code>crypto</code> key generation, or similar (feels like cheating)</li>
<li>Mouse/touch events, <a href="https://developer.mozilla.org/en-US/docs/Web/API/Ambient_Light_Events">ambient light events</a>, mic/webcam noise (hard to use on page load)</li>
<li>Geolocation API, Bluetooth API, or similar (need permission, doesn’t work on page load)</li>
<li>WebGL/video performance shenanigans</li>
<li>Most APIs <a href="https://developer.mozilla.org/en-US/docs/Web/API">listed here</a></li>
</ul>
<p>Here’s our slower (because it’s not native code) and unstable (because I haven’t tested it) replacement for <code>Math.random()</code>. Also note that PRNGs have requirements for the seed state (e.g. prime numbers, 128-bit). Our algorithm doesn’t comply with the <a href="http://vigna.di.unimi.it/ftp/papers/ScrambledLinear.pdf">seed recommendations</a> for the Xoshiro family.</p>
<div data-language="javascript"><pre><code>

Math<span>.</span>random <span>=</span> <span>(</span><span>function</span> <span>xoshiro128p</span><span>(</span><span>)</span> <span>{</span>
  
  
  <span>let</span> a <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>,</span>
    b <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>,</span>
    c <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>,</span>
    d <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span>
  <span>return</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
    <span>let</span> t <span>=</span> b <span>&lt;&lt;</span> <span>9</span><span>,</span>
      r <span>=</span> a <span>+</span> d
    c <span>=</span> c <span>^</span> a
    d <span>=</span> d <span>^</span> b
    b <span>=</span> b <span>^</span> c
    a <span>=</span> a <span>^</span> d
    c <span>=</span> c <span>^</span> t
    d <span>=</span> <span>(</span>d <span>&lt;&lt;</span> <span>11</span><span>)</span> <span>|</span> <span>(</span>d <span>&gt;&gt;&gt;</span> <span>21</span><span>)</span>
    <span>return</span> <span>(</span>r <span>&gt;&gt;&gt;</span> <span>0</span><span>)</span> <span>/</span> <span>4294967296</span>
  <span>}</span>
<span>}</span><span>)</span><span>(</span><span>)</span>

Math<span>.</span><span>random</span><span>(</span><span>)</span> 
Math<span>.</span><span>random</span><span>(</span><span>)</span> </code></pre></div>
<h2 id="so-mission-accomplished"><a href="#so-mission-accomplished" aria-label="so mission accomplished permalink"></a>So, Mission Accomplished?</h2>
<p>Sadly it’s impossible to create a fully ECMAScript compliant replacement for <code>Math.random()</code> since the specification requires “distinct realms [to] produce a distinct sequence of values from successive calls.” A <em>realm</em> roughly means a different global environment (e.g. a different window, or a different <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API">WebWorker</a>). Our version cannot reach outside its realm thus cannot make this guarantee.</p>
<p>However, there have been proposals for a <a href="https://github.com/tc39/proposal-realms">Realms API</a>. It’s not inconceivable that such an API would provide access to something like an incrementing realm id. This would give our algorithm the loophole it needs — access to Realm-unique entropy!</p>
<p><small>Thanks to <a href="https://commons.wikimedia.org/wiki/File:Lcg_3d.gif">JN~commonswiki</a> for the 3D GIF of the spectral test.</small></p></section></div>]]>
            </description>
            <link>https://healeycodes.com/creating-randomness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814713</guid>
            <pubDate>Sun, 12 Jul 2020 20:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The nostalgic world wide web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814631">thread link</a>) | @passbe
<br/>
July 12, 2020 | https://www.passbe.com/2020/07/07/the-nostalgic-internet/ | <a href="https://web.archive.org/web/*/https://www.passbe.com/2020/07/07/the-nostalgic-internet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			<p>A common theme emerges among people born in the 70s and 80s, who grew up when the world wide web (internet) was still young. They miss the "good old days", the pre-2010 internet when things weren't as commercialized. A time when &nbsp;<a href="https://en.wikipedia.org/wiki/Internet_Relay_Chat">IRC</a> and <a href="https://en.wikipedia.org/wiki/Windows_Live_Messenger">MSN Messenger</a> were common place, <a href="https://en.wikipedia.org/wiki/Myspace">MySpace</a> was the new kid on the block and you had bookmarked hundreds of fascinating G<a href="https://en.wikipedia.org/wiki/Yahoo!_GeoCities">eocities</a> sites.</p><p>I too feel this sentiment from time to time and I'm not alone:</p><ul><li><a href="https://www.reddit.com/r/nostalgia/comments/60f73h/anyone_else_nostalgic_for_the_older_internet/">Anyone else nostalgic for the older internet?</a></li><li><a href="https://www.reddit.com/r/nostalgia/comments/7mwmwx/i_miss_the_90s2000s_internet/">I miss the 90s/2000s internet</a></li><li><a href="http://misc-stuff.terraaeon.com/articles/miss-old-internet.html">I miss the old internet</a></li></ul><h3 id="down-the-rabbit-hole-">Down the rabbit hole...</h3><p>We use to spend countless hours browsing one website to another, following the "friends of this website" links going down rabbit holes on topics we never would have encountered otherwise. I remember looking at the clock reading 3am and wondering why I'm still up, reading a website about bee keeping.</p><p>It took me a while to understand exactly what I missed about the nostalgic world wide web.</p><blockquote>I miss the effort</blockquote><p> I miss reading usenet / blogs / websites where a person devoted to that subject puts effort into sharing that information with the world. The website didn't have to be pretty, in most cases they weren't, however I consumed that content knowing this was someones passion - and that made it interesting.</p><p>In a modern internet it takes mere seconds to post content online. We are even encouraged to not try very hard with things like Twitter. It is disappointing.</p><h3 id="there-is-still-hope-">There is still hope!</h3><p>There is plenty of content out there but I believe it is harder to locate due to world wide web being commercialized. Here are some of my favorites:</p><ul><li><a href="https://wiby.me/">Wiby</a> - "The Wiby search engine is building a web of pages as it was in the earlier days of the internet.". I personally bookmark <a href="https://wiby.me/surprise/">Wiby Surprise</a> and discover some fascinating sites.</li><li><a href="https://millionshort.com/">Million Short</a> - "we aim to provide alternative methods for organizing, accessing, and discovering the vast web of information on the Internet". You can easily search for a topic and remove the top n number of popular sites leaving the lesser known possibly more interesting.</li><li><a href="https://reddit.com/">Reddit</a> - Some sub-reddits are amazing communities of people helping each other and sharing content. I use <a href="https://reddit.com/r/random">Reddit Random</a> to find interesting sub-reddits.</li></ul><p>If you struggle to keep track of everything, using an <a href="https://en.wikipedia.org/wiki/RSS">RSS Reader</a> can help. I've used <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> for a long time and its helped me keep up to date with very niche topics. If you do operate a blog or website, <strong>please enable RSS feeds!</strong></p><h3 id="contribute-and-encourage">Contribute and Encourage</h3><p>The world wide web was built for knowledge transfer. If you are passionate about something - share it with the world, there are plenty of places to do this for free online. </p><p>If you come across someones website that you enjoyed, reach out to them. Over the years I have emailed plenty of individuals encouraging them to continue sharing. When you do, they are usually surprised anyone is reading their content and are usually very happy you reached out.</p><p>Please reach out to me if you've had similar experiences.</p>
		</section></div>]]>
            </description>
            <link>https://www.passbe.com/2020/07/07/the-nostalgic-internet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814631</guid>
            <pubDate>Sun, 12 Jul 2020 20:48:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Liner GitLog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814526">thread link</a>) | @mraza007
<br/>
July 12, 2020 | https://knowledge-book.mraza007.now.sh/2020/07/12/git-command/ | <a href="https://web.archive.org/web/*/https://knowledge-book.mraza007.now.sh/2020/07/12/git-command/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<article itemscope="" itemtype="http://schema.org/BlogPosting">
  <header>
    
    <p>
      <time datetime="2020-07-12T00:00:00+00:00" itemprop="datePublished">Jul 12, 2020</time>
      

      
  		

  		
  		

  		·	<span itemprop="tags">
  				
  				
  				<a href="https://knowledge-book.mraza007.now.sh/tagged#git">#git</a>
  			<a href="https://knowledge-book.mraza007.now.sh/tagged#devops">#devops</a>
  			<a href="https://knowledge-book.mraza007.now.sh/tagged#quickhack">#quickhack</a>
  			</span>

  	  

    </p>
  </header>
  <div itemprop="articleBody">
    <p>So I found a useful command that allows you to view entire git log of the repo.</p>

<div><div><pre><code><span>git log --decorate --graph --oneline --all
</span></code></pre></div></div>

<p>This command generates the entire log of the git repo in one line</p>

<p>and if you like to view entire log with commit messages in detail you can run this command</p>

<div><div><pre><code><span>git log --decorate --graph --all
</span></code></pre></div></div>

<p>I hope you found this useful and if you have further tips related to command line feel free to follow me and DM me on <a href="https://twitter.com/muhammad_o7">twitter</a></p>

  </div>
  <hr>
  
<a href="https://knowledge-book.mraza007.now.sh/">Home</a>
<!--<div>-->
  <!-- Remarkbox - Your readers want to communicate with you -->
<!--<div id="remarkbox-div">-->
<!--  <noscript>-->
<!--    <iframe id=remarkbox-iframe src="https://my.remarkbox.com/embed?nojs=true" style="height:600px;width:100%;border:none!important" tabindex=0></iframe>-->
<!--  </noscript>-->
<!--</div>-->
<!--<script src="https://my.remarkbox.com/static/js/iframe-resizer/iframeResizer.min.js"></script>-->
<!--<script>-->
<!--  var rb_owner_key = "79e72a11-4c41-11e9-9d67-040140774501";-->
<!--  var thread_uri = window.location.href;-->
<!--  var thread_title = window.document.title;-->
<!--  var thread_fragment = window.location.hash;-->

<!--  var rb_src = "https://my.remarkbox.com/embed" + -->
<!--      "?rb_owner_key=" + rb_owner_key +-->
<!--      "&thread_title=" + encodeURI(thread_title) +-->
<!--      "&thread_uri=" + encodeURIComponent(thread_uri) + -->
<!--      thread_fragment;-->

<!--  function create_remarkbox_iframe() {-->
<!--    var ifrm = document.createElement("iframe");-->
<!--    ifrm.setAttribute("id", "remarkbox-iframe");-->
<!--    ifrm.setAttribute("scrolling", "no");-->
<!--    ifrm.setAttribute("src", rb_src);-->
<!--    ifrm.setAttribute("frameborder", "0");-->
<!--    ifrm.setAttribute("tabindex", "0");-->
<!--    ifrm.setAttribute("title", "Remarkbox");-->
<!--    ifrm.style.width = "100%";-->
<!--    document.getElementById("remarkbox-div").appendChild(ifrm);-->
<!--  }-->
<!--  create_remarkbox_iframe();-->
<!--  iFrameResize(-->
<!--    {-->
<!--      checkOrigin: ["https://my.remarkbox.com"],-->
<!--      inPageLinks: true,-->
<!--      initCallback: function(e) {e.iFrameResizer.moveToAnchor(thread_fragment)}-->
<!--    },-->
<!--    document.getElementById("remarkbox-iframe")-->
<!--  );-->
<!--</script>-->
<!--</div>-->
</article>

    </div></div>]]>
            </description>
            <link>https://knowledge-book.mraza007.now.sh/2020/07/12/git-command/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814526</guid>
            <pubDate>Sun, 12 Jul 2020 20:33:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text-Only Social Network]]>
            </title>
            <description>
<![CDATA[
Score 437 | Comments 226 (<a href="https://news.ycombinator.com/item?id=23814517">thread link</a>) | @lcnmrn
<br/>
July 12, 2020 | https://subreply.com/trending | <a href="https://web.archive.org/web/*/https://subreply.com/trending">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://subreply.com/trending</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814517</guid>
            <pubDate>Sun, 12 Jul 2020 20:32:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrate from RAID1 Disk to ZFS on NixOS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814408">thread link</a>) | @immae
<br/>
July 12, 2020 | https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/ | <a href="https://web.archive.org/web/*/https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p><em>As of 2020-06-06 I only made those tests inside a VM (See
<a href="#libvirtd">below</a> if you want to play with it too). I’m not fully at
peace with the process yet to actually apply it on my server. Use at
your own risk!</em></p>
<h2>Context</h2>
<p>I’m the happy owner of a server which holds my whole infrastructure
for more than one year now, powered by NixOS for declarative
deployments. When I installed it the first time, I didn’t know about
ZFS and all its features (see <a href="https://pthree.org/2012/12/04/zfs-administration-part-i-vdevs/">there</a>
if you want some examples)</p>
<p>Since I cannot afford to reinstall everything from scratch, I had to
find a way to deploy ZFS safely (i.e. without losing redundancy).
This article explains step by step the choices I made.</p>
<h2>Setup</h2>
<p>The server has a single relevant partition mounted on <code>/</code> (the other
partitions are BIOS boot and swap, non-relevant here). This partition is
a RAID1 array, backed by two disks. The partition holding <code>/</code> on the
underlying disks is the third one, that is <code>/dev/md0</code> containing
<code>/dev/sda3</code> and <code>/dev/sdb3</code>.</p>
<p>The distribution of my server is NixOS, installed remotely via
nixops. Some commands will rely on that fact below, but might be
adapted depending on your distribution (or if you don’t use
nixops)</p>
<p>I ordrered an additional disk to my server provider
(<code>/dev/sdc</code>). The sole purpose of this disk is to ensure
redundancy in case of failure during the process. The process itself
could be adapted to not need it if you’re confident enough. It can
be thrown away at the end of the process.</p>
<h2><a name="libvirtd"></a> Play with libvirtd</h2>
<p>Since I didn’t want to break my server, I created a libvirtd rough
equivalent of my setup: three disk images, two of them mounted as RAID
array. Since it is a quite specific setup, I couldn’t make a fully
declarative VM handled by nixops, but I still made use of some of
nixpkgs helpers.</p>
<p>The derivation below will produce an output with three disks image
as described above:</p>
<div><pre><span></span><span># base_image.nix</span>
<span>{</span> system <span>?</span> <span>builtins</span><span>.</span>currentSystem<span>,</span> size <span>?</span> <span>"10"</span> <span>}:</span>
<span>let</span>
  <span>pkgs =</span> <span>import</span> <span>&lt;nixpkgs&gt;</span> <span>{};</span>
  <span>config =</span> <span>(</span><span>import</span> <span>&lt;nixpkgs/nixos/lib/eval-config.nix&gt;</span> <span>{</span>
    <span>inherit</span> system<span>;</span>
    <span>modules =</span> <span>[</span> <span>{</span>
      fileSystems<span>.</span><span>"/"</span><span>.</span><span>device =</span> <span>"/dev/disk/by-label/root"</span><span>;</span>

      boot<span>.</span>loader<span>.</span>grub<span>.</span><span>version =</span> <span>2</span><span>;</span>
      boot<span>.</span>loader<span>.</span>grub<span>.</span><span>devices =</span> <span>[</span> <span>"/dev/vda"</span> <span>"/dev/vdb"</span> <span>];</span>
      boot<span>.</span>loader<span>.</span><span>timeout =</span> <span>0</span><span>;</span>
      boot<span>.</span><span>kernelParams =</span> <span>[</span><span>"console=ttyS0,115200"</span><span>];</span>

      services<span>.</span>openssh<span>.</span><span>enable =</span> <span>true</span><span>;</span>
      services<span>.</span>openssh<span>.</span><span>startWhenNeeded =</span> <span>false</span><span>;</span>
      services<span>.</span>openssh<span>.</span><span>extraConfig =</span> <span>"UseDNS no"</span><span>;</span>
    <span>}</span> <span>];</span>
  <span>})</span><span>.</span>config<span>;</span>
  <span>the_key =</span> <span>builtins</span><span>.</span>getEnv <span>"NIXOPS_LIBVIRTD_PUBKEY"</span><span>;</span>
<span>in</span> pkgs<span>.</span>vmTools<span>.</span>runInLinuxVM <span>(</span>
  pkgs<span>.</span>runCommand <span>"libvirtd-image"</span>
    <span>{</span> <span>memSize =</span> <span>768</span><span>;</span>
      <span>preVM =</span>
        <span>''</span>
<span>          mkdir $out</span>
<span>          diskImage1=$out/image</span>
<span>          diskImage2=$out/image2</span>
<span>          diskImage3=$out/image3</span>
<span>          </span><span>${</span>pkgs<span>.</span>vmTools<span>.</span>qemu<span>}</span><span>/bin/qemu-img create -f qcow2 $diskImage1 "</span><span>${</span>size<span>}</span><span>G"</span>
<span>          </span><span>${</span>pkgs<span>.</span>vmTools<span>.</span>qemu<span>}</span><span>/bin/qemu-img create -f qcow2 $diskImage2 "</span><span>${</span>size<span>}</span><span>G"</span>
<span>          </span><span>${</span>pkgs<span>.</span>vmTools<span>.</span>qemu<span>}</span><span>/bin/qemu-img create -f qcow2 $diskImage3 "</span><span>${</span>size<span>}</span><span>G"</span>
<span>          mv closure xchg/</span>
<span>        ''</span><span>;</span>
      <span>postVM =</span>
        <span>''</span>
<span>          mv $diskImage1 $out/disk.qcow2</span>
<span>          mv $diskImage2 $out/disk2.qcow2</span>
<span>          mv $diskImage3 $out/disk3.qcow2</span>
<span>        ''</span><span>;</span>
      <span>QEMU_OPTS =</span> <span>builtins</span><span>.</span>concatStringsSep <span>" "</span> <span>[</span>
        <span>"-drive file=$diskImage1,if=virtio,cache=unsafe,werror=report"</span>
        <span>"-drive file=$diskImage2,if=virtio,cache=unsafe,werror=report"</span>
        <span>"-drive file=$diskImage3,if=virtio,cache=unsafe,werror=report"</span>
      <span>];</span>
      <span>buildInputs =</span> <span>[</span> pkgs<span>.</span>utillinux pkgs<span>.</span>perl pkgs<span>.</span>kmod <span>];</span>
      <span>exportReferencesGraph =</span>
        <span>[</span> <span>"closure"</span> config<span>.</span>system<span>.</span>build<span>.</span>toplevel <span>];</span>
    <span>}</span>
    <span>''</span>
<span>      </span><span>${</span>pkgs<span>.</span>parted<span>}</span><span>/bin/parted --script /dev/vda -- \</span>
<span>        mklabel gpt \</span>
<span>        mkpart ESP fat32 8MiB 256MiB \</span>
<span>        set 1 boot on \</span>
<span>        set 1 bios_grub on \</span>
<span>        mkpart sap1 linux-swap 256MiB 512MiB \</span>
<span>        mkpart primary ext4 512MiB -1</span>
<span>      </span><span>${</span>pkgs<span>.</span>parted<span>}</span><span>/bin/parted --script /dev/vdb -- \</span>
<span>        mklabel gpt \</span>
<span>        mkpart ESP fat32 8MiB 256MiB \</span>
<span>        set 1 boot on \</span>
<span>        set 1 bios_grub on \</span>
<span>        mkpart sap1 linux-swap 256MiB 512MiB \</span>
<span>        mkpart primary ext4 512MiB -1</span>
<span>      </span><span>${</span>pkgs<span>.</span>mdadm<span>}</span><span>/bin/mdadm --create /dev/md0 --metadata=0.90 --level=1 --raid-devices=2 /dev/vda3 /dev/vdb3</span>

<span>      # Create an empty filesystem and mount it.</span>
<span>      </span><span>${</span>pkgs<span>.</span>e2fsprogs<span>}</span><span>/sbin/mkfs.ext4 -L root /dev/md0</span>
<span>      </span><span>${</span>pkgs<span>.</span>e2fsprogs<span>}</span><span>/sbin/tune2fs -c 0 -i 0 /dev/md0</span>
<span>      mkdir /mnt</span>
<span>      mount /dev/md0 /mnt</span>

<span>      export HOME=$TMPDIR</span>
<span>      export NIX_STATE_DIR=$TMPDIR/state</span>

<span>      mkdir -p /mnt/etc/nixos</span>

<span>      # The initrd expects these directories to exist.</span>
<span>      mkdir /mnt/dev /mnt/proc /mnt/sys</span>
<span>      mount --bind /proc /mnt/proc</span>
<span>      mount --bind /dev /mnt/dev</span>
<span>      mount --bind /sys /mnt/sys</span>

<span>      # Copy all paths in the closure to the filesystem.</span>
<span>      storePaths=$(perl </span><span>${</span>pkgs<span>.</span>pathsFromGraph<span>}</span><span> /tmp/xchg/closure)</span>

<span>      echo "filling Nix store..."</span>
<span>      mkdir -p /mnt/nix/store</span>
<span>      set -f</span>
<span>      cp -prd $storePaths /mnt/nix/store/</span>

<span>      mkdir -p /mnt/etc/nix</span>
<span>      echo </span><span>'</span><span>build-users-group = </span><span>'</span><span> &gt; /mnt/etc/nix/nix.conf</span>
<span>      export USER=root</span>

<span>      ## Register the paths in the Nix database.</span>
<span>      printRegistration=1 perl </span><span>${</span>pkgs<span>.</span>pathsFromGraph<span>}</span><span> /tmp/xchg/closure | \</span>
<span>          chroot /mnt </span><span>${</span>config<span>.</span>nix<span>.</span>package<span>.</span>out<span>}</span><span>/bin/nix-store --load-db</span>

<span>      mkdir -p /mnt/nix/var/nix/profiles</span>
<span>      # Create the system profile to allow nixos-rebuild to work.</span>
<span>      chroot /mnt </span><span>${</span>config<span>.</span>nix<span>.</span>package<span>.</span>out<span>}</span><span>/bin/nix-env \</span>
<span>          -p /nix/var/nix/profiles/system --set </span><span>${</span>config<span>.</span>system<span>.</span>build<span>.</span>toplevel<span>}</span><span></span>

<span>      # `nixos-rebuild</span><span>'</span><span> requires an /etc/NIXOS.</span>
<span>      mkdir -p /mnt/etc/nixos</span>
<span>      touch /mnt/etc/NIXOS</span>

<span>      # `switch-to-configuration</span><span>'</span><span> requires a /bin/sh</span>
<span>      mkdir -p /mnt/bin</span>
<span>      ln -s </span><span>${</span>config<span>.</span>system<span>.</span>build<span>.</span>binsh<span>}</span><span>/bin/sh /mnt/bin/sh</span>

<span>      # Generate the GRUB menu.</span>
<span>      chroot /mnt </span><span>${</span>config<span>.</span>system<span>.</span>build<span>.</span>toplevel<span>}</span><span>/bin/switch-to-configuration boot</span>

<span>      mkdir -p /mnt/etc/ssh/authorized_keys.d</span>
<span>      echo </span><span>'</span><span>${</span>the_key<span>}</span><span>'</span><span> &gt; /mnt/etc/ssh/authorized_keys.d/root</span>
<span>      umount /mnt/proc /mnt/dev /mnt/sys</span>
<span>      umount /mnt</span>
<span>    </span><span>''</span>
<span>)</span>
</pre></div>


<p>When deploying with nixops (via the libvirtd backend), you will need to
make each image available. However, nixops only handles one and only one
image, so we will need a bit of manual tasks. This is the nixops
configuration I’m using:</p>
<div><pre><span></span><span># libvirtd.nix</span>
<span>{</span>
  <span>testzfs =</span> <span>{</span> pkgs<span>,</span> lib<span>,</span> <span>...</span> <span>}:</span>
  <span>{</span>
    fileSystems<span>.</span><span>"/"</span><span>.</span><span>device =</span> lib<span>.</span>mkForce <span>"/dev/disk/by-label/root"</span><span>;</span>

    <span># Serial access via virsh console (quite handy for debugging)</span>
    boot<span>.</span><span>kernelParams =</span> <span>[</span><span>"console=ttyS0,115200"</span><span>];</span>
    boot<span>.</span>loader<span>.</span>grub<span>.</span><span>extraConfig =</span> <span>''</span>
<span>      serial --unit=0 --speed=115200 --word=8 --parity=no --stop=1</span>
<span>      terminal_output serial</span>
<span>      terminal_input serial</span>
<span>    ''</span><span>;</span>
    boot<span>.</span>loader<span>.</span><span>timeout =</span> lib<span>.</span>mkForce <span>2</span><span>;</span>

    <span># You need to explicitely specify the additional disk here</span>
    boot<span>.</span>loader<span>.</span>grub<span>.</span><span>devices =</span> <span>[</span> <span>"/dev/sdb"</span> <span>];</span>

    <span>deployment =</span> <span>{</span>
      <span>targetEnv =</span> <span>"libvirtd"</span><span>;</span>
      libvirtd<span>.</span><span>baseImage =</span> pkgs<span>.</span>callPackage <span>.</span><span>/base_image.nix</span> <span>{};</span>
      <span># Additional images need to be specified explicitely here (only the sda one will be picked by nixops)</span>
      libvirtd<span>.</span><span>extraDevicesXML =</span> <span>''</span>
<span>        &lt;disk type="file" device="disk" snapshot="external"&gt;</span>
<span>          &lt;driver name="qemu" type="qcow2"/&gt;</span>
<span>          &lt;source file="/path/to/disk2.qcow2"/&gt;</span>
<span>          &lt;target dev="hdb"/&gt;</span>
<span>        &lt;/disk&gt;</span>
<span>        &lt;disk type="file" device="disk" snapshot="external"&gt;</span>
<span>          &lt;driver name="qemu" type="qcow2"/&gt;</span>
<span>          &lt;source file="/path/to/disk3.qcow2"/&gt;</span>
<span>          &lt;target dev="hdc"/&gt;</span>
<span>        &lt;/disk&gt;</span>
<span>      ''</span><span>;</span>
    <span>};</span>

    <span># Some dummy service that writes to disk regularly</span>
    systemd<span>.</span>services<span>.</span><span>nag-var =</span> <span>{</span>
      <span>description =</span> <span>"Some service reading and writing to /var"</span><span>;</span>
      <span>after =</span> <span>[</span> <span>"network.target"</span> <span>];</span>
      <span>wantedBy =</span> <span>[</span> <span>"multi-user.target"</span> <span>];</span>
      <span>script =</span> <span>''</span>
<span>        #!</span><span>${</span>pkgs<span>.</span>stdenv<span>.</span>shell<span>}</span><span></span>
<span>        mkdir -p /var/nagvar</span>
<span>        while true; do</span>
<span>          </span><span>${</span>pkgs<span>.</span>coreutils<span>}</span><span>/bin/date &gt; /var/nagvar/last</span>
<span>          </span><span>${</span>pkgs<span>.</span>coreutils<span>}</span><span>/bin/sleep 10</span>
<span>        done</span>
<span>      ''</span><span>;</span>
    <span>};</span>
  <span>};</span>
<span>}</span>
</pre></div>


<p>Now prepare the VM. Beware, this will rapidly fill-in your /nix/store
with big images. (<code>nix-store --delete /nix/store/*libvirtd-image*</code> to
clean them selectively if you’re doing tests)</p>
<div><pre><span></span><span># This command will fail due to missing images</span>
nixops deploy --create-only
<span># Find the path to images at the beginning of the output. It will be</span>
<span># slightly different from what you would get with nix-build due to</span>
<span># some parameters given by nixops</span>
<span>P</span><span>=</span>/nix/store/eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee-libvirtd-image

<span># Stop VM.</span>
virsh destroy nixops-...-testzfs

<span># Copy additional disks to places written in libvirtd.nix</span>
<span># For some reason, sometimes I had to replace the first disk too in</span>
<span># libvirtd folder.</span>
cp <span>$P</span>/disk2.qcow2 /path/to/disk2.qcow2
cp <span>$P</span>/disk3.qcow2 /path/to/disk3.qcow2
chmod gu+w /path/to/disk2.qcow2 /path/to/disk3.qcow2

<span># Same action done by nixops on the first disk</span>
qemu-img rebase -f qcow2 -b <span>""</span> /path/to/disk2.qcow2
qemu-img rebase -f qcow2 -b <span>""</span> /path/to/disk3.qcow2

<span># Edit libvirtd and add console configuration</span>
virsh edit nixops-...-testzfs
<span># &lt;serial type='pty'&gt;&lt;target port='0'/&gt;&lt;/serial&gt;</span>
<span># &lt;console type='pty'&gt;&lt;target type='serial' port='0'/&gt;&lt;/console&gt;</span>

nixops deploy --force-reboot
</pre></div>


<p>Now you should have a running VM containing two drives in a RAID1 array
plus one unused drive, that mimics your production server, and that I
used as a base for the migration process below.</p>
<p>In case of problem, you should be able to use <code>virsh console</code> to get an
actual console of what’s happening on your VM (as early as grub stage).
Also think of doing snapshots if you want to repeat some steps.</p>
<h2>Migration process</h2>
<h3>Add the new disk to the RAID array</h3>
<div><pre><span></span><span># Copy partitionning without boot partition</span>
sfdisk -d /dev/sda <span>|</span> grep -v ^sector-size: <span>|</span> sed -e <span>"s/21686148-6449-6E6F-744E-656564454649/0657FD6D-A4AB-43C4-84E5-0933C84B4F4F/"</span> <span>|</span> sfdisk /dev/sdc

<span># Add the new partition to RAID array</span>
mdadm --grow /dev/md0 --level<span>=</span><span>1</span> --raid-devices<span>=</span><span>3</span> --add /dev/sdc3

<span># Wait for synchronisation to finish</span>
cat /proc/mdstat
<span>(</span>...<span>)</span>
</pre></div>


<h3>Remove …</h3></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/">https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/</a></em></p>]]>
            </description>
            <link>https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814408</guid>
            <pubDate>Sun, 12 Jul 2020 20:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reaching Out of Your Confidence Zone]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814301">thread link</a>) | @tmatthe
<br/>
July 12, 2020 | http://tiffanymatthe.com/reach | <a href="https://web.archive.org/web/*/http://tiffanymatthe.com/reach">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>07.07.2020</time> — <a href="http://tiffanymatthe.com/tags/mindset">Mindset</a> — <span>2<!-- --> min read</span></p><section><img src="http://tiffanymatthe.com/static/f2f49bd6a3636574a101d4b52d6fa385/a6c62/reach-stars.jpg"><p>During my first year of university, there were posters everywhere on campus promoting a physics research experience. I would immediately dismiss it every time I saw it because I wasn't a physics extraordinaire. I did not build rockets or read thick physics theory books during my spare time. And there were a lot more qualified candidates at UBC for this award. So I didn't really consider applying for it until a week before the deadline.</p><p>I had casually<sup id="fnref-1"><a href="#fn-1">1</a></sup> mentioned this award while talking with my parents over dinner, and they were confused that I hadn't applied. I came up with the usual excuses. There wasn't enough time. I wasn't a mastermind in physics. But they convinced me that I could do it and so I found myself scrambling and stressed during that one week before the deadline. I had to find reference letters from professors I had rarely talked to, and write paragraphs about a subject that I was greatly interested in but had little concrete evidence to show this interest.</p><p>A few weeks later, I got the award! And I was so close to not trying. The fear of asking for reference letters on such a tight deadline alone was almost enough to deter me. All of this was definitely out of my 80% confidence zone<sup id="fnref-2"><a href="#fn-2">2</a></sup>, and that's probably why I felt more excited than usual when I received the email telling me the good news.</p><p>However, not every reach out of my 80% confidence zone is a success. In high school, I applied for multiple universities in the States and did not get in a single one. I knew I was reaching a bit high, especially being an international student. It was disappointing not getting in, but I am glad that I tried.</p><p>Many times, after failures like these, I hesitate to try anything that's out of my 80% confidence zone because there is a higher risk of failing. It seems like a waste of time and energy. But if I shift my mindset, and look towards the possible reward and my own skills, it's not all that bad. Yes, I might fail<sup id="fnref-3"><a href="#fn-3">3</a></sup>. But I might also succeed. I think it's better than not trying and missing out on some great opportunities.</p><p>And a note on "oh, I'm not..." a funny person, an artist, a programmer, a swimmer, and &lt;insert some of your own<!-- -->&gt;<!-- -->. In the past, I often told myself these absolutes. Although they might have been true in the moment, by saying these phrases, I was limiting myself and making sure I would keep these absolutes true forever. But once I changed from "oh, I'm not..." to "I could become", it gave me freedom to try things out and have a chance at success. "Could", which denotes a possibility, also allows me to accept failure.</p><p>I like to remind myself that no one is born a charismatic friend, a great writer, a professional basketball player, a famous Youtuber, an awesome doctor. They become those people because they allow themselves to reach for uncertain success.</p><p>So that's why I reach<sup id="fnref-4"><a href="#fn-4">4</a></sup>.</p></section></div></div>]]>
            </description>
            <link>http://tiffanymatthe.com/reach</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814301</guid>
            <pubDate>Sun, 12 Jul 2020 20:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The High Cost of Caring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23814270">thread link</a>) | @maxdeviant
<br/>
July 12, 2020 | https://maxdeviant.com/posts/2020/the-high-cost-of-caring/ | <a href="https://web.archive.org/web/*/https://maxdeviant.com/posts/2020/the-high-cost-of-caring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I care too much. This is a fact.</p>
<p>In particular, I care too much about the art of building software.</p>
<p>As time goes on, software continues to become an increasingly present and critical element in our world. I take my job as a software practitioner incredibly seriously, as I believe it is my ethical responsibility to do so. As a result, I care deeply about things like technical excellence, code quality and maintability, and treating code with the same importance as the end deliverable.</p>
<p>This care does not come without cost. On the contrary, the cost of caring is enormously high. I routinely suffer from high levels of stress and anxiety as a result of my caring about a particular matter. I am especially inundated with these adverse effects when I'm surrounded by people who don't care as much as I do.</p>
<p>Would it be healthier for me to not care so much? Almost certainly. At the very least it may slow the rate at which gray hairs are appearing on my head.</p>
<p>But, for me, not caring is not an option. I have the choice between caring too much or becoming entirely apathetic. There is no in-between. Presented with these two extremes, I would choose caring every single time.</p>
<p>Not caring is lazy. It takes work to care. There is a high cost to caring, but it is absolutely worth it.</p>

  </div></div>]]>
            </description>
            <link>https://maxdeviant.com/posts/2020/the-high-cost-of-caring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814270</guid>
            <pubDate>Sun, 12 Jul 2020 19:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to secure a multitenant application architecture]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814066">thread link</a>) | @wyldfire
<br/>
July 12, 2020 | https://authress.io/knowledge-base/creating-a-multitenant-application | <a href="https://web.archive.org/web/*/https://authress.io/knowledge-base/creating-a-multitenant-application">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      <h3 id="a-multitenant-application">A Multitenant application</h3>

<p>Multitenancy is the concept that your application serves distinct non-overlapping accounts, with resources assigned to and belonging to each account. A simple example of this is an off-line console video game. Each game copy is bought and paid for by a single owner (“account”), and in that copy there may be some amount of gameplay saved data, development data, and user configuration which is unique and sequestered to that copy. In some cases that data may need to be synced with other copies that the user owns. For example a PC version or potentially a status update on their mobile device.</p>

<p>On the opposite side of the spectrum there are open communities where no data is restricted to the users, a simplified version of Twitter is a good example. Tweets are public, anyone can read them. While a user may be able to post new tweets and delete ones they posted, the environment that user sees is a combination of all users on that platform.</p>

<p>In these extremes, access control policies aren’t that meaningful, since users either have access to nothing (except their resources) or everything. It becomes required and thus more challenging, when resources are partially shared. Take a photo sharing application. While photos may be owned by a single account, a user may want to share their photos with their friends. Additionally they could create albums which their whole family can see, or public ones they intend to demonstrate their photography prowess.</p>

<p>Users create separate accounts which have their own data, own configuration, but may need to share that data with users in that account, or users in other accounts. This is at the core of what is considered a multitenant application.</p>

<h3 id="application-resources">Application resources</h3>

<p>If we use a document repository example we can start to build out what the recommendations might be to secure that data. To start off we’ll look at the types of actions users may want to perform, these are often called user stories.</p>

<ul>
  <li>A user can create an account and provision the necessary resources, add anything to that account, and additionally a user should be able to edit. They are the Owner of that account.</li>
  <li>An account administrator would like to be able to add additional users to the account to manage the documents that are there.</li>
  <li>An account manager needs to upload documents, change documents, and delete them.</li>
  <li>A user in an account needs to be able to share a document with anyone else, or potentially just specific people, irrespective of the account the user is part of.</li>
</ul>

<p>This is just some of the functionality necessary to be built into a document repository. While it is trivial to save documents (depending on their size), getting the permissions right so that they are both easy to maintain but can also provide the necessary flexibility for your users to control access they want to is difficult. We’ll walk through one possible implementation below.</p>

<h3 id="modeled-actions">Modeled Actions</h3>

<ol>
  <li>Create Account - Let’s assume no restricted access is necessary here, anyone can create an account.</li>
  <li>Invite User to Account - Perhaps something like
    <ol>
      <li>Resource: <strong>accounts/{accountId}/users</strong>
</li>
      <li>Permissions: <strong>AddUser/InviteUser, RemoveUser, ReadUsers</strong>
</li>
    </ol>
  </li>
  <li>List accounts - I’ll assume accounts are private. A user can only list accounts they are part of, potentially if you share a document a user might need to be able to see some aspects about that account that owns the document:
    <ol>
      <li>Resource: <strong>accounts/{accountId}</strong> and <strong>accounts/{accountId}/info</strong>
</li>
      <li>Permissions: <strong>updateName/Description, ReadAccount</strong>
</li>
    </ol>
  </li>
  <li>List documents - Need to be able to list the documents in the account
    <ol>
      <li>Resource: <strong>accounts/{accountId}/documents/(documentPath)</strong>
</li>
      <li>Permissions: <strong>AddDocument, DeleteDocument, ReadDocument, EditDocument</strong>
</li>
    </ol>
  </li>
  <li>List users - Need to be able to list users that have access to a document
    <ol>
      <li>Resource: <strong>accounts/{accountId}/documents/(documentPath)/members</strong>
</li>
      <li>Permissions: <strong>ShareDocument, RemoveAccess, UpdateAccess, AssignDocumentOwner</strong>
</li>
    </ol>
  </li>
</ol>

<p>These resource uris are a good match for our user stories about a document repository. For these we would create the relevant roles. So far we listed out the permissions, since the permissions are checked by services we’ll want role abstractions that contain these permissions for the resources.</p>

<h4 id="relevant-roles">Relevant Roles</h4>

<ul>
  <li>Account Admin:
    <ul>
      <li>Will own everything about an account</li>
      <li>Permissions: *</li>
    </ul>
  </li>
  <li>Account Manager:
    <ul>
      <li>Can modify users and documents</li>
      <li>Permissions: <em>AddDocument, DeleteDocument, ReadDocument, EditDocument, ShareDocument, RemoveAccess, UpdateAccess, AssignDocumentOwner</em>
</li>
    </ul>
  </li>
  <li>Account Member:
    <ul>
      <li>Can modify documents</li>
      <li>Permissions: <em>AddDocument, DeleteDocument, ReadDocument, EditDocument, ShareDocument</em>
</li>
    </ul>
  </li>
  <li>Document Viewer:
    <ul>
      <li>Can read a document</li>
      <li>Permissions: <em>ReadDocument, (ShareDocument)</em>
</li>
    </ul>
  </li>
</ul>

<h4 id="relevant-resources">Relevant Resources</h4>
<ul>
  <li><strong>accounts/{accountId}/users</strong></li>
  <li><strong>accounts/{accountId}/info</strong></li>
  <li><strong>accounts/{accountId}/documents/(documentPath)</strong></li>
</ul>

<h3 id="standard-multitenant-resource-recommendations">Standard Multitenant Resource Recommendations</h3>

<p>It can be difficult to get the resource paths just right for your application. What’s important is matching up the user stories to necessary access control checks. Since Authress provides scoped permissions and resources, the best recommendation are resource uris that looks similar to the following:</p>

<blockquote>
  <p><code>NS:tenants/{tenantId}/parentResources/{parentResourceId}/resources/{resourceId}/subResources/{subResourceId}</code></p>
</blockquote>

<ul>
  <li>NS is a custom namespace, your usage of security policies might span across different product spaces, if these are to be separate, prefixing them goes a long way.</li>
  <li>We can separate each section of the path with hardcoded identifier. This is important so that resources of different types are easily distinguishable. If we had <strong>/{id}/{id2}</strong> it would not be possible to differentiate access to <em>/resources/{id}/<strong>sub</strong>/{id2}</em> and <em>/{accounts}/{id}/<strong>resource</strong>/{id2}</em>, since they look the same.</li>
  <li>Always scope with the tenant. There are some situations where resources might be shared, but someone fundamentally one tenant/account always ows the resource.</li>
  <li>Resources in Authress are cascading, so if there is a hierarchy relation between them, this is expressible in the resourceUri. This is a great way to automatically grant access to sub child resources when they are created without needing to create or updating access records. If a user has access to <strong>/resources/{id}</strong> then they will also have the same roles/permissions to all sub resources <strong>/resources/{id}/subResource/{sub1}</strong>
</li>
</ul>

<p>(Another example exists in the <a href="https://authress.io/knowledge-base/zoom-case-study">Zoom Case study</a>)</p>

<p>In some cases resources are very fluid and too much scoping can be a problem, but in Authress these can be changed by updating access records and a simple migration can be used to propagate them if the access control model needs to be changed.</p>

    </div></div>]]>
            </description>
            <link>https://authress.io/knowledge-base/creating-a-multitenant-application</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814066</guid>
            <pubDate>Sun, 12 Jul 2020 19:30:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring how different framings of the same learning task affect performance]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23813670">thread link</a>) | @andersource
<br/>
July 12, 2020 | https://andersource.dev/2020/07/12/supervised-task-framing.html | <a href="https://web.archive.org/web/*/https://andersource.dev/2020/07/12/supervised-task-framing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Supervised learning is the machine learning branch that deals with function approximation: using several input-output pairs generated by an unknown target function, construct a different function that approximates the target function. For example, the target function may be my personal movie preferences, and we might be interested in obtaining a model that can predict (approximately) how much I will enjoy watching some new movie. With such a model we can create a movie recommendation app.</p>

<p>Some functions can be easier to approximate than others (given a definition of approximation difficulty, but I won’t go down that rabbit hole right now), and some tasks can be framed as more than one function. This raises the question - do different framings result in different model performance? To find out I tried playing with two framings of a toy problem.</p>

<h2 id="the-data">The data</h2>
<p>I used the <a href="https://scikit-learn.org/stable/datasets/index.html#olivetti-faces-dataset">Olivetti faces dataset</a>, which contains grayscale, 64x64 images of the faces of 40 subjects (10 images per subject). Here are some of the faces:
<img src="https://andersource.dev/assets/faces_framing/faces_sample.png" alt="Face data sample"></p>

<h2 id="the-task">The task</h2>
<p>The task is the classical face recognition task (which has been quite controversial lately due to questionable use in settings such as law enforcement). To make things more interesting, I decided to use only two images from each subject for training, and the rest as the test set. So the goal is to train a model which, given an image, outputs the subject that the model believes this face belongs to.</p>

<h3 id="scope">Scope</h3>
<p>I wanted to focus just on the aspects of training that pertain to the problem framing, and treat it as a general problem. For that purpose I excluded many specifics that would be very important for a real face recognition application:</p>
<ul>
  <li>Using existing face recognition models or <a href="https://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html">existing techniques specific to face recognition</a></li>
  <li>Using <a href="https://link.springer.com/article/10.1186/s40537-019-0197-0">data augmentation</a> to generate more training samples</li>
  <li>Obtaining more face data (even without subject information) and perform unsupervised pre-training</li>
  <li>Assigning each prediction a confidence score, and fixing a confidence threshold below which no result is reported</li>
</ul>

<p>In short, I wanted to see what difference just changing the target function would make. Since the functions are different the models may be somewhat different as well, but they are trained on the same (base) data.</p>

<h3 id="performance-metric">Performance metric</h3>
<p>To measure model performance, I used the accuracy metric - percentage of correct classifications. For each framing I ran about 100 train/test splits (with two images in the training set and eight in the test set).</p>

<h2 id="baseline">Baseline</h2>
<p>As a baseline I used a (single) nearest neighbor classifier with the L2 norm. I.e. when classifying a new face, for each face in the training set we calculate the sum of the squared differences bewteen every two pixels (in similar positions), and take as the answer the face that was closest.</p>

<p><img src="https://andersource.dev/assets/faces_framing/faces_knn.png" alt="Nearest neighbor face classification"></p>

<p>Intuitively it’s hard to tell how well this model would fare. On one hand there should obviously be many similarities between images of the same person (including factors 
we would have liked to exclude, such as lighting and clothing).
On the other hand, many of the similarities we perceive in faces will not be reflected in the pixel-level comparison.
In this case the performance (measured as accuracy - percent of correct classifications) of the model was about  <strong>70.5%</strong>, which is quite impressive in my opinion, considering that a random model would achieve about 2.5% accuracy on average.</p>

<p>Let’s see how a more sophisticated model fares.</p>

<h2 id="first-approach">First approach</h2>
<p>The first framing is the explicit one: given an image, we want to know whose face it is, so that’s what we’ll ask the model. The function maps images to subject identifiers.</p>

<p><img src="https://andersource.dev/assets/faces_framing/first_approach.png" alt="Mapping image to subject ID"></p>

<p>For the model I used a simple network with Keras:</p>

<figure><pre><code data-lang="python"><span>model</span> <span>=</span> <span>Sequential</span><span>([</span>
		<span>Dense</span><span>(</span><span>128</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span> <span>),</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>32</span><span>),</span>
		<span>Dense</span><span>(</span><span>y_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span> <span>activation</span><span>=</span><span>'softmax'</span><span>)</span>
	<span>])</span>

<span>model</span><span>.</span><span>compile</span><span>(</span><span>loss</span><span>=</span><span>'categorical_crossentropy'</span><span>,</span> <span>optimizer</span><span>=</span><span>'adam'</span><span>)</span>
<span>model</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>epochs</span><span>=</span><span>1200</span><span>)</span></code></pre></figure>

<p>I played with several variations and this seemed to be the best with regards to number of layers, their sizes and activation functions. Its test accuracy was, on average, about <strong>70.9%</strong> - an ever so slight improvement.
I think part of the challenge is that classifying faces requires relatively complex features, but we have very little training data (especially considering the number of positive instances for each class).
So the model either fails to find a pattern if the network is too small, or overfits if it’s too large.</p>

<h2 id="second-approach">Second approach</h2>
<p>Let’s try a less direct framing. We know that if two images belong to the same person, they should be relatively similar, and vice versa. Therefore, instead of training the model to identify faces, we can train the model to <em>compare</em> faces. In this case, instead of 40 classes (one for every subject) we only have two classes: “same person” or “not the same person”.</p>

<p><img src="https://andersource.dev/assets/faces_framing/second_approach.png" alt="Mapping image pairs to similarity"></p>

<p>Training this model was a little trickier:</p>
<ul>
  <li>The best architecture turned out to be pretty similar to two (“sideways”) concatenations of the first approach model, which I thought was pretty neat.</li>
  <li>Due to a vanishing gradients issue, I had to go with a slower learning rate and slow it even more as the loss decreased.</li>
  <li>This time we have an <em>imbalanced</em> classification task, so I gave the positive class a bigger weight.</li>
  <li>Training took longer and in a handful of cases (about 5 out of 100) didn’t converge and needed restarting.</li>
</ul>

<p>Another difference is that using this framing, inference isn’t straightforward. Instead, we run the model on the input image along with each of the training images, and pick the subject of the image that the model deemed most similar to the input image.</p>

<p>Here is the code for the model and training:</p>

<figure><pre><code data-lang="python"><span>model</span> <span>=</span> <span>Sequential</span><span>([</span>
		<span>Dense</span><span>(</span><span>256</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span> <span>),</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>128</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>64</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>2</span><span>,</span> <span>activation</span><span>=</span><span>'softmax'</span><span>)</span>
	<span>])</span>

<span>model</span><span>.</span><span>compile</span><span>(</span><span>loss</span><span>=</span><span>'categorical_crossentropy'</span><span>,</span> 
	      <span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>.</span><span>0001</span><span>))</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>45</span><span>):</span>
	<span>hist</span> <span>=</span> <span>model</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>to_categorical</span><span>(</span><span>y_train</span><span>),</span>
			 <span>epochs</span><span>=</span><span>10</span><span>,</span> <span>class_weight</span><span>=</span><span>{</span><span>0</span><span>:</span> <span>1</span><span>,</span> <span>1</span><span>:</span> <span>79</span><span>},</span> <span>verbose</span><span>=</span><span>0</span><span>)</span>
	<span>last_loss</span> <span>=</span> <span>hist</span><span>.</span><span>history</span><span>[</span><span>'loss'</span><span>][</span><span>-</span><span>1</span><span>]</span>
	<span>lr</span> <span>=</span> <span>.</span><span>0001</span>
	<span>if</span> <span>last_loss</span> <span>&lt;=</span> <span>.</span><span>1</span><span>:</span>
		<span>lr</span> <span>=</span> <span>.</span><span>00001</span>
	<span>model</span><span>.</span><span>compile</span><span>(</span><span>loss</span><span>=</span><span>'categorical_crossentropy'</span><span>,</span>
		      <span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>lr</span><span>))</span></code></pre></figure>

<p>The accuracy of this model was, on average, about <strong>74.4%</strong>, which is an improvement over both the first approach and the baseline. However, the spread of the results was larger, resulting in both much worse and much better runs. In this problem, a different framing made quite a significant difference.</p>

<h2 id="combined-approach">Combined approach</h2>
<p>After seeing the better average but also bigger spread of the second approach I wondered if it would be possible to create a model that optimizes for both using a non-linear computation graph.
The idea was this: each input sample would contain two faces, which would each “go through” several dense layers. The images would be transformed by the same layers separately, and the resulting representation would be used in two ways:</p>
<ol>
  <li>Classify each face</li>
  <li>Concatenate the two representations and, after several more dense layers, classify whether or not they belong to the same person</li>
</ol>

<p>I also used different weights for the two framings, which worked a little better.</p>

<p>Here’s the code for this model and its training:</p>

<figure><pre><code data-lang="python"><span>x1</span> <span>=</span> <span>Input</span><span>(</span><span>shape</span><span>=</span><span>(</span><span>pre_X_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],),</span> <span>name</span><span>=</span><span>'face1'</span><span>)</span>
<span>x2</span> <span>=</span> <span>Input</span><span>(</span><span>shape</span><span>=</span><span>(</span><span>pre_X_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],),</span> <span>name</span><span>=</span><span>'face2'</span><span>)</span>
<span>L1</span> <span>=</span> <span>Dense</span><span>(</span><span>128</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>x1</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],),</span> <span>name</span><span>=</span><span>'face_rep1'</span><span>)</span>
<span>BN1</span> <span>=</span> <span>BatchNormalization</span><span>(</span><span>name</span><span>=</span><span>'batch_norm1'</span><span>)</span>
<span>L2</span> <span>=</span> <span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>128</span><span>,),</span> <span>name</span><span>=</span><span>'face_rep2'</span><span>)</span>
<span>BN2</span> <span>=</span> <span>BatchNormalization</span><span>(</span><span>name</span><span>=</span><span>'batch_norm2'</span><span>)</span>
<span>L3</span> <span>=</span> <span>Dense</span><span>(</span><span>32</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>64</span><span>,),</span> <span>name</span><span>=</span><span>'face_rep3'</span><span>)</span>
<span>O1</span> <span>=</span> <span>Dense</span><span>(</span><span>40</span><span>,</span> <span>activation</span><span>=</span><span>'softmax'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>32</span><span>,),</span> <span>name</span><span>=</span><span>'face_class'</span><span>)</span>

<span>R1</span> <span>=</span> <span>BN2</span><span>(</span><span>L2</span><span>(</span><span>BN1</span><span>(</span><span>L1</span><span>(</span><span>x1</span><span>))))</span>
<span>R2</span> <span>=</span> <span>BN2</span><span>(</span><span>L2</span><span>(</span><span>BN1</span><span>(</span><span>L1</span><span>(</span><span>x2</span><span>))))</span>

<span>C1</span> <span>=</span> <span>concatenate</span><span>([</span><span>R1</span><span>,</span> <span>R2</span><span>],</span> <span>name</span><span>=</span><span>'face_rep_concat'</span><span>)</span><span>i</span>
<span>L4</span> <span>=</span> <span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>128</span><span>,),</span> <span>name</span><span>=</span><span>'comparison_dense'</span><span>)</span>
<span>BN3</span> <span>=</span> <span>BatchNormalization</span><span>(</span><span>name</span><span>=</span><span>'batch_norm3'</span><span>)</span>
<span>O2</span> <span>=</span> <span>Dense</span><span>(</span><span>2</span><span>,</span> <span>activation</span><span>=</span><span>'softmax'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>64</span><span>,),</span> <span>name</span><span>=</span><span>'comparison_res'</span><span>)</span>

<span>face1_res</span> <span>=</span> <span>O1</span><span>(</span><span>L3</span><span>(</span><span>R1</span><span>))</span>
<span>face2_res</span> <span>=</span> <span>O1</span><span>(</span><span>L3</span><span>(</span><span>R2</span><span>))</span>
<span>comparison_res</span> <span>=</span> <span>O2</span><span>(</span><span>BN3</span><span>(</span><span>L4</span><span>(</span><span>C1</span><span>)))</span>

<span>model</span> <span>=</span> <span>Model</span><span>(</span><span>inputs</span><span>=</span><span>[</span><span>x1</span><span>,</span> <span>x2</span><span>],</span> <span>outputs</span><span>=</span><span>[</span><span>face1_res</span><span>,</span> <span>face2_res</span><span>,</span> <span>comparison_res</span><span>])</span>

<span>tf</span><span>.</span><span>keras</span><span>.</span><span>utils</span><span>.</span><span>plot_model</span><span>(</span><span>model</span><span>,</span> <span>'model.png'</span><span>,</span> <span>show_shapes</span><span>=</span><span>True</span><span>)</span>

<span>model</span><span>.</span><span>compile</span><span>(</span><span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>.</span><span>0005</span><span>),</span>
			  <span>loss</span><span>=</span><span>[</span>
					<span>tf</span><span>.</span><span>keras</span><span>.</span><span>losses</span><span>.</span><span>categorical_crossentropy</span><span>,</span>
					<span>tf</span><span>.</span><span>keras</span><span>.</span><span>losses</span><span>.</span><span>categorical_crossentropy</span><span>,</span>
					<span>weighted_categorical_crossentropy</span><span>([</span><span>1</span><span>,</span> <span>79</span><span>]),</span>
			  <span>],</span>
			  <span>loss_weights</span><span>=</span><span>[.</span><span>1</span><span>,</span> <span>.</span><span>1</span><span>,</span> <span>1.</span><span>])</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>130</span><span>):</span>
	<span>hist</span> <span>=</span> <span>model</span><span>.</span><span>fit</span><span>([</span><span>X1_train</span><span>,</span> <span>X2_train</span><span>],</span> <span>[</span><span>y1_train</span><span>,</span> <span>y2_train</span><span>,</span> <span>y3_train</span><span>],</span>
			 <span>epochs</span><span>=</span><span>10</span><span>,</span> <span>verbose</span><span>=</span><span>0</span><span>)</span>
	<span>last_loss</span> <span>=</span> <span>hist</span><span>.</span><span>history</span><span>[</span><span>'comparison_res_loss'</span><span>][</span><span>-</span><span>1</span><span>]</span>
	<span>lr</span> <span>=</span> <span>.</span><span>0005</span>
	<span>if</span> <span>last_loss</span> <span>&lt;=</span> <span>.</span><span>5</span><span>:</span>
		<span>lr</span> <span>=</span> <span>.</span><span>0001</span>
	<span>if</span> <span>last_loss</span> <span>&lt;=</span> <span>.</span><span>1</span><span>:</span>
		<span>lr</span> <span>=</span> <span>.</span><span>00001</span>

	<span>model</span><span>.</span><span>compile</span><span>(</span><span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>lr</span><span>),</span>
				  <span>loss</span><span>=</span><span>[</span>
					  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>losses</span><span>.</span><span>categorical_crossentropy</span><span>,</span>
					  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>losses</span><span>.</span><span>categorical_crossentropy</span><span>,</span>
					  <span>weighted_categorical_crossentropy</span><span>([</span><span>1</span><span>,</span> <span>39</span><span>]),</span>
				  <span>],</span>
				  <span>loss_weights</span><span>=</span><span>[.</span><span>05</span><span>,</span> <span>.</span><span>05</span><span>,</span> <span>1.</span><span>])</span></code></pre></figure>

<p>Here’s a visual description of what’s happening:</p>

<p><img src="https://andersource.dev/assets/faces_framing/combined_approach.png" alt="Combined approach model"></p>

<p>This model took the longest to train. The average accuracy was <strong>73.3%</strong>, better than the baseline and the first approach but not as good as the second; however, it was much more stable and there were no incidents of non-convergence. So it seems like the combination indeed enabled us to enjoy both worlds: a little better performance while preserving stability.</p>

<h2 id="comparison">Comparison</h2>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Description</th>
      <th>Mean</th>
      <th>Median</th>
      <th>5%</th>
      <th>95%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Baseline</td>
      <td>Nearest neighbor</td>
      <td>70.55%</td>
      <td>70.625%</td>
      <td>65%</td>
      <td>76.25%</td>
    </tr>
    <tr>
      <td>First approach</td>
      <td>Face classification</td>
      <td>70.916%</td>
      <td>71.094%</td>
      <td>65.587%</td>
      <td>76.25%</td>
    </tr>
    <tr>
      <td>Second approach</td>
      <td>Similarity classification</td>
      <td><strong>74.381%</strong></td>
      <td><strong>75.312%</strong></td>
      <td>65.75%</td>
      <td><strong>81.9%</strong></td>
    </tr>
    <tr>
      <td>Combined approach</td>
      <td>first + second</td>
      <td>73.298%</td>
      <td>72.969%</td>
      …</tr></tbody></table></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andersource.dev/2020/07/12/supervised-task-framing.html">https://andersource.dev/2020/07/12/supervised-task-framing.html</a></em></p>]]>
            </description>
            <link>https://andersource.dev/2020/07/12/supervised-task-framing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813670</guid>
            <pubDate>Sun, 12 Jul 2020 18:43:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contrastive Code Representation Learning: deep type prediction for TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23813283">thread link</a>) | @parasj
<br/>
July 12, 2020 | https://parasj.github.io/contracode/ | <a href="https://web.archive.org/web/*/https://parasj.github.io/contracode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <h2>Summary</h2>
                <ul>
                    <li>Developer tools increasingly use machine learning to understand and modify human-written code.</li>
                    <li>For the best code understanding results, we hypothesize that learned code representations should be similar for functionally equivalent programs and dissimilar for non-equivalent programs.</li>
                    <li>We propose ContraCode: a methodology to learn similar representations for functionally equivalent programs through contrastive pre-training.</li>
                    <li>During pre-training, we apply compiler transformations to generate (approximately) equivalent, textually divergent batches of programs.</li>
                    <li>Finetuned models improve automated code summarization and type inference in JavaScript.</li>
                </ul>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Abstract</h2>
                <p>
                    Machine-aided programming tools such as type predictors and code summarizers are increasingly learning-based. However, most code representation learning approaches rely on supervised learning with task-specific annotated datasets.
                    We propose <em>Contrastive Code Representation Learning (ContraCode)</em>, a self-supervised algorithm for learning task-agnostic semantic representations of programs via contrastive learning. Our approach uses no human-provided labels, relying only on the raw text of programs.
                    In particular, we design an unsupervised pretext task by generating textually divergent copies of source functions via automated source-to-source compiler transforms that preserve semantics.
                    We train a neural model to identify variants of an anchor program within a large batch of negatives. To solve this task, the network must extract program features representing the functionality, not form, of the program.
                    This is the first application of instance discrimination to code representation learning to our knowledge. We pre-train models over 1.8m unannotated JavaScript methods mined from GitHub. ContraCode pre-training improves code summarization accuracy by 7.9% over supervised approaches and 4.8% over RoBERTa pre-training.
                    Moreover, our approach is agnostic to model architecture; for a type inference task, contrastive pre-training consistently improves the accuracy of existing baselines.
                <br>
                </p>
            </div>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Compiler transforms for code data augmentation</h2>
                <p>Finding equivalent programs in a dataset is challenging. In computer vision, random crops of a source image are frequently used as "equivalent" views of it for augmenting training sets or for unsupervised pre-training. However, it's challenging to define similar data augmentations for natural and programming languages. We propose to use <em>automated source-to-source compiler transformations</em> to generate augmentations of programs that preserve functionality. These transforms include dead code elimination, variable renaming and constant folding. We also explore lossy transforms like code deletion that only preserve some of the program semantics.
                <br></p>
                <p><img src="https://parasj.github.io/contracode/assets/img/codetransform.png"><em>An example JavaScript method from the unlabeled GitHub training set and two semantically equivalent programs. The equivalent programs were automatically generated through compiler transformations, serving as "augmentations" or "views" of the original program.</em></p></div>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Contrastive pre-training</h2>
                <p>
                    Contrastive Code Representation Learning (ContraCode) is a pretext representation learning task that uses these code augmentations to construct a challenging <em>discriminative</em> pretext task that requires the model to identify equivalent programs out of a large dataset of distractors. 
                    In doing so, it has to embed the functionality, not form, of the code. 
                    In essence, the domain knowledge from our code transformations induces the knowledge of the structure of programs onto learned representations.
                <br></p>
                <p><img src="https://parasj.github.io/contracode/assets/img/training.png"><em>ContraCode extends the Momentum Contrast vision pretraining framework to learn an encoder of programs from a database of unlabeled programs and a suite of semantics-preserving transformations.</em></p></div>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Finetuning on downstream tasks</h2>
                <p>
                    By learning functionality-based representations, a model pre-trained with ContraCode outperforms baselines that are are trained from scratch or pre-trained with reconstruction objectives like masked language modeling. We demonstrate these improvements by finetuning LSTM and Transformer models on type inference and code summarization tasks.
                <br></p>
                <p><img src="https://parasj.github.io/contracode/assets/img/typeinference.png">
                <em>After finetuning, an LSTM pretrained with ContraCode predicts the argument and return types of an untyped TypeScript method correctly, which can be useful for developers.</em>
                <img src="https://parasj.github.io/contracode/assets/img/methodnames.png">
                <em>A finetuned model can also predict the name of a method from its body, a form of code summarization that demonstrates understanding of the code and could be useful for deobfuscation.</em>
            </p></div>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Citation</h2>
                <p>Paras Jain*, Ajay Jain*, Tianjun Zhang, Pieter Abbeel, Joseph E. Gonzalez, Ion Stoica. Contrastive Code Representation Learning.<strong>&nbsp;In submission,</strong>&nbsp;2020. <em>* Denotes equal contribution.</em><br></p><p><code>@article{jain2020contrastive,<br>&nbsp; title={Contrastive Code Representation Learning},<br>&nbsp; author={Paras Jain and Ajay Jain and Tianjun Zhang<br>&nbsp;&nbsp;and Pieter Abbeel and Joseph E. Gonzalez and Ion Stoica},<br>&nbsp; year={2020},<br>&nbsp; journal={arXiv preprint}<br>}<br></code></p></div>
        </div>
    </div>
    
    



</div></div>]]>
            </description>
            <link>https://parasj.github.io/contracode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813283</guid>
            <pubDate>Sun, 12 Jul 2020 18:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A visual introduction to machine learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813266">thread link</a>) | @peytoncasper
<br/>
July 12, 2020 | http://www.r2d3.us/visual-intro-to-machine-learning-part-1/?from=@ | <a href="https://web.archive.org/web/*/http://www.r2d3.us/visual-intro-to-machine-learning-part-1/?from=@">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="intro">
		<div>
			<div id="set-up">
				
				<p><img alt="language:" src="http://www.r2d3.us/static/app/global/world.png">: </p>
				<p>In machine learning, computers apply <strong>statistical learning</strong> techniques to automatically identify patterns in data. These techniques can  be used to make highly accurate predictions.</p>
				<p><em>Keep scrolling.</em> Using a data set about homes, we will create a machine learning model to distinguish homes in New York from homes in San Francisco. </p>
			</div>
			
			<hr>
			<div id="first-two">
				<h2> First, some intuition </h2>
				<p> Let’s&nbsp;say you had to determine whether a home is in <strong> San Francisco</strong> or in <strong>New York</strong>. In machine learning  terms, categorizing data points is a <strong>classification</strong> task. </p>
				<p> Since San Francisco is relatively hilly, the elevation of a home may be a good way to distinguish the two cities. </p>
				<p> Based on the home-elevation data to the right, you could argue that a home above 73 meters should be <strong> classified</strong> as one in San Francisco. </p>
			</div>
			<hr>
			<div id="add-nuance">
				<h2> Adding nuance </h2>
				<p> Adding another <strong>dimension</strong> allows for more nuance. For example, New York apartments can be extremely expensive per square foot. </p>
				<p> So visualizing elevation <em>and</em> price per square foot in a <strong>scatterplot</strong> helps us distinguish lower-elevation homes. </p>
				<p> The data suggests that, among homes at or below 73 meters, those that cost more than $19,116.7 per square meter are in New York City. </p>
				<p> Dimensions in a data set are called <strong>features</strong>, <strong>predictors</strong>, or <strong>variables</strong>. <span></span></p>
			</div>
			<hr>
			<div id="set-boundaries">
				<h2> Drawing boundaries </h2>
				<p> You can visualize your elevation (&gt;73 m) and price per square foot (&gt;$19,116.7) observations as the boundaries of regions in your scatterplot. Homes plotted in the green and blue regions would be in San Francisco and New York, respectively. </p>
				<p> Identifying boundaries in data using math is the essence of statistical learning. </p>
				<p> Of course, you’ll need additional information to distinguish homes with lower elevations <em>and</em> lower per-square-foot prices. </p>
			</div>
			<hr>
			<div id="more-variables">
				
				<div id="listing-the-variables">
					<!--<div id="data-table"></div>-->
				<p> The dataset we are using to create the model has 7 different dimensions. Creating a model is also known as <strong>training</strong> a model. </p>
				<p> On the right, we are visualizing the variables in a <strong>scatterplot matrix</strong> to show the relationships between each pair of dimensions. </p>
				<p> There are clearly patterns in the data, but the boundaries for delineating them are not obvious. </p>
				</div>
				<div id="from-boundaries-to-pattern">
				<hr>

				<h2> And now, machine learning </h2>
				<p> Finding patterns in data is where machine learning comes in. Machine learning methods use statistical learning to identify boundaries. </p>
				<p> One example of a machine learning method is a <strong>decision tree</strong>. Decision trees look at one variable at a time and are a reasonably accessible (though rudimentary) machine learning method. </p>
				</div>

				<hr>
			</div>
		</div>
	</div><div id="split">
		<div>
			<div id="elevation-to-histogram">
				<hr>
				<h2> Finding better boundaries </h2>
				<p> Let's revisit the 73-m elevation boundary proposed previously to see how we can improve upon our intuition. </p>
				<p> Clearly, this requires a different perspective.  </p>
				<hr>
				<p> By transforming our visualization into a <strong>histogram</strong>, we can better see how frequently homes appear at each elevation. </p>
				<p> While the highest home in New York is 73m, the majority of them seem to have far lower elevations. </p>

			</div>
			<div id="introduce-split">
				<hr>
				<h2>Your first fork</h2>
				<p> A decision tree uses if-then statements to define patterns in data. </p>
				<p> For example, <strong>if</strong> a home's elevation is above some number, <strong>then</strong> the home is probably in San Francisco. </p>

			</div>
			<div id="explain-gini">
				<hr>
				<p> In machine learning, these statements are called <strong>forks</strong>, and they split the data into two <strong>branches</strong> based on some value. </p>
				<p> That value between the branches is called a <strong>split point</strong>. Homes to the left of that point get categorized in one way, while those to the right are categorized in another. A split point is the decision tree's version of a boundary. </p>

				<hr>
				<h2>Tradeoffs</h2>
				<p> Picking a split point has tradeoffs. Our initial split (~73 m) incorrectly classifies some San Francisco homes as New York ones. </p>
				<p> Look at that large slice of green in the left pie chart, those are all the San Francisco homes that are misclassified. These are called <strong>false negatives</strong>. </p>

				<hr>
				<p> However, a split point meant to capture every San Francisco home will include many New York homes as well. These are called <strong>false&nbsp;positives</strong>. </p>
				<hr>

				<h2>The best split</h2>
				<p> At the <strong>best split</strong>, the results of each branch should be as homogeneous (or pure) as possible. There are several mathematical methods you can choose between to calculate the best split.<span></span></p>
				<hr>
				<p>As we see here, even the best split on a single feature does not fully separate the San Francisco homes from the New York ones.</p>
				<hr>
			</div>
			<div id="further-split">
				<hr>
				<h2>Recursion</h2>
				<p>To add another split point, the algorithm repeats the process above on the subsets of data. This repetition is called <strong>recursion</strong>, and it is a concept that appears frequently in training models.<span></span></p>

				<p>The histograms to the left show the distribution of each subset, repeated for each variable.</p>
				<hr>
				<p>The best split will vary based which branch of the tree you are looking at.<span></span></p> 
				<p>For lower elevation homes, price per square foot is, at $1061 per sqft, is the best variable for the next if-then statement. For higher elevation homes, it is price, at $514,500</p><p>.

				</p><hr>
			</div>

		</div>
	</div><div id="tree">
		<div>
			<div>
				<hr>
				<h2>Growing a tree</h2>
				<p>Additional forks will add new information that can increase a tree's <strong>prediction accuracy</strong>.</p>
				<hr>
				<p>Splitting one layer deeper, the tree's accuracy improves to <strong>84%</strong>.</p>
				<hr>
				<p>Adding several more layers, we get to <strong>96%</strong>.</p>
				<hr>
				<p>You could even continue to add branches until the tree's predictions are <strong>100% accurate</strong>, so that at the end of every branch, the homes are purely in San Francisco or purely in New York.</p>

			</div>
			<div>
				<hr>
				<p>These ultimate branches of the tree are called <strong>leaf nodes</strong>. Our decision tree models will classify the homes in each leaf node according to which class of homes is in the majority.</p>
				<hr>
			</div>

		</div>
	</div><div id="test">
		<div>
			<div id="classify-training-data">
				<hr>
				<h2>Making predictions</h2>
				<p>The newly-trained decision tree model determines whether a home is in San Francisco or New York by running each data point through the branches.</p>
				<hr>
				<p>Here you can see the data that was used to train the tree flow through the tree.</p>

				<p>This data is called <strong>training data</strong> because it was used to train the model.</p>

				<hr>
				<p>Because we grew the tree until it was 100% accurate, this tree maps each training data point perfectly to which city it is in.</p>

			</div>
			<div id="classify-test-data">
				<hr>
				<h2>Reality check</h2>
				<p>Of course, what matters more is how the tree performs on previously-unseen data.</p>
				<hr>
				<p>To <strong>test</strong> the tree's performance on new data, we need to apply it to data points that it has never seen before. This previously unused data is called <strong>test data</strong>.</p>
				<hr>
				<p>Ideally, the tree should perform similarly on both known and unknown data.</p>
				<hr>
				<p>So this one is less than ideal.<span></span></p>
				<hr>

			</div>
			<div id="misclassification">

				<p>These errors are due to <strong>overfitting</strong>. Our model has learned to treat every detail in the training data as important, even details that turned out to be irrelevant.</p>

				<p>Overfitting is part of a fundamental concept in machine learning explained in our next post.<span></span></p>
				<hr>
			</div>
		</div>
	</div></div>]]>
            </description>
            <link>http://www.r2d3.us/visual-intro-to-machine-learning-part-1/?from=@</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813266</guid>
            <pubDate>Sun, 12 Jul 2020 17:58:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parallel Gzip – Pigz]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23813159">thread link</a>) | @keyboardman
<br/>
July 12, 2020 | https://leimao.github.io/blog/Parallel-Gzip-Pigz/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Parallel-Gzip-Pigz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Sometimes, we would like to compress one or several files into one zipped file or decompress a zipped file. It is very common to use tools such as gzip, zip, or 7zip to create or decompress <code>.gz</code>, <code>.zip</code>, and <code>.7z</code> files, respectively. However, none of these tools on Linux uses multicore and multithread during compression and decompression. When the number of files are large or the file sizes are large, compression and decompression would take a lot of time using single thread.</p>



<p>Pigz is one of the parallel implementation for gzip and zip. Using pigz could greatly save us the time spent on compression and decompression. In this blog post, I would like to briefly discuss how to use pigz.</p>

<h3 id="pigz">Pigz</h3>

<p>The pigz usages in the blog post are mainly targeted for Ubuntu systems. However, its usages on other Linux operating systems should be almost the same.</p>

<h4 id="installation">Installation</h4>

<div><div><pre><code><span>sudo </span>apt update
<span>sudo </span>apt <span>install </span>pigz
</code></pre></div></div>

<h4 id="pigz-usages">Pigz Usages</h4>

<div><div><pre><code>$ pigz --help
Usage: pigz [options] [files ...]
  will compress files in place, adding the suffix '.gz'. If no files are
  specified, stdin will be compressed to stdout. pigz does what gzip does,
  but spreads the work over multiple processors and cores when compressing.

Options:
  -0 to -9, -11        Compression level (level 11, zopfli, is much slower)
  --fast, --best       Compression levels 1 and 9 respectively
  -b, --blocksize mmm  Set compression block size to mmmK (default 128K)
  -c, --stdout         Write all processed output to stdout (won't delete)
  -d, --decompress     Decompress the compressed input
  -f, --force          Force overwrite, compress .gz, links, and to terminal
  -F  --first          Do iterations first, before block split for -11
  -h, --help           Display a help screen and quit
  -i, --independent    Compress blocks independently for damage recovery
  -I, --iterations n   Number of iterations for -11 optimization
  -J, --maxsplits n    Maximum number of split blocks for -11
  -k, --keep           Do not delete original file after processing
  -K, --zip            Compress to PKWare zip (.zip) single entry format
  -l, --list           List the contents of the compressed input
  -L, --license        Display the pigz license and quit
  -m, --no-time        Do not store or restore mod time
  -M, --time           Store or restore mod time
  -n, --no-name        Do not store or restore file name or mod time
  -N, --name           Store or restore file name and mod time
  -O  --oneblock       Do not split into smaller blocks for -11
  -p, --processes n    Allow up to n compression threads (default is the
                       number of online processors, or 8 if unknown)
  -q, --quiet          Print no messages, even on error
  -r, --recursive      Process the contents of all subdirectories
  -R, --rsyncable      Input-determined block locations for rsync
  -S, --suffix .sss    Use suffix .sss instead of .gz (for compression)
  -t, --test           Test the integrity of the compressed input
  -v, --verbose        Provide more verbose output
  -V  --version        Show the version of pigz
  -Y  --synchronous    Force output file write to permanent storage
  -z, --zlib           Compress to zlib (.zz) instead of gzip format
  --                   All arguments after "--" are treated as files
</code></pre></div></div>

<p>A typical command for compressing and decompressing a file is like the following:</p>

<div><div><pre><code><span># Compress</span>
<span># Always use -k to keep the original file</span>
<span>$ </span>pigz <span>-k</span> <span>-p8</span> image.png
<span># Decompress</span>
<span>$ </span>pigz <span>-dk</span> <span>-p8</span> image.gz
</code></pre></div></div>

<p>However, vanilla pigz is not very friendly to compressing multiple files into one single file and custom output filepath. We would need to rely on tar, the archive tool.</p>

<h4 id="tar-pigz-usages">Tar-Pigz Usages</h4>

<p>Using pipe <code>|</code>, we could first archive multiple files or directories first to <code>.tar</code> file and compress using pigz to further generate <code>.tar.gz</code> file.</p>

<div><div><pre><code><span># Compress</span>
<span>$ </span><span>tar</span> <span>-cf</span> - data/ index.json | pigz <span>-k</span> <span>-p8</span> <span>&gt;</span> dataset.tar.gz
<span># Decompress (Unfortunately two steps)</span>
<span>$ </span>pigz <span>-k</span> <span>-p8</span> dataset.tar.gz
<span># Extract file to another directory</span>
<span>$ </span><span>mkdir</span> <span>-p</span> new_dataset
<span>$ </span><span>tar</span> <span>-xf</span> dataset.tar <span>-C</span> new_dataset
</code></pre></div></div>

<p>Alternatively, tar has already integrated custom compressor in its interface, which makes the command looks more clear.</p>

<div><div><pre><code><span># Compress</span>
<span>$ </span><span>tar</span> <span>--use-compress-program</span><span>=</span><span>"pigz -k -p8"</span> <span>-cf</span> dataset.tar.gz data/ index.json
<span># Extract file to another directory</span>
<span>$ </span><span>mkdir</span> <span>-p</span> new_dataset
<span># Decompress</span>
<span>$ </span><span>tar</span> <span>--use-compress-program</span><span>=</span><span>"pigz -dk -p8"</span> <span>-xf</span> dataset.tar.gz <span>-C</span> new_dataset
</code></pre></div></div>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://zlib.net/pigz/">Pigz</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Parallel-Gzip-Pigz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813159</guid>
            <pubDate>Sun, 12 Jul 2020 17:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to reduce RDS costs in AWS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813099">thread link</a>) | @pcast
<br/>
July 12, 2020 | https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/ | <a href="https://web.archive.org/web/*/https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article, we will give describe some strategies to reduce Amazon RDS costs. This article is part of our <a href="https://www.iobasis.com/How-to-reduce-AWS-Costs/">How to reduce AWS Costs</a> article series.</p>
<p>Amazon RDS is a relational database service. The usual way to deploy a database is by installing it on your OS. Instead, Amazon RDS provides a database-as-a-service. And AWS takes care of hardware provisioning, database setup, patching, and backups.</p>
<p>Here are some benefits that Amazon RDS brings you:</p>
<ul>
<li>AWS manages the <strong>database hardware</strong> for you.</li>
<li>AWS manages the <strong>operating system</strong> (this includes configuration and patches) for you.</li>
<li>AWS manages the <strong>database</strong> service configuration and software patches for you.</li>
<li>Provides <strong>Multi-AZ</strong> deployment (this sets up a standby database instance with synchronous replication to master, and automatic failover/failback)</li>
<li>Provides database <strong>licenses</strong>, so you don’t have to acquire them.</li>
<li>Deploys <strong>Read replicas</strong> deployment.</li>
<li>Deploys <strong>automatic snapshots</strong>, and you can recover your database from any point in time within the last 35 days)</li>
<li>Deploys database <strong>at-rest encryption</strong> (with AWS KMS)</li>
<li>Deploys <strong>in-transit</strong> encryption (so you don’t need to deploy your SSL certificates)</li>
<li>Provides monitoring <strong>metrics</strong> integrated into AWS console (using CloudWatch)</li>
<li>Automatically uploads database <strong>logs</strong> to CloudWatch for a centralized management</li>
<li>Supports <strong>storage autoscaling</strong>, so you don’t run out of space when your database grows.</li>
<li>Supports <strong>IAM</strong> authentication (you store users’ credentials out of DB, so they can be used for multiple DBs or other AWS services)</li>
<li>Supports Amazon <strong>Aurora</strong> database which has additional features.</li>
</ul>
<p>In summary, Amazon RDS will simplify the operation and maintenance of your DB. But one of the main problems with relational databases is that they scale vertically. The database grows with time. And you need to use bigger hardware. That makes database costs increase fast.</p>
<p>So our objective is to describe some strategies to reduce your Amazon RDS costs. Note that each strategy has to be analyzed with the requirements of your workload. And you should use the strategies that work best for you.</p>
<h2>1. Changing the DB engine</h2>
<p>Amazon RDS supports 6 different types of relational database engines: MySQL, PostgreSQL, MariaDB, Oracle, Microsoft SQL Server, and Amazon Aurora.</p>
<p>These are all relational database technologies. The first 3 ones are open source database technologies. Oracle and Microsoft SQL Server are proprietary database technologies. And the last one, Amazon Aurora, is an AWS proprietary database. But it’s compatible with my MySQL and PostgreSQL.</p>
<p>The following picture compares the monthly price of a db.r5.xlarge OnDemand DB engine in us-east-2 (Ohio) region using Single-AZ configuration.</p>
<p>
  <span>
    <span>
      <img alt="RDS monthly price by db engine" title="" src="https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/5a190/RDS-monthly-price-by-db-engine-type.png" srcset="https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/772e8/RDS-monthly-price-by-db-engine-type.png 200w,
https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/e17e5/RDS-monthly-price-by-db-engine-type.png 400w,
https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/5a190/RDS-monthly-price-by-db-engine-type.png 800w,
https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/40601/RDS-monthly-price-by-db-engine-type.png 945w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>These 10 DB instances all use the same HW (a db.r5.xlarge instance). But the price has a huge variation based on the DB engine type.</p>
<p>Note that the 3 open source databases (MySQL, PostgreSQL, MariaDB) almost have the same price. And they are the most economical. And Amazon Aurora is a bit more expensive than them.</p>
<p>Amazon RDS engine pricing includes the licensing for the corresponding database engine. So it’s not necessary to bring your license (BYOL) for this service. The cost of Microsoft (or Oracle) database licenses is already included in the RDS service price. For this reason, these are more expensive than the rest.</p>
<p>Changing the database engine is not a simple task. Not only the database data has to change. You have to make sure the code using it could also be changed. And your team has to know how to use it.</p>
<p>But having that said, it’s important to note that the type of database technology will have a big impact on your costs. If you can change the technology of your database, that could avoid the licensing fees. For example, if you change from RDS for Oracle SE2 to Aurora PostgresSQL, you will save <strong>44%</strong> monthly.</p>
<p>In case you decide to migrate your database, you can use <a href="https://aws.amazon.com/dms/">AWS Database Migration Service</a>. This is a tool that allows you to migrate your database (and schema) to a new engine. And it’s free (you only pay for the EC2 instance to run it).</p>
<h2>2. Using Amazon EC2 instead of Amazon RDS</h2>
<p>This strategy is probably an option that no cloud specialist will mention. But it’s worth evaluating. As we mentioned before, Amazon RDS has lots of benefits and makes the database administration much easier. But it also brings higher costs.</p>
<p>Let’s compare the cost of a database in EC2 and RDS. We will use an on-demand EC2 r5.xlarge instance which has 4 vCPUs with 32 GiB of memory. It uses the same hardware as the db.r5.xlarge database. Here are the results:</p>
<table>
<thead>
<tr>
<th>EC2 AMI</th>
<th>EC2 Price ($)</th>
<th>RDS Price ($)</th>
<th>Savings</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows Server 2019 with SQL Server 2019 Enterprise</td>
<td>1393.92</td>
<td>1800.72</td>
<td>23%</td>
</tr>
<tr>
<td>Windows Server 2019 with SQL Server 2019 Standard</td>
<td>659.52</td>
<td>1094.4</td>
<td>40%</td>
</tr>
<tr>
<td>Windows Server 2019 with SQL Server 2019 Web</td>
<td>362.88</td>
<td>633.6</td>
<td>42%</td>
</tr>
<tr>
<td>Linux with SQL Enterprise</td>
<td>1261.44</td>
<td>1800.72</td>
<td>30%</td>
</tr>
<tr>
<td>Linux with SQL Standard</td>
<td>527.04</td>
<td>1094.4</td>
<td>51%</td>
</tr>
<tr>
<td>Linux with SQL Web</td>
<td>230.4</td>
<td>633.6</td>
<td>63%</td>
</tr>
<tr>
<td>Linux</td>
<td>181.44</td>
<td>345.6</td>
<td>47%</td>
</tr>
</tbody>
</table>
<p>For example in the first row, the price of Amazon RDS with SQL Server is $ 1800.72 per month (in Ohio). If we host the in an EC2 instance with <em>Windows Server 2019 with SQL Server 2019 Enterprise</em> AMI, the price is $ 1393.92 per month. That’s <strong>23%</strong> below RDS price. And if we use it on an EC2 with “Linux with SQL Enterprise” the cost will be <strong>30%</strong> less.</p>
<p>In the last row, the price of Amazon RDS MySQL-compatible is $ 345.6 per month. But hosting the database on an EC2 with Linux AMI costs $ 181.44. That’s <strong>47%</strong> less.</p>
<p>Additionally, hosting a database on Amazon EC2 will also bring more flexibility regarding the types of EC2 instances you can choose. For example, there are 254 types of EC2 instances and only 18 RDS database instance types.</p>
<p>You can choose this strategy if you want to reduce your database costs, and you can afford the overhead of deploying and maintaining the database yourself.</p>
<h2>3. Right-Sizing your database instance</h2>
<p>This strategy consists of choosing the right database instance for your workload. The good point is that there are only 5 families of databases instances: “t”, “m”, “r”, “x” and “z”. And the number of instance types is low as well (compared with the number of AWS EC2 instance types). For example, there are currently 22 database instances for Amazon RDS for PostgreSQL. This makes the decision easier.</p>
<p>How to decide what is the best database instance for my workload? The right approach is to determine your database requirements (including memory, CPU, IOPs, and others). And then choosing the most cost-effective instance that complies with them.</p>
<p>You can start monitoring your database using CloudWatch Metrics for RDS. Metrics like CPUUtilization, FreeableMemory, and ReadIOPS are very useful to understand the utilization of the CPU, memory, and storage. You can also enable Enhanced Monitoring (it has a small fee). This will show how each process in the database is using memory and CPU.</p>
<p>Here is a quick approach to filter database instances. First, you visit <a href="https://www.ec2instances.info/">EC2 instances info</a>. You choose RDS and your region. Then remove the unnecessary price columns (for example, all price-related columns except “MySQL On-Demand Cost”). And afterward, you add the required GiB in the Memory filter. For example, if your database uses 9 GiB of memory, so might choose 16 GiB. You will get a list with all the instances that match this memory size, and they will be ordered by the lowest cost. For example, after setting the filters, we got only 9 database instances types. And finally, you could choose the right instance according to the estimated CPU usage. Here you have both price and hardware characteristics of the database instances, and this will simplify your decision.</p>
<p>Note that each time you switch to a smaller instance, the database half the previous size (except some specific cases). And you will save <strong>50%</strong>. That’s why it’s very important to find the right instance size for your workload.</p>
<h2>4. Using Reserved DB Instances</h2>
<p>Reserved Instances allows you to save money by committing to use the database instance for 1 or 3 years. You purchase a Reserved Instance plan, and that gives you a discount.</p>
<p>For example, here are current Amazon RDS savings expected for a MySQL database using a db.r5.xlarge DB instance in Ohio.</p>
<table>
<thead>
<tr>
<th>Payment Option</th>
<th>Monthly Price (r5.xlarge)</th>
<th>Savings over On-Demand</th>
</tr>
</thead>
<tbody>
<tr>
<td>On-Demand</td>
<td>345.6</td>
<td></td>
</tr>
<tr>
<td>Reserved 1 year (No Upfront)</td>
<td>199.44</td>
<td>42%</td>
</tr>
<tr>
<td>Reserved 1 year (All Upfront)</td>
<td>186.48</td>
<td>46%</td>
</tr>
<tr>
<td>Reserved 3 year (All Upfront)</td>
<td>125.28</td>
<td>64%</td>
</tr>
</tbody>
</table>
<p>Purchasing Reserved Instances will allow you to save <strong>30% to 64%</strong> (depending on the payment term, region, database engine, and instance type). So you should evaluate if this works for your workload.</p>
<h2>5. Stopping and Starting database engines</h2>
<p>The database instance is charged proportionally to the time it’s running. You can stop your testing instances after business hours, or when they aren’t used. This can be done using the console. Or you can automate stopping (and restarting) the database instances at certain times of the day.</p>
<p>For example, let’s say that you use some database instances on standard business hours only. That’s 45 hours a week (out of 168 hours). So you will save <strong>73%</strong> of the costs of this database instance.</p>
<p>Keep in mind that when your database is not running, you will still pay for the storage and snapshots used. Additionally, a database can be stopped for up to 7 days. After this period, AWS will start it automatically.</p>
<p>Stopping and starting the database instances is available only to instances with Single-AZ configuration and without Read replicas.</p>
<h2>6. Using Aurora Serverless</h2>
<p>In case you are using Aurora, you can switch to Aurora Serverless. It automatically scales the database instance hardware (assigning up to 488 GiB of memory). AWS charges you proportionally to the provisioned compute in terms of ACUs.</p>
<p>But apart from autoscaling, Aurora Serverless will pause your database if you aren’t using it. When that happens, you will only be charged for storage (but not for the DB instance).</p>
<p>The most important point is that the database instance will scale to accommodates current usage. In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/">https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/</a></em></p>]]>
            </description>
            <link>https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813099</guid>
            <pubDate>Sun, 12 Jul 2020 17:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Investor Due Diligence: A Breakdown and Investor Funnel Template]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812918">thread link</a>) | @aleberry
<br/>
July 12, 2020 | https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template | <a href="https://web.archive.org/web/*/https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="2b3385af-b82e-4ad2-6d91-62ecc32da36c"><p>Let's flip the conversation from your typical research, Google searches, and thought process on fundraising in tech.</p><p>There are plenty of resources by funds themselves on how VCs, Angels, CVCs, and even&nbsp;PEs perform due diligence on potential portfolio companies. </p><p>As a founder or startup, you should absolutely be doing the same internal due diligence on investors PRIOR&nbsp;to reaching out &amp; pitching. Think about dating, recruiting, or interviewing for a job. Are you swiping right on every single person or job? For your sanity,&nbsp;I&nbsp;hope not! </p><p>By creating your investor funnel and running through the checklist, you'll prevent wasted resources &amp; a bad taste in your mouth. More importantly, you'll get to your end goal faster! &nbsp;<strong>Cuz let's be honest... $$$.</strong></p><p>‍</p><figure id="w-node-05b9cbd3c263-ddfd485f"><p><img src="https://assets.website-files.com/5cf81ba4df6b3245b963fc60/5f0642f501cd0245c3dfe5d3_giphy.gif" alt="this is bad parks and rec GIF"></p></figure><p>‍</p><blockquote>Before we jump in, you should note that fundraising &amp;&nbsp;Investor Relations (IR)&nbsp;are full-time jobs for a reason.&nbsp;There is an art to communication, relationship building, &amp; the entire R&amp;D process. You will not be able to find ALL this information easily, and that's ok. We are always here to hold your hand, but you should identify what you are looking for before speaking to us or another consultant. <p>TL;DR:&nbsp;Don't go to a matchmaker without some kind of list. This is time-consuming, but you are asking for $$$.</p></blockquote><p>‍</p><h3>Investor Funnel Template</h3><p>When startups &amp; companies hire us for investor relations &amp; fundraising, this is where we start. In addition to our own database that we keep up to date, we add new contacts based off previous syndicate deals, partnerships, and of course any new funds that may be a good fit. </p><p>This funnel can be integrated with your CRM and Dealflow management platform. If you have questions about that, <a href="https://www.aleberrycreative.com/contact" target="_blank">just send us a note</a>! We also recommend an Investor Relations (IR) page or form option on your website.</p><p>‍</p><figure><p><img src="https://assets.website-files.com/5cf81ba4df6b3245b963fc60/5f0756577bd62fc02173ef67_investor%20funnel%20gif%20-%20blog.gif" alt="Investor Due Diligence Investor Funnel"></p></figure><p>‍</p><p>Here's a quick overview of our sheet (for free, just for you!) in both Grid &amp;&nbsp;Kanban view.</p><p>‍</p><p>‍</p><p><a href="https://airtable.com/invite/l?inviteId=invW6Pi6kgNCe5oGK&amp;inviteToken=27c71005995b7ac891c9f3c23fbb43f5186b09bee4f9606462f98f61537f0f4d" target="_blank">You can also access it here, if you prefer to export or duplicate.</a></p><p>‍</p><blockquote>By the way, we're huge fans of <a href="https://airtable.com/invite/r/SCZ6qu5g" target="_blank">Airtable</a>! Innovating Spreadsheets, I mean come on - it's genius! For folks like us that preferred to stay away from&nbsp;<a href="https://www.aleberrycreative.com/who-we-are" target="_blank">Media Buying in&nbsp;Ad School</a>, they make spreadsheets super easy to use &amp; customize.</blockquote><blockquote>Not-Really-A-Disclaimer: They are not a client. Hey Airtable, if you ever want to chat - we so would!</blockquote><p>‍</p><p>‍</p><h3>The basics - the tabs / categories</h3><p>We'll break down each tab in detail:</p><ul role="list"><li>Investor /&nbsp;Fund List</li><li>Contacts (individual investors or points of contact at said funds)</li><li>Industry Companies (not direct competition, but other funded companies in your vertical)</li><li>Pitch Feedback (this is an Aleberry thing, but you'd be surprised how useful this is for noticing patterns)</li></ul><p>‍</p><p>This organization lends itself to a solid setup on your CRM&nbsp;or Dealflow platform, if that's your preference for Investor Relations. We would generally do this sheet first, then integrate actual applicable funds into your CRM as you contact them.</p><p>‍</p><p>‍</p><h3>Investor / Fund Tab</h3><p>This is your main overall focus, ie. the first tab. We also put this one in Kanban view based off Status.</p><ul role="list"><li>Fund or Investor Name</li><li>Status</li><li>HQ&nbsp;Location</li><li>Website</li><li>Type</li><li>How To Reach Out</li><li>Social Links (LI, Twitter, Angel.co, Crunchbase)</li><li>Applicable Portfolio Companies</li><li>Verticals</li><li>Avg.&nbsp;Investment Size</li><li>Deals/Year</li><li>Key Metrics,&nbsp;Requirements, &amp; Notes</li><li>Connections</li><li>Contacts (links to CONTACTS tab)</li><li>Feedback (links to Pitch Feedback)</li><li>Industry&nbsp;Companies (links to INDUSTRY&nbsp;COMPANIES&nbsp;tab)</li></ul><p>‍</p><p><strong>Fund or Investor Name:</strong></p><p>Obviously.</p><p>‍</p><p><strong>Status: </strong></p><p>This is how the Kanban view is sorted, and you can think of this as your CRM /&nbsp;Funnel&nbsp;Status. Where are you with the investor in the dealflow process?</p><ul role="list"><li>Internal R&amp;D: Initial status.&nbsp;You heard of them &amp;&nbsp;jotted their name, but need to do or are in the process of some R&amp;D to ensure they are the right fit.</li><li>Contacted: You did some R&amp;D; it seems like they would be good. You've reached out. If you are curious about how to approach this, <a href="https://www.aleberrycreative.com/contact" target="_blank">talk to us</a>!</li><li>Follow Up Initial Contact: Follow up on the initial contact if you haven't heard back, or if they requested a few more details</li><li>Deck Sent:&nbsp;Things are moving along &amp; you sent your deck! Maybe you already sent it with the initial contact, maybe you need tweaks, either way - they have something of yours to review.</li><li>Pitching: They love your (hopefully <a href="https://www.aleberrycreative.com/our-work" target="_blank">beautifully crafted deck &amp; story by Aleberry</a> :) ) and have requested a pitch / meeting.</li><li>Follow Up Post Pitch:&nbsp;I hope you sent a thank you of some kind post pitch. As your mum would say: Manners! Follow Up if you haven't heard back, or if you need to submit more information.</li><li>Bad Fit: You're going to end your funnel here 90% of the time. Keep your head up, and remember the analogy of dating! </li><li>Term Sheet Review: WOOT!! Negotiate or Sign or Pass.&nbsp;Either way you got their attention.</li></ul><p>‍</p><p><strong>HQ&nbsp;Location:</strong></p><p>As a one positive of this COVID world, we're finding this is becoming less important.&nbsp;However, it is good to note where they are located for post-COVID, in-person pitches &amp; general timezone coordination.</p><p>‍</p><p><strong>Website:&nbsp;</strong></p><p>Good to refer back to. Also depending on your CRM, you may be able to auto-pull some data.</p><p>‍</p><p><strong>Type:</strong></p><p>How would you categorize them? Important for pitching &amp; understanding if they are a good fit or not.</p><ul role="list"><li>Individual Angel</li><li>Individual VC</li><li>Group (Syndicate or other)<br></li><li>VC Fund</li><li>PE</li><li>CVC</li><li>MicroVC</li></ul><p>‍</p><p><strong>How to Reach Out:</strong></p><p>In an effort to promote more diverse founders, many funds are opening their doors to cold intros. We've always been a big proponent of this because while relationships will always be an important aspect of every facet in life - innovations come from all kinds of founders. </p><p>If your product or company are amazing, you should have access to funds -- no matter your background. </p><p>Some funds may have specific details on their website about a) if they have an open round or are open to new deals b) how to send your submission. </p><p>If they don't, there are always ways to find out!</p><p>‍</p><p><strong>Social Links:</strong></p><p>LinkedIn,&nbsp;Twitter,&nbsp;Angel.co, Crunchbase, Pitchbook, F6S... the list goes on, but we just selected a few. This is not an invitation to bombard them :) . It is an invitation to listen &amp; see past investments.</p><p>VCs are more active on&nbsp;LinkedIn &amp;&nbsp;Twitter. Often their thoughts are posted on potential investments, the market, and general ideas. Our mate <a href="http://haystack.vc/" target="_blank">Semil&nbsp;Shah with&nbsp;Haystack</a>'s <a href="https://twitter.com/semil" target="_blank">Twitter</a> account is full of great insight. </p><p>‍</p><p><strong>Applicable Portfolio&nbsp;Companies:</strong></p><p>Are there any companies you know / are connected to? Any portfolio companies in your industry?</p><p>Founders who successfully raised are amazing resources, and most of the time - they are happy to lend a hand or intro.</p><p>‍</p><p><strong>Verticals:</strong></p><p>Does the fund only invest in specific verticals/industries? We included a few common ones here, but feel free to edit. </p><p>If a fund only invests in FinTech &amp;&nbsp;Enterprise SaaS platforms, your Medical Device will not even be looked at. </p><p>‍</p><p><strong>Average Investment Size &amp;&nbsp;Deals Per Year:</strong></p><p>Both these columns can be identified together. This will determine if the fund is the right fit based off your ask &amp; what your chances are to receive funding.</p><p>Some investors make a handful of investments a year at $3-5M each, others do 30 at $1M each, and large funds may invest in a large number for both check size &amp; deals.</p><p>‍</p><p><strong>Key Metrics,&nbsp;Requirements, and Notes:</strong></p><p>Many investor websites openly state what metrics (traction, ARR, team, geography, etc.) they look for. You can also take a quick look at their portfolio &amp; make some assumptions. </p><p>Use this column as a junk drawer of random notes if needed. </p><p>‍</p><p><strong>Connections:</strong></p><p>We don't know every investor in the world, nor do we pretend to! What you will quickly find is the investor world, especially in specific verticals, is small. We use these columns to see if there are any shared connections who could offer insight or intros to outside our investor network. </p><p>You can do the same &amp; use the founder method if needed.</p><p>If we have an awesome AgTech company that would be a perfect fit for a CVC, we may not know the venture arm - but we may know someone at the corporation who can provide some insights or an intro.</p><p>VERY&nbsp;TARGETED outreach can be done delicately, just don't come off as a spammer. :) Scratch that, just talk to us first! </p><p>‍</p><p><strong>Contacts:</strong></p><p>This is linked to the CONTACTS tab. It is a good place to connect specific folks to the fund. The team pages are full of insights into which LP / investor works in which vertical. Integrate this into your CRM once you start communicating with them.</p><p>‍</p><p><strong>Feedback:</strong></p><p>Linked to the PITCH&nbsp;FEEDBACK&nbsp;TAB. As mentioned, this is an Aleberry thing - but we find it helpful when working with both funds &amp; founders. </p><p>This tab is incredibly helpful for noticing patterns. </p><p>ASK&nbsp;FOR&nbsp;FEEDBACK &amp;&nbsp;TAKE&nbsp;IT&nbsp;KINDLY. We can not stress the latter enough. An investor not only reviewed your deck, but they are willing to give you some insights on why they passed. Listen &amp; decide if the advice is applicable or not, but don't burn bridges.</p><p>‍</p><p><strong>Industry Companies:</strong></p><p>This will auto-populate from the INDUSTRY&nbsp;COMPANIES&nbsp;tab. More on that below.</p><p>‍</p><p>‍</p><h3>Contacts:</h3><p>This one needs a lot less explanation. It's basically your Rolodex for contact information. Make sure to tie the name to fund for Tab One. We added the last two columns on initial contact &amp; last contacted, but don't always use those. If you are not using a CRM for Investor Relations - these two columns may be helpful.</p><p>‍</p><p>‍</p><h3>Industry&nbsp;Companies</h3><p>Are there any companies in your industry / vertical that have successfully raised? Who did they raise from?&nbsp;This is a fantastic way to identify funds that will be further down your pipeline. It may also give you an in if you know the company.</p><p>While you should identify direct competitors, you should note that funds will not invest in direct competition. This may eliminate a fund for you, while also giving you insight into a similar raise. </p><p>Tag the funds! </p><p>‍</p><p>‍</p><h3>Pitch&nbsp;Feedback:</h3><p>We included a few common themes that we see, but you should add simple phrases here. Tag the Main INVESTOR&nbsp;Tab. Use the notes area to jot any additional details.</p><p>This will help you identify patterns, as well as make some fixes if possible (or just eliminate the fund from your list).</p><p>‍</p><p>‍</p><h3>That's a lot of information!</h3><p>Yes it is, but don't feel overwhelmed. </p><p>You are asking for money, so you should expect to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template">https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template</a></em></p>]]>
            </description>
            <link>https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812918</guid>
            <pubDate>Sun, 12 Jul 2020 17:14:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proving Algebraic Datatypes Are “Algebraic”]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812854">thread link</a>) | @sendilkumarn
<br/>
July 12, 2020 | https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html | <a href="https://web.archive.org/web/*/https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   
   <div>
    
    <p>
    Several programming languages allow programmers to define (potentially
    recursive) custom types, by composing together existing ones. For instance,
    in OCaml, one can define lists as follows:
    </p>
    <pre>type 'a list =
| Cons of 'a * 'a list
| Nil
</pre>
    <p>
    This translates in Haskell as
    </p>
    <pre>data List a =
  Cons a (List a)
| Nil
</pre>
    <p>
    In Rust:
    </p>
    <pre>enum List&lt;A&gt; {
  Cons(A, Box&lt; List&lt;a&gt; &gt;),
  Nil,
}
</pre>
    <p>
    In Coq:
    </p>
    <pre>Inductive list a :=
| cons : a -&gt; list a -&gt; list a
| nil
</pre>
    <p>
    And so forth.
    </p><p>
    Each language will have its own specific constructions, and the type systems
    of OCaml, Haskell, Rust and Coq —to only cite them— are far from being
    equivalent. That being said, they often share a common “base formalism,”
    usually (and sometimes abusively) referred to as <i>algebraic datatypes</i>. This
    expression is used because under the hood any datatype can be encoded as a
    composition of types using two operators: sum (<span>+</span>) and product (<span>*</span>) for
    types.
    </p>
    <ul>
     <li>
      <span><span title="var">a</span></span> <span>+</span> <span><span title="var">b</span></span> is the disjoint union of types <span><span title="var">a</span></span> and <span><span title="var">b</span></span>. Any term of <span><span title="var">a</span></span>
        can be injected into <span><span title="var">a</span></span> <span>+</span> <span><span title="var">b</span></span>, and the same goes for <span><span title="var">b</span></span>. Conversely,
        a term of <span><span title="var">a</span></span> <span>+</span> <span><span title="var">b</span></span> can be projected into either <span><span title="var">a</span></span> or <span><span title="var">b</span></span>.
     </li>
     <li>
      <span><span title="var">a</span></span> <span>*</span> <span><span title="var">b</span></span> is the Cartesian product of types <span><span title="var">a</span></span> and <span><span title="var">b</span></span>. Any term of <span><span title="var">a</span></span> <span>*</span>
        <span><span title="var">b</span></span> is made of one term of <span><span title="var">a</span></span> and one term of <span><span title="var">b</span></span> (remember tuples?).
     </li>
    </ul>
    <p>
    For an algebraic datatype, one constructor allows for defining “named
    tuples”, that is ad-hoc product types. Besides, constructors are mutually
    exclusive: you cannot define the same term using two different constructors.
    Therefore, a datatype with several constructors is reminescent of a disjoint
    union.  Coming back to the <span><span title="var">list</span></span> type, under the syntactic sugar of
    algebraic datatypes, the <span><span title="var">list</span></span> <span><span title="var">α</span></span> type is equivalent to <span><span title="var">unit</span></span> <span>+</span> <span><span title="var">α</span></span> <span>*</span> <span><span title="var">list</span></span> <span><span title="var">α</span></span>,
    where <span><span title="var">unit</span></span> models the <span><span title="var">nil</span></span> case, and <span><span title="var">α</span></span> <span>*</span> <span><span title="var">list</span></span> <span><span title="var">α</span></span> models the <span><span title="var">cons</span></span> case.
    </p><p>
    The set of types which can be defined in a language together with <span>+</span> and
    <span>*</span> form an “algebraic structure” in the mathematical sense, hence the
    name. It means the definitions of <span>+</span> and <span>*</span> have to satisfy properties
    such as commutativity or the existence of neutral elements. In this article,
    we will prove some of them in Coq. More precisely,
    </p>
    <ul>
     <li>
      <span>+</span> is commutative, that is <span><span><span>
      <math xmlns="http://www.w3.org/1998/Math/MathML">
       <semantics>
        <mrow>
         <mi mathvariant="normal">
          ∀
         </mi>
         <mo stretchy="false">
          (
         </mo>
         <mi>
          x
         </mi>
         <mo separator="true">
          ,
         </mo>
         <mi>
          y
         </mi>
         <mo stretchy="false">
          )
         </mo>
         <mo separator="true">
          ,
         </mo>
         <mtext>
          &nbsp;
         </mtext>
         <mi>
          x
         </mi>
         <mo>
          +
         </mo>
         <mi>
          y
         </mi>
         <mo>
          =
         </mo>
         <mi>
          y
         </mi>
         <mo>
          +
         </mo>
         <mi>
          x
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         \forall (x, y),\ x + y
        = y + x
        </annotation>
       </semantics>
      </math>
     </span>
     
    </span>
    

   </span>
  </li>
  <li>
   <span>+</span> is associative, that is <span><span><span>
   <math xmlns="http://www.w3.org/1998/Math/MathML">
    <semantics>
     <mrow>
      <mi mathvariant="normal">
       ∀
      </mi>
      <mo stretchy="false">
       (
      </mo>
      <mi>
       x
      </mi>
      <mo separator="true">
       ,
      </mo>
      <mi>
       y
      </mi>
      <mo separator="true">
       ,
      </mo>
      <mi>
       z
      </mi>
      <mo stretchy="false">
       )
      </mo>
      <mo separator="true">
       ,
      </mo>
      <mtext>
       &nbsp;
      </mtext>
      <mo stretchy="false">
       (
      </mo>
      <mi>
       x
      </mi>
      <mo>
       +
      </mo>
      <mi>
       y
      </mi>
      <mo stretchy="false">
       )
      </mo>
      <mo>
       +
      </mo>
      <mi>
       z
      </mi>
      <mo>
       =
      </mo>
      <mi>
       x
      </mi>
      <mo>
       +
      </mo>
      <mo stretchy="false">
       (
      </mo>
      <mi>
       y
      </mi>
      <mo>
       +
      </mo>
      <mi>
       z
      </mi>
      <mo stretchy="false">
       )
      </mo>
     </mrow>
     <annotation encoding="application/x-tex">
      \forall (x, y, z),\ (x
        + y) + z = x + (y + z)
     </annotation>
    </semantics>
   </math>
  </span>
  
 </span>
 

</span>
</li>
<li>
<span>+</span> has a neutral element, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
 <semantics>
  <mrow>
   <mi mathvariant="normal">
    ∃
   </mi>
   <msub>
    <mi>
     e
    </mi>
    <mi>
     s
    </mi>
   </msub>
   <mo separator="true">
    ,
   </mo>
   <mtext>
    &nbsp;
   </mtext>
   <mi mathvariant="normal">
    ∀
   </mi>
   <mi>
    x
   </mi>
   <mo separator="true">
    ,
   </mo>
   <mtext>
    &nbsp;
   </mtext>
   <mi>
    x
   </mi>
   <mo>
    +
   </mo>
   <msub>
    <mi>
     e
    </mi>
    <mi>
     s
    </mi>
   </msub>
   <mo>
    =
   </mo>
   <mi>
    x
   </mi>
  </mrow>
  <annotation encoding="application/x-tex">
   \exists e_s,
        \ \forall x,\ x + e_s = x
  </annotation>
 </semantics>
</math>
</span>

</span>


</span>
</li>
<li>
<span>*</span> is commutative, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
 ∀
</mi>
<mo stretchy="false">
 (
</mo>
<mi>
 x
</mi>
<mo separator="true">
 ,
</mo>
<mi>
 y
</mi>
<mo stretchy="false">
 )
</mo>
<mo separator="true">
 ,
</mo>
<mtext>
 &nbsp;
</mtext>
<mi>
 x
</mi>
<mo>
 ∗
</mo>
<mi>
 y
</mi>
<mo>
 =
</mo>
<mi>
 y
</mi>
<mo>
 ∗
</mo>
<mi>
 x
</mi>
</mrow>
<annotation encoding="application/x-tex">
\forall (x, y),\ x * y
        = y * x
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
<li>
<span>*</span> is associative, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo separator="true">
,
</mo>
<mi>
y
</mi>
<mo separator="true">
,
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
∗
</mo>
<mi>
y
</mi>
<mo stretchy="false">
)
</mo>
<mo>
∗
</mo>
<mi>
z
</mi>
<mo>
=
</mo>
<mi>
x
</mi>
<mo>
∗
</mo>
<mo stretchy="false">
(
</mo>
<mi>
y
</mi>
<mo>
∗
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\forall (x, y, z),\ (x
        * y) * z = x * (y * z)
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
<li>
<span>*</span> has a neutral element, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∃
</mi>
<msub>
<mi>
e
</mi>
<mi>
p
</mi>
</msub>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi mathvariant="normal">
∀
</mi>
<mi>
x
</mi>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
∗
</mo>
<msub>
<mi>
e
</mi>
<mi>
p
</mi>
</msub>
<mo>
=
</mo>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
\exists e_p,
        \ \forall x,\ x * e_p = x
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
<li>
The distributivity of <span>+</span> and <span>*</span>, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo separator="true">
,
</mo>
<mi>
y
</mi>
<mo separator="true">
,
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
∗
</mo>
<mo stretchy="false">
(
</mo>
<mi>
y
</mi>
<mo>
+
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
<mo>
=
</mo>
<mi>
x
</mi>
<mo>
∗
</mo>
<mi>
y
</mi>
<mo>
+
</mo>
<mi>
x
</mi>
<mo>
∗
</mo>
<mi>
z
</mi>
</mrow>
<annotation encoding="application/x-tex">
\forall
        (x, y, z),\ x * (y + z) = x * y + x * z
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
<li>
<span>*</span> has an absorbing element, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∃
</mi>
<msub>
<mi>
e
</mi>
<mi>
a
</mi>
</msub>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi mathvariant="normal">
∀
</mi>
<mi>
x
</mi>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
∗
</mo>
<msub>
<mi>
e
</mi>
<mi>
a
</mi>
</msub>
<mo>
=
</mo>
<msub>
<mi>
e
</mi>
<mi>
a
</mi>
</msub>
</mrow>
<annotation encoding="application/x-tex">
\exists e_a,
        \ \forall x, \ x * e_a = e_a
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
</ul>
<p>
For the record, the <span><span title="var">sum</span></span> and <span><span title="var">prod</span></span> types are defined in Coq as follows:
</p>
<pre>Inductive sum (A B : Type) : Type :=
| inl : A -&gt; sum A B
| inr : B -&gt; sum A B

Inductive prod (A B : Type) : Type :=
| pair : A -&gt; B -&gt; prod A B
</pre>

<ol>
<li>
<a href="#1">An Equivalence for <span><span title="keyword">Type</span></span></a>
<ol>
<li>
<a href="#2">Introducing <span><span title="var">type_equiv</span></span></a>
</li>
<li>
<a href="#3"><span><span title="var">type_equiv</span></span> is an Equivalence</a>
</li>
<li>
<a href="#4">Examples</a>
<ol>
<li>
<a href="#5"><span><span title="var">list</span></span>’s Canonical Form</a>
</li>
<li>
<a href="#6"><span><span title="var">list</span></span> is a Morphism</a>
</li>
<li>
<a href="#7"><span><span title="var">nat</span></span> is a Special-Purpose <span><span title="var">list</span></span></a>
</li>
<li>
<a href="#8">Non-empty Lists</a>
</li>
</ol>
</li>
</ol>
</li>
<li>
<a href="#9">The <span><span title="var">sum</span></span> Operator</a>
<ol>
<li>
<a href="#10"><span><span title="var">sum</span></span> is a Morphism</a>
</li>
<li>
<a href="#11"><span><span title="var">sum</span></span> is Commutative</a>
</li>
<li>
<a href="#12"><span><span title="var">sum</span></span> is Associative</a>
</li>
<li>
<a href="#13"><span><span title="var">sum</span></span> has a Neutral Element</a>
</li>
</ol>
</li>
<li>
<a href="#14">The <span><span title="var">prod</span></span> Operator</a>
<ol>
<li>
<a href="#15"><span><span title="var">prod</span></span> is a Morphism</a>
</li>
<li>
<a href="#16"><span><span title="var">prod</span></span> is Commutative</a>
</li>
<li>
<a href="#17"><span><span title="var">prod</span></span> is Associative</a>
</li>
<li>
<a href="#18"><span><span title="var">prod</span></span> has a Neutral Element</a>
</li>
</ol>
</li>
<li>
<a href="#19"><span><span title="var">prod</span></span> has an Absorbing Element</a>
</li>
<li>
<a href="#20"><span><span title="var">prod</span></span> and <span><span title="var">sum</span></span> Distributivity</a>
</li>
<li>
<a href="#21">Bonus: Algebraic Datatypes and Metaprogramming</a>
</li>
</ol>

<div id="history">
<details>
<summary>
Revisions
</summary>
<p>
This revisions table has been automatically generated
    from <a href="https://code.soap.coffee/writing/lthms.git">the <code>git</code> history
    of this website repository</a>, and the change
    descriptions may not always be as useful as they
    should.
</p>
<p>
You can consult the source of this file in its current
    version <a href="https://code.soap.coffee/writing/lthms.git/tree/site/posts/AlgebraicDatatypes.v">here</a>.
</p>
<table>
<tbody>
<tr>
<td id="modified-at">
2020-07-12
</td>
<td>
More spellchecking and typos
</td>
<td>
<a href="https://code.soap.coffee/writing/lthms.git/commit/site/posts/AlgebraicDatatypes.v/?id=48a9b49581e953ce7f7c6c36da107e07e3c7345f">
        48a9b49
      </a>
</td>
</tr>
<tr>
<td>
2020-07-12
</td>
<td>
Invert the table of contents and the revision tables
</td>
<td>
<a href="https://code.soap.coffee/writing/lthms.git/commit/site/posts/AlgebraicDatatypes.v/?id=0a750a2f3cd95842f22b89bf23f92e7781291a8b">
        0a750a2
      </a>
</td>
</tr>
<tr>
<td>
2020-07-12
</td>
<td>
Spellchecking
</td>
<td>
<a href="https://code.soap.coffee/writing/lthms.git/commit/site/posts/AlgebraicDatatypes.v/?id=cec5638c1a23303723464bf5f73cea475fb4d94c">
        cec5638
      </a>
</td>
</tr>
<tr>
<td id="created-at">
2020-07-12
</td>
<td>
New article on Algebraic Datatypes
</td>
<td>
<a href="https://code.soap.coffee/writing/lthms.git/commit/site/posts/AlgebraicDatatypes.v/?id=41007fce2a333ba78be703c35f4afccade3369e5">
        41007fc
      </a>
</td>
</tr>
</tbody>
</table>
</details>
</div>
</div>

<div>
<h2 id="1">
An Equivalence for <span><span title="keyword">Type</span></span>
</h2>
<p>
Algebraic structures come with <i>equations</i> expected to be true.  This means
    there is an implicit dependency which is —to my opinion— too easily
    overlooked: the definition of <span>=</span>. In Coq, <span>=</span> is a built-in relation that
    states that two terms are “equal” if they can be reduced to the same
    “hierarchy” of constructors. This is too strong in the general case, and in
    particular for our study of algebraic structures of <span><span title="keyword">Type</span></span>. It is clear
    that, to Coq’s opinion, <span><span title="var">α</span></span> <span>+</span> <span><span title="var">β</span></span> is not structurally <i>equal</i> to <span><span title="var">β</span></span> <span>+</span> <span><span title="var">α</span></span>, yet
    we will have to prove they are “equivalent.”
</p>
<h3 id="2">
Introducing <span><span title="var">type_equiv</span></span>
</h3>
<p>
Since <span>=</span> for <span><span title="keyword">Type</span></span> is not suitable for reasoning about algebraic
    datatypes, we introduce our own equivalence relation, denoted <span>==</span>.  We say
    two types <span><span title="var">α</span></span> and <span><span title="var">β</span></span> are equivalent up to an isomorphism (denoted by <span><span title="var">α</span></span> <span>==</span>
    <span><span title="var">β</span></span>) when for any term of type <span><span title="var">α</span></span>, there exists a counter-part term of type
    <span><span title="var">β</span></span> and vice versa. In other words, <span><span title="var">α</span></span> and <span><span title="var">β</span></span> are equivalent if we can
    exhibit two functions <span><span title="var">f</span></span> and <span><span title="var">g</span></span> such that:
</p>
<p><span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
:
</mo>
<mi>
α
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
=
</mo>
<mi>
g
</mi>
<mo stretchy="false">
(
</mo>
<mi>
f
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo stretchy="false">
)
</mo>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\forall (x : α),\ x = g(f(x))
</annotation>
</semantics>
</math>
</span>

</span>


</span></p>
<p><span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
y
</mi>
<mo>
:
</mo>
<mi>
β
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
y
</mi>
<mo>
=
</mo>
<mi>
f
</mi>
<mo stretchy="false">
(
</mo>
<mi>
g
</mi>
<mo stretchy="false">
(
</mo>
<mi>
y
</mi>
<mo stretchy="false">
)
</mo>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\forall (y : β),\ y = f(g(y))
</annotation>
</semantics>
</math>
</span>

</span>


</span></p><p>
In Coq, this translates into the following inductive types.
</p></div>

<div><p>
As mentioned earlier, we prove two types are equivalent by exhibiting
    two functions, and proving these functions satisfy two properties. We
    introduce a
</p><tt>
Ltac
</tt><p>
notation to that end.
</p></div>
<div>

<p><span title="keyword">Tactic Notation</span> "equiv" "with" <span title="var">uconstr</span>(<span title="var">f</span>) "and" <span title="var">uconstr</span>(<span title="var">g</span>)<br>
&nbsp;&nbsp;:= <span title="tactic">apply</span> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#mk_type_equiv"><span title="constructor">mk_type_equiv</span></a> <span title="var">f</span> <span title="var">g</span>).</p></div>
<div><p>
The tactic <span><span title="var">equiv</span></span> <span><span title="keyword">with</span></span> <span><span title="var">f</span></span> <span><span title="var">and</span></span> <span><span title="var">g</span></span> will turn a goal of the form <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span> into
    two subgoals to prove <span><span title="var">f</span></span> and <span><span title="var">g</span></span> form an isomorphism.
</p>
<h3 id="3">
<span><span title="var">type_equiv</span></span> is an Equivalence
</h3>

<p><span><span title="var">type_equiv</span></span> is an equivalence, and we can prove it by demonstrating it is
    (1) reflexive, (2) symmetric, and (3) transitive.
</p>
<p><span><span title="var">type_equiv</span></span> is reflexive.
</p></div>

<div><p>
This proof is straightforward. A type <span><span title="var">α</span></span> is equivalent to itself because:
</p>
<p><span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
:
</mo>
<mi>
α
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
=
</mo>
<mi>
i
</mi>
<mi>
d
</mi>
<mo stretchy="false">
(
</mo>
<mi>
i
</mi>
<mi>
d
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo stretchy="false">
)
</mo>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\forall (x : α),\ x = id(id(x))
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</p></div>
<div>

<p><span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="var">now</span> <span title="var">equiv</span> <span title="keyword">with</span> (@<a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#id"><span title="definition">id</span></a> <span title="var">α</span>) <span title="var">and</span> (@<a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#id"><span title="definition">id</span></a> <span title="var">α</span>).<br>
<span title="keyword">Qed</span>.</p></div>
<p><span><span title="var">type_equiv</span></span> is symmetric.
</p>

<p>
If <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span>, then we know there exists two functions <span><span title="var">f</span></span> and <span><span title="var">g</span></span> which
    satisfy the expected properties. We can “swap” them to prove that <span><span title="var">β</span></span> <span>==</span> <span><span title="var">α</span></span>.
</p>
<div>

<p><span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="tactic">destruct</span> <span title="var">equ</span> <span title="keyword">as</span> [<span title="var">f</span> <span title="var">g</span> <span title="var">equ1</span> <span title="var">equ2</span>].<br>
&nbsp;&nbsp;<span title="var">now</span> <span title="var">equiv</span> <span title="keyword">with</span> <span title="var">g</span> <span title="var">and</span> <span title="var">f</span>.<br>
<span title="keyword">Qed</span>.</p></div>
<p><span><span title="var">type_equiv</span></span> is transitive
</p>

<div><p>
If <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span>, we know there exists two functions <span><span title="var">fα</span></span> and <span><span title="var">gβ</span></span> which satisfy
    the expected properties of <span><span title="var">type_equiv</span></span>. Similarly, because <span><span title="var">β</span></span> <span>==</span> <span><span title="var">γ</span></span>, we
    know there exists two additional functions <span><span title="var">fβ</span></span> and <span><span title="var">gγ</span></span>. We can compose
    these functions together to prove <span><span title="var">α</span></span> <span>==</span> <span><span title="var">γ</span></span>.
</p><p>
As a reminder, composing two functions <span><span title="var">f</span></span> and <span><span title="var">g</span></span> (denoted by <span><span title="var">f</span></span> <span>&gt;&gt;&gt;</span> <span><span title="var">g</span></span>
    thereafter) consists in using the result of <span><span title="var">f</span></span> as the input of <span><span title="var">g</span></span>:
</p></div>
<div>

<p><span title="keyword">Infix</span> <a name="e0ed7cfa6eddbb0bdd997b69ba91f3de"><span title="notation">"</span></a>&gt;&gt;&gt;" := (<span title="keyword">fun</span> <span title="var">f</span> <span title="var">g</span> <span title="var">x</span> =&gt; <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#g"><span title="variable">g</span></a> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#f"><span title="variable">f</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#x"><span title="variable">x</span></a>)) (<span title="tactic">at</span> <span title="keyword">level</span> 70).</p></div>
<p>
Then comes the proof.
</p>
<div>

<p><span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="tactic">destruct</span> <span title="var">equ1</span> <span title="keyword">as</span> [<span title="var">fα</span> <span title="var">gβ</span> <span title="var">equαβ</span> <span title="var">equβα</span>],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">equ2</span> <span title="keyword">as</span> [<span title="var">fβ</span> <span title="var">gγ</span> <span title="var">equβγ</span> <span title="var">equγβ</span>].<br>
&nbsp;&nbsp;<span title="var">equiv</span> <span title="keyword">with</span> (<span title="var">fα</span> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#e0ed7cfa6eddbb0bdd997b69ba91f3de"><span title="notation">&gt;&gt;&gt;</span></a> <span title="var">fβ</span>) <span title="var">and</span> (<span title="var">gγ</span> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#e0ed7cfa6eddbb0bdd997b69ba91f3de"><span title="notation">&gt;&gt;&gt;</span></a> <span title="var">gβ</span>).<br>
&nbsp;&nbsp;+ <span title="tactic">intros</span> <span title="var">x</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="tactic">rewrite</span> &lt;- <span title="var">equβγ</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equαβ</span>.<br>
&nbsp;&nbsp;+ <span title="tactic">intros</span> <span title="var">x</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="tactic">rewrite</span> &lt;- <span title="var">equβα</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equγβ</span>.<br>
<span title="keyword">Qed</span>.</p></div>
<p>
The Coq standard library introduces the <span><span title="var">Equivalence</span></span> type class. We can
    provide an instance of this type class for <span><span title="var">type_equiv</span></span>, using the three
    lemmas we have proven in this section.
</p>

<div>
<h3 id="4">
Examples
</h3>

<h4 id="5">
<span><span title="var">list</span></span>’s Canonical Form
</h4>
<p>
We now come back to our initial example, given in the Introduction of this
    write-up. We can prove our assertion, that is <span><span title="var">list</span></span> <span><span title="var">α</span></span> <span>==</span> <span><span title="var">unit</span></span> <span>+</span> <span><span title="var">α</span></span> <span>*</span> <span><span title="var">list</span></span>
    <span><span title="var">α</span></span>.
</p></div>

<div>
<h4 id="6">
<span><span title="var">list</span></span> is a Morphism
</h4>
<p>
This means that if <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span>, then <span><span title="var">list</span></span> <span><span title="var">α</span></span> <span>==</span> <span><span title="var">list</span></span> <span><span title="var">β</span></span>. We prove this by
    defining an instance of the <span><span title="var">Proper</span></span> type class.
</p></div>

<div><p>
The use of the <span><span title="var">Proper</span></span> type class allows for leveraging hypotheses of the
    form <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span> with the <span><span title="tactic">rewrite</span></span> tactic. I personally consider providing
    instances of <span><span title="var">Proper</span></span> whenever it is possible to be a good practice, and
    would encourage any Coq programmers to do so.
</p>
<h4 id="7">
<span><span title="var">nat</span></span> is a Special-Purpose <span><span title="var">list</span></span>
</h4>
<p>
Did you notice? Now, using <span><span title="var">type_equiv</span></span>, we can prove it!
</p></div>
<div>

<p><span title="keyword">Lemma</span> <a name="nat_and_list"><span title="lemma">nat_and_list</span></a> : <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#nat"><span title="inductive">nat</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#12489c9c79e91749bd1f337dd0c899e9"><span title="notation">==</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#list"><span title="inductive">list</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#unit"><span title="inductive">unit</span></a>.</p><p>


<span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="var">equiv</span> <span title="keyword">with</span> (<span title="keyword">fix</span> <span title="var">to_list</span> <span title="var">n</span> :=<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="keyword">match</span> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#n"><span title="variable">n</span></a> <span title="keyword">with</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#S"><span title="constructor">S</span></a> <span title="var">m</span> =&gt; <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#tt"><span title="constructor">tt</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#cbcf67aac0c2a85b8d93d37de9969adf"><span title="notation">::</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#to_list"><span title="variable">to_list</span></a> <span title="var">m</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <span title="var">_</span> =&gt; <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Lists.List.html#ae9a5e1034e143b218b09d8e454472bd"><span title="notation">[]</span></a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="keyword">end</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">and</span> (<span title="keyword">fix</span> <span title="var">of_list</span> <span title="var">l</span> :=<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="keyword">match</span> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#l"><span title="variable">l</span></a> <span title="keyword">with</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <span title="var">_</span> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#cbcf67aac0c2a85b8d93d37de9969adf"><span title="notation">::</span></a> <span title="var">rst</span> =&gt; <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#S"><span title="constructor">S</span></a> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#of_list"><span title="variable">of_list</span></a> <span title="var">rst</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <span title="var">_</span> =&gt; 0<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="keyword">end</span>).<br>
&nbsp;&nbsp;+ <span title="tactic">induction</span> <span title="var">x</span>; <span title="tactic">auto</span>.<br>
&nbsp;&nbsp;+ <span title="tactic">induction</span> <span title="var">y</span>; <span title="tactic">auto</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="tactic">rewrite</span> &lt;- <span title="var">IHy</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">now</span> <span title="tactic">destruct</span> <span title="var">a</span>.<br>
<span title="keyword">Qed</span>.</p></div>
<div>
<h4 id="8">
Non-empty Lists
</h4>
<p>
We can introduce a variant of <span><span title="var">list</span></span> which contains at least one element by
    modifying the <span><span title="var">nil</span></span> constructor so that it takes one argument instead of
    none.
</p></div>

<p>
We can demonstrate the relation between <span><span title="var">list</span></span> and <span><span title="var">non_empty_list</span></span>, which
    reveals an alternative implementation of <span><span title="var">non_empty_list</span></span>. More precisely,
    we can prove that <span><span title="keyword">forall</span></span> <span>(<span title="var">α</span></span> <span>:</span> <span><span title="keyword">Type</span>),</span> <span><span title="var">non_empty_list</span></span> <span><span title="var">α</span></span> <span>==</span> <span><span title="var">α</span></span> <span>*</span> <span><span title="var">list</span></span> <span><span title="var">α</span></span>.  It
    is a bit more cumbersome, but not that much. We first define the conversion
    functions, then prove they satisfy the properties expected by
    <span><span title="var">type_equiv</span></span>.
</p>

<div>
<h2 id="9">
The <span><span title="var">sum</span></span> Operator
</h2>

<h3 id="10">
<span><span title="var">sum</span></span> is a Morphism
</h3>
<p>
This means that if <span><span title="var">α</span></span> <span>==</span> <span><span title="var">α'</span></span> and <span><span title="var">β</span></span> <span>==</span> <span><span title="var">β'</span></span>, then <span><span title="var">α</span></span> <span>+</span> <span><span title="var">β</span></span> <span>==</span> <span><span title="var">α'</span></span> <span>+</span> <span><span title="var">β'</span></span>. To
    prove this, we compose together the functions whose existence is implied by
    <span><span title="var">α</span></span> <span>==</span> <span><span title="var">α'</span></span> and <span><span title="var">β</span></span> <span>==</span> <span><span title="var">β'</span></span>. To that end, we introduce the auxiliary function
    <span><span title="var">lr_map</span></span>.
</p></div>

<p>
Then, we prove <span><span title="var">sum</span></span> is a morphism by defining a <span><span title="var">Proper</span></span> instance.
</p>
<div>

<p><span title="keyword">Instance</span> <a name="sum_Proper"><span title="instance">sum_Proper</span></a><br>
&nbsp;&nbsp;: <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Classes.Morphisms.html#Proper"><span title="class">Proper</span></a> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#type_equiv"><span title="inductive">type_equiv</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Classes.Morphisms.html#8dc5652698a6e16f72dd37bd17d3b973"><span title="notation">==&gt;</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#type_equiv"><span title="inductive">type_equiv</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Classes.Morphisms.html#8dc5652698a6e16f72dd37bd17d3b973"><span title="notation">==&gt;</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#type_equiv"><span title="inductive">type_equiv</span></a>) <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#sum"><span title="inductive">sum</span></a>.</p><p>


<span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="var">add_morphism_tactic</span>.<br>
&nbsp;&nbsp;<span title="tactic">intros</span> <span title="var">α</span> <span title="var">α'</span> [<span title="var">fα</span> <span title="var">gα'</span> <span title="var">equαα'</span> <span title="var">equα'α</span>]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">β</span> <span title="var">β'</span> [<span title="var">fβ</span> <span title="var">gβ'</span> <span title="var">equββ'</span> <span title="var">equβ'β</span>].<br>
&nbsp;&nbsp;<span title="var">equiv</span> <span title="keyword">with</span> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#lr_map_sum"><span title="definition">lr_map_sum</span></a> <span title="var">fα</span> <span title="var">fβ</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">and</span> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#lr_map_sum"><span title="definition">lr_map_sum</span></a> <span title="var">gα'</span> <span title="var">gβ'</span>).<br>
&nbsp;&nbsp;+ <span title="tactic">intros</span> [<span title="var">x</span>|<span title="var">y</span>]; <span title="var">cbn</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;++ <span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equαα'</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;++ <span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equββ'</span>.<br>
&nbsp;&nbsp;+ <span title="tactic">intros</span> [<span title="var">x</span>|<span title="var">y</span>]; <span title="var">cbn</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;++ <span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equα'α</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;++ <span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equβ'β</span>.<br>
<span title="keyword">Qed</span>.</p></div>


<div>
<h3 id="12">
<span><span title="var">sum</span></span> is Associative
</h3>
<p>
The associativity of <span><span title="var">sum</span></span> is straightforward to prove, and should not pose
    a particular challenge to perspective readers; if we assume that this
    article is well-written, that is!
</p></div>

<div>
<h3 id="13">
<span><span title="var">sum</span></span> has a Neutral Element
</h3>
<p>
We need to find a type <span><span title="var">e</span></span> such that <span><span title="var">α</span></span> <span>+</span> <span><span title="var">e</span></span> <span>==</span> <span><span title="var">α</span></span> for any type <span><span title="var">α</span></span>
    (similarly to <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi>
x
</mi>
<mtext>
&nbsp;
</mtext>
<mo>
+
</mo>
<mtext>
&nbsp;
</mtext>
<mn>
0
</mn>
<mtext>
&nbsp;
</mtext>
<mo>
=
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x~+~0~=~x
</annotation>
</semantics>
</math>
</span>

</span>


</span>
 for any natural
    number <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics>
</math>
</span>

</span>


</span>
 that is).
</p><p>
Any empty type (that is, a type with no term such as <span><span title="var">False</span></span>) can act as the
    …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html">https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html</a></em></p>]]>
            </description>
            <link>https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812854</guid>
            <pubDate>Sun, 12 Jul 2020 17:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wt – C++ Web Toolkit]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 81 (<a href="https://news.ycombinator.com/item?id=23812791">thread link</a>) | @gtirloni
<br/>
July 12, 2020 | https://www.webtoolkit.eu/wt | <a href="https://web.archive.org/web/*/https://www.webtoolkit.eu/wt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="osdufu1">
    <section>
      
      
      <div>
        <div>
          <div>
            <div>
              <div>
                
                <p data-wow-delay="0.3s">
                  
    
      Wt is a web GUI library in modern C++.
    
    
    Quickly develop highly interactive web UIs with widgets,
    without having to write a single line of JavaScript.
    Wt handles all request handling and page rendering
    for you, so you can focus on functionality.
  
                </p>
                
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </section>
    <section>
      <div>
        
        <div>
          <p>
    You don't want to focus on details like request handling or page rendering.
    You want your application to continue to work
    even when JavaScript is unavailable.
    You just want to write your web application in C++ without sacrificing interactivity.
    Wt allows you to focus on functionality and create highly interactive, secure, and future proof applications
    quickly.
  </p>
        </div>
        <div>
	  
    <div data-wow-delay="0.3s">
      <div>
        <p><img alt="Save Time" src="https://www.webtoolkit.eu/images/icon-development@2x.png" width="121px"></p><h3>Save Time</h3>
         <p>
    Wt handles all the nitty-gritty of requests and responses and
    client-side JavaScript, and allows you to focus on functionality
    in pure C++.
  </p>
       </div>
    </div>
  
	  
    <div data-wow-delay="0.1s">
      <div>
        <p><img alt="Built to Maintain" src="https://www.webtoolkit.eu/images/icon-products@2x.png" width="98px"></p><h3>Built to Maintain</h3>
         <p>
    Wt's widget abstraction represents HTML elements as C++ objects, allowing
    them to be easily composable and extendable.
  </p>
       </div>
    </div>
  
	  
    <div data-wow-delay="0.1s">
      <div>
        <p><img alt="Future Proof" src="https://www.webtoolkit.eu/images/icon-support@2x.png" width="86px"></p><h3>Future Proof</h3>
         <p>
    Stay up to date with the latest web technologies without changing your code, thanks to Wt's stable API.
    <!--    Wt uses Ajax and WebSockets when available and can fall back on plain HTML automatically, without
    the need for specific code.-->
  </p>
       </div>
    </div>
  
	  
    <div data-wow-delay="0.25s">
      <div>
        <p><img alt="Secure" src="https://www.webtoolkit.eu/images/icon-smartphone@2x.png" width="52px"></p><h3>Secure</h3>
         <p>
    Wt is designed to be resilient against the most common types of exploits:
    SQL injection,  XSS and CSRF vulnerabilities.
  </p>
       </div>
    </div>
  
        </div>
      </div>
    </section>
    
    <section>
      <div>
        <div>
          <p>
            <h3>
 	      
    Contact us for more information
    <br>
    or a personalised quotation
  
            </h3>
          </p>
          
        </div>
      </div>
    </section>
  
    
    <section>
      <div>
        
        <div>
          <p>
    
    Wt has a lot to offer. It includes the essential basic widgets and building blocks to
    build web applications, but also offers built-in security, PDF rendering, a 2D and 3D painting system, 
    an object-relational mapping library, a charting library, and an authentication framework.
  
    <a href="https://www.webtoolkit.eu/wt/features?wtd=UM2u7UkmUwe9EWlU">You can see the full list of features here</a>, but here's a short overview:
  </p>
        </div>
      </div>
      <div>
        <div>
	  
    
  
	  
    <div>
      <div>
        <hr>
          <p><img src="https://www.webtoolkit.eu/images/icon-purple-desktop@2x.png" width="66px">
          </p>
          <h4>Server side, client optimized</h4>
          <p>Wt employs a signal-slot system. Instead of worrying about the sending of Ajax requests and serving of pages, you can simply connect the click of a button to a callback function on the server.
    
      <a href="https://www.webtoolkit.eu/widgets/forms#form-simple">Take a look at this example in the widget gallery.</a>
    
    
    Wt will use whatever technology available for communication: Ajax or WebSockets, but will fall back on full HTML
    page loads when JavaScript is unavailable. This makes Wt applications accessible to any browser or web crawler.
  </p>
      </div>
    </div>
  
	  
    <div>
      <div>
        <hr>
          <p><img src="https://www.webtoolkit.eu/images/icon-purple-laptop@2x.png" width="75px">
          </p>
          <h4>Built-in security</h4>
          <p>
    Wt automatically protects against misuse by only allowing visible and enabled widgets to be interacted with.
    This also helps to avoid CSRF attacks, which are doubly avoided because Wt does not store session information in cookies.
    By using the widget abstraction, Wt discourages the inserting of raw HTML into a web page, preventing XSS attacks.
    
      Wt::Dbo prevents SQL injection by encouraging the use of prepared statements when accessing the database.
    
    Wt also includes an authentication and registration system with support for OAuth
    providers like Google, Facebook, and OpenID Connect.
  </p>
      </div>
    </div>
  
        </div>
        <div>
	  
    
  
	  
    <div>
      <div>
        <hr>
          <p><img src="https://www.webtoolkit.eu/images/icon-purple-servers@2x.png" width="67px">
          </p>
          <h4>2D and 3D painting system</h4>
          <p>
    Use a single 2D drawing API with many backends (PNG, JPEG, SVG, HTML canvas, VML, and PDF) so you only need to write
    your drawing code once to support any web browser and save to many formats. Write server-side (OpenGL) and
    client-side (WebGL) 3D graphics with a uniform API. Wt's 2D and 3D charting libraries were built on top of this
    graphics API.
    
      <a href="https://www.webtoolkit.eu/widgets/graphics-charts">Check out the examples in the widget gallery.</a>
    
    
  </p>
      </div>
    </div>
  
	  
    
  
        </div>
      </div>
      
    </section>
    <section>
      <div>
        
        <div id="osdufm4"><div id="osdufm3">
    <h4><a id="osdufm2" href="https://www.webtoolkit.eu/wt/news/2020/04/20/wt_3_6_1___4_3_1?wtd=UM2u7UkmUwe9EWlU"><span id="osdufm1">Wt 3.6.1 &amp; 4.3.1</span></a></h4>
    
    
    <div>
      <p>Wt 4.3.0 was released almost a month ago, so itâ€™s about time for a patch release. Wt 4.3.1 (and Wt 3.6.1) is a tiny patch release, with the most notable fix being an issue in the destructor of WWebWidget when user-defined ids were used. There will be no JWt 4.3.1 since nothing has changed to JWt.</p>
<p>Read the release notes for more information.</p>
<p>Here are the links:</p>



    </div>
    
  </div></div>
      </div>
    </section>
    <section>
      
    </section>
    
  </div></div>]]>
            </description>
            <link>https://www.webtoolkit.eu/wt</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812791</guid>
            <pubDate>Sun, 12 Jul 2020 17:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Soul of a New Debugger]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812677">thread link</a>) | @nbaksalyar
<br/>
July 12, 2020 | https://nbaksalyar.github.io/2020/07/12/soul-of-a-new-debugger.html | <a href="https://web.archive.org/web/*/https://nbaksalyar.github.io/2020/07/12/soul-of-a-new-debugger.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			

<time datetime="2020-07-12 00:00:00 +0000">12 Jul 2020</time>

<p><em>This blog post is a follow-up to <a href="https://nbaksalyar.github.io/2020/05/19/rust-debug.html">A Future for Rust Debugging</a></em></p>

<p>Why developers are reluctant to use interactive debuggers and prefer <code>print</code>s instead?</p>

<p>This is a question that has been perplexing me, and while it’s not possible to have a definite answer, we can make some educated guesses.
<code>print</code>s are simple and very effective: you don’t have to painstakingly step through your code to understand what’s happening
and you don’t need any external tools – everything is already there, you just need to add a few statements and run your program again.</p>

<p>Here’s the trick, though: if you code in a language like Python, JavaScript or Ruby, all you need to do to run your program is to execute it.
But there is a bit more friction with compiled native languages like C++ or Rust: every recompilation step costs time, and with larger
code bases with many dependencies it can quickly become non-negligible. It’s even more complicated if you want to debug a problem that occurs on a remote machine (e.g., a production server) or on an embedded platform, since you will need to redeploy the newly compiled binary every time you want to run a new debug experiment.</p>

<p>Interactive debuggers solve these problems: you can take an existing program that was compiled in the debug mode and probe it to your liking,
setting up conditional breakpoints, looking up current values of variables, and doing a lot of other useful things. However, in my view, the widely-used interactive debuggers have a set of problems of their own:</p>

<ul>
  <li>
    <p>A lot of them were designed in a different era. At that time, we didn’t have always-on Internet connections, high-resolution multi-colour displays, and devices with many gigabytes of memory. While the fundamental principles remain the same, the modern needs have changed and so do modern means.</p>
  </li>
  <li>
    <p>Many existing debuggers are general-purpose. While there is some support for scripting and language-specific extensions, it’s harder to use them for specific domains and it’s harder to integrate them with your dev environment. In practical terms, this means you have to use <em>other</em> tools in addition to debuggers to observe the behaviour of your software, and oftentimes it’s just easier &amp; faster to move along with <code>print</code>s instead of trying to find a suitable tool.</p>
  </li>
</ul>

<p>I also see more general problems with regards to debuggers. They are perceived mostly as a tool to help you find and fix bugs in your code, but not as much as a tool of discovery and exploration. It’s been 8 years since Bret Victor published his “<a href="http://worrydream.com/#!/LearnableProgramming">Learnable Programming</a>”, and these ideas are as relevant today as ever. Debuggers should strive to be a good learning tool too.</p>

<p>Lastly, interactive debuggers rely on underlying principles that are quite similar to profilers, dynamic tracers like <a href="https://en.wikipedia.org/wiki/DTrace">DTrace</a> and <a href="https://en.wikipedia.org/wiki/eBPF">eBPF</a>, memory leak detectors, and other developer tools. Ideas and code can – and should – be shared across this ecosystem, but it seems like whilst one type of tools gets a lot of attention, the others may still lack support for important features.</p>

<p>So what can we do to try solving these problems?</p>

<h2 id="elements-of-a-modern-debugger">Elements of a modern debugger</h2>

<p>In my <a href="https://nbaksalyar.github.io/2020/05/19/rust-debug.html">previous article</a>, I argued for a case of extending the existing debuggers to provide better support for Rust. However, after some more research and thinking, I feel that we should consider the idea of creating a new debugger framework from scratch, taking inspiration from other great projects. Not-invented-here syndrome aside, I think there are some valid reasons for going in this direction.</p>

<p>Modern languages like Rust have lots of new important features that weren’t available in languages that the classic debuggers were written in. Things like fearless concurrency, first-class modules &amp; packages, async I/O and zero-cost abstractions can affect the design of a new debugger in a significant way. With the Rust’s package manager, <a href="https://doc.rust-lang.org/cargo/">Cargo</a>, extensibility becomes even more relevant and viable. We’ve already seen what modular debuggers are capable of – for example, the Illumos Modular Debugger, <a href="https://illumos.org/books/mdb/preface.html">mdb</a>, allows to debug both native and JavaScript code in Node.js with an <a href="https://github.com/joyent/mdb_v8">mdb_v8</a> extension, and the architecture of the debugger itself allows to extend it further using a simple, modular interface. With language features like traits, it can become even easier to create your own domain-specific debuggers using a new framework.</p>

<p>Another project to take inspiration from is <a href="https://github.com/go-delve/delve">Delve</a>, a Go debugger. It’s built with modern tools and has several features important for Go developers, but I want to highlight the <a href="https://github.com/go-delve/delve/tree/master/Documentation/api/json-rpc">JSON-RPC API</a> it provides. This API addresses the important problem of integration with the development environment, and by using <a href="https://microsoft.github.io/debug-adapter-protocol/">a well-defined protocol</a> we can create an ecosystem for debuggers that’s similar to the one that’s flourished around the <a href="https://microsoft.github.io/language-server-protocol/">language server protocol</a>. With an HTTP-based API, we can build custom debugger front-ends using HTML and WebAssembly and run them in web browsers. With the rich front-end tools &amp; frameworks, it opens up lots of interesting options for data representation and visualisation. Integration doesn’t have to be one-sided, too: language servers can be reused for debugging purposes, and integrating a Rust-specific debugger with the Rust compiler would allow us to utilise the full power of the existing language syntax parser and other compiler components.</p>

<h2 id="whats-next">What’s next?</h2>

<p>Overall, I believe this is a project worth building. While we’re seeing a lot of innovation in compilers and language design, debuggers are somewhat neglected, even though debugging is no less important; as Kernighan’s law postulates, it’s twice as hard as writing the code in the first place.</p>

<p>Creating a new debugger is an insurmountable task and a very long journey. But it can have a modest start: if we cover only a few popular operating systems and a few simple cases first, we can quickly achieve small wins that can save us a lot of time and frustration.</p>

<p>This post outlines the initial project plan for <strong><a href="https://github.com/headcrab-rs/headcrab">Headcrab</a></strong>, a Rust debugger library. I will be publishing more code and documentation in the coming weeks. If you are interested in updates, please <a href="https://twitter.com/nbaksalyar">follow me on Twitter</a>. Progress updates will be also published on this blog.</p>

<ul>
  <li>You can find a more detailed roadmap in the <a href="https://github.com/headcrab-rs/headcrab/blob/master/README.md">project repository</a>.</li>
</ul>

<h2 id="resources-and-further-reading">Resources and further reading</h2>

<ul>
  <li><a href="https://rustc-dev-guide.rust-lang.org/debugging-support-in-rustc.html">Debugging support in the Rust compiler</a></li>
  <li><a href="https://illumos.org/books/mdb/preface.html">mdb, Illumos Debugger</a></li>
  <li>Rosenberg, J.B. (1996). <em>How debuggers work : Algorithms, data structures, and architecture</em>. ISBN 0471149667.</li>
  <li>Uresh Vahalia (1996). <em>UNIX internals : the new frontiers</em>. ISBN 9780131019089.</li>
</ul>



		</article></div>]]>
            </description>
            <link>https://nbaksalyar.github.io/2020/07/12/soul-of-a-new-debugger.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812677</guid>
            <pubDate>Sun, 12 Jul 2020 16:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of calculus and analysis in 200 symbols]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812448">thread link</a>) | @R3G1R
<br/>
July 12, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><p><span>I</span>n mathematics, <strong>calculus</strong> formalizes the study of continuous change, while <strong>analysis</strong> provides it with a rigorous foundation in <a href="https://mathvault.ca/hub/higher-math/math-symbols/logic-symbols/" target="_blank" aria-label="logic (opens in a new tab)" rel="noreferrer noopener">logic</a>. The following list documents some of the most notable symbols and notations in calculus and analysis, along with each symbol’s usage and meaning.</p><p>For readability purpose, these symbols are categorized by <strong>topic</strong> and <strong>function</strong> into tables. Other comprehensive lists of <a href="https://mathvault.ca/hub/higher-math/math-symbols/" target="_blank" aria-label="math symbols (opens in a new tab)" rel="noreferrer noopener">math symbols</a> — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p> </div></div></div></div><h2><span id="Constants_and_Variables"></span>Constants and Variables<span></span></h2><p>In calculus and analysis, constants and variables are often reserved for <strong>key mathematical numbers</strong> and <strong>arbitrarily small quantities</strong>. The following table documents some of the most notable symbols in these categories — along with each symbol’s example and meaning.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$e$</td><td><strong><a aria-label="Euler's number (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/E_(mathematical_constant)" target="_blank">Euler’s number e</a></strong></td><td>$\displaystyle e = \frac{1}{0!} + \frac{1}{1!} + \cdots$</td></tr><tr><td>$\pi$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Pi (opens in a new tab)" rel="noreferrer noopener">Pi</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Pi" target="_blank" aria-label="Archimedes' constant (opens in a new tab)" rel="noreferrer noopener">Archimedes’ constant</a></strong></td><td>$\dfrac{\pi^2}{6} = \dfrac{1}{1^2} + \dfrac{1}{2^2} +$<br>$\dfrac{1}{3^2} + \dfrac{1}{4^2} + \cdots$</td></tr><tr><td>$i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank" aria-label="Imaginary unit (opens in a new tab)" rel="noreferrer noopener">Imaginary unit</a></strong></td><td>$e^{\pi i} = \cos \pi + i \sin \pi$</td></tr><tr><td>$\gamma$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Gamma (opens in a new tab)" rel="noreferrer noopener">Gamma</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Euler%E2%80%93Mascheroni_constant" target="_blank" aria-label="Euler–Mascheroni constant (opens in a new tab)" rel="noreferrer noopener">Euler–Mascheroni constant</a></strong></td><td>$\displaystyle \left( \sum_{k=1}^{n} \dfrac{1}{k}-\ln n \right) \to$<br>$\gamma \approx 0.577$</td></tr><tr><td>$\Omega$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Capital omega (opens in a new tab)" rel="noreferrer noopener">Capital omega</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Omega_constant" target="_blank" aria-label="Omega constant (opens in a new tab)" rel="noreferrer noopener">Omega constant</a></strong></td><td>$\Omega e^{\Omega} = 1$</td></tr><tr><td>$m$</td><td>Variable for <strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Slope" target="_blank">slope</a></strong></td><td>$m = \dfrac{y_2-y_1}{x_2-x_1}$</td></tr><tr><td>$h$, $\Delta x$, $\delta x$</td><td><strong><a aria-label="Limiting variables (opens in a new tab)" href="https://en.wikipedia.org/wiki/List_of_limits#Limits_involving_derivatives_or_infinitesimal_changes" target="_blank" rel="noreferrer noopener">Limiting variables</a></strong> for <a href="https://en.wikipedia.org/wiki/Difference_quotient" target="_blank" aria-label="difference quotient (opens in a new tab)" rel="noreferrer noopener">difference quotient</a></td><td>$\displaystyle \lim_{h \to 0} \dfrac{f(x+h)-f(x)}{h}$</td></tr><tr><td>$L$</td><td>Variable for <strong><a aria-label="limiting value (opens in a new tab)" href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" rel="noreferrer noopener">limit</a></strong></td><td>If $f(x) \to L$, then $f(x)^2 \to L^2$.</td></tr><tr><td>$\varepsilon$ (<a aria-label="Epsilon (opens in a new tab)" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" rel="noreferrer noopener">Epsilon</a>),<br>$\delta$ (<a aria-label="Delta (opens in a new tab)" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" rel="noreferrer noopener">Delta</a>)</td><td>Variables for <strong><a href="https://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit" target="_blank" aria-label="arbitrarily small quantities (opens in a new tab)" rel="noreferrer noopener">arbitrarily small quantities</a></strong></td><td>$\forall \varepsilon \, \exists \delta \, \big( 0&lt;|x-x_0|&lt;\delta$ $\implies |f(x)-L|&lt; \varepsilon \big) $</td></tr><tr><td>$a, b$</td><td>Variables for <strong>endpoints</strong> in <a aria-label=" (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Intervals" target="_blank">intervals</a> and <a href="#Univariate_Integralrelated_Symbols" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">definite integrals</a></td><td>$\displaystyle \int_a^b 2x \, \mathrm{d}x= b^2-a^2$</td></tr><tr><td>$C$</td><td><strong><a href="https://en.wikipedia.org/wiki/Constant_of_integration" target="_blank" aria-label="Constant of integration (opens in a new tab)" rel="noreferrer noopener">Constant of integration</a></strong></td><td>$\displaystyle \int \dfrac{1}{x} \, \mathrm{d} x = \ln |x| + C$</td></tr></tbody></table></figure><h2><span id="Sequence,_Series_and_Limit"></span>Sequence, Series and Limit<span></span></h2><p>The concepts of <strong><a href="https://en.wikipedia.org/wiki/Sequence" target="_blank" rel="noopener noreferrer">sequence</a></strong>, <strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" rel="noopener noreferrer">series</a></strong> and <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" rel="noopener noreferrer">limit</a></strong> form the foundation of calculus (and by extension real and complex analysis). The following table features some of the most common symbols related to these topics — along with each symbol’s usage and meaning.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$+\infty$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infinity#Real_analysis" target="_blank" aria-label="Positive infinity (opens in a new tab)" rel="noreferrer noopener">Positive infinity</a></strong></td><td>$\dfrac{1}{1} + \dfrac{1}{2} + \cdots = \infty$</td></tr><tr><td>$-\infty$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infinity#Real_analysis" target="_blank" aria-label="Negative infinity (opens in a new tab)" rel="noreferrer noopener">Negative infinity</a></strong></td><td>As $x \to -\infty$, $e^x \to 0$.</td></tr><tr><td>$(a_n), (b_n), (c_n)$</td><td><strong><a aria-label="Sequence (opens in a new tab)" href="https://en.wikipedia.org/wiki/Sequence" target="_blank" rel="noreferrer noopener">Sequences</a></strong></td><td>$\displaystyle (a_n)_{n=0}^\infty =$<br>$(a_0, a_1, a_2, \ldots)$</td></tr><tr><td>$\displaystyle \sum_{n = i}^k a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" aria-label="Series (opens in a new tab)" rel="noreferrer noopener">Series</a></strong></td><td>$\displaystyle \sum_{n=1}^k b_n = \\ b_1 + \cdots + b_k$</td></tr><tr><td>$\| \mathrm{x}-\mathrm{y}\|$</td><td><strong><a href="https://en.wikipedia.org/wiki/Euclidean_distance" target="_blank" aria-label="Euclidean distance (opens in a new tab)" rel="noreferrer noopener">Euclidean distance</a></strong> between points $\mathrm{x}$ and $\mathrm{y}$</td><td>$\| \mathrm{x}-\mathrm{x}_0 \| &lt; 1 \implies$<br>$| f(\mathrm{x})-f(\mathrm{x}_0) | &lt; 2 $</td></tr><tr><td>$d(x, y)$</td><td><strong><a aria-label="Metric (opens in a new tab)" href="https://en.wikipedia.org/wiki/Metric_(mathematics)" target="_blank" rel="noreferrer noopener">Distance function</a></strong></td><td>$d(x, y) = |x-y|$</td></tr><tr><td>$\displaystyle \lim_{n \to \infty} a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Limit_of_a_sequence" target="_blank" aria-label="Limit of sequence (opens in a new tab)" rel="noreferrer noopener">Limit of sequence</a></strong></td><td>$\displaystyle \lim_{n \to \infty} \left(1+\dfrac{1}{n}\right)^n = e$</td></tr><tr><td>$\displaystyle \lim_{k \to \infty} \sum_{n=i}^k a_n, \sum_{n=i}^{\infty} a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" aria-label="Limit of series (opens in a new tab)" rel="noreferrer noopener">Limit of series</a></strong></td><td>$\displaystyle \sum_{n=0}^{\infty} \dfrac{1}{2^n} = 2$</td></tr><tr><td>$\mathrm{x} \to a$</td><td>Variable $\mathrm{x}$ <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" aria-label="tends to (opens in a new tab)" rel="noreferrer noopener">tends to</a></strong> $a$</td><td>$\lim (a_n) = 1/4$ as $n \to \infty$.</td></tr><tr><td>$f(x) \to L$</td><td>Function $f(x)$ <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" aria-label="tends to (opens in a new tab)" rel="noreferrer noopener">tends to</a></strong> limit $L$</td><td>Since $g(x)$ is continuous at $c$, $g(x) \to g(c)$ as $x \to c$.</td></tr><tr><td>$\displaystyle \lim_{x \to a} f(x)$</td><td><strong><a aria-label="Limit of function (opens in a new tab)" href="https://en.wikipedia.org/wiki/Limit_of_a_function" target="_blank" rel="noreferrer noopener">Limit of function</a></strong> $f(x)$ as $x$ tends to $a$</td><td>$\displaystyle \lim_{x \to 0} \dfrac{\sin x}{x} = 1$</td></tr><tr><td>$\displaystyle \lim_{x \to a^+} f(x)$, $\displaystyle \lim_{x \, \downarrow \, a} f(x)$</td><td><strong><a href="https://en.wikipedia.org/wiki/One-sided_limit" target="_blank" aria-label="Right-sided limit (opens in a new tab)" rel="noreferrer noopener">Right-sided limit</a></strong><br>(Limit of $f(x)$ as $x$ tends to $a$ from the right)</td><td>$\displaystyle \lim_{x \to 3^+} \dfrac{1}{x-3} = +\infty$</td></tr><tr><td>$\displaystyle \lim_{x \to a^-} f(x)$, $\displaystyle \lim_{x \, \uparrow \, a} f(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/One-sided_limit" target="_blank">Left-sided limit</a></strong><br>(Limit of $f(x)$ as $x$ tends to $a$ from the left)</td><td>$\displaystyle \lim_{x \to 0^-} \sqrt{-x} = 0$</td></tr><tr><td>$\min (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Maxima_and_minima#In_relation_to_sets" target="_blank" aria-label="Minimum (opens in a new tab)" rel="noreferrer noopener">Minimum</a></strong> of set $A$</td><td>$\min (a_n) + \min (b_n) \le$ $\min (a_n + b_n)$</td></tr><tr><td>$\max (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Maxima_and_minima#In_relation_to_sets" target="_blank" aria-label="Maximum (opens in a new tab)" rel="noreferrer noopener">Maximum</a></strong> of set $A$</td><td>If $f$ is continuous on $[a, b]$, then $\max (f(x))$ exists on that interval.</td></tr><tr><td>$\inf (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infimum_and_supremum" target="_blank" aria-label="Greatest lower bound (opens in a new tab)" rel="noreferrer noopener">Greatest lower bound</a></strong> of set $A$</td><td>$\inf\left(\left\{\dfrac{1}{n} \, \middle| \, n \in \mathbb{N} \right\}\right)$<br>$= 0$</td></tr><tr><td>$\sup (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infimum_and_supremum" target="_blank" aria-label="Least upper bound (opens in a new tab)" rel="noreferrer noopener">Least upper bound</a></strong> of set $A$</td><td>$\sup \left(\left\{x \in \mathbb{Q} \, \middle| \, x^2 &lt; 2 \right\}\right)$ $= \sqrt{2}$</td></tr><tr><td>$\liminf a_n$</td><td><strong><a aria-label="Limit infimum (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Limit_superior_and_limit_inferior" target="_blank">Limit inferior</a></strong> of sequence $a_n$</td><td>$\displaystyle \liminf_{n \to \infty} \dfrac{2}{n+1} =$<br>$\displaystyle \lim_{n \to \infty} 0$</td></tr><tr><td>$\limsup a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Limit_superior_and_limit_inferior" target="_blank" aria-label="Limit superior (opens in a new tab)" rel="noreferrer noopener">Limit superior</a></strong> of sequence $a_n$</td><td>$\displaystyle \limsup_{n \to \infty} b_n =$<br>$\displaystyle \lim_{n \to \infty} \left( \sup_{m \ge n} b_m \right)$</td></tr></tbody></table></figure><h2><span id="Derivative_and_Integral"></span>Derivative and Integral<span></span></h2><p>The field of calculus (e.g., multivariate/vector calculus, differential equations) is often said to revolve around two opposing but complementary concepts: <strong>derivative</strong> and <strong>integral</strong>. The following tables document the most notable symbols related to these — along with each symbol’s usage and meaning.</p><p>(For a review on function and related operators, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Functionrelated_Symbols" target="_blank" rel="noopener noreferrer"><strong>function-related operators</strong></a>.)</p><h3>Univariate Derivative-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f^{\prime}(\mathrm{x}), f^{\prime \prime}(\mathrm{x}), f^{(n)}(\mathrm{x})$</td><td>First, second and $n$th <strong><a aria-label="derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Lagrange's_notation" target="_blank">derivative</a></strong> of $f$ at $\mathrm{x}$<br>(Lagrange’s notation)</td><td>$f'(c) =$<br>$\displaystyle \lim_{h \to 0} \dfrac{f(c + h)-f(c)}{h}$</td></tr><tr><td>$\dfrac{d}{d\mathrm{x}} f, \dfrac{df}{d\mathrm{x}}$</td><td><strong><a aria-label="Derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Leibniz's_notation" target="_blank">Derivative</a></strong> of function $f$ in terms of $\mathrm{x}$<br>(Leibniz’s notation)</td><td>$\dfrac{d}{dx} f = f'(x)$</td></tr><tr><td>$\dfrac{d^n}{d\mathrm{x}^n} f, \dfrac{d^n f}{d\mathrm{x}^n}$</td><td><strong><a aria-label="Nth derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Leibniz's_notation" target="_blank">Nth derivative</a></strong> of function $f$ in terms of $\mathrm{x}$<br>(Leibniz’s notation)</td><td>$\dfrac{d^2 f}{dx^2} = \dfrac{d}{dx}\left(\dfrac{df}{dx}\right)$</td></tr><tr><td>$\dot{y}$, $\ddot{y}$, $\overset{n}{\dot{y}}$</td><td>First, second and $n$th <strong><a aria-label="derivative (opens in a new tab)" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Newton's_notation" target="_blank" rel="noreferrer noopener">derivative</a></strong> of $y$ in terms of time variable $t$<br>(Newton’s notation)</td><td>$\ddot{y}= \dfrac{d^2 y}{dt^2}$</td></tr><tr><td>$D(f), D^2(f), D^{n}(f)$</td><td>First, second and $n$th <strong><a href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Euler's_notation" target="_blank" aria-label="derivative (opens in a new tab)" rel="noreferrer noopener">derivative</a></strong> of $f$<br>(Euler’s notation)</td><td>$D^2(f) = D(D(f))$</td></tr><tr><td>$\Delta \mathrm{x}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Delta_(letter)#Upper_case" target="_blank" aria-label="Increment (opens in a new tab)" rel="noreferrer noopener">Increment</a></strong> in variable $\mathrm{x}$</td><td>$\Delta y \approx f'(x) \Delta x$</td></tr><tr><td>$d \mathrm{x}$</td><td><strong><a aria-label="Differential (opens in a new tab)" href="https://en.wikipedia.org/wiki/Differential_(infinitesimal)" target="_blank" rel="noreferrer noopener">Differential</a> </strong>of variable $\mathrm{x}$</td><td>$dy = \dfrac{dy}{dx}\, dx$</td></tr></tbody></table></figure><h3>Multivariate Derivative-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f_\mathbf{x}$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank">Partial derivative</a></strong> of $f$ in terms of $\mathbf{x}$<br>(Lagrange’s notation)</td><td>$\displaystyle f_x (a, b) = \lim_{h \to 0}$<br>$\frac{f(a+h, \, b) \, – \, f(a,\, b)}{h}$</td></tr><tr><td>$\dfrac{\partial}{\partial \mathrm{x}} f, \dfrac{\partial f}{\partial \mathrm{x}}$</td><td><strong><a aria-label="Partial derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank">Partial derivative</a></strong> of $f$ in terms of $\mathrm{x}$<br>(Leibniz’s style)</td><td>If $f$ has continuous second partial derivatives, then $\dfrac{\partial}{\partial y}\dfrac{\partial f}{\partial x} = \dfrac{\partial}{\partial x}\dfrac{\partial f}{\partial y}$</td></tr><tr><td>$\dfrac{\partial^n}{\partial \mathrm{x}^<br>n} f, \dfrac{\partial^n f}{\partial \mathrm{x}^n}$</td><td><strong><a aria-label="Nth partial derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative#Notation" target="_blank">Nth partial derivative</a></strong> of $f$ in terms of $\mathrm{x}$<br>(Leibniz’s style)</td><td>$\dfrac{\partial^2 f}{\partial y^2} = \dfrac{\partial}{\partial y}\dfrac{\partial f}{\partial y}$</td></tr><tr><td>$\partial_x f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank" aria-label="Partial derivative (opens in a new tab)" rel="noreferrer noopener">Partial derivative</a></strong> of $f$ in terms of $x$<br>(Euler’s notation)</td><td>$\partial_{xy} f = \dfrac{\partial}{\partial y} \dfrac{\partial f}{\partial x}$</td></tr><tr><td>$\nabla_{\mathbf{v}} f$</td><td><strong><a aria-label="Directional derivative (opens in a new tab)" href="https://en.wikipedia.org/wiki/Directional_derivative" target="_blank" rel="noreferrer noopener">Directional derivative</a></strong> of $f$ with respect to direction $\mathbf{v}$</td><td>$\nabla_{\mathbb{v}} f(\mathbf{x}) =$<br>$\displaystyle \lim_{h \to 0} \dfrac{f(\mathbf{x}+h\mathbf{v})-f(\mathrm{x})}{h}$</td></tr><tr><td>$\partial \mathrm{x}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables" target="_blank" aria-label="Partial differential (opens in a new tab)" rel="noreferrer noopener">Partial differential</a></strong> of variable $\mathrm{x}$</td><td>$\dfrac{\partial f}{\partial x} dx \le df$</td></tr><tr><td>$df$</td><td><strong><a aria-label="Total differential (opens in a new tab)" href="https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables" target="_blank" rel="noreferrer noopener">Total differential</a></strong> of function $f$</td><td>$df = \dfrac{\partial f}{\partial x_1} dx_1 +$<br>$\displaystyle \cdots + \dfrac{\partial f}{\partial x_n} dx_n$</td></tr><tr><td>$\nabla f, \mathrm{grad}\,f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Gradient" target="_blank" aria-label="Gradient (opens in a new tab)" rel="noreferrer noopener">Gradient</a></strong> of function $f$</td><td>$\nabla f =$<br>$\left( \dfrac{\partial f}{\partial x_1}, \ldots, \dfrac{\partial f}{\partial x_n} \right)$</td></tr><tr><td>$\Delta f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Laplace_operator#Definition" target="_blank" aria-label="Laplace operator (opens in a new tab)" rel="noreferrer noopener">Laplace operator</a></strong> of function $f$</td><td>$\displaystyle \Delta f = \sum_{i=1}^n \dfrac{\partial^2 f}{\partial x_i^2}$</td></tr><tr><td>$\nabla \cdot \mathbf{F}, \mathrm{div}\, \mathbf{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Divergence" target="_blank" aria-label="Divergence (opens in a new tab)" rel="noreferrer noopener">Divergence</a></strong> of vector field $\mathbf{F}$</td><td>$\nabla \cdot \mathbf{F} = \dfrac{\partial F_x}{\partial x} +$<br>$\dfrac{\partial F_y}{\partial y} + \dfrac{\partial F_z}{\partial z}$</td></tr><tr><td>$\nabla \times \mathbf{F}, \mathrm{curl} \, \mathbf{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Curl_(mathematics)" target="_blank" aria-label="Curl (opens in a new tab)" rel="noreferrer noopener">Curl</a></strong> of vector field $\mathbf{F}$</td><td>$\nabla \times \mathbf{F} =$<br>$\left( \dfrac{\partial}{\partial x}, \dfrac{\partial}{\partial y}, \dfrac{\partial}{\partial z} \right) \times$<br>$\left( F_x, F_y, F_z \right)$</td></tr></tbody></table></figure><h3><span id="Derivative/Integralrelated_Shorthands"></span>Derivative/Integral-related Shorthands<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \left. f(x) \right|_{x = a}$</td><td><strong>Shorthand</strong> for ‘$f(x)$ with $x$ substituted by $a$’</td><td>$\displaystyle \left. f'(x) \right|_{x =g(t)} =$<br>$f'(g(t))$</td></tr><tr><td>$\displaystyle \left[f(x)\right]_{a}^{b}$</td><td><strong>Shorthand</strong> for <br>‘$f(b)-f(a)$’</td><td>$\left[\dfrac{x^2}{2}\right]_{1}^{\pi} = \dfrac{\pi^2}{2}-\dfrac{1}{2}$</td></tr></tbody></table></figure><h3>Univariate Integral-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \int_a^b f(x) \, dx$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Integral" target="_blank">Integral</a></strong> of function $f$ with respect to $x$ from $a$ to $b$</td><td>$\displaystyle \int_0^{\infty} \dfrac{1}{1+x^2} \, dx = \dfrac{\pi}{2}$</td></tr><tr><td>$\displaystyle \int f(x) \, dx$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Antiderivative#Uses_and_properties" target="_blank">Indefinite integral</a></strong> of function $f$ with respect to $x$</td><td>$\displaystyle \int \cos y \, dy = \\ \sin y + C$</td></tr><tr><td>$F(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Antiderivative" target="_blank">Antiderivative</a></strong> of function $f$</td><td>For all constants $c$, $(F(x) + c)’ = f(x)$.</td></tr><tr><td>$(Jf)(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Fractional_calculus" target="_blank">Integration operator</a></strong><br>(Integral function of $f$)</td><td>$(Jf)(x) =$<br>$\displaystyle \int_0^x f(t) \, dt$</td></tr></tbody></table></figure><h3>Multivariate Integral-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \int_C f(\mathbf{r}) \, ds$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Line_integral#Definition" target="_blank">Line integral</a></strong> of function $f$ along curve $C$ (under parametrization $\mathbf{r}$)</td><td>$\displaystyle \int_C f(\mathbf{r}) \, d s =$<br>$\displaystyle \int_a^b f(\mathbf{r}(t)) \, |\mathbf{r}'(t)| \, d t$</td></tr><tr><td>$\displaystyle \int_{C} f(z) \, dz$, $\displaystyle \oint_{C} f(z) \, dz$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Contour_integration#For_continuous_functions" target="_blank">Contour integral</a></strong> of function $f$ along curve $C$</td><td>$\displaystyle \int_{\gamma} f(z) \, dz =$<br>$\displaystyle \int_a^b f(\gamma(t)) \, \gamma'(t) \, dt$</td></tr><tr><td>$\displaystyle \int_C \mathbf{F}(\mathbf{r}) \cdot d\mathbf{r}$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Line_integral#Definition_2" target="_blank">Line integral</a></strong> of vector field $\mathbf{F}$ along curve $C$</td><td>$\displaystyle \int_C \mathbf{F}(\mathbf{r}) \cdot d \mathbf{r} =$<br>$\displaystyle \int_a^b \mathbf{F}(\mathbf{r}(t)) \cdot \mathbf{r}'(t) \, d t$</td></tr><tr><td>$\displaystyle \iint_D f …</td></tr></tbody></table></figure></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/">https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812448</guid>
            <pubDate>Sun, 12 Jul 2020 16:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robot Game: Comparing 6502 C, Assembly, and Forth]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 33 (<a href="https://news.ycombinator.com/item?id=23812187">thread link</a>) | @druzyek
<br/>
July 12, 2020 | http://calc6502.com/RobotGame/summary.html | <a href="https://web.archive.org/web/*/http://calc6502.com/RobotGame/summary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
			
			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_main_screen.png" alt="Robot Game screenshot"></p><p>
				A few years ago, I started doing small projects with the 65C02 processor to build up to using it to make a graphing calculator. There are a few different languages that you can use to write programs for this processor with assembly offering the best performance. One of the projects I worked on is an optimizer to make assembly programs run faster. It works by tracing program flow then assigning fixed addresses to local variables in functions instead of storing them on the stack. To figure out how much of an improvement the optimizer adds, I made a game in Python then ported it to both traditional assembly and the new optimized assembly format. I also ported the game to C and Forth to see how fast they are compared to the assembly versions.
			</p>
			
			
			

			<h2>Table of Contents</h2>
			
			<ol>
				<li><a href="#Why6502">Why 65C02?</a></li>
				<li><a href="#TheLanguages">The Languages</a></li>
				<li><a href="#TheSimulator">The Simulator</a></li>
				<li><a href="#TheGame">The Game</a></li>
				<li><a href="#ExtractingGameAssets">Extracting Game Assets</a></li>
				<li><a href="#PortingTradAsm">Porting the Game to Traditional Assembly</a></li>
				<li><a href="#PortingOptAsm">Porting the Game to Optimized Assembly</a></li>
				<li><a href="#PortingC">Porting the Game to C</a></li>
				<li><a href="#PortingForth">Porting the Game to Forth</a></li>
				<li><a href="#Results">Speed Comparison</a></li>
				<li><a href="#SizeTime">Size and Time to Implement</a></li>
				<li><a href="#CodeAnalysisRand">Code Analysis: rand</a></li>
				<li><a href="#CodeAnalysisCalcStats">Code Analysis: CalcStats</a></li>
				<li><a href="#Conclusions">Conclusions</a></li>
				<li><a href="#Improvement">Areas for Improvement</a></li>
			</ol>

			<a name="Why6502">
			<h2>Why 65C02?</h2>
			
			</a><p><a name="Why6502">
				The </a><a href="https://en.wikipedia.org/wiki/WDC_65C02">65C02</a> is an improved version of the <a href="https://en.wikipedia.org/wiki/MOS_Technology_6502">6502</a> used in the <a href="https://en.wikipedia.org/wiki/Atari_2600">Atari 2600</a>, <a href="https://en.wikipedia.org/wiki/Nintendo_Entertainment_System">Nintendo Entertainment System (NES)</a>, and the <a href="https://en.wikipedia.org/wiki/Apple_I">first</a> <a href="https://en.wikipedia.org/wiki/Apple_II">two</a> computers made by Apple. Because the 65C02 is made with more modern CMOS transistors, it’s much more energy efficient and runs at up to 14 MHz, compared to the 1-3 MHz of the original 6502. Both of these things make it a good choice for a graphing calculator. For comparison, the very common <a href="https://en.wikipedia.org/wiki/TI-83_series#TI-83_Plus">TI-83+</a> made by Texas Instruments has a <a href="https://en.wikipedia.org/wiki/Zilog_Z80">Zilog Z80</a> running at 6 MHz. Since the Z80 needs 3-4 times more cycles to accomplish the same work as a 6502, a 65C02 running at full speed should be 7-9 times more powerful than the Z80 in a TI-83+. Another advantage of the 65C02 is that it’s still sold in a DIP package, so it’s easy to find and experiment with on a breadboard. There aren’t many better choices in a throughhole package. The <a href="https://en.wikipedia.org/wiki/Motorola_68000">Motorola 68000</a> is more powerful MHz for MHz, but it's already used in the <a href="https://en.wikipedia.org/wiki/TI-89_series">TI-89</a>, so I would like to use something different. Some throughhole microcontrollers have much more processing power, though not much RAM and no way to add more without an external address bus. The throughhole <a href="https://en.wikipedia.org/wiki/PIC_microcontrollers#PIC32M_MIPS-based_line">PIC32</a>, for example, runs at up to 50 MHz, but only has 64 kB of RAM. For comparison, the TI-89 introduced in 1998 and the <a href="https://en.wikipedia.org/wiki/HP_49/50_series#49G">HP-49G</a> from 1999 had 256 kB and 512 kB of RAM respectively. Since the 65C02 has an open address bus, there is no limit to the amount of RAM and ROM it can access.
			</p>

			<a name="TheLanguages">
			<h2>The Languages</h2>
			
			<p>
				These are the languages that I want to compare:
			</p>
			</a><ol><a name="TheLanguages">
				<li><b>Traditional assembly</b> - This is plain old 65C02 assembly. Like many 65(C)02 (ie 6502 or 65C02) programs, it uses the X register as a stack pointer for a data stack (more details on this below). Some functions copy and save data from the fastest region of memory called zero page to free it up for use and restore the data when the function ends (more details on this below too).</li>
				<li><b>Optimized assembly</b> - This version of the game differs from traditional assembly since it doesn’t use the X register as a data stack pointer. Instead, local variables in each function are assigned a fixed address at compile time. The addresses are determined by a Python script that analyzes the flow of the program and tracks how much memory each function needs (more details below).</li>
				</a><li><a name="TheLanguages"><b>C</b> - This version is compiled with </a><a href="https://cc65.github.io/">CC65</a>, which seems to be the most popular C compiler for the 65(C)02.</li>
				<li><b>Forth</b> - This version is compiled using a modified version of <a href="https://github.com/scotws/TaliForth2">Tali Forth 2</a>. I picked this Forth since it generates subroutine threaded code (STC) which is generally the fastest, though largest, type of Forth code.</li>
			</ol>

			<a name="TheSimulator">
			<h2>The Simulator</h2>
			<span></span></a><p><a href="https://github.com/JoeyShepard/65C02_Emulator">65C02 Emulator on GitHub</a></p><p>
				All of the code runs on a JavaScript-based simulator I made that works in the browser. The simulation itself runs very fast on a separate thread using a web worker, while the main page is only responsible for the interface. This setup lets the simulation run at the equivalent of 40-50 MHz, several times faster than an actual 65C02 running at 14 MHz. Because it runs in the browser, you can try each version of the game for yourself:
			</p>
			
			<p>
				<a href="http://calc6502.com/RobotGame/TradAsm/main.html">Robot Game - Traditional assembly version</a><br>
				<a href="http://calc6502.com/RobotGame/OptAsm/main.html">Robot Game - Optimized assembly version</a><br>
				<a href="http://calc6502.com/RobotGame/CC65/main.html">Robot Game - C version</a><br>
				<a href="http://calc6502.com/RobotGame/TaliForth2/main.html">Robot Game - Forth version</a>
			</p>
			
			<p>
				The simulator has sixteen memory banks of 16 kB each for a total of 256 kB of memory. The 65C02 has a 16 bit address bus, so it can only address 64 kB of memory at a time. To access the memory outside of the first 64 kB, the simulator simulates a memory banking system. Each 16 kB range of the 64 kB address space can point to any of the sixteen memory banks. This was a common strategy in retro computers to get around the limitations of a small address space.
			</p>

			<p>
				Memory map:
			</p>
			<ul>
				<li>0x0000 to 0x01FF - No banking</li>
				<li>0x0200 to 0x3FFF - Memory window 1</li>
				<li>0x4000 to 0x7FFF - Memory window 2</li>
				<li>0x8000 to 0xBFFF - Memory window 3</li>
				<li>0xC000 to 0xFFDF - Memory window 4</li>
				<li>0xFFE0 to 0xFFFF - Peripherals</li>
			</ul>

			<p>
				The first 512 bytes are not banked since they contain the fast zero page memory and the hardware stack which always need to be visible from all banks. The last 32 bytes are for peripherals like the keyboard and for vectors for reset and interrupts. Each peripheral is assigned a specific address in this range, and the processor communicates with them by reading and writing to those addresses. Four bytes in the peripheral region control which of the sixteen memory banks each window points to. For example, if memory window 2 points to memory bank 7, then reading the first byte of memory window 2 at 0x4000 will access the first byte of memory bank 7 which is at 0x1C000.
			</p>
			
			<p>
				The video memory is mapped one byte per pixel and takes up the 32 kB from 0x10000 to 0x17FFF (memory banks 5 and 6). The resolution is 256x128. Each byte has two bits each of red, green, and blue. Valid color codes are therefore 0-63.
			</p>
			
			<p>
				The simulator has some interesting tools that helped port the game. Some of them were added during development because a specific problem arose that I needed to add them for. The main page lets you step through the code and shows the status of all the registers and each memory region that it accesses. There is also a memory viewer and a log of exactly which instructions have been executed. Copying this information into Excel or a text diff program helped track down several bugs in the game.
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_simulator.png" alt="Screenshot of simulator Robot Game runs on">
			<span>Simulator debug interface</span></p><p>
				Getting the cycle counts right for the executed instructions was a little tricky. For example, when an X-indexed instruction fetches an address where adding X to the low byte of the address overflows and the high byte of the address has to be adjusted, the instruction takes an additional cycle. After I got the logic for that fixed, the test code I was using was still a few cycles out of 3.5 million cycles off. Single stepping the program through all of those cycles to figure out which instruction was off would take too long. Instead, I loaded the code into the <a href="http://exifpro.com/utils.html">Kowalski simulator</a> then used a Python script to automate pressing the single step button and record the cycle count for every instruction. This generated way too much data to load into a spreadsheet, so I made another script to compare those cycles to the ones I generated in my own simulator and tracked the problem down to incorrect cycle times for the STZ instruction.
			</p>

			<a name="TheGame">
			<h2>The Game</h2>
			<span></span></a><p><a href="https://github.com/JoeyShepard/RobotGame">Robot Game on GitHub</a></p><p>
				The game is made in Python with the <a href="https://www.pygame.org/">PyGame library</a>. It was easy to read one big image into memory then copy parts of it into individual tiles that PyGame draws to the screen. Here are the images I came up with in Paint:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_tiles.png" alt="Graphics tiles for Robot Game">
			<span>Graphics tiles for Robot Game</span></p><p>
				Several of these are tiles that I was experimenting with that didn’t make it into the game. Bright magenta (0xFF00FF) and bright cyan (0x00FFFF) are replaced with transparency when the tiles are created. Most of the tiles only have placeholder colors and are used as the basis to create other tiles. For example, the green, yellow, and grey color in the generic crystal graphic above are filled in depending on what type of crystal the game needs to draw:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_crystals.png" alt="Crystal tiles for Robot Game"></p><p>
				The rock and lava tiles are constructed similarly from the generic tile above. There are four dirt tiles that are colored slightly differently and rotated at 90, 180, and 270 degrees to give the background some variety:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_dirt_tiles.png" alt="Dirt tiles for Robot Game"></p><p>
				There is only one type of monster which is always colored the same, so a few tiles like that don’t have any pixels that change colors. Adding in some stats and a randomly generated map gets us to the main game window:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_main_screen.png" alt="Dirt tiles for Robot Game"></p><p>
				The map is formed from the output of a random number generator. Using the same generator algorithm for each port results in the same beginning map for all four versions (and the same gameplay if the player makes the same decisions). I had to try several seed values for the RNG until I got a map I liked the look of as seen in the screenshot above. Here are a few that didn’t make the cut:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_failed_maps.png" alt="Random maps for Robot Game that failed"></p><p>
				The rest of the game is just the three menu screens. The first displays a couple of stats and an inventory page. Moving the cursor over an item shows that item’s stats and what is currently equipped in that slot. Equipping an item changes the color of the corresponding part of the robot to match. In the tiles page above, the image of the robot is drawn with different colors that all correspond to the same colors that the generic item tile has. This means that the easy find and replace function to color in the individual items also works with the same color information on the larger image of the full robot.
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_character_menu.png" alt="Robot Game character menu">
			<span>Robot Game character menu</span></p><p>
				The skills page is pretty straightforward. There are three paths and unlocking any skill requires first unlocking the skill before it in that path. Every …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://calc6502.com/RobotGame/summary.html">http://calc6502.com/RobotGame/summary.html</a></em></p>]]>
            </description>
            <link>http://calc6502.com/RobotGame/summary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812187</guid>
            <pubDate>Sun, 12 Jul 2020 15:47:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alston Poverty Report – The Parlous State of Poverty Eradication [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812118">thread link</a>) | @DanBC
<br/>
July 12, 2020 | https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf | <a href="https://web.archive.org/web/*/https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>^Eÿ»ËŠÑ
Nœb\‚ÿÎzÎ–u2VLlKl04c‹%
†&gt;Q‘¬¿±hýÒþvnÃ§žijž9t{&lt;íú~�,¢°È’�}‘yVS€VÝ™�Û5‡žVï·èýû¦s[¨X°Ñ'â¢Ô–ú ¢9:ÿX�Vëctîíàê6z×—½r<s«u5lë™�ƒÌŒ`�ûïíÊ(}0f�ÍpÆ¡õ5¸ÑÅ°ðÿÚ0Â¦>_7,5öúSS®Ú� ÚZ¬{š¥†³d¢ïÎ,u¶”ÝÊ¢e&amp;‘µëNVe.™]rˆVD•9Z#«¬{’m
:½t½C)r¼õ^Úª‘JúvQN#ÎþÂ&amp;ªŽî�˜Ï2ºØû¤þ �Î(,l(wOr2ìI‰]qýYÓ&nbsp;w'2k'GÊ&amp;É«ÊÌicV±j�Ý©­‡_…\Ót»yÿœœ¬Ÿ@Yu6ødý¼²˜„%ÄLêðHYu€`Uþ™L›TôðôÔßÎ1Iš,v&gt;Ñ¬—ÐJŸ|£‰@ÍúÛˆF�Œ6�­Â•M]þLCh2ÕÜp
nôñšuwéd.HZgYŠšÏY{VÙn?¹Ëz¥³5µ“»ü:ä’»&lt;�NòsPK,Œ&nbsp;G™›zò€¹ôä±~ø¡&amp;¯ÊŽõ×Ñ3¡
L¦˜J�/ñ2=‰Ê®ºx™�ÒÉ4`Ð‘`¥xÁJý QÂHY§êâê�Ñ%pßÄI=
ðSÀ¢óãÏõTv~Öát�Ä@^�nyÜd„ã3Šá`'ôU–»îß•l*ÀU¶1Ðô!zmc­	ÿþ—õ„½é‰‚pfäÖë`™ñU$Â[GÙõèÛÃnl‰Oý¸ßQQtÔwÇÓéY{‡ºï†]?í*üÂ©{Ü³ntãaNnI´ŽxÃ
“ãë²D©'¤“—Ë@^”/?M3ìŽÔäÁ¾[fi¼°ÌL•¿|ÿÈö‹Nå¢®jõ›É.º+@Á¬VMX�^z]ÿ =ükÒ')èuãîpð¡e%nrØÄ¡ùWÁaUtUtD–m®~N2ƒÉù0Õ]­Rçð_HSE&lt;×ä¤àÒ2ÁÑ|%ËTi^-ð¨Ø3¹ƒbÒEÌË»Lg	¦rçÓ¸;ì‹i|8,lZVûzaÓ²éÛÝ°Ùu0/´M5É^ÖkÈ&amp;Uÿ’½°ú)Í,û&amp;»xq$od’¬ËÉ	îô"àßàäZÌUÚw	ß¨ÛÁùNÿevK†«ÕÄÈØ ¬t�á
…ÙŸÁ¾ÔE(±&gt;KlEcÒð«‹ÏTë`¼Ø�&amp;+­»¨7²{8´ÄX×p¶7´¡áÝ\Ã&amp;b÷wcîA%6…£¤d™¼Kj%uC‡¡~3•À*Ií3\�e˜é')�Y«a-ëc”àÝ³äŒh\šòŒ’ýçpãÍd�VÝ&gt;\W­l ö’d÷:÷'ç]¯º&lt;�³ph]…�jù£î)µÑ�_FkT]¨¼Ùõ�ÉÆ™]Kâš‚­&gt;âJê+¨I<vwöŽÐ„\~"šy¤u¢9¶��ìÄÐ¨Œ„)¤„ó«Ù€ ek5xrð+.ï‡[|+ÑÍy.yt]¹ðŽûè—�“="" •vbÃy¿»u="">£¿s2ï'‰^®a%æfq”I¥ÀqGÎLb/�S=Á¹(ÿ/ÎåcýhüHª:‰rwûH€€ò&nbsp;Ì¦ê‹2°+[b�ê?jk›_ušî&amp;.ð­Ú¢J&gt;žyqFÉ¡®ÿ0W˜1†U’p�÷ºñl4½||÷À»pö[W€Ý‘?©,_Aí˜˜w‘üŒÌ˜¦ºQe¹ˆî¡.¾÷õ.Á”ó|wg�BXœ=&nbsp;lx®{BÏ&gt;Á¸oêGXÞÜ¯¦;|D™×(€9‡ühç:,UÒò&amp;94±¸ý[·ûW7º`¨ ­ó˜Ba'™¼dfÏ…ná¬¡Ð;Aâ˜n½¿ËãM}ñÊ¢„cÇÄw3º÷.XS‡ð^&gt;‚SºóK÷2õ.í}n8{÷³é®³h&gt;Ý]¶ÒS=„9!÷­˜—.w%ˆ¨Ã§kRGÀ\¢y'wM•&nbsp;ŠÕ¦Ï1K†¨7Sñ‹qbÅ­b&amp;–ñ+§”f©[h¢á3CÇ¨²@ó;xÅ2ùØÂDðMÎi¹}­uJ4¿G‰\&nbsp;p‚
Ùç¯¦m\›œÞþ~z°Éb¸¤4¡†4±v[³£åÆe×’ƒuÎùÆ†äTç¥}ù'='P­='àuÙTlgÕÄ”ÓGI¹&lt;åM ˆb«¬x;¯&amp;&amp;…™UQU†Ÿ*°&amp;4ój¢Û¢šàYˆL´jëˆ)

ó(ÔìWï©Oò93gÐÙÕí5fbf|ƒ…G¥‰©Ä?AæOÎzv—´aSq”¦+YÙÚ™x±±é‚1¸]yš“£NjÚó{Õq‡7ÕIo‚!ˆ¸hÞË`çD+ÒWé[ÖuÖ(¤d&gt;äî�Yê8g*[Í’¢•ÑPl¬D�)C–GÛè÷ü¼‘�¾!¶¡UCc&gt;2ª1dÌ%ŸëÆÙ¨ÿMoþ�¢[©³qot…¢…éŠÕ’Ø©³hGÄ0F­›1cck5mærZ«
')†
F&nbsp;‡&nbsp;u#Ìsž“5R3¥…ÉZz†?Qõ%†'mMš’7žoF¥Ò±]!ËsV.T*á&gt;èË¶¸b	}„1•¯R(F’~dà#9».R
N‰¦&gt;-š÷%Õ;ùáM¢Ô²Ê¥´TäÔùjâ#þÍÆs¦|Ø;]þ´tS\_ý¥ÌÖÓ§M¶’†™€ç\X|Î4øÖÖ™‡Wvdà´t¼Oû
ž�éÑ€,N/äÒ:â¢ý]¤‹{Ä‚îà tø*pß&gt;ÈV6Í6¦u’g#”òwé,gÉîÐZåhFâÞ–?»Fñ�Ë§¸KÃÌõŽOx6å¥Æ=m‰;&amp;*¾¦ûñ°()@ÙneÅö«„!®F+2ñŸ&nbsp;¢@fÚ„�½y§6x)Y]Q7M7	Ã:‰ëÐè}–A‚u/³oŸÐ�¹—Ö.ÍŒ»�W4štÂ2¤¤u€,€É…Œ8=ÇÄj!œ7“o †Ør—6í_¦JŽýÒ5x#å"
.²³&gt;I„ËÒj&lt;oÏ3Eæ0òð^~»"Å*N&gt;^J3­¢Þ¹»õŒ:‚–*?n$ÃöGTè•Zd¨ÑX¢{éýè{‰F&lt;ÈDo\Kê8.án©«b³7‹zOˆ:KN“I%ñ3P,€™M¥³7k‰‘‚­SðƒwqzAÈ¡b¢C°ìLÞy¥{ 3�†—³]Z©n\‡”‰"@Œ$½Îq6\sÎM¨ÙT§T
(Îyˆ7[n ‘9ÕüXrª½í¦dàSÂ÷ƒÅEa³A—ˆ„aþÁà‚Ø!ó^Aœí"zoÄaÐGüJC�6!íAvWi¸Ë$]©í÷»CÏêÝ¹HYÉ­�µÚÈ5™'/}ò[ ÓÑ	Eò	/ûçÓ&lt;ÌZìðàê!¢¤bWì�hÉ¶	çA9‚±/ñzøéð	fZpåf3ý+B¡
òXÿ"JÖ¢`dõPl]®�Z z˜·Æ<fÄ™sÂ¥ôs ×m˜="" –ö4="" x–Ü<+ißš£="ˆ§$·DÎa" u¡="" Îa™ëcÿd·ÔçÃwÖ×zåx»-ÿk`ùxâ±‰àýŸqÔ¦:r*jh+x½%evÔh^Ô&ì¬¨m°¬¨Íðsq›ÁÎŠÚ–="¼ìN7Õ!÷¹)ßÝTOzºò”ã|;˜g˜×žðšJÛopvË.¦" n="" ¼‡šl<þd¾"@ë˜7u_kÉÇt§bÍæ�="" ^pÀs“É@»�˜="">œ/ŒS]üÖò$ÅdrÓÍóÎÌ,@Äþ™ÚZ­ÔâãÏÕÅïµƒ¡ØÀNÅ¸ÑL&amp;ë�í¬…ŒÀúÂ¡(ã,Ga1‚�	1× ‹m¬
›†jc\kžJ¿¼ƒsý‰)2¨³-&lt;·Aûlx"ã4`à_1“
¯ö©Â…µŒå@*š&gt;%rqów–Ö¯?ÿ?ùã;¤—ŒHW6åBÔ$Þ$É¥Xl/ÖS‹¥Zo®(e&nbsp;¹‰‘e-aTšjqé(èc‘õ#Èø¥,h H²5¼Á¨U:”ãÏ0eÁšÆ�‹+ð�±&lt;ã*�žd8&nbsp;ˆúÓÈÞ:‘–R'â,VæŠœ¢³]öô+Y(qžb”^/Ä•¼F\…¶­�F8˜ô'©œÊ­”Üp.YÈ;
§Ú}Âp[7F†ÃîØpÿµuÌ2&nbsp;…¤îlõüþY…§#zAZ¤ÑDì)~/�A•;)O)g¯qx³4ÿž¹Låš“»cä"ê™QZ‰faí†õ,áW»]qÂµw¾ñ|Î›m3E°nÄn'ÅÃ†&nbsp;‰SäPOx4OÓn–pÝ\S1J‚‹ýù÷^ÖŒÏ°®âùNÏjÇ2Çó®L+a8	¸ÌèÐÅlâÀãÇ‘C}ñïšîüv+dõMËÓñ¼Ðæ–so)²äÒG¶^€êåÑ­#&amp;Ÿ‘Kï­|$ýnN“÷µÖ„Eª×Ì”¤4&nbsp;r‰)Ñ³óŠ¥�îð&lt;ÅE»³gj†¾úè{(š=”øÔõ�ç�­2Ê¤hÿ9Ê €]§&amp;§®{ˆ™â˜”‹wÐ	z¨1‚~a¸’{»›r(˜õ–Ü_vT|Œ"&amp;–Ôw[7eÛñÄë™Ç¶nK%Þ4íMT³·-ŸtK'¿ï‘^ý¬xŠ*îÌ¤„sÊ~(Ë~#÷T�&gt;ºÇ½(MGIˆ‹[:	;Ë~lÊ~ëÀÏž¿«2Ø&lt;ûmå-�ÅÄx”~é±(ÜÛòiy}@ì&lt;ï�4î;×_â£¸k²9–ø•N"r+Â1¸^ì”ç&lt;`8
8qEØ¢¿ÑÄáè-8•L^?×õÃ³&gt;��³ÓB¼N4lDƒãö­­çÂ‹áã‘ô%¾žqi#–¼
�DÊ‹È'î�3bF8gØÄ±Ö`Õ”dÔ„Œœ&amp;Œá¼ÕXøWU@`{¡:¶Îß^ê…µé®21Ì(›àùø“*b,3�‘2™ðª6è�Í$1¥Õà"çÒ±.»¤œ&amp;‰Q²ñÌÜÐ{J´ÝŸío/$!gú&lt;36R&nbsp;ßù1�=|¡wž¾ð[±=d¯EXmF6èØ&gt;’Šm'uQFÐMmf�u©Z	1‡Å½K•¥V}÷ñ5$=Zû|p'Ž8¿GôÙfZÄe$]¸½‰ÄA›b3ß~×ç.HKüG²D)à(Ý?òä“é�~Î!.&amp;÷´$¥Q¢¢]Z�˜Ì'VeÉ‚hÅÁ„QÇtöbø‰­u5§ª¾9�íu/TQevÂ^,ÕÂ-Lâ´°ƒWøÿï&amp;ÓÁóz©+£7“OZDl¿Q$ÑIG�o�¢Ñ°ÿo/£Õ«žw¾äúJêôltCqÚ¾NºõÝ³ds›áÅ†2ð_•
ç¶�Ç(ŠªÁ£pXfú'Ë&amp;~
ÕÙtæ-ip:ÞäWÎu"[ÄÙôFeVº.,ù4ÄBÞæzsÉŒJê/–Œþ“ÚUefKçÙ±ƒgAÛ¶¯ó©J7]{MÁtmx6cvKf£èAJ»}|]îÍú½/dtÇƒMqŽrO1†4‹JE€_˜‡ÁE&amp;À�&gt;Z.h£ƒ§�e…:eo¯ŠFHlÆ•žÅ²ä¯R�DË2²Ä'†…�a¼©â‘oísã„Ê"ézSP1'ÙZR&amp;¶!8^t°&amp;ÃØÏ*¾RT•ÑY-E�’òúf&amp;_4H(�õ6—[+äNÒ‹Fèù”Ç»5¿&nbsp;\Ž’ú"låúñ­“ç`®BÕÖy&amp;NÁ•©^À�5ó'ä�Z_—ªÝó‰•c?Ô�K•­ŽcóñÕqí¾<kŠxæ³8… j–—‘ÅÛµ¡èu�h ì69æ3mÇw‚ãÆf}ª²r¥¨mt³="">Š…l³&gt;@±YooÕ	&lt;ÑK&nbsp;©üP'ßÄ˜ÊŸýÿÑ+$‘7«â5¡œÁ6q˜PF×\…ñ¶N‚MZµ6ŒÞƒ˜}©oVô%˜¼äoC	Ìy*ÄYâ3á/ÐC&lt;ƒæüuÆS£ß9’/$ñbËô�£•Ê[– ‰Qñþáœ\s óâ}ì_Hn:^]Ø‚Œ­$G^]K°»«ýùèËN¸&amp;¥óœE+÷ù²Ó‘÷#eŸ¼&lt;ø'ïûÁ^@_x|tN®ÙDâÃq7àcAnK�ú&gt;èÊw‘ö|±ê™ä¶ìï³Ï¸ãKT"¬Ja¯6ÌÛðIŒ–{ö3r²À®›a„§§ç}Q°e×b°ícÚ¹„`KøÏ;½•×•ÓºnT¤È£É!žà®«­ì°Úù‡ï&lt;ºÛZf”íß“'¾=—�7["a}þÚðô½]ØèßÛ’ç«fÞÍA$^åB8ªI” O€Ñ-ÜøòMeäÒ´€çÈw.úƒ©ÂØ?'n¤ŒÝIõëëuÏ7Çö¾rN�­×‡QÖëm'pÁýi:êáíÙ"Ì[YÆ÷æRÜËwÄNò1Ÿ~ÎLÁBYéåñË•Öm¼#_á’È'ÉØŒä	ï]ÏëÓÅóÒìòæ¥ü6×R`÷ÜË—åÆž¨?†ò/[èþT„Ra¥i÷|ÉŠ`’xixØ}ì×˜QV„™ó'¦•R_	‹åœN„?”óÏP^xé]x!ÁÙ�ä]ÞÄY1Ÿ�[ÑKbå,àŠ‰FŠgšé&amp;ÏhŸÒóCÉËgë1¨‡JËÛòˆV�“ô”§o?ýƒ]‡¯8P‰|‘%zgZŸ|Þ©Mce®¾9–îPÚ¯K1´,u‡aX¢¼°ÑUz0‘´ÿTÓÔ~Ÿ±¦yOÆ|�Š�n­Máø@&gt;9˜]S›M/n¹ú–Ä|‘ä+g‡“ê‘W6”ŒM�‚‘RÆù,MS#qÒòì{jÆÊlw}–&amp;Æ”¯V±WBðš»¥¼ÿ5}…é3Û=¦€ÓŠBþ)xøg³€ÿôY¥þÃ$h¼¿ËÍ\3* Á#
Â?ç
�ú
D×·ºþÄ,ØãU¥ts™ä«•Ó·zŠ¯IÈ{qG™öIÏòy½5¯OúDæCz½èIŸoû-23I‘Ÿ­V.ÎÑ·š¸�Ä9äüã«üÿMÒ	ÅX©Ç¹ueUæœfc-Ú]sà~õŒÍÂ1Ë]æÜ1ç~&gt;IÍ{*âçÏ|0²E"„ð/Â9lK¬\_C—›öGÐÔ6ÿÉàsþ{ÉïÈ¥Û°g¡#{;òÂ¾ëÙmª”%Ú«ë1`NnR5ÕÜóCÊ:9¬ÏÈ!¹ùëGn@ÿÉ\Î¼–Mgçæ–ÉÕwÅƒ±ô†[²övý‘(uÆÍÒ‡J­±:üŽQ	(ðÁ?nÄ¼�þ™O¤–lnŒMè8ñ¹¯úù{!ª8‰ Tbò•“þÄ×5u3X¹W�¸›ò
j¿³|ˆÚ/‡‘Nœ²­A�—~EWMíŒä@99¥5FR`U†_àÎh–øoR¥»ªHŸ_h&amp;ÜŒfÑ×ùl;òOù0L¨1˜ã¸Í&gt;¥tÌ•SÇ¹K0'ÑÌp3š�ŸxªßT�ì…å|¢ûæønAs†_e›!;4Ó&amp;Gf£¥qôüA¿]¥%,ó¤Ë&lt;)9*Ãêä»º‰Àƒƒòè|U4’£H&gt;#é0÷}†™p
†%…Kñ†²PN3i.c3p1�#4¥ï¾àIhv|Í©ä3ƒ&gt;–L¸S&gt;³¾žfÊdO
ž�3Ã-hþù÷Œn¥
endstream
endobj
5 0 obj
6498
endobj
2 0 obj
&lt;&lt; /Type /Page /Parent 3 0 R /Resources 6 0 R /Contents 4 0 R /MediaBox [0 0 595.2756 841.8898]
&gt;&gt;
endobj
6 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs1 7 0 R &gt;&gt; /Font &lt;&lt; /TT2 9 0 R
/TT3 10 0 R /TT1 8 0 R &gt;&gt; &gt;&gt;
endobj
11 0 obj
&lt;&lt; /Length 12 0 R /N 3 /Alternate /DeviceRGB /Filter /FlateDecode &gt;&gt;
stream
x�–wTSÙ‡Ï½7½Ð" %ôz	 Ò;HQ‰I€P†„&amp;vDF)VdTÀG‡"cEƒ‚b×	òPÆÁQDEåÝŒk	ï­5óÞšýÇYßÙç·×Ùgï}×ºPü‚ÂtX€4¡XîëÁ\ËÄ÷XÀáffGøDÔü½=™™¨HÆ³öî.€d»Û,¿P&amp;sÖÿ‘"7C$
EÕ6&lt;~&amp;å”S³Å2ÿÊô•)2†12¡	¢¬"ãÄ¯lö§æ+»É˜—&amp;ä¡YÎ¼4žŒ»PÞš%á£Œ¡\˜%àg£|e½TIšå÷(ÓÓøœL0™_Ìç&amp;¡l‰2Eî‰ò”Ä9¼r‹ù9hžx¦gäŠ‰Ib¦×˜iåèÈfúñ³Sùb1+”ÃMáˆxLÏô´Ž0€¯o–E%Ym™h‘í­ííYÖæhù¿Ùß~Sý=ÈzûUñ&amp;ìÏžAŒžYßlì¬/½ö$Z›³¾•U´m@åá¬Oï ò´Þœó†l^’Äâ'‹ììlsŸk.+è7ûŸ‚oÊ¿†9÷™ËîûV;¦?�#I3eEå¦§¦KDÌÌ—Ïdý÷ÿãÀ9iÍÉÃ,œŸÀñ…èUQè”	„‰h»…&lt;�X�.d
„Õá6'~�khu_}…9P¸IÈo=C#$n?z}ë[1
È¾¼h­‘¯s�2zþçú\ŠnáLA"Sæö�dr%¢,£ß„lÁ�t&nbsp;
4�.0,`
€3pÞ „€H–.Hi@²A&gt;Ø
A1ØvƒjpÔ�zÐN‚6p\WÀ
p€G@
†ÁK0Þ�i‚ð¢Aª�¤™BÖZyCAP8ÅC‰�’@ùÐ&amp;¨*ƒª¡CP=ô#tº]ƒú&nbsp;Ð 4ý}„˜Óa
Ø¶€Ù°;GÂËàDxœÀÛáJ¸&gt;·Âáð,…_Â“@ÈÑFXñDB�X$!k‘"¤©Eš�¤¹�H‘qä‡¡a˜Æã‡YŒábVaÖbJ0Õ˜c˜VLæ6f3�ù‚¥bÕ±¦X'¬?v	6›�-ÄV`�`[°—±Øaì;ÇÀâp~¸\2n5®·×Œ»€ëÃ
á&amp;ñx¼*Þï‚Ásðb|!¾
ß�Æ¿'�	Zk‚!– $l$Tçý„Â4Q�¨Ot"†yÄ\b)±ŽØA¼I&amp;N“I†$R$)™´�TIj"]&amp;=&amp;½!“É:dGrY@^O®$Ÿ _%’?P”(&amp;OJEBÙN9J¹@y@yC¥R
¨nÔXª˜º�ZO½D}J}/G“3—ó—ãÉ­“«‘k•ë—{%O”×—w—_.Ÿ'_!Jþ¦ü¸QÁ@ÁS�£°V¡Fá´Â=…IEš¢•bˆbšb‰bƒâ5ÅQ%¼’�’·O©@é°Ò%¥!BÓ¥yÒ¸´M´:ÚeÚ0G7¤ûÓ“éÅôè½ô	e%e[å(ååå³ÊRÂ0`ø3R¥Œ“Œ»Œ�ó4æ¹ÏãÏÛ6¯i^ÿ¼)•ù*n*|•"•f••�ªLUoÕÕ�ªmªOÔ0j&amp;jajÙjûÕ.«�Ï§ÏwžÏ�_4ÿäü‡ê°º‰z¸újõÃê=ê“š¾U—4Æ5šnšÉšåšç4Ç´hZµZåZçµ^0•™îÌTf%³‹9¡­®í§-Ñ&gt;¤Ý«=­c¨³Xg£N³Î]’.[7A·\·SwBOK/X/_¯Qï¡&gt;QŸ­Ÿ¤¿G¿[ÊÀÐ Ú`‹A›Á¨¡Š¡¿aža£ác#ª‘«Ñ*£Z£;Æ8c¶qŠñ&gt;ã[&amp;°‰�I’I�ÉMSØÔÞT`ºÏ´Ïkæh&amp;4«5»Ç¢°ÜYY¬FÖ&nbsp;9Ã&lt;È|£y›ù+=‹X‹�Ý_,í,S-ë,Y)YXm´ê°úÃÚÄšk]c}Ç†jãc³Î¦Ýæµ­©-ßv¿í};š]°Ý»N»Ïöö"û&amp;û1=‡x‡½÷Øtv(»„}Õëèá¸ÎñŒã'{'±ÓI§ß�YÎ)Î
Î£ðÔ-rÑqá¸r‘.d.Œ_xp¡ÔUÛ•ãZëúÌM×�çvÄmÄÝØ=Ùý¸û+K‘G‹Ç”§“çÏ^ˆ—¯W‘W¯·’÷bïjï§&gt;:&gt;‰&gt;�&gt;¾v¾«}/øaýývúÝó×ðçú×ûO8¬	è
¤FV&gt;2	uÃÁÁ»‚/Ò_$\ÔBüCv…&lt;	5]ús.,4¬&amp;ìy¸Ux~xw-bEDCÄ»H�ÈÒÈG‹�KwFÉGÅEÕGME{E—EK—X,Y³äFŒZŒ ¦={$vr©÷ÒÝK‡ãìâ
ãî.3\–³ìÚrµå©ËÏ®�_ÁYq*ßÿ‰Â©åL®ô_¹wå×“»‡û’çÆ+ç�ñ]øeü‘—„²„ÑD—Ä]‰cI®IIãOAµàu²_ò�ä©”�”£)3©Ñ©Íi„´ø´ÓB%aŠ°+]3='½/Ã4£0CºÊiÕîU¢@Ñ‘L(sYf»˜ŽþLõHŒ$›%ƒY³j²ÞgGeŸÊQÌæôäšänËÉóÉû~5f5wug¾vþ†üÁ5îk­…Ö®\Û¹Nw]Áºáõ¾ë�m mHÙðËFË�eßnŠÞÔQ&nbsp;Q°¾`h³ïæÆB¹BQá½-Î[lÅllíÝf³­jÛ—"^ÑõbËâŠâO%Ü’ëßY}WùÝÌö„í½¥ö¥ûwàvwÜÝéºóX™bY^ÙÐ®à]­åÌò¢ò·»Wì¾Va[q`i�d�´2¨²½J¯jGÕ§ê¤ê��šæ½ê{·í�ÚÇÛ×¿ßmÓ�Å&gt;¼È÷Pk­AmÅaÜá¬ÃÏë¢êº¿g_DíHñ‘ÏG…G¥ÇÂ�uÕ;Ô×7¨7”6Â�’Æ±ãqÇoýàõC{«éP3£¹ø8!9ñâÇøïž&lt;ÙyŠ}ªé'ýŸö¶ÐZŠZ¡ÖÜÖ‰¶¤6i{L{ßé€Ó�Î-?›ÿ|ôŒö™š³ÊgKÏ‘Îœ›9Ÿw~òBÆ…ñ‹‰‡:Wt&gt;º´äÒ�®°®ÞË�—¯^ñ¹r©Û½ûüU—«g®9];}�}½í†ý�Ö»ž–_ì~iéµïm½ép³ý–ã­Ž¾}çú]û/Þöº}åŽÿ�‹úî.¾{ÿ^Ü=é}ÞýÑ©^?Ìz8ýhýcìã¢'
O*žª?­ýÕø×f©½ôì&nbsp;×`Ï³ˆg�†¸C/ÿ•ù¯OÃÏ©Ï+F´FêG­GÏŒùŒÝz±ôÅðËŒ—Óã…¿)þ¶÷•Ñ«Ÿ~wû½gbÉÄðkÑë™?JÞ¨¾9úÖömçdèäÓwiï¦§ŠÞ«¾?ö�ý¡ûcôÇ‘éìOøO•Ÿ�?w|	üòx&amp;mfæß÷„óû
endstream
endobj
12 0 obj
2612
endobj
7 0 obj
[ /ICCBased 11 0 R ]
endobj
14 0 obj
&lt;&lt; /Length 15 0 R /Filter /FlateDecode &gt;&gt;
stream
xÅ�Ë¶ä´†çõÖPø~É¬»é�ÎJVœÀ +h 4éærº!—÷ÌûäÛÚ’l¹l•Ë¥&gt;�EUYþuÿ´½%™Ÿ³O²Ÿ³þÔäÕ`¿ò6kºþT¶]Ÿõe}êûbÈ¾É¾È~È&gt;|ö¶È^¾ÍróïÛ—Ü›ŸÊZÿ–Mw*Ëªï²nÈOuÙô‡—o²§÷ÄÊóaÈî_fUgbÛ¯û7Ù‡÷÷eVd÷ßfÍŽO&gt;¼ËÚìø»OŸé�ú.«²£~~xwà’þÎï²¿e÷¿Ïžß›„™(ò�\ÔµÏD¦™’&gt;I³»ìþ{•kšS×S]_›"do²¦ÎOMözV�†š¢æoÕ&nbsp;ìuö]öíz-•Ã©ê›¾t¬´nÌ—Í`¡u3ÍàY¥WÃ©()]"9ß†´fCÁlî¤
«ž6&lt;$=À~iEÚ|Ò†Ï~¼#ÏÇÌç»»¬ÌŽßœ…¼Õ&lt;¬4`'i•Yæ ’.õsp
8¯Ÿ®8U]EwîªþT�
úC¦Å¨Lu¢Õ]æ§¶*š¹œÔOOGžõqÛŽ*,}üÏ_šÚø»ù¤fÖ;rãÖeÜŽ¦¥Œoé'¾a)AC¿³ruašÓ~Í«‡¡:õƒ©ÖPNê¡©¥bÂ/Nãˆ›7Ø0œ:(Òf]¨Ó›à¹\Q0Ñ›ËmÊ(
ö‚®ü¢/Ó¯èÞò××òu8þ¢½ä‹Ž®Q^™ˆ67¯·pÑV§ªé@Uš’"gP&gt;““’RyšätáŸõVÖ³t'ÈXN÷ö]—½�l¤£Tå,ÝÉt³œ®L7›Ó]%J�ÏÒ}¤òÖý,Ý]å]xô�ÅþC]
ðí×fBˆ\»õî¦ªež»J®ŠÖÓ5ÉØMŸ¼LAWÝV]‘u¡Ü&amp;h_lÃk(½³•G¼†r’ÓAì×o–ºx}þ/c#€NÌ»‡»¬6ö„}swÐ2Eò	ß¹ü“‰
Yaí¯Î´àªÞ¦ÿ6á7ÙcRk8æ^UÐøþÕDMïÒ˜LÓÄ×8š“‡»Yd']&amp;®j|¦B4\•5&gt;qÖ'€²cÄõ-ÖfXy;Û¢ìZj]Œ×Pî}OU3K÷±€XÍÒÝÄ…	H°±lœŽŒ´Ul‹o±Õ©ddäV¹¸qê¹Aî`»Ž›—›NçŒ•5KÜ3²åÙJ,Ð¥ºÛþàãíÄ4rd39OÁ30&gt;±6~±S˜µNmÝ4™S¾Íò.ªæTÈ¼:““ŒÖíeâþQÔÜp±7Lí²ãk
úòî@(ã|ñ	¾¸L£büÞeƒ»`ï°Zp�È0“Èîv‘²7\.èe#%ß™+š–½òÆ4‰é=šäë»ƒDö™‰µíO]UÕ¾rFùùtö6¦£§”¾“Uhþóù_7‹N)…Öâ‡rðû3+�Yæ½WuôªÆ§@ÄŸ^¥™ÕT“¹�«ç s¿©RTMÕan#\ãë½(£&nbsp;šÄ_¯—:ç±—Œ¯—Ûú`�:Óœ÷Á÷ú¨Q÷³tÇæ]IwÊ&amp;Oú£œ
ì
v£&lt;ßÉ9¾_!WG
ëlà+äè}—ùÞ¶IùžDnä{('Ø4dˆòýéi½ÜÂ÷_HÖZåÛÆÖÈ÷PN¬¸-õ=LÅ,
ñT‘
Þ	‚\†m|Â6#²á
Qá
!z³†O­n½W-ê(oÊb8ÉˆtU²4Œ¬Ó­°†H¤g•¥ögm·4ìCªý°_ù±Þ²•ÇÜySP¸øÃÍåtWÍÂÊcnSy©ÈEÌ]]Þº�ÕómõzÅz3Úõ�Û†ÌˆÙ°�b[¤»yWÃ¹ë"…õ˜M“;çÈmk–nnwä:wk¹³aî<fcþ€ã³m˜ •w6òˆÙpîzÌ®[]e“ãËÎ™Â4öf¹©xÚ:—“,7f}-"Œqû-f©˜Öx�°’oñ`ó…[ƒ="" ]®34Âæä‹t®k�½®wªÊ®«il,¦‰Ì<#2*h2—h+Š�+ÙÌ<þ&,][«y¢="" wøÊ¶Äm^´¾vc“‹yÑ1ù_{¤="" �ÛÜ5Òe›Ò¸‘í¬µÂx¼Ž…Ê¹Í]º·ÁÖ§¨?ÖÝõµs›»t="" –7Íä22?É`™ŸfÎ›ÖÛåúõÆõ‹w®’oœà<ó«$‹wžùiäfæ‡rÂ|ã:‰2ÿ£Ìw×i¨áœ jí="" ed~(·qrúsd¹ÆÞmyølÏ•="" vhþü…y’ÿÈsoigæc_õÃ<�xe|Ér—ŸŠö\nf]ÉŽ“åbø�yv ¾yb`jÑ™ƒß?1ðÇ_cv¾eŠ="" ”ù‚o¼c="">Þ�ßš)F~úñW�Î&lt;ÀÓ“±e8¬íô(;aÕÀ&lt;`ëüâ&lt;užzïùLNêƒš˜ûé2œ÷Ü¥ûXó€óž»tSÍë]nœÂQéh±á<niäü°]nˆÖ›ýÛå"ì½çeŠÆž¥ªz€Êioß°cÛãl{g3�ÓËyv—|ºÎ­ – ú®(yøt¿,¬1z|²öoÔÏzîµÅ¤å*ë€ê!!>dâ'!ªL«u‡…</niäü°]nˆö›ýûå"ì½çešæž¥ªz€êioß°cûãl{g3�óëyv—|ºî­ – ú®(yøt¿,¬1z|²öoôïzîµå¤å*ë€ê!!></fcþ€ã³m˜></kšxæ³8…></fä™sâ¥ôs></vwöžð„\~"šy¤u¢9¶��ìäð¨œ„)¤„ó«ù€></s«u5lë™�ƒìœ`�ûïíê(}0f�ípæ¡õ5¸ñå°ðÿú0â¦></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf">https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf</a></em></p>]]>
            </description>
            <link>https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812118</guid>
            <pubDate>Sun, 12 Jul 2020 15:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WireGuard as VPN Server on Kubernetes with AdBlocking]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23812063">thread link</a>) | @coding_coffee
<br/>
July 12, 2020 | https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/ | <a href="https://web.archive.org/web/*/https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Lets be frank, the Internet is simply unusable with all the ads floating around.</p><p>I use the <a href="https://github.com/gorhill/uBlock" target="_blank" rel="noopener">uBlock Origin</a> extension in my browser, as do most of the people reading this genre of articles, but the same is not true for the majority of the population, including other members of my family. So in order to enhance their web browsing experience I decided to block ads at the DNS level.</p><p>But why stop there I thought, why not also improve their privacy while I'm at it. So I also decided to setup a VPN. Now let me clarify some things here, I'm not a big fan of VPNs, the way they're advertised by the big companies, here's a <a href="https://www.youtube.com/watch?v=WVDQEoe6ZWY" target="_blank" rel="noopener">great video by Tom Scott</a> explaining what I mean. But they also have their use cases, some of which are:</p><ul><li>Prohibiting ISPs from collecting data on my browsing patterns</li><li>Circumvent internet censorship</li><li>Connect to my home network from anywhere</li></ul><p>I took a look at apps like <a href="https://blokada.org/" target="_blank" rel="noopener">Blokada</a> and <a href="https://github.com/julian-klode/dns66" target="_blank" rel="noopener">DNS66</a> which grant you device wide ad blocking on mobile devices. On Android <a href="https://block.blokada.org/post/2018/06/17/how-does-blokada-work" target="_blank" rel="noopener">the way this works is</a>, by creating an internal VPN on the phone, so that all traffic from the device can be routed via it, and it has a file with all the blacklisted domains, to filter out traffic.</p><p>But there's a caveat with this approach. I cannot use another VPN to route my traffic, due to an Android <a href="https://developer.android.com/reference/android/net/VpnService" target="_blank" rel="noopener">limitation</a>.</p><blockquote><p>There can be only one VPN connection running at the same time. The existing interface is deactivated when a new one is created.</p></blockquote><p>This means my browsing patterns are still accessible to my ISP. So, I started looking for ad blocking DNS servers, so that I could point Android's global DNS to it. I found <a href="https://adguard.com/" target="_blank" rel="noopener">AdGuard</a> and <a href="https://pi-hole.net/" target="_blank" rel="noopener">PiHole</a> to be the top projects. Hosting these at home, on Raspberry Pi seemed like a plausible solution, but then again one can't use it while traveling. The solution is to obviously host it on a publicly accessible server. Amongst the two I found AdGuard more appealing due to the following reasons</p><ul><li>It has out of the box support for DNS-over-TLS</li><li>It maintains a single file for its entire configuration</li><li>It's written in Golang, and is much lighter on resources compared to PiHole</li></ul><p>You can find more about their differences <a href="https://github.com/AdguardTeam/AdGuardHome#how-does-adguard-home-compare-to-pi-hole" target="_blank" rel="noopener">here</a>. Both are great projects, but AdGuard met my requirements perfectly.</p><p>When it comes to VPN, I did not even consider using OpenVPN, <a href="https://www.wireguard.com/" target="_blank" rel="noopener">WireGuard</a> was the obvious choice, because of it's speed, smaller, easily auditable codebase (not that I was going to audit it, but still), cross platform compatibility and integration into the Linux Kernel.</p><p>Being a big fan of Kubernetes and maintaining infrastructure as code, I wanted a way to be able to easily deploy and version control my deployment. After much searching I stumbled upon, <a href="https://github.com/squat/kilo" target="_blank" rel="noopener">kilo</a>, a network overlay built on WireGuard for Kubernetes. It could do exactly what I wanted, while also enhancing the security of my cluster, by encrypting the inter pod communication, and allowing me to build secure clusters, over nodes spanning multiple cloud providers. Also it would give me the added benefit of easily debugging applications deployed on my Kubernetes Cluster, since when connected I would be a peer on the network, thereby getting access to the all the private IPs of the deployments, services etc. You can watch <a href="https://www.youtube.com/watch?v=iPz_DAOOCKA" target="_blank" rel="noopener">this talk by Lucas Servén Marín</a> to know more.</p><p>Without further ado, let's jump right into the setup. I'll be explaining the steps for setting it up on a <a href="https://k3s.io/" target="_blank" rel="noopener">k3s</a> cluster. You may need to modify them as per your cluster. After deploying k3s, the 1st thing which needs to be done is to setup kilo. First download the <a href="https://raw.githubusercontent.com/squat/kilo/master/manifests/kilo-k3s.yaml" target="_blank" rel="noopener">manifest</a> for kilo on k3s.</p><pre><code>curl -LO https://raw.githubusercontent.com/squat/kilo/master/manifests/kilo-k3s.yaml
</code></pre><p>Now you need to modify and add <code>- --mesh-granularity=full</code> to the <code>DaemonSet</code> section under the <code>args</code> for the <code>kilo</code> container.</p><pre><code>...
containers:
- name: kilo
  image: squat/kilo
  args:
  - --kubeconfig=/etc/kubernetes/kubeconfig
  - --hostname=$(NODE_NAME)
  - --mesh-granularity=full
  env:
  - name: NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
...
</code></pre><p>This is done to ensure all our nodes are meshed together regardless of the datacenter. Then simply apply the manifest.</p><pre><code>kubectl apply -f kilo-k3s.yaml
</code></pre><p>This will later be useful for setting up WireGuard VPN. More on this later. Now we can proceed to setup AdGuard. Here is the spec for AdGuard.</p><pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: adguardhome
spec:
  selector:
    matchLabels:
      app: adguardhome
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 0
  template:
    metadata:
      labels:
        app: adguardhome
    spec:
      volumes:
        - name: tls-cert-secret
          secret:
            secretName: production-tls-cert
        - name: adguard-config
          hostPath:
            path: "/path/to/store/conf"
            type: DirectoryOrCreate
        - name: adguard-logs
          hostPath:
            path: "/path/to/store/work"
            type: DirectoryOrCreate

      containers:
        - name: adguardhome
          image: adguard/adguardhome:v0.102.0
          ports:
            # Regular DNS Port
            - containerPort: 53
              hostPort: 53
              protocol: UDP
            - containerPort: 53
              hostPort: 53
              protocol: TCP
            # DNS over TLS
            - containerPort: 853
              hostPort: 853
              protocol: TCP
          volumeMounts:
            - name: tls-cert-secret
              mountPath: /certs
            - name: adguard-config
              mountPath: /opt/adguardhome/conf
            - name: adguard-logs
              mountPath: /opt/adguardhome/work

      terminationGracePeriodSeconds: 20

---

apiVersion: v1
kind: Service
metadata:
  name: adguardhome
  labels:
    app: adguardhome
spec:
  type: ClusterIP
  selector:
    app: adguardhome
  ports:
  - port: 80
    # targetPort: 3000
    targetPort: 80
    protocol: TCP

</code></pre><p>The <code>RollingUpdate</code> is intentionally configured to not wait till a new pod is up, and directly terminate the existing pod during deploys. On the surface it seems like an anti-pattern, but since I'm using the <code>hostPort</code> directive, a new Pod wouldn't get scheduled unless port <code>53</code> was available on the host for it to bind to, so the existing Pod has to terminate before a new Pod can be deployed.</p><p>Also I initially intended to use a <code>ConfigMap</code> for holding the <code>AdGuardHome.yml</code>, but there was some issue with AdGuard trying to write to it while initally comming up, but since <code>ConfigMap</code>'s are moundted as <code>ReadOnly</code>, Pod creation used to fail, so I decided to go with a Volume instead, until I could figure out the issue.</p><p>For the initial setup, the AdGuard admin UI will be accessible on port 3000, so you'll have to switch the <code>targetPort</code> to <code>3000</code> in the <code>adguardhome</code> service initially, access the admin UI, setup the password, and then revert the <code>targetPort</code> to <code>80</code>.</p><p>You may also enable <code>DNSSEC</code> under <code>DNS Settings</code> for guaranteeing authenticity of DNS responses by signing them, and making tampering detectable.</p><p>The volume mounts for <code>tls-cert-secret</code> are only necessary if you want to enable DNS-over-TLS. And you need to configure your ingress resource before mounting it here.</p><p>For enabling DNS-over-TLS, on the AdGuard admin UI you can goto <code>Encryption Settings</code> -&gt; <code>Enable Encryption</code>, and put in the Certificate path as <code>/certs/tls.crt</code> and the Key path as <code>/certs/tls.key</code>. Again let me re-iterate that your Ingress resource needs to be configured properly and you need to have a valid TLS certificate for the domain you're hosting AdGuard on.</p><p>On Android phones for Android Pie and later, you may goto <code>Settings</code> -&gt; <code>WiFi and Internet</code> -&gt; <code>Private DNS</code>. Select <code>Private DNS Hostname Provider</code> and set it to the domain name to the once you've configured on. You may also configure it on your home router to ensure all the devices get DNS level Ad Blocking.</p><p>This concludes the AdGuard part of the setup.</p><hr><p>Now coming to setting up WireGuard.</p><p>I'll be referring to the k3s cluster as the server and the local laptop as the client from here on.</p><p>You'll need WireGaurd installed on both your server and client machine. Follow the <a href="https://www.wireguard.com/install" target="_blank" rel="noopener">steps as per your distribution</a> to install the same. If you're using a bleeding edge distro like Archlinux or Gentoo, you don't need to do anything on the server side, since WireGuard is already baked into the kernel at this point. On the client side however you'll need to install it for getting the command line client to enable / disable the interface.</p><p>Another useful tool to have on the client side is <code>kgctl</code>. You can install it using</p><pre><code>go get github.com/squat/kilo/cmd/kgctl
</code></pre><p>Now we need to create a private and a public key pair on the client.</p><pre><code>wg genkey | tee privatekey | wg pubkey &gt; publickey
</code></pre><p>This'll create 2 files with the respective key contents. This key pair needs to be authorized on the server. You can do this simply by creating a peer resource. Create a file named <code>archie.yaml</code></p><pre><code>apiVersion: kilo.squat.ai/v1alpha1
kind: Peer
metadata:
  name: archie
spec:
  allowedIPs:
  - 10.120.120.1/32 # This is just and example, you can use any valid available CIDR here
  publicKey: CLIENT_PUBLIC_KEY # Enter the public key here, the one you just generated
  persistentKeepalive: 10
</code></pre><p>Finally apply the manifest</p><pre><code>kubectl apply -f archie.yaml
</code></pre><p>Remember, the <code>allowedIPs</code> should be a valid CIDR, which is available on both the server and the client. Now we can use the <code>kgctl</code> tool to generate the <code>peer</code> section of the client WireGuard config.</p><pre><code>kgctl showconf peer archie
</code></pre><p>This will return something like</p><pre><code>[Peer]
AllowedIPs = 10.42.0.0/24, 10.42.0.0/32, 10.4.0.1/32
Endpoint = YOUR_SERVER_IP:51820
PersistentKeepalive = 10
PublicKey = SERVER_PUBLIC_KEY
</code></pre><p>Create a file on the client named <code>adgaurd.yaml</code> at the location <code>/etc/wireguard</code> and add the following contents to it</p><pre><code>[Interface]
Address = 10.120.120.1/32 # Use the same CIDR whitelisted in the Peer manifest
PrivateKey = CLIENT_PRIVATE_KEY # The one you generated above on your client
DNS = YOUR_SERVER_IP # Enter the IP of the server to block ads, FQDN don't work on Android for some reason

[Peer]</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/">https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/</a></em></p>]]>
            </description>
            <link>https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812063</guid>
            <pubDate>Sun, 12 Jul 2020 15:29:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla Starts Petition to Oppose the Earn IT Act]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23811935">thread link</a>) | @Fjolsvith
<br/>
July 12, 2020 | https://darkrebel.net/mozilla-starts-petition-to-oppose-the-earn-it-act | <a href="https://web.archive.org/web/*/https://darkrebel.net/mozilla-starts-petition-to-oppose-the-earn-it-act">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                            <h2>
                                In March of this year, the U.S. Senate introduced a bill called the Eliminating Abusive and Rampant Neglect of Internet Technologies Act (EARN IT Act)...                            </h2>
                        </p><div>
                        <p><span>In March of this year, the U.S. Senate introduced a bill called the Eliminating Abusive and Rampant Neglect of Interactive Technologies Act (<a href="https://www.congress.gov/bill/116th-congress/senate-bill/3398/text">EARN IT Act</a>), which, like similar bills in the past, gives law enforcement agencies and other members of government near unlimited access to citizens' personal data.</span></p>
<p><span>Those who understand encryption realize that it is responsible for protecting things like financial and health data, but this seems to slip through the cracks when the anti-encryption discussion comes up in congressional debates. As a result, the Mozilla Foundation has started a petition for ordinary citizens to dispute the EARN IT Act, which can be signed at <a href="https://foundation.mozilla.org/en/campaigns/oppose-earn-it-act/">Mozilla Foundation - Oppose the EARN IT Act</a>.</span></p>

<p><img src="https://darkrebel.net/uploads/images/2020/07/image_750x_5eff1b2722e6d.jpg" alt=""></p>
<p><span>This petition is part of a larger campaign for, as Mozilla calls it, a "healthy internet." Other issues that Mozilla encompasses in this campaign are privacy on video calling apps (like Zoom), misinformation regarding the COVID-19 pandemic, and data collection by a number of IoT devices (watches, phones, gaming consoles, etc.).</span></p>
                    </div></div>]]>
            </description>
            <link>https://darkrebel.net/mozilla-starts-petition-to-oppose-the-earn-it-act</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811935</guid>
            <pubDate>Sun, 12 Jul 2020 15:09:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Fix Twitter, and Hopefully American Discourse Too]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811714">thread link</a>) | @jfeiwell
<br/>
July 12, 2020 | https://jfeiwell.com/essays/2020/07/12/fix-twitter.html | <a href="https://web.archive.org/web/*/https://jfeiwell.com/essays/2020/07/12/fix-twitter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://jfeiwell.com/Folders/Essays.html">⇠ Essays</a>


<h3>In order to make Twitter a more productive and engaging forum for public discourse, substantial changes need to be made to the productâ€™s core architecture and user policy</h3>

<p>When I first joined Twitter in 2012, it was a great place to be. A lot of my friends were there, cracking jokes and posting pictures with yfrog while hoping the fail whale didnâ€™t ruin the fun. I recall that the company was pitching Twitter as a â€œpublic agoraâ€�, which made sense but wasnâ€™t an accurate reflection at that time. Really, it was juxtaposed against Facebook as a better social network.</p>

<p>Now that Twitter <em>is</em> the public agora, its functionality defines the rules of engagement for public debate, and those rules allow for chaos and massacre. Twitterâ€™s current functionality gravely endangers the future of the Republic. If they do not take it upon themselves to act now, they will be responsible for the American equivalent of moving the capital from St. Petersburg to Moscow.</p>

<p>I know that sounds a little alarmist, because it is. However, Twitter can take a few steps to reverse their role in warehousing division and hate. As well as the mental health crisis that is outrage. â€œThe medium is the messageâ€� has become trite, but Mcluhanâ€™s point remains - Twitter needs to alter the medium before Americans succumb to the message. Here are a few ideas to do so:</p>

<ul>
	<li>Federate Twitter</li>
	<li>Hide Likes</li>
	<li>Reform the Quote Tweet</li>
	<li>Sentiment Analysis, Higher Quality &amp; Lower Speed</li>
	<li>Tweet Wrapper =&gt; Thread</li>
	<li>Clean Up Usernames</li>
</ul>

<h2 id="federate-twitter">Federate Twitter</h2>
<p>The most audacious ask. People already use terms like â€œbaseball Twitterâ€� or â€œVC Twitterâ€� as if they were clearly federated channels - why not actually do that?</p>

<p>Donâ€™t get me wrong, the aggregation of all my interests into one feed is amazing (and why no one visits news sites anymore), but in practice the intended effect hardly occurs. Usually my feed is plagued with the story of the day as if Iâ€™m turning on cable news.</p>

<p>Yes, itâ€™s possible to tune it out sometimes, but that comes at the expense of missing out on other great content. I donâ€™t want to follow Brian Koppelman or Buster Olney for their political takes, even if I agree with them 100%, I want to learn about storytelling and get updates on baseball.</p>

<p><strong>Deescalating</strong> the politicization of <em>everything</em>, and reducing the speed at which takes come flying through the Twittersphere, will turn down the temperature and volume while providing for deeper engagement.</p>

<p>The way to do this would be to require users to tag the vertical(s) they want to post in before posting. <strong>The follower would then see the tweet only if they follow both the person and the vertical.</strong> Users would be able to follow all of someoneâ€™s tweets if they want, but it would require one extra step - as the default follow functionality would result in only seeing the nexus of that personâ€™s tweets and your follow tags.</p>

<p>Users would still be able to tweet without specific channels tagged. Only followers selecting all tweets or just personal (non-vertical) tweets would see them.</p>

<p>In terms of defining verticals, Twitter can do most of the leg work - defining the official taxonomy with layups like Football &gt; NFL &gt; Cleveland Browns. And with multiple entry points like Tech / Money / Cryptography &gt; Cryptocurrencies &gt; Bitcoin. There are easily thousands that can be defined (Topics is a far cry from what could be). Then figure out how to allow users to define new categories, maybe put the blue check to good use!</p>

<p>The upshot? <strong>This would also be a great business decision.</strong> Twitterâ€™s Q1 2020 CPM was $4.97. If they were to fully embrace contextual advertising, leveraging their first-party data as well, they could own a burgeoning segment of the digital ad market and raise their avg CPM well into double digits. Think about it, has a Twitter ad ever actually made an impact on you? Contextual is the natural response to the death of the cookie, most competition in this space wonâ€™t have the first party data nor the free inventory.</p>

<h2 id="hide-likes">Hide Likes</h2>
<p>Make likes only visible to both the liker and likee. Twitter is optimized for virtue signalling, period. Weâ€™ve all read how tribal Twitter is, well this single feature is the forcing function of that tribalism in every last vertical.</p>

<p>By making likes private, Twitter can still use the signal to optimize the home feed algo. In fact this will provide a much richer signal as the likes become a more honest indication of someoneâ€™s opinions, while preserving the personal satisfaction (dopamine) users get from likes. Iâ€™d wager this would make engagement go <em>up</em>!</p>

<p>What about the ability to scan someone elseâ€™s likes? Maybe this is where a new Quote Tweet comes in. A separate feed created by users that allows them to syndicate tweets without the full endorsement of a Retweet or the aforementioned problems of a like. No footprint on the tweet object itself.</p>

<h2 id="reform-the-quote-tweet">Reform the Quote Tweet</h2>
<p>On April, 6 2015 the Quote Tweet was born. I do not believe it an accident that, at least anecdotally, the culture of outrage and personal attack has grown exponentially on Twitter in the last 5 years. â€œDunkingâ€� on someone seems to be the primary use of the Quote Tweet feature, and so many of the viral outrage tweets are in the form of the Quote Tweet.</p>

<p>Now, users were hacking this together before it happened so itâ€™s obviously a popular feature. It makes sense; syndicating information is the primary purpose of Twitter - whether thatâ€™s from your brain or another source, everyoneâ€™s just a router. But the madness must stop.</p>

<p><b>Solutions</b></p>
<p>Add permissions on any tweet that gets Quote Tweeted:</p>
<ul>
	<li>If a user comes by my tweet via a Quote Tweet, allow me to block them from viewing my  tweet via the Quote Tweet</li>
	<li>Allow me to set max absolute Quote Tweets or max Retweet of a subsequent Quote Tweet</li>
	<li>Allow me to disable Quote Tweets all together</li>
</ul>

<p>OR, drum roll pleaseâ€¦ <em>edit button</em>! It would solve so much. Then add a versionsioning system to allow the original to be preserved.</p>

<p>Federation will actually solve this, but without it, these solutions are necessary.</p>

<h2 id="sentiment-analysis-higher-quality--lower-speed">Sentiment Analysis, Higher Quality &amp; Lower Speed</h2>
<p>One of the questions raised by the federation idea is, what happens to generally public features like Trends? Twitter as a resource for breaking news canâ€™t be disputed at this point; that functionality must be preserved and strengthened. But the current set up just aint it.</p>

<p>Here are two tweets taken from two recent trends, â€˜Susan Collinsâ€™ and â€˜Nancy Pelosiâ€™ respectively.</p>

<blockquote><div lang="en" dir="ltr"><p>F*ck Trump<br>F*ck Barr<br>F*ck Lindsey Graham<br>F*ck Mitch McConnell<br>F*ck Susan Collins<br>F*ck Ted Cruz<br>F*ck John Cornyn<br>F*ck Tom Cotton<br>F*ck Cory Gardner<br>F*ck Chuck Grassley<br>F*ck John Kennedy<br>F*ck Matt Gaetz<br>F*ck Jim Jordan<br>F*ck Kelly Loeffler<br>F*ck Rand Paul</p><p>F*CK THE ENTIRE GOP <a href="https://t.co/PR0KyoE5K8">pic.twitter.com/PR0KyoE5K8</a></p></div>— JosÃ© (@yoruguaenusa) <a href="https://twitter.com/yoruguaenusa/status/1281774758967889921?ref_src=twsrc%5Etfw">July 11, 2020</a></blockquote>


<blockquote><p lang="en" dir="ltr">â�¦<a href="https://twitter.com/JoeBiden?ref_src=twsrc%5Etfw">@JoeBiden</a>â�© â�¦<a href="https://twitter.com/SpeakerPelosi?ref_src=twsrc%5Etfw">@SpeakerPelosi</a>â�© Sums it well <a href="https://t.co/OnsAyce9Mp">https://t.co/OnsAyce9Mp</a></p>— nicole (@nicole47877716) <a href="https://twitter.com/nicole47877716/status/1281977304567222274?ref_src=twsrc%5Etfw">July 11, 2020</a></blockquote>


<p>Both of these were less than 20 tweets into the â€œTopâ€� section that is ostensibly a filter of quality compared to the â€œLatestâ€� option. Twitter has to stop this type of hyperbolic outrage, and nonsensical filler. Those tweets are of no value to anyone (not to mention, inciting violence?).</p>

<p>If those same accounts wanted to make reasoned and informed arguments against those politicians, by all means. Even if the arguments are far outside the Overton window, so long as they are thoughtful they should be surfaced equally.</p>

<p>Sentiment analysis, scoring primarily thoughtfulness, can raise the quality bar. Modern advances in NLP should make this not only possible but possible to do well.</p>

<p>Secondly, sentiment analysis should be used to grade tweets that begin to go viral. Auto-braking tweets at certain Retweet and reply counts could be detrimental when serious breaking news occurs, so that will have to be a consideration. But scoring the sentiment to make sure itâ€™s not vitriolic outrage based in emotion could lower the speed of hate and reduce the collective blood pressure.</p>

<p>As a general rule of thumb, the <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy effect</a> should be the governing principle. If you cap Retweets and replies in absolute numbers or by sentiment, and the content is actually good enough, it will continue to rise to the top over time.</p>

<h2 id="tweet-wrapper--thread">Tweet Wrapper =&gt; Thread</h2>
<p>Threads are awesome, but thereâ€™s a reason services like unroll exist. Reading a thread interrupted by the username, picture, etc. every 280 characters is taxing. Secondly, syndication of a tweet in a thread can lose all context.</p>

<p><b>Solution</b></p>

<p>Convert the thread into a single object segmented by 280 character fields, separated either by nothing or slightly darker/lighter backgrounds. The reader sees breaks every 280 characters like normal, but itâ€™s much cleaner and more importantly - will convey a sense of coherence. The world is an incredibly nuanced place. Discourse in 280 characters is not.</p>

<p>The user can then choose which tweet in the thread serves as a wrapper. And/or when Retweeted, that user can choose which tweet will serve as the wrapper. The wrapper is more or less a headline - when the user clicks on the wrapper tweet, they move to the seamless thread.</p>

<p>This solution has the additional benefit of synchronizing replies onto a single thread object.</p>

<h2 id="clean-up-usernames">Clean Up Usernames</h2>
<p>So much of the nonsensical outrage comes from usernames like â€˜jack09324189â€™. The username from the Pelosi example above is â€˜nicole47877716â€™, and the account is following 5 people with one follower.</p>

<p>Iâ€™m against a strict real name policy - but Twitter can also make a constitutive choice that bifurcates users into real names and pseudonyms. If youâ€™re going to use a real name - great, you must have a real profile. If you want to be anonymous - great, you must set up a truly pseudonymous account. The strangle between the two is what accounts for most of the filler in replies.</p>

<p>Facebook is obviously a bit draconian with their policy, <em>but at least they have one</em>. If Twitter is to be …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jfeiwell.com/essays/2020/07/12/fix-twitter.html">https://jfeiwell.com/essays/2020/07/12/fix-twitter.html</a></em></p>]]>
            </description>
            <link>https://jfeiwell.com/essays/2020/07/12/fix-twitter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811714</guid>
            <pubDate>Sun, 12 Jul 2020 14:44:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Crsh – A JavaScript based command line shell]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23811673">thread link</a>) | @_carl_jung
<br/>
July 12, 2020 | https://crwi.uk/2020/07/12/crsh.html | <a href="https://web.archive.org/web/*/https://crwi.uk/2020/07/12/crsh.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      


<h2>Introducing crsh: a Javascript based command line shell</h2>
<p>12 July 2020</p>
<p>TL;DR: <a href="https://github.com/curlywurlycraig/crsh">GitHub link -&gt; Install instructions</a></p>

<hr>

<p>Existing shells generally operate with their own somewhat archaic syntax,
continuous with the underlying operating system and set of historical design choices.</p>

<p>This puts the majority of shell syntax just out of reach for a very large subset of command line users who use the command line for little more than launching one or two command line tools, navigating directories, and maybe ocassionally piping commands or outputting them to files. These users will usually write scripts in a language more familiar to them as soon as things get a little trickier (because the value of learning the control flow syntax in <code>bash</code>, <code>zsh</code>, or <code>fish</code> does not seem like time well spent).</p>

<p>This is not a criticism of those shells, exactly. But it does highlight a potential space for new shells that can better fulfill the needs of these users. Conversely, if you are an experienced bash shell scripter, and terms like “file descriptors” and <code>SIGCHLD</code> mean something to you, you will probably dislike my approach here. But please feel free to stick around and provide some advice.</p>

<h2 id="enter-crsh">Enter crsh</h2>

<p>I’ve started work on a shell that can seamlessly interoperate Javascript syntax (and in fact works by <code>eval</code>ing JS in the Deno runtime) and traditional shell execution.</p>

<p>Regular command execution will be familiar to those who have used the command line:</p>

<div><div><pre><code>$ ls | grep .js
builtins.js
dsh.js
functions.js
</code></pre></div></div>

<p>And inline anonymous functions will be familiar to those who have used Javascript:</p>

<div><div><pre><code><span>$</span> <span>()</span> <span>=&gt;</span> <span>"Hello world!"</span>
<span>Hello</span> <span>world</span><span>!</span>
</code></pre></div></div>

<p>Returning a list from an inline function will be outputted as separate lines:</p>

<div><div><pre><code><span>$</span> <span>()</span> <span>=&gt;</span> <span>new</span> <span>Array</span><span>(</span><span>5</span><span>).</span><span>fill</span><span>().</span><span>map</span><span>((</span><span>line</span><span>,</span> <span>index</span><span>)</span> <span>=&gt;</span> <span>`Line </span><span>${</span><span>index</span><span>}</span><span>`</span><span>)</span>
<span>Line</span> <span>0</span>
<span>Line</span> <span>1</span>
<span>Line</span> <span>2</span>
<span>Line</span> <span>3</span>
<span>Line</span> <span>4</span>
</code></pre></div></div>

<p>Combining these concepts can yield a very expressive shell:</p>

<div><div><pre><code><span>$</span> <span>ls</span> <span>|</span> <span>({</span> <span>lines</span> <span>})</span> <span>=&gt;</span> <span>lines</span><span>.</span><span>map</span><span>((</span><span>line</span><span>,</span> <span>index</span><span>)</span> <span>=&gt;</span> <span>`line </span><span>${</span><span>index</span><span>}</span><span>: </span><span>${</span><span>line</span><span>}</span><span>`</span><span>)</span> <span>|</span> <span>grep</span> <span>line</span> <span>3</span>
<span>line</span> <span>3</span><span>:</span> <span>functions</span><span>.</span><span>js</span>
</code></pre></div></div>

<p>Note in the above that <code>lines</code> is made available to piped inline functions.
JSON output piped into an inline function is automatically parsed and made available as a <code>json</code> parameter:</p>

<div><div><pre><code>$ curl https://ghibliapi.herokuapp.com/films/58611129-2dbc-4a81-a72f-77ddfc1b1b49 | ({ json }) =&gt; json.title
My Neighbor Totoro
</code></pre></div></div>

<p>As can be seen, such a shell lends itself very well to parsing JSON (it is <em>Javascript</em> Object Notation after all).</p>

<p>To go one step further in this example, we can navigate multi-request JSON API calls in a human-readable way:</p>

<div><div><pre><code><span>$</span> <span>curl</span> <span>https</span><span>:</span><span>//ghibliapi.herokuapp.com/films/ | ({ json }) =&gt; json[0].people | xargs curl | ({ json }) =&gt; json[0].name</span>
</code></pre></div></div>

<p>While the above may look less readable than something like <code>jq</code>, those with a Javascript background will appreciate the transferability of knowledge. Even without such a background, the advantage of executing arbitrary logic inline with other shell calls in a modern language should be apparent.</p>

<h2 id="configuration">Configuration</h2>

<p>Currently, the easy parts to configure are the prompt and auto-completion rules. This is done by way of editing the JS source directly. The prompt is specified as a function which returns a string, and exported from a <code>prompt.js</code> file like so:</p>

<div><div><pre><code><span>import</span> <span>{</span> <span>magenta</span><span>,</span> <span>stripColor</span> <span>}</span> <span>from</span> <span>"https://deno.land/std/fmt/colors.ts"</span><span>;</span>

<span>export</span> <span>const</span> <span>prompt</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>currentDir</span> <span>=</span> <span>magenta</span><span>(</span><span>Deno</span><span>.</span><span>cwd</span><span>());</span>
  <span>return</span> <span>`</span><span>${</span><span>currentDir</span><span>}</span><span> › `</span><span>;</span>
<span>};</span>

<span>export</span> <span>const</span> <span>promptLength</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>stripColor</span><span>(</span><span>prompt</span><span>()).</span><span>length</span><span>;</span>
</code></pre></div></div>

<p>And the auto-completion rules are specified as a list of objects representing the regex to match the input on, and the logic to return the list of completion to cycle through:</p>

<div><div><pre><code><span>const</span> <span>gitRules</span> <span>=</span> <span>[</span>
  <span>{</span>
    <span>match</span><span>:</span> <span>/^git add /</span><span>,</span>
    <span>complete</span><span>:</span> <span>completeFile</span><span>,</span>
  <span>},</span>
  <span>{</span>
    <span>match</span><span>:</span> <span>/^git checkout /</span><span>,</span>
    <span>complete</span><span>:</span> <span>completeBranches</span><span>,</span>
  <span>},</span>
  <span>{</span>
    <span>match</span><span>:</span> <span>/^git branch -D /</span><span>,</span>
    <span>complete</span><span>:</span> <span>completeBranches</span><span>,</span>
  <span>},</span>
  <span>{</span>
    <span>match</span><span>:</span> <span>/^git /</span><span>,</span>
    <span>complete</span><span>:</span> <span>completeCommands</span>
<span>];</span>
</code></pre></div></div>

<p>Community-made auto-completion rules and prompts could be hosted in the usual <a href="https://deno.land/x">Deno way</a>.</p>

<h2 id="future-work">Future work</h2>

<p>There is still a lot to do to make this better. Bug fixes, features like multiline support, persisting history, etc. Any feedback is welcome in the form of issues in the GitHub repo.</p>




    </div></div>]]>
            </description>
            <link>https://crwi.uk/2020/07/12/crsh.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811673</guid>
            <pubDate>Sun, 12 Jul 2020 14:40:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Online Identity Is Decentralized]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 191 (<a href="https://news.ycombinator.com/item?id=23811568">thread link</a>) | @Yolta
<br/>
July 12, 2020 | https://yarmo.eu/post/future-online-identity-decentralized | <a href="https://web.archive.org/web/*/https://yarmo.eu/post/future-online-identity-decentralized">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Online identity</h2>
<p><a href="https://en.wikipedia.org/wiki/Online_identity">Online&nbsp;identity</a> refers to the concept of "being" in the digital world. As an internet user, you exist. You create accounts on websites. You write on social media and blogs. You post photos. All this online activity has in common that one and the same person performed these actions; it defines your "online&nbsp;identity".</p>
<p>However, your "online&nbsp;identity" is not <em>per se</em> representative of your "social&nbsp;identity" in the physical world.</p>
<p>You may choose to use your own name or a pseudonym. You may choose to publish personally identifiable information or not. You may choose to remain truthful to your social identity or deceive. In short, you may choose for authenticity or for anonymity.</p>
<h2>Authenticity versus anonymity</h2>
<p>Authenticity and anonymity aren't mutually exclusive and that is the beauty of the internet. In the physical realm, you are (mostly) limited to a single social identity. In the digital space, there are no such restrictions. While you can't embody multiple persons in the offline world, you can have several identities online. In fact, you can even have multiple accounts on the same platform, opting for a different balance between authenticity and anonymity for each one of them.</p>
<p>The anonymity has its downsides, creating psychological artifacts like <a href="https://en.wikipedia.org/wiki/Online_disinhibition_effect">online&nbsp;disinhibition</a> and facilitating <a href="https://en.wikipedia.org/wiki/Cyberbullying">cyberharassment</a>. However, even though we are far from completely overcoming these challenges, the internet that allows us to remain anonymous is still the one we should want and fight for.</p>
<h2>Consolidation of identity and internet corporations</h2>
<p>Removing the possibility for anonymity could solve the problem of online toxicity. Large internet corporations like Google and Facebook allow all to create an account on condition that some personally identifiable information is revealed, usually a phone number.</p>
<p>The benefit is that it deters most from repeatably creating new accounts when older accounts have been flagged or banned due to improper behavior. These companies gain the function of "identity provider": they manage your online identity that can be used to login in different locations of the internet. We all know many websites that offer a "Google login" or "Facebook login".</p>
<p>But there is a problem: handling the entire online identity of a single person is too much responsibility for any corporation or organization, especially if it is in their interest to gain intimate individual knowledge and sell it (Google) or use it to manipulate moods and influence decision making (Facebook).</p>
<p>That phone number that was once used to prevent online toxicity is now the first of many pieces of personally identifiable information that these corporations will seek and use to figure out who you are.</p>
<p>"You have nothing to hide"? Great. The internet corporations will still make money hand over fist by selling your personality, your preferences, your buying patterns and your vote. And not just yours. That of entire populations.</p>
<p>Know that profits are just the tip of the iceberg. Governments all around the world are also interested in knowing what their citizens think, say and do for very different motives.</p>
<h2>Going decentralized</h2>
<p>The solution is relatively simple. When you create a new account and get to choose between "Google&nbsp;login", "Facebook&nbsp;login" and "Email&nbsp;login", pick "Email&nbsp;login".</p>
<p>The benefit of not giving away any more personal data and tracking possibilities outweigh the inconvenience of having to fill in your email address and a password, especially when using a password manager. As tempting as the alternative is, making these changes will improve your life and ultimately, when enough people join these efforts, that of the world population.</p>
<p>A different problem arises: how to prove online identity when decentralized?</p>
<h2>Decentralized online identity</h2>
<p>When you are no longer relying on an identity provider to manage your entire online identity, you lose the one common thing all your accounts on different platforms had: if two accounts on different online platforms are created by the same Google or Facebook account, we can safely assume they belong to the same person.</p>
<p>But this "trust by proxy" is lost when the accounts on those platforms were created without identity provider. And whether authentic or anonymous, it can sometimes be extremely useful to know and trust that separate accounts on the internet belong to the same person, even when not knowing who this person is.</p>
<p>The username is not sufficient to identify accounts across platforms. If you are "Alice" on one website, chances are you might need to be "Alice123" on the next one. And what if someone close to you is contacted by an "Aliss" requesting an amount of money to be transferred because they believe you to be in some sort of trouble? A poor attempt at impersonation, I know… Don't worry, a real bad actor will put in more effort and make a much more convincing act.</p>
<h2>Proving decentralized online identity</h2>
<p>What if not only your online identity is decentralized, but also the tool to prove said online identity? This would mean that you wouldn't need to depend on a single company or entity to prove your identity across platforms. Decentralized identity, decentralized proofs!</p>
<p>Such solutions are already being deployed in industry, for example by firms like <a href="https://indicio.tech/">Indicio.tech</a> which focus on blockchain technology.</p>
<p>Built for individuals, I recently launched <a href="https://keyoxide.org/">Keyoxide</a> which uses cryptographic keypairs to accomplish decentralized identity verification. While it doesn't (and shouldn't!) link an account to a person in the physical realm, it links accounts across platforms.</p>
<p>If you trust an account on one platform, you can trust any other account on any other platform as long as they are both verified by "identity proofs" stored in the same keypair. Whether you choose authenticity or anonymity, decentralized identity proofs allow you to build a cross-platform online identity.</p>
<p>Here's my <a href="https://keyoxide.org/9f0048ac0b23301e1f77e994909f6bd6f80f485d">Keyoxide profile</a>. In this case, I link to several "authentic" accounts but I could easily generate a new keypair void of personal data that links to several anonymous accounts. The accounts don't need to be authentic to create an online persona.</p>
<p>All the accounts listed in the link above belong to me. No one else could claim these accounts. Here's how.</p>
<h2>Identity proofs</h2>
<p>An "identity proof" is nothing more than a link to an account A on some platform P stored inside your keypair K. If a "proof verification tool" such as Keyoxide follows this link and discovers some piece of data linking back to keypair K (which is only possible if keypair K and account A on platform P belong to the same person), the account is verified. If this proof verification is done for several accounts on different platforms, it is beyond reasonable doubt that the same person owns said accounts.</p>
<p>No bad actor could claim one of your accounts: the piece of data that links back is specific to your keypair, not the bad actor's keypair. And the bad actor also couldn't insert a proof inside your keypair as long as your keypair isn't compromised. Only you, the owner of the keypair, can add new proofs. But the entire world can read and verify them.</p>
<p>These identity proofs are decentralized because Keyoxide doesn't store them, your cryptographic keypair does. Keyoxide simply reads the keys and verifies the proofs. When you remove a proof from your keypair, Keyoxide will no longer have access to it. You own your proofs and your online identity.</p>
<p>In fact, the proofs are readable by everyone and are not specifically designed for Keyoxide. Anyone can use any tool or create new ones to verify these proofs and developers are encouraged to enrich this field with additional tools and services. Let's build a decentralized identity ecosystem we can all trust.</p>
<h2>Online identity beyond today's internet</h2>
<p>Initiatives like <a href="https://inrupt.com/solid">Solid</a> by <a href="https://en.wikipedia.org/wiki/Tim_Berners-Lee">Sir Tim Berners-Lee</a> are paving the way for a new internet where all data is owned by the user and shared with platforms with consent and restrictions. This would solve the online identity problem: you get the benefits of a "pseudo centralized" account while maintaining full ownership over all account-related data stored on a decentralized platform. Social media would be allowed to see some data, messaging platforms some other data. But there would still be one single account to rule all the platforms.</p>
<p>On today's internet, the best we can do is make fully separated accounts, link them using technologies like decentralized online identity proofs and create our own online personas, with our own open tools that ensure we maintain ownership over them.</p></div></div>]]>
            </description>
            <link>https://yarmo.eu/post/future-online-identity-decentralized</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811568</guid>
            <pubDate>Sun, 12 Jul 2020 14:30:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust for JavaScript Developers – Pattern Matching and Enums]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23811431">thread link</a>) | @rkwz
<br/>
July 12, 2020 | http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is the fourth part in a series about introducing the Rust language to JavaScript developers. Here are the past chapters:</p>
<ol>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-tooling-ecosystem-overview/">Tooling Ecosystem Overview</a></li>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-variables-and-data-types/">Variables and Data Types</a></li>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/">Functions and Control Flow</a></li>
</ol>
<h2 id="Pattern-Matching"><a href="#Pattern-Matching" title="Pattern Matching"></a>Pattern Matching</h2><p>To understand Pattern Matching, let’s start with something familiar in JavaScript - Switch Case.</p>
<p>Here’s a simple example that uses <code>switch case</code> in JavaScript:</p>
<pre><code><span>function</span> <span>print_color</span><span>(</span>color<span>)</span> <span>{</span>
  <span>switch</span> <span>(</span>color<span>)</span> <span>{</span>
    <span>case</span> <span>"rose"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"roses are red,"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"violet"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"violets are blue,"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>default</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"sugar is sweet, and so are you."</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>print_color</span><span>(</span><span>"rose"</span><span>)</span><span>;</span> 
<span>print_color</span><span>(</span><span>"violet"</span><span>)</span><span>;</span> 
<span>print_color</span><span>(</span><span>"you"</span><span>)</span><span>;</span> </code></pre>
<p>Here’s the equivalent Rust code:</p>
<pre><code><span>fn</span> <span>print_color</span><span>(</span>color<span>:</span> <span>&amp;</span>str<span>)</span> <span>{</span>
  <span>match</span> color <span>{</span>
    <span>"rose"</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"roses are red,"</span><span>)</span><span>,</span>
    <span>"violet"</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"violets are blue,"</span><span>)</span><span>,</span>
    _ <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"sugar is sweet, and so are you."</span><span>)</span><span>,</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>print_color</span><span>(</span><span>"rose"</span><span>)</span><span>;</span> 
  <span>print_color</span><span>(</span><span>"violet"</span><span>)</span><span>;</span> 
  <span>print_color</span><span>(</span><span>"you"</span><span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>Most of the code should be immediately understandable. The <code>match</code> expression has the following signature:</p>
<pre><code><span>match</span> VALUE <span>{</span>
  PATTERN1 <span>=</span><span>&gt;</span> EXPRESSION1<span>,</span>
  PATTERN2 <span>=</span><span>&gt;</span> EXPRESSION2<span>,</span>
  PATTERN3 <span>=</span><span>&gt;</span> EXPRESSION3<span>,</span>
<span>}</span></code></pre>
<p>The fat arrow <code>=&gt;</code> syntax might trip us up because of the similarities with JavaScript arrow functions but they’re unrelated. The last pattern that uses underscore <code>_</code> is called the catchall pattern and is similar to the default case in switch case. Each <code>PATTERN =&gt; EXPRESSION</code> combination is called a <code>match arm</code>.</p>
<p>The above example doesn’t really convey how useful pattern matching is - it just looks like switch case with a different syntax and a fancy name. Let’s talk about destructuring and enums to understand why pattern matching is useful.</p>
<h2 id="Destructuring"><a href="#Destructuring" title="Destructuring"></a>Destructuring</h2><p>Destructuring is the process of extracting the inner fields of an array or struct into separate variables. If you have used destructuring in JavaScript, it is very similar in Rust.</p>
<p>Here’s an example in JavaScript:</p>
<pre><code><span>let</span> rgb <span>=</span> <span>[</span><span>96</span><span>,</span> <span>172</span><span>,</span> <span>57</span><span>]</span><span>;</span>
<span>let</span> <span>[</span>red<span>,</span> green<span>,</span> blue<span>]</span> <span>=</span> rgb<span>;</span>
console<span>.</span><span>log</span><span>(</span>red<span>)</span><span>;</span> 
console<span>.</span><span>log</span><span>(</span>green<span>)</span><span>;</span> 
console<span>.</span><span>log</span><span>(</span>blue<span>)</span><span>;</span> 

<span>let</span> person <span>=</span> <span>{</span> name<span>:</span> <span>"shesh"</span><span>,</span> city<span>:</span> <span>"singapore"</span> <span>}</span><span>;</span>
<span>let</span> <span>{</span> name<span>,</span> city <span>}</span> <span>=</span> person<span>;</span>
console<span>.</span><span>log</span><span>(</span>name<span>)</span><span>;</span> 
console<span>.</span><span>log</span><span>(</span>city<span>)</span><span>;</span> </code></pre>
<p>Here’s the same example in Rust:</p>
<pre><code><span>struct</span> Person <span>{</span>
  name<span>:</span> String<span>,</span>
  city<span>:</span> String<span>,</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> rgb <span>=</span> <span>[</span><span>96</span><span>,</span> <span>172</span><span>,</span> <span>57</span><span>]</span><span>;</span>
  <span>let</span> <span>[</span>red<span>,</span> green<span>,</span> blue<span>]</span> <span>=</span> rgb<span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> red<span>)</span><span>;</span> 
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> green<span>)</span><span>;</span> 
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> blue<span>)</span><span>;</span> 

  <span>let</span> person <span>=</span> Person <span>{</span>
    name<span>:</span> <span>"shesh"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>,</span>
    city<span>:</span> <span>"singapore"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>,</span>
  <span>}</span><span>;</span>
  <span>let</span> Person <span>{</span> name<span>,</span> city <span>}</span> <span>=</span> person<span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> name<span>)</span><span>;</span> 
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> city<span>)</span><span>;</span> 
<span>}</span></code></pre>
<h2 id="Comparing-Structs"><a href="#Comparing-Structs" title="Comparing Structs"></a>Comparing Structs</h2><p>It’s very common to write “if this then that” type of code. Combining destructuring and pattern matching allows us to write these type of logic in a very concise way.</p>
<p>Let’s take this following example in JavaScript. It’s contrived but you have probably written something like this sometime in your career:</p>
<pre><code><span>const</span> point <span>=</span> <span>{</span> x<span>:</span> <span>0</span><span>,</span> y<span>:</span> <span>30</span> <span>}</span><span>;</span>
<span>const</span> <span>{</span> x<span>,</span> y <span>}</span> <span>=</span> point<span>;</span>

<span>if</span> <span>(</span>x <span>===</span> <span>0</span> <span>&amp;&amp;</span> y <span>===</span> <span>0</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>"both are zero"</span><span>)</span><span>;</span>
<span>}</span> <span>else</span> <span>if</span> <span>(</span>x <span>===</span> <span>0</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`x is zero and y is </span><span><span>${</span>y<span>}</span></span><span>`</span></span><span>)</span><span>;</span>
<span>}</span> <span>else</span> <span>if</span> <span>(</span>y <span>===</span> <span>0</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`x is </span><span><span>${</span>x<span>}</span></span><span> and y is zero`</span></span><span>)</span><span>;</span>
<span>}</span> <span>else</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`x is </span><span><span>${</span>x<span>}</span></span><span> and y is </span><span><span>${</span>y<span>}</span></span><span>`</span></span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>Let’s write the same code in Rust using pattern matching:</p>
<pre><code><span>struct</span> Point <span>{</span>
  x<span>:</span> i32<span>,</span>
  y<span>:</span> i32<span>,</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> point <span>=</span> Point <span>{</span> x<span>:</span> <span>10</span><span>,</span> y<span>:</span> <span>0</span> <span>}</span><span>;</span>

  <span>match</span> point <span>{</span>
    Point <span>{</span> x<span>:</span> <span>0</span><span>,</span> y<span>:</span> <span>0</span> <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"both are zero"</span><span>)</span><span>,</span>
    Point <span>{</span> x<span>:</span> <span>0</span><span>,</span> y <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"x is zero and y is {}"</span><span>,</span> y<span>)</span><span>,</span>
    Point <span>{</span> x<span>,</span> y<span>:</span> <span>0</span> <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"x is {} and y is zero"</span><span>,</span> x<span>)</span><span>,</span>
    Point <span>{</span> x<span>,</span> y <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"x is {} and y is {}"</span><span>,</span> x<span>,</span> y<span>)</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre>
<p>It’s a bit concise compared to the <code>if else</code> logic but also might be confusing as we’re performing comparison, destructuring and variable binding at the same time.</p>
<p>This is how it looks like visually:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-for-javascript-developers-4/pattern-matching-rust-1.png" alt=""><br><img src="http://www.sheshbabu.com/images/2020-rust-for-javascript-developers-4/pattern-matching-rust-2.png" alt=""></p>
<p>We begin to see why it’s named as “pattern matching” - we take an input and see which pattern in the match arms “fits” better - It’s like the <a href="https://www.google.com/search?q=shape+sorter" target="_blank" rel="noopener">shape sorter</a> toys that kids play with. Apart from comparison, we also do variable binding in the 2nd, 3rd and 4th match arms. We pass variables x or y or both to their respective expressions.</p>
<p>Pattern matching is also <code>exhaustive</code> - that is, it forces you to handle all the possible cases. Try removing the last match arm and Rust won’t let you compile the code.</p>
<h2 id="Enum"><a href="#Enum" title="Enum"></a>Enum</h2><p>JavaScript doesn’t have Enums but if you’ve used TypeScript, you can think of Rust’s Enums as a combination of TypeScript’s <a href="https://www.typescriptlang.org/docs/handbook/enums.html" target="_blank" rel="noopener">Enums</a> and TypeScript’s <a href="https://www.typescriptlang.org/docs/handbook/advanced-types.html#discriminated-unions" target="_blank" rel="noopener">Discriminated Unions</a></p>
<p>In the simplest case, Enums can be used as a group of constants.</p>
<p>For example, even though JavaScript doesn’t have Enums, you might have used this pattern:</p>
<pre><code><span>const</span> DIRECTION <span>=</span> <span>{</span>
  FORWARD<span>:</span> <span>"FORWARD"</span><span>,</span>
  BACKWARD<span>:</span> <span>"BACKWARD"</span><span>,</span>
  LEFT<span>:</span> <span>"LEFT"</span><span>,</span>
  RIGHT<span>:</span> <span>"RIGHT"</span><span>,</span>
<span>}</span><span>;</span>

<span>function</span> <span>move_drone</span><span>(</span>direction<span>)</span> <span>{</span>
  <span>switch</span> <span>(</span>direction<span>)</span> <span>{</span>
    <span>case</span> DIRECTION<span>.</span>FORWARD<span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Forward"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> DIRECTION<span>.</span>BACKWARD<span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Backward"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> DIRECTION<span>.</span>LEFT<span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Left"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> DIRECTION<span>.</span>RIGHT<span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Right"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>move_drone</span><span>(</span>DIRECTION<span>.</span>FORWARD<span>)</span><span>;</span> </code></pre>
<p>Here, we could’ve defined the FORWARD, BACKWARD, LEFT and RIGHT as separate constants, yet grouping it inside the DIRECTION object has the following benefits:</p>
<ul>
<li>The names FORWARD, BACKWARD, LEFT and RIGHT are namespaced under DIRECTION so naming conflicts can be avoided</li>
<li>It is self-documenting as we can quickly see all the valid directions available in the codebase</li>
</ul>
<p>However, there are some problems with this approach:</p>
<ul>
<li>What if someone passes NORTH or UP as an argument to move_drone? To fix this, we can add a validation to make sure that only values present in the DIRECTION object is allowed in the move function.</li>
<li>What if we decide to support UP and DOWN in future or rename LEFT/RIGHT to PORT/STARBOARD? We need to find all the places where similar switch-case or if-else is used. There’s a chance that we might miss out a few places which would cause issues in production.</li>
</ul>
<p>Enums in strongly typed languages like Rust are more powerful as they solve these problems without us writing extra code.</p>
<ul>
<li>If a function can take in only a small set of valid inputs, Enums can be used to enforce this constraint</li>
<li>Enums with pattern matching force you to cover all cases. Useful when you’re updating Enums in future</li>
</ul>
<p>Here’s the equivalent Rust example:</p>
<pre><code><span>enum</span> Direction <span>{</span>
  Forward<span>,</span>
  Backward<span>,</span>
  Left<span>,</span>
  Right<span>,</span>
<span>}</span>

<span>fn</span> <span>move_drone</span><span>(</span>direction<span>:</span> Direction<span>)</span> <span>{</span>
  <span>match</span> direction <span>{</span>
    Direction<span>:</span><span>:</span>Forward <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Forward"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Backward <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Backward"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Left <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Left"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Right <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Right"</span><span>)</span><span>,</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>move_drone</span><span>(</span>Direction<span>:</span><span>:</span>Forward<span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We access the <code>variants</code> inside Enum using the <code>::</code> notation. Try editing this code by calling “move_drone(Direction::Up)” or adding “Down” as a new item in the Direction enum. In the first case, the compiler will throw an error saying that “Up” is not found in “Direction” and in the second case, the compiler will complain that we haven’t covered “Down” in the match block.</p>
<p>Rust Enums can do much more than act as a group of constants - we can also associate data with an Enum variant.</p>
<pre><code><span>enum</span> Direction <span>{</span>
  Forward<span>,</span>
  Backward<span>,</span>
  Left<span>,</span>
  Right<span>,</span>
<span>}</span>

<span>enum</span> Operation <span>{</span>
  PowerOn<span>,</span>
  PowerOff<span>,</span>
  <span>Move</span><span>(</span>Direction<span>)</span><span>,</span>
  Rotate<span>,</span>
  TakePhoto <span>{</span> is_landscape<span>:</span> bool<span>,</span> zoom_level<span>:</span> i32 <span>}</span><span>,</span>
<span>}</span>

<span>fn</span> <span>operate_drone</span><span>(</span>operation<span>:</span> Operation<span>)</span> <span>{</span>
  <span>match</span> operation <span>{</span>
    Operation<span>:</span><span>:</span>PowerOn <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Power On"</span><span>)</span><span>,</span>
    Operation<span>:</span><span>:</span>PowerOff <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Power Off"</span><span>)</span><span>,</span>
    Operation<span>:</span><span>:</span><span>Move</span><span>(</span>direction<span>)</span> <span>=</span><span>&gt;</span> <span>move_drone</span><span>(</span>direction<span>)</span><span>,</span>
    Operation<span>:</span><span>:</span>Rotate <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Rotate"</span><span>)</span><span>,</span>
    Operation<span>:</span><span>:</span>TakePhoto <span>{</span>
      is_landscape<span>,</span>
      zoom_level<span>,</span>
    <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"TakePhoto {}, {}"</span><span>,</span> is_landscape<span>,</span> zoom_level<span>)</span><span>,</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>move_drone</span><span>(</span>direction<span>:</span> Direction<span>)</span> <span>{</span>
  <span>match</span> direction <span>{</span>
    Direction<span>:</span><span>:</span>Forward <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Forward"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Backward <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Backward"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Left <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Left"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Right <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Right"</span><span>)</span><span>,</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>operate_drone</span><span>(</span>Operation<span>:</span><span>:</span><span>Move</span><span>(</span>Direction<span>:</span><span>:</span>Forward<span>)</span><span>)</span><span>;</span>
  <span>operate_drone</span><span>(</span>Operation<span>:</span><span>:</span>TakePhoto <span>{</span>
    is_landscape<span>:</span> <span>true</span><span>,</span>
    zoom_level<span>:</span> <span>10</span><span>,</span>
  <span>}</span><span>)</span>
<span>}</span></code></pre>
<p>Here, we’ve added one more Enum called Operation that contains “unit like” variants (PowerOn, PowerOff, Rotate) and “struct like” variants (Move, TakePhoto). Notice how we’ve used pattern matching with destructuring and variable binding.</p>
<p>If you’ve used TypeScript or Flow, this is similar to <code>discriminated unions</code> or <code>sum types</code>:</p>
<pre><code><span>interface</span> <span>PowerOn</span> <span>{</span>
  kind<span>:</span> <span>"PowerOn"</span><span>;</span>
<span>}</span>

<span>interface</span> <span>PowerOff</span> <span>{</span>
  kind<span>:</span> <span>"PowerOff"</span><span>;</span>
<span>}</span>

type Direction <span>=</span> <span>"Forward"</span> <span>|</span> <span>"Backward"</span> <span>|</span> <span>"Left"</span> <span>|</span> <span>"Right"</span><span>;</span>

<span>interface</span> <span>Move</span> <span>{</span>
  kind<span>:</span> <span>"Move"</span><span>;</span>
  direction<span>:</span> Direction<span>;</span>
<span>}</span>

<span>interface</span> <span>Rotate</span> <span>{</span>
  kind<span>:</span> <span>"Rotate"</span><span>;</span>
<span>}</span>

<span>interface</span> <span>TakePhoto</span> <span>{</span>
  kind<span>:</span> <span>"TakePhoto"</span><span>;</span>
  is_landscape<span>:</span> <span>boolean</span><span>;</span>
  zoom_level<span>:</span> <span>number</span><span>;</span>
<span>}</span>

type Operation <span>=</span> PowerOn <span>|</span> PowerOff <span>|</span> Move <span>|</span> Rotate <span>|</span> TakePhoto<span>;</span>

<span>function</span> <span>operate_drone</span><span>(</span>operation<span>:</span> Operation<span>)</span> <span>{</span>
  <span>switch</span> <span>(</span>operation<span>.</span>kind<span>)</span> <span>{</span>
    <span>case</span> <span>"PowerOn"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Power On"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"PowerOff"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Power Off"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Move"</span><span>:</span>
      <span>move_drone</span><span>(</span>operation<span>.</span>direction<span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Rotate"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Rotate"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"TakePhoto"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span><span>`TakePhoto </span><span><span>${</span>operation<span>.</span>is_landscape<span>}</span></span><span>, </span><span><span>${</span>operation<span>.</span>zoom_level<span>}</span></span><span>`</span></span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>function</span> <span>move_drone</span><span>(</span>direction<span>:</span> Direction<span>)</span> <span>{</span>
  <span>switch</span> <span>(</span>direction<span>)</span> <span>{</span>
    <span>case</span> <span>"Forward"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Forward"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Backward"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Backward"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Left"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Left"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Right"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Right"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>operate_drone</span><span>(</span><span>{</span>
  kind<span>:</span> <span>"Move"</span><span>,</span>
  direction<span>:</span> <span>"Forward"</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>operate_drone</span><span>(</span><span>{</span>
  kind<span>:</span> <span>"TakePhoto"</span><span>,</span>
  is_landscape<span>:</span> <span>true</span><span>,</span>
  zoom_level<span>:</span> <span>10</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<h2 id="Option"><a href="#Option" title="Option"></a>Option</h2><p>We learnt about the <code>Op…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums">http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums</a></em></p>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811431</guid>
            <pubDate>Sun, 12 Jul 2020 14:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some popular self help books]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23811333">thread link</a>) | @imshashank
<br/>
July 12, 2020 | https://dailyjag.com/literature/read-these-self-help-books-and-make-most-of-our-this-downtime/ | <a href="https://web.archive.org/web/*/https://dailyjag.com/literature/read-these-self-help-books-and-make-most-of-our-this-downtime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Continual upskilling is critical for accelerating your career progression. However, the time constraint that corporate employment entail tends to spare limited time for you to improve your skillset. In this light, it can be said that downtime is the best time to update the skills you require to transcend the role that you hold. Developing the ability to teach yourself can help you make the most of self-help books available in the market. We have put together a list of popular books that can help you get started.&nbsp;</p><h2>1) <strong>Fastlane Millionaire by MJ DeMarco</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-1024x576.jpg" alt="The Millionaire Fastlane by M.J. Demarco - animated book summary ..." srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-1024x576.jpg 1024w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-300x169.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-768x432.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-192x108.jpg 192w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-384x216.jpg 384w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-364x205.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-728x409.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-561x316.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-1122x631.jpg 1122w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-608x342.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-758x426.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-1152x648.jpg 1152w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-85x48.jpg 85w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-171x96.jpg 171w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-313x176.jpg 313w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco.jpg 1280w" sizes="100vw"></figure></div><p>This book will change your perspective of the process involved in getting rich. The author demolishes the conventional ideas of earning riches by exposing its many flaws. MJ redefines wealth in Fastlane Millionaire and outlines a quick practical way of getting wealthy and retiring young. This book can help you start your own profitable business that can yield you both reputation and wealth.</p><h2>2) <strong>Creativity Inc by Ed Catmull and Amy Wallace</strong></h2><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-1024x574.jpg" alt="Creativity Inc by Ed Catmull and Amy Wallace" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-1024x574.jpg 1024w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-300x168.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-768x431.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-192x108.jpg 192w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-384x216.jpg 384w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-364x205.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-728x409.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-561x314.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-1122x629.jpg 1122w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-608x341.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-758x426.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-1152x646.jpg 1152w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-86x48.jpg 86w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-171x96.jpg 171w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-313x175.jpg 313w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace.jpg 1379w" sizes="100vw"></figure><p>The authors base this book on the premise that everyone has creativity in them. They believe that various unseen forces suppress or even quench this innate creativity. They emphasize the fact that creative inspiration is not associated with job titles or organizational hierarchy. This is a great book for managers as it helps them understand the importance of a good team and educates them about acceptable team dynamics.&nbsp;</p><h2>3) <strong>Range by David Epstein</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein.jpg" alt="Range by David Epstein" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein.jpg 837w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-300x182.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-768x465.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-561x340.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-364x220.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-728x441.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-608x368.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-758x459.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-79x48.jpg 79w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-158x96.jpg 158w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-313x190.jpg 313w" sizes="100vw"></figure></div><p>We have all heard time and again about the importance of starting early, honing skills, and striving to succeed. The book will help you understand the reason behind generalists’ success during times of increasing specialization. In his book, Range, David Epstein draws a vivid comparison between those who start young and those who take time to find their interest. He uses real-life celebrities as examples to draw takeaways about specializing, experimenting, and abstract thinking. This is a breakthrough book that can help parents, teachers, managers, and leaders look at success and performance in the right way.</p><h2>4) <strong>Designing Your Life by Bill Burnett and Dave Evans</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-1024x719.jpg" alt="Designing Your Life by Bill Burnett and Dave Evans" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-1024x719.jpg 1024w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-300x211.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-768x540.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-265x186.jpg 265w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-561x394.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-1122x788.jpg 1122w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-364x256.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-728x511.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-608x427.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-758x532.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-1152x809.jpg 1152w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-68x48.jpg 68w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-137x96.jpg 137w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-313x220.jpg 313w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans.jpg 1200w" sizes="100vw"></figure></div><p>This book is a New York Times Best Seller that can impact you positively irrespective of your age or stage in life. The authors give you a prototype of design thinking that can help you design and build your work as well as personal life. Living out the guidelines and concepts available in this book can help you live a more fulfilling life filled with creativity, productivity, and joy.</p><h2>5)&nbsp;<strong>Find Your Why by Simon Sinek, David Mead, and Peter Docker</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-1024x576.jpg" alt="Find Your Why by Simon Sinek, David Mead, and Peter Docker" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-1024x576.jpg 1024w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-300x169.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-768x432.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-192x108.jpg 192w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-384x216.jpg 384w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-364x205.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-728x409.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-561x316.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-1122x631.jpg 1122w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-608x342.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-758x426.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-1152x648.jpg 1152w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-85x48.jpg 85w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-171x96.jpg 171w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-313x176.jpg 313w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker.jpg 1280w" sizes="100vw"></figure></div><p>The authors of this book believe that statements that start with ‘why’ are more actionable than others. This book will help you find your purpose (if you haven’t already) and will aid in renewing your passion for what you are doing. This read will redefine the definition of happiness, fulfillment, and purpose for you. The authors have also followed up with a second book, ‘Start With Why’ to help you get started on the path that will make your life more meaningful.</p><h2>6) <strong>The $100 Startup by Chris Guillebeau</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau.jpg" alt="The $100 Startup by Chris Guillebeau" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau.jpg 820w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-300x164.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-768x421.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-561x307.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-364x199.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-728x399.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-608x333.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-758x415.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-88x48.jpg 88w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-175x96.jpg 175w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-313x171.jpg 313w" sizes="100vw"></figure></div><p>This book has its focus set on solopreneurs and individual entrepreneurs who wield their capabilities and earn profits through sheer passion and micro-businesses. The author taps into his own experience as an entrepreneur and delivers speaking assignments on micro-businesses. The book is a great source of small ideas that can be worked on to earn a substantial income. The author generously uses infographics, checklists, and sidebars to help convey his message effectively.</p><h2>7) <strong>Originals by Adam Grant</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1.jpg" alt="Innovation Design In Education - ASIDE: Book Club Discussion ..." srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1.jpg 710w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-300x161.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-561x300.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-364x195.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-608x325.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-90x48.jpg 90w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-179x96.jpg 179w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-313x168.jpg 313w" sizes="(max-width: 710px) 100vw, 710px"></figure></div><p>This book gives you a glimpse into the world-view of successful innovators. Reading this book will encourage you to stand out by correctly expressing your new ideas. He analyses the non-conformist moves made by leading innovators in various markets and highlights their success strategies to provide you with actionable insights.</p><h2>8) <strong>Antifragile by Nassim Nicholas Taleb</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb.jpg" alt="Antifragile by Nassim Nicholas Taleb" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb.jpg 900w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-300x183.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-768x468.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-561x342.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-364x222.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-728x443.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-608x370.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-758x462.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-79x48.jpg 79w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-158x96.jpg 158w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-313x191.jpg 313w" sizes="100vw"></figure></div><p>Antifragile is a thought-provoking book that encourages you to work towards making yourself stronger by exposing yourself to volatile circumstances. The author segregates all things into three categories – fragile, robust, and antifragile. He appeals to develop features that will slot you in the antifragile category, where every disruption only makes you stronger.&nbsp;</p><h2>9) <strong>When by Daniel H Pink</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink.jpg" alt="When by Daniel H Pink" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink.jpg 776w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-300x232.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-768x594.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-561x434.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-364x281.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-728x563.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-608x470.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-758x586.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-62x48.jpg 62w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-124x96.jpg 124w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-313x242.jpg 313w" sizes="100vw"></figure></div><p>This book explores scientific facts that imply that the impact of the decision taken is dependent on their timing. The author suggests that our cognitive abilities are subject to change over the course of the day. Daniel leverages his research takeaways and highlights the importance of scheduling and timing of routine practices to culminate your efforts into success.</p><h2>10) <strong>Grit by Angela Duckworth</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth.jpg" alt="Grit by Angela Duckworth" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth.jpg 791w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-300x169.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-768x432.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-192x108.jpg 192w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-384x216.jpg 384w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-364x205.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-728x409.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-561x316.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-608x342.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-758x426.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-85x48.jpg 85w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-171x96.jpg 171w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-313x176.jpg 313w" sizes="100vw"></figure></div><p>This book will keep your motivation levels high while you strive to gain success. The author emphasizes the fact that passion must be backed by perseverance to achieve the unattainable. In Grit, Angela records her meetings with people who have exercised grit to savor success. The takeaways she notes in this book and the life accounts of the champions she interviews will energize you to persevere and win.</p><div><div><div><p><a href="https://dailyjag.com/profile/admin/" rel="author"> <img alt="" src="https://secure.gravatar.com/avatar/33563973b6f338002e574f30a3f94788?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/33563973b6f338002e574f30a3f94788?s=160&amp;d=mm&amp;r=g 2x" height="80" width="80"> </a></p><div> <p><span>  </span> <span> <span>Member since</span> <time datetime="2020-04-17 12:37"> August 16, 2011 </time> </span></p></div></div><p><span>I am an android developer, hacker, web developer, professional blogger and a complete tech freak. I love computers and everything related to computers. I love learning new things and sharing the knowledge with the world.</span> <a href="https://www.facebook.com/agarwal.shashank">https://www.facebook.com/agarwal.shashank</a></p></div></div><p><a href="https://pipfeed.com/" target="_blank"> <img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/White_Feature_image_2.jpg"> </a></p></div></div>]]>
            </description>
            <link>https://dailyjag.com/literature/read-these-self-help-books-and-make-most-of-our-this-downtime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811333</guid>
            <pubDate>Sun, 12 Jul 2020 14:02:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SAS Rescue 3 Trapped British Diplomats in Albania]]>
            </title>
            <description>
<![CDATA[
Score 179 | Comments 75 (<a href="https://news.ycombinator.com/item?id=23811306">thread link</a>) | @Hansig_jw
<br/>
July 12, 2020 | https://www.mydiplomaticlife.com/sas-rescue-trapped-diplomats-in-albania/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/sas-rescue-trapped-diplomats-in-albania/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><span>This is a story of how the SAS rescued myself and two colleagues who were trapped in the British embassy in Tirana having been evacuated into the embassy on 12th September 12th 1998 as the country erupted into civil unrest and lawlessness. The boys from Hereford did good!</span></p>
<p>This was my first diplomatic posting and during the course of my career I took part in the <span>evacuation of British nationals&nbsp;(and others)</span><span>&nbsp;in a number of locations but on this occasion, I was the one being evacuated albeit from my residence to the embassy as a place of safety.<a href="https://www.mydiplomaticlife.com/libya-timely-evacuation-of-oil-workers/">Libya – Timely Evacuation Of Oil Workers During Arab Spring 2011</a></span></p>
<p>This was a day I was not going to forget in a hurry. I had just under four months left before my tour ended and I had spent the previous day at work trawling through future job opportunities. The Ambassador was again out of the country and the Deputy Head of Mission (DHM) was once more in charge. I should have known from previous experience and recent incidents that trouble always seemed to flare up when Ambassadors are away from post.</p>
<p>On this day, I awoke very early to the sounds of large explosions and the rattle of gunfire that seemed to be going off in all directions. What was going on? There had been no forewarning of trouble and things had been relatively quiet and stable in the city over the preceding weeks.</p>
<p>I tried to get hold of the DHM on my mobile phone but the network was down, always a bad sign. I immediately got on the embassy radio net and contacted her. She said that she had just heard from the German Embassy that a local high profile opposition politician, Azem Hajdari, had been assassinated outside the Parliament building and his Democratic Party (DP) supporters were on the warpath blaming the Socialist government party for the murder.</p>
<p>Tanks, automatic weapons and armoured personnel carriers had been seized by DP members and the government were now calling this an attempted coup d’etat and responding with armed force of its own.</p>
<p>She advised me to keep my head down, keep the radio close to hand and they would try and get an Embassy armoured vehicle to me as soon as possible and we would all rendezvous at the embassy. By this time, the noise of fighting outside seemed to be getting louder and getting nearer. The main government quarter was only just two blocks away from my apartment and it sounded like the main fighting was in this area. I cautiously pulled back a shutter and looked outside and saw there was a lot of smoke billowing forth from that quarter.</p>
<p>After about an hour, I heard a familiar voice on the radio, it was Benny our Embassy driver calling from the armoured car radio just outside my front gate. Not for the first time had he come to get me out of another messy situation. He advised me to be careful coming out as there was a body in front of my gate.</p>
<p>As I came out, the noise was deafening, there was small arms firing which appeared to be coming from the next street and there was indeed a man in what looked like a policeman’s uniform lying just to the side of my gate.</p>
<p>I didn’t hang around to assess his condition as just at that moment, a large group of armed men turned the corner on to my street firing in our direction as they advanced. Why they were shooting at a vehicle that was clearly marked as a diplomatic car, I had no idea. I jumped into the car and Benny quickly reversed the vehicle away from the onrushing crowd, turned it around at the intersection and off we sped to the embassy taking as many back roads as possible.</p>
<p>We reached the embassy safely but it was disturbing to see that the usual government provided armed security guarding the Embassy and the surrounds was nowhere to be seen. We drew up to the embassy and I ran into the building. Both the DHM and Management Officer (MO) were already there. The DHM had already contacted London and appraised them of the situation. It appeared that the violence was escalating and that it could very well be a coup d’etat. London advised us to remain in lockdown in the embassy and to stay there until further notice. Not very reassuring.</p>
<p>The hours went by, nighttime came and the sky was lit up with explosions and the gunfire seemed to be getting closer to the embassy. Throughout all of this, the DHM was updating London via our secure communication channels of our ever-growing precarious situation. They continued to advise us to stay in the embassy as help was on the way. What did that mean? How on earth were they going to help us? They were in London and we were trapped and bottled up at the sharp end.</p>
<p>Well, indeed help was on the way in the most unexpected form. After a long, restless and uncomfortable night trying to sleep on the floor of my office under my desk, as dawn was breaking, there was the sound of screeching tyres outside the embassy.</p>
<p>At first we thought this was it, the bad guys had arrived and we were destined for some form of uncertain captivity or worse, but no, out of two strange looking 4x4s, poured a section of heavily armed and equipped Special Air Service (SAS) troopers who had flown into Tirana airport from the UK in an RAF transport aircraft (without any flight clearance), offloaded themselves and sped the 17 Kms to the embassy.</p>
<p>There were no formalities, the SAS section commander immediately told the DHM that he was in charge and that we were to follow his instructions until further notice. For the time being, he said, there were no orders for evacuating us, his men would go out and evaluate the situation on the ground and then make a recommendation back to London.</p>
<p>They then set up their own communications suite in the Ambassador’s office (their communication specialist felt very much at home behind the large Ambassadorial desk), brought in their weapons and stores and after a short briefing, their patrol set off. Benny our driver volunteered to go with them and act as guide and interpreter if needed.</p>
<p>While one party was employed on this task another group made a start of setting up defensive positions within the embassy and thoroughly briefing us on what to do if we were subjected to an attack. It really was a boost to our morale that we had these guys now with us, more than able to physically protect us and if needed get us out of there to a place of safety if things deteriorated.</p>
<p>Later that afternoon the first patrol returned to the embassy. The good news was that they reported our homes had appeared from the outside not to have been looted. They said there was still heavy fighting going on in various parts of the city, but it seemed to be centred mainly around the government quarter. Benny told us later that the patrol had been menaced on several occasions by armed men, but a few well aimed shots above the heads of the mob had convinced them to melt away and not to mess with the patrol.</p>
<p>The fighting went on for about three days. Each day the sound of gunfire and explosions seemed to decrease. The SAS continued to send out rotating patrols to monitor the situation in and around the city, deciding after the third day that there was no need to evacuate us out of the country as their assessment was the fighting had run its course. Indeed thankfully, on the fourth day there was silence, no gunfire and no explosions.</p>
<p>The SAS kept us in the embassy for just over a week before they deemed it fully safe for us to return to our homes and resume normal work. We also received reassurances from the Albanian government that the fighting had now ceased, order had been restored and our local security would be reinstated. All of this was good news indeed.</p>
<p>However, it was a sad day when we came to bid farewell to our SAS rescuers as they packed up to leave. We had got to know them pretty well over the course of a long week. They were a thoroughly professional, no nonsense group of guys who were extremely sociable in the rare moments they took time out to relax in between patrols with a wealth of stories that kept us entertained during the long days and nights we were cooped up in the embassy.</p>
<p>I personally would miss their army ration packs on which we all lived, apart from rare welcome pizzas they brought back occasionally from goodness knows where by some of the patrols.</p>
<p>With impeccable timing, the day after they left, the Ambassador returned to post. Even he, not usually one to crack a joke at the best of times remarked tongue in cheek that in future he would give us ample warning of his next trip out of country so that we could be prepared for the next crisis. Not funny. Yes, by all means forewarn us of your next absence but make it far enough in advance so that I for one could also ensure I was not around as well!</p>

              </article></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/sas-rescue-trapped-diplomats-in-albania/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811306</guid>
            <pubDate>Sun, 12 Jul 2020 13:55:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shadow Daemon – a web application firewall]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811061">thread link</a>) | @realpanzer
<br/>
July 12, 2020 | https://shadowd.zecure.org/overview/introduction/ | <a href="https://web.archive.org/web/*/https://shadowd.zecure.org/overview/introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="main-content">
        <section>
          <div>
            <div>
              <section>
                <div>
                  



<p><img id="logo" src="https://shadowd.zecure.org/img/logo_small.png"></p>

<h2 id="what-is-shadow-daemon:2767292a573dc549b9b4297b701af3ab">What is Shadow Daemon?</h2>

<p><em>Shadow Daemon</em> is a collection of tools to <em>detect</em>, <em>record</em>, and <em>block</em> <em>attacks</em> on <em>web applications</em>.
Technically speaking, Shadow Daemon is a <em>web application firewall</em> that intercepts requests and filters out malicious parameters.
It is a modular system that separates web application, analysis, and interface to increase security, flexibility, and expandability.</p>

<p>Shadow Daemon is <a target="_blank" href="https://www.gnu.org/philosophy/free-sw.html">free software</a>. It is released under the license <a href="https://shadowd.zecure.org/about/license/">GPLv2</a>, so it is open source and the code can be examined, modified, and distributed by everyone.</p>

<h2 id="what-differentiates-shadow-daemon:2767292a573dc549b9b4297b701af3ab">What differentiates Shadow Daemon?</h2>

<h3 id="ease-of-use:2767292a573dc549b9b4297b701af3ab">Ease of use</h3>

<p>Shadow Daemon is easy to install and can be managed with a clear and structured web interface that lets you examine attacks in great detail.</p>

<p>The interface also comes with shell scripts that can be used to send weekly reports via e-mail, rotate the logs, and the like.</p>




<h3 id="high-coverage:2767292a573dc549b9b4297b701af3ab">High coverage</h3>

<p>Shadow Daemon uses small connectors on application level to intercept requests.
This guarantees that the analyzed data is exactly the same as the input data of the web application, a task many firewalls fail to do properly.
The installation of the connectors is easy and does not require coding abilities.</p>

<p>At the moment the following programming languages, libs, and frameworks are supported:</p>

<ul>
<li>PHP</li>
<li>Perl

<ul>
<li>CGI</li>
<li>Mojolicious</li>
<li>Mojolicious::Lite</li>
</ul></li>
<li>Python

<ul>
<li>CGI</li>
<li>Django</li>
<li>Werkzeug</li>
<li>Flask</li>
</ul></li>
</ul>

<p>Additional connectors are planned and will be released at some point in the future.
If you want to <a href="https://shadowd.zecure.org/development/contributing/">contribute</a> why not develop a new <a href="https://shadowd.zecure.org/documentation/connectors/">connector</a>?</p>

<h3 id="accurate-detection:2767292a573dc549b9b4297b701af3ab">Accurate detection</h3>

<p>Shadow Daemon combines <a href="https://shadowd.zecure.org/documentation/blacklist/">blacklisting</a>, <a href="https://shadowd.zecure.org/documentation/whitelist/">whitelisting</a>, and <a href="https://shadowd.zecure.org/documentation/integrity/">integrity checking</a> to accurately detect malicious requests.
The blacklist makes use of sophisticated regular expressions to search for known attack patterns in the user input.
The whitelist on the other hand searches for irregularities in the user input based on strict rules that define how the input should look like.
The integrity check compares cryptographically secure checksums of the executed scripts against predefined values.</p>

<p>Together they can detect almost any attack on a web application and still have a very low false-positive rate.</p>

<p>Shadow Daemon is able to detect common attacks like:</p>

<ul>
<li>SQL injections</li>
<li>XML injections</li>
<li>Code injections</li>
<li>Command injections</li>
<li>Cross-site scripting</li>
<li>Local/remote file inclusions</li>
<li>Backdoor access</li>
<li>And more …</li>
</ul>

<h3 id="discreet-protection:2767292a573dc549b9b4297b701af3ab">Discreet protection</h3>

<p>Unlike many other web application firewalls Shadow Daemon does not completely block malicious requests if possible.
Instead it only filters out the dangerous parts of a request and lets it proceed afterwards.
This makes attacks impossible, but does not unnecessary frustrate visitors in the case of false-positives.</p>

<h3 id="secure-architecture:2767292a573dc549b9b4297b701af3ab">Secure architecture</h3>

<p>Shadow Daemon is closer to the application than most other web application firewalls.
It receives <em>exactly</em> the same input that the web application receives and thus it is almost impossible to bypass the detection by obfuscating the attack.
However, the most complex parts of Shadow Daemon are separated from the web application to guarantee a certain standard of security.</p>

<h2 id="who-should-use-shadow-daemon:2767292a573dc549b9b4297b701af3ab">Who should use Shadow Daemon?</h2>

<p>Shadow Daemon is for people who want to run their own dynamic website without constantly having to worry about attacks and vulnerabilities.</p>

<p>Shadow Daemon is for people who want to know if and how their website is attacked.</p>

<p>Shadow Daemon is for people who do not want to blindly place their trust in closed-source software that does its work in secret and costs a fortune.</p>

<h2 id="how-do-i-install-shadow-daemon:2767292a573dc549b9b4297b701af3ab">How do I install Shadow Daemon?</h2>

<p><em>Getting Started</em> contains everything you need to know. Start by reading <a href="https://shadowd.zecure.org/overview/shadowd/">shadowd</a>.
Installing Shadow Daemon is easy and only takes some minutes, really.</p>

<h2 id="how-can-i-follow-the-development-of-shadow-daemon:2767292a573dc549b9b4297b701af3ab">How can I follow the development of Shadow Daemon?</h2>

<p>The development of Shadow Daemon takes place at <a href="https://github.com/zecure">Github</a>.
Announcements are published via <a href="https://twitter.com/zecureit">Twitter</a>.
Make sure to star/follow to stay up to date.</p>

<figure>
 <a href="https://github.com/zecure">
  <img src="https://shadowd.zecure.org/img/octocat.png" height="100px">
  <figcaption><h4>Github</h4></figcaption>
 </a>
</figure>

<figure>
 <a href="https://twitter.com/zecureit">
  <img src="https://shadowd.zecure.org/img/twitter.png" height="90px">
  <figcaption><h4>Twitter</h4></figcaption>
 </a>
</figure>

<h2 id="do-you-want-more-security:2767292a573dc549b9b4297b701af3ab">Do you want more security?</h2>

<p>Shadow Daemon is a passive security system.
It intercepts requests and tries to block attacks on your web applications.
If this is not enough for you and you want to actively find and fix vulnerabilities in your PHP and Java applications to reduce the attack surface to an absolute minimum you should check out the <em>source code analyser</em> <a href="https://www.ripstech.com/">RIPS</a>.</p>

<p>The new <a href="https://www.ripstech.com/">RIPS</a> engine is armed with innovative code analysis algorithms that are specifically dedicated to the intricate features of the PHP and Java languages.
It is capable of analyzing modern applications for complex security vulnerabilities within minutes.
The full feature stack of both languages is supported, including object-oriented code, pitfall-prone security mechanisms, and built-in functions.
Security vulnerabilities are accurately detected by analyzing the data flow from user-controlled input parameters to sensitive operations in your application with 100% code coverage.</p>

                </div>
              </section>
            </div>
          </div>
          
        </section>
      </section></div>]]>
            </description>
            <link>https://shadowd.zecure.org/overview/introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811061</guid>
            <pubDate>Sun, 12 Jul 2020 13:10:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Merging and Patches (2017)]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23810902">thread link</a>) | @lelf
<br/>
July 12, 2020 | https://jneem.github.io/merging/ | <a href="https://web.archive.org/web/*/https://jneem.github.io/merging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    <time datetime="2017-05-08T00:00:00+00:00">May 08, 2017</time>
  </header>
<p>A <a href="https://arxiv.org/abs/1311.3903">recent paper</a> suggested a new mathematical
point of view on version control. I first found out about it from <code>pijul</code>,
a new version control system (VCS) that is loosely inspired by that paper. But
if you poke around the <code>pijul</code> <a href="https://pijul.com/">home page</a>, you won’t find
many details about what makes it different from existing VCSes. So I did a bit
of digging, and this series of blog posts is the result.</p>

<p>In the first part (i.e. this one), I’ll go over some of the theory developed in
the paper. In particular, I’ll describe a way to think about patches and
merging that is guaranteed to never, ever have a merge conflict. In the second
part, I’ll show how <code>pijul</code> puts that theory into action, and in the third part
I’ll dig into <code>pijul</code>’s implementation.</p>

<p>Before getting into some patch theory, a quick caveat: any real VCS needs to
deal with a lot of tedious details (directories, binary files, file renaming,
etc.). In order to get straight to the interesting new ideas, I’ll be skipping
all that. For the purposes of these posts, a VCS only needs to keep track of
a single file, which you should think of as a list of lines.</p>



<p>A patch is the difference between two files. Later in this series we’ll be
looking at some wild new ideas, so let’s start with something familiar and
comforting. The kind of patches we’ll discuss here go back to the early days of
Unix:</p>

<ul>
  <li>a patch works line-by-line (as opposed to, for example, word-by-word); and</li>
  <li>a patch can add new lines, but not modify existing lines.</li>
</ul>

<p>In order to actually have a useful VCS, you need to be able to delete lines
also. But deleting lines turns out to add some complications, so we’ll deal
with them later.</p>

<p>For an example, let’s start with a simple file: my to-do list for this morning.</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_1.svg" alt=""></p>

<p>Looking back at the list, I realize that I forgot something important. Here’s the new one:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_2.svg" alt=""></p>

<p>To go from the original to-do list to the new one, I added the line with the
socks. In the format of the original Unix “diff” utility, the patch would look like this:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_3.svg" alt=""></p>

<p>The “1a2” line is a code saying that we’re going to add something after line 1 of the
input file, and the next bit is obviously telling us what to insert.</p>

<p>Since this blog isn’t a command line tool, we’ll represent patches with pretty diagrams
instead of flat files. Here’s how we’ll draw the patch above:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_4.svg" alt=""></p>

<p>Hopefully it’s self-explanatory, but just in case: an arrow goes from left to
right to indicate that the line on the right is the same as the one on the
left. Lines on the right with no arrow coming in are the ones that got added.
Since patches aren’t allowed to re-order the lines, the lines are guaranteed
not to cross.</p>

<p>There’s something implicit in our notation that really needs to be said out
loud: for us, <b>a patch is tied to a specific input file</b>. This is the first point
where we diverge from the classic Unix ways: the classic Unix patch that we
produced using “diff” could in principle be applied to <em>any</em> input file, and it
would still insert “* put on socks” after the first line. In many cases that
wouldn’t be what you want, but sometimes it is.</p>



<p>The best thing about patches is that they can enable multiple people to edit
the same file and then merge their changes afterwards. Let’s suppose that my
wife also decides to put things on my to-do list: she
takes the original file and adds a line:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_5.svg" alt=""></p>

<p>Now there are two new versions of my to-do list: mine with the socks, and my
wife’s with the garbage. Let’s draw them all together:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_6.svg" alt=""></p>

<p>This brings us to merging: since I’d prefer to have my to-do list as a single
file, I want to merge my wife’s changes and my own. In this example, it’s
pretty obvious what the result should be, but let’s look at the general problem
of merging. We’ll do this slowly and carefully, and our endpoint might be
different from what you’re used to.</p>

<h2 id="patch-composition">Patch composition</h2>

<p>First, I need to introduce some notation for an obvious concept: the
<em>composition</em> of two patches is the patch that you would get by applying one
patch and then applying the other. Since a “patch” for us also includes the
original file, you can’t just compose any two old patches. If <code>p</code> is a patch
taking the file <code>O</code> to the file <code>A</code> and <code>r</code> is a patch taking <code>A</code> to <code>B</code>, then
you can compose the two (but only in one order!) to obtain a patch from <code>O</code> to
<code>B</code>. I’ll write this composition as <code>pr</code>: first apply <code>p</code>, then <code>r</code>.</p>

<p>It’s pretty easy to visualize patch composition using our diagrams: to compute
the composition of two paths, just “follow the arrows”</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_7.svg" alt=""></p>

<p>to get the (dotted red) patch going from <code>O</code> to <code>B</code>.</p>

<h2 id="merging-as-composition">Merging as composition</h2>

<p>I’m going to define carefully what a merge is in terms of patch composition.
I’ll do this in a very math-professor kind of way: I’ll give a precise
definition, followed by some examples, and only afterwards will I explain
why the definition makes sense.
So here’s the definition: if <code>p</code> and <code>q</code> are two different patches
taking the file <code>O</code> to the files <code>A</code> and <code>B</code> respectively, a <em>merge</em> of <code>p</code> and <code>q</code>
is a pair of patches <code>r</code> and <code>s</code> such that</p>

<ul>
  <li><code>r</code> and <code>s</code> take <code>A</code> and <code>B</code> respectively to a common output file <code>M</code>, and</li>
  <li><code>pr = qs</code>.</li>
</ul>

<p>We can illustrate this definition with a simple diagram, where the capital
letters denote files, and the lower-case letters are patches going between
them:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_8.svg" alt=""></p>

<p>Instead of saying that <code>pr = qs</code>, a mathematician (or anyone who wants
to sound fancy) would say that the diagram above <em>commutes</em>.</p>

<p>Here is an example of a merge:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_9.svg" alt=""></p>

<p>And here is an example of something that is not a merge:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_10.svg" alt=""></p>

<p>This is not a merge because it fails the condition <code>pr = qs</code>: composing the
patches along the top path gives</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_11.svg" alt=""></p>

<p>but composing them along the bottom path gives</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_12.svg" alt=""></p>

<p>Specifically, the two patches disagree on which of the shoes in the final list
came from the original file. This is the real meaning underlying the condition
<code>pr = qs</code>: it means that there will never be any ambiguity about which lines
came from where. If you’re used to using <code>blame</code> or <code>annotate</code> commands with
your favorite VCS, you can probably imagine why this sort of ambiguity would be
bad.</p>

<h2 id="a-historical-note">A historical note</h2>

<p>Merging patches is an old idea, of course, and so I just want to briefly
explain how the presentation above differs from “traditional” merging:
traditionally, merging was defined by algorithms (of which there are
<a href="https://en.wikipedia.org/wiki/Merge_(version_control)#Merge_algorithms">many</a>). These algorithms would try to automatically find a good merge; if
they couldn’t, you would be asked to supply one instead.</p>

<p>We’ll take a different approach: instead of starting with an algorithm, we’ll
start with a list of properties that we want a good merge to satisfy. At the end,
we’ll find that there’s a unique merge that satisfies all these properties
(and fortunately for us, there will also be an efficient algorithm to find it).</p>



<p>The main problem with merges is that they aren’t unique. This isn’t a huge
problem by itself: lots of great things aren’t unique. The problem is that we
usually want to merge automatically, and an automatic system needs an
unambiguous answer. Eventually, we’ll deal with this by defining a special
class of merges (called perfect merges) which will be unique. Before that,
we’ll explore the problem with some examples.</p>

<h2 id="a-silly-example">A silly example</h2>

<p>Let’s start with a silly example, in which our merge tool decides to
add some extra nonsense:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_13.svg" alt=""></p>

<p>No sane merge tool would ever do that, of course, but it’s still a valid
merge according to our rule in the last section. Clearly, we’ll have
to tighten up the rules to exclude this case.</p>

<h2 id="a-serious-example">A serious example</h2>

<p>Here is a more difficult situation with two merges that are actually
reasonable:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_14.svg" alt=""></p>

<p>Both of these merges are valid according to our rules above, but you need to
actually know what the lines <em>mean</em> in order to decide that the first merge is
better (especially if it’s raining outside). Any reasonable automatic merging
tool would refuse to choose, instead requiring its user to do the merge
manually.</p>

<p>The examples above are pretty simple, but how would you decide in general
whether a merge is unambiguous and can be performed automatically? In existing
tools, the details depend on the merging algorithm. Since we started off with
a non-algorithmic approach, let’s see where that leads: instead of specifying
explicitly which merges we can do, we’ll describe the properties that an ideal
merge should have.</p>



<p>The main idea behind the
definition I’m about to give is that it will never cause any regrets. That is,
no matter what happens in the future, we can always represent the history just
as well through the merge as we could using the original branches. Obviously,
that’s a nice property to have; personally, I think it’s non-obvious why it’s
a good choice as the <em>defining</em> property of the ideal merge, but we’ll get to
that later.</p>

<p>Ok, here it comes. Consider a merge:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_15.svg" alt=""></p>

<p>And now suppose that the original creators of patches <code>p</code> and <code>q</code>
continued working on their own personal branches, which merged sometime in
the future at the file <code>F</code>:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_16.svg" alt=""></p>

<p>We say that the merge <code>(r, s)</code> is a <em>perfect merge</em> if for <em>every</em> possible
choice of the merge <code>(u, v)</code>, there is a unique patch <code>w</code> so that <code>u = rw</code>
and <code>v = sw</code>. (In math terms, the diagram commutes.)
We’re going to call <code>w</code> a <em>continuation</em>, since it tells us how to continue
working from the merged file. To repeat, a merge is perfect if for every
possible future, there is a unique continuation.</p>

<h2 id="a-perfect-merge">A perfect merge</h2>

<p>Let’s do a few examples to explore the various corners of our definition.
First, an example of a perfect merge:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_17.svg" alt=""></p>

<p>It takes a bit of effort to actually <em>prove</em> that this is a perfect merge;
I’ll leave that as an exercise. It’s more interesting to see some examples
that fail to be perfect.</p>

<h2 id="a-silly-example-1">A silly example</h2>

<p>Let’s start with the silly example of a merge that introduced an unnecessary
line:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_18.svg" alt=""></p>

<p>This turns out (surprise, surprise) not to be a perfect merge.
To understand how our definition of merge perfection excludes merges like this,
here is an example of a possible future without a continuation:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_19.svg" alt=""></p>

<p>Since our patches can’t delete lines, there’s no way to get from <code>merged</code>
to <code>future</code>.</p>

<h2 id="a-serious-example-1">A serious …</h2></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jneem.github.io/merging/">https://jneem.github.io/merging/</a></em></p>]]>
            </description>
            <link>https://jneem.github.io/merging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810902</guid>
            <pubDate>Sun, 12 Jul 2020 12:41:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Science Eats Its Young]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810885">thread link</a>) | @george3d6
<br/>
July 12, 2020 | https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG | <a href="https://web.archive.org/web/*/https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-07-12</p>
        
<p>Let's start by talking about scientific literacy. I'm going to use a weak definition of scientific literacy, one that simply requires familiarity with the Baconian method of inquiry.</p>
<p>I don't want to place an exact number on this issue, but I'd wager the vast majority of the population of "educated" countries scientifically illiterate.</p>
<h2>I - The gravity of the issue</h2>
<p>I first got a hint that this could be a real issue when I randomly started asking people about the theory of gravity. I find gravity to be interesting because it's not at all obvious. I don't think any of us would have been able to come up with the concept in Newton's shoes. Yet it is taught to people fairly early in school.</p>
<p>Interestingly enough, I found that most people were not only unaware of how Newton came up with the idea of gravity, but not even in the right ballpark. I think I can classify the mistakes made into three categories, which I'll illustrate with an answer each:</p>
<ol>
<li>The <strong>Science as Religion</strong> mistake: Something something, he saw apples falling towards earth, and then he wrote down the formula for gravity (?)</li>
<li>The <strong>Aristotelian Science</strong> mistake: Well, he observed that objects of different mass fell towards Earth with the same speed, and from that he derived that objects attract each other. Ahm, wait, hmmm.</li>
<li>The <strong>Lack of information</strong> mistake: Well, he observed something about the motion of the planets and the moon... and, presumably he estimated the mass of some, or, hmmm, no that can't be right, maybe he just assumed mass_sun &gt;&gt; mass_plant &gt;&gt; mass_moon and somehow he found that his formula accounted for the motion of the planets.</li>
</ol>
<p>I should caveat this by saying I don't count mistake nr 3 as scientific illiteracy, in this case, I think most of us fall in that category most of the time. Ask me how gravity can be derived in principle and I might be able to make an educated guess and maybe (once the observations are in) I could even derive it. But the chances of that are small, I probably wouldn't know the exact information I'd need which can be measured with 17th-century devices. I most certainly don't have the information readily sitting in my brain.</p>
<p>It's mainly failure modes 1 and 2 that I'm interested in here.</p>
<h2>II - And Science said: Let there be truth</h2>
<p>I think failure mode 1 is best illustrated by the <a href="https://www.youtube.com/results?search_query=how+newton+discovered+gravity">first youtube result</a> if you search for "how newton discovered gravity". This failure mode includes two mistakes:</p>
<ul>
<li>Not understanding the basis of the actual theory (in this case 'gravity' is presented as "objects fall towards Earth", rather than objects attracting each other proportional to their mass and distance).</li>
<li>Not understanding the idea of evidence as a generator of theory.</li>
</ul>
<p>In this failure, mode science works more or less like religion. There's a clergy (researchers, teachers, engineers) and there are various holy texts (school manuals, papers, specialized books).</p>
<p>I think a good indication of this failure mode is that people stuck here don't seem to differentiate between "what other humans in authority positions are saying" versus "what we observe in the world" as having fundamentally different epistemic weight.</p>
<p>Good examples here are e.g. young-earth creationists, people the believe the earth was created ~6000 years ago. Most of these kinds of people are obviously not scientists, but some are, a quick google search brings up Duane Gish (Berkely P.hD) and Kurt Wise (professor at a no-name university in Georgia).</p>
<p>However, young-earth creationism is not the only unscientific belief system people have, there are insane conspiracy theories aplenty, from vaccines being brainwashing mechanisms or 5G causing viral infections.</p>
<p>This kind of insanity is usually not represented in people affiliated with scientific or engineer institutions, but I'm unsure it is for the right reasons.</p>
<p>That is to say, assume you think of science as a religion. Your epistemology is based on what other people tell you, you weigh that by their social rank and thus derive what you hold as "truth".</p>
<p>Assume you are a doctor that falls into this category and 70% of your friends tell you "5G towers cause covid-19". Well, then, you could probably start believing that yourself. <em>But</em> keep in mind, it's not the only number of people that matters, the status also matters. If the priest tells you about the word of God that counts 100x as much as the village idiot telling you about the word of God.</p>
<p>Even with this context, if our good doctor's boss tells him "covid-19 infection is caused by an airborne coronavirus that passes from human to human via various bodily fluids dispersed in the air and on objects", then whatever this boss told him would have enough status magnitude to make him set his opinion on the more scientifically correct explanation.</p>
<p>The problem here is that our good doctor would be unable to come up with this explanation on his own, even in a hypothetical, he lacks even the foundational epistemology required to understand how such answers can be derived.</p>
<p>Even worst, our doctor's boos could share his epistemology, all that would be needed is for her boos to have told her the same thing and she would have believed it in an instant.</p>
<p>This Science as a Religion worldview is likely sprinkled through all engineers and scientists. The reason we don't see it is that for it to become obvious, one needs to start believing an obviously insane thing (e.g. young-earth creationism), however, the chance of this happening is fairly low since it would require all their peers to also believe insane things.</p>
<p>As long as "correct" ideas are observed throughout his professional environment, unless he is socially inept, he will only hold the correct idea.</p>
<p>You would need to look at his research or question him on the scientific method or on his epistemology more broadly in order to spot this mistake. Sadly enough, I've yet to find a university that has "scientific epistemology" as a subject on the entrance exam or even as a graduation or employment requirement.</p>
<p>I won't speculate as to how many people who are called scientists and engineers fall into this failure mode. I think there's a gradient between this and failure mode nr 2.</p>
<p>However, it should be noted that this failure mode is unobvious <strong>until</strong> a new idea comes along. Then, the real scientists will assume it's probably false but judge it on its merit. The religious scientists will assume it's false because their peers haven't said it's right yet.</p>
<p>This is both an issue in regards to new ideas proliferating and an issue with the scientific consensus. Scientific consensus is valuable if you assume everyone pooled reasoned their way through theory, independent research, and primary source dissection to reach a conclusion.</p>
<p>In a world where 90% of scientists just assume that science works like a religion, a 96%-4% consensus is not a good indicator for implementing policy, it's an indicator that the few real scientists are almost evenly split on the correct solution.</p>
<p>This is bleak stuff, if most scientists were understanding science as a religion then the whole institution would be compromised. Not only would academia have to be thrown in the bin, but all evidence and theory produced for the last half-century would have to be carefully curated and replicated before it can be considered scientifically true.</p>
<p>Surface level intuitions want me to think there's a significant probability this might be the case with certain sub-fields. But my theory of mind and the fact that science seems to keep progressing tells me this is unlikely to be the case in relevant areas.</p>
<h2>III - If there's a fit there's a way</h2>
<p>In short, these are the people that don't understand why a regression being fit on all the data is different from using the same regression to determine correlation strength via cross-validation.</p>
<p>I think most people and most scientists probably fall under the second failure mode, they are not Baconians or Popperians, but rather they are Aristotelians.</p>
<p>Aristotle understood the idea that we can observe the world and we can come up with theories about how it works based on observation.</p>
<p>He lacked was a rigorous understanding of how observations should be undertaken. He was probably unaware of the idea of having similar experimental error standards and replications as the rules by which the validity of data can be compared.</p>
<p>He lacked an understanding of the language of probability which would allow him to formulate these experimental standards.</p>
<p>He lacked an understanding of falsifiability and Occam's razor, he didn't have a rigorous system for comparing competing theories.</p>
<p>In an Aristotelian framework, dropping 3 very heavy and well-lackered balls towards Earth and seeing they fall with a constant and equal acceleration barring any wind is enough to say <code>FG = G * m1 * m2 / r^2</code> is a true scientific theory.</p>
<p>If things like the constant <code>G</code> and the mass of the ball and the radius of the earth are already known, then the Aristotelian has no issue with declaring the theory correct. He needn't ask:</p>
<ul>
<li>Why do you assume this holds for all objects? After all, the only thing we have observed is three objects falling towards Earth. Even more, the balls are too light to observe this effect between them.</li>
<li>Why can this equation not be simpler? I could simplify this equation to only a single term if what you wished to describe is just the fall of objects towards the Earth, which is the only thing your experiment is showing anyway.</li>
<li>Why is dropping 3 balls enough to derive anything? Why are 2 not enough, why aren't 100 needed? Also, why is weight the property in question here and not some other property of the ball? Maybe it works for lead balls but not for copper balls?</li>
</ul>
<p>I will grant I might be straw-manning Aristotle here, he would have been able to ask some of those questions, he just didn't have a rigorous frameworks from which to derive them. He was working from Aristotelian logic and intuition.</p>
<p>This seems to be the kind of failure that most people …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG">https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810885</guid>
            <pubDate>Sun, 12 Jul 2020 12:38:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operators and Sidecars Are the New Model for Software Delivery]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23810718">thread link</a>) | @kiyanwang
<br/>
July 12, 2020 | http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html | <a href="https://web.archive.org/web/*/http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Today’s developers are expected to develop resilient and scalable 
distributed systems. Systems that are easy to patch in the face of 
security concerns and easy to do low-risk incremental upgrades. Systems 
that benefit from software reuse and innovation of the open source 
model. Achieving all of this for different languages, using a variety of
 application frameworks with embedded libraries is not possible.</p>
<p>Recently I’ve <a href="https://www.infoq.com/articles/multi-runtime-microservice-architecture/" rel="external" target="_blank">blogged</a>
 about “Multi-Runtime Microservices Architecture” where I have explored 
the needs of distributed systems such as lifecycle management, advanced 
networking, resource binding, state abstraction and how these 
abstractions have been changing over the years. I also&nbsp;<a href="https://www.youtube.com/watch?v=CZPEIJFJV9k" rel="external noopener noreferrer" target="_blank">spoke</a>&nbsp;about&nbsp;“The
 Evolution of Distributed Systems on Kubernetes” covering how Kubernetes
 Operators and the sidecar model are acting as the primary innovation 
mechanisms for delivering the same distributed system primitives.</p>
<p>On both occasions, the main takeaway is the prediction that the 
progression of software application architectures on Kubernetes moves 
towards the sidecar model managed by operators. Sidecars and operators 
could become a mainstream software distribution and consumption model 
and in some cases even replace software libraries and frameworks as we 
are used to.</p>
<p>The sidecar model allows the composition of applications written in 
different languages to deliver joint value, faster and without the 
runtime coupling. Let’s see a few concrete examples of sidecars and 
operators, and then we will explore how this new software composition 
paradigm could impact us.</p>
<h2>Out-of-Process Smarts on the Rise</h2>
<p>In Kubernetes, a sidecar is one of the <a href="http://k8spatterns.io/" rel="external" target="_blank">core design patterns</a>
 achieved easily by organizing multiple containers in a single Pod. The 
Pod construct ensures that the containers are always placed on the same 
node and can cooperate by interacting over networking, file system or 
other IPC methods. And <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/" rel="external" target="_blank">operators</a>
 allow the automation, management and integration of the sidecars with 
the rest of the platform. The sidecars represent a language-agnostic, 
scalable data plane offering distributed primitives to custom 
applications. And the operators represent their centralized management 
and control plane.</p>
<p>Let’s look at a few popular manifestations of the sidecar model.</p>
<h3>Envoy</h3>
<p>Service Meshes such as Istio, Consul, and others are using transparent service proxies such as <a href="https://www.envoyproxy.io/" rel="external" target="_blank">Envoy</a>
 for delivering enhanced networking capabilities for distributed 
systems. Envoy can improve security, it enables advanced traffic 
management, improves resilience, adds deep monitoring and tracing 
features. Not only that, it understands more and more Layer 7 protocols 
such as Redis, MongoDB, MySQL and most recently Kafka. It also added 
response caching capabilities and even WebAssembly support that will 
enable all kinds of custom plugins. Envoy is an example of how a 
transparent service proxy adds advanced networking capabilities to a 
distributed system without including them into the runtime of the 
distributed application components.</p>
<h3>Skupper</h3>
<p>In addition to the typical service mesh, there are also projects, such as<a href="https://skupper.io/" rel="external" target="_blank"> Skupper</a>,
 that ship application networking capabilities through an external 
agent. Skupper solves multicluster Kubernetes communication challenges 
through a Layer 7 virtual network and offers advanced routing and 
connectivity capabilities. But rather than embedding Skupper into the 
business service runtime, it runs an instance per Kubernetes namespace 
which acts as a shared sidecar.</p>
<h3>Cloudstate</h3>
<p><a href="https://cloudstate.io/" rel="external" target="_blank">Cloudstate</a>
 is another example of the sidecar model, but this time for providing 
stateful abstractions for the serverless development model. It offers 
stateful primitives over GRPC for EventSourcing, CQRS, Pub/Sub, 
Key/Value stores and other use cases. Again, it an example of sidecars 
and operators in action but this time for the serverless programming 
model.</p>
<h3>Dapr</h3>
<p><a href="https://dapr.io/" rel="external" target="_blank">Dapr</a>
 is a relatively young project started by Microsoft, and it is also 
using the sidecar model for providing developer-focused distributed 
system primitives. Dapr offers abstractions for state management, 
service invocation and fault handling, resource bindings, pub/sub, 
distributed tracing and others. Even though there is some overlap in the
 capabilities provided by Dapr and Service Mesh, both are very different
 in nature. Envoy with Istio is injected and runs transparently from the
 service and represents an operational tool. Dapr, on the other hand, 
has to be called explicitly from the application runtime over HTTP or 
gRPC and it is an explicit sidecar targeted for developers. It is a 
library for distributed primitives that is distributed and consumed as a
 sidecar, a model that may become very attractive for developers 
consuming distributed capabilities.</p>
<h3>Camel K</h3>
<p>Apache Camel is a mature integration library that rediscovers itself on Kubernetes. Its subproject <a href="https://camel.apache.org/camel-k/latest/index.html" rel="external" target="_blank">Camel K</a>
 uses heavily the operator model to improve the developer experience and
 integrate deeply with the Kubernetes platform. While Camel K does not 
rely on a sidecar, through its CLI and operator it is able to reuse the 
same application container and execute any local code modification in a 
remote Kubernetes cluster in less than a second. This is another example
 of developer-targeted software consumption through the operator model.</p>
<h2>More to Come</h2>
<p>And these are only some of the pioneer projects exploring various 
approaches through sidecars and operators. There is more work being done
 to reduce the networking overhead introduced by container-based 
distributed architectures such as the data plane development kit (<a href="https://www.dpdk.org/" rel="external" target="_blank">DPDK</a>),
 which is a userspace application that bypasses the layers of the Linux 
kernel networking stack and access directly to the network hardware. 
There is work in the Kubernetes project to create <a href="https://github.com/kubernetes/enhancements/issues/753" rel="external" target="_blank">sidecar</a> containers with more granular lifecycle guarantees. There are new Java projects based on GraalVM implementation such as <a href="https://quarkus.io/" rel="external" target="_blank">Quarkus</a>
 that reduce the resource consumption and application startup time which
 makes more workloads attractive for sidecars. All of these innovations 
will make the side-car model more attractive and enable the creation of 
even more such projects.</p>
<p><a href="https://1.bp.blogspot.com/-ajKfxQnN7Eg/Xs1961D9WzI/AAAAAAAAORs/_hu-KhmUN1wsQ8PfeIaNKaHNVyi8-3iYACK4BGAsYHg/d/multiruntine1.png"><img alt="Sidecars Providing Distributed Systems Primitives" data-original-height="944" data-original-width="1670" height="226" src="https://1.bp.blogspot.com/-ajKfxQnN7Eg/Xs1961D9WzI/AAAAAAAAORs/_hu-KhmUN1wsQ8PfeIaNKaHNVyi8-3iYACK4BGAsYHg/w400-h226/multiruntine1.png" title="Sidecars Providing Distributed Systems Primitives" width="400"></a></p><p>Sidecars providing distributed systems primitives</p>
<p>I’d not be surprised to see projects coming up around more specific 
use cases such as stateful orchestration of long-running processes such 
as Business Process Model and Notation (BPMN) engines in sidecars. Job 
schedulers in sidecars. Stateless integration engines i.e. Enterprise 
Integration Patterns implementations in sidecars. Data abstractions and 
data <a href="https://github.com/teiid/teiid-operator" rel="external" target="_blank">federation</a> engines in sidecars. OAuth2/<a href="https://github.com/louketo/louketo-proxy" rel="external" target="_blank">OpenID</a>
 proxy in sidecars. Scalable database connection pools for serverless 
workloads in sidecars. Application networks as sidecars, etc. But why 
would software vendors and developers switch to this model? Let’s see a 
few of the benefits it provides.</p>
<h2>Runtimes with Control Planes over Libraries</h2>
<p>If you are a software vendor today, probably you have already 
considered offering your software to potential users as an API or a 
SaaS-based solution. This is the fastest software consumption model and a
 no-brainer to offer, when possible. Depending on the nature of the 
software you may be also distributing your software as a library or a 
runtime framework. Maybe it is time to consider if it can be offered as a
 container with an operator too. This mechanism of distributing software
 and the resulting architecture has some very unique benefits that the 
library mechanism cannot offer.</p>
<h3>Supporting Polyglot Consumers</h3>
<p>By offering libraries to be consumable through open protocols and 
standards, you open them up for all programming languages. A library 
that runs as a sidecar and consumable over HTTP, using a text format 
such as JSON does not require any specific client runtime library. Even 
when gRPC and Protobuf are used for low-latency and high-performance 
interactions, it is still easier to generate such clients than including
 third party custom libraries in the application runtime and implement 
certain interfaces.</p>
<h3>Application Architecture Agnostic</h3>
<p>The explicit sidecar architecture (as opposed to the transparent one)
 is a way of software capability consumption as a separate runtime 
behind a developer-focused API. It is an orthogonal feature that can be 
added to any application whether that is monolithic, microservices, 
functions-based, actor-based or anything in between. It can sit next to a
 monolith in a less dynamic environment, or next to every microservice 
in a dynamic cloud-based environment. It is trivial to create sidecars 
on Kubernetes, and doable on many other software orchestration platforms
 too.</p>
<h3>Tolerant to Release Impedance Mismatch</h3>
<p>Business logic is always custom and developed in house. Distributed 
system primitives are well-known commodity features, and consumed 
off-the-shelf as either platform features or runtime libraries. You 
might be consuming software for state abstractions, messaging clients, 
networking resiliency and monitoring libraries, etc. from third-party 
open source projects or companies. And these third party entities have 
their release cycles, critical fixes, CVE patches that impact your 
software release cycles too. When third party libraries are consumed as a
 separate runtime (sidecar), the upgrade process is simpler as it is 
behind an API and it is not coupled with your application runtime. The 
release impedance mismatch between your team and the consumed 3rd party 
libraries vendors becomes easier to manage.</p>
<h3>Control Plane Included Mentality</h3>
<p>When a feature is consumed as a library, it is included in your 
application runtime and it becomes your responsibility to understand how
 it works, how to configure, monitor, tune and upgrade. That is because 
the language runtimes (such as the JVM) and the runtime frameworks (such
 as Spring Boot or application servers) dictate how a third-party 
library can be included, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html">http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html</a></em></p>]]>
            </description>
            <link>http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810718</guid>
            <pubDate>Sun, 12 Jul 2020 12:03:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft to End Support of PHP on Windows]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23810641">thread link</a>) | @kiyanwang
<br/>
July 12, 2020 | https://externals.io/message/110907 | <a href="https://web.archive.org/web/*/https://externals.io/message/110907">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="110909-body">
            <div>
                <p>Hi Sara,</p>
<p>Thank you for responding back.</p>
<p>We have tooling in place to allow for building and testing.  We did build the latest bits on 8.0 to test some things, but we are not moving forward with any more builds.</p>
<p>Please let me know how we can help with the transition as it moves forward.</p>
<p>Thank you for your time,</p>
<p>Dale</p>
<p>From: Sara Golemon <a href="https://externals.io/cdn-cgi/l/email-protection#5929363535302d381929312977373c2d"><span data-cfemail="8efee1e2e2e7faefcefee6fea0e0ebfa">[email&nbsp;protected]</span></a> <br>
Sent: Thursday, July 9, 2020 1:01 PM <br>
To: Dale Hirt <a href="https://externals.io/cdn-cgi/l/email-protection#2743464b424f4e5553674a4e445548544841530944484a"><span data-cfemail="14707578717c7d666054797d77667b677b72603a777b79">[email&nbsp;protected]</span></a> <br>
Cc: PHP Internals <a href="https://externals.io/cdn-cgi/l/email-protection#a9c0c7ddccdbc7c8c5dae9c5c0daddda87d9c1d987c7ccdd"><span data-cfemail="c9a0a7bdacbba7a8a5ba89a5a0babdbae7b9a1b9e7a7acbd">[email&nbsp;protected]</span></a>; <a href="https://externals.io/cdn-cgi/l/email-protection#f0809880dd87999e949f8783b09c99838483de809880de9e9584" rel="nofollow" target="_blank"><span data-cfemail="d4a4bca4f9a3bdbab0bba3a794b8bda7a0a7faa4bca4fabab1a0">[email&nbsp;protected]</span></a>; <a href="https://externals.io/cdn-cgi/l/email-protection#e68f8892839488878a95cb918f88a68a8f959295c8968e96c8888392" rel="nofollow" target="_blank"><span data-cfemail="c3aaadb7a6b1ada2afb0eeb4aaad83afaab0b7b0edb3abb3edada6b7">[email&nbsp;protected]</span></a>; Greg Arnits <a href="https://externals.io/cdn-cgi/l/email-protection#7c1b0e191b1d0e3c11151f0e130f131a08521f1311"><span data-cfemail="97f0e5f2f0f6e5d7fafef4e5f8e4f8f1e3b9f4f8fa">[email&nbsp;protected]</span></a>; Antoni Hathaway <a href="https://externals.io/cdn-cgi/l/email-protection#65240b110a0b0c4b2d04110d0412041c25080c06170a160a03114b060a08"><span data-cfemail="93d2fde7fcfdfabddbf2e7fbf2e4f2ead3fefaf0e1fce0fcf5e7bdf0fcfe">[email&nbsp;protected]</span></a> <br>
Subject: [EXTERNAL] Re: [PHP-DEV] Microsoft Support of PHP on Windows</p>
<p>My name is Dale Hirt and I am the project manager for PHP inside Microsoft. <br>
We are not, however, going to be supporting PHP for Windows in any capacity for version 8.0 and beyond.</p>
<p>Hi Dale! <br>
First, let me convey all our appreciation for the work Microsoft has put into supporting PHP on Windows over the years.  Thank you also for letting us know in advance to not expect 8.0 builds.  I guess this decision must have only been made very recently since 8.0.0alpha1 and alpha2 builds were produced already.</p>
<p>I won't say I'm not bummed, of course.  Nevertheless, y'all gotta do what you gotta do.  I'm sure we can work out an alternative by the end of the year.</p>
<p>All the best, <br>
-Sara Golemon (PHP 8.0 Release Manager)</p>

            </div>
                    </div></div>]]>
            </description>
            <link>https://externals.io/message/110907</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810641</guid>
            <pubDate>Sun, 12 Jul 2020 11:48:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frank Gehry started off building cities with his grandma]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23810540">thread link</a>) | @pseudolus
<br/>
July 12, 2020 | https://www.cbc.ca/radio/podcastnews/frank-gehry-started-off-building-cities-with-his-grandma-1.5491434 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/podcastnews/frank-gehry-started-off-building-cities-with-his-grandma-1.5491434">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>World renowned architect Frank Gehry is comfortable talking about his work but when asked about his early days, the 91 year old pauses. "Now you're gonna make me cry." In a wide-sweeping conversation he recalls the roots of his curiosity, and they days when he's build wood block cities with his grandma.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5491446.1583781956!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/frank-gehry.JPG"></p></div><figcaption>At 91, architect Frank Gehry is still dreaming up and working on new projects. "There's always something new to chase after, some new corner to turn around and go around."<!-- --> <!-- -->(Mike Blake/Reuters)</figcaption></figure><p><span></span><span>Listen<!-- --> to the full episode</span><span>54:27</span></p><p><span><p>It's pretty easy to spot a Frank Gehry building: all curves and glass and movement.</p>  <p>He'll tell you his designs — from the Guggenheim Museum in Bilbao, Spain to the Walt Disney Concert Hall in Los Angeles — "speak" to the buildings and environment around them. But to the onlooker, they clearly stand apart.&nbsp;</p>    <p>In the latest episode of <em>More&nbsp;with Anna Maria Tremonti</em>, it also becomes clear that Gehry sees his buildings as a way to bring people together,&nbsp;and sees his own role in life as much more than an architect. In a wide-sweeping conversation, he traces his craft back to the days when his grandmother would encourage him to build cities out of&nbsp;wood blocks&nbsp;for the fire — an act of imagination he's adapted for&nbsp;students of today.&nbsp;</p>  <p><em>The following excerpt from their conversation has been condensed for length and clarity. Find the full interview here or on your favourite podcast app.</em></p>  <p><strong>As I listen to you I hear that you are so much more than an architect. That you care&nbsp;about more than the building of buildings.</strong></p>  <p>I do, yeah. Well I grew up that way.</p>  <p>You know my grandfather used to read Talmud to me. I don't think he was&nbsp;sellout religious. He was just interested in the philosophy. And Talmud starts with the word "Why." It's about curiosity. And I think that is really important. You've got to be curious.&nbsp;</p>  <p>Buildings are backgrounds for activity but the activity has to be&nbsp;a life, a thing. It's got to be more than just making money. It's a cultural thing and it brings people together to talk to each other, live together, work together. So, just the building alone is not that relevant.</p>  <p><strong>Do you think that most architects understand that? Most people?</strong></p>  <p>Not most.&nbsp;I don't think so.</p>  <p>Although architects tend to be idealists. They start out very idealistic. They want to make the world better. Most of the architects I know and work with have an idealistic base. They're trying to make a better world.&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/frank-gehry.JPG 300w,https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/frank-gehry.JPG 460w,https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/frank-gehry.JPG 620w,https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/frank-gehry.JPG 780w,https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/frank-gehry.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/frank-gehry.JPG"></p></div><figcaption>People pass in front of the Frank Gehry designed Guggenheim Museum at dusk in Bilbao.<!-- --> <!-- -->(Reuters)</figcaption></figure></span></p>  <p><strong>How important was your family life in creating the man who you are today? Those early days when you were a kid.</strong></p>  <p>Okay, so now you're gonna make me cry. Well my grandparents were great. My grandmother brought the wood blocks home for the fire, for the wood stove. And she would throw them on the floor and make cities with me.</p>    <p>And I don't know why she decided to do that. Architecture wasn't in any part of our family at that time. So that was an&nbsp;important memory.</p>  <p>My father was not educated at all. He probably didn't even go to school. He was living on the streets in New York — Tenth Avenue. His father was a tailor who came from Russia and is actually buried in Toronto. And his name was Frank Goldberg. So there is a Frank Goldberg buried in a cemetery in Toronto — that's my grandfather.</p>  <p>Anyway, so my father ...&nbsp;had a heart attack at 49. He lost everything. And his brother moved him to L.A.</p>  <p>We got here and we were very poor because he had lost everything. But he became a truck driver and I became a truck driver. I was 17 or 18. Now, after he's gone — he died at 63 or something like that — I've seen evidence now that I find in some of the things he left behind, that we never looked at really until recently, and it's pretty clear that he had an artistic bent and that that's what he liked doing.</p>  <p>He would paint toys for people. He would make things.&nbsp;I remember him drawing with me but he never got to see what I started to do. By time I was an architect, he was out of it.</p>  <p><strong>What do you think you would have thought of your work? Would he have been proud of you?</strong></p>  <p>He would be shocked and proud. I think, yeah. I liked that thought.&nbsp;</p>    <p><strong>So, what advice do you give to your son as he tries to carve his own path?</strong></p>  <p>Just stay curious. Do where your head takes you. And be conscious of the people who are working with you and the people who are you're working for and the importance of what you do in relation to your contribution to what's going on around us.</p>  <p><strong>That sounds like advice you could give to lots of people.</strong></p>  <p>Yeah. Well, I'm not holier than thou about it.&nbsp;I know that I just live that way. But there's a lot of different ways to live and still be creative and still be part of the world and still be doing important things. So my way is not the only example.&nbsp;</p>  <p><strong>Well, I think in these times though it's nice to hear you know to connect the work you do and the wider concept of architecture to the idea of humanity and being humane.</strong> <strong>I think it's a really important thing to hear from you.</strong></p>  <p>Yeah. But I think the history of architecture shows that that was prevalent from the beginning.</p>  <p>You know all the great artists of the Renaissance became architects. So Giotto was a great painter, became an architect. El Greco was a great painter, became an architect. Architecture was treated as an art in those times.</p>    <p>After the war here architecture became less of an art and more&nbsp;engineering issues and financial issues. And not that they're not important but that became the driver. Not the humanity of it. And that's why our cities are kind of the way they are I think. And the cities look the same all over the world. You go to Seoul, Korea. It looks like downtown L.A.</p>  <p><strong>Do you see yourself as an artist more than an architect?</strong></p>  <p>Absolutely. I hope so.&nbsp;I think it's the same. They're not mutually exclusive. When I got out of school, I hung out with the artists more than with the architects because I just felt that's where I should be. And I still do.</p>    <div>   <h2>Want to hear the full conversation?</h2>   <p>Listen for free at&nbsp;<a href="https://www.cbc.ca/radio/podcasts/more-with-anna-maria-tremonti/index.html">cbc.ca/more</a>&nbsp;or on your favourite podcast app — including&nbsp;<a href="https://podcasts.apple.com/ca/podcast/more-with-anna-maria-tremonti/id1494930679">Apple Podcasts</a>,&nbsp;<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly93d3cuY2JjLmNhL3BvZGNhc3RpbmcvaW5jbHVkZXMvbW9yZS54bWw%3D">Google Podcasts</a>&nbsp;and&nbsp;<a href="https://open.spotify.com/show/17PsCUS5j6WN1GiqBGDIxn">Spotify</a>. And if you're new to podcasts&nbsp;entirely,&nbsp;<a href="https://www.cbc.ca/radio/how-to-download-a-podcast-1.4593484">start here</a>.&nbsp;</p>   <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/frank-gehry.jpg 300w,https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/frank-gehry.jpg 460w,https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/frank-gehry.jpg 620w,https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/frank-gehry.jpg 780w,https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/frank-gehry.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/frank-gehry.jpg"></p></div><figcaption>Episode 7: "Frank Gehry built small cities with grandma" is available now on the More with Anna Maria Tremonti podcast.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  </div>    </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/podcastnews/frank-gehry-started-off-building-cities-with-his-grandma-1.5491434</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810540</guid>
            <pubDate>Sun, 12 Jul 2020 11:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM looking for 12 years’ experience in Kubernetes administration]]>
            </title>
            <description>
<![CDATA[
Score 384 | Comments 251 (<a href="https://news.ycombinator.com/item?id=23810519">thread link</a>) | @tosh
<br/>
July 12, 2020 | https://intellijobs.ai/job/IBMCloud-Native-Infrastructure-Engineer-Architect-bvJJ6yraexfWOk1nMRKP-bvJJ6yraexfWOk1nMRKP | <a href="https://web.archive.org/web/*/https://intellijobs.ai/job/IBMCloud-Native-Infrastructure-Engineer-Architect-bvJJ6yraexfWOk1nMRKP-bvJJ6yraexfWOk1nMRKP">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://intellijobs.ai/job/IBMCloud-Native-Infrastructure-Engineer-Architect-bvJJ6yraexfWOk1nMRKP-bvJJ6yraexfWOk1nMRKP</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810519</guid>
            <pubDate>Sun, 12 Jul 2020 11:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Animals Keep Pets?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810320">thread link</a>) | @sjcsjc
<br/>
July 12, 2020 | https://primatology.net/2010/07/05/do-animals-keep-pets/ | <a href="https://web.archive.org/web/*/https://primatology.net/2010/07/05/do-animals-keep-pets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>After reading an article from <em>Psychology Today <span>by Hal Herzog,</span></em> it got me thinking about the idea of pet-keeping.&nbsp;The article&nbsp;“<a href="http://www.psychologytoday.com/blog/animals-and-us/201006/are-humans-the-only-animals-keep-pets"><em>Are Humans The Only Animals That Keep Pets?</em></a>“, claims that humans are the only animal that keeps members of other species for an extended point of time purely for enjoyment. Herzog points out that while&nbsp;some animals are documented having pets, this behavior almost always happen in captive or semi-captive environment where food and shelter are provided.&nbsp;The author believes that humans are “true” pet owners because the owner-pet relationship occurs in a natural setting and argues that animal pet owners are not “true” pet owners because they do so in captive or semi-captive settings. Thus, Herzog believes that humans are the only animals that keep pets.</p>
<p>Cited in the article is a paper by Izar et al. (2006), on cross-genus adoption of a marmoset by wild capuchin monkeys (link to the paper is below on References). While the paper specifically refers to the behavior as an adoption, Herzog and paper co-author Dorothy Fragaszy think that there is a parallel between the capuchin-marmoset adoption and pet-keeping in humans. However, these capuchins live in a site where food are provided daily. So,&nbsp;Despite the similarities,&nbsp;these capuchins are not “true” pet owners&nbsp;according to Herzog’s definition of pet-keeping,</p>
<p><a href="http://4.bp.blogspot.com/_Hbo7Ung0Hbg/TC1ORXYQLXI/AAAAAAAABX8/VTgk4NGKO4I/s1600/capuchin+marmoset.jpg"><img src="https://i2.wp.com/4.bp.blogspot.com/_Hbo7Ung0Hbg/TC1ORXYQLXI/AAAAAAAABX8/VTgk4NGKO4I/s320/capuchin+marmoset.jpg" alt="" width="256" height="320"></a></p>
<p>A young marmoset taking food (cracked palm nut) from its adoptive mother’s (capuchin) hand. Photo&nbsp;by Jeanne Shirley (Izar et al., 2006).</p>
<p>What is a pet and how would you define one? Herzog (2010) defines a pet as a member of other species that are being kept for an extended period of time for enjoyment. According to the Merriam-Webster dictionary, the definition of a pet is “a domesticated animal kept for pleasure rather than utility”. The definition of a pet in Oxford English Dictionary is “a domestic or tamed animal or bird kept for companionship or pleasure and treated with care and affection”.&nbsp;<a href="http://www.vet.upenn.edu/FacultyandDepartments/Faculty/tabid/362/Default.aspx?faculty_id=6361798">Dr. James Serpell</a> defines pet-keeping as a leisure activity but not necessarily without function, much like there are function in play or other recreational pursuits (Serpell, 1990). He thinks that pet-keeping is functional in a broad sense but not easily evaluable in economic terms.</p>
<p><a href="http://1.bp.blogspot.com/_Hbo7Ung0Hbg/TC0T9RLNqeI/AAAAAAAABX4/ou8MLJEVT30/s1600/great+ape_cats.jpg"><img src="https://i1.wp.com/1.bp.blogspot.com/_Hbo7Ung0Hbg/TC0T9RLNqeI/AAAAAAAABX4/ou8MLJEVT30/s320/great+ape_cats.jpg" alt="" width="320" height="153"></a></p>
<div>
<p>Some primate pet owners include (left)&nbsp;<a href="http://en.wikipedia.org/wiki/Koko_(gorilla)">Koko</a> and (right)&nbsp;<a href="http://en.wikipedia.org/wiki/Tonda_(orangutan)">Tonda</a>,&nbsp;who both had cats as pets.</p>
<p>While it is impossible to define what a pet is from an animal standpoint, at least in humans, we can agree that a pet can be defined as a companion animal that we treat with affection whose function is to provide us with&nbsp;enjoyment.</p>
<p>Did the behavior of animal domestication evolved into pet-keeping? Is pet-keeping a reflection of human’s nurturing instinct? Or is pet-keeping a reflection of human’s constant need of social interaction, even outside of our own species? What do you think? Well … that’s for another blog post.</p>
</div>
<p>References:</p>
<p>Herzog, H. 2010.&nbsp;<em><span>Are Humans The Only Animals That Keep Pets?</span> </em>Retrieved July 1, 2010&nbsp;<a href="http://www.psychologytoday.com/blog/animals-and-us/201006/are-humans-the-only-animals-keep-pets">http://www.psychologytoday.com/blog/animals-and-us/201006/are-humans-the-only-animals-keep-pets</a></p>
<p>Izar, P. Verderane, MP. Visalberghi E. Ottoni, E. De Oliveira, MG. Shirley, J. Fragaszy, D. 2006. Cross-Genus Adoption of a Marmoset (<em>Callithrix jacchus</em>)&nbsp;by Wild Capuchin Monkeys (<em>Cebus libidinosus</em>):&nbsp;Case Report. <em>American Journal of Primatology</em> 68:692-700. Retrieved July 1, 2010&nbsp;<a href="http://psychology.uga.edu/primate/pub/Cross-genus%20adoption%20AJP%2068,%20692-700%202006.pdf">http://psychology.uga.edu/primate/pub/Cross-genus%20adoption%20AJP%2068,%20692-700%202006.pdf</a></p>
<p>Serpell, JA. 1990. Pet-keeping and Animal Domestication: A reappraisal. <em>In</em> The Walking Larder. Clutton-Brock, J, ed. Pp. 10-21.&nbsp;Massachusetts: Unwin Hyman Inc. Retrieved July 1, 2010&nbsp;<a href="http://research.vet.upenn.edu/Portals/36/media/Serpell_pet_keeping_domestication.pdf">http://research.vet.upenn.edu/Portals/36/media/Serpell_pet_keeping_domestication.pdf</a></p>
<p>Originally posted on <a href="http://theprancingpapio.blogspot.com/2010/07/do-animals-keep-pets.html">The Prancing Papio</a>.</p>
			
			
						</div></div>]]>
            </description>
            <link>https://primatology.net/2010/07/05/do-animals-keep-pets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810320</guid>
            <pubDate>Sun, 12 Jul 2020 10:21:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker Network – Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810286">thread link</a>) | @lukasbar
<br/>
July 12, 2020 | https://knowledgepill.it/posts/docker_network/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/docker_network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Containers need to communicate with each other and outside world.<br>
Docker has wide network capabilities.</p>
<p>What we can do with docker network? How to use it?</p>

<p>What elements we have in docker network?</p>
<ul>
<li>CNM</li>
<li>libnetwork</li>
<li>drivers</li>
</ul>
<p>Docker network concept is based on open-source design specification called Container Network Model(CNM). CNM assume that network drivers should be pluggable.<br>
Docker CNM implementation is in <code>libnetwork</code> library.</p>
<p>What we can do with docker CNM?</p>
<ul>
<li>single-host bridges</li>
<li>multi-host overlay networks</li>
<li>networks plugged into VLAN’s</li>
<li>ingress networks with load balancing
Also we get auto service discovery for our containers.</li>
</ul>
<p>What elements we have in docker CNM implementation?</p>
<ul>
<li>sandboxes - container network stack - isolated - ethernet interfaces, ports, routing tables and DNS config</li>
<li>endpoint - virtual interfaces in containers - veth</li>
<li>networks - virtual switches(bridges) - connect endpoints</li>
</ul>
<p>What drivers are built-in by default into docker(Linux)?</p>
<ul>
<li>bridge</li>
<li>overlay</li>
<li>macvlan</li>
</ul>

<p>By default docker creates one brigde after instalation.</p>
<p>All containers are by default connected to it unless we override it.<br>
To set another non-default network we use <code>--network</code> flag for <code>docker run</code>.</p>
<p>What is the diference between default bridge and user created one:</p>
<ul>
<li>Default brigde is less secure - provide less isolation - by default all containers will be connected to it</li>
<li>We can connect/disconnect containers from user defined bridges without restarting containers</li>
<li>Defualt bridge does not have DNS included - we must use IP in such network - on user defined bridge we get DNS(all containers added to bridge network automatically will be added also to DNS) - just connect container to bridge and you can talk with other containers in network by their names(works for named containers with <code>--name</code> at creation time)</li>
</ul>
<p>We can see that all default networks are local - what means that we can’t connect with them containers on multiple docker hosts.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker network ls</span>
NETWORK ID          NAME                DRIVER              SCOPE
740857ece0a5        bridge              bridge              local
13396ccbb663        host                host                local
44424eae56f4        none                null                local
</code></pre></div><p>We can check details about default bridge network</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker network inspect bridge</span>
<span>[</span>
    <span>{</span>
        <span>"Name"</span>: <span>"bridge"</span>,
        <span>"Id"</span>: <span>"740857ece0a5fc38891b919d2f7506e32e699b4e79a449f8fef9824d0cde39b2"</span>,
        <span>"Created"</span>: <span>"2020-05-07T21:07:19.137450998+02:00"</span>,
        <span>"Scope"</span>: <span>"local"</span>,
        <span>"Driver"</span>: <span>"bridge"</span>,
        <span>"EnableIPv6"</span>: false,
        <span>"IPAM"</span>: <span>{</span>
            <span>"Driver"</span>: <span>"default"</span>,
            <span>"Options"</span>: null,
            <span>"Config"</span>: <span>[</span>
                <span>{</span>
                    <span>"Subnet"</span>: <span>"172.17.0.0/16"</span>,
                    <span>"Gateway"</span>: <span>"172.17.0.1"</span>
                <span>}</span>
            <span>]</span>
        <span>}</span>,
        <span>"Internal"</span>: false,
        <span>"Attachable"</span>: false,
        <span>"Ingress"</span>: false,
        <span>"ConfigFrom"</span>: <span>{</span>
            <span>"Network"</span>: <span>""</span>
        <span>}</span>,
        <span>"ConfigOnly"</span>: false,
        <span>"Containers"</span>: <span>{</span><span>}</span>,
        <span>"Options"</span>: <span>{</span>
            <span>"com.docker.network.bridge.default_bridge"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.enable_icc"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.enable_ip_masquerade"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.host_binding_ipv4"</span>: <span>"0.0.0.0"</span>,
            <span>"com.docker.network.bridge.name"</span>: <span>"docker0"</span>,
            <span>"com.docker.network.driver.mtu"</span>: <span>"1500"</span>
        <span>}</span>,
        <span>"Labels"</span>: <span>{</span><span>}</span>
    <span>}</span>
<span>]</span>
</code></pre></div><p>As we see docker bridge is build on Linux bridge:</p>
<div><pre><code data-lang="bash"><span>"com.docker.network.bridge.name"</span>: <span>"docker0"</span>
</code></pre></div><div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># ip link show docker0</span>
3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span>1500</span> qdisc noqueue state DOWN mode DEFAULT group default
    link/ether 02:42:9d:73:fa:48 brd ff:ff:ff:ff:ff:ff
</code></pre></div><h2 id="creating-network-bridge">Creating network bridge</h2>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker network create -d bridge lukas-bridge</span>
3836e34c6950d80e032e322f915935b51472059ea19cfd65c409263c74ba2b45
</code></pre></div><div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># ip a</span>
&lt;snip&gt;
5: br-3836e34c6950: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span>1500</span> qdisc noqueue state DOWN group default
    link/ether 02:42:0b:b8:19:54 brd ff:ff:ff:ff:ff:ff
    inet 172.19.0.1/16 brd 172.19.255.255 scope global br-6c8ad698150b
       valid_lft forever preferred_lft forever
</code></pre></div><p>As we see there is new bridge at OS level with name coresponding to ID of our newly created docker bridge.</p>
<h2 id="starting-container-connected-to-new-bridge">Starting container connected to new bridge</h2>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker container run -d --name web_server --network lukas-bridge httpd</span>
08e885099d0ebca6ab5b533bffd0245dccfaab79149657ad9161fe26c370b879
</code></pre></div><h2 id="list-containers-connected-to-network">List containers connected to network</h2>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker network inspect lukas-bridge --format "{{json .Containers}}"</span>
<span>{</span><span>"08e885099d0ebca6ab5b533bffd0245dccfaab79149657ad9161fe26c370b879"</span>:<span>{</span><span>"Name"</span>:<span>"web_server"</span>,<span>"EndpointID"</span>:<span>"ade95c4b553f8cebfbf8f24338b6d0f9e7b2d41744c501816ac734d1bb8ccc1f"</span>,<span>"MacAddress"</span>:<span>"02:42:ac:14:00:02"</span>,<span>"IPv4Address"</span>:<span>"172.20.0.2/16"</span>,<span>"IPv6Address"</span>:<span>""</span><span>}</span><span>}</span>
</code></pre></div><h2 id="test-connection-between-containers-connected-to-bridge">Test connection between containers connected to bridge</h2>
<p>If we use <code>--name</code> flag when creating container we can use docker built-in DNS feature.
Containers automatically know hostname to ip mapping of other containers.</p>
<p>Create second container:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker container run -d --name web_server2 --network lukas-bridge httpd</span>
34bb16b0c43c64c935c8a44c0ed13fa2a7972f79700db290144eba54aa93336a
</code></pre></div><p>Get into one of containers and ping other one</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker exec -it web_server2 /bin/bash</span>
root@34bb16b0c43c:/usr/local/apache2# ping web_server

PING web_server <span>(</span>172.20.0.2<span>)</span> 56<span>(</span>84<span>)</span> bytes of data.
<span>64</span> bytes from web_server <span>(</span>172.20.0.2<span>)</span>: icmp_seq<span>=</span><span>1</span> ttl<span>=</span><span>64</span> time<span>=</span>0.712 ms
<span>64</span> bytes from web_server <span>(</span>172.20.0.2<span>)</span>: icmp_seq<span>=</span><span>2</span> ttl<span>=</span><span>64</span> time<span>=</span>0.649 ms
^C
</code></pre></div>
<p>We can add DNS to container - this DNS will be queired when Docker built-in DNS won’t be able to resolve request.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker run -d --dns 8.8.8.8 httpd</span>
4bde944868b492a5cef84676de1cfb1a211069c67c494d4ab742115d4fc17ee9

<span>[</span>root@docker-host1 ~<span>]</span><span># docker exec -it 4bde944868b492a5cef84676de1cfb1a211069c67c494d4ab742115d4fc17ee9 bash</span>
root@4bde944868b4:/usr/local/apache2# cat /etc/resolv.conf
search lukas.int
nameserver 8.8.8.8
</code></pre></div>
<p>We can tell docker to expose port from container on docker host port that other server or clients can access service running in container.<br>
We can achive this with <code>--publish</code> flag.</p>
<h2 id="start-container-with-port-published">Start container with port published</h2>
<p>We start container with <code>httpd</code> service which expose port 80 - to connect to this port in container we can connect to docker host on port 1234.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker run -d --name web_server --network lukas-bridge --publish published=1234,target=80  httpd</span>
304ddf53a801763c769545eb91c6c5522fc2eedf7cf5f4d252bace1d5e0b8a37
</code></pre></div><h2 id="check-what-ports-are-published-from-container">Check what ports are published from container</h2>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker port web_server</span>
80/tcp -&gt; 0.0.0.0:1234
</code></pre></div>
<p>Docker gives us possibility to integrate container network stack into host stack.<br>
In such situation container will not get his own IP address and MAC(neither externally from docker host network, neither internally from network created by docker engine) - he will be reachable as he will be normal software running on our host.</p>
<p>This is good solution if we want to run some software that use network but we want to have full isolation of process(pid), mount(mnt), user and IPC namespaces.</p>
<p>To active such mode we use <code>--network=host</code> parameter to <code>docker run</code>.<br>
In this mode <code>--publish</code> doesn’t work - if service in container listen on port 80 - port 80 on docker host will be taken.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker run -d --name web_server --network host httpd</span>
dedc6c9e1c05ccb3621fa4272975036f7b9266371a20221f3ba9dbc237eff3b0
</code></pre></div><p>If we inspect container we will see that there is no IP adress and network mode is set to host:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker container inspect web_server</span>
<span>[</span>...<span>]</span>
<span>"NetworkMode"</span>: <span>"host"</span>,
            <span>"PortBindings"</span>: <span>{</span>
                <span>"80/tcp"</span>: <span>[</span>
                    <span>{</span>
                        <span>"HostIp"</span>: <span>""</span>,
                        <span>"HostPort"</span>: <span>"1234"</span>
                    <span>}</span>
<span>[</span>..<span>]</span>
<span>"Networks"</span>: <span>{</span>
    <span>"host"</span>: <span>{</span>
        <span>"IPAMConfig"</span>: null,
        <span>"Links"</span>: null,
        <span>"Aliases"</span>: null,
        <span>"NetworkID"</span>: <span>"13396ccbb6635016d4381588204f9724401cf7200b67cb8f44f065ebfbb8f069"</span>,
        <span>"EndpointID"</span>: <span>"256edba4bd98f86e4a3af9331ff24aca958805ff5f0a3bb202fa67c0b8d4ab07"</span>,
        <span>"Gateway"</span>: <span>""</span>,
        <span>"IPAddress"</span>: <span>""</span>,

</code></pre></div><p>Apache server is listening correctly:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># curl -X GET 127.0.0.1:80</span>
&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;
</code></pre></div>
<p>If we want to expose our container to world but it is important for us that container has got own IP and MAC adress from network where docker host is connected, we can use MACVLAN network driver. It allows also to connect to certain VLAN.</p>
<p>It will create for us docker network - all containers connected to this network will be visible in docker host network as they were normal separate from docker host that host them machines.</p>
<p>Remember that:</p>
<ul>
<li>with MACVLAN you can easily exhaust IP adresses in your network</li>
<li>you have to set network card in promiscious mode</li>
<li>this solution is created mainly for legacy apps or network monitoring apps</li>
</ul>
<hr>
<h3 id="important">Important!</h3>
<p>To use MACVLAN mode our network card has to be in promiscious mode!<br>
Activiting promoscius mode in CentOS(ens18 is my main network card):</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># ip link set ens18 promisc on</span>
</code></pre></div><p>Check if mode was activeted - PROMISC flag:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># ip a</span>
<span>[</span>..<span>]</span>
2: ens18: &lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP&gt; mtu <span>1500</span> qdisc fq_codel state UP group default qlen <span>1000</span>
    link/ether 62:ae:db:67:8c:08 brd ff:ff:ff:ff:ff:ff
    inet 10.10.10.20/24 brd 10.10.10.255 scope global noprefixroute ens18
       valid_lft forever preferred_lft forever
    inet6 fe80::8f98:eb7:2724:a548/64 scope link noprefixroute
       valid_lft forever preferred_lft forever
<span>[</span>...<span>]</span>
</code></pre></div><hr>
<p>As my docker host is in <code>10.10.10.0/24</code> network connected by <code>ens18</code> network card, I will create proper network with macvlan driver.</p>
<p>I also add <code>--ip-range</code> flag because I want that containers get IP’s from second half of my network(in first half are my …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/docker_network/">https://knowledgepill.it/posts/docker_network/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/docker_network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810286</guid>
            <pubDate>Sun, 12 Jul 2020 10:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growing Risks in the Software Supply Chain]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810247">thread link</a>) | @msolujic
<br/>
July 12, 2020 | https://platformsecuritysummit.com/2019/speaker/sherman/ | <a href="https://web.archive.org/web/*/https://platformsecuritysummit.com/2019/speaker/sherman/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <h3 id="growing-risks-in-the-software-supply-chain">Growing Risks in the Software Supply Chain</h3>
<p><strong>Mark Sherman</strong>
<br>
<em>Carnegie Mellon University</em></p>
<p>
Today’s software is largely assembled rather than written, and most of the assembly comes from open source components. The creation of components and their inclusion into applications creates a “supply chain” just like in conventional manufacturing. While physical supply chains have well established chains-of-custody to establish properties like refrigeration maintenance, authenticity or spoilage avoidance, the software supply chain is very much a wild, wild west, filled with vulnerabilities that can be (and are) inadvertently inserted into applications.
</p>
<p>
As supply chain risk and mitigations are being explored by government and academia, a larger attack surface is being uncovered that needs to be addressed. This presentation describes the parts of the software supply chain, how vulnerabilities have been introduced, the growing attack surface from new methods of building and distributing software, and the actions that developers can employ to avoid or mitigate the risks inherent in an assembly-based software development strategy.
</p>






<h3 id="resources">Resources</h3>

<ul>
  <li><a href="https://first.org/">Forum of Incident Response and Security Teams (FIRST)</a> — <a href="https://www.first.org/cvss/workitems">CVSS v4.0</a></li>
  <li>NTIA, <a href="https://www.ntia.doc.gov/SoftwareTransparency">Software Component Transparency</a> —  <a href="https://www.ntia.doc.gov/files/ntia/publications/ntia_sbom_formats_and_standards_whitepaper_2019_0904.pdf">SBOM Survey</a> (2019)</li>
  <li>NIST, <a href="https://csrc.nist.gov/CSRC/media/Presentations/RMF-2-0-Risk-Management-Framework-Simplify-Inno/images-media/sp800-37r2-ipd-rollout-DOJ-20180509.pdf">Risk Management Framework 2.0</a> (2018)</li>
  <li>ATOS, <a href="http://www.qsos.org/method">Method of Qualification and Selection of Open Source software (QSOS)</a> (2013)</li>
  <li>FinServ ISAC, <a href="http://docs.ismgcorp.com/files/external/WP_FSISAC_Third_Party_Software_Security_Working_Group.pdf">Appropriate Software Security Control Types for Third Party Service and Product Providers</a> (2013)</li>
  <li><a href="https://www.us-cert.gov/Information-Sharing-Specifications-Cybersecurity">TAXII, STIX and CybOX</a></li>
</ul>

<h3 id="references">References</h3>

<ul>
  <li>Sonatype, <a href="https://www.sonatype.com/hubfs/SSC/2019%20SSC/SON_SSSC-Report-2019_jun16-DRAFT.pdf">State of the Software Supply Chain</a> (2019)</li>
  <li><em>Graham</em>, <a href="https://www.alienvault.com/blogs/security-essentials/software-bill-of-materials-sbom-does-it-work-for-devsecops">Software Bill of Materials (SBoM) - Does It Work for DevSecOps?</a> (2019)</li>
  <li><em>Alberts et al</em>, <a href="http://www.crosstalkonline.org/storage/issue-archives/2017/201705/201705-alberts.pdf">Assessing DoD System Acquisition Supply Chain Risk Management</a> (2017)</li>
  <li><em>Axelrod</em>, <a href="http://www.crosstalkonline.org/storage/issue-archives/2014/201403/201403-Axelrod.pdf">Malware, Weakware and the Security of Software Supply Chains</a> (2014)</li>
  <li><em>Christey &amp; Martin</em>, Buying Into the Bias: Why Vulnerability Statistics Suck: <a href="https://media.blackhat.com/us-13/US-13-Martin-Buying-Into-The-Bias-Why-Vulnerability-Statistics-Suck-Slides.pdf">slides</a> · <a href="https://www.youtube.com/watch?v=3xs1oWWA6pY">video</a> (Blackhat 2013)</li>
  <li><em>Clark et al</em>, <a href="https://www.researchgate.net/profile/Stefan_Frei2/publication/221046575_Familiarity_breeds_contempt_The_honeymoon_effect_and_the_role_of_legacy_code_in_zero-day_vulnerabilities/links/0deec5270217aa6357000000/Familiarity-breeds-contempt-The-honeymoon-effect-and-the-role-of-legacy-code-in-zero-day-vulnerabilities.pdf?origin=publication_detail">Familiarity Breeds Contempt: The Honeymoon Effect and the Role of Legacy Code in Zero-Day Vulnerabilities</a> (2010)</li>
</ul>

<h3 id="presenter">Presenter</h3>

<ul>
  <li><a href="https://resources.sei.cmu.edu/asset_files/Presentation/2017_017_001_495829.pdf">Risks in the Software Supply Chain</a> (2017)</li>
</ul>



<ul>
  <li><a href="https://cyber-itl.org/">Cyber Independent Testing Lab (CITL)</a></li>
  <li>Linux Foundation, <a href="https://github.com/coreinfrastructure/best-practices-badge/blob/master/doc/criteria.md">Core Infrastructure Initiative (CII) Best Practices for FLOSS</a></li>
</ul>




  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://platformsecuritysummit.com/2019/speaker/sherman/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810247</guid>
            <pubDate>Sun, 12 Jul 2020 10:03:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Being a Full Stack Developer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23809506">thread link</a>) | @ingve
<br/>
July 12, 2020 | https://shekhargulati.com/2020/07/12/on-being-a-full-stack-developer/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2020/07/12/on-being-a-full-stack-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6281">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I am doing software development for the last 15 years. Since I heard the term “Full Stack Developer” few years back I had a strong dislike for this term. To most people full stack developer is someone who can write frontend code, build backend APIs, and deploy applications to cloud. They can code in multiple programming languages(JS/Typescript, Golang/Java/C#/Python), knows enough to design and store data in either relational and NoSQL databases, follow DevOps practices (CI, Configuration management, etc.), knows about multiple architecture styles – Microservices, Monolithic, Serverless, and can at least deploy to one public cloud. Along with all this they also know and practice automation testing and can write clean, maintainable code.</p>



<p>In my 15 years of software engineering career I have grown technically by following many hypes and technology movements. It takes year to build proficiency in technologies and you have to keep evolving yourself.</p>



<ol><li>In my first four (2005-2009) years I got introduced to Agile and extreme programming so I started practicing automation testing, refactoring, and continuous integration since the beginning of my career.</li><li>In my next three (2009-2011) years I got associated with software craftsmanship movement so clean code, SOLID principles became part of me.</li><li>Then in the next three years(2011-2014) I got into NoSQL and cloud computing. I was OpenShift technology evangelist for a couple of years.</li><li>Then in the next five+ (2014-till now) got into DevOps, containerisation, functional programming(Scala, Haskell), React/Angular, Microservices, Serverless, and many other.</li></ol>



<p>I didn’t pick all these technologies in a couple of years. It took me 15 years. I followed different movements and I was at the right place at the right time. So, I end up riding these waves. One thing that is true with technologies is that once you have worked and seen plenty of them then most new technologies make sense easily to you. Many new things are just old rehashed stuff.</p>



<p>These days every young engineer I meet say they are a full stack developer. Most organisations are trying to hire full stack developers with 2-4 years of working experience. We are just fooling ourselves. There are even courses on full stack software development. We find new ways to mint money.</p>



<p>You can’t become a full stack developer in a couple of years. It takes years when you have strong interest in technology and work with good mentors on interesting software development projects over time. </p>



<p>If someone ask me today do if I consider myself a full stack developer then my answer will be No. I have strong preference for backend development but I can do other stuff if required.</p>



<blockquote><p>To me being a full stack developer has less to do with technology but it has more to do with learning and open mindset. The mindset needed to get things done and learn stuff on the job and in your free time. You don’t want to be labelled one thing or the another. You have to care about the whole stuff even when you work in one specific area. It takes years of effort to become proficient in a specific technology area. You can become an expert in one specific technology area but at the same time you should care about other pieces of your ecosystem as well.</p></blockquote>



<p>Let me share a small example. Few months back I had to help a team that was building an application with REST APIs written in Java Spring Boot, frontend written in Angular, and deployment on Azure. The team was rushed into development and timelines were very short. So, they end up taking many shortcuts. One of the shortcuts was that they didn’t use pagination. This all worked well during development when team was working with limited data but when customer testing team tested with realistic data application started giving performance and memory issues. Application code was fetching all the data from database doing filtering and transformation in Java process and dumping everything to frontend in the JSON payload.</p>



<p>The team estimated that to fix the 20 API endpoints they would require 20 man days. It would be combination of database , frontend, and backend developers that would get this done. This was a no go for the customer as it would impact project delivery. But when you have developers who only care and know about their areas you can’t do much. There are hand offs and integration points when people divide work along technology boundaries. It also leads to wasted effort.</p>



<p>In my view these are the situations where having full stack mindset is important. You have to know different aspects of your stack and get your hands dirty with them.</p>



<p>To conclude the example I took two days and got the full thing working i.e. database, backend, frontend. And deployed it to Azure using Kubernetes. It does not mean full application has to be built this way. I can quickly make code changes on already written frontend code but if you ask me to create a frontend app from scratch and care about all nitty-gritties of CSS along with the backend development then I might not be effective. There is a cost of context switching. The cost we pay when we switch between different technologies. I am not proficient in fronted development but I am good enough to reason it out and make changes if required.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2020/07/12/on-being-a-full-stack-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809506</guid>
            <pubDate>Sun, 12 Jul 2020 07:15:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting your entire web application using S3 and CloudFront]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 120 (<a href="https://news.ycombinator.com/item?id=23809318">thread link</a>) | @root993
<br/>
July 11, 2020 | https://www.sankalpjonna.com/posts/hosting-your-entire-web-application-using-s3-cloudfront | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/hosting-your-entire-web-application-using-s3-cloudfront">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>There are several ways to host an application on the internet, but the one that I am most familiar with is to use a web server such as Apache or NGINX where you can host all the static components of your application and also use it as a reverse proxy server to direct API calls.&nbsp;</p><p>‍</p><p>But recently I came across another way to host a web application which is more elegant, cost effective and has no need for maintenance. This method makes use of AWS S3 and AWS Cloudfront and it’s turned out to be significantly easier to set up, scales infinitely and is cheaper than the alternative.</p><p>‍</p><h4><strong>Why did we need S3 to host a web application?</strong><br></h4><p>The <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">product</a> that I have built is currently architected in this way - we use an open source version of Nginx that is hosted on an AWS VPS instance which takes care of hosting our static files for our web app and also works as a reverse proxy server to send API calls to our backend applications.</p><p>This setup worked great so far because we have a limited number of users that need access to the application dashboard and there is no need for a CDN either because the users, especially the ones on a paid plan do not have any problem waiting a couple of seconds more for the website to load.</p><p>This requirement changed when there was a new feature requirement within our product. Our users are e-commerce merchants and most of them accept “Cash on delivery” as an option while accepting orders and this leaves a lot of room for fraud to occur where somebody places an order and selects the payment method as “Cash on delivery” without the intention to actually buy the product.</p><p>In order to fix this we introduced a feature where the customer who places a COD order gets an automated message on WhatsApp to confirm their order via a link.</p><figure id="w-node-c4a1f5223dce-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c3967fc45b644bd89_23sxkg2VnH0KczPacTa60TpnJXRd675pY-TD7m1i8DzhDDZvosqX5cXv9tXTpgyHrF6Rd_PM_-xv37qWKFQOsc6Bx818rC_OcCfJxhfHC-FojE8HjpC9EXqQL_jVq8DJbeIynX31.png" alt=""></p><figcaption>Automated WhatsApp message to confirm a COD&nbsp;order</figcaption></figure><p>Clicking on this link would open this web page</p><p>‍</p><figure id="w-node-11a95fb1ed82-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951bd3ce595371f24095_FScpPINWKrHotUgTY8aLaV9wlay9dcXXurWkK_Ce-jcsF07e5bxofrU9qjaSspkf5UvCAE40CvgKZ57KouSas0GsPBF_RHbLppjgiOhpGqLN0LbQiVIGd0f7yV9pw9pc2g5t6nEP.png" alt=""></p><figcaption>Reactjs web app used to confirm a COD&nbsp;order</figcaption></figure><p>Now this web page would be accessed by the customers that buy from the merchants that use our application, so the traffic to this page could be very erratic, not to mention the fact that it would come from various parts of the world where the users internet connection would also be erratic and vary according to the region.</p><p>Therefore it did not make sense to host this web page the way the rest of our application is hosted. This web app had the following requirements</p><ul role="list"><li>High availability from any part of the world</li><li>Fast load time</li><li>Ability to handle any amount of traffic</li><li>Not having the need to manage or monitor</li></ul><p>It turns out that all of these things can be achieved if you host the app using a combination of S3 and CloudFront which is the CDN offered by AWS.</p><h4><strong>How to host an application on s3</strong><br></h4><p>There is a comprehensive guide in the AWS documentation on how to do this - <a href="https://docs.aws.amazon.com/AmazonS3/latest/user-guide/static-website-hosting.html" target="_blank">link to documentation</a>.&nbsp;</p><p>The TL:DR for this is to Create an s3 bucket with the same name as the domain/subdomain where you want to host your web app.&nbsp;</p><p>For instance, our web page had to be hosted on<a href="http://cod.superlemon.xyz/" target="_blank"> cod.superlemon.xyz</a>, so this is what the s3 bucket would be called. After this there are a bunch of properties and settings that you would have to change on the bucket which are mentioned in the doc.&nbsp;</p><p>Once this is done, you can test whether it worked or not by using either of the below links based on the region where you are hosted</p><figure id="w-node-30ce7d6ec647-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c849c2b0521c7c2f0_AToH07QToYYzbJ9Hj3iliaW3JMuv0_jHNoaEopFciAvlAf-Ajqr0VpnnKS22_3du4E4vmnV-5Eh3fLajnyQ48kEFHFGjwpKVa_wTl7EXOQu2ZrOX_OgbBq1ba08CWAgeUKTuN0no.png" alt=""></p><figcaption>End points for verifying if the s3 hosting worked or not</figcaption></figure><p>Though the steps in the AWS doc are quite comprehensive, there is one gotcha here that you must keep in mind. If your web app runs on a framework like react which is what we are using, you must make sure that under the “static website hosting” settings of the AWS bucket, you set the index document as well as error document as index.html.</p><figure id="w-node-bc6f0af8aa89-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951ce32edcd6fc8e8c88_JNhV0zwqHr-nOGJWip4t3WDyp9wB8Ld7aXF3KHr30jHAeKpRQVkB_gUIG-Z911vMOLNRZplgM7vUasVAs5Wm7NUtxkTZS6-HI9YzPh2I78EAwCEezHDfzxR08lDBQu7z4aLBhXSX.png" alt=""></p><figcaption>S3 static web hosting settings</figcaption></figure><p>This is to ensure that if you have any URL routes set up in your react application, those routes are honoured.&nbsp;</p><h4><strong>How to put the s3 application behind a CDN</strong><br></h4><p>The above step only completes one step of the process where your application is now residing in s3. But the process is only complete if the application is accessible as a CDN. For this you would have to use CloudFront and configure it to use your s3 bucket as the source. A comprehensive documentation for this process is given <a href="https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-requests-s3/" target="_blank">here</a>.&nbsp;</p><p>There are a few gotchas here as well. The first one being that you will require an SSL certificate to host your application as <strong>https://</strong>. You can get an SSL certificate easily using <a href="https://aws.amazon.com/premiumsupport/knowledge-center/install-ssl-cloudfront/" target="_blank">AWS Certificate manager</a>. This process becomes even more easy if you are using Route53 to manage your domains and subdomains. Even if you use another provider like Godaddy or Bigrock for your domains, I would highly recommend following <a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/migrate-dns-domain-in-use.html#migrate-dns-change-name-servers-with-provider" target="_blank">these steps</a> to plug in your domains to Route53.&nbsp;</p><p>The other gotcha here is once again something to do with reactjs URL routing. If you are using this in your application, there is another step that you have to follow. Under your CloudFront distribution, you must navigate to error pages and create a new custom error response as follows</p><figure id="w-node-a5d3bf85872d-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c40228a0a31b66d85_Xtn0dT_NkHLal0TU8T9vqg_t9AGSxaLs9wvMlIbGxfXCIrH7coSBdYVtZQdkiJJI6oj6WtfPpMjYius2H4gDZrX1_29_TwlPOiHrWeB24cS65VzitHgu9yK5U43S0ByQf3Z4l7uc.png" alt=""></p><figcaption>CloudFront distribution error pages settings</figcaption></figure><figure id="w-node-283c3bc077ec-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c8fbf67d9dc26bd63_XTsEDUFowLfUmq3r3YixmsOrB-fMsmIqSr2r5HiymcBaBxt79EQiVT-1qZM3Aps7l27IZNzbSDSxRCZ-FV7HPUu3utQckFitE1tjnr_Stn9YA_HSgjwjB-rQwiD6lC48o0BhiBVg.png" alt=""></p><figcaption>CloudFront distribution handling 403 error</figcaption></figure><p>This will ensure that if the CDN is not able to find the URL path you specify, it will default to index.html which will handle the routing in case of a reactjs application.&nbsp;</p><p>After finishing all these steps you will receive a url for your CloudFront distribution that looks something like this -<a href="https://dohgltcrfo5nj.cloudfront.net/" target="_blank"> dohgltcrfo5nj.cloudfront.net</a>. You just need to use this URL as an alias and map it to your domain/subdomain which in our case is<a href="http://cod.superlemon.xyz/" target="_blank"> cod.superlemon.xyz</a></p><figure id="w-node-ec229573544f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951ccd92d9716216562a_S_OJrarz5VxJWIVBHKu-wpg2Ine5qGjwdGzIb0Ban3S5Ya41_TbycPcpfnL5IQbu73mNS7oMmqNsrTQjatzC1qUSgsuy5q_CGEL25PITgZlWNJ3xUouo0G-DkloWeR_zPIfW9qA2.png" alt=""></p><figcaption>Route53 subdomain targeting</figcaption></figure><p>And that’s it, it's done! You now have a highly available application which does not need to be monitored or managed. Once you launch your application this way, it is now on a CDN and if you have to update the application in the future, the CDN cache must be invalidated for the changes to take effect. This can be done under the “invalidations” tab.</p><figure id="w-node-4a1c808b9f87-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c64584095bc4b3701_5oYoQ3CFjxE69GyZKHZ1HlboCYnrtEcRAZok14fLisD0VU7JCm1s3416Q5roMUIWFy-XX7PzNWwXQ3ogLygpMhV1AsPciPjqGAs9E9Dyx1drA9qLf6GmDCN_1otqPOhMwJ3ep9ei.png" alt=""></p><figcaption>CloudFront cache invalidation</figcaption></figure><p>Then supply all the paths that have been updated and you would like the CDN cache to invalidate. If you would like to invalidate the entire app, just enter "*".</p><figure id="w-node-33b54a1119a6-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951cde4cdd2f582b3238_7JLSDXaOYN0gpc6dfgedqOpLyO9yFs-WDTLFGyWvpj10HJbsQjynURxaWOBo4TfuI1P8J8Xma0R2D3Z1dEbAm-SLZR-gptJVZkuySjNGJN1DMsMm1ma9h_EBs-lOoL64BlgY0ZlZ.png" alt=""></p><figcaption>CloudFront cache invalidation for specific paths</figcaption></figure><h4><strong>Closing notes</strong><br></h4><p>This approach works great for a use case where the web application is mostly static and can be completely decoupled from the backend applications.&nbsp;</p><p>In terms of cost, with this approach you will only incur the CDN cost since the s3 storage cost for any web application would be quite low and the CDN cost will depend on how much traffic you have so it would scale well with usage.&nbsp;</p><p>For reference, we had around 100k hits on our web page in the month of June and our cost was roughly 0.79$</p><figure id="w-node-724c6c1a2415-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c14ae487790c28040_oj2_EYWg5l2I2CbcSiZVf4aPvLlR2zey8lD9JlrvJP2GtwSc1tOLJ-loHFeSl2qCpweRm5cPgPg6nPhlPs_HtHHmnTNpDr52NwU3zKLXtQcJWFuhqyGPBoCGfK1KJahaqMpN5QWK.png" alt=""></p><figcaption>Our cost for this setup in the month of June</figcaption></figure></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/hosting-your-entire-web-application-using-s3-cloudfront</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809318</guid>
            <pubDate>Sun, 12 Jul 2020 06:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do (Some) Chinese People Pick 'Weird' English Names for Themselves?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23809255">thread link</a>) | @hunglee2
<br/>
July 11, 2020 | https://yiqinfu.github.io/posts/chinese-people-weird-english-names/ | <a href="https://web.archive.org/web/*/https://yiqinfu.github.io/posts/chinese-people-weird-english-names/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-body">
                    

<p>If you’ve spent some time in China, especially as an English teacher, you would probably know a few Tigers, Luckys, or Pizzas. Why do some Chinese people pick “funny” names for themselves?</p>

<p>Here’s my theory: In China, most people share a few common family names and thus distinguish themselves by having unique given names. The opposite is true in Europe and the U.S. – common given names, unique family names. Thus, when Chinese students give themselves English names, they try to pick words that are as unique as possible, similar to how their parents picked their Chinese names.</p>

<h2 id="family-names-unique-in-the-u-s-and-the-u-k">Family Names - Unique in the U.S. and the U.K.</h2>

<p>Below are the three most common family names in China, the U.S., and the U.K., as well as their share of the country’s population. It’s clear that family names are a lot more concentrated in China than in the U.S. or the U.K.</p>

<table>
<thead>
<tr>
<th>China</th>
<th></th>
<th>U.S.</th>
<th></th>
<th>U.K.</th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td><strong>Family Name</strong></td>
<td><strong>% of Population</strong></td>
<td><strong>Family Name</strong></td>
<td><strong>% of Population</strong></td>
<td><strong>Family Name</strong></td>
<td><strong>% of Population</strong></td>
</tr>

<tr>
<td>Wang 王</td>
<td>7.25</td>
<td>Smith</td>
<td>0.79</td>
<td>Smith</td>
<td>0.76</td>
</tr>

<tr>
<td>Li 李</td>
<td>7.19</td>
<td>Johnson</td>
<td>0.62</td>
<td>Jones</td>
<td>0.61</td>
</tr>

<tr>
<td>Zhang 张</td>
<td>6.83</td>
<td>Williams</td>
<td>0.53</td>
<td>Williams</td>
<td>0.46</td>
</tr>
</tbody>
</table>

<p><em>Sources: <a href="http://www.gov.cn/jrzg/2007-04/24/content_594226.htm">China</a>; <a href="https://www.census.gov/topics/population/genealogy/data/2010_surnames.html">U.S.</a>; <a href="https://www.bbc.com/news/uk-england-38003201">U.K.</a></em></p>

<h2 id="given-names-unique-in-china">Given Names - Unique in China</h2>

<p>Next, I plot the concentration of given names for the three countries. The U.S. and U.K. data is from administrative records, while the Chinese data is assembled from my various other projects (n=300k). The latter is by no means a representative sample of the country’s population, but I was able to confirm that the broad patterns in this non-representative dataset are similar to those seen in China’s 2010 Census.</p>

<p><img src="https://yiqinfu.github.io/images/cn-names/10.png" alt="10">
<img src="https://yiqinfu.github.io/images/cn-names/50.png" alt="50">
<img src="https://yiqinfu.github.io/images/cn-names/100.png" alt="100"></p>

<h2 id="conclusion">Conclusion</h2>

<p>A fifth of the Chinese population shares just <em>three</em> family names. Thus, parents try to give as distinct a given name as possible to their children. The typical naming process involves opening a dictionary and finding (often esoteric) characters that embody the values the parents wish to impart on the child. For example, the parents may decide that they like the concept of light and shine. In Chinese, any character with the “sun” radical would work as a given name, e.g. 光, 明, 亮, 闪, 皓, 晖, 昭, 璨, 煜, etc. In English, however, the options would be quite limited, and parents in the U.S. and the U.K. typically do not start the naming process with some “values” in mind anyways.</p>

<p>Many Chinese people adopt the “find-a-unique-word” approach when picking their English names, so that’s why you may know a Shimmer Zhang or a Sparkle Wang. The broader trend in the U.S. and the U.K. is towards more and more unique given names, so maybe Shimmers and Sparkles won’t be that odd in a few decades!</p>

                </section></div>]]>
            </description>
            <link>https://yiqinfu.github.io/posts/chinese-people-weird-english-names/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809255</guid>
            <pubDate>Sun, 12 Jul 2020 06:08:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CRDTs in a Nutshell]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808774">thread link</a>) | @todsacerdoti
<br/>
July 11, 2020 | https://amattn.com/p/riaks_two_contentions_and_crdts.html | <a href="https://web.archive.org/web/*/https://amattn.com/p/riaks_two_contentions_and_crdts.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- The top of the page -->
	
	
	<table>
	<tbody><tr>
		<td>
	<h2 id="subhead">SW engineering, engineering management and the business of software</h2>
		</td>
		<td>
<!-- Begin MailChimp Signup Form -->

<!--End mc_embed_signup-->
		</td>
	</tr>
	</tbody></table>


	<br>

<!-- The middle of the page -->


	
	
	
	
	
	
	<p>

Updated 2020-07-15: 

There is a an updated, expanded version of this post available <a href="http://amattn.com/p/crdts_in_a_nutshell.html">here</a>.

</p>

<p>

Updated 2020-07-13: 

Riak is not really a thing anymore, but the post still stands up well as a very simple explanation of CRDTs. If you swap out any mention of Riak with multi-node, multi-region distributed datastore, you will get basically the same value out of the post.
</p>

<p>Every time I talk to someone about Riak, I mention about how difficult it was to get distributed counters working.  Then I mention about how I ended up implementing a impoverished man’s version of CRDTs (Conflict-free Replicated Data Types).</p>

<p>The usual response is along the lines but doesn’t Riak solve that with their read/write quorum functionality?</p>

<p>The answer is no.</p>

<p>This is a surprising answer to a common misperception of Riak.  So common that at my very first Riak meetup, I asked a variation of the same question.</p>

<p>In a distributed data store such as Riak, you have two basic kinds of inconsistencies that require resolution:</p>

<ol>
<li>Simultaneous Read and Write</li>
<li>Simultaneous Write and Write</li>
</ol>

<p>In case 1, If you are writing a value to a key, that value needs to be replicated to a few other nodes.  This is where the read quorum (for fetches) and write quorum (for stores) come into play: While reading or writing, I must have X number of nodes agree on what the correct value is.  You can set X to be all the nodes to get a strong certainty of getting the most recent value.  If X is 1 then you might give up on getting the latest value in exchange for some improvement to latency.  The typical, balanced and default solution is to set X to be a simple majority of nodes.</p>

<p>In case 2, the write quorum has no practical use.  If you have a 10-node cluster, and some client writes “flub” to nodeA and some other client writes “biggle” to nodeF, then we have something called siblings.  How do you decide who wins?  This is where sibling resolution comes into play.  There are many, many strategies for this.  The simplest involve last-write-wins (which is a good way to lose data if you have a counter).</p>

<p>What happens in practice is that you cannot think about a distributed data store in terms of sets and gets.  You need to approach it more like an operation log.  A counter works well in a distributed system if you are only adding.  Each client simply tags his increment with some arbitrary but unique client ID.  The operation is not get x, then set x+1, but rather <code>counterID:ABC:clientID:XYZ:count:+1</code>.  Since it’s add-only, if you have multiple counters incrementing at once, they will only modify their own clientID entry.  If client <code>PRQ</code> adds 1 to nodeA while client <code>XYZ</code> adds 1, 1 and 1 to nodeF, you would see something like this:</p>

<pre><code>[
    counterID:ABC:clientID:PRQ:count:1
    counterID:ABC:clientID:XYZ:count:3
]
</code></pre>

<p>or posisbly this:</p>

<pre><code>[
    counterID:ABC:clientID:PRQ:count:1
    counterID:ABC:clientID:XYZ:count:1
    counterID:ABC:clientID:XYZ:count:2
    counterID:ABC:clientID:XYZ:count:3
]
</code></pre>

<p>To get the total count of the <code>ABC</code> counter, simply add up all the counts, taking the highest value per clientID. Both of the above examples resolve to 4.  You could eventually whip up some garbage collection to clean up older entries if space is something you care about.</p>

<p>Add-only-counters are great but if you need counters that go up <em>and</em> down, you have to get a little clever.  If you keep two counters, <code>posABC</code> and <code>negABC</code> and subtract, you effectively get a couter that can go in both directions.</p>

<p>And now we have Conflict-free Replicated Data Types:</p>

<blockquote>
<p>CRDTs can be thought of as primitive, resolvable operation logs that can be composed into useful data types.</p>
</blockquote>

<p>In a real world operation, you would do lots and lots of finicky housekeeping around compression of the log as high-volume writes start to get expensive in terms of storage.  But hopefully the concept is clearer.</p>

<p>CRDTS are exciting (in the way that only useful mathematical properties are).  The add-only-counter and the add-only-set versions of these are relatively straight-forward.  Some very smart people have created CRDTs for more complex data types like lists, maps and even directed graphs.  Searching for CRDTs should bring you to the work of <a href="http://research.microsoft.com/apps/video/dl.aspx?id=153540">Marc Shapiro</a>.</p>

<p>If you are patient, the very smart people at Basho are working to integrate CRDTs into Riak itself.</p>

<p>But if you really want to learn this stuff go implement a multi-node, write-heavy counter in a three node Riak cluster (make sure allow_mult=true).  I found it to be a great learning experience.</p>



<br>


<br>


<!-- The bottom of the page -->
	<br>
	
	
	<a href="" id="backup" name="bottom">back ⬆</a>



</div>]]>
            </description>
            <link>https://amattn.com/p/riaks_two_contentions_and_crdts.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808774</guid>
            <pubDate>Sun, 12 Jul 2020 04:20:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Millennials Are Killing Ham Radio]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23808659">thread link</a>) | @rmason
<br/>
July 11, 2020 | https://n0ssc.com/posts/583-millennials-are-killing-ham-radio | <a href="https://web.archive.org/web/*/https://n0ssc.com/posts/583-millennials-are-killing-ham-radio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>I just wanted to write this to start the conversation in order to disrupt amateur radio’s status quo, in response to K0NR’s blog, “<em><a href="http://www.k0nr.com/wordpress/2017/11/internet-destroying-amateur-radio/">Is The Internet Destroying Amateur Radio?</a></em>” This was a great analysis by Bob, and it really paints a picture of the current state of the hobby, including the apparent distaste for internet-connected amateur radio technologies.</p>
<p>And also because nobody else has had an article with this title, so why not?&nbsp; Despite being clickbait, the title isn’t wrong. Millennials are definitely killing ham radio, just like <a href="http://www.businessinsider.com/millennials-are-killing-list-2017-8">they’re killing everything else.</a> Here’s how.</p>
<p>Full disclosure: I am 25 years old. Also and this blog is a rant, full of unverifiable anecdotes and wild propositions, probably a few spelling errors, and many incoherent thoughts. Opinions are my own. QRZ OM’s beware.</p>

<p>The Hobbiest Computer movement of the 80s (all of you with a TRS-80) is now the hacker/maker movement, automating life with microcontrollers, tiny computers, and data centers.</p>
<p>Amateur radio is to The Baby Boomer and Generation X’s youth as IOT is to Millennials and Gen Y.</p>
<p>Interest in “talking to people on the radio” is waning; it’s about talking to machines, and enabling machines to talk to us. That’s why the maker movement is such a hit, especially now as commercial entities have also entered the fray with off the shelf IoT devices. I’m thankful for the the ARRL for realizing this critical market, and repping ham radio at many Makerfaires and Hackercons.</p>

<p>China controls hardware development and manufacturing. We (the US (Silicon Valley)) specialize in software. Homebrewing hardware from scratch isn’t going to be a thing in the next 20 years, because the ashes of failed electronic appliances from which many a ham radio Phoenix was born are no longer durable, salvageable, salvageable goods – once dead and broken, they’re trash.</p>
<p>Now is the time of software homebrewing, and the idea of ham radio as a means to an end.</p>
<p>The evidence:</p>
<ol>
<li>Heathkit, despite their resurrection, can’t figure their $h!+ out. They just can’t. Other kit companies (like Ramsey) have shut down, as well as Radioshack.</li>
<li>Elecraft stopped making thru-hole kits in favor of assembly projects with pre-populated surface-mount PCBs. Many other outfits stopped kit building entirely, because it’s just cheaper to have China do all of the fab and assembly.</li>
<li>Software defined radio, in general, is dominating the radio communications market, both from a hobbyist perspective (RTLSDR, HackRF), an academic one (GNURadio, USRP) to commercial and military (to name a few: cell phones, airband radios; weather, civil air, and tactical radar systems; radio observatories;<a href="https://en.wikipedia.org/wiki/Mobile_ad_hoc_network">&nbsp;MANET</a>; <a href="https://en.wikipedia.org/wiki/Joint_Tactical_Information_Distribution_System">JTIDS</a>)</li>
<li>The non-traditional sense of ham radio is quickly becoming a centerpiece, if not a regular side-item, of <a href="https://hackaday.com/">Hackaday</a>&nbsp;articles, makerspaces, and makerfaires.</li>
</ol>
<p>However,&nbsp; I will admit the <a href="https://heilsound.com/amateur-radio-post/the-pine-board-project/">Ham Nation Pineboard project</a> is particularly popular, and is doing a great thing bringing tubes back into focus and captivating/inspiring viewers to try it themselves, but I’m going out on a limb saying it’s probably most popular with their target demographic…a young person might be following along but it’s not changing the face of the hobby anytime soon. One of the student members of&nbsp; W0EEE (Missouri S&amp;T) is a die-hard tube fanatic, but to everyone else, he’s the tube guy.</p>
<p>Speaking of which – target demographic. The target demographic of every single amateur radio show, podcast, club, media outlet, society, magazine, livestream, or otherwise, is not young people.</p>
<p>The ARRL however, has been making a lot of good strides to engage the new generation of hams (<a href="http://www.arrl.org/news/arrl-expands-initiative-to-fire-up-collegiate-amateur-radio-clubs">1</a>)(<a href="https://www.instagram.com/arrlhq/">2</a>)(<a href="http://www.arrl.org/news/arrl-now-on-snapchat">3</a>)(<a href="http://www.arrl.org/news/arrl-represented-at-world-maker-fair-in-new-york-city-school-club-to-exhibit">4</a>), yet still, the ARRL can only do so much to interest younger people, which takes away resources from engaging their demographic core of white male retirees.&nbsp; For example – why no youth editor? I was the last one, before my editor, Khrystyne K1SFA, left the ARRL, which left a hole requiring them to kill the Youth Editor (<a href="http://n0ssc.com/blogs/arrlyouthcolumns">the articles still remain on their website</a>), and The Amateur Amateur (<a href="http://gary-ross-hoffman.com/Ham/index.html">which still exists at his website</a>). But why no top-level Youth Coordinator? Why not a report on the effort of, or a collaboration between, our Section Youth Coordinators in the <a href="http://www.arrl.org/field-organization">ARRL Field Organization Structure</a>? Are we all just relying on <a href="http://www.arrl.org/news/carole-perry-wb2mgp-set-to-host-her-30th-hamvention-youth-forum">Carole Perry</a>‘s and the late <a href="http://oralhistory.boulderlibrary.org/interview/oh1264/">Ellie and Rip Van Winkel’s</a>&nbsp;of the ham radio world to inspire and educate young people about ham radio? Surely there’s opportunity for ARRL, as well as every ham radio club out there.</p>

<p>No. From my experience over the last seven years, digital Amateur Radio is not intrinsically exciting to young people, as many have been touting. It is a lot better than voice and CW, but still exists the fact that as an individual, it’s a troubling process to decide where to spend your (mother’s) money – $300 on a DSTAR radio, $100 for a DMR, both full of people talking about how robotic they sound, or $400 for an HF station to do digital data modes, full of canned responses (PSK31) or hardly any response at all (FT8).</p>
<p>These are also communication between people, which begs the titular question posed by K0NR. People-to-people communication is trivial, and although some young hams (me) find it really cool to talk to people beyond shouting distance with the raw elements of a radio station,what’s much more interesting and impactful to the next generation is is the idea of people-to-machine communication. In other words, Digital Voice is dumb, Digital Data is smart, and the only ways to utilize digital data are explicitly NOT provided by the commercial manufacturers of amateur radio(1), but instead by Adafruit, Ubiquiti; HackRF, RFSpace, and USRP; and soon <a href="https://faradayrf.com/">FaradayRF</a>, among others.</p>

<h2>Remote Operating for HF</h2>
<p>Here’s where I disagree with K0NR’s analysis.</p>
<blockquote>
<p>Perhaps more importantly, we can’t really stop the impact of new technology. Oh, I suppose the amateur radio community could petition the FCC to restrict [internet assisted] use of ham radio. There could be regulations that limit the use of the internet being interconnected with Part 97 radio operation.</p>
</blockquote>
<p>I believe that remote operating, and other internet-assisted means of ham radio operation, are critical to youth engagement.</p>
<p>RemoteHamRadio is the shining example of where ham radio operating is heading. they have an awesome <a href="http://www.remotehamradio.com/youth/">Youth Program</a>, allowing young people that are:</p>
<p>– 25 years old or younger<br>– A General class or higher license<br>– A member of the ARRL<br>– Interested in or Experienced with in DXing/Contesting</p>
<p>to operate remote online stations for free.</p>
<p><a href="http://www.remotehams.com/">Remote Hams</a> is a totally free alternative, but it’s up to the host to restrict operation, which is frustrating when you’re clicking through servers, only to find it’s locked by membership to whatever radio club is hosting it.</p>
<p>Finally <a href="http://websdr.org/">WebSDR</a> and <a href="http://sdr.hu/openwebrx">OpenWebRX</a> are always open to everyone to receive tons of spectrum, remotely.</p>
<p>Despite that, it’s ultimately a much MUCH better solution in the short term for young hams to operate remotely, than it is to persuade their mom’s to fork up a relative ton of money for a radio, antenna, a pole if no trees are around…etc.</p>
<p>Because young people do not often have access to the the kind of money an HF radio station requires, I strongly believe to captivate more young people, we need to do more of one of these two things.</p>
<ol>
<li>Promote your club’s shack, your own shack to young people.</li>
<li>Put your shack on a remote service provider for others to use when you’re not.</li>
</ol>
<p>For young people to join the hobby, it’s critically important to&nbsp;<strong>bring ham radio where the young people are,&nbsp;</strong>which is, for the most part, the internet.</p>
<p>If I knew this when I was younger, my mom would have been around $900 richer!</p>
<h2>Ham Radio Hackathons</h2>
<p>One thing I’m thinking of&nbsp; starting up are Ham Radio Hackathons. I mentioned it<a href="http://n0ssc.com/posts/560-ham-radio-analysis-paralysis"> in a previous blog</a> which has surprisingly gotten a lot of traction with my <a href="http://n0ssc.com/wp-content/uploads/2017/11/T2miAyF.png">tiny contingent of readers</a>.</p>
<p>A hackathon isn’t a coding competition. It’s explained well in <a href="https://medium.com/hackathons-anonymous/wtf-is-a-hackathon-92668579601">this Medium article.</a> It goes even further than that, not limited to coders and engineers, but open to thinkers, doers, philosophers, system engineers, math people, teachers, students, artists, stakeholders…anyone with an interest in <strong>solving a problem with technology. </strong></p>
<p>Ham radio has a bunch of problems with technology.</p>
<ol>
<li>It’s far behind the curve. We’re spitting out digital modes faster than K9PG can work a sweep, but compared to what’s already on the shelf, why would anyone bother with ham radio?</li>
<li>When I think about software like Log4OM, LOTW, eQSL, and HRD, I get frustrated. It’s great software, and many volunteer hours have poured into their development, but it’s so feature dense, developed in vacuums, hard to use, buggy, and lacking in UX.&nbsp; A good example of software is Fldigi – it’s fast, and light…hence *<strong>FL*</strong>digi. APRS is really nifty, especially <a href="http://aprs.fi/">aprs.fi</a>, but a person needs too much stuff or really expensive radios to get on it via RF (most people seem to be going direct to APRS-IS anyway) and getting into the development side of it is making me pull my hair out, just starting with the fact it’s based on the Bell 202 modem invented in 1972!!! Are you $#!++!n&amp; me!? I mean, what a fantastic utilization of resources…in 1978. <a href="https://faradayrf.com/">It’s time for something fresh, now.&nbsp;</a></li>
<li>There are dozens of ham radio websites stuck in 1990 (two of them are in K0NR’s blog (<a href="http://www.on4kst.com/index.php">1</a>)(<a href="http://www.pingjockey.net/">2</a>)…I’d&nbsp; almost argue that ham radio is killing the internet!), it seems like every ham radio developer has to repeatedly reinventing the wheel with logging programs, everyone still uses email reflectors, tons of ham radio apps just crash upon startup, the Digital Voice debate (when we should really focus on digital data, breaking through the baudrate limitation, and interlinking everything), the logistical challenges of testing (3 VEs to proctor a test in person, c’mon…that’s not to say I don’t disagree with the lack of practical on-the-air knowledge in the newbie amateur radio generation; however I don’t think that’s not a fault of the amateur, that’s a fault on the lack of elmership to personally show them how it’s done).</li>
<li>What gets us …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://n0ssc.com/posts/583-millennials-are-killing-ham-radio">https://n0ssc.com/posts/583-millennials-are-killing-ham-radio</a></em></p>]]>
            </description>
            <link>https://n0ssc.com/posts/583-millennials-are-killing-ham-radio</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808659</guid>
            <pubDate>Sun, 12 Jul 2020 03:53:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US states' Covid-19 infection rates over the last 30 days – States above 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808469">thread link</a>) | @askaboutio
<br/>
July 11, 2020 | https://askabout.io/covid-19/ask/what-are-the-current-infection-rates-for-us-states/?activeCUSSIRTab=Above%201 | <a href="https://web.archive.org/web/*/https://askabout.io/covid-19/ask/what-are-the-current-infection-rates-for-us-states/?activeCUSSIRTab=Above%201">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://askabout.io/covid-19/ask/what-are-the-current-infection-rates-for-us-states/?activeCUSSIRTab=Above%201</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808469</guid>
            <pubDate>Sun, 12 Jul 2020 03:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Feature Flags Do and Don’t Make Sense]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808253">thread link</a>) | @nomdep
<br/>
July 11, 2020 | https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.redbubble.com/i/canvas-print/If-Else-Software-Developer-Joke-Beer-Lover-by-VaSkoy/33140544.5Y5V7" target="_blank"><img data-attachment-id="282" data-permalink="https://software.rajivprab.com/flag/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png" data-orig-size="896,1480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="flag" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=620" src="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" alt="" srcset="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182 182w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=364 364w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=91 91w" sizes="(max-width: 182px) 100vw, 182px"></a></figure></div>



<p>Over the past years, I’ve worked in multiple teams adopting very different strategies when it comes to feature flags. I’ve seen the pros and cons of both, and over time, I found myself disagreeing with any fundamentalist position on their use. There is a lot of nuance to this topic, and I think it is worth considering more carefully the various scenarios where feature flags do and do not make sense.</p>



<h2>The Reasons For</h2>



<p>There are a few major scenarios where feature flags make a lot of sense. The first is when it’s used for <a rel="noreferrer noopener" aria-label="A/B testing (opens in a new tab)" href="https://en.wikipedia.org/wiki/A/B_testing" target="_blank">A/B testing</a>, where you absolutely do want different behaviors for different users, based on their randomly assigned treatment. I’ve seen this strategy employed extremely well at Amazon where new features are gated by a “feature flag” that is actually controlled by an internal A/B testing framework. The framework randomly exposes some Amazon customers to the new feature, and then monitors their subsequent behavior in order to estimate the business impact of launching the feature.&nbsp;</p>



<p>I was initially skeptical, but was soon won over by how easy the framework was to use, and the valuable insights it provided on the benefits (or drawbacks) of certain features. “Flavor of the month” decisions were replaced with real data. And none of this is possible without the use of “feature flags” to dynamically toggle new features.</p>



<hr>



<p>Another great use case for feature flags, is when you’re working on a very complex epic that require many different sub-tasks to be completed in different parts of the system. Sub-tasks that are too numerous and invasive to be done in a single pull-request. </p>



<p>In such cases, trying to keep all these disparate changes in side-branches and coordinating a simultaneous merge and deployment, is a recipe for disaster. It’s far more manageable to gate any disruptive changes behind a master flag, merge and deploy all the sub-commits incrementally, and do a flag-flip once all the pieces are in place.</p>



<hr>



<p>One last use case for feature flags, is when you do not have control over your deployments. For example, consider the Facebook Android app, which contains code contributed by hundreds of different teams, all combined and deployed as a single binary. In such scenarios, performing rollbacks can be infeasible. For practical, political, bureaucratic or even marketing reasons. In such cases, feature flags allow your team to toggle new functionality or mitigate risky changes, without having to rollback or deploy any new binaries.</p>



<h2>Risk Aversion</h2>



<p>The above are all fantastic use cases for feature flags, but I’ve also seen teams get bogged down by policies that overreach in their use. For example, mandating that every single code change should be behind a feature flag, <em>“just in case we made a mistake”</em>.</p>



<p>Risk management should indeed be a priority for all teams. But there are better ways of doing this than relying on feature flags, especially if your team has control over its own deployments. The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/" target="_blank">vast majority of your bugs should be caught by your automated test suite</a> and/or QA process. And the last few stragglers should be handled using <a rel="noreferrer noopener" aria-label="incremental deployments, production alarms and rollbacks (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">incremental deployments, production alarms and rollbacks</a>.</p>



<p>Besides, as soon as any problem is detected, the recommendation at places like Google is to <a rel="noreferrer noopener" aria-label="rollback first and ask questions later (opens in a new tab)" href="https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons" target="_blank">rollback first and investigate the problem later</a>. When things are on fire, the last thing you want to do is root-cause the bug and figure out which flag-flip will safely fix the problem. And that may not even fix things – there’s no guarantee that even if your teammate tried to put his changes behind a feature flag, he didn’t inadvertently introduce a bug that cannot be solved by a flag-flip.</p>



<p>Feature flags are no substitute for the ability to do binary rollbacks, and they definitely aren’t a substitute for having a great automated test suite and a robust QA process. If you’re relying on feature flags to remedy production bugs, you should stop and evaluate your team’s practices. Risk aversion is often a smell of your team <a href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank" rel="noreferrer noopener" aria-label="entering into a doom loop which will only get worse and worse with time (opens in a new tab)">entering into a doom loop which will only get worse and worse with time</a>.</p>



<h2>Death By Feature Flags</h2>



<p>You may be wondering at this point why we shouldn’t use feature flags anyway. After all, <em>“defense in depth” …</em> and it never hurts to have more fine-grain flexibility right?</p>



<p>While feature flags are great in some cases, we should also keep in mind their costs. Software engineering is primarily an exercise in managing complexity. And each feature flag immediately doubles the universe of corner cases that your programmers have to understand, and your code is required to handle. <em>“But what would happen if Foo is enabled, Bar is disabled, and we do independent A/B tests on Baz and Kaz on the same day?”</em> In my experience, this combinatorial explosion in complexity can and <strong>will</strong> lead to bugs. Not to mention slowing down the speed at which your team can make any changes.</p>



<p><em>“But these feature flags are only temporary. You should be removing them as soon as possible!”</em></p>



<p>Sure, and we should also not allow our tech debt to accumulate and we should follow every single best-practice religiously. Unfortunately, this never happens in any corporate environment. Even in great teams, tech debt often gets de-prioritized in the face of new requests. Newcomers to the team or those on their way out, aren’t always disciplined enough to clean up their flags after a successful rollout. And sometimes, these tasks simply slip through the cracks and get forgotten.</p>



<p>There is no better illustration of this than the KCG debacle where a financial firm lost half a billion dollars and almost went bankrupt in 30 minutes, partly due to dead code that was behind a feature flag.</p>



<blockquote><p><a href="https://www.bugsnag.com/blog/bug-day-460m-loss"><em>The cause of the failure</em></a><em> was due to multiple factors. However, one of the most important was that a flag which had previously been used to enable Power Peg… Power Peg had been obsolete since 2003, yet still remained in the codebase some eight years later.</em></p><p><em>In 2005, an alteration was made to the Power Peg code which inadvertently disabled safety-checks which would have prevented such a scenario. However, this update was deployed to a production system at the time, despite no effort having been made to verify that the Power Peg functionality still worked</em></p></blockquote>



<hr>



<p>Feature flags are a powerful tool that can help you experiment with new features, manage the rollout of complex epics, and mitigate the problems associated with not controlling your team’s deployments. </p>



<p>But they come at a significant cost, in the form of code complexity, tech debt, slower development speeds, and inevitably, bugs. </p>



<p>As tempting as it may be, there is no silver bullet here. Weigh the pros against the cons, and use this tool judiciously when it makes sense to do so.</p>
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808253</guid>
            <pubDate>Sun, 12 Jul 2020 02:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PS/2 keyboard on a 65C02 breadboard computer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808183">thread link</a>) | @krallja
<br/>
July 11, 2020 | https://jacob.jkrall.net/ps2-on-65c02 | <a href="https://web.archive.org/web/*/https://jacob.jkrall.net/ps2-on-65c02">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body">
<div>
  <div>
    
    <div>


<div id="postunit-ps2-on-65c02">
  <div>
    <div>
        <h3><a href="https://jacob.jkrall.net/ps2-on-65c02">PS/2 keyboard on a 65C02 breadboard computer</a></h3>
        <p><img src="https://jacob.jkrall.net/image/2020/ps2_hero.jpg" alt="A 6502-based breadboard computer with a PS/2 keyboard"></p>

<p>I’ve been following Ben Eater’s series on
<a href="https://eater.net/6502">building a 6502 computer on a breadboard</a>.
Once I got the 65C22 VIA working with a bigger 4-line x 20-character
LCD display, I wondered if I could interface the computer directly
with an external keyboard. The IBM Personal System/2 (PS/2), released
in 1987, had what became a very commonly used keyboard and mouse
connector, which uses some convenient electrical signals for
interfacing with even-more-ancient technology like the
WDC 65C02 and 65C22 this breadboard computer is based on.</p>

<h2 id="physical-layout">Physical layout</h2>
<p>Electrically, PS/2 is very simple: power, ground, clock, and data.
The clock is driven by a microcontroller inside the keyboard, at a
rate around 10-16.7 kHz. The data line is valid when the clock is low.
Data and clock are open-collectors, so they can be connected directly to
the computer with pullup resistors.</p>

<p>I acquired a PS/2 connector and soldered four wires to the correct pins.
+5V on power, 0V on ground, and the keyboard flashed its three status lights
so I know I didn’t short it out or install the pins backwards. That’s good.</p>

<p><img src="https://jacob.jkrall.net/image/2020/ps2_solder.jpg" alt="PS/2 connector soldered to four wires"></p>

<p>I connected the PS/2 clock wire to <code>NMIB</code> (pin 6 on the DIP-40 W65C02S),
and tied it to the 5V rail using a 1kΩ pull-up resistor.
Because I was making hardware changes anyway, I also added a pushbutton
to <code>IRQB</code> (pin 4 of the W65C02S) for an easy way to trigger a second
kind of interrupt. (It helped a lot when debugging - in the interrupt
service handler, I could print whatever info I wanted.)
<img src="https://jacob.jkrall.net/image/2020/ps2_clk.jpg" alt="PS/2 Clock line tied to 65C02S NMIB"></p>

<p>Similarly, the data line is tied to <code>PA0</code> (pin 2 of the 40-pin W65C22)
with a 1kΩ pull-up resistor as well.</p>

<p><img src="https://jacob.jkrall.net/image/2020/ps2_data.jpg" alt="PS/2 Data line tied to VIA PA0"></p>

<h2 id="6502-interrupts">6502 interrupts</h2>
<p>The two interrupt pins on the 6502 are used slightly differently.
The non-maskable interrupt (<code>NMIB</code>) is edge-triggered, which generally
means only one interrupt source can use it. But that’s great for PS/2,
since we only want to interrupt on each clock signal once.</p>

<p>The interrupt request (<code>IRQB</code>) is level-triggered: the processor will
generate interrupts as long as interrupts are enabled and the input is low.
This means it’s much easier to service multiple devices, but there has to
be some way to clear the interrupt on the other end - and we don’t really have
that ability on the PS/2 bus, so it’s not a good choice, unless we want
to add some glue logic. That sounds expensive, and I don’t have a lot of
space left on my breadboard.</p>

<h2 id="using-some-nicer-vasm-flags">Using some nicer <code>vasm</code> flags</h2>
<p>The WDC65C02S supports some additional opcodes, so I’m going to let vasm
understand those with the <code>-wdc02</code> flag. I also added <code>-chklabels</code>, <code>-wfail</code>,
and <code>-x</code>. These warn when a label matches a mnemonic/directive, return an
error code on warnings, and show an error when referencing an undefined
symbol, respectively.</p>

<h2 id="do-nothing-interrupts">Do-nothing interrupts</h2>
<p>First, define two no-op interrupt handlers, <code>nmi</code> and <code>irq_brk</code>.</p>

<figure><pre><code data-lang="nesasm"><span>irq_brk:</span>
  <span>rti</span>

<span>nmi:</span>
  <span>rti</span></code></pre></figure>

<p>Set up the vectors for each of them - this replaces the <code>.org $fffc</code>
from Ben Eater’s video:</p>

<figure><pre><code data-lang="nesasm">  <span>.</span><span>org</span> <span>$fffa</span>
  <span>.</span><span>word</span> <span>nmi</span>
  <span>.</span><span>word</span> <span>reset</span>
  <span>.</span><span>word</span> <span>irq_brk</span></code></pre></figure>

<p>In our reset handler, we will need to enable interrupts with</p>

<figure><pre><code data-lang="nesasm">  <span>cli</span></code></pre></figure>

<p>Now, it’s time to declare and initialize some memory. First,
name four bytes in the zero-page:</p>

<figure><pre><code data-lang="nesasm"><span>KEY_BUF_X</span> <span>=</span> <span>$00</span>
<span>KEY_READ_X</span> <span>=</span> <span>$01</span>
<span>PS2_BIT_NUMBER</span> <span>=</span> <span>$02</span>
<span>PS2_NEXT_BYTE</span> <span>=</span> <span>$03</span></code></pre></figure>

<p>The actual values aren’t important -
they’re pointers to bytes in the first 256B of RAM.</p>

<p>The first two, <code>KEY_BUF_X</code> and <code>KEY_READ_X</code> are offsets into a
256-byte circular array. Let’s name that array:</p>

<figure><pre><code data-lang="nesasm"><span>KEY_BUF</span> <span>=</span> <span>$0200</span></code></pre></figure>

<p>The second two variables are used for decoding the PS/2 byte. For now,
let’s initialize them all to zero in the <code>reset</code> handler.</p>

<figure><pre><code data-lang="nesasm">  <span>stz</span> <span>KEY_BUF_X</span>
  <span>stz</span> <span>KEY_READ_X</span>
  <span>stz</span> <span>PS2_BIT_NUMBER</span>
  <span>stz</span> <span>PS2_NEXT_BYTE</span></code></pre></figure>

<p>All of this does nothing, but we’ve reserved all the space in RAM
needed to decode the raw PS/2 byte stream.</p>

<h2 id="handling-the-interrupts">Handling the interrupts</h2>
<p>As I mentioned before, the PS/2 clock rate is between 10-16.7 kHz, and the
data line is only valid for the low half of the clock cycle.</p>

<p>My computer has a 1MHz clock, so that means we have 1M/16.7k = 59.88 cycles
to completely handle the NMI. And the data is only valid in the first half.</p>

<p>The WDC65C02 takes 6 (or 7?) cycles to process an interrupt, and can only
process an interrupt once the previous instruction has completed, so
we may already be 12 or 13 cycles in by the time we start the very first
instruction of the interrupt handler!</p>

<p>We’ll read PORTA from the 65C22 VIA, and need to use some bitmasking to get
the first bit. It would be very convenient if the high bit were set, instead
of the low bit, but I’m already using <code>PA7</code> for the <code>E</code> pin on the LCD, and
don’t want to break compatibility with Ben’s code just for convenience.</p>

<p>So, during the interrupt routine, I’ll rotate <code>PA0</code> into the <code>PA7</code> position,
and then mask it out.</p>

<p>Define the <code>PA7</code> bit mask:</p>

<figure><pre><code data-lang="nesasm"><span>KEY_DATA</span> <span>=</span> <span>%10000000</span></code></pre></figure>

<p>And update the NMI handler to write the PS/2 bit into <code>KEY_BUF</code>:</p>

<figure><pre><code data-lang="nesasm"><span>nmi:</span>
  <span>pha</span> <span>; preserve A register</span>

  <span>lda</span> <span>PORTA</span> <span>; the data bit is in the low bit of A</span>
  <span>ror</span>       <span>; the data bit is in the carry flag</span>
  <span>ror</span>       <span>; the data bit is in the high bit of A</span>
  <span>and</span> <span>#KEY_DATA</span> <span>; all other bits have been cleared</span>


  <span>; store A in KEY_BUF[KEY_BUF_X]</span>
  <span>phx</span>
  <span>ldx</span> <span>KEY_BUF_X</span>
  <span>sta</span> <span>KEY_BUF</span><span>,</span><span>x</span>
  <span>inc</span> <span>KEY_BUF_X</span>

  <span>; restore X,A in correct order</span>
  <span>plx</span>
  <span>pla</span>

  <span>; complete the interrupt</span>
  <span>rti</span></code></pre></figure>

<h2 id="decoding-the-bitstream">Decoding the bitstream</h2>
<p>Decoding a PS/2 bitstream takes a few more cycles than we can afford
in our non-maskable interrupt handler. So, the handler is wasteful
and writes the bit samples as bytes in a 256-byte circular buffer.</p>

<p>In our main loop, we can chase after the bitstream using a simple
state machine.</p>

<p>The states are defined by the number of bits we’ve seen.</p>

<p>First bit (state 0) is a start bit.
It’s followed by eight data bits (states 1-8), least-significant-first.
Then, there’s a parity bit (state 9).
Then, there’s a stop bit (state 10).</p>

<figure><pre><code data-lang="nesasm"><span>loop:</span>

<span>ps2_check_bit:</span>
  <span>lda</span> <span>KEY_READ_X</span>
  <span>cmp</span> <span>KEY_BUF_X</span>
  <span>beq</span> <span>loop</span>

<span>process_one_ps2_bit:</span>
  <span>lda</span> <span>PS2_BIT_NUMBER</span>
  <span>cmp</span> <span>#0</span>
  <span>beq</span> <span>ps2_start_bit</span>
  <span>cmp</span> <span>#9</span>
  <span>beq</span> <span>ps2_parity_bit</span>
  <span>cmp</span> <span>#10</span>
  <span>beq</span> <span>ps2_stop_bit</span>
  <span>; otherwise, fallthrough to ps2_data_bit</span>

<span>ps2_data_bit:</span>
  <span>; move the $80/$00 into the top bit of PS2_NEXT_BYTE</span>
  <span>ldx</span> <span>KEY_READ_X</span>
  <span>lda</span> <span>PS2_NEXT_BYTE</span>
  <span>ror</span>
  <span>and</span> <span>#$7F</span>
  <span>ora</span> <span>KEY_BUF</span><span>,</span><span>x</span>
  <span>sta</span> <span>PS2_NEXT_BYTE</span>

<span>next_ps2_bit:</span>
  <span>; advance the state machine</span>
  <span>inc</span> <span>PS2_BIT_NUMBER</span>
  <span>; advance the read-bit pointer</span>
  <span>inc</span> <span>KEY_READ_X</span>
  <span>; check if there are more bits to decode</span>
  <span>jmp</span> <span>ps2_check_bit</span>

<span>ps2_start_bit:</span>
  <span>; TODO: we could verify the start bit is correct</span>
  <span>jmp</span> <span>next_ps2_bit</span>
<span>ps2_parity_bit:</span>
  <span>; TODO: we could verify the parity bit is correct</span>
  <span>jmp</span> <span>next_ps2_bit</span>

<span>ps2_stop_bit:</span>
  <span>lda</span> <span>PS2_NEXT_BYTE</span>
  <span>; TODO: we could verify the stop bit is correct</span>
  <span>; TODO: we have successfully decoded the PS/2 byte</span>
  <span>;       into the A register.</span>
  <span>stz</span> <span>PS2_BIT_NUMBER</span>
  <span>inc</span> <span>KEY_READ_X</span>
  <span>; give the main loop (currently empty) a chance to run</span>
  <span>jmp</span> <span>loop</span></code></pre></figure>

<h2 id="reading-scan-codes">Reading scan codes</h2>
<p>PS/2 does not send ASCII, it sends scan codes. Most PS/2 keyboards
use the “Set 2” codes. The characters we are concerned with send a
one-byte “make” code when the key is pressed (and a few times per
second while the key is held), and a two-byte “break” code when the
key is released.</p>

<p>A nice abstraction would be to decode these scancodes into a buffer,
which would allow us to do line editing and so forth, but I’m just
going to print all the characters I recognize directly to the LCD.</p>

<p>In <code>ps2_stop_bit</code>, add a</p>

<figure><pre><code data-lang="nesasm">  <span>jsr</span> <span>print_ps2_key</span></code></pre></figure>

<p>and let’s go implement that now.</p>

<p>First, we need to create a map for the PS/2 scan codes. You can
sort of see how the key matrix is wired in the keyboard.</p>

<figure><pre><code data-lang="nesasm">  <span>.</span><span>align</span> <span>8</span>
<span>ps2_scan_codes:</span>
  <span>;       0123456789ABCDEF</span>
  <span>.</span><span>asc</span> <span>"??????????????`?"</span> <span>; 0</span>
  <span>.</span><span>asc</span> <span>"?????Q1???ZSAW2?"</span> <span>; 1</span>
  <span>.</span><span>asc</span> <span>"?CXDE43?? VFTR5?"</span> <span>; 2</span>
  <span>.</span><span>asc</span> <span>"?NBHGY6???MJU78?"</span> <span>; 3</span>
  <span>.</span><span>asc</span> <span>"?,KIO09??./L;P-?"</span> <span>; 4</span>
  <span>.</span><span>asc</span> <span>"??'?[=?????]?</span><span>\</span><span>??"</span> <span>; 5</span></code></pre></figure>

<p>Now, add another byte to the zero page so we can ignore break codes:</p>

<figure><pre><code data-lang="nesasm">  <span>PS2_IGNORE_NEXT_CODE</span> <span>=</span> <span>$04</span>

  <span>; ... in `reset`:</span>
  <span>stz</span> <span>PS2_IGNORE_NEXT_CODE</span></code></pre></figure>

<p>Finally, let’s implement the <code>print_ps2_key</code> subroutine:</p>

<figure><pre><code data-lang="nesasm"><span>print_ps2_key:</span>
  <span>; if we received #$F0 previously, ignore this byte</span>
  <span>bit</span> <span>PS2_IGNORE_NEXT_CODE</span>
  <span>bmi</span> <span>code_ignored</span>

  <span>; A is scan code.</span>
  <span>; see if we got a break code</span>
  <span>cmp</span> <span>#$F0</span>
  <span>beq</span> <span>ignore_next</span>

  <span>; Bounds check ps2_scan_codes</span>
  <span>cmp</span> <span>#$5F</span>
  <span>bpl</span> <span>too_high</span>

  <span>; index into ps2_scan_codes</span>
  <span>tax</span>
  <span>lda</span> <span>ps2_scan_codes</span><span>,</span><span>x</span>
  <span>jsr</span> <span>print_char</span>
  <span>rts</span>

<span>too_high:</span>
  <span>rts</span>

<span>ignore_next:</span>
  <span>lda</span> <span>#$FF</span>
  <span>sta</span> <span>PS2_IGNORE_NEXT_CODE</span>
  <span>rts</span>

<span>code_ignored:</span>
  <span>stz</span> <span>PS2_IGNORE_NEXT_CODE</span>
  <span>rts</span></code></pre></figure>

<p>There’s still a ton more work to do, like Shift, Backspace, arrow keys
and even outputting lines to the correct place on the screen. Like I
mentioned above, it would probably make more sense to store these ASCII
codes in a line buffer, or whatever suits your application’s purpose.
You could even use another circular buffer with chasing pointers.</p>

<p>But hey, at least we can say <code>HELLO, WORLD,</code> and that’s what matters.</p>

<h2 id="postscript-1-day-later">Postscript (1 day later)</h2>
<p>Fairly frequently, I saw extraneous NMIs. Since I’m not doing any
error checking on the stop/start/parity bits, this would appear as a
shifted bit in the byte stream. The first thing I changed was using
a 1kΩ resistor on the NMI pin instead of 1MΩ. I thought
the higher resistance was causing the voltage to rise too slowly.
It certainly helped, but I still could rarely type a full 80-character
page of text without seeing a desynchronization. I tried using a
faster 1.8432 MHz oscillator, to see if my interrupt code was too slow,
but that neither made sense, nor fixed the issue. (A 7.3728 MHz
oscillator was too fast for the existing LCD code. Needs <code>NOP</code>s.)
Finally, I wondered if the additional power demanded by the keyboard
(and its long cable) was still causing voltage drops.
I added another 10µF capacitor to the power rails,
near the PS/2 power wires, and now it is much better.
I still see desynchronization if I mash on the keyboard, but it’s
waaaaay more usable than it was.</p>

    </div>
  </div>
</div>

    </div>
  </div>
</div>
</div></div>]]>
            </description>
            <link>https://jacob.jkrall.net/ps2-on-65c02</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808183</guid>
            <pubDate>Sun, 12 Jul 2020 02:22:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reward behaviour, win a customer for life]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808056">thread link</a>) | @cyberomin
<br/>
July 11, 2020 | https://cyberomin.github.io/business/2020/07/11/brand-loyalty.html | <a href="https://web.archive.org/web/*/https://cyberomin.github.io/business/2020/07/11/brand-loyalty.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
          <p><span></span> read
          </p>
          <a name="topofpage"></a>
          <p>I have been thinking about brand loyalty for a while now and I thought I’d share some rough thoughts about this. Nothing ground breaking, but one that I think most businesses can begin to apply if they have the right tools. Let’s start with the <em>Loyalty</em></p>

<h3 id="loyalty">Loyalty</h3>
<p>Brand loyalty is hard to build, especially in the face of increasing competition. Why should a person stick to a brand? While exceptional customer service is great and one that all business should take seriously, in most cases, it may not be enough. 
People will begin to want more if exceptional customer service becomes  the common denominator(in an ideal world).</p>

<p>So how else do you keep people coming back? I will suggest rewarding their behaviour and create a <em>cool</em> factor in the process. This both helps the people feel great about their choices and benefits the brand too.</p>

<p>Prints, radio, TV and in recent times, online advertisement have all been effective marketing tools. While there’s nothing generally wrong with these mediums, I, as a customer, will appreciate a tangible reward as a way of marketing. It could be as simple as shopping vouchers. I strongly believe there’s a high likelihood of another person seeing this and wanting a piece of the action.</p>

<p>But today, I will propose another form of reward; experiences. Give people experiences as a form of reward. I strongly believe people rarely forget experiences, especially if it makes them feel good about themselves.</p>

<h3 id="aspiration">Aspiration</h3>
<p>Most people, if not everyone is aspirational. It’s inherently a human nature to aspire to something; social class, economic status, security, etc. We are always looking forward to the next level and this is perfectly okay.</p>

<p>Brands who are looking to build mindshare for a long time, especially within a certain income class should position themselves as aspirational brands. Little wonder why people begin to feel “cool” with themselves the moment the snag their first Apple product; iPhone, Watch, Mac, iPad. It’s the cool factor and satisfaction that these products give.</p>

<h3 id="mechanics-of-the-reward-system">Mechanics of the reward system</h3>
<p>In this case, these brands can use the loyalty/rewards system to build their own cool. For example, if every time you shopped at a certain location or make a certain transaction with some organisation you get a point, these organisations can now begin to segment its user base based on point. Let’s take a case simple scenario here.</p>

<p>Customers with a certain amount of points will qualify for Bronze, Silver, Gold and Platinum. These points can now be converted for different things, in this case, I will suggest experiential. Bronze member can get a full body massage at a spa or a one-month gym membership, Silver members can get a one-month gym membership, Gold Members can get both a full body massage and a one-month gym membership. The platinum members can, on the other hand, get a full body massage, a one-month gym membership and a private networking event with other platinum members once a month for a quarter.</p>

<p>As you begin to use these offers, you fall to a certain level, if a Bronze member uses their spa points, they fall to level zero, when a Silver member use either of their offers, they fall to Bronze and can work their way back up. When a Gold member use one of their offers, they fall to the Silver level, they can choose to build back their points and stay as Gold members or even progress to the Platinum membership band. Platinum members don’t fall, they maintain that status for as long as they want, but the moment they activate/use an offer they have 6 months to use the benefits or risk losing it.</p>

<p>The business can then change the rewards on a yearly basis. It is one way to keep the users hook, especially when the rewards will always come as a surprise.</p>

<p>This actually explain why I go to SPAR for groceries instead of ShopRite.</p>

<h3 id="cross-marketing">Cross Marketing</h3>
<p>The great things about the offers are that it forms an opportunity for cross-marketing for all the participating businesses. People who go to the gym can suddenly discover that brand X will offer free gym membership if they signed up for their services and the same goes for the spa. The gym and spa can now have opportunities to market to new potential customers. A win-win for everyone.</p>

<h3 id="brand-equity">Brand equity.</h3>
<p>Brand equity is a really big deal. People associate themselves with brand names than the actual product themselves. Little wonder why people will be quick to remind you that they are wearing Gucci than talk about the feel of the cotton fabric. You almost can’t place value to it. And as people watch close friends and allies begin to associate with the cool of your brand, they will want the same for themselves.</p>


          <p>I'll love to hear from you</p>
          <p><em>Do you want to say hello? <a href="mailto:celestineomin@gmail.com">Email me</a></em> - celestineomin@gmail.com</p>
          <p><em>I tweet at <a href="https://twitter.com/cyberomin">@cyberomin</a></em></p>
          <!-- Go to www.addthis.com/dashboard to customize your tools -->
          
          


          <!-- Go to www.addthis.com/dashboard to customize your tools -->
          <em>If you enjoyed this post, please consider sharing it.</em>
          

          
  
    
    
    <a href="http://disqus.com/">comments powered by </a>

    
  

  
  
  
  

  

        </section></div>]]>
            </description>
            <link>https://cyberomin.github.io/business/2020/07/11/brand-loyalty.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808056</guid>
            <pubDate>Sun, 12 Jul 2020 02:03:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a No-Slot MIDI Interface on the Apple ][ Game I/O Socket]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23807949">thread link</a>) | @empressplay
<br/>
July 11, 2020 | https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/ | <a href="https://web.archive.org/web/*/https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://paleotronic.com/wp-content/uploads/2020/07/Practical-Computing-1983-June-121-copy-1024x438.jpg" alt="" title="Practical Computing 1983 June -121 copy">
</figure>

<p><span>In today’s world of plug-and-play peripheral devices, it is difficult to understand the fundamentals of what is happening at the lower levels.<span>&nbsp; </span>How does the computer connect to the device?<span>&nbsp; </span>How does it communicate with the device?<span>&nbsp; </span>How does the software make the device do its magic?</span></p>
<p><span>My name is Eric Rangell and I was a teenager in the 1980s.<span>&nbsp; </span>My first computer was an Apple //e in 1983.<span>&nbsp; </span>Before my family got a computer, I learned Basic programming from my brother’s college textbook and practiced writing programs on paper for a year before the Apple found a home in my brother’s room.<span>&nbsp; </span>With the limited computer time I had, I practiced coding, debugging, and refining my programs until they did what I wanted.<span>&nbsp; </span>The Apple ][ series of computers was designed so that owners could learn everything about how their machines worked if they took the time to study the available documentation and experiment with the machine.<span>&nbsp; </span>Today, early Apple computers can help young people grasp the fundamentals of how a computer works, and that will help them as they progress in their studies and careers.</span></p>
<p><span>In this article I will walk through a simple project that can be built using an Apple ][ series computer that has an internal Game I/O socket.<span>&nbsp; </span>It uses one of the Annunciator digital outputs to send MIDI data to a MIDI instrument.<span>&nbsp; </span>The process of building it and persisting through any problems you encounter will give you a sense of mastery and enjoyment, give you a tool to express your creativity, and challenge you to continue tinkering with the project as you learn more advanced computer science concepts.<span>&nbsp; </span>Parents and teachers are encouraged to learn how to build this project and help children work through it as they build an electronic device, write simple programs in Basic to control the device, and imagine additional applications that can use the device.</span></p>
<p><span>MIDI can play notes and music on keyboard synthesizers, as well as send commands to modules which control music playback, drum patterns, and even lighting.<span>&nbsp; </span>MIDI uses a very simple communication protocol to send binary messages to instruments.<span>&nbsp; </span>There really is nothing magical about it – the computer is just sending bytes which represent commands such as “Play a middle C”, “Stop playing the middle C”, “Change the instrument sound to Violin”, “Change the volume”.<span>&nbsp; </span>The objective of this project is for the student to understand how the computer varies voltage levels on an output port using specific timings according to a protocol that the musical instrument receiving the data understands.<span>&nbsp; </span>By building the interface from scratch, the student knows that the data is traveling on wires that they connected, and controlled by software that they wrote, using a driver program that is conceptually easy to understand.</span></p>
<p><span>Before you start building the interface, read this entire article and gather the parts you need.<span>&nbsp; </span>Many modern musical instruments have USB interfaces for MIDI.<span>&nbsp; </span>Look for older synthesizer keyboards with the round 5 pin DIN MIDI sockets, or USB MIDI interfaces that have the round connectors.<span>&nbsp; </span>You may need a MIDI coupler in order to connect a MIDI cable to one of those interfaces.</span></p>
<p><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture1.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture1-404x1024.png" alt="" width="150" height="380" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture1-404x1024.png 404w, https://paleotronic.com/wp-content/uploads/2020/07/Picture1-118x300.png 118w, https://paleotronic.com/wp-content/uploads/2020/07/Picture1.png 500w" sizes="(max-width: 150px) 100vw, 150px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture1-404x1024.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture1-404x1024.png 404w, https://paleotronic.com/wp-content/uploads/2020/07/Picture1-118x300.png 118w, https://paleotronic.com/wp-content/uploads/2020/07/Picture1.png 500w"></a>Since this project is going to be built on an Apple ][ game I/O socket, the first task is to build a cable that makes the socket pins more accessible outside the computer.<span>&nbsp; </span>The best connection is a 16 pin to 16 pin cable where one end plugs into the socket and the other end plugs into a breadboard.<span>&nbsp; </span>If you cannot obtain this cable, you can make your own using ribbon cable with Male to Male pin connectors.<span>&nbsp; </span>If this MIDI interface is the only project you want to build on the Game I/O socket, there are only 3 pins that need to be routed externally.<span>&nbsp; </span>On an Apple //e or //gs, 2 of those pins (+5V and GND) can come from the 9 pin Game connector on the back panel of the computer using a DE-9 connector.</span></p>
<p><span>The following pictures illustrate various options for connecting the game socket to a breadboard.<span>&nbsp; </span>Keep track of which pins on the external connector correspond to which pins on the internal connector.<span>&nbsp; </span>On the Apple //gs, pin 1 is in the upper left corner of the socket.<span>&nbsp; </span>For all other Apples, pin 1 is in the lower right corner of the socket.<span>&nbsp; </span>Pins are numbered from pin 1 to pin 8, then pin 9 is on the opposite side of pin 8, then pins 9-16 are numbered using the remaining pins.</span></p>
<figure id="attachment_13185"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture2.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture2.png" alt="" width="974" height="608" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture2.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture2-300x187.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture2-768x479.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture2.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture2.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture2-300x187.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture2-768x479.png 768w"></a><figcaption>16 pin ribbon cable connection from Apple ][+ Internal Game I/O socket to breadboard. Pin 1 is in the upper-right corner of the connector shown.</figcaption></figure><figure id="attachment_13190"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture3.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture3.png" alt="" width="974" height="550" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture3.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture3-300x169.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture3-768x434.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture3.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture3.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture3-300x169.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture3-768x434.png 768w"></a><figcaption>Ribbon cables connected to 2 pairs of headers: 8 pin and 6 pin. Pins 9 and 16 are not used on the Apple ][+ and Apple //e, so only 6 pins are needed on one of the cables.</figcaption></figure>
<figure id="attachment_13191"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture4.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture4.png" alt="" width="974" height="329" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture4.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture4-300x101.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture4-768x259.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture4.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture4.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture4-300x101.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture4-768x259.png 768w"></a><figcaption>Ribbon cables inserted into Apple //e Game I/O socket. Note that pins 9 and 16 are unconnected.</figcaption></figure>
<figure id="attachment_13192"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture6.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture6.png" alt="" width="150" height="278" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture6.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture6-162x300.png 162w" sizes="(max-width: 150px) 100vw, 150px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture6.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture6.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture6-162x300.png 162w"></a><figcaption>Single wire connected to pin 15 (Annunciator 0) of Apple //e internal game socket</figcaption></figure>
<p><span><b>Testing your wiring</b></span></p>
<p><span>Before you proceed any further, you want to make sure all wires are properly connected and that the signals from the Apple are reaching the breadboard.<span>&nbsp; </span>While there are only 3 pins needed to build the MIDI interface project, take the time to test the additional signals available on the Internal Game I/O socket.<span>&nbsp; </span>All pin numbers below refer to pin numbers on the Internal Game I/O socket.</span></p>

<p><span>1. Test the voltage between +5V (pin 1) and GND (pin 8).<span>&nbsp; </span>Use a multimeter to verify that the voltage level coming to the breadboard is at least +5 volts. The red wire connects pin 1 to the side holes for Power and the green wire connects pin 8 to side holes for Ground. Connect the probes of the multimeter to the Power and Ground of the breadboard, and set the dial to measure voltage.</span></p>

<p><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture8.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture8-250x300.png" alt="" width="200" height="240" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture8-250x300.png 250w, https://paleotronic.com/wp-content/uploads/2020/07/Picture8.png 449w" sizes="(max-width: 200px) 100vw, 200px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture8-250x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture8-250x300.png 250w, https://paleotronic.com/wp-content/uploads/2020/07/Picture8.png 449w"></a></p>
<figure id="attachment_13193"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture5.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture5.png" alt="" width="200" height="364" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture5.png 304w, https://paleotronic.com/wp-content/uploads/2020/07/Picture5-165x300.png 165w" sizes="(max-width: 200px) 100vw, 200px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture5.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture5.png 304w, https://paleotronic.com/wp-content/uploads/2020/07/Picture5-165x300.png 165w"></a><figcaption>Homemade DE9 cable for rear Game I/O socket of Apple //e or //gs.</figcaption></figure>
<p><span>2. Test the digital logic from the Annunciator outputs.<span>&nbsp; </span>Each of the 4 Annunciator outputs is controlled by a pair of soft-switches which are mapped to memory locations.<span>&nbsp; </span>One of each pair sends a digital HIGH signal to the output, and the other soft-swich of the pair sends a digital LOW signal.</span></p>



<p><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture10.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture10-300x285.png" alt="" width="200" height="190" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture10-300x285.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture10.png 412w" sizes="(max-width: 200px) 100vw, 200px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture10-300x285.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture10-300x285.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture10.png 412w"></a>To test the HIGH signal for Annunciator #0 (pin 15) go into the Apple Monitor by typing CALL -151 from Basic, and enter the hex address: C059, as shown below.<span>&nbsp; </span>The Apple will return a value for that memory location, which you can ignore.<span>&nbsp; </span>Now you can test to verify that Pin 15 has a HIGH signal.</span></p>


<p><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture9.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture9-150x150.png" alt="" width="150" height="150" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture9-150x150.png"></a><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture11.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture11-150x150.png" alt="" width="150" height="150" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture11-150x150.png"></a>While the multimeter is connected, enter the hex address: C058 in the Apple Monitor.<span>&nbsp; </span>The voltage should drop to a very low value.</span></p>



<p><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture12.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture12-300x279.png" alt="" width="300" height="279" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture12-300x279.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture12.png 491w" sizes="(max-width: 300px) 100vw, 300px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture12-300x279.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture12-300x279.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture12.png 491w"></a></p>
<p><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture13.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture13-166x300.png" alt="" width="166" height="300" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture13-166x300.png 166w, https://paleotronic.com/wp-content/uploads/2020/07/Picture13.png 308w" sizes="(max-width: 166px) 100vw, 166px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture13-166x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture13-166x300.png 166w, https://paleotronic.com/wp-content/uploads/2020/07/Picture13.png 308w"></a><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture14.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture14-148x300.png" alt="" width="148" height="300" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture14-148x300.png 148w, https://paleotronic.com/wp-content/uploads/2020/07/Picture14.png 272w" sizes="(max-width: 148px) 100vw, 148px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture14-148x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture14-148x300.png 148w, https://paleotronic.com/wp-content/uploads/2020/07/Picture14.png 272w"></a></span></p>
<p><span>You can also test the logic of the </span><span>Annunciators using a Digital Logic Probe, as shown left.<span>&nbsp; </span>Connect the probe terminals to the +5V and GND signals on the breadboard, then touch the tip of the probe to the Annunciator pin.<span>&nbsp; </span>The photos below show how the Digital Logic Probe responds when it detects logical HIGH and logical LOW voltages on Annunciator 0.</span></p>




<p><span><b>Inverters and Buffers</b></span></p>
<p><span>The MIDI specification defines the MIDI OUT Circuit as follows:</span></p>
<p><span>The signal from the transmitting device (labeled UART in the diagram below-left) passes through 2 inverters, then a 220 Ohm resistor, and is sent to Pin 5 on the circular 5 pin DIN connector labelled MIDI OUT.<span>&nbsp; </span>The +5V signal is sent through a 220 Ohm resistor to Pin 4 of the MIDI OUT connector.<span>&nbsp; </span>Pin 2 is connected to Ground, and the shield of the MIDI cable.<span>&nbsp; </span>Pins 1 and 3 are not connected.<span>&nbsp; </span>Polarity matters because a MIDI cable will connect your MIDI OUT port to the MIDI IN port of a musical instrument.<span>&nbsp; </span>The signals sent on your MIDI OUT port need to drive a phototransistor inside an opto-isolator in the MIDI IN circuit.<span>&nbsp; </span>When the signal from the UART is negative, the current loop is completed and the opto-isolator receives the signal.<span>&nbsp; </span>Communication is established by following a timing protocol for flipping the signals to represent the bits and bytes of MIDI messages.<span>&nbsp; </span>In this project we will control the timing of the messages with the Apple’s 6502 timing, to illustrate that there is nothing magical going on – if we get the timing right and follow the protocol, we will successfully communicate with a MIDI instrument.</span></p>
<figure id="attachment_13210"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture15.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture15.png" alt="" width="974" height="610" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture15.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture15-300x188.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture15-768x481.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture15.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture15.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture15-300x188.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture15-768x481.png 768w"></a><figcaption>Source: International MIDI Association, Document No. MIDI-1.0, August 5, 1983.</figcaption></figure>
<p><span>Inverters change the input signal from HIGH to LOW, or LOW to HIGH.<span>&nbsp; </span>So, two inverters will leave the input signal unchanged.<span>&nbsp; </span>The two inverters form a buffer, which ensures that the signal does not get degraded if voltage fluctuates due to additional loads on the circuit.<span>&nbsp; </span>While it may be possible to drive the signal directly from the Apple without using the buffers, that introduces an element of uncertainty that can make your device unreliable under certain conditions.<span>&nbsp; </span>So initially we will build the circuit with two inverters (following the MIDI spec), and then test modifying it to use only one inverter (by logically inverting all the signals sent by the driver software).</span></p>
<p><em><strong><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture17.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture17-224x300.png" alt="" width="224" height="300" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture17-224x300.png 224w, https://paleotronic.com/wp-content/uploads/2020/07/Picture17.png 375w" sizes="(max-width: 224px) 100vw, 224px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture17-224x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture17-224x300.png 224w, https://paleotronic.com/wp-content/uploads/2020/07/Picture17.png 375w"></a><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture18.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture18-225x300.png" alt="" width="225" height="300" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture18-225x300.png 225w, https://paleotronic.com/wp-content/uploads/2020/07/Picture18.png 375w" sizes="(max-width: 225px) 100vw, 225px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture18-225x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture18-225x300.png 225w, https://paleotronic.com/wp-content/uploads/2020/07/Picture18.png 375w"></a>Testing your chips</span></strong></em></p>
<p><em><span>Use a logic probe to verify the outputs of each chip for each set of possible inputs.<span>&nbsp; </span>Use batteries or an electronics kit to test the chips before you use them in your project.<span>&nbsp; </span>The photos below show how one inverter of a 7404 Hex Inverter chip can be tested with a logic probe.<span>&nbsp; </span>The probe’s +5V and GND alligator clips are connected to the corresponding buses on the breadboard.<span>&nbsp; </span>The probe tip then is touched to the logic gate output.<span>&nbsp; </span>In the left photo, pin 1 (the yellow wire) is connected to +5V, so the logic probe reads LOW on pin 2.<span>&nbsp; </span>In the right photo, pin 1 is connected to GND, so the logic probe reads HIGH on pin 2.<span>&nbsp; </span>For both circuits, Pin 7 is connected to GND and pin 14 is connected to +5V.</span></em></p>
<p><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture16.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture16.png" alt="" width="974" height="933" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture16.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture16-300x287.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture16-768x736.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture16.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture16.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture16-300x287.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture16-768x736.png 768w"></a></p>
<p><span>There are several integrated circuit chips that can be used to build the buffer needed for this circuit:</span></p>
<p><span>4001: QUAD NOR – contains 4 NOR (NOT OR) gates</span></p>
<p><span>4011: QUAD NAND – contains 4 NAND (NOT AND) gates</span></p>
<p><span>7404: HEX INVERTER – contains 6 inverter circuits.</span></p>
<p><span>The two breadboards above show the three chips that may be used for this project.<span>&nbsp; </span>The left breadboard shows the 4011 chip on top and 4001 chip on the bottom.<span>&nbsp; </span>The right breadboard shows …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/">https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/</a></em></p>]]>
            </description>
            <link>https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23807949</guid>
            <pubDate>Sun, 12 Jul 2020 01:43:25 GMT</pubDate>
        </item>
    </channel>
</rss>
